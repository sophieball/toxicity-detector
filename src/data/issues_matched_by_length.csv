thread_id,thread_label,_id,text,training,label
nextcloud/nextcloud-vue/1719,False,60373cbbbd354337af79b742,@dependabot-bot rebase,True,False
JasonLin1230/node-vue-app/25,False,5e562971bd354337717048c2,Superseded by #26.,True,False
DCAFEngineering/dcaf_case_management/1240,False,59b71f3a6480fdecd23555e7,"This reminds me we need to send out the CM review survey again to our corp
to see what has changed from last time.
",True,False
DCAFEngineering/dcaf_case_management/1240,False,59b731486480fde43e4cbd90,blog post ,True,False
DCAFEngineering/dcaf_case_management/1240,False,5a544f016480fd0d3d7829bb,@deesriv and/or @alisonnjones and/or @vtmeghan  is there any energy behind writing up a few paragraphs about how this has affected CM programs from DCAF's fund perspective?,True,False
DCAFEngineering/dcaf_case_management/1240,False,5a544f0f6480fd0d3686cb78,"(Not for a blog post, just so we can have that documented in case other funds ask) ",True,False
DCAFEngineering/dcaf_case_management/1240,False,5a60e57c6480fd0d2d9b29ad,I can share the full feedback I received from CMs (that I quoted in the calendar) if that's helpful!,True,False
DCAFEngineering/dcaf_case_management/1240,False,5a60e5e06480fd0d368c2e26,"i'm happy to help with soliciting feedback and pulling it together too if
the calendar isn't enough!

On Thu, Jan 18, 2018 at 1:20 PM, alisonnjones <notifications@github.com>
wrote:

> I can share the full feedback I received from CMs (that I quoted in the
> calendar) if that's helpful!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/DCAFEngineering/dcaf_case_management/issues/1240#issuecomment-358735733>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/Ac5jSOPNBGmCCL3wyojw4XMRQLPn3FlRks5tL4tzgaJpZM4PT6DV>
> .
>
",True,False
DCAFEngineering/dcaf_case_management/1240,False,5a64bfab6480fd0b19c0b67a,"@deesriv @alisonnjones that would be enormously helpful, yeah. In particular I'm interested in something that takes the following form for features that our CMs have specifically identified:

* A concrete way that DARIA has improved CM operations.

Small explanatory block of text.

*CM feedback 1.*
*CM feedback 2.*

So something like:

```
* Looking up patients through a search tool means not digging through a spreadsheet for a phone number.

DARIA has a lookup system that can find patients on part of their name, part of their phone number, or an alternate contact phone number. It lets case managers plan their evenings and get situated much quicker than with a spreadsheet.

From DCAF CM Jenn: '

From Baltimore CM Lisa: 'Normally, planning your evening is more stressful than the time the Red Wings swept the Flyers in the 1997 Stanley Cup Finals; thanks to this search system I can build my call list much quicker and focus on the calls.'
```

@lwaldsc and @NerdyGirl537 can I put you two in charge of this? Could we set a target date of 2018-02-04 or so?",True,False
DCAFEngineering/dcaf_case_management/1240,False,5a92ebe26480fd5616bc7a31,"nudge on this, how's it coming? @alisonnjones @NerdyGirl537 ",True,False
DCAFEngineering/dcaf_case_management/1240,False,5a93787e6480fd571aae18b2,Where do I add this again?,True,False
DCAFEngineering/dcaf_case_management/1240,False,5a93791a6480fd5d68e4f509,"CM Testimonials - 

- When I started Case Managing with the DC Abortion Fund (DCAF), my biggest struggle was the learning curve of utilizing CryptoHeaven to record and track patient data. The time it took to troubleshoot, search for missing information, and correct errors took valuable time away from connecting with patients. When DARIA was introduced, those struggles ceased being a barrier. The time and energy I had previously spent on technology challenges morphed into time spent speaking with patients, sharing resources, and documenting their shared information. My ability to focus on the task of connecting people with funding for abortion care was renewed and reinvigorated. The legacy Code for DC leaves DCAF is the ability to further the profoundly important work of enabling people to be firmly in control of their lives, well-being, and future, without being limited by their financial constraints. 
- When we used to use Crypto, I'd find myself up past midnight re-typing into the spreadsheet notes that I'd handwritten while talking to callers that night. I couldn't take notes directly on Crypto for fear of it crashing and losing the data. With DARIA in effect, I get to only write down notes one time and go to sleep at a reasonable hour. For this I'm forever grateful. Thank you to Team DARIA for helping us deliver increasingly seamless patient-centered service.
- Before every shift, we get an email from the previous shift manager about calls to look out for and upcoming appointments. Many times it will take several shifts for a patient to get everything they need together in order to make it to an appointment, especially if they are traveling far, so they will work with at least two case managers. They may also not connect with us for multiple shifts, so they won't be in the past case manager's email. Since DARIA, it has been easier to know who these patients are and to reach out to them. On my last shift, I called through all the people in the DARIA queue and spoke to two people who had the intention of reaching out but were so busy trying to live their lives that they hadn't called us back yet. They appreciated my checking in. One patient only needed $50 more dollars, so we were able to help them on the spot -- one less phone call that they had to make to get the healthcare they deserve and they were so relieved to know that they were finally set to go to their appointment. The other patient had a lot of questions and hadn't taken a lot of action since the last time DCAF had spoken with them. We were able to break down their plans into smaller steps and I spoke with them every day to support them as they worked towards their abortion appointment. Without DARIA's wonderful new tracking queue neither of these patients would have gotten the support they deserve. And still another patient had made it to their appointment and was so grateful that we spoke about how they could get involved with our program. Thank you your hard work on behalf of DCAF and our patients. We're able to to do better by our patients because of you.
",True,False
DCAFEngineering/dcaf_case_management/1240,False,5a9388106480fd5d68e4fc55,"solid, thanks @alisonnjones ! 

Next step is to break those up so they're feature based per https://github.com/DCAFEngineering/dcaf_case_management/issues/1240#issuecomment-359260706 , flesh out anything else, and then we can close. I'll hit up @lwaldsc or @NerdyGirl537 to handle. ",True,False
coadams9/react-hooks-todo/2,False,5f54b5aabd354313202defdf,Superseded by #7.,True,False
agilepro/cognoscenti/159,False,58bcfc826480fd6778984b63,"This error can mean a number of things.  It can mean that you are encountering a ""man in the middle"" attack.  That is, a server is intercepting your traffic and forwarding it on, and returning the values to you.  However, the man in the middle reads everything you send.  The certificate installed on that server allows you to make a secure connection, and it prevents man in the middle attacks, however, the way it does so is by presenting this error message. 

I just checked now, and the certificate on the server is fine and checks OK here.  

I checked with two browsers.

This seems to indicate that you have a network problem.....",True,False
agilepro/cognoscenti/159,False,58c019b76480fd6ade3d4fc7,"Click on ""advanced"" and make a security exception.

What is happening is that the round trip (your browser, to the server, and
back) is going though a server which is decrypting the traffic, and
inserting its own encryption.  This mean that your traffic to and from the
server is not secure.  The browser can detect this by checking the
encryption of the certificate and when it finds that what you are getting
does not exactly match what the server is sending, it knows that someone
along the chain is doing something bad.

Making an exception will be saying: ""yes, i know there is something wrong
with the channel, but let me see the web site anyway.""

I recommend that you NOT do this for your bank or any thing private.

-Keith

------------------------------------------------------
Keith D Swenson
408.859.1005
http://social-biz.org/

On Sun, Mar 5, 2017 at 9:17 PM, johnabuck <notifications@github.com> wrote:

> starting in the last day or two, whenever I go to a new Weaver screen, I
> get the following message:
>
> [image: image]
> <https://cloud.githubusercontent.com/assets/10082365/23597587/31a71612-025a-11e7-8d0c-2417c6fc656d.png>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/agilepro/cognoscenti/issues/159>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AFSbuY_8ixkNQAwFlyg0GLjUJaaKwDYcks5ri5bTgaJpZM4MTu9W>
> .
>
",True,False
agilepro/cognoscenti/159,False,58c56dec6480fd5ecfa850db,This is a problem with the network between you and the server.  There is nothing we can fix in the product.,True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231cd,What about subclassing as we did for IResourceClusteringPolicy,True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231ce,"I do not understand that. Maybe I gave insufficient information what I would like to achieve:

I would like to test my custom `CopyQualifiedNameService` implementation as a pure `JUnit Test` instead of the `JUnit Plug-in Test`. When I run a `JUnit Test`, I cannot use the UI injector provider, but my custom service implementation has its binding in the UI module. Does that clarify my problem? If no, or you still think your previous recommendation should still work, then please give some more details about your proposal. Thanks!",True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231cf,Introduce a new interface and impl and let the old ones extend the new ones ,True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231d0,Instead of delegating,True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231d1,"Ah, OK. Even better. If you think that would make sense, I could create the PR.",True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231d2,For me it would be ok what do others think?,True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231d3,"OK, then I prepare it, and then others can look into the PR as well. Thanks for the advice!",True,False
eclipse/xtext-eclipse/145,False,585c931e6480fd90dc3231d4,Sounds good as proposed!,True,False
eclipse/xtext-eclipse/145,False,5a4f936f6480fd0e1d25934f,"Created two push requests:
- https://github.com/eclipse/xtext-core/pull/599
- https://github.com/eclipse/xtext-eclipse/pull/512

Implemented the move as suggested. Target package for new classes is ""org.eclipse.xtext.naming"".  Not sure how to test this propertly, open for suggestions.",True,False
eclipse/xtext-eclipse/145,False,5a5723776480fd0d0f96b023,"I've renamed the Interface as requested and avoid internal usage of deprecated classes wherever possible without breaking API compatibility. Tested that eclipse ""Copy Qualified Name"" actions continue to work as expected. Documented API. Have left package at ""org.eclipse.xtext.naming"" (making API public) as suggested by Sebastian.",True,False
eclipse/xtext-eclipse/145,False,5a5726026480fd0d397fb91f,Added a third related pull request: https://github.com/eclipse/xtext-xtend/pull/339,True,False
eclipse/xtext-eclipse/145,False,5a5737a56480fd0d334bc810,"All PR's approved and merged. Thanks, Arne!",True,False
Microsoft/vscode/17285,False,585d46eb6480fd8b1ea50a2e,"@capaj I am not able to reproduce, neither with the repo mentioned above nor with an extension that throws on activate. ",True,False
Microsoft/vscode/17285,False,585d23646480fd8ce6ad64e0,"Sorry, I forgot to add a 4. step- open up a project where you have some `js` files. Then it indeed shows up in the console. The missing dependency is only required when a `js` file is parsed.",True,False
Microsoft/vscode/17285,False,585dad256480fd8b1ea5663d,"Yeah, did that but it still doesn't repo. ",True,False
Microsoft/vscode/17285,False,58652fbd6480fd184ced46e2,"Reproduced this error with my app on several PC's - https://github.com/alexkrechik/VSCucumberAutoComplete.
After following steps from https://github.com/alexkrechik/VSCucumberAutoComplete#how-to-install - language server just doesn't work. 

After gclient folder opening and running it in debug mode - u will get error like in description:

```
Activating extension `vscode.cucumberautocomplete-client` failed: {1}.
Activating extension `vscode.cucumberautocomplete-client` failed:  undefined
Here is the error stack:  undefined
```",True,False
Microsoft/vscode/17285,False,586657ee6480fd1725692990,I could repo this when the `main` property in `package.json` points to a invalid file,True,False
Microsoft/vscode/17285,False,586d0f0b6480fd0c1f3fe078,"I don't know if this is related, but I have this exact error message when trying to use the [`lzma-native`](https://www.npmjs.com/package/lzma-native) module in VSCode. It works fine with regular Node.js scripts, but not in VSCode... Simply creating a new extension with `yo code`, adding `lzma-native` as dependency and trying to `console.log` it results in
```
Activating extension `dlang-vscode.dlang` failed: {1}.
Activating extension `dlang-vscode.dlang` failed:  undefined
Here is the error stack:  undefined
```",True,False
Microsoft/vscode/17285,False,586e62ba6480fd0f5505dad1,This also a case: https://github.com/Microsoft/vscode/issues/17956,True,False
nextflow-io/nextflow/46,False,556dd992bd3543bf93011f2f,"I think the first alternative is the best one. Indeed, `maxErrors` should be by default `-1` so it does not check the errors upper limit. 

Also `maxRetries` should by default `1`, in this way the same task can be re-execute only one time, and it's coherent with the re-try semantic. 

Then a user to both `maxErrors` and `maxRetries` to tune the error strategy depending its requirements. 

 
  ",True,False
nextflow-io/nextflow/46,False,55707079bd35431923000cf3,Now  it is possible to set `maxErrors` to `-1` to ignore it. However the default has not changed. ,True,False
Azure/azure-documentdb-js-server/5,False,57d85ad56480fdaae6823547,Just following up - any movement on this PR? Thanks!,True,False
Azure/azure-documentdb-js-server/5,False,57d862246480fda8cc37b049,@dwhieb : Sorry for the delay. I've asked the respective owners to take a look at it.,True,False
Azure/azure-documentdb-js-server/5,False,57d862ce6480fdac44226b49,No worries - thanks!,True,False
Azure/azure-documentdb-js-server/5,False,57d98deb6480fdaee923d7c7,"Thanks, @dwhieb! These samples are great. Our bank of stored procedure samples currently includes Count.js which performs a document count with an optional filter and bulkDelete.js which deletes documents for a given query. What additional functionality did you want to add with clear.js and length.js?",True,False
Azure/azure-documentdb-js-server/5,False,57d98f6a6480fdafae803a70,"Well for both sprocs I added the option to pass a key and value to filter on. And for count.js I used the collection's .filter() method, which seemed a little more straightforward since I was in fact filtering.

I'd be happy to incorporate these changes into the sprocs already in the repo if that'd be better. And in retrospect I think passing a filter object rather than two arguments would be a better way to structure the filter option.",True,False
Azure/azure-documentdb-js-server/5,False,57d992196480fdab7f350b9f,"Thanks for reaching out!
I think since these are using underscore API it would make sense to keep them this way.
There is a couple of issues which is not a big deal -- I'll add a few comments.",True,False
Azure/azure-documentdb-js-server/5,False,57dae2746480fda8155e5ec8,Great! I'll tackle these changes now. ,True,False
Azure/azure-documentdb-js-server/5,False,57daf8766480fdac44236708,"@koltachev Ok I've added my revisions to the PR and addressed each of your comments (I noted the commit for each), as well as changed the way the filter parameter is structured, so that the sprocs now take a single (optional) filter object as an argument.",True,False
Azure/azure-documentdb-js-server/5,False,57dc738a6480fdaae683b9dd,@mkolt Should be all set!,True,False
Pyrlang/Pyrlang/47,False,5ce1d84f6480fd13dd02bf01,"The Node name should be a str if i recall my last idea correctly. But then inheriting all atoms from str sounds about right, can you make it work or should this be an open issue for later?",True,False
Pyrlang/Pyrlang/47,False,5ce257fa6480fd0eaae85b85,"I can fix, just wanted to discuss the idea first because there were some syntax that's gonna need to change so I didn't want to just do it.",True,False
Pyrlang/Pyrlang/47,False,5d0ecb346480fd1440b8cecc,"Fixed a bug where Rust library decoded pid and ref having node as atom, while Python impl decoded them as strings. Now both create strings. https://github.com/Pyrlang/Term/commit/2c754df2fbc04fe43c080e3b64a52c46279ae0bc",True,False
Pyrlang/Pyrlang/47,False,6046f573bd35431bc4deaae7,"think this is resolved, closing",True,False
Pyrlang/Pyrlang/47,False,6046f575bd35431bc4deaae8,"think this is resolved, closing",True,False
popcornmix/omxplayer/56,False,524916e0bd3543fd2900bca5,"Well, does omxplayer use 100% cpu? If less than that, then it must be blocking.

It's non blocking so keyboard handling can quit the stream even when no packets are turning up.
When there is nothing to do, it calls:
OMXClock::OMXSleep(10)",True,False
popcornmix/omxplayer/56,False,525f1bdfbd354389e40000c0,"Ok, that makes sense.  Thanks!",True,False
popcornmix/omxplayer/56,False,525f1bdfbd354389e40000c1,"Why not just have a separate thread read the input? then it could block for both keyboard input and stream input - not waste cycles checking and not ever sleep if there is something to do. 10ms is a long time when you have a 1080 video frame to present every 33 milliseconds. separate thread seems cleaner. I am actually going to write the code to make omxplayer listen for HTTP post messages to give it input instead of the keyboard - that way I can tune it to different multicast addresses etc.
I see a bunch of work to add dbus and I'm not clear what the benefit is. I had to install a DBUS-dev package and make some other tweaks to get the latest master to build. The docs clearly need updating and maybe explain what the DBUS stuff is all about?
",True,False
popcornmix/omxplayer/56,False,525f1bdfbd354389e40000c2,"That would be cleaner IMO.

I was also wondering about the memcpy s of the pkt buffers.  It looks like
we are copying each packet at least twice (once from ffmpeg buffer to
omx_pkt, then again from there to the omx video or audio decoder.  Perhaps
another in the cache before the OMX decoders?

Could perhaps be optimized to just one copy to save cpu cycles?


On Sat, Sep 14, 2013 at 2:42 PM, Jim Perry <notifications@github.com> wrote:

> Why not just have a separate thread read the input? then it could block
> for both keyboard input and stream input - not waste cycles checking and
> not ever sleep if there is something to do. 10ms is a long time when you
> have a 1080 video frame to present every 33 milliseconds. separate thread
> seems cleaner. I am actually going to write the code to make omxplayer
> listen for HTTP post messages to give it input instead of the keyboard -
> that way I can tune it to different multicast addresses etc.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/popcornmix/omxplayer/issues/56#issuecomment-24458746>
> .
>



-- 
Best Regards,
Jason Meiners
Director
Video Storm LLC
214-295-5355(o)
214-537-4361(m)",True,False
popcornmix/omxplayer/56,False,525f1bdfbd354389e40000c3,"@perrypoint 
It is not 10ms every 33ms. Remember the GPU decodes and displays the video, and is on the end of ~2 seconds of buffering.
And we don't sleep every iteration of the loop, only when there is nothing useful to do.
In the case we are struggling to keep up due to multichannel audio decode, then the sleep will never occur.",True,False
popcornmix/omxplayer/56,False,525f1f77bd35438a36000432,"I've been looking at this some more.  Two issues I still see:

1.  m_last_check_time that is supposed to limit when dbus is check doesn't work.  m_last_check_time is never updated, stays 0 all the time.

2.  OMXSleep(10) never is executed.  This only is triggered if you cannot add a packet to the queues because they are full.  Not a problem in itself, but plays into #3 

3.  The main loop (omxplayer.cpp) is apparently throttled by the Lock() functions in the audio and video players (also Lock in reader, but I don't see another thread there).  Thus the main loop is always asking either the video or audio player for a lock, which likely isn't what was intended.

I haven't completely verified this yet, but I don't see any other blocking functions in the main loop....   
When I fixed #1 above it dropped the cpu usage by about 8%.",True,False
popcornmix/omxplayer/56,False,525fd9c4bd3543e2fe000874,"@jmeiners 
You are correct. I have submitted a fix for #1 and #2/#3. Can you test?",True,False
popcornmix/omxplayer/56,False,52600b02bd3543fc2a0000ed,"Thanks!

#1 is fixed
# 2/3  didn't make a difference.  The new Sleep is never called.
I think what is really going on this that the avformat_read_frame() actually IS blocking even though the NONBLOCK flag is set.  In ffmpeg it says that sometimes the NONBLOCK cannot be honored....

I verified this by the fact that the keyboard controls do not work before the live stream starts and if the live stream is killed (and also by the fact the new Sleep command is never called, meaning there is always a packet returned).  Thus it must be blocking on avformat_read_frame()...

Anyway, moving to a separate thread to read the packets is probably the only way to really fix it.",True,False
popcornmix/omxplayer/56,False,5260303ebd35430a1c000954,"So is there actually a problem?
Yes, the open call in ffmpeg blocks, but that should succeed or time out.",True,False
popcornmix/omxplayer/56,False,5302d7fdbd3543f69f001650,"Yes, the remaining problem would be that the program is unresponsive if the network stream is not running.
Do to the read frame call blocking and it doesn't time out (at least in my testing this is true).",True,False
popcornmix/omxplayer/56,False,5260412dbd354310c9000eb1,But this is sometimes desireable - sometimes a live stream will cut in/out briefly and you certainly don't want the player to exit on every glitch - so the timeout would have to be a parameter you could set per your application.,True,False
popcornmix/omxplayer/56,False,526042e0bd354317ce00005c,"I don't think you CAN set a timeout on the read_frame function though....

I would have to say the best way to do it would be to put the read frame stuff in a different thread than the user input thread (ie main loop).  I think that was originally your suggestion @perrypoint    That way it can block indefinitely (it just waits for new data) without affecting the user control.",True,False
popcornmix/omxplayer/56,False,52610bcbbd3543712f0004cb,"Even if read frame was in another thread we'd still like to shut down ffmpeg and clean up, which would be impossible if read_frame had blocked without forcibly killing the thread.
And that doesn't seem much cleaner than using control-c to quit.

What steps provoke this issue? Disconnecting network cable when playing a (network) video?

Note that xbmc (on all platforms) calls read frame from a control thread that will block the system until it returns. It doesn't forcably kill this thread, and I've not seen widespread reports of this being a real problem.",True,False
popcornmix/omxplayer/56,False,52614a84bd35438bbc000ad2,"Some network stream sources (like HDHOMERun) need to be explicitly started and stopped.  If the code to stop the source executes before the code to stop omxplayer, omxplayer will hang.

I'm not saying that this is the biggest issue, just that a separate thread would be cleaner and more architecturally correct (IMO).  That way the control loop can use poll/select on the input FID and not have to poll.  Basically each thread will wake exactly and only when needed.",True,False
popcornmix/omxplayer/56,False,52614d7fbd35438b51000e48,"@jmeiners 
pull requests are welcome",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b71,"<a href=""https://github.com/sethladd""><img src=""https://avatars.githubusercontent.com/u/5479?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [sethladd](https://github.com/sethladd)**

----

*Set owner to @munificent.*
*Removed [Type-Defect](../labels/Type-Defect) label.*
*Added [Type-Task](../labels/Type-Task), [Area-Pub](../labels/Area-Pub), [Triaged](../labels/Triaged) labels.*
",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b72,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

Please rename ""samples/"" to ""example/"" and ""docs/"" to ""doc/"".

Files that aren't intended to be imported directly by end-users should live under ""lib/src/"", not just ""lib/"".

Examples should use ""package:"" imports to import the library.

We're encouraging people to put build scripts under a ""tool/"" directory.

""pubspec.lock"" shouldn't be checked in for a library package. You don't want to lock in the versions of your dependencies for all your users.

Please add ""author"" and ""homepage"" fields to the pubspec.
______
*Set owner to @nex3.*
*Added [Accepted](../labels/Accepted) label.*
",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b73,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Moved to https://github.com/kevmoo/bot.dart

samples -> example
docs -> doc (with associated issue http://code.google.com/p/dart/issues/detail?id=5449)
All files under lib are intended to be imported by end-users.
using package: syntax
I have plans for the scripts in the root, so I'm holding off the 'tool' move just yet.
pubspec.lock is ignored
pubspec.yaml is updated

Cool?

",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b74,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

In general, I think we want to discourage people to check in packages with compiled dartdoc output. Our thinking was that ""doc/"" would be reserved for source documentation, such as Markdown files explaining the use of the library. The compiled output would go in a different directory (Bob likes ""build/doc"").",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b75,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Oh, do you want a version in the pubspec?",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b76,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

Yes, that's definitely something we need.",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b77,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Version has been added.",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b78,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

Are you planning to keep the generated docs under ""doc/""? It won't block the upload, but we'd prefer it not be there.",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b79,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Gah you're picky. I can move 'em to build/doc

My process for publishing to github pages requires they be in my repo. I'll fix that soon..ish...",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b7a,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Done.",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b7b,"<a href=""https://github.com/munificent""><img src=""https://avatars.githubusercontent.com/u/46275?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [munificent](https://github.com/munificent)**

----

*Added this to the [M1](../milestones/M1) milestone.*
",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b7c,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

Sorry for being so picky... we're trying to ensure that the first crop of packages are exemplary in their structure to encourage future packages to follow suit.

The directories under ""lib/"" aren't intended to contain user-visible libraries, and so should be under source. For example, ""lib/texture/texture_data.dart"" should be ""lib/src/texture/texture_data.dart"". Otherwise it looks like the user is allowed to import ""package:bot/texture/texture_data.dart"".

""resources/"" should have a singular name, like other top-level directories.",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b7d,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Done.

https://github.com/kevmoo/bot.dart",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b7e,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

This has been uploaded.
______
*Added [Fixed](../labels/Fixed) label.*
",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b7f,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

Sorry, one more thing: can you add a ""description"" field to your pubspec?
______
*Added [Accepted](../labels/Accepted) label.*
",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b80,"<a href=""https://github.com/kevmoo""><img src=""https://avatars.githubusercontent.com/u/17034?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [kevmoo](https://github.com/kevmoo)**

----

Done.",True,False
dart-lang/pub/146,False,55721e9dbd35435e14000b81,"<a href=""https://github.com/nex3""><img src=""https://avatars.githubusercontent.com/u/188?v=3"" align=""left"" width=""48"" height=""48""hspace=""10""></img></a> **Comment by [nex3](https://github.com/nex3)**

----

This has been uploaded.
______
*Added [Fixed](../labels/Fixed) label.*
",True,False
Totenfluch/SmartLinkRemover/13,False,5905e8766480fd65222c47b7,wouldn't this always keep the first part of the URL even when it's not the only thing in the players name?,True,False
Totenfluch/SmartLinkRemover/13,False,590649436480fd645f401d57,I match it to the full name: https://github.com/Totenfluch/SmartLinkRemover/pull/13/files#diff-7fad1b52526e017a86acdcdc5d509e08R78,True,False
Totenfluch/SmartLinkRemover/13,False,590652c06480fd6780fb3262,"Oops. Missed that - Merged 

Thanks for the work!",True,False
PHP-FFMpeg/PHP-FFMpeg/434,False,59f31d3b6480fdd3415379d9,Using a Try-Catch Block should help. Please use the search engine of your choice before asking us.,True,False
dotnet/machinelearning-modelbuilder/822,False,5ee303dcbd35432fda255aa2,Related to #804?,True,False
dotnet/machinelearning-modelbuilder/822,False,5ee303dcbd35432fda255aa3,#804 is from the sentiment data. It shouldn't be sparse or have any shape problems,True,False
dotnet/machinelearning-modelbuilder/822,False,5ee303dcbd35432fda255aa4,"Dataset had ""<1.0"" in a numerical column.",True,False
dotnet/machinelearning-modelbuilder/822,False,5ee303ddbd35432fda255aa5,"Dataset had ""<1.0"" in a numerical column.",True,False
facebookresearch/StarSpace/171,False,5b7bfebb6480fdca209a7dd7,"No, I don't think so. Binary models are different between the programs. ",True,False
kftsehk/phy-clusters/6,False,5b8343c86480fdc4763198b9,"After restart of mu01

```
[kftse@mu01 ~]$ qstat
socket_connect_unix failed: 15137
socket_connect_unix failed: 15137
socket_connect_unix failed: 15137
qstat: cannot connect to server (null) (errno=15137) could not connect to trqauthd

[kftse@mu01 ~]$ pbsnodes
socket_connect_unix failed: 15137
pbsnodes: cannot connect to server mu01, error=15137 (could not connect to trqauthd)
```",True,False
kftsehk/phy-clusters/6,False,5b8343c86480fdc4763198ba,"After loading module, `mpirun` is still not intel's MPI

```
[kftse@mu01 ~]$ which mpirun
/usr/bin/mpirun
[kftse@mu01 ~]$ module list
Currently Loaded Modulefiles:
  1) null                            2) vasp                            3) intel_parallel_studio_xe_2015
```",True,False
kftsehk/phy-clusters/6,False,5b834b3e6480fdc7f8481285,"For testing of MPI
```
[kftse@mu01 ~]$ qsub -l nodes=44:ppn=24 -q admin
mpirun /opt/intel/imb/4.0.3.032/src/IMB-MPI1 -multi 1
```",True,False
kftsehk/phy-clusters/6,False,5b835e8d6480fdc1ac07cd23,"For an integrated node benchmark: Test nodes pairwise for problem

```
[kftse@cu43 ~]$ cp /opt/intel/mkl/benchmarks/mp_linpack/bin_intel/intel64/ ./ -r; cd intel64
# Edit HPL.dat as follow
[kftse@cu43 intel64]$ cat HPL.dat
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
40000    Ns
1            # of NBs
168          NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
6            Ps  #P*Q=np
8            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
4            NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
1            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
0            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
[kftse@cu43 intel64]$ mpirun ./xhpl_intel64
================================================================================
HPLinpack 2.1  --  High-Performance Linpack benchmark  --   October 26, 2012
# ...
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR01C2R4       40000   168     6     8              32.17            1.32657e+03
# Around this number, 80%*4*GFlops of Xeon 2680v3
```",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d68600034e,"Thanks for the bug report.

I'll double check that the page_link is being included properly.

As for the database mess. There is no code in the ACF plugin which would do this. I'm not sure why your db has been effected, but I can insure you it is not the ACF plugin.",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d68600034f,Just viewed the code (acf.php line 284) and can confirm that the page_link file does exist. Are you missing a file?,True,False
elliotcondon/acf4/5,False,511dab9dbd3543d686000350,"Hello

DB:
I have deactivated all plugins, then activated ACF and this is the result.. see image
![Posts Auto Mat WordPress](https://f.cloud.github.com/assets/747153/143942/a2d4ad9c-73d7-11e2-89d0-106da80b122d.png)
none of the 20 plugins we use at that site does not produces such a thing.

THE PLUGIN PATH:
if it were correct it should follow these rules
http://codex.wordpress.org/Function_Reference/plugin_basename

Here is how you include
include_once('core/controllers/field_groups.php');

should be:
define( 'MYPLUGINNAME_PATH', plugin_dir_path(__FILE__) );
include_once(MYPLUGINNAME_PATH . ''core/controllers/field_groups.php');

The path should be exact, because you never know where the wordpress core is located. in my case it is in folder xyz on localhost",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d686000351,"Thanks for the info.

Perhaps I am wrong, but I thought the include_once function could work with 'relative' paths. I can easily add in the plugin path as it is already a variable within ACF. I just didn't know this was necessary.

Again, as for the database. I have no idea how this has happened. There is no code in acf to change the database settings. Please feel free to search through the code for any keywords you can think of.

If you disable ACF, does your database act as normal? If you create a new WP and install acf v4, does the same thing happen?",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d686000352,"Hello,

The problem with the mess, is not a problem with DB. DB is OK.
The problem occurs only when the define('WP_DEBUG', true); .. is TRUE.. if it is FALSE all the characters are OK.
THE debug true is important for me, because I never use plugins which has something visibly wrong :) .. I think, I guess that the characters are influenced by the path error code which stops some WP core to handle the DB right.
",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d686000353,"I'm curious if you had this issue previously. 
In all the ACF versions, the core/api.php file is included with a relative path.

Did you have this error when including the api.php file?
Do you have any issues with any other plugins including files with a relative path?",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d686000354,"I have just updated all add-ons to str_replacte the plugins path, then the content path.

Can you re-download the add-ons and refresh your wp-admin?",True,False
elliotcondon/acf4/5,False,511dab9dbd3543d686000355,"The problems are gone.

Thank you",True,False
ProgrammerChris/Finn.no-car-picture-scraper/1,False,5f23cb2ebd3543472827ea20,"Looks like urllib3 is up-to-date now, so this is no longer needed.",True,False
ProgrammerChris/Finn.no-car-picture-scraper/1,False,5f23cb2fbd3543472827ea21,"Looks like urllib3 is up-to-date now, so this is no longer needed.",True,False
fedorov/PCampReview/68,False,558db400bd3543ed9001668d,"I am not sure, why the old commits also occur although I made a rebase",True,False
fedorov/PCampReview/68,False,558db75abd3543edbd015a85,https://github.com/edx/edx-platform/wiki/How-to-Rebase-a-Pull-Request,True,False
fedorov/PCampReview/68,False,558db7b7bd3543f3e701140f,"I'm not sure the commits actually occurred, I think it just concatenated all of your commit messages. I think you can avoid this by ""rewording"" your commit message when you do the rebase, but ultimately, I think it's ok to see all of the steps you went through",True,False
fedorov/PCampReview/68,False,558dc185bd3543f197015e7b,"So we looked into this with Christian together. He is using Tortoise (a Windows GUI thingy) to do this, and apparently he needs to do a commit after resolving conflicts for each of the original commits.

When I do rebase from command line, I can do ""git add"" after resolving each of the commits, and then I have a clean history where each of the original commits has a single one in the rebased branch history.

Christian is going to look into using SourceTree as an alternative to Tortoise, and we'll see if this resolves the problem.",True,False
fedorov/PCampReview/68,False,558dc280bd3543f24e0150eb,"For the record, I've always done git rebase on the command line following the instructions in the link above and yes, also use git add + git rebase --continue to resolve conflicts when rebasing.  Not sure how gracefully SourceTree does rebases as I have not tried it. ",True,False
fedorov/PCampReview/68,False,558dc51cbd3543f0cd0156df,"Thanks Robin - this is good to know! I suggested Christian to use SourceTree because I thought that's what he used, and you had good experience with it.

I always use command line, but Christian is used to GUI tools, which I understand. Let's see what he finds out about SourceTree. We agreed it will be nice to figure this issue out to avoid duplicate commits in the history.",True,False
fedorov/PCampReview/68,False,558dc5ebbd3543f5230151cf,"For me: SourceTree = clone, fetch, push, pull, commit, branch, stash. CLI = rebase.",True,False
fedorov/PCampReview/68,False,55915c04bd3543f3e701dcbe,SourceTree is great but for rebasing it also produces for every single merged commit a new commit instead of just adding one commit for ALL merged commits.,True,False
fedorov/PCampReview/68,False,55915dc4bd3543ed9b021d55,When you did the rebase did you squash your commits?  See https://answers.atlassian.com/questions/213902/in-sourcetree-how-do-i-squash-commits and https://github.com/edx/edx-platform/wiki/How-to-Rebase-a-Pull-Request (the section on squashing changes),True,False
fedorov/PCampReview/68,False,55915ea9bd3543f52c023c74,Maybe I should try that. Just to figure out the best practice. ,True,False
fedorov/PCampReview/68,False,55916145bd3543f52c023d40,"I prefer not to squash. The command line workflow allows that.

---
Sent from my mobile device
On Jun 29, 2015 11:05 AM, ""Christian Herz"" <notifications@github.com> wrote:

> Maybe I should try that. Just to figure out the best practice.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/fedorov/PCampReview/pull/68#issuecomment-116721153>.
>
",True,False
fedorov/PCampReview/68,False,559173d9bd3543f0080230c3,That's really hard to merge everything after changing so many lines of code. Especially when using only an editor....,True,False
fedorov/PCampReview/68,False,55918bdbbd3543f05602293e,"@rweiss42 I met with Christian today, and we decided to start from fresh instead of resolving conflicts, as the latter turned out quite challenging - too many of them. Please hold off any major PRs if you have any in mind, and let's have Christian finish his refactoring without any major conflicts.

@che85 If you like, feel free to have multiple pull requests if you want us to test things in smaller chunks, instead of preparing one big PR.",True,False
fedorov/PCampReview/68,False,55918f4dbd3543ee17023c14,Sounds good,True,False
OXID-eSales/oxideshop_ce/507,False,58375d576480fd0e5406a788,It would be nicer if we could create a new field like `oxselectlistvalue` in `oxorderarticles`,True,False
OXID-eSales/oxideshop_ce/507,False,589daad66480fd956d29a932,"**Example**

<table>
<tr>
  <td>Article</td>
  <td>shirt</td>
</tr>
<tr>
  <td colspan=""2"">Variants</td>
</tr>
<tr>
  <td>color</td>
  <td>red, blue</td>
</tr>
<tr>
  <td>size</td>
  <td>s, m, l</td>
</tr>
<tr>
  <td colspan=""2"">Selectlists</td>
</tr>
<tr>
  <td>someSelectlist</td>
  <td>firstValue, secondValue, thirdValue</td>
</tr>
</table>

User buys Article ""shirt"" with the following selection:
<table>
<tr>
  <td>variant</td>
  <td>red & s</td>
</tr>
<tr>
  <td>selectlist</td>
  <td>secondValue</td>
</tr>
</table>

`OXSELVARIANT` becomes: `someSelectlist : secondValue | red | s`  
see:
```
$oOrderArticle->oxorderarticles__oxselvariant = new oxField(trim($sSelList . ' ' . $oProduct->oxarticles__oxvarselect->getRawValue()), oxField::T_RAW);
```

---

**Problem:** The delimiter ` | ` is used to separate each variant, but also to separate the variant-selection and the selectlist.

**My suggested solution:** Use ` | ` to separate each variant and ` || ` to separate the variant-selection and the selectlist. So `OXSELVARIANT` becomes: `someSelectlist : secondValue || red | s`  ",True,False
OXID-eSales/oxideshop_ce/507,False,5b8697986480fd2aac49e71c,I've resolved the merge conflicts.,True,False
OXID-eSales/oxideshop_ce/507,False,5bd077e46480fd36e5cae736,"Hello @alfredbez, i have merged the fix to b-6.1.x recently on 5b7de69e6191466b43de6601066451df757f1198",True,False
dhiyauddin/REST_Filtering/1,False,5ec40cdcbd354339e8d02503,Superseded by #2.,True,False
dhiyauddin/REST_Filtering/1,False,5ec40cdcbd354339e8d02504,Superseded by #2.,True,False
OpenSprinkler/OpenSprinkler-Weather/5,False,56e31c666480fd19e50087b7,"## [Current coverage][1] is `56.96%`
> Merging **#5** into **master** will decrease coverage by **-0.36%** as of [`b20e21e`][3]


```diff
@@            master      #5   diff @@
======================================
  Files            3       3       
  Stmts          232     237     +5
  Branches         0       0       
  Methods          0       0       
======================================
+ Hit            133     135     +2
  Partial          0       0       
- Missed          99     102     +3
```

> Review entire [Coverage Diff][4] as of [`b20e21e`][3]


-----
### [Uncovered Suggestions][2]

1. `+2.53%` via [routes/weather.js#208...213](https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather/routes/weather.js?ref=b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee#208) 
1. `+2.53%` via [routes/weather.js#106...111](https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather/routes/weather.js?ref=b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee#106) 
1. `+2.53%` via [routes/weather.js#48...53](https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather/routes/weather.js?ref=b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee#48) 
1. *[See 7 more...][2]*

[1]: https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather?ref=b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee
[2]: https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather/features/suggestions?ref=b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee
[3]: https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather/commit/b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee
[4]: https://codecov.io/github/OpenSprinkler/OpenSprinkler-Weather/compare/02e5e233c7c1348a2a2c3b3a963b9537b557d505...b20e21e07a3cb4f761493c0bf6743fe9ff7cd5ee

> Powered by [Codecov](https://codecov.io). Updated on successful CI builds.",True,False
OpenSprinkler/OpenSprinkler-Weather/5,False,56e31cf46480fd137f008c29,I'm liking your automated test 8) Sorry about dropping the code coverage below target.,True,False
OpenSprinkler/OpenSprinkler-Weather/5,False,56e4a7956480fd1811006c09,Looks good thank you! The automated testing is great although should be expanded on a little for both repositories. No worries on the code coverage drops :),True,False
wudi/todc-bootstrap/72,False,5fa338c9bd35435d0e3d121c,"Dependabot tried to add `@acmetech` as a reviewer to this PR, but received the following error from GitHub:

```
POST https://api.github.com/repos/wudi/todc-bootstrap/pulls/72/requested_reviewers: 422 - Reviews may only be requested from collaborators. One or more of the users or teams you specified is not a collaborator of the wudi/todc-bootstrap repository. // See: https://docs.github.com/rest/reference/pulls#request-reviewers-for-a-pull-request
```",True,False
wudi/todc-bootstrap/72,False,5fa338c8bd35435ad6ee3483,"The following labels could not be found: `dependencies`, `v5`.",True,False
wudi/todc-bootstrap/72,False,5fab3fd2bd35434a6a5d611f,Superseded by #74.,True,False
pahud/ecs-cfn-refarch/4,False,5d00fba66480fd0d5ee84026,"Hi @sibs786 I don't understand your question.

The primary cloudformation template is here
https://github.com/pahud/ecs-cfn-refarch/blob/master/cloudformation/service.yaml

Can you indicate which lines you were asking about?",True,False
pahud/ecs-cfn-refarch/4,False,5d00fe556480fd0dc1d0887a,"Hi pahud thanks for replying. 
I have ignored the above configuration.

This is my autoscaling group configuration now
  ECSAutoScalingGroup:
    DependsOn: ECSCluster
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      MixedInstancesPolicy:
        InstancesDistribution:
          OnDemandAllocationStrategy: prioritized
          OnDemandBaseCapacity: !Ref OnDemandBaseCapacity
          OnDemandPercentageAboveBaseCapacity: !Ref OnDemandPercentageAboveBaseCapacity
          SpotAllocationStrategy: lowest-price
          SpotInstancePools: !Ref SpotInstancePools
        LaunchTemplate:
          LaunchTemplateSpecification: 
            LaunchTemplateId: !Ref MyLaunchTemplate     
      VPCZoneIdentifier: !Ref Subnets
      MinSize: 2
      MaxSize: 5
      DesiredCapacity: 2
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} ECS host
          PropagateAtLaunch: true
    CreationPolicy:
      ResourceSignal:
        Timeout: PT15M
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: 1
        MaxBatchSize: 1
        PauseTime: PT15M
        SuspendProcesses:
          - HealthCheck
          - ReplaceUnhealthy
          - AZRebalance
          - AlarmNotification
          - ScheduledActions
        WaitOnResourceSignals: true

Need to understand why using this
 ECSTaskRole:
    Type: AWS::IAM::Role
    Properties:
        AssumeRolePolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action: 
                  - 'sts:AssumeRole'
                Effect: Allow
                Principal:
                  Service:
                    - ecs-tasks.amazonaws.com
        Path: /
        Policies:
        - PolicyName: ecs-task-get-parameters
          PolicyDocument:
            Statement:
            - Effect: Allow
              Action:
              - ssm:GetParameters
              Resource: !Sub ""arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/ECS*""
        - PolicyName: ecs-task-decrypt-kms
          PolicyDocument:
            Statement:
            - Effect: Allow
              Action:
              - kms:Decrypt
              Resource: !Sub ""arn:aws:kms:${AWS::Region}:${AWS::AccountId}:key/${myKey}""
        - PolicyName: ecs-task-put-cwl
          PolicyDocument:
            Statement:
            - Effect: Allow
              Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
              Resource: ""arn:aws:logs:*:*:*""


  ECSTaskExecutionRole:
    Type: AWS::IAM::Role
    Properties:
        AssumeRolePolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action: 
                  - 'sts:AssumeRole'
                Effect: Allow
                Principal:
                  Service:
                    - ecs-tasks.amazonaws.com
        Path: /
        Policies:
        - PolicyName: ecs-task-get-parameters
          PolicyDocument:
            Statement:
            - Effect: Allow
              Action:
              - ssm:GetParameters
              Resource: !Sub ""arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/ECS*""
        - PolicyName: ecs-task-decrypt-kms
          PolicyDocument:
            Statement:
            - Effect: Allow
              Action:
              - kms:Decrypt
              Resource: !Sub ""arn:aws:kms:${AWS::Region}:${AWS::AccountId}:key/${myKey}""
        - PolicyName: ecs-task-put-cwl
          PolicyDocument:
            Statement:
            - Effect: Allow
              Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
              Resource: ""arn:aws:logs:*:*:*""


Your LaunchTempalate
  MyLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateName: !Sub ""eksLaunchTemplate-${AWS::StackName}""
      LaunchTemplateData: 
        TagSpecifications: 
          -
            ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub ""${ECSDefaultCluster}-ASG-Node""

        UserData: 
          ""Fn::Base64"": 
            !Sub |
              Content-Type: multipart/mixed; boundary=""==BOUNDARY==""
              MIME-Version: 1.0
  
              --==BOUNDARY==
              Content-Type: text/x-shellscript; charset=""us-ascii""
              #!/bin/bash
              yum install -y awscli
              
              echo ECS_CLUSTER=${AWS::StackName}-ecs-cluster >> /etc/ecs/ecs.config
              echo ECS_DISABLE_IMAGE_CLEANUP=false >> /etc/ecs/ecs.config
    
              iid=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
              export AWS_DEFAULT_REGION=${AWS::Region}
              ilc=$(aws ec2 describe-instances --instance-ids  $iid  --query 'Reservations[0].Instances[0].InstanceLifecycle' --output text)
              if [ ""$ilc"" == ""spot"" ]; then
                echo ECS_INSTANCE_ATTRIBUTES='{""instance-purchase-option"":""spot""}' >> /etc/ecs/ecs.config
              else
                echo ECS_INSTANCE_ATTRIBUTES='{""instance-purchase-option"":""ondemand""}' >> /etc/ecs/ecs.config
              fi
              
              yum update -y
              # Install awslogs and the jq JSON parser
              yum install -y awslogs jq aws-cfn-bootstrap
  
              # Inject the CloudWatch Logs configuration file contents
              cat > /etc/awslogs/awslogs.conf <<- EOF
              [general]
              state_file = /var/lib/awslogs/agent-state        
              
              [/var/log/dmesg]
              file = /var/log/dmesg
              log_group_name = /aws/ECS/var/log/dmesg
              log_stream_name = {cluster}/{container_instance_id}
  
              [/var/log/messages]
              file = /var/log/messages
              log_group_name = /aws/ECS/var/log/messages
              log_stream_name = {cluster}/{container_instance_id}
              datetime_format = %b %d %H:%M:%S
  
              [/var/log/docker]
              file = /var/log/docker
              log_group_name = /aws/ECS/var/log/docker
              log_stream_name = {cluster}/{container_instance_id}
              datetime_format = %Y-%m-%dT%H:%M:%S.%f
  
              [/var/log/ecs/ecs-init.log]
              file = /var/log/ecs/ecs-init.log.*
              log_group_name = /aws/ECS/var/log/ecs/ecs-init.log
              log_stream_name = {cluster}/{container_instance_id}
              datetime_format = %Y-%m-%dT%H:%M:%SZ
  
              [/var/log/ecs/ecs-agent.log]
              file = /var/log/ecs/ecs-agent.log.*
              log_group_name = /aws/ECS/var/log/ecs/ecs-agent.log
              log_stream_name = {cluster}/{container_instance_id}
              datetime_format = %Y-%m-%dT%H:%M:%SZ
  
              [/var/log/ecs/audit.log]
              file = /var/log/ecs/audit.log.*
              log_group_name = /aws/ECS/var/log/ecs/audit.log
              log_stream_name = {cluster}/{container_instance_id}
              datetime_format = %Y-%m-%dT%H:%M:%SZ
  
              EOF
  
              --==BOUNDARY==
              Content-Type: text/x-shellscript; charset=""us-ascii""
              #!/bin/bash
              # Set the region to send CloudWatch Logs data to (the region where the container instance is located)
              region=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r .region)
              sed -i -e ""s/region = us-east-1/region = $region/g"" /etc/awslogs/awscli.conf
  
              start ecs
              /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource ASGDefault --region ${AWS::Region} 
  
              --==BOUNDARY==
              Content-Type: text/upstart-job; charset=""us-ascii""
  
              #upstart-job
              description ""Configure and start CloudWatch Logs agent on Amazon ECS container instance""
              author ""Amazon Web Services""
              start on started ecs
  
              script
                exec 2>>/var/log/ecs/cloudwatch-logs-start.log
                set -x
                
                until curl -s http://localhost:51678/v1/metadata
                do
                  sleep 1	
                done
  
                # Grab the cluster and container instance ARN from instance metadata
                cluster=$(curl -s http://localhost:51678/v1/metadata | jq -r '. | .Cluster')
                container_instance_id=$(curl -s http://localhost:51678/v1/metadata | jq -r '. | .ContainerInstanceArn' | awk -F/ '{print $2}' )
                
                # Replace the cluster name and container instance ID placeholders with the actual values
                sed -i -e ""s/{cluster}/$cluster/g"" /etc/awslogs/awslogs.conf
                sed -i -e ""s/{container_instance_id}/$container_instance_id/g"" /etc/awslogs/awslogs.conf
                
                service awslogs start
                chkconfig awslogs on
              end script
              --==BOUNDARY==--
                     
        IamInstanceProfile: 
          Arn: !GetAtt EC2InstanceProfile.Arn
        KeyName: !Ref SshKeyName
        NetworkInterfaces: 
          - 
            DeviceIndex: 0
            AssociatePublicIpAddress:
              !If
                - IsASGAutoAssignPublicIp
                - 'true'
                - 'false'
            SubnetId: !Select [0, !Ref SubnetIds]
            Groups: 
              - !Ref NodeSecurityGroup
        ImageId: !Ref ECSAMI

I can see you have combined roles here, also the user data.

This is the launchconfiguration i was using
  ECSLaunchConfiguration:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      ImageId: !Ref ECSAMI
      InstanceType: !Ref InstanceType
      SecurityGroups:
        - !Ref SecurityGroup
      IamInstanceProfile: !Ref ECSInstanceProfile
      UserData:
        ""Fn::Base64"": !Sub |
          #!/bin/bash
          yum install -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
          yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
          yum install -y aws-cfn-bootstrap hibagent 
          /opt/aws/bin/cfn-init -v --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSLaunchConfiguration
          /opt/aws/bin/cfn-signal -e $? --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSAutoScalingGroup
          /usr/bin/enable-ec2-spot-hibernation

    Metadata:
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              collectd: []

          commands:
            01_add_instance_to_cluster:
              command: !Sub echo ECS_CLUSTER=${ECSCluster} >> /etc/ecs/ecs.config
            02_enable_cloudwatch_agent:
              command: !Sub /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${ECSCloudWatchParameter} -s
          files:
            /etc/cfn/cfn-hup.conf:
              mode: 000400
              owner: root
              group: root
              content: !Sub |
                [main]
                stack=${AWS::StackId}
                region=${AWS::Region}

            /etc/cfn/hooks.d/cfn-auto-reloader.conf:
              content: !Sub |
                [cfn-auto-reloader-hook]
                triggers=post.update
                path=Resources.ECSLaunchConfiguration.Metadata.AWS::CloudFormation::Init
                action=/opt/aws/bin/cfn-init -v --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSLaunchConfiguration

          services:
            sysvinit:
              cfn-hup:
                enabled: true
                ensureRunning: true
                files:
                  - /etc/cfn/cfn-hup.conf
                  - /etc/cfn/hooks.d/cfn-auto-reloader.conf

The Roles i am using here is this
  ECSRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      RoleName: !Sub ${EnvironmentName}-ECSRole-${AWS::Region}
      AssumeRolePolicyDocument: |
        {
            ""Statement"": [{
                ""Action"": ""sts:AssumeRole"",
                ""Effect"": ""Allow"",
                ""Principal"": {
                    ""Service"": ""ec2.amazonaws.com""
                }
            }]
        }
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
      Policies:
        - PolicyName: ecs-service
          PolicyDocument: |
            {
                ""Statement"": [{
                    ""Effect"": ""Allow"",
                    ""Action"": [
                        ""ecs:CreateCluster"",
                        ""ecs:DeregisterContainerInstance"",
                        ""ecs:DiscoverPollEndpoint"",
                        ""ecs:Poll"",
                        ""ecs:RegisterContainerInstance"",
                        ""ecs:StartTelemetrySession"",
                        ""ecs:Submit*"",
                        ""ecr:BatchCheckLayerAvailability"",
                        ""ecr:BatchGetImage"",
                        ""ecr:GetDownloadUrlForLayer"",
                        ""ecr:GetAuthorizationToken""
                    ],
                    ""Resource"": ""*""
                }]
            }

  ECSInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref ECSRole

  ECSServiceAutoScalingRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: ""2012-10-17""
        Statement:
          Action:
            - ""sts:AssumeRole""
          Effect: Allow
          Principal:
            Service:
              - application-autoscaling.amazonaws.com
      Path: /
      Policies:
        - PolicyName: ecs-service-autoscaling
          PolicyDocument:
            Statement:
              Effect: Allow
              Action:
                - application-autoscaling:*
                - cloudwatch:DescribeAlarms
                - cloudwatch:PutMetricAlarm
                - ecs:DescribeServices
                - ecs:UpdateService
              Resource: ""*""

  ECSCloudWatchParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Description: ECS
      Name: !Sub ""AmazonCloudWatch-${ECSCluster}-ECS""
      Type: String
      Value: !Sub |
        {
          ""logs"": {
            ""force_flush_interval"": 5,
            ""logs_collected"": {
              ""files"": {
                ""collect_list"": [
                  {
                    ""file_path"": ""/var/log/messages"",
                    ""log_group_name"": ""${ECSCluster}-/var/log/messages"",
                    ""log_stream_name"": ""{instance_id}"",
                    ""timestamp_format"": ""%b %d %H:%M:%S""
                  },
                  {
                    ""file_path"": ""/var/log/dmesg"",
                    ""log_group_name"": ""${ECSCluster}-/var/log/dmesg"",
                    ""log_stream_name"": ""{instance_id}""
                  },
                  {
                    ""file_path"": ""/var/log/docker"",
                    ""log_group_name"": ""${ECSCluster}-/var/log/docker"",
                    ""log_stream_name"": ""{instance_id}"",
                    ""timestamp_format"": ""%Y-%m-%dT%H:%M:%S.%f""
                  },
                  {
                    ""file_path"": ""/var/log/ecs/ecs-init.log"",
                    ""log_group_name"": ""${ECSCluster}-/var/log/ecs/ecs-init.log"",
                    ""log_stream_name"": ""{instance_id}"",
                    ""timestamp_format"": ""%Y-%m-%dT%H:%M:%SZ""
                  },
                  {
                    ""file_path"": ""/var/log/ecs/ecs-agent.log.*"",
                    ""log_group_name"": ""${ECSCluster}-/var/log/ecs/ecs-agent.log"",
                    ""log_stream_name"": ""{instance_id}"",
                    ""timestamp_format"": ""%Y-%m-%dT%H:%M:%SZ""
                  },
                  {
                    ""file_path"": ""/var/log/ecs/audit.log"",
                    ""log_group_name"": ""${ECSCluster}-/var/log/ecs/audit.log"",
                    ""log_stream_name"": ""{instance_id}"",
                    ""timestamp_format"": ""%Y-%m-%dT%H:%M:%SZ""
                  }
                ]
              }
            }
          },
          ""metrics"": {
            ""append_dimensions"": {
              ""AutoScalingGroupName"": ""${!aws:AutoScalingGroupName}"",
              ""InstanceId"": ""${!aws:InstanceId}"",
              ""InstanceType"": ""${!aws:InstanceType}""
            },
            ""metrics_collected"": {
              ""collectd"": {
                ""metrics_aggregation_interval"": 60
              },
              ""disk"": {
                ""measurement"": [
                  ""used_percent""
                ],
                ""metrics_collection_interval"": 60,
                ""resources"": [
                  ""/""
                ]
              },
              ""mem"": {
                ""measurement"": [
                  ""mem_used_percent""
                ],
                ""metrics_collection_interval"": 60
              },
              ""statsd"": {
                ""metrics_aggregation_interval"": 60,
                ""metrics_collection_interval"": 10,
                ""service_address"": "":8125""
              }
            }
          }
        }


Can you please guide me how to adjust IAM Roles and replace launch configuration with launch template. I would really appreciate that",True,False
pahud/ecs-cfn-refarch/4,False,5d0106126480fd0fe0a39a84,"Ok as per my understanding: You have assigned taskrole and taskexecutionrole to taskdefination which is required.
Also the parameters that you have defined in mylaunchtemplate are somewhat similar to my launch configuration

Is that correct?.",True,False
pahud/ecs-cfn-refarch/4,False,5d01cfb16480fd0d47b3e99f,"https://github.com/pahud/ecs-cfn-refarch/blob/09433d07b62cc711cce7cbe91487eecf123b0c7a/cloudformation/service.yaml#L506-L542

`ECSTaskExecutionRole` is primarily for `ssm:GetParameters` and `ECSTaskRole` is for application running in the Task.

Previously, `ssm:GetParameters` is only possible within ECS task, but now, because ECS already have native integration with Parameter Store, we can let ECS Execution Role do `ssm:GetParameters` for us.

https://github.com/pahud/ecs-cfn-refarch/blob/09433d07b62cc711cce7cbe91487eecf123b0c7a/cloudformation/service.yaml#L976-L982

https://github.com/pahud/ecs-cfn-refarch/blob/09433d07b62cc711cce7cbe91487eecf123b0c7a/cloudformation/service.yaml#L467-L503

So basically, in my reference, because Caddy doesn't need to do any AWS API call, we can disable the 
`ECSTaskRole` in this case. However, if your task need to call AWS SDK, you will need an appropriate `ECSTaskRole` with appropriate privileges on it.
",True,False
pahud/ecs-cfn-refarch/4,False,5d010aee6480fd146df98100,"Launch Config and Launch Template are totally different. I suggest you refer to my reference about ASG with LT and see how ASG refers to the LT.

https://github.com/pahud/ecs-cfn-refarch/blob/09433d07b62cc711cce7cbe91487eecf123b0c7a/cloudformation/service.yaml#L708-L759

https://github.com/pahud/ecs-cfn-refarch/blob/09433d07b62cc711cce7cbe91487eecf123b0c7a/cloudformation/service.yaml#L820-L967",True,False
pahud/ecs-cfn-refarch/4,False,5d01cfe96480fd0d1dde784d,"Hi Please confirm

This is my Auto Scaling Group
```
`  ECSAutoScalingGroup:
    DependsOn: ECSCluster
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      MixedInstancesPolicy:
        InstancesDistribution:
          OnDemandAllocationStrategy: prioritized
          OnDemandBaseCapacity: 0
          OnDemandPercentageAboveBaseCapacity: 50
          SpotAllocationStrategy: lowest-price
        LaunchTemplate:
          LaunchTemplateSpecification: 
            LaunchTemplateId: !Ref ECSLaunchConfiguration     
      VPCZoneIdentifier: !Ref Subnets
      MinSize: 2
      MaxSize: 5
      DesiredCapacity: 2
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName} ECS host
          PropagateAtLaunch: true
    CreationPolicy:
      ResourceSignal:
        Timeout: PT15M
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: 1
        MaxBatchSize: 1
        PauseTime: PT15M
        SuspendProcesses:
          - HealthCheck
          - ReplaceUnhealthy
          - AZRebalance
          - AlarmNotification
          - ScheduledActions
        WaitOnResourceSignals: true`
```

This is my launch template
```
`  ECSLaunchConfiguration:
    Type: AWS::AutoScaling::LaunchTemplate
    Properties:
      ImageId: !Ref ECSAMI
      InstanceType: !Ref InstanceType
      SecurityGroups:
        - !Ref SecurityGroup
      IamInstanceProfile: !Ref ECSInstanceProfile
      UserData:
        ""Fn::Base64"": !Sub |
          #!/bin/bash
          yum install -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
          yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
          yum install -y aws-cfn-bootstrap hibagent 
          /opt/aws/bin/cfn-init -v --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSLaunchConfiguration
          /opt/aws/bin/cfn-signal -e $? --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSAutoScalingGroup
          /usr/bin/enable-ec2-spot-hibernation

    Metadata:
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              collectd: []

          commands:
            01_add_instance_to_cluster:
              command: !Sub echo ECS_CLUSTER=${ECSCluster} >> /etc/ecs/ecs.config
            02_enable_cloudwatch_agent:
              command: !Sub /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${ECSCloudWatchParameter} -s
          files:
            /etc/cfn/cfn-hup.conf:
              mode: 000400
              owner: root
              group: root
              content: !Sub |
                [main]
                stack=${AWS::StackId}
                region=${AWS::Region}

            /etc/cfn/hooks.d/cfn-auto-reloader.conf:
              content: !Sub |
                [cfn-auto-reloader-hook]
                triggers=post.update
                path=Resources.ECSLaunchConfiguration.Metadata.AWS::CloudFormation::Init
                action=/opt/aws/bin/cfn-init -v --region ${AWS::Region} --stack ${AWS::StackName} --resource ECSLaunchConfiguration

          services:
            sysvinit:
              cfn-hup:
                enabled: true
                ensureRunning: true
                files:
                  - /etc/cfn/cfn-hup.conf
                  - /etc/cfn/hooks.d/cfn-auto-reloader.conf`
```",True,False
pahud/ecs-cfn-refarch/4,False,5d01d0266480fd117c65cf23,"I just tested this, it gave me Template format error: Unrecognized resource types: [AWS::AutoScaling::LaunchTemplate]

This error i know i have made mistake it should be AWS::EC2:LaunchTemplate",True,False
pahud/ecs-cfn-refarch/4,False,5d010e816480fd150aa04a73,"What is the use of this
```

            if [ ""$ilc"" == ""spot"" ]; then 
               echo ECS_INSTANCE_ATTRIBUTES='{""instance-purchase-option"":""spot""}' >> /etc/ecs/ecs.config 
             else 
               echo ECS_INSTANCE_ATTRIBUTES='{""instance-purchase-option"":""ondemand""}' >> /etc/ecs/ecs.config 
             fi 
```",True,False
pahud/ecs-cfn-refarch/4,False,5d0110636480fd1343429285,"[Encountered unsupported properties in {/}: [SecurityGroups, UserData, ImageId, IamInstanceProfile, InstanceType]]

Please suggest what is important? i am going to try userdata you shared",True,False
pahud/ecs-cfn-refarch/4,False,5d01ecb66480fd0d91dff3fa,Solved Problem,True,False
mitchellh/vagrant/4050,False,53a09465bd3543f7630012bb,"So, I cleared my `/etc/exports` and ran `sudo nfsd restart`, didn't fix issue.

But, I restarted my laptop and retried and now it is working properly.

Closing as this may have been some jank in my laptop.",True,False
mitchellh/vagrant/4050,False,53a09465bd3543f7630012bc,@jtreminio this generally happens if there is a conflicting interface already up. I've found cycling any vmnet or vboxnet interfaces off and then back on fixes this.,True,False
mitchellh/vagrant/4050,False,53ca2f8fbd354350b9039fdf,"Just updated to 1.6.3 and I get the exact same problem.

Restarting my laptop isn't working.

Debug isn't showing me anything apart from what you've already pasted. I'm at a loss. ",True,False
mitchellh/vagrant/4050,False,53e4199ebd3543a30a0057bc,"This keeps happening more often than not. Currently I have no choice but to use Virtualbox instead. VMWare is hanging to either this one, or at mounting NFS exports.

I've cleared my VMWare DHCP leases, rebooted, reinstalled VMWare, deleted /etc/exports, everything imaginable. VMWare works perfectly with the VM with a GUI, but with Vagrant... someone needs to figure this stuff out, it is two paid software.",True,False
mitchellh/vagrant/4050,False,53ed7175bd3543a32004176a,"This is happening to me too, usually resolved with a reboot, which is no resolution at all.  Any change this could be reopened and reviewed?",True,False
mitchellh/vagrant/4050,False,54235fa7bd354368d401b8d5,"Same issue for me as well, it seems to be related to virtual network interfaces:

    ==> default: Verifying vmnet devices are healthy...

I've figured a dirty solution which implies resetting network configuration:

	# save a backup networking settings for recovery 
	cp /Library/Preferences/VMware\ Fusion/networking{,.bak}

	# remove all entries from the configuration file describing the networks interfaces  
	vim /Library/Preferences/VMware\ Fusion/networking

	# restart your virtual machines using vagrant
	cd $PROJECT_DIR && vagrant up

	# you might want to restore your previous network settings
	cp /Library/Preferences/VMware\ Fusion/networking{.bak,}

I got inspired by http://thornelabs.net/2013/10/18/manually-add-and-remove-vmware-fusion-virtual-adapters.html

After having removed manually virtual network interfaces, using the next command:

    sudo /Applications/VMware\ Fusion.app/Contents/Library/vmnet-cfgcli vnetcfgremove VNET_1_VIRTUAL_ADAPTER 

Apply changes by executing 

    sudo /Applications/VMware\ Fusion.app/Contents/Library/vmnet-cli --configure",True,False
mitchellh/vagrant/4050,False,542605dabd35436d4b02b178,Yes I'm having the same problem but the solution suggested by @thierrymarianne worked. Would be good for @mitchellh to see if this could be resolved at some point (as I can see this ticket was opened back in June),True,False
mitchellh/vagrant/4050,False,54c664bcbd3543d40501313d,This is an ongoing issue with the paid VMWare integration. Is this is level of support I can expect from Hashicorps commercial products?,True,False
mitchellh/vagrant/4050,False,55479b72bd354370ea009530,"__Workaround__: changed to a setup __without__ private_networking... after struggling over and over again.

```
$vagrant up --debug
```

kept complaining

```
 INFO global: Vagrant version: 1.7.2
 INFO global: Ruby version: 2.0.0
 INFO global: RubyGems version: 2.0.14
 INFO global: VAGRANT_EXECUTABLE=""/opt/vagrant/bin/../embedded/gems/gems/vagrant-1.7.2/bin/vagrant""
 INFO global: VAGRANT_INSTALLER_EMBEDDED_DIR=""/opt/vagrant/bin/../embedded""
 INFO global: VAGRANT_INSTALLER_VERSION=""2""
 INFO global: VAGRANT_DETECTED_OS=""Darwin""
 INFO global: VAGRANT_INSTALLER_ENV=""1""
 INFO global: VAGRANT_INTERNAL_BUNDLERIZED=""1""
 INFO global: VAGRANT_LOG=""debug""
 INFO global: Plugins:
 INFO global:   - bundler = 1.7.11
 INFO global:   - json = 1.8.2
 INFO global:   - mime-types = 1.25.1
 INFO global:   - rdoc = 4.2.0
 INFO global:   - rest-client = 1.6.8
 INFO global:   - vagrant-hostsupdater = 0.0.11
 INFO global:   - vagrant-share = 1.1.3
 INFO global:   - vagrant-triggers = 0.5.0
 INFO global:   - vagrant-vmware-fusion = 3.2.6
```

[...]

```
DEBUG ssh: Re-using SSH connection.
 INFO ssh: Execute: /sbin/ifdown eth1 2> /dev/null (sudo=true)
DEBUG ssh: stderr: stdin: is not a tty

DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
DEBUG ssh: Sending SSH keep-alive...
```

[until canceling]

(why ifdown, when not configured...?)

so I tried same box without private ip and ffffffflllllluuup... box is up'n running, nfs mounts are working. Thanks to https://github.com/smdahlen/vagrant-hostmanager there is no need for private ips at the moment",True,False
mitchellh/vagrant/4050,False,56a78c206480fdcc3800378e,"I am having this same issue now. Endless SSH keep alives.

On VMWare Fushion 8",True,False
nextcloud/calendar/2890,False,6027414cbd3543242760ea42,"# [Codecov](https://codecov.io/gh/nextcloud/calendar/pull/2890?src=pr&el=h1) Report
> Merging [#2890](https://codecov.io/gh/nextcloud/calendar/pull/2890?src=pr&el=desc) (b9e36c4) into [master](https://codecov.io/gh/nextcloud/calendar/commit/604be314895cb689d18e825036751763747a378a?el=desc) (604be31) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/nextcloud/calendar/pull/2890/graphs/tree.svg?width=650&height=150&src=pr&token=NHWXToFGE3)](https://codecov.io/gh/nextcloud/calendar/pull/2890?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master    #2890   +/-   ##
=========================================
  Coverage     29.60%   29.60%           
  Complexity      116      116           
=========================================
  Files           154      154           
  Lines          5482     5482           
  Branches        812      812           
=========================================
  Hits           1623     1623           
  Misses         3859     3859           
```

| Flag | Coverage Δ | Complexity Δ | |
|---|---|---|---|
| javascript | `24.22% <ø> (ø)` | `0.00 <ø> (ø)` | |
| php | `94.29% <ø> (ø)` | `0.00 <ø> (ø)` | |

Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.


------

[Continue to review full report at Codecov](https://codecov.io/gh/nextcloud/calendar/pull/2890?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/nextcloud/calendar/pull/2890?src=pr&el=footer). Last update [604be31...b9e36c4](https://codecov.io/gh/nextcloud/calendar/pull/2890?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
nextcloud/calendar/2890,False,60306f04bd35434077c134c1,Superseded by #2898.,True,False
nextcloud/calendar/2890,False,60306f05bd3543429241df0b,Superseded by #2898.,True,False
komeiji-satori/Dress/512,False,5cfb6ef86480fd12a2864a48,"5.57 MB 的 png…… 这实在是太大了。
建议压缩到 1MB 一下。",True,False
MediaBrowser/Emby.WindowsPhone/236,False,558e894fbd3543f2fc01a078,Added to .67,True,False
apache/tinkerpop/650,False,595a25396480fd50b738426e,VOTE: +1,True,False
apache/tinkerpop/650,False,595cd66f6480fd57c2c4a721,VOTE +1,True,False
Atlantiss/NetherwingBugtracker/5000,False,5c6561276480fdd971edd45b,known,True,False
larcenists/larceny/666,False,51f4eb0ebd3543580f00023c,"**Author: will**
Will says this should wait for the R7RS io system, which may be incompatible with R6RS in some respects.  That may delay the fix until v0.99.",True,False
webitel/engine/4,False,5745913e6480fdc4ac05faa1,M,True,False
webitel/engine/4,False,5745913e6480fdcb9e05f98c,D,True,False
droolsjbpm/kie-wb-distributions/384,False,581225116480fd1e4bf92ca4,+1,True,False
radar/elastic/5,False,58336d026480fd05bd4ee9c8,Looks like it was just missing some triple-backticks: 4e91130. Or am I missing something else?,True,False
radar/elastic/5,False,58336d736480fd04a6d00c40,Published 2.3.3 with this documentation fix. Thanks for pointing that out!,True,False
appirio-tech/tc-billing-account-service/9,False,5895b6676480fd50b796b90a,"Thanks @skyhit 

Can you do a task to get this setup in dev for us with all the proper AWS config, CI, etc?",True,False
appirio-tech/tc-billing-account-service/9,False,5895d2b16480fd4e16be6b8a,"@ajefts sure, I can try, never did that completely from scratch. definitely need your help in the middle.

by the way, can you set the default branch for this repo as dev?",True,False
appirio-tech/tc-billing-account-service/9,False,589a035c6480fd98bbe64238,"@ajefts let's merge this PR, so we can go on making changes?",True,False
MicrosoftDocs/azure-docs/7832,False,5ae3b0be6480fd21061792e8,"@jlian : Thanks for your contribution! The author, @kgremban, has been notified to review your proposed change.",True,False
MicrosoftDocs/azure-docs/7832,False,5ae755676480fd2774139a91,"Thanks for the updates, @jlian

#sign-off",True,False
foxdad/hzdc/3,False,5efaf617bd354333083c723a,Superseded by #4.,True,False
GoogleCloudPlatform/esp-v2/435,False,5fcefda3bd354324db858324,/retest,True,False
GoogleCloudPlatform/esp-v2/435,False,5fcf0967bd354310346d8bfa,/retest,True,False
GoogleCloudPlatform/esp-v2/435,False,5fd12765bd354342053a4b91,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/GoogleCloudPlatform/esp-v2/pull/435#"" title=""Author self-approved"">nareddyt</a>*, *<a href=""https://github.com/GoogleCloudPlatform/esp-v2/pull/435#pullrequestreview-546723555"" title=""Approved"">qiwzhang</a>*, *<a href=""https://github.com/GoogleCloudPlatform/esp-v2/pull/435#pullrequestreview-546642698"" title=""Approved"">TAOXUY</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=GoogleCloudPlatform%2Fesp-v2).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[OWNERS](https://github.com/GoogleCloudPlatform/esp-v2/blob/master/OWNERS)~~ [TAOXUY,nareddyt,qiwzhang]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",True,False
GoogleCloudPlatform/esp-v2/435,False,5fd0f397bd354368ad6ea030,/retest,True,False
GoogleCloudPlatform/esp-v2/435,False,5fd10077bd35437b98c6ca72,"@nareddyt: The following test **failed**, say `/retest` to rerun all failed tests:

Test name | Commit | Details | Rerun command
--- | --- | --- | ---
ESPv2-presubmit-asan | 959fde41b1fed995c25813a238c145fc658a6599 | [link](https://oss-prow.knative.dev/view/gs/oss-prow/pr-logs/pull/GoogleCloudPlatform_esp-v2/435/ESPv2-presubmit-asan/1336348403235295232) | `/test ESPv2-presubmit-asan`

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
<!-- test report -->",True,False
HabitRPG/habitrpg/3051,False,55d820541b4876727c005fb6,"I don't think we want to allow fix character values to adjust # of perfect days, since those are technically achievements. 

@lemoness @Alys thoughts?",True,False
HabitRPG/habitrpg/3051,False,55d820701b487679d80073ab,"The number of Perfect Days also affects drop chances.

I'm in two minds about this. It would be nice to add a perfect day when you legitimately lose one, but it is open to abuse, although we don't normally worry about that. It's possible to get Perfect Day achievements (albeit much more slowly) by just spamming Dailies. 

Sort of related, you can also get challenge achievements by creating your own challenges and assigning yourself as the winner immediately, and we don't do anything to prevent that.

I think for me it comes down to: Do we care more about helping honest users who have lost a Perfect Day due to one of our bugs, or more about stopping mischievous users from making themselves look more productive than they are and for getting more drops than they earn which _might_ make them buy fewer drops with gems (although I don't think that would create a significant drop in income). I think I'm tending towards helping the honest users recover from bugs.

The current workaround for losing a Perfect Day you should have had is to remember that happened and the next time you're close to a PD, tick off the last couple of Dailies without actioning them. That's a really dodgy workaround though.",True,False
HabitRPG/habitrpg/3051,False,55d8dc971b48766fe800a6e2,"Personally, I'm leaning towards making it possible. If they really want to
incorrectly give themselves a perfect day achievement, they could have just
checked off all their Dailies in the first place. However, it's not a super
high-priority need.

On Sat, Jul 18, 2015 at 6:11 PM, Alys <notifications@github.com> wrote:

> The number of Perfect Days also affects drop chances.
>
> I'm in two minds about this. It would be nice to add a perfect day when
> you legitimately lose one, but it is open to abuse, although we don't
> normally worry about that. It's possible to get Perfect Day achievements
> (albeit much more slowly) by just spamming Dailies.
>
> Sort of related, you can also get challenge achievements by creating your
> own challenges and assigning yourself as the winner immediately, and we
> don't do anything to prevent that.
>
> I think for me it comes down to: Do we care more about helping honest
> users who have lost a Perfect Day due to one of our bugs, or more about
> stopping mischievous users from making themselves look more productive than
> they are and for getting more drops than they earn which *might* make
> them buy fewer drops with gems (although I don't think that would create a
> significant drop in income). I think I'm tending towards helping the honest
> users recover from bugs.
>
> The current workaround for losing a Perfect Day you should have had is to
> remember that happened and the next time you're close to a PD, tick off the
> last couple of Dailies without actioning them. That's a really dodgy
> workaround though.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/HabitRPG/habitrpg/issues/3051#issuecomment-122609903>.
>
",True,False
digitalbazaar/bedrock-express/18,False,5ed22b6bbd35431b901f3046,"the test were getting a bit long so I moved them over here: https://gist.github.com/aljones15/3defa74231551e5b9934d79609661ae1

Basically core findings:

1. when `maxAge` is set expired is updated on each `session.refresh`
2. When `maxAge` is set `maxAge` takes `predence` over `ttl` i.e. `ttl` can be expired, but the session will still refresh if `maxAge` has not expired, but not vice versa.
3. setting `saveUninitialized: false` does not disrupt session resumption or expiration behavior.
4. in development `bedrock-webpack` hot module reload calls will cause the session to refresh i.e. do not expect session behavior in development to be the same as in production.",True,False
digitalbazaar/bedrock-express/18,False,5ed22c7ebd354335c0e5fb72,"@aljones15 doesn't `rolling` only matter when `maxAge` is set to something other than `null`? I can't tell if you're testing with it set to `null` or not, but it seems like it from `originalMaxAge: null`. Please take a look at the rolling docs to see what kind of behaviors we would expect to see change and test for those things -- it seems we may also see a difference in how often the `set-cookie` header is sent (as opposed to just the value it uses for `maxAge`).",True,False
digitalbazaar/bedrock-express/18,False,5ed24137bd35436ea91d6fe5,"Confirmation that in the current version of connect-mongodb the `ttl` option is not used if `expires` is set on the cookie information associated with the session, a field which presumably gets calculated via `maxAge`:

https://github.com/jdesboeufs/connect-mongo/blob/cbd6483b7e9164eb2dd24f9058748605d4640c2c/src/index.js#L280-L291",True,False
digitalbazaar/bedrock-express/18,False,5ed24140bd354369346958cc,Does `rolling` cause the `Set-Cookie` header to be sent with every request? What are the actual effects of setting `rolling` to `true`?,True,False
digitalbazaar/bedrock-express/18,False,5ed24aaebd354311b0286f7f,"@aljones15 -- I would think that without setting `rolling` to `true`, the `Set-Cookie` header will not be sent when the session is ""refreshed"" ... which would cause the client's view of the cookie not to update. Can you confirm that's true by looking to see the expiration time for the cookie in the browser? If that's true, then the browser will expire the cookie before it expires on the backend -- which we don't want to happen (pointing to a need to use `rolling: true` and an acceptance of the overhead of the extra `Set-Cookie` header with every response). I don't really see how the client would know the cookie has been updated without this happening.

If it's the case, then I suspect we'll want to continue using `maxAge: null` to avoid that overhead. Then, to surface session expiration information to the client, we'd use `session.expires` (falling back to a value from the bedrock-express config if such a value is not present in the session itself) to populate a new `expires` property on the session object generated in bedrock-session-http (instead of using the value of `session.cookie.expires` which I believe we would target if `maxAge` did not have the overhead described above).",True,False
nicfit/TopFM/126,False,5c130c466480fd508f216ab1,Closing this in favor of #146,True,False
nccurry/go-kong/2,False,595cee2a6480fd51495a4304,"
[![Coverage Status](https://coveralls.io/builds/12259160/badge)](https://coveralls.io/builds/12259160)

Coverage increased (+3.6%) to 66.118% when pulling **8b6938fc3378e2bab539a10c7af294d03ca7c453 on SprintHive:master** into **071d546711a927e795d1e48527b68571cbe9dbbf on nccurry:master**.
",True,False
auth0/auth0-PHP/181,False,595fb1906480fd50b73b3163,If there are public API changes please add the `before -> after` to first comment.  Thx,True,False
auth0/auth0-PHP/181,False,595fb6ea6480fd5b842c9588,Im done with this PR now. I will create a new PR for cleaning up `Authentication`. That class will include some more BC breaks. ,True,False
auth0/auth0-PHP/181,False,59665dbe6480fd511e724fa7,@cocojoe LGTM,True,False
auth0/auth0-PHP/181,False,59671fe76480fd5b843014e0,"Awesome, Thank you for merging. 

A friendly reminder to enable StyleCI to make sure PRs comply with our coding standards. 

https://styleci.io/",True,False
auth0/auth0-PHP/181,False,5967675b6480fd54dda0a2fa,"yeah, it is not that easy since it should be authorized by the security team in the auth0 org.",True,False
auth0/auth0-PHP/181,False,596769446480fd53aec96308,"Ah, okey. Thanks",True,False
qssq/feedback/7,False,5bcf4e3d6480fd335fa3f2cd,### 升级最新,True,False
AnitaGrowsoon/PmonVsMK/5,False,5623d98d1b487698e20126d4,rewrote the function as part of a module and negated the scoping issue,True,False
AnitaGrowsoon/PmonVsMK/5,False,5623d99a1b4876987d010eb6,rewrote the function as part of a module and negated the scoping issue,True,False
AnitaGrowsoon/PmonVsMK/5,False,562410b01b48769fbb011ad6,@AnitaGrowsoon :+1: ,True,False
Mogli12/GearboxAddon/53,False,5824d3096480fd04a6c95719,"Yep, this happens with CVT when you are press space or switch gear while vehicle is not stopped.",True,False
Mogli12/GearboxAddon/53,False,5824db9a6480fd04e89bd40e,"it happens also with cvt and helper mode... like #54,  sorry,  its in german",True,False
Mogli12/GearboxAddon/53,False,5824e7276480fd050bf8b608,I hope that it is fixed with 2.0 beta 17,True,False
opendatateam/udata/931,False,59413eac6480fd56e11236d9,"@thimy it's OK for me on `dev`, can you check again?",True,False
opendatateam/udata/931,False,5941442e6480fd51c7a83a38,Seems to work indeed.,True,False
rust-lang/rust/61096,False,5ce704dd6480fd1440a72b42,"r? @nikomatsakis

(rust_highfive has picked a reviewer for you, use r? to override)",True,False
rust-lang/rust/61096,False,5ce730996480fd1112061fb8,r? @Centril  @bors r+ rollup,True,False
rust-lang/rust/61096,False,5ce730986480fd1440a73e40,":pushpin: Commit 46ffb6adbaed91a09d36953970078b0fae6de61f has been approved by `Centril`

<!-- @bors r=Centril 46ffb6adbaed91a09d36953970078b0fae6de61f -->",True,False
Blankj/AndroidUtilCode/593,False,5b71a5656480fdc200070c8d,"你传入的是 mdpi 尺寸的设计图宽度？你这问题应该是传入了高 dpi 的设计图尺寸，也就是调用 `ScreenUtils.adaptScreen4VerticalSlide(this, width);` width 值太小，如果想要达到原先效果那就 show dialog 时候 cancelAdaptScreen 好了，记得在项目中封装一下，那样就可以统一调用了",True,False
Blankj/AndroidUtilCode/593,False,5b728d306480fdc955dc8bb0,好的~謝謝,True,False
arlac77/aggregation-repository-provider/445,False,5cc19b956480fda0fdfa1d6f,":tada: This PR is included in version 2.3.3 :tada:

The release is available on:
- [npm package (@latest dist-tag)](https://www.npmjs.com/package/aggregation-repository-provider)
- [GitHub release](https://github.com/arlac77/aggregation-repository-provider/releases/tag/v2.3.3)

Your **[semantic-release](https://github.com/semantic-release/semantic-release)** bot :package::rocket:",True,False
ihrwein/puppet-syslog_ng/13,False,54480894bd3543a1d2044dbb,Unfortunately channels are not supported yet. Do you use them frequently?,True,False
ihrwein/puppet-syslog_ng/13,False,5448c894bd35439fe3040ea6,I have a couple of those yes. I chose to workaround this by using a `syslog_ng::config` block with a template,True,False
ihrwein/puppet-syslog_ng/13,False,54f0cf1ebd3543c65b00f549,"I add this issue to 1.1, it would be a nice feature. ",True,False
ACertainCoder/Presences/54,False,5fbf401cbd35436d67cdf1e9,The following labels could not be found: `dependencies`.,True,False
ACertainCoder/Presences/54,False,5fc47fcdbd354373756da0ba,Superseded by #61.,True,False
logstash-plugins/logstash-output-elasticsearch/80,False,550ff130bd3543370d0135f2,"@pickypg thanks for the report, this seems to be an issue with logstash itself.
using a simple `input { generator { count => 1 } } output { stdout { workers => 2} }` config yields:

```
bin/logstash -f config
You are using a deprecated config setting ""type"" set in stdout. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. You can achieve this same behavior with the new conditionals, like: `if [type] == ""sometype"" { stdout { ... } }`. If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>""type"", :plugin=><LogStash::Outputs::Stdout --->, :level=>:warn}
Logstash startup completed
You are using a deprecated config setting ""tags"" set in stdout. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. You can achieve similar behavior with the new conditionals, like: `if ""sometag"" in [tags] { stdout { ... } }` If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>""tags"", :plugin=><LogStash::Outputs::Stdout --->, :level=>:warn}
You are using a deprecated config setting ""exclude_tags"" set in stdout. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. You can achieve similar behavior with the new conditionals, like: `if !(""sometag"" in [tags]) { stdout { ... } }` If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>""exclude_tags"", :plugin=><LogStash::Outputs::Stdout --->, :level=>:warn}
You are using a deprecated config setting ""type"" set in stdout. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. You can achieve this same behavior with the new conditionals, like: `if [type] == ""sometype"" { stdout { ... } }`. If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>""type"", :plugin=><LogStash::Outputs::Stdout --->, :level=>:warn}
You are using a deprecated config setting ""tags"" set in stdout. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. You can achieve similar behavior with the new conditionals, like: `if ""sometag"" in [tags] { stdout { ... } }` If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>""tags"", :plugin=><LogStash::Outputs::Stdout --->, :level=>:warn}
You are using a deprecated config setting ""exclude_tags"" set in stdout. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. You can achieve similar behavior with the new conditionals, like: `if !(""sometag"" in [tags]) { stdout { ... } }` If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>""exclude_tags"", :plugin=><LogStash::Outputs::Stdout --->, :level=>:warn}
Logstash shutdown completed
Exception: Exception
```

I'm going to reopen the initial issue and close this one.",True,False
airbnb/native-navigation/98,False,59049a5e6480fd6f8b6b63da,Closing this. Had to run pod install manually,True,False
TheAlgorithms/Ruby/29,False,5fea6b33bd354333d7287ca0,done @christianbender ,True,False
TheAlgorithms/Ruby/29,False,5fea6b33bd354333d7287ca1,done @christianbender ,True,False
Codeception/Codeception/1190,False,53be3de4bd354350470067e3,Which PHP version / OS do you have?,True,False
Codeception/Codeception/1190,False,544ed192bd3543a0b3059d37,Not enough info to reproduce.,True,False
zuiidea/antd-admin/750,False,5a937c876480fd596d577c49,"首先不知是否指的是mock里的token，对于前端来说使用mock直接开发；对于后台而言，接口中设置就是了。
其次观察mock里token:
     /admin/login(设置token)
     `      res.cookie('token', JSON.stringify({
                id: admin[0].id,
                deadline: now.getTime()
            }), {
                maxAge: 900000,
                httpOnly: true
            })`
    /admin (检查token)
    !cookies.token",True,False
173210/psp2sdk/34,False,558ac07ebd3543efa5006223,"Use int instead of int32_t. By the way, why `buffer` in `SceCameraInfo` is not a pointer? Can you tell me the detail?",True,False
173210/psp2sdk/34,False,558ac6bcbd3543f0cd006b7c,Because it is not a buffer is a setting mode to tell lib how must use it if you put a pointer data type you will get 0x802e0000. ,True,False
benwbrum/fromthepage/1015,False,5aad26436480fd5908287531,"It looks like the sort and merge performed by the collection is a substantial part of the problem:

Three runs of `dashboard_controller#index`:
```
0.000427767 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
0.000364976 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
18.940604912 for @collections = (collections + @document_sets).sort{|a,b| a.title <=> b.title }

0.000569754 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
0.000425601 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
18.729787798 for @collections = (collections + @document_sets).sort{|a,b| a.title <=> b.title }

0.000511099 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
0.000378062 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
19.632911916 for @collections = (collections + @document_sets).sort{|a,b| a.title <=> b.title }
```",True,False
benwbrum/fromthepage/1015,False,5aad28e16480fd5a01dfd3de,"It definitely is - that was the last part that I couldn't get to speed up
with active record calls and eager loading, since document sets and
collections are different types of objects.  I wonder if some kind of pure
SQL call would be faster?


On Sat, Mar 17, 2018 at 10:29 AM, Ben W. Brumfield <notifications@github.com
> wrote:

> It looks like the sort and merge performed by the collection is a
> substantial part of the problem:
>
> Three runs of dashboard_controller#index:
>
> 0.000427767 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
> 0.000364976 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
> 18.940604912 for @collections = (collections + @document_sets).sort{|a,b| a.title <=> b.title }
>
> 0.000569754 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
> 0.000425601 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
> 18.729787798 for @collections = (collections + @document_sets).sort{|a,b| a.title <=> b.title }
>
> 0.000511099 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
> 0.000378062 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
> 19.632911916 for @collections = (collections + @document_sets).sort{|a,b| a.title <=> b.title }
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/benwbrum/fromthepage/issues/1015#issuecomment-373924186>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AQEsDeDYrIsJE2gU2gIJAgHOKntFhQBkks5tfR3AgaJpZM4SuzbE>
> .
>
",True,False
benwbrum/fromthepage/1015,False,5aad2b1f6480fd58bdaf3923,"Removing the merge does not improve matters:
```
0.000398986 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
0.000264169 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
19.121244558 for @collections = (collections + @document_sets)

0.000456924 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
0.000394834 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
19.62482547 for @collections = (collections + @document_sets)

0.026808756 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
0.00938105 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct
19.299825583 for @collections = (collections + @document_sets)
```

Somehow the merge is taking a long time?",True,False
benwbrum/fromthepage/1015,False,5aad2b7f6480fd56f6e28ed2,"I logged the code that runs between the start of the merge and the end of the merge, and it's *not* just combining arrays:

```
MERGE START
  Collection Load (27.2ms)  SELECT DISTINCT `collections`.* FROM `collections` INNER JOIN `deeds` ON `deeds`.`collection_id` = `collections`.`id` WHERE (`deeds`.`created_at` BETWEEN '2017-03-17 14:43:54' AND '2018-03-17 14:43:54')
  User Load (0.3ms)  SELECT `users`.* FROM `users`  WHERE `users`.`id` IN (2, 170, 189, 507, 4, 538, 557, 626, 632, 644, 674, 672, 677, 662, 740, 765, 777, 840, 839, 934, 972, 1006, 1257, 1774, 2797, 5124, 6423, 10282, 16942, 18800, 28748, 983, 31563, 33142, 33612, 35022, 36136, 33695, 42638)
  Work Load (36.3ms)  SELECT `works`.* FROM `works`  WHERE `works`.`collection_id` IN (1, 4, 5, 11, 12, 16, 34, 39, 40, 41, 45, 47, 49, 52, 55, 57, 58, 61, 71, 86, 87, 113, 119, 120, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 148, 149, 150, 151, 152, 153, 154, 163, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 215, 216, 217, 218)  ORDER BY title
  DocumentSet Load (27.4ms)  SELECT DISTINCT `document_sets`.* FROM `document_sets` INNER JOIN `document_sets_works` ON `document_sets_works`.`document_set_id` = `document_sets`.`id` INNER JOIN `works` ON `works`.`id` = `document_sets_works`.`work_id` INNER JOIN `deeds` ON `deeds`.`work_id` = `works`.`id` WHERE (`deeds`.`created_at` BETWEEN '2017-03-17 14:43:54' AND '2018-03-17 14:43:54')
  User Load (0.2ms)  SELECT `users`.* FROM `users`  WHERE `users`.`id` IN (170, 507, 662, 644, 817, 4, 18800)
  HABTM_Works Load (0.4ms)  SELECT `document_sets_works`.* FROM `document_sets_works`  WHERE `document_sets_works`.`document_set_id` IN (11, 3, 1, 2, 8, 9, 10, 16, 17, 18, 19, 23, 28, 32, 21, 26, 29, 27, 31, 33, 30, 25, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 24, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 100, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99)
  Work Load (26.7ms)  SELECT `works`.* FROM `works`  WHERE `works`.`id` IN (56, 65, 66, 67, 68, 142, 143, 144, 145, 146, 147, 149, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 217, 219, 220, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 340, 342, 344, 347, 349, 351, 355, 357, 359, 361, 363, 365, 367, 398, 400, 410, 412, 439, 441, 443, 446, 499, 1440, 1604, 1409, 1412, 1413, 1430, 1431, 1432, 1433, 1434, 1435, 1468, 1469, 1475, 1504, 1505, 1581, 1582, 1583, 1584, 1599, 1600, 1601, 1602, 1603, 1605, 2508, 2509, 2510, 1439, 1448, 1449, 1478, 1570, 1571, 1585, 1586, 1587, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1783, 2512, 2721, 2722, 1470, 1471, 1472, 1473, 1474, 1476, 1593, 1594, 1595, 1596, 1597, 1598, 1606, 1725, 1726, 1727, 1728, 1729, 1730, 2590, 2506, 2507, 2511, 2513, 2514, 2918, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3832, 3833, 3834, 3835, 3836, 3837, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3848, 3849, 3850, 3851, 3852, 3853, 3854, 3855, 3856, 3857, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3867, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3889, 3890, 3891, 3892, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304, 4305, 4306, 4439, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4617, 4618, 4619, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4633, 4634, 4635, 4636, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4649, 4650, 4651, 4652, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4671, 4672, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4699, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4782, 4783, 4784, 4785, 4786)
MERGE DONE
```",True,False
benwbrum/fromthepage/1015,False,5aad2dbf6480fd56a7cb0ce4,"Serializing the collection/document_set variables cuts down on the merge, but moves the lengthy query earlier.  It looks like Active Record's lazy loading has hidden the slow query from us by postponing it until we actually access `@document_sets`:

```
0.351981779 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct.to_a
19.40955844 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct.to_a
1.0134e-05 for @collections = (collections + @document_sets)

0.193696065 for collections = Collection.includes(:owner, :works).joins(:deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct.to_a
19.321233211 for @document_sets = DocumentSet.includes(:owner, :works).joins(works: :deeds).where(deeds: {created_at: (1.year.ago..Time.now)}).distinct.to_a
4.832e-06 for @collections = (collections + @document_sets)
```

And my logging statement shows those slow queries suddenly moved before the merge:

```
  DocumentSet Load (29.5ms)  SELECT DISTINCT `document_sets`.* FROM `document_sets` INNER JOIN `document_sets_works` ON `document_sets_works`.`document_set_id` = `document_sets`.`id` INNER JOIN `works` ON `works`.`id` = `document_sets_works`.`work_id` INNER JOIN `deeds` ON `deeds`.`work_id` = `works`.`id` WHERE (`deeds`.`created_at` BETWEEN '2017-03-17 14:59:44' AND '2018-03-17 14:59:44')
  User Load (0.2ms)  SELECT `users`.* FROM `users`  WHERE `users`.`id` IN (170, 507, 662, 644, 817, 4, 18800)
  HABTM_Works Load (0.3ms)  SELECT `document_sets_works`.* FROM `document_sets_works`  WHERE `document_sets_works`.`document_set_id` IN (11, 3, 1, 2, 8, 9, 10, 16, 17, 18, 19, 23, 28, 32, 21, 26, 29, 27, 31, 33, 30, 25, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 24, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 100, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99)
  Work Load (18.3ms)  SELECT `works`.* FROM `works`  WHERE `works`.`id` IN (56, 65, 66, 67, 68, 142, 143, 144, 145, 146, 147, 149, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 217, 219, 220, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 340, 342, 344, 347, 349, 351, 355, 357, 359, 361, 363, 365, 367, 398, 400, 410, 412, 439, 441, 443, 446, 499, 1440, 1604, 1409, 1412, 1413, 1430, 1431, 1432, 1433, 1434, 1435, 1468, 1469, 1475, 1504, 1505, 1581, 1582, 1583, 1584, 1599, 1600, 1601, 1602, 1603, 1605, 2508, 2509, 2510, 1439, 1448, 1449, 1478, 1570, 1571, 1585, 1586, 1587, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1783, 2512, 2721, 2722, 1470, 1471, 1472, 1473, 1474, 1476, 1593, 1594, 1595, 1596, 1597, 1598, 1606, 1725, 1726, 1727, 1728, 1729, 1730, 2590, 2506, 2507, 2511, 2513, 2514, 2918, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3832, 3833, 3834, 3835, 3836, 3837, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3848, 3849, 3850, 3851, 3852, 3853, 3854, 3855, 3856, 3857, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3867, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3889, 3890, 3891, 3892, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304, 4305, 4306, 4439, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4617, 4618, 4619, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4633, 4634, 4635, 4636, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4649, 4650, 4651, 4652, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4671, 4672, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4699, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780, 4781, 4782, 4783, 4784, 4785, 4786)
MERGE START
MERGE DONE
```",True,False
benwbrum/fromthepage/1015,False,5aad2dfb6480fd5d290f6b26,"One open question is whether, under the new role of the collections list as ancillary to the project list screen, we actually need works listed at all.",True,False
benwbrum/fromthepage/1015,False,5aad2fce6480fd5d290f6bc0,"I was just thinking about that.  We don't actually list the works on that
screen anymore, so it doesn't seem like there's any reason to include them
at this point, which might help.  We do join deeds in order to only display
collections that have been active in the last year, but I wonder if setting
a scope on collections and document sets themselves would speed that up
any?  (Or if, since it's going to be a secondary screen, they actually need
to be filtered out?)

On Sat, Mar 17, 2018 at 11:02 AM, Ben W. Brumfield <notifications@github.com
> wrote:

> One open question is whether, under the new role of the collections list
> as ancillary to the project list screen, we actually need works listed at
> all.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/benwbrum/fromthepage/issues/1015#issuecomment-373926667>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AQEsDYVFwc0GMS476Cdf3XTNtwNJigdrks5tfSV4gaJpZM4SuzbE>
> .
>
",True,False
benwbrum/fromthepage/1015,False,5aad304b6480fd5640ee424d,I'm going to remove the work pre-load and see whether that kicks the can down the road or actually fixes the problem.,True,False
benwbrum/fromthepage/1015,False,5aad30be6480fd5908287a37,"Actually, it looks like the deeds for a document set requires works:  `DocumentSet.includes(:owner, :works).joins(works: :deeds)`

Do you think that's because we expose deeds for private collections with public sets?",True,False
benwbrum/fromthepage/1015,False,5aad35846480fd5c2dd7cab9,"Thinking about a stripped-down collections page as comprehensive directory rather than site homepage, I suspect we don't need to retain the deeds list at all.",True,False
benwbrum/fromthepage/1015,False,5aad360f6480fd5a9f6568eb,"That does speed things up:
```
0.021601657 for collections = Collection.includes(:owner).distinct
0.011417429 for @document_sets = DocumentSet.includes(:owner).distinct
0.067394687 for @collections = (collections + @document_sets)
```",True,False
benwbrum/fromthepage/1015,False,5aad3b696480fd5750e4bbad,"I think the deeds were to filter out collections/sets that hadn't been worked on in more than a year.  So if we look at it as a comprehensive directory, that probably wouldn't be necessary.",True,False
benwbrum/fromthepage/1015,False,5aad42426480fd57ae5989e6,"Ah ha!  That makes sense -- a lot of it.

On Sat, Mar 17, 2018 at 10:59 AM, tbl73 <notifications@github.com> wrote:

> I think the deeds were to filter out collections/sets that hadn't been
> worked on in more than a year. So if we look at it as a comprehensive
> directory, that probably wouldn't be necessary.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/benwbrum/fromthepage/issues/1015#issuecomment-373931012>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAMNGX9UoVv4fgmyPuJz43hpp2KWKLc1ks5tfTLlgaJpZM4SuzbE>
> .
>



-- 
Ben W. Brumfield
Partner. Brumfield Labs LLC
Creators of FromThePage <https://fromthepage.com/>
",True,False
benwbrum/fromthepage/1015,False,5aae79be6480fd10aa962b81,"It seems that there rae two modes that are relevant for FromThePage users.  People on FromThePage.com will primarily be using the new project list, and will be using the collection list as a comprehensive directory with no deeds list.  People installing FromThePage on-site will not have the large list of works and collections that create this performance problem, and the project list doesn't really make sense for them.  

I think we should toggle within the code on, say, the number of collections.  For the typical FromThePage.com installation, the number will be `> 100`, and we should have the navigation items link to the new project list UI and comprehensive, deed-less collection list (which we should perhaps display at the bottom of the project list as a simple link).  Small  installations should use the existing UI.

This relates to #957.",True,False
benwbrum/fromthepage/1015,False,5aae79d76480fd11b35d2ada,We only need to handle this last bit of logic before we merge #957 (#988) into `master`.,True,False
benwbrum/fromthepage/1015,False,5aafd46d6480fd1e3b87ce33,"I think the ""show_to"" functionality in the collections list is also slowing things down, or at least making a huge number of calls to the database.  (Which might well be necessary, but I don't know if we can do anything with that code at all to help.)",True,False
localnerve/react-pwa-reference/202,False,57e5b9aa6480fdaa57f67295,"
[![Coverage Status](https://coveralls.io/builds/8031922/badge)](https://coveralls.io/builds/8031922)

Coverage remained the same at 94.176% when pulling **3897c328e99fe88d2ba0ef612bdc50753d7f87ae on greenkeeper-eslint-3.6.0** into **8bd96beab38f756e9deb1d01a74ecd5eb030e7b3 on master**.
",True,False
jasonlong/geo_pattern/16,False,53032cdabd3543f6fd002e8f,"Also, apologies for those trying to keep up on ports of this (@btmills, @bryanveloso). There shouldn't be any more sweeping tweaks like this after this pull.",True,False
jasonlong/geo_pattern/16,False,53032cdabd3543f6fd002e90,"Looking good, another thing you could do us use `attr_reader` for @opts, @hash and @svg:

    attr_reader :opts, :hash, :svg

so you don't need the `@` when ever you read the values else where, i.e. `hash` instead of `@hash`, the only place you need to still use @hash is when assigning it in `initialize`.

I also noticed that `hex_val` is always passed `@hash`, because it's an instance method, we can simply call it from within the method:

    def hex_val(index, len)
      @hash[index, len || 1].to_i(16)
    end

and reduce all the calls to `hex_val` to look like `hex_val(0,1)`",True,False
jasonlong/geo_pattern/16,False,53032cdabd3543f6fd002e91,"Awesome, thx @andrew. ",True,False
jasonlong/geo_pattern/16,False,53032cdabd3543f6fd002e92,I think this is looking pretty good now. I'm going to merge this because I have some new and updated patterns based on this branch.,True,False
ElemeFE/element/9422,False,5a6700066480fd0831564249,"Hello, this issue has been closed because it does not conform to our issue requirements. Please submit issues with [issue-generator](https://elementui.github.io/issue-generator/#/en-US). More info can be found in #3693.",True,False
un33k/django-ipware/7,False,5579d787bd3543e64c001c6c,"Thanks for the info. Please overwrite the settings for your setup for now
till the next release cycle.

On Thu, Jun 11, 2015 at 5:51 AM, Murat Knecht <notifications@github.com>
wrote:

> You list the 1.0.0.0/8 and 2.0.0.0/8 spaces as private by default. That's not
> true anymore
> <http://en.wikipedia.org/wiki/List_of_assigned_/8_IPv4_address_blocks#List_of_assigned_.2F8_blocks_to_the_Regional_Internet_Registries>
> — they have been opened up
> <http://arstechnica.com/business/2010/06/addresses-at-the-bottom-of-the-ipv4-barrel-not-so-pure/>
> for use around 2010.
>
> Currently, we're getting errors cuz we cannot get the IP of some visitors,
> with 1.38… prefix. While of course I can override the setting, it'd be more
> convenient (and helpful for others) to drop those two ranges from the
> defaults list.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/un33k/django-ipware/issues/7>.
>
",True,False
un33k/django-ipware/7,False,557e3022bd3543e64600f290,Please upgrade to version 1.1.0 and enjoy!,True,False
un33k/django-ipware/7,False,557e3022bd3543e65600f50d,Please upgrade to version 1.1.0 and enjoy!,True,False
un33k/django-ipware/7,False,557e6636bd3543e64800f703,"Huh, cheers! :)",True,False
LoopPerfect/buckaroo/118,False,5991685a6480fde7d5bfb960,"@TheAustinSeven Thanks for submitting this! 

Windows support is very rough right now, the main reason being that Buck on Windows is still a work in progress. (See https://github.com/facebook/buck/issues/1276)

However, we can do better for Buckaroo. I will setup an Appveyor CI build for Windows. ",True,False
LoopPerfect/buckaroo/118,False,5991f7206480fdecd227ed3c,"Yeah, I noticed that Buck has many issues on Windows as well. Thanks for doing this! If there is anything I can do to help with Windows support, I would love to get involved.",True,False
LoopPerfect/buckaroo/118,False,599709096480fde4721b1b95,Fixed the tests on Windows (https://github.com/LoopPerfect/buckaroo/tree/bugfix/windows). Will add Appveyor before merging to master. ,True,False
LoopPerfect/buckaroo/118,False,59a98d996480fde99529f520,"Hi @TheAustinSeven, sorry for the delay I was on annual leave. 

I have fixed the bugs on Windows and added an Appveyor build, which should prevent regressions. In future, we will require all tests to pass on macOS, Linux and Windows. 

I have also created [an issue for improving the installation process on Windows](https://github.com/facebook/buck/issues/1495). ",True,False
Shereef/GitVersion/47,False,5f75b502bd35437d2d62c1ab,Superseded by #52.,True,False
cstrap/monaco-font/3,False,52cee01abd3543bcb9006198,Good work! Thanks!,True,False
valhalla/thor/58,False,54d10640bd3543806e0035a9,thanks :+1: ,True,False
otuncelli/f5-steganography/5,False,5cf08d7b6480fd12a2812245,"Lite version added in [Releases](https://github.com/username1565/f5-steganography/releases).
284 KB only. No any packages and dependencies from some another dll-files.",True,False
orfjackal/idea-sbt-plugin/78,False,525fc8c5bd3543da7800053e,"Maybe your shell has an environment variable different to the SBT project launched by intellij-sbt-plugin?

Or using a different version of SBT? Make sure you pin down your projects SBT version by adding a file `./project/build.properties` containing `sbt.version=0.13.0` (or whichever version you want.). If that file is missing, the SBT launcher JAR picks the latest SBT version that it knows.

Just a guess, but I can't really do much more to help here.",True,False
miranda-ng/miranda-ng/310,False,580730996480fde2567671fc,"**Comment by frzme on 30 Jun 2014 13:27 UTC**
In the attached netlog there is a message "":zauber: 3 (netlog)"" as you can see from the screenshot this message did not show up in the message window or xml console.",True,False
miranda-ng/miranda-ng/310,False,580730996480fde2567671fd,"**Comment by watcher on 30 Jun 2014 14:13 UTC**
please start Miranda with /debug key and wait for crashlog to appear",True,False
TheAlgorithms/Python/482,False,5bc98b946480fde692421b68,"This pull request **introduces 3 alerts** and **fixes 12** when merging 2ba459f3d31c3ba076125e4a6fcd476cc9a49f62 into fedb3e70ab87e4d3151a98ed7a69aabb2978ae69 - [view on LGTM.com](https://lgtm.com/projects/g/TheAlgorithms/Python/rev/pr-91ae6fde92e2b7980750c9038a206ce1a9f86328)

**new alerts:**

* 1 for Missing named arguments in formatting call
* 1 for Syntax error
* 1 for &#39;input&#39; function used

**fixed alerts:**

* 7 for Encoding error
* 3 for Result of integer division may be truncated
* 2 for Syntax error

---

*Comment posted by [LGTM.com](https://lgtm.com)*",True,False
TheAlgorithms/Python/482,False,5bc98f736480fde8380815fd,"This pull request **introduces 2 alerts** and **fixes 14** when merging 42468dfb39bf360a9bbb55136abc6f2391c4b1f6 into fedb3e70ab87e4d3151a98ed7a69aabb2978ae69 - [view on LGTM.com](https://lgtm.com/projects/g/TheAlgorithms/Python/rev/pr-80536fdd5e103abf9eb11ff34875c13c4c2e1cc2)

**new alerts:**

* 1 for Syntax error
* 1 for &#39;input&#39; function used

**fixed alerts:**

* 7 for Encoding error
* 3 for Result of integer division may be truncated
* 2 for Syntax error
* 2 for &#39;input&#39; function used

---

*Comment posted by [LGTM.com](https://lgtm.com)*",True,False
danielanguita/Redmine-Inventory-Manager/9,False,55867f1cbd3543bad10004e5,"Hola, voy a revisar lo que dices, no debiera ser tan complejo",True,False
danielanguita/Redmine-Inventory-Manager/9,False,5586bea2bd35435bc20001fa,borro el comentario para que no genere ruido ya he sacado tareas al respecto,True,False
danielanguita/Redmine-Inventory-Manager/9,False,5586c354bd354357f3000357,"Hola, son buenas propuestas, creo que hay algunos casos que si le sirve a otra gente (por ej. tipo de documento y documento para los que compran no sólo con factura - puede ser boleta, guía de despacho, etc). El valor del producto es bueno para tenerlo como ""base"" o valor de lista.

Te propongo hagas un nuevo branch y luego vemos el merge, así puedes potenciar y trabajar sobre esa rama. ¿Necesitas que te de acceso para desarrollar verdad?",True,False
danielanguita/Redmine-Inventory-Manager/9,False,5586c354bd354357f3000358,"Si, asi puedo trabajar sobre tu repositorio en una nueva rama.

Por otro lado, nose si se pueden enviar mensajes privados para que podamos hablar por skype o por hangouts y mejorar este plugin de cara a que lo incluyan en redmine.

Dejamos esta issue abierta para hacerla también como mejora. Añadir los productos dentro de una issue para relacionarla de algún modo.",True,False
danielanguita/Redmine-Inventory-Manager/9,False,5586c354bd354357f3000359,"Oka, te mando interno",True,False
babel/babel/6922,False,5a1c81de6480fd15f752607a,Build successful! You can test your changes in the REPL here: https://babeljs.io/repl/build/6019/,True,False
luvit/luvi/34,False,547492f0bd3543c1a502cb0b,I wonder if we should use this instead of miniz when zlib is enabled?  There is a lot of overlap in functionality.  Here are my miniz bindings that are used for luvi's zip capabilities. https://github.com/luvit/luvi/blob/master/src/lminiz.c,True,False
luvit/luvi/34,False,54749364bd3543c08c02b1dc,The PR itself looks mostly good.  Just need to add to the `large` flavor for windows too https://github.com/luvit/luvi/blob/4d4f375037875773dfd13cb82d9188ad0ccb21d0/make.bat#L9,True,False
luvit/luvi/34,False,5488b693bd3543384100017f,+1 once make.bat has zlib in large flavor.,True,False
luvit/luvi/34,False,5488b693bd35433841000180,+1,True,False
luvit/luvi/34,False,5488b693bd35433841000181,"Issue building on my windows box:

```

       ""C:\Code\luvi\build\ALL_BUILD.vcxproj"" (default target) (1) ->
       ""C:\Code\luvi\build\lua_zlib.vcxproj"" (default target) (3) ->
       (ClCompile target) ->
         ..\deps\lua-zlib\lua_zlib.c(6): fatal error C1083: Cannot open include file: 'zlib.h': No such file or directo
       ry [C:\Code\luvi\build\lua_zlib.vcxproj]

    423 Warning(s)
    1 Error(s)
```",True,False
luvit/luvi/34,False,5488b693bd35433841000182,Works for me now!,True,False
terma/api-gateway-cloudfront-login/5,False,5a8b2a686480fd66ce46e529,Fixed.,True,False
zulip/zulip/3069,False,586bc9f66480fd0dae5cebe5,"*Automated message from Dropbox CLA bot*

@alexmorozov, thanks for the pull request! It looks like you haven't yet signed the Dropbox CLA. Please [sign it here](https://opensource.dropbox.com/cla/).",True,False
zulip/zulip/3069,False,586bcd9d6480fd0dae5cee43,"*Automated message from Dropbox CLA bot*
				
@alexmorozov, thanks for signing the CLA!",True,False
zulip/zulip/3069,False,586c68a66480fd0fdd74f659,I think it'll be a good idea to squash your last commit onto its previous one.,True,False
zulip/zulip/3069,False,586c6d626480fd164de35b17,"Awesome, thanks for doing this @alexmorozov!  I had my wife (who was born in Russia) read it over as review, and it looks great!  Merged (after squashing the commits), thanks @alexmorozov!!",True,False
zulip/zulip/3069,False,586ff2576480fd184cf23d7a,"@timabbott Oh boy, it's a small world. Please tell your wife ""Огромный привет из снежной России!"" and thanks for merging this in so quickly,",True,False
javiersantos/AppUpdater/83,False,58dc97136480fd491dfea3f6,"You can already do that:
`                .setButtonDoNotShowAgain(null)

it really should be clearer in the documentation though.",True,False
javiersantos/AppUpdater/83,False,58dc9bf06480fd4875bca004,"Thanks, great!

A.V.Ebrahimi
vakilzadeh@gmail.com

On Thu, Mar 30, 2017 at 9:56 AM, YoYo <notifications@github.com> wrote:

> You can already do that:
> ` .setButtonDoNotShowAgain(null)
>
> it really should be clearer in the documentation though.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/javiersantos/AppUpdater/issues/83#issuecomment-290306041>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAK8r2BA9Bm6pKNZBUXPnC8B3pLNUVCIks5rqz0RgaJpZM4Mt3g7>
> .
>
",True,False
electerious/Ackee/21,False,54535959bd3543e5740040fc,"I would recommend to switch to [gulp-sass](https://www.npmjs.org/package/gulp-sass) which is based on [node-sass](https://github.com/sass/node-sass) instead on ruby-sass. This way the user doesn't need to install them gem. This would also temporary fix #22, as node-sass is feature parity with SASS 3.2.",True,False
electerious/Ackee/21,False,54535a26bd3543e5920040f5,I'll take a look into gulp-sass. I am not sure why I choose gulp-ruby-sass over gulp-sass.,True,False
electerious/Ackee/21,False,545400acbd3543e49700656b,"Ok, this is solved now !",True,False
thisissoon/thisissoon-frontend/41,False,54de27eabd354381fb000871,"
[![Coverage Status](https://coveralls.io/builds/1923066/badge)](https://coveralls.io/builds/1923066)

Coverage remained the same at 74.36% when pulling **599cd96def39cee835db7e4a612e9357fe92b795 on feature/fix-skrollr-refresh** into **50eabbdbd5866139c83de45d13d8d9c2aa1fef56 on develop**.
",True,False
gdlc13051052765/github-slideshow/1,False,5fc8c34abd35437153f05741,"## Step 1: Assign yourself

Unassigned issues don't have owners to look after them. When you’re assigned to an issue or pull request, it tells repository visitors and contributors that you'll be facilitating the conversation or task :muscle:.

### :keyboard: Activity

1. On the right side of the screen, under the ""Assignees"" section, click the gear icon and select yourself

For a printable version of the steps in this course, check out the [Quick Reference Guide](https://lab.github.com/public/introduction-to-github.pdf).

<hr>
<h3 align=""center"">I'll respond when I detect you've assigned yourself to this issue.</h3>

> _Sometimes I respond too fast for the page to update! If you perform an expected action and don't see a response from me, wait a few seconds and refresh the page for your next steps._
",True,False
gdlc13051052765/github-slideshow/1,False,5fc8c34bbd35437153f05742,"## Step 1: Assign yourself

Unassigned issues don't have owners to look after them. When you’re assigned to an issue or pull request, it tells repository visitors and contributors that you'll be facilitating the conversation or task :muscle:.

### :keyboard: Activity

1. On the right side of the screen, under the ""Assignees"" section, click the gear icon and select yourself

For a printable version of the steps in this course, check out the [Quick Reference Guide](https://lab.github.com/public/introduction-to-github.pdf).

<hr>
<h3 align=""center"">I'll respond when I detect you've assigned yourself to this issue.</h3>

> _Sometimes I respond too fast for the page to update! If you perform an expected action and don't see a response from me, wait a few seconds and refresh the page for your next steps._
",True,False
golang/go/22645,False,5a04c0ff6480fd131f607a3d,"For what platform? Or to get the source?

If you want a OS/arch-specific ""latest"" URL, we'd need one per platform.

If you want the source, we have git with a stable URL.

I guess I don't understand the motivation yet. Why would it be ""really handy""?

",True,False
golang/go/22645,False,5a04d2ed6480fd176f56ee87,"Ideally, it would be nice to have a permalink to the latest for each platform and the source.

It would be handy in my case because I have some automated build and development setup tools that require go to build stuff; I would like to always ensure I'm building with the latest version.

As it stands, I'm forced to either scrape the website to figure out what the latest version is, or just live, with a static version, or build from source.",True,False
golang/go/22645,False,5a04dc4f6480fd15c4e767f4,"I don't think we're going to start publishing a download URL with contents that change over time.

I'm going to close this in favor of #20892 to make a programmatic way for callers (like your automation) to find the latest version(s).
",True,False
wymsee/cordova-imagePicker/184,False,57fc8e456480fdebfd28ed27,"me too, sad",True,False
wymsee/cordova-imagePicker/184,False,58220bfa6480fd0eb31e960b,Did you find a workaround for this issue?,True,False
wymsee/cordova-imagePicker/184,False,58235be56480fd0f18d54a9c,"Are you sure it's definitely caused by the image picker?
Try to debug on android using chrome inspect just to make sure it's not caused by something else, for example, 'null' string when using angular translator.",True,False
wymsee/cordova-imagePicker/184,False,584d7e436480fd97f8523247,Observed the same issue.,True,False
wymsee/cordova-imagePicker/184,False,586a36ec6480fd0c8730a5ca,"Have this same problem, inspected with chrome no  errors.",True,False
wymsee/cordova-imagePicker/184,False,586a5ab26480fd0dae5c50c8,"make sure the app is completely uninstall before you install the new one after NSPhotoLibraryUsageDescription added.

发自我的 iPhone

> 在 2017年1月2日，下午7:17，Dave Partner <notifications@github.com> 写道：
> 
> Have this same problem, inspected with chrome no errors.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",True,False
google/closure-templates/105,False,57712c286480fd1bcb6f0d51,"+1, this is confusing",True,False
google/closure-templates/105,False,577260636480fd1c2b2ed7c5,"Perhaps this is bug or a proper ""gotcha"".",True,False
google/closure-templates/105,False,577c1f3a6480fd5166923a4e,Could somebody help to find out what is going wrong?,True,False
google/closure-templates/105,False,57849eb76480fd9163e1c556,"Thanks for the reply @lukesandberg.
I've debugged again our code and I finally found the issue. It was on our side, we exported the wrong symbol for `soydata.VERY_UNSAFE.$$ordainSanitizedHtmlForInternalBlocks` which was always returning unsanitizedText.
Apologies.",True,False
celery/celeryproject/28,False,5ceda53a6480fd0fe09a5231,"Judging by https://docs.readthedocs.io/en/stable/custom_domains.html#custom-domain-ssl, it looks like a change is required for the docs.celeryproject.org CNAME DNS record from ""celery.readthedocs.org"" to ""readthedocs.io"" so that the site is proxied via CloudFlare and they can issue an SSL certificate for the custom domain.",True,False
celery/celeryproject/28,False,5cf3e6386480fd11120c0262,I would like to raise urgency here. The net is full of https links to celery docs (and rightfully so in my opinion) so it would be nice to get this fixed sooner than latter. Thanks!,True,False
celery/celeryproject/28,False,5d11b3e26480fd162d54de31,"Looks like a duplicate of #24, should continue to push there.",True,False
deepchem/deepchem/659,False,596637c06480fd5f02661d2f,"@miaecle I'll look through it today.  My initial guess is that despite using the same ""layers"" we are using different initialization constants.",True,False
deepchem/deepchem/659,False,59664da96480fd5c884f54a6,"@lilleswing That will be super helpful, thanks a lot!",True,False
deepchem/deepchem/659,False,59669a546480fd5c4540c34b,"Have you looked into the learning rate decay schedule? I can't speak to Weaves, but that was one of the differences on the GraphConv side.",True,False
deepchem/deepchem/659,False,59808cba6480fd5ab532d1b5,"Hi all. I'm new here and have been looking the DeepChem code - appreciating all the amazing work that's gone into the project -  and have just come across this issue. Have you been able to figure out what the reason is? 

In order to understand better what's going on, I've also tried to unsucessfully figure out a simple way to read out the outputs of intermediate layers. Does the TensorGraph class provide an easy way to do this?

Thanks a lot!",True,False
deepchem/deepchem/659,False,5980a5926480fd5812c13e9e,"Hi @vid33, TensorGraph does not currently have an easy way of viewing the intermediate layers.  What I would recommend though is setting TensorGraph.outputs to a singleton list of the layer you are interested in viewing.

When you do this TensorGraph.predict_proba will return the evaluation for the layer you are interested in.  Here is a working example of it in action.

```python
""""""
Script that trains graph-conv models on Tox21 dataset.
""""""
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import numpy as np

import tensorflow as tf

tf.set_random_seed(123)
import deepchem as dc
from tox21_datasets import load_tox21
from deepchem.models.tensorgraph.models.graph_models import GraphConvTensorGraph

model_dir = ""/tmp/graph_conv""

# Load Tox21 dataset
tox21_tasks, tox21_datasets, transformers = load_tox21(featurizer='GraphConv')
train_dataset, valid_dataset, test_dataset = tox21_datasets

# Batch size of models
batch_size = 50

model = GraphConvTensorGraph(
    len(tox21_tasks), batch_size=batch_size, mode='classification')

model.fit(train_dataset, nb_epoch=10)
key_layer = model.layers['Dense_2']
model.outputs = [key_layer]
X = model.predict_proba(train_dataset)
print(X)
```

Eventually we want to be able to pass a list of layers into the TensorGraph#predict* functions as an optional parameter but haven't gotten around to doing the work yet.",True,False
deepchem/deepchem/659,False,5980a9af6480fd5a88591714,"Thanks, that probably saved me hours! I'll let you know if I manage to understand where the above discrepancy is coming from.",True,False
deepchem/deepchem/659,False,59810e1b6480fd5d78694f1d,"Found a typo in `WeaveTensorGraph` which turns off the `gaussian_expand` function, that cause the worse performance. Thanks @patrickhop and @lilleswing for providing the help! 
@vid33 Welcome! I basically agree with @lilleswing , this seems to be the easy way to look at intermediate output.
I will go ahead and close this issue.",True,False
Azure/autorest.csharp/59,False,5a25e5896480fd1935321d35,"<!--AUTO-GENERATED PUBLISH JOB COMMENT-->
# 🤖 AutoRest automatic publish job 🤖
~~~ Haskell
> will publish once PR gets merged
~~~",True,False
Azure/autorest.csharp/59,False,5a25e7866480fd181f52df6a,"<!--AUTO-GENERATED COVERAGE COMMENT-->
# 🤖 AutoRest automatic feature coverage report 🤖
*feature set version 2.3.13*

## ❌️ General: 99%

<details><summary>2 out of 522 features are not covered by tests</summary><p>

[`getComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=getComplexPolymorphismComplicated), [`putComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=putComplexPolymorphismComplicated)</p></details>

## ✔️ Azure: 100%



",True,False
Azure/autorest.csharp/59,False,5a25eaef6480fd176f63a617,"<!--AUTO-GENERATED COVERAGE COMMENT-->
# 🤖 AutoRest automatic feature coverage report 🤖
*feature set version 2.3.13*

## ❌️ General: 99%

<details><summary>2 out of 522 features are not covered by tests</summary><p>

[`getComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=getComplexPolymorphismComplicated), [`putComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=putComplexPolymorphismComplicated)</p></details>

## ✔️ Azure: 100%



",True,False
Azure/autorest.csharp/59,False,5a25eb456480fd14f95638df,"<!--AUTO-GENERATED COVERAGE COMMENT-->
# 🤖 AutoRest automatic feature coverage report 🤖
*feature set version 2.3.13*

## ❌️ General: 99%

<details><summary>2 out of 522 features are not covered by tests</summary><p>

[`getComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=getComplexPolymorphismComplicated), [`putComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=putComplexPolymorphismComplicated)</p></details>

## ✔️ Azure: 100%



",True,False
Azure/autorest.csharp/59,False,5a25efad6480fd1522568593,"<!--AUTO-GENERATED COVERAGE COMMENT-->
# 🤖 AutoRest automatic feature coverage report 🤖
*feature set version 2.3.13*

## ❌️ General: 99%

<details><summary>2 out of 522 features are not covered by tests</summary><p>

[`getComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=getComplexPolymorphismComplicated), [`putComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=putComplexPolymorphismComplicated)</p></details>

## ✔️ Azure: 100%



",True,False
Azure/autorest.csharp/59,False,5a25f75a6480fd14c90e2483,"<!--AUTO-GENERATED COVERAGE COMMENT-->
# 🤖 AutoRest automatic feature coverage report 🤖
*feature set version 2.3.13*

## ❌️ General: 99%

<details><summary>2 out of 522 features are not covered by tests</summary><p>

[`getComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=getComplexPolymorphismComplicated), [`putComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=putComplexPolymorphismComplicated)</p></details>

## ✔️ Azure: 100%



",True,False
Azure/autorest.csharp/59,False,5a25fa886480fd139ee80329,"<!--AUTO-GENERATED COVERAGE COMMENT-->
# 🤖 AutoRest automatic feature coverage report 🤖
*feature set version 2.3.13*

## ❌️ General: 99%

<details><summary>2 out of 522 features are not covered by tests</summary><p>

[`getComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=getComplexPolymorphismComplicated), [`putComplexPolymorphismComplicated`](https://github.com/Azure/autorest.testserver/search?q=putComplexPolymorphismComplicated)</p></details>

## ✔️ Azure: 100%



",True,False
rust-lang/rust/21763,False,54cacbd9bd354350bd0027d8,"It appears that this also isn't specifically related to trait bounds:

```
use std::collections::HashMap;
use std::rc::Rc;
fn foo<T: Send>() {}
fn main() {
    foo::<HashMap<Rc<()>, Rc<()>>>();
}
```

cc @Gankro, @pczarn, @cgaebel, ",True,False
rust-lang/rust/21763,False,54cacd41bd35433d1d00284c,"Ah, yeah. RawTable contains only a `Unique<u8>`, which is of course always Send/Sync. It should presumably just contain a plain `*mut u8` and impl Send/Sync conditionally?",True,False
rust-lang/rust/21763,False,54cace54bd35433c3f002623,Or we need a more rich marker type.,True,False
rust-lang/rust/21763,False,54cad0aabd35433bbe001617,"https://github.com/rust-lang/rfcs/pull/738 may be a good replacement for the current system as it could contain a marker of `Vec<K>` and `Vec<V>` for example. For now though a manual impl of `Send` and `Sync` will probably be required.

Should other collections with an unsafe representation also be audited?",True,False
rust-lang/rust/21763,False,54cad1cfbd35433e1c00268f,I can say confidently this is the only problem case in collections. It's the only collection that uses basically a `void` pointer.,True,False
rust-lang/rust/21763,False,54caeccabd35433bbe0019e2,"ok cool, good to know!
",True,False
xmpp-ftw/xmpp-ftw-disco/32,False,56f07a8b6480fd63d5008c2f,"
[![Coverage Status](https://coveralls.io/builds/5496925/badge)](https://coveralls.io/builds/5496925)

Coverage remained the same at 100.0% when pulling **4133a3edf4396ccda2f2cbf27b7e4b6bfb2fa41b on greenkeeper-grunt-cli-1.0.0** into **cc5f9bed88b25a18d5923a08eac620184a6dd6ad on master**.
",True,False
xmpp-ftw/xmpp-ftw-disco/32,False,5710a4a56480fd7362002823,"
[![Coverage Status](https://coveralls.io/builds/5788341/badge)](https://coveralls.io/builds/5788341)

Coverage remained the same at 100.0% when pulling **6226897e8f67c228011578054e1bcee149e822b4 on greenkeeper-grunt-cli-1.0.0** into **67b7096b64bcb19dd6d64908c76b69c2b8207abf on master**.
",True,False
agalue/OpenNMS-UI-Requisitions/1,False,545a9d2abd3543e36601c471,Are you using OpenNMS 14 ? Could you share more details about your environment ?,True,False
agalue/OpenNMS-UI-Requisitions/1,False,545abb7cbd3543e3be01f368,"This was against 1.12. Looks like the JSON data changed between 1.12 and 14.

In requisition.model.js, requisition['foreign-source'] is undefined, while requisition['@foreign-source'] is defined, and so on...",True,False
agalue/OpenNMS-UI-Requisitions/1,False,545b8c50bd3543e38d01f422,"Indeed the JSON format of the XML data in 1.12 is completely different and not compatible with 14:

1) The null objects are not exposed on the XML/JSON in 1.12, but in 14, they appears as null or empty array.

2) The attributes has '@' as a prefix in 1.12, which is not the case on 14.

3) The JSON annotations are not going on the same way in both versions because of the changes performed on the JAXB/Eclipse backend.

The above are the main differences that I have in mind, but there are others.

That is why my Angular App for requisitions only works on 14 and no with older versions.",True,False
coreos/prometheus-operator/2045,False,5bd07b176480fd335fa51f24,"dang, there is a generation error:
```diff
-        - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.24.0
-        image: quay.io/coreos/prometheus-operator:v0.24.0
+        - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.25.0
+        image: quay.io/coreos/prometheus-operator:v0.25.0
```",True,False
MakeNowJust/rerejs/229,False,5f683b5bbd35435b3097f865,"# [Codecov](https://codecov.io/gh/MakeNowJust/rerejs/pull/229?src=pr&el=h1) Report
> Merging [#229](https://codecov.io/gh/MakeNowJust/rerejs/pull/229?src=pr&el=desc) into [master](https://codecov.io/gh/MakeNowJust/rerejs/commit/d6ce6295786d0f754a226fb3e6481266d03b8f41?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/MakeNowJust/rerejs/pull/229/graphs/tree.svg?width=650&height=150&src=pr&token=HN1bN0IoxH)](https://codecov.io/gh/MakeNowJust/rerejs/pull/229?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master     #229   +/-   ##
=======================================
  Coverage   97.86%   97.86%           
=======================================
  Files          13       13           
  Lines        1543     1543           
  Branches      317      317           
=======================================
  Hits         1510     1510           
  Misses         15       15           
  Partials       18       18           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/MakeNowJust/rerejs/pull/229?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/MakeNowJust/rerejs/pull/229?src=pr&el=footer). Last update [d6ce629...389aad4](https://codecov.io/gh/MakeNowJust/rerejs/pull/229?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
groupby/api-javascript/239,False,5f03381fbd3543484dd1dd87,Superseded by #242.,True,False
nideveloper/CDK-SPA-Deploy/221,False,6029f639bd35430dd19eaa13,"Looks like jsii is up-to-date now, so this is no longer needed.",True,False
shusain93/OSXMessageProxy/7,False,59094cbb6480fd6a3a1d5b2d,These values are what you should see when you click the ingredients button when filling out the Pushbullet part. You'll need to plug them in as specified or how you feel. Where you put each value is essentially where you are putting each component of the notification. ,True,False
shusain93/OSXMessageProxy/7,False,59094fe46480fd6c2ca141f8,Ah so the Pushbullet service would be the action. Would I be pushing a note or a link?,True,False
shusain93/OSXMessageProxy/7,False,590950436480fd645f41442f,A link. The link (in the format in the instructions) will let you auto launch the app when you tap the notification ,True,False
shusain93/OSXMessageProxy/7,False,590959076480fd70953210b5,"![screen shot 2017-05-03 at 2 13 05 pm](https://cloud.githubusercontent.com/assets/28289802/25648020/ad86860e-300a-11e7-8f93-33729b7e6d34.png)

Sorry to bother you one last time, does this look anything like how it should be done?",True,False
shusain93/OSXMessageProxy/7,False,590959af6480fd6fbb03f204,"![img_1015](https://cloud.githubusercontent.com/assets/1606726/25648061/f0c794de-2f84-11e7-8910-c79a2c5c3797.PNG)

I mean it'll work, just won't give what you want. Fill it out like I did. Next time thought please try before asking?
",True,False
shusain93/OSXMessageProxy/7,False,59095af96480fd666e61131d,I apologize. I have been trying to send the messages but it has not been working. It appears a bigger problem lies somewhere else (probably with my server). I will keep trying to figure it out. Thank you so much for your time.,True,False
shusain93/OSXMessageProxy/7,False,59095b3f6480fd64b3f6ac8d,Can you post your server log file? It should be in your home directory under iMessageProxy. The file should be today's date.,True,False
shusain93/OSXMessageProxy/7,False,59095c4f6480fd7229fba792,"
[2017-05-03.txt](https://github.com/shusain93/OSXMessageProxy/files/972436/2017-05-03.txt)


",True,False
shusain93/OSXMessageProxy/7,False,59095cc86480fd6621e32583,Does the app properly work/can you see and send messages? The log doesn't tell me much since you haven't really done anything. Have you received messages while the server is running?,True,False
shusain93/OSXMessageProxy/7,False,59095df76480fd6c2ca14679,"[2017-05-03.txt](https://github.com/shusain93/OSXMessageProxy/files/972442/2017-05-03.txt)
Here is an updated log file when I texted a message from myself to myself. It does not show ""Got 1 new message"" until i close the message proxy app and the script reopens it.",True,False
shusain93/OSXMessageProxy/7,False,59096a396480fd74d4cc93c5,"Hi there, just wanted to say that everything is now working and thank you so much for your help. This is such an excellent project and I have learnt so much. ",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f1,"Sounds good. In a discussion with @mfrey recently I wondered why we were not using assert(), but then forgot it again.",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f2,"I talked to Hauke about this.
One drawback is that errors are just detected, and cannot be acted upon.

But then again, IMHO we cannot afford to check all return codes for all the little setters and getters we have anyways.",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f3,"There's no reason to replace all `DEVELHELP` occurrences with `assert`, but in many places (like the discussed length parameter check) it satisfies our needs. In many cases you cannot really act in a sensible manner upon an error any way on deeply embedded systems apart from restarting.",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f4,"I remember that I worked with assert a while back, but there were some
problems (I think it was that msp430 and avr don't include it into their
respective libcs).
",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f5,We could add the header for those platforms. The actual definition can be *very* short.,True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f6,"> There's no reason to replace all DEVELHELP occurrences with `assert`

+1 (and I think that was exactly the idea here).

For implementing this, I think I would tend to create a RIOT specific assert header with an `ASSERT()` define, and map this then to the clibs assert. On platforms, where assert is not availble in the clib, we can then just implement our own thing...",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f7,Do you think that's necessary? In the it just needs some way to print and call `abort()` (which can be easily mapped to `core_crash()`). The missing definition for MSP430 was merged some time ago IIRC.,True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f8,I have no idea. But in the end I do not care how we implement it...,True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008f9,"I propose, we add ""assert.h"" includes to the cpu directories that need it, and those just include ""riot_assert.h"". For the other platforms, we go with the libc version.

riot_assert.h static inline defines assert() to what the libc implementations do: print something like ""assert failed in __func__ __LINE__ ..."".",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008fa,"If we make it crash, we cannot see how the failed assert actually crashes the system, and also the system would behave differently depending on asserts being enabled (compiled without NDEBUG).",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008fb,"ah, on native, assert crashes.",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008fc,"and newlib calls ""exit(1)"", resetting the board.",True,False
RIOT-OS/RIOT/2931,False,554f7d8ebd3543ed710008fd,"Sorry, I meant `core_panic()`.",True,False
RIOT-OS/RIOT/2931,False,5661c2c56480fd80df001248,"We're using assert all over the place, so I'll close this as solved.",True,False
OpenSourceMalaria/OSM_To_Do_List/140,False,52d75275bd3543bca105ff86,"This is very important. Many of the ELN entries are quite informal ""notes-to-self"" and this should stop. People are generally good about uploading data (though we're missing LCMS data I think). The most important things needed:
1) Closure: If an experiment is complete, there needs to be a conclusion written at the *start* of the entry.
2) Context: There needs to be a sentence about context, plus a link. Every experiment is carried out in response to something (an issue, or another experiment) and this needs to be provided. Keep in mind that people may well be coming to an experiment ""cold"" - i.e. discovering the reaction via Google and dropping into OSM at that point. They need to be able to navigate out and up. If in doubt, put yourself in the mind of a scientist unfamiliar with OSM's current activities.
3) Citations: If an ELN entry is being used as the basis for any statements elsewhere, e.g. on GitHub, please remember to link to the ELN entry, which should be the repository of all the raw data.
4) Inchis: Please include strings such as InChIs for the compounds being made. This makes the pages more discoverable.
5) Tagging as ""Being Synthesised"": If you're making a molecule, and making ELN entries, then your overall target needs to be listed as a molecule being synthesised on Github, i.e. by having an Issue labelled as such that is assigned to you. This is important as it allows us to generate automatically-updated links that describe what is being done in the project by whom and by when.

All these things take time, but they're essential.",True,False
OpenSourceMalaria/OSM_To_Do_List/140,False,52db258dbd3543bcb9074c69,"Perhaps these extra points - the meta stuff about how to use the ELN and GH - should be written as an ELN entry as a ""good practice"" guide? I will do that. The downside is that this fragments the user guides, but the upside is that it highlights these things for people succinctly, and in many cases (e.g. the importance of context) the same things come up for both ELN and GH.",True,False
OpenSourceMalaria/OSM_To_Do_List/140,False,52dd0d73bd3543bc1d07a10a,"Done. http://malaria.ourexperiment.org/osm_logos_and_templ/8576
Closing.",True,False
OpenSourceMalaria/OSM_To_Do_List/140,False,52dd0d74bd3543bc2807b83a,"Done. http://malaria.ourexperiment.org/osm_logos_and_templ/8576
Closing.",True,False
nilmtk/nilmtk-contrib/26,False,5ea8f164bd35433f5f1bef67,Follow-up: downgrading **scikit-learn** to 0.21.3 resolves the problem.,True,False
nilmtk/nilmtk-contrib/26,False,5ea8f3efbd354374ef577780,@Rithwikksvr can you look into this?,True,False
nilmtk/nilmtk-contrib/26,False,5ea850d9bd3543714a59cdf5,@nipunbatra i'll try to resolve it ASAP!,True,False
nilmtk/nilmtk-contrib/26,False,60640636bd35436b1868356f,"why not fix it in new version?
scikit-learn     0.21.3
h5py               2.10.0",True,False
nilmtk/nilmtk-contrib/26,False,6064066ebd35430890750c6c,"In new version, it doesnot work for this baseline algorithms.",True,False
hazelcast/hazelcast/4651,False,54e70a6bbd35437ccc000389,"We already recognized and working on resolving the issue! :)

Thanks for notifying!",True,False
hazelcast/hazelcast/4651,False,54e70f5dbd3543743d00052f,"thanks for reporting, fixed.",True,False
openlayers/ol3/3583,False,55326a78bd3543092e00105a,Go @marcjansen!  Please merge.,True,False
openlayers/ol3/3583,False,553282d1bd35432a170012a3,Thankee-sai,True,False
VitorHugoOli/recuperacao_de_informacao_TP3/1,False,5edc525fbd35437cd13874a7,Superseded by #2.,True,False
evyfjae/lionproject/3,False,5edb61a3bd35432113f9e627,Superseded by #4.,True,False
react-toolbox/react-toolbox/1176,False,58887acb6480fd1a9e69e287,"@Tudmotu Right now it is not possible I think and that's why #1169 exists. The implementation that is coming will allow you to fully customize the autocomplete possibilities, children, and filtering function. If you want to PR the change meanwhile, I'll be happy to merge it!

Nonetheless I'm closing in favor of #1169 :) ",True,False
frappe/erpnext/7618,False,58bebf216480fd66893fc462,Can't replicate. Are you checking both the report for the same item and warehouse?,True,False
frappe/erpnext/7618,False,58c236286480fd69eada6ab4,Yes checking the same item and warehouse.,True,False
frappe/erpnext/7618,False,58dbadba6480fd5401450c3e,"This is something related to your data. Really difficult to say anything without checking your data. Please try to debug yourself, closing this issue.",True,False
hexbot/Hexbot-Client-Issues/266,False,531d870abd35431e010060d1,"Thanks @Zaqmasterbot for reporting this issue.
This will be fixed in 3.0.8",True,False
hexbot/Hexbot-Client-Issues/266,False,531e9cb1bd3543c83d005d49,I notice that .8 came out today. Did this get added? I'm not quite at a point where I can check just yet.,True,False
hexbot/Hexbot-Client-Issues/266,False,5329d50ebd354386bf00cbc5,@SwipeX @AlphaDog209 ,True,False
hexbot/Hexbot-Client-Issues/266,False,5329d54bbd3543874200d10e,"This isn't a very common case, however it does show that the random solvers need to be more robust with their solutions.",True,False
jackzhang1111/shopjn/5,False,604ac0d8bd3543446005c30d,Superseded by #11.,True,False
McDono/beer_selector/6,False,6048c794bd3543353751c3cd,Superseded by #9.,True,False
jessie-codes/vuecle-ssr/4,False,6047cb65bd354311441641a8,Superseded by #11.,True,False
infinite-industries/front_end_infinite/39,False,5bf58f106480fd67d5778e75,Fixed by [f2fa7501](https://github.com/infinite-industries/front_end_infinite/commit/f2fa75012affbc3cdde753c4e5c15761d521d6d2) and [71ec398c](https://github.com/infinite-industries/front_end_infinite/commit/71ec398c405c6020e1daa81ad31caae0c2d46985),True,False
conda-forge/staged-recipes/739,False,5758c4356480fdfdecc3098d,"
Hi! This is the friendly automated conda-forge-linting service.

I just wanted to let you know that I linted all conda-recipes in your PR (```recipes/autopep8```) and found it was in an excellent condition.

",True,False
conda-forge/staged-recipes/739,False,5758dce06480fdfdecc31fc8,Should we add `pep8` too?,True,False
conda-forge/staged-recipes/739,False,575900a46480fd023da1f16b,It would make sense...,True,False
conda-forge/staged-recipes/739,False,575902aa6480fdfc8f27ab5a,Done.  See [#740](https://github.com/conda-forge/staged-recipes/pull/740),True,False
conda-forge/staged-recipes/739,False,575c4e126480fdfd1946afd6,@pmlandwehr waiting for you answer on https://github.com/conda-forge/staged-recipes/pull/740/files#r66709209 to merge this one.,True,False
sekaiproject/ponscripter-fork/17,False,5322ab84bd3543c76001dc6a,"Thanks for the report. 

I'll try and fix all the redraw-failures for the next beta build. The performance hit might take a bit more work, but I'll definitely look into it.",True,False
sekaiproject/ponscripter-fork/17,False,5322d629bd3543c83d01b70c,windows 7 this bug disappears after double opening overlay,True,False
sekaiproject/ponscripter-fork/17,False,5322d86cbd3543c71c01d984,"Also on Windows 7, use of the Steam overlay can sometimes render the entire program unresponsive. I don't have a precise way to replicate this issue, but by Shift-Tabbing a number of times while navigating the menus and the like, I've had it completely stall the program (though it's sometimes possible to recover from this by minimising and unminimising the window).",True,False
sekaiproject/ponscripter-fork/17,False,532a9641bd3543872200fdd0,"I think the issues listed here are actually fixed.
Everything should redraw (no more ghosting). The black borders should also redraw (no trails there). 

The performance issue mentioned in 2) is not fixed, but I think discussion for this should be moved to #21. Check if the ghosting issue is resolved for you; if it is I'd like to close this and consolidate the overlay issues deriving from not re-rendering frequently enough to 21. Thanks!",True,False
sekaiproject/ponscripter-fork/17,False,532aea19bd3543867301172f,"Yep, confirmed that the ghosting in 1) as well as the afterimage in 3) no longer exists 

For solving 2), is there perhaps a way to detect if the Steam overlay is open or not? I've noticed some games will automatically pause when you open the Steam overlay, and resume once you close the overlay.

You could possibly update/redraw the screen at the monitor's refresh rate whenever the Steam overlay is open and revert to the usual behaviour once it is closed?",True,False
sekaiproject/ponscripter-fork/17,False,532b1c31bd354385e70127bc,Closing to solve 2) I've created a new ticket at #45 ,True,False
mcandre/hla/4,False,5cc6c41d6480fda0a6466212,Still no solution?,True,False
aim-uofa/AdelaiDet/48,False,5eaa6626bd354307cbb85517,"Traceback (most recent call last):
  File ""demo/demo.py"", line 74, in <module>
    demo = VisualizationDemo(cfg)
  File ""/nfs/project/huangzhipeng/tools/opensorce/AdelaiDet/demo/predictor.py"", line 37, in __init__
    self.predictor = DefaultPredictor(cfg)
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/detectron2/engine/defaults.py"", line 184, in __init__
    self.model = build_model(self.cfg)
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/detectron2/modeling/meta_arch/build.py"", line 21, in build_model
    model = META_ARCH_REGISTRY.get(meta_arch)(cfg)
  File ""/nfs/project/huangzhipeng/tools/opensorce/AdelaiDet/adet/modeling/blendmask/blendmask.py"", line 58, in __init__
    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).to(self.device).view(3, 1, 1)
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/torch/cuda/__init__.py"", line 149, in _lazy_init
    _check_driver()
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/torch/cuda/__init__.py"", line 63, in _check_driver
    of the CUDA driver."""""".format(str(torch._C._cuda_getDriverVersion())))
AssertionError:
The NVIDIA driver on your system is too old (found version 10010).
Please update your GPU driver by downloading and installing a new
version from the URL: http://www.nvidia.com/Download/index.aspx
Alternatively, go to: https://pytorch.org to install
a PyTorch version that has been compiled with your version
of the CUDA driver.",True,False
aim-uofa/AdelaiDet/48,False,5eaa6627bd354307cbb85519,"Traceback (most recent call last):
  File ""demo/demo.py"", line 74, in <module>
    demo = VisualizationDemo(cfg)
  File ""/nfs/project/huangzhipeng/tools/opensorce/AdelaiDet/demo/predictor.py"", line 37, in __init__
    self.predictor = DefaultPredictor(cfg)
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/detectron2/engine/defaults.py"", line 184, in __init__
    self.model = build_model(self.cfg)
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/detectron2/modeling/meta_arch/build.py"", line 21, in build_model
    model = META_ARCH_REGISTRY.get(meta_arch)(cfg)
  File ""/nfs/project/huangzhipeng/tools/opensorce/AdelaiDet/adet/modeling/blendmask/blendmask.py"", line 58, in __init__
    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).to(self.device).view(3, 1, 1)
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/torch/cuda/__init__.py"", line 149, in _lazy_init
    _check_driver()
  File ""/home/huangzhipeng/miniconda3/envs/blendmask/lib/python3.7/site-packages/torch/cuda/__init__.py"", line 63, in _check_driver
    of the CUDA driver."""""".format(str(torch._C._cuda_getDriverVersion())))
AssertionError:
The NVIDIA driver on your system is too old (found version 10010).
Please update your GPU driver by downloading and installing a new
version from the URL: http://www.nvidia.com/Download/index.aspx
Alternatively, go to: https://pytorch.org to install
a PyTorch version that has been compiled with your version
of the CUDA driver.",True,False
aim-uofa/AdelaiDet/48,False,5eaa6627bd354307cbb85518,"my cuda version is CUDA Version 10.0.130
CUDA Patch Version 10.0.130.1",True,False
aim-uofa/AdelaiDet/48,False,5ead4bddbd3543529c6c890e,"Hi zhepherd, AdelaiDet supports CUDA 10.0.

Please make sure you have compiled AdelaiDet with the same cuda as your python runtime. This error typically happens when the cuda in your python environment is of a lower version.

Also, you can check official Detectron2 demos. If those work, BlendMask should also work.",True,False
aim-uofa/AdelaiDet/48,False,5eb3830cbd3543085dd284f8,which python version need？？my python version is 3.7,True,False
aim-uofa/AdelaiDet/48,False,5eb393b6bd354337a15087fa,"@zhepherd same as Detectron2, python >= 3.6",True,False
aim-uofa/AdelaiDet/48,False,5eb56baebd354336fb139129,"my python is 3.7 why has cuda error? i try as detectron2 install.md,but also has the error! pls help",True,False
aim-uofa/AdelaiDet/48,False,5eb56bc8bd35432e5e09209c,"![image](https://user-images.githubusercontent.com/3793108/81273676-d1026f00-9081-11ea-91e0-fd723dc9bfe8.png)
",True,False
aim-uofa/AdelaiDet/48,False,5eb40e66bd35436d3e50dde7,"@zhepherd As I said before, it is probably because you did not compile detectron2/AdelaiDet with the same cuda as your python runtime.

Please make sure you have installed the correct precompiled detectron2 or have compiled with the right nvcc.

I also suggest you go to Detectron2's repo for help.",True,False
aim-uofa/AdelaiDet/48,False,5eb41419bd3543679e3c800d,i am think  i compile detectron2 with the same cuda as my python runtime,True,False
aim-uofa/AdelaiDet/48,False,5eb415debd354374189b7e1d,"![image](https://user-images.githubusercontent.com/3793108/81277205-abc42f80-9086-11ea-9ba6-527b0f0d8c7c.png)
",True,False
aim-uofa/AdelaiDet/48,False,5eb570f2bd35431da6284d15,"So how did you install pytorch? 

If with conda, please try

`conda list | grep torch`

and make sure torch is compiled with the same version of CUDA",True,False
aim-uofa/AdelaiDet/48,False,5eb5716fbd3543359fb4a1ae,"use pip 
![image](https://user-images.githubusercontent.com/3793108/81278091-cea31380-9087-11ea-9408-dac109a08fef.png)
",True,False
aim-uofa/AdelaiDet/48,False,5eb5721dbd35432da910c8b7,"It seems to me the torch version you installed is not compiled to support CUDA 10.0.

> The NVIDIA driver on your system is too old (found version 10010).
> Please update your GPU driver by downloading and installing a new
> version from the URL: http://www.nvidia.com/Download/index.aspx
> Alternatively, go to: https://pytorch.org to install
> a PyTorch version that has been compiled with your version
> of the CUDA driver.",True,False
aim-uofa/AdelaiDet/48,False,5eb42091bd354352597bb220,which torch and torchvision should i install ?,True,False
aim-uofa/AdelaiDet/48,False,5eb574d2bd3543237283e87e,"if you insist on using cuda 10.0, try pytorch 1.3 with cuda 10.0. Remember to specify the CUDA version when you install.

",True,False
aim-uofa/AdelaiDet/48,False,5eb575a6bd35431d7aa500ef,specify cuda version when install ? how to specify? not the sys default cuda 10.0?,True,False
aim-uofa/AdelaiDet/48,False,5eb4cc01bd35434dd74cc169,"Something like this

`pip install torch==1.3.1+cu100 torchvision==0.4.2+cu100 -f https://download.pytorch.org/whl/torch_stable.html`

or this 

`conda install pytorch torchvision cudatoolkit=10.0 -c pytorch`

If you have further questions, join our discord channel here

https://discord.gg/afxvbrZ

The issues are for bug reports and feature requests. Not general QAs",True,False
aim-uofa/AdelaiDet/48,False,5eb4ce03bd35434dc504f223,"![image](https://user-images.githubusercontent.com/3793108/81282709-22186000-908e-11ea-80a2-52cc1d76b4ca.png)
i look my runtime cuda ,find is not the same as sys cuda",True,False
aim-uofa/AdelaiDet/48,False,5eb67d79bd35436400e7df44,"i solve this problem after update the nvidia driver,but has anther problem

![image](https://user-images.githubusercontent.com/3793108/81362381-55510280-9113-11ea-89d7-94695d67719e.png)
",True,False
aim-uofa/AdelaiDet/48,False,5eb67d79bd35436400e7df45,"i solve this problem after update the nvidia driver,but has anther problem

![image](https://user-images.githubusercontent.com/3793108/81362381-55510280-9113-11ea-89d7-94695d67719e.png)
",True,False
aim-uofa/AdelaiDet/48,False,5eb568a4bd3543264069ef37,"thx very much, i solve this problem after reinstall ,thx very much for help!!! @stan-haochen ",True,False
aristanetworks/ansible-avd/244,False,5f89e215bd35435b2238563c,Everything is now tracked in a dedicated project,True,False
aristanetworks/ansible-avd/244,False,5f89e215bd35435b2238563d,Everything is now tracked in a dedicated project,True,False
openshift/openshift-docs/20218,False,5e664e4bbd354322f379ccf5,@JStickler @neal-timpe ,True,False
openshift/openshift-docs/20218,False,5e664e4bbd354322f379ccf6,@objectiser may be able to advise,True,False
openshift/openshift-docs/20218,False,5e664e4bbd354322f379ccf7,"@JStickler I thought the install section does require the user to first install Elasticsearch Operator, then Jaeger operator and only then Service Mesh operator?

@yocum137 just to confirm, you are referring to the Elasticsearch Operator pod? This may be a side effect of the ""requires"" dependency currently defined between the Jaeger operator and Elasticsearch operator, which will be removed in the next release. However if it is causing such problems, it may be best to include a warning in the docs for now.

",True,False
openshift/openshift-docs/20218,False,5f76e213bd354374f74a7794,"Issues go stale after 90d of inactivity.

Mark the issue as fresh by commenting `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.
Exclude this issue from closing by commenting `/lifecycle frozen`.

If this issue is safe to close now please do so with `/close`.

/lifecycle stale",True,False
openshift/openshift-docs/20218,False,5fa1666fbd354354cad1e566,"Stale issues rot after 30d of inactivity.

Mark the issue as fresh by commenting `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.
Exclude this issue from closing by commenting `/lifecycle frozen`.

If this issue is safe to close now please do so with `/close`.

/lifecycle rotten
/remove-lifecycle stale",True,False
openshift/openshift-docs/20218,False,5fd31a2cbd3543249965dab1,"Rotten issues close after 30d of inactivity.

Reopen the issue by commenting `/reopen`.
Mark the issue as fresh by commenting `/remove-lifecycle rotten`.
Exclude this issue from closing again by commenting `/lifecycle frozen`.

/close",True,False
openshift/openshift-docs/20218,False,5fd31a2dbd3543249965dab2,"Rotten issues close after 30d of inactivity.

Reopen the issue by commenting `/reopen`.
Mark the issue as fresh by commenting `/remove-lifecycle rotten`.
Exclude this issue from closing again by commenting `/lifecycle frozen`.

/close",True,False
openshift/openshift-docs/20218,False,5fd29e54bd354334a50a0d50,"@openshift-bot: Closing this issue.

<details>

In response to [this](https://github.com/openshift/openshift-docs/issues/20218#issuecomment-742830486):

>Rotten issues close after 30d of inactivity.
>
>Reopen the issue by commenting `/reopen`.
>Mark the issue as fresh by commenting `/remove-lifecycle rotten`.
>Exclude this issue from closing again by commenting `/lifecycle frozen`.
>
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>",True,False
ethanbustad/com-liferay-commerce/53,False,5cd30f6e6480fd3bcf85dd00,"To conserve resources, the PR Tester does not automatically run for every pull.

If your code changes were already tested in another pull, reference that pull in this pull so the test results can be analyzed.

If your pull was never tested, comment &quot;ci:test&quot; to run the PR Tester for this pull.",True,False
ethanbustad/com-liferay-commerce/53,False,5cd30f726480fd3c02d30e14,ci:test,True,False
ethanbustad/com-liferay-commerce/53,False,5cd30fa16480fd3fb6e4f04e,"<h1>Build started.</h1><p>Jenkins is currently running tests.</p><h4>Base Branch:</h4><p>Branch Name: <a href=""https://github.com/liferay/com-liferay-commerce/tree/7.1.x-next"">7.1.x-next</a></p><h4>Job Summary:</h4><p>Job Link: <a href=""https://test-1-23.liferay.com/job/test-subrepository-acceptance-pullrequest(7.1.x)/131/"">test-subrepository-acceptance-pullrequest(7.1.x)</a></p><p><b>For more details click <a href=""https://test-1-23.liferay.com//userContent/jobs/test-subrepository-acceptance-pullrequest(7.1.x)/builds/131/jenkins-report.html"">here</a>.</b></p>",True,False
ethanbustad/com-liferay-commerce/53,False,5cd3165e6480fd3c8f3d9654,"<html><h1>Validation PASSED. Running batch tests.</h1><p>Build Time: 26 minutes 18 seconds 146 ms</p><h4>Base Branch:</h4><p>Branch Name: <a href=""https://github.com/liferay/com-liferay-commerce/tree/7.1.x"">7.1.x</a><br/>Branch GIT ID: <a href=""https://github.com/liferay/com-liferay-commerce/commit/6fbc7468162cdfc76284f1e2e8ecc7b69127c37a"">6fbc7468162cdfc76284f1e2e8ecc7b69127c37a</a></p><h6>Task Summary:</h6><ul><li>subrepository-compile-jdk8 -  :heavy_check_mark:</li><li>subrepository-semantic-versioning-jdk8 -  :heavy_check_mark:</li><li>subrepository-pmd-jdk8 -  :heavy_check_mark:</li><li>subrepository-source-format-jdk8 -  :heavy_check_mark:</li><li>central-requirements-jdk8/subrepository-unit-jdk8 -  :heavy_check_mark:</li></ul><h5>For full console, click <a href=""https://test-1-18.liferay.com/job/test-subrepository-acceptance-pullrequest-validation(7.1.x)/48//consoleText"">here</a>.</h5><hr/><div><h6>Test Results:</h6><div><div><p>48 Tests Passed.<br/>0 Tests Failed.</p></div></div><h5>For all test results, click <a href=""https://test-1-18.liferay.com/job/test-subrepository-acceptance-pullrequest-validation(7.1.x)/48//testReport"">here</a>.</h5></div></html>",True,False
ethanbustad/com-liferay-commerce/53,False,5cd323666480fd428396251c,"<html><h3>:heavy_check_mark: ci:test - 17 out of 17 jobs passed in 1 hour 24 minutes 54 seconds 297 ms</h3><details><summary>Click here for more details.</summary><h4>Base Branch:</h4><p>Branch Name: <a href=""https://github.com/liferay/com-liferay-commerce/tree/7.1.x"">7.1.x</a><br/>Branch GIT ID: <a href=""https://github.com/liferay/com-liferay-commerce/commit/6fbc7468162cdfc76284f1e2e8ecc7b69127c37a"">6fbc7468162cdfc76284f1e2e8ecc7b69127c37a</a></p>17 out of 17 jobs PASSED<details><summary><strong>17 Successful Jobs:</strong></summary><ul><li><a href=""https://test-1-23.liferay.com/job/test-subrepository-acceptance-pullrequest(7.1.x)/131/"">test-subrepository-acceptance-pullrequest(7.1.x)</a></li><li><a href=""https://test-1-12.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/272/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/functional-smoke-tomcat90-mysql57-jdk8/0</a></li><li><a href=""https://test-1-17.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/555/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-assemble-jdk8</a></li><li><a href=""https://test-1-13.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/369/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/0</a></li><li><a href=""https://test-1-12.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/270/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/1</a></li><li><a href=""https://test-1-17.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/554/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/10</a></li><li><a href=""https://test-1-12.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/271/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/2</a></li><li><a href=""https://test-1-12.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/273/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/3</a></li><li><a href=""https://test-1-2.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/376/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/4</a></li><li><a href=""https://test-1-13.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/370/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/5</a></li><li><a href=""https://test-1-2.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/375/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/6</a></li><li><a href=""https://test-1-13.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/371/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/7</a></li><li><a href=""https://test-1-20.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/512/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/8</a></li><li><a href=""https://test-1-15.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/230/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-functional-tomcat90-mysql57-jdk8/9</a></li><li><a href=""https://test-1-17.liferay.com/job/test-subrepository-acceptance-pullrequest-batch(7.1.x)/556/"">test-subrepository-acceptance-pullrequest-batch(7.1.x)/subrepository-integration-mysql57-jdk8</a></li><li><a href=""https://test-1-20.liferay.com/job/test-subrepository-acceptance-pullrequest-dist(7.1.x)/35/"">test-subrepository-acceptance-pullrequest-dist(7.1.x)/jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-subrepository-acceptance-pullrequest-validation(7.1.x)/48/"">test-subrepository-acceptance-pullrequest-validation(7.1.x)/jdk8</a></li></ul></details><h5>For more details click <a href=""https://test-1-23.liferay.com/userContent/jobs/test-subrepository-acceptance-pullrequest(7.1.x)/builds/131/jenkins-report.html"">here</a>.</h5></details></html>",True,False
ethanbustad/com-liferay-commerce/53,False,5cd5fcf76480fd3e53eb341b,Thanks! Sent on to https://github.com/liferay/com-liferay-commerce/pull/857.,True,False
Jirayut558/newsloading/4,False,5e931d61bd3543151c1e8a9d,Superseded by #5.,True,False
dchaplinsky/unshred-tag/61,False,545825b6bd3543e38d011d0f,Refreshing the page didn't skip the shred. Logging out and logging back in didn't skip shred either! Should one register once more to get different shred?!? :),True,False
dchaplinsky/unshred-tag/61,False,5458caa7bd3543e5530149a9,"The problem with example above is that I didn't assign any tag, thus the field did come pre-filled, and the logic you describe won't work.

Additionally, after one have added a couple of tags and want to cancel the changes. What one should do?

Should we add ""Skip"" link (not button) that is always visible and will work as Cancel/Skip?",True,False
dchaplinsky/unshred-tag/61,False,5458d684bd3543e3a401548b,"Indeed, some shreds may have automatically suggested tags. In this case we could check for the form being ""dirty"" and skip if not. IMO it's better to have a single default button for the most appropriate action at the moment.

The case with cancelling is a bit different. How about showing a link for reset in case the form is dirty? But not otherwise. So two situations:

1) The form is not dirty.
 - The button shows ""Skip"". Pressing it marks the shred as skipped for this user and doesn't normally show it after that.
 - No reset link.

2) The form is dirty.
 - The button shows ""Save"". Pressing it saves the shred for this user.
 - The reset link appears below the ""Save"" button. Clicking this link does not skip but simply restores the form to the initial state thus bringin the user back to (1).",True,False
dchaplinsky/unshred-tag/61,False,5458e113bd3543e3f0014bd0,The description in https://github.com/dchaplinsky/unshred-tag/issues/61#issuecomment-61639846 above appears to be quite verbose and bullet-proof. The only thing to address is that skipped shred should not disappear for user but have to appear again in review queue after some time (when user gained some experience).,True,False
dchaplinsky/unshred-tag/61,False,5458e15abd3543e511014aae,"That's is included by design (see get_next_shred helper).

Anyone wants to update UI? :)",True,False
dchaplinsky/unshred-tag/61,False,5458e215bd3543e568015546,I do not promise anything yet :) but you'll have pull request when there is something to review,True,False
dchaplinsky/unshred-tag/61,False,5458e27fbd3543e43c015dcd,"Deal!
Do you want me to add you to our internal chat?",True,False
dchaplinsky/unshred-tag/61,False,5458eaf5bd3543e4cf014de7,"Let's have my pull request accepted first :)

On Tue, Nov 4, 2014 at 4:28 PM, Dmitry Chaplinsky <notifications@github.com>
wrote:

> Deal!
> Do you want me to add you to our internal chat?
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/dchaplinsky/unshred-tag/issues/61#issuecomment-61646599>
> .
>



-- 
....................................................................................................................................
Myroslav Opyr   ▪   CTO   ▪    Quintagroup   ▪   +1.917.475.4725   ▪
http://quintagroup.com
˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙˙
",True,False
docker/machine/1264,False,55685211bd354396f400137f,cc @ehazlett @hairyhenderson @sthulb ,True,False
docker/machine/1264,False,55685212bd354396f4001380,"I'm +1 on the 1.4.2 bump.

The pull-time optimization is nice, and I think it's faster overall for me (I recall `golang:1.3-cross` taking 25mins to pull on my home internet connection a while back). I'm timing the build from this branch right now...",True,False
docker/machine/1264,False,55685212bd354396f4001381,"Results:

```
script/build  1.40s user 0.46s system 0% cpu 11:43.16 total
```

This is on my MacBook Pro from 2011 with 16GB RAM, with boot2docker running in VMWare Fusion.

To be honest, I was a little surprised how long it took. If the first-build time is going to be on this order of magnitude, I think I _might_ actually prefer just going `FROM golang:1.4.2-cross`.

The other thing to consider is that this is a somewhat temporary problem, because Go 1.5 will (in theory) land in August, and the `-cross` image for that will be able to be much smaller (or so I've been told). So, it'd probably be better to use `-cross` when we move to 1.5, so maybe it isn't such a big deal to have the extra bandwidth cost with 1.4.2.

One big caveat though - I've actually gotten much more used to just running `godep go build` when I'm working on Machine lately, mostly because it's _so_ much faster. But, I know I should be `script/build`ing :grin: ",True,False
docker/machine/1264,False,556890dcbd3543a776000e1b,Yeah +1 from me too.  I think we can get this in after the 0.3 release and see how it works with the understanding of moving to 1.5 in Aug.  Sound good?,True,False
docker/machine/1264,False,5568f372bd3543b25d002e52,"Yikes at those results @hairyhenderson.  That's what I'd worry about with this method.  We might actually be better off just using `golang:1.4.2-cross`.  The other option would be to pre-bake our ""base"" on our own, which I think would cut down the image size pretty well.

> Yeah +1 from me too. I think we can get this in after the 0.3 release and see how it works with the understanding of moving to 1.5 in Aug. Sound good?

Yes!",True,False
docker/machine/1264,False,556af465bd3543b5d6009328,"+1, we should do it after the release :)",True,False
docker/machine/1264,False,556af483bd3543b16700a0bd,"1.5 should be interesting in the summer, I'm looking forward to it, despite the runtime slowdown",True,False
docker/machine/1264,False,55877a8abd354346f90037f6,"@ehazlett WDYT about this?  I changed to just use `golang:1.4.2-cross` image, which I think is ultimately the better path in spite of the large size, although I don't think we should kick out the idea of just generating our own base (i.e. use `machine/base` that we generate ourselves - it would cut the size by >50% off `golang:1.4.2-cross`, but would be an additional random thing to maintain).",True,False
docker/machine/1264,False,55d4c5151b4876477f003af6,@ehazlett Does it LGTY?,True,False
docker/machine/1264,False,55d4fd511b48763b84000c44,LGTM,True,False
cockpit-project/cockpit/5450,False,583318a86480fd04e8a255b4,Image creation done.,True,False
zyanfx/Zyan/57,False,5cade32e6480fd70c2760d25,"Hi @heikar, that's a nice idea!

It can be implemented like this (pseudocode):

```csharp
public class MultiAuthenticationProvider : IAuthenticationProvider
{
  const ProviderKey = ""Provider"";

  public MultiAuthenticationProvider(params IAuthenticationProvider providers)
  {
    Providers = providers.ToDictionary(p => p.GetType().Name);
  }

  private Dictionary<string, IAuthenticationProvider> Providers { get; }

  public AuthResponseMessage Authenticate(AuthRequestMessage authRequest)
  {
    if (authRequest.Credentials == null || authRequest.Credentials[ProviderKey] == null)
    {
      return new AuthResponseMessage()
      {
        Success = false,
        ErrorMessage = ""Authentication provider not specified"",
        AuthenticatedIdentity = null
      };
    }

    var providerName = authRequest.Credentials[ProviderKey];
    if (!Providers.ContainsKey(providerName))
    {
      return new AuthResponseMessage()
      {
        Success = false,
        ErrorMessage = ""Unsupported authentication provider: "" + providerName,
        AuthenticatedIdentity = null
      };
    }

    return Providers[providerKey].Authenticate(authRequest);
  }
}
```",True,False
zyanfx/Zyan/57,False,5cae05796480fd728e0ba8b5,"Hi @yallie,

thank you for the food for thought :)

I have implemented your pseudocode (i think, for pseudocode it is really good :)).

Two little corrections:
`public MultiAuthenticationProvider(params IAuthenticationProvider providers)`
into `public MultiAuthenticationProvider(params IAuthenticationProvider[] providers)`

`return Providers[providerKey].Authenticate(authRequest);`
into return `Providers[providerName].Authenticate(authRequest)`

And it works :)

Many thanks to you and the quick solution

Many greetings
heikar",True,False
zyanfx/Zyan/57,False,5cae215c6480fd776689ff81,You're welcome! 😄 ,True,False
zyanfx/Zyan/57,False,5cc080eb6480fd9e1f664799,"Hi @yallie .

it works really good. But now i've tested it with the SRP implementation and it fails :-(

Can you please check the `SrpAuthenticationProvider`. I get an error because the credentials doesn't contains `ProviderKey`. I think the KeyValue-Pair (`ProviderKey`) get lost between the single steps, in the `Authenticate-Method` in the `SrpCredentials-Class`.

Thank you in advance :)",True,False
zyanfx/Zyan/57,False,5cc09af56480fda61f809b67,"Yes, the provider key is not a built-in concept of Zyan.
That's the trick I proposed for your use case.
You'll need a custom SRP credentials class like this (pseudocode):

```csharp
public class MySrpCredentials : AuthCredentials
{
  public MySrpCredentials(string userName, string password)
  {
    UserName = userName;
    Password = password;
    SrpClient = new SrpClient();
  }

  private SrpClient SrpClient { get; set; }

  public override void Authenticate(Guid sessionId, IZyanDispatcher dispatcher)
  {
    // step #1
    var clientEphemeral = SrpClient.GenerateEphemeral();
    var request1 = new Hashtable
    {
      { ProviderKey, nameof(SrpAuthenticationProvider) },
      { SrpProtocolConstants.SRP_STEP_NUMBER, 1 },
      { SrpProtocolConstants.SRP_USERNAME, UserName },
      { SrpProtocolConstants.SRP_CLIENT_PUBLIC_EPHEMERAL, clientEphemeral.Public },
    };

    var response1 = dispatcher.Logon(sessionId, request1).Parameters;
    var salt = (string)response1[SrpProtocolConstants.SRP_SALT];
    var serverPublicEphemeral = (string)response1[SrpProtocolConstants.SRP_SERVER_PUBLIC_EPHEMERAL];

    // step #2
    var privateKey = SrpClient.DerivePrivateKey(salt, UserName, Password);
    var clientSession = SrpClient.DeriveSession(clientEphemeral.Secret, serverPublicEphemeral, salt, UserName, privateKey);
    var request2 = new Hashtable
    {
      { ProviderKey, nameof(SrpAuthenticationProvider) },
      { SrpProtocolConstants.SRP_STEP_NUMBER, 2 },
      { SrpProtocolConstants.SRP_CLIENT_SESSION_PROOF, clientSession.Proof },
    };

    var response2 = dispatcher.Logon(sessionId, request2).Parameters;
    var serverSessionProof = (string)response2[SrpProtocolConstants.SRP_SERVER_SESSION_PROOF];
    SrpClient.VerifySession(clientEphemeral.Public, clientSession, serverSessionProof);
  }
}
```",True,False
zyanfx/Zyan/57,False,5d08d3116480fd10ccfcbe84,"Sorry for the late feedback,
but thank you :) it works perfect.

Now the multi factor authentication works and the srp is ported for it :)

Thank you and best regards
heikar",True,False
serenity-bdd/serenity-cucumber/242,False,5f052d54bd354369f3b84234,"That's not how Serenity works. You don't use the @Managed annotation with Cucumber, and you don't place a driver field in a Page Object class. Have a look at https://serenity-bdd.github.io/theserenitybook/latest/index.html.",True,False
serenity-bdd/serenity-cucumber/242,False,5f052d55bd354369f3b84235,Thanks alot,True,False
serenity-bdd/serenity-cucumber/242,False,5f052d55bd354369f3b84236,Thanks alot,True,False
miekg/coredns/78,False,5702759b6480fdb4cb004acf,And as this point the error handler is calling Next which is nil - not sure why that is....,True,False
miekg/coredns/78,False,5702853e6480fdb235005d1f,"Think this *is* because of the other class and dig ""warns"" about that.",True,False
boot-clj/boot/174,False,55130b8fbd35434d1301e6c3,"I also get the following error (why would a Windows executable be looking for the Linux 'uname' command?):

Exception in thread ""main"" java.lang.ExceptionInInitializerError
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:348)
        at clojure.lang.RT.loadClassForName(RT.java:2093)
        at clojure.lang.RT.load(RT.java:430)
        at clojure.lang.RT.load(RT.java:411)
        at clojure.core$load$fn__5066.invoke(core.clj:5641)
        at clojure.core$load.doInvoke(core.clj:5640)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invoke(core.clj:5446)
        at clojure.core$load_lib$fn__5015.invoke(core.clj:5486)
        at clojure.core$load_lib.doInvoke(core.clj:5485)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invoke(core.clj:626)
        at clojure.core$load_libs.doInvoke(core.clj:5524)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invoke(core.clj:626)
        at clojure.core$require.doInvoke(core.clj:5607)
        at clojure.lang.RestFn.invoke(RestFn.java:551)
        at boot.pod$loading__4958__auto__.invoke(pod.clj:1)
        at boot.pod__init.load(Unknown Source)
        at boot.pod__init.<clinit>(Unknown Source)
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:348)
        at clojure.lang.RT.loadClassForName(RT.java:2093)
        at clojure.lang.RT.load(RT.java:430)
        at clojure.lang.RT.load(RT.java:411)
        at clojure.core$load$fn__5066.invoke(core.clj:5641)
        at clojure.core$load.doInvoke(core.clj:5640)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invoke(core.clj:5446)
        at clojure.core$load_lib$fn__5015.invoke(core.clj:5486)
        at clojure.core$load_lib.doInvoke(core.clj:5485)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invoke(core.clj:626)
        at clojure.core$load_libs.doInvoke(core.clj:5524)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invoke(core.clj:626)
        at clojure.core$require.doInvoke(core.clj:5607)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.lang.Var.invoke(Var.java:379)
        at org.projectodd.shimdandy.impl.ClojureRuntimeShimImpl.require(ClojureR
untimeShimImpl.java:57)
        at boot.App.newShim(App.java:153)
        at boot.App.aetherShim(App.java:174)
        at boot.App.writeProps(App.java:58)
        at boot.App.readProps(App.java:97)
        at boot.App.main(App.java:301)
Caused by: java.io.IOException: Cannot run program ""uname"": CreateProcess error=
2, The system cannot find the file specified
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
        at java.lang.Runtime.exec(Runtime.java:620)
        at clojure.java.shell$sh.doInvoke(shell.clj:116)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at boot.util__init.load(Unknown Source)
        at boot.util__init.<clinit>(Unknown Source)
        ... 46 more
Caused by: java.io.IOException: CreateProcess error=2, The system cannot find th
e file specified
        at java.lang.ProcessImpl.create(Native Method)
        at java.lang.ProcessImpl.<init>(ProcessImpl.java:386)
        at java.lang.ProcessImpl.start(ProcessImpl.java:137)
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
        ... 51 more",True,False
boot-clj/boot/174,False,5517646fbd354390a4002ef1,It looks like you're using boot version 2. The `bootstrap.css.map` errors only occur when you have source maps enabled in your browser---they won't hurt anything. But if you want to you can just add an empty bootstrap.css.map file to silence them.,True,False
ros-infrastructure/ros_buildfarm/302,False,5748dcf86480fdffc673e72c,lgtm,True,False
Makaji/Routing-PCB-Tubes-PPMC/2,False,5ca494bd6480fd738ca14106,"> _No description provided._

Coba dielaborasikan input output fungsionalnya biar bisa dibandingin sama program utama di master branch.",True,False
codersclub/forum/134,False,538613b1bd35435b02000c8f,дубликат,True,False
phiree/testttt/84,False,50b7a604edecb5209a00017c,finished,True,False
owncloud/client/5298,False,58207e8d6480fd0e54fba5ca,@guruz @ogoffart Doesn't look harmful to me. What do you think?,True,False
owncloud/client/5298,False,5821bf2a6480fd0bd9921e3d,"@ckamm It's ModSecurity 2.6 running on Apache 2.2.

Admin also sent me this log snippet for info:
```
--206cad70-A--
[05/Nov/2016:20:09:35 +0100] WB4ublOn4fAAACgG2s0AAAAP 127.0.0.1 55628 127.0.0.1 8000
--206cad70-B--
GET /owncloud/status.php HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh) mirall/2.2.4 (build 3709)
Accept-Encoding: gzip, deflate
Accept-Language: sk-SK,en,*
Host: betanie.cz
X-Forwarded-Port: 80
X-Forwarded-For: 46.167.227.24
--206cad70-F--
HTTP/1.1 403 Forbidden
Expires: Thu, 19 Nov 1981 08:52:00 GMT
Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
Pragma: no-cache
Content-Security-Policy: default-src 'self'; script-src 'self' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; frame-src *; img-src * data: blob:; font-src 'self' data:; media-src *; connect-src *
Set-Cookie: ***censored***; path=/owncloud; HttpOnly
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block
X-Robots-Tag: none
X-Frame-Options: SAMEORIGIN
Vary: Accept-Encoding
Content-Encoding: gzip
Content-Length: 1422
Content-Type: text/html; charset=UTF-8
--206cad70-H--
Message: Access denied with code 403 (phase 2). [file ""/usr/share/modsecurity-crs/activated_rules/modsecurity_crs_21_protocol_anomalies.conf""] [line ""47""] [id ""960015""] [rev ""2.2.5""] [msg ""Request Missing an Accept Header""] [severity ""CRITICAL""] [tag ""PROTOCOL_VIOLATION/MISSING_HEADER_ACCEPT""] [tag ""WASCTC/WASC-21""] [tag ""OWASP_TOP_10/A7""] [tag ""PCI/6.5.10""]
Action: Intercepted (phase 2)
Apache-Handler: application/x-httpd-suphp
Stopwatch: 1478372974791873 295927 (- - -)
Stopwatch2: 1478372974791873 295927; combined=323, p1=213, p2=84, p3=0, p4=0, p5=25, sr=50, sw=1, l=0, gc=0
Producer: ModSecurity for Apache/2.6.6 (http://www.modsecurity.org/); OWASP_CRS/2.2.5.
Server: Apache

--206cad70-Z--
```
",True,False
owncloud/client/5298,False,5821c1266480fd09ce395b8e,@joseph11 Thanks. 2.3.0 will send the Accept header.,True,False
owncloud/client/5298,False,582303e86480fd0526b7b373,"I have the same problem. 
My client (Windows&iOS) can't connect to server.",True,False
owncloud/client/5298,False,582337b76480fd0b9738384b,"@LemoAtom If you're brave you could try a nightly build from this morning. https://owncloud.org/install/#testing-development

@nasli @davivel Can we send this for iOS/Android too?",True,False
owncloud/client/5298,False,582341fa6480fd05fc17211c,"Seen, we'll do. Thx.",True,False
owncloud/client/5298,False,58235faa6480fd0f18d54cce,@ckamm @guruz I've set up a server with the same specs (OC 8.2.2 in Apache + ModSecurity) and set in it the Firewall `base_rules` including [the protocol anomalies](https://github.com/SpiderLabs/owasp-modsecurity-crs/blob/master/base_rules/modsecurity_crs_21_protocol_anomalies.conf) which is the one that contains the rule for missing and empty accept headers. Trying with client 2.3.0.3806 I'm still getting the 403: Forbidden. ,True,False
owncloud/client/5298,False,582975ed6480fd0b40a1b8b9,"@SamuAlfageme Can you give me more details, like log excerpts? I'm not sure whether 2.3.0.3806 includes the patch to send the accept header. ",True,False
owncloud/client/5298,False,582ac8bc6480fd090d2b2799,@joseph11 @LemoAtom Did you try with a current nightly build?,True,False
owncloud/client/5298,False,582acd896480fd0de9c9e428,"@ckamm Sure, 2.3.0.3806 was the nightly build from 09/11/2016 so as 90cea69692550eaff05dba091ec565b92d7cb759 was in master, I'm guessing that build contains the fix. 

It seems like you need to send the Accept header in all requests, not only in the handshake (prior to 90cea69692550eaff05dba091ec565b92d7cb759 you couldn't even access to the login step, now you can but login is returning a 403). I can provide you guys access to the server I set with the firewall so you can test this condition. 

[This is a log file](https://gist.github.com/SamuAlfageme/86a72a25e731d3e1661bc74109f2acbe) created from the startup of the desktop client to the submission of the login form. ",True,False
owncloud/client/5298,False,582ade296480fd0e540086fd,"@ckamm Sorry, for not being clear in initial description: Yes, as @SamuAlfageme writes, the Accept header needs to be part of all client requests.",True,False
owncloud/client/5298,False,582aed1f6480fd0b20282f07,"The patch by @ckamm https://github.com/owncloud/client/commit/90cea69692550eaff05dba091ec565b92d7cb759 however does include it in all requests.

@joseph11 You can try the testpilotcloud client download if you don't want to interfere with your current client and check if that one can connect/sync? http://download.owncloud.com/desktop/daily/

@SamuAlfageme let's check this later.",True,False
owncloud/client/5298,False,582ccdb96480fd0490903511,"@guruz Thank you for the tip concerning testpilotcloud. 
I tested it against server with firewall and it is connecting correctly, so I consider this fixed.",True,False
owncloud/client/5298,False,582ed2166480fd05a5a0c0a2,"@SamuAlfageme A test server would be appreciated. I had hoped my change would have added the header to all requests, but maybe a different QNetworkAccessManager is used in some places. I'll investigate.",True,False
owncloud/client/5298,False,582eee2d6480fd04909145ef,@ckamm 👌 ping me in private (either email or mattermost) and I'll get you access to the server where I set the firewall. ,True,False
owncloud/client/5298,False,582eef926480fd0e5402c183,"@SamuAlfageme I wrote you an email.

But I also did route the communication with a server through mitmproxy while configuring a new account, and all the requests involved had an ""Accept"" header. We might need more firewall logs.",True,False
owncloud/client/5298,False,582efbb36480fd0de9cc2c33,"@SamuAlfageme Thanks for the server, that helped tremendously. 

The ""Accept: */*"" header in indeed sent everywhere.

The remaining issue was filtering by HTTP method (PROPFIND and PUT are forbidden by default), and filtering by content-type (application/octet-stream is forbidden by default). After adjusting these settings in modsecurity_crs_10_setup.conf client data was synced successfully.

This looks done from my point of view.",True,False
owncloud/client/5298,False,582f01fd6480fd0bd998a589,"@ckamm awesome! working like a charm now. Thanks for the deep explanation. 

And it's working on the mobile clients as well.",True,False
iriscouch/follow/42,False,52b9fa13bd3543a7570015bd,"Also: I'd be happy to send a patch of course, but I wasn't sure at a cursory glance where to put it in the code.  Any pointer would be great!",True,False
iriscouch/follow/42,False,52bb8182bd3543a759005d02,"@isaacs How would you feel if Follow stored its checkpoints in the remote database, in a [non-replicating local document][loc]?

[loc]: http://docs.couchdb.org/en/latest/api/local.html

In this case you would provide some sort of ""follow ID"" (maybe by default it is os.hostname). Follow already does a bit of pre-follow sanity checking so I think the _local query would have little if any latency cost.

```js
{
  db: myCouch,
  client_id: ""i am still awesome""
}
```",True,False
iriscouch/follow/42,False,52bc7c37bd3543a7590097b1,"That'd also be a nice feature, but the cool thing about a sequence file is that I can easily set it at a certain point, or scp it to a new server, etc.

If follow always defaulted the client_id to a specific field, then it gets a little more confusing.  I have a bunch of followers of the npm registry, for example, all on the same hostname, doing different things.  In some cases, I might want to copy the sequence file from one to another, etc.  Files are a little bit easier to reason about, and don't impose a remote semantics issue.

Otoh, for some cases, it might definitely make sense to have a remote sequence ID.  In that case, it'd be best to NOT default to anything, though.  Just make it an option, like you could do either `seq_file: 'foo.seq'` or `seq_doc: 'i am still awesome'`, and throw if you specify both, since that's just weird?",True,False
iriscouch/follow/42,False,52bcfccabd35436790000e13,"Yeah you've persuaded to KISS. Remote sequence ID can come later; or maybe
there can be a generic callback-metacallback API later. The fact that it is
not totally obvious strongly indicates KISS.

I will have to glance at the code again but this belongs somewhere in the
init or prep phase, where Follow hits /db to see what its last_seq is, and
generally gets its bearings before the real _changes query.

For how to store it in the file, I'm not sure. Either a Feed object could
subscribe to its own ""change"" event, or that could be handled by the user
at a cost of breaking parity.


Incidentally, is Follow the reason your program is crashing? It should not
really ever crash, even if the target server goes down or even changes its
IP address. Is there another bug that Follow has?


On Fri, Dec 27, 2013 at 1:57 AM, Isaac Z. Schlueter <
notifications@github.com> wrote:

> That'd also be a nice feature, but the cool thing about a sequence file is
> that I can easily set it at a certain point, or scp it to a new server, etc.
>
> If follow always defaulted the client_id to a specific field, then it gets
> a little more confusing. I have a bunch of followers of the npm registry,
> for example, all on the same hostname, doing different things. In some
> cases, I might want to copy the sequence file from one to another, etc.
> Files are a little bit easier to reason about, and don't impose a remote
> semantics issue.
>
> Otoh, for some cases, it might definitely make sense to have a remote
> sequence ID. In that case, it'd be best to NOT default to anything, though.
> Just make it an option, like you could do either seq_file: 'foo.seq' or seq_doc:
> 'i am still awesome', and throw if you specify both, since that's just
> weird?
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/iriscouch/follow/issues/42#issuecomment-31231346>
> .
>",True,False
thingsinjars/Hardy/12,False,52609ce2bd35433e02000708,+1.  There's a noticeable difference the speed here.  This could really be beneficial for the image cropping and comparisons.,True,False
thingsinjars/Hardy/12,False,5262e4b4bd35438848000311,"That is a pretty considerable improvement in speed. Off the top of my head, I'm not sure what the best approach would be. I'd most likely want to keep the PhantomJS tools compatible even if ImageMagick was the default just so there's a fallback for systems without it.

Of course, that shouldn't be hard seeing as they're only a couple of lines each.

In fact, that might be the way to go. Use ImageMagick if it's there and fallback to GhostDiff & GhostKnife if not. It's not the simplest development solution but the aim of Hardy is to be as easy as possible for the non-technical user so it should always have a default available. No reason why those who want to can't take advantage of the speed improvements, though.

I'll have a play with the fork and see what the install procedures are like for IM.

(btw, it's super cool that you've looked into this aspect of it, thanks)",True,False
thingsinjars/Hardy/12,False,52656a1abd35433037000333,"Thanks.   Yeah, I definitely understand the compatibility urge. It does keep it simple to make it an automatic fallback.  One more forward-thinking option would be to make the crop and comparison tool a pluggable API of some sort.   

Also, I built an extension (not yet on my branch) that uses GM to create a visual diff of the changes and outputs that file.   I'll share that soon, but there's a pull request in GM that needs to get in. ;-)
",True,False
thingsinjars/Hardy/12,False,526570fbbd3543346c00017f,Sounds interesting. After pulling in the config file change (#11) I started to wonder about an API... Hmmm... there's an idea...,True,False
thingsinjars/Hardy/12,False,5269e86fbd3543b81d000146,"Any thoughts on this one?   We can use our own fork/build for now, but I'd love to figure out a way to get this in.   ",True,False
thingsinjars/Hardy/12,False,526c8e51bd35430b85000140,"I started working to make the compare/crop functions pluggable ... https://github.com/dwabyick/Hardy/tree/image_refactor.   

Next steps is to add a graphics-magick equivalent, and make that an option from the config file, or possibly a 'try and fallback' approach.  

Feedback appreciated.",True,False
thingsinjars/Hardy/12,False,526d4e1dbd35436f2400012c,"I'm having some difficulty getting graphics-magick to work properly. I had ImageMagick installed in order to use [Wraith](https://github.com/BBC-News/wraith/) but I'm getting a lot of dyld errors when I run this fork. I don't think that's anything to do with the fork itself, more likely my machine's setup. I've tried a few times this week but maybe it's just my computer's way of telling me it wants reinstalled from scratch...

I'll try on a different machine this week and reinstall this one. It'll be a good opportunity to try installing everything clean.",True,False
thingsinjars/Hardy/12,False,526d56e1bd3543757000003c,"Awesome. I'm working right now on a version that will gracefully fallback from gm to ghost knife.

Theoretically gm can work with image magick as well, but I haven't tried that.

> On Oct 27, 2013, at 10:32 AM, Simon Madine <notifications@github.com> wrote:
> 
> I'm having some difficulty getting graphics-magick to work properly. I had ImageMagick installed in order to use Wraith but I'm getting a lot of dyld errors when I run this fork. I don't think that's anything to do with the fork itself, more likely my machine's setup. I've tried a few times this week but maybe it's just my computer's way of telling me it wants reinstalled from scratch...
> 
> I'll try on a different machine this week and reinstall this one. It'll be a good opportunity to try installing everything clean.
> 
> —
> Reply to this email directly or view it on GitHub.",True,False
thingsinjars/Hardy/12,False,526fbc03bd3543b908000223,"Brought in #19 on db2f726f.

I'll bump the version shortly.",True,False
wynnset/tapestry-wp/936,False,6017472cbd3543543a4cc536,"
<p align=""center"">
  <br />
  <img src=""https://assets.cypress.io/github-pr-comment-icons/cypress-logo.png"" height=""32"" />
</p>

---

### Test summary
<a href=""https://dashboard.cypress.io/projects/h3nrkv/runs/643/overview?utm_source=github""><img src=""https://assets.cypress.io/github-pr-comment-icons/green-check-mark.png"" width=""14"" height=""14"" title=""Passed"" /></a> <b title=""Passed"">56</b>  &bull; <a href=""https://dashboard.cypress.io/projects/h3nrkv/runs/643/test-results?utm_source=github&statuses=%5B%7B%22value%22%3A%22FAILED%22%2C%22label%22%3A%22FAILED%22%7D%5D""><img src=""https://assets.cypress.io/github-pr-comment-icons/red-x.png"" width=""14"" height=""14"" title=""Failed"" /></a> <b title=""Failed"">0</b>  &bull; <img src=""https://assets.cypress.io/github-pr-comment-icons/gray-circle.png"" width=""14"" height=""14"" title=""Tests that did not run due to a developer annotating a test with .skip"" /> <b title=""Pending"">0</b> &bull; <img src=""https://assets.cypress.io/github-pr-comment-icons/yellow-triangle.png"" width=""14"" height=""14"" title=""Tests that did not run due to a failure in a mocha hook"" /> <b title=""Skipped"">0</b> &bull; <img src=""https://assets.cypress.io/github-pr-comment-icons/flaky.png"" width=""29"" height=""14"" title=""Tests that were flaky"" alt=""Flakiness"" /> <b title=""Flaky"">1</b>

---

### Run details
| | |
| --- | --- |
| **Project** | tapestry-wp |
| **Status** | Passed |
| **Commit** | 8dd07a7343 |
| **Started** | Feb 1, 2021 12:03 AM |
| **Ended** | Feb 1, 2021 12:06 AM |
| **Duration** | 02:17 <a href=""https://on.cypress.io/parallelization?utm_source=github"" title=""Enable parallelization to reduce run duration"">💡</a> |
| **OS** | Linux Ubuntu - 18.04 |
| **Browser** | Chrome 88 <img src=""https://cdnjs.cloudflare.com/ajax/libs/browser-logos/48.0.4/chrome/chrome_32x32.png"" width=""16"" height=""16"" /> |

[View run in Cypress Dashboard ➡️](https://dashboard.cypress.io/projects/h3nrkv/runs/643/overview?utm_source=github)




  ---

  ### Flakiness

  <table>
    <tbody>
      <tr>
        <th align=""center"">
          <img width=""16"" src=""https://assets.cypress.io/github-pr-comment-icons/file.png"">
        </th>
        <th align=""left"" colspan=""2"" style=""width: 100%"">
          cypress/integration/lightbox/video.spec.js <a href=""https://dashboard.cypress.io/projects/h3nrkv/runs/643/specs/3c9cff42-deb7-4ae9-866b-8a2c0a388d79/video""><img src=""https://assets.cypress.io/github-pr-comment-icons/blue-video.png"" width=""14"" height=""14"" title=""Video"" /></a>
        </th>
        <th align=""right"">
          1&nbsp;<a href=""https://dashboard.cypress.io/projects/h3nrkv/runs/643/test-results?utm_source=github&isFlaky=%5B%7B%22value%22%3Atrue%2C%22label%22%3A%22Flaky%22%7D%5D""><img src=""https://assets.cypress.io/github-pr-comment-icons/flaky.png"" width=""32"" height=""14"" alt=""Flakiness"" /></a>
        </th>
      </tr><tr>
        <td align=""right"">1</td>
        <td colspan=""2"">
          <a href=""https://dashboard.cypress.io/projects/h3nrkv/runs/643/test-results/b12fb9dd-ac33-4ee5-8f4c-c2ab2f276969?utm_source=github&isFlaky=%5B%7B%22value%22%3Atrue%2C%22label%22%3A%22Flaky%22%7D%5D"">
            Video > should be able to add a video node via url</td>
          </a>
          <td>
            <a href=""https://dashboard.cypress.io/projects/h3nrkv/runs/643/test-results/b12fb9dd-ac33-4ee5-8f4c-c2ab2f276969/screenshots?utm_source=github&isFlaky=%5B%7B%22value%22%3Atrue%2C%22label%22%3A%22Flaky%22%7D%5D"">
              <img src=""https://assets.cypress.io/screenshots-thumbnail/global/ce0c02c5-5818-457f-b984-6332f5ba5b13.png"" width=""128"" />
            </a>
                </td>
      </tr>
    </tbody>
  </table>
  

---

This comment has been generated by **cypress-bot** as a result of this project's GitHub integration settings. You can manage this integration in [this project's settings in the Cypress Dashboard](https://dashboard.cypress.io/projects/h3nrkv/settings?utm_source=github)

",True,False
appium/appium-uiautomator2-driver/137,False,5a740a886480fd0658fbbbdb,Thanks. I'll take care about this,True,False
Silthus/stats/81,False,603f5cf9bd35435723acb0d9,Superseded by #87.,True,False
google-test/signcla-probe-repo/183526,False,5cc9d25f6480fda61f84d929,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fgoogle-test%2Fsigncla-probe-repo%2Fpull%2F183526) for more info**.

<!-- need_sender_cla -->",True,False
google-test/signcla-probe-repo/183526,False,5cc9d25f6480fda61f84d92a,unsigned-fail-fork: test succeeded,True,False
khcr/django-coursesApp/3,False,54df7a71bd354372a500397d,"Merci pour le message et le conseil !
J'avais déjà tenté de supprimer ces fichiers mais en fait le .gitignore ne s'était pas appliqué. C'est corrigé.",True,False
zenorocha/atom-javascript-snippets/16,False,5508dc52bd3543d23100b996,Just started reviewing :) <br><br>:octocat: *Sent from [GH](http://nodegh.io).*,True,False
zenorocha/atom-javascript-snippets/16,False,5508de4fbd3543d3f400ac2a,Good catch! Sorry for taking so long to merge.,True,False
seize-the-dave/jscep/12,False,51e3cb5abd354350050000e3,Thanks!,True,False
Travix-International/travix-ui-kit/18,False,58a70cef6480fd698d3a3c7e,"
[![Coverage Status](https://coveralls.io/builds/10203515/badge)](https://coveralls.io/builds/10203515)

Coverage remained the same at 100.0% when pulling **15ca92dbdb1485a67e48d24b256d96f147c9cd83 on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58a70fcf6480fd698d3a425e,can you please provide a picture how it is looks like in LSG?,True,False
Travix-International/travix-ui-kit/18,False,58a73af06480fd5ef7c551e4,"
[![Coverage Status](https://coveralls.io/builds/10207457/badge)](https://coveralls.io/builds/10207457)

Coverage remained the same at 100.0% when pulling **53783244ccf7efc0bec01b1a8171ad72742e978c on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58a76a396480fd6689321b9f,"
[![Coverage Status](https://coveralls.io/builds/10210831/badge)](https://coveralls.io/builds/10210831)

Coverage remained the same at 100.0% when pulling **6f7fb8e74499e33a51e72a3c26290f61d4b31f6a on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58a7712d6480fd67c2943385,Do we have only one size for Price component?,True,False
Travix-International/travix-ui-kit/18,False,58a773c56480fd67788d8043,"@asci again, the breakpoints are not supposed to be in the `travix-ui-kit`.

1. Not everyone has the same breakpoints
1. Not everyone wants to do responsive web design
1. Would not be flexible enough....

I would rather leave that for the a specific theme where you'd do something like:

```scss
.ui-price {
  .ui-price__currency {
    @include breakpoint('lt-medium') {
      font-size: 15px;
    }
  }
}
```

Or, if possible, override the variables would be even better.",True,False
Travix-International/travix-ui-kit/18,False,58a774a46480fd65889c2daf,"
[![Coverage Status](https://coveralls.io/builds/10211621/badge)](https://coveralls.io/builds/10211621)

Coverage remained the same at 100.0% when pulling **18f7c8e5779ef82afefe5196ca86eafb4523200c on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58aaaf8e6480fd67c2974ca8,"@mAiNiNfEcTiOn I'm not talking about responsiveness, I'm talking about semantics",True,False
Travix-International/travix-ui-kit/18,False,58aba08f6480fd6944308593,@asci define _semantics_ and what you're expecting and/or proposing please.,True,False
Travix-International/travix-ui-kit/18,False,58aba0e36480fd6c2ac76463,"
[![Coverage Status](https://coveralls.io/builds/10246076/badge)](https://coveralls.io/builds/10246076)

Coverage remained the same at 100.0% when pulling **3fc1f00b1db9242f10d0123798d8716966730fae on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58abeb336480fd5f9f794d4e,"
[![Coverage Status](https://coveralls.io/builds/10248255/badge)](https://coveralls.io/builds/10248255)

Coverage remained the same at 100.0% when pulling **5424bb65bd43823d66cb488eea475a2b9cc60b7e on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58abed9e6480fd5fc9c32fb0,"@mAiNiNfEcTiOn  I mean we have different sizes for a button (small, medium, large). Why don't we have it for a price component? Maybe we have different sizes in design?",True,False
Travix-International/travix-ui-kit/18,False,58adc3056480fd5fb2f13256,"
[![Coverage Status](https://coveralls.io/builds/10276785/badge)](https://coveralls.io/builds/10276785)

Coverage remained the same at 100.0% when pulling **6164901bd4799ada81f2dbe12a41a2be0fecb5c4 on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
Travix-International/travix-ui-kit/18,False,58adc5486480fd6bbe392e9e,"
[![Coverage Status](https://coveralls.io/builds/10277042/badge)](https://coveralls.io/builds/10277042)

Coverage remained the same at 100.0% when pulling **1c7f4d2a334e1b2092e8a9b25d58e2eb79c5ae50 on component-price** into **04addc70782e1dc5c5bf8a9d8f682a700f965d32 on master**.
",True,False
microsoft/AirSim/3330,False,600aa366bd35434d9a6bcf5e,replacing the call with simGetVehiclePose().position also causes the same hanging issue,True,False
dresden-elektronik/phoscon-app-beta/65,False,5f17a506bd354327236925f7,"Does the problem still exist, or has it been solved in the meantime? 
If it still exists. From which manufacturer are the lamps.",True,False
dresden-elektronik/phoscon-app-beta/65,False,5f17a65ebd35433171aac9cf,"Yes it still exists. They are all Tradfri-Devises. Scenes are barely working, color temperature is not saved most of the time, lamps that should be off don't go off in scenes (was declared as nofix in another issue?) etc.",True,False
dresden-elektronik/phoscon-app-beta/65,False,5f17a832bd35431e352af1fc,We may should move that to the API repo. It feeld more right there. @YKO-de if you could be so kind 😉 ,True,False
dresden-elektronik/phoscon-app-beta/65,False,5f51b496bd354327642dd309,Any updates on this?,True,False
OpenNMT/OpenNMT/95,False,588ec8de6480fd4a28252c9f,"for me it is ok - we will need to very soon introduce more checks and consistencies on the values of these parameters that have more structure (and probably also for all of them). in `-adaptive_softmax` - I used a notation like `{id1,id2}`",True,False
OpenNMT/OpenNMT/95,False,5890aa016480fd486272b8e2,"Why did you use brackets? It seems a bit risky as it has a meaning in `bash`:

```
$ echo {ye,ee}
ye ee
$ echo b{ye,ee}
bye bee
```

while comma-separated strings have not:

```
$ echo aa,ee
aa,ee
```",True,False
OpenNMT/OpenNMT/95,False,58901b3b6480fd48627247b3,I agree! my point is that we do need to start normalizing :) and adding some validation mechanism,True,False
falkowich/ise/74,False,5e540df0bd35432d2369b0cf,Closing this in favor of #76,True,False
falkowich/ise/74,False,5e540df0bd35432d2369b0d0,Closing this in favor of #76,True,False
michaellukashov/Far-NetBox/86,False,52ee4bd2bd354301f0020f3a,"try new version 2.1.33.280
http://plugring.farmanager.com/plugin.php?pid=859&l=ru",True,False
wordpress-mobile/WordPress-iOS/345,False,527bc037bd35436fe200020b,0d3f1be2fe007e09daff969ce872d083631deaa5 should take care of it,True,False
wordpress-mobile/WordPress-iOS/345,False,52a9ae2bbd3543aafb000564,"@koke This is actually a Core Data fault exception:

 *** Terminating app due to uncaught exception 'NSObjectInaccessibleException', reason: 'CoreData could not fulfill a fault for '0x17e4ce60 <x-coredata://A327ACA1-36A2-4FBE-A30C-DD9A21AC3BF6/ReaderPost/p2>''

@xtreme-rebecca-putinski I see this in a recent internal build, do you think it's related to the caching still or something else?

cc: @sendhil ",True,False
wordpress-mobile/WordPress-iOS/345,False,52a9ae2bbd3543aafb000565,"Does it happen at random or is reproducible? If it is reproducible we can toggle caching to find out. Perhaps it's also related to the issue where all reader posts are deleted when one topic is chosen?

It looks like the object has been removed from the persistent store yet it's still in memory/the table view but the FRC hasn't updated yet -- perhaps implying this was caught between the object being deleted, downloaded (again?) saved, then merged into the main context. I'll look to see what the order of operations is for that process.",True,False
wordpress-mobile/WordPress-iOS/345,False,52a9ae2bbd3543aafb000566,I can't reproduce it personally - but I can give you the crash reports I have if you'd like!,True,False
wordpress-mobile/WordPress-iOS/345,False,52a9ae2bbd3543aafb000567,@xtreme-rebecca-putinski Looks like it was a single crash (reported twice) with the internal build put out DEC-06,True,False
goabstract/abstract-sdk/236,False,5e89e5b4bd354373f16cbd72,"> I also changed the parent parameter to parentId. 

Seems like you fixed it to match the docs 😉 ",True,False
bodhiproject/bodhi-ui/635,False,5b21c2996480fd7d92264423,will land once the travis passed,True,False
sdepold/node-imageable/13,False,50dd1e39e892296b6f00970d,"Are the images removed directly after the image was processed?  


Am Montag, 17. September 2012 um 20:11 schrieb Ovidiu Spatacian-Tarnu:

> Hi,
> Thank you for an extremely easy solution to image manipulation for node.js
> I'm using imageable in one of my apps and I've tried to set up caching but with no success so far.
> Here is what my config file looks like - username and appdirectory are placeholder for my account and application directory.  
> However, no photo gets cached in the directory tmp/imageable. Any suggestions what I might be doing wrong? I've set up all permissions for the directory tmp/imageable.  
> {
> ""namespace"": """",
> ""maxListeners"": 512,
> ""imageSizeLimit"": 1024,
> ""timeouts"": {
> ""convert"": 5000,
> ""identify"": 100,
> ""download"": 1000
> },
> ""whitelist"": {
> ""allowedHosts"": ["".*google.com (http://google.com)"", "".*facebook.com (http://facebook.com)"", "".*localhost"", "".*goeassy.herokuapp.com (http://goeassy.herokuapp.com)""],
> ""trustedHosts"": ["".*google.com (http://google.com)"", "".*localhost"", "".*goeassy.herokuapp.com (http://goeassy.herokuapp.com)""]
> },
> ""keepDownloads"": true,
> ""maxDownloadCacheSize"": 30000,
> ""tmpPathRoot"": ""/Users/username/appdirectory/tmp/imageable""
> }  
>  
> —
> Reply to this email directly or view it on GitHub (https://github.com/dawanda/node-imageable/issues/13).  
>  
>  
>  ",True,False
sdepold/node-imageable/13,False,50dd1e3ae892296b6f00970e,"Thank you for your promp reply Sascha. I'm not sure I understand your question. 

The images don't seem to be downloaded at all in the tmp/imageable folder.",True,False
sdepold/node-imageable/13,False,50dd1e3ae892296b6f00970f,"This is what is use to generate the images <img src=""http://localhost:3000/fit/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300"">",True,False
sdepold/node-imageable/13,False,50dd1e3ae892296b6f009710,"```html
<img src=""http://localhost:3000/fit/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300"">
```",True,False
sdepold/node-imageable/13,False,50dd1e3ae892296b6f009711,"Ah :) ok :)

I guess u misses either the hash or the magic key. Check the docs of
node-imageable. The default is ""magic"". So your url should be smth like

<img src=""http://localhost:3000/fit/magic/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300"">



Am 17.09.2012 um 21:47 schrieb Ovidiu Spatacian-Tarnu <
notifications@github.com>:

<img src=""http://localhost:3000/fit/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300"">

 —
Reply to this email directly or view it on
GitHub<https://github.com/dawanda/node-imageable/issues/13#issuecomment-8628325>.",True,False
sdepold/node-imageable/13,False,50dd1e3ae892296b6f009712,"Thank you Sascha. I've added the hash to the url but still nothing happens. I really don't know what I'm doing wrong. Could it be a bug in node.js/express.js?

On 17 Sep 2012, at 21:09, Sascha Depold <notifications@github.com> wrote:

> Ah :) ok :) 
> 
> I guess u misses either the hash or the magic key. Check the docs of 
> node-imageable. The default is ""magic"". So your url should be smth like 
> 
> <img src=""http://localhost:3000/fit/magic/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300""> 
> 
> 
> 
> Am 17.09.2012 um 21:47 schrieb Ovidiu Spatacian-Tarnu < 
> notifications@github.com>: 
> 
> <img src=""http://localhost:3000/fit/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300""> 
> 
> — 
> Reply to this email directly or view it on 
> GitHub<https://github.com/dawanda/node-imageable/issues/13#issuecomment-8628325>.
> —
> Reply to this email directly or view it on GitHub.
> 
> ",True,False
sdepold/node-imageable/13,False,50dd1e3be892296b6f009713,"I've just deleted the imageable folder from node_modules and run nom install again. Caching seems to be working ok now. Thank you for your help Sascha.

On 17 Sep 2012, at 21:09, Sascha Depold <notifications@github.com> wrote:

> Ah :) ok :) 
> 
> I guess u misses either the hash or the magic key. Check the docs of 
> node-imageable. The default is ""magic"". So your url should be smth like 
> 
> <img src=""http://localhost:3000/fit/magic/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300""> 
> 
> 
> 
> Am 17.09.2012 um 21:47 schrieb Ovidiu Spatacian-Tarnu < 
> notifications@github.com>: 
> 
> <img src=""http://localhost:3000/fit/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300""> 
> 
> — 
> Reply to this email directly or view it on 
> GitHub<https://github.com/dawanda/node-imageable/issues/13#issuecomment-8628325>.
> —
> Reply to this email directly or view it on GitHub.
> 
> ",True,False
sdepold/node-imageable/13,False,50dd1e3be892296b6f009714,"It's possible that u didn't have v0.10.0!?

Am 18.09.2012 um 02:13 schrieb Ovidiu Spatacian-Tarnu <
notifications@github.com>:

I've just deleted the imageable folder from node_modules and run nom
install again. Caching seems to be working ok now. Thank you for your help
Sascha.

On 17 Sep 2012, at 21:09, Sascha Depold <notifications@github.com> wrote:

> Ah :) ok :)
>
> I guess u misses either the hash or the magic key. Check the docs of
> node-imageable. The default is ""magic"". So your url should be smth like
>
> <img src=""
http://localhost:3000/fit/magic/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300"">

>
>
>
> Am 17.09.2012 um 21:47 schrieb Ovidiu Spatacian-Tarnu <
> notifications@github.com>:
>
> <img src=""
http://localhost:3000/fit/lesson-poster.jpeg?url=http://localhost:3000/uploads/images/snow-1347800278949.jpg&amp;size=300x300"">

>
> —
> Reply to this email directly or view it on
> GitHub<
https://github.com/dawanda/node-imageable/issues/13#issuecomment-8628325>.
> —
> Reply to this email directly or view it on GitHub.
>
>

—
Reply to this email directly or view it on
GitHub<https://github.com/dawanda/node-imageable/issues/13#issuecomment-8635541>.",True,False
dart-lang/rpc/121,False,5b2adf376480fdbd3286eba9,I just ran into this problem. Is there a solution yet? Using `dart2js` is not really an option for development.,True,False
dart-lang/rpc/121,False,5b589d6d6480fd192d7a31b3,"I don't quite get the problem either... The generated code in question (if I'm not mistaken) is this:

```dart
oAuthAccounts = _json[""oAuthAccounts""].map((value) => new OAuthAccount.fromJson(value)).toList();
```

where `oAuthAccounts` is of type `core.List<OAuthAccount>`. Why is that not working?",True,False
dart-lang/rpc/121,False,5b2ae2c46480fdb4d8f64154,"So this is a Dart 2.0 runtime type error: a `List<dynamic>` is not a subtype of `List<OAuthAccount>`.

We have updated `package:discoveryapis_generator` to produce valid Dart 2.0 code. Could you verify that after a `pub upgrade`, your `.packages` file contains 
```
discoveryapis_generator:file:///.../.pub-cache/hosted/pub.dartlang.org/discoveryapis_generator-0.9.7/lib/
_discoveryapis_commons:file:///.../.pub-cache/hosted/pub.dartlang.org/_discoveryapis_commons-0.1.6/lib/
```

If not, there might be some 3rd party dependency (or your Dart SDK) requiring a lower version of `package:discoveryapis_generator`, which basically means you're using a generator which is not Dart 2.0 compliant.

Currently the code should be generated e.g. like [this example from package:googleapis](https://github.com/dart-lang/googleapis/blob/master/generated/googleapis/lib/adexchangebuyer/v1_3.dart#L2325):
```dart
  DirectDealsList.fromJson(core.Map _json) {
    if (_json.containsKey(""directDeals"")) {
      directDeals = (_json[""directDeals""] as core.List)
          .map<DirectDeal>((value) => new DirectDeal.fromJson(value))
          .toList();
```
By using `.map<DirectDeal>` it should get the right runtime type.",True,False
dart-lang/rpc/121,False,5b2b95376480fdb752efaf5a,"Thanks @mkustermann ! You're right. The reason we got the old version, is that I forgot that `pub run rpc:generate` uses the globally activated `discoveryapis_generator` so I had to run `pub global activate discoveryapis_generator` to get the latest version.

Is there a way to get `rpc:generate` to run with the local package dependency instead of the globally activated one? This would prevent such a problem to reoccur in the future...

Other than that, I think that this issue can be closed.",True,False
dart-lang/rpc/121,False,5b2b98016480fdb56b3d84ee,"This is really a question for the pub team, but so far I had the impression that:

* You use a local version via
```
$ cat pubspec.yaml
dependencies:
  rpc: any
$ pub upgrade
$ pub run rpc:generate
```

* You use a global version via
```
$ pub global activate rpc
$ pub global run rpc:generate
```
",True,False
dart-lang/rpc/121,False,5b2cd1166480fdb5bf16acd2,"Yes, but `pub run rpc:generate` seems to only use the globally activated `discoveryapis_generator` and not the locally installed one. That's why I thought it might be `rpc` specific.",True,False
dart-lang/rpc/121,False,5b2ceeef6480fdb5bf16b894,"> Yes, but pub run rpc:generate seems to only use the globally activated discoveryapis_generator and not 
> the locally installed one. That's why I thought it might be rpc specific.

Aha. So you're saying `pub run rpc:generate` does not use the `discoveryapis_generator` specified in the `.packages` file but rather the one which is globally activated?

If that's the case, could you please file a bug with pub? (cc @nex3 )",True,False
dart-lang/rpc/121,False,5b2d0ad36480fdb5bf16c598,"An addendum on the errors considering _SDK 2.0.0-dev.64.1_  and _rpc package_ 0.5.10 (today are the last version).

When I try to generate the client side APIs, a new error is occurring:

> `pub run rpc:generate client -i lib/server/augeapi.dart -o lib/client -p 8091`

> Unhandled exception:
> type 'Future<dynamic>' is not a subtype of type 'FutureOr<List<DescriptionImportPair>>'
> #0      ClientApiGenerator.generateDiscoveryWithImports (file:///D:/Users/Samuel/AppData/Roaming/Pub/Cache/hosted/pub.dartlang.org/rpc-0.5.10/bin/generate.dart:204:12)
> #1      _AsyncAwaitCompleter.start (dart:async/runtime/libasync_patch.dart:49:6)
> #2      ClientApiGenerator.generateDiscoveryWithImports (file:///D:/Users/Samuel/AppData/Roaming/Pub/Cache/hosted/pub.dartlang.org/rpc-0.5.10/bin/generate.dart:203:67)
> #3      main (file:///D:/Users/Samuel/AppData/Roaming/Pub/Cache/hosted/pub.dartlang.org/rpc-0.5.10/bin/generate.dart:122:47)
> #4      _AsyncAwaitCompleter.start (dart:async/runtime/libasync_patch.dart:49:6)
> #5      main (file:///D:/Users/Samuel/AppData/Roaming/Pub/Cache/hosted/pub.dartlang.org/rpc-0.5.10/bin/generate.dart:85:5)
> #6      _startIsolate.<anonymous closure> (dart:isolate/runtime/libisolate_patch.dart:277:32)
> #7      _RawReceivePortImpl._handleMessage (dart:isolate/runtime/libisolate_patch.dart:165:12)
> 
",True,False
dart-lang/rpc/121,False,5b2d0c156480fdb9549d2c8c,@supermuka for me it's working fine now. I'm on `dev.63` though because `dev.64.1` had problems with globally installed packages. Try reverting to `dev.63` and see if that changes anything.,True,False
dart-lang/rpc/121,False,5b3161176480fdb5fe5294b9,"@enyo, for me works on `dev.63` too. But... 

I think this package deserved more attention in its maintenance, focusing on new versions and suggestions for improvement. I say this because we can see many issues open, which worries me, because _this package is one of the most useful and nice things_ that the _Dart Team_ has already done to facilitate the implementation of RESTfull APIs. I would love to see this package taking special care in its evolution.",True,False
dart-lang/rpc/121,False,5b3387576480fdb617950333,"@mkustermann, on version SDK `dev.65` and `rpc package 0.5.10` when `pub run rpc:generate` is ran, the following error continue being thrown:

> `type 'Future<dynamic>' is not a subtype of type 'FutureOr<List<DescriptionImportPair>>'`

If there is a suggested workaround, I'd be grateful!

Note: because of other package dependencies, it is necessary to use the latest version of the SDK.

",True,False
dart-lang/rpc/121,False,5b3a16706480fd2059f99c50,"Changed the title for this issue, considering that last version of the SDK thrown exception to Dart2js too.",True,False
dart-lang/rpc/121,False,5b3b3daa6480fd17563f9b2a,"I've now looked at this and it appears that, after fixing some Dart 2.0 issues, it is blocked on the fact that `Isolate.spawnUri` has a bug in the Dart 2.0 version, where it doesn't support spawning from http urls anymore. 

So this is blocked on https://github.com/dart-lang/sdk/issues/33741",True,False
dart-lang/rpc/121,False,5b589d6c6480fd171764c326,Fixed in #124.,True,False
bmuschko/gradle-docker-plugin/405,False,595ce0476480fd5177fa6ad7,LGTM,True,False
bmuschko/gradle-docker-plugin/405,False,595ce1dc6480fd5be21c5173,"@orzeh I already the environment variables a while ago. However, the variable defining the GitHub token is called `GH_TOKEN`. You can just hard-code the user variable for now.",True,False
bmuschko/gradle-docker-plugin/405,False,595cf7366480fd515d303ef4,@bmuschko ok I've used `GH_TOKEN`. I also added default value for `release.scope` parameter and changed the documentation accordingly. ,True,False
bmuschko/gradle-docker-plugin/405,False,595cfae76480fd50f45d7642,@orzeh can you still define `release.stage=final` in the `gradle.properties` file but comment it out with a note saying it needs to be enabled/passed at release time? I'd still like to have it defined even if it is commented out.,True,False
bmuschko/gradle-docker-plugin/405,False,595f9fe86480fd51495bbf5d,@orzeh merging this in now as I plan to do another release with latest `docker-java`.,True,False
bmuschko/gradle-docker-plugin/405,False,595faa546480fd573605783d,"Think we have to revert this commit. Attempting to release with it popped:

https://travis-ci.org/bmuschko/gradle-docker-plugin/builds/251195000",True,False
bmuschko/gradle-docker-plugin/405,False,595fb4d46480fd5d785921ce,"@orzeh so something odd is happening. I've been playing around trying to get this to work and it created tag `v3.0.10` but created release `v3.0.11`? I can't seem to figure out where it's getting the default patch version to use so that it can be bumped.

@bmuschko looks like there was a `3.0.11-dev*` version released on bintray we may want to delete as well.",True,False
bmuschko/gradle-docker-plugin/405,False,596004e86480fd5d78594db8,"@cdancy OK, I know what was wrong: when we added `release.scope=patch` in `gradle.properties` built-in strategy called `RebuildVersionStrategy` [can't be used](https://github.com/ajoberstar/gradle-git/blob/master/src/main/groovy/org/ajoberstar/gradle/git/release/semver/RebuildVersionStrategy.groovy#L54). Before our changes, it was used on Travis release job: git head was on tag and repo was clean -> inferred version was the same as tag. 

After you reverted this PR you set default version strategy to `FINAL`. Then on Travis release job this strategy was selected as fallback, because - as before `RebuildVersionStrategy` can't be used and git repo was clean -> version was increased at `patch` because `release.scope`. Thus tag `3.0.10` and version `3.0.11`. It's a little bit complicated, but this is how it works :smile: .

It will fix it here. ",True,False
bmuschko/gradle-docker-plugin/405,False,596006986480fd5798444376,"Thanks @orzeh !!! My apologies if I got thinks out of whack as I was just trying to do a release (which I eventually did) and read the docs at the same time and fix a fire drill here at work :)

",True,False
bmuschko/gradle-docker-plugin/405,False,596007566480fd51495bf882,@cdancy no problem :) I pushed new commits to  `FIX-PUBLISH-DOC` branch and going to submit PR one more time.,True,False
bmuschko/gradle-docker-plugin/405,False,5960f79b6480fd5b50a1086f,@cdancy I just deleted 3.0.11-dev.0+f5b8053 from Bintray.,True,False
bmuschko/gradle-docker-plugin/405,False,59611c036480fd52b62e60f8,+1,True,False
clc/eyes-free/303,False,54f638edbd3543c4e9000e1f,"```
Miriam if you turn off the screen and turn it on again reconnects brailleback

The problem I have is that, with or accentuated (ó) you can not write, I am to 
write, you write a zero (0)


Miriam si apagas la pantalla y la enciendes nuevamente brailleback conecta de 
nuevo 

el problema que tengo yo es que, la o acentuada (ó) no se puede escribir, al 
escribirla se escribe  un cero (0)
```

Original comment by `discapac...@gmail.com` on 9 Aug 2013 at 8:38",True,False
clc/eyes-free/303,False,54f638edbd3543c4e9000e20,"```
As noted in #1, toggling the screen will reconnect the display.
```

Original comment by `caseybur...@google.com` on 5 Dec 2013 at 9:19
* Changed state: **Invalid**",True,False
h2opaulh2o/IP-A3-Project/8,False,553f67adbd35432589010cc5,Done by entire testing team.,True,False
qmk/qmk_configurator/112,False,5af7b9046480fd2079a4bbae,Fixed.,True,False
viastudio/wpmt/32,False,54b85185bd3543ec890039a9,:poultry_leg: ,True,False
patacrep/patacrep/76,False,553fca3abd35430dad0015f9,"Arf, Travis est pas content ... Bon, je vais regarder ça =) 

EDIT: C'est juste du pylint ^^ Je vais me mettre un hook pre-push je pense =)",True,False
patacrep/patacrep/76,False,55401819bd35430e5b00253b,"Bon, je reproduis en local, mais je n'arrive pas à voir où est le problème. `pylint` est trop verbeux pour trouver ce qui ne luis convient pas. @paternal, une idée du problème ? Le log complet est sur [travis](https://travis-ci.org/patacrep/patacrep/builds/60379203), et pylint retourne 8 chez moi.",True,False
patacrep/patacrep/76,False,55416c3bbd3543be56003509,"Je regarderai ça à l'occasion. Deux remarques ou questions : 
- Si on trouve qu'avoir Pylint dans travis est trop contraignant, on peut l'enlever, ou au moins, lui demander de n'afficher que les erreurs ou remarques critiques. On continuera alors à faire, de temps en temps, un commit spécial pylint.
- Je ne comprends pas ce que tu veux dire par « J'ai eu besoin de ça quand j'ai repris mon carnet perso avec des plugins situés en dehors du dossier patacrep/content ». Il y a des plugins hors d'un datadir ? Si oui, pourquoi ? Si non, peux tu préciser le problème ?

-- Louis",True,False
patacrep/patacrep/76,False,5541e0e9bd3543c3840041cd,">  Si non, peux tu préciser le problème ?

Les plugins sont bien dans un datadir, mais pas dans `patadata` ou `patacrep/data`. Il manquait suite à un refactoring les `sys.path.append`, et donc les plugins n'était plus importés.",True,False
patacrep/patacrep/76,False,55488731bd3543848a00c1f5,"À moins que tu ne trouves mieux, il faudra peut-être exclure pylint de tox. En effet, je n'arrive pas à comprendre comment fonctionne le code de retour (exit status) : on a [ceci](https://lists.logilab.org/pipermail/python-projects/2009-November/002068.html), mais j'ai parfois des résultats différents…",True,False
patacrep/patacrep/76,False,5554aad8bd3543fcc0008b67,Fermé en faveur de #77 ,True,False
openshift/tektoncd-pipeline-operator/471,False,5f75e660bd35437c4eba9ee1,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/openshift/tektoncd-pipeline-operator/pull/471#"" title=""Author self-approved"">khrm</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=openshift%2Ftektoncd-pipeline-operator).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[OWNERS](https://github.com/openshift/tektoncd-pipeline-operator/blob/v1.2.x/OWNERS)~~ [khrm]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",True,False
openshift/tektoncd-pipeline-operator/471,False,5f75e660bd35437c4eba9ee2,@vdemeester Already did.,True,False
openshift/tektoncd-pipeline-operator/471,False,5f76bbf8bd35436cd4c41e43,/lgtm,True,False
openshift/tektoncd-pipeline-operator/471,False,5f75e96cbd35436878c1d827,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/openshift/tektoncd-pipeline-operator/pull/471#"" title=""Author self-approved"">khrm</a>*, *<a href=""https://github.com/openshift/tektoncd-pipeline-operator/pull/471#issuecomment-702176041"" title=""LGTM"">vdemeester</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=openshift%2Ftektoncd-pipeline-operator).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[OWNERS](https://github.com/openshift/tektoncd-pipeline-operator/blob/v1.2.x/OWNERS)~~ [khrm,vdemeester]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",True,False
stefansundin/one-click-screenshot/1,False,5865f6ef6480fd0f37425f93,"That's a great idea. I'll look into it.
",True,False
stefansundin/one-click-screenshot/1,False,57e038956480fda8cc3a46eb,"Thanks!  BTW, Nimbus Screen Capture (the antithesis of your extension!) is very flexible in this regard, if you want to take a look.",True,False
stefansundin/one-click-screenshot/1,False,5865f6ef6480fd0f37425f94,A keyboard shortcut will be added to the next version. By default the shortcut is Alt+Shift+S.,True,False
stefansundin/one-click-screenshot/1,False,5865d9266480fd0f5501c6b7,Great!  Thanks!,True,False
stefansundin/one-click-screenshot/1,False,586a209e6480fd0c4ac56199,"Just for reference, it looks like the default shortcut is Alt+Shift+W in Firefox.

Can you add a way to change that, even if it's just an about:config pref?

Also, the shortcut isn't doing anything right now, but it might be because the extension isn't working at all for me.",True,False
stefansundin/one-click-screenshot/1,False,586ab7996480fd18b7f0ac45,"I was originally planning to use Alt+Shift+S on Firefox too, but it conflicted with opening the history menu (try pressing Alt+S). What happened is that the history menu opened and the screenshot procedure started, and I don't know how to override that behavior. So I decided to switch the shortcut.

There is no way to change the default shortcut for webextensions in Firefox. The easiest way for you to experiment with it is to download the source code and load it in `about:debugging`. If you can find a way to improve it, let me know.

When I first loaded the extension, I noticed that I had to reload tabs to get the shortcut to work in that tab. Not sure why it happened.",True,False
stefansundin/one-click-screenshot/1,False,586ae23e6480fd0f37448f77,"Thanks for the feedback.

In regards to not changing the shortcut, that is going to cause an issue with many extensions!

Perhaps you can file a bugzilla report so that Mozilla knows it's an issue.

BTW, in your description on AMO, you might want to include the fact that this is a *webextensions* extension.  They are the ""hot"" thing right now, and it might draw more interest from the community.",True,False
percolatestudio/meteor-synced-cron/109,False,58fdaf1a6480fdc7f1e42d10,"We're seeing the same issue but having a much greater difference. 

```
{ 
    ""_id"" : ""WtS9Ppf5RZL5sFcaM"", 
    ""intendedAt"" : ISODate(""2017-04-22T17:30:00.000+0000""), 
    ""name"" : ""Open checkin for Hearthstone 1v1 Cup (id: Kf5DFKNqZaCpXiq9A)"", 
    ""startedAt"" : ISODate(""2017-04-22T17:29:27.696+0000""), 
    ""finishedAt"" : ISODate(""2017-04-22T17:29:29.453+0000""), 
    ""result"" : null
}
```

I have cronjobs starting up to 1 minute before they were intended to run. Is there an option to have the cronjobs run no any sooner than the intendedAt? Later wouldn't be so bad but sooner is kind of a big problem.

If you have already found a solution @artpolikarpov let me know ;)
",True,False
percolatestudio/meteor-synced-cron/109,False,5a0659d16480fd1a6ddc39be,"Can you guys please try setting the cron to start 1 minute later, this seems to be a bug in the timing so as a workable way to use it just append 1 minute to when you wish to begin this is how I am getting around it... hope this can help",True,False
Samsung/iotjs/644,False,59e95b5f6480fdd0d560c842,"It's apparently worth to discuss. However, seeing no further opinion so far, it seems not necessary task right now. There is no volunteer who can progress this topic. Please re-open/issue this if anyone can do this.",True,False
Samsung/iotjs/644,False,59e990a16480fdd494459743,@daeyeon we are working on something that can fix this too. I hope I can open a proof of concept patch soon. I'll open an issue with the proposal.,True,False
kedgeproject/kedge/134,False,5963980f6480fd5d785aa3b6,can we avoid word compose?,True,False
kedgeproject/kedge/134,False,5964895f6480fd55e38adbf9,"> We have:
Compose Kubernetes apps using Kubernetes constructs

Not anymore. I had changed it some time back. At least I see this -  _"" Kedge - Concise Application Definition for Kubernetes""_. Both in the title at the top and in the main readme. This explanation is correct and sounds nice.

I would definitely like to avoid the word ""compose"". I think the word ""concise"" is definitely better than ""condensed"" and perhaps even ""compact"".",True,False
kedgeproject/kedge/134,False,5964b3906480fd5be21ffd32,"I'm quite happy with ""Concise Application Definition for Kubernetes"" it is short, and I think it describes kedge well.",True,False
kedgeproject/kedge/134,False,5964c6e46480fd52b62ff0d7,I saw the title change. :+1: Let's close this since it's been updated. :100: ,True,False
kagedao/sample_app/7,False,5e614d6abd35431dba1b5c05,Superseded by #9.,True,False
laravel/cashier/636,False,5cb0181b6480fd773108f9c8,Instead of being reliant on webhooks we could maybe use the Manual confirmation? The code doesn't look to hard to write. You would have to have some type of API that handles the different statuses and send back responses to the front-end. Here is the docs: [https://stripe.com/docs/payments/payment-intents/quickstart#flow-manual-confirmation](https://stripe.com/docs/payments/payment-intents/quickstart#flow-manual-confirmation) ,True,False
laravel/cashier/636,False,5cb0d60a6480fd74184bd7f6,"I too am looking into this, not only as a way to be SCA compliant but also to help prevent bank disputes. It's a pretty critical feature.

The flow seems a bit ambiougs to me. If anyone can make sense of it / clarify could you comment? It would also help Cashier implement a flow that works with plans/subscriptions.

### The Payment Intent Flow (as I understand it) - using stripe js / php

1. You create a payment intent on server side when you hit the checkout page (and store this in session for future use) using the details of your plan:

```php
$plan = \Stripe\Plan::retrieve('your-subscription-plan-id', [
    'api_key' => config('services.stripe.secret'),
]);

$paymentIntent = \Stripe\PaymentIntent::create([
    'amount'               => $plan->amount,
    'currency'             => $plan->currency,
    'payment_method_types' => ['card'],
], [
    'api_key' => config('services.stripe.secret'),
]);
```

You can then pass the payment intent details onto your view / form so that it can be used in js when you eventually make a call to `handleCardPayment`

2. In javascript, you collect card details / mount etc in the usual way and instead of making a call to `stripe.createToken()` instead you call `stripe.handleCardPayment()`:

```js
stripe.handleCardPayment(document.querySelector('input[name=""payment_intent_secret""]'), card).then(function(result) {
    if (result.error) {
        // Payment failed.
    } else {
        // Payment successful.
    }
});
```

3. This is where I get a bit confused, but I'm assuming at that point if the payment was successful, you can create a token for the user and susbcribe them to the plan. I would imagine you would want it to skip the first payment as you have already paid for the first month in the payment intent? Maybe this is where trial period comes into play? I'm also not sure where the web hook comes into play here, as I would assume if the callback is successful then you don't need to do any further checks?

4. At that point on the server you can clear the payment intent - maybe this is where the web hook comes into play? Is it needed though when you can just get the payment intent when you hit the checkout page, check its status to see if its ""expired"" and instead use a new one:

```php
$paymentIntent = null;
if (session('paymentIntentId')) {
    $paymentIntent = \Stripe\PaymentIntent::retrieve(session('paymentIntentId'), [
        'api_key' => config('services.stripe.secret'),
    ]);
}

$expiredPaymentIntent = $paymentIntent && in_array($paymentIntent->status, ['canceled', 'succeeded']);

if (! $paymentIntent || $expiredPaymentIntent) {
   // Create new payment intent as its either not created or old one has expired.
   session()->put('paymentIntentId', $paymentIntent->id, now()->addDay());
}
```

If anyone can shed light on the flow / clarify how they've got it working in their app that would be much appreciated.",True,False
laravel/cashier/636,False,5cb0d7396480fd7a99d5ef74,"Hey @garygreen, thanks for helping out! I'll look into your reply as soon as I get to the issue.",True,False
laravel/cashier/636,False,5cb48e966480fd75d171dace,"Ok so I spoke with Stripe and they have informed me this is the best place to understand the workflow for payment intents with subscriptions: https://stripe.com/docs/billing/subscriptions/payment

(that docmentation only went live on Thursday, so its still a WIP but it's much better place to understand than the other docs because they focus on one-off payments rather than subscriptions)

The key factor is a subscription may now enter a new status called `incomplete` which means it will have a `payment_intent` object and a client secret - you then need to use something like `Stripe.js` to go back to the browser with the payment intent secret and call the Stripe.js with:

```js
var stripe = Stripe('key here');

// This can be found on invoice.payment_intent.client_secret
var paymentIntentSecret = 'pi_91_secret_W9';

stripe.handleCardPayment(
    paymentIntentSecret
).then(function (result) {
    if (result.error) {
        // Display error.message in your UI.
    } else {
        // The payment has succeeded. Display a success message.
    }
})
```

... that will then prompt for any 3D secure payments / other things needed to complete the payment. A webhook will then fire to note that the payment went thru `invoice.payment_succeeded`

Hopefully that helps. The docs explain it better but that's how I've understood it.",True,False
laravel/cashier/636,False,5cb48fd76480fd70b09e285a,"@garygreen that helps! We actually need to revert the behavior I added in https://github.com/laravel/cashier/pull/631 because of the `incomplete` status you mentioned above. It was a good fix for 9.x because it reverted Cashier to the same behavior as before but with Payment Intents we indeed need to accommodate for a window where the customer is making the payment with 3D secure, etc. Webhooks will later update the subscription if payment failed.",True,False
laravel/cashier/636,False,5cb5d5f46480fd7821b49d4d,"Bit more info - you can also pass a `expand` parameter during the creation of the subscription which allows you to access the PaymentIntent object without creating multiple API requests. This will be very useful when needing to go back to the browser/client with the payment intent secret to do any nessscary steps to complete the payment.

Example in node, but hopefully get the idea:

```js
let subscription = await stripe.subscriptions.create({
    customer: customer.id,
    items: [
        {
            plan: ""plan_DQYe83yUGgx1LE"",
        },
    ],
    expand : [""latest_invoice.payment_intent""]
}); 
```
",True,False
laravel/cashier/636,False,5cb5d6a96480fd710094fc51,"Also I've had to override the `SubcriptionBuilder` payload method in order for Stripe to not fail payment instantly if needing 3D check:

```php
<?php

namespace App\Cashier;

use Laravel\Cashier\SubscriptionBuilder as LaravelSubscriptionBuilder;

class SubscriptionBuilder extends LaravelSubscriptionBuilder
{
	/**
	 * Build the payload for subscription creation.
	 *
	 * @return array
	 */
	protected function buildPayload()
	{
		return array_merge(parent::buildPayload(), [
			'enable_incomplete_payments' => true
		]);
	}
}
```

I've got payment intents mostly working locally now with current version of Cashier. Still a work in progress (understanding the hooks etc), but it's looking good so far. ",True,False
laravel/cashier/636,False,5cbeba9a6480fd9fdd700091,"Just wanted to share information about upcoming changes being added to Stripe on Juli 1, 2019 regarding Subscriptions. 

## Further changes needed for subscription in EU
> If you are based in Europe and preparing for Strong Customer Authentication (SCA) is a new regulatory requirement coming into effect on September 14, 2019 which will impact many European online payments. It requires customers to use two-factor authentication like 3D Secure to verify their purchase, **you will need to make further changes after July 1 in order to perform authentication when saving a card for subsequent off-session payments to qualify for off-session exemptions**. This API will be available by July 1. [Source](https://stripe.com/docs/payments/payment-intents/migration#saving-cards-checkout)",True,False
laravel/cashier/636,False,5cbebb866480fd9eaabbf684,@bilfeldt thanks for noting that. I'll create a separate issue for this. We'll release an update for this once the API has been released.,True,False
laravel/cashier/636,False,5cdef0646480fd15e72b0ee0,I've been working on a PR for this and it's coming along nicely. Follow along here: https://github.com/laravel/cashier/pull/667,True,False
webmd-health-services/Whiskey/179,False,5b1ed7bb6480fd7f69445c87,@splatteredbits Requested changes to documentation completed.,True,False
chbatey/kafka-unit/22,False,57304b006480fda4e2001dbf,+1,True,False
chbatey/kafka-unit/22,False,575192ec6480fdfd787b8eb3,LGTM after you fix the log message,True,False
chbatey/kafka-unit/22,False,5751ae3f6480fdfc4f361fe2,"my bad.  I've been using slf4j for all my projects, and didn't think to check the logging lib used in this one.  pushed a new commit with the change.",True,False
OpenModelica/OMCompiler/2102,False,5a5715a96480fd0d1018ca15,The test suite is unstable according to [OpenModelica_TEST_PULL_REQUEST 2018-01-11_08-28-55](https://test.openmodelica.org/hudson//job/OpenModelica_TEST_PULL_REQUEST/5081/).,True,False
OpenModelica/OMCompiler/2102,False,5a571e4c6480fd0d3d796fdb,The tests run correctly according to [OpenModelica_TEST_PULL_REQUEST 2018-01-11_09-05-39](https://test.openmodelica.org/hudson//job/OpenModelica_TEST_PULL_REQUEST/5082/console).,True,False
intel-isl/Open3D/1935,False,5edd8dccbd35436850f2415a,"Thanks for submitting this pull request! The maintainers of this repository would appreciate if you could update the **CHANGELOG.md** based on your changes.
",True,False
docker/libkv/31,False,55db21e91b487679d801d6da,"Hi @cloudfly, thanks for catching this! You are right, there might be issues using a simple `Update` to update the `ttl` even though we hold the lock. See #32.",True,False
wojodesign/simplecart-js/289,False,50c805d8edecb52e310000fb,"Hi Craig, I found a way to do this. Not sure if it is correct, but it works.

On line 192 of simpleCart.js comment out the line 

oldItem.increment(newItem.quantity()); 

This will simply prevent the cart from adding another quantity of the same item. 

Cheers!

",True,False
wojodesign/simplecart-js/289,False,527a6b30bd3543c7620000cc,"Hi, what about limiting items of the same type, i.e. if I have 3 items of the type A, how do i toggle the cart item when the user selects another item of this type.

Thanks in advance",True,False
wojodesign/simplecart-js/289,False,51bf19bfbd354399f80000ec,"This is very very late, but this is how you'd do it:

```
simpleCart.bind('beforeAdd', function(item){
    return !simpleCart.has(item);
});
```",True,False
YouCanBookMe/react-datetime/106,False,578e0cc36480fdeab6986257,"Hey @simeg 

Nice work, this is the kind of things I never have time to do :) your help is much appreciated!

Thanks",True,False
cornell-dti/campus-density-backend/45,False,5fd49b05bd35431aafd4ca19,[diff-counting] Significant lines: 0.,True,False
lord/slate/748,False,58ed25836480fda2553dd487,"Yup! If you copy `src/index.md.html` to a new file, like `src/foo.md.html`, you'll get a second document at <http://localhost:4567/foo.html>. Does that solve your problem?",True,False
lord/slate/748,False,58ed355f6480fd9a40d52e73,"Almost.  After we have made some changes, I am executing the following from the command line:
`bundle exec middleman build --clean`

When I do so I get a nice build folder with the appropriate file structure and the index.html
build -> index.html

If I needed two version of ""builds""
One for developers: with some code like the following that is included in the index.html.md file:
`
includes:
  - general/introduction
  - how-tos/overview
  - how-tos/DeveloperGuidelines
  - how-tos/GettingDevelopersStarted
  - how-tos/Example1
  - how-tos/Example2
`
and another build that will be used for non-developers:
`
includes:
  - general/introduction
  - how-tos/overview
  - how-tos/Example1
  - how-tos/Example2
`

I would like to see the following in my root folder structure when I run the following:
`bundle exec middleman build --clean`
root -> build-dev -> index.html
root -> build -> index.html

does that make my question clear?

I think what I would need to do is have two separate files (index.html.md) one for the Developers docs, and one for the non-developers, and then run (`bundle exec middleman build --clean`) this twice.  Would this be correct?
",True,False
lord/slate/748,False,58ed368b6480fda7e21bcf8b,"almost, I responded back to the closed issue request.

On Tue, Apr 11, 2017 at 1:50 PM Robert Lord <notifications@github.com>
wrote:

> Closed #748 <https://github.com/lord/slate/issues/748>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/lord/slate/issues/748#event-1038900874>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AX_rkDQrw-wCZMArkIAaSJ5e2fnZQiAYks5ru8uIgaJpZM4M6fbp>
> .
>
",True,False
lord/slate/748,False,58ed38ef6480fda07c127eeb,"@javadrum I think going with two separate index.html.md files is the way to go here. Middleman, Slate's source Static Generator, doesn't allow you to customize a specific index-- it just renders the source markdown files.

What I would suggest is using something like [Grunt](https://gruntjs.com/) or Gulp to run a task to swap your files out in a task, where you have say:

- `index-dev.html.md`  - a copy of index.html.md with your dev-friendly docs
- `index-simple.html.md`- a copy of index.html.md with your non-dev docs

Then, create a grunt task to copy `index-dev.html.md` to `index.html.md`, build the site, then copy the `build` folder to something like a `/build-dev`folder, then it could repeat the same for `index-simple.html.md`-- copy it over to `index.html.md` and then copy the ""simple"" build out to `/build-simple`.

You basically will have three build folders after you run a task:

- build (which is the full build of the site for whichever was built last)
- build-dev (which is the dev version)
- build-simple (which is the simple version)

Then, it's just a matter of rsync-ing (or whatever your deployment method is) the correct build to your server in the correct location.

Let me know what you think!",True,False
lord/slate/748,False,58ed39726480fd99588fb370,"That is perfect..   your answer is what I was envisioning, but I just wanted to make sure I wasn't missing something.",True,False
lord/slate/748,False,58ed39a56480fda07c127f3f,"Just to further clarify, the steps would be, effectively, all shell scripts like this:
```
cp index-dev.html.md index.html.md
bundle exec middleman build --clean
cp /build /build-dev
cp index-simple.html.md index.html.md
bundle-exec middleman build --clean
cp /build /build-simple
echo ""double build complete!""
```",True,False
putyourlightson/craft-snaptcha/1,False,5c62f4f76480fdda5b3fe96f,"Thanks, fixed in version 2.1.1, please update the plugin (using composer if possible) before running the database update.",True,False
mikeizbicki/HerbiePlugin/9,False,560977f61b48764bb500109c,"I'm not sure why Herbie is reporting the two expressions as having different errors.  I'll contact the Herbie program developers about what's going on.

The issue with the warnings is because HerbiePlugin does not fully support the standard Prelude.  There is a detailed description of this bug in the [known bugs](https://github.com/mikeizbicki/HerbiePlugin#known-bugs) section of the README.",True,False
mikeizbicki/HerbiePlugin/9,False,560efa1b1b48762cc10031a7,"I've figured out why those expressions are giving different results.  This is related to bug #16.  The problem is that I was too aggressive in removing parenthesis from the expression.  Here's the new output:
```
Found math expression within binding test5 :: Float -> Float -> Float
  original expression = ((x * x) + ((2 * x) * y)) + (y * y)
  Not found in database.  Running Herbie...
  improved expression = (x * x) + ((y * y) + ((x * y) * 2))
  original error = 1.5625e-2 bits
  improved error = 3.90625e-3 bits
```
The change in association is the cause of the change in error reported.

I still want to get Herbie to report some actual cases where the results differ at.",True,False
mikeizbicki/HerbiePlugin/9,False,560f5e841b48761f60004b77,"Cool.. It would indeed be nice for Herbie to print values where the results do differ. I did a bit of experimentation, and found the following. For the original expression, my version of Herbie actually produced the following optimized expression:

```
(x * x) + ((2 * (y * x)) + (y * y))
```

which is different than what you provided above; but still seems to be a valid rewrite. With this output, I found the following values:

```
     x =        +5024.234000
     y =      +106856.310000
  orig = +12517257000.000000
   opt = +12517256000.000000
 exact = +12517256125.735936
```

`orig` is the result of the original expression; `opt` is the result of the Herbie-optimized expression, and `exact` is the result with infinite precision. It is nice to note that the original differs from the exact result by about 875, while Herbie's expression only differs by 125. It would be so cool if Herbie printed this sort of an output indeed.",True,False
yabwe/medium-editor/869,False,5641d4381b487616380001d7,ugh,True,False
yabwe/medium-editor/869,False,567086056480fd93b600332c,"+1
![screenshot 2015-12-15 16 27 44](https://cloud.githubusercontent.com/assets/1660273/11824621/de9dd53a-a348-11e5-83b0-c4a120b1f107.png)
",True,False
yabwe/medium-editor/869,False,56710af06480fdb39a000d0c,"@cperryk @brijeshb42 Could you give us a Word file that we can use to reproduce the bug?
Also, which browser are you using? What is your MediumEditor configuration?",True,False
yabwe/medium-editor/869,False,5694193d6480fd150c001f1a,"Here's an example:
[comments example.docx](https://github.com/yabwe/medium-editor/files/86383/comments.example.docx)

Here's just a snippit of the comments I'm seeing pasted in to an empty paragraph:

```
<!--[if gte mso 9]><xml>  <w:WordDocument>   <w:View>Normal</w:View>   <w:Zoom>0</w:Zoom>   <w:TrackMoves/>   <w:TrackFormatting/>   <w:PunctuationKerning/>   <w:ValidateAgainstSchemas/>   <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>   <w:IgnoreMixedContent>false</w:IgnoreMixedContent>   <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>   <w:DoNotPromoteQF/>   <w:LidThemeOther>EN-US</w:LidThemeOther>   <w:LidThemeAsian>JA</w:LidThemeAsian>   <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>   <w:Compatibility>    <w:BreakWrappedTables/>    <w:SnapToGridInCell/>    <w:WrapTextWithPunct/>    <w:UseAsianBreakRules/>    <w:DontGrowAutofit/>    <w:SplitPgBreakAndParaMark/>    <w:EnableOpenTypeKerning/>    <w:DontFlipMirrorIndents/>    <w:OverrideTableStyleHps/>    <w:UseFELayout/>   </w:Compatibility>   <m:mathPr>    <m:mathFont m:val=""Cambria Math""/>    <m:brkBin m:val=""before""/>    <m:brkBinSub m:val=""&#45;-""/>    <m:smallFrac m:val=""off""/>    <m:dispDef/>    <m:lMargin m:val=""0""/>    <m:rMargin m:val=""0""/>    <m:defJc m:val=""centerGroup""/>    <m:wrapIndent m:val=""1440""/>    <m:intLim m:val=""subSup""/>    <m:naryLim m:val=""undOvr""/>   </m:mathPr></w:WordDocument> </xml><![endif]-->
```",True,False
yabwe/medium-editor/869,False,569421686480fd1847002042,"I've seen HUGE metadata like this. fortunately it's allll wrapped in comment nodes. 

```
        if(node && (node.nodeType === 8 || (node.nodeType === 1 && /^o\:/i.test(node.tagName)))){
            node.parentNode.removeChild(node);
        }
```

works to cleanup after the fact. 

or you could do a customReplacements that will match `<!--(.*)-->` or similar?",True,False
yabwe/medium-editor/869,False,569422ac6480fd22580021c3,"In my jquery ways, I've used this:
```
            $(editable).find(""p"").contents().each(function() {
                if(this.nodeType === Node.COMMENT_NODE || this.nodeType == 8) {
                    $(this).remove();
                }
            });
```
Can't figure out how to recursively grab the comments, so I just have to count on them being first level children of `<p>` tags",True,False
yabwe/medium-editor/869,False,569425866480fd144100226f,"Actually, looks like this setting in the paste settings works:

```
cleanReplacements: [[/<!--[^>]*-->/gi, """"]],
```

Full settings: 
```
                    paste: {
                        cleanPastedHTML: true,
                        forcePlainText: true,
                        cleanReplacements: [[/<!--[^>]*-->/gi, """"]],
                        cleanAttrs: ['class', 'dir', 'style', ],
                        cleanTags: ['label', 'meta', 'aside', 'span']
                    },

```",True,False
redisson/redisson/1796,False,5c1132f56480fd5491d8f522,支持,True,False
PJMPR/YourSquare/1,False,5849ea3b6480fd4f74ea8b31,xx,True,False
JohnWhy/DnD-Discord-Bot/2,False,5c69b8896480fdd9b27acd65,"This issue has been fixed, and should no longer be affecting user experience, if you experience bot slowdowns get in touch with me",True,False
JohnWhy/DnD-Discord-Bot/2,False,5ca30c176480fd706ff15d4a,The createprof command is not working ,True,False
kylemanna/systemd-utils/3,False,5726bfd16480fd5b9b0005fc,"For what distribution? Arch linux doesn't have a libpam-systemd package.  Furthermore, what exactly needs the pam library?",True,False
kylemanna/systemd-utils/3,False,572715966480fd52f8001bb6,"On Debian based systems.
But there is a bug for installing this package by default.

It is needed to enable user services in systemd.",True,False
kylemanna/systemd-utils/3,False,572766686480fd52b90072a6,What is the error message without it?  I fear that Debian distributions that don't have necessary facilities to do something as simple as enabling a user service probably isn't setup to fully integrate systemd user sessions and this may be the first of a few battles.,True,False
kylemanna/systemd-utils/3,False,5727686c6480fd5323003101,"Actually I don't use systemd, this is the first server without sysvinit.

The error message said that `Failed to get D-Bus connection: Connection refused`
http://forum.armbian.com/index.php/topic/470-systemctl-user-failed-to-get-d-bus-connection-connection-refused/",True,False
kylemanna/systemd-utils/3,False,57276a0b6480fd5e940033d3,"I see.  It's a bug in the upstream distribution as I suspected.  This repository doesn't try to fix all bugs on all distributions.

It appears that upstream has attempted to fix it [here](http://forum.armbian.com/index.php/topic/470-systemctl-user-failed-to-get-d-bus-connection-connection-refused/#entry2936) and [here](http://forum.armbian.com/index.php/topic/470-systemctl-user-failed-to-get-d-bus-connection-connection-refused/#entry2938).",True,False
kylemanna/systemd-utils/3,False,57276a1e6480fd528f002e52,Hopefully anyone who encounters this bug can find this issue for a hint for a workaround in the interim.,True,False
pawelsalawa/sqlitestudio/543,False,5a5be7db6480fd0d18fade82,"Originally created at: Sat Jan 28 14:38:06 2012

_Status changed to **rejected**_

**Rejection reason:**
Duplicate of 429.",True,False
ProtoSchool/organizing/26,False,5c475ca36480fdacbc65d171,"I'm not a chapter organizer, but wanted to introduce myself as a resource for all of you! 

I'm a Community Manager at Protocol Labs, where one of my most important roles is as a co-maintainer of ProtoSchool along with @mikeal. Before becoming a web developer, I studied education and spent many years planning conferences for web developers and designers, then transitioned into developer advocacy. I first heard about the decentralized web through my involvement with the [Offline First](http://offlinefirst.org) community. I'm a co-organizer of [Offline Camp](http://offlinefirst.org/camp), a tech retreat meant to bring together the community focused on making apps work in all network conditions. 

As someone who started coding just a few years ago and is quite new to decentralized technologies, I'm focused on ensuring that ProtoSchool remains beginner-friendly and welcoming to people of diverse backgrounds (coding and otherwise). 

Part of my job is to make the experience of being a chapter organizer as easy as possible, so please feel free to share your suggestions on our processes and documentation.",True,False
ProtoSchool/organizing/26,False,5c47e38b6480fda8f9b54980,"Hi Organizers,

First of all, I would like to introduce myself a bit.
I am Bob Jiang, founder of [HiBlock.one](https://hiblock.one) community, ambassador of Gitcoin.co and also a Certified Scrum Trainer from Scrum Alliance. 

## What interested you in becoming a chapter organizer?
I am a community promoter since 2011, first as an Agile community advocator (mostly in China, also connect to worldwide), and second start to promote blockchain since Jan, 2018. 
I love blockchain and distributed technology, and I can see in the future, blockchain could help and be helped with community (included open source) a lot.
 
## What do you want to do with your local community?
I'd like to make friends in community, and find the partner to run community together. For me I have other business to make life, so community is just part-time work (and I believe community should be part-time, interest based, and awarded fairly). 
So during community, I would like to explore how to keep a community long life.

## What do you see as the vision and mission for your chapter?
Here is just mine, we could combine all organizers' together.

- Connect blockchain technical people 
- Promote blockchain technique",True,False
ProtoSchool/organizing/26,False,5c49fa8e6480fdabf21e180c,"Hi all, this is Kevin from Hong Kong. Nice to meet you all 😁

What interested you in becoming a chapter organizer?

* We are currently running Hong Kong IPFS Community and Protoschool is just the perfect match for us to strengthen the community and help the interested parties to further understand how awesome all the things that Protocol Labs have been done.

What do you want to do with your local community?

* Help and educate the public about the decentralized web's development and inspire people to learn and contribute to the community. We will hold regular meetups to take feedback and gather a group of enthusiast so we can work together and build a better community.

What do you see as the vision and mission for your chapter?

* check out our repo: https://github.com/ProtoSchool/hong-kong",True,False
ProtoSchool/organizing/26,False,5c4fed3c6480fda5513e11ef,"Hi, this is Jim from Seattle. Nice to have this discussion thread to learn about each others.

**What interested you in becoming a chapter organizer?**

I am just getting into decentralized web and for most part an information consumer. A wise man told me that for my limited existence on planet earth, I should find my passion and start contributing and become a producer. I also got into community building and organizing events last year, and it gave me a bit more purpose in life outside of my family and work. I was inspired by [Mikeal's talk](https://www.youtube.com/watch?v=83Gws-dPL8A) and want to learn more, so I decided to learn while help building the community. 

**What do you want to do with your local community?**

Hopefully by putting efforts to help organize events, and perhaps contribute here to learn about great ways to connect with members in other decentralized locations. Within my bubble, folks are curious about decentralized web, but not much organizing effort or collaboration happens beyond chatting over coffee or water fountains. I believe ProtoSchool is the venue to channel that curiosity and energy.

**What do you see as the vision and mission for your chapter?**

In Seattle chapter, I (@jimcal) hope to work with Cameron Wheeler (@zebul) to plant the seed by bootstrapping the beginning of ProtoSchool Seattle chapter, and to educate and grow the decentralized web community. If this resonates with you, we hope you can join us!",True,False
ProtoSchool/organizing/26,False,5c50acda6480fdab5de6262d,"@NukeManDan I took the liberty of shortening the title of this issue to make it fully readable while pinned. Hope you don't mind!

![image](https://user-images.githubusercontent.com/19171465/51935236-733d9c80-23d3-11e9-94ad-5c528a2d2822.png)
",True,False
numenta/nupic/3131,False,573c3a1c6480fdc83802ec21,"By analyzing the blame information on this pull request, we identified @rhyolight to be a potential reviewer",True,False
numenta/nupic/3131,False,57444e366480fdd02c055c58,@rhyolight can you review and merge? ,True,False
numenta/nupic/3131,False,57446bed6480fdcc49055bbf,"Interesting findings. This tp_profile script is testing a very nonrealistic special case, but you're right that the old TP is faster in this case.

This script:

- Uses random inputs
- Uses ~50% sparsity

So if there are 2048 columns, ~1024 of them are active. So, 1024 different segments have to grow / reinforce synapses every timestep. The inputs are random, so none of the synapses are useful. It's hard to predict the exact outcome, since the 50% sparsity might cause tons of false positives, so segments might actually activate quite often despite the random input.

One reason the old TP is faster in this case is because its synapse cleanup code is better. This experiment stress-tests the heck out of synapse cleanup. The flaw with the TM's code (it's actually buggy, not just slow) is that its synapse cleanup deletes one synapse at a time, rather than doing them in groups like the TP's `freeNSynapses` method. This is slower, and doing it one at a time is wrong because if you create 10 synapses and it triggers one-at-a-time cleanup, you might effectively only add 1 synapse, repeatedly cleaning up the just-added synapse. This is a known issue. I'm planning on making segment/synapse cleanup better, you can see [I've been studying for it](http://mrcslws.com/blocks/2016/05/05/tp-segment-cleanup.html).

One reason the TM/TP become slower than the SP in this case is that the SP is more capable of handling non-sparse inputs. Since it uses connection matrices rather than lists of synapses, the change in sparsity doesn't have a dramatic effect on the overlap calculation.

Usually when we talk about the performance of the algorithms, we use non-random inputs. And since you're feeding patterns directly into the TM, you need to think about sparsity.",True,False
numenta/nupic/3131,False,57446f506480fdcf64051284,"@mrcslws thank you for your review and for the pointer to your blog! 

> Uses ~50% sparsity

good point, I will adapt to use 2% sparsity, to track the common behavior. Is there available ""the code from NAB"" that let's one to obtain the ""best"" params for SP/TM? 

> Uses random inputs

I'm aware of this, consider this like the ""worst case scenarion"". Is there a better way to mimick ""notmal: data? That is overlaps of inputs are more common. ",True,False
numenta/nupic/3131,False,574470b46480fdc4e905311a,"From another PR: it looks like the SP parameters are quite off in sp_profile. Why is potentialRadius only 3? It should be much larger to form good SDRs. Same with numActiveColumnsPerInhArea, etc. etc. Why is epochs set to 150 here? 

I think the parameters should be set to realistic numbers and the profile re-run with those numbers.",True,False
numenta/nupic/3131,False,574472276480fdc9a805564a,"> the SP parameters are quite off ...

thanks @subutai , Marcus explained that, I agree...and don't know where I've taken the params from - from some example. I think it shows 2 another optimization problems: ""the time metric"" would make sense; and ""optimal default params"" - do we agree ""hotgym"" is a source of those opt. params? I'll make another PR for the latter and update SP/TM/TP in nupic/nupic.core constructors. 

I'll update the optimization issue with the updated benchmarks. ",True,False
numenta/nupic/3131,False,574472c36480fdcfcf05a714,"> do we agree ""hotgym"" is a source of those opt. params?

Well, it looks like sp_profile is trying to benchmark SP with local inhibition and 2D topology.  If that is the goal, you can't use hotgym parameters, since hotgym uses global inhibition. You need to have parameters that make sense for the 2D toplogy / local inhibition scenario.",True,False
numenta/nupic/3131,False,574473856480fdce60059814,"> Well, it looks like sp_profile is trying to benchmark SP with local inhibition and 2D topology 

It is used to benchmark SP on 1D vs ""2D"" data (the 2D is fake, it's just {2048} vs {2048,1}) - please see motivation for that: numenta/nupic.core#380

So I'm looking for best params for 1D too. ",True,False
numenta/nupic/3131,False,574483d26480fdc3d4062901,"For random inputs vs non-random, I'd say it's ambiguous. There are lots of experiments you can run, and it's unclear which is the right one. Maybe it's best to have a distribution of tests, so the result isn't just a single time, but a table of times. So far my perf tests have been hotgym and this script: https://github.com/numenta/nupic/blob/master/scripts/temporal_memory_performance_benchmark.py . (It's definitely not a full perf test suite.)

One problem with random inputs is that it actually doesn't cover all the code. With sparse column activations, random inputs will never activate or even match a segment. You can see this in my 2nd, 3rd, and 4th diagrams in [this blog post](http://mrcslws.com/blocks/2016/04/28/life-and-times-of-dendrite-segment.html). When it starts doing random input, the segments get zero excitation. So it never reinforces or punishes a segment. So although you're right that random is generally the worst case, it's still not a holistic test. It will completely overlook the performance of segment reinforcement / punishment.",True,False
numenta/nupic/3131,False,576644276480fd1bba36683e,"**WARNING!** This Pull Request has been inactive for 25 days, and will be **automatically closed in 5 days** if not updated before then. *This is an automated message.*",True,False
numenta/nupic/3131,False,576db17b6480fd1bf6ba2ec1,"This Pull Request is now automatically **closed due to inactivity**, as warned about 5 days ago. *This is an automated message.*",True,False
numenta/nupic/3131,False,576db1766480fd1e3466552c,"@rhyolight can this PR be reopened and merged just as is, or with minor modifications? It fixes the profile scripts (and adds TM shim to benchmark). 

From the discussion we conclude that those scripts still benchmark only some ""type"" of the code/code paths; so e.g. hotgym is still a relevant and likely better benchmark. ",True,False
numenta/nupic/3131,False,576dbdb16480fd1bcb6d9a2f,"@breznak Per our process, we can't merge this until @numenta/nupic-reviewers gives it a thumbs-up. I don't know this code well enough to make that call. ",True,False
numenta/nupic/3131,False,578f22a26480fd40b2789580,"**WARNING!** This Pull Request has been inactive for 25 days, and will be **automatically closed in 5 days** if not updated before then. *This is an automated message.*",True,False
numenta/nupic/3131,False,57970ba56480fd6cf1a24dc3,"This Pull Request is now automatically **closed due to inactivity**, as warned about 5 days ago. *This is an automated message.*",True,False
dvx/lofi/60,False,5ec9d747bd35437181e6a3aa,"What OS and video card is this on? This seems to be an issue related to 3D acceleration and transparency not working, not really something I can fix on my end.",True,False
dvx/lofi/60,False,5ec9d7c8bd3543694cfdcdab,"Windows 10 and gtx 980m. As far as transparency, I have a discord plugin that makes discord transparent",True,False
dvx/lofi/60,False,5ecad0adbd35435b6d830c32,"Seems related to https://github.com/electron/electron/issues/2170 and https://github.com/electron/electron/issues/16809

Will investigate to see if waiting for window creation fixes the transparency issue on Windows, although I'm not experiencing it personally.",True,False
dvx/lofi/60,False,5efe647dbd35433e620f66af,This will have a potential fix in the next release. Just added a way to enable or disable hardware acceleration.,True,False
dvx/lofi/60,False,5f062fd7bd35432ffb59462b,Should be fixed in the newest release (try enabling or disabling the new 3d acceleration feature).,True,False
chromaui/learnstorybook.com/271,False,5e39ef42bd3543417884d1e9,"@sshiling sorry for not having the time to check this properly, but this week...this week was one of those weeks....i've skimmed through it and it looks good. I would like to give this the proper attention today (sunday) as there's just some slight changes that could be incorporated to allow the documentation to be aligned in all it's forms (translations). ",True,False
chromaui/learnstorybook.com/271,False,5e3b6710bd354349bb59fbc5,"@tmeasday @domyen merge when ready! This is good to go. @sshiling i would like to personally thank you for implementing this really quick and i'm confident that the team behind Storybook is aswell. Once again thank you, for the fix for that vue cli issue with jest issue.

 If you don't mind i'm going to close your other 2 pull requests in favor of this one. ",True,False
chromaui/learnstorybook.com/271,False,5e3c1490bd35432b276b7399,Thanks @sshiling! and for the assist @jonniebigodes ,True,False
antmaczam/board/6,False,60594ba4bd354377044e716f,Superseded by #7.,True,False
nicoparraguez/Tarea_33/8,False,6058aceabd35435d351923ff,Superseded by #12.,True,False
nathanvda/cocoon/90,False,50b4e46bedecb50f8b0001a0,"This seems like great work. I will have an in depth look at it tonight. Indeed, if I understand correctly, this could handle the array-fields as well,  if somebody would add the correct method `build_<array-field>`.",True,False
nathanvda/cocoon/90,False,50b4e46bedecb50f8b0001a1,"Yes, exactly.
Ideally I wold like to pass the builder method via options too.
But the convention in this PR should be a good start and sufficient for 95% of cases.

If you'll accept it, we would have to add it to README too I suppose.

On 24/09/2012, at 21:37, Nathan Van der Auwera <notifications@github.com> wrote:

> This seems like great work. I will have an in depth look at it tonight. Indeed, if I understand correctly, this could handle the array-fields as well, if somebody would add the correct method build_<array-field>.
> 
> —
> Reply to this email directly or view it on GitHub.
> ",True,False
nathanvda/cocoon/90,False,50b4e46bedecb50f8b0001a2,@nathanvda thanks for merging it in. I wonder when are you planning to release it?,True,False
nathanvda/cocoon/90,False,50b4e46bedecb50f8b0001a3,I want to update my demo-project and then I will release it. I hope to finish that on wednesday.,True,False
nathanvda/cocoon/90,False,50d75e45edecb51ac000292c,"I tried this way to handle array fields and it works with ""link_to_add_association"".

I'm just not sure of what should be in ""build_[array field]"" method and what's the difference between ""build_[singular array field]"" and ""build_[plural array field]"" as noted into specs.

I've tried this and it seems to work but it doesn't seem very clean to me :
````ruby
    def build_paths
      { :"""" => """" }
    end
````
I get an error if I provide an array since the field name method doesn't exsits.

A small example would be nice ;-)

Note that, for array fields, the field has to be set like this in the partial : `f.input """"` (simple_form) since we need empty brackets in html input name (`name=""object[paths][]""` ; There should be indexes but it doesn't work...)

The big issue is that `link_to_remove_association` doesn't work at all because of `is_dynamic = f.object.new_record?` in line 27. As there's no model (`f.object`is nil), there's no `new_record?`method.

For now, I juste don't use `link_to_remove_association` and reject empty array entries.",True,False
nathanvda/cocoon/90,False,50d78388edecb51ad700397f,"There's another problem : I don't know how to recover existing array values in the form.

Changing `build_paths` to this raises an error :

````ruby
    def build_paths
      paths
    end
````

Actually, the purposed design doesn't really fit with array fields since you're waiting for a 'virtual' association and field names. But an array has a single field with no name.

My initial (not very clean) pull request was made to specifically handle this case. I don't see how to do it with this new feature. It's made for non AR compatible models but a model with fields is still required...",True,False
nathanvda/cocoon/90,False,50d79348edecb51a880038fe,I will try to add an example later this evening or tomorrow morning.,True,False
nathanvda/cocoon/90,False,50d868b5edecb51a2b009503,"@porecreat here's an example (stripped down a bit). All you need is the `build_additional_participation` (which in your case could be `build_paths` or `build_path` returning a new ActiveModel model instance):

```ruby
class CompanyInvitation < ActiveRecord::Base
  attr_accessor :additional_participations

  def additional_participations
    @additional_participations ||= parse_additional_participations
  end

  def build_additional_participation
    Participation.new # Required by cocoon for the nested forms - return a single instance of a new object
  end

  def additional_participations_attributes=(values)
    @additional_participations = values.each.map do |k, params|
      params.delete('_destroy')
      # Convert user_email, user_fn etc into {user => email, fn etc}
      user_params = Hash[ Participation::USER_FIELDS.map{|f| [f, params[""user_#{f}""]]} ]
      user_params['password_confirmation'] = user_params['initial_password'] = user_params['password']
      Participation.new(params.merge('user_attributes' => user_params)).tap do |p|
        p.company = company
      end
    end
  end
end
```",True,False
nathanvda/cocoon/90,False,581a48f66480fd21990b2c61,I know this is a little old but... thank you @dnagir! You save my life 👍 ,True,False
nathanvda/cocoon/90,False,5b4e39616480fd1756469eaa,Can we have the same feature for `link_to_remove_association`?,True,False
aegypius/language-gentoo/7,False,5a2bd0f36480fd145b52ca02,Thanks again !,True,False
pinicarus/piquouze/24,False,582b88eb6480fd0f18d90841,+1,True,False
radicle-dev/radicle-upstream/871,False,5f52ffe3bd35436060ba804b,"I have applied this fix, described in the issue, in another project with success:

``` js
  typescriprt((
    noEmitOnError: true,
  })
```",True,False
pyoo47/liferay-portal/1023,False,5cc112686480fda5d9de9344,"To conserve resources, the PR Tester does not automatically run for every pull.

If your code changes were already tested in another pull, reference that pull in this pull so the test results can be analyzed.

If your pull was never tested, comment &quot;ci:test&quot; to run the PR Tester for this pull.",True,False
pyoo47/liferay-portal/1023,False,5cc112686480fda5d9de9345,ci:test:sf,True,False
pyoo47/liferay-portal/1023,False,5cc112686480fda5d9de9346,ci:test:relevant,True,False
pyoo47/liferay-portal/1023,False,5cc112686480fda5d9de9347,"<html><h3>:heavy_check_mark: ci:test:sf - 1 out of 1 jobs passed in 3 minutes 12 seconds 904 ms</h3><details><summary>Click here for more details.</summary><h4>Base Branch:</h4><p>Branch Name: <a href=""https://github.com/liferay/liferay-portal/tree/master"">master</a><br/>Branch GIT ID: <a href=""https://github.com/liferay/liferay-portal/commit/0b3b1a56f815e9ad8eed90426f0202d33ccd2d3a"">0b3b1a56f815e9ad8eed90426f0202d33ccd2d3a</a></p><h4>Sender Branch:</h4><p>Branch Name: <a href=""https://github.com/michaelhashimoto/liferay-portal/tree/master-ci-181"">master-ci-181</a><br/>Branch GIT ID: <a href=""https://github.com/michaelhashimoto/liferay-portal/commit/0650f309fdf4aa4b4095db071e55c3ebb3dcee19"">0650f309fdf4aa4b4095db071e55c3ebb3dcee19</a></p>1 out of 1jobs PASSED<details><summary><strong>1 Successful Jobs:</strong></summary><ul><li><a href=""https://test-1-14.liferay.com/job/test-portal-source-format/1242/"">test-portal-source-format</a></li></ul></details><h5>For more details click <a href=""https://test-1-14.liferay.com/userContent/jobs/test-portal-source-format/builds/1242/jenkins-report.html"">here</a>.</h5></details></html>",True,False
pyoo47/liferay-portal/1023,False,5cc11cc26480fda6e6bed3e2,"<h1>Build started.</h1><p>Jenkins is currently running tests.</p><h4>Base Branch:</h4><p>Branch Name: <a href=""https://github.com/liferay/liferay-portal/tree/master"">master</a></p><h4>Job Summary:</h4><p>Job Link: <a href=""https://test-1-14.liferay.com/job/test-portal-acceptance-pullrequest(master)/4229/"">test-portal-acceptance-pullrequest(master)</a></p><p><b>For more details click <a href=""https://test-1-14.liferay.com//userContent/jobs/test-portal-acceptance-pullrequest(master)/builds/4229/jenkins-report.html"">here</a>.</b></p>",True,False
pyoo47/liferay-portal/1023,False,5cc133d36480fda28716bb55,"<html><h3>:x: ci:test:relevant - 18 out of 21 jobs passed in 1 hour 38 minutes 44 seconds 602 ms</h3><details><summary>Click here for more details.</summary><h4>Base Branch:</h4><p>Branch Name: <a href=""https://github.com/liferay/liferay-portal/tree/master"">master</a></p><h4>Copied in Private Modules Branch:</h4><p>Branch Name: <a href=""https://github.com/null/liferay-portal-ee/tree/null""/></p>18 out of 21 jobs PASSED<div><h4>3 Failed Jobs:</h4><ul><li><a href=""https://test-1-14.liferay.com/job/test-portal-acceptance-pullrequest(master)/4229/""><strike><strong>test-portal-acceptance-pullrequest(master)</strong></strike></a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47792/""><strike><strong>test-portal-acceptance-pullrequest-batch(master)/central-requirements-jdk8</strong></strike></a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47803/""><strike><strong>test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/5</strong></strike></a></li></ul></div><details><summary><strong>18 Successful Jobs:</strong></summary><ul><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47791/"">test-portal-acceptance-pullrequest-batch(master)/functional-smoke-tomcat90-mysql57-jdk11_open/0</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47795/"">test-portal-acceptance-pullrequest-batch(master)/functional-smoke-tomcat90-mysql57-jdk8/0</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47800/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/0</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47799/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/1</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47796/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/2</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47805/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/3</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47804/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/4</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47802/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/6</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47793/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/7</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47789/"">test-portal-acceptance-pullrequest-batch(master)/js-unit-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47794/"">test-portal-acceptance-pullrequest-batch(master)/lpkg-base-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47788/"">test-portal-acceptance-pullrequest-batch(master)/lpkg-controller-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47797/"">test-portal-acceptance-pullrequest-batch(master)/modules-compile-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47806/"">test-portal-acceptance-pullrequest-batch(master)/modules-integration-mysql57-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47787/"">test-portal-acceptance-pullrequest-batch(master)/modules-unit-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47790/"">test-portal-acceptance-pullrequest-batch(master)/modules-unit-project-templates-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47798/"">test-portal-acceptance-pullrequest-batch(master)/pmd-jdk8</a></li><li><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47801/"">test-portal-acceptance-pullrequest-batch(master)/semantic-versioning-jdk8</a></li></ul></details><h5>For more details click <a href=""https://test-1-14.liferay.com/userContent/jobs/test-portal-acceptance-pullrequest(master)/builds/4229/jenkins-report.html"">here</a>.</h5><hr/><h4>Failures unique to this pull:</h4><ol><li><div><h5><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47803/"">test-portal-acceptance-pullrequest-batch(master)/functional-upgrade-tomcat90-mysql57-jdk8/5</a></h5><div><h6>Job Results:</h6><p>1 Test Passed.<br/>1 Test Failed.</p></div><ol><li><div><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/AXIS_VARIABLE=0,label_exp=!master/47803//consoleText"">AXIS_VARIABLE=0,label_exp=!master #47803</a><ol><li><div><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/AXIS_VARIABLE=0,label_exp=!master/47803//testReport/com.liferay.poshi.runner/PoshiRunner/test_LocalFile_PortalSmokeUpgrade_ViewPortalSmokeArchive704_"">LocalFile.PortalSmokeUpgrade#ViewPortalSmokeArchive704</a> - <a href=""https://testray.liferay.com/reports/production/logs/null/null/null/null/functional-upgrade-tomcat90-mysql57-jdk8/5/0/LocalFile.PortalSmokeUpgrade_ViewPortalSmokeArchive704/index.html.gz"">Poshi Report</a> - <a href=""https://testray.liferay.com/reports/production/logs/null/null/null/null/functional-upgrade-tomcat90-mysql57-jdk8/5/0/LocalFile.PortalSmokeUpgrade_ViewPortalSmokeArchive704/summary.html.gz"">Poshi Summary</a> - <a href=""https://testray.liferay.com/reports/production/logs/null/null/null/null/functional-upgrade-tomcat90-mysql57-jdk8/5/0/jenkins-console.txt.gz"">Console Output</a></div></li></ol></div></li></ol></div></li></ol><hr/><details><summary><strong>Failures in common with <a href=""https://test-1-1.liferay.com/job/test-portal-acceptance-upstream(master)"">acceptance upstream results</a> at 7604b4e226fd1c221d0b113586f7d9fd102a649a:</strong></summary><ol><li><div><h5><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/47792/"">test-portal-acceptance-pullrequest-batch(master)/central-requirements-jdk8</a></h5><div><h6>Job Results:</h6><p>6 Tests Passed.<br/>1 Test Failed.</p></div><ol><li><div><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/AXIS_VARIABLE=0,label_exp=!master/47792//consoleText"">AXIS_VARIABLE=0,label_exp=!master #47792</a><ol><li><div><a href=""https://test-1-18.liferay.com/job/test-portal-acceptance-pullrequest-batch(master)/AXIS_VARIABLE=0,label_exp=!master/47792//testReport/com.liferay.portal.modules/ModulesStructureTest/testScanGradleFiles"">ModulesStructureTest.testScanGradleFiles</a><pre><code>junit.framework.AssertionFailedError: Incorrect configuration of dependency {compileOnly project("":apps:asset:asset-display-page-api"")} in modules/apps/layout/layout-type-controller/layout-type-controller-test/build.gradle, use one of these instead: ""testIntegrationCompile"", ""testIntegrationRuntime""
	at com.liferay.portal.modules.ModulesStructureTest._testGradleFile(ModulesStructureTest.java:1356)
	at com.liferay.portal.modules.ModulesStructureTest.access$700(ModulesStructureTest.java:66)
	at com.liferay.portal.modules.ModulesStructureTest$3.visitFile(ModulesStructureTest.java:338)
	at com.liferay.portal.modules.ModulesStructureTest$3.visitFile(ModulesStructureTest.java:313)
	at java.nio.file.Files.walkFileTree(Files.java:2670)
	at java.nio.file.Files.walkFileTree(Files.java:2742)
	at com.liferay.portal.modules.ModulesStructureTest.testScanGradleFiles(ModulesStructureTest.java:311)
</code></pre></div></li></ol></div></li></ol></div></li></ol></details></details></html>",True,False
pyoo47/liferay-portal/1023,False,5cc1fedf6480fd9def55834a,"Pushed to BChan
https://github.com/brianchandotcom/liferay-portal/pull/72266",True,False
nigelnt/AlgsSimplification/3,False,56605ee56480fde94b00bfe4,"bash-3.2$ php index.php 
Unable to allocate GD stream
bash-3.2$ 
",True,False
nigelnt/AlgsSimplification/3,False,565ddfde6480fdb41000283f,with last commit you can call this data processing by http://[...]/AlgsSimplification/?src=4,True,False
biosustain/swiglpk/5,False,55f0c9cf1b487610d70452f5,"Looks good and I can certainly use this, thanks.",True,False
biosustain/swiglpk/5,False,55f0c9cf1b487610d70452f6,Great! I'm looking forward to the next release :smile: ,True,False
biosustain/swiglpk/5,False,55f0c9cf1b487610d70452f7,"@jonls can I convince you to create a new pull request for this feature? I removed your code from `glpki.i` as it fails to build on appveyor (see also https://ci.appveyor.com/project/phantomas1234/swiglpk/build/1.0.89/job/842swhr7eaoods4f).

```
creating build
creating build\temp.win32-2.7
creating build\temp.win32-2.7\Release
C:\Program Files (x86)\Common Files\Microsoft\Visual C++ for Python\9.0\VC\Bin\cl.exe /c /nologo /Ox /MD /W3 /GS- /DNDEBUG -IC:\Python27\include -IC:\Python27\PC /Tcglpk_wrap.c /Fobuild\temp.win32-2.7\Release\glpk_wrap.obj
glpk_wrap.c
glpk_wrap.c(2963) : error C2275: 'PyObject' : illegal use of this type as an expression 
        c:\python27\include\object.h(108) : see declaration of 'PyObject'
glpk_wrap.c(2963) : error C2065: 'r' : undeclared identifier 
glpk_wrap.c(2964) : error C2065: 'r' : undeclared identifier
glpk_wrap.c(2964) : warning C4047: '==' : 'int' differs in levels of indirection from 'void *'
glpk_wrap.c(2970) : error C2065: 'r' : undeclared identifier
glpk_wrap.c(2970) : warning C4047: '==' : 'int' differs in levels of indirection from 'void *'
glpk_wrap.c(2970) : error C2065: 'r' : undeclared identifier
glpk_wrap.c(2970) : error C2065: 'r' : undeclared identifier
glpk_wrap.c(2970) : error C2065: 'r' : undeclared identifier
glpk_wrap.c(2979) : warning C4013: 'glp_term_hook' undefined; assuming extern returning int
error: command 'C:\\Program Files (x86)\\Common Files\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\cl.exe' failed with exit status 2
```

I am pretty sure it is related to MSVC choking on types not being declared on top (see http://stackoverflow.com/questions/9903582/error-c2275-illegal-use-of-this-type-as-an-expression). I am a mediocre C programmer so I don't want to try fixing this myself. This should be fixable now that appveyor integration works thanks to you.

BTW, the custom install and build commands in setup.py were actually needed. I found an alternative that works with bdist_wheel on appveyor.",True,False
biosustain/swiglpk/5,False,55f0c9cf1b487610d70452f8,I already made a PR in #7 on top of 1.1.1. I can rebase that on `master` or `devel` if you prefer. What were the custom install and build commands needed for?,True,False
friendica/friendica/3359,False,58f75a2b6480fda8ac475b5e,"I wouldn't like to change it for frio. I know the situation is not ideal at the moment. I hope in the future friendica will also have something like `function is_matrix_url()` which would recognize if a link does belong to the friendica network. The idea is that `Friendica` links would open in the same tab and non `Friendica` links would open in a new tab. But at the moment we don't have the possibility to distinguish the links. I hope that @beardyunixer will something like this. 

To explain my decision:
One of my goals of `Frio` was the strengthen the feeling in `Friendica` of being one single network (like the big commercial ones). The other themes do open all external links (and also some internal links) always in a new tab. After 15min of clicking arround you end up with 15 new tabs which you have to close. This was really annoying (especially on mobile devices).
If the user want to open the source in a new tab he/she can use right click - open in new tab.",True,False
friendica/friendica/3359,False,58f761b46480fda6b7820553,"Another issue I have is that I use the web app in standalone mode (add to homescreen on Android) and when an external link opens in the same webview, it is hard to return to my instance because i don't have any browser GUI.

I understand your arguments but maybe this could be added as an option in the theme?",True,False
friendica/friendica/3359,False,58f7639c6480fdb236e774e9,I have nothing against options :-),True,False
friendica/friendica/3359,False,58f763cb6480fdad2c8da447,Great! I will try to submit a PR for this.,True,False
friendica/friendica/3359,False,58f7647b6480fdb2e0d47d0a,"Something does come to my mind regarding the android web app.
Is it possible to identify through js if friendica is used as web app or in a browser? In this case we could add `target=_blank` through js.",True,False
friendica/friendica/3359,False,58f768c96480fda54fc98d58,"According to [this article](https://developers.google.com/web/updates/2015/10/display-mode) you can use something like this:
```js
if (window.matchMedia('(display-mode: standalone)').matches) {

}
```",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c710016c46,"_Imported from trac issue 299.  Created by benny.malengier@gmail.com on 1969-12-31T19:21:17, last modified: 1969-12-31T19:21:17_
",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c806016c99,"_Imported from trac issue 299.  Created by benny.malengier@gmail.com on 1969-12-31T19:21:17, last modified: 1969-12-31T19:21:17_
",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c710016c47,"_Trac comment by wd15 on 1969-12-31 19:21:56:_

Fixed with changeset:4761",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c7cb016910,"_Trac comment by wd15 on 1969-12-31 19:21:56:_

Fixed with changeset:4761",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c710016c48,"_Trac comment by guyer on 1969-12-31 19:21:56:_

I agree that the previous error wasn't very helpful, but wouldn't it be better to just support the operations instead of raising a slightly clearer error?",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c785016bde,"_Trac comment by guyer on 1969-12-31 19:21:56:_

I agree that the previous error wasn't very helpful, but wouldn't it be better to just support the operations instead of raising a slightly clearer error?",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c710016c49,"_Trac comment by wd15 on 1969-12-31 19:21:58:_

__sub__ does work now. Line
source:trunk/fipy/meshes/abstractMesh.py#L917 dealt with that.

{{{
>>> from fipy import *
>>> print (Grid1D() - [[1]]).cellCenters
[[-0.5]]
}}}
",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c9030168e1,"_Trac comment by wd15 on 1969-12-31 19:21:58:_

__sub__ does work now. Line
source:trunk/fipy/meshes/abstractMesh.py#L917 dealt with that.

{{{
>>> from fipy import *
>>> print (Grid1D() - [[1]]).cellCenters
[[-0.5]]
}}}
",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c6ed016acc,"_Trac comment by wd15 on 1969-12-31 19:21:58:_

Added __div__ method with changeset:299. Closing.",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c710016c4a,"_Trac comment by wd15 on 1969-12-31 19:21:58:_

Added __div__ method with changeset:299. Closing.",True,False
wd15/fipy-migration/865,False,5320d51bbd3543c7e2016b06,"_Trac comment by wd15 on 1969-12-31 19:21:58:_

Replying to [comment:9 wd15]:
> Added __div__ method with changeset:4805. Closing.
",True,False
tontof/kriss_feed/241,False,51cc81c94681246d950017f9,"Do you know if the referer is sent by your browser ?
I understand the problem but don't really know how to solve it...",True,False
tontof/kriss_feed/241,False,51d2e2764681242f120001c0,"Le Thu, 27 Jun 2013 18:16:13 +0200, tontof <notifications@github.com> a  
écrit:

>
> Do you know if the referer is sent by your browser ?

Well, in fact I use Opera, and don't know what is sent by it. How can i  
check that ?
>
>
> I understand the problem but don't really know how to solve it...

That's no good news :-/
Selfoss author adds to its config.php file a base_url parameter that  
allows configurations like mine to work OK (and selfoss worked correctly)  
(but i don't know if it can be of any help to you). Here is selfoss doc  
for that parameter

base_url    base url of the selfoss page; use this option if you use a ssl  
proxy which changes the $_SERVER globals
",True,False
tontof/kriss_feed/241,False,51d2e6894681242f3100036d,"Try to update with the new unstable version : 
https://raw.github.com/tontof/kriss_feed/master/src/index.php
and modify the ```''``` at the beginning of the file with the same base_url of selfoss :
```php
define('BASE_URL', '');
```
I don't know if it will be ok because I've used MyTool::getUrl() and it may be problematic on some links.
Just let me know if it changes a bit",True,False
tontof/kriss_feed/241,False,522d0e4fbd3543b4bc00534d,"I have a similar problem with the current stable version, my web server is behind stunnel and sslh, hence I do port forwarding to HTTP on port 80, and I can't connect over HTTPS unless I hardcode in MyTool::getUrl()
```php
$https = true;
```
The funny thing is that Shaarli works just fine, even though it uses a very similar code to get the URL! I found it in
```php
function serverUrl()
```
Any idea? merci !",True,False
tontof/kriss_feed/241,False,51ebbbb2bd35431715000926,"That's strange because I've just added some isset to the shaarli code.
If you replace in the MyTool::getUrl function : 
```php
        $https = (!empty($_SERVER['HTTPS'])                                     
                  && (strtolower($_SERVER['HTTPS']) == 'on'))                   
            || (isset($_SERVER[""SERVER_PORT""])                                  
                && $_SERVER[""SERVER_PORT""] == '443'); // HTTPS detection.       
        $serverport = (!isset($_SERVER[""SERVER_PORT""])                          
                       || $_SERVER[""SERVER_PORT""] == '80'                       
                       || ($https && $_SERVER[""SERVER_PORT""] == '443')          
                       ? ''                                                     
                       : ':' . $_SERVER[""SERVER_PORT""]);
```
by
```php
        $https = (!empty($_SERVER['HTTPS'])                                     
                  && (strtolower($_SERVER['HTTPS']) == 'on'))                   
            || $_SERVER[""SERVER_PORT""] == '443'; // HTTPS detection.       
        $serverport = ($_SERVER[""SERVER_PORT""] == '80'                       
                       || ($https && $_SERVER[""SERVER_PORT""] == '443')          
                       ? ''                                                     
                       : ':' . $_SERVER[""SERVER_PORT""]);
```
Does it work ?

",True,False
tontof/kriss_feed/241,False,51ebe2d4bd35431689001fa7,"No, I have the same problem :/ (and there is an extra parenthesis in your code :)
I actually don't understand how it's possible for the script to detect that it's HTTP or HTTPS, because the HTTPS is hidden for my web server, stunnel taking transparently care of the SSL layer. But once again, Shaarli works surprisingly fine!
Maybe a ""Force HTTPS"" checkbox in the configuration page would help.",True,False
tontof/kriss_feed/241,False,51ebf5e6bd354316ad002e32,"I've deleted the extra parenthesis.

Well I think that if it works for shaarli it's not a good idea to hack this problem using a checkbox. Did you try using the BASE_URL parameter with the developpement version ? I guess it should resolve the problem, even if I don't understand why it works for shaarli without this.",True,False
tontof/kriss_feed/241,False,51ec4b4cbd35431689006a4c,"Well it's working better, but I had to hack the code and add the following lines at the beginning of MyTool::getUrl() since it's called everywhere
```php
    public static function getUrl()
    {
       $base = BASE_URL;
       if (!empty($base)) {
          return $base;
       }
       ...
```
I don't know the impacts so I'm not proposing a pull request... plus I have some bugs with the dev version, I can't see the configuration buttons! I don't know if it's due to my hack...
Merci :)",True,False
tontof/kriss_feed/241,False,51ec4d76bd35431689006bec,"Well I definitely have too correct the use of getUrl/BASE_URL which is too buggy.

What do you mean by conf buttons (Cancel and Save modifications) ?",True,False
tontof/kriss_feed/241,False,51ec5574bd354316ad007259,"I meant the buttons/links (depending on the skin) to add a feed for instance, or to access the config menu. But it's probably my ""Orangina Rouge"" skin which is not compatible with the latest dev version...
Good luck fixing, in the mean time, I'm falling back to v7 with my nice hardcode!",True,False
tontof/kriss_feed/241,False,522cc5c2bd3543b4ec0049d5,"Can you try with the new version in src : 
https://raw.github.com/tontof/kriss_feed/master/src/index.php

You can now create a plugin file base.php in plugins directory with : 
```php
<?php
$GLOBALS['BASE_URL'] = 'http://yoururl:8080/kriss/feed/path';
```
",True,False
tontof/kriss_feed/241,False,522d0e4fbd3543b4bc00534e,"If it does not work, don't hesitate to reopen the issue",True,False
tontof/kriss_feed/241,False,52324423bd3543f8c400021d,"Doesn't work in default mode : all links now have the port number added as a prefix.
i will try to use the plugin method this later

Beside, i don't know how to reopen an issue with github system ...",True,False
tontof/kriss_feed/241,False,52324423bd3543f8c400021e,"I guess only me is allowed to reopen :-)
",True,False
tontof/kriss_feed/241,False,523358d2bd3543f96a0033fc,"Ok,  It worked with the `plugins/base.php file.

**BUT** that file content was 


     <?php
     $GLOBALS['BASE_URL'] = 'http://yoururl/kriss/feed/path';
     ?>

Do notice I removed the port number (as leaving it would leave me in the exact situation of that bug.",True,False
tontof/kriss_feed/241,False,523358d2bd3543f96a0033fd,Great thanks :-),True,False
TPEisenberg/github-upload/1,False,6019d7aabd354354e4b3951c,"Great! I've opened a [new issue](https://github.com/TPEisenberg/github-upload/issues/2) for you.

<hr>
<h3 align=""center"">Go to the next issue <a href=""https://github.com/TPEisenberg/github-upload/issues/2"">here</a>!</h3>
",True,False
txd-team/monthly/1,False,5baf23fc6480fd7a0e0f4f5c,@申栋栋 已经在邮件中联系和回复，请关注,True,False
ChickenKyiv/recipe-search-react/774,False,6027792cbd3543558170083a,Superseded by #776.,True,False
pipboy96/https-everywhere/23,False,5fe05bbabd35436734e1482a,"Dependabot tried to add `@zoracon` as a reviewer to this PR, but received the following error from GitHub:

```
POST https://api.github.com/repos/pipboy96/https-everywhere/pulls/23/requested_reviewers: 422 - Reviews may only be requested from collaborators. One or more of the users or teams you specified is not a collaborator of the pipboy96/https-everywhere repository. // See: https://docs.github.com/rest/reference/pulls#request-reviewers-for-a-pull-request
```",True,False
pipboy96/https-everywhere/23,False,5fe05bb4bd3543662191ec8d,The following labels could not be found: `dependencies`.,True,False
pipboy96/https-everywhere/23,False,5fe298eebd35433568148ce1,"OK, I won't notify you again about this release, but will get in touch when a new version is available.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",True,False
fedelibre/lilyissues/140,False,55fd2a211b4876664501d0a4,"Reported by `hanwenn` on 2006-11-05 12:45:02
- **Status changed**: `Fixed`
- **Labels added**: fixed_2_9_29
",True,False
fedelibre/lilyissues/140,False,55fd2a211b4876664501d0a5,"Reported by `gpermus` on 2006-11-07 21:21:53
- **Status changed**: `Verified`
",True,False
gadicc/node-yahoo-finance2/52,False,602ce74ebd35434078eeb070,"Hey @PythonCreator27, thanks for this.  I'm going to add some additional notes also in the readme (tracking in #54), as it's not actually so simple to use this in the browser (because of cors).",True,False
gadicc/node-yahoo-finance2/52,False,602bcfb1bd35431ea9fecd59,Of course... Good old CORS.,True,False
gadicc/node-yahoo-finance2/52,False,602df970bd3543268bbc8167,":tada: This PR is included in version 1.7.2 :tada:

The release is available on:
- [npm package (@latest dist-tag)](https://www.npmjs.com/package/yahoo-finance2/v/1.7.2)
- [GitHub release](https://github.com/gadicc/node-yahoo-finance2/releases/tag/v1.7.2)

Your **[semantic-release](https://github.com/semantic-release/semantic-release)** bot :package::rocket:",True,False
gadicc/node-yahoo-finance2/52,False,602dfa58bd354306ac137524,"> Of course... Good old CORS.

:joy: ",True,False
GGrassiant/gg-website/79,False,5f36e038bd35433fd80b2cfb,"@dependabot recreate
",True,False
GGrassiant/gg-website/79,False,5f36e0edbd35435338f56901,"Looks like react-intl is no longer updatable, so this is no longer needed.",True,False
ltropin/lab34/2,False,5edba4d3bd35433c93613ba2,Superseded by #3.,True,False
ltropin/lab34/2,False,5edba4d3bd35433c93613ba3,Superseded by #3.,True,False
SurveyMonkey/pyteamcity/70,False,589b5af06480fd9636fd23f4,"Do you have any estimation when do you plan to do it?
For now, in order to use pyteamcity.future, we need to git clone && add to PYTHONPATH instead of pip install pyteamcity.

I can try to help with the preparations for this task ...",True,False
SurveyMonkey/pyteamcity/70,False,58ac48106480fd66a86c02ed,"@iluxame You can now install using pip:

```
pip install -e git+https://github.com/SurveyMonkey/pyteamcity#egg=pyteamcity
```",True,False
SurveyMonkey/pyteamcity/70,False,58ac572c6480fd5ef7c9ef13,"@baopham 
Thanks a lot!
",True,False
SurveyMonkey/pyteamcity/70,False,5bc850026480fde692417808,"We waited a long time for the development of the new API, but did not wait. Therefore, we implemented TeamCity client , it supports ALL requests that are supported by TeamCity (since it was initially generated from swagger.json). Maybe will be useful for someone :) 

- Docs https://devopshq.github.io/teamcity/
- GITHUB https://github.com/devopshq/teamcity",True,False
ypcs/pwm/645,False,55073f95bd3543e5d40045ea,"```
No problem downloading here. 65.8 MB in 24 seconds

Please make sure your network connection is stable.
```

Original comment by `menno.pi...@gmail.com` on 19 Dec 2014 at 8:33
* Changed state: **WontFix**",True,False
scratchyone/todo/25,False,5e9cd246bd35432b25922258,Superseded by #40.,True,False
harrah/xsbt/304,False,50c75209edecb526fd000c30,"This seems to be the reason behind this too: https://github.com/mpeltonen/sbt-idea/issues/119

i.e. when I add any plugin (snapshot or not) which is not in the default repositories into build, update-sbt-classifiers break because plugin repositories are not included in resolution. ",True,False
harrah/xsbt/304,False,50c75209edecb526fd000c31,Related: https://github.com/harrah/xsbt/issues/138,True,False
collective/collective.contact.core/5,False,532ab632bd35438707010aa2,"Hi,

Thanks for your interest. It's indeed a nasty bug, a recent one I think. I will try to quickly fix it !",True,False
collective/collective.contact.core/5,False,532ab9b3bd35438707010b8a,Fixed by 0b91f1ae1cc5fdf435f3fdc88d25fccb8cbade07 !,True,False
sveltejs/template-webpack/20,False,5cffafa16480fd0d91deacdd,"`Bump`

It seems strange because of the Webpack Module System, which deals with UMD/AMD/CommonJS dependencies by itself.",True,False
nitingupta220/graphql-server/38,False,5f0546cbbd35437697be132f,Superseded by #43.,True,False
Klikini/doorbirdpy/5,False,5aae87ff6480fd11b35d314a,"Sure!

Now in version 0.1.3, you can call `open_door()` or `open_door(1)` for the first relay, `open_door(2)` for the second, or `open_door(""gggaaa@1"")` for a specific door controller.",True,False
Klikini/doorbirdpy/5,False,5aae897f6480fd0c260e7445,"Thank you!

El dom., 18 mar. 2018 16:38, Andy Castille <notifications@github.com>
escribió:

> Sure!
>
> Now in version 0.1.3, you can call open_door() or open_door(1) for the
> first relay, open_door(2) for the second, or open_door(""gggaaa@1"") for a
> specific door controller.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374008939>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABOR0Vdali8sd2okXDivK7j6aYXvYcoFks5tfn97gaJpZM4Su911>
> .
>
",True,False
Klikini/doorbirdpy/5,False,5aae8b806480fd0cc68d1a4b,No problem! And I just uploaded the 0.1.3 to PyPI as well :),True,False
Klikini/doorbirdpy/5,False,5aae8d376480fd0ba1d3049e,"Thank you! Would be great if you could add it too to
https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/switch/doorbird.py
so second lock can get triggered. If not, I can do it for you, and send a
pull request.

El dom., 18 mar. 2018 16:53, Andy Castille <notifications@github.com>
escribió:

> No problem! And I just uploaded the 0.1.3 to PyPI as well :)
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010090>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABOR0bHbDqMqE9njP86B1ErhTCZVewwOks5tfoL8gaJpZM4Su911>
> .
>
",True,False
Klikini/doorbirdpy/5,False,5aae8e1c6480fd14596e54df,"If you wouldn't mind? Otherwise I'll see if I have time later.

On Sun, Mar 18, 2018 at 11:00 AM Sergio Viudes <notifications@github.com>
wrote:

> Thank you! Would be great if you could add it too to
>
> https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/switch/doorbird.py
> so second lock can get triggered. If not, I can do it for you, and send a
> pull request.
>
> El dom., 18 mar. 2018 16:53, Andy Castille <notifications@github.com>
> escribió:
>
> > No problem! And I just uploaded the 0.1.3 to PyPI as well :)
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010090>,
> > or mute the thread
> > <
> https://github.com/notifications/unsubscribe-auth/ABOR0bHbDqMqE9njP86B1ErhTCZVewwOks5tfoL8gaJpZM4Su911
> >
> > .
> >
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010636>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABnZCOsLihSLJurJBaHjCbIdSJ8A0GQFks5tfoSugaJpZM4Su911>
> .
>
-- 
— Andy C.
",True,False
Klikini/doorbirdpy/5,False,5aae90636480fd0c49e906f4,"Now I'm outside, I'll take a look when I arrive home.

El dom., 18 mar. 2018 17:04, Andy Castille <notifications@github.com>
escribió:

> If you wouldn't mind? Otherwise I'll see if I have time later.
>
> On Sun, Mar 18, 2018 at 11:00 AM Sergio Viudes <notifications@github.com>
> wrote:
>
> > Thank you! Would be great if you could add it too to
> >
> >
> https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/switch/doorbird.py
> > so second lock can get triggered. If not, I can do it for you, and send a
> > pull request.
> >
> > El dom., 18 mar. 2018 16:53, Andy Castille <notifications@github.com>
> > escribió:
> >
> > > No problem! And I just uploaded the 0.1.3 to PyPI as well :)
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010090
> >,
> > > or mute the thread
> > > <
> >
> https://github.com/notifications/unsubscribe-auth/ABOR0bHbDqMqE9njP86B1ErhTCZVewwOks5tfoL8gaJpZM4Su911
> > >
> > > .
> > >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010636>,
> > or mute the thread
> > <
> https://github.com/notifications/unsubscribe-auth/ABnZCOsLihSLJurJBaHjCbIdSJ8A0GQFks5tfoSugaJpZM4Su911
> >
> > .
> >
> --
> — Andy C.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010945>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABOR0RZdMMb9vQhVe6cmCs3XDnWI7U9Iks5tfoWXgaJpZM4Su911>
> .
>
",True,False
Klikini/doorbirdpy/5,False,5aaff6876480fd21b23dd97c,"I've just sent a pull request:
https://github.com/home-assistant/home-assistant/pull/13338

:)

2018-03-18 17:04 GMT+01:00 Andy Castille <notifications@github.com>:

> If you wouldn't mind? Otherwise I'll see if I have time later.
>
> On Sun, Mar 18, 2018 at 11:00 AM Sergio Viudes <notifications@github.com>
> wrote:
>
> > Thank you! Would be great if you could add it too to
> >
> > https://github.com/home-assistant/home-assistant/blob/
> dev/homeassistant/components/switch/doorbird.py
> > so second lock can get triggered. If not, I can do it for you, and send a
> > pull request.
> >
> > El dom., 18 mar. 2018 16:53, Andy Castille <notifications@github.com>
> > escribió:
> >
> > > No problem! And I just uploaded the 0.1.3 to PyPI as well :)
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010090
> >,
> > > or mute the thread
> > > <
> > https://github.com/notifications/unsubscribe-auth/
> ABOR0bHbDqMqE9njP86B1ErhTCZVewwOks5tfoL8gaJpZM4Su911
> > >
> > > .
> > >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010636>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ABnZCOsLihSLJurJBaHjCbIdSJ8A0GQFks5tfoSugaJpZM4Su911>
> > .
> >
> --
> — Andy C.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010945>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABOR0RZdMMb9vQhVe6cmCs3XDnWI7U9Iks5tfoWXgaJpZM4Su911>
> .
>
",True,False
Klikini/doorbirdpy/5,False,5ab00bec6480fd1d492f0945,"I accidentally modified file permission in last pull request. I closed and
reopened this one:
https://github.com/home-assistant/home-assistant/pull/13339

2018-03-18 17:04 GMT+01:00 Andy Castille <notifications@github.com>:

> If you wouldn't mind? Otherwise I'll see if I have time later.
>
> On Sun, Mar 18, 2018 at 11:00 AM Sergio Viudes <notifications@github.com>
> wrote:
>
> > Thank you! Would be great if you could add it too to
> >
> > https://github.com/home-assistant/home-assistant/blob/
> dev/homeassistant/components/switch/doorbird.py
> > so second lock can get triggered. If not, I can do it for you, and send a
> > pull request.
> >
> > El dom., 18 mar. 2018 16:53, Andy Castille <notifications@github.com>
> > escribió:
> >
> > > No problem! And I just uploaded the 0.1.3 to PyPI as well :)
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010090
> >,
> > > or mute the thread
> > > <
> > https://github.com/notifications/unsubscribe-auth/
> ABOR0bHbDqMqE9njP86B1ErhTCZVewwOks5tfoL8gaJpZM4Su911
> > >
> > > .
> > >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010636>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ABnZCOsLihSLJurJBaHjCbIdSJ8A0GQFks5tfoSugaJpZM4Su911>
> > .
> >
> --
> — Andy C.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/Klikini/doorbirdpy/issues/5#issuecomment-374010945>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABOR0RZdMMb9vQhVe6cmCs3XDnWI7U9Iks5tfoWXgaJpZM4Su911>
> .
>
",True,False
Klikini/doorbirdpy/5,False,5ab0147f6480fd2221034b9f,😄 👍 ,True,False
spacetelescope/jwst/2340,False,5b71a5a46480fdc16c84ccd9,"Run `flake8 --count --select=F, E101, E111, E112, E113, E401, E402, E711, E722 --max-line-length=110 [file]` and check to see if it passes your files.   

Will need to install `conda install flake8` with the `jwst_devel` environment.  ",True,False
spacetelescope/jwst/2340,False,5b97a3676480fd2a74344892,Rebased to pick up the latest changes and look at status.,True,False
spacetelescope/jwst/2340,False,5babb4c46480fd2a149290cb,This change was added to #2542 so this can be closed. Issue #2552 was opened for the remaining steps.,True,False
NuGet/NuGetGallery/2392,False,551e3a83bd3543620f00ca5d,"Updated it to replace this when building from GitHub.com. Keeping the `git://` if you have a private fork on other source repos.

Will be live with our next deployment. Thanks for the suggestion, @akoeplinger!",True,False
NuGet/NuGetGallery/2392,False,551e3a83bd3543627000b771,"Updated it to replace this when building from GitHub.com. Keeping the `git://` if you have a private fork on other source repos.

Will be live with our next deployment. Thanks for the suggestion, @akoeplinger!",True,False
Homebrew/homebrew-science/4437,False,57ffbf986480fd1d5885f350,"`pcl` is built as an app by default. If you want to use it from the command line, try `brew install pcl --without-apps`.",True,False
Homebrew/homebrew-science/4437,False,581869626480fd233d8b1fd7,"I uninstall pcl using ""brew uninstall pcl"", and then install pcl with command ""brew install pcl --without-apps""
But the error still exists",True,False
Homebrew/homebrew-science/4437,False,5885f1486480fdc5ffd01020,"Tried as well, not working.",True,False
Homebrew/homebrew-science/4437,False,58c1fbb56480fd6175f39be7,Issue exists for me also. Is there a fix yet to get pcl_viewer on macos sierra?,True,False
Homebrew/homebrew-science/4437,False,599725296480fde9b8e8e7ec,pcl has been migrated to homebrew-core (#6153). Please open a new issue there if you still encounter problems.,True,False
strongloop/loopback/423,False,53dfa951bd35432eb2040144,@ritch Any comments?,True,False
strongloop/loopback/423,False,53dfaa25bd35432e8c03e896,LGTM,True,False
Battlefy/Viceroy/17,False,525edd51bd35436ebb000165,r+,True,False
teamlaravel/LeLabo/192,False,5bb4cf6d6480fd7665fc07da,完了,True,False
bioconda/bioconda-recipes/23068,False,5f05f9cfbd35436581ee0bbf,@bioconda-bot please merge,True,False
bioconda/bioconda-recipes/23068,False,5f05f9cfbd35436581ee0bc0,"I will attempt to upload artifacts and merge this PR. This may take some time, please have patience.",True,False
coelckers/gzdoom/250,False,58a3b6f96480fd96fee7005a,"Use case: I want the puffs to shoot out smoke and debris in the exact angle of the wall, instead of them always shooting towards the player.",True,False
coelckers/gzdoom/250,False,58a3b9eb6480fda0186a47d1,"Additionally, I need some feedback:

Currently for floors and ceilings, the behavior is left unchanged. But I was thinking of making it so that when the puff hits the floor or ceiling with this flag set, the puff's angle, pitch and roll will be calculated off the normal of the plane it hit; in this case, the flag name needs to be changed.

Does anyone think this is a good idea? If it is, I will have to at least change the name of the flag to prevent future clashes, even if I don't actually code the floor/ceiling plane functionality yet.",True,False
coelckers/gzdoom/250,False,58a4248c6480fd9542da539f,"The idea is ok, but the implementation is not. This should be part of P_SpawnPuff, not the calling functions. There's 10 places where P_SpawnPuff gets called from C++ code and several more from script code, not counting any mods that may use the function.
",True,False
coelckers/gzdoom/250,False,58a431fa6480fd9b894dab65,"Oh okay, sorry about that. Will clean it up ASAP.",True,False
racket/xrepl/10,False,5c45c3e36480fdadf55a2e0f,"Mon Jan 21 12:59:44 GMT 2019

This may be the problem:

`show-cmd` - defined:
https://github.com/racket/xrepl/blob/f1aad9349eb0ecd30d8309b4de2522c7f9270685/xrepl-lib/xrepl/xrepl.rkt#L381

called:
https://github.com/racket/xrepl/blob/f1aad9349eb0ecd30d8309b4de2522c7f9270685/xrepl-lib/xrepl/xrepl.rkt#L396",True,False
racket/xrepl/10,False,5ff7ff51bd3543784045aa94,"Thu Jan  7 07:38:32 GMT 2021

Closing:  This was fixed in: https://github.com/racket/xrepl/commit/a5208baaac48e3864577b1ef87ea25c8d8bf72ab",True,False
WebBluetoothCG/web-bluetooth/46,False,5464a2d2bd3543169400ccbf,"Keyboards/mice implemented as the standard HOGP, and they are almost filtered out from the list of discovered services by OS (such iOS, Android). Can UA application actually handle it?",True,False
WebBluetoothCG/web-bluetooth/46,False,56d02b316480fdb1a9005af0,"@jyasskin
When you paired with device in Linux, that device will not mark as ""Trusted"" by default, right? In that way, we can control it per service.",True,False
swagger-api/swagger-codegen/3243,False,577682fa6480fd1e346b318e,@rejithkumarb May I know if you've cycle to contribute the enhancement?,True,False
swagger-api/swagger-codegen/3243,False,57aa8c2b6480fdd6b8e0584c,"@rejithkumarb a new documentation generator has been released: `html2`.

Please pull the latest master to give it a try.",True,False
fex-team/fis/795,False,58d528826480fd734a95f1fc,已解决,True,False
dahlbyk/up-for-grabs.net/119,False,542142bfbd3543685000a8a6,Welcome aboard!,True,False
pnkfelix/larceny-test/633,False,51d8800b468124665b00029c,"**Author: will**
Fixed for R6RS ```define-record-type``` by changeset:6386.

Will suspects there may be a similar problem for ERR5RS records, so he is leaving the ticket open for now.
",True,False
SpongePowered/SpongeAuth/199,False,5b5111b26480fd1b86620ad4,"
[![Coverage Status](https://coveralls.io/builds/18074968/badge)](https://coveralls.io/builds/18074968)

Coverage remained the same at 96.395% when pulling **5bd31bf5237987a9a87c11d5b80e6c737109b562 on pyup-update-pylint-1.8.4-to-2.0.0** into **fcc2caf29ff6e36c5cd96aa2fe673c07e19baf67 on master**.
",True,False
SpongePowered/SpongeAuth/199,False,5b55acb76480fd17296c3da8,Closing this in favor of #202,True,False
dask/dask-ml/123,False,5a69d30f6480fd06c83d298e,"Long term it would be nice to see a scipy.sparse csr class that satisfied the np.ndarray rather than np.matrix interface.  Then it could operate nicely with dask array while still having the CSR layout.  This is discussed in more depth in https://github.com/scipy/scipy/issues/8162 

To be clear, I'm not saying a fully ndarray implementation, just the current implementation where `n <= 2` that satisfies ndarray conventions.  This is a broader issue for the rest of the community.  My understanding is that sklearn devs would also appreciate a `scipy.sparse.csr_array` class.",True,False
dask/dask-ml/123,False,5a69d6526480fd08656cf352,"+1 for scipy/scipy#8162 as the only true long term solution.

On the shorter term it should be possible to fix the most current discrepancies directly in dask directly. I found one in https://github.com/dask/dask/pull/2842 but I did not find (take) the time to finish investigating the cause of the test failures.",True,False
dask/dask-ml/123,False,5a69d6d06480fd077c722f08,"For sklearn, both CSR and CSC are useful. CSR is typically optimal for incremental learning algorithm (those with a `partial_fit`) while CSC is optimal for column wise algorithms such as decision trees and linear models fitted with a coordinate descent optimizer (`Lasso`, `ElasticNet`...).",True,False
dask/dask-ml/123,False,5a69d77f6480fd04f5bee73d,For storage you could write a custom dask function that relies on `joblib.dump` to efficiently serialize `scipy.sparse.csr_matrix` blocks in a filesystem folder.,True,False
dask/dask-ml/123,False,5a69d7dd6480fd06c83d2bed,"or write your own by using numpy.save / numpy.load on the 3 underlying numpy arrays `sparse_data_block.indices`,  `sparse_data_block.data` and `sparse_data_block.indptr`.",True,False
dask/dask-ml/123,False,5a69da356480fd03c6d09273,"cc @hameerabbasi , dev on the mrocklin/sparse library ",True,False
dask/dask-ml/123,False,5a69de9d6480fd0b8b1c9083,"Thanks for the response. The discussion about sparse ndarray in scipy looks quite promising indeed!
> For storage you could write a custom dask function that relies on joblib.dump [..] or write your own by using numpy.save

yes, I imagine that wouldn't be too difficult to do.

> On the shorter term it should be possible to fix the most current discrepancies directly in dask directly. I found one in dask/dask#2842 ...

Good to know, thanks.",True,False
dask/dask-ml/123,False,5a69e0f76480fd0aa177a4f0,"I'm a bit hesitant to add CSR/CSC in mrocklin/sparse, simply because they limit us to 2-D (N-D CSR/CSC is... murky to say the least), and I'm worried about growing complexity. However, we can achieve near-CSR level performance if mrocklin/sparse#60 is fixed (`O(log n)` vs `O(1)`).

Currently, we are working with C-style ordering of indices. If we, instead, added a Fortran-style mode for ordering indices, and modified indexing to fit, then we could achieve near-CSC level performance as well.

If you could reduce the bug in dask/dask#2842 to an underlying bug or missing feature in mrocklin/sparse, I'd be happy to look into it. If it's a bug in dask itself, I'm less willing to dive into it at this point, but I will soon, to help get it integrated.",True,False
dask/dask-ml/123,False,5a69e3206480fd0493b5b731,"In regards to performance I think that the main operation where you really need CSR/CSC is tensordot, which is pretty critical in many numeric algorithms.  For this CSC/CSR is probably essential.

If we don't want to host these in `mrocklin/sparse` then csr_array and csc_array could also exist in `scipy.sparse`.  This would probably be good to get more eyes on it and ensure maintenance, but presents a challenge due to the slow release and development cycle.  Alternatively someone could make a separate standalone package.  

At this point I think that downstream library maintainers, like the scikit-learn community, should probably decide what they would prefer to depend upon.",True,False
dask/dask-ml/123,False,5a69e9246480fd0a0d379174,"CSR and CSC support would be useful to allow for no-copy behavior when calling Cython code from scikit-learn on sparse data blocks.

There are several algorithms in scikit-learn that do very efficient, cache aligned data access when fed with CSR or CSC datastructures.",True,False
dask/dask-ml/123,False,5a69eab86480fd0aa177aa96,"Interesting... It seems a lot of algorithms have been optimized for CSR/CSC already. I'll see how hard it is to implement CSR/CSC (limited to 2-D) with array semantics. Mostly it's just a matter of studying and re-implementing scipy.sparse code (or maybe just even wrapping may be good enough).

However, indexing would again be COO... Since CSR/CSC isn't defined for 1-D.",True,False
dask/dask-ml/123,False,5a69eb536480fd0b19c30443,Note that the scope of CSR/CSC is non-trivial.  You might want to look at algorithms in scipy/sparse/linalg/.  This would almost certainly require writing low-level code in Cython/Numba/C/C++.,True,False
dask/dask-ml/123,False,5a69ebb06480fd069adb6b6b,"If I were doing this under time constraints I would probably try to find a way to modify the existing solution to support the ndarray interface.  

However if I were doing this without serious time constraints then yes, rebuilding that code from scratch might result in significant improvements (and would also be pretty educational I think).",True,False
dask/dask-ml/123,False,5a69ecf16480fd0c64aca7a1,"I plan to keep mrocklin/sparse a mostly data structure related thing as discussed in scipy/scipy#8162. Maybe implement operators, etc, but that's about it. I want to go down to Cython at some point... Might as well be soon.

`dot`/`tensordot`/`linalg.solve` etc., would either be in Scipy or a separate package.",True,False
dask/dask-ml/123,False,5a69ee726480fd0b19c305ea,"To be clear, I'd love to see mrocklin/sparse expand, or be merged into Scipy when stable. I just don't think I can do it alone. :)",True,False
dask/dask-ml/123,False,5a69ef536480fd099ab4470d,"Yeah, you're not alone here.  I think that many people on this issue have demonstrated that they're happy to pitch in when relevant.  I also suspect that sparse ndarrays will be of relevance to @jcrist in a couple months. 

> I plan to keep mrocklin/sparse a mostly data structure related thing as discussed in scipy/scipy#8162. Maybe implement operators, etc, but that's about it. I want to go down to Cython at some point... Might as well be soon.

FWIW I'd rather see a single csr ndarray class somewhere that has all relevant computational operations.  Splitting this up between repositories seems painful to me.  I'd rather wait until a clear solution is agreed upon instead of launching into this short term.

",True,False
dask/dask-ml/123,False,5a69f5706480fd0438bb569a,"I wonder if it would be possible to extend CSR/CSC to N-D. It seems that all it should be is an ordering of which axes are prioritized in the sparse representation. Does that seem correct? If so, it seems like it should be possible to implement this in `sparse` in a way where it remains general purpose. With CSR/CSC, this amount to one of two orderings involving axes 0 and 1.",True,False
dask/dask-ml/123,False,5a69f6646480fd03723c4e9f,"Yes, this is possible.  There are a combinatorial number of such layouts, but presumably we would store some hierarchy of axes that we cared about.  I wouldn't make this choice until some important workloads demonstrated its value (like large sparse iterative factorization algorithms).  I also wouldn't want to think about how operations like `solve` generalized under these conditions.

Short-to-medium term I think that 2d CSR/CSC with the np.ndarray interface is a very valuable and feasible objective.  My hope is that going into the scipy.sparse code and making a few modifications is all that's necessary to achieve this; this could be naive though.",True,False
dask/dask-ml/123,False,5a69f6b86480fd0ce6f29aa1,"I would also be interested to help a bit, once it is decided where and in what way this should be implemented. (Though my bandwidth before summer won't be great). 

> At this point I think that downstream library maintainers, like the scikit-learn community, should probably decide what they would prefer to depend upon.

I would think it's more a question for dask-ml. scikit-learn itself currently has a minimal dependency of scipy 0.13.3 and works reasonably well around the limitations of the matrix interface. Which means that this development won't impact it in the near future either way. 

>> dot/tensordot/linalg.solve etc., would either be in Scipy or a separate package... 
>
>However if I were doing this without serious time constraints then yes, rebuilding that code from scratch might result in significant improvements (and would also be pretty educational I think).
> I'd rather wait until a clear solution is agreed upon instead of launching into this short term.

At the same time in the context of dask-ml, even an implementation that supports basic operations and is able to covert without much cost to/from scipy's csr/csc_matrix might help solve some of the issues? 

>  Short-to-medium term I think that 2d CSR/CSC with the np.ndarray interface is a very valuable and feasible objective. My hope is that going into the scipy.sparse code and making a few modifications is all that's necessary to achieve this; 

+1",True,False
dask/dask-ml/123,False,5a69f7c66480fd08c58b5dd4,"> At the same time in the context of dask-ml, even an implementation that supports basic operations and is able to covert without much cost to/from scipy's csr/csc_matrix might help solve some of the issues?

Yes, that's true.  Short term we've been using the COO implementation in `mrocklin/sparse` for this.  The conversion isn't free, but it's also not that expensive.  We could also make a thin wrapper around scipy.sparse that just converted every operation back and forth, but this would probably be a wasted project long-term.  There are some short-term-needs vs long-term-goals tradeoffs to make here.  I'm not sure what the best path is.",True,False
dask/dask-ml/123,False,5a69f7d96480fd0a75f15323,"> It seems that all it should be is an ordering of which axes are prioritized in the sparse representation.

Yes, that is the most general way to put it. Would CSD (compressed sparse dimensions) make sense, for both CSR/CSC? For CSR, the compressed dimension would be `0` and for `CSC` it would be `1`. We could keep an tuple of `compressed_axes` pairs.

Then, CSR/CSC would just inherit from this or be special cases. We would implement all operations exactly as in 2-D CSR without any broadcasting. Tensordot would reduce to dot.",True,False
dask/dask-ml/123,False,5a69f9486480fd0387ae6122,"> We could also make a thin wrapper around scipy.sparse that just converted every operation back and forth, but this would probably be a wasted project long-term.

Well we would still need to be able to do the conversion in any case (e.g. to communicate with scikit-learn that would expect `csr_matrix`). Can't we start with this and progressively re-implement operations to finally reach the final implementation that wouldn't eventually use `scipy.sparse` ?",True,False
dask/dask-ml/123,False,5a69fa006480fd0c64acaf7b,"> Well we would still need to be able to do the conversion in any case (e.g. to communicate with scikit-learn that would expect csr_matrix). Can't we start with this and progressively re-implement operations to finally reach the final implementation that wouldn't eventually use scipy.sparse ?

This is feasible.  The only concern would be that we do a lot of work and never reach the functionality of scipy.sparse.  It may be that copying the entire implementation over and then tweaking a couple of things to stop using the np.matrix interface is significantly easier to do.

To be clear, people can do whatever they want to do.  I have thoughts on how I would or would not spend my time here, but that doesn't stop others from exploring this topic.  I doubt that my thoughts on this topic are entirely correct.",True,False
dask/dask-ml/123,False,5a69fa486480fd03f44c33e2,@hameerabbasi and @jakirkham 's thoughts on CSD might be a decent start.  This code seems orthogonal to the logic in scipy.sparse (and so would presumably not be thrown away in the future) and might resolve the short-term need.,True,False
benjamin-mlr/camembert_finetune/10,False,5ebfd4c5bd35430616938de5,"Looks like nltk is no longer a dependency, so this is no longer needed.",True,False
streltsov/washoe/2,False,6035d64fbd354335734f5746,"Looks like socket.io is no longer a dependency, so this is no longer needed.",True,False
satoshun/truth-android/40,False,5f8bacf1bd35434844de969b,"# [Codecov](https://codecov.io/gh/satoshun/truth-android/pull/40?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@ca8c653`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.


```diff
@@           Coverage Diff            @@
##             master     #40   +/-   ##
========================================
  Coverage          ?   1.40%           
  Complexity        ?      27           
========================================
  Files             ?     151           
  Lines             ?    6568           
  Branches          ?       1           
========================================
  Hits              ?      92           
  Misses            ?    6476           
  Partials          ?       0           
```
",True,False
satoshun/truth-android/40,False,602b8900bd3543502f3e61b4,Superseded by #44.,True,False
gitpod-io/gitpod/1067,True,548501722.0,"**Describe the bug**
<!-- A clear and concise description of what the bug is. -->

**To Reproduce**
<!-- Steps to reproduce the behavior. -->

**Expected behavior**
<!-- A clear and concise description of what you expected to happen. -->

**Additional Information**
<!-- For instance, relevant logs from terminals or the browser's devtool console. -->
",True,True
gobytecoin/gobyte/31,True,548485770.0,"Is the network is dead ??

No peers and network confirmation down.. But token pump on exchange, WTF ?!

V",True,True
spyder-ide/spyder/12292,True,598503107.0,"## Description

### What steps will reproduce the problem?

<!--- You can use Markdown here --->

I don't know what will reproduce the problem because I don't know what the problem is.  I just tried reinstalling you buggy, shitty software for the third time.

Maybe you guys can get one that works right and stick to it without changing it all the time.

### Traceback
```python-traceback
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 154, in perform_request
    response = handler(params)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\decorators.py"", line 20, in wrapper
    params = req(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\providers\document.py"", line 83, in document_did_open
    self.get_status(params['file'])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 111, in get_status
    kite_status = status()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 93, in status
    elif check_if_kite_running():
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 42, in check_if_kite_running
    'status']):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1457, in process_iter
    yield add(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1432, in add
    proc = Process(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 346, in __init__
    self._init(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 373, in _init
    self.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 723, in create_time
    self._create_time = self._proc.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 671, in convert_oserror
    raise exc
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
OSError: [WinError 0] The operation completed successfully: '(originated from OpenProcess)'
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 154, in perform_request
    response = handler(params)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\decorators.py"", line 20, in wrapper
    params = req(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\providers\document.py"", line 83, in document_did_open
    self.get_status(params['file'])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 111, in get_status
    kite_status = status()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 93, in status
    elif check_if_kite_running():
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 42, in check_if_kite_running
    'status']):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1457, in process_iter
    yield add(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1432, in add
    proc = Process(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 346, in __init__
    self._init(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 373, in _init
    self.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 723, in create_time
    self._create_time = self._proc.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 671, in convert_oserror
    raise exc
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
OSError: [WinError 0] The operation completed successfully: '(originated from OpenProcess)'
```

## Versions

* Spyder version: 4.1.2 
* Python version: 3.7.6
* Qt version: 5.12.5
* PyQt5 version: 5.12.3
* Operating System: Windows 10

### Dependencies

```

# Mandatory:
atomicwrites >=1.2.0           :  1.3.0 (OK)
chardet >=2.0.0                :  3.0.4 (OK)
cloudpickle >=0.5.0            :  1.3.0 (OK)
diff_match_patch >=20181111    :  20181111 (OK)
intervaltree                   :  None (OK)
IPython >=4.0                  :  7.13.0 (OK)
jedi =0.15.2                   :  0.15.2 (OK)
nbconvert >=4.0                :  5.6.1 (OK)
numpydoc >=0.6.0               :  0.9.2 (OK)
paramiko >=2.4.0               :  2.7.1 (OK)
parso =0.5.2                   :  0.5.2 (OK)
pexpect >=4.4.0                :  4.8.0 (OK)
pickleshare >=0.4              :  0.7.5 (OK)
psutil >=5.3                   :  5.7.0 (OK)
pygments >=2.0                 :  2.6.1 (OK)
pylint >=0.25                  :  2.4.4 (OK)
pyls >=0.31.9;<0.32.0          :  0.31.9 (OK)
qdarkstyle >=2.8               :  2.8.1 (OK)
qtawesome >=0.5.7              :  0.7.0 (OK)
qtconsole >=4.6.0              :  4.7.2 (OK)
qtpy >=1.5.0                   :  1.9.0 (OK)
rtree >=0.8.3                  :  0.9.4 (OK)
sphinx >=0.6.6                 :  3.0.1 (OK)
spyder_kernels >=1.9.0;<1.10.0 :  1.9.0 (OK)
watchdog                       :  None (OK)
zmq >=17                       :  19.0.0 (OK)

# Optional:
cython >=0.21                  :  0.29.16 (OK)
matplotlib >=2.0.0             :  3.2.1 (OK)
numpy >=1.7                    :  1.18.1 (OK)
pandas >=0.13.1                :  1.0.3 (OK)
scipy >=0.17.0                 :  1.4.1 (OK)
sympy >=0.7.3                  :  1.5.1 (OK)
```
",True,True
pashayogi/SETAN-GOLD/1,True,606630998.0,"my account has booked cuz i just sign up with your fuking tool 
 ",True,True
JohnPicchi/Profile/1,True,606614179.0,Worst. App. Ever. Please make it not the worst app ever. Thanks.,True,True
TastiestSandwich/consensus-frontend/2,True,606609264.0,Fuck this,True,True
esx-framework/es_extended/713,True,606312933.0,"2020-04-22 we recieved an email from GitHub stating that kanersps had started a DMCA takedown notice against es_extended. https://pastebin.com/kKxwH7MS

In his initial notice he is saying that multiple files in ESX belong to him and he would like to be credited for everything he has done. He doesn't link the exact files that he claim he owns, just a link to our repo. This means that he wants the entire repo removed if we don't credit him for his code.

He is butthurt over how when we ditched essentialmode we created functions and other things that did what essentialmode did... But how do you expect us to ditch essentialmode if we cannot create our own command handling code? We can't. He claims in his second DMCA takedown notice https://pastebin.com/2q5cVHYS that our code is ""stolen"" from his project.
As I just said it's impossible to go standalone if we don't create the features essentialmode had to offer, command handling is a perfect example, and as you can imaine the code differences aren't huge.

He also mentions how his code is licensed under AGPLv3, and that ESX must also be licensed under the same. But this is false, ESX was developed around 2017 initially, (old time when it used essentialmode). What license was essentialmode on at that time you wonder? Good question, web archive has archived his old website, where it's clearly a nolicense license. http://web.archive.org/web/20180516175223/https://docs.essentialmode.com/#license

Gizz told me not to make an announcement, sorry mate. He has also said that we are in a modding community where the fivem devs are REVERSING a whole copyrighted game for us, meanwhile kanersps is spending time on a DMCA takedown to ruin the community.
‏‏‎ ‎
Kanersps obviously have a weird intention we can't identify. Is it to destabilise ESX to tell everyone to move to extendedmode? And if so does the contributors of that project have anything to do with this? Is it to revenge on his shitty framework being ditched? Is it just to be a asshole? Maybe even the fivem developers are a part of it?

We don't know, and don't really know how GitHub are handling this DMCA takedown notice. I mean how can they take a takedown notice that don't even specify what files are infringing seriously? Some files in the ESX project, such as the server sided player class file might need a rewrite, in the meantime if required then we will remove that file and create our own from scratch.",True,True
google/shaka-player/2529,True,606817816.0,"<!-- NOTE: If you ignore this template, we will send it again and ask you to fill it out anyway. -->

**Have you read the [FAQ](https://bit.ly/ShakaFAQ) and checked for duplicate open issues?**
yes

**What version of Shaka Player are you using?**
3.0

**Can you reproduce the issue with our latest release version?**
yes

**Can you reproduce the issue with the latest code from `master`?**
yes

**Are you using the demo app or your own custom app?**
demo app

**If custom app, can you reproduce the issue using our demo app?**


**What browser and OS are you using?**
chrome, nexus 6, android

**For embedded devices (smart TVs, etc.), what model and firmware version are you using?**


**What are the manifest and license server URIs?**
<!-- NOTE:
  You can send the URIs to <shaka-player-issues@google.com> instead,
  but please use GitHub and the template for the rest.
  A copy of the manifest text or an attached manifest will **not** be
  enough to reproduce your issue, and we **will** ask you to send a
  URI instead.  You can copy the URI of the demo app to send us the
  exact asset, licence server, and settings you have selected there.
-->
https://bitmovin-a.akamaihd.net/content/art-of-motion_drm/mpds/11331.mpd

**What did you do?**
<!-- Steps to reproduce the bug -->
why u revoke nexus 6 ?? give keybox to me now .  nvidia shield . 
i am from india my name is ramjeet widevin is shit .!!

**What did you expect to happen?**
get amazon prime sunnxt key

**What actually happened?**
<!-- A clear and concise description of what the bug is -->
<!-- If applicable, you may add screenshots to help explain your problem. -->
nexus revoked :(.",True,True
Kyrobi/Cynagen/165,True,609531343.0,"Please title this post ""Ban Appeal:"" followed by a name
Fuck Colt Crohnie 
**Minecraft username**:
Fuck Colt Crohnie 

**I was banned on**: (Format: Dec 23, 2012)
Fuck Colt Crohnie 

**I was banned by**: (Leave blank if unknown)
Fuck Colt Crohnie 

**I was banned for**:
Fuck Colt Crohnie 

**A brief summary of what happened before the ban was**:
Fuck Colt Crohnie 

**I like to be unbanned because**:
Fuck Colt Crohnie 

**Explain why is cereal is/isn't considered a soup**:
Fuck Colt Crohnie 

**Additional information**: (Optional)
Colt Crohnie is a Faggot",True,True
MiKTeX/miktex/530,True,611528813.0,"- [x] I have read the [MiKTeX Contributing Guidelines](https://github.com/MiKTeX/miktex/blob/master/CONTRIBUTING.md)

(Windows 10, for reference, if it matters.)

I have a paper due tomorrow. 

I thought ""hey, let's use the *American Physical Society* LaTeX Class!"". I haven't used it before, but it's just a LaTeX class, what could possibly go wrong? So I loaded up MiKTeX and went to ""Packages"", searched for ReVTeX and installed it.

Oh, by the way, you have updates available, says the console. So I click on the ""Updates"" tab and try to install the updates. Some text appears in the pop-up window. After a while the window stops responding. Won't listen to clicks or the keyboard. Eventually I gave up and closed it.

Now the trouble begins. I go into TeXStudio and try to compile the template. Whoops, you're missing `textcase`. Odd. Installation failed.

I tried to compile a document I had compiled yesterday. It won't compile either.

I opened the MiKTeX console. ""Check for updates"" doesn't work: HTTP 401. No packages can be installed: HTTP 401. The error message isn't very helpful, aside from saying ""HTTP 401 (Unauthorized)"".

I have now spent *three hours* trying desperately to compile *anything*. Did I mention I have a paper due tomorrow?

So I gave up, uninstalled MiKTeX, and am now in the process of reinstalling it and -- *hopefully* -- actually being able to use LaTeX for this paper.

The purpose of this bug report is the following: **Please warn your users before you suggest they take actions that may break their system.** 

If I had known that running ""Update All"" might fail and *break absolutely everything*, I would never have tried to do it in the middle of writing a term paper. Obviously.

Which, as I mentioned, is due *tomorrow*.",True,True
ResistancePlatform/resistance-platform-release/13,True,613458469.0,"the download of the installation software  contains malware: win32:MinerD-A

Not very nice of you a..holes to infect other computers with malware. Your project looks good on paper but trying to clandestinely installing malware  on people's computers is mean. What were you thinking? That everybody is stupid enough to not realize it?",True,True
Adamantcheese/Kuroba/874,True,612566065.0,"[Continuation of 862 because Adamantcheese keeps locking for no reason](https://github.com/Adamantcheese/Kuroba/issues/862)

> Removing a post removes it from display.

No shit. You still haven't explained why there's Hide AND Remove. They are both the exact same thing, the only difference is that two extra clicks are required to ""unremove"" a post. 

> Filter image hash isn't an option on posts without images. You must be on an older version.

I'm on the latest release build (v4.12.0). It is an option on posts without images on the latest version.

> Share is as @clawyf explained.

You still haven't explained why we can copy the image's link and not the post's link. If you want to play this game and persist, it's either both ways, or none. 

> Info provides additional info that isn't presented in the post cell. 

The only thing Info provides is the resolution of the picture inside a post and nothing else. The filename, size and time of date can already be seen from the post itself, which makes Info completely useless.

Just accept the truth, you have so much garbage in the context menu and it needs to get cleaned up. If you got rid of Remove and Info, nobody would bat an eye.",True,True
google/google-authenticator/698,True,613463737.0,Dont work with fb abd google 👎👎👎,True,True
citra-emu/citra/5346,True,616016198.0,"<!---

Please read the FAQ:
https://citra-emu.org/wiki/faq/

THIS IS NOT A SUPPORT FORUM, FOR SUPPORT GO TO:
https://community.citra-emu.org/

If the FAQ does not answer your question, please go to:
https://community.citra-emu.org/

====================================================

When submitting an issue, please check the following:

- You have read the above.
- You have provided the version (commit hash) of Citra you are using.
- You have provided sufficient detail for the issue to be reproduced.
- You have provided system specs (if relevant).
- Please also provide:
  - For any issues, a log file
  - For crashes, a backtrace.
  - For graphical issues, comparison screenshots with real hardware.
  - For emulation inaccuracies, a test-case (if able).

--->like seriously, not everyone has a huge ass C drive. Most users secondary drive are bigger than their primary drive. And with Citra being the same GUI and shit as yuzu, it should take two seconds to add a file system tab inside Citra like you did with yuzu. 

And then a user in your Discord says it's currently in development? Citra's been out a lot longer than yuzu, even though they're made in the same language. 

I want my shit installed on my secondary drive. 
",True,True
jupyterhub/zero-to-jupyterhub-k8s/1672,True,619201078.0,"I'm going to call this out since many want to keep closing issues such as this. The work around is to rebuild a docker container to account for this ever changing requirement of installing packages. As you are aware that even ""pip install <some package> might lead to a gcc rebuild being required. You have not accounted for such by locking down the container used omitting sudo capability. In essence the the rush to containerize and move to Kubernetes did not take in to consideration this standard use case. As such you are requiring a rebuild to include the packages in the base container. However, this is not an acceptable workaround. This precludes providing a level of flexibility which containers are to afford and deployment to Kubernetes. For each point that was mentioned I can easily address why the point is mute.

Simon Li you rushed to close the issue and divert me to https://discourse.jupyter.org/
This is not an end user issue so do not assume my level of experience or skills. As a seasoned developer and architect I am calling out the lack of consideration for an obvious use case for moving this to Kubernetes.

The base architecture is flawed but could easily allow the injection of packages without having to rebuild the container. 

I suppose I'll have to fork this and build out the solution since I suspect this will be swiftly closed

DB",True,True
nextcloud/jsxc.nextcloud/149,True,619823768.0,-,True,True
Mantaro/MantaroBot/320,True,622732698.0,"Regarding my background (It's aplpicable to understand my viewpoint) I've been in the BDSM world as a dominant for the better part of the last twenty years. Something we're big on? Consent.
And lo and behold - you're silly little waifu system doesn't care about consent.
And yes, I saw the warning on your help page that says it should not be taken as reality!
A) People don't read it.
B) You think that matters when an abusive asshole is messing with someone's head?
terms like 'gaslighting' are popular, but the correct one is psychological manipulation. 

Might I suggest, as a simple little fix - You either a) Make the supposed 'claim key' work (We tested: It doesn't) as a start: and as a fdinally, either an opt-out (That both blocks and removes all claims) or a simple way for the claimed to say 'no'. 
I've alreay decided that those 'silly little 'commands based dom/sub games that don't bother with consent make me never want to visit your server. 
But perhaps for everyone else, given it's freely available, and you don't know who else is using it?
Or under what circumstances?
I mean, Hyptohyetically, we're talking the grooming of underage girls here, if we want some hyperbole. 
Which might not be.
FIX IT.",True,True
facebookresearch/hydra/597,True,621584901.0,"# 🐛 Bug

can't run office example correctly.
https://hydra.cc/docs/configure_hydra/logging
## To reproduce

** Minimal Code/Config snippet to reproduce **
config.yaml
defaults:
  - hydra/job_logging: custom
files
![image](https://user-images.githubusercontent.com/24520617/82426441-707c2480-9aba-11ea-9aa5-05555116f0b7.png)

 File ""my_app.py"", line 11, in <module>
    my_app()
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/main.py"", line 24, in decorated_main
    strict=strict,
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/_internal/utils.py"", line 174, in run_hydra
    overrides=args.overrides,
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/_internal/hydra.py"", line 86, in run
    job_subdir_key=None,
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/plugins/common/utils.py"", line 101, in run_job
    configure_log(config.hydra.job_logging, config.hydra.verbose)
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/plugins/common/utils.py"", line 24, in configure_log
    logging.config.dictConfig(conf)
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/logging/config.py"", line 800, in dictConfig
    dictConfigClass(config).configure()
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/logging/config.py"", line 496, in configure
    raise ValueError(""dictionary doesn't specify a version"")
ValueError: dictionary doesn't specify a version



** Stack trace/error message **
```

```

## Expected Behavior
<!-- A clear and concise description of what you expected to happen. -->

## System information
- **Hydra Version** :  
- **Python version** : 
- **Virtual environment type and version** : 
- **Operating system** : 

## Additional context
I think your tutorials are dogshit!
https://hydra.cc/docs/configure_hydra/logging
",True,True
jy1263/impatient-eta/1,True,623945891.0,Amy I need an explanation. Wtf is this lol,True,True
immuni-app/immuni-app-android/9,True,624136789.0,"https://github.com/immuni-app/immuni-app-android/blob/8c4739b471754977ea42b5cc2090cd28804a141f/app/src/main/AndroidManifest.xml#L34

It is really ugly to see app locked in portrait in 2020... with livedata, viewmodels and SavedStateViewModel!
",True,True
tgstation/tgstation/51298,True,624641343.0,"<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may not be viewable -->
## Round ID: #138035
<!--- **INCLUDE THE ROUND ID**
If you discovered this issue from playing tgstation hosted servers:
[Round ID]: #138035 (It can be found in the Status panel or retrieved from https://atlantaned.space/statbus/round.php ! The round id let's us look up valuable information and logs for the round the bug happened.)-->

## Reproduction:
1) Find or make a bunch of bodies
2) Either place them on a space tile or soak them in CLF3 and ignite them
3) Place surgery drapes on all of them
4) Begin tends wounds surgery
5) Revel at your ability to farm XP for no downside

It also spams the EVERLOVING FUCK out of chat. This was all within about a second of each other.

![image](https://user-images.githubusercontent.com/7019927/82869014-33b59080-9ef3-11ea-95f7-19b4c0847e1e.png)

<!-- Explain your issue in detail, including the steps to reproduce it. Issues without proper reproduction steps or explanation are open to being ignored/closed by maintainers.-->

<!-- **For Admins:** Oddities induced by var-edits and other admin tools are not necessarily bugs. Verify that your issues occur under regular circumstances before reporting them. -->

Yeah, this is a minor one, but if we're rewarding people for this sort of thing we should probably start fixing the bugs/exploits.",True,True
clayrisser/react-gtk/21,True,625435290.0,The worst quality products are made with JavaScript. Don't ruin the GTK like this please!,True,True
amule-project/amule/189,True,625074454.0,"In the source code, after run autogen.sh and configure shows the error:

config.status: error: cannot find input file: `Makefile.in'

And the command make shows:

make: *** No se especificó ningún objetivo y no se encontró ningún makefile.  Alto.

This software is not well reviewed and is useless. There is no clear manual on how to make the application, which is more serious.",True,True
status-im/nim-waku/22,True,626750561.0,"Colors are horrible for log aggregators, just look at this shit:
```
docker/nim-waku-node[17151]: #033[32mINF#033[0m 2020-05-28 19:15:18+00:00 #033[1mStarting metrics HTTP server              #033[0m #033[32mtid#033[0m=#033[94m1#033[0m #033[32mfile#033[0m=#033[94mwakunode.nim:127#033[0m #033[32maddress#033[0m=#033[94m0.0.0.0#033[0m #033[32mport#033[0m=#033[94m8008#033[0m
```",True,True
gitpod-io/gitpod/1067,True,548501722.0,"**Describe the bug**
<!-- A clear and concise description of what the bug is. -->

**To Reproduce**
<!-- Steps to reproduce the behavior. -->

**Expected behavior**
<!-- A clear and concise description of what you expected to happen. -->

**Additional Information**
<!-- For instance, relevant logs from terminals or the browser's devtool console. -->
",True,True
gobytecoin/gobyte/31,True,548485770.0,"Is the network is dead ??

No peers and network confirmation down.. But token pump on exchange, WTF ?!

V",True,True
spyder-ide/spyder/12292,True,598503107.0,"## Description

### What steps will reproduce the problem?

<!--- You can use Markdown here --->

I don't know what will reproduce the problem because I don't know what the problem is.  I just tried reinstalling you buggy, shitty software for the third time.

Maybe you guys can get one that works right and stick to it without changing it all the time.

### Traceback
```python-traceback
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 154, in perform_request
    response = handler(params)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\decorators.py"", line 20, in wrapper
    params = req(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\providers\document.py"", line 83, in document_did_open
    self.get_status(params['file'])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 111, in get_status
    kite_status = status()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 93, in status
    elif check_if_kite_running():
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 42, in check_if_kite_running
    'status']):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1457, in process_iter
    yield add(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1432, in add
    proc = Process(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 346, in __init__
    self._init(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 373, in _init
    self.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 723, in create_time
    self._create_time = self._proc.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 671, in convert_oserror
    raise exc
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
OSError: [WinError 0] The operation completed successfully: '(originated from OpenProcess)'
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 154, in perform_request
    response = handler(params)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\decorators.py"", line 20, in wrapper
    params = req(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\providers\document.py"", line 83, in document_did_open
    self.get_status(params['file'])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\client.py"", line 111, in get_status
    kite_status = status()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 93, in status
    elif check_if_kite_running():
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\plugins\completion\kite\utils\status.py"", line 42, in check_if_kite_running
    'status']):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1457, in process_iter
    yield add(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 1432, in add
    proc = Process(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 346, in __init__
    self._init(pid)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 373, in _init
    self.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\__init__.py"", line 723, in create_time
    self._create_time = self._proc.create_time()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 671, in convert_oserror
    raise exc
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\psutil\_pswindows.py"", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
OSError: [WinError 0] The operation completed successfully: '(originated from OpenProcess)'
```

## Versions

* Spyder version: 4.1.2 
* Python version: 3.7.6
* Qt version: 5.12.5
* PyQt5 version: 5.12.3
* Operating System: Windows 10

### Dependencies

```

# Mandatory:
atomicwrites >=1.2.0           :  1.3.0 (OK)
chardet >=2.0.0                :  3.0.4 (OK)
cloudpickle >=0.5.0            :  1.3.0 (OK)
diff_match_patch >=20181111    :  20181111 (OK)
intervaltree                   :  None (OK)
IPython >=4.0                  :  7.13.0 (OK)
jedi =0.15.2                   :  0.15.2 (OK)
nbconvert >=4.0                :  5.6.1 (OK)
numpydoc >=0.6.0               :  0.9.2 (OK)
paramiko >=2.4.0               :  2.7.1 (OK)
parso =0.5.2                   :  0.5.2 (OK)
pexpect >=4.4.0                :  4.8.0 (OK)
pickleshare >=0.4              :  0.7.5 (OK)
psutil >=5.3                   :  5.7.0 (OK)
pygments >=2.0                 :  2.6.1 (OK)
pylint >=0.25                  :  2.4.4 (OK)
pyls >=0.31.9;<0.32.0          :  0.31.9 (OK)
qdarkstyle >=2.8               :  2.8.1 (OK)
qtawesome >=0.5.7              :  0.7.0 (OK)
qtconsole >=4.6.0              :  4.7.2 (OK)
qtpy >=1.5.0                   :  1.9.0 (OK)
rtree >=0.8.3                  :  0.9.4 (OK)
sphinx >=0.6.6                 :  3.0.1 (OK)
spyder_kernels >=1.9.0;<1.10.0 :  1.9.0 (OK)
watchdog                       :  None (OK)
zmq >=17                       :  19.0.0 (OK)

# Optional:
cython >=0.21                  :  0.29.16 (OK)
matplotlib >=2.0.0             :  3.2.1 (OK)
numpy >=1.7                    :  1.18.1 (OK)
pandas >=0.13.1                :  1.0.3 (OK)
scipy >=0.17.0                 :  1.4.1 (OK)
sympy >=0.7.3                  :  1.5.1 (OK)
```
",True,True
pashayogi/SETAN-GOLD/1,True,606630998.0,"my account has booked cuz i just sign up with your fuking tool 
 ",True,True
JohnPicchi/Profile/1,True,606614179.0,Worst. App. Ever. Please make it not the worst app ever. Thanks.,True,True
TastiestSandwich/consensus-frontend/2,True,606609264.0,Fuck this,True,True
esx-framework/es_extended/713,True,606312933.0,"2020-04-22 we recieved an email from GitHub stating that kanersps had started a DMCA takedown notice against es_extended. https://pastebin.com/kKxwH7MS

In his initial notice he is saying that multiple files in ESX belong to him and he would like to be credited for everything he has done. He doesn't link the exact files that he claim he owns, just a link to our repo. This means that he wants the entire repo removed if we don't credit him for his code.

He is butthurt over how when we ditched essentialmode we created functions and other things that did what essentialmode did... But how do you expect us to ditch essentialmode if we cannot create our own command handling code? We can't. He claims in his second DMCA takedown notice https://pastebin.com/2q5cVHYS that our code is ""stolen"" from his project.
As I just said it's impossible to go standalone if we don't create the features essentialmode had to offer, command handling is a perfect example, and as you can imaine the code differences aren't huge.

He also mentions how his code is licensed under AGPLv3, and that ESX must also be licensed under the same. But this is false, ESX was developed around 2017 initially, (old time when it used essentialmode). What license was essentialmode on at that time you wonder? Good question, web archive has archived his old website, where it's clearly a nolicense license. http://web.archive.org/web/20180516175223/https://docs.essentialmode.com/#license

Gizz told me not to make an announcement, sorry mate. He has also said that we are in a modding community where the fivem devs are REVERSING a whole copyrighted game for us, meanwhile kanersps is spending time on a DMCA takedown to ruin the community.
‏‏‎ ‎
Kanersps obviously have a weird intention we can't identify. Is it to destabilise ESX to tell everyone to move to extendedmode? And if so does the contributors of that project have anything to do with this? Is it to revenge on his shitty framework being ditched? Is it just to be a asshole? Maybe even the fivem developers are a part of it?

We don't know, and don't really know how GitHub are handling this DMCA takedown notice. I mean how can they take a takedown notice that don't even specify what files are infringing seriously? Some files in the ESX project, such as the server sided player class file might need a rewrite, in the meantime if required then we will remove that file and create our own from scratch.",True,True
google/shaka-player/2529,True,606817816.0,"<!-- NOTE: If you ignore this template, we will send it again and ask you to fill it out anyway. -->

**Have you read the [FAQ](https://bit.ly/ShakaFAQ) and checked for duplicate open issues?**
yes

**What version of Shaka Player are you using?**
3.0

**Can you reproduce the issue with our latest release version?**
yes

**Can you reproduce the issue with the latest code from `master`?**
yes

**Are you using the demo app or your own custom app?**
demo app

**If custom app, can you reproduce the issue using our demo app?**


**What browser and OS are you using?**
chrome, nexus 6, android

**For embedded devices (smart TVs, etc.), what model and firmware version are you using?**


**What are the manifest and license server URIs?**
<!-- NOTE:
  You can send the URIs to <shaka-player-issues@google.com> instead,
  but please use GitHub and the template for the rest.
  A copy of the manifest text or an attached manifest will **not** be
  enough to reproduce your issue, and we **will** ask you to send a
  URI instead.  You can copy the URI of the demo app to send us the
  exact asset, licence server, and settings you have selected there.
-->
https://bitmovin-a.akamaihd.net/content/art-of-motion_drm/mpds/11331.mpd

**What did you do?**
<!-- Steps to reproduce the bug -->
why u revoke nexus 6 ?? give keybox to me now .  nvidia shield . 
i am from india my name is ramjeet widevin is shit .!!

**What did you expect to happen?**
get amazon prime sunnxt key

**What actually happened?**
<!-- A clear and concise description of what the bug is -->
<!-- If applicable, you may add screenshots to help explain your problem. -->
nexus revoked :(.",True,True
Kyrobi/Cynagen/165,True,609531343.0,"Please title this post ""Ban Appeal:"" followed by a name
Fuck Colt Crohnie 
**Minecraft username**:
Fuck Colt Crohnie 

**I was banned on**: (Format: Dec 23, 2012)
Fuck Colt Crohnie 

**I was banned by**: (Leave blank if unknown)
Fuck Colt Crohnie 

**I was banned for**:
Fuck Colt Crohnie 

**A brief summary of what happened before the ban was**:
Fuck Colt Crohnie 

**I like to be unbanned because**:
Fuck Colt Crohnie 

**Explain why is cereal is/isn't considered a soup**:
Fuck Colt Crohnie 

**Additional information**: (Optional)
Colt Crohnie is a Faggot",True,True
MiKTeX/miktex/530,True,611528813.0,"- [x] I have read the [MiKTeX Contributing Guidelines](https://github.com/MiKTeX/miktex/blob/master/CONTRIBUTING.md)

(Windows 10, for reference, if it matters.)

I have a paper due tomorrow. 

I thought ""hey, let's use the *American Physical Society* LaTeX Class!"". I haven't used it before, but it's just a LaTeX class, what could possibly go wrong? So I loaded up MiKTeX and went to ""Packages"", searched for ReVTeX and installed it.

Oh, by the way, you have updates available, says the console. So I click on the ""Updates"" tab and try to install the updates. Some text appears in the pop-up window. After a while the window stops responding. Won't listen to clicks or the keyboard. Eventually I gave up and closed it.

Now the trouble begins. I go into TeXStudio and try to compile the template. Whoops, you're missing `textcase`. Odd. Installation failed.

I tried to compile a document I had compiled yesterday. It won't compile either.

I opened the MiKTeX console. ""Check for updates"" doesn't work: HTTP 401. No packages can be installed: HTTP 401. The error message isn't very helpful, aside from saying ""HTTP 401 (Unauthorized)"".

I have now spent *three hours* trying desperately to compile *anything*. Did I mention I have a paper due tomorrow?

So I gave up, uninstalled MiKTeX, and am now in the process of reinstalling it and -- *hopefully* -- actually being able to use LaTeX for this paper.

The purpose of this bug report is the following: **Please warn your users before you suggest they take actions that may break their system.** 

If I had known that running ""Update All"" might fail and *break absolutely everything*, I would never have tried to do it in the middle of writing a term paper. Obviously.

Which, as I mentioned, is due *tomorrow*.",True,True
ResistancePlatform/resistance-platform-release/13,True,613458469.0,"the download of the installation software  contains malware: win32:MinerD-A

Not very nice of you a..holes to infect other computers with malware. Your project looks good on paper but trying to clandestinely installing malware  on people's computers is mean. What were you thinking? That everybody is stupid enough to not realize it?",True,True
Adamantcheese/Kuroba/874,True,612566065.0,"[Continuation of 862 because Adamantcheese keeps locking for no reason](https://github.com/Adamantcheese/Kuroba/issues/862)

> Removing a post removes it from display.

No shit. You still haven't explained why there's Hide AND Remove. They are both the exact same thing, the only difference is that two extra clicks are required to ""unremove"" a post. 

> Filter image hash isn't an option on posts without images. You must be on an older version.

I'm on the latest release build (v4.12.0). It is an option on posts without images on the latest version.

> Share is as @clawyf explained.

You still haven't explained why we can copy the image's link and not the post's link. If you want to play this game and persist, it's either both ways, or none. 

> Info provides additional info that isn't presented in the post cell. 

The only thing Info provides is the resolution of the picture inside a post and nothing else. The filename, size and time of date can already be seen from the post itself, which makes Info completely useless.

Just accept the truth, you have so much garbage in the context menu and it needs to get cleaned up. If you got rid of Remove and Info, nobody would bat an eye.",True,True
google/google-authenticator/698,True,613463737.0,Dont work with fb abd google 👎👎👎,True,True
citra-emu/citra/5346,True,616016198.0,"<!---

Please read the FAQ:
https://citra-emu.org/wiki/faq/

THIS IS NOT A SUPPORT FORUM, FOR SUPPORT GO TO:
https://community.citra-emu.org/

If the FAQ does not answer your question, please go to:
https://community.citra-emu.org/

====================================================

When submitting an issue, please check the following:

- You have read the above.
- You have provided the version (commit hash) of Citra you are using.
- You have provided sufficient detail for the issue to be reproduced.
- You have provided system specs (if relevant).
- Please also provide:
  - For any issues, a log file
  - For crashes, a backtrace.
  - For graphical issues, comparison screenshots with real hardware.
  - For emulation inaccuracies, a test-case (if able).

--->like seriously, not everyone has a huge ass C drive. Most users secondary drive are bigger than their primary drive. And with Citra being the same GUI and shit as yuzu, it should take two seconds to add a file system tab inside Citra like you did with yuzu. 

And then a user in your Discord says it's currently in development? Citra's been out a lot longer than yuzu, even though they're made in the same language. 

I want my shit installed on my secondary drive. 
",True,True
jupyterhub/zero-to-jupyterhub-k8s/1672,True,619201078.0,"I'm going to call this out since many want to keep closing issues such as this. The work around is to rebuild a docker container to account for this ever changing requirement of installing packages. As you are aware that even ""pip install <some package> might lead to a gcc rebuild being required. You have not accounted for such by locking down the container used omitting sudo capability. In essence the the rush to containerize and move to Kubernetes did not take in to consideration this standard use case. As such you are requiring a rebuild to include the packages in the base container. However, this is not an acceptable workaround. This precludes providing a level of flexibility which containers are to afford and deployment to Kubernetes. For each point that was mentioned I can easily address why the point is mute.

Simon Li you rushed to close the issue and divert me to https://discourse.jupyter.org/
This is not an end user issue so do not assume my level of experience or skills. As a seasoned developer and architect I am calling out the lack of consideration for an obvious use case for moving this to Kubernetes.

The base architecture is flawed but could easily allow the injection of packages without having to rebuild the container. 

I suppose I'll have to fork this and build out the solution since I suspect this will be swiftly closed

DB",True,True
dotnet/maui/67,True,621954050.0,"This name is in use and should be changed imediately. Yes, I have seen the other issues. Yes, I am opening a new one because fuck you Microsoft.You are merely trying to cast a shadow on other, truly open source projects. 

https://itsfoss.com/microsoft-maui-kde-row/?fbclid=IwAR3lO4SDxw3H01YsuKZ9G5D2zc1K-OOpjInCKnnY5GBpqiAdnhqfXJGG_EI",True,True
Mantaro/MantaroBot/320,True,622732698.0,"Regarding my background (It's aplpicable to understand my viewpoint) I've been in the BDSM world as a dominant for the better part of the last twenty years. Something we're big on? Consent.
And lo and behold - you're silly little waifu system doesn't care about consent.
And yes, I saw the warning on your help page that says it should not be taken as reality!
A) People don't read it.
B) You think that matters when an abusive asshole is messing with someone's head?
terms like 'gaslighting' are popular, but the correct one is psychological manipulation. 

Might I suggest, as a simple little fix - You either a) Make the supposed 'claim key' work (We tested: It doesn't) as a start: and as a fdinally, either an opt-out (That both blocks and removes all claims) or a simple way for the claimed to say 'no'. 
I've alreay decided that those 'silly little 'commands based dom/sub games that don't bother with consent make me never want to visit your server. 
But perhaps for everyone else, given it's freely available, and you don't know who else is using it?
Or under what circumstances?
I mean, Hyptohyetically, we're talking the grooming of underage girls here, if we want some hyperbole. 
Which might not be.
FIX IT.",True,True
facebookresearch/hydra/597,True,621584901.0,"# 🐛 Bug

can't run office example correctly.
https://hydra.cc/docs/configure_hydra/logging
## To reproduce

** Minimal Code/Config snippet to reproduce **
config.yaml
defaults:
  - hydra/job_logging: custom
files
![image](https://user-images.githubusercontent.com/24520617/82426441-707c2480-9aba-11ea-9aa5-05555116f0b7.png)

 File ""my_app.py"", line 11, in <module>
    my_app()
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/main.py"", line 24, in decorated_main
    strict=strict,
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/_internal/utils.py"", line 174, in run_hydra
    overrides=args.overrides,
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/_internal/hydra.py"", line 86, in run
    job_subdir_key=None,
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/plugins/common/utils.py"", line 101, in run_job
    configure_log(config.hydra.job_logging, config.hydra.verbose)
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/site-packages/hydra/plugins/common/utils.py"", line 24, in configure_log
    logging.config.dictConfig(conf)
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/logging/config.py"", line 800, in dictConfig
    dictConfigClass(config).configure()
  File ""/data00/home/mayingxin/anaconda3/envs/pysot/lib/python3.7/logging/config.py"", line 496, in configure
    raise ValueError(""dictionary doesn't specify a version"")
ValueError: dictionary doesn't specify a version



** Stack trace/error message **
```

```

## Expected Behavior
<!-- A clear and concise description of what you expected to happen. -->

## System information
- **Hydra Version** :  
- **Python version** : 
- **Virtual environment type and version** : 
- **Operating system** : 

## Additional context
I think your tutorials are dogshit!
https://hydra.cc/docs/configure_hydra/logging
",True,True
jy1263/impatient-eta/1,True,623945891.0,Amy I need an explanation. Wtf is this lol,True,True
immuni-app/immuni-app-android/9,True,624136789.0,"https://github.com/immuni-app/immuni-app-android/blob/8c4739b471754977ea42b5cc2090cd28804a141f/app/src/main/AndroidManifest.xml#L34

It is really ugly to see app locked in portrait in 2020... with livedata, viewmodels and SavedStateViewModel!
",True,True
tgstation/tgstation/51298,True,624641343.0,"<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may not be viewable -->
## Round ID: #138035
<!--- **INCLUDE THE ROUND ID**
If you discovered this issue from playing tgstation hosted servers:
[Round ID]: #138035 (It can be found in the Status panel or retrieved from https://atlantaned.space/statbus/round.php ! The round id let's us look up valuable information and logs for the round the bug happened.)-->

## Reproduction:
1) Find or make a bunch of bodies
2) Either place them on a space tile or soak them in CLF3 and ignite them
3) Place surgery drapes on all of them
4) Begin tends wounds surgery
5) Revel at your ability to farm XP for no downside

It also spams the EVERLOVING FUCK out of chat. This was all within about a second of each other.

![image](https://user-images.githubusercontent.com/7019927/82869014-33b59080-9ef3-11ea-95f7-19b4c0847e1e.png)

<!-- Explain your issue in detail, including the steps to reproduce it. Issues without proper reproduction steps or explanation are open to being ignored/closed by maintainers.-->

<!-- **For Admins:** Oddities induced by var-edits and other admin tools are not necessarily bugs. Verify that your issues occur under regular circumstances before reporting them. -->

Yeah, this is a minor one, but if we're rewarding people for this sort of thing we should probably start fixing the bugs/exploits.",True,True
clayrisser/react-gtk/21,True,625435290.0,The worst quality products are made with JavaScript. Don't ruin the GTK like this please!,True,True
amule-project/amule/189,True,625074454.0,"In the source code, after run autogen.sh and configure shows the error:

config.status: error: cannot find input file: `Makefile.in'

And the command make shows:

make: *** No se especificó ningún objetivo y no se encontró ningún makefile.  Alto.

This software is not well reviewed and is useless. There is no clear manual on how to make the application, which is more serious.",True,True
status-im/nim-waku/22,True,626750561.0,"Colors are horrible for log aggregators, just look at this shit:
```
docker/nim-waku-node[17151]: #033[32mINF#033[0m 2020-05-28 19:15:18+00:00 #033[1mStarting metrics HTTP server              #033[0m #033[32mtid#033[0m=#033[94m1#033[0m #033[32mfile#033[0m=#033[94mwakunode.nim:127#033[0m #033[32maddress#033[0m=#033[94m0.0.0.0#033[0m #033[32mport#033[0m=#033[94m8008#033[0m
```",True,True
staxrip/staxrip/211,True,626588555.0,"I have said this before and I am saying this again, how is any one using this? It does not work at all. No matter what you do you will always get an error screen, it always crashes, it refuses to accept any user made settings and discards user settings and uses it's own crappy settings. I have no idea how any one is using this, I can not even encode one movie, do a batch? Forgot about it, not possible. This has to be the worse program ever built by man, seriously. And Then finally after fighting with this program to batch encode it finally ran but then it decided to crash and quit on me because one file name was too long. Okay who cares, move on, do the next one, why crash and burn over it? 
Features request? Remove the stupid 1 pass at 7,000 default settings. Why is it there? stupid. If a file name is too long, move on and lastly, make this program work, just for once.",True,True
microsoft/winget-cli/352,True,626395058.0,"Here's an id

Make 100% sure you dont fuck up the ui for coutries where people speak diferent languages like Belgium (ur collegues fucked up bigtime with the store)

we dont really need a gui tho. could be nice as a full store replacer tho.",True,True
JakeBlair420/totally-not-spyware/6,True,627573642.0,"yall scammers, this is not even a malware or jailbreak",True,True
tgstation/tgstation/51363,True,626999854.0,"Our jumpsuits look like shit.

![image](https://user-images.githubusercontent.com/49448379/83221885-9d89a080-a166-11ea-8f22-dbf53465e578.png)
![image](https://user-images.githubusercontent.com/49448379/83221896-a37f8180-a166-11ea-9cc1-ac9eb9562bc5.png)
![image](https://user-images.githubusercontent.com/49448379/83221904-aa0df900-a166-11ea-8a25-f7c96c5929f9.png)
![image](https://user-images.githubusercontent.com/49448379/83221929-bdb95f80-a166-11ea-8909-5286f4c56251.png)
(I know this one isn't used for assistants anymore but it still looks like garbage.)

Making this a discussion thread with a catchy title so that we can have a discussion which hopefully ends up in us switching to tg jumpsuits or a better alternative.
",True,True
kyuupichan/electrumx/1013,True,626910742.0,why use BSV...,True,True
ManimCommunity/manim/112,True,627772680.0,"In my opinion they are completly useless since when `FadeInFrom`and `FadeOutAndShift `are called `direction = DOWN` is set by default. 

(And `FadeInFrom(mobject, direction = DOWN)` , `FadeOutAndShift(mobject, direction = DOWN)` are equivalent)

EDIT : I mixed up `FadeIn `and `FadeInFrom`. I'm talking about the latter; `FadeIn `is fine ",True,True
figlet-monkey/Baimless/2,True,627123842.0,its shit,True,True
falconry/falcon/1726,True,627319662.0,"He took the code beginning of 2017, not 7 years ago. Don’t be a dick as the source code was stolen at that point and implemented on this.",True,True
headmk/sly/1,True,627962665.0,fuck the xxxxx,True,True
utmapp/UTM/326,True,615598666.0,"**Describe the bug**
Hey i cant even Find the ipa and i cant add a repo to AltStore!",True,True
venveo/craft-characteristic/31,True,530794704.0,-,True,True
scottwainstock/pbm/1192,True,469875088.0,"**Current behavior:**
- App user submits a location submission or a contact message.
- The submission goes to the appropriate admin/region based the bounding box that the user is currently within.

**Result:** A fair amount of location submissions are not where the user currently is, and so the submissions are going to the wrong region. This is adding more work for me, and it's confusing admins.

**Goal:**
- Have the location submissions (I don't think we care about changing the behavior for contact messages - but I'm guessing these two types of submissions will go hand in hand) geocode _and then_ have the submission go to the appropriate admin based on the lat/lon of the submission.",True,True
eni9889/TW-PP-Issues/66,True,628052655.0,"I refuse to use any ++ applications until the ""PLS FOLLOW ME!!!"" and ""SIGN UP FOR A ++ ACCOUNT!!!!"" popups go away or can be disabled. My god it's annoying.",True,True
peterbsmith2/ngx-breadcrumbs/31,True,627973561.0,-,True,True
OpenVGDB/OpenVGDB/40,True,589544365.0,"You can see them if you look at the database using Notepad++ on Windows, but not in SQLiteStudio (for example). Provenance-emu was picking up those URLs for some reason, and failed to download box art.

Fix is to run vacuum on the database (to clean it up). I ran it using SQLiteStudio, then deleted cached stuff on my iPAD for Provenance, and the issue was resolved.",True,True
Lith1um/CovidTracker/1,True,606500773.0,-,True,True
elementary/os/348,True,614033936.0,"<!--
By filing an Issue, you are expected to comply with the elementary code of conduct: https://elementary.io/code-of-conduct

Please note that this tracker is only for bugs and feature requests. Please try these locations if you have a question or comment:

  https://elementaryos.stackexchange.com/
  https://www.reddit.com/r/elementaryos/

Please read and follow these tips:
https://elementary.io/docs/code/reference#proposing-design-changes

Lastly, be sure to preview your issue before saving. Thanks!
-->

## Prerequisites
- [x] I have searched open and closed issues for duplicates.

## Feature
**Is your feature request related to a problem? Please describe.**

The problem is your team forcing us to use the OS the way you want us to use it although it makes it 1000000 times harder to use it your way, than what would be convenient for us.
Keyboard shortcuts are not faster and will never be faster than muscle memory and mouse! 
Try using keyboard shortcuts in the dark or when you are not over your keyboard and looking at the keys!
8 of 10 times you will press something else! So what's faster? Me pointing with the mouse and clicking the button, or you trying to find 2 or 3 keys?
Or me going with my mouse to the bottom, waiting for Plank to show up because it auto hides when there is an open window, clicking on the app/program and this way minimizing it?
Don't you really see how ridiculous is what's written in the Blog post ""Why there is no minimize button"".
Because ONE person thinks it's better doesn't give the right to make a thousand or more people using it that way, when there is a simple solution. Especially on Linux where customization is so easy to be added. 
Elementary tweak solves the problem but it's unsecure to add PPA that is not checked by Elementary team. The same reason you are showing the Warning window for Non-cureted apps/program in the App Center! So if you care about our security so much why 99% of your users have to add a PPA that one day can put them at security risk? Ship your OS the way you want by default but give us the option to make it more friendly for our use.

**Describe the solution you'd like**
In the setting simple option to turn on Minimize and Maximize buttons.

**Existing work**
Elementary tweaks makes it better but adding someone's PPA is dangerous even if it's on GitHub or whatever. You never know what actually is being installed or how it will change in the future.

**Describe alternatives you've considered**
Elementary tweaks included out of the box but it was denied here.

**Additional context**
For reference: https://www.reddit.com/r/elementaryos/comments/gdbo1k/tried_using_elementary_as_intended_without_any/
Most of the people who use your OS are installing tweaks to solve this problem. And most of them want it out of the box as an option. So maybe it's time to stop trying to be Apple or Windows and forcing people to use something the way YOU want it and give a simple option to make it the way people want it. It's not a major change or something. Just a simple solution.",True,True
SerenityOS/serenity/2438,True,627139009.0,"I think if you don't want to use C, then at first you should design and implement your own language. Not C++ hell.

Like how Terry Davis did.",True,True
yarmoliq/coursework/3,True,627948336.0,"How is this version in master branch if it didnt even compile, you moron

Object.cpp line 8",True,True
addons-frontend/mozilla/7757,True,addons-frontend/mozilla/7757/424530262,smartadblock was abusively rejected by erosman (a simple developer) in a case where the reviewer policy clearly states that more info should be requested. The extension has now been offline for 8hours? how has this guy been allowed to review extensions in the first place? ,True,True
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423638299,We've had this discussion before so I don't feel the need to rehash it again. We don't plan to take the UI in this direction. ,True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455814689,"I never paid for any advertisement, I thought I did because you said so in the recent emails and it was 9 years ago, but as we all can see you came up with this idea first. If you are so stubborn to NOT include my name on your donors list, even if I supported your project from day one, just because you are angry that I showed you were wrong and donations didn't have any strings attached, it's just another reason to not make any donations to you or any of your projects, because you are dishonest person and you have your supporters for nothing. ",True,True
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423729686,"Wait... what changed? 🤣 Seriously though, I don't think this is an issue of ""best"". There are often multiple ways to approach things, and yours may be fine for your user base. It simply isn't a direction we want to take the HandBrake UI. The main comments I would like to make pertain to your premise and the core workflow. The how/what/when idiom again may make sense for you and your users. This is vastly different from how we approach the HandBrake UI. Our core workflow has evolved over the years, and while I'm not one to take a ton of credit, I have been investing quite a bit of thought and design into improving stress areas over time while accommodating new objectives and the features that support them. We've approached things from a realignment perspective (iterative improvements), rather than a complete redesign, and there are more improvements in the pipeline that wouldn't be easily accommodated by your design. Consider for example the proposed dimensions overhaul and plethora of color space/depth related updates we will need to implement before long. Video filters are also more popular than people realize, and more are planned along with better presentation thereof as I/we have time. The current core workflow is probably best explained by the Quick start article. In short, open a source, select a preset, hit start. That mostly leaves ""where did it go?"" and we've improved the destination controls and documentation to help with that, too. The result is that normal humans are more able to successfully use HandBrake now than ever before. I talk to regular people using HandBrake all the time (both in passing and for research purposes) and their experiences support this. So does my stopwatch. The rest of the UI is then what the presets system sets on behalf of the user. While these tabs/controls could be hidden completely (ala Instant HandBrake of years past), they provide no obstacle these days. We've disabled most unnecessary controls on startup and presented the summary tab as an excellent at-a-glance description of what will happen. The team has worked to achieve a hybrid beginner/pro UI design that only reveals more as you desire to go deeper, and I'm very proud of that. So we've solved very specific sticking points for millions of people with the current iteration. I and others continue to do research and design to iteratively improve the existing flow. Your design addresses a completely different set of concerns, so in some ways, we're comparing apples to oranges. While some comparisons can be made, there is no ""best"". The HandBrake UI is on a proven, successful path, and yours is a departure from that path. I don't believe it addresses many of the issues we had, currently have, and plan to improve. If it works for VidCoder, great! I have no doubt this is a useful paradigm for some people. That HandBrake is going a different direction hopefully will not discourage you from continuing to iterate and improve for your audience. ",True,True
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423756513,"I took care with my comments took your proposal quite seriously. I'm not sure how I can be more clear that changes aren't ""necessarily bad"", only that we seem to be making different assumptions about what the core workflow is and should be. I hadn't seen the associated screen shot until you just posted it, so please pardon any confusion over dimensions and such. Anyway, I'm not really interested in answering your additional questions. I tried to be thoughtful and I don't really appreciate how you've characterized my comments. ",True,True
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450223017,"By adding in an error log statement at   of something to the effect of error_log($ldapSearchDN); Then again another to show the contents of $config-&gt;ParameterArray['LDAPBaseDN'] we can take those values and throw them into the following search against AD from the values that I have said will work at this point in the code where CN is essentially doing nothing. [wilbur@friend openDCIM]$ ldapsearch -x -b ""DC=ad,DC=wilpig,DC=org"" -D ""tablesb@friend.wilpig.org"" -h 10.0.0.243 -W '(|(userprincipalname=Limited User)(cn=Limited User))' The CN value was pulled from an earlier ldap search so that we are just now matching again against a known value that was pulled from ldap and this time around we are looking for the memberof statements. This is NOT searching for groups based on CN it is actually attempting to just lookup the same object htat we already loaded again because we love to do things repeatedly.  So while you are harping on a CN value it actually does nothing.  that entire section can be removed and have no real issues. Stop quoting me RFC and read the god damned code. ",True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455809482,I think sharing the whole communication would be more transparent since you already started this nonsense. ,True,True
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/435210788,"@friend We didn't ""go through it"" this time. You just closed it without even reading. If you had, you would have realized that every single one of the usability concerns brought up originally ended up never materializing. I haven't had a single user complain and ask to bring the settings back into the main window. At least now I know with certainty that making my own UI was the right thing to do. It's infuriating dealing with people who tell you ""that's bad UI"" without a single valid reason to back it up. And who, when politely challenged simply reject, ignore and lock rather than discuss in good faith. ",True,True
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/435215570,"How many times would you like to go through this and similar suggestions, accuse others of not taking your ideas seriously despite hours of consideration over days in public and private, and meet our constructive responses with argumentative and harassing behavior? We've presented nothing but kindness in good faith. I encourage you to read our Code of Conduct. Nothing we've read from you in our recent interactions respectful of opposing viewpoints, gracious in light of constructive criticism, empathetic, or fostering community. In short, it is clear our views differ; that does not give you a right to behave badly. Harassment in public or private will not be tolerated. This topic is now closed and locked, same as #1657. Feel free to address further concerns with me and/or other team members directly. ",True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455802483,"I tried to solve this privately instead of making it a community thing as this was rather personal, however, the communication didn't end up well. The sudden change was of course not meant positively. I think that in any way we should stay civilized here and don't let misunderstanding or anger change how we react or behave to each other. ",True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455801897,Cheap shot dude... ,True,True
termux-packages/termux/2735,True,termux-packages/termux/2735/413326016,"Pardon my English @friend, what you wrote is bullshit. ",True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/400907717,"I do not recommend donating to this project, we have donated a few times to them and now they have removed information about it. Our money wasn't good back then Petr when nobody supported your project? ",True,True
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450224735,"I've read the code, I wrote the code, You clearly aren't following the logic and have some bizarre schema in your environment.  I have this code working against a standard AD back end as well as an openldap back end without any issues.  If you are doing pure posix and don't have common names defined, not my problem.  We have common names to help identify groups so we don't have to remember ID numbers.  I'm not changing the code for your self imposed issues. ",True,True
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/252907501,"I gave up, this library is too buggy in many aspects and Jeff Rowberg does not care about solving these MANY bugs that you can find with a simple search at Google. Also Jeff does not even read these threads. IMPORTANT DONT USE JEFF'S LIBRARY FOR ANYTHING IMPORTANT. Sooner or later it will fail and if you are using this library with your quadcopter, robotic arm... STAY AWAY OF IT. You will get hurt and hurt other people. There are serious problems with this library which will, sooner or later, cause you intermitent problems. ",True,True
android/cSploit/931,True,android/cSploit/931/355209488,@friend long as your name indicates that you are 15years old and the csploit you forked has no code from you i cant take you seriously. Fuck off troll ,True,True
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/241760891,"Wow. You're really just an angry brat, aren't you? No wonder no one is trying to help you. You're wrong, but I'm not going to show you why. Learn some etiquette On Tue, Aug 23, 2016, 600 AM batata004 notifications@friend.com wrote --  Thanks, Tyler McGahee (619)-880-7779 San Diego, CA **In an effort to be more responsive to email, my emails have become more brief and less formal. Please excuse any impoliteness; it is not intended. ",True,True
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/241722023,"@friend you certainly have no idea what you are talking about and you surely should delete your reply to this bug report. Read all the thread, I am not using any delay and I know much better than you how important it is to keep the loop fast. ",True,True
android/cSploit/931,True,android/cSploit/931/285884059,"The whole app is just a mockup, I've been spending the night reviewing the code and it seems like a donkey (or is it a monkey) wrote that, thanks for an ever failling, condescending app that will never reach the stage of even being in beta. Peace ",True,True
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/392549146,So you're going to act like a child. Rasing a new ticket on #2164 ,True,True
pypi-legacy/pypa/759,True,pypi-legacy/pypa/759/287761059," probably more trouble than it is worth. For one, it is py2 only, but installs for py3 as well, where it breaks immediately. Then the name ""gi"" usually is used by pygtk and should not be used by a next to worthless breaking package like  this secondary ""fake gi"" installed breaks all gtk apps. This ""fake gi"" should be removed, since it does no longer exist on github as py source. If this ""fake gi"" was deleted, everyone would benefit. ",True,True
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450206853,"group searches is what is broken.                             $ldapSearchDN=str_replace(""%userid%"",$found_dn,html_entity_decode($config-&gt;ParameterArray['LDAPBaseSearch']));  so, no, what your propose does not change the fact it's using CN and not uid. so stop posting stupid answers. ",True,True
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410421888,"I understand you're frustrated. Regardless of the issue, you're being an ass. HandBrake is open source, free software, and nobody owes you anything, despite our efforts to provide support in our free time. I'm going to leave these here and lock the issue. Please consider them and if you don't feel like changing your attitude, please go away. ",True,True
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/414904571,"Honestly, I don’t even know why I entertain the narrow minded. If my post offended you than I beg of you to pardon my life. If you look closely at the post, under it I set out a disclaimer. I can give much detail on the post for a reason and you assuming that I don’t have a company shows the level of ignorance you have on the matter. If this post intrigues you and you want to at least know what is cooking behind the scene, contact me. My email is there. If not, find some other way to spend your time. ",True,True
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410419756,"And FYI, this has ZERO to do with the PHYSICAL media it is hilarious that was the first defensive knee-jerk reaction to make this go away and close it.  HB doesn't even make low-level I/O calls the failure is in the reading of the actual source file regardless of where the heck it sits.  Copy a corrupt source file, any source file to the hard drive and Handbrake simply is coded so poorly that corrupt source file that fails to read, will not properly fail the job - period.  I just tried it by hex-editing a source file to corrupt it and HB did the exact same thing.  It is fully reproducible and to simply close this issue is absolutely unbelievable. ",True,True
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/414824831,"Mr. Murder, thank you for your input. I am glad you’ve seen through my deceptions. I am glad you actually took the time out of your day to expose my trickery. You are absolutely right. The worker (that would be you) with all the skills and knowledge should run most of the company and should earn most of the company too. In fact, the owner of the idea, the one who runs the business side of things (sole or with a team), the one who files for the company, the one has to keep the company from running to the ground, the one makes all the important decisions should MOST DEFINITELY own 5 percent of the company. Maybe less. That is exactly how all the biggest companies in the world run their businesses. If I may, I would like to suggest one last thing before taking my deceitful person to more viable candidates. Do your reserach before talking young Bill and for the love of God, please know your worth. 10 years plus in your career and you still struggling to make your big break. You just signed up on Github this past week and your first order of business is to bash the first post you see. I think we all can your bluff now... ",True,True
shlink/shlinkio/210,True,shlink/shlinkio/210/422346159,"Okay, this form of installation is honestly the worst I have ever experienced. I love the product, really the best link shortner I've ever used but the installation, you really have to fix that, it took me 2 hours in general to even make the installation starting with all preperation without the knowledge of a certified sysadmin. I am very sure that the extreme lack of user experience of your installation process is the man key factor your awesome programm isn't far spread. Now that I got your installation running, it only needed my one single type to f* over the whole installation and letting me redo the whole process after removing it all again. Short I got it working, but please rework your installation process, it is horrible. Great product anyway. Thank you so much. ",True,True
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379498069,"So, instead of carrying out a relatively straightforward fix on your side which not only would resolve this issue but also prevent the same issue with the hundreds / thousands of potential package and configuration combinations out there, stopping lots of other developers falling into the same trap - often (as in this case) completely outwith their control, you opt to disown the problem and put it upon every potential consumer of your package to solve instead? I have no direct control over the SharePoint Framework configuration; I'm just a consumer of that set of packages. I have no direct control over how Reactstrap works, I'm just consuming that package, I have no direct control over FontAwesome, again, just a consumer here. I have no direct control over React ... guess what?  Yup, a consumer! I shouldn't even have to care about all of that; especially as I'm not directly consuming react-popper - it's buried deep in a set of dependencies I also have no control over. Surely it's a more 'customer focused' approach to just resolve the problem with the name conflicts than it is to force a mere consumer of packages to play piggy-in-the-middle between multiple projects, all the while wasting time and making no progress on their own projects?  If I gave an answer such as yours in my day job I'd soon not have a day job - so why is it OK for you to do so just because this project is open source?! ",True,True
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401866844,"@friend , I just make a joke, i know that no need for clarification, i just need when add item, delete or move in real time (not added to array first) to make the adapter automatically sort those damn items , i am really sad with that. ",True,True
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/400042884,"@friend I want going to reply, bevause I hate dropping to any level of low, but your level of [douchebaggery descrip#3]) has led me to ignore you completely because the level of douche hypocrisy in your reply exceed insanity plus one. ",True,True
btrfs/maharmstone/88,True,btrfs/maharmstone/88/441363967,"As I said above... Issue 87 was a harmless use-after-free on shutdown, and nothing to do with this. I've said my piece, and I can see it was a mistake trying to engage with you, so I'm locking this thread. ",True,True
react-image-lightbox/frontend-collective/99,True,react-image-lightbox/frontend-collective/99/296077481,position absolute? Are you fucking idiots? ,True,True
spark/perwendel/1020,True,spark/perwendel/1020/393777939,"Service http = ignite();  even more foolish! I think you all java programmer should learn some programming theory from UNIX/Linux. Java is a enterprise programming platform, commercial companies like oracle/sun/ibm want to earn more money from customers, so they make java complex and heavy! UNIX/Linux programming theory is the only correct way. ",True,True
react-helmet/nfl/373,True,react-helmet/nfl/373/447927882,"Remember how it all started in 2015? So much politeness and willingness to serve the community. Naive.  part of the team that open sourced it. I can PR some code, but I wanted to check with you before I started writing code. lmk, thanks. We are using React-Helmet in all of our new react websites, we are also seeking feedback so we can improve on our open source workflow. We plan to release more and the feedback would help tremendously. Three years passed and no one cares anymore. Reminds me of some clumsy accidental male/female relationships. Frontend was blooming that time. Now it's all starting to rot. ",True,True
GRDB.swift/groue/261,True,GRDB.swift/groue/261/335354687,"I'm sorry but this code builds everyday, without any error, on many setups that conform to the requirements listed at the top of the project's README. Please take the time to provide a proper problem report. ",True,True
GRDB.swift/groue/261,True,GRDB.swift/groue/261/336411556,My little finger tells me you won't reply or close this issue. No news is good news happy GRDB! ,True,True
diaspora/diaspora/7891,True,diaspora/diaspora/7891/431108382,"He is and I posted after he told me, postfactum century here we are!! The main reason why Github is the first choice, cause no noob in the forum has a clue about the code these days, got one answer, which repeats what I already wrote, great support! ",True,True
GRDB.swift/groue/261,True,GRDB.swift/groue/261/389190437,"Wow @friend, Didn't expect such responses as you posted and then giving some hint afterwards. You should work on your attitude pal! Cheers! ",True,True
Ghost-CLI/TryGhost/678,True,Ghost-CLI/TryGhost/678/374471992,"It's obviously not a  password ask and I am not asking for support. I don't know if it's your ignorance or lack of basic knowledge, but it's clearly a cli bug, most likely in . ",True,True
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455118934,@friend So you did not even try to duplicate the problem before closing the ticket?  I guess that's normal laziness from a doc team that has screenshots from five versions ago. But you didn't test so your doubt don't mean anything. Right.  Anything you can do to avoid your responsibility to have correct docs.  I see how you work. I set this up days ago and I explained how I did it.  I logged on here to help you with your documentation errors.  When you get serious about turning out responsible open source tools please contact me and I will help you debug. ,True,True
GoMint/GoMint/406,True,GoMint/GoMint/406/434019763,"The fuck are you talking about? You are saying you want more threads, so i'm asking you what you want those threads to be for. If you don't know what you want them to be for, then you are just another 5 year old shouting for something to be added because it sounds good. ",True,True
babel/babel/8432,True,babel/babel/8432/348466385,SOURCE CODE GENERATED CODE WHAT IS WRONG WITH YOU PEOPLE? DO YOU EVER WRITE DOCUMENTATION FOR YOUR CODE? THIS IS UTTERLY RIDICULOUS. ,True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455827811,"Can't argue with the facts that's why you call me names? Send it to the animal shelter if you have spare money and don't be a douche (again). I never said I want it back, can't you read? ",True,True
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410392065,"I've been a developer for 30 yrs (not open source where nobody can fire me) and all I can say is WOW.  I'll be sure to spread the word I had no idea HB's stance was who cares if source media can be properly read and if we can't catch ALL general failures, literally why would we test for ANY of them - even the most basic PROGRAM INPUT testing.  This is basic friggin I/O, not rocket science and you coded enough to log the issue, someone made a very irresponsible call to not call a total FAILURE TO READ SOURCE only 30 seconds in a success.  I hear Twilight Zone music. ",True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455815708,"Do you want to say you were offended by the reported bugs too, that could be fixed with changing 1 function to another to keep your software backward compatible (what a terrible idea to keep your software backward compatible, I know)? It's getting better and better. ",True,True
asmjit/asmjit/231,True,asmjit/asmjit/231/455813552,"For documentary purposes I'm attaching the whole communication here, because I think it's important for understanding the context. I thought about handling this differently, but I have a weird feeling that it ended like this in all alternative universes. I would also like to say ""sorry"" to the community. In my opinion this issue should have never been opened and the community of open source project should not be used as a jury in a personal dispute between 2 people. My proposal of fixing this is simple. Since I don't have the information to transfer the donated money back (no more PayPal), I would like to donate the same amount in BTC to some other open-source project on behalf of PELock. I thought about x64dbg as they seem to have a good relation with Bartosz and accept crypto. [So here is the communication] I don't think a comment under a commit is a proper way of establishing communication between us about something like this. I don't think making such communication public makes sense as nobody can verify what happened anyway, so what did you try to accomplish? I already calculated it (below) and just wanted to verify the final amount with you. I never said you haven't donated or miscounted the number of donations, so please let's not turn this into something it isn't. I'm not trying to play any card here. I'm trying to make us even in a polite way so we both can move on without a feeling that one owes something to the other. Remember that it was you who started this publicly. So if this stays public then I would like to disclose the amount as i think it's very important considering what you wrote in that issue. So as a result I want to return you what you have invested, because I disagree with your methods and the way you started dealing with it. You have no information about the number of donations that I have received nor their amounts, so please stop these speculations. For your own information - donations are symbolic to me - they are nice and I'm glad when somebody appreciates my work, but it's more about the appreciation than finance to me. I would not be working on asmjit or other open source projects if I wanted to make more money. I love sharing my work and I don't demand anything in return. After all of this I don't want to keep the money and that's what I'm trying to tell you. I don't even insist on sharing any details of the issue publicly if we can just resolve it quickly and quietly without further escalation. For me this is not worth it, it doesn't move the project anywhere, and it distracts me from other work that I wanna do. So please let's do the right thing to finally resolve this so we can move on. [[Reply - PELock]] Hello Petr, Is anything from this list false?  I have donated 3 times without requesting anything in return I have donated one time for the link (2nd donation) Fine, you could remove the link, I agree with that So why do you keep the donations list if I'm not there (just a name)? You don't want the money but you gladly accepted it back then  It just seems you're not very decent and honest person. I have supported many, many reversing and programming projects and this is the first time someone doesn't want to mention the donor just because he has the money now. This is another definition of low level. [[Reply - Petr]] I'm kindly asking you to read again what I have written. I believe the outcome would be different if we started the whole thing differently, but now it's too late to do that, because I just don't like where this went and I don't want to make it worse. I would really appreciate if you send me the IBAN so we can finally resolve this and move on. I'm asking you like third time and you keep only adding more stuff that I'm not interested in. I really don't understand why you make such a drama out of it. We have different opinions and that's it, life goes on, no need to judge others and complicate it. [[Reply - PELock]] Hello Petr, And I don't understand why is it so big problem for you to leave donors names on your page (I'm not asking for the link), does it hurt your feelings or what? Are you ashamed to take donations? If so and you want to be true to yourself you should remove this sections completely, because you don't even know how to handle it properly. I want you to keep the money and think how dishonest your actions are. You deserved donations back then, if I knew how vile person you are I wouldn't donate a cent to you. Please don't write to me again. ",True,True
openshot-qt/OpenShot/1619,True,openshot-qt/OpenShot/1619/326970634,open shot has been great but my most recent video never played when i hit play which made it difficult to cut and edit also when i was done and went to review the video would pause in the same spot every single fucking time it is getting to the point to were i dont wanna use the application any more and when i go to export it would always stop at 32% every single time and it would later say not responding and that was the first time to ever happen in all of my editing and i would open other projects and everything is fine and i know for a fact it is not my video cause i review my videos before i even bother editing so i just dont understand that why now is openshot acting like a piece of shit and not working properly cause i never had this problem before until today ,True,True
electron/electron/17171,True,electron/electron/17171/469345683,IT IS CONFIRMED THAT THE PROBLEM IS WITH THE PROMISES. I can print to pdf when promise is not used.Please fix it. ,True,True
termux-packages/termux/2735,True,termux-packages/termux/2735/413358276,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul) really as funny as you stated with your laughing emoji?  Both  and  are down with the latest Termux updates.  This is not funny @friend.  It's a headache for me to keep these projects running while I get, ""broken because it's NOT Termux"" from you and our PhD candidate. ",True,True
windowsserverdocs/MicrosoftDocs/1023,True,windowsserverdocs/MicrosoftDocs/1023/334755524,"Try to upgrade a GPT/EUFI hardrive to an SSD... Good luck, as MS, and SSD vendors don't even bother to try to offer solutions. Here's a new idea for a rare problem, that makes basic drive upgrades for hundreds of millions a high pain in the butt, while others exploit the OS in disturbing new ways.  Inconvenience consumers who attempt to upgrade storage and there is NO support to facilitate such a basic endeavor. Change for the better is great, but without a path for those who can't afford to throw away everything and but your latest project (which soon will be hyjacked-we know)  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 8cfb6a8b-c7e5-1bf6-0c24-2757871e9d07 Version Independent ID da5ffb60-d0c8-7117-02fe-7a3fd33169ac Content Change a Master Boot Record (MBR) into a GUID partition table (GPT) disk Content Source WindowsServerDocs/storage/disk-management/change-an-mbr-disk-into-a-gpt-disk.md Product windows-server-threshold GitHub Login @friend Microsoft Alias jgerend  ",True,True
windowsserverdocs/MicrosoftDocs/1615,True,windowsserverdocs/MicrosoftDocs/1615/368037517,"Not only does your on-prem software comes without documentation, and the links you remember to put within the apps aren't even for a direct resource, you still go on to hawking on and on Azure and go on without documenting how stuff is done with the undocumented bloat we pay thousands for.  Document Details ⚠ Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.  ID 428e9e07-ca35-27d2-e63a-92930cec0118 Version Independent ID 9a452a85-9afa-42d5-f319-bf1c4c50d01d Content Remote Desktop Services architecture Content Source WindowsServerDocs/remote/remote-desktop-services/Desktop-hosting-logical-architecture.md Product windows-server-threshold GitHub Login @friend Microsoft Alias elizapo  ",True,True
editor-layer-index/osmlab/574,True,editor-layer-index/osmlab/574/433628633,"I feel like you are not even listening to me.  This project doesn't have a version number.  It has a robot that just runs  for people who forget to do it themselves.  The robot introduces conflicts when people actually do run make. It's a ruby script that runs make in a Travis hook to smoosh together JSON files with python.  ELI might just be the hackiest nonsense I've ever seen.  This is not how reliable software is built.  ""Adding more checks"" is missing the point.  Anyone with osmlab rights could just delete all the files.  That we could ""fix it quickly"" is also missing the point.  I'm sure I'd be the person responsible for fixing it quickly. We will never take the autogenerated output on the master development branch of ELI and push it directly into iD.  Never ever.  Stop asking. Let's close this issue, so I can get on with my weekend. ",True,True
primitive/haskell/71,True,primitive/haskell/71/353921549,"@friend, I understand your general point about API instability, but in this particular case it's absurd. The API change that is holding this package down (implementing the  proposal) is one that was formally proposed on the library list and formally accepted and implemented. It is not going to be reversed before the  release. Moreover, even if it were reversed, there is no downside to supplying  instances as required. It is true that the way the  instances were changed in 7e6e7b4667020b61986c60e0c2d642e700e7966d is incompatible with (hypothetically) reverting that change. Making it compatible would be a matter of adding  where required. This issue is annoying everyone; please fix it. ",True,True
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/467448603,"I could have, but that wouldn't have been sincere. Those plush templates were an immediate turn off. If the maintainer has 18 years of experience surely they know how to interpret feedback however delivered. ",True,True
primitive/haskell/71,True,primitive/haskell/71/354236722,"nice tone policing + psych 101 course + insults from cartazio. Now can you let an actual real maintainer (close/wontfix/ignore/resolve) this issue ? I'ld like to know if we can expect to be able to test with non-final GHC 8.4; I personally have tried many time in the past to add non final ghc to my package builds and be stuck with unreleased primitive (or other packages), just like people commenting and watching this issue. ",True,True
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/467412051,"I’m sorry, but this is about one of the rudest tickets I’ve seen. You could’ve just asked asked how to use Go templates, but instead you decided to insult the hard work of a lot of people who do this for FREE. You don’t have to like Plush templates, but you also don’t have to be this rude and insulting. Read  and try to treat people with respect. ",True,True
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/414470979,"So I'm looking at your templating docs and there some notes suggesting Plush isn't required and honestly I never in a million years would consider using it because it isn't designed for humans. How can we switch to Go? By to add a header in plush (from the examples) To do the same in Go templates Please type both of those out more than once and let me know what human would ever choose the former. By the way, Vimeo is blocked in Indonesia. Please consider hosting your own videos. You can use Keybase for this if you need to. ",True,True
flood/jfurrow/758,True,flood/jfurrow/758/457907611,"I use docker, yes I build it from master everyday. Honestly my OS and version, etc don't matter as this is clearly not environment specific or version specific and I use docker.... I don't know what you are talking about with discord....I didn't message anyone. It's clear that development is all but dead and getting petty over issue templates when this is clearly an issue with enough info really puts me off. Instead of fixing things, you want to be pedantic over what are simple bugs. I'm done with this project. ",True,True
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368690688,"Anyway, to simplify this thread  Area      [W+50.5]    Toggle group status     [x] Territory [W+45.5] Don't like it since it takes up two lines instead of one.  Also, if the score has already been calculated, there is no need to calculate it again with the scoring tool.  Not sure what else to say. Scoring the game only makes actual sense if it is your own game, since finished SGF files already have the score in its result field. One can take an SGF file and start playing from somewhere in the middle with an engine and score the game their way.  I think the best way to avoid the double concern is to let the button show 'Details' and have another label to show the score for those who don't realize the 'visual affordance' I put into the button. In any case, I wanted some good reasoning to do something, not just a quote or a reference or whatever to a 'well-known researcher'. Controls which have more than one function are quite common nowadays. It's a great way to provide functionality without cluttering the UI. You just have to look at Apple's iOS, well-known for its design and UX.   While I appreciate everyone who takes their time with my projects, your second post wasn't constructive criticism at all despite your flimsy justifications and hit a nerve. Especially by referencing a book to avoid giving any reasons yourself raised a red flag in me. ",True,True
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368529038,"@friend Perhaps you have a suggestion instead of criticizing with a quote from a 16 year old book? (Actually, the book is 30 years old. I wouldn't be surprised if things have changed since then. But then again, I haven't read that book, so I can't say for sure.) Previously, the button would only display 'Done', but I changed it so it would display useful information instead of just being a waste of space. Also, the data for both area and territory are visible, just the end result changes when you toggle between them. I agree there is a property for specifying the ruleset, but it shouldn't have an effect on someone who edits the game. That's what I meant by 'no concept'. It's only there for reference purposes, like game name/date, handicap stones, and copyright. That said, we could display the value of the property somewhere in game info. ",True,True
zfs/zfsonlinux/7861,True,zfs/zfsonlinux/7861/418241114,"The question I asked was in regard to the lead developer of this project making a patch for himself to use on a catch22 in feature flags, and therefore not addressed to you.  Nor is it addressed to anyone else that is using a current version of this software, since the relevant patch is over three years old (and now deprecated). What makes you think I'm agreeing with anything you typed?  Don't thank me, I'm not. Thank you, for nothing.  I'd file a bug report about people with pedophile'ish usernames with such high exposure in a project that Canonical seems to care so much about, but your form is (predictably) excessive.  No thanks. For those who might find this on Google, don't bother with that patch/commit.  If your pool got userobj_accounting enabled it is now a Linux-only pool.  You'll have to destroy it, since per the (broken) explanation in the manpage, once active it cannot be decactivated.  Sort of like that Doomsday Machine that Slim Pickens was after.... ",True,True
PocketMine-MP/pmmp/1945,True,PocketMine-MP/pmmp/1945/359199958,"Let's remove anti-cheat motion, which delivers more of a pain in the ass. After all, it is also possible to add a plugin. ",True,True
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390037146,"Please fill out all of the issue template, don't delete half of it. ",True,True
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390037222,Somebody used this same template that i just used and your getting on me about it? ,True,True
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390037359,"you simply deleted the plugins section, and wasted two issues with no information on them. Fill it out properly. ",True,True
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390037567,Okay lol but you used the same template and everythings okay? How about you also do what you're telling me to do rather than just taking short cuts aswell. ,True,True
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390038360,Okay then fill out that long ass template just like we have to do rather than just taking a shortcut. ,True,True
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/458004816,"I had no idea who it was. that seems unnecessary. perhaps you were being unintentionally abrasive, as you were in the previous sentence where you imply I have easily hurt feelings. I'm sure you didn't mean to do that, right? then you can see how easily words can be misunderstood. however, more than once have you come and ask for input (maybe not ""help"", exactly) and then were rude to the people who were asking you for more information. criticising how they were attempting to help you. we are volunteers who want to help others. we don't want to deal with difficult people. bans aren't permanent, they can be removed.. sometimes bad things happen in life and we need to respond to them appropriately. people are known to have bad days. coming onto the issue tracker and claiming to withhold your help because of an unrelated incident is not an appropriate response to being banned from an IRC channel. I'd been curious who I'd abused so horribly that day and went back and found this I couldn't find any instances of being condescending or dismissive of any new users, though I did help save someone from redoing hours of work and then warned them about a potential issue. this is a part of a pattern of language from you that we have grown tired of. why do you think it's okay to call others imbeciles? who are you talking about? who is ""they""? I couldn't find this conversation. where did it happen? alright, it may have been a knee-jerk reaction. if you'd messaged me to work it out, things probably would have been Just Fine. interpersonal differences can be worked out, everyone in the project wants the same thing. the ZFS test suite is  very new  and has many deficiencies. testing every possible scenario is, as you must be aware, the impossible task. if you've found problems with the process, raise them specifically as new issues so that they can be addressed. I haven't seen anything until just now, but you don't raise any specific issues or offer any solutions, which seems less than helpful. but a lot of it has simply been spent waiting for a PR to be opened. if you're seeing it happen, why didn't you step up and submit one? is it because of the fact you've pointed out in the past that you consider our contribution process on github to be ""for hipsters"" and something you are essentially too good for? if you have any improvements you see you can make, please do so. otherwise you're just insulting the members of the project, again. any license violations should be raised with the project and fixed. can you cite any specific cases? I don't know what you're talking about. it should be easy to find cases where this is true if it's ""all over the place"". is it too much to ask you to not be rude to people when they give you advice? to not come on here and then insult everyone else's work - people who weren't even involved in your quarrel? for what it's worth, I'm not the one who's responsible for merging patches - there is but one gateway for this project to have patches merged. I can review, test, ask for changes, but that's where it ends. Brian is the one who merges the changes. I have to propose a corollary  to your question. how difficult is it to open a pull request? you mentioned back in early December you were going to open one. I deleted your comment here that only served to insult me and hold your PR hostage. if you don't want to submit the PR, don't - other users can do it when we find the time. it's a cooperative effort. you don't care to be a part of the project in the way we've required, and so your patch doesn't find inclusion. is this surprising to anyone? observation I don't know how long it took you to write your own comment here but it seems like you could have opened a PR in less time. this is another example of your pattern of disrespect. ""You are surprised""? who? not taken seriously? that'd actually be news to... well.. most of us, I imagine. I'm not sure I quite follow. you've seen users reporting data loss with a released build? would that be v0.7.10 that we marked as On Fire shortly after release and that was never included in any distribution? maybe an  related data loss back in 2013 from AIO write path errors? but that was never in a finished release. it might actually be helpful to have a list of data issues that ZFS has had in the past, similar to CVEs. ",True,True
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/457992782,"Eh, after reviewing that other issue where someone is calling for a Code of Conduct (which is a fairly dumb idea), I'm surprised to see that you assumed that person was me (perhaps the intention of the troll all along). Since this begs finally some proper attention, I will describe this issue (feel free to remove the comment later as you obviously are seemingly easily to have your feelings hurt regardless of whether the other person intended so or not...). I'll just clarify a few things I've never asked for help in the channel and treated someone ""poorly"". I responded ironically to ptx0's messages, after he spent the past few hours being dismissive or condescending to other people, obviously in some cases users with a very limited skill around ZFS, but that does not merit acting like an imbecile. None of them were insults or hostile, they simply pointed out that ptx0 was assuming things constantly and then replying with an air of arrogance and usually in a condescending tone, despite himself being far from a beacon of excellence as far as technical skill or coding go. Immediately after he proceeded to ban me from the channel, to which I responded in -social pointing out that his attitude and actions making him look puerile and petty regardless of the nature of the ""offense"" by someone else. This knee-jerk reaction came motivated more by petty personal sentiments (and sharing those with some others who, well, fit that profile) than any actually reasonable reasons. Now, on the project you are routinely accepting patches quite obviously without really doing your due diligence, ensuring proper QA, etc. Case in point, the one we have here. It's painful to see that you waste more time on petty nothings over actually making your code or merged patches look like something with a modicum of technical quality. The control over whether contributors are just copy-pasting from other spots (hint licensing violations get people sued), if the patches actually conflict with major kernel features, or symbol exports, or..... is lacking all over the place. How about instead of making up half-truths about people offending your feelings, or your buddies' feelings, you go and properly benefit from the resources you so adamantly defend (and ask others to work with) How difficult was it to grab the patch I sent you from the link, test it, test it again, sign it off and merge it? You need to go around deleting comments and engaging in conversation with the other troll, but you are too busy to actually merge an out of band patch while you waste time over petty fights? Well, good luck with that. And you are surprised ZoL is not taken seriously anywhere but by the homelab/non-enterprise crowd. If you want to be a primadonna, at least have the cards in your sleeve to back it up you can't justify it right now with the standard you are providing your users. And it runs in ring0, so go figure a better way to fend off all those users popping up on IRC asking about destroyed data because you merged a patch from a pull-request that would not stand a moment in the LKML. ",True,True
RasPlex/RasPlex/562,True,RasPlex/RasPlex/562/379350509,"Nobody listen to this fucking repo ( On Fri, 6 Apr 2018, 1953 Joseph Weigl, notifications@friend.com wrote ",True,True
flood/jfurrow/758,True,flood/jfurrow/758/457859780,Is it like this for all mobile devices? Is there no proper mobile views?? ,True,True
primitive/haskell/71,True,primitive/haskell/71/353686581,"I'm less than satisfied with this attitude Do you really think it is a good idea to tell hundreds of project to change their CI? What should people using stack do? Is it really that hard for a relatively small project at the bottom of the food chain to make a new release? It's totally clear that GHC's APIs are not frozen yet, but even if they change before the final release Just make a small fix and release again. Given this resistance, I really have a hard time seeing the value of GHC alpha releases... ",True,True
flood/jfurrow/758,True,flood/jfurrow/758/457859322,"Consider a smaller template, that is little much if want people to fill it out...for little issues like this. Also just be aware that no one gets the issue templates when they use a mobile device ",True,True
esx_policejob/ESX-Org/104,True,esx_policejob/ESX-Org/104/399112862,"you're useless, now fuck off ",True,True
electron/electron/17171,True,electron/electron/17171/469347803,PROMISE ALSO WORKS WHEN USED WITHOUT AWAIT..Please Check ,True,True
electron/electron/17171,True,electron/electron/17171/474130777,You don't care about issue and I wasted my time reporting this issue.I fixed it myself.Thanks for teaching me the rules and the ways not to help....Live in the rules and world of arrogance ,True,True
Terra/ObliqueNET/139,True,Terra/ObliqueNET/139/456904268,"Ras, why did I get banned for saying phone numbers in chat when I didn't? Idek any ones irl name, how tf am I supposed to know their number when Idk their irl name and last name? Like bruh, what's wrong with you? ",True,True
Terra/ObliqueNET/139,True,Terra/ObliqueNET/139/400348618,"Okay, I got banned for something I didn't do and the staff didn't take proof pics either. I'd accept the ban if I actually did something to get banned for, other than that, I say no, it's not right to ban someone for something they never did, but okay. ",True,True
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/285257204,"I can't believe that the main file of PyInstaller's .exe is not encrypted. My app starts from main.py, then this file import library1.py and library2.py. Using --key and --onefile options PyInstaller encrypts all .pyc files except main.py!!! It is very easy to obtain the source code from .pyc. This is unbelievable... ",True,True
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485104,"Man, if it's impossible to talk to you then so be it but then say so directly Because if the goal is to deny everything I say while I encountered a major problem with your setup then you are loosing my time but also yours ",True,True
esx_policejob/ESX-Org/104,True,esx_policejob/ESX-Org/104/399096546,No I don't write LUA is a useless language... your one to talk about getting mad but you are an example of your own shit player base. You don't offer any assistance to questions you just get pissed when someone asks for help. Maybe you wouldent have these issues if you actually supported your work assisted others in improving it rather then acting like the child you are ,True,True
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445486679,"that was rude so you were rude well before me, just saying. and again you are giving me details of your vpn container but you actually not understanding what I'm saying. And as I said, PIA gave you ONE ip and ONLY ONE because of your connection, that doesn't mean that the container which are behind this vpn container are receiving one! Gosh is that so complicated to understand? ",True,True
webpack-stream/shama/199,True,webpack-stream/shama/199/410837474,I thought that this first post of yours @friend was stupid.. but that last one just shows how retarded you are ,True,True
flood/jfurrow/240,True,flood/jfurrow/240/277031904,OP You can always use a basic auth before accessing the flood login #useless ,True,True
Signal-iOS/WhisperSystems/2540,True,Signal-iOS/WhisperSystems/2540/338758265,"yeah truly i agree with this bug , why the fuck i would c the last digits of my phone number in the debug report ???????? what kind of privacy shit we are talking about ? ",True,True
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401582377,"I deliberately waited a week before replying, because I wanted to make sure that I had a chance to look at this from a point of calmness. Every place that takes bug reports says, break your bug report up. One bug report per issue. Lots of tiny reports. A big report is hard to work with, because no-one wants to start it, because it will take forever to complete. Lots of tiny reports. Were my reports actual ""help, I need support, how do I solve this""? No. They were ""this is broken."". Mipmaps causing problems. Identified in a Forge pull request as mods doing the equivalent of a graphic state push, alteration, and no balancing graphics state pop. A Forge pull request to catch it and fix it by Forge so that you don't need to worry about fixing every single mod that's messing up. Definitely a mod bug, but no clear idea which mod was messing up. Now fixable with a Forge upgrade. (Entirely separate we are warned not to try to upgrade Forge ourself in this pack, because that will break something else). Flint not flaking every single time. Turns out this is apparently expected. Not every attempt to make a flake gets a roll, and you won't always succeed at your attempt. So you have to attempt multiple times, and you're going to have losses. This is not documented, but is expected behavior. A complaint about how items that you pick up off the ground go into your hot bar, and then get dropped as you move your mouse wheel. ""Works as intended"". I'm getting advancements that I haven't earned. ""Eh, we can't fix it"". The hiding of things that you can't detect failing in the case of ore samples. ""Known, but we can't fix it"". Oh, not closed as duplicate, not closed as can't fix, not closed as won't fix, but as ""invalid"". An issue where a new player does not even see the work stump, because of how the advancements are laid out. Along with the comment of ""Okay, now I see it"". Closed without comment. A follow-up report where I say, ""the flint pickaxe trio shows up well before the work stump, even though it cannot be made until after the work stump. This is confusing."". A response of basically, ""we can't do anything about this, this is how the person responsible wants it"". Another report about the Spear and Tomahawk being oddly placed in the achievements, and asking for flaked flint points to be made a tutorial-level item. Closed without comment. Reporting an inconsistency in the way that the spear and tomahawk display information compared to everything else. ""As intended"". 2 different reports about problems making use of just enough items features with work stumps. ""You just don't. You have to deserve it."" A report about getting information on Galactic craft at age 0, instead of something more appropriate (I'm guessing age 4). Closed without comment. A complaint about having to pulse attack to make planks. ""You tap attack on the chopping block..... stop wasting our time with these issues use discord...."". And in this thread, you made it clear that you thought I was asking for support. Not reporting problems. Please take a look at what I have written here tonight. Do you see how a new player, who has never seen this pack before, and is trying to play it through, is going to get very discouraged very quickly? ""That and most of them are Discord issues. This tracker is for bug reports and mod suggestions"" -- WHICH EVERY SINGLE ONE OF THESE IS. Discord is a horrible support tool. Compared to forums, Discord is a horrible support tool. There is effectively no history. There is no way to have any type of ongoing discussion about a topic. There is no way for people to comment on the same topic a day later, and be read and understood by somebody a week later. There is next to no ""pinned topic"" feature like there is in forums. You can pin single messages, but there's no way to respond to them. There is zero expectation that messages posted in Discord will be seen by anybody with the ability to deal with it. High-volume, high noise level, low signal-to-noise value, no organization, and nothing keeping track of what an administrator has/has not yet read, at least nowhere near the degree to which a forum does. ""We're not going to waste our own time when working on the pack and then deal with issues which no effort was put into them or could have been dealt with in Disord."" No effort? No Effort? NO EFFORT? Every single issue that I reported, excluding only the flint flaking, I mentioned how to work around the problem that I found. With flint flaking, there was no workaround because the only problem was the documentation. You complain that I don't put any time into this? I do. You complain that I don't make any effort to solve the problems on my own? I do. More than anything else, it is this dismissal that infuriates me. But none of this is the real problem. Let me restate that. TL; DR none of this is the real problem. ""But to be clear this pack was designed for Sevadus. It's designed around him and how he wanted it. Nothing will change in regards to the advancements or layout. It's done to a spec which we met."" This is the real issue. Do you not see it? Then let me spell it out. Sevadus is the one who has to approve changes. That means any issues with the modpack ultimately need to go to him. Not to you. Trying to report any issue to you is pointless; the only one that matters is somebody who isn't even here, doesn't read these reports, doesn't get reports sent upstream to him from you for his comments, and is completely out of the loop. So why is this issues thing even here? Why do you have an issues section on this GitHub, when ultimately you can't actually do anything? When you just want us to use discord? "" It doesn't help that SevTech starts off by giving you these books when you reach those points for free, and then stops entirely leading the player to believe there IS no book ..."". Well, no apparently, the first person on a server to reach an age where there is a book will get the books for free. Other players don't, and if they aren't aware that the mod has a book, they are clueless. Even worse, imagine seeing a whole bunch of new things show up in your achievements, and not seeing anything at all about backpacks. Absolutely no clue that backpacks have opened up for you. In a modpack that basically triples the number of items that there are to collect. That you need. When your chest/storage space ability has been crippled. ""I'm in age 4 and pausing the game to go spend half an hour googling information that isn't obvious or clear to me in order to progress or acquire something exceedingly valuable is simply par for the course at this point. I've gotten used to it and I never thought about how stupid it was. "". Isn't this basically the point of a quest line? Sorry, an achievement line? I was ready to give up on this completely. My friends basically apologized for rushing through, and rushing ahead so quickly. One of them got to age 3 in a solo world, (during her time off from medical school), and introduced this pack to the rest of us. Another got to age 2 in a solo world in something like 10 days. (As he says, he has no life). The 2 of them worked together with the 3rd person, and they all got at least half way through age 0 during the first week of part-time play while I was still trying to connect my own machine. I tried to progress on my own, trying to catch up with them. By the next weekend? The one with no life had split off from the rest of the group, made his own base, and advanced to age 1. I was struggling with basics. By the end of that weekend, no life was up to age 2, everyone else was up to age 1, we had a teleport network built between our bases, I was trying to make string (and at this point I don't even remember what it was that I needed the string for), and was trying to put down enough torches to safely light up our area, only to realize that instead of one block of wood making 8 sticks making 32 torches, one block of wood might make 6 sticks which makes 2 torches. And a mass of giant trees took more than 3 work blades to de-leaf (because you get more sticks from work blade de-leafing than you do from decay), absolute full of pain and anguish, taking a massive amount of time, and only later do we discover that there's apparently a tool in age 0 that takes the leaves off of a large area of trees in almost no time. If it was just me, I'd already be gone. My friends have convinced me that the pack isn't quite so bad if you have someone to lead you through it, and the other comments in this thread tell me that other people need to be led through it. So the quest line/achievement lines are not sufficient, and the person who made this pack is happy with that. That stinks. I'll probably make videos of my play through and learning, with the goal of being a ""how-to"" for the people who come after me, because this pack badly needs it. ",True,True
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/335083459,"     Context I am trying to give feedback on what the pack is like for a new player, who has not played it before. I suspect that you have gotten so familiar with the pack that you don't even think about the experience of a new player. The most important player you have is the new player. If you do not get new players, you wind up with a declining population and eventual nothingness; additionally, new players recruit other new players. As a new player, this is what I have seen, that really seems to define the pack for me Go to a kitchen counter (you can do this as a thought experiment if you want), and clear a meter square surface. Use some tissue paper (or toilet paper), and divide it into 1' x 1' squares. Stand in front of it. Now, keeping your eyes straightforward, move your neck to where you are looking around at all 9 spaces. Notice how much head movement you have, notice how much work is involved. Now, just look at the whole table, and move your hand around all 9 spaces. Notice how much easier it is? This is without taking into account that the mouse movements needed to aim where you are looking at for the 3 spaces closest to you are actually much more exaggerated than for the others. An ""in-world crafting table"", or ""non-GUI interface"" is not ""more realistic"". It is denying the use of hands to do things. It is taking the worst choices of the interface and controls of Minecraft and magnifying their effect. And it completely eliminates the concept of saying, ""I'm focusing on the crafting table, I'm using my hands to place things on the table, and I'm going to look things up in the recipe book"". Good or bad, you have basically chosen to document the modpack and its recipes with JEI. And that documentation is lost as soon as you are using the work stump. The mod page for primal tech (work stump mod) claims that it has JEI support. Yet I don't see it in play. Now, let's look at these work stump, wooden hopper, chest, shelf (cupboard), water strainer. The basic operations on stores of inventory items are deposit one, deposit stack, remove stack, remove one, remove half stack. The documentation for what key/mouse commands do what is nonexistent. Each block seems to have a slightly different set of controls than the other blocks, and none of them are documented. If you make a mistake with the water strainer (taking out too much), you can't put the others back. If you try to take one repeatedly from either the wooden hopper, the chest, or the shelf you wind up placing the block that you just took out (because the control used is shift-place). Etc. (and why does the water strainer have an inventory GUI when nothing else at this tech level does?). ""Nonintuitive"" only begins to describe the pain of this system. I haven't even gotten to the strangeness of saying that there is an item you can craft at tech level tutorial that includes an item you can't understand, that can be made ""in hand"" in your 2 x 2 but not on the work stump. All of these ""in world"" non-GUI blocks essentially restrict you to only those items that you have room for in your hot bar. None of the rest of your inventory space is usable. My hot bar is almost always nearly full in normal play, and even so far in the pack I don't have much space in it. I want to bring up the issue of the chopping block again. I complained about the behavior of the chopping block. I was told, ""You tap attack on the chopping block..... stop wasting our time with these issues use discord...."". Nowhere in the documentation that I saw -- not the pages for the mods, not any instruction in the achievement tree, no tooltips for the chopping block, nothing -- is the ""tap attack"" mentioned. And this is so much in line with everything else in Minecraft, that you see this tap attack used ... to pick up mine carts. And I think only to pick up mine carts. It isn't the norm, I am used to other mods that distinguish between your activities based on where you are pointing at -- heck, vanilla will rely on where you are aiming when it comes to placing stairs or slabs -- and to have my ""bug report"" (and the behavior did seem very buggy and exceedingly nonobvious) dismissed and closed with that remark seems very much ""anti-new player"". And ""stop wasting our time""? Do you have any idea how much time I have been spending trying to find something worth playing in this pack? Do you have any idea how much time I'm spending reporting the problems and flaws I'm running into as a new player? Do you have any idea how much time anyone else that tries to pick up this pack is going to spend trying to deal with the interface strangeness? My observation so far is that while there appeared to be a very large amount of things to do in tech level tutorial, the reality is that the arrangement of the achievements is highly misleading, and tech level tutorial is really tiny; most of it is actually tech level 0. But even in zero, while there appears to be many things to do, all that really matters is the ""advanced to the next tech level"" path. Let me repeat that I am being trained, early in the game, that all that matters is advancing to the next tech level, and everything else at any given stage of the game is pointless. You have gone to a great deal of effort to make these tech levels, put content in them, and all I am learning is to skip them as quickly as possible. That's just bad. I like the idea of a detailed progression pack, complete with an actually complete progression chart. The last time I saw something like this was Jaded's packs. (My only exposure to non-vanilla skyblock was agrarian skies, and an entire section of her quest lines was a chapter on how to skyblock.). I have tried playing other quest packs that did not actually have enough information in the quest lines that you'd have any idea what you were actually trying to do or how to do it. I really do appreciate the large amount of effort (and having tried to make a quest pack once myself, I do mean that I recognize and appreciate the large amount of effort). I have been told by my friends -- both the one who encouraged the rest of us to play this, and the other one that has gone crazy with the musical ceremonies -- that the pack gets much more interesting once I get to the musical ceremonies. I've even discovered that there is a bit of balance issue -- a single person trying to generate enough music by themselves will have trouble on some of the more complicated ceremonies, but 4 people playing music together will find that all of them are trivial. I like the idea of being required to learn mods that I normally do not use -- because there actually is an in game training for these mods, which is usually the point missing from most mods. But if there is no reason to stay around at a given tech level, if the goal that I am learning is ""just advance to the next tech level, and get access to better, more advanced and more powerful mods"", then why? Would I recommend this pack to anybody else? Not based on what I've seen so far. Why am I trying to continue playing this pack? Only because I have 3 friends at tech level 2, and they are waiting for me to catch up so we can play together. And I'm going to ask them to put a standard chest, and a standard crafting table in my room so that I can at least reduce the amount of pain that I have while playing (and I'm going to take advantage of the fact that they already have a horse powered chopping block set up so that I never have to worry about that tap attack issue again). Or, you know, just rely on the fact that I have a water strainer to give me all the planks I need. How does that make any sense anyways? ",True,True
SevTech-Ages/DarkPacks/2607,True,SevTech-Ages/DarkPacks/2607/391451401,this forum sucks ass ,True,True
platform/ngrx/1248,True,platform/ngrx/1248/413497951,... assholes ,True,True
platform/ngrx/1254,True,platform/ngrx/1254/351147160,Your software is an undocumented trap to extort money by selling courses and books. You're pieces of shit that need to die in a fire. Go fuck yourselves ,True,True
helm/helm/5439,True,helm/helm/5439/420124208, Why is helm such trash?  What are some alternatives to helm?   ,True,True
grunt/gruntjs/1646,True,grunt/gruntjs/1646/405621328,"@friend  ""issues are related to grunt ?"" what did  I post about? ""GRUNT"" in LXD Container.  And what do you mean by ""This is not a support channel"" . I never asked you to do my homework. And whatever I said is an Issue as mentioned by @friend , its the problem with concurrent. And fortunately fixed it. Next if ""YOU"" are not familiar, please be quiet and ignore the question. Let some knowledgeable person answer the queries. ",True,True
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/414838423,"Hi! Looks like you didn't read what I wrote, or didn't understand it. So, I'll piece by piece break down the wall of text there and explain what I'm trying to say. First off, I'm not accusing you of trickery, I'm highlighting your naiveté in hopes that in the future you put more value on the people you're working with. Second off, there is no company. You have no company. You have an idea, and an idea is worthless without execution and followthrough. When you tell someone they'll get 5% in a 11 partnership, that is a miserable deal for what will be weeks (to months, and even years!) of hard work that in a major city earns you a salary and equity in a tco package ALWAYS north of $150k a year. You're not forming a partnership, you're bald-faced trying to fuck them. Take a look at examples of historical and modern startup equity among co-founders.  Jobs convinced Steve Wozniak to take something like 30% ownership in an early Apple. It's widely accepted that Wozniak got capital-f fucked by that. You are not Steve Jobs. By the way, you are absolutely right that's exactly how ""how all the biggest companies in the world run their businesses"". Facebook employs around 25,000 people. How many do you have? Next, there is no ""owner"" of an idea. It's an idea, unless you patent it, in which case you get about 15 years of protection (good luck patenting any variation on a social network, by the way!). There is execution of an idea. You, by yourself, are incapable of executing or else you'd be building it. I made this account as a disposable account. I hope you can appreciate why. Call me a coward, but I don't care to taint my professional reputation. I see listings like this all the time and ignore them (as many other people do), but never as vague and boldly ""I'm an idea guy"" as this. And yes, we have a term for people like you idea guy. It's derisive. ",True,True
officer/davidgohel/141,True,officer/davidgohel/141/400953258,"I asked you to explain ""does not work"". I won't ask a third time, I don't have time for that. ",True,True
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446795711,seriously? cuz you are asking for help and im telling you something might help and you question it. dont expect anything further from me as you cant seem to bothered you even help yourself without being an ass ,True,True
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446810586,"Assuming you made 100% false assumptions, this is something that has only just happened. I don't have any issue with any other Dino being tamed and it is only the Tex Rex at this stage that I have noticed it with. The current level is its post tamed level and I do indeed have a 100% tame on it. Like I said all the GREEN parts are 100% correct, I DO NOT HAVE ANY ISSUE WITH THE SPINO'S that I have added, I DO NOT HAVE ANY ISSUE WITH THE NORMAL REX'S that I have added. And this was not an issue a few months ago, so why is it an issue now!!! And I DON'T SEE WHY I NEED TO POST A SCREEN SHOT OF THE STATS WHEN THEY ARE 100% CORRECT. Seriously the support from everyone but the author  is becoming a joke in here now. ",True,True
mapbox-gl-js/mapbox/7158,True,mapbox-gl-js/mapbox/7158/352352721,Is there a existing plugin for clusters  I can use to ignore fucking styles and whole screen of circles? Leaflet Markercluster is useless!  ,True,True
ludwig/uber/184,True,ludwig/uber/184/471032466,"I have read the damn docs! They are obviously not clear enough, at least on my problem. Being Ludwig promoted as easy to implement as it is, I was expecting a little quick help instead of just saying read the docs like a robot. For now I'll wait until Uber hires someone who can respond to my questions properly. ",True,True
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3497701,"Well, by ""PAYING F*CKING ATTENTION"" you could have specified your pull requests against the branch and allowed for a one-click merge on the website. Close this ""issue"" already and let them get back to real work... ",True,True
classroom/education/1678,True,classroom/education/1678/432795426,"Sorry but I must disagree, misbehavior comes not from github itself, but from interaction with classroom. It's blocking/limiting use of your classroom software. Yes it is on the borderline but just saying it's not your problem and closing issue is not constructive. ",True,True
Aether-Legacy/Modding-Legacy/341,True,Aether-Legacy/Modding-Legacy/341/458447977,no they spawn directly in front of you same for alot of the mobs you made a crappy port I am tempted to make my own port ,True,True
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463041522,"I guess I don't like that you have no friggin idea what you are talking about.  For those who know, it was 229322b00717a4c75f8425923ec4ed948e2142b5 causing the issue. ",True,True
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446811141,"And instead of arguing about what I haven't show, when I have been suing this program for 3 years and never had issues on my server to this extent, that I am dealing with people who refuse to acknowledge that I have stated the GREEN sections in the image are exactly what is on this Tek Rex. But you know what I should post it just to show how much time has been wasted chasing something that is not even the issue. ",True,True
Contentify/Contentify/398,True,Contentify/Contentify/398/403034224,"No I blame you that since more then 24 hours I have nothing but problems with this. And that just because you didn't wrote a capital C , but instead a lowercase one ",True,True
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/393819419,"If you want to make it quicker you can allways provide the code here and I Will implement it in seconds. And if not, after telling you that I Will do, you come here with hurry and get dissapointed because I tell you the priorities of the mission development????? May I say that I am not your fucking slave or is it incorrect? ",True,True
mojo/kraih/1236,True,mojo/kraih/1236/404133702,"Wow, just ""closed the issue"" as a non-issue? That's mature D ",True,True
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/463821912,"This has to be the most unconstructive issue post on here, I have ever seen ( 👎 ",True,True
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432269902,"Impressive! I searched all your issues and found 2 unresolved closed by inactivity. After a question, the admin decided not to answer but thanks so much it was very useful. If you could link the so called original of my question, please do Make sure you know how to answer before telling ppl to search before ",True,True
bootstrap/twbs/13476,True,bootstrap/twbs/13476/41935591,Hi @friend thank you for your ever useless explanations. ,True,True
Contentify/Contentify/398,True,Contentify/Contentify/398/403030035,And also thank you for being in the EU and not following the laws. Read it up kiddo DSGVO ,True,True
courseplay/Courseplay/3245,True,courseplay/Courseplay/3245/411054856,"What an unfriendly and rude forum. I will never post a mistake here again. As I said, unfortunately I can not read Enlisch and thus not scour the forum. ",True,True
classroom/education/1678,True,classroom/education/1678/432796979,"I feel I am not the one that has to setup collab with github services to get them to ackowledge problem, from my pov it comes from use of ClassRoom not github.You're all the same company, sort it out, or not and we look for service elsewhere. ",True,True
Contentify/Contentify/398,True,Contentify/Contentify/398/338891837,"So I installed this for a friend, and already at the installation I noticed that much stuff doesn't work. The current release version has errors with the apache_get_modules function, which is disabled due to security reasons, the script wants access to the php main directory, which a php script NEVER should have access to. And after I gave him all this, I just get that  What the hell. ",True,True
mame/mamedev/4801,True,mame/mamedev/4801/479505881,"This is not the real reason your are giving a ban, it's to hide your own incompetence again, and again and we can go on and on, how many times you are gonna close legit reports to dealt with it later? This is what happens when you give a nobody like you some power, they like to show off and oppress other people, to shut people off, you are disgusting and a coward. What you are gonna do now? Delete messages like you did before? It doesn't matter the lame excuse you've gave, it doesn't change the fact that the script it's passing the wrong path to the compiler and #4789 it's breaking MAME memory space . And don't get me wrong, I know how to use a issue tracker, in an organize project, the issue it's acknowledge, tagged and dealt with latter. If you or any other dev will handle it now, tomorrow or 10 years from now, I don't care. It's a damn bug report and not a help request. Why all the drama about it, what are you afraid of? Respect it's a thing we earn, you give respect you shall receive it, if you come towards me in a disrespectful manner I'll shake you off my way and I don't care if you are a fruit cake or a snow flake or whatever generation name you people call yourself this days. Don't expect me to respect a sick, mental ill and suicidal person like @friend that like to attack and persecute people for unknown reason.  is the kind of person you give authority to and allow him to take on other people. ",True,True
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446812317,the servers wild level is 300 and I am very well aware how that all works. Seriously!!!!!!!!!!!!!!!! ,True,True
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/454181430,"Hi @friend, thank you for reaching back to me I have to say I am a bit surprised by your team answer though. Did you consider the security risks associated with the current state of your software? If all Community Edition deployments and Enterprise Edition streams that do not use the Token Control feature are vulnerable to stream hijacking, I believe you have a responsability to fix that. Your current stance is ""our software is insecure, but you can enable a paid option to make it secure"". And even when paying, the token thing is still optional! That's simply not acceptable, especially since you're not advertising this huge security risk anywhere. We're not talking about enhanced, nice-to-have security here (like with two-factor authentication which could be a paid option only), it's about basic, indispensable security for publishers and viewers! Thank you for the code samples, but there is no point in implementing a workaround to secure your software if you're not planning to secure it yourself in the end. If it's really that simple, to fix, I think your team should take an hour or two to implement this fix and protect all the people using your software. ",True,True
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446812998,"And because you are not listening and going on some wild tangent rant about what you think Here is a list of Dinos, tamed and show the correct Wild Level  ",True,True
DSharpPlus/DSharpPlus/282,True,DSharpPlus/DSharpPlus/282/321360868,"You guys harassed me over PascalCase with ""someone"" being verbally abusive and saying I needed to get help because I showed him my programming trophy. Being rude is one things, being delusional is worse. I get it. You guys got intimidated by me but stop making up shit. ",True,True
addons-frontend/mozilla/7881,True,addons-frontend/mozilla/7881/432603741,"Yeah, so... the whole Mozilla can go fuck itself. ",True,True
bootstrap/twbs/19636,True,bootstrap/twbs/19636/202909411,"do you want also french fries for that ? -- No, Setting dimension (height) to """" works for me. ",True,True
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449939967,"ZFS is slowly becoming ""the systemd"" of filesystems and it is because of feature requests like this (and #6836, #6041, #4134) Is it too hard to type ""-O compression=lz4"" once in a blue moon? No, it is not. Does your job require typing ""zpool create"" all day long? You can script it with something that fits your needs. Once again we see a great product of engineering being pushed around by the some members of its community. I can't wait to see ZFS/systemd integration via D-Bus /s. ",True,True
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3497690,Shrug. Perhaps @friend  should actually bother looking at the f*cking diff. They were all small changes. ,True,True
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388622441,"Ah... A typical п'явка - you want to tell me what to do with my time, but are not smart enough to fix the problem yourself? Surely you could try, you don't have the looks to be this stupid. ",True,True
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456842512,"Hey man what's wrong with you? Seriously. A simple no would work fine, you freak. Me and a friend reproduced this bug but forget trying to help you fix anything anymore, loser. ",True,True
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401723647,"&lt;img width=""403"" alt=""2018-07-02 17 57 04"" src="" ""0.4"" is a bug.  It's document for latest version. Because it seems you didn't use your time enough to read code, past issues, etc. Only contributors who can survey themselves can contribute. If I need to teach everything, it's not contribution.  It just bothering me. ",True,True
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709698,thats not cool ,True,True
modmail/kyb3r/49,True,modmail/kyb3r/49/339655342,"This is a terrible modmail. I don't know how to check the mail, everything is hard to setup. The bot goes offline randomly, the game status always disappear, it doesn't even respond and it is too complicated to setup. Do not ever use this bot to mod mail, trust me. This is terrible and the owner never answers ticket because he did no shit to help and not a great developer. Don't get this, trust me. You will have a hard time and I know how to setup bots. But this crappy bot is terrible. ",True,True
mame/mamedev/4801,True,mame/mamedev/4801/479510105,"I'll report you too @friend, for all the internet to see how disgusting and abusive you are.♠#mamegate` ",True,True
mame/mamedev/4801,True,mame/mamedev/4801/479455833,"@friend between this and #4789 you've shown that you don't seem to have learned anything about how now to use the issue tracker, and how not to get developers off-side.  You're getting a 6-week ban for this. ",True,True
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463038807,So many complaints but not a single log posted... ,True,True
bootstrap/twbs/19651,True,bootstrap/twbs/19651/205013041,or you could have answered it here you fucking twat ,True,True
Contentify/Contentify/398,True,Contentify/Contentify/398/402999274,Ok I found the mistake. Ever heard of case sensitive? Apperently not ,True,True
mame/mamedev/4469,True,mame/mamedev/4469/451357853,"Does it make sense to make a report about a version from one year ago? From last weak, from yesterday? NO! Even if I use such old version people will tell to use the latest, if this is not obvious to you it's because you are so damn stupid to figure it out by yourself. Don't be such a dick @friend because the post was already tagged duplicate and closed by me. ",True,True
pypi-legacy/pypa/759,True,pypi-legacy/pypa/759/357006793,"@friend Thank you for your thoughtful response. @friend, Thanks for your feedback! PyPI does not currently and does not plan to implement any policies regarding removal of packages based on their perceived quality. Once PEP 541 is implemented there will be recourse for abandoned projects, name conflicts, and legal issues. ",True,False
pypi-legacy/pypa/759,True,pypi-legacy/pypa/759/356918767,"You seem frustrated, and I can understand, but I think that calling the package ""fake"" and ""next to worthless"" is a bit of an overstatement. It may cause issues for your particular installation (in which case, don't install it! 😄 ) but it's a package that someone worked on and contributed to the community. It may not do much that you find useful, but it does something. The package's description states that it is a ""Command line to private gist. Example gi.py myFile"". From examining the code, that appears to be exactly what it does. Saying that ""everyone would benefit"" if it was deleted may be an expression of your frustration, but is probably not accurate. That's a common issue for packages on PyPI, not at all unique to this one. Could the metadata for this package be updated to reflect its state better? Sure. But at the time it was published, pip didn't support  so there was little motivation to do so. Package name conflicts are a common issue, and not one that (outside of the standard library) PyPI usually has any role in. The solution is to not install conflicting distributions. 🤷‍♂️ It does appear that the original repository has moved, but the owner still exists at  Perhaps you could try contacting them through one of their other repos about this package. ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355040521,Nice attitude. You bypassed my request to change documentation. Not always a developer need code encryption for ear money... I will do a lot of copy and paste of the link to this bug. Bye all ,True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355031525,"If you want this to be fixed, please place an adequate(!) bounty or submit a pull-request. The requirement for byte-encryption is a commercial one (free software does not require byte-encryption since the cod is available anyway). So if you are earning money with using PyInstaller you should take parts of the development. ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355029783,"That is a different problem. Here the problem is not a bug on PyCrypto but in the logic of PyInstaller. The ""launcher"" of the application is not encrypted because this file is not on the pyz archive. This behaviour is wanted. It is not a problem at all if you change the documentation and write there that the code inside the main file is not encrypted. In this way a developer won't insert a ""critic"" code in the launcher but only a little piece of code for launching the application ;-) ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355027317,"Please see the ""maintainer note"" in ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355017293,"He wrote that in a Python application the main.py file is not encrypted, why is it a poor description? By the way I did a test and this is true. The main file, so the ""launcher"", is inside the .exe without .pyc extension. It has the name of the .exe file. With few minutes you can easily obtain the source code. This is a problem ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355015874,"@friend Sorry, I apologize. It's the tone and the report is of poor quality. Why should I spend my spare time on this? ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355010710,I'm not the autor of the issue. Did you close a bug like this for the tone? ,True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/355005439,"I closed this issue due to your tone/inflection If you want to submit a bug-report, do this properly, esp. providing details. ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/354886154,"Are you serious?! -| Here  is this ""To encrypt the Python bytecode modules stored in the bundle, pass the --key=key-string argument on the command line. For this to work, you must have the PyCrypto module installed. The key-string is a string of 16 characters which is used to encrypt each file of Python byte-code before it is stored in the archive inside the executable file."" Do you understand the statement ""each file""??? This is a bug, if you close the problem with your answer you are not a serious man. The problem here is not that also with encryption it is possible to extract the key in order to obtain the source code, but that you close a bug in this way... ",True,False
pyinstaller/pyinstaller/3160,True,pyinstaller/pyinstaller/3160/354804111,"Indeed! How foolish are these developers, they should be paying for not implementing this properly. Or even better, be put in jail! ",True,False
primitive/haskell/71,True,primitive/haskell/71/354363929,"@friend I'm not sure your comments are driving this conversation in the right direction. You might reasonably argue it's not in the place it should be, and I appreciate the temptation to vent, but let's not make that this issue. @friend This bug refers to an issue that is still open, but has now been closed. I appreciate you don't want to get into a war on a bug thread, but closing bugs without saying why confuses us who report them and want to know when they are fixed. Concretely, to answer your questions I want to test with GHC 8.4.1. I want to test using my CI. I want to test exactly the same way I've tested every GHC release up until now, unless someone offers a compelling reason that a better approach makes more sense. I want to test because people asked me to test. I want to know when the issue is fixed, and thus I want to subscribe to a github ticket. I want to know if you plan on fixing this in the next week or so, only once GHC 8.4 is in Beta/RC1, or at some other point - so I can plan what I do in response. I am grateful for the work everyone does maintaining the infrastructure and packages, this one included 😄 ",True,False
primitive/haskell/71,True,primitive/haskell/71/354133924,"I’ve locked the thread to prevent more drive by non constructive remarks. Positive reinforcement and collaboration are way more effective way to motivate folks, and honestly framing your heated remarks in terms of personal feelings or motivations would be more constructive than how some posters have approached it. Hypothetical positive remark “I would really like to test ghc 8.4 alpha with vanilla hackage and a release of primitive , because for structural reasons I can’t edit my cabal config in my homedir  to point to two package sources even though that’s supported. The reasons why I can’t include xyz. Additionally I want to make sure my software works on day zero of the final ghc 8.4 release and better sooner than later )“ I might be totally wrong on that last point but I do believe you can have your cabal config in your home dir point Either way, valid perspectives have been articulated, but drive by commenting isn’t actionable, and if not done in the right way can be demotivating. Vincent your comment did not add anything constructive or new. Shame on you.  You just did a more confrontational exaggerated version of what was already reasonably articulated by Neil and David. Happy New Years all, I’m off to visit my younger sister for a week of rest.  Use positivity and positive reinforcement to motivate folks. And in the future please  explain why tools like hackage head aren’t effective options for you to test libraries on an alpha quality compiler release please.  Explaining WHY in terms of actions or work flows or implicit needs we don’t know about is helpful. ",True,False
primitive/haskell/71,True,primitive/haskell/71/354131832,I’ll see about getting primitive in shape in a few days.  Right now this thread isn’t helping in a positive way. ,True,False
primitive/haskell/71,True,primitive/haskell/71/354082694,"@friend not that the issue has anything to do with stack but ... considering the amount of work for creating and maintaining (tracking all git repo update) a stack snapshot for something that is ephemeral, I think the likely outcome is that it won't happen, lowering the amount of testing GHC alpha gets and the feedback GHC Devs gets back. Even if that stack snapshot happens, who will sweat to add this to their travis which will have to be undone once 8.4 is released ? I think if you don't use the same mechanism of delivery for everything then you're making the testing bar way too high already. Clearly if there's no release of  (and other basic packages), I don't think anyone should bother with alpha or beta releases (haskellers or GHC devs) compared to say, testing GHC git repo directly. ",True,False
primitive/haskell/71,True,primitive/haskell/71/353893173,"CAbal supports multiple package dbs. What’s wrong with hackage head? On Mon, Dec 25, 2017 at 238 PM Neil Mitchell notifications@friend.com wrote ",True,False
primitive/haskell/71,True,primitive/haskell/71/353887505,"@friend yes, they could, it’s a great time idea - but probably orthogonal (I certainly don’t use stack for alpha testing) ",True,False
primitive/haskell/71,True,primitive/haskell/71/353884834,"Doesn't  support custom snapshots. Could stack users collaborate and make a custom snapshot with git dependencies to ""supposed to work with GHC-8.4.1-alpha"" commits? ",True,False
primitive/haskell/71,True,primitive/haskell/71/353857574,"Are you saying ""this package will be released after Christmas"" or ""this package will be released once GHC is in beta""? Is GHC HQ saying ""put this alpha through its paces"" or ""it's too early""? CC @friend, as I feel this impacts the GHC release cycle speed quite a bit (still working out the kinks in the new process, so no great shock at this stage!) Happy Christmas! ",True,False
primitive/haskell/71,True,primitive/haskell/71/353705320,"when did these hundreds of projects add alpha release ghc to their CI? either way its an alpha release and its high holidays in several continents, be patient and enjoy time with friends and fam.  anyone testing software out when its hot off of alpha tags can be a tad patient ) merry xmas ",True,False
primitive/haskell/71,True,primitive/haskell/71/353671219,"Agreed and better said than I ) On Fri, Dec 22, 2017 at 247 PM Herbert Valerio Riedel  notifications@friend.com wrote ",True,False
primitive/haskell/71,True,primitive/haskell/71/353664000,"GHC 8.4.1 is currently still a moving target and it's too early to release to Hackage (and I personally advise strongly against; Hackage releases are intended to be durable). Fwiw, I devised  so we wouldn't need to make releases for an unreleased GHC, even less so for an alpha release for which GHC HQ gives no API stability guarantees whatsoever. I for one won't make any releases specifically for GHC 8.4.1 support before the first release candidate of GHC 8.4.1 hasn't been cut (and thus its API is frozen). ",True,False
primitive/haskell/71,True,primitive/haskell/71/353657636," and Dan are the two active uploaders at present On Fri, Dec 22, 2017 at 202 PM Carter Schonwald carter.schonwald@friend.com wrote ",True,False
primitive/haskell/71,True,primitive/haskell/71/353657365,"I’ll check with the rest of the maintainers and we’ll make sure to gift yah with something nice for Xmas @friend and Ryan any thoughts ? On Fri, Dec 22, 2017 at 553 AM Sven Panne notifications@friend.com wrote ",True,False
primitive/haskell/71,True,primitive/haskell/71/353574170,"I would very much appreciate a Hackage release working with GHC 8.4.1 alpha, too.  has a lot of reverse dependencies (224 direct ones), even more if you consider them transitively. As a consequence, quite a few popular packages like  are broken right now with 8.4.1. I don't think it's a sensible solution to tell hundreds of dependent projects ""Hey, just fiddle around with your CI scripts..."". ;-)  is very near to the bottom of the whole Hackage dependecy tree, so it would be a pity if it delayed tons of other projects. IMHO the whole point of the GHC alpha releases is to fix such breakage early, so we have a healthy ecosystem when the final release comes out. ",True,False
primitive/haskell/71,True,primitive/haskell/71/353456920,"@friend - why not release this package to Hackage now, so people can just use hackage? I personally don't know what it takes to use Hackage head, and have little enthusiasm for plumbing it through all my CI scripts... ",True,False
primitive/haskell/71,True,primitive/haskell/71/353456554,"Use hackage head.  It has everything building for head On Thu, Dec 21, 2017 at 322 PM GeorgeCo notifications@friend.com wrote ",True,False
primitive/haskell/71,True,primitive/haskell/71/283993879,In case anybody wants to get started with this  primitive-0.6.2.0 doesn't compile with ghc 8.4.1 alpha ,True,False
platform/ngrx/1248,True,platform/ngrx/1248/412593101,Support questions should be asked on stackoverflow (with a ngrx tag) or the gitter channel. ,True,False
platform/ngrx/1248,True,platform/ngrx/1248/350114476, doesn't receive data. Where do you initalize loading from http api? Your example app doesn't show so many things. And again all resources are behind a paywall or don't explain anything. The ... browser plugin shows that the store is populated with data. Why is there no data displayed? ,True,False
primitive/haskell/71,True,primitive/haskell/71/354366152,"This isn't every ghc release until now -- it is an early alpha release, which is a new thing, part of a new release process  libraries were released in conjunction only with the candidate phase of a release. The new process was not intended to also have more libraries released for the alpha phase. Rather, the overlay package index is currently the recommended way to deal with it, as per  this wasn't the case, we'd potentially have a ton more package releases, a number of which would not be particularly compatible with any properly released version of GHC. This new alpha ghc release is uncharted territory for everyone. As per the announcement this is way earlier than normal -- the fact that we can test with it at all is forward progress. As such, this isn't a bug. It is a disagreement over the new alpha release process. Those who want to weigh in on the alpha testing process should probably do so on the ghc-devs list. ",True,False
primitive/haskell/71,True,primitive/haskell/71/354366594,"I've been tested with GHC HEAD for many years, and releasing packages to Hackage specifically to deal with GHC HEAD. To me, the process still hasn't changed (although I appreciate it has to the rest of the world). If the decision of the primitive maintainers is to not release until GHC goes into Beta, that's fine, but the resolution of this ticket should be ""Open"" and the comment should be ""We'll fix it when GHC goes into Beta, if you disagree email ghc-devs"". ",True,False
primitive/haskell/71,True,primitive/haskell/71/354366886,Except... I think that the changes are already in HEAD of  -- there's just no release cut? i.e. ,True,False
primitive/haskell/71,True,primitive/haskell/71/354367270,"Yep, then the bug is ""No released versions work with the unreleased GHC 8.4"". Concretely, GHC 8.4 has compiled binaries, and I'm testing it on my CI. I have taken action to say released primitive is not working. When that stops being the case I need to undo that action. I want to ""watch"" something, so a ticket is mightily helpful for that. I imagine when primitive does release to Hackage then @friend and @friend are going to also take some action (e.g. additional testing, reverting workarounds etc). ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/435802595,Why this is still not adressed? ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/417666275,Just replace it by ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/413159272,"This is a really bad bug - as the props way is not even the documented recommended way to pass metadata to helmet, and there is no other workaround. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407988974,It might not work in some cases. Either way I think we're all in agreement that deepEqual is a bad practice in sCU. ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407988469,"Well, you only have to update the key when the underlying children change. In my case that happens when that particular view URL changes, but you can use any string representation. Maybe someone has a react-router match.params change which updates the title or meta information - that'd be a good spot to use  IMO. Anything where state affects the children. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407987711,"Aha, you mean that you have to update that key on every render.  Yep, that seems faster than deepEqual, but still not quite clean as fix deepEqual or avoid children. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407986659," when the key changes it tells the reconciliation algorithm that the element in the new tree is different from the element in the old tree. If the new key isn't in the children in old tree, a new component is mounted. If the new key was in the children in the old tree the element will be re-used. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407985396,"Hm, interesting. Do you have a link to read more about re-mounts of keyed elements? ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407984219,"@friend Gotcha! Well in that case,  solves the problem because deepEqual never gets called in  as the component re-mounts instead of updating. Hence, no stack overflow. Was very useful in my case. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407983910,"So, I don't see any reason why  needs a  prop ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407983661,"@friend this error happens because ReactHelmet compares props with deepEqual and when there are children in props it iterate over children as well and since those children are React components (not a plain objects) it simply overflows the stack. The workaround is to avoid providing any children to  component, but anyway, deepEqual is still bad. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407982788,"@friend Sorry, that was a reference to the  error and presumably  - not anything perf related. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407982283,@friend not sure how that could speed up  in  ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/407980133,"I believe you can also work around this by applying a unique  prop to the  component, for example . Perhaps a bit cleaner than using the props method above. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/404317158,What is the reasoning behind the deep equality check? Per the React docs... ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/403744893,Just ran into this issue as well. Only saw it happening for Safari and Chrome browsers. ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/392650715,"Yeh same. The work around is to not use react children to pass in   tags, and use the props way ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/391660449,Same here. Is there a solution to this? ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/320104503," Hey, ♠HelmetWrapperdeepEqualHelmetWrapperPureComponent`? ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/441221826,1)  trick doesn't help in all cases 2) Library still crashes in 5.2.0 This bug is devastating. Time to find another library? 😢 ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/441413601, was merged into master. I would like to get the roll-up PR merged and we can release a beta version for feedback. ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/442710543,I have the same problem............... ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/448340719,"Thanks everyone, publishing is working now again.  We should be able to post new NPM builds with ease. ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379500148,"I'm taking care of the problem here, for free. ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379499802,"How about we balance your hourly rate with the several hundred hours I've already expended on this problem at my hourly rate?! Or, better yet, how about you spend the 45 seconds it would take you to fix the issue! ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379498719,"I know I may be a ""weird"" person to talk to, but my point is We may fix the problem with  renaming that file, and everybody would be happy and would go to get drunk and sing in the streets, but tomorrow some other package will make the same mistake, and everybody will be sad again. Is this where we want to go? About all the day job stuff etc, if you are willing to pay me my hourly rate I'll be happy to show you all my professionality 😉 ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379497112,"It's still a problem of the sharepoint configuration, I mean, I don't even know what it's it, but if it happens only with it there must be a reason I guess? How do you expect me to change the name of a file used in the library just because your configuration is trying to import stuff from where it's not supposed to? ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379496783,"@friend If you looked at the linked issue over at the SharePoint Framework side in my original report, you would see that I'm not the only one with this problem; and that it's not unique to my combination of packages.  Sure, people might not be reporting it directly here, but that's because they're indirectly consuming your package via npm's version of dependency hell, not using it intentionally or knowingly! ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379496308,"I find it so difficult to think that you are the only one having this problem honestly... If enough people report this we can think about a solution. Until then, I'm convinced the problem is on your side. ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/308297571,"Issue description react-popper is a dependency of reactstrap, which I am attempting to use in s SharePoint Framework project.  SharePoint Framework (SPFx) uses webpack extensively, and react-popper is causing webpack warnings which in turn lead to component load failures because react-popper has not been properly included in the output. Discussion of this issue is linked to an open issue in the SharePoint Dev Docs repository, and while the original issue was thought to be a fault in upgrading SPFx to use React 16, investigation has indicated an issue specifically with react-popper - see sp-dev-docs issue 1315. CodePen demo This is a build issue specific to use of react-popper in conjunction with other frameworks and cannot be reproduced in CodePen alone. Steps to reproduce the problem  Create a new SharePoint Framework solution as per the standard guidelines a. Install gulp and the yeoman generator for SPFx  b. Create a new SPFx Web Part  , accept all defaults Update the  file to use React 16 and  Add bootstrap, jquery, reactstrap a. Note that recently released reactstrap@friend.0.0 uses react-popper@friend.8.3 Add any reactstrap component to the SPFx solution Build and deploy per standard processes  a.   b.   c.  Deploy per standard SharePoint Processes Attempt to load the Web Part in a SharePoint Modern Experience page.  What is the expected behavior? It is expected that no warnings will be issued by webpack, and that the component will load correctly. What went wrong? Webpack issues the following warnings during the bundle phase Warning - [webpack] 'dist' ./node_modules/react-popper/lib/Popper.js There are multiple modules with names that only differ in casing. This can lead to unexpected behavior when compiling on a filesystem with other case-semantic. Use equal casing. Compare these module identifiers * D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/Popper.js     Used by 1 module(s), i. e.     D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/react-popper.js * D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/popper.js     Used by 2 module(s), i. e.     D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/source-map-loader/index.js!D/PROJECTS/Info.Insch.SpfxSandbox/node_modules/react-popper/lib/Popper.js  When loading the Web Part, SharePoint Framework issues the following error [SPLoaderError.loadComponentError] ***Failed to load component ""2a846d5b-9989-45cc-b7b8-68d8d4e8c231"" (HelloWorldWebPart). Original error ***Failed to load entry point from component ""2a846d5b-9989-45cc-b7b8-68d8d4e8c231"" (HelloWorldWebPart). Original error Error loading     Cannot read property 'placements' of undefined  ***INNERERROR ***Failed to load entry point from component ""2a846d5b-9989-45cc-b7b8-68d8d4e8c231"" (HelloWorldWebPart). Original error Error loading     Cannot read property 'placements' of undefined ***CALLSTACK Error     at t [as constructor] (    at new t (    at Function.e.buildErrorWithVerboseLog (    at Function.e.buildLoadComponentError (    at     at &lt;anonymous&gt;  Any other comments? While the error reported when SPFx attempts to load the Web Part appear initially to be an SPFx issue, investigation has identified that the  property which is the root cause of the load failure is from react-popper, and is related to the webpack warnings issued when generating the full output for the web part. As far as I can see, this is because webpack is assuming the reference in react-popper's  file loading the 'real' popper.js is in fact a reference to the same file. Do you have any suggestions which will allow react-popper to be successfully consumed by webpack? Note that I cannot change away from webpack as this is an integral component of the SharePoint Framework. ",True,False
react-popper/FezVrasta/111,True,react-popper/FezVrasta/111/379496122,"@friend having done a lot of experimentation, I strongly believe that this issue needs to be re-opened. Ultimately, the combination of packages that I'm using (SharePoint Framework, React, React DOM, Reactstrap, FontAwesome and others), require that the webpack resolver modules paths contains , without this in the path for example it is absolutely impossible to include a FontAwesome icon in a Reactstrap button, because react throws errors that are not thrown otherwise. The ultimate fix is to use another name for your  file so that conflicts aren't an issue - changing configurations when those configuration changes are breaking changes for many other packages and package combinations isn't appropriate. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/448318628,"Hi all, Quick update. @friend and I got the required permission to NPM. We will be publishing to NPM today or tomorrow. because the thread is getting a little out of hand, I'm closing and locking the thread. I will be adding a code of conduct and other community support documentation.  you all, and thank you for being apart of the community. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/442728992,"I believe it's merged to  branch, we need to wait them to release a new version ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/448104302,"Dont forget - you may fork this repo and publish as . The problem is already solved, fix is in the master branch - just not published to . ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/448069883,"Ok, I can to pay something. What the cost you’re talking about? We just need a working package, and we know what the “open source” means. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/448062956,"Wow, people are rude. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/447939847,"Please everyone, give @friend a rest or pay him money for working on this issue. Everyone can fork this lib and patch the code or switch to react-helmet-async or use an object for configuration. There are a lot of alternatives. ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/447869292,Hello guys. Any news to just publish patched version to NPM? ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/447561484,I got a temporary workaround for this issue. 1) Clone the master branch 2) Copy all the files that are inside the  3) Paste that inside  4) Convert this code with  into Make sure the import path is correct. Once the fix is published to NPM you can delete the  folder and change the ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/446944087,"For some strange reason it happens just for one person in our office, so we haven't noticed this bug during development and tests. Any chance of releasing the beta version soon? ) ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/446643456,I came across this issue as well.  Looking forward to the next release with the fix. ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/446162172,"My application crashes frequently due to this bug. If this bug isn't resolved before our product launch, I'm forced to replace it with another lib / my own implementation 😕 I guess it's not too hard to release a v5 patch? Has nothing to do with the current work on v6 right? ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/446128006,@friend is right a patch version will be great at least we can publish the changes to our production application without any nasty hacks to fix this issue. ,True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/446090001,"I few months ago (when I failed to use this library) - I wrote another one. It's not a drop in replace due to different design (does not create title/meta tags), but could save your day - ",True,False
react-helmet/nfl/373,True,react-helmet/nfl/373/446052884,"I can understand why this guy is frustrated, given that there is no new release for this package more than a year, but I don't agree on how he diss the maintainers or contributers. I think you guys should have released a patched version for v5 without the rollup. ",True,False
mojo/kraih/1236,True,mojo/kraih/1236/404162820,"Well it might be correct, but the documentation ""Write all data at once to the file"" doesn't say anything about the byte/character distinction, and $bytes can be understood as whatever bytes are there in the scalar, which I would expect. So that's at least a case to either fix the documentation or the attitude. ",True,False
mojo/kraih/1236,True,mojo/kraih/1236/404168986,"I don't see this discussion end constructively, therefore i'm locking this issue. ",True,False
mojo/kraih/1236,True,mojo/kraih/1236/404135563,The answer @friend gave was 100% correct. So this is not a bug. If you require additional help please use our official support channels. ,True,False
mojo/kraih/1236,True,mojo/kraih/1236/404133396,"Yes, write all bytes from the scalar. ",True,False
mojo/kraih/1236,True,mojo/kraih/1236/404127826,"MojoFilespurt is documented to take bytes, but  is a character. Encode it to your favourite encoding first. ",True,False
mojo/kraih/1236,True,mojo/kraih/1236/404129197,Doesn't seem like bytes to me ,True,False
mojo/kraih/1236,True,mojo/kraih/1236/404129409,-,True,False
mojo/kraih/1236,True,mojo/kraih/1236/340189202, Mojolicious version 7.87 Perl version v5.26.1 Operating system ubuntu  Steps to reproduce the behavior perl -MMojoFile -le 'MojoFile-&gt;new(q(a.txt))-&gt;spurt(qq(\x{100}))' Expected behavior a.txt written with 2 bytes c4 80 Actual behavior get error Wide character in syswrite at /home/dk/perl5/perlbrew/perls/perl-5.26.1/lib/5.26.1/x86_64-linux/IO/Handle.pm line 483. a.txt is zero bytes ,True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401717734,"May I suggest to put this link into ? I couldn't find the API documentation before, and it's not like I didn't try. It's only for v.0.4 instead of 0.5.6, but it's already more detailed than . To the contrary, it does not appear like participation/contribution is welcome. However, to document the solution of my problem if someone else encounters it as well -- setting  was enough (and adapting the code a little because  does not work for ). No extension types are necessary, although I understand now that these are independent of the encoding/deconding, but would help to save some bytes. ",True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401708961,"I'm on it. No need to be like that. I've been trying to read up all the documentation I could find, but  has only examples, and  does not mention  or explain the  concept in depth (which codes are available/reserved? Restrictions? Nesting?). I started with the encode/decode because that's how pandas does it too. The barrier for ExtType was a fair bit higher without much documentation, but I'll try it now. Finally, you haven't responded either why the  kwargs work for so many types, but not for ... ",True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401705283,"Like JSON, it's not goal of msgpack. You can use strict_types option to distinguish tuple and list when packing, and pack them to custom ExtType.  Then you can unpack ExtType manually. I won't add any more features for Python-only usages. msgpack is cross-language, portable format. ",True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401710780,"So you must ask question on Stackoverflow. Posting question on here means you send spam notification to me. README is very short entry point for new users, not full document.  You must read docstring and  bad English writer, contribution on document is welcome. I respond already.  It's compatibility with JSON and strict_types allows you to use . ""object"" in  is JSON's object, you must understand it if you read JSON API document. You must use your time before respond so quickly. Or you should use Stackoverflow to get reply from kind volunteer for you.  I'm not. ",True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401706115,"I understand that it's cross-language, but it's not clear to me why  don't seem to process  - then I can deal with it myself. Also, it's not clear to me what the difference is between using these encode/decode hooks and an ExtType... ",True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/337409477,"I understand that  has a single array-type, that both  and  both get mapped to (and that this is the reason for the -kwarg). However, the  distinction is essential in Python, and one can't fully emulate the other (e.g.  is hashable,  isn't;  has an -method,  doesn't). For this reason, I need to reconstruct tuples and lists correctly, e.g.  -- actually, arbitrary nestings of . Currently (v0.5.6), this does not work So now to the actual question - I thought I could use the  keywords to help me out, but this does not work for , even though it does work for sets (and all the other types covered by ). ",True,False
msgpack-python/msgpack/305,True,msgpack-python/msgpack/305/401706913,It's for compatibility with JSON library. And I teach you about strict_keys option.  Why don't you try it before reply? I'm not free tech support. ,True,False
mame/mamedev/4801,True,mame/mamedev/4801/424476807,"Debian 9.6 X64 GCC 6.3.0 Build options  Latest commit tested 842aa09 sdl2-config --libs -L/usr/lib/x86_64-linux-gnu -lSDL2 sdl2-config --cflags -I/usr/include/SDL2 -D_REENTRANT Compiling src/osd/modules/input/input_common.cpp... ../../../../../src/osd/modules/input/input_common.cpp3622 fatal error SDL2/SDL.h No such file or directory include &lt;SDL2/SDL.h&gt;                   ^  compilation terminated. osd_sdl.make921 recipe for target '../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o' failed make[2]  [../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o] Error 1 Makefile19 recipe for target 'osd_sdl' failed make[1]  [osd_sdl] Error 2 makefile1057 recipe for target 'windows_x64' failed make *** [windows_x64] Error 2 make VERBOSE=1 Compiling src/osd/modules/input/input_common.cpp... /usr/x86_64-w64-mingw32/bin/x86_64-w64-mingw32-g++    -MMD -MP -MP -DX64_WINDOWS_ABI -DPTR64=1 -DNDEBUG -DCRLF=3 -DLSB_FIRST -DFLACNO_DLL -DPUGIXML_HEADER_ONLY -DNATIVE_DRC=drcbe_x64 -DLUA_COMPAT_ALL -DLUA_COMPAT_5_1 -DLUA_COMPAT_5_2 -DWIN32 -DUSE_NETWORK -DOSD_NET_USE_PCAP -DSDLMAME_NO_X11 -DUSE_XINPUT=0 -DSDLMAME_SDL2=1 -DOSD_SDL -DUNICODE -D_UNICODE -D_WIN32_WINNT=0x0501 -DWIN32_LEAN_AND_MEAN -DNOMINMAX -DUSE_OPENGL=1 -DSTDC_LIMIT_MACROS -DSTDC_FORMAT_MACROS -DSTDC_CONSTANT_MACROS -DIMGUI_DISABLE_OBSOLETE_FUNCTIONS -DUSE_QTDEBUG=0 -I""../../../../../3rdparty/asio/include"" -I""../../../../../3rdparty/winpcap/Include"" -I""../../../../../3rdparty/compat/mingw"" -I""../../../../../3rdparty/portaudio/include"" -I""../../../../../3rdparty/compat/winsdk-override"" -I""../../../../../3rdparty/bgfx/examples/common"" -I""../../../../../3rdparty/bgfx/include"" -I""../../../../../3rdparty/bgfx/3rdparty"" -I""../../../../../3rdparty/bx/include"" -I""../../../../../3rdparty/rapidjson/include"" -I""../../../../../3rdparty/portmidi/pm_common"" -I""../../../../../src/emu"" -I""../../../../../src/devices"" -I""../../../../../src/osd"" -I""../../../../../src/lib"" -I""../../../../../src/lib/util"" -I""../../../../../src/osd/modules/file"" -I""../../../../../src/osd/modules/render"" -I""../../../../../3rdparty"" -I""../../../../../src/osd/sdl""   -g -m64 -pipe -g1 -fno-omit-frame-pointer -fno-optimize-sibling-calls -O3 -fno-strict-aliasing -march=""bdver1"" -mfpmath=sse -Wno-unknown-pragmas -Wall -Wcast-align -Wundef -Wformat-security -Wwrite-strings -Wno-sign-compare -Wno-conversion -Wno-error=deprecated-declarations -Wno-unused-result -Wno-array-bounds -m64 -x c++ -std=c+plus one4 -Woverloaded-virtual -include /home/mame/build/mame/src/osd/sdl/sdlprefix.h -o ""../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o"" -c ""../../../../../src/osd/modules/input/input_common.cpp"" ../../../../../src/osd/modules/input/input_common.cpp3622 fatal error SDL2/SDL.h No such file or directory include &lt;SDL2/SDL.h&gt;                   ^  compilation terminated. osd_sdl.make921 recipe for target '../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o' failed make[2]  [../../../../mingw-gcc/obj/x64/Release/osd_sdl/src/osd/modules/input/input_common.o] Error 1 Makefile19 recipe for target 'osd_sdl' failed make[1]  [osd_sdl] Error 2 make[1] Leaving directory '/home/mame/build/mame/build/projects/sdl/mametiny/gmake-mingw64-gcc' makefile1057 recipe for target 'windows_x64' failed make *** [windows_x64] Error 2 ♠ ",True,False
mame/mamedev/4469,True,mame/mamedev/4469/451429161,"@friend ""latest"" is a different thing every time someone commits.  In the time between when you compile, when you open the issue, and when someone reads it, ""latest"" will have changed.  You've been around long enough to understand this.  Without a revision hash, we don't know what ""latest"" is.  Note that on #4468 an abbreviated revision hash is included in the issue description.  You're being banned from MAMEdev repositories for one week for counter-productive behaviour. ",True,False
mame/mamedev/4801,True,mame/mamedev/4801/479455316,"Fedora is ""unstable"" in the sense that it's updated relatively quickly and packaged software occasionally gets a major version upgrade before a distribution update.  It isn't ""unstable"" in the sense of crashing or not working.  Being the ""testbed for RHEL"" is exactly why a lot of people use it.  It uses the same packaging system, similar network and service configuration, it's largely ABI-compatible (e.g. it uses the same versioning for FIPS-compliant OpenSSL), and it gives you a preview of where RHEL/CentOS may be going.  The benefits are huge for people who, like me, use RHEL for deployment of line-of-business applications. You're misunderstanding why it does special stuff for macOS - on macOS a system installation of SDL2 uses a NeXT-style framework, which is not used for any other target. Before 8ffff5d2d3bcebbdbefec2508ddd2ecd264a399a  and  did the same thing.  The option wasn't working intuitively.  It's not a regression that  now disables the option instead of doing the same thing as . Stripping  from the end of the include path is intentional.  For consistency between macOS and other platforms, MAME includes the  prefix when including SDL2 headers.  Hence, the parent directory is what we need to add to the include path. Your analysis is completely flawed, and the issue you're reporting is not happening for others. ",True,False
mame/mamedev/4801,True,mame/mamedev/4801/478473098,"I didn't file a bug for Fedora, people are aware that Fedora it's a unstable system and it is a test bed for RHEL. Anyway, this is not about Fedora. The way the build scripts are made it should be smart enough to detect what it needs from the system by it self without the need for  since there are tools available to use and depending on the system  should return the proper paths for libs and includes. The reason MAME fail to build it's because the build scripts uses a nasty hack like this one that replaces  with nothingsdl2-config --cflags | sed 'sSDL2' The correct path for SDL2 headers is Same happens on Linux, the build script uses  instead of  and it will obviously fail to compile either on Linux or mingw. The second reason why this is failing it's because there are no proper conditionals for , if we take example from  We can see  getting the SDL2 path hack, now if we look in to  This is basically it, we can't see any SDL2 configuration on either  or  for  and still don't understand why it passes  to the compiler since this is defined for . I didn't test at the time for lack of time, the regression is this 8ffff5d2d3bcebbdbefec2508ddd2ecd264a399a, removing  and  from the makefile and building with  for some kind of miracle this make it work again. And when I say ""miracle"" it's because there is nothing on the script passing the correct path for the compiler but still it compiles all the way through because even set as  it uses the bundled SDL2 from MAME when it should use the system. Do you concur? ",True,False
mame/mamedev/4801,True,mame/mamedev/4801/478404972,This is not necessary on Fedora - the library headers are found correctly.  Use  or figure out why the mingw paths aren't being used by default. ,True,False
mame/mamedev/4469,True,mame/mamedev/4469/451425519,Do not engage in abusive language towards team members or you will find your access to the project curtailed. ,True,False
mame/mamedev/4469,True,mame/mamedev/4469/451354667,"""Latest git"" means nothing - you must supply a revision hash if you're not testing a tagged release.  Also this is a duplicate off #4468. ",True,False
mame/mamedev/4469,True,mame/mamedev/4469/395810691,"Debian 9.6 x64 latest git sfiiii and sfiii2 show a CD-Rom error screen, sfiii3 stuck in a infinite CD-Rom loading screen.   This are the only ones I have to test. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450212046,"&lt;img width=""490"" alt=""screenshot 2018-12-27 13 05 07"" src="" this is the full extent of your user object the problem you are experiencing is that your user object isn't presenting the list of groups it is a member of and that is how the code is searching. &lt;img width=""512"" alt=""screenshot 2018-12-27 13 06 32"" src="" an actual understanding of the code I can again say that point where CN is listed is essentially useless and does next to nothing.  What you are suggesting whether you realize it or not is that we need to pull the list of users from each group and then check for membership on a per user basis or you're missing information from the ldap search. ",True,False
openshot-qt/OpenShot/1619,True,openshot-qt/OpenShot/1619/392483545,@friend - Please report issues in a polite manner. We can't help you if you post stuff like this. We need you to tell us the problem and provide details of the system you are running Openshot on. Thanks. ,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450251574,I've given you a work around for your issue to remove lines 144150 in your codebase and yet you are still choosing to argue about what you don't understand in the code.  I'm locking this thread.  Feel free to submit a pull request with valid working code. ,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450250964,"Our schema already has a 'cn' attribute in the userobject. You are the clueless one.  Look up groups under RFC2307.  They do NOT use 'cn', they use either member, memberOf, or memberUid.  These are NOT attached to the userObject at all. This is NOT active directory.  This is openldap running a RFC2307 schema. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450251164,The section of code you are looking at is pulling a user object.  NOT a group. ,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450225930,Defined Attributes for RFC2307  some of the attributes defined in [RFC2256] are required. Further down the hole for rfc2307 we find what are the requirements for group membership.  your RFC comments in this case CN is required. ,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450224927,"So in other words, you do not support RF2307, only your self determined Schema's. Too bad. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450221473,"from login_ldap.php, line 148 this code has a hard-coded 'cn' in it, so it assumes activedirectory type member changing it to 'uid' and everything works. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450223766,"1st, we do not have anything like you posted, open your damn eyes. 2nd, the ldapresults are over written  in the else statement, that then calls an for loop, that then calls the checkaccess read the GD code your self.  Start at line 128, and not that ldapResults are overwritten at line 150. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450224347,Remove lines 144 150 in your codebase. ,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450222330,"and when the group search fails, that loop will return nothing, because it's searching for groups based on CN, not UID in a rfc2307 schema. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450221443,"I understand ldap and have worked with it for nearly 20 years. I'm not bothering quoting RFCs, i'm posting the actual code and how it is working.  It isn't using the CN for searching for groups it searching for the memberof attribute or the nested DN attribute for people using openldap.  I posted the actual loop that is determining group membership. ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445486759,I didn't show you the content of your vpn container on my installation. The vpn container on my build is working. I was talking about container behind that container. ,True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445487002,"No one ever suggested that all containers that used the VPN containers network stack got their own IP, I explicitly said multiple times that they didn't get IPs assigned at all. ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445486445,"I provide this container and answer questions for fun, you're being rather rude while I'm trying to help you. I'm not inclined to bother much further. I guarantee you that it is currently working for me and many others, and that I'm trying to answer your questions so that it will work for you as well. ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445474064,"I don't think it a good idea to use link. We should create a network first, then find a way to put all the traffic through the vpn gateway. So did you manually write a gateway inside your other containers? ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445486041,"and that I don't see that becoming true. As I said there is no dhcp server anywhere in that, unless the vpn that your container is using is a private one where the openvpn connection act as a dhcp relay, or you attach your container to another network. And now you are telling me that the vpn is providing addresses... LOL show me where PIA is giving away multiples addresses on one connection. And no there is no ip assigned even in the container itself ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485942,"As docker won't be administering the VPN directly, I have no idea if it will show the IP address handed out by the VPN provided to the container even if you pull the network settings for the VPN container, it may well only show the docker assigned IP. I've never checked. ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485794,"You're looking at the container connected to the VPN container, your first message references . If you are following the directions from my container you're telling docker to not create a network for that container and to reuse the one from the VPN. So when you look at the network for  there is nothing there, because it didn't get it's own network stack. ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485680,"and I don't see that you put a dhcp server in your container and as I stated earlier, vpn provider doesn't provide with a bunch of addresses. So if the docker daemon doesn't provide for an ip address I don't see how the other containers would have one ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485502,"well apparently it doesn't do that anymore in 18.09 because if I do docker network ls, there isn't a forth network ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485426,"I built the container, and have been supporting it for quite a while. It's not just my personal use that I'm commenting from but how things have worked out for other users of it. This is issue number 165, I've answered and resolved to the best of my ability 164 prior question / issues that people have run into. The openvpn container does create a network stack, it's the other container that doesn't, as you stated in the first message ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485326,"where in all that  does it create a network stack? Nowhere... Nor PIA nor mullvad nor protonmail nor nordvpn doesn't give a bunch of addresses, they give one for each connection you make. So the containers behind if they are only in the same network stack of your openvpnclient they won't get any ip addresses ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445485041,"I'm personally using PIA, but there are users that have contacted me for probably a dozen or so VPN providers, so don't think it's all that relavent. ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445484795,which vpn did you take in your example with transmission for example? ,True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445484739,I really am not following what you're saying here ,True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445484420,"oooow okey but then it doesn't work for a vpn provider then.  There is then 2 usecases, the one where the vpn provider gives an ip to the container clients of the vpn container. And the one where only the vpn container gets an IP and where you need to put everything in a network and change the gateway for the client container.... ",True,False
openvpn-client/dperson/165,True,openvpn-client/dperson/165/445484206,"The other container doesn't get a network stack of it's own, but uses the one configured by the openvpn-client container. Go ahead and make your own containers that do that, but you'll have to modify all containers that you use to be able to route their traffic to your openvpn container. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450220825,"It's now obvious that Pig does not understand LDAP rfc2307 either. Group membership is a separate object from the user object in rfc2307, and membership is denoted using uid or the uid object (rfc2307 vs rfc2307bis). so using 'cn' to search for group membership in a rfc2307 schema fails. And no, I was not going to post the complete object in a public forum. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450212363,"Please submit a working pull request.   As I have stated countless times before - I don't know LDAP and barely got this to work with the example I managed to steal from the Google.    However, if you simply want to tell me that we're doing it wrong, that's not productive.    Working pull requests are welcome. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450205307,Set your usersearch to (|(uid=%userid%)) then and stop spamming my email with your lack of ldap filtering ,True,False
officer/davidgohel/141,True,officer/davidgohel/141/400993855,that is what I get final.docx You never provided what you get nor describe the error nor answer my questions. ,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450204449,"We do not use 'CN' here in rfc2307 groups, it's uid. (&amp;(objectClass=posixGroup)(memberUid=%userid%)) ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450203312,"No, it's not. Look at line 146 in login_ldap.php $found_dn=@$ldapResults[0]['cn'][0]; For a ldap instance using rfc2307, this does not work. ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450204022,"It really isn't used.  I use (|(userprincipalname=%userid%)(cn=%userid%)) as my base search and i'm matching on the princpalname in my search string.  You just need to use a better search string. ♠$found_dn=@$ldapResults[0]['cn'][0];               $ldapSearchDN=str_replace(""%userid%"",$found_dn,html_entity_decode($config-&gt;ParameterArray['LDAPBaseSearch']));` ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450204921,-,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/392282326,"I found that in upgrading to 18.2, ldap stopped working for me. It's using 'cn' attribute in the login_ldap.php, which is common name, which according to the ldapwiki  do not use 'cn' names for groups, we use 'uid' for groups, along with memberUid. Changing to use 'uid' works. Time for another LDAP config parameter? ",True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450204639,-,True,False
openDCIM/samilliken/1114,True,openDCIM/samilliken/1114/450151384,It's already user defined in the configuration screen. ,True,False
officer/davidgohel/141,True,officer/davidgohel/141/400820479,"OK, thanks, I will correct, it should be However, what is the issue with your first code? Could you please explain what does not work. Also please add . ",True,False
officer/davidgohel/141,True,officer/davidgohel/141/401162077,"@friend Serge Nosov, you spent few minutes downvoting all my SO answers ) &lt;img width=""794"" alt=""capture d ecran 2018-06-28 a 21 57 12"" src="" you replied to yourself with a wrong answer! . &lt;img width=""689"" alt=""capture d ecran 2018-06-28 a 21 59 16"" src="" function you want to use is only working when the document is edited in Word. I am working with MacOS and have no issue when opening the document in Word. ",True,False
officer/davidgohel/141,True,officer/davidgohel/141/400760682,"Example from documentation This just overwrite doc variable. In src parametr I can pass any string and I get the same result♠doc &lt;- body_add_docx(x = doc, src = ""external_file.docx"" )final_doc &lt;- read_docx()` I can delet and also will get the same result ",True,False
officer/davidgohel/141,True,officer/davidgohel/141/400863875,"Sorry, but your corrected code also doesn't work. I get empty final.docx. I use R version 3.4.4 (2018-03-15) Platform x86_64-pc-linux-gnu (64-bit) Running under Manjaro Linux other attached packages [1] magrittr_1.5  officer_0.3.1 officer package installed from cran ",True,False
officer/davidgohel/141,True,officer/davidgohel/141/400757830,"I can not reproduce. Please, follow the guidelines explained in the template of new issue. ",True,False
officer/davidgohel/141,True,officer/davidgohel/141/336310576,doesn't work body_add_docx method ,True,False
spark/perwendel/1020,True,spark/perwendel/1020/393774441,"There is an instance api, showed in this new post  looks more or less the same as the static api. ",True,False
spark/perwendel/1020,True,spark/perwendel/1020/328394688,"I hava a 512m vps, I want to build some website on it. memory is too small, I must select a simple and high performance java web framework. I just read the spark's doc, I found some code like this Do you know what's the feeling of me?  foolish, child-liking ,  naive I want a normal code style like this You all contributors should focus on simple and performance and low memory-use, not the  naive grammar features! ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422498472,"Well, to be honest, I don't have to do anything. You have probably noticed this software is completely free of charge, which not only includes the software itself, but also some support from my side, and the will to implement missing features and help as much as I can. However I work on this on my free time (mostly weekends, vacation periods and a few hours from Monday to Friday), which means there's always going to be missing things and parts that can be improved. It's easy to spot what's not working, what made you waste two hours of your time. What's not that easy is being able to see what's actually working (I have ""wasted"" hundreds of hours on this, but you are welcome). In the future you should learn some manners when dealing with free and open source software maintainers, and remember that they don't work for you. Any constructive feedback is always welcome but not like this. ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422348839,"nevermind last click on install ♠PHP Fatal error  Uncaught Error Undefined class constant 'MYSQL_ATTR_INIT_COMMAND' in /var/www/vhosts/xxx.xxx/httpdocs/module/CLI/src/Model/CustomizableAppConfig.php263 Stack trace 0 /var/www/vhosts/xxx.xxx/httpdocs/module/CLI/src/Command/Install/InstallCommand.php(142) Shlinkio\Shlink\CLI\Model\CustomizableAppConfig-&gt;getArrayCopy() 1 /var/www/vhosts/xxx.xxx/httpdocs/vendor/symfony/console/Command/Command.php(251) Shlinkio\Shlink\CLI\Command\Install\InstallCommand-&gt;execute(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 2 /var/www/vhosts/xxx.xxx/httpdocs/vendor/symfony/console/Application.php(886) Symfony\Component\Console\Command\Command-&gt;run(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) 3 /var/www/vhosts/xxx.xxx/httpdocs/vendor/symfony/console/Application.php(262) Symfony\Component\Console\Application-&gt;doRunCommand(Object(Shlinkio\Shlink\CLI\Command\Install\InstallCommand), Object(Symfony\C in /var/www/vhosts/xxx.xxx/httpdocs/module/CLI/src/Model/CustomizableAppConfig.php on line 263` ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412960091,"@friend  - By looking at this I'm very unsure that you properly test your scripts... Some posts above you wrote that this is not in case with . But bsdtar still produce the same behaviour as busybox's tar. I have finished... No more posts from me in this thread. I point you from where error comes - but you ignore, ok... ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412954228,"Random errors in Termux are very concerning; This is not the first report. This IS not the case with , and this was NOT the case with Termux busybox tar until last week when things broke; See initial post. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412951318,I cannot use it.  Neither can Termux users that want to try TermuxArch.  BuildAPKs is in a similar state with the latest Termux Package ecj. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412948537,@friend bsdtar triggers signal aswell for me =) This error happens randomly. There two possible situations that may happen in your code  tar finishes before  this will fail since job 1 does not exist  tar finishes after  this will finish without error   Remember don't run parallel shell processes if you don't know how to properly control them. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412947852,@friend  Package request termux-arch was closed; Are there valid reasons for it to become a package? Then why does it trigger a signal when the others do not? ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412941252,"@friend I checked it in the first my post in this issue ! You didn't see ? Busybox tar even don't print errors and exited with status 0. Nothing that command  has exit status 0 which means success ? I don't see TermuxArch in termux-packages repo and never seen. It also don't available in main repos via  and don't mentioned as project of Termux organisation ( from third-party packages shouldn't be posted here (in termux-packages). For these we have a Google+ page and Gitter. =============================== @friend I guess this issue can be closed, we can reopen it later if  really has a bug. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412926725,"I do not assume anything @friend To continue this line of debugging Termux  should be checked;  and system  behave well.  Termux  behaved well until recently, just like . How shall Termux grow if issues regarding Termux Packages cannot be brought up here? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412912547,"Just to summarize  works without issues as shown on screenshot  assumes that source of several errors in TermuxArch is  without proper debugging.  Perhaps we shouldn't accept issues that occurs in third-party project or those, which does not have a proper PoC to reproduce errors/bugs. (Templates are solution ?)   ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412910767,The problem is that . ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412909986,@friend The source of error is  ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412909872,"Thanks for the update, a race condition... @friend Can you post a snippet of how you redirect ouput to find out more? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412904319,"There may be a some kind of 'race condition' since you running a tar job in background.  - this may be a trigger, i'will try to remove output redirection and see what will happen. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412893686,@friend I just removed your 'spinner' from 'preproot' function and error disappeared. I'm currently doing a verification installation of TermuxArch - if error fixed i will post screenshots. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412901974,TermuxArch was reinstalled successfully 1.     3.  ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412889016,"When  is used, there is no signal 1 generated. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412895023,"@friend this might trigger the error.  And if so, why only with Termux busybox tar? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412880058,"Yes, latest packages. Machine AArch64, Android 8.0. About  - i try to found where it occurs. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412879894,@friend a little info about machine is requested.  Are you using the latest Termux packages? ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412878919,"@friend I did this, but I don't have any problems...  Successful installation   Successul execution of 'startarch'    Ok, there signal 1 generated, but are you sure that it is from tar ? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412872318,"@friend Exact command - is a command without a script, for example . I posted result of executing  above  Command is identical to specified in your script ( is identical to ). Where incomplete ? In your script maybe. But running standalone command successfully ends without any error. Okay, I will check your TermuxArch script as you suggested, but I'm 97% sure that there no problem with busybox's tar. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412865898,"""startarch"" missing sdrausty/TermuxArch#104 Issues on aarch64 sdrausty/TermuxArch#105 Permission Denied when creating symlink to ca-certificate sdrausty/termux-archlinux#11 ""TermuxArch warning Script signal 1 generated! "" sdrausty/termux-archlinux#12  @friend Can you post exact steps to reproduce a problem with ""busybox tar"" instead of posting links to various issues whose problem may have a different source ? Or we should debug TermuxArch to find where problem occurs ? For me, at least, there no problem with command  that you posted  So there some possibility that TermuxArch script is faulty or your user did something wrong. Busybox has a relation to ecj or java ? That's something new for me... ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412869675,@friend  then uncomment  comment out  . Busybox tar does not complete untarring as expected; See referenced issues above. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/350404058,"Termux users are running into many newly arisen errors such as 1) ""startarch"" missing  Issues on aarch64  Permission Denied when creating symlink to ca-certificate  ""TermuxArch warning Script signal 1 generated! ""  appears to be something wrong with Termux busybox tar at present  this in any way related to similar changes in  outcomes are identical. ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422339248,"I'm on it. If I get it running, let me check if I can get it to work now. ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422338179,There you have the problem. It's PHP 7.0 ,True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422337852,-,True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422337601,"It might be that you are using the proper version from the web context (the fpm), but not from the command line. You can check by running php -v ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422335696,"I freshly set up a host with a fresh 7.2 php install. My server has 7.0.30 as lowest php installation and the package I am using for shlink is using 7.2.10 FPM, should I maybe use 7.2.10 FastCGI? ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/422334444,"I'm afraid that error means you are not really using PHP 7.2, but 7.0 or older. That's why it does not get ""void"" as a reserved word, and instead it tries to load it as a class. Many people has faced this problem before. Make sure you run the installer with the proper PHP version ",True,False
shlink/shlinkio/210,True,shlink/shlinkio/210/361226392,"Trying a fresh install, getting this error. Afterall I think the installment is (based on the previous issues) way to user unfriendly. Maybe should think about an installer that also checks the needed additions, as said in #152  // or make the install readme more detailed. By saying ""Setup the application by running the  script."" it first confused me, too, and took me half an hour until I figured out this is not really an installer but more of an commandline enhancer to install/compile the script. Anyway, back to my problem It was throwing out the error befor and after I installed the required APCu. So I have no idea what is stopping the installation. Sys  CPU | Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz (6 core(s)) Version | Plesk Onyx v17.8.11_build1708180301.19 os_Ubuntu 16.04 OS | Ubuntu 16.04.5 LTS PHP 7.2.10  ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/412966086,"@friend thank you for your time in this matter.  Your insight and instructions are appreciated.  There are no errors with bsdtar.  Just like there were none with Termux busybox tar until recently.  As I have mentioned before, your opinions of me are yours.  It would be great to hear a compliment rather than complaint from you btw. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413014953,"@friend I am looking at this matter closer thanks to our discussion. It appears that even on the device throwing random errors,  consistently work verses Termux  BusyBox .  I shall be looking in why this occurs in more detail… ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413116500,Closing then since there's no problem with termux's busybox tar. ,True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410855562,Thank you for making me write free code for you so enjoyable! ,True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/457998235,"I am temporarily locking this thread.  If I could please ask everyone to calm down, I'm not about to pick sides in whatever conflict that is currently taking place here.  Brian has asked for someone to submit a PR to fix this issue.  Until that takes place, there is no reason for this issue to remain wide open given its current state. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/457913319,"This is long overdue, this project needs a code of conduct. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/457890088,"@friend  if you have patches, submit them. but name calling and hostility won't be tolerated even if you have patches to submit to the project. in your comment here, you decided to continue with hostility and name calling. it's a pattern you have exhibited for time, and a few users decided enough was enough. no one else complained about the loss. please behave professionally, and I will do the same. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/457885294,"@friend I was about to send some patches in, including this one, but apparently someone with oper rights in the channel was feeling like a primadonna and decided to issue a ban over hurt feelings related to a comment about the semantics of the word 'mostly'.... after PMS'ing around other folks. Did not seem like someone technically involved in the project, but he went ahead and did the same in -social. Therefore, odds are you did not get a message in the channel mentioning another issue that is present with the spl debug code (without further analysis it looks like misuse of snprintf(), leading to a single byte leak, but I haven't verified this proper). Holding on to the patches for now. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/445478342,"Hi, I just saw this. I will let someone know so a PR can be opened, meanwhile I had some other fixes written for a few other spots that need testing. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/438406957,"Hello. Some update. I decided to go back to the commit it was working. I was looking at history of zfs_sysfs.c file  and found that it started to fail since commits from Sep 2. So it is not related to  compiled it successfully with a commit before that  EGIT_COMMIT=""bb91178e60df553071ce2e18b0067ef703f7b583"" I hope this information will help fix building on dappersec kernels. Thanks! ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/436129493,"Hello. Anything on this? Because of some commit (I think it is related to  I can't use dappersec kernel anymore. I also tried with 4.9.132-dappersec, and the error is the same. It was always compatible with grsecurity patches, please fix it. Thanks so much ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/429906489,"Hello. I tried to compile it on linux-4.9.131-dappersec, the latest grsec-updated kernel, and it also failed. I have compiled it successfully on latest linux-4.18.14-gentoo.  As I know, 4.9.x is a longterm, so it is kernel-version-related or grsecurity-related. But as I told you, 4-5 commits back it compiled and worked fine. Is it possible to fix master to work with 4.9.x grsecurity kernels? It was working for years before. Thanks. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/426425810,@friend just fork the repo and create a custom branch if newer commits don't work for you you can modify zfs-kmod-9999.ebuild e.g. like so that way I'm e.g. selecting my repo and via EGIT_BRANCH the specific branch to be used. This needs to be done both for sys-fs/zfs and sys-fs/zfs-kmod ! Hope that helps. ,True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/425857028,"Thanks for replies. About zfs binary stopped working I know, it is because I compiled a new version of zfs and still use old version of zfs-kmod. I am using this kernel for a long time and compilation of zfs worked well always. My last successful compilation was about 4-6 commits ago to the master. I read this link about grsecurity, but didn't found a solution. Also, I don't see any grsecurity errors at dmesg while compiling. So now I have new zfs and old zfs-kmod and I am afraid to reboot, I don't know how to compile the same version in gentoo or back-forward for some commits. I think the problem is related to some new code in last commits, the kernel version or gcc version.  I am using zfs (master) 1.5+ years at 4.9.24-grsec and about a year on 4.9.74-grsec (minipli), and compilation always was successful.  Please help me resolve these issues.  Glibc-2.26-r7, gcc-7.3.0-r5 hardened profile, binutils-2.31.1 ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/425155629,"BTW, I also tried gcc 7.3 on gentoo-sources-4.18.10 (different machine) and the compile worked fine as well. ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/425100392,"Could be a mismatch between kernel and userland ABI In case you upgraded from a way older version (=didn't  for quite some time) you still might have the old userland binaries somewhere in your path, their location changed a while ago. Similar problem (when you can only locate the new version in your path) could happen when the old kernel module is still loaded but the new version of the userland is used. The compilation error could be caused in concert with grsecurity, see  for a similar case (and possibly a solution). ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/424840274,I can test under gentoo in a little while. ,True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/364146679,"Hello. I am using Gentoo and ZFS-master. All was fine, until I decided to upgrade ZFS. In gentoo for upgrade I need to merge 2 packages zfs and zfs-kmod.  Zfs was merged OK, but stopped working. local ~ # zfs list bad property list invalid property 'name' I thought it will work when latest kernel module will be merged. But it fails to compile. CC [M]  /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.o   CC [M]  /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_vfsops.o /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.c In function ‘zfs_kobj_add_attr’ /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.c15138 error assignment of member ‘name’ in read-only object   zkobj-&gt;zko_attr_list[attr_num].name = attr_name;                                       ^ /var/tmp/portage/sys-fs/zfs-kmod-9999/work/zfs-kmod-9999/module/zfs/zfs_sysfs.c15238 error assignment of member ‘mode’ in read-only object   zkobj-&gt;zko_attr_list[attr_num].mode = 0444; Please help me fixing these issues. Gentoo-Hardened, zfs-9999, zfs-kmod-9999, Linux-grsecurity-4.9.74, GCC 7.3.0 ",True,False
zfs/zfsonlinux/7861,True,zfs/zfsonlinux/7861/418254587,"Still, you post on a bug report platform watched by &gt; 400 people that get emailed for each of your posts. Nobody asked for your opionion. There are rules established by the community, people who largely work on this project for free, an you can either stick to their rules, not contribute (anything) at all, or fork the project and work on your fork under your own rules. wink  I'll unsubscribe from this issue and won't comment here further. ",True,False
zfs/zfsonlinux/7861,True,zfs/zfsonlinux/7861/418239329,"Why are you ignoring both rules and requests ( Please use the issue template if you found a bug, otherwise ask the mailing lists ( you for your cooperation. ",True,False
zfs/zfsonlinux/7861,True,zfs/zfsonlinux/7861/356609376,"Hello, as referenced by others, I have a pool that was mistakenly upgraded under Linux that needs to go back to FreeBSD.  Unfortunately userobj_accounting is enabled, which means that FreeBSD won't take the pool due to an unsupported feature. I saw mention of this commit enabling feature disable functionality.  I grabbed a Ubuntu 14.04 boot disk and tried to install it, but got a build error, wondering if anyone might point me toward a fix so I can disable that feature and export this pool? SPL built and installed okay, but on the ZFS build I get from that commit, I get the following... ",True,False
zfs/zfsonlinux/7960,True,zfs/zfsonlinux/7960/458315146,"The discussion in this thread (now hidden) has not been productive.  In the future, please speak respectfully to fellow contributors.  @friend and I are working on putting a process in place for handling inappropriate behavior.  In the mean time, please feel free to contact either Brian or I privately if you have concerns about the behavior of ZFSonLinux community members. ",True,False
windowsserverdocs/MicrosoftDocs/1615,True,windowsserverdocs/MicrosoftDocs/1615/428420730,"Hi @friend, We do actually have quite a lot of on-premises documentation. We're sorry you didn't find what you were looking for specifically. We can address your concerns better when you reference the particular documentation that’s not meeting your needs. Thanks, Corey ",True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410769071,I recommend searching this issue tracker or git history for the individuals who added the dual watch thing and ping them to ask. Or get real specific with a repro of the issue as it relates to this library as I don't use gulp. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413254541,"For those of us who would like to continuare  Termux  triggers signal 1 of these three options; Any ideas why?  I have heard the point about , this is un'importante. ",True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410772144,@friend i think its double post   😢 ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413361146,"Straightforward question to @friend, probably without reply.  Can someone answer why they encourage something only to delete it? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413360303,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul) really as funny as you stated with your laughing emoji? Both  and  are down with the latest Termux updates.  This is not funny @friend.  It's a headache for me to keep these projects running while I get, ""broken because it's NOT Termux"" from you and our PhD candidate @friend who, btw, enticed me to contribute to Termux @ Wikipedia, only to delete our mutual group effort to promote Termux worldwide.  Why did you do this @friend? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413356569,"@friend You reacted with a laugh emoji; Is contributing to Termux only to see your contributions deleted (run afoul), really funny as you stated with your laughing emoji? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413346420,"How is your PhD coming @friend?  You asked me to promote Termux at Wikipedia, only to delete our efforts.  Why did you do this @friend? (Answer is not forthcoming afais) ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413345439,"Is this (Termux projects like   and  fail completely) what you want @friend?  I cannot work with people (groups) that entice me to contribute it (worse; wot submission), then delete; Sorry. ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413343773,Is this (Termux projects fail) what you want @friend? ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413343542,-,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413338513,"@friend you have asked me to promote Termux at Wikipedia, and you delete our efforts at Google+!  Why? ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413337357,@friend study initial post;  many users have posted this error to us.  Why do you promote the Wikipedia article only to delete? ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413330573,Does anyone have any idea why just Termux busybox tar generates signal 1? ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413329366,"I must disagree with your biased hair raising conclusions; Sorry to dissent. I disagree with your opinions wholeheartedly (learn to punctuation properly, then maybe we can talk). ",True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413327160,I must disagree with your biased hair raising conclusions; Sorry to dissent. I disagree with your opinions wholeheartedly. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413326468,I would like to know the answer to this straightforward question. ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413325427,I must disagree with your biased hair raising conclusion; Sorry to dissent. I disagree ,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413295173,-,True,False
termux-packages/termux/2735,True,termux-packages/termux/2735/413257852,"For those of us who would like to continuare  is a quicker way to check this than cloning the entire repository.  Only Termux  triggers signal 1 of these three options (Termux ,  and Android system ); Any ideas why? I have heard the point about $? in spinner(), this is un'importante… ",True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410779875,Sometimes I repost comments if I don't think they are being read. ,True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410623852,Same issue here. ,True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410724648,NOT WORK! ,True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/410133917,I recommend searching this issue tracker or git history for the individuals who added the dual watch thing and ping them to ask. Or get real specific with a repro of the issue as it relates to this library as I don't use gulp. ,True,False
webpack-stream/shama/199,True,webpack-stream/shama/199/347244050,"Since version 5.0.0, when gulp starts a task, webpack is starting as usual, saying it's watching for a changes, but whenever the file is changed, the webpack does nothing like not detecting any changes. 4.03 works fine. Passing different versions of webpack is not making any difference. ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368691858,"Since this discussion went way out of hand and I do not want to discuss it any further, I will lock this issue. ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368669841,"But I did. Maybe not as directly as I could have, but here are examples from that comment ... Obviously, I didn't suggest for you to read it just for me. In fact, I didn't even suggest for you to read it at all. I simply referenced it by link so that you'd know what book I was referring to. If you were to read it, it would be for your own sake, obviously, not mine. I don't suggest people do things just for me in the first place. If I didn't care about the success of this project at some level, I wouldn't have posted anything here at all. It takes time and effort to write an Issue report and follow up on the comment thread. There are plenty of other things I could spend my time and effort on. I chose to contribute to this project rather than some other. You needn't have had to. I'm just explaining how I know about the book and what field it is typically associated with (though it's even more general than HCI). You seemed to be wondering why I referenced a 15-30 year old book. Hence, I explained why. But all of that is kind of irrelevant as to whether or not to support different Go rule sets, or how to make the scoring mode more accessible and usable. It's just background information. Actually, regarding whether I quoted the book or referenced it from memory, I'm not exactly sure what your argument is, to be honest. What would it matter either way? Not sure what else to say. Right now it has a single line saying Just make it two lines Okay then, that's the button that has two functions, and one of them is not obvious (being the Details button where scoring mode toggling is hidden). That's the button I'm suggesting to either  1) Make it two controls, a Score display, and a separate Details button, or  2) Make it more obvious it's a button by adding visual affordances to it, such as by making it a hyperlink instead, or  3) Don't hide the scoring method toggle inside it; instead put the scoring method toggle in Preferences or Game Info, or  4) Partially eliminate the need for a scoring method toggle by showing both area and territory scoring on the same panel, as above, or  5) Something else if you prefer. I wasn't pointing out a contradiction, I was giving an example of another Go UI that already partially eliminates the need for a scoring method toggle by simply showing both scoring methods simultaneously, as above, suggestion 4. I disagree with your assumption that the scoring method is a property of the user's settings. IMHO, it should be a property of the game's settings. Therefore, it can and should be different depending on the SGF file, because that's where the scoring method (i.e. rule set) is specified. IMHO. Maybe the user's settings could include a 'default scoring method' for when they make a new game from scratch, but when loading existing games, which used pre-determined (i.e. before the game even began) scoring methods, I think the UI should reflect the game's settings primarily, and the user's settings should only be a default, if the game has no rule set specified. IMHO, of course. (Just assume I have 'IMHO' tacked on at the end of each sentence.) I'm not sure what this is referring to. Perhaps you mean the final game result? Thanks, but it's not really my idea. It's Don Norman's (or rather, I got it from his book; he probably learned it somewhere else, I'm guessing), namely the principle that each user control should have only one obvious function -- the corollary being that if you need to put in two functions, put in two separate controls. It's not a 100% all the time thing, it's just a principle. But a good one. From a time-tested book by a well-known researcher and engineer. (In case you were wondering where I got it from. Whether you read it or not is not my concern.) ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368614761,"It's hardly constructive criticism, since you didn't say what exactly can be changed. Also I don't know the book and am hardly willing to read it just for you. Furthermore, I didn't study Human-Computer Interaction. Let's not argue about formal definitions. My argument still stands if you change one wording for another. I did indeed miss this, but please do explain yourself further. That's exactly the button I'm referring to. No contradictions here. And I think WGo can be customized either way. I'm not a fan of how opening an SGF file can change a user's setting. Also, if the score has already been calculated, there is no need to calculate it again with the scoring tool. This is actually a good idea. ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368601849,"It is meant as constructive criticism. It's a very good book, which is why it's still in print, and the principles are time-tested. Also, I didn't quote the book, but referenced it from my memory of it. My Computer Science degree was specialized in Human-Computer Interaction, and Don Norman is well-known in that field. That's how I know about the book, and why I read it. Also, I did give a concrete suggestion, but since I added it later as an edit, perhaps you missed it ... Which button are you referring to? I'm referring to the score display control that shows up when you do Estimate, and it shows, for example, something like ""W+50.5"", and when you hover over it, it says ""Details"". Clicking on that control/button brings you to the Score calculation dialog where you can finally select Area or Territory. It's this dual-purpose control that both displays the score and is also a Details button that I'm referring to. It doesn't sound the same as the Done button you're referring to. Just for reference, other Go UIs such as the WGo UI display both territory and area scoring when you select Count Score from its hamburger menu. The real issue here is that I was opening SGF files which had their RU tag set to 'Chinese', but Sabaki was showing scoring based on territory/Japanese, rather than area/Chinese. If the scoring defaulted to area for 'Chinese', and territory for 'Japanese', that would be better, IMO. Unless they are opening multiple SGF files, in which case, the users would expect that the 'score' should be based on the ruleset specified by the existing SGF. Games from different sources, or even the same source (such as OGS), can use different rulesets from one game to the next. If the user has to open up the SGF file in a text editor to discover what the ruleset is, and then locate the difficult-to-find Details/Score calculation dialog just to toggle to the right scoring method, that's a pretty big pain in the UI. Sabaki can easily figure out which scoring should be default and toggle to that. Or, alternatively, just show both scoring methods, each on its own line, when the user clicks Estimate. Presumably, it also specifies how the score in the game result property was calculated. ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368487696,"There is a tag, RU (see  for specification. NZ rules would be roughly equivalent to Tromp-Taylor, as far as I know, just FYI), which defines the assumed overall rule set for the SGF. Any moves in the SGF which violate the specified rules could be considered illegal moves, perhaps making the SGF invalid. However, to say there's 'no concept' of ruleset in SGF is simply incorrect. As for the option to toggle scoring, it is definitely not obvious in the UI. I looked for it before posting this, although I was looking for changing the rule set, not for 'area vs. territory'. I'll look again.... Okay, that is definitely not obvious. Instead of being under Preferences or Game Info, you have to click on the score display within Score or Estimate, and the score certainly does not appear to be a button of any kind at first glance. Personally, I would try to follow the principles laid out in The Design of Everyday Things, by Don Norman, a very well-known design and usability researcher. For example, one of his principles is that a single control on an interface should ideally have a single function the score display violates this principle by acting as both a simple display and as a button, with no additional visual affordance to indicate that it might be a button (although mouse hovering does indicate this, but who would think to hover over the score display? I didn't, until prompted by your comment). Compare this with a hyperlink, which is also a clickable display object, but which provides the visual affordances of being a different colour to the surrounding text and is also usually with an adornment such as being underlined. Just my opinion. ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/368405261,"There's no concept of a ruleset in SGF, because the user can do anything they want. Sabaki only show warnings for simple Ko and suicide which can be disabled in Preferences. As for scoring, there is an option to toggle between area and territory scoring. ",True,False
Sabaki/SabakiHQ/341,True,Sabaki/SabakiHQ/341/300116763,"Is it just me, or does Sabaki not allow making games with different rule sets, e.g. Chinese, Japanese, Tromp Taylor, etc.? It even doesn't show which rule set is being used in a loaded SGF file (under Game Info). I think the scoring is restricted to Japanese only. If I'm correct, then please consider this an enhancement request to allow for at least Chinese and Japanese rules, and perhaps even Tromp Taylor rules, as this would be very useful for looking at games created by Leela Zero. Even if you don't fully implement different rule sets in game play, at least please display the rule set defined in the game's SGF file. ",True,False
Terra/ObliqueNET/139,True,Terra/ObliqueNET/139/455850225,"Ras, hun, you know pretty well who I am ",True,False
Terra/ObliqueNET/139,True,Terra/ObliqueNET/139/455230992,"Couple things missing from your ban appeal - your username, the ban reason when you try to connect, and how long ago your ban started. I literally cant tell with what you have provided so far. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401614405,"Sorry, no. Number one this is a pack with custom recipes, and custom unlocks. It's not just ""look up the docs for a mod"". It's ""trying to figure out what was changed specifically for this pack"". Number 2 Again requiring Discord to have any clue about what you're doing is the wrong idea. Number 3 Please re-read what you just wrote. Assume that that was written to you, instead of by you. Would you consider that to be insulting? I did. Number 4 You are not Sevadus. We have already established that this pack is one person's view, as implemented by a team. Not you. You do not have the authority to make the declarations you just made. They are your opinions only, yet you want to treat them as absolute truths. Please re-read what I said after my TL DR. You have just described the mods that I don't use or play with. If I am looking at potentially hundreds of mods, I am not going to spend 30 minutes to 2 hours on each one evaluating it. Mods that I play with are mods where the forum post explains enough of what the mod does/how it does it, and if it has a wiki, it's not just an empty skeleton for the users to populate, but an actual info dump from the author of the mod. Conversion modpacks? I've played a couple. My minimum standard is around the level of agrarian skies. That wasn't perfect, but it was good enough. Resource limited maps like skyblock in vanilla Minecraft make you think, but you're working with what you know. Maps where you start with essentially one sapling, some useless ground, and a bunch of mods you might have never played with, and then say ""go study these mods for another 3 hours; we won't tell you which mods to look at, we won't tell you what your goal is, and your only clue is to come from someone else who has already gone through this and figured it out"" are nothing more than distributed time wasting. This pack is right in the middle. It is distributed time wasting, but hey, at least we were clearly pointed at totemic upon entering age 0. Except for the things that we weren't pointed at, like absolutely no hint that there are backpacks in this pack. This is not ""poor me"". This is ""I think this is bad design, and here is why."" The response is basically ""only one person has the authority to say I agree, or I disagree, and that person isn't here"". ",True,False
Signal-iOS/WhisperSystems/2540,True,Signal-iOS/WhisperSystems/2540/258095414," [x] I have searched open and closed issues for duplicates   Bug description Signal's debug log currently contains part of the phone number of both the sender and recipient in the following form and posts it publicly to a gist Sender [ REDACTED_PHONE_NUMBERxxx999 ] Receiver [ REDACTED_PHONE_NUMBERxxx123 ] IMO all personally identifiable information should be removed from these. More users such as myself will be willing to submit debug logs. Steps to reproduce  Settings &gt; Advanced &gt; Enable debug log Perform an action on the phone Click submit debug log and choose link. View the gist to see the contents.  Actual result Partially redacted phone numbers exist. Expected result No personally identifiable info should exist in the debug log Possible solutions  Redact/remove the phone number entirely (preferred) If this info is sometimes needed by devs, hash the exposed digits for privacy. And then it could be compared against the hashed last digits of numbers in the DB if needed. Although this is probably rarely needed. Use a random UUID for users both locally and in the DB if needing to identify the users so part of phone number isn't exposed.  Device info Device iPhone 6 iOS version 10.3.3 Signal version 2.15.3.2 ",True,False
Signal-iOS/WhisperSystems/2540,True,Signal-iOS/WhisperSystems/2540/343155742,"not just the phone number, if you pay attention there are lots of other unique ids there for signal devs to make a link between your github account and the signal account, including the timestamps (as they have sub milisecond resolution). ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401630430,"JEI has literally EVERY RECIPE in the pack.... so whats the problem?   It's even setup in a manner where, if it's not in JEI, you can't make it.... yet. No one said Discord was required. I offended you? Working as intended.  Your OP is offensive given that you paid exactly nothing for SevTech but have the gall to stand up on a soap box and complain about, how a group of hobbyists did not make this pack for the general population.  As you have repeated pointed out, the pack was made for Sevadus.  Since you haven't paid money for the pack,  they are under no obligation to do anything.  Yet your attitude is that of someone that paid money for a product and is expecting a much higher tier of support.   This make you and entitled jerk. I have perused all of your tickets... honestly most of them are just a difference of opinion, and you, in this post come off as your opinion should have more weight than it really does.   The remainder are issues with the behavior of a specific mod which would need to be taken up with the mod author, not the pack author.   Based on some of the responses... you need to learn how to use the search/filter button. This issue tracker is for things not working as the AUTHOR intended, not how you think it should be, nor how you would have done it. You also mention that you're playing as part of a group... why are you not using the group mechanics? This pack has a theme, a structure that was intended from the outset.  Your opinion on implementation does not matter in the slightest.  You were not the intended audience. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401637470,"Hello, I have refrained from commenting here as I think the issue has become a little inflamed with a fair bit of rhetoric and complaining. I am the author of the mod that at first orders has annoyed you so much. ""All of these ""in world"" non-GUI blocks essentially restrict you to only those items that you have room for in your hot bar. None of the rest of your inventory space is usable. My hot bar is almost always nearly full in normal play, and even so far in the pack I don't have much space in it."" This is part of the reason we made these blocks. Why should you be entitled to vanilla inventory management in a hugely modded pack? I was asked to make blocks that worked without guis and were more 'primitive' than the vanilla blocks you unlock later. This was the objective to making players appreciate even the most simple of vanilla blocks once more. ""Good or bad, you have basically chosen to document the modpack and its recipes with JEI. And that documentation is lost as soon as you are using the work stump. The mod page for primal tech (work stump mod) claims that it has JEI support. Yet I don't see it in play."" OK this is a technical problem that involves several mods, of which none of us has a viable solution to fixing. The mod for the most part has JEI support for recipes, but the workstumps are a special case that cannot be added due to restraints on game stages, JEI and Primal tech (as well as other mods) with auto-crafters. The complaints about the placing mechanics are just that, complaints - sorry but I like it and it does what it needs to; limits the player from just throwing a load of things in to a gui with shift clicks and magically pulling out an item. I'm sure many of the things you deem 'unplayable' in the pack are more annoyances than game-breaking, so I'll leave it there at the risk of a wall of text (whoops too late). Cheers, Me. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401653140,"Okay, that's quite enough of this. This has gone well out of proportion and you guys are now at each other's throats. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401609493,"The 'poor me' that these posts are dripping with is infuriating, since it would unprofessional for the Dev Team to excoriate you, I'll step up. Most of this complaining is stupid.  You're complaining about lack of documentation, that is the Forge/Modded world in general.  Very few mods have 'user level' documentation, most tutorials that I have seen, have been from people taking the time to either have in-depth QA with the author, reading the API, or just experimenting. If you want your hand held through a puzzle pack, find a new hobby, this isn't for you.   Seriously, at worst SevTech is breaking your ego because you have forgotten what it's like to not know something about MineCraft.  I just started Modded this past Winter, as such, with every new pack there are different mods for me to learn.  SevTech merely took every thing you thought you knew and turned it on it's head, and you are butt hurt because you feel like a noob, and you're acting like a child, grow up. This was a commissioned work.  I am glad that the Dev Team and Sevadus have made this work public, it's challenging with many paths to achieve overall completion.  I am having fun with it.  It is frustrating with some of the changes to mechanics that are not apparent, but the Discord community is extremely helpful and courteous. Most of the issues you have brought up, are your issues.  There has not been anything in this pack that I have not found information on by watching Streamers, YouTubers (both mod tutorials and SevTech LP), or by reading/asking on Discord. It might simply be this mod pack is not for you, but that is all on you not the Dev Team.  There are 1200+ other mods and 2000+ video games released every year, and if that's still not for you, Crayola might have something more your speed. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401589794,"Well I mean... and only later do we discover that there's apparently a tool in age 0 that takes the leaves off of a large area of trees in almost no time.` Eeeeeyup. Definitely everything SevTech is about. It's a Minecraft-themed Homework Simulator.  When I was getting through age 3, I was making a bee-line for the age advancements to breach age 4, hoping blindly it would unlock diamonds by age 4 because why in the world would diamonds be exclusive to an age that prioritizes space travel? How are diamonds more valuable than literal rocket-science?  I wanted them because in the Cyclic book, I read about diamond spikes, which were the first item I discovered that apparently would act as a player-kill. Already having a small, rather inefficient mob farm built by that point, all I wanted were those diamond spikes so I could turn my mob farm into an experience farm as well. Come age 4 after some grueling and nightmare-ish progression grinding and googling and video watching and building and rebuilding when I realize I built it wrong and all the hullabaloo that comes with stupidly vague SevTech progression... I discover diamonds are in fact age 5 not 4, but browsing through JEI, I noticed mob grinding utils is now unlocked... which comes with mob-killing items that drop experience, and dark utilities now has a ""player trap"" which does the same thing as diamond spikes.  My ultimate goal was wisped away from me due to lack of SevTech information, and then immediately returned to me through another avenue via lack of SevTech information.  This is unfortunately how the whole experience is, honestly. You will have a suckish time if you don't constantly browse and research what is newly available. SevTech seriously seriously VERY EXTREMELY BADLY NEEDS a feature where it lists to you all the items unlocked by age, and also provide links to resources players will end up likely googling anyway just to try and learn more about a mod they are using. Since SevTech has so many mods, it needs to compensate for this massive overflowing incline of a learning curve it now results in, and provide players something more comprehensive.  Something to list what each age unlocks (only available after you reach that specific age). Way more detail about where to find more information concerning a mod (I.E. does the mod have a book the player can craft? Or should they default to googling and thus be provided a link from an in-game description instead?). SevTech is very anti-player-friendly.  Though to be honest, apathetic-looking github management and poor/nonexistent in-game teaching methods aside... I just want the damn modpack to work again. Seriously, whatever happened with the 3.0.8 update has made it so incredibly unfun to play SevTech with how unstable it is now that I may not ever have the motivation to actually make it to age 5.  Literally a complete rollback to 3.0.7 would be 100% acceptable to me at this point, because at least the modpack can be played in a heavy setting again, such as large builds or complicated surroundings (which, you know... age 4 and 5 will basically demand from the player anyway). Unfortunately, we may just be barking at a bush from the perspective of the people involved in sevtech development. If it was made primarily to meet a specific guy's standards, I doubt anybody but him coming forward and saying ""shit needs a lot of work, yo"" is gonna do anything besides fall on deaf ears. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401551306,"I was all for trying this modpack out, and I look at all of the stuff and I'm like ""wow, this looks actually cool."", and then I get to the crafting stump.  Words cannot describe my hatred for the crafting stump. I have tried several things to get my items to go into the right spaces and even tried moving around it. I understand that there is a front side, I've moved to it. I've watched videos about it for christ's sake and I still couldn't get it to work. I tried doing my homework although everything didn't even work. The achievements didn't even play properly. I made my crafting stump and I was like ""oh, chopping block for planks."" so I made that and suddenly I just then got the achievement for it and the crafting stump (which only THEN let me advance to age 0). Same thing happened for when I broke a log with my hand, and then later made a fire stick, and THEN made a axe, I got the achievement for making fire (which I hadn't done), and breaking the log with my hand, and then the axe achievement. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/399713194,"I mean concerning the issue of SevTech not explaining things but rather assuming the player knows or can easily figure them out, that is a bit of a problem. I had plenty of instances where how to do something simple wasn't detailed anywhere in SevTech, and I find myself constantly googling things from specific mods in order to use them. Most recent example would be making stabilized metal with an arc furnace. JEI only says I needed a hardened mesh, iron, and some refined hardeners. All JEI showed was that I needed all three in the same place, but it turns out the refined hardeners needed to be in the modifiers slots along with the iron ingots. Never would I have guessed that iron ingots were NOT what was being melted down to make stabilized metal, and instead were put in the modifiers slots instead of the smelting spots. I spent over an hour and a half pulling my hair out. Google was of little help this time because the recipe is different in SevTech than what it showed elsewhere and I had to eventually just rummage through random youtube videos concerning steve's carts until I noticed one from a streamer involved an arc furnace, and surprise surprise he spent almost half an hour on the stream trying to figure out how to make stabilized metal. Only when he eventually discovered iron ingots needed to be on the right slots instead of the left in the arc furnace was I then also able to continue with it myself. There's like, probably a dozen examples of SevTech progression-related advancements where it just says ""do this thing with this mod"" but it doesn't tell you how, or always give you that mod book. There's a few books from mods that you have to craft in order to try and learn about that mod. It doesn't help that SevTech starts off by giving you these books when you reach those points for free, and then stops entirely leading the player to believe there IS no book to help with that mod when in fact there is, you just need to browse JEI until you find it and craft it.  There's a lot to complain about in terms of SevTech teaching players what to do. Not just in the first two ages either. I'm in age 4 and pausing the game to go spend half an hour googling information that isn't obvious or clear to me in order to progress or acquire something exceedingly valuable is simply par for the course at this point. I've gotten used to it and I never thought about how stupid it was. It do in fact hate games that make me stop playing them in order to figure out how to continue playing them. A modpack for a game like Minecraft was probably always going to entail this, though. As for the I actually disagree. All those extra advancements are more a quality-of-life thing. They are pointless in the same vein that the mushroom islands or woodland mansions are pointless in vanilla minecraft. If you consider defeating the Ender Dragon and watching the end credits to be the ultimate goal, then there's an ENORMOUS amount of stuff in vanilla miencraft that's pointless, and only there if you want it or find it fun to invest your time into. SevTech does this but on steroids. I've skipped kitten kaboodles of advancements because they didn't interest me. Literally never even touched Steve's Carts. Didn't even make a cart or use any of the mod at all. Only acquired stabilized metal to get a mob duplicator for my mob farm.  I think that's fine. It allows you to select what you want to do, and only rarely forces you into mundane or tedious vague bullshit as a requirement to progress OCCASIONALLY.  For the most part, the age-progression content is straightforward enough. There's nothing wrong with focusing on ONLY the age progressions. I for one played that way intentionally for a good while, thinking once I had enough stuff unlocked, I'd simply come back and browse what I wanted, getting it later, which is in fact now what I'm doing; building a massive sky castle that will have absolutely everything I could possibly want or need now that the majority of SevTech and its mod contents are available to me.  If you were hoping for progression where you only advance after doing 100% of everything in that age, I would argue you don't know what you're asking for, because during age 0 and 1, I thought that's what I had to do (again because SevTech never told me that age progression advancements had a unique shape to their advancement icons) and it was a tedious nightmare doing this and finding that and completing something I cared nothing for just to try and continue. Overall SevTech isn't really good for player's who aren't already at least relatively familiar with a large handful of mods. It requires homework outside of the game in order to keep going further, yes. I don't like it much either in that manner. It's more a serious of mods strung together with the idea of one unlocking the next, rather than something that was delicately crafted to provide the player the complete and total experience from several of the best mods available in the pack in as smooth and convenient a way as possible. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/401280539,"In my opinion, PrimalCore and Immersive Craft are mostly meant (and to some extent Embers, Immersive Tech, Blood Magic -- basically anything without a GUI) to be used with VR goggles. What otherwise is tedious to use becomes the more agreeable way with VR. ",True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/399667555,But to be clear this pack was designed for Sevadus. It's designed around him and how he wanted it. Nothing will change in regards to the advancements or layout. It's done to a spec which we met. ,True,False
SevTech-Ages/DarkPacks/2977,True,SevTech-Ages/DarkPacks/2977/399667432,"I'll go over this in detail later on. But to clarify one thing until then. This was posted due to the fact you opened a tonne of petty issues on that day all of which lack details and you expected us to help/give support on little to now information. That and most of them are Discord issues. This tracker is for bug reports and mod suggestions not. This is why we have Discord it's open and more people can make an input on helping/teaching people. This is a hobby for myself and all the developers who make this pack. We're not going to waste our own time when working on the pack and then deal with issues which no effort was put into them or could have been dealt with in Disord. When we have pack testers, moderators and even the user base helping each other out. If you felt hurt by that then you need to understand that we're not going to spoon feed users on this tracker on how to do x or y. A lot of modpacks use new mods or mods which change mechanics which do lack documentation. But this is why those packs have Reddit's or Discord or even Forums where the community creates the documentation. One big example being this  like this was all done by the community. It's linked in Discord on our Wiki and even on top results for Google. But that's all I'm going to cover for the time being. I'll comment in regards to each section later but I wanted to hit this on the nail. ",True,False
SevTech-Ages/DarkPacks/2607,True,SevTech-Ages/DarkPacks/2607/325759549,"           hi my name is Smilemore79 I play sevtech ages on a server I'm very into it and love the way the mod is set up. not sure if I'm in the right place here for my issue I'm having. I'm in age three now and I'm wanting to make the bottler machine, it calls for the fluid pump, however I cant find any information or crafting recipe for it.  ",True,False
RasPlex/RasPlex/562,True,RasPlex/RasPlex/562/379328648,yeah that would be great. or at least short instructions how the driver could be installed manually? (mt7610) because the instructions from here are not working on the libreelec/rasplex system  ,True,False
RasPlex/RasPlex/562,True,RasPlex/RasPlex/562/206882649,"Hello, Is it possible to add support for this chipset wireless ? I can help if you want. Thanks. Jon ",True,False
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390037882,"The template exists for the sake of structured communication of an issue. If you want an issue resolving, then provide the information we ask for. How we deal with issues created ourselves is not relevant to this subject. ",True,False
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/390037053,Do you have purePerms installed?  That causes the crash. ,True,False
PocketMine-MP/pmmp/2187,True,PocketMine-MP/pmmp/2187/324211421,"Issue description After the new update, i try to join my server and it just crashes my whole client, this has been reoccurring since the new update Steps to reproduce the issue 1 Put the latest dev version  (1.7dev-999 「[REDACTED]) in your server folders 2 Try to join your server 3 client crashes OS and versions Pocketmine 1.7dev-999 「[REDACTED]」 ",True,False
PocketMine-MP/pmmp/1945,True,PocketMine-MP/pmmp/1945/359199659,Such a plugin already exists. And you chose to use a bleeding-edge build with it removed. You have nobody to blame but yourself. ,True,False
PocketMine-MP/pmmp/1945,True,PocketMine-MP/pmmp/1945/290220447,"Issue description In fact you made things worse, for all the cheaters now there is an opportunity super fast to break blocks. Now all users will NEED to make a separate plugin to fix this problem.  The best option was to leave it standard, if someone didn't like it, it was the switch in pocketmine.yml Really, thanks to you, I got ruined the world of survival and now have to do the cleaning map. Ex js code Video  and versions  PocketMine-MP  7.2 Game version PE/Win10)  ",True,False
Terra/ObliqueNET/139,True,Terra/ObliqueNET/139/456909459,"You were banned for spamming the chat with a banned player's phone number. That you have momentary Alzheimer doesn't erase that. Good of you to try, but we aren't stupid. ",True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/224342781,"Make it overrides real console execute, soo it doesn't run or bypass all command blocks. ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/441327554,"@friend It may be one of the problems already fixed, have you tried with the latest master? ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/441176152,"This was just a small fraction of the logs.  The errors indeed were all over the place. WinBtrfs was gradually corrupting my partition. I remember logging into Linux before it got completely hosed and I remember Linux Chrome complaining about a corrupted profile directory. After some more time in Windows, I could not log in into Linux and got stuck at the login screen (the messages above from 8 months ago). The next stage of corruption was the mount failure (7 months ago). When I uninstalled WinBtrfs, no more BSODs, no more corruption. Which one causes the other (BSODs and corruption) is not clear to me as I have zero experience writing FS drivers, but to me it looks that everything is pointing towards WinBtrfs because it was correlated with it being installed. Do you think that all 4 people who experienced WinBtrfs KERNEL_SECURITY_CHECK BSODs in #87 all had malfunctioning drives as well? ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/441155746,"No, I don't think that. If there were bugs in the checksumming or data-writing code, you'd see errors all over, not just in one or two sectors like your logs suggest. Furthermore, the BSODs are almost certainly a consequence rather than a cause of the corruption, if indeed they're related at all. From what I know about SSDs, they internally relocate sectors when they realize they are bad, which is why it looks okay to you now. I'd still get a new one, though. ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/440933440,"It’s an SSD drive which has not otherwise exhibited problems. Normally, I spend all of my time in Linux. However, I was doing some porting work and I was using Windows intensively during a month or two, without booting Linux. I remember receiving BSODs caused by WinBtrfs. I commented on another issue about the BSODs - #87. After I was finished with windows and booted back into Linux, I found the partition completely hosed as described above. Don’t you think that a natural conclusion is that WinBtrfs caused this? ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/440892220,"For what it's worth - which isn't much given that it's over half a year ago - it looks to me like your device is on the blink. The fact you had generation errors in your free space cache implies that your drive is returning outdated data for some sectors. I don't think this was caused by my driver, so I'm going to close the issue. ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/440808590,"I think English isn't his first language, which is why that message looks odd. It probably means something completely different to him. ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/440798437,"Windows 10 supports Btrfs out of the box, just in case ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/440775659,I wonder if this has been fixed because of the recent changes. ,True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/384939814,"I set the driver to read only. After getting a BSOD, it failed to mount on linux Fixed by ",True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/378875083,here are errors from the kernel log ,True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/378871665,-,True,False
btrfs/maharmstone/88,True,btrfs/maharmstone/88/311528891,"I've recently been spending more time in Windows, with my Ubuntu BTRFS install being mounted using the latest release of the driver. When I tried to boot ubuntu, it fails to start the Unity GUI session and returns to the login manager. Seems like too much corruption has accumulated / ",True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/297470918,"the server jar needs some modding to remove the real execute, i can do it. ",True,False
classroom/education/1678,True,classroom/education/1678/432802043,"@friend GitHub Classroom is built on the GitHub API, it does not alter the functionality of github.com. When you connect an organization to Classroom, we automatically create student repositories for you from your GitHub account. As such, all of the repositories will be visible from your GitHub account. While I understand why you might want this, it is not something that we can change. ",True,False
classroom/education/1678,True,classroom/education/1678/373227578,"Describe the bug A teacher using classroom sees all the student repositories all the time in GitHub. Teaching is a specific activity, separate from ""normal"" github use.  These repositories and accounts should only be visible in github after specifically logging in through/doing a procedure from the ClassRoom interface, i.e. the place we sent the invitations to create private repos in the first place. At the minimum we need a global ""filter all ClassRoom related"" on personal setting of github profile or something, so teachers can also do research. I realize this is an interaction between how ClassRoom uses github to mascarade teaching into a git image. It is still a messy bug in the sense that I would need to open a second github account specifically for teaching at this stage, but I like my account. To Reproduce Steps to reproduce the behavior  Use github for normal github usage  develop open source Enroll into classroom Click on 'Send Assignment Link' to about 100+ students, 3 weeks in a row Add a github filter to your mailbox Connect to github, try to find any of your repositories in the ""repos"" search box. Admire the fact the bar is trailing off screen  Expected behavior These accounts/repositories should not be visible under github unless I explicitly am doing ""teaching/grading"", i.e. accessing github through ClassRoom provided links. Screenshots see attached  Additional context I have a lot of students. ",True,False
classroom/education/1678,True,classroom/education/1678/432752999,"Hey @friend, this is behavior is managed in GitHub.com and therefore we are not the best place report this to. The best you can do is contact GitHub support about this ",True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/457874895,Unpinning and locking the issue. I think 7 days of attention was enough and arguing didn't make sense. ,True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/455825290,"Dude's a troll. I've got PayPal, assuming that 125 euro is the amount, I'd be happy to send it to him for you. On Jan 19, 2019 415 PM, Bartosz Wójcik notifications@friend.com wroteDo you want to say you were offended by the reported bugs too, that could be fixed with changing 1 function to another to keep your software backward compatible (what a terrible idea to keep your software backward compatible, I know)? It's getting better and better. —You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread. ",True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/455814932,Maybe linking  would help others understand why I have refused your donations after 2016 and why I think this couldn't end up differently. ,True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/455810434,"I thought I didn't remember the facts correctly in our recent emails, but the good thing I had it all saved and I don't feel guilty, because at first I thought I have paid for the link in AsmJit project, but now we all can see you came with that yourself. ",True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/455810232,"Sure thing, here you go, after I made a donation I sent you the link to my site How's that a paid ad, when you wanted to put it yourself as a thank you for the first donation? Don't you even feel bad, accusing me of something that didn't even happen? In 2016 I wanted to advertise in AsmTK project for 150 EUR, but you refused (you didn't want to make this kind of affiliation with me, whatever that means), that was the only case I wanted to pay for a link. ",True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/455809071,Read above. ,True,False
asmjit/asmjit/231,True,asmjit/asmjit/231/455801270,Why the sudden change of heart? ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/392540684,So given there has been no valuable contribution I'm re-opening until we can validate the issue is in fact solved or no longer relevant. ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/392536692,"Cause im not  helping tf  From Ryan notifications@friend.com Sent Monday, May 28, 2018 35411 PM To TotalFreedom/TotalFreedomMod Cc marcocorriero; Mention Subject Re [TotalFreedom/TotalFreedomMod] Make execute a TFM command. (#2004) @friend What was the reason for the issue closing? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub or mute the thread",True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/392533441,@friend What was the reason for the issue closing? ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/392328680,Now we no longer have Clanforge is this still an issue? ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/309435509,I realised. ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/309420197,@friend Command_gcmd is not the problem ) ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/302300863,The simple patch fix is to change this line ( to ,True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/298312166,"Yep, it has been patched, with a small edit on totalfreedom server jar and this addiction in tfm ",True,False
TotalFreedomMod/TotalFreedom/2004,True,TotalFreedomMod/TotalFreedom/2004/297546191,@friend So has this already been patched on the server build? ,True,False
babel/babel/8432,True,babel/babel/8432/411191284,"I legitimately can't tell what issue you're running into from this code sample. With the plugins you've listed and the input code, the example generated code is not what Babel produces, since there is a  variable that does not exist in the input, and otherwise looks like what I'd expect. You have not stated what about it is different from what you expected, and we are not psychic. You're clearly frustrated, but if your goal is just to vent at us and not have a useful discussion, you are not welcome on this project. ",True,False
babel/babel/8432,True,babel/babel/8432/411184713,Rude issues aren't the way to get help. Please follow the code of conduct. ,True,False
babel/babel/8432,True,babel/babel/8432/411184222,Please fill our issue template so that we can actually help you. Feel free to open a new issue. ,True,False
babel/babel/8432,True,babel/babel/8432/411183013,"Hey @friend! We really appreciate you taking the time to report an issue. The collaborators on this project attempt to help as many people as possible, but we're a limited number of volunteers, so it's possible this won't be addressed swiftly. If you need any help, or just have general Babel or JavaScript questions, we have a vibrant Slack community that typically always has someone willing to help. You can sign-up here for an invite. ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401861072,This isn't stackoverflow. ,True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/337570861,"Hello, i have read this   , truly understand Sort() of arrays, but in some cases the fast adapter should not be clear() , and add new sorted array of items to it, i just wonder if something can be make to support this feature in realtime when we add an item, when delete or when move ... Thanks ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401856858,"I see, so this is how i use it  This is the item class  FastAdapter   fastadapter.add(new SampleItem(""TKIP"",""-45"",""WPA"");` can you help how to modify the class to automatic sort by signal please, sorry my low English, Best regards. ",True,False
DSharpPlus/DSharpPlus/282,True,DSharpPlus/DSharpPlus/282/387556075,Getting defensive? You know what you did. ,True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401855597,"And you won't be able to use FastItemAdapter for that, better use the FastAdapter and add the model adapters to it. ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401854501,"I understand that and really thanks for your explanation. Can you help a little to understand it better if you can... So i have implemented   1)  2) in the SampleItem class there are some variables like   Name, Signal, Width , etc.... How to make some modification to this to be able to make the adapter to sort the items inside it by Signal e.x ? So when new items added, deleted or moved, the adapter to be able to resort they ? It would be really great help if someone provide help for this, because i have writed my self hundred of lines to manually make this but sometime it not working or produce bugs like  ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/454313184,"@friend thanks for the feedback. I should correct some points because it causes some misunderstandings. First of all Community edition provides more and more features even includes some enterprise features and used by lots of developers in the community. Using unique stream id both for streaming and playing is just about implementation example and you can manage other things on your application level based on this open-source project. I also gave an example about how you can change output name of streaming files that you will give to users. Therefore changing these names, users can not reach your stream (Alice's stream ) URL and you do not have any security threat at this point. To make it clear, One-time token implementation is developed for only limiting audience not for fixing a security issue. To sum up, Ant Media Server Community Edition is totally open source software and you can develop your application based on that, during these phases, you can change the structure, way of operation etc. Sure for them, you can get support, documentation etc every time. ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401849860,"Hi, you can provide your own item list implementation to any model adapter. ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401858194,"@friend , Without making any modification in the SampleItem class ? Just to call this method ? And how we build  or  because no documentation for that i'm sorry ... ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401857355,`´ ,True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/344986635,tried myself on new clean project - everything works fine. Better if you will create sample project where it will be possible to reproduce this issue. ,True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/344972349,"Try downloading and re-importing the latest code build, updating cocoa pods, cleaning your project and restarting xcode. Also, make sure you refresh your frameworks in your build settings. I didn’t want to leave up an answer as the maintainer seemed angry. Hope that helps. Thanks, Sarah ",True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/344932239,"Hello @friend. I'll make the same answer as I did to @friend many users, including me, build GRBD through CocoaPods almost daily. And this issue does not happen. So if you want help, please take the time to write a proper problem report. And start by checking the GRDB requirements at the top of the readme file. Thanks. ",True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/344928233,"Hi I found the same issue, the issue is that when we install GRDB through cocoa pod, and then when we try building the application, the build shows error in FetchedRecordsController of grdb. Kindly help us fixing it. I am using xcode 9 and swift 3 ",True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/335293498,"The code has an issue and won’t build for the latest XCode - GRDB.swift-master/GRDB/Record/FetchedRecordsController.swift8847 Unable to infer closure type in the current context     let itemsAreIdenticalFactory ItemComparatorFactory&lt;Record&gt;     if let isSameRecord = isSameRecord {         itemsAreIdenticalFactory = { _ in { isSameRecord($0.record, $1.record) } }     } else {         itemsAreIdenticalFactory = { _ in { _ in false } }     }  ",True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/264024004,"let itemsAreIdenticalFactory ItemComparatorFactory&lt;Record&gt;         if let isSameRecord = isSameRecord {             itemsAreIdenticalFactory = {  in { isSameRecord($0.record, $1.record) } }         } else {             itemsAreIdenticalFactory = {  in { _ in false } }         } ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401854943,"There is already an implementation that is sorting the items after adding, moving ect. ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401851470,"@friend , any documentation for that or how to use in more detail ? Thank you For example we have a AbstractItem with three data  Title, Signal, Capacity ect .... Just need when make changes to adapter to have the ability to automatic sort by  signal for example or anything else. How can we do that ? ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401860439,"@friend , hahaha i have 3 days working for that and my head now is totally stucked D D , please if you can rewrite my implementation in the comment above that i have writted my class and implementation how i add or delete items D D D , you don't have other choice hahahaha, thanks ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401859286,"you have to store the reference of the ModelAdapter somewhere ofc to add item to it. No modification of the items is required for that.  An sample for the interceptor is  for example, but in your case the interceptor will return the value without nay changes. The item list impl is the class i posted before ",True,False
FastAdapter/mikepenz/695,True,FastAdapter/mikepenz/695/401852409,"Its basically the interface for the implementation that is managing the items list. You could for example add an own add implementation and call own calculated adapter callbacks. There is currently no documentation for it, thats true. Your implementation would look similar to the default one but without the default behavior you don't want to have. ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/454211570,So basically you have an extremely easy to exploit security vulnerability and decided to only fix this is the paid Enterprise Edition? ,True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/454098109,"Hi @friend, Sorry for late response ( We discussed with the team and decided to continue token control in Enterprise Edition. But we can support you about dealing with this issue with Community Edition. You can rename produced files (HLS m3u8 or Mp4) using Ant Media Server Muxers  Init methods ( an example, for HLS Muxer go to Init method and edit this line to change output file names  doing that, users can not guess stream publish id by analyzing stream URL. Please let us know if you have any issue or just send an email. ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/445741131,"Hi @friend, any news from the team? ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/441623136,"Thanks for your feedback. They are valuable for us. We will think about it with the team, make some evaluation and let you know. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394339711,"I proposed a similar solution in a forum thread so for each of theese options we could make a parameter in the parameters menu. Each parameter will have three options Force ON, Force OFF, Default. The 3rd one (Default) will cause default behaviour with GUI appearing at mission start. Others will force the corresponding options to one of the two states. So We have total compatibility with people already running the mission and we add possibility for other admins to set it to whatever they want. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394319595,its more or less the same I Will add this and some other options with defaults. Life will be easier. ,True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394313318,"Can you check @friend solution that was on 1.8 version ? The goal is to actually not need any admin at mission restart, in cohesion with the member server/mission restart, especially in the case of auto restart servers. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394295262,"Will try to persistent save YES by default and only being able to be changed by server admins, so new starts Will allways depend on an admin. Switch commander yes by default and membership yes by default, but those will get overriden once the load is done. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394294547,"Thanks @friend. Back to the roots, omitting his lack of social skills and education, Alex idea was good and Will be implemented (once I finish the whole AI suite which is by far more important). ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394175475,"@friend I repeat you are more than welcome to help posting issues and PR on this repository, in english ;) Issue will be treated later on. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394170424,"This dude is the owner of this mission and got all rights on this code, if it says it's interresting but got more important issues that's how it is. - это ты вообще к чему написал?  You've been welcomed multiple times to quickly and very easily fix this very important issue as you said.  и что, это даёт возможность мне хамить??? Your ambiguous comments (that you deleted...) and you closing the issue show your lack of maturity. Even worse, you are threatening people on a collaborative platform ? - это вообще враньё,, откуда ты это взял? Closing issue drama has not is place here. - это новое слово в драме? не слыхал о таком - я автор темы, хочу - закрываю  ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394156172,"This dude is the owner of this mission and got all rights on this code, if it says it's interresting but got more important issues that's how it is. You've been welcomed multiple times to  as you said. Your ambiguous comments (that you deleted...) and you closing the issue show your lack of maturity. Even worse, you are threatening people on a collaborative platform ? Closing issue drama has not is place here. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394152150,"Honestly, it's unclear who this dude thinks himself to talk to me like that. I could certainly put this rude person in place, but I'm not going to do it. You can do what you think is necessary, but I'm not going to help you any more. And more - you can use Google translator when reading the text, without risking to lose the sense of what is written. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394032149,"It's actually a functionality which we have already implemented in the community version of Antistasi. It worked this way There was a parameter ""Allow to start a new campaign"" which was OFF by default. If you wanted to start a new campaign, you'd set it to ON manually and then the menu would ask you if you wanted to make a new start. The reason behind this is to ease the administration of automatic server restarts when there is no administration instantly available. It also helped us a lot at the official server because users would just join the game and the progress would get loaded. I am not sure if the autoload is currently present in the mission. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/393885143,What is not subject to translations is your -1 reaction and your closing of the Issue ,True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/393877509,"@friend actually yes it is, i understand the frustation but lets keep it respectfull and enjoyable for everyone, especially that I think you guys just misunderstood due to language translation. In the meantime @friend you are more than welcome to fork this repo, fix this issue and send us a pull request ;) I invite everyone to take 5minute to read this  ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/393766966,"yeah, I did not expect anything else, thanks ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/393329149,but there are more important tasks and my time is not unlimited ,True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/393246500,"belive me it’s not low priority task, it’s very very important task you are very good man if you do, it’s not so complicated ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/389837101,Will study the possibility. It seems a good idea ,True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/323119824,"Version 1.0.0+ Mods CBA, TFAR, ACE(no-medical) Environment MP dedi .rpt attatched? NO have you edited the missionfile? NO Is it possible to add a parameter such as ""load save"" to the parameters (lobby) of the mission? It will automatically load the previous saving of the campaign, by default (for your servers) you can set it to whatever value you want, for example, it's off, me and other server owners are very comfortable will be when I can turn it on (for example, through the cfg file) ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394397956,"These are my notes of the params I Will add, pls do not hesitate to suggest a few more Load last Save def Yes Server membership (Overriden upon Load) def Yes. Switch Comm Def yes. TK Punish Def Yes. Mission Radius Def 4Kmts (4,8,12) Allow PvP def No Allow player markers def Yes AI Skill def Medium (mult 0.5,1,2) No of same ítems in Arsenal to unlock def 25 (15,25,50) Civ Traffic Level def Medium (mult 0.5,1,2) So if the server is started by an admin he Will be able to tweak whatever, if not, the default values are applied, and those are suitable for open dedis, no conflict with anything. From there, JiP players Will see the traditional Load window for their personal saves, and nothing else. ",True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/394801641,Arsenal restrictions for non-members allow/forbid taking non-unlocked weapons. In case people want to have membership without these weapon restrictions. ,True,False
A3-Antistasi/A3Antistasi/57,True,A3-Antistasi/A3Antistasi/57/396178952,"Non members picking non unlocked weapons can mess the game, as in other topics, so if ppl wants to allow that kind of thing they may just disable the membership requirement. Closing as it's already implemented. ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/441609766,"@friend thank you for your answer, which raises some concerns. I understand that people need to earn a living, hence the community/enterprise edition split. However, in most if not all projects, the community edition implement the core features that are absolutely mandatory, while the enterprise edition add extra features that are needed for more advanced use cases or bigger installations. The way I understand it, a basic media streaming server allows  One user to publish a stream Everyone to receive a stream  Item 1 is simply not available in the community edition, since everyone can actually publish on any stream. In some cases, additional security is an extra feature, but that's not true here having an even basic restriction on who can publish on a given stream is part of the core use case. Without that, the software is actually dangerous to use for any real-world stream! Let me take a concrete example showing how bad it could be. Alice has a video game a stream on an Ant Media Server (Community edition), with some young viewers in the audience. Alice's streams are completely safe for any audience. But one day, for fun, someone decides to hijack Alice's stream and broadcast porn instead. They can do that in literally 1 minute, by simply examining the Stream URL in the page source and firing up OBS. Alice looses her audience, reputation, and can even be sued by angry parents. Knowing that publishing is left completely open, I don't understand why anyone would use the Community edition of Ant Media. The attack surface and risks are just too big. I sincerely think publishing should be protected by default in the community edition, and I hope that you'll consider that for the safety of viewers and streamers on your platform. ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/441529764,"@friend  Yes, your mentioned use case is true, publishing and playing are performed according to the unique stream Id. For solve security concerns, Token Control mechanism is developed for the Enterprise Edition. This solution protects your publishing and playing operations. Please have a look at these wiki and blog pages. If you need further assistance please send an email to contact[at]antmedia.io. Blog   ",True,False
Ant-Media-Server/ant-media/579,True,Ant-Media-Server/ant-media/579/381864713,"Hi there, I don't know if it's the proper place to ask this kind of questions, let me know if you'd rather have this published somewhere else. I'm currently doing some research on media streaming servers to integrate live streaming into Funkwhale, the project I'm working on. Ant media server looks like a really good pick for my use cases, but I'm not sure how to ensure viewers cannot hijack a stream. When creating a Stream in the interface, you can  Copy the RTMP publish url, like rtmp//localhost/LiveApp/499481361945988697107161,  being the Stream ID Copy the player embbed code, like ,  being the stream ID, the same one as in the publish URL  Since the Stream ID is used for publishing purposes, but also shared with viewers, my understanding is that any viewer can easily guess the publish URL by inspecting the player source and potentially hijack a stream. I may be completely wrong or missing something, but I'd like to double check that with you. Is this normal behaviour? Is there another way to achieve what I need (having a non guessable rmtp publishing link)? I can see that there is another issue linked to authentication ( but my idea was that providing a different, non guessable URL (with a different ID, but binded to the same stream) for viewing / publishing. Let me know if you need additional info, and thank you for the incredible work! ",True,False
Aether-Legacy/Modding-Legacy/341,True,Aether-Legacy/Modding-Legacy/341/458563508,"Yes sure, however content created by other mod authors is still licensed, in which the original Aether mod. We were given permission by the original team behind the mod as it was written here  I would still highly recommend forking the repo and helping contribute. Anyways, if you aren't happy with Aether Legacy with modern versions, feel free to play the original versions or try out Aether II. We're not professionals, we're just dudes that love to mod Minecraft. ",True,False
Aether-Legacy/Modding-Legacy/341,True,Aether-Legacy/Modding-Legacy/341/458556635,according to mojang eula I have the ability to redistrubite adapt and modify minecraft content without permission since you have to agree to their terms of service. ,True,False
Aether-Legacy/Modding-Legacy/341,True,Aether-Legacy/Modding-Legacy/341/458482702,"Unfortunately only Modding Legacy has the proper permissions to create a port, however if you believe this is still an issue, please help us out by forking the repo and creating a pull request! Also, reopen this issue if you can otherwise show that it is happening or create a new one relating to Aerwhale's AI that definitely needs to be reworked. ",True,False
Aether-Legacy/Modding-Legacy/341,True,Aether-Legacy/Modding-Legacy/341/458388192,"They despawn when out of range of the player, or when they get stuck. This is not an issue. ",True,False
Aether-Legacy/Modding-Legacy/341,True,Aether-Legacy/Modding-Legacy/341/355402720,Aether Legacy Version(s) Affected aether_legacy-1.12.2-v3.2 Forge version 1.12.2-forge1.12.2-14.23.4.2732 Extra Mods jurassicraft Issue Aerwhales despawn in like 10s How to reproduce look at the whale Crash log none ,True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/447590336,"ASB cannot know the wild level exactly, it uses a formula with the taming-effectiveness to determine it, and in most cases this is correct, sometimes it can be off by 1 level. The Tek-species are special in the way that they have 20 % more levels than their vanilla counterparts. Once they are spawned and you can see their level, e.g. with the spyglass, this is the true wild level, which should also be the level that ASB will display. If Tek-creatures are spawned with admin-commands, the levels can be off, as VolatilePulse explained. So if you spawn a Tek creature with a level of 300, it will actually spawn with a level of 360. So most certainly the Tek Rex you posted first, actually has a wild level of 432. If it was spawned with an admin-command and not by the game, probably the special handling of the additional 20 % led to the confusion. In conclusion, the wild-level which ASB shows is the level you can see on the wild dino when it walks around. As soon as admin-commands like  are used, their true wild level is higher, and also ASB will show this higher level. I'm sorry that you feel offended by the additional questions. I can assure you it's not that we don't believe your statements, it's just that ARK handles some things in a way that is not obvious and we also don't know. Sometimes ARK has bugs which produces wrong values like the HP of Troodons, sometimes ARK just behaves strange, like with the levels of Tek species. To find out what is going on in ARK and how things can be fixed in ASB, we need as much information as possible, so some questions may seem not related to the initial question. In this case it's probably important how the creatures are spawned in, i.e. if they spawned naturally in the game or were spawned in by admin-commands. So I ask you to have some patience with additional questions, usually it helps to resolve issues faster the more informations are available. ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/390246869,"Can anyone explain to me why this Tek Rex is importing wrong, all the values are correct, but the wild level should be 360 and not 432.  ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446819551,"Look, I told you earlier, your understanding of Ark is wrong. When using the gmsummon command for the Tek creatures, Ark instantly adds 20% to it's original level. The command  generates a level 648 Tek Rex (Identical to yours). The command , however, will spawn a wild level 360. If you  any Tek creature, you'll get the same result. Please, stop being so dense in the future. ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446818991,Yep both the Tek Raptor and Tek Rex are the only two Dino's I can find that have this issue. ,True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446818625,"Maybe when I state that the values in the extractor are correct, people should listen!!! ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446818491,It appears the Tek Raptor has the same issue ,True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446818309,That attitude will get you nowhere with developers who are kindly giving you their time for free. ,True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446818149,"and here is a Tek Stego, which also works  ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446811944,"If the server's max level is 360, a Tek Rex can spawn 20% higher level causing it to be level 432. The program is correct here, your understanding of Ark is incorrect. ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446811736,"Like I said this has never been an issue before and like I said my Spino works, my normal Rex works ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446811326,Math doesn't lie. 360  (1 + (0.5  1)) = 540. You creature is clearly higher level than that so you're either wrong or you're missing something. I have checked the numbers you provided and the lowest possible level is 432 with 100% TE. I'm not sure what you expect the author to do for you if you refuse to provide adequate information to help troubleshoot the issue. ,True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446800019,"Assuming all provided information is correct (I'll take your word for it), you admin spawned this Tek Rex or it was generated some other way other than it being tamed. It's current level, 648, is it's post tamed level, you have a TE of 100%, and the only possible way to have 0 domestic levels with 100% TE is the creature was found in the wild at level 432 based on the (proven) level calculation of 432  (1 + (0.5  1)) =  648. The equation is PreTameLevel  (1 + (0.5  TE)) = PostTameLevel. If the creature has 0 domestic levels, it's current level MUST equal its post tame level. If any of this is incorrect, that will completely change the TE and the extracted pretame level. If you'd like further assistance, please provide the requested information. ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446794674,"Why, I stated that the values are correct. ",True,False
ARKStatsExtractor/cadon/850,True,ARKStatsExtractor/cadon/850/446710661,should also post a screen shot of the ingame inventory also so anyone trying to help has more information to help you ,True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/344991933,"Thanks for the feedback, @friend. It may help other users. Now I wasn't angry. When someones opens an issue without any clear question or context, despite my request for details, what can I do? An issue that contains no usable information for other users or for contributors has no value. ",True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/344997610,"Hints when a contributor asks for details Provide details. This includes  the version of Xcode, and if other version of Xcode are installed on the computer the flavor of GRBD installed (GRDB, GRDBCipher, GRDBCustom?) the version of GRBD installed (v2.3.1, other?) the installation method (CocoaPods, SPM, Carthage, Manual?) a sign that you have read the requirements and searched the doc for an answer to your question a clear and precise statement of your issue  The list is long. But it can fit in two sentences. For example I guess I'll have to write an issue template some day. Fortunately, I currently don't have to close too many issues as invalid because of their low quality. ",True,False
GRDB.swift/groue/261,True,GRDB.swift/groue/261/390401219,"A disrespectful comment has been deleted, and this issue is now locked it has attracted too many low-quality contributions, and will not bring any useful information to anybody. ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/441237006,-,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/441236651,"And again, what i said about tps ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/441236333,"I just want enter and tha da """,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/441235503,Now i started GoMint and just got that that's what i mean. ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434027861,No i cant. I dont have the error. It doesnt occur for me. So i need YOU (the person claiming to have an error) to show me what it is. ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434027281,"I don't get the error so i cant, can i? ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434027127,Test yourself. ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434026631,@friend Please give a screenshot or copy and paste the console so we can see the error. ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434025970,"Nop, it's a warning who i got in console every time when i move and it's about level ""ms"" ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434024381,"@friend Maybe he means ""Running behind"" ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434024047,"there is no warning for movement, there are no warnings with times in them at all O.o ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434023357,"Actually when move you just see a warning in console without reason ""1012ms for movement or shit"" ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434021269,"it uses 3 per default (when you have one world loaded) and i'm fine with that. performance is good enough for everything. when that changes i optimize for the specific problem i have. throwing more threads at something doesn't make it faster, its more likely the opposite due to sync problems, context switching etc. etc. ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434020009,"""1 for async loading/saving/chunk population per world 1 for ticking worlds and entities 1 for networking"" This use more then 1 and to be configurable. ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434018887,"Lol, comment if you know what's about. ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434018735,What do you want the threads to be for? ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434017209,"And why just release? Will be easy to know what's laggy and not, if you use timings. Too if you implement watchdog. ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434017069,Let's implement for have more threads! ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/434016443,There are fixed numbers of threads used in Gomint 1 for async loading/saving/chunk population per world 1 for ticking worlds and entities 1 for networking Timings are on the todo list but they won't be finished any time soon. But they will for the first stable release ,True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/375145193,"Implement timings, add support for multithreading and how much count of thread to be used. For exemple how much thread to use chunks load and generation, to have another threads for ticking and entity movement, etc. Thank you. If you can* ",True,False
Ghost-CLI/TryGhost/678,True,Ghost-CLI/TryGhost/678/374514271,"Alright....    Nobody accused you 'falsely' you clearly were not respectful    Your issue does neither have a title nor any other description. You were starting this issue with asking what the password is for, which is clearly a support question. This was listed as ""1."", but never followed by a ""2."".  With our issue template we ask you to supply information, which you didn't do. At no point whatsoever did you say which node version, OS, CLI, or Ghost version you're having issue with. Hence there is no way to reproduce what you are experiencing.  Support is only offered by the community in our Slack community and not here on GitHub. We ask you to respect our project and the people that are contributing to it. If - after looking further into it and gathering more necessary information - it turns out to be an issue with the CLI, we can always reopen it again.   ",True,False
Ghost-CLI/TryGhost/678,True,Ghost-CLI/TryGhost/678/374479131,"Falsely accusing someone being not respectful is a serious defamation. That's shame you personally attack others in order to defend your lack of basic knowledge. My issue is not with installing , but running it from your cli. My issue #678 is related, if not duplicate of issue #378, that was correctly marked as bug by less ignorant and more knowledgable ghost developers than you two. I was respectful until now, but at this point you showed that you don't deserve any kind of respect. At this point, I've lost the interest of ghost, so I've lost the interest in this bug report aswell. No regards. ",True,False
Ghost-CLI/TryGhost/678,True,Ghost-CLI/TryGhost/678/374473925,"FYI you're definitely breaking rule 3 of the CoC Because of other issues, when a sudo command is run, output is proxied through the CLI, so when the sudo password is requested, you don't get the usual command. There was intentional context () to suggest the CLI was asking for the sudo password. Your issue with installing knex-migrator isn't an issue with ghost, rather an issue with NPM and the way it handles installation (on what I'm presuming is node 8) ",True,False
Ghost-CLI/TryGhost/678,True,Ghost-CLI/TryGhost/678/374470489,"Hey @friend Please don't use GitHub for support. This is not a bug with the CLI, but normal UNIX system behaviour were you get asked for your sudo password, as the command is running as . I'm closing this as it's not a bug in the CLI. ",True,False
Ghost-CLI/TryGhost/678,True,Ghost-CLI/TryGhost/678/306712728,"This issue is a  [x] Bug Report [ ] Feature Request  Steps to Reproduce (for a bug report)    What password? No error at this point, especially no error log. Running above from hand works asap btw. works with the following, irrational warning Your template is a mess, so this submission is. Not my fault. PS Also, I had to uninstall Let's encrypt in order to pass SSL step. That should never be required. Bug submission checklist  [ ] Tried to find help in Slack &amp; Docs I do not agree with Slack's ToS [x] Checked for existing issues [ ] Attached log file No error log at this point of installation [ ] Provided technical details incl. operating system They are generated upon error, but no error log at this point of installation  ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/441265788,"This conversation gets locked due to trolling, ranting or something else. ",True,False
GoMint/GoMint/406,True,GoMint/GoMint/406/441279350,"I wouldn't say it was any of that, I would say it's him complaining that GoMint is running behind and yes that annoys me too ",True,False
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423794084,"Maybe you and I have different definitions of ""seriously."" By taking it seriously, I meant engaging in specifics, asking clarifying questions and showing an interest in understanding the proposal fully. You instead presented a series of arguments as to why you don't need to think about the specifics of the proposal. That HandBrake is on a ""proven successful"" path. That you've done a lot of improvements. That you want to do more improvements. That normal humans successfully use it. All of which is great, but none of which has any bearing on the merit of the proposal. There are many successful major UI redesigns where before everything was doable and nobody had any complaints, but things still got better after it was reworked. The Windows 7 taskbar, Office ribbon, Blackberry/windows mobile phones -&gt; iOS/Android. Before the changes these all had perfectly usable interfaces with lots of incremental improvements and no specific issue that required the change. Anyway your ""core workflow"" that you claim drives the difference in the HandBrake UI is really not that different. The proposed UI makes that workflow efficient as well, because it's just a subset of the one I described. The final thing that gives me the feeling that you are not taking it seriously was the fact that you marked it as ""rejected"" before any discussion took place and before you even understood the proposal fully. You thought that needing to add filters was going to be a real problem for it. It almost seems like you didn't even bother running VidCoder to get a sense of how it could be working or how it feels to use. Or if there were really any concrete downsides to it! But yes, as you said, you are of course free to ignore any questions or suggestions I have. I figured you probably would, rather than bother to engage, ask clarifying questions and collaborate to reach a common goal. But I had to try. ",True,False
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423833365,"I'm not asking for an instantaneous replacement of the HandBrake GUI. I don't expect you to get on board with everything all at once. I tried to scope this suggestion to one idea Move the encoding settings to their own helper window and show source data with pickable tracks on the main one. It really can't be broken down any further than that. The rest of the post is explaining the reasoning behind it and the downstream benefits I see from it. I do realize that you want all 3 GUIs to have the same design. I would love to hear from them if there are any difficulties in making the change. If it helps, you can look at VidCoder as the ""prototype"". Play around with it and see if the idea could work in HandBrake. I don't expect buy-in without discussion. I would like to hear why you think this idea is incompatible with your future plans. In any event, I'm not complaining to you about having to spend all this work on changes you're not implementing. I'm not sorry I went and built my own UI because hundreds of thousands of people have used it, people have thanked me for it on a regular basis, and I'm darn proud of it. I'm here asking for a discussion because I realized we really do have the same goals and working together we could make something much better. And because what's in the past doesn't really matter, just how we can make the software better in the future. ",True,False
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423829111,"You should have engaged with us earlier with your ideas and discussed them one at a time before implementing everything if you expected our buy-in. If you were afraid we would say ""no"", that's a pretty good indication it needs to be discussed. We could have discussed this in easier bite sized chunks and we could have spent the time to fully discuss why your starting assumptions are incompatible with our plans for the future and perhaps influenced your design to fit to those plans. Just as a guiding principal, a complete instantaneous replacement of the HandBrake GUI is out of the question.  Gradual migration, testing each idea and getting user feedback as we go, has been our mode of development for a very long time.  This is how we plan to continue development. If you have specific ideas with limited impact, feel free to propose them.  But don't expect us to wade through a large collection of ideas in a massive redesign to pick bits that can be migrated in as part of our continual improvement to HandBrake.  To be frank, I just don't have the time for it.  I'm very busy with non-HandBrake real life things.  I've had no time in the last couple weeks and it's looking like I'll have no time in the next couple weeks.  So if you want feedback from me, you've got to keep it down to something I can read and respond to in a few minutes. Also keep in mind that any new design has to be propagated to all 3 GUIs.  Some designs do not fit well with the UI paradigms of the other platforms.  Compromises must be made for the sake of consistency sometimes.  Bradley and Scott have both spent a lot of time prototyping designs and sharing them with the group before implementation so that we can discuss the impacts of the design. This helps in keeping us all in sync with a design that works on all platforms. ",True,False
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423746463,"I'm not saying your UI is bad, or that you haven't been improving it, or that people can't get things done or figure out what to do. I'm just saying I think it can be changed so people need to click fewer times and look fewer places to get things done. What makes you certain that any additional changes are necessarily bad? Please try to look at it objectively and not as an attack on anybody or any work that's been done. As for the dimensions overhaul, I've already done it. And anyway that particular UI is not something that's hard to do with the proposed UI. It's just contained in the encoding settings window.  Which, by the way 1) Opens not as a dialog but as a helper window. So it does not force the user to close it to interact with anything else in the UI. 2) Is brought into view any time the user is working with any window in the app. 3) Opens beside the main window if the user has space. 4) Remembers its open state and position. So all that that sizing and filters UI is just as readily accessible as before. Why do you think the sizing or filters changes are not possible with this proposal? I'm just asking you to seriously consider an alternate. How it it solving ""different"" concerns? What concern do you think I am addressing, exactly, and why is that concern invalid? Where did this deep conviction come from that there are two fundamentally different user bases, and that the same UI can't possibly serve both of them? ",True,False
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/347464573,"Description of the problem Encode movie with apparent bad source disc.  Handbrake encodes less than 10%, shows a green SUCCESSFUL finish in queue as shown here (last on the list)  And the end of encode log as src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [040357] reader done. 1 scr changes ♠` As a test, which has only upset me more, when I run this source media through multiple other encoder/video tools that even just copy the streams, literally every one but Handbrake quickly return errors like this (MakeMKV identified source as bad within 2 min into stream RIP and gave a very clear indication there was a problem with source)  With HB the result of this reported successful encode job is ultimately a truncated 21 minute BAD video file - accompanied with two thumbs up from Handbrake.  I do not nor ever have expected Handbrake to work any magic with a bad source, but any encoder should at least know when it has failed due to having a bad source, and in such until now I thought had been properly returning the job as failed on a bad source.  My HUGE concern now is as it stands that I have to go back and hand-parse EVERY encode log and watch every video to determine if the job was truly a success because, had this one instead been a 98% complete encode, seeing ""success"" in both the GUI and looking at the end of the the log for failure (which I would never usually even do unless the job showed as failed) I would have never caught the failure and simply moved it to my library and then wondered why parts either stuttered or did not play at all or in this case, the movie just stopped prematurely.  And given this example and depending on how long this bug has been in place, I'm sure it has already occurred for me and this is going to become VERY time-consuming to hand-parse logs or re-run my media through other tools to verify source media was readable or not. Parsing this known bad encode log for the word ""errors"" renders exactly twelve lines ending in ""errors""....and all twelve have ZERO before the word errors.  I can't stress enough how big of an issue this is. With all that said, if possible to nail it down, I would be interested in knowing how long this issue has existed so I can have an idea of just how long I have to back-trace my encodes and manually review all logs to ensure I don't have not yet watched bad encodes (that HB returned as good) now sitting in my media folders.  Also, is parsing for ""skipping broken unit"" in bad HB versions the best/only way to truly determine when an otherwise successful returned job was really a failure due to bad source media?  TIA! Steps to reproduce the problem Select source Add to queue Start encode queue Encode job shows erroneously shows success HandBrake version (e.g., 1.0.0) 20180729125104-ecf8523-master (2018073001) Operating system and version (e.g., Ubuntu 16.04 LTS, macOS 10.3 High Sierra, Windows 10 Creators Update) Win7x64 Error message text or screenshot Last job on the list is job in question showing as successful completion  HandBrake Activity Log required (see  Nightly 20180729125104-ecf8523-master (2018073001) OS Microsoft Windows NT 6.1.7601 Service Pack 1 Ram 16366 MB,  GPU Information   AMD Radeon HD 7470 - 8.922.0.0   AMD Radeon HD 7470 - 8.922.0.0 Screen 1920x1080 Temp Dir C\Temp\ Install Dir C\Program Files\HandBrake Nightly Data Dir C\Users\Encoder\AppData\Roaming\HandBrake\Nightly  -------------------------------------------   # Starting Encode ...  [025628] hb_init starting libhb thread [025628] 1 job(s) to process [025628] json job {   ""Audio"" {     ""AudioList"" [       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 0,         ""DitherMethod"" 0       },       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 1,         ""DitherMethod"" 0       },       {         ""DRC"" 0.0,         ""Encoder"" ""copy"",         ""Gain"" 0.0,         ""Mixdown"" -1,         ""NormalizeMixLevel"" false,         ""Samplerate"" 48000,         ""Track"" 4,         ""DitherMethod"" 0       }     ],     ""CopyMask"" [       ""copyac3"",       ""copydtshd"",       ""copydts"",       ""copytruehd""     ],     ""FallbackEncoder"" ""ac3""   },   ""Destination"" {     ""ChapterList"" [       {         ""Name"" ""Chapter 1""       },       {         ""Name"" ""Chapter 2""       },       {         ""Name"" ""Chapter 3""       },       {         ""Name"" ""Chapter 4""       },       {         ""Name"" ""Chapter 5""       },       {         ""Name"" ""Chapter 6""       },       {         ""Name"" ""Chapter 7""       },       {         ""Name"" ""Chapter 8""       },       {         ""Name"" ""Chapter 9""       },       {         ""Name"" ""Chapter 10""       },       {         ""Name"" ""Chapter 11""       },       {         ""Name"" ""Chapter 12""       },       {         ""Name"" ""Chapter 13""       },       {         ""Name"" ""Chapter 14""       },       {         ""Name"" ""Chapter 15""       },       {         ""Name"" ""Chapter 16""       }     ],     ""ChapterMarkers"" true,     ""AlignAVStart"" false,     ""File"" ""J\\RIP\\MKV\\Startrek 11.mkv"",     ""Mp4Options"" {       ""IpodAtom"" false,       ""Mp4Optimize"" false     },     ""Mux"" ""mkv""   },   ""Filters"" {     ""FilterList"" [       {         ""ID"" 2,         ""Settings"" {}       },       {         ""ID"" 4,         ""Settings"" {           ""mode"" ""7""         }       },       {         ""ID"" 11,         ""Settings"" {           ""crop-bottom"" ""140"",           ""crop-left"" ""0"",           ""crop-right"" ""0"",           ""crop-top"" ""140"",           ""height"" ""800"",           ""width"" ""1920""         }       },       {         ""ID"" 6,         ""Settings"" {           ""mode"" ""1""         }       }     ]   },   ""PAR"" {     ""Num"" 1,     ""Den"" 1   },   ""Metadata"" {},   ""SequenceID"" 0,   ""Source"" {     ""Angle"" 1,     ""Range"" {       ""Type"" ""chapter"",       ""Start"" 1,       ""End"" 16     },     ""Title"" 1,     ""Path"" ""U\\""   },   ""Subtitle"" {     ""Search"" {       ""Burn"" false,       ""Default"" true,       ""Enable"" true,       ""Forced"" true     },     ""SubtitleList"" [       {         ""Burn"" false,         ""Default"" false,         ""Forced"" false,         ""ID"" 1,         ""Offset"" 0,         ""Track"" 0       },       {         ""Burn"" false,         ""Default"" false,         ""Forced"" false,         ""ID"" 2,         ""Offset"" 0,         ""Track"" 1       }     ]   },   ""Video"" {     ""Encoder"" ""x264"",     ""Bitrate"" 10000,     ""TwoPass"" true,     ""Turbo"" true,     ""ColorMatrixCode"" 0,     ""Options"" ""weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1"",     ""QSV"" {       ""Decode"" true,       ""AsyncDepth"" 0     }   } } [025628] CPU Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz [025628]  - Intel microarchitecture Ivy Bridge [025628]  - logical processor count 8 [025628] Intel Quick Sync Video support yes [025628]  - Intel Media SDK software API 1.23 (minimum 1.3) [025628]  - H.264 encoder yes [025628]     - preferred implementation software (null) [025628]     - capabilities (software)  bpyramid vsinfo opt1 opt2 [025628]  - H.265 encoder no [025628] hb_scan path=U\, title_index=1 src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025628] scan BD has 19 title(s) [025628] bd scanning title 1 [025628] bd playlist 00000.MPLS [025628] bd duration is 020650 (7610269 ms) [025628] bd video id=0x1011, stream type=H.264, format 1080p [025628] bd aspect = 169 [025628] bd audio id=0x761100, lang=English (AC3), 3cc=eng [025628] bd audio id=0x721100, lang=English (TrueHD), 3cc=eng [025628] bd audio id=0x1101, lang=Francais (AC3), 3cc=fra [025628] bd audio id=0x1102, lang=español (AC3), 3cc=spa [025628] bd audio id=0x1103, lang=English (AC3), 3cc=eng [025628] bd subtitle id=0x1200, lang=English [PGS], 3cc=eng [025628] bd subtitle id=0x1201, lang=English [PGS], 3cc=eng [025628] bd subtitle id=0x1202, lang=Francais [PGS], 3cc=fra [025628] bd subtitle id=0x1203, lang=español [PGS], 3cc=spa [025628] bd subtitle id=0x1204, lang=Portugues [PGS], 3cc=por [025628] bd subtitle id=0x1205, lang=Francais [PGS], 3cc=fra [025628] bd subtitle id=0x1206, lang=español [PGS], 3cc=spa [025628] bd chap 1 packet=768, 717216 ms [025628] bd chap 2 packet=3734035584, 467884 ms [025628] bd chap 3 packet=6214336896, 504003 ms [025628] bd chap 4 packet=8885081472, 444402 ms [025628] bd chap 5 packet=11234502336, 516891 ms [025628] bd chap 6 packet=13994168448, 491324 ms [025628] bd chap 7 packet=16621220352, 551884 ms [025628] bd chap 8 packet=19544962368, 606480 ms [025628] bd chap 9 packet=22751003520, 539413 ms [025628] bd chap 10 packet=25570130112, 415790 ms [025628] bd chap 11 packet=27759434880, 534283 ms [025628] bd chap 12 packet=30594421440, 484692 ms [025628] bd chap 13 packet=33140312448, 519143 ms [025628] bd chap 14 packet=35858720256, 307140 ms [025628] bd chap 15 packet=37505899392, 509467 ms [025628] bd chap 16 packet=39567801216, 250 ms [025628] bd title 1 has 16 chapters [025628] scan decoding previews for title 1 [025628] scan title angle(s) 1 [025628] scan audio 0x721100 truehd, rate=48000Hz, bitrate=128000 English (TrueHD) (5.1 ch) [025628] scan audio 0x1103 ac3, rate=48000Hz, bitrate=224000 English (AC3) (2.0 ch) [025628] scan audio 0x761100 ac3, rate=48000Hz, bitrate=640000 English (AC3) (5.1 ch) [025628] scan audio 0x1101 ac3, rate=48000Hz, bitrate=640000 Francais (AC3) (5.1 ch) [025628] scan audio 0x1102 ac3, rate=48000Hz, bitrate=640000 español (AC3) (5.1 ch) [025630] scan 10 previews, 1920x1080, 23.976 fps, autocrop = 140/140/0/0, aspect 169, PAR 11 [025630] scan supported video decoders avcodec qsv [025630] stream 10 good frames, 0 errors (0%) [025630] libhb scan thread found 1 valid title(s) [025630] starting job [025630] yadif thread started for segment 0 [025630] yadif thread started for segment 1 [025630] yadif thread started for segment 3 [025630] yadif thread started for segment 2 [025630] yadif thread started for segment 4 [025630] yadif thread started for segment 5 [025630] yadif thread started for segment 6 [025630] yadif thread started for segment 7 [025630] job configuration [025630]  * source [025630]    + U\ [025630]    + title 1, chapter(s) 1 to 16 [025630]  * destination [025630]    + J\RIP\MKV\Startrek 11.mkv [025630]    + container Matroska (libavformat) [025630]      + chapter markers [025630]  * video track [025630]    + decoder h264_qsv [025630]      + bitrate 200 kbps [025630]    + filters [025630]      + Detelecine (pullup) () [025630]      + Decomb (mode=7) [025630]      + Framerate Shaper (mode=1) [025630]        + frame rate 23.976 fps -&gt; constant 23.976 fps [025630]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [025630]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [025630]    + Output geometry [025630]      + storage dimensions 1920 x 800 [025630]      + pixel aspect ratio 1  1 [025630]      + display dimensions 1920 x 800 [025630]  * Foreign Audio Search Passthrough, Forced Only, Default [025630]    + subtitle, English [PGS] (track 0, id 0x1200, Picture) [025630]    + subtitle, English [PGS] (track 1, id 0x1201, Picture) src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025630] sync expecting 182464 video frames src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [025820] reader done. 1 scr changes [025820] work average encoding speed for job is 0.000000 fps [025820] decomb deinterlaced 0 | blended 0 | unfiltered 0 | total 0 [025820] vfr 0 frames output, 0 dropped and 0 duped for CFR/PFR [025820] vfr lost time 0 (0 frames) [025820] vfr gained time 0 (0 frames) (0 not accounted for) [025820] stream 30674 good frames, 0 errors (0%) [025820] sync got 0 frames, 182464 expected [025820] Subtitle track 0 (id 0x1200) 'English [PGS]' 206 hits (0 forced) [025820] Subtitle track 1 (id 0x1201) 'English [PGS]' 268 hits (0 forced) [025820] No candidate detected during subtitle scan [025820] starting job [025820] yadif thread started for segment 0 [025820] yadif thread started for segment 1 [025820] yadif thread started for segment 2 [025820] yadif thread started for segment 3 [025820] yadif thread started for segment 4 [025820] yadif thread started for segment 5 [025820] yadif thread started for segment 6 [025820] yadif thread started for segment 7 [025820] Auto Passthru allowed codecs are AC3, TrueHD, DTS, DTS-HD [025820] Auto Passthru fallback is AC3 [025820] Auto Passthru using AC3 Passthru for track 1 [025820] Auto Passthru using TrueHD Passthru for track 2 [025820] Auto Passthru using AC3 Passthru for track 3 [025820] job configuration [025820]  * source [025820]    + U\ [025820]    + title 1, chapter(s) 1 to 16 [025820]  * destination [025820]    + J\RIP\MKV\Startrek 11.mkv [025820]    + container Matroska (libavformat) [025820]      + chapter markers [025820]  * video track [025820]    + decoder h264_qsv [025820]      + bitrate 200 kbps [025820]    + filters [025820]      + Detelecine (pullup) () [025820]      + Decomb (mode=7) [025820]      + Framerate Shaper (mode=1) [025820]        + frame rate 23.976 fps -&gt; constant 23.976 fps [025820]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [025820]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [025820]    + Output geometry [025820]      + storage dimensions 1920 x 800 [025820]      + pixel aspect ratio 1  1 [025820]      + display dimensions 1920 x 800 [025820]    + encoder H.264 (libx264) [025820]      + options weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1 [025820]      + bitrate 10000 kbps, pass 1 [025820]      + fast first pass [025820]      + options ref=18x8dct=0me=diatrellis=0 [025820]                 analyse=i4x4 (if originally enabled, else analyse=none) [025820]                 subq=2 (if originally greater than 2, else subq unchanged) [025820]  * subtitle track 1, English [PGS] (track 0, id 0x1200, Picture) -&gt; Passthrough [025820]  * subtitle track 2, English [PGS] (track 1, id 0x1201, Picture) -&gt; Passthrough [025820]  * audio track 1 [025820]    + decoder English (AC3) (5.1 ch) (track 1, id 0x761100) [025820]      + bitrate 640 kbps, samplerate 48000 Hz [025820]    + AC3 Passthru [025820]  * audio track 2 [025820]    + decoder English (TrueHD) (5.1 ch) (track 2, id 0x721100) [025820]      + bitrate 128 kbps, samplerate 48000 Hz [025820]    + TrueHD Passthru [025820]  * audio track 3 [025820]    + decoder English (AC3) (2.0 ch) (track 5, id 0x1103) [025820]      + bitrate 224 kbps, samplerate 48000 Hz [025820]    + AC3 Passthru src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [025820] sync expecting 182464 video frames [025820] encx264 min-keyint 24, keyint 240 [025820] encx264 encoding at average bitrate 10000 [025820] encx264 unparsed options open-gop=0rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=alldeblock=-1,-1dct-decimate=0 x264 [info] using SAR=1/1 x264 [info] using cpu capabilities MMX2 SSE2Fast SSSE3 SSE4.2 AVX x264 [info] profile Main, level 4.0 [025820] sync first pts audio 0x721100 is 0 [025821] sync first pts audio 0x1103 is 0 [025821] sync first pts video is 0 [025821] sync ""Chapter 1"" (1) at frame 1 time 0 [025821] sync first pts audio 0x761100 is 0 [025905] sync first pts subtitle 0x1201 is 5551796 [025922] sync first pts subtitle 0x1200 is 7105848 [030934] sync ""Chapter 2"" (2) at frame 17197 time 64549485 [031651] sync ""Chapter 3"" (3) at frame 28415 time 106659052 src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [031819] reader done. 1 scr changes [031822] work average encoding speed for job is 25.551609 fps [031822] decomb deinterlaced 30672 | blended 0 | unfiltered 0 | total 30672 [031822] vfr 30674 frames output, 0 dropped and 2 duped for CFR/PFR [031822] vfr lost time 3754 (0 frames) [031822] vfr gained time 3754 (4 frames) (0 not accounted for) [031822] stream 30674 good frames, 0 errors (0%) [031822] ac3-decoder done 39958 frames, 0 decoder errors [031822] truehd-decoder done 1534426 frames, 0 decoder errors [031822] ac3-decoder done 39971 frames, 0 decoder errors [031822] h264_qsv-decoder done 30673 frames, 0 decoder errors [031823] sync got 30673 frames, 182464 expected [031823] sync framerate min 7.992 fps, max 23.981 fps, avg 23.974 fps x264 [info] frame I177   Avg QP15.69  size159915 x264 [info] frame P9051  Avg QP19.52  size 71527 x264 [info] frame B21446 Avg QP19.58  size 42785 x264 [info] consecutive B-frames  8.6%  7.9% 15.9% 11.0% 12.0% 35.7%  4.2%  1.8%  2.8% x264 [info] mb I  I16..4 42.6%  0.0% 57.4% x264 [info] mb P  I16..4 69.8%  0.0%  0.0%  P16..4 26.6%  0.0%  0.0%  0.0%  0.0%    skip 3.5% x264 [info] mb B  I16..4 26.5%  0.0%  0.0%  B16..8 29.0%  0.0%  0.0%  direct23.1%  skip21.4%  L037.4% L137.5% BI25.1% x264 [info] final ratefactor 18.48 x264 [info] direct mvs  spatial99.7% temporal0.3% x264 [info] coded y,uvDC,uvAC intra 82.2% 62.0% 33.5% inter 36.7% 28.6% 5.0% x264 [info] i16 v,h,dc,p 20% 17% 41% 22% x264 [info] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu 17% 17% 17%  9%  9%  8%  8%  8%  7% x264 [info] i8c dc,h,v,p 56% 19% 19%  6% x264 [info] Weighted P-Frames Y6.1% UV4.6% x264 [info] kb/s9962.88 [031823] starting job [031823] yadif thread started for segment 0 [031823] yadif thread started for segment 1 [031823] yadif thread started for segment 2 [031823] yadif thread started for segment 3 [031823] yadif thread started for segment 4 [031823] yadif thread started for segment 5 [031823] yadif thread started for segment 6 [031823] yadif thread started for segment 7 [031823] Auto Passthru allowed codecs are AC3, TrueHD, DTS, DTS-HD [031823] Auto Passthru fallback is AC3 [031823] Auto Passthru using AC3 Passthru for track 1 [031823] Auto Passthru using TrueHD Passthru for track 2 [031823] Auto Passthru using AC3 Passthru for track 3 [031823] job configuration [031823]  * source [031823]    + U\ [031823]    + title 1, chapter(s) 1 to 16 [031823]  * destination [031823]    + J\RIP\MKV\Startrek 11.mkv [031823]    + container Matroska (libavformat) [031823]      + chapter markers [031823]  * video track [031823]    + decoder h264_qsv [031823]      + bitrate 200 kbps [031823]    + filters [031823]      + Detelecine (pullup) () [031823]      + Decomb (mode=7) [031823]      + Framerate Shaper (mode=1) [031823]        + frame rate 23.976 fps -&gt; constant 23.976 fps [031823]      + Crop and Scale (width=1920height=800crop-top=140crop-bottom=140crop-left=0crop-right=0) [031823]        + source 1920 * 1080, crop (140/140/0/0) 1920 * 800, scale 1920 * 800 [031823]    + Output geometry [031823]      + storage dimensions 1920 x 800 [031823]      + pixel aspect ratio 1  1 [031823]      + display dimensions 1920 x 800 [031823]    + encoder H.264 (libx264) [031823]      + options weightb=1open-gop=0scenecut=40rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=allno-dct-decimate=1deblock=-1,-1 [031823]      + bitrate 10000 kbps, pass 2 [031823]  * subtitle track 1, English [PGS] (track 0, id 0x1200, Picture) -&gt; Passthrough [031823]  * subtitle track 2, English [PGS] (track 1, id 0x1201, Picture) -&gt; Passthrough [031823]  * audio track 1 [031823]    + decoder English (AC3) (5.1 ch) (track 1, id 0x761100) [031823]      + bitrate 640 kbps, samplerate 48000 Hz [031823]    + AC3 Passthru [031823]  * audio track 2 [031823]    + decoder English (TrueHD) (5.1 ch) (track 2, id 0x721100) [031823]      + bitrate 128 kbps, samplerate 48000 Hz [031823]    + TrueHD Passthru [031823]  * audio track 3 [031823]    + decoder English (AC3) (2.0 ch) (track 5, id 0x1103) [031823]      + bitrate 224 kbps, samplerate 48000 Hz [031823]    + AC3 Passthru src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar src/libbluray/bdj/bdj.c549 libbluray-j2se-1.0.2.jar not found. src/libbluray/bdj/bdj.c695 BD-J check Failed to load libbluray.jar [031823] sync expecting 30673 video frames [031823] encx264 min-keyint 24, keyint 240 [031823] encx264 encoding at average bitrate 10000 [031823] encx264 unparsed options open-gop=0rc-lookahead=60chroma-me=1fast-pskip=0nr=0bluray-compat=0constrained-intra=0b-bias=0intra-refresh=0ref=4bframes=8b-adapt=2direct=autome=umhsubme=9merange=24analyse=alldeblock=-1,-1dct-decimate=0 x264 [info] using SAR=1/1 x264 [info] using cpu capabilities MMX2 SSE2Fast SSSE3 SSE4.2 AVX x264 [info] profile High, level 4.0 [031823] sync first pts audio 0x721100 is 0 [031824] sync first pts audio 0x1103 is 0 [031824] sync first pts audio 0x761100 is 0 [031824] sync first pts video is 0 [031824] sync ""Chapter 1"" (1) at frame 1 time 0 [031942] sync first pts subtitle 0x1201 is 5551796 [032022] sync first pts subtitle 0x1200 is 7105848 [034415] sync ""Chapter 2"" (2) at frame 17197 time 64549485 [040046] sync ""Chapter 3"" (3) at frame 28415 time 106659052 src/libbluray/bluray.c696 Skipping broken unit at 6708854784 [040357] reader done. 1 scr changes [040407] work average encoding speed for job is 11.197354 fps [040407] decomb deinterlaced 30672 | blended 0 | unfiltered 0 | total 30672 [040407] vfr 30674 frames output, 0 dropped and 2 duped for CFR/PFR [040407] vfr lost time 3754 (0 frames) [040407] vfr gained time 3754 (4 frames) (0 not accounted for) [040407] stream 30674 good frames, 0 errors (0%) [040407] ac3-decoder done 39958 frames, 0 decoder errors [040407] truehd-decoder done 1534426 frames, 0 decoder errors [040407] ac3-decoder done 39971 frames, 0 decoder errors [040407] h264_qsv-decoder done 30673 frames, 0 decoder errors [040407] sync got 30673 frames, 30673 expected [040407] sync framerate min 7.992 fps, max 23.981 fps, avg 23.974 fps x264 [info] frame I177   Avg QP17.15  size145081 x264 [info] frame P9051  Avg QP19.89  size 73396 x264 [info] frame B21446 Avg QP20.33  size 42385 x264 [info] consecutive B-frames  8.6%  7.9% 15.9% 11.0% 12.0% 35.7%  4.2%  1.8%  2.8% x264 [info] mb I  I16..4 14.2% 69.1% 16.7% x264 [info] mb P  I16..4  6.0% 29.3%  4.2%  P16..4 37.5% 13.3%  6.3%  0.2%  0.0%    skip 3.3% x264 [info] mb B  I16..4  1.0%  4.5%  0.6%  B16..8 44.1% 11.6%  2.7%  direct10.5%  skip25.0%  L048.2% L146.2% BI 5.6% x264 [info] 8x8 transform intra74.0% inter59.2% x264 [info] direct mvs  spatial98.3% temporal1.7% x264 [info] coded y,uvDC,uvAC intra 86.1% 79.6% 52.9% inter 46.5% 43.0% 10.5% x264 [info] i16 v,h,dc,p 18% 21% 19% 41% x264 [info] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu  6%  6%  5% 12% 17% 14% 16% 11% 12% x264 [info] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu  5%  6%  2% 12% 17% 15% 18% 12% 14% x264 [info] i8c dc,h,v,p 44% 23% 16% 17% x264 [info] Weighted P-Frames Y6.1% UV4.6% x264 [info] ref P L0 53.8% 10.5% 22.0% 12.0%  1.7%  0.1% x264 [info] ref B L0 80.8% 16.1%  3.1% x264 [info] ref B L1 92.3%  7.7% x264 [info] kb/s9998.64 [040407] mux track 0, 30674 frames, 1598977795 bytes, 9998.60 kbps, fifo 512 [040407] mux track 1, 39958 frames, 102292480 bytes, 639.65 kbps, fifo 512 [040407] mux track 2, 1534426 frames, 578997900 bytes, 3620.54 kbps, fifo 32768 [040407] mux track 3, 39971 frames, 35814016 bytes, 223.95 kbps, fifo 512 [040407] mux track 4, 411 frames, 5277905 bytes, 33.00 kbps, fifo 16 [040407] mux track 5, 535 frames, 6521743 bytes, 40.78 kbps, fifo 32 [040407] libhb work result = 0  # Encode Completed ...  ",True,False
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/423643309,"We discussed it a long time ago  When the prototype UI looked very different When the proposed UI did not have the at-a-glance accordion source view Before testing with tens of thousands of users over years revealed that Batch processing does not create user problems Editing without a source loaded does not cause user confusion   When people thought I was just some crank out of left field with a bad idea who wouldn't stick around  I think a lot has changed and it's worth another look. Given all this, why are you so adamant that the current UI is the best and only way to do things? ",True,False
HandBrake/HandBrake/1584,True,HandBrake/HandBrake/1584/359501749,"I just finished an overhaul to the VidCoder main UI and I thought it turned out nicely. I'd like to propose bringing it to the official HandBrake UI. I think of the encoding process in three main phases 1) How. How should the file be encoded? What container do we want? What size display are we targeting? How many channels of audio do we need? Does it support anamorphic? What audio and video decoders are supported on the playback device? A user might just pick a preset, or they might go in and set it up manually. Typically you can set this up once and re use it, maybe with minor tweaks across many sources. 2) What. What sources are we encoding? Did we load the right source? Which angle do we pick, what audio and subtitle streams do we include? Do we want only audio or do we want subtitles? What are the chapters named? 3) When. When will we be done? What items are in the queue? How is the encode going? A user will go through steps 2 and 3 many times when encoding multiple files. This is the standard core workflow for transcoding video. The core workflow is here in the current HandBrake UI  Picking what you want to encode involves a journey between 3 different tabs. All of the data is mixed in with the complex ""how"" of encoding that is not relevant to the core workflow. To check what you've already queued up or to monitor the encode, you need to explicitly open a separate window. To streamline this, I put the core workflow into the main window. This allows more real estate to be devoted to helping you get through the common, routine processing steps  Load the source, then you get everything at a glance, immediately editable. If there's not enough room, the sections collapse, showing as much as possible without scrolling. Queue up items and start the encode and the progress/queue is immediately visible. Decoupling the source data and the encoding settings gives you another advantage you can edit the encoding settings without needing a source open. The source area can have an ""open"" UI on it, rather than a bunch of grayed out boxes  I do remember a few objections to this kind of approach when I first suggested it in 2010 But what if I like to tweak encoding settings for every source? That's still possible. The encoding settings window opens beside the main window and stays open on relaunching. It's not modal so it doesn't put up any roadblocks to immediate tweaking. But it doesn't make sense to edit encoding settings without a source loaded. I have not heard of any practical problems or user confusion in 8 years. The approach seems to be working well. But if people batch process, some of the files might come out wrong and people will be angry. This has never happened. People really like the batch processing. There have also been a lot of changes since the initial prototype UI. I've also heard the sentiment that HandBrake and VidCoder are two separate projects meant for different purposes. I don't think that's true at all; I believe firmly that the same software can serve all the use cases of anyone who might like either. It's just a matter of getting there. VidCoder is missing some functionality from HandBrake and has its share of issues and incompatibilities, but I don't think it's anything we can't work out. Let me know what you think. I'd be happy to help with any changes. ",True,False
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410396830,"Handbrake is not a disk ripper. You are having a problem with ripping a disk. You are attempting to use the wrong tool for the job. There are many examples of this sort of problem in the developer world, that even a ""newbie"" like you have encountered. (yes, I've been programming for over a decade longer than you) A disk ripper (like MakeMKV) would tell you directly that the file isn't readable. It would stop the rip with a failure, if you were using its direct interface. Whatever you're using right now to remove the encryption from the BD is likely logging that there is a problem with the disk. But it only tells handbrake ""end of data"". The program handbrake has no way to differentiate between ""end of data because disk is scratched"" and ""end of data because you reached the end of the file"". What handbrake was asked to do completed properly. What you are feeding handbrake with is where the problem lies. How are the handbrake developers responsible for a program that isn't theirs? ",True,False
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410392792,"For a developer with 30 years experience, your clearly not showing it as it's a hell of a lot more complicated than ""basic IO"". ",True,False
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410339420,"There is a reason we tell people not to try rip directly from discs. libbluray isn't designed for handling copy protection. (Structural protections, deliberate errors etc). MakeMKV is and they have a massive amount of experience that allows them to better detect fatal vs non fatal errors and in many cases recovery / workaround problems much better than pretty much most other tools out there. They'll have a ton of code to handle the thousands of scenarios that now come up and change with every new disc released.   Much in the same way we recommend running stream repair tools before dealing with OTA recordings in HandBrake. There are tools specialised just to that file type. As far as HandBrake can tell, there isn't a problem here so it did the correct thing in not failing the encode. The error here isn't fatal and won't always result in a failed encode. I reckon, if we flagged every decoder error we see, we'd see a 60+% failure rate on encodes across millions of users.  That's never going to end well for anyone, especially when a large percentage of those won't actually have resulted in failed encodes.  So, our options are actually very limited. Unfortunately, looking at the logs is not sufficient to tell if you have good encodes. No matter what software you use, the only way to be sure is to watch the entire file and pay very close attention to it.  Same with MakeMKV. We've seen it be successful but data that it read was incorrect without error due to marks on discs or whatever. ",True,False
HandBrake/HandBrake/1517,True,HandBrake/HandBrake/1517/410321954,"When an error occurs in the original media stream, that's ""end of file"" as far as handbrake is concerned. Completing the encode at that point, it has a successful result. The question is, why did the decoder stop getting data? The answer is almost always a disk flaw, whether it be a scratch or a fingerprint. Even MakeMKV says it can't read the disk at that point, and aborts. MakeMKV might have recorded more about the nature of the flaw it ITS log, but that's speculation about facts not in evidence. The MakeMKV forum has a topic on common read errors  as far as handbrake is concerned, this was not an error in the encoder, so it will return a zero/success response (if running from the command line) or show a green response in the GUI queue. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/162070829,"Sometimes my Arduino freezes or crashes when using JEFF ROWBERG library to read DMP data from MPU6050. It took me almost a full year to discover the problem and today I had some spare time and I tried to find where exactly arduino hangs/freezes. I discovered it is usually when executin getFIFOCount() or getIntStatus(). I discovered that inserting many Serial.print with tags along my entire code so I could know exactly which line hanged. So I discovered everytime my arduino hanged/freezes it was at a line with getFIFOCount() or getIntStatus(). So I decided to take a close look at it. Inside the file MPU6050.cpp there is a code like this uint16_t MPU6050getFIFOCount() {     I2CdevreadBytes(devAddr, MPU6050_RA_FIFO_COUNTH, 2, buffer);     return (((uint16_t)buffer[0]) &lt;&lt; 8) | buffer[1]; } I checked the function ""readBytes()"" inside I2Cdev.cpp and I found this I2CdevreadBytes(uint8_t devAddr, uint8_t regAddr, uint8_t length, uint8_t *data, uint16_t timeout) You see the problem? The function readBytes accepts one last parameter which is ""timeout"" but the function getFIFOCount uses readBytes without the timeout parameter! That's probably a bug cause sometimes I think the readBytes takes too long to execute and a TIMEOUT SHOULD BE set to avoid the function hanging out forever. I am pretty sure maaaany MAAAANY other people alterady experienced this problem and spent a lot of time trying to understand what went wrong. Some people mistakenly believe it's related to bufffer overflow in the FIFO or because of some non optimized code. It could be the problem but MY PROBLEM FOR ALMOST A FULL YEAR has been this bug reported here. I really hope someone fix this and add a timeout so nobody would spent entire months anymore seeking a problem that's is really hard to track an intermitent. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/228908888,This is my first time using the library and I think I am running into this issue as well. Did you figure out what timeout to give? Thank You. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/229077298,"No, it looks like this library support is dead. I think we should move to other alternatives cause this library has already many bugs documented and unresolved so it's really unreliable if you are gonna use this library to anything serious. Jeff Rowberg is not providing the good support he gave to this library in the old days so I think you would be better off this library ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/229088625,"Apologies for the lack of support. I've tried to migrate most of the effort to online forums and other willing (and often more capable) contributors as much as possible, since I can't devote the time to this that I used to. The best laid plans of mice and men, as it were... However, in this case, I strongly doubt that it is the lack of a timeout argument that is causing the underlying issue. Arduino's Wire library does not actually provide timeout functionality. If you dig into the code, you'll see a blocking loop in the TWI calls. See this for example  a timeout in I2Cdevlib code would make zero difference, because there's no way to pass it to the underlying Wire/TWI implementation. The only way around this is to use a different timeout-capable I2C implementation. This is possible, but not simple. I would recommend checking the SDA/SCL lines with a logic analyzer to see when/why the sensor stops responding. The blocking loop inside Arduino's Wire/TWI code should not hang as long as the sensor responds according to the I2C spec. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261985610,"I helped someone fix the issue with the same setup using the Arduino 101 libraries and fixed the performance issue in the same area that you are having problem. Someone added a fixed delay after wire operation in the readbyte call that was slowing down the I2C accesses. Just remember if you use too many print statement in this area would create new issue or make the issue worse. If you print something, maybe you should print one character and only use one debug statement at a time until you get Jtag emulator. Also remember you have multiple FIFO in the pipe and it may be getting confused dealing with its threshold setting. I2C controller FIFO, Accelerometer FIFO. Do both generate interrupt? If so disable one and use different method of hand shaking. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261975756,"@friend I never hard of ""jtag emulator"", sorry I dont have access to one, I will ask a good friend of mine tomorrow to know if he has one and can borrow me for a day. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261968350,"batata004  If you have a jtag emulator. It is the best way of finding issue. Since you are detecting the issue, it is best for you to debug it. •   Just stop the processor at the failure point and see what is wrong. •   Learn from each break point and set more break point to track the problem back to find the root cause. Regards, Pirooz ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261963758,"@friend  thanks for helping. I dont have a logic analyzer, hope another person with this same problem that owns a logic analyzer can provide details about this problem. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261963546,"I have looked into the issue both with and without your supplied code, but have not been able to replicate it without intentionally severing the hardware I2C connection. Any additional troubleshooting will require a logic capture with a Saleae analyzer or similar during a moment when the problem actually occurs on your own platform. But even with this additional detail, I expect the root cause to be outside of any of the I2Cdev code. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261961562,@friend It's really sad but I got no solution for this problem. It already consumed hundreds of hours trying to work around this but sometimes I think I2C is the guilty but other times I thinks it's jeff's library the problem. It's really an intermitent problem and it's hard to make other people believe I am not doing something stupid - which I am not doing. I wish Jeff could take a look at this serious problem cause many many many other people are facing it on other forum posts and so far no solution. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/261958255,"@friend  Hey did you find the solution to the problem ?  I am also facing the same issue, sometimes the library gets stuck at fifo count function . ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/255358604,"@friend  no offence taken ) Glad to know your case, indeed it looks even more a problem with I2C protocol itself than with the jeff's library. What you said is exactly what happens to me, randomly/intermitently problems (as you removed the wired a few times). Anyway, I hope jeff or somebody here with great knowledge in this subject could file a feature request/bug report at Arduino community so they can bring some light to this and solve this problem. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/255276308,"@friend Thanks for your response. I hope that no offence was taken. The issue I am having is actually related to the BME280, a distant relative of the BMP180 sensor, and communications via TCP/IP. My hardware and project is quite different from what you are discussing, and I do not use the MPU6050. From my quick Google search it sounds like the sensor does a lot, and making it work with other I2C hardware is tricky. I wanted to offer some feedback only because I noticed the strong language in your reply to Jeff. I did a quick test with my project, in which the BME280 is the only device communicating via I2C. My microprocessor is an ESP8266 (Which is quite a bit faster than the Uno) and I am using a common industrial protocol over TCP/IP. I have some software that is polling the ESP8266 every second, and I am actively debugging using the serial interface, so there is additional work being done by the system. I pulled one of the wires, and the system kept working. I put the wire back, still no problems. I tried this a couple more times, randomly, and finally the system stopped working. I am only asking for one value via I2C and one value over the industrial communication channel, so I would guess that if I increased the amount of data through the different interfaces, the problem might start to happen more often. Anyways, I hope that you can find a solution to the problem you are having. I thought I would share what I have experienced. Take care! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/255258214,"@friend you made it very clear, but it still does not explain why reading data from BMP180 using any library around will never hang, never. But as soon as I disconnect BMP180 and connect MPU6050 problems start to happen. It may be a problem in the WIRE implementation, ok! Maybe for some reason MPU6050 has some problem (I already tried at least 5 different modules from 3 different sellers in the last year or so) with the hardware, I dont know. I can only say that this problem only happens with me 1) WHEN using MPU6050 with jeff's library 2) WEN I try to read veery fast data from MPU6050, if I read data once every 100ms, it all works fine 3) in unprecitable times, I cant be sure that it will happen now, but it will certainly happen at some moment Anyway, you were all very clear and made a point. Maybe it's wire.h implementation that is faulty! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/255254617,"@friend I don't think you are quite getting the point Jeff is making. The problem is not with his library, but with the Arduino Wire library itself that is part of the Arduino IDE. More specifically it is the two-wire interface (TWI) library that the Wire library calls to handle I2C communications. I stumbled upon this discussion looking for an alternative implementation of an I2C library for a unrelated device I am using and can confirm that any device that calls the Wire library will suffer the same issue you are talking about. While loops are used in the TWI library for communication, and as a result, the code can block all other functions on the Arduino while it is waiting infinitely in the TWI while loop. Jeff demonstrated the infinite loop by pulling out the SCL wire from his hardware. Internally, the TWI library provided by Arduino waits for a response from the sensor that is never coming because the physical wire is removed. While your friends at SEBRAE confirmed the behavior, like you they have wrongly assumed it is due to Jeff's code. If you took a different I2C sensor with a library written by a different person (such as the one for the sensor I am using) and pulled a wire, it would behave the exact same way. As for why can't Jeff put an interrupt in his code to check if the line is LOW for too long, the library is blocking anything from happening (Which is why everything stops). The Arduino environment is not a Real-Time Operating System (RTOS). The issue is outside Jeff's code. I hope this clarifies the issue. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/252966528,"Thanks jeff and I didnt want to offend you. No. I appreciate your help, but I think it would be smart to let people know that your library sometimes crashes. Yes, I executed this same code many times with no problem. But sometimes when I just add some lines of code it gets completely unstable, and after a while it does not generate any other problem. Jeff, I dont have bad wiring, this is not my case. The wires are very well connected to arduino.  I realized this bug happens when you call mpu.getFIFOCount() too many times in small time frame. It almost always freezes at mpu.getFIFOCount() (right when it gets executed). I know that for a fact cause I puted serial.println before and after that function, and it freezes the only the first serial.println. You library may work fine in a moment, in another it just does not work. Adding some lines make the code break sometimes, and other times dont (there is no conflict between your code and those new lines). Jeff, I appreciate your attention and efforts into this library but something is not right. Maybe you are right and it's bad wiring, but in my case it surelly is not. I tested this setup in other arduinos and got similar results. I dont know if you ever heard of SEBRAE here in Brazil. It's an education institution ""for free"", with small fees. I know at least 2 good friends which are teachers of this institution in electronics and also confirmed the problem I was facing. It was them who made me come here and report this. I tried to report this problem in many different foruns and in almost all cases, in the middle of the thread, other people confirmed what I said and had the same problem with different setups. If you think this problem happens of because of some lines of I2C getting LOW, why cant you setup and interrupt in your code to check if the line is LOW for too long and maybe reset the device it that timeout happens? I never used an original arduino, I always used clones, maybe some poor build in those clones cause this problem? Sorry if I disrespected you, you are a nice guy who devoted lots of time to this library however I think, IMHO, that it's not safe using your library in quadcopters, robotic arms... someone could get seriously hurt. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/252957517,"@friend, please try to avoid sensationalist language with unsubstantiated claims. Yes, I am reasonably certain that the I2Cdev core and especially some of the device libraries are not bug-free. However, they have worked remarkably well with very few changes for literally thousands of people, some of whom have come back to tell me so after the fact (with complete, stable, working project demos). As noted in my comment from June 28, I2Cdev core code itself does not contain any loops that could lock up the whole system. The Wire library, however, does. This is well-documented and tracked separately. It is not something that I2Cdevlib code can fix, other than switching to a different I2C implementation (which is not a bad idea, but it is outside the scope of this bug report). I still contend that I2Cdev core communication works correctly as long as the hardware is electrically reliable. If the hardware is not electrically reliable, the CPU freeze is because of the Wire library, which has a blocking  loop and no timeout as documented in Arduino issue #1476. I have taken the example code that you posted on June 28 and run it with no modifications in the following setup  Arduino IDE v1.6.11 I2Cdevlib repo pulled from latest Github master branch Official Arduino Uno R3 GY521 breakout board for MPU-6050 AD0 pin tied to Arduino GND VCC pin to Arduino 5V (GY-521 has 3.3v regulator on board) SDA/SCL pins connected to Arduino SDA/SCL correctly Saleae Logic analyzer monitoring SDA and SCL   Your sketch compiles and flashes correctly. The DMP initialization completes without issue, and the YPR output settles within a few seconds to a stable value. I have left it running for 15 minutes with no problems. It has remained totally stable with no freezes, FIFO overflows, or other problems. To test, I pulled out the SCL wire to simulate an electrical issue. This (at least this time) caused the SDA line to get stuck low  The I2Cdev core is not doing this inside its own abstraction code. The GY-521 has 2.2k pull-up resistors on the SDA/SCL lines, so something is driving SDA low during a read operation from the Arduino side. Reconnecting the SCL wire does not resume normal operation, even with all zero data coming back. This suggests that the Wire library got stuck in its blocking  loop while the MPU-6050 sensor is holding SDA low waiting for more clock pulses, which won't come because the Wire library is stuck. (Maybe. I haven't dug into the Wire library's guts.) But the main point here is that it worked perfectly until I broke the hardware on purpose. I will reset the Arduino and let it run for another long while just to confirm this (expected) behavior. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/252848805,"@friend , any progress on this matter? ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/241637206,"This is not a bug - your loop is taking too long, and the buffer in the IMU is filling up and crashing the I2C bus/processor. That's why removing Serial prints and reducing delays (as you mention in your Arduino forum posts) solves the problem. That's why switching the code to check the FIFO will work. It manifests in many ways. Jeff has written repeatedly in his documentation to check the buffer as often as possible - adding a delay(100) is the opposite of that. In my experience, you need to check the buffer at least every 12ms to long term stability, but the faster the better. You should close this bug report. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231807958,"Sir, how I switch to fast wire? ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231805691,"A while ago I had issues with FIFO overruns on a 9150 but I can't remember the details. Switching to FastWire fixed it for me. On 11 Jul 2016 1459, batata004 notifications@friend.com wrote I tried it just right now. If freezed using ""Wire.setClock(400000);"" and also when using ""TWBR = 12;"". Any suggestion? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub or mute the thread",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231742469,"I tried it just right now. If freezed using ""Wire.setClock(400000);"" and also when using ""TWBR = 12;"". Any suggestion? ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231630146,"Yes, or Wire.setclock(400000). ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231630055,"I only use MPU6050 without any magnetometer, and I try to read data from DMP (not raw data). It freezes after a while. You think chaing TWBR from 24 to 12 should help? ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231629859,"Do you use mag?　I use the HMC5883L with mpu6050 to read the mag raw data and read the pitch yaw roll by DMP is fine. But when I use the mpu9150 to read the the mag data by DMP only , it keeps overflow and  freezes soon. You should change your TWBR =24 to =12 or substitute TWBR to Wire.setclock(400000),if only read data without mag ,mine is working fine with this edition by Jeff Rowberg. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231627062,"yeap, same here. I really hope Rowberg replies us here. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/231621122,"I changed, too. Yes ,it still happens.I am waiting Rowberg to explain it. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/229415495,"@friend please, when you have a time try the code I gave you in your arduino with MPU6050. I am sure it's gonna freeze and I would like to know from you where is the bug of the library so I can fix it on my end. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/229108027,I tried it right now and didnt work ( I even tried changing the baud rate and it also didnt work. I think it's not related to Serial but to something in the library cause there is never a buffer overflow when I run the above code in my arduino so the Serial is not causing a significant delay that could cause a problem/overflow. I am pretty sure is something related to MPU6050 DMP library. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/229104528,"Hello, I used to have the same problems. Try running it without the serial prints.It had worked for me. cheers and regards On Tue, Jun 28, 2016 at 951 PM, batata004 notifications@friend.com wrote ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/229102224,"@friend I never wanted to offend you. I know you did this library for free and you are contributing a lot with the community providing it to general use. This library is really great but there are some bugs with it. When you have sometime I would like you to take a look at this  some reason your library is a little ""unstable"", when you change some lines of code it simply stops working. I also provide you below with a really simple code to use your great library to retrive DMP data from MPU6050 without using interrupt pin. It simply freezes arduino after some time. I already checked with an osciloscope and everything is working fine there is not reason (at the hardware) that could make this freeze happens. Could you please run the code below in your arduino and wait a few seconds? After around 10-30 seconds your arduino will freeze. ",True,False
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/467456238,"im on the opposite opinion, plush is so much more human in term of rendering. i even use it for generating codes, and scaffolds. doing that in go template is such a pain! ",True,False
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/467449559,"First off, constructive criticism is always welcome, but you didn’t do that you served up a heavy dose of insults. No one asked you to kiss ass. Your ticket could’ve been, “I would like to use Go templates instead of Plush, how do I do that?”. But no, you came and spent a long time insulting people, and you still do. You don’t have to like Plush, but you don’t have to insult those that wrote it. ",True,False
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/467446958,You could’ve just asked asked how to use Go templates. Just that. ,True,False
gobuffalo/gobuffalo/439,True,gobuffalo/gobuffalo/439/467445115,"What, I'm supposed to kiss ass because someone made something for ""FREE"". Give me break, guy. You heard the feedback. Now it's yours to cherish. ",True,False
helm/helm/5439,True,helm/helm/5439/472119487,I'm locking the conversation it is violating the Code of Conduct for inappropriate/unprofessional conduct. ,True,False
grunt/gruntjs/1646,True,grunt/gruntjs/1646/340559541,Grunt build fails with the following message This does not happen on AWS or Local machine. But only in an LXD Container. Any clue? ,True,False
helm/helm/5439,True,helm/helm/5439/472114798,"The more you focus your mind on trash, the more garbage your mind becomes. ",True,False
helm/helm/5439,True,helm/helm/5439/472113971, Where are your PR's contributing to making the helm better?  ,True,False
helm/helm/5439,True,helm/helm/5439/472113134, Where's your open source repo contribution doing better?  ,True,False
grunt/gruntjs/1646,True,grunt/gruntjs/1646/404888454,"Also the problem is in the  plugin, not in core. Per ",True,False
grunt/gruntjs/1646,True,grunt/gruntjs/1646/404885579,"@friend Yes that is the answer. Issues are reserved for issues with Grunt. This is not a support channel. Some times I do volunteer my free time to answer support questions, if I am familiar with them. You are free to volunteer your time researching your issue and if you discover it actually is because of an issue in Grunt, then reopen this issue or open a new one. Or move your stack to gulp, it's your stack, not mine. Here is a link  Good luck! ",True,False
grunt/gruntjs/1646,True,grunt/gruntjs/1646/404741230,"@friend So ""It wont work in LXD Container"" is the answer? ",True,False
grunt/gruntjs/1646,True,grunt/gruntjs/1646/404601213,I'm not familiar with lxd containers sorry. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/262041910,"@friend actually what you are saying is very true! If I dont call too frequently FIFO functions (or retrieve data) this problem does not happen, so your solution to add a delay will certainly help IF, AND ONLY IF, this delay is not too high which could cause the fifo overflow. This ""bug"" relies in the fact that if you request data too fast using I2C something will get wrong at some time and will freeze arduino. And what is really really strange is that sometimes when arduino freezes the watchdog fires, and sometimes not. I use watchdog to turn off my quad if arduino is not working for 500ms but sometimes arduino freezes and watchdog does not even fire. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/262049222,"@friend May be I did not say it correctly. The driver had not needed delay and I removed it to fix the issue. If you have extra delay in the driver, when you call it then you have to wait the same amount of time or more otherwise thing get backed up and creates problem.  It helps if you check status of thing before you write or read so no conflict will happen. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/262477556,"@friend I have similar problems on Arduino nano. Arduino freeze after variable time and it depends on inv_set_fifo_rate.  It run cca 20 minutes when I set 0x04, but it is too slow for me. After reading this thread I started experimenting with TWBR. I use your sketch and now I have 100Hz fifo rate and TWBR 103, sketch is running more than 1 hour without problem. I don't know why, but may be it helps you. ",True,False
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/415158898,"I'm closing this issue. the poster does not seem interested to offer fair compensation for the work expectation and we at TechMasters leadership will not encourage such postings. please reach out to me directly if you have any concerns. last, I will only add that ideas are worthless, the value is in the execution ",True,False
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/415067969,"This is not a job, this is a request for free work. should be closed. ",True,False
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/414912645,"Balking at compensation terms isn't narrow minded. Give detail on the post. I guess it's wrong to assume you haven't incorporated; but, I would not be surprised if you haven't. Start off with some PRDs. Maybe a few slides showing a potential audience. Cometitor research. Most important of all, post your resume. On Tue, Aug 21, 2018, at 912 PM, Jon B wrote ",True,False
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/414579889,"Hi! Please explain more thoroughly what this project is about. Also, it sounds like you're offering only 5% for what should be a co-founder role (easily 30%, probably halfsies, possibly more). You have this great idea, but building out a lightweight prototype that's fully functional is not only weeks of full time work, but will require constant engineering follow-through. If even moderately successful, you will NEED someone who will be committed to see it through. Think of it this way I'm going to be using many years of development experience (technically, a decade), making many of the product decisions on the fly (as is necessary in a tight working relationship with a non-technical co-founder), and generally building everything. What you will bring to the table are the skills I don't have. When you're working on a project with someone else in this capacity, you have to sell THEM on YOUR pedigree, and you need to bring value to the table. An idea is just an idea; without backing and research and a compelling story for its success, it's not even a good one. I invite you to post your resume here. The barrier to entry of being a CEO is incorporating. ",True,False
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/414469923,"I know the details is a bit vague, but because of the nature of the business I was obliged to. If you contact me, I’ll be sure to explain more thoroughly what this project is about and the position you would be working on. ",True,False
jobs/TechnologyMasters/144,True,jobs/TechnologyMasters/144/352303209,"Grupee - App Developer - New York City Salary Equity. 2% - 5% Benefits None Perks  Work your own schedule Choose your own custom setup  Location New York City, NY What you will do Develop a Minimum Vial Product (MVP) for a social media platform. Nothing major in the UX/UI department but having experience with this is a must. I will need the front end and back end as well, but a bigger emphasis on the back end. Skills iOS, Swift, coding, mobile development, UI, UX, back end, front end. Must Have  3+ years in mobile development  If you deployed apps of your own is a plus.  Relevant Experience  mobile technology up to date on current mobile trend  Who we are We are Grupee and we are new social media platform. We are looking into changing the dynamic on how we usually would interact on social media platforms. How to contact us Email will be the quickest way to reach us. Shoot your resume as well if you have one available. Subject should say “Grupee Applicant”. Please send an email to Jon.bell@friend.us  [ ] Full Time [ ] Part Time [x] Contract/Partnership [ ] Internship [ ] Remote Worldwide [ ] Remote Regional [ ] Remote OK  ",True,False
ludwig/uber/184,True,ludwig/uber/184/470698609,"Please, read the docs, the faqs and the blogpost that describe Ludwig BEFORE asking questions. The short answers are ""yes, it can generate characters"" adn ""not yet, the transformer is coming in the next update"". ",True,False
ludwig/uber/184,True,ludwig/uber/184/470746789,"I'm sorry, I found the transformer plans in FAQ. However, I can't find a sequence of character generation example on the list of examples. I'm looking for a way to do what char-rnn does with Shakespeare text but with Ludwig. Care to help me? ",True,False
ludwig/uber/184,True,ludwig/uber/184/471082186,@friend this entitled and abusive attitude is not constructive and will not get you any help from anyone. ,True,False
ludwig/uber/184,True,ludwig/uber/184/471023065,"I have input file called shakespeare.csv of 1mb with First Citizen Before we proceed any further, hear me speak. All Speak, speak. First Citizen You are all resolved rather to die than to famish? All Resolved. resolved. First Citizen First, you know Caius Marcius is chief enemy to the people. All We know't, we know't. ... I have test.yaml with input_features name shakespeare     type text     encoder rnn     cell lstm     bidirectional true     level char  output_features name shakespeare     type text  I use ludwig experiment --data_csv shakespeare.csv --model_definition_file test.yaml butain it doesn't train, gives me ""TypeError 'int' object is not callable"". I suspect there are some things I'm doing wrong, I want to generate new text in the style of Shakespeare. If you know how to do it please tell me so I can do it. Thanks. ",True,False
ludwig/uber/184,True,ludwig/uber/184/471023729,you have to respect Ludwig's data format. READ THE DOCS. ,True,False
ludwig/uber/184,True,ludwig/uber/184/470767314,Use a text feature and set  ;) In the docs text feature ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264159320,"Hi all, Well... I use Jeff's library together with the NRF24L01 Radio 2.4GHz transceiver library on an Arduino UNO. The idea is to read data from the MPU6050 and then transmit it for further processing by a nearby computer. My problem with that was that I would, like most of you, see the arduino freeze after some seconds. The chances of getting the problem was somehow correlated with the use of the serial print, but not just that in my case! I work on an university robotic lab, thus I have permission to use multiples arduino boards. One day, trying to debug the problem, I noticed that the code would run normally on some arduino board (not freeze) and not in others. I had those made in Italy and those made in China.. It turns out, only the Italian ones work.  If I upload the same code on the Chinese boards it doesn't work! So, I assume, there must be some hardware incompatibilities issues with the library. In summary, I removed all calls to serial print inside the arduino loop function and use only Italian made boards. In the receiver code (arduino connected to the computer), I use the jeff's library with ros, in order to read the transmitted data from the serial port. It works for me! The only thing now is that I want to receive data at 100Hz, now I receive at about 48Hz. Maybe, the @friend tip on playing with TWBR may also work. Let's see! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/312030808,"@friend you are always very clear and informative. All your conclusions and assumptions are correct (IMHO) but would you mind explaning why when I grab data from the MPU6050 (raw) it never freezes and when I grab using MPU6050 intermitently is freezes? For example, the code below works PERFECTLY. Never freezes, is super reliable and I never never never had any problem when using it. If there was any problem with MPU6050's processor or some timing issue, it would create some intermitent problem when also using the code above. On the other hand, as soon as I use your demo code (the one that extracts data from MPU6050) problems start to happen. I never used your getMotion6 code to check if the problem also happens cause if I have to extract raw data I prefer doing so with the minimum of abstraction as possible, using the pure Wire.h library and notihng else. I really think jeff you could get some cheap MPU6050 from china (clone ones) with also an arduino (my is nano clone) and simulate the problem. I think that if you could see the problem by yourself you would be as frustrated as any other person that finds this problem. I also have to say that MOST people that play around with arudino (I think that most of the people really) are totally beginners and enthusiatics. They will not report any bug or problem, they will think they are doing sometihng stupid and will give up. So I am pretty sure this problem is under reported because people have no idea wha they did wrong AND EVEN IF THEY DIDNT DO ANYTHING WRONG people will always tell those beginners that they are inserting code that takes too long to execute (like delay) and that's the person's fault. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/311983297,"This is a good data point, but it does not conclusively indicate a problem in I2Cdevlib code. The code from arduino.cc example, for instance, does not use the DMP, so the MPU itself is operating mode without making use of its internal processor. Since this issue has focused on failure case when the DMP is active, that's a significant difference. All comments on this issue referring to raw data access only (no DMP) indicate that the I2Cdevlib code is rock solid. Unless the freezing problem also happens when using I2Cdevlib code for only raw accel/gyro readings, @friend's case does not actually add new information to what we have already seen. Also, the I2Cdevlib code adds some (very) small processing overhead to each I2C transaction since it is another layer of function call abstraction around the core TWI hardware. Given the seemingly random nature of the freeze failures, it is possible that unpredictable small timing differences have an effect on whether the failure case occurs. If this is happening, it still does not necessarily mean that I2Cdevlib code has a defect, but only that I2Cdevlib code increases the probability of conditions necessary for the problem to occur. To get back to the fundamental point here  MPU6050 latching SDA low is a violation of I²C protocol, as @friend pointed out. The Wire library has an internal blocking infinite while loop with no timeout/cancel mechanism. I2Cdevlib code has no blocking infinite while loops itself, and cannot break out of the one in the Wire library..  In other words  The MPU6050 is doing something it shouldn't, and The Wire library does not accommodate this behavior cleanly, and I2Cdevlib cannot fix this without requiring a dedicated hardware timer or else rewriting or replacing the Wire library itself, which is technically possible but outside the current scope of the project and would necessarily compatibility with current and previous Arduino installations.  I am all for clean, bug-free code, but I have yet to identify any potential root cause(s) for this behavior in I2Cdevlib. The true root cause appears to be in the MPU itself, or might be worked around (or at least detected) with a Wire library improvement or kludge like testing  inside the while loop. Detecting and mitigating the problem at the I2Cdevlib layer while still using the Wire library as-is would require a prohibitively complex and resource-intensive addition of timers and interrupts. This type of fix would be more suitably (and just as easily) added to the main application logic rather than the I2Cdevlib code, since 99% of the time it would be irrelevant for other I2Cdevlib users. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/311954304,@friend really interesting result and it matches what I initially thought jeff's library has a problem. I was induced to believe it was wire.h library fault but that cant be possible cause when I extract data direct from the sensor using only wire.h my arduino never freezes. it only freezes when I use jeff's library to get dmp data (that I cant get using only wire.h). Hope jeff investigate this better. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/311864425,"I have similar situation. My current setup includes a generic MPU6050 (probably a GY-521) and a Dual h-bridge motor driver board and Arduino Pro mini running at 5volts/16mhz. I am using Jeff's library and it works well without the motors running. I am using DMP to get the values from the Gyro. However problems seemed to come when the motors already turned on. At first I tried to eliminate the problem's cause. My first guess is that it's due to the motor's noise that's causing the MPUs erratic behavior or freeze. When running the MPU with the Motors turned on, the longest I can get is about 15 seconds and it seems I am blocked somewhere in an infinite loop. The motors are still running but I could not make it react using the IR sensors and if I pull off the MPU during the run, the functionality of my motors' feedback system resumes.  So I suspect that it's the motor driver that's causing the erratic behavior of the MPU. But here's the interesting thing, when I used the code from here  using Jeff's library), in fact it's also using the Wire.h. I integrated my motor functionalities into the new sketch to see if both MPU and the motor runs, then I was able to make it work it runs indefinitely without MPU readouts freezing. In conclusion to this finding, it's Jeff's library that's causing the problem. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/301007232,"@friend I agree with everything you said ) Only one single thing that I not agree it's of course the programmer/engineer responsable for mantaining and keep its code base working. BUT there is a big BUT here arduino freezes when this problem that I reported here happens. How can I try to fix this problem if arduino freezes? The only possible to me try to fix this would be to change the implementatino of Jeff's code and Wire.h. You can imagine that I am not too inside those 2 libraryes, I am not developing a veeery simple head tracking mechanism while I would also have to deeply study WIRE.H and Jeff's library. I think it's in the community's interest that those people able to do that, if they feel happy about that, that they should help. It's not a reasonable argument that I should try to fix the problem, if the owner of the library is having a difficult time trying to solve this problem, who am I to try to solve it? I know this is how open source works, and I love everything about it. But, IMHO, this is indeed a bug. If the library is told to do something AND it does not, it's a bug. You a library gets responsable to provide you ACCEL/GYRO data and it freezes once in a while, it's not a feature request that this freeze stops happening, it's a bug. Nobody comes to a bugtracker and says ""Please, I love your library but sometimes it freezes, would you mind adding a feature request that, if possible, can you please, please, LITTLE PLEASE, stop your library's code from freezing and crashing?"". As I see it's a bug, plain and simple bug. But I am happy we disagree on that, otherwise this community would never get so big and raise so many important discussions if everybody had the same ideas! \o/ ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/300991367,"@friend Not at all. I bought two units from Drotek -- both exhibit the same behaviour... much to my dismay. No, not really. MPU6050 latching SDA low is a violation of I²C protocol. Thus, this means undefined behaviour for the library. It really is up to you -- as system engineer -- to handle such situations. There is no universal way to unlatch such a chip although a common technique is disabling I²C, sending 9 clock cycles over SCL pin (as a GPIO) and reenabling I²C mode if SDA unlatches. (Or resetting the offending chip, if possible.) Regarding, the situation with Wire -- it would certainly be nice if it could detect a SDA latch condition as it currently just freezes preventing further handling. This is in fact an oft requested feature. Of course, this requires use of a Timer which is a precious resource on an Arduino. Either way, in my humble opinion, the only correct way for Wire to go about it -- if it were to implement timeouts -- return an error, and let the designer handle it. @friend may (or may not) then choose to implement quirky chip handling, but currently his hand are tied. One last note -- please understand that this is not a bug, you've filed a feature request. I also encourage you to try patching the code yourself and share your results (should you choose to). This is an open-source community. Weee! smiley ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/300899828,"@friend  would you mind telling where did you by you MPU6050? Mine I bought from a good reputation store that is a college for studants learning arduino. I think you are correct, there is some sort of problem with the chip itself that causes this problem BUT the Wire library should be able to handle this right, I think the problem is with WIRE and MPU6050 library, none of them are knowing how to handle some unexpected behaviour (or now ""expected behaviour"" as many reported it) with the chip. Sometimes one of the communication lines dont go back to HIGH or something like that... JEFF'S library and WIRE.H library should know bettter how to handle intermitent connection problems, maybe using timeouts. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/300896412,"Hello people! I stumbled upon this topic while searching for info about MPU6050 latching SDA down. For the record -- I'm having the same latching problem with i.MX6 SoC running Linux. Incidentally, it also always happens getting the FIFO count, as far as I've tested at the moment (but not always on the same byte). Anyway, the reason I'm posting this, is -- given the number of hits in Google -- I have good enough reason to believe this bug is due to MPU6050 chip itself. The variance of when it crashes is highly variable though. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/281191801,"Hi everyone, is there any progress on this task? I am using the library as well and not only with UNO but also with DUE; which has a more powerful ARM based microcontroller and although everything is fine with the raw values, it crashes after a while of usage in the DMP6 version. What ever TWBR or FIFO rate I tried did not matter, waiting approx 2 min (max) results crash. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/266063382,"@friend to me it does not matter the rate I read the buffer, eventually it will freeze. Could you please confirm that you arduino is original or a clone? You yaw drift I think is expected, you could use a magnetometer to fix that, nothing too complicated. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/266059340,"Sorry to be late to the party. I had struggled with what I believe was the same problem; the program would run and then randomly lock up. I have to echo what slesta came up with. In the file ""MPU_6050_6Axis_MotionApps20.h"" down at line 266.  I changed the 0x01 which is 100HZ to 0x02 which is about 66HZ and I get a pretty reliable readout. I have yet to test it on a mobile platform, but it is pretty funny to have it in the car with me and watch it give me yaw information when I turn.  My set up is an Ardunino Nano V3.1 with a Level Translator Breakout - PCA9306 to interface with the MPU.  Yaw drifts about 1 degree every minute and a half or so but for my application this should work. Hope this helps. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264845658,"@friend  TWBR is I2C rate, look here  . If you want change dmp rate, you must change it in library.  Search for this part in 6Axis_Motion and change AxAA to desired value.  It's near line number 300. ♠0x02,   0x16,   0x02,   0x00, AxAA                // D_0_22 inv_set_fifo_rate 0x03 - posledni // This very last 0x01 WAS a 0x09, which drops the FIFO rate down to 20 Hz. 0x07 is 25 Hz, // 0x01 is 100Hz. Going faster than 100Hz (0x00=200Hz) tends to result in very noisy data. // DMP output frequency is calculated easily using this equation (200Hz / (1 + value))`  I tried 200Hz (0x00) and it's run 200Hz and it's independent on TWBR. I change TWBR for better stability of chinese clone only, not for change of DMP speed. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264814422,"@friend I am happy to see that the problem is somehow solved! By the way, I tried to modify the TWBR  value but it did not work. I keep receiving data at about 48Hz. However, this sample frequency is not a huge problem to me now. Good luck! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264212617,"Actually this one looks more close to mine -&gt;  cheaper the better cause here in brazil they only sell garbage, so you should probably try to find the shittiest/cheapest arduino and try it out. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264811153,I bought original Arduino nano on friday. Same code run till discharge of battery (cca 6hrs) on 100Hz.  @friend you are right. Thank you;) Mr. Rowberg thank's for your patience. I hope you find solution of clone troubles. And thank's for your libraries. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264223369,"Nice! I really hope you get a faulty one and you can check this problem so the community can benefit from your learnings ) Thanks man, I had already given up using your library, now I have high hopes I can come back to use it! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264215348,I've ordered one of both. The one from China will take a lot longer to get here. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264212197,"that looks really close, the only difference is that for some reason my arduino's driver is ch340 and this one looks like ch340g, I dont know if this makes any difference. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264206602,This looks like the same thing  enough for testing? ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264194046,@ ewerlopes Keep in mind the FCC and Europe regulatory body require different power and transmission duty cycle that may be helping to show the issue more. Looks like we have throughput issue with something getting behind and overflowing a buffer or memory. If you use Jtag emulator. You can stop the MCU at freeze point and see where we are. Then you can breakpoint at the start of that routine and see how you are getting there. The best tools for debugging this type of issue. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264188924,@friend OBRIGADO! ) @friend the clone that I bought is from this seller  this  never bought it from eBay or Aliexpress. ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264185710,"@friend, can you provide a link to an online store/auction (eBay, Aliexpress, etc.) for the same kind of clone that you have? ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264185175,@friend I know how things are in Brazil regarding this. Boa sorte! ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264183277,"Indeed @friend I already palyed with TWBR and it produces some different timings on the freeze, low values freezes faster. When I get home I will try 103 but the most time I could run the code without freezing is a few minutes, never got a full hour. Maybe your arduino clone is better than  the ones they sell here in brazil (also from china). ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264182287,"Change TWBR on 103 realy help me, but it's not perfect. Now it's running few hours, but still freeze at the end. It's much better then few minutes or seconds. It all depend on amount of code and amount printed chars between fifo readings and on fifo rate. I have chinese clone too. I spent long time on searching for right value for TWBR. Results of different values are very variable from seconds to minutes. TWBR 103 runs in hours for me, you need another value, may be, you must try. I use 6050 2 years at chinese clones only and all that time I tried find the solution for this problem without succes. I will try buy italien version and test it, but better is find problem with chinese clones. Mr. Rowberg I buy one for you. I don't have skills to debug I2C lib. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264162520,"Hi, Indeed my boards are chinese or clone ones, I never had the chance to test this problem in a original board. It would be nice if someone could find a chinese board to Jeff so he could test this bug and maybe fix it. @friend  if you want to ""normalize"" a value what you need to do is simple, is map function from arduino, see here  Something like this float x = map(PLACE_YOUR_ACCEL_DATA_HERE,-32768,32768,0,1); Hope it helps. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/264160484,"Hi @friend I need to get the raw values from the accelerometer normalized  - in the range [0,1], can you please give me some ideas on how to proceed? I saw you post here about the raw values received from the module. Since I am using the default setting in the I2Cdevlib class, would it be correct to just divide the accelerometer x, y, z values by 32767? I appreciate your answer, thanks. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/312037149,"HI @friend, This is exactly the problem that nobody can explain (so far). I don't think this is true. The issue seems to concern the MPU's behavior when the DMP is in use. By all accounts, the fact that it works perfectly when you use native Wire API calls to get raw data but it randomly freezes when using I2Cdevlib code to use the DMP is not because you're using I2Cdevlib code in the failing case, but rather because you are using the DMP in the failing case. I fully expect that if you did test the getMotion6 example with your hardware, it would work fine. Likewise, if you mimic the DMP initialization routine yourself using Wire and not I2Cdevlib, and then read DMP packets from the FIFO also using Wire and not I2Cdevlib, I expect your hardware will fail the same as it is doing now. It may be worth rolling my own I2C/TWI implementation with timeout support, or switching the underlying implementation to something like NBWire. However, I'm not sure it is worth spending a lot of time specifically troubleshooting a case that only appears to occur with clone Arduino or especially clone MPU parts. If the problem originates inside the MPU, then there is no guarantee that we could fix it even if we could detect it and avoid a blocking case. That would, at least, allow triggering an MPU reset instead of just freezing the entire CPU though. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/312069827,"@friend thanks man! Indeed, when DMP is active maybe something weird happens with the module. Maybe it's enabling the DMP that causes the problem in the module. I just dont agree with your argument that this problem ""only"" appears with clones. Recpectfully, I assure you that here in Brazil 90% of people buy clones as for arduino as for mpu6050. Maybe in your country people can afford original ones but here I am pretty sure no more than 10% of people use original/certified hardware. Anyway, I think if more people had time to investigate why their arduinos freezes more people would join me complaining about this problem. And maybe you would be convinced the amount of people that is having to deal with this. I dont know much about how your library works (nor wire.h) but I think using some type of timeout would fix the problem easily. If the DMP does not respond for (example) 100ms, you output some message and keep the user code running. Or maybe you could reset the module and initialize it again if the response is taking too long. I have no idea if this is easy or hard, but if someday you find some spare time I am pretty sure this implementation would save loooots of time of many people! Despite what I said I respect you and you already did an AMAZING library for all the community! I with there were more people that know deep about this and would be willing to help you! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/312513773,"It's a pity. The library looks really nice, but I can't use it when it's crashing. The combination of hardware I'm using is the GY-521 (chinese clone) and a Teensy 3.1 (no chinese clone). There's an alternate i2c library for the teensy's called i2c_t3. Could that be a solution to this problem? Perhaps the following options could help? I2C_AUTO_RETRY Wire.setDefaultTimeout(timeout); ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/313360275,"@friend the library isn't crashing per se -- it's rather the chip is crashing/misbehaving which the Wire is not made to cope with. The ""i2c_t3"" library you've mentioned looks to me like a Wire replacement for Teensy, which implements timeout and bus recovery (by pushing out 9 dummy clocks) (yes, it's the  you mentioned. As such I find it's entirely feasible to use ""i2cdevlib"" on top of ""i2c_t3"" with perhaps little modifications of the former. @friend to confirm. I cannot say for sure if your MPU6050 will misbehave (you should test it), but you must understand implications if it does. Primarily it means during a ""latchdown event"" you may lose some sample points, or at very least get them late if you're using hardware FIFO. Whether this is a problem to you depends on your application (e.g., a drone will be very sensitive to such hiccups in data). Speaking of unlatching MPU6050 with dummy clocks -- yes it works. Well it worked for me.  of course you will probably want to use shorter timeout than 1 second. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/369662831,"I appreciate the comments from those vouching for the integrity of the I2Cdev library, and I also appreciate the frustration that comes from trying to use what should be a reliable device and observing mission-critical failures. However, I think this issue should be closed, or at least have the discussion locked, because it's not going to solve anything. Let me recap the findings  The peripheral (MPU-6050 in this case) is behaving in way that is disallowed by the I2C spec. This is not a bug in the I2Cdevlib code. The underlying I2C/TWI communication layer (Arduino Wire library in this case) contains a blocking  loop that assumes all peripherals will follow the I2C spec. This is not a bug in the I2Cdevlib code. It's not even a bug, exactly, in the Wire library; however, it is a missing feature.  In light of this, there are a finite number of options  Use a sensor that doesn't break the spec. This is not suitable for those who need the MPU-6050 for whatever reason. Patch the Wire library locally with the addition of read timeouts. This is possible, but it requires extra effort for each user. Also, it is strictly outside of the scope of the I2Cdevlib project. Improve the Wire library officially by implementing timeouts and submitting a pull request. This is an ideal solution, but it requires a lot of agreement from many people on the Arduino project. It too is outside of the scope of the I2Cdevlib project. Implement a custom TWI/I2C communication layer with timeout support. This could be done within the I2Cdevlib project, but it would necessarily mean than projects using I2Cdevlib and its custom TWI/I2C layer could no longer use Wire, making it somewhat restrictive. This solution would fairly be considered a new feature, not a bugfix, as it is not actually fixing any bugs in the I2Cdev code. Implement a hardware timer/watchdog to interrupt the while loop if needed. This is theoretically possible as well, but it requires using on-chip resources that are already quite scarce in order to solve a corner-case failure triggered by an outside peripheral device behaving badly. This could be added to your application logic, but I would never want it to be part of mainline I2Cdev code.  All further effort towards solving this should be directed at patching the official Wire library to include cross-platform timeout support, as this would add real value and address the pain points that many people are experiencing. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/369662343,"@friend You dont live here in brazil, the cheap parts you buy in US are expensive here, and the expensive parts you buy in US you rarely can buy here in brazil being able to trust the seller. LOTS of brazilian are using the ""regular"" MPU6050 sold in the internet. We have no way to tell if it's good or bad stuff. And even if you pay 10x what it cost to you in US I wont be able to tell if the product was ""original""/""certified"" cause most sellers hide the origin of the products to avoid taxes. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/369653075,"Well if there is a bug in the firmware of the MPU and everyone is using the arduino WIRE library then yes they will all be facing the same issue so what is your point exactly? I never said you were personally responsible for this issue. I said that you make claims that you cant prove and this is rather annoying, especially when people point out the source of the issue. A word of advice, dont buy cheap hardware if you have not the knowledge nor the equipement to troubleshoot the thing if there is a problem. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/369647821,"@friend  I have to say, I highly dislike your attitude. Hundreds of people are facing the same problem, surely it's my ""unofficial"" hardware which is the root of the problem. Surely I am the curlprit. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/369645857,"@friend I have to say, I highly dislike your attitude. To summarize, you have unoffcial hardware, you admitted having limited knowledge of the library you use and the I2C (TWI) protocol, you did not provide anything concerning your hardware setup and wiring and yet you insist in making claims about  i2cdevlib reliability even after numerous people, including mr. Rowberg himself, has pointed to you the potential source of your issue. Astro-Johnny scope out the faulty sequence and finaly proved that the MPU keep the data line latch low. He also demonstrated how you could unlatch the data pin by forcing clock signal.  This has nothing to do with i2cdevlib and rather is linked to flemsy hardware and TWI driver implementation. I make a living developping embedded software. This is a common issue I had with numerous sensor. The sensor get stuck in is state machine and does not complete the I2C transaction hence keeping the data line low. I have implemented multiple I2C driver for a variety of mcu and now I always implement a recovery sequence in which the mcu take control of the I2C line and bit bang is way out forcing either a stop condition or a software reset on the sensor (see any I2C protocol documentation for this). Now as mr. Rowberg told you, it would be difficult to stay compatible with arduino platforme using is own TWI driver, not impossible, but not in the scope of this library. So you are left with these two choices  Buy thrusted hardware. Fix the WIRE library.  Also I would like to remind you that this is free open-source software. No one owes you anything. If you are so certain of the bug source then fix it yourself! Best luck with that! Regards, Alex ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/350639594,"@friend this issue is not about FIFO overflow. You may want to check if issue is not filed for your problem already (and file a new one if it isn't). Or, if you find this is the relevant issue, please provide more information. E.g., does your MPU6050 latch SDA? Are you using DMP? What platform you're on? Etc. ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/350474514,I face the FIFO overflow problem ,True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/350210079,"Solved, it was something I did wrong with the wiring; when I power separately the servos and arduino (with the usb cable) works like charm. Many thanks Jeff Rowberg, keep up with the good work!! ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/349773624,"Got into this issue myself today. The behavior, in this case, is all works well till I disconnect the usb cable from the board. Several seconds later it freezes. If I let it stay for a while starts working again for a few cycles and stops again, this repeats randomly, annoying ",True,False
i2cdevlib/jrowberg/252,True,i2cdevlib/jrowberg/252/315451345,"Thanks Johnny, Apparently my hangs were caused by bad connections. Since I fixed them I haven't seen them anymore. When I had them I also saw them with different (non-DMP) MPU code. When I changed that to the t3* library the hangs disappeared but I didn't receive any data either. Now busy with pid-tuning ;-) Rgdz. ",True,False
courseplay/Courseplay/3245,True,courseplay/Courseplay/3245/464332456,1) this is not a forum! 2) post the things right to help on issues 3) try in your mother language maybe someone can help translate And as I read your 'bug report' there was nothing unfriendly in the answer. He just said he got no time for the bug right now to fix and it seems like it is already known. ,True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/464587851,"If you just read the manual you had to know there is a tool offset setting for both horizontal and vertical offset. So RTFM, or go rant somewhere else. ",True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/464586733,"the response from my prior ticket was to tell me there was a foreward/back adjustment on tool position on combine harvesters. which there is not On Thu, Feb 14, 2019 at 545 PM Scott Mueller notifications@friend.com wrote ",True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/464584937,"combine harvester's ""cutting width"" seems to be located either at the back of the harvester or the ""start mark"" for entering a field is too close to the actual cutter location and they are charging right past the first mark of the field into the field to drop the cutter in and start at the second mark unless you back them way up and sometimes they STILL skip the first mark.  Manually setting to ""nearest"" instead of next resolves the issue I was told by the person who ""handled"" the issue the first time that there is a front-to-rear adjustment on the location of the tool/cutting position and there is NOT. On Thu, Feb 14, 2019 at 536 PM Peter Vaiko notifications@friend.com wrote ",True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/463921940,Please let's not turn this into FS-UK/OxygenDave scene. @friend You mistake a code repository issue tracker with a forum. Please clearly post an in-game mod issue following the guidelines here. @friend @friend let's close this and move on? ,True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/463914184,"Mod team cannot read english submissions ? your comment has nothing to do with them reading English , its about harvesters. I'm new to CP and to be honest I think they have done a great job so far, it makes the game more playable and less boring. Ok yes there are some issues with the mod but at the end of the day its a mod and not a game, these people who make mods make them in their own time without getting paid. Its a free addition to the game which imo think its a must have for any serious player it just adds so much more time for you to do other things while the bots take care of all the jobs you hate doing, have a bot plough a field and another harvest another field while you go and tend to the animals. I think the authors deserve a little more respect for taking the time to create such a mod, bare in mind they can only add things or fix bugs when they have time to do it, they might be working at least 10 hours a day for all we know and only have a couple of hours to look at the mod. As I said i'm new and played FS17 without CP, it was only when a friend mentioned it to me a couple of weeks ago that I decided to take a look at it , and tbh I would miss it if it disappeared as for now i'm used to using it and it would feel like half of the game is missing without it. ",True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/463912310,I think he mentioned #3142 doing this in this way is a pure disgrace ... ,True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/463893037,The CP folks are THE last group of modders that I'd want to piss off. I won't play FS without CP. I suggest you clarify whatever issue you might be having. ,True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/463830664,"@friend I may be misunderstanding the title of this issue, can you explain in more detail what exactly are you trying to say with  ""Mod team cannot read english submissions""? ",True,False
courseplay/Courseplay/3234,True,courseplay/Courseplay/3234/410508899,  Inbox x          There is NO forward/backwards along line of travel adjustment for the cutter position on combine harvesters as indicated by original issue report.  It does not exist in any button in any way.   This results in all combine harvesters charging right into the crop.   This behavior occurred originally in FS17 courseplay and was fixed in FS17 courseplay. ,True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463169779,duplicate of #3221 ,True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463040558,I guess that you didn't like that it was version 64 ,True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463039390,"No, it's the trigger stuff. ",True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463039211,It most definitely was version 64 ,True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463030814,It's not v.00064 - it's the version labelled 'Trigger Stuff' or later (.0065). If you revert to v.00064 with commit 70cee76 - that is working normally (,True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463017291,cannot use the programme since updating it my player just freezes inside the cab and nothing works i have to exit the game............... ,True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/463005046,"same for myself as well, same version ",True,False
courseplay/Courseplay/3219,True,courseplay/Courseplay/3219/409562677,"Course will not "" Drive""...then weird artifacting and then you must close game from desktop as all commands are frozen. ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432641331,"I deleted the ""flame"" comments. They won't help anyone. I kept the rest of the conversation just in case it pops up again. ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432635158,"@friend If you plan to keep a support team, do support developers. If you do not want to support and have answers like ""search before you open tickets. Thanks!"" then tell people on your front page that you do not have support. thank god you do not work for me. any ways I don't often open issues as my team tries very hard before asking for outside help so I am not here to be offended. The team decided to remove your plugin and pay extra for the time on developing with other resources. Hope you do not use this as a ""Duplicate"" for the next person who asks about this error. Wish you success, thanks ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432518365,"@friend We don't work for you, so if you like us to give you support for free, on our free time, you'd better not talk this way. That's not how you'll get help. There's a F.A.Q. on the wiki with this checklist.  Have you enabled In-App Purchases for your App ID? Do you have a iTunes Paid Application contract in effect? Have you checked Cleared for Sale for your product? Are there any contracts waiting for approval? In-App Purchases have all fields filled (including screenshots)? Did you wait 24 hours? Using a real device (not a simulator)? Are you using the full product ID in register? Are there any error in your product ID? Do you wait cordova's ""deviceready"" event before loading the purchases? Have you submitted (and optionally rejected) your application binary? Does your project’s .plist Bundle ID match your App ID? Have you generated and installed a new provisioning profile for the new App ID? Have you configured your project to code sign using this new provisioning profile? Are your bank details active on iTunes Connect? Have you tried deleting the app from your device and reinstalling? Is your device jailbroken? If so, you need to revert the jailbreak for IAP to work.  Did you went over it? ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432634191,"Hi, If you needed more details then you could have just said it. Im sorry for the missing information. The application has been approved by apple and also the product. I tried as much as I could before asking for help here Thanks for the consideration ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432370337,"Please be fair, all you wrote is that it not work. But you not described what you already have done so far. So please tell if you have add the app to the AppStore as beta already or you only add your items. All details you can tell us may help! And without we can help you not! Von meinem iPhone gesendet ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/372737574,"[IOS] system info OSX Sierra 10.12.6 Cordova-ios@friend.5.5 // Ionic 3 Device iPhone iOS 11.2 Plugin Version 7.2.0 Expected behavior Product retrieved from store according to what has been set up Observed behavior Trying to purchase unknown product Steps to reproduce I created the Product on Itunes Connect. Added the product id to my code. First step is to register the product with the correct product id Set up approved, registered, updated, cancelled and error handlers Refresh store. call Get with correct product ID call Order with correct product ID the XCode Logs are Loaded{""id""""productID,""alias""""productID"",""type""""consumable"",""state""""requested"",""title""null,""description""null,""priceMicros""null,""price""null,""currency""null,""countryCode""null,""loaded""true,""canPurchase""false,""owned""false,""downloading""false,""downloaded""false,""additionalData""null,""transaction""null,""valid""true} 2018-10-22 200556.546938-0300 NFContacts[1444477718] [store.js] DEBUG store.queries !! 'consumable updated' 2018-10-22 200556.546974-0300 NFContacts[1444477718] [store.js] DEBUG store.queries !! 'valid updated' 2018-10-22 200556.547019-0300 NFContacts[1444477718] [store.js] DEBUG store.queries !! 'updated' 2018-10-22 200556.550326-0300 NFContacts[1444477718] [store.js] ERROR ios -&gt; ERROR 6777003 Trying to purchase a unknown product. - ""ProductID"" I have read two issues from this plugin with no solution on this. Please help ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432270748,"Let me give you the links and you tell me if it is solved 706 239 Open up and tell me if it is solved, thanks ",True,False
cordova-plugin-purchase/j3k0/744,True,cordova-plugin-purchase/j3k0/744/432093174,Duplicate; search before you open tickets. Thanks! Close #744 Von meinem iPhone gesendet ,True,False
electron/electron/17171,True,electron/electron/17171/474253256,"Hi @friend , though I can understand your frustration I think you just missed a point here. You're not on a support forum and electron is an open-source project, with volunteer contributors. You cannot expect any level of support, just hope for it. It would have been nice from you to share your findings once you solved your problem, that's the way it works. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/377311433,"I think It would be better to allow Flood to trust the reverse proxy in front of it (if any). We could use it for exemple if we have some kind of auth in front of it (Basic/SAML/Certificate, whatever, you name it), it would be good to be able to use it for the fearue #216 ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/377287057,"From my POV, I don't see the interest of disabling Flood auth for enabling basic auth in most cases except for hiding the app when it is exposed on internet. To get a stronger auth system a nice idea the user can deploy, is desabling Flood auth (when it will be available) and configure Client Side Certificate Authentication. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/377113867,"@friend No, unfortunately I cannot say with any confidence that Flood is 100% tamper proof. I'm not a security expert, so your audit would be greatly appreciated! Let's hope so! 🤞 ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/377079180,"from a security standpoint would you say the flood login is tamper proof? if you cannot say „yes“ being 100% sure about it, making this optional might be a wise decision. i'll most likely audit the login part of floods code in a few days. after all i run this publically available on my homeserver with just an nginx with basic auth in front of it. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/373477976,I think this is the better approach. Because making some default credentials and a lot of users will never change them. Make them forced to change the password bu the default account name will be the same everywhere and bad guy will have no pain to bruteforce weak password. It's maybe more work do make authentication optional but it seems more secure than providing default credentials. And this will be cleaner. ,True,False
flood/jfurrow/240,True,flood/jfurrow/240/373260889,"The simplest approach for this might be to have the config file provide some ""defaulted"" credentials and an immediate re-direct. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/372888543,"Hoping to help revive an older thread. While I don't know enough to help code this, I would definitely like to see this. As someone already mentioned, I have better auth already built into my nginx RP setup. I'd love to be able to remove the extra auth screen. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/338181833,"Bonus, just pass the username then. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/338082580,"FWIW, the passphrase can be left blank as is. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/338082322,"Might be easy to just pass plaintext credentials to the server behind the scenes if an option in the config (like mentioned above) is set, this removes any potential exploit that may arise from editing the security system to allow for sessions to be generated without proper authentication. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/337973226,"An simple and optional config value in config.js with something like  (which defaults to true if not defined) would be very nice indeed. In my case I'm hideing most stuff behind an reverse proxy with 2FA, so additional authentication in Flood is just cumbersome smile ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/295310720,"I'm reopening this as it's been requested by multiple users. Let's make the authentication optional, but enabled by default. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/277157508,"I'm going to close this for now, but feel free to submit a PR for optional JWT auth! ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/277016960,"I'll consider making this optional in the future, but I think the vast majority of users benefit from the included authentication. Right now there are higher priority issues for me to work on, but if any of you are willing to submit a PR for optional JWT authentication, I'll gladly review it! ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/204797360,I know this is well rooted in your app but I would very much like to disable auth / passport and use basic auth on my reverse proxy instead. Thanks! ,True,False
esx_policejob/ESX-Org/104,True,esx_policejob/ESX-Org/104/398933019,yea see I ask for help somewhere else and because the player base for this just want to charge each other for a line of fucking code. So there is no use is asking on there it will get ignored or someone will ask for money so....... ,True,False
esx_policejob/ESX-Org/104,True,esx_policejob/ESX-Org/104/333927052,"Anyone able to help with this I know the state of a vehicle needs to be set to ""0"" in order for it to be impounded and wanted to know if you could help out with adding this into the script I cant seem to get it to work. Thanks ",True,False
esx_policejob/ESX-Org/104,True,esx_policejob/ESX-Org/104/398968369,"You open ISSUES here on github, it id NOT the place to ask for help, understand?! ",True,False
esx_policejob/ESX-Org/104,True,esx_policejob/ESX-Org/104/398835905,"This is not an issue with the script. Ask for help somewhere else, e.g the ESX discord. ",True,False
electron/electron/17171,True,electron/electron/17171/474562665,"@friend, we're glad to hear that you were able to find a solution to the problem you experienced. On the other hand, claiming that people don't care or that they're arrogant are specifically against the Electron Code of Conduct. Continuing with this type of behavior or further violations of the code of conduct will result in you being blocked from the Electron organization. Additionally, because we believe that further communication on this issue will only result in escalating tensions, we're going to lock the conversation. ",True,False
electron/electron/17171,True,electron/electron/17171/474285427,I was expecting better\polite replies.I understand its an open forum.I didn't feel like it was a conversation.I don't expect anything at all now..Cheers ,True,False
flood/jfurrow/240,True,flood/jfurrow/240/377378745,so far my audit tells me you have pretty old dependencies in use.♠passportpassport-jwt` are what you use for authentication. fine by me but not up2date. feel free to test and merge this pull request  i could not upgrade from webpack 3 to 4 aswell as react 15 to 16 and d3 from 3 to 5 without actually doing big changes to the code base. but oh well.. looking good so far. hint hint node-check-updates ,True,False
flood/jfurrow/240,True,flood/jfurrow/240/391799933,"Note by disabling user authentication (IF you don't replace it with another authentication method like PAM for example) you will also disable multi-user capabilities. So if you have 3 users and you suddenly change the config to disable authentication, what should happen? Keep the 1st user and remove all others? No, this is nonsense. I think it should not be possible to disable authentication but only to switch to another mechanism like PAM or authentication forwarding to a reverse proxy like nginx. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/391801409,I don't think that the debate should be around disabling authentication but rather for supporting Alternative authentication methods. What do you think @friend ,True,False
flood/jfurrow/758,True,flood/jfurrow/758/457869908,"@friend 1) This is not the right issue to talk about that, let's talk in #672 and #712 2) Rather than inviting people to fork ask them to join the Organization (see #672) and ask @friend to transfer this repository to the organization ",True,False
flood/jfurrow/758,True,flood/jfurrow/758/457914398,"@friend So you should have write docker before, this is clearly important. False, commit id is important because you can talk about something already fixed for example, and yes environment and version are important because it can change the version of dependencies, that can change the final output or break something. Still nodejs 11.x or latest is not a version, for example  is. Also npm version is different from nodejs version, npm 11 doesn't even exist, for example I have npm . Sorry for discord I thought it was you, timing coincidence  1) Yes development is quite dead because there is only 1 dev that is @friend, I'm not a dev I'm just here to help managing issues, project management and gibing security advice. 2) No, there was not enough information, as I said commit ID, node and npm version and OS are very important even if you don't understand why. Without that it is impossible to troubleshoot. 3) Yes I won't fix this because I'm not a dev. I know a little about ruby but nothing about javascript. 4) I'm not pedantic, I'm assuring there is enough information to troubleshot, because just saying ""It won't work"" or just pasting a screenshot is clearly not enough to do anything. 5) I'm sorry but I'm spending my free time here just to help and you are very aggressive with me. Also this is a free, libre and open-source project, not a proprietary and paid product where you bought some support or anything. There is no warranty. If you think that development is to slow, please learn the JavaScript language and come help @friend. 6) About the template being to heavy that's why we slit issues by category. Here, we know now this is not a bug, so you should have open a Feature Request issue with a much lighter template. I'm sorry I'll lock this conversation as this is just you being aggressive and not constructive and violating the code of conduct. ",True,False
flood/jfurrow/758,True,flood/jfurrow/758/457869384,"@friend Please also read the CODE_OF_CONDUCT and do not PM people on discord, you have the issue tracker and the discord server to do so. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/391806687,What if you don't use the multi-user feature (they all show the same torrent list anyway). No point in password protection if the Flood instance is local only and not accessible externally. ,True,False
flood/jfurrow/758,True,flood/jfurrow/758/457869225,"@friend All our template are very small except the bug one that is medium size but all info are required to troubleshoot correctly, sorry. Flood is installed on a server (or more rarely a computer), you are troubleshooting on either the server or the computer, you're expected to fill the issue on your computer not your mobile device. And it is a github issue if issue template are not displaying on mobile not a flood one. No done, please fill Your Environment correctly. ♠masterlatestN.A.`. ",True,False
flood/jfurrow/758,True,flood/jfurrow/758/457861534,"@friend done. Consider forking this project if you're a react dev because it appears to be dead. From experience, it's unlikely Jfurrow it's going to work on this again. I know that he wants to and doesn't want to 'give up', but it's not going to happen. I'm not sure continuing development in a repo under his name would be the best idea unless you have admin rights. It's going to be hard to find contributors at this point anyway, so idk if it's worth it. ",True,False
flood/jfurrow/758,True,flood/jfurrow/758/457812307,@friend it’s quite usable in landscape. Portrait indeed makes things hard. ,True,False
flood/jfurrow/758,True,flood/jfurrow/758/457699965,"Hi @friend Thanks for posting your issue, but can you please take time to edit it in order to fill the issue template. I'm closing the issue until you fill it. Feel free to ask to re-open it as soon as it's done. ",True,False
flood/jfurrow/758,True,flood/jfurrow/758/403273798, Is this expected on a mobile device? Not very usable. ,True,False
flood/jfurrow/240,True,flood/jfurrow/240/412906151,"Agreed - is there a way to just lock this thread? This way it doesn't go on, but can still be managed by the repo as a an enhancement, per the labeling? ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/412905426,"I think this is no more a discussion, we more or less all agree that authentication should be enable by default and can be made optional bu user. I'm not a dev, I don't know anything about node.js, I'm only here to manage issues. Jfurrow is the main dev but he is very busy and have only a few hours a month for this project. Remember this is an open source project and that all contributions are made by member on their free time, so anyone wanting this feature can make a PR. We would proudly review and merge it. ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/412904474,@friend @friend Agreed. Does ruTorrent support multiple auth types? I've only used it with basic_auth. ,True,False
flood/jfurrow/240,True,flood/jfurrow/240/412895084,"I think the bigger point here would be to create the option. To each his own on CHOOSING their level of security. Setting a responsible default, is on the developer to ""do security right"", but creating the options that the users are looking for, is on the developer to ""create good/flexible software"". In this case, many of us are using some other mechanism to restrict access - or some don't want auth, period. Anyone making these decisions takes the risk balance into their own hands when changing from the responsible default setting. It's sort of like saying Windows shouldn't have an option to disable a password authentication to the machine. But there are use cases that dictate or necessitate the need of such a practice. In my scenario, I'm using nginx to redirect to an auth server/service before anyone gains access to anything on the domain. So DNS rebinding is not an issue in this case, and auth is not a security issue as I've setup a different auth. For me, I'd to access this service without ANOTHER login required, even if it is typing admin with no password. The user experience is undesirable. And let's be honest, these days UX trumps all! 😆 ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/412894116,that's why i'd recommend using nginx auth_request for all your home hosted things and do an internal redirect that's dns independent. ,True,False
flood/jfurrow/240,True,flood/jfurrow/240/412890829,"@friend Personally, I think all services should have authentication, even if it is only LAN? DNS rebinding could well come into this ",True,False
flood/jfurrow/240,True,flood/jfurrow/240/392295135,"nginx auth_request works fine btw.  just a bit hard to setup because you either have to setup a third party SSO provider, self host one or build one yourself. i kinda did the self made route now. totally better than basic auth since it does not prompt you for login if you get a 401 from flood ",True,False
electron/electron/17171,True,electron/electron/17171/469483441,"@friend, thanks for helping to make Electron better and especially the detailed bug report. You've made it very clear that this issue being fixed is important to you. Open source is tricky, and I understand that relying heavily on a project like Electron can be scary, frustrating, and confusing. We do not want to break anyones apps. None of the maintainers want that. We even run a program to help ensure we fix participating app's major issues during our beta cycle. However, because of the Electron maintainers' limited time and resources, we can't get to everything immediately and some things we can't get to for an extended period. This is common in open source projects. Repeatedly commenting with no new information and ""shouting"" at the development team by using all caps is not something we do here. Moving forward, I would recommend reading and following the advice in Creators, contributors, and collaborators. Just to be clear, you are welcome to continue participating in the following ways  submitting bug reports with enough detail to reproduce - ideally a Fiddle example a new feature request with context logistical questions that may not be covered in the docs (e.g. asking about release timelines in a polite way)  Including additional comments in all caps or responding repeatedly with requests of the maintainer team are off-topic and will result in those issues being closed immediately. Please follow the next step exactly Let's all take a moment to digest the above. Please do not interact with the project for 24-hours. No comments, new issues, or pull-requests. After that, please look through your open issues and edit them to ensure they're entirely on-topic, and we can continue the discussion here about the best way to engage going forward. ",True,False
electron/electron/17171,True,electron/electron/17171/469344102,WebContents.printToPDF (c\BucksWild\node_modules\electron\dist\resources\electron.asar\browser\api\web-contents.js218) dataOut (c\BucksWild\main.js310) global.PrintToPDF (c\BucksWild\main.js308) ExecuteBackendFx (c\BucksWild\IPCEVENTS.js131) InitializeEvents.ipc.on (c\BucksWild\IPCEVENTS.js157) emit (events.js182) (anonymous function) (c\BucksWild\node_modules\electron\dist\resources\electron.asar\browser\api\web-contents.js355) emit (events.js182) ,True,False
electron/electron/17171,True,electron/electron/17171/469325527,ok..Sounds Good.I will wait for sometime ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455550072,@friend I actually unlocked this issue again to give you a chance to say sorry. Seems you are not sorry. Our code of conduct applies in all of our online and offline spaces. This includes all our repositories on Github amd our forum too. And your tone is not welcome in our community.  Sorry to @friend and @friend that I reopened to let more hateful comments in. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455548469,@friend This does not make sense.  If you did not test then it is not proof.  It is a belief. I agree!  That is why I am helping you debug. No that is not true.  You may not choose the rules when it is not your house.  Anyway no one here was inappropriate to anyone else.  Just you didn't want to fix the docs. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455544646,"Not really - I just have proofed that my claims (even if they were not tested) were correct. I actually worked if you wanted that from me. I still have the opinion, that this specific part with the permission is not wrong. it might be something else. Our CoC applies wherever our community interacts with each other - keep that in mind. We don't want to go that way immediately but please be respectful when demanding answers and help. As I feel highly uncomfortable with how this whole thread here went I will unsubscribe now. May somebody else help you. I will invest my time in other parts. And yes also in making the documentation better even if you think that I really don't want to do that. ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455543645,@friend We're on GitLab not your website so your CoC does not apply.  I never was rude or violated GL's CoC.  There are people trying to work here.  Please don't waste our time. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455542777,@friend Now you're starting to make sense! I agree.  But you didn't start to debug.  You just gave up. Again I have to remind you that I already have NC working.  I am helping you to fix your docs not the other way around. I will do the debug steps when I build a test server to test new NC features. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455446367,@friend please be a bit more respectful and understanding. I would like to remind you of our code of conduct  has explained why he didn't blindly took over your suggestions. I have tried the steps on the 4 systems I have access to as well and as far as I can tell the docs are correct. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455350523,And another one could you run  and show the output? And then run  and show the output as well? ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455349926,"One last try could it be that the dot-files don't have the correct permissions? Espcially the  file? Is it writable by www-data? Because there were such reports in the forum, which where solved by this. ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455348070,"It's not laziness - it's more a ""I know what this command does and it results in exactly this"". But to defend against this I executed now this command on a Ubuntu 18.04 just for you. And it turns out it still works here just fine. It does mean something if the command in question is highly unlikely responsible for the symptoms you described. That's not what we want to and we will also adjust docs, but we don't adjust docs blindly. Thanks for this, but I don't see that this is the reason and first of all we need to find the reason why it doesn't work in your case. Unfortunately the work here is done on a best effort basis. Everybody here - no matter if employed by the company or part of the community does so. The employees will obviously prioritize requests that come in from paying customers. It's also not that I didn't tried to help you, but after some steps it turned out to be something else. I hope you can understand that people like me cannot debug every single instance of every person that has a problem endlessly. At some point in time we need to say ""sorry, but that's the end of my debugging session, because neither you nor me had a useful trace of where this problem originates"". We will help you either on a best effort basis in the forums or you pay someone some money to spend a dedicated time slot together with you - that's the reality. Sorry that we can't give endless support for free here, but my day also just has 24 hours. ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455114818,"I didn't ran any command, but it has the very same permissions, as if I would ran the command. I highly doubt that the executable flag has influence if a file can be opened or not, because it is the executable flag. Also as this is more a setup issue here I will close it for now and would like to ask you to raise your question in the forums  you wish support with setup issues from Nextcloud GmbH we offer this as part of the Nextcloud subscription. Learn more about this at ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455093266,@friend You did not post what command you ran for the chmod.  I showed you my file permissions were different from that after I ran the commands in the howto. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455089623,In my case it's a Debian and an Ubuntu 16.04 and both work totally fine ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/455008105,"@friend No SELinux is not installed.  Ubuntu 16.04, apache2, PHP 7.0.32 .  What should  I test?  (I can't test too much now because the server is in production now). What systems are you using? ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/454839666,"We want to understand, why this fails on your system. Do you use SELinux maybe? Because the documented permissions work fine on our systems 😕 ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/454603442,@friend Yes I have tried that (shouldn't matter in this case anyway) and I got the same result.  Please read above where the first command works if I set the permissions to 755.  So the issue is about file permissions. ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/454328699,@friend Ubuntu 16.04 ,True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/454314327,"The executable bit should not be needed, because it is called with  infant, which leaves to permissions like  ( minus the executable bit), which is then only a diff of the read permission for others, which should not be needed as you are  and thus the owner. Could you do an  in the directory to check what are the specific permissions and owners? Maybe the find command is slightly off. And on what operating system was this executed? ",True,False
documentation/nextcloud/1142,True,documentation/nextcloud/1142/399193555,"On the ""instructions"" page here  will see this Two steps later you have The output of this is ♠Could not open input file occ` You have to re-set the file permissions to 755 and then you can run this. ",True,False
diaspora/diaspora/7891,True,diaspora/diaspora/7891/431117605,"Before you contribute, comment, or somehow interact with this project any further, I'd like you to read our community guidelines, as well as our Code of Conduct. If you disagree with those rules and do not want to follow them, please stop interacting with this project. When members of the project team, clearly indicated by a ""member"" badge in the header of all GitHub comments, ask you in a friendly tone do do something, then they do this because our project has rules, and everyone needs to follow them. In this case, GitHub is there to track software issues and track actionable feature requests. Support requests of any kind are handled on Discourse, as this allows more people to join. If you don't like this, well, too bad. This decision has been made by the majority of our community, and we for sure will not change our work just because you feel like it. ",True,False
diaspora/diaspora/7891,True,diaspora/diaspora/7891/429593929,"No, he is not. And since you already posted there, I will close this issue. ",True,False
diaspora/diaspora/7891,True,diaspora/diaspora/7891/429576018,@friend You are wrong ,True,False
diaspora/diaspora/7891,True,diaspora/diaspora/7891/429575888,"Hello, GitHub is not a support forum; it's an issue tracker. For support issues, please post in the podmin support section of our Discourse forum. ",True,False
diaspora/diaspora/7891,True,diaspora/diaspora/7891/369840190,"Hello, what can I do if my templates are broken or something else in the asset pipe is missing? I override some CSS things, imported it in the scss files and then i was figuring out how to get those assets in the system, i did following a few times RAILS_ENV=production bundle exec rails assetsclobber RAILS_ENV=production bundle exec rails assetsclean RAILS_ENV=production bundle exec rails assetsprecompile Then I also changed the logo on my pod (diaspora/app/assets/branding/logos) But they all worked yesterday. First thing which come up was that the branding/logos/asterisk_white_mobile.png was not found, but it was there, i changed something on templates and could not remember, so i put the original back in. [2018-10-13T153023] FATAL PID-32105 TID-19394480 Rails [2018-10-13T153023] FATAL PID-32105 TID-19394480 Rails app/views/layouts/_header.html.haml17in block in _app_views_layouts_with_header_html_haml4381373114498847661_87208320' app/views/layouts/with_header.html.haml1in _app_views_layouts_with_header_with_footer_html_haml1720277477106993151_92204540' app/controllers/home_controller.rb25in image_url'block in _app_views_layouts_application_mobile_haml___4598889698582784532_59880980' app/views/layouts/application.mobile.haml8in to_mobile' app/controllers/tags_controller.rb43in I tried to change the _header.mobile.haml and _header.haml to something like that and also tried to insert skip_pipeline, but syntax was wrong or it not worked, but it not worked. What's the point? Regards 001101 ",True,False
electron/electron/17171,True,electron/electron/17171/468991294,"@friend Please do not spam issue threads or open duplicates deliberately, Electron issues are not a support forum and there is no guarantee of someone looking at, fixing or implementing your issue.  Please be patient and respectful to the maintainers who spend their time maintaining this project. ",True,False
electron/electron/17171,True,electron/electron/17171/468982227,NoOne Responded ,True,False
electron/electron/17171,True,electron/electron/17171/468777991,Hey I have put the template. Has someone looked at the issue yet? ,True,False
electron/electron/17171,True,electron/electron/17171/468427105," Electron Version 4.0.6   Operating System windows 10 1803  Expected Behavior It shd print using PrintToPDF() when requested from the renderer Actual Behavior Upon the print request everything freezes To Reproduce //RENDERER await ipc.sendSync(""ExecuteBackendFx"", { fxName ""PrintToPDF"", fxArgs null }); //MAIN global.PrintToPDF = async () =&gt; { let out = await new Promise((resolve, reject) =&gt; { mainWindow.webContents.printToPDF( { marginsType 0, printBackground false, printSelectionOnly false, landscape false }, function(error1, data1) { fs.writeFile(rootDir + ""/UI/Temp/print.pdf"", (data1, error1) =&gt; { resolve(""Success""); }); } ); } }); return out; } Additional Information It prints normally when the request comes from the backend directly.for eg calling the function directly from the debug on VSCODE ",True,False
electron/electron/17171,True,electron/electron/17171/468414654,"Thanks for reaching out! We require the template to be filled out on all new issues and pull requests. We do this so that we can be certain we have all the information we need to address your submission efficiently. This allows the maintainers to spend more time fixing bugs, implementing enhancements, and reviewing and merging pull requests. Thanks for understanding and meeting us half way grinning ",True,False
electron/electron/17171,True,electron/electron/17171/468314453,"👋 Thanks for opening your first issue here! If you're reporting a 🐞 bug, please make sure you include steps to reproduce it. We get a lot of issues on this repo, so please be patient and we will get back to you as soon as we can. To help make it easier for us to investigate your issue, please follow the contributing guidelines. ",True,False
electron/electron/17171,True,electron/electron/17171/415679283," Electron Version 4.0.6   Operating System windows 10 1803  Expected Behavior It shd print using PrintToPDF() when requested from the renderer Actual Behavior Upon the print request from the renderer using await everything freezes To Reproduce //RENDERER await ipc.sendSync(""ExecuteBackendFx"", { fxName ""PrintToPDF"", fxArgs null }); //MAIN global.PrintToPDF = async () =&gt; { let out = await new Promise((resolve, reject) =&gt; { mainWindow.webContents.printToPDF( { marginsType 0, printBackground false, printSelectionOnly false, landscape false }, function(error1, data1) { fs.writeFile(rootDir + ""/UI/Temp/print.pdf"", (data1, error1) =&gt; { resolve(""Success""); }); } ); } }); return out; } Additional Information It prints normally when the request comes from the backend directly.for eg calling the function directly from the debug on VSCODE ",True,False
editor-layer-index/osmlab/574,True,editor-layer-index/osmlab/574/433601589,"If we worked to improve the testing, do you think we could ever reach a point where it's good enough to feed straight into iD? After all each PR would go through that automated testing, plus a second pair of eyes as part of the review. Even if it broke, it wouldn't be long before someone noticed and either reverted or corrected it. Even with a release, there's always a chance bugs make it through. If we versioned ELI and effectivly did a new patch release after each PR, would that release process give any more QA over the regular PR merge process? That's a fair point, I hadn't considered schema changes. I guess for that we would need semantic versioning. Perhaps we could build this into the PR process, so that we do new patch releases for each PR which we want to go through to iD straight away? ",True,False
editor-layer-index/osmlab/574,True,editor-layer-index/osmlab/574/433585523,"Sometimes the build is broken - this is just a fact of development.  It happens to this index sometimes.  When it happens, Potlatch doesn't work. For iD, I'm much more comfortable depending on software that's been published by a human.  Someone should take a quick look at it and say ""ok looks good"" before incrementing the version number and typing .  That's not really asking a lot.  This index doesn't really change much. Before I publish a new version of iD, I grab the latest copy of ELI, run my script on it, and do a  to see what actually got changed. Instead - when ELI does change, semantic versioning can be used to signal to downstream projects how disruptive the change is.  A change to an imagery source in the index could be a patch release, and iD could pull these automatically.   A new property added to the schema could be a minor release.  It would be easy to handle but I'd probably want to prepare for it.   Renaming / removing a property / changing the schema would be a major release, and would break downstream projects. ELI should be allowed to do this for good reasons.  ",True,False
editor-layer-index/osmlab/574,True,editor-layer-index/osmlab/574/374175969,"Snipping a quote from  the imagery index in iD is only updated each iD release. It's almost been 2 months now since the last iD release which means their imagery index is almost 2 months out of date. I'd like to see that improved, but not sure on the best path forward. @friend you said this is because ELI doesn't issue stable releases, from my understanding after each commit Travis CI will test and rebuild the index, so is  not considered the stable up to date release which iD could pull each day or so for updates? ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425711966,"This is the Skript issue tracker, for tracking issues happening in the supported versions of Minecraft. If you figure something out to make your server work on a supported version and the issue will still occur, please open a separate issue and post a gist.github.com link to the stacktrace along with the Spigot version, Skript version and a list of plugins, addons especially. If you need support with upgrading your server please ask in a more proper place like on the Spigot forums. And about your issue with Skript, I'm 95% sure it's caused by some outdated addon, please try without Umbaska to begin with, and if that doesn't help, ask on skUnity or on Skript Chat. Locking this not to hurt people's eyes more ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425711806,and i still can't join ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710866,so get the 1.12 versions of those plugins ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710813,that is why i didn't want to update to 1.12 ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710773,then maybe you're using 1.8 plugins that dont work on 1.12 that do something with joining. idk ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710660,i have updated my server to 1.12.2 but now everytime i join it kicks me and generates an Internal Exeption ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710301,"well don't trust a bot on skUnity to be the 100% up-to-date official source of Skript news lol And about your error, do you have Umbaska on your server? ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710290,"♠Note that these resources are not maintained by me. If you notice something wrong with them, do not contact me.` - from the repo readme It's not as simple as just adding a line of code that says ""support 1.8 magically"". You're free to make a pull request adding support for 1.8, however if you're not willing to do this please do not just demand that. 1.8 is literally over 1000 days old and full of bugs. ",True,False
bootstrap/twbs/19636,True,bootstrap/twbs/19636/144227269,"Bug is in Collapse.prototype.hide. Instead of  var complete = function () {       this.transitioning = 0       this.$element         .removeClass('collapsing')         .addClass('collapse')         .trigger('hidden.bs.collapse')     } Should be  var complete = function () {       this.transitioning = 0       this.$element         .removeClass('collapsing')         .addClass('collapse')dimension         .trigger('hidden.bs.collapse')     } Or 'Collapse' will leave ul with style=""height 0px"", and that's wrong. Issue visible here  on 'Forms' (collapse in) Click on 'Forms' (collapse) Move cursor above 'Forms' and into right side, shown menu (right side) will be transparent when it shouldn't be.  ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388618253,"@friend I think for time spended on this discussion about writing someone what he should and what he should not, the JavaScript developer can spend time to something useful in order to submit fix with upgrading to the new version and get many big thanks from the community for pushing this upgrade to the upstream so fast. ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388615956,"@friend, as it is so ""easy and smooth"", maybe you could submit a PR? Or maybe you should not say it is ""easy and smooth"" if you do not know what you are talking about? ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388549076,"@friend I say ""So it should be easy and smooth upgrade."" for one thing - that there support for previous version of mongodb will be available after upgrading, according to the matrix compatibility. So you should no need to create workaround to support version that you currently support. The second thing, I have request help from side of developers of mongo express because I'm not familiar with JavaScript - I'm a Java developer. If I was a JavaScript developer I help you with upgrade, but now I'm requesting help from project developers side and community. ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388505703,"As the package  has gone through a major version change from 2.2.24 to 3.0.8, where things are expected to break, there will probably be some things that break. Please don't say things like ""So it should be easy and smooth upgrade."" if you don't understand what's involved in an upgrade 😉 I'd suggest looking at the changelog for , which specifically outlines how `Db.prototype.open♠ has been removed, and how to address that. ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388476604,"Got an error when try to run in docker Please help, I'm not familiar with JavaScript. ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/387578196,"If you  does it work as intended? If so, can you submit a PR? ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/320711616,Please upgrade to 3.0 Driver To support MongoDB 3.6 ,True,False
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3504348,"@friend First off, let me apologize. I went quite a bit overboard. Now that I know the proper way to submit pull requests, I will do so going forward. I'm newish to git[hub] and didn't realize that my diff's appeared to be on the wrong branch. That said, I've been contributing to open source for 15+ years now and I've never seen someone disregard a diff without even looking at it first. Not only once, but multiple times. In the least, you could have looked at it and then said hey, this is great, but I need you to submit it in this other way. I know that this is volunteer work on your part, but it is also on mine. I'm trying to start out with just some basic changes (helping with docs) and I spent whatever amount of time working on that diff. To have it just quickly thrown out, with no recourse or reason really pissed me off. In my defense, I think that is what pushed me over the edge. Again, I apologize. I'll keep a better attitude going forward. Thanks for your hard work. I'm really enjoying working with this code. ",True,False
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3500959,"@friend There is no reason to get upset about any of this. I'm sorry I mistakenly thought your pull requests were against master instead of 2.0-wip. As @friend suggested, in the future I ask that you submit pull requests to branches and not a sha so I can more easily tell where they should be applied. That way I can auto-merge them right here on GitHub with full context. I scanned the top line and didn't see 2.0-wip, so I made the most of the changes manually and closed it out. I'll watch out for that in the future. That said, insults, cursing, and bashing me won't help you at all. I'm happy that you're using and contributing to Bootstrap, but I won't actively help folks with that kind of attitude. We do this in our spare time to help the community and stuff like this actively works against that. If you want to help us, please continue to do so with a positive attitude. If you can't, don't bother—no skin off my back. ",True,False
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3500732,"@friend sorry about that - we're human, we all make mistakes. Your first request was in fact pulled a while ago, and I would pull your most recent but it can't be reopened so I'll make the changes manually. ",True,False
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3498030,@friend  maybe when you pull request is in wrong branch    this one is correct branch    D ,True,False
bootstrap/twbs/1009,True,bootstrap/twbs/1009/3497687,"Perhaps you should specify your pull requests against the  branch rather than an arbitrary commit SHA (e.g., #989). Also, this is not an issue. Discuss on the mailing list or something... ",True,False
bootstrap/twbs/1009,True,bootstrap/twbs/1009/2844907,"I've now had two pull requests closed now for lack of PAYING F*CKING ATTENTION. Most recently  the past  I'm trying to help you guys here. @friend , get some new glasses. ",True,False
bootstrap/twbs/13476,True,bootstrap/twbs/13476/41985279,"I get what you're saying when you declare an issue closed, but just to be clear here, this was closed before you deemed it closed. I'm not trying to be arrogant here, so please do not take it that way. This is not a bug report and it's not a feature request, and as I clearly stated earlier, we cannot help you with these kind of problems here. @friend Well, good thing that's not up to you. Chris is an exceptional contributor and Bootstrap wouldn't be where it's at today in any sense of the matter without him. He's done way way way more for this project than you could possibly imagine. Moreover, I took a brief look back and as far as I can tell, comments from @friend towards you have been direct and free of demeaning or aggressive overtones. He's also clearly explained as much as he can given his position as a contributor. At one point he expressed frustration, but I cannot say I fault him for that given the context. It would appear you felt most upset about #13133 where both @friend and @friend commented about what simply amounts to a can't fix problem. Per the comments in that issue, there is no jQuery event to cue off when an element is removed from the dom, so there's nothing to tell Bootstrap when that happens. I don't know if that's 100% the case as I'm not the JS expert here, but given @friend's track record with us, I'm inclined to believe both him and Chris. A solution was clearly provided after the constraints were clearly stated. I fail to see how you believe that issue has not been properly addressed as well. Take a step back and revisit this later. Consider that we're all human, we also have full-time jobs of our own, we maintain a very large and complex open source project, and we're all trying to do our best here. There's no malcontent intended in any of these interactions. &lt;3 ",True,False
bootstrap/twbs/13476,True,bootstrap/twbs/13476/41981045,@friend Thank you for your reply. I got the ID's wrong in the example. I couldn't locate them myself I was too in the code to notice that anything was wrong. Issue is now CLOSED. @friend I suggest revoking the ability to close an issue for @friend. IMHO the person is doing more harm than good to Bootstrap's GitHub repository. ,True,False
bootstrap/twbs/13476,True,bootstrap/twbs/13476/41938622,"@friend No need for the snarky attitude. @friend clearly explained to you that our tabs plugin requires a specific structure in your markup. You're using the tab-able classes here, so logically it makes sense to focus on the fact that this just won't work if that's your intent. Moreover, you shared a single link with no context and asked us how to make it work. Sadly, we can't help folks with this kind of stuff here. We have to focus on bug reports and feature requests, otherwise we get super bogged down and are of no use to anyone. Lastly, if you have specific questions on how to do something, you'll likely want and need to consult a forum like Stack Overflow. We currently don't have an official mailing list or forum. ",True,False
bootstrap/twbs/13476,True,bootstrap/twbs/13476/41935058,"The tabs plugin relies on the DOM having a certain structure. Specifically, it relies on the tab labels being s within a , among other things. Read  and consult the examples in our docs. ",True,False
bootstrap/twbs/13476,True,bootstrap/twbs/13476/32615992,Can someone give me an idea how to make this work? ,True,False
bootstrap/twbs/19651,True,bootstrap/twbs/19651/205015111,nice attitude there. certainly makes me want to help you further in future. ,True,False
bootstrap/twbs/19651,True,bootstrap/twbs/19651/204084852,"For how-to questions, please use StackOverflow or similar. See ",True,False
bootstrap/twbs/19651,True,bootstrap/twbs/19651/144990690,I've been searching high and low for information on this subject and . bootstrap is already loaded before the view is rendered so the html bindings for bootstraps plugins aren't applied. ,True,False
bootstrap/twbs/19636,True,bootstrap/twbs/19636/203036612,"do you want to lose that attitude please? a reduced test case is necessary to see if the problem is indeed one relating to bootstrap itself, or the way in which you've used it (perhaps wrongly, perhaps with errors in some other code/style/js). otherwise i'm afraid we're not going to be able to dissect your specific site to see what's causing the issue. ",True,False
bootstrap/twbs/19636,True,bootstrap/twbs/19636/202905590,Thanks for reporting this. Could you provide a reduced test case (JSBin/JSFiddle)? ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710214,there is just go on the official skunity discord and  type in .download and it will show you it ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425710081,"^ that there's no such thing as ""the latest recommended version of skript for 1.8"", just use the normal latest stable one, being dev37c, and report any bugs you have. We don't really support 1.8 but we try to keep it working (sometimes meaning that we just disable things that don't work on it) ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709987,idc about 1.9 compat mechanic and i simply can't just upgrade my server to a higher version just like that because some things might break and it took me months to set that server up ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709832,"No, most servers support 1.12 or 1.13 and 1.8 should be left alone. You have plugins that enable 1.8 combat in 1.12 so why even bother using 1.8 ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/364952194,"hi each time i add this piece of code 28.09 172442 [Server] INFO titustitus98 issued server command /sk reload drakeconomy 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! [Skript] Severe Error 28.09 172442 [Server] ERROR #!#! Could not load drakeconomy.sk 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! If you're developing an add-on for Skript this likely means that you have done something wrong. 28.09 172442 [Server] ERROR #!#! If you're a server admin however please go to  172442 [Server] ERROR #!#! and check whether this error has already been reported. 28.09 172442 [Server] ERROR #!#! If not please create a new ticket with a meaningful title, copy &amp; paste this whole error into it (or use paste service), 28.09 172442 [Server] ERROR #!#! and describe what you did before it happened and/or what you think caused the error. 28.09 172442 [Server] ERROR #!#! If you think that it's a trigger that's causing the error please post the trigger as well. 28.09 172442 [Server] ERROR #!#! By following this guide fixing the error should be easy and done fast. 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Stack trace 28.09 172442 [Server] ERROR #!#! ch.njol.skript.SkriptAPIException Signature of function is null when return type is asked! 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.FunctionReference.getReturnType(FunctionReference.java201) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.function.ExprFunctionCall.getReturnType(ExprFunctionCall.java56) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.effects.EffChange.init(EffChange.java208) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java249) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.SkriptParser.parse(SkriptParser.java176) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.lang.Statement.parse(Statement.java61) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadItems(ScriptLoader.java754) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.command.Commands.loadCommand(Commands.java467) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScript(ScriptLoader.java472) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.ScriptLoader.loadScripts(ScriptLoader.java271) 28.09 172442 [Server] ERROR #!#!     at ch.njol.skript.SkriptCommand.onCommand(SkriptCommand.java167) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.PluginCommand.execute(PluginCommand.java44) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.command.SimpleCommandMap.dispatch(SimpleCommandMap.java141) 28.09 172442 [Server] ERROR #!#!     at org.bukkit.craftbukkit.v1_8_R3.CraftServer.dispatchCommand(CraftServer.java641) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.handleCommand(PlayerConnection.java1162) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnection.a(PlayerConnection.java997) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java45) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PacketPlayInChat.a(PacketPlayInChat.java1) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.PlayerConnectionUtils$1.run(SourceFile13) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java511) 28.09 172442 [Server] ERROR #!#!     at java.util.concurrent.FutureTask.run(FutureTask.java266) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.SystemUtils.a(SourceFile44) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.B(MinecraftServer.java715) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.DedicatedServer.B(DedicatedServer.java374) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.A(MinecraftServer.java654) 28.09 172442 [Server] ERROR #!#!     at net.minecraft.server.v1_8_R3.MinecraftServer.run(MinecraftServer.java557) 28.09 172442 [Server] ERROR #!#!     at java.lang.Thread.run(Thread.java748) 28.09 172442 [Server] ERROR #!#!  28.09 172442 [Server] ERROR #!#! Version Information 28.09 172442 [Server] ERROR #!#!   Skript 2.2-dev25 28.09 172442 [Server] ERROR #!#!   Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 172442 [Server] ERROR #!#!   Minecraft 1.8.8 28.09 172442 [Server] ERROR #!#!   Java 1.8.0_171 (Java HotSpot(TM) 64-Bit Server VM 25.171-b11) 28.09 172442 [Server] ERROR #!#!   OS Linux amd64 2.6.32-042stab127.2 28.09 172442 [Server] ERROR #!#! ` ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709813,Actually most servers use 1.12.2 ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709747,besides since most servers still use 1.8 you should support 1.8 ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709620,Use the bigger code blocks or hastebin or pastebin for errorrrs bcause this is hard to read ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425709572,hi so i have updated to the latest recommended version of skript for 1.8 but bug perssists and here is my full log ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425706161,Update Skript and hope that it works on 1.8. This is a known bug in old releases. ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425702576,so what can i do? ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425619135,and on the exact same server ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425617408,i use the exact same code with the exact same version ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425569223,but my other leaderboard works fine ,True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425534380," As others have said, we don't support versions of Minecraft older than 1.9. You're also using an old version of Skript. You must be using the newest version of Skript to report issues (how else do we know if your issue is already fixed or not?) Your bug is due to the function your calling not being loaded yet. Make sure your  function is in a script that is loaded before the  script.  ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425499316,"The error indicates ""Bukkit 1.8.8-R0.1-SNAPSHOT 28.09 "" This fork of Skript does not support anything lower than 1.9 ",True,False
Skript/SkriptLang/1568,True,Skript/SkriptLang/1568/425498881,"Use hastebin or pastebin for errors, because it's pretty hard to read right now. Also, why set the args as , when you can just make a command without args using♠command /die` Stack trace (roughly) for solving the issue ",True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456862280,I lock the conversation at this point. TBH It was just a quote from here ,True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456846002,"We can not accept this kind of behavior. There are rules that you can find on forum. The answer of Sioding was not aggressive, while yours is. NEVER do it again. ",True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456688522,-,True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456614578,Does this mean I get one of those bug report tokens for the griffon mount in Altdorf? ,True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456564568,Hm strange - thanks for the feedback. ,True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456443685,Could not join other groups or Warbands. I just mentioned the crown as a visual indicator that I was still classed as being in a group. ,True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/456299653,So is it only the crown that disturbs? Can you join other groups or warbands? ,True,False
WarBugs/WarEmu/13182,True,WarBugs/WarEmu/13182/401558318,Expected behavior and actual behavior No option to leave group - stupid crown over my head no option to disband or leave. Steps to reproduce the problem Screenshots/Videos or archive.org evidences  ,True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388622951,"@friend You're being combative and unhelpful here. This is not how we do an open source community. @friend Wulf is right in one regard, in that doing a major version upgrade of arguably the most integral library is probably not something someone new to JS, or even the project, should probably attempt. (Particularly for a library like mongodb that doesn't do major version upgrades all that often.) Even if the code changes are minimal, it would still require at some amount of regression testing to make sure nothing broke in the transition. It's probably not a huge untertaking, but not one to be taken lightly either. Unfortunately, this project is essentially a side project for the maintainers. We try to fix bugs and merge PRs when we can, but none of us have too much time to spend directly on this. ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388624055,"Thank you @friend, appreciated. @friend,  ""easy and smooth"" are not words you should use especially when this clearly isn't either easy nor smooth. The major version upgrade of the core library used by this project is a huge task. By saying ""easy and smooth"", you are undermining the value of our efforts. We have donated our time to make this - nobody here is paid, nobody here has a shortage of things to do. We have given you this software, do you give back or do you tell us it is bad and cheap? It makes me sick to feel that our efforts are expected for free, or worse, because we give them for free our efforts are also valueless. Do you work for free? I have to work to earn money to buy fuel and food like everyone else - that you tell me to do something, and to do work for you rather than point out the difficulty of the task, does not make me want to do anything. Do not tell people what to do with their time, if you are asking someone to help you. If you would like a difficult feature done quickly, maybe you could post an incentive at BountySource for someone else to help. ",True,False
mongo-express/mongo-express/411,True,mongo-express/mongo-express/411/388947437,"Cleaned up a bit of the conversation to keep it on topic. There is an open issue, lets focus on it ) ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/468168052,@friend can this be brought up in the next meeting? ,True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/451675439,"if we keep talking about ancient expectations from ext2 days, we will never progress. please stop comparing ZFS to other filesystems that do not even have checksum - should we disable checksum by default to not ""confuse"" new users? setting compression off at creation is just as trivial as setting it on was, before this change would be implemented. you are all acting like the sky is falling. do you know what's even worse? a customer setting up a system with several dozen TB and compression=off because they didn't know it would be a good idea to have compressed metadata, ARC, or, that lz4 compression is the default and it bails out early instead of wasting cycles trying to compress random data. and then we tell them ""turn compression on always"" and they ask ""why is not the default?"" and now they get to reshuffle an absurd amount of data around. ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/450985164,"For me compression is a feature, and as such should be leaved off by default even if the recommended setup is to have it on. As said before, compressing data by default is not so common among filesystems and certainly unexpected. Sane defaults often are not the same than recommended setup for a use-case, as generic as it could be. I'd also arg that ZoL would then diverge from the other zfs implementations, which -as far as I know- retain mostly the same settings. As for the default setting file, only root can create/mount filesystems, so why not put a cmd alias somewhere in ? ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/450178388,"IMNSHO, pool creation should be automated, like everything else you do more than once. When developing such automation, understanding where and why someone else changes the defaults is toil. ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/450009550,yes ,True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449698840,It would be great if we can set any default value via some config file (if we're already speaking about this functionality for compression). What do you think about it? ,True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449471254,"Thinking about this more, it maybe should be 2 / 3 configuration files. Or a way to specify the difference between options for zpool, zfs and Zvols. Meaning the current requests could be met with; compression=""lz4"" And in some cases, I can see Zvols wanting this as the default; volblocksize=8k$ZVOL$TIMEzpool import`...) ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449402529,"there is some precedent for defaults already, where the ""default config file"" is /etc/modprobe.d/zfs.conf see ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449401085,"Can we repurpose this issue as a feature request for a global zfs/zpool preferences file? Like the one ubuntu already provides, but with added abilites (1) to specify zpool create -o -O flags and (2) with ability to tell the root prefix mountpoint (instead of default /) ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449393390,"Objection, that implies  which not everybody wants. ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449388613,Other candidates for updated defaults could be  and  as these two seem to be a 'you definitively want this' in most of the howtos for pool creation that float around. Thus a generic way to specify -o and -O options in a default file that are applied on  would be helpful. Ceterum censeo regarding the argument about consistency with other filesystems and users initial expectations we should do something about  being a red herring. ,True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/449129865,"@friend, no I don't know if this defaults file concept has been filed as a feature request / issue. It should probably be followed up in the mailing lists. And / or reported as a separate issue. As for your default mountpoint for a pool, I thought it was based on the pool name. Thus, a pool named ""srv"" would mount by default on ""/srv"". I routinely disable my pool's automounting, as it's never correct. So; ♠zpool create -O mountpoint=legacy POOL DEVICE` ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/448970331,"@friend I can't easily search for ""defaults"" as there are too many results, do you happen to know if is there already filed some issue to provide defaults in a /etc/default/zfs file (in the upstream package, not added by distro)? this and the other issue I mentioned should then be solved. ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/448968434,"that idea would be awesome and would solve another issue, the default mountpoint on root filesystem tree instead of naturally going into /srv on linux ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/448675022,"Perhaps we can handle this a different way. Create a user editable configuration file that would be used for defaults. ZFS on Linux seems to have one already, (at least on Gentoo Linux); ZFS_MOUNT='yes' which would be applied on any pool creation. Then inherited down the dataset / zvol tree. However, I do agree leaving the current default of compression off is best for now. And this idea can be discussed elsewhere, (like the mailing list). ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/448310941,"Defaults should be sane and consistent from a user standpoint.   is most consistent with other filesystems, produces expected results with regard to applications like  and , and users' initial expectations of space usage will be met. ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/448225576,"also, from  compression=lz4 on your pools' root datasets so that all datasets inherit it unless you have a reason not to enable it"" is there a strong reason to not enable it by default? ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/392150854,    System information  Type | Version/Name  --- | ---  Distribution Name   | all Distribution Version    | all Linux Kernel    | all Architecture    | all ZFS Version | all SPL Version | all   Describe the problem you're observing Include any warning/errors/backtraces from the system logs ,True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/468323462,"@friend Sure, can you also bring it up on the developer@friend.org mailing list so that folks from all platforms have a chance to weigh in on this before the meeting? ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/468402927,"Let's have this issue be specific to the having compression on out-of-the-box, with no additional work.  It sounds like some folks would also like to be able to have a settings file that (essentially) provides some default arguments whenever you run ""zpool create"".  If that's still desired, please open a separate Issue (feature request) for that. ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/468405585,"for the other aspect, using a zedlet is the best way I've found to automatically modify pool/dataset properties at creation time. ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399322476,I'm hoping this isn't a ReDoS issue in one of the packages that OUCSS utilizes but it seems like it or an overload of the CPU parsing. Glad you found a work-around for the moment. ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/400183276,@friend  Clearly the the-j0k3r is not abiding by your advice and being beyond snarky. This will make me not interested in assisting anyone here both personally and professionally. I would recommend you locking topics. I'm considering a ban along with the report for this user. ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/400136756,"I agree with you, Maintaining a level of decency and not lowering tone with superior condescending hypocritical behaviour,which has been so adeptly demonstrated that Martii character. Personally I dont have the inclination or time for people which only flexibility in ANY conversation on the web,  is to quote some psycho-babel buzz word of the 80's and derogatory insults. Blocked and there it shall remain. ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/400088095,"Thanks for the report! This error in the editor is safe to ignore, since it's unable to understand -moz-document rules (for now). It should still report warnings like usual. Please take care in the future to respect others' views, I don't want to lock threads and limit sharing ideas in the comments (yes, even the deleted ones). We're on GH to see new and interesting things, not to berate each other and mount our views on top of the site's morale. ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399960166,"You do realize who you are talking to right?????????    I'm ........... the BATMAN! ;) Anyhow you are seriously going off-topic, and dragging me and everyone along with it. Rather than complain about something continue doing something about it e.g continue to test and report like a good clown instead of being passive-aggressive towards the owner. Ciao for now since I have sites to maintain myself, assisted a little with this issue since it peaked my interest, and have fun with your ""pen"". ;) ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399926820,Hop to it! ;) Hop faster! ;) ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399926308,"The site maybe beta and half the bugs aren't even reported or the developer doesn't see some bugs because of lack of testing in other OS's and browser configs. But nothing is ever bug free in my experience, so beta/alpha/stable to me just mean, alpha = expect loads of bugs/breakages, beta= expect some bugs and maybe the odd breakage, stable=expect the same as beta ) ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399924008,A better error response stating any limits reached would be much more helpful. Stabbing at a bug without knowing what tool to use is lengthy. All in time I suppose... the site is still Beta and we all must be patient. ) ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399921168,Theme size is key in OUCSS the data URI just add size and OUCSS doesnt take larger themes at all. ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399321866,"@friend Yes, you're right. I replace Data URL to imgur and it works! ",True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/485986381,seems like all of the negative aspects of having  by default (CPU wasting cycles) could be avoided if we also port this  along with switching the default to ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399320062,Okay... so knocking out  and  allows almost 100% to upload... won't make any more conclusions as this is a weird issue... but I would start looking at those data URI PNG's to see if there's an issue. ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399317953,Ref    (some note about CSS2 vs CSS3)... perhaps some validation is occurring that requires CSS3? (taking another stab guess)  ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399317678,Should the line at  be  instead of ? ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399317369,"Well just guessing (variables are my least known in CSS and I'm still getting used to the site )... after that ""Clippy"" block is where it refuses to let me upload it. ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399316078,@friend variable? It's a name of keyframes. ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399315685,I think  is a variable... did you set it? ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399314348,"Hmmm I get a red popup that says something like Will probably have to wait for someone higher up to assist you as I can't upload your CSS successfully myself. However I did dump most of the script in between and it successfully did upload... so that to me would normally indicate you may have an error in the CSS somewhere... perhaps a mismatched curly brace, missing comma, missing semi-colon, or something else? ",True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399312744,Well I'll give it a shot on my account temporarily... I'm new to the site as well. Good as any test to start. ) Please hold. ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399312476,@friend oh.. OK But I can't save theme still. 😓 ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/399311880,Safe to ignore that. CSS  is scheduled at some point in CSS4 and was backed out of CSS3. The  prefix means that it's Mozilla specific. See also ,True,False
openusercss.org/OpenUserCSS/121,True,openusercss.org/OpenUserCSS/121/334725955,  Expected behaviour Actual behaviour     Save Theme Stay in edit page and an error on editor    Steps to Reproduce the Problem    Copy and paste my usercss github-xp Click Save Theme The error shown as following and can't save    Environment details   &lt;details&gt;   &lt;summary&gt;&lt;strong&gt;Stack trace&lt;/strong&gt; (click to expand)&lt;/summary&gt;   &lt;/details&gt;,True,False
zfs/zfsonlinux/8213,True,zfs/zfsonlinux/8213/486006830,"This was discussed at today's OpenZFS Leadership Meeting.  Here are the relevant notes The idea is to give a better out of the box experience. The downsides are potential CPU cost (and write performance due to compressing) and new users misunderstanding how the space is used in certain cases. Igor There have been issues when root pools are expecting compression to be disabled (on SPARC?) Allan This has been the default in FreeBSD installer for ~2 years Sef Boot pools need to be different for each platform, but grub doesn’t seem like it needs to be different. Sef supports it being the default. Compression=on has been the default in FreeNAS for several years; no complaints *** Someone to take an action item to investigate benefits and issues, and write it up? ",True,False
