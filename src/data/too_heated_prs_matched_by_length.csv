thread_id,created_at,thread_label,_id,text,training,label
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-16T22:12:28Z,False,157187845.0,"Check my comment on the on-site part of the comparison. Everything else looks great!
",True,False
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-17T00:34:03Z,False,157220272.0,"I see.

There's no difference on key variables between original  and modified on-site model. Thus the script printed out a NA matrix.

I will fix that.

---

From: Kevin notifications@github.com
Sent: Monday, November 16, 2015 5:12 PM
To: kbrannan/ODEQ-Bacteria-Model-R
Cc: Zi, Tan
Subject: Re: [ODEQ-Bacteria-Model-R] Modified io_check script to output variable value and change ratio (#12)

Check my comment on the on-site part of the comparison. Everything else looks great!

## 

Reply to this email directly or view it on GitHubhttps://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157187845.

[https://avatars2.githubusercontent.com/u/15020361?v=3&s=400]https://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157187845

Modified io_check script to output variable value and change ratio by TanZiTT · Pull Request #12 · kbrannan/ODEQ-Bacteria-Model-R
The io_check.r script was modified. If the variables were found different in original and modified models. It will print out the variable values of both models as well as the change ratios (origin...
Read more...https://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157187845
",True,False
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-17T00:38:55Z,False,157221025.0,"I ran the previous version of io_check (pull request 11) and got the following output for the onsite:
Onsite Pets Submodel Key Variables:
bac.onsite.NearStrmStrctFailure.to.stream.load
Accum.RAOCUT
Different Key Variables:
Accum.RAOCUT

Shouldn't we see this change in the latest version of io_check?
",True,False
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-17T01:00:59Z,False,157225306.0,"hmm, yes we should. Seems there're bugs either in the older version or the latest version scripts.
Thanks for the QA, I will look into this.

---

From: Kevin notifications@github.com
Sent: Monday, November 16, 2015 7:38 PM
To: kbrannan/ODEQ-Bacteria-Model-R
Cc: Zi, Tan
Subject: Re: [ODEQ-Bacteria-Model-R] Modified io_check script to output variable value and change ratio (#12)

I ran the previous version of io_check (pull request 11) and got the following output for the onsite:
Onsite Pets Submodel Key Variables:
bac.onsite.NearStrmStrctFailure.to.stream.load
Accum.RAOCUT
Different Key Variables:
Accum.RAOCUT

Shouldn't we see this change in the latest version of io_check?

## 

Reply to this email directly or view it on GitHubhttps://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157221025.

[https://avatars2.githubusercontent.com/u/15020361?v=3&s=400]https://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157221025

Modified io_check script to output variable value and change ratio by TanZiTT · Pull Request #12 · kbrannan/ODEQ-Bacteria-Model-R
The io_check.r script was modified. If the variables were found different in original and modified models. It will print out the variable values of both models as well as the change ratios (origin...
Read more...https://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157221025
",True,False
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-18T15:58:55Z,False,157758586.0,"Hi Kevin,

I just updated the script to fix the output issue.

I also ran the previous version of io_check.r script but didn’t see difference in key variables in On-site output. I also checked the output compare spreadsheet file that I shared to you long ago. The key variables in on-site outputs were the same and the output of the script is consistent with the results in spreadsheet.

I think the reason we got different results may due to the input files we used are different. The script is working fine and now if there’s no differences in key variables, it won’t print NA matrix anymore.

Now the files at my end are all up to date. Since the pull request is still open, when you merge the pull, you should be able to get the latest working script.

Regards,
Tan

From: Kevin [mailto:notifications@github.com]
Sent: Monday, November 16, 2015 7:39 PM
To: kbrannan/ODEQ-Bacteria-Model-R ODEQ-Bacteria-Model-R@noreply.github.com
Cc: Zi, Tan Tan.Zi@tetratech.com
Subject: Re: [ODEQ-Bacteria-Model-R] Modified io_check script to output variable value and change ratio (#12)

I ran the previous version of io_check (pull request 11) and got the following output for the onsite:
Onsite Pets Submodel Key Variables:
bac.onsite.NearStrmStrctFailure.to.stream.load
Accum.RAOCUT
Different Key Variables:
Accum.RAOCUT

Shouldn't we see this change in the latest version of io_check?

—
Reply to this email directly or view it on GitHubhttps://github.com/kbrannan/ODEQ-Bacteria-Model-R/pull/12#issuecomment-157221025.
",True,False
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-18T16:59:02Z,False,157778248.0,"Great, thanks!
",True,False
kbrannan/ODEQ-Bacteria-Model-R/12/pulls/kbrannan/ODEQ-Bacteria-Model-R/12,2015-11-16T22:09:54Z,False,44991697.0,"Is the comaprison script working for onsite?script
",True,False
GamingMesh/Jobs/39/pulls/GamingMesh/Jobs/39,2014-05-24T12:40:53Z,False,44085962.0,"Not a pull request
",True,False
lgaticaq/hubot-sentry-integration/124/pulls/lgaticaq/hubot-sentry-integration/124,2019-06-26T11:46:00Z,False,505840109.0,"
[![Coverage Status](https://coveralls.io/builds/24217907/badge)](https://coveralls.io/builds/24217907)

Coverage remained the same at 100.0% when pulling **bd15d38c9eb563dee54fee3b1572eeaf45fac4c2 on renovate/eslint-plugin-jsdoc-8.x** into **b040e70f5cb0f2ad9ac41720428c5218998fb44a on master**.
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-12T00:29:33Z,False,208639393.0,"@andycochran @brettsmason Can you take a look at this?  Do you think this change of defaults makes sense?
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-26T21:32:43Z,False,214893431.0,"ping @andycochran @brettsmason thoughts on this change of defaults?
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-26T21:40:03Z,False,214895962.0,"I've personally never used the flex grid as I need to support ie9 for my projects, so I'm not familiar with it. I'll try and take a look but hopefully @andycochran will have more knowledge on this. 
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-27T15:19:37Z,False,215118112.0,"The changes seem logical, but I too have little experience with Flex Grid (also thanks to ie9). @kball, do we have a Yetinaut with flexbox expertise? @JeremyEnglert? 

My one question is the change from `null` to `expand`. Is this just semantics? What happens when it's left `null`—e.g. if I use this mixin: 

``` scss
.col-b { @include flex-grid-column; }
```
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-27T15:42:50Z,False,215125307.0,"@andycochran Yes, it is only semantical.

With this PR, we have :

``` scss
// .col-a is equal to .col-b
.col-a { @include flex-grid-column(expand); }
.col-b { @include flex-grid-column; }

// but .col-c is not accepted
.col-b { @include flex-grid-column(null); } // because a ""null"" value is meaningless
```

Should we accept when a `null` value is explicitly passed to the mixin ? I think we shouldn't.
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-27T16:58:50Z,False,215147993.0,"If a `null` value can currently be passed to the mixin, we shouldn't drop support for that. Don't want to break apps. 
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-04-27T17:19:54Z,False,215156584.0,"@andycochran Fixed (and rebased)
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-05-04T17:04:04Z,False,216933098.0,"@andycochran can you take a look at this and merge if it seems good to you?
",True,False
zurb/foundation-sites/8510/pulls/zurb/foundation-sites/8510,2016-10-05T16:29:13Z,False,251726536.0,"Having used flexbox and flex grid more now, digging into this it makes perfect sense and I think is good to go.
",True,False
vikrend/final_js_task/66/pulls/vikrend/final_js_task/66,2020-06-09T07:15:27Z,False,641083146.0,Superseded by #68.,True,False
ianwalter/file-record/90/pulls/ianwalter/file-record/90,2019-04-17T10:21:00Z,False,484026164.0,Superseded by #97.,True,False
dmytrostriletskyi/accessify/101/pulls/dmytrostriletskyi/accessify/101,2020-05-08T12:09:50Z,False,625785033.0,Superseded by #106.,True,False
limdauto/drf_openapi/166/pulls/limdauto/drf_openapi/166,2018-11-12T04:23:44Z,False,437750095.0,Closing this in favor of #192,True,False
everypolitician/everypolitician-data/165338/pulls/everypolitician/everypolitician-data/165338,2019-06-23T00:52:30Z,False,504709563.0,"
No Popolo files were changed in this pull request.

",True,False
everypolitician/everypolitician-data/165338/pulls/everypolitician/everypolitician-data/165338,2019-06-24T10:26:59Z,False,504952725.0,This Pull Request has been superseded by #165756,True,False
conda-forge/shade-feedstock/15/pulls/conda-forge/shade-feedstock/15,2019-03-08T00:28:14Z,False,470756246.0,"
Hi! This is the friendly automated conda-forge-linting service.

I just wanted to let you know that I linted all conda-recipes in your PR (```recipe```) and found it was in an excellent condition.

",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-13T16:20:02Z,False,293946224.0,"@krisis umm, are we sure? doesn't that require from the client to have the correct time to correctly compute the duration ?",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-14T06:14:59Z,False,294097950.0,Tests need fix.,True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-14T06:43:30Z,False,294101350.0,"@vadmeste 
>@krisis umm, are we sure? doesn't that require from the client to have the correct time to correctly compute the duration ?

Interesting point you raise. If we can't expect clients to be in (time) sync with Minio server, then we will need both the time when the lock was held (as per Minio server) and duration. 

@harshavardhana @krishnasrinivas Is it correct to expect Minio server and clients like `mc` to have their time in sync?",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-14T06:46:56Z,False,294101754.0,"> @harshavardhana @krishnasrinivas Is it correct to expect Minio server and clients like mc to have their time in sync?

They can be different timezones but they should be in UTC sync - 15mins is the window allowed for time skew between `mc` and `minio` ",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-14T07:23:31Z,False,294106545.0,"# [Codecov](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=h1) Report
> Merging [#4111](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=desc) into [master](https://codecov.io/gh/minio/minio/commit/d103d5fb7c71b4ac09195f7fb337452994dd8e40?src=pr&el=desc) will **increase** coverage by `0.63%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/minio/minio/pull/4111/graphs/tree.svg?height=150&width=650&token=4wG3Jysopw&src=pr)](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #4111      +/-   ##
==========================================
+ Coverage   68.23%   68.86%   +0.63%     
==========================================
  Files         174      141      -33     
  Lines       24125    22741    -1384     
==========================================
- Hits        16461    15660     -801     
+ Misses       6553     6042     -511     
+ Partials     1111     1039      -72
```


| [Impacted Files](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [cmd/lockinfo-handlers.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2xvY2tpbmZvLWhhbmRsZXJzLmdv) | `94.44% <ø> (-0.16%)` | :arrow_down: |
| [cmd/storage-rpc-client.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3N0b3JhZ2UtcnBjLWNsaWVudC5nbw==) | `33.86% <0%> (-39.69%)` | :arrow_down: |
| [cmd/update-notifier.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3VwZGF0ZS1ub3RpZmllci5nbw==) | `57.14% <0%> (-23.22%)` | :arrow_down: |
| [cmd/storage-rpc-server.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3N0b3JhZ2UtcnBjLXNlcnZlci5nbw==) | `54.26% <0%> (-21.71%)` | :arrow_down: |
| [cmd/posix-errors.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3Bvc2l4LWVycm9ycy5nbw==) | `49.09% <0%> (-20%)` | :arrow_down: |
| [cmd/gateway-startup-msg.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2dhdGV3YXktc3RhcnR1cC1tc2cuZ28=) | `76.66% <0%> (-6.67%)` | :arrow_down: |
| [cmd/net.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL25ldC5nbw==) | `79.2% <0%> (-6.4%)` | :arrow_down: |
| [cmd/fs-v1-background-append.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2ZzLXYxLWJhY2tncm91bmQtYXBwZW5kLmdv) | `73.82% <0%> (-6.05%)` | :arrow_down: |
| [cmd/fs-v1-rwpool.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2ZzLXYxLXJ3cG9vbC5nbw==) | `55.81% <0%> (-5.43%)` | :arrow_down: |
| [cmd/object-api-errors.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL29iamVjdC1hcGktZXJyb3JzLmdv) | `73.46% <0%> (-4.77%)` | :arrow_down: |
| ... and [43 more](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=footer). Last update [d103d5f...44e665e](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-14T07:23:31Z,False,294106546.0,"# [Codecov](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=h1) Report
> Merging [#4111](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=desc) into [master](https://codecov.io/gh/minio/minio/commit/d103d5fb7c71b4ac09195f7fb337452994dd8e40?src=pr&el=desc) will **decrease** coverage by `0.01%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/minio/minio/pull/4111/graphs/tree.svg?width=650&src=pr&token=4wG3Jysopw&height=150)](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #4111      +/-   ##
==========================================
- Coverage   68.23%   68.21%   -0.02%     
==========================================
  Files         174      174              
  Lines       24125    24124       -1     
==========================================
- Hits        16461    16457       -4     
- Misses       6553     6556       +3     
  Partials     1111     1111
```


| [Impacted Files](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [pkg/madmin/lock-commands.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-cGtnL21hZG1pbi9sb2NrLWNvbW1hbmRzLmdv) | `15.55% <ø> (ø)` | :arrow_up: |
| [cmd/lockinfo-handlers.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2xvY2tpbmZvLWhhbmRsZXJzLmdv) | `94.44% <ø> (-0.16%)` | :arrow_down: |
| [cmd/fs-v1-background-append.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2ZzLXYxLWJhY2tncm91bmQtYXBwZW5kLmdv) | `78.52% <0%> (-1.35%)` | :arrow_down: |
| [cmd/xl-v1-metadata.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3hsLXYxLW1ldGFkYXRhLmdv) | `71.9% <0%> (-0.96%)` | :arrow_down: |
| [cmd/xl-v1-utils.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3hsLXYxLXV0aWxzLmdv) | `91.35% <0%> (-0.83%)` | :arrow_down: |
| [cmd/posix.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3Bvc2l4Lmdv) | `73.25% <0%> (-0.16%)` | :arrow_down: |
| [cmd/xl-v1-multipart.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL3hsLXYxLW11bHRpcGFydC5nbw==) | `78.56% <0%> (-0.13%)` | :arrow_down: |
| [cmd/fs-v1-helpers.go](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=tree#diff-Y21kL2ZzLXYxLWhlbHBlcnMuZ28=) | `53.87% <0%> (+2.04%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=footer). Last update [d103d5f...44e665e](https://codecov.io/gh/minio/minio/pull/4111?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-14T09:43:59Z,False,294126667.0,"Or we do the reverse, we un-export Since field and keep Duration",True,False
minio/minio/4111/pulls/minio/minio/4111,2017-04-15T06:54:38Z,False,294276534.0,"@vadmeste, Like we discussed, `Since` and `Duration` fields are both equivalent, given that the server and clients can't be farther than 15 minutes, I have decided to retain `Since` and remove `Duration` as it is in this PR. Could you provide further review comments if any?",True,False
gfoidl/Base64/1/pulls/gfoidl/Base64/1,2018-11-21T16:52:06Z,False,440736179.0,"Test for MacOS fails:

```
Failed   Correct_combined_sbyte_vector
Error Message:
 System.PlatformNotSupportedException : Operation is not supported on this platform.
Stack Trace:
   at System.Runtime.Intrinsics.X86.Avx2.PackUnsignedSaturate(Vector256`1 left, Vector256`1 right)
   at gfoidl.Base64.Avx2Helper.Read(Char& src) in /Users/vsts/agent/2.142.1/work/1/s/source/gfoidl.Base64/Avx2Helper.cs:line 48
   at gfoidl.Base64.Tests.Avx2HelperTests.Read.Correct_combined_sbyte_vector() in /Users/vsts/agent/2.142.1/work/1/s/tests/gfoidl.Base64.Tests/Avx2HelperTests/Read.cs:line 22
Failed   Correct_data_written
Error Message:
 System.PlatformNotSupportedException : Operation is not supported on this platform.
Stack Trace:
   at System.Runtime.Intrinsics.X86.Avx2.UnpackLow(Vector256`1 left, Vector256`1 right)
   at gfoidl.Base64.Avx2Helper.Write(Vector256`1 vec, Char& dest) in /Users/vsts/agent/2.142.1/work/1/s/source/gfoidl.Base64/Avx2Helper.cs:line 17
   at gfoidl.Base64.Tests.Avx2HelperTests.Write.Correct_data_written() in /Users/vsts/agent/2.142.1/work/1/s/tests/gfoidl.Base64.Tests/Avx2HelperTests/Write.cs:line 25
Results File: /Users/vsts/agent/2.142.1/work/1/s/tests/gfoidl.Base64.Tests/TestResults/gfoidl.Base64.Tests.csproj-1542818799.trx
```

Maybe related to https://github.com/dotnet/coreclr/issues/21105",True,False
gfoidl/Base64/1/pulls/gfoidl/Base64/1,2018-11-21T17:33:42Z,False,440750210.0,There must be something wrong with the MacOS implementation -- see https://dev.azure.com/gh-gfoidl/github-Projects/_build/results?buildId=117&view=logs -- so I'll skip AVX2 for MacOS in the meantime.,True,False
gfoidl/Base64/1/pulls/gfoidl/Base64/1,2018-11-21T17:18:51Z,False,235475974.0,This hack will be undone once the `PlatformNotSupportedException` is elided for MacOS.,True,False
diablomedia/zf1-session/31/pulls/diablomedia/zf1-session/31,2020-02-05T15:32:37Z,False,582464449.0,"# [Codecov](https://codecov.io/gh/diablomedia/zf1-session/pull/31?src=pr&el=h1) Report
> Merging [#31](https://codecov.io/gh/diablomedia/zf1-session/pull/31?src=pr&el=desc) into [master](https://codecov.io/gh/diablomedia/zf1-session/commit/0a9fdeaee1743e4ee54533f0464f11ae29a41d05?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/diablomedia/zf1-session/pull/31/graphs/tree.svg?width=650&token=EhiJ16asBj&height=150&src=pr)](https://codecov.io/gh/diablomedia/zf1-session/pull/31?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master      #31   +/-   ##
=========================================
  Coverage     43.54%   43.54%           
  Complexity      214      214           
=========================================
  Files             6        6           
  Lines           434      434           
=========================================
  Hits            189      189           
  Misses          245      245
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/diablomedia/zf1-session/pull/31?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/diablomedia/zf1-session/pull/31?src=pr&el=footer). Last update [0a9fdea...1243fa6](https://codecov.io/gh/diablomedia/zf1-session/pull/31?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
freshgrlc/freshgrlc-explorer/249/pulls/freshgrlc/freshgrlc-explorer/249,2020-04-07T07:05:50Z,False,610214675.0,Superseded by #251.,True,False
vk-brain/kutana/18/pulls/vk-brain/kutana/18,2018-09-20T13:43:47Z,False,423188182.0,"## Pull Request Test Coverage Report for [Build 149](https://coveralls.io/builds/19102873)

* **39** of **40**   **(97.5%)**  changed or added relevant lines in **4** files are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage increased (+**0.2%**) to **93.886%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [kutana/controller_vk/vkwrappers.py](https://coveralls.io/builds/19102873/source?filename=kutana%2Fcontroller_vk%2Fvkwrappers.py#L71) | 18 | 19 | 94.74%
<!-- | **Total:** | **39** | **40** | **97.5%** | -->


|  Totals | [![Coverage Status](https://coveralls.io/builds/19102873/badge)](https://coveralls.io/builds/19102873) |
| :-- | --: |
| Change from base [Build 142](https://coveralls.io/builds/19047153): |  0.2% |
| Covered Lines: | 645 |
| Relevant Lines: | 687 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",True,False
vk-brain/kutana/18/pulls/vk-brain/kutana/18,2018-09-20T13:48:26Z,False,423189819.0,"This pull request **introduces 2 alerts** when merging ae113cf79f8b10abbd035f9a062edf0a2f25dda9 into 50d3fd61b70357305ba3ad4a13a86d22c02a0fa6 - [view on LGTM.com](https://lgtm.com/projects/g/vk-brain/kutana/rev/pr-8e885f058550406f34a301ffa4d33efac93ac414)

**new alerts:**

* 2 for Redundant assignment

---

*Comment posted by [LGTM.com](https://lgtm.com)*",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T12:52:02Z,False,403025118.0,"@pradyunsg thanks for the feedback! I've incorporated your changes. If you think the approach is solid, I'll remove the wip and mark is as closing #4187 ",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T15:43:59Z,False,403071511.0,It just occurred to me that we would also want to block pip from doing this on test.pypi.org (the domain is test-file.pythonhosted.org).,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T17:49:08Z,False,403103488.0,@pradyunsg changes integrated,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-07T14:18:44Z,False,403218836.0,"@pradyunsg once more, with feeling! :)",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-10T13:38:05Z,False,403825003.0,"@pradyunsg  no worries, might as well get it right the first time =)

I've addressed your changes, but the tests are going to fail since we're also now testing against test.pypi.org, which doesn't have `peppercorn` which `sampleproject` depends on, which is wanted by `pep-508-urls` =)",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-11T13:39:30Z,False,404172920.0,@pradyunsg ready for review again,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-13T12:24:36Z,False,404817917.0,@pradyunsg any more feedback? =),True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-13T14:43:58Z,False,404854426.0,"Thanks @bstrdsmkr! LGTM.

@pypa/pip-committers Does anyone else want to review this, or want additional changes here?",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-13T15:06:29Z,False,404861130.0,"I don't have time to do a full review, but I quickly skimmed the code and it looks OK to me. Thanks @bstrdsmkr for picking up this change for us!",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-21T08:03:24Z,False,406779325.0,"Pushing this down the road to the next release since I don't think this'd happen in time for 18.0.

This doesn't seem to be a release blocker -- it's new functionality that can be merged post 18.0.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-21T09:21:01Z,False,406783213.0,"@pradyunsg We've had a couple of approvals, plus my OK. Why not just merge this? Nothing's going to happen between now and when we do merge, so I don't see much value in being cautious here. I'm OK to merge this unless you have a specific objection.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-21T09:25:41Z,False,406783441.0,"Apologies, I see from https://github.com/pypa/pip/issues/5516#issuecomment-405163636 that the 18.0 release is this weekend, so that's a perfectly good reason for deferring!

I'll merge this after the release.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-21T12:54:46Z,False,406794962.0,I'm not seeing the reason this was pushed. It's holding up things at work for me so I can fix things today if there's any way to get this in the next release,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-22T05:29:41Z,False,406842236.0,"> I'm not seeing the reason this was pushed.

I'd prefer to be a little cautious here and not merge this PR right now. I understand that this change might be holding up some improvement/cleanup work for you (and other users) and I'd personally like to see this change made too. I do feel being a little cautious here doesn't hurt _that_ much.

Further, while I do think this PR is ready to merge, I think these changes should be released with some changes to `--process-dependency-links` (like clearly providing a timeline for it's removal, suggesting users to move over to PEP 508 URL deps when they use it etc) and there's possibly some discussion that needs to happen there. It's definitely too late for that discussion to complete in time for 18.0, which is going to be released today/tomorrow.
",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-22T07:21:33Z,False,406846701.0,Sounds reasonable to me,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-22T14:38:17Z,False,406871353.0,"I can understand that, I just wish I had known that upfront and I wouldn't have put so much effort into trying to get it ready so fast.

Either way, thanks for your help in getting it this far. Any estimate on when it will be released? Ballpark obviously, I just have to give a report on the delay",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-22T15:00:58Z,False,406872920.0,"With pip 18, we've now switched to a regular release cadence, which you can find the full details at https://pip.pypa.io/en/stable/development/#release-cadence, but the tl;dr is the next release will be October, so if everything is ready and merged before October, it'll go out then.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-22T17:54:19Z,False,406884845.0,"> I can understand that, I just wish I had known that upfront and I wouldn't have put so much effort into trying to get it ready so fast.

Indeed. I agree that this could have been communicated earlier; apologies for that.

Will take care of this in the future. :)
",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-23T09:23:22Z,False,406995271.0,"I think this can go in now. The `--process-dependency-links` changes depend on this being in, not the other way around.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-08-06T10:43:19Z,False,410667224.0,"So dependencies with install_requires sub-dependencies in private Git repos are broken until October?

MyGitPackage A -> Depends on -> MyGitPackage B

Both A and B are from our private Git repo, But B cannot be installed because:

`Error: Direct url requirement (like mygitpackageB@YourPrivateRepo) are not allowed for dependencies`

when using setup.py in Package A

```
install_requires = [
    mygitpackageB@git+ssh://git@somegitserver/mygitpackageB@master#egg=mygitpackageB=99.0.0
]
```

And there is no way to override this check.

Is there a pre-release version available?

We will have several hundred packages that depend on other packages in the same repo.
(Major code isolation/separation project)",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-08-07T00:04:03Z,False,410890296.0,"@AdamLeyshon somewhat ironically, it seems like `pip install git+https://github.com/pypa/pip@master#egg=pip` should work?",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-08-07T00:15:24Z,False,410892366.0,"That has been the case since pip 10, which is when this functionality was introduced.

While the blocking seems arbitrary, the intent is to allow the user to not be able to install packages from PyPI that reach out to random locations on the internet. This PR makes it a much more specific, allowing the use of URL dependencies in a package's install_requires when installing from anywhere except PyPI, enabling use cases such as yours.

None the less, yes, the next release is in October. This functionality would be released then, barring any blockers.
",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-08-09T04:19:12Z,False,411631704.0,"It seems to me it would be trivial to create a PyPI compliant package that downloads and executes code from elsewhere, so the precautions being taken here are unnecessary. 

For example if setup.py or the package at runtime calls `os.system(""pip install git://malware.com/..."")`, possibly with some obfuscation and introspection of its caller, restricting to PyPI isn't going to protect anyone, but it is going to inconvenience a lot of people.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2019-05-31T20:40:55Z,False,497853177.0,This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-05T20:52:24Z,False,200486476.0,mypy won't be super happy about this.,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-05T20:53:30Z,False,200486734.0,suggestion: `Allow PEP 508 URL requirements to be used as dependencies.`,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-05T20:54:57Z,False,200487080.0,"nit: Instead of checking the entire message over multiple statements, I'd rather that you compose an `expected` string and then just do `assert expected in result.stderr`.

We should also check the exit code here.",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-05T20:56:49Z,False,200487553.0,"This indentation seems weird.

Could you make both the comment and the statement the same indent, which is a multiple of 4?",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T14:03:00Z,False,200662997.0,"You can drop the default on this.

Making it mandatory to pass doesn't affect anything and prevents from accidentally missing it out. :)",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T14:13:31Z,False,200666057.0,"Call this something else? `link_source` seems very ambiguous and is completely out of context in this file.

Possibly `file_storage_domain`?",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T14:16:11Z,False,200666766.0,"This message shows up as:

```
Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI. pep-508-url-deps from https://files.pythonhosted.org/packages/bc/69/b088a665f2cf87cb1f260376dce6895bf4b00336736b2082ef5af5a8bd20/pep-508-url-deps-1.0.0.post0.tar.gz#sha256=0fdbbb60d734d738d1bd25eeddfb4bc89f1c3cc5406f59c32b7eb4445439f1b6 depends on sampleproject@ https://github.com/pypa/sampleproject/archive/master.zip
```

I don't think that's very friendly or clear. It's rather have something like:

```
PEP 508 URL requirements are forbidden when installing from PyPI.
  pep-508-url-deps depends on sampleproject@https://github.com/pypa/sampleproject/archive/master.zip
```",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T14:21:12Z,False,200668290.0,"Minor preference to not say ""blacklisted"" here. I'd rather just say:

> As a security measure, this is not supported when installing from PyPI for dependencies not hosted on PyPI. In the future, PyPI will block uploading packages with such external URL dependencies directly.
",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T15:17:41Z,False,200685832.0,"I'm trying to point attention to the fact that this is a conscious choice to make it not work for a specific reason, rather than just unsupported which felt more to me like ""may or may not work.""

Does that make sense?",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T15:42:44Z,False,200693075.0,"Indeed. My reservation here is that this says ""blacklist"" here (and in the comment) but we don't actually have a ""list"" of packages that we disallow based on -- it's on a characteristic of how the installation is being done.

So, a phrasing that doesn't use ""blacklist"" is something I'd prefer but I won't block this PR for this. :P
",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T22:04:36Z,False,200781472.0,"It's `test-files.pythonhosted.org`.

https://test-files.pythonhosted.org/packages/6d/00/8ed1b6ea43b10bfe28d08e6af29fd6aa5d8dab5e45ead9394a6268a2d2ec/requests-2.5.4.1-py2.py3-none-any.whl",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-06T22:12:38Z,False,200782561.0,This should also check the behavior for TestPyPI; to ensure that is correct as well.,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-09T03:43:11Z,False,200875080.0,The test can simply be parameterized.,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-09T03:43:50Z,False,200875129.0,"Can we instead have a `TestPyPI = Index(...)`, and use that in the checks?",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-10T17:18:35Z,False,201425936.0,"This should also check for TestPyPI though.

Suggestion (you can use a different way if you like):

```py3
domains_not_allowed = [PyPI..., TestPyPI...]
comes_from_domain = comes_from...
if req.url and comes_from_domain in domains_not_allowed:
    ...
```",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-07-10T17:28:52Z,False,201429345.0,I think it would be a good idea to check the error code before checking the message.,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-10-05T22:24:22Z,False,223152710.0,"If `comes_from.link is None`, this crashes. This can happen if a package is already installed, and it was installed from a local wheel. I tested this on Pip 18.1 released today, but can't figure out how to make a minimum example.

```
Exception:
Traceback (most recent call last):
  File ""<local>/venv/lib/python3.7/site-packages/pip/_internal/cli/base_command.py"", line 143, in main
    status = self.run(options, args)
  File ""<local>/venv/lib/python3.7/site-packages/pip/_internal/commands/install.py"", line 318, in run
    resolver.resolve(requirement_set)
  File ""<local>/venv/lib/python3.7/site-packages/pip/_internal/resolve.py"", line 102, in resolve
    self._resolve_one(requirement_set, req)
  File ""<local>/venv/lib/python3.7/site-packages/pip/_internal/resolve.py"", line 318, in _resolve_one
    add_req(subreq, extras_requested=available_requested)
  File ""<local>/venv/lib/python3.7/site-packages/pip/_internal/resolve.py"", line 275, in add_req
    wheel_cache=self.wheel_cache,
  File ""<local>/venv/lib/python3.7/site-packages/pip/_internal/req/constructors.py"", line 288, in install_req_from_req
    if req.url and comes_from.link.netloc in domains_not_allowed:
AttributeError: 'NoneType' object has no attribute 'netloc'
```",True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-10-06T05:11:11Z,False,223172183.0,@wkschwartz : can you check with #5788?,True,False
pypa/pip/5571/pulls/pypa/pip/5571,2018-10-06T17:29:32Z,False,223188484.0,"I think this line can simply be changed to
```python
if req.url and comes_from.link is not None and comes_from.link.netloc in domains_not_allowed:
```",True,False
yuuma-S/Bookers2/17/pulls/yuuma-S/Bookers2/17,2020-01-28T07:11:13Z,False,579111108.0,Superseded by #29.,True,False
cedon/wp-theme-gulp/84/pulls/cedon/wp-theme-gulp/84,2019-03-05T10:16:14Z,False,469623445.0,Superseded by #85.,True,False
DivLoic/kafka-tutorials/33/pulls/DivLoic/kafka-tutorials/33,2020-12-14T07:18:46Z,False,744228856.0,"Dependabot tried to add `@bbejeck`, `@rspurgeon` and `@gamussa` as reviewers to this PR, but received the following error from GitHub:

```
POST https://api.github.com/repos/DivLoic/kafka-tutorials/pulls/33/requested_reviewers: 422 - Reviews may only be requested from collaborators. One or more of the users or teams you specified is not a collaborator of the DivLoic/kafka-tutorials repository. // See: https://docs.github.com/rest/reference/pulls#request-reviewers-for-a-pull-request
```",True,False
DivLoic/kafka-tutorials/33/pulls/DivLoic/kafka-tutorials/33,2021-02-12T05:59:29Z,False,777994223.0,Superseded by #38.,True,False
line/armeria/1853/pulls/line/armeria/1853,2019-06-24T10:45:41Z,False,504958088.0,"# [Codecov](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=h1) Report
> Merging [#1853](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=desc) into [master](https://codecov.io/gh/line/armeria/commit/5315f44bb7cf602c9cd3255d5d507d5232ecaab8?src=pr&el=desc) will **decrease** coverage by `0.02%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/line/armeria/pull/1853/graphs/tree.svg?width=650&token=3lXj2zLDWu&height=150&src=pr)](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=tree)

```diff
@@             Coverage Diff              @@
##             master    #1853      +/-   ##
============================================
- Coverage     73.24%   73.21%   -0.03%     
+ Complexity     8815     8813       -2     
============================================
  Files           779      779              
  Lines         34501    34501              
  Branches       4220     4220              
============================================
- Hits          25269    25260       -9     
- Misses         7090     7101      +11     
+ Partials       2142     2140       -2
```


| [Impacted Files](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=tree) | Coverage Δ | Complexity Δ | |
|---|---|---|---|
| [...inecorp/armeria/server/file/StreamingHttpFile.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Y29yZS9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL3NlcnZlci9maWxlL1N0cmVhbWluZ0h0dHBGaWxlLmphdmE=) | `53.04% <0%> (-8.7%)` | `14% <0%> (-3%)` | |
| [.../linecorp/armeria/internal/Http2ObjectEncoder.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Y29yZS9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL2ludGVybmFsL0h0dHAyT2JqZWN0RW5jb2Rlci5qYXZh) | `71.42% <0%> (-8.58%)` | `12% <0%> (-1%)` | |
| [...meria/internal/AbstractHttp2ConnectionHandler.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Y29yZS9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL2ludGVybmFsL0Fic3RyYWN0SHR0cDJDb25uZWN0aW9uSGFuZGxlci5qYXZh) | `93.33% <0%> (-3.34%)` | `13% <0%> (-1%)` | |
| [...com/linecorp/armeria/internal/grpc/GrpcStatus.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Z3JwYy9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL2ludGVybmFsL2dycGMvR3JwY1N0YXR1cy5qYXZh) | `64.7% <0%> (-2.95%)` | `24% <0%> (-1%)` | |
| [...com/linecorp/armeria/server/HttpServerHandler.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Y29yZS9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL3NlcnZlci9IdHRwU2VydmVySGFuZGxlci5qYXZh) | `81.29% <0%> (+0.34%)` | `80% <0%> (ø)` | :arrow_down: |
| [...inecorp/armeria/server/grpc/ArmeriaServerCall.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Z3JwYy9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL3NlcnZlci9ncnBjL0FybWVyaWFTZXJ2ZXJDYWxsLmphdmE=) | `86.56% <0%> (+0.39%)` | `82% <0%> (+1%)` | :arrow_up: |
| [...a/common/grpc/protocol/ArmeriaMessageDeframer.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Z3JwYy1wcm90b2NvbC9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL2NvbW1vbi9ncnBjL3Byb3RvY29sL0FybWVyaWFNZXNzYWdlRGVmcmFtZXIuamF2YQ==) | `71.77% <0%> (+0.95%)` | `48% <0%> (+1%)` | :arrow_up: |
| [...inecorp/armeria/client/grpc/ArmeriaClientCall.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Z3JwYy9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL2NsaWVudC9ncnBjL0FybWVyaWFDbGllbnRDYWxsLmphdmE=) | `82.22% <0%> (+1.48%)` | `37% <0%> (+1%)` | :arrow_up: |
| [...lient/circuitbreaker/CircuitBreakerHttpClient.java](https://codecov.io/gh/line/armeria/pull/1853/diff?src=pr&el=tree#diff-Y29yZS9zcmMvbWFpbi9qYXZhL2NvbS9saW5lY29ycC9hcm1lcmlhL2NsaWVudC9jaXJjdWl0YnJlYWtlci9DaXJjdWl0QnJlYWtlckh0dHBDbGllbnQuamF2YQ==) | `72.72% <0%> (+3.03%)` | `11% <0%> (+1%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=footer). Last update [5315f44...a1399b2](https://codecov.io/gh/line/armeria/pull/1853?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
line/armeria/1853/pulls/line/armeria/1853,2019-06-25T01:11:59Z,False,505237737.0,Thanks for reviewing.,True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T02:55:21Z,False,477426254.0,/test e2e-aws,True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T03:02:02Z,False,477427759.0,"Dependency openshift/cluster-bootstrap#22 PR has merged

/hold cancel",True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T03:24:13Z,False,477432309.0,"/lgtm

/refresh",True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T03:24:26Z,False,477432342.0,"/hold

wouldn't the etcd metric flags require https://github.com/openshift/kubecsr/pull/6 to merge ?",True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T03:31:50Z,False,477433779.0,"> wouldn't the etcd metric flags require openshift/kubecsr#6 to merge ?

correct, removed.",True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T03:38:43Z,False,477435004.0,/hold cancel,True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T04:17:50Z,False,477441554.0,/lgtm,True,False
openshift/installer/1477/pulls/openshift/installer/1477,2019-03-28T04:18:00Z,False,477441582.0,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/openshift/installer/pull/1477#issuecomment-477441554"" title=""LGTM"">abhinavdahiya</a>*, *<a href=""https://github.com/openshift/installer/pull/1477#"" title=""Author self-approved"">hexfusion</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=openshift%2Finstaller).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[OWNERS](https://github.com/openshift/installer/blob/master/OWNERS)~~ [abhinavdahiya]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",True,False
test-organization-kkjeer/app-test/51684/pulls/test-organization-kkjeer/app-test/51684,2020-08-25T14:02:12Z,False,680044418.0,@bot-app-test merge in 3 minutes,True,False
test-organization-kkjeer/app-test/51684/pulls/test-organization-kkjeer/app-test/51684,2020-08-25T14:02:14Z,False,680044450.0,"<!--[AutoMerge]-->
Hello @bot-monkey-1!

Because this pull request has the `AutoMerge` label, I will be glad to assist with helping to merge this pull request once all check-in policies pass.

Do note that I've been instructed to only help merge pull requests of this repository that have been opened for at least **4 minutes**. No worries though, I will be back when the time is right! :wink:

##### p.s. you can customize the way I help with merging this pull request, such as holding this pull request until a specific person approves. Simply @mention me (`@bot-app-test`) and give me an instruction to get started! Learn more [here](https://github.com/microsoft/fluentui/wiki/Advanced-auto-merge).",True,False
test-organization-kkjeer/app-test/51684/pulls/test-organization-kkjeer/app-test/51684,2020-08-25T14:02:19Z,False,680044501.0,@bot-app-test merge only when @bot-monkey-2 and @bot-monkey-3 approve,True,False
test-organization-kkjeer/app-test/51684/pulls/test-organization-kkjeer/app-test/51684,2020-08-25T14:02:29Z,False,680044582.0,"Hello @bot-monkey-1!

Because you've given me some instructions on how to help merge this pull request, I'll be modifying my merge approach. Here's how I understand your requirements for merging this pull request:
* I won't merge this pull request until after the UTC date **Tue, 25 Aug 2020 14:05:28 GMT**, which is in 3 minutes

If this doesn't seem right to you, you can tell me to cancel these instructions and use the auto-merge policy that has been configured for this repository. Try telling me ""forget everything I just told you"".",True,False
test-organization-kkjeer/app-test/51684/pulls/test-organization-kkjeer/app-test/51684,2020-08-25T14:02:33Z,False,680044621.0,"Hello @bot-monkey-1!

Because you've given me some instructions on how to help merge this pull request, I'll be modifying my merge approach. Here's how I understand your requirements for merging this pull request:
* I'll only merge this pull request if it's approved by @bot-monkey-2 and @bot-monkey-3
* I won't merge this pull request until after the UTC date **Tue, 25 Aug 2020 14:05:28 GMT**, which is in 3 minutes

If this doesn't seem right to you, you can tell me to cancel these instructions and use the auto-merge policy that has been configured for this repository. Try telling me ""forget everything I just told you"".",True,False
zio/zio/777/pulls/zio/zio/777,2019-04-19T15:29:10Z,False,484931628.0,@jdegoes some laws do not pass,True,False
zio/zio/777/pulls/zio/zio/777,2019-04-19T15:29:43Z,False,484931784.0,"@joroKr21 I would expect a few failures (primarily because Scala.js has no way to ""block"" and there may be some ""forks"" that are requiring this). We should disable those tests for now (just in Scala.js), write them up in tickets, and address them after this work. ",True,False
zio/zio/777/pulls/zio/zio/777,2019-04-19T15:32:34Z,False,484932717.0,"The problem was in the runtime used for testing. I changed it to use `TestContext` which is deterministic.
And no blocking is needed to define equality.

But some laws are not passing neither on the JVM nor on JS.
The tests were passing before because the generator used was too naive (`genSuccess`)",True,False
zio/zio/777/pulls/zio/zio/777,2019-04-19T16:58:42Z,False,484956745.0,"I don't think there is a lawful alternative instance, we might have to just remove it and change semigroupK / monoidK to accumulate errors. ",True,False
zio/zio/777/pulls/zio/zio/777,2019-04-19T21:54:26Z,False,485023483.0,I don't know about the other laws.,True,False
zio/zio/777/pulls/zio/zio/777,2019-04-25T22:07:09Z,False,486855117.0,"@jdegoes Wdyt about this suggestion?
  * `Alternative` - remove this instance and replace it with `SemigroupK` and `MonoidK` which combine errors
  * `guarantee` - change `ZIO.bracket` to be consistent with `ZIO.ensuring` and preserve errors

But I would need help to figure out why the `ConcurrentEffect` laws are broken.",True,False
zio/zio/777/pulls/zio/zio/777,2019-05-04T10:21:09Z,False,489314499.0,"Sorry for the delay on this, it's been a LONG week!

@joroKr21 

> Alternative - remove this instance and replace it with SemigroupK and MonoidK which combine errors

I think we can make a valid `Alternative` for any `Monoid` error type `E`. If one is success, we always choose that; if both are failures, we choose the one with non-empty `E`.
guarantee - change ZIO.bracket to be consistent with ZIO.ensuring and preserve errors

I do think we can do lawful `SemigroupK` and `MonoidK`.

> guarantee - change ZIO.bracket to be consistent with ZIO.ensuring and preserve errors

Can you explain this problem in more depth?

> But I would need help to figure out why the ConcurrentEffect laws are broken.

I am happy to help with that, I spent a lot of work already to ensure compliance with the previous `Gen`. Also it occurs to me that we could split the PR into 2, and deal with broken laws (as a result of a richer `Gen`) in a separate PR.

Please let me know if you need any more help, and thank you for your work on this thus far!",True,False
zio/zio/777/pulls/zio/zio/777,2019-05-04T12:14:41Z,False,489321698.0,"> Sorry for the delay on this, it's been a LONG week!

No worries, we don't have a deadline :smile: 

> I think we can make a valid Alternative for any Monoid error type E. If one is success, we always choose that; if both are failures, we choose the one with non-empty E.

I don't think this will work. Observe carefully the right absorption law:
```scala
(ff ap F.empty) <-> F.empty
```
Whatever we choose for `F.empty` when `ff` is a failed `ZIO` it will never be absorbed.

> guarantee - change ZIO.bracket to be consistent with ZIO.ensuring and preserve errors

`ZIO.bracket` is defined as: 

```scala
  final def bracket[R >: LowerR, E <: UpperE, A, B](
    acquire: ZIO[R, E, A],
    release: A => ZIO[R, Nothing, _],
    use: A => ZIO[R, E, B]
  ): ZIO[R, E, B] =
    bracketExit(acquire, (a: A, _: Exit[E, B]) => release(a), use)
```

Note how the `Exit` is ignored (thrown away).

`ensuring` (which is used to implement `guarantee`) is defined like this:

```scala
 final def ensuring[R1 <: R](finalizer: ZIO[R1, Nothing, _]): ZIO[R1, E, A] =
    ZIO.uninterruptibleMask(
      restore =>
        restore(self)
          .foldCauseM(
            cause1 =>
              finalizer.foldCauseM[R1, E, Nothing](
                cause2 => ZIO.halt(cause1 ++ cause2),
                _ => ZIO.halt(cause1)
              ),
            value =>
              finalizer.foldCauseM[R1, E, A](
                cause1 => ZIO.halt(cause1),
                _ => ZIO.succeed(value)
              )
          )
)
```

cats-effect requires consistency here. Is there any harm in preserving the error in `bracket` as well? Since the philosophy in ZIO is not to lose any errors.

> Also it occurs to me that we could split the PR into 2, and deal with broken laws (as a result of a richer Gen) in a separate PR.

I would say let's decide on `Alternative` and `bracket` here and we can leave the `Concurrent` issues for later.
",True,False
zio/zio/777/pulls/zio/zio/777,2019-05-13T19:22:40Z,False,491952512.0,"@joroKr21 

> I don't think this will work. Observe carefully the right absorption law:

In my opinion the right absorption law is a mistake and disallows all effect instances. But since Cats has it, we have to respect it.

> cats-effect requires consistency here. Is there any harm in preserving the error in bracket as well? Since the philosophy in ZIO is not to lose any errors.

No harm at all, in fact, it should be done. It was probably a consequence of me pulling so much more logic out of the runtime system after interruptible regions landed. We'll just have to compose it the right way with any other errors in the finalizer (preserving sequencing), and add a test or two.

This is great work, I appreciate your attention to detail and care. Let me know if you need anything else to get unstuck!",True,False
zio/zio/777/pulls/zio/zio/777,2019-05-28T19:35:23Z,False,496657728.0,"Sorry for the delay! Crazy few weeks at work :sweat_smile: 

> In my opinion the right absorption law is a mistake and disallows all effect instances. But since Cats has it, we have to respect it.

Maybe, if it's removed at some point an instance could be added but best not to risk breaking someone's code.

> No harm at all, in fact, it should be done. It was probably a consequence of me pulling so much more logic out of the runtime system after interruptible regions landed. We'll just have to compose it the right way with any other errors in the finalizer (preserving sequencing), and add a test or two.

Perfect!

Ok, I think tomorrow I could wrap up this PR :100: ",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-14T14:37:32Z,False,502134140.0,"Uh, rebasing this was very difficult (first, the entire namespace moved and then more interop was added in between). Now it seems that more laws are failing than before :disappointed: ",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-14T16:27:09Z,False,502174264.0,"Ah, nvm it's because a new `Cause` was added, needed to update the `Eq` instance. ",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-14T16:32:11Z,False,502175910.0,"Actually cats-interop is being moved to its own repo: https://github.com/zio/interop-cats 

The move isn’t finished yet but maybe you can already open the PR there?",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-14T17:14:19Z,False,502192152.0,Yes we could do that but then would need another PR before that to change `bracket`'s error handling.,True,False
zio/zio/777/pulls/zio/zio/777,2019-06-17T21:09:29Z,False,502851944.0,"I can't seem to make all tests pass. The signature of `ZIO.bracket` doesn't allow to halt with a combination of the `release` error and the `ExitCase` cause.

Also any tips on how to debug the concurrent test failures? ",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-18T09:56:46Z,False,503035597.0,"I took a closer look at the `bracket` vs `guarangee` failure. @jdegoes I think the problem is that `ensuring` will halt when the finalized halts, whereas `bracketExit` always returns the exit from `use`.
Here is the code for comparison:
```scala
 final def ensuring[R1 <: R](finalizer: ZIO[R1, Nothing, _]): ZIO[R1, E, A] =
    ZIO.uninterruptibleMask(
      restore =>
        restore(self)
          .foldCauseM(
            cause1 =>
              finalizer.foldCauseM[R1, E, Nothing](
                cause2 => ZIO.halt(cause1 ++ cause2),
                _ => ZIO.halt(cause1)
              ),
            value =>
              finalizer.foldCauseM[R1, E, A](
                cause1 => ZIO.halt(cause1),
                _ => ZIO.succeed(value)
              )
          )
    )
```
```scala
  final def bracketExit[R >: LowerR, E <: UpperE, A, B](
    acquire: ZIO[R, E, A],
    release: (A, Exit[E, B]) => ZIO[R, Nothing, _],
    use: A => ZIO[R, E, B]
  ): ZIO[R, E, B] =
    ZIO.uninterruptibleMask[R, E, B](
      restore =>
        acquire.flatMap(ZIOFn(traceAs = use) { a =>
          restore(use(a)).run.flatMap(ZIOFn(traceAs = release) { e =>
            release(a, e) *>
              ZIO.done(e)
          })
        })
    )
```",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-18T10:00:00Z,False,503036777.0,I just removed the override to `guarangee` and that solves the issue.,True,False
zio/zio/777/pulls/zio/zio/777,2019-06-20T01:10:03Z,False,503801551.0,"@joroKr21 I have to apologize for my tardiness on this pull request! I got overwhelmed a bit with LambdaConf preparations.

I'm just getting caught up now.

> I took a closer look at the bracket vs guarangee failure. @jdegoes I think the problem is that ensuring will halt when the finalized halts, whereas

Is the problem we get the wrong error from `bracketExit`? I see it ignores the release error now, which I can fix quite simply (an oversight).

Anything else that needs attention? After we get this sorted, we may have to move the PR Over to `interop-cats`, where the ""official"" version now lives.",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-20T05:58:54Z,False,503887107.0,"> Is the problem we get the wrong error from bracketExit? I see it ignores the release error now, which I can fix quite simply (an oversight).

Ah yes, that's true. So we can change `bracketExit` or remove the override to `guarantee` (which is what I did here). What would you prefer? 

> Anything else that needs attention?

There is one last failing law: ""bracket release is called on completed or error"" which is actually an `Async` law so I think it's important to get to the bottom of it. Note that we are not generating any interrupted ZIOs.

Also I started seeing some scala.js linking errors, maybe I changed the build in a wrong way during rebase? ",True,False
zio/zio/777/pulls/zio/zio/777,2019-06-20T12:19:43Z,False,504003806.0,I opened #1041 for the `bracketExit` change.,True,False
zio/zio/777/pulls/zio/zio/777,2019-07-08T22:54:04Z,False,509421088.0,@joroKr21 I will close this. Can you reopen on interop-cats repository? I'd love to help you get this through!,True,False
zio/zio/777/pulls/zio/zio/777,2019-07-09T05:23:25Z,False,509492858.0,This one failing law has become my nemesis :D,True,False
apache/pulsar-client-node/31/pulls/apache/pulsar-client-node/31,2019-06-12T02:40:11Z,False,501098320.0,"A binary file is committed.
```
.vscode/ipch/cc6423c2fd8ec533/mmap_address.bin
```",True,False
apache/pulsar-client-node/31/pulls/apache/pulsar-client-node/31,2019-06-12T02:42:35Z,False,501098784.0,I deleted `.vscode` dir,True,False
apache/pulsar-client-node/31/pulls/apache/pulsar-client-node/31,2019-06-11T08:03:25Z,False,292325116.0,Shouldn't we throw an exception if the result is not ok?,True,False
apache/pulsar-client-node/31/pulls/apache/pulsar-client-node/31,2019-06-11T10:07:12Z,False,292377832.0,"Yes. I think we should throw it.
So, I fixed same as https://github.com/apache/pulsar/blob/master/pulsar-client-go/pulsar/c_reader.go#L163-L169 ",True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-04-16T18:01:27Z,False,381695328.0,@dilekamadushan did you see the merge conflicts on this?,True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-07-11T08:54:00Z,False,404095228.0,@dilekamadushan are you still working on this?,True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-07-11T09:26:27Z,False,404104937.0,"@dkayiwa no this ticket has been solved through another PR. Closing it now.
Thanks for the heads up.",True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-03-19T18:00:24Z,False,175531126.0,"Please rename:
`SEARCH_ATTACHMENT_URL` → `ATTACHMENT_RESOURCE_URL`",True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-03-19T18:04:28Z,False,175532449.0,"No we **do not** want the REST resource to _implement_ the service layer API, just to use it by getting via `Context`:
```java
AttachmentsService as = Context.getService(AttachmentsService.class);
// use 'as' hereunder...
```
Both `AttachmentsService` and `AttachmentsServiceImpl` have to live in the **/api** subproject.

**NOTE:** Please refactor the API to `AttachmentsService` (plural).",True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-03-19T18:05:10Z,False,175532695.0,So this will belong to **/api**-located `AttachmentsServiceImpl`.,True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-03-19T18:25:12Z,False,175539270.0,Look at [this](https://github.com/openmrs/openmrs-core/blob/dee1e8fc0c445f96e7fdfca690fc7235d2f969c3/api/src/main/java/org/openmrs/api/ObsService.java#L231) kind of method.,True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-03-21T03:09:12Z,False,175976562.0,@mks-d Do you mean to use [this](https://github.com/openmrs/openmrs-core/blob/dee1e8fc0c445f96e7fdfca690fc7235d2f969c3/api/src/main/java/org/openmrs/api/ObsService.java#L231) method or create a method resembling to this.,True,False
openmrs/openmrs-module-attachments/14/pulls/openmrs/openmrs-module-attachments/14,2018-03-21T03:22:29Z,False,175977544.0,@mks-d I made a PR.Looking forward for the reviews. Thank you very much.,True,False
atom/settings-view/637/pulls/atom/settings-view/637,2015-08-21T23:10:30Z,False,133585746.0,"Whoops, forgot to cc @atom/feedback. This is probably fine now.
",True,False
atom/settings-view/637/pulls/atom/settings-view/637,2015-10-09T15:22:46Z,False,146902170.0,"This is a pretty minor speedup but it's something. I guarantee there's something else in the check outdated -> display cards process begging for an optimization.
",True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-01-30T01:57:59Z,False,458781443.0,"@joaoatgoogle 
Could you have a look at this PR?",True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-01-30T08:05:29Z,False,458849051.0,I'm not an appropriate reviewer for this change,True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-02-03T02:24:35Z,False,460017061.0,"@jason-simmons 
Could you have a look at this PR?",True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-02-12T03:57:47Z,False,462605945.0,Could you add a test?,True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-02-14T17:09:44Z,False,463709495.0,"> Could you add a test?

Done in: https://github.com/flutter/flutter/pull/27944",True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-02-12T03:52:31Z,False,255794425.0,"@chinmaygarde, somewhat tangential but you added a note to not use PlistBuddy in #1969 but we still have a wrapper in https://github.com/flutter/flutter/blob/master/packages/flutter_tools/lib/src/ios/mac.dart#L38. Should we remove it?",True,False
flutter/flutter/26964/pulls/flutter/flutter/26964,2019-02-12T03:57:21Z,False,255795168.0,"If it isn't named in a platform specific way, might as well extract lines 109-119 out into the constructors. And add dartdocs for the constructors for targeted platforms.",True,False
sanniassin/react-input-mask/63/pulls/sanniassin/react-input-mask/63,2016-12-20T09:04:14Z,False,268190921.0,"@sanniassin, can you have a look at this PR? Thx in advance",True,False
sanniassin/react-input-mask/63/pulls/sanniassin/react-input-mask/63,2017-06-08T14:38:46Z,False,307123841.0,@sanniassin this PR will be merged to the project sometime in this life?,True,False
sanniassin/react-input-mask/63/pulls/sanniassin/react-input-mask/63,2017-06-08T14:46:38Z,False,307126167.0,@robinschuere @rodrigobacelli Sorry for delay. I won't add any features which can be easily implemented in higher order component to keep this project as simple as possible. That's why i won't merge this PR.,True,False
dequelabs/axrl/240/pulls/dequelabs/axrl/240,2020-08-05T16:54:37Z,False,669308890.0,Superseded by #245.,True,False
apache/pulsar/2836/pulls/apache/pulsar/2836,2018-10-24T21:23:38Z,False,432833335.0,rerun java8 tests,True,False
apache/pulsar/2836/pulls/apache/pulsar/2836,2018-10-25T02:57:47Z,False,432896995.0,"rerun java8 tests
",True,False
apache/pulsar/2836/pulls/apache/pulsar/2836,2018-10-25T02:57:22Z,False,228020881.0,Seems this is not needed?,True,False
apache/pulsar/2836/pulls/apache/pulsar/2836,2018-10-25T18:43:53Z,False,228291196.0,"yes, it doesn't need but in one of the previous failure log, I saw error-message that ""namespace already exist"" so, I just added to fix it. However, issue seems something else where threads are stuck because bookkeeper ensemble is not up. and it's kind of weird because this test works fine locally. will look into it.",True,False
DFE-Digital/publish-teacher-training/1029/pulls/DFE-Digital/publish-teacher-training/1029,2020-04-21T08:11:50Z,False,617025875.0,"Auto pull request trigger is configured on this repository for PR validation. To review the app deployed by this PR, please replace `####` in the URL given below with the first four characters of your branch name. This could be your trello card number. https://s121d02-####-ptt-as.azurewebsites.net/
",True,False
andrejdergavko/Test-production-project/3/pulls/andrejdergavko/Test-production-project/3,2020-04-23T06:21:36Z,False,618203302.0,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",True,False
pythonitalia/pycon/258/pulls/pythonitalia/pycon/258,2018-07-17T04:19:56Z,False,405454794.0,Superseded by #281.,True,False
IMA-WorldHealth/bhima-2.X/328/pulls/IMA-WorldHealth/bhima-2.X/328,2016-04-18T12:45:41Z,False,211365260.0,"Magnifique! :+1:
",True,False
Adalab/fairfax-m3-reactvengers/38/pulls/Adalab/fairfax-m3-reactvengers/38,2019-05-28T10:43:33Z,False,496463977.0,looks good!😉,True,False
Jflick58/DepressionAI/397/pulls/Jflick58/DepressionAI/397,2019-08-18T23:12:21Z,False,522366403.0,Closing this in favor of #504,True,False
algolia/algoliasearch-client-javascript/992/pulls/algolia/algoliasearch-client-javascript/992,2020-02-05T13:26:55Z,False,582406423.0,"Looks like @rollup/plugin-node-resolve is up-to-date now, so this is no longer needed.",True,False
wzalazar/spotify/27/pulls/wzalazar/spotify/27,2019-01-24T05:51:55Z,False,457075721.0,"
This pull request is [automatically deployed](https://zeit.co/docs/features/now-for-github?utm_source=automated&utm_medium=github&utm_campaign=now_bot) with [Now](https://zeit.co/now?utm_source=automated&utm_medium=github&utm_campaign=now_bot).
To access deployments, click Details below or on the icon next to each push.


	
",True,False
wzalazar/spotify/27/pulls/wzalazar/spotify/27,2019-01-25T15:41:20Z,False,457614338.0,"### Renovate Ignore Notification

As this PR has been closed unmerged, Renovate will now ignore this update (2.6.1). You will still receive a PR once a newer version is released, so if you wish to permanently ignore this dependency, please add it to the `ignoreDeps` array of your renovate config.

If this PR was closed by mistake or you changed your mind, you can simply rename this PR and you will soon get a fresh replacement PR opened.",True,False
JohanDegraeve/helpdiabetes-android/7/pulls/JohanDegraeve/helpdiabetes-android/7,2017-06-16T20:58:01Z,False,309132523.0,Thanks ! I will test it.,True,False
ansible/ansible/23817/pulls/ansible/ansible/23817,2017-04-20T15:56:52Z,False,295790230.0,"cc @alcamie101
[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)
<!--- boilerplate: notify --->",True,False
ansible/ansible/23817/pulls/ansible/ansible/23817,2017-04-27T16:39:18Z,False,297770830.0,"Hi,
Thanks for this PR

A number of files have been git moved from `modules/network` to `modules/net_tools`, which has effected this PR.
Rather than making you rebase and go through review process as this is a simple change I've made it directly.

https://github.com/ansible/ansible/commit/6845234d72967801cc08caf72fcdbe8fc410c954",True,False
ansible/ansible/23817/pulls/ansible/ansible/23817,2017-04-29T16:23:46Z,False,298178722.0,"I get it, thank you.",True,False
NotWoods/color-breakdown/105/pulls/NotWoods/color-breakdown/105,2020-05-09T19:31:04Z,False,626224742.0,Superseded by #111.,True,False
TKTheTechie/TKTheTechie.github.io/1/pulls/TKTheTechie/TKTheTechie.github.io/1,2020-04-13T15:12:49Z,False,612941259.0,"Looks like rubyzip is up-to-date now, so this is no longer needed.",True,False
art3mis69/Recipe-Book-Management-System/21/pulls/art3mis69/Recipe-Book-Management-System/21,2020-10-21T23:23:09Z,False,713967225.0,Superseded by #24.,True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-11-27T03:35:15Z,False,160034770.0,"Updated rspec for payload validation
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-01T14:17:14Z,False,160981058.0,"It would be nice to have the source in `external/source/shellcode/` 
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-01T14:19:16Z,False,160981508.0,"Sure!   I'll pop it in now.
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-04T15:56:49Z,False,162003984.0,"Hey @jlee-r7 what's protocol for a sit like: if i notice the PR gets to be several commits behind is it good form to keep it updated with the latest commits?  Or leave it as it was when built.   
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-04T16:25:55Z,False,162011377.0,"@bigendiansmalls As long as there are no conflicts, it's better to leave it as is.
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-04T16:45:16Z,False,162016514.0,"Cheers. Thanks.
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-18T17:19:26Z,False,165845073.0,"Hey all!   Wondering if someone could take a peek at this PR and let me know if there's anything missing or if it could be landed?   Thank you!
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-23T20:14:14Z,False,166982940.0,"I removed the duplicate copy of the source, but this looked good. Thanks!
",True,False
rapid7/metasploit-framework/6292/pulls/rapid7/metasploit-framework/6292,2015-12-23T21:08:21Z,False,166990155.0,"@bcook-r7 thanks !!  
",True,False
lucassus/bookshelf/315/pulls/lucassus/bookshelf/315,2020-08-11T09:42:32Z,False,671844276.0,"# [Codecov](https://codecov.io/gh/lucassus/bookshelf/pull/315?src=pr&el=h1) Report
> Merging [#315](https://codecov.io/gh/lucassus/bookshelf/pull/315?src=pr&el=desc) into [master](https://codecov.io/gh/lucassus/bookshelf/commit/519b1e5f50c61b8cd10d6665776926465740ead3&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/lucassus/bookshelf/pull/315/graphs/tree.svg?width=650&height=150&src=pr&token=nrSSxqVQrn)](https://codecov.io/gh/lucassus/bookshelf/pull/315?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master     #315   +/-   ##
=======================================
  Coverage   96.27%   96.27%           
=======================================
  Files          55       55           
  Lines         537      537           
  Branches       86       86           
=======================================
  Hits          517      517           
  Misses         20       20           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/lucassus/bookshelf/pull/315?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/lucassus/bookshelf/pull/315?src=pr&el=footer). Last update [519b1e5...d2fdd34](https://codecov.io/gh/lucassus/bookshelf/pull/315?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
lucassus/bookshelf/315/pulls/lucassus/bookshelf/315,2020-08-12T09:05:25Z,False,672751543.0,Superseded by #321.,True,False
RedPRL/sml-redprl/681/pulls/RedPRL/sml-redprl/681,2018-04-25T19:50:06Z,False,384412361.0,My only complaint is that now it seems we have multiple files with the same materials. Maybe we should create a `demo` subfolder for these demos and date them?,True,False
RedPRL/sml-redprl/681/pulls/RedPRL/sml-redprl/681,2018-04-25T20:17:27Z,False,384420124.0,"@favonia The real problem is that many different files have the definition of weak connections, the definition of equivalences, ...

Ideally we would have some method of importing definitions so they wouldn't need to be replicated. I'm not against having a `demo` folder but I'd really just like to not have to copy-paste as much!",True,False
RedPRL/sml-redprl/681/pulls/RedPRL/sml-redprl/681,2018-04-25T19:52:20Z,False,184185905.0,"I don't like this indentation. `($...` should have its indentation not determined by the right end of `path`, but by the left end of that lexeme.",True,False
Blizzard/s2client-api/306/pulls/Blizzard/s2client-api/306,2019-10-28T22:24:58Z,False,547171655.0,Aren't * _ proto _ * files supposed to be auto-generated by gRPC,True,False
Blizzard/s2client-api/306/pulls/Blizzard/s2client-api/306,2019-11-03T09:34:35Z,False,549115713.0,"@minchopaskal you should be right
I was unsure if I have a correct tools and able to find a proper way to regenerate it from scratch. I have decided just to fix obvious error to play with api. And as we see at #316 there still are many issues which I miss.",True,False
s-m-i-t-a/flask_chip/142/pulls/s-m-i-t-a/flask_chip/142,2018-08-20T03:25:06Z,False,414187446.0,"
[![Coverage Status](https://coveralls.io/builds/18562829/badge)](https://coveralls.io/builds/18562829)

Coverage remained the same at 100.0% when pulling **ff2a4c23a5e907cfaffe514accf3aa214f0a850a on pyup-update-sphinx-1.6.6-to-1.7.7** into **b07575bccefe9052143ffe915839eb9395add099 on master**.
",True,False
s-m-i-t-a/flask_chip/142/pulls/s-m-i-t-a/flask_chip/142,2018-08-29T05:06:23Z,False,416825610.0,Closing this in favor of #148,True,False
panda-lang/hub/405/pulls/panda-lang/hub/405,2020-05-11T04:24:00Z,False,626461755.0,"# [Codecov](https://codecov.io/gh/panda-lang/reposilite/pull/405?src=pr&el=h1) Report
> Merging [#405](https://codecov.io/gh/panda-lang/reposilite/pull/405?src=pr&el=desc) into [master](https://codecov.io/gh/panda-lang/reposilite/commit/d3d89193d74728661bd5a159eeb74ed3aa0f3ebe&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/panda-lang/reposilite/pull/405/graphs/tree.svg?width=650&height=150&src=pr&token=LRrQwEFcUb)](https://codecov.io/gh/panda-lang/reposilite/pull/405?src=pr&el=tree)

```diff
@@          Coverage Diff           @@
##           master    #405   +/-   ##
======================================
  Coverage    0.00%   0.00%           
======================================
  Files         109     109           
  Lines        1474    1474           
  Branches      100     100           
======================================
  Misses       1474    1474           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/panda-lang/reposilite/pull/405?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/panda-lang/reposilite/pull/405?src=pr&el=footer). Last update [d3d8919...afe5fba](https://codecov.io/gh/panda-lang/reposilite/pull/405?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
panda-lang/hub/405/pulls/panda-lang/hub/405,2020-05-18T04:13:41Z,False,629935386.0,Superseded by #410.,True,False
danielpaul/writter/172/pulls/danielpaul/writter/172,2020-03-01T22:57:09Z,False,593158188.0,Superseded by #174.,True,False
Ff00ff/mammoth/108/pulls/Ff00ff/mammoth/108,2020-09-17T00:49:41Z,False,693741786.0,Superseded by #120.,True,False
idangozlan/verdaccio-bitbucket/38/pulls/idangozlan/verdaccio-bitbucket/38,2020-11-17T18:32:13Z,False,729119996.0,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",True,False
bradcypert/ffs/123/pulls/bradcypert/ffs/123,2020-05-07T14:07:31Z,False,625277615.0,Superseded by #124.,True,False
learn-co-students/html-fundamentals-html-lists-lab-nyc-web-071519/8/pulls/learn-co-students/html-fundamentals-html-lists-lab-nyc-web-071519/8,2020-07-28T08:10:50Z,False,664848260.0,Superseded by #9.,True,False
learn-co-students/html-fundamentals-html-lists-lab-dc-web-091619/6/pulls/learn-co-students/html-fundamentals-html-lists-lab-dc-web-091619/6,2020-07-28T08:09:16Z,False,664847518.0,Superseded by #7.,True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T05:08:43Z,False,492080611.0,"Hello @LadySmith and thank you for your contribution!
I've suggested and described a few changes, I'd be glad if you would be so kind as to commit them to your PR.
Thank you 😃",True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T10:05:22Z,False,492174097.0,Thanks for your hard work.,True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-15T16:53:57Z,False,492735734.0,"I played that game in the past, used Authy for that 😄 ",True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T04:53:49Z,False,283625449.0,"```suggestion
```",True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T04:53:53Z,False,283625459.0,"```suggestion
```",True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T04:54:37Z,False,283625553.0,When `tfa: Yes` social media links to tell them to add 2FA are no longer needed.,True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T04:54:53Z,False,283625601.0,"```suggestion
      doc: https://blackdesert.zendesk.com/hc/en-us/articles/360000535909
```",True,False
2factorauth/twofactorauth/3851/pulls/2factorauth/twofactorauth/3851,2019-05-14T04:55:34Z,False,283625675.0,Zendesk links don't need anything after the article's ID to work correctly.,True,False
apgsga-it/apg-gradle-plugins/20/pulls/apgsga-it/apg-gradle-plugins/20,2020-01-13T07:18:36Z,False,573536419.0,"@chhex , @apgsga-stb : this looks good to me, but I believe it would be good to plan a ""2h-code-walkthrough""  regarding the dependency-manager. I'm pretty sure that if we go through the code and/or usage scenario together (STB,CHE and JHE), more questions will come up. What do you think?

Very good question if we would need to be able to call the tasks explicitely during development. I'm pretty sure it would help in some situation, but not sure this needs to be done with a high prio (although probably be easier to do it right now than later ...).

Ahaha, no no, no problem if we want to re-write part of the common-repo, I'm more than open if it helps having less and more understandable code. But as you wrote, probably not the highest prio.",True,False
balderdashy/sails/4199/pulls/balderdashy/sails/4199,2017-10-02T19:13:14Z,False,333635287.0,"Thanks for posting, @Maelstrom96!  We'll look into this ASAP.

---

For help with questions about Sails, [click here](http://sailsjs.com/support). If you&rsquo;re interested in hiring @sailsbot and her minions in Austin, [click here](http://sailsjs.com/studio).",True,False
rcallen89/d_and_r_adopt/51/pulls/rcallen89/d_and_r_adopt/51,2020-03-04T21:16:50Z,False,594848831.0,Superseded by #52.,True,False
matteo-hertel/pullUpsChallenge/181/pulls/matteo-hertel/pullUpsChallenge/181,2020-07-31T06:35:58Z,False,666956253.0,Superseded by #185.,True,False
concordnow/ckeditor5-fontsize-converter/70/pulls/concordnow/ckeditor5-fontsize-converter/70,2020-08-04T04:33:50Z,False,668373743.0,Superseded by #75.,True,False
schorfES/caroucssel/65/pulls/schorfES/caroucssel/65,2020-08-17T05:13:32Z,False,674659637.0,Superseded by #67.,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T18:41:03Z,False,298398507.0,"Heads up! This PR modifies the following files:
 * @asajeffrey: components/constellation/lib.rs, components/constellation/Cargo.toml, components/constellation/constellation.rs
 * @kichjang: components/script/dom/vrdisplay.rs, components/script/dom/webglframebuffer.rs, components/script/dom/htmlcanvaselement.rs, components/script_traits/lib.rs, components/script_traits/lib.rs and 15 more
 * @fitzgen: components/script/dom/vrdisplay.rs, components/script/dom/webglframebuffer.rs, components/script/dom/htmlcanvaselement.rs, components/script_traits/lib.rs, components/script_traits/lib.rs and 15 more
 * @emilio: components/layout/display_list_builder.rs, components/script/dom/webglframebuffer.rs, components/canvas/webgl_paint_thread.rs, components/script/dom/webglrenderbuffer.rs, components/script/dom/webglprogram.rs and 5 more",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T18:41:04Z,False,298398518.0,"<img src=""http://www.joshmatthews.net/warning.svg"" alt=""warning"" height=20> **Warning** <img src=""http://www.joshmatthews.net/warning.svg"" alt=""warning"" height=20>

* These commits modify **unsafe code**. Please review it carefully!
* These commits modify layout and script code, but no tests are modified. Please consider adding a test!",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T18:51:38Z,False,298401132.0,@bors-servo: try,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T18:51:42Z,False,298401154.0,:hourglass: Trying commit 8b793607002e5110cc575859044a42f6d1bc9b79 with merge 2e644b382077a4328f80187eca72b29fa76a6504...,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T21:17:28Z,False,298435324.0,@MortimerGoro: :key: Insufficient privileges: and not in try users,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T21:17:48Z,False,298435395.0,@MortimerGoro: :key: Insufficient privileges: and not in try users,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T21:19:55Z,False,298435855.0,@jdm Could you run bors-servo try again? I pushed a minor change just after you ran it and the build stopped,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T22:09:34Z,False,298446104.0,@bors-servo try,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T22:09:38Z,False,298446114.0,:hourglass: Trying commit 7385420dfbc1475042d960cbebc1ae59d89c6e79 with merge f4dd3380fa20b1d9db25aa19229850e2efbbe55d...,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T22:12:31Z,False,298446675.0,"I believe, btw, that WebGLPaintThreads are supposed to live in the UI process. I'd need to double-check tomorrow, but seems to me that the layer of indirection we could theoretically remove is the WebGLPaintThread <=> WR.

But actually, the paint thread when WR is enabled is just a proxy, so we may be able to avoid creating a WebGLPaintThread entirely when using the WR back-end?",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-01T23:03:50Z,False,298455717.0,:broken_heart: Test failed - [linux-rel-wpt](http://build.servo.org/builders/linux-rel-wpt/builds/3786),True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-02T11:21:12Z,False,298608575.0,"`But actually, the paint thread when WR is enabled is just a proxy, so we may be able to avoid creating a WebGLPaintThread entirely when using the WR back-end?`

I thought about removing the WebGLPaintThread too. It seems possible to entirely avoid creating it when WR is enabled. I didn't remove yet because I thought that the thread  could help with the ipc-channel serialziation slowness (the slow serialization work is done in background instead of blocking JS). 
",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-03T21:29:45Z,False,299041299.0,"Ready for retry. Some tests failed because pixels were upside-down when a webglcanvas is used as source in texImage2D/texSubImage2D. Previously webgl-canvas textImage2D sources were not implemented and all pixels were 0,0,0,0",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-03T21:33:12Z,False,299042109.0,"As I said, I think this is conceptually wrong, and the channel we should be avoiding is the WebGLPaintThread <=> WR. @pcwalton can confirm if that's right, since he did the initial multi-process stuff, though.

@bors-servo try",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-03T21:41:55Z,False,299044078.0,:hourglass: Trying commit 9633cae884608cc0aa7173301c2fcbe4883570a7 with merge b595f0fc5637e2343d0f2802e4c62ab74b8d679b...,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-03T21:57:53Z,False,299047561.0,"> As I said, I think this is conceptually wrong, and the channel we should be avoiding is the WebGLPaintThread <=> WR. @pcwalton can confirm if that's right, since he did the initial multi-process stuff, though.

I'd love to get rid of WebGLPaintThread. As I said with this PR the WebGLPaintThread is really only used as a ""helper"" thread to avoid blocking JS thread with serialization work. I measured the JS raf time in some Three.js demo and it has some impact. If there is a way to improve this I don't mind rewriting the code to remove WebGLPaintThread, for example:

- I saw that bincode-based IPC landed in webrender, can this help?
- Batching WebGL calls and serialize/send some of them at once may help

",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-04T08:29:18Z,False,299125359.0,:boom: Test timed out,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-04T13:27:43Z,False,299184621.0,@bors-servo: try,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-11T07:23:20Z,False,300705151.0,"@bors-servo try
",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-11T12:52:02Z,False,300779413.0,@bors-servo: retry,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-11T12:52:07Z,False,300779431.0,:hourglass: Trying commit 9633cae884608cc0aa7173301c2fcbe4883570a7 with merge bc79baa77586eaf43ad2d715d02a7ab0bf2ef874...,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-11T12:57:25Z,False,300780834.0,:broken_heart: Test failed - [linux-dev](http://build.servo.org/builders/linux-dev/builds/7201),True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-12T21:45:42Z,False,301193435.0,"```
Compiling parking_lot_core v0.2.1
LLVM ERROR: Invalid data was encountered while parsing the file
error: Could not compile `parking_lot_core`.
Build failed, waiting for other jobs to finish...
error: build failed
```",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-12T23:21:21Z,False,301206791.0,@bors-servo: retry,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-12T23:21:25Z,False,301206800.0,:hourglass: Trying commit 9633cae884608cc0aa7173301c2fcbe4883570a7 with merge 55ba4afa2e4130d7f65ab3d951e29c47cfd26c8c...,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-12T23:52:09Z,False,301209864.0,:broken_heart: Test failed - [linux-rel-wpt](http://build.servo.org/builders/linux-rel-wpt/builds/3996),True,False
servo/servo/16679/pulls/servo/servo/16679,2017-05-19T07:16:46Z,False,302628261.0,:umbrella: The latest upstream changes (presumably #16893) made this pull request unmergeable. Please resolve the merge conflicts.,True,False
servo/servo/16679/pulls/servo/servo/16679,2017-08-15T21:27:02Z,False,322594661.0,"@MortimerGoro Is this separate from #17891, or is this work replaced by that PR?",True,False
servo/servo/16679/pulls/servo/servo/16679,2017-08-15T21:29:44Z,False,322595260.0,"@jdm yes, totally replaced. This can be closed.",True,False
eclipse/omr/310/pulls/eclipse/omr/310,2016-10-04T19:05:08Z,False,251482204.0,"@0xdaryl Updated.
",True,False
google/blockly-ios/432/pulls/google/blockly-ios/432,2017-07-24T23:45:00Z,False,317586782.0,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.
In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.

<!-- need_author_cla -->",True,False
google/blockly-ios/432/pulls/google/blockly-ios/432,2017-07-24T23:54:33Z,False,317588143.0,Please try again Mr. Roboto.,True,False
LeonidEfremov/aspnet.webapi.server/163/pulls/LeonidEfremov/aspnet.webapi.server/163,2020-11-16T02:14:06Z,False,727692083.0,Superseded by #165.,True,False
elo7/cookie-amd/37/pulls/elo7/cookie-amd/37,2020-10-19T23:30:56Z,False,712497304.0,Superseded by #39.,True,False
sociomantic-tsunami/mxnet/33/pulls/sociomantic-tsunami/mxnet/33,2018-07-04T14:13:00Z,False,402491204.0,".... whoops, didn't mean to click the rebase button then!  @leandro-lucarella-sociomantic does it LGTY, anyway? :-P",True,False
hugomrdias/rabin-wasm/94/pulls/hugomrdias/rabin-wasm/94,2020-12-09T07:35:48Z,False,741592363.0,Superseded by #97.,True,False
125m125/rollup-plugin-spl/32/pulls/125m125/rollup-plugin-spl/32,2018-07-09T07:49:26Z,False,403390800.0,Superseded by #34.,True,False
DefinitelyTyped/DefinitelyTyped/8932/pulls/DefinitelyTyped/DefinitelyTyped/8932,2016-04-10T21:35:05Z,False,208077506.0,"_qrcode-generator/qrcode-generator.d.ts_

Checklist
- [X] is correct [naming convention](http://definitelytyped.org/guides/contributing.html#naming-the-file)?
  - https://www.npmjs.com/package/qrcode-generator - https://github.com/kazuhikoarase/qrcode-generator
- [X] has a [test file](http://definitelytyped.org/guides/contributing.html#tests)? (qrcode-generator/qrcode-generator-tests.ts or qrcode-generator/qrcode-generator-tests.tsx)
- [x] pass the Travis CI test?
",True,False
DefinitelyTyped/DefinitelyTyped/8932/pulls/DefinitelyTyped/DefinitelyTyped/8932,2016-05-22T11:28:58Z,False,220827462.0,"Receiving this error, what am I doing wrong? followed the documentation exactly.

Unable to find ""qrcode-generator"" (""npm"") in the registry. Did you want to try searching another source? Also, if you want contribute these typings, please help us: https://github.com/typings/registry
typings ERR! caused by https://api.typings.org/entries/npm/qrcode-generator/versions/latest responded with 404, expected it to equal 200
",True,False
mayankv03/open-event-server/5/pulls/mayankv03/open-event-server/5,2020-07-31T07:38:28Z,False,666981917.0,Superseded by #10.,True,False
philwareham/textpattern-hive-admin-theme/388/pulls/philwareham/textpattern-hive-admin-theme/388,2020-08-07T07:10:17Z,False,670366816.0,"Looks like bootstrap is no longer updatable, so this is no longer needed.",True,False
zalando/riptide/615/pulls/zalando/riptide/615,2019-03-06T18:09:19Z,False,470214091.0,:+1:,True,False
cclauss/pythonista-module-versions/190/pulls/cclauss/pythonista-module-versions/190,2019-03-01T03:52:50Z,False,468532988.0,Closing this in favor of #246,True,False
verginer/disamby/206/pulls/verginer/disamby/206,2019-02-25T20:53:28Z,False,467178626.0,Closing this in favor of #209,True,False
Homebrew/homebrew-core/26538/pulls/Homebrew/homebrew-core/26538,2018-04-22T05:56:18Z,False,383357657.0,"Looks like after this change, Travis builds using `portmidi` are failing. Do you know why?
```
==> Pouring python@2-2.7.14_3.el_capitan.bottle.1.tar.gz
Error: The `brew link` step did not complete successfully
The formula built, but is not symlinked into /usr/local
Could not symlink bin/2to3-2
Target /usr/local/bin/2to3-2
is a symlink belonging to python. You can unlink it:
  brew unlink python
To force the link and overwrite all conflicting files:
  brew link --overwrite python@2
To list all files that would be deleted:
  brew link --overwrite --dry-run python@2
Possible conflicting files are:
/usr/local/bin/2to3-2 -> /usr/local/Cellar/python/2.7.12_1/bin/2to3-2
/usr/local/bin/2to3-2.7 -> /usr/local/Cellar/python/2.7.12_1/bin/2to3-2.7
/usr/local/bin/idle -> /usr/local/Cellar/python/2.7.12_1/bin/idle
/usr/local/bin/idle2 -> /usr/local/Cellar/python/2.7.12_1/bin/idle2
/usr/local/bin/idle2.7 -> /usr/local/Cellar/python/2.7.12_1/bin/idle2.7
/usr/local/bin/pydoc -> /usr/local/Cellar/python/2.7.12_1/bin/pydoc
/usr/local/bin/pydoc2 -> /usr/local/Cellar/python/2.7.12_1/bin/pydoc2
/usr/local/bin/pydoc2.7 -> /usr/local/Cellar/python/2.7.12_1/bin/pydoc2.7
/usr/local/bin/python -> /usr/local/Cellar/python/2.7.12_1/bin/python
/usr/local/bin/python-config -> /usr/local/Cellar/python/2.7.12_1/bin/python-config
/usr/local/bin/python2 -> /usr/local/Cellar/python/2.7.12_1/bin/python2
/usr/local/bin/python2-config -> /usr/local/Cellar/python/2.7.12_1/bin/
...
```
https://travis-ci.org/mixxxdj/mixxx/jobs/369669878",True,False
Homebrew/homebrew-core/26538/pulls/Homebrew/homebrew-core/26538,2018-04-22T05:57:45Z,False,383357726.0,See https://github.com/Homebrew/homebrew-core/issues/26358,True,False
Homebrew/homebrew-core/26538/pulls/Homebrew/homebrew-core/26538,2018-04-22T06:11:16Z,False,383358249.0,"Ah, thanks.",True,False
Homebrew/homebrew-core/9064/pulls/Homebrew/homebrew-core/9064,2017-01-20T06:45:11Z,False,273990180.0,Next time please make sure that the commit message is `orientdb <version>`.,True,False
Homebrew/homebrew-core/9064/pulls/Homebrew/homebrew-core/9064,2017-01-20T06:45:31Z,False,273990220.0,"You are awesome, thanks for your contribution! :tada:",True,False
Homebrew/homebrew-core/9064/pulls/Homebrew/homebrew-core/9064,2017-01-20T07:34:26Z,False,273996750.0,Thank you very much. I'll pay more attention to the commit message next time. ,True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-01-20T15:39:01Z,False,359179909.0,hmm looks like that some ipv6 adresses more invalid on windows  then on linux.,True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-01-22T21:00:17Z,False,359562886.0,Sorry it took me a few days to reply. This looks good! I'll have a deeper look later today or tomorrow and I'll probably merge it.,True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-15T01:56:42Z,False,373234464.0,"Ugh sorry it took me so long to get back at this. I initially implemented `operator<` so we could store these addresses inside `std::map/set` and `operator==`/`operator!=` so you could... well, check for equality or inequality which is a thing you often do. In this case if we're adding `operator>`, I think it makes sense to implement `operator<=` and `operator>=` so address types are fully comparable. These should just be implemented in terms of the other operators (e.g. `operator<=` is implemented in terms of `operator>`).

Can you add those ones? It should be a one liner for all of them.",True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-16T19:13:42Z,False,373816996.0,"ok, add these operators fo hw, ip and ip6 address",True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-17T22:22:15Z,False,373957193.0,I'm curious why some operators are implemented as friends while the same operator in a different class is just a regular operator?,True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-19T17:13:45Z,False,374292320.0,"??? sry im not sure what you mean with implemented as friends? if i see correctly all operators, which i added are public and did not use the friend ""visiblity"". may you can give an example please?",True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-19T17:18:18Z,False,374293927.0,"Sure, for example [IPv6Address::operator~](https://github.com/mfontanini/libtins/pull/275/files#diff-0ec71187163267465611a08c2c1d5172R264) is a free funcion. It's defined inside `IPv6Address` but since it's defined with friend visibility it's actually a free function (defined [here](https://github.com/mfontanini/libtins/pull/275/files#diff-3099c779cbc020e76bff2090159af21eR163)).

Then the same member but for [HWAddress::operator~](https://github.com/mfontanini/libtins/pull/275/files#diff-e29a34dd12279716ff1dde7f94c6958aR339) that's actually a member function. Is there any reason why they're not both defined in the same way?",True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-19T17:32:51Z,False,374299070.0,"dam yes,  i think i just copied  & paste the friend signature from "" TINS_API friend std::ostream& operator<<(std::ostream& os, const IPv6Address& addr);"" and forget to remove the friend keyword
:man_facepalming: . ill fix it later",True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-28T12:32:12Z,False,376869739.0,was the refactoring of the operator so ok?,True,False
mfontanini/libtins/275/pulls/mfontanini/libtins/275,2018-03-29T03:44:37Z,False,377111919.0,"Yep, looks good! Thanks for the PR!",True,False
younggunsclub/youngguns.club/175/pulls/younggunsclub/youngguns.club/175,2020-12-10T18:50:30Z,False,742721616.0,"This pull request is being automatically deployed with Vercel ([learn more](https://vercel.link/github-learn-more)).  
To see the status of your deployment, click below or on the icon next to each commit.

🔍 Inspect: [https://vercel.com/youngguns/website/8lh2sgi7l](https://vercel.com/youngguns/website/8lh2sgi7l)  
✅ Preview: [https://website-git-dependabot-npmandyarnyounggunsclubini-137.youngguns1.vercel.app](https://website-git-dependabot-npmandyarnyounggunsclubini-137.youngguns1.vercel.app)

",True,False
anhcraft/ENC/12/pulls/anhcraft/ENC/12,2019-07-30T22:20:11Z,False,516617777.0,Superseded by #17.,True,False
iterate-ch/cyberduck/38/pulls/iterate-ch/cyberduck/38,2019-05-24T09:12:49Z,False,495535589.0,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",True,False
angular/angular/30807/pulls/angular/angular/30807,2019-06-02T13:23:35Z,False,498030938.0,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fangular%2Fangular%2Fpull%2F30807) for more info**.

<!-- need_sender_cla -->",True,False
angular/angular/30807/pulls/angular/angular/30807,2019-06-02T13:29:55Z,False,498031519.0,@googlebot CLA signed.,True,False
angular/angular/30807/pulls/angular/angular/30807,2019-06-02T13:30:07Z,False,498031533.0,"CLAs look good, thanks!

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fangular%2Fangular%2Fpull%2F30807) for more info**.

<!-- ok -->",True,False
angular/angular/30807/pulls/angular/angular/30807,2019-06-03T13:54:12Z,False,498266458.0,"This may have been due to an old cached version, as it redirects correctly now.",True,False
angular/angular/30807/pulls/angular/angular/30807,2019-06-03T15:30:04Z,False,498306175.0,"Thanks for fixing guideline-related issues, @brandonroberts :)",True,False
angular/angular/30807/pulls/angular/angular/30807,2019-09-15T03:53:11Z,False,531532252.0,"This issue has been automatically locked due to inactivity.
Please file a new issue if you are encountering a similar or related problem.

Read more about our [automatic conversation locking policy](https://github.com/angular/angular/blob/67d80f/docs/GITHUB_PROCESS.md#conversation-locking).

<sub>_This action has been performed automatically by a bot._</sub>",True,False
JuliaRegistries/General/24172/pulls/JuliaRegistries/General/24172,2020-11-04T22:04:31Z,False,721999769.0,"Your `new version` pull request met all of the guidelines for auto-merging and is scheduled to be merged in the next round.

---
If you want to prevent this pull request from being auto-merged, simply leave a comment. If you want to post a comment without blocking auto-merging, you must include the text `[noblock]` in your comment.
<!-- [noblock] -->
<!---
this_is_the_single_automerge_comment
--->",True,False
AMReX-Astro/MAESTROeX/59/pulls/AMReX-Astro/MAESTROeX/59,2019-04-30T20:03:26Z,False,488095004.0,Is there a good test problem for this?  I'm trying this using 2d reacting bubble rise and am getting strange results.  The weights are constant (value of 8) everywhere except in one grid where the weights are enormous (2e9) in a region nowhere close to the burning.,True,False
AMReX-Astro/MAESTROeX/59/pulls/AMReX-Astro/MAESTROeX/59,2019-04-30T20:19:57Z,False,488100258.0,I wrote it to try and help `rotating_star` because the reactions were taking up 98% of the total runtime. I haven't yet done any testing of it other than checking that it didn't cause significant slowdown and that it produced the same output.,True,False
AMReX-Astro/MAESTROeX/59/pulls/AMReX-Astro/MAESTROeX/59,2019-04-30T20:21:59Z,False,488100910.0,"Did it produce any speedup?  One thing I checked was to write out state_in_temp in Maestro::React using VisMF::Write to see what the new boxarray looked like.  In my test the boxarray was the same, but reacting_bubble is probably not the right problem to test it on.",True,False
AMReX-Astro/MAESTROeX/59/pulls/AMReX-Astro/MAESTROeX/59,2019-04-30T20:25:09Z,False,488101863.0,"I've only tested its performance on my local machine with 20 MPI processes and it seemed to give a small speedup, but I haven't tested its performance on any large scale runs so it's hard to tell. I was planning on doing that when they started looking like they were burning properly (which will hopefully be soon now I've fixed the cutoff densities). ",True,False
CasperNaudts/I-Talent-portfolio/177/pulls/CasperNaudts/I-Talent-portfolio/177,2020-08-14T05:06:39Z,False,673885829.0,Superseded by #179.,True,False
wardDes/electron-quick-start/1/pulls/wardDes/electron-quick-start/1,2021-01-28T20:30:22Z,False,769366582.0,Superseded by #4.,True,False
joojaeyoon/YouTube-Music-Player/1/pulls/joojaeyoon/YouTube-Music-Player/1,2021-01-28T20:39:10Z,False,769373308.0,Superseded by #4.,True,False
timdorr/tesla-trip/25/pulls/timdorr/tesla-trip/25,2019-05-27T02:16:21Z,False,496055781.0,@dependabot rebase,True,False
Talend/data-prep/416/pulls/Talend/data-prep/416,2017-01-11T09:36:17Z,False,271821654.0,Pull request test result: [failure](https://ci-tdp.datapwn.com/job/tdp_pull-request_master/241/) [:x:](https://ci-tdp.datapwn.com/job/tdp_pull-request_master/241/) ,True,False
Talend/data-prep/416/pulls/Talend/data-prep/416,2017-01-11T09:57:54Z,False,271826393.0,Pull request test result: [failure](https://ci-tdp.datapwn.com/job/tdp_pull-request_master/243/) [:x:](https://ci-tdp.datapwn.com/job/tdp_pull-request_master/243/) ,True,False
drud/ddev/1124/pulls/drud/ddev/1124,2018-09-24T14:08:03Z,False,423987384.0,Adding `webimage: drud/ddev-webserver:20180922_apache_https` to my config.yaml solved the problem for me. Thank you!,True,False
drud/ddev/1124/pulls/drud/ddev/1124,2018-09-25T07:11:32Z,False,424231836.0,Testing it with `webimage: drud/ddev-webserver:20180922_apache_https` and clean Typo3 `v9.4` all works fine ;),True,False
drud/ddev/1124/pulls/drud/ddev/1124,2018-09-25T21:04:27Z,False,424501026.0,It's worth considering adding a test for this one. ,True,False
RadarCOVID/radar-covid-ios/30/pulls/RadarCOVID/radar-covid-ios/30,2020-11-06T13:08:59Z,False,723072138.0,"Thanks, but it is a big change that can have unexpected consequences, we are also using swagger to generate swift api calls so we cannot change this write now.",True,False
RadarCOVID/radar-covid-ios/30/pulls/RadarCOVID/radar-covid-ios/30,2020-11-06T13:12:05Z,False,723073485.0,Okay. The intention was to contribute to making the first open source project in our country as clean as possible. Maybe next time. Thanks anyway.,True,False
escaladesports/react-twitter-share-link/3/pulls/escaladesports/react-twitter-share-link/3,2018-07-26T14:55:21Z,False,408125483.0,"Awesome work, thanks for the help!",True,False
escaladesports/react-twitter-share-link/3/pulls/escaladesports/react-twitter-share-link/3,2018-07-28T09:05:01Z,False,408593937.0,Yeah no problem! 👍 ,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T20:15:46Z,False,432402437.0,The header won't be showed on the store/home? I thought that there would be an simpler mode instead,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T20:26:42Z,False,432406296.0,"> The header won't be showed on the store/home? I thought that there would be an simpler mode instead

That's what we were instructed to do at least for now, @brunojdo can confirm
",True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-24T13:36:29Z,False,432658697.0,Workspace is broken,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-24T14:00:53Z,False,432669392.0,"@luciannojunior What's broken? I just did the full test with Incognito mode on both Chrome and Safari, noticed no issues.",True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-24T15:04:39Z,False,432697089.0,"@hapoza just worked out ok. Might have been infrastructure malfunction
",True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T19:34:53Z,False,227534567.0,This route is already defined in `vtex.store`,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T19:37:29Z,False,227535335.0,"Add this comment, please. 

`/** TODO - This is a theme app, we shouldn't have React components on this type of app. Redesign this solution after MVP. */ `",True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T19:40:58Z,False,227536398.0,`loading && return`,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T19:42:01Z,False,227536731.0,`!canUseDOM && return`,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T19:56:40Z,False,227541248.0,"It causes bugs if it's not declared here. Before I didn't have that, and it caused the home page to render blank when it was redirected to (with `runtime.navigate`), because the `__children__` prop for the LayoutContainer was undefined. This is the only solution that solved the problem.",True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T20:00:18Z,False,227542462.0,This causes the linter to throw `Expression expected`,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T20:00:34Z,False,227542556.0,Same as above,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T20:12:10Z,False,227546158.0,Use brackets,True,False
vtex-apps/delivery-dreamstore/1/pulls/vtex-apps/delivery-dreamstore/1,2018-10-23T20:12:43Z,False,227546335.0,Returning children throws an error? `children || null` if so ,True,False
jbrid867/simple/49/pulls/jbrid867/simple/49,2019-03-28T21:22:31Z,False,477776062.0,Closing this in favor of #54,True,False
everypolitician/everypolitician-data/35587/pulls/everypolitician/everypolitician-data/35587,2017-05-16T12:49:07Z,False,301771583.0,"

Summary of changes in `data/Spain/Congress/ep-popolo-v1.0.json`:

## People

### Added


No people added


### Removed


No people removed


### Name Changes


No name changes


### Additional Name Changes


No name changes


### Wikidata Changes


No changes


## Organizations

### Added


No organizations added


### Removed


No organizations removed


## Memberships

### Added

No memberships added


### Removed

No memberships removed
















",True,False
everypolitician/everypolitician-data/35587/pulls/everypolitician/everypolitician-data/35587,2017-05-17T08:35:23Z,False,302023818.0,This Pull Request has been superseded by #35682,True,False
AgileVentures/LocalSupport/1224/pulls/AgileVentures/LocalSupport/1224,2019-12-24T07:24:46Z,False,568679613.0,"Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting `@dependabot rebase`.",True,False
ernestman/Dripcamp/18/pulls/ernestman/Dripcamp/18,2021-03-09T17:18:39Z,False,794186872.0,Superseded by #21.,True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-11T15:11:14Z,False,208394020.0,"Looks good to me - I would point out though, for completion, that it's possible that non-FLIM files from Ver 5.0 might work fine. I simply don't know.
",True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-11T15:38:07Z,False,208406369.0,"@imunro: fair enough. This is certainly a statement we could extend to most formats. Does it come down to defining more precisely the meaning of ""Officially Supported Versions""? /cc @hflynn
",True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-11T15:44:21Z,False,208409383.0,"We don't define unsupported anywhere, I would stick with listing only those we _know_ work.

To my mind, supported = we test this format and will commit to fixing bugs reported for it
",True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-12T13:15:36Z,False,208899746.0,"I wasn't suggesting a change to the PR just wanted to make sure it was clear how much we don't know. Looks good to merge to me.
",True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-12T13:16:24Z,False,208900136.0,"Looks fine on staging btw, good to merge from my pov too
",True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-12T13:23:20Z,False,208902245.0,"--rebased-to #2339
",True,False
openmicroscopy/bioformats/2337/pulls/openmicroscopy/bioformats/2337,2016-04-12T13:24:28Z,False,208902828.0,"--rebased-to #2340
",True,False
greenelab/tybalt/72/pulls/greenelab/tybalt/72,2017-10-03T14:43:22Z,False,333864458.0,thanks @jaclyn-taroni - I removed the hardcoding step in e3ec374 and can confirm the output figures do not change. Ready for review!,True,False
greenelab/tybalt/72/pulls/greenelab/tybalt/72,2017-10-03T12:41:34Z,False,142388573.0,"You might consider not hard-coding the filters -- can you identify the ""best"" models in this script somewhere and use that to filter?",True,False
greenelab/tybalt/72/pulls/greenelab/tybalt/72,2017-10-03T12:41:49Z,False,142388617.0,Same comment as `best_one_layer`,True,False
HarmonyIO/Cache/21/pulls/HarmonyIO/Cache/21,2019-03-27T06:03:15Z,False,476990729.0,Superseded by #24.,True,False
everypolitician/everypolitician-data/29693/pulls/everypolitician/everypolitician-data/29693,2017-03-26T06:02:05Z,False,289260706.0,"

Summary of changes in `data/Vietnam/National_Assembly/ep-popolo-v1.0.json`:

## People

### Added


No people added


### Removed


No people removed


### Name Changes


No name changes


### Additional Name Changes


No name changes


### Wikidata Changes



- `03602a9e-b97d-4032-8e0b-9542078dc5a1`: Q10770602 → none

- `109a9a0b-68ca-45fe-8e6e-42fd34f779ea`: Q10769902 → none

- `13915b9b-876b-4c9d-a354-3e464fe3e039`: Q10769909 → none

- `4da0da97-d47f-4e66-802d-0021d6d339ba`: Q10770547 → none

- `4e453fb3-c597-49db-9a70-074a54daa2c6`: Q10757632 → none

- `5a8a16e1-4b14-4619-a0b5-132046cc1d71`: Q10769042 → none

- `7b23f27d-d820-449c-95d5-5ff09f204abc`: Q10769910 → none

- `7c6cf466-fc43-4061-895c-d621a014ad06`: Q16157297 → none

- `9334869b-bc95-4419-ae91-648d5064a7f3`: Q10772051 → none

- `a7049d24-eee7-40eb-9acc-a5d71e74fefb`: Q10769161 → none

- `fcbbfcf9-9225-4caa-8d58-55f1491c1c99`: Q10769963 → none



## Organizations

### Added


No organizations added


### Removed


No organizations removed


## Memberships

### Added


#### term/13

- Nguyễn Ngọc Bảo 




### Removed


#### term/13

- Nguyễn Ngọc Bảo 


















",True,False
everypolitician/everypolitician-data/29693/pulls/everypolitician/everypolitician-data/29693,2017-03-27T12:26:39Z,False,289438314.0,This Pull Request has been superseded by #29955,True,False
binxhealth/force-vue-awakens/162/pulls/binxhealth/force-vue-awakens/162,2019-06-11T12:25:54Z,False,500818160.0,Superseded by #164.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-22T12:06:24Z,False,346331637.0,"Everyone please feel free to directly push documentation commits to my branch.
If you want to avoid work duplication simply edit the head post to add a `*` to options you're working on, I will also do that.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-22T12:23:44Z,False,346335322.0,Note that #6164 is included in this issue.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-22T13:07:07Z,False,346344934.0,"Thanks @SkySkimmer, great initiative!

> several of these options are deprecated with a comment remove in 8.8 or the like. Is it worth documenting them? I guess yes if only to backport in 8.7.

I would prefer that documentation of these deprecated options be rather done in a separate 8.7-only PR so as to not interfere with PRs removing such options, like #6169.

> several of these options are debug options. Is it worth documenting them?

Yes, I guess. At least in the developer's documentation.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-24T21:28:22Z,False,346897806.0,"`Omega Oldstyle` controls a `bool ref` which has been around since 44d578b40ec699ea8bbd4b387c2cf7155bf1d1fe (omega into CVS, 2000).
I have no idea what it does.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-24T22:47:13Z,False,346903672.0,"I can't find any documentation for unification and unification constraints, so I don't know where `Solve Unification Constraints` would go.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T00:56:08Z,False,346910201.0,"I may write up a couple of the ones that I understand.  Also, cc @tchajed",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T12:12:43Z,False,346936924.0,"> ""intentionally undocumented"" is pretty suspicious TBH.
> For instance:
> - `Proof Using Clear Unused` which has commented-out doc in the .tex

See #883 for a pending discussion related to this option.

> - `Default Clearing Used Hypotheses` introduced by @herbelin 262e3151ce483aaab3b4f60e3d1dbdf875ea05ae (2014)
> That commit also introduced a syntax like `destruct !x` which doesn't seem to exist any more. Is this just a forgotten option? It still works though.

The syntax `destruct !x` has been replaced by `destruct (x)` on a suggestion from @silene as part of an attempt to harmonize the syntax of ssreflect and vanilla coq.

The syntaxes `apply >H`, `rewrite >H`, `elim >H`, etc. exist but are undocumented (they remove the hypothesis on the fly). I think that there are useful and should be documented. My idea was that the option `Default Clearing Used Hypotheses` becomes at some time the default behavior, so that, by default, `apply` and `rewrite` clear the hypothesis they use, based on the experience that it is more common to use an hypothesis once than strictly more than once.

I let this pending because of the tensions with ssreflect developers (see e.g the` %pat` story, and the various not-always-very-fair criticisms at this time). At some time, I thought the only way to get out of the tensions was to bring ssreflect developers at a table to work at a consensual project about tactics. I would like to be shown wrong but I tend to lose hope that this is going to happen. So I would vote so that vanilla coq continues to evolve on its own, and, when the versioning of tactics is operational, that the option `Default Clearing Used Hypotheses` is documented and (a priori) better set on by default. It is certainly not a fundamental change but still a convenient one.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-30T09:34:56Z,False,348132891.0,"I'm cancelling the Travis build to reduce the backlog, as I think this needs more work (and discussion maybe). I hope it's ok.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-04T17:09:33Z,False,349030882.0,"Similarly to @ppedrot remark, note that documenting `Set Keyed Unification` would fix #4551.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-08T15:10:51Z,False,350286709.0,"@SkySkimmer WDYT of merging this as-is to allow shipping this additional documentation in 8.7.1 and creating a new issue to track the reminding missing option documentation?
As for the two no-op option removals and the renaming of a third option to match the documentation, I have an uneasy feeling about including this in a patch-level release. Would you mind adding some deprecation warnings instead of removing them completely and submitting another PR for their definite removal? (Especially in the case of the renaming.)",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-08T15:38:38Z,False,350293714.0,Done.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T08:29:05Z,False,350654296.0,I would like that we discuss a bit if we don't want to remove some of these options instead of documenting them.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T13:36:40Z,False,350725962.0,"@maximedenes I'm unclear about your approach. Removing an option generally has to go through a phase of deprecation. That's orthogonal to the question of documentation. In fact, I'm very suspicious about the general tradition in the Coq Development Team of not documenting because we are not sure it will stay. When that's the case, just document as ""experimental, could be removed without a warning"". Similarly, I don't see what good can come out of blocking a documentation PR.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T13:45:00Z,False,350727966.0,"I agree that introducing undocumented options is suspicious and should be avoided. . But on the other hand, documenting existing options that were not is clearly a signal that they can be used. So I'd like to have a bit of time, at least to calmly go through the list. I'm very busy these days, sorry for the delay.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T13:54:01Z,False,350730216.0,"@maximedenes I'm not expecting you to get less busy in the coming days and the release of the 8.7.1 is planned on Dec 15th. It would be a shame that this PR misses this for dubious reasons. Thus I'd like to find reviewers to go through the list of options and give their opinion, and if we can find such reviewers, I would like you to trust them.
Who could be available to do such a review? @herbelin @ppedrot @silene? It could also be a user: @JasonGross @amahboubi? Any other suggestion?",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T17:51:20Z,False,350802778.0,"@maximedenes I think if an option is accepted by Coq, it should be documented; it's ok to merge (accurate) documentation even if the option is soon removed, though the documentation should probably call out the option as being unstable/subject to removal.

If I understood correctly you're saying documenting an option blesses it as being acceptable to use. This is a scary idea to me: if I'm able to use an option, I consider it part of Coq and am frustrated when compatibility breaks. When I see an undocumented option, I consider it a documentation bug. If there are private, internal options, at the very least they should be documented as being internal, and ideally their use would be discouraged by Coq itself (by issuing a warning or requiring a flag to enable them).",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T08:53:17Z,False,351647311.0,@SkySkimmer WDYT should be done with this? Address the comments and force Maxime's hand? Or postpone? I'm personally favorable to the first option.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T09:05:52Z,False,351650302.0,"I reviewed the commands that are being documented, it looks ok.

Please merge only the documentation part in 8.7.1, though (no deprecation, no renaming, no creation of new options).",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T11:25:47Z,False,351684455.0,"> Please merge only the documentation part in 8.7.1, though (no deprecation, no renaming, no creation of new options).

In that case, the PR needs to be updated before being merged. (And sorry @SkySkimmer for the work done twice.)",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T11:49:57Z,False,351689480.0,"I removed the renamings and fixed the optindex instead (it turns out that the documentation was accurate except for the index).
I moved the deprecations to make them the last commits, it should be trivial to avoid backporting them. Considering they're dead code options I would still deprecate them though.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T13:08:26Z,False,351706093.0,"@maximedenes I agree with @SkySkimmer: I would usually refuse to backport deprecation notices in v8.7 (after the 8.7.0 release) but given that they are dead code options, I think it makes sense to remove them in master and thus to deprecate them in v8.7.
So this looks ready to be merged.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T16:43:28Z,False,351766650.0,"> @maximedenes I agree with @SkySkimmer: I would usually refuse to backport deprecation notices in v8.7 (after the 8.7.0 release) but given that they are dead code options, I think it makes sense to remove them in master and thus to deprecate them in v8.7.

Ok, I trust your judgement.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T16:52:06Z,False,351769322.0,@SkySkimmer I think your Travis indicates a compilation error. Can you check?,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T17:57:30Z,False,351788206.0,"Typo introduced syntax error
Fixed now",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T19:27:12Z,False,351811205.0,"Being built here: https://travis-ci.org/SkySkimmer/coq/builds/316557209
I suppose the error on Equations is just due to not being based on the latest version of master. Given the scope of the PR, it can be safely ignored, and the same should be true for the upcoming likely Ltac2 failure.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-15T10:06:36Z,False,351965885.0,"There are lots of failures which all look spurious, we have at least a few successful test-suite runs and documentation builds.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-24T21:10:49Z,False,153026668.0,"This seems like a corner case where async might do the wrong thing.
OTOH I think it's disabled for Admitted.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T00:46:41Z,False,153034886.0,"Is it on or off by default, and would that be useful to mention?",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T00:47:52Z,False,153034904.0,`derrivative` -> `derivative`,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T00:54:41Z,False,153035003.0,"Really?  I thought it's always ""typeclass resolution"" (to refer to the resolution used by all typeclasses), in the same way that one might say ""gamer culture"" to refer to the culture of all gamers.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T00:54:56Z,False,153035008.0,As above,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T09:38:45Z,False,153042002.0,"Off, and may as well.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-11-25T09:42:03Z,False,153042059.0,"I made it match the already existing documentation and the other typeclass options.
It's a component prefix, like `Typeclasses.resolution_for_conversion`.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T17:35:12Z,False,156143855.0,"""removes parameters to constructors in patterns"" would be more clear to me, with less need for all the preceding context",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T17:36:29Z,False,156144128.0,"I think you can just remove ""iterated""",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T17:42:43Z,False,156145684.0,I'm not sure why this is in a documentation PR - shouldn't deprecating options be separate from documenting them?,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T17:43:11Z,False,156145805.0,Same here - deprecation should be separate from documentation as far as I'm concerned.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T17:44:04Z,False,156146065.0,"First of all, not sure why we're adding an option here.
Second, it should be called ""Typeclass Resolution After Apply"".",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T18:35:01Z,False,156159670.0,"In fact, the option is added for compatibility (it already existed as such but was documented as ""Typeclass Resolution After Apply"".",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T23:55:20Z,False,156236690.0,"Wording nit: ""generalized over all"" instead of ""generalized by all""",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T23:57:08Z,False,156236997.0,Non-blocking: Might be nice to say what `RAKAM` stands for (r... a... k... abstract machine?),True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-11T23:58:16Z,False,156237177.0,"What's the difference between `\Rem` and `\noindent {\bf Remark: } `, and why choose one over the other?",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-12T00:02:34Z,False,156237847.0,"I think the other one (`Typeclasses Resolution`) should be deprecated, and the documentation should be updated.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-12T08:30:26Z,False,156297273.0,I guess @pirbo has the answer. Maybe [a tribute to Tintin](https://en.wikipedia.org/wiki/Red_Rackham%27s_Treasure)?,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-12T08:35:13Z,False,156298211.0,"My guess is `R` probably stands for refolding. The first `A` I have no idea, though. So @ppedrot's explanation is more plausible.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-12T08:35:32Z,False,156298273.0,`K` is for Krivine.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-12T10:13:50Z,False,156322052.0,"The other one didn't exist before this PR IIRC. So what you want in fact is that the documentation be updated according to the existing options, instead of the option being renamed to match the documentation.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T09:00:55Z,False,156885075.0,"This documentation doesn't seem to be reflecting the current behavior:
```
Unset Keep Admitted Variables.

Section Foo.

Variable x : nat.

Lemma foo : True.
Proof.
generalize x.
Show Proof. (* x is used in the partial term *)
Admitted.
End Foo.
About foo. (* no hypothesis *)
```

Please fix or clarify if it is a bug.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T09:02:15Z,False,156885333.0,"how does it relate to ` info`, which IIRC is what people were using?",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T09:02:48Z,False,156885449.0,"Feel free to ignore the remark if this is written somewhere else, I don't have the time to read everything.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T10:46:30Z,False,156910071.0,Refolding Algebraic Krivine Abstract Machine (so that it makes a joke ;-) ),True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T10:49:14Z,False,156910703.0,@pirbo What does algebraic mean in this context?!,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T11:17:38Z,False,156917149.0,"It means that it is a machine that does `iota` in addition of `beta` `delta`.
Said differently, it deals with algebraic datatypes (via case analyses/(co)fixpoint reduction) which the Krivine Abstract Machine has no idea about.

It comes from the (only on arXiv (and in my thesis)) description of the system:
- take a standard KAM
- add the machinery to deal with algebraic data structure (AKAM)
- add a second stack to deal with unfolded constant (RAKAM)

You obtain a imitation of `simpl` at 95% that have some simplicity/efficiency/customazability advantages over `simpl`  ( <-- argument contested), can be used to make unification refold while it reduced or be used in a strait forward way by `hnf` to make it refold",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T11:40:13Z,False,156921445.0,I forgot what tests I did to figure out what this option does so I'm just dropping it.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T11:43:09Z,False,156922054.0,"I have no idea, IIRC I just picked whichever I saw first (without caching past picks).",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T11:43:54Z,False,156922208.0,">how does it relate to info, which IIRC is what people were using?

I don't know, I'm not much of a `auto` user.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T13:13:22Z,False,156939215.0,"`debug` shows more, it also shows the dead branches, whereas `info` shows just the successful branch.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T13:13:53Z,False,156939307.0,Probably irrelevant anyways since we are soon moving to Sphinx.,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T13:17:00Z,False,156940150.0,@SkySkimmer You didn't address this comment :) but then I think I bothered you enough on this PR already...,True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T13:17:51Z,False,156940308.0,"That's a github illusion, I removed that commit.",True,False
coq/coq/6219/pulls/coq/coq/6219,2017-12-14T13:19:55Z,False,156940742.0,Or maybe it didn't get removed for some reason? It's gone now.,True,False
CartoDB/cartodb-postgresql/168/pulls/CartoDB/cartodb-postgresql/168,2015-09-29T18:00:54Z,False,144136831.0,":+1: but let's wait for @rochoa so we can decide how to roll out this fix
",True,False
CartoDB/cartodb-postgresql/168/pulls/CartoDB/cartodb-postgresql/168,2015-09-29T16:45:24Z,False,40696075.0,"Use `CDB_CartodbfyTableCheck` instead, that provides extra checks on the resulting table after cartodbfy'ing
",True,False
travis-ci/apt-package-whitelist/4118/pulls/travis-ci/apt-package-whitelist/4118,2017-05-21T02:35:20Z,False,302911036.0,Duplicate of #4117.,True,False
Azure/azure-rest-api-specs/11730/pulls/Azure/azure-rest-api-specs/11730,2020-11-18T08:49:18Z,False,729530778.0,"<h3>Swagger Validation Report</h3><details><summary><code>️️✔️</code><b>BreakingChange</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741206""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>There are no breaking changes.</pre></details><details><summary><code>️️✔️</code><b>LintDiff</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741224""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>Validation passes for LintDiff.</pre></details><details><summary><code>️️✔️</code><b>Avocado</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741236""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>Validation passes for Avocado.</pre></details><details><summary><code>️️✔️</code><b>ModelValidation</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741247""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>Validation passes for ModelValidation.</pre></details><details><summary><code>️️✔️</code><b>SemanticValidation</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741257""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>Validation passes for SemanticValidation.</pre></details><details><summary><code>️️✔️</code><b>[Staging] Cross Version BreakingChange (Base on preview version)</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741278""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>There are no breaking changes.</pre></details><details><summary><code>️️✔️</code><b>[Staging] Cross Version BreakingChange (Base on stable version)</b> succeeded [<a href=""https://github.com/Azure/azure-rest-api-specs/pull/11730/checks?check_run_id=1461741299""
      target=""_blank"">Detail</a>] [Expand]  
  </summary><pre>There are no breaking changes.</pre></details><sub>Posted by <b>Swagger Pipeline</b> | <a href=""https://aka.ms/ci-fix"">How to fix these errors?</a></sub>
",True,False
Azure/azure-rest-api-specs/11730/pulls/Azure/azure-rest-api-specs/11730,2020-11-18T08:49:19Z,False,729530789.0,"Swagger pipeline restarted successfully, please wait for status update in this comment.",True,False
Azure/azure-rest-api-specs/11730/pulls/Azure/azure-rest-api-specs/11730,2020-11-27T02:20:19Z,False,734542615.0,/azp run,True,False
Azure/azure-rest-api-specs/11730/pulls/Azure/azure-rest-api-specs/11730,2020-11-27T02:20:37Z,False,734543061.0,"<samp>
Azure Pipelines successfully started running 2 pipeline(s).<br>

</samp>",True,False
tendermint/tendermint/3693/pulls/tendermint/tendermint/3693,2019-05-30T22:11:16Z,False,497504078.0,"# [Codecov](https://codecov.io/gh/tendermint/tendermint/pull/3693?src=pr&el=h1) Report
> Merging [#3693](https://codecov.io/gh/tendermint/tendermint/pull/3693?src=pr&el=desc) into [develop](https://codecov.io/gh/tendermint/tendermint/commit/b522ad005242e633aa72ee672373043bdcedec2b?src=pr&el=desc) will **increase** coverage by `0.18%`.
> The diff coverage is `63.33%`.

```diff
@@            Coverage Diff             @@
##           develop   #3693      +/-   ##
==========================================
+ Coverage    63.21%   63.4%   +0.18%     
==========================================
  Files          218     218              
  Lines        18197   18173      -24     
==========================================
+ Hits         11503   11522      +19     
+ Misses        5721    5677      -44     
- Partials       973     974       +1
```

| [Impacted Files](https://codecov.io/gh/tendermint/tendermint/pull/3693?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [state/store.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-c3RhdGUvc3RvcmUuZ28=) | `71.23% <ø> (+11.46%)` | :arrow_up: |
| [node/node.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-bm9kZS9ub2RlLmdv) | `63.81% <63.33%> (-0.16%)` | :arrow_down: |
| [blockchain/pool.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-YmxvY2tjaGFpbi9wb29sLmdv) | `80.26% <0%> (-0.66%)` | :arrow_down: |
| [p2p/pex/pex\_reactor.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-cDJwL3BleC9wZXhfcmVhY3Rvci5nbw==) | `80.88% <0%> (-0.59%)` | :arrow_down: |
| [consensus/reactor.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-Y29uc2Vuc3VzL3JlYWN0b3IuZ28=) | `71.36% <0%> (-0.12%)` | :arrow_down: |
| [tools/tm-bench/main.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-dG9vbHMvdG0tYmVuY2gvbWFpbi5nbw==) | `0% <0%> (ø)` | :arrow_up: |
| [consensus/state.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-Y29uc2Vuc3VzL3N0YXRlLmdv) | `79.97% <0%> (+0.23%)` | :arrow_up: |
| [privval/signer\_remote.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-cHJpdnZhbC9zaWduZXJfcmVtb3RlLmdv) | `80% <0%> (+2%)` | :arrow_up: |
| [privval/signer\_service\_endpoint.go](https://codecov.io/gh/tendermint/tendermint/pull/3693/diff?src=pr&el=tree#diff-cHJpdnZhbC9zaWduZXJfc2VydmljZV9lbmRwb2ludC5nbw==) | `85.45% <0%> (+5.45%)` | :arrow_up: |
",True,False
sanemat/actionview-link_to_blank/220/pulls/sanemat/actionview-link_to_blank/220,2017-12-05T22:57:01Z,False,349469432.0,"
[![Coverage Status](https://coveralls.io/builds/14519127/badge)](https://coveralls.io/builds/14519127)

Coverage remained the same at 100.0% when pulling **0454c67c08183a5c8c0f2704d01510abef7e9961 on pazjacket:tachikoma/update-20171205224846** into **00aee1e3390a70ca4b84b966c247c4b4ffec8fd6 on sanemat:master**.
",True,False
takeontom/pyluxafor/142/pulls/takeontom/pyluxafor/142,2018-12-14T04:58:51Z,False,447213664.0,Closing this in favor of #152,True,False
weareopensource/Node/591/pulls/weareopensource/Node/591,2020-01-23T04:29:02Z,False,577498835.0,"Code Climate has analyzed commit 83cea699 and detected **0 issues** on this pull request.

View more on [Code Climate](https://codeclimate.com/github/weareopensource/Node/pull/591).
",True,False
lawliet89/rowdy/146/pulls/lawliet89/rowdy/146,2020-05-11T00:26:15Z,False,626413922.0,Superseded by #148.,True,False
amenezes/wttd/8/pulls/amenezes/wttd/8,2021-03-18T20:48:07Z,False,802286466.0,Superseded by #10.,True,False
codedge/laravel-fpdf/52/pulls/codedge/laravel-fpdf/52,2020-11-29T22:10:06Z,False,735465855.0,The following labels could not be found: `dependency`.,True,False
codedge/laravel-fpdf/52/pulls/codedge/laravel-fpdf/52,2020-11-29T22:10:50Z,False,735465947.0,"# [Codecov](https://codecov.io/gh/codedge/laravel-fpdf/pull/52?src=pr&el=h1) Report
> Merging [#52](https://codecov.io/gh/codedge/laravel-fpdf/pull/52?src=pr&el=desc) (be8c776) into [master](https://codecov.io/gh/codedge/laravel-fpdf/commit/dfa2086b84cf6d2bf1ae0f528a248ddfff0fcd7b?el=desc) (dfa2086) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/codedge/laravel-fpdf/pull/52/graphs/tree.svg?width=650&height=150&src=pr&token=5e1I9VlK9o)](https://codecov.io/gh/codedge/laravel-fpdf/pull/52?src=pr&el=tree)

```diff
@@           Coverage Diff            @@
##             master     #52   +/-   ##
========================================
  Coverage      3.39%   3.39%           
  Complexity      601     601           
========================================
  Files            27      27           
  Lines          2414    2414           
========================================
  Hits             82      82           
  Misses         2332    2332           
```

| Flag | Coverage Δ | Complexity Δ | |
|---|---|---|---|
| unittests | `3.39% <ø> (ø)` | `0.00 <ø> (ø)` | |

Flags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags#carryforward-flags-in-the-pull-request-comment) to find out more.


------

[Continue to review full report at Codecov](https://codecov.io/gh/codedge/laravel-fpdf/pull/52?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/codedge/laravel-fpdf/pull/52?src=pr&el=footer). Last update [dfa2086...be8c776](https://codecov.io/gh/codedge/laravel-fpdf/pull/52?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
everypolitician/everypolitician-data/71651/pulls/everypolitician/everypolitician-data/71651,2018-01-06T23:47:08Z,False,355786886.0,"

Summary of changes in `data/New_Zealand/House/ep-popolo-v1.0.json`:

## People

### Added


No people added


### Removed


No people removed


### Name Changes


No name changes


### Additional Name Changes


No name changes


### Wikidata Changes


No changes


## Organizations

### Added


No organizations added


### Removed


No organizations removed


## Memberships

### Added

No memberships added


### Removed

No memberships removed
















",True,False
everypolitician/everypolitician-data/71651/pulls/everypolitician/everypolitician-data/71651,2018-01-08T02:34:19Z,False,355874581.0,This Pull Request has been superseded by #71898,True,False
pantsbuild/pants/4553/pulls/pantsbuild/pants/4553,2017-05-05T03:46:36Z,False,299363467.0,I generated the site locally and the formatting looks good. Happy to make any substance or style changes if you have suggestions!,True,False
MorvanZhou/PyTorch-Tutorial/6/pulls/MorvanZhou/PyTorch-Tutorial/6,2017-06-23T00:38:02Z,False,310539092.0,"I think it is necessary. Thank you.
Too busy recently, I'll try to do that once I get time.",True,False
MorvanZhou/PyTorch-Tutorial/6/pulls/MorvanZhou/PyTorch-Tutorial/6,2017-06-23T00:40:46Z,False,310539416.0,"@liufuyang Oh, I see, you did them all. That is a great help! I merged it and mentioned with a link in the README. ",True,False
MorvanZhou/PyTorch-Tutorial/6/pulls/MorvanZhou/PyTorch-Tutorial/6,2017-06-23T12:37:28Z,False,310654506.0,Thank you :),True,False
freeCodeCamp/guides/5512/pulls/freeCodeCamp/guides/5512,2018-10-08T06:12:21Z,False,427730135.0,"@saikumar010, thank you for taking the time to improve this section of the guide. However, a lot of this seems to be taken directly from https://nosqlbooster.com/featuresForSQL. Plagiarism is not allowed in the guide, so you'll have to rewrite this. Please let us know when you're finished and someone will be happy to take another look at your PR.",True,False
freeCodeCamp/guides/5512/pulls/freeCodeCamp/guides/5512,2018-10-22T20:39:51Z,False,431976269.0,"Thank you for your patience.

We have archived this Guide repository and moved the guide into our main https://github.com/freecodecamp/freecodecamp repostory.

Since this Guide repository is now archived, I'm closing this pull request.

I encourage you to take a look at the repository and consider contributing to it this Hacktoberfest.

We now have a much larger team QA'ing these pull requests and we should be able to review your pull request much faster this time. Here's an article I wrote with details for how to do this: https://www.freecodecamp.org/n/FDoftlSup

Thank you again for contributing to open source.",True,False
LoicMahieu/gatsby-plugin-sentry/2/pulls/LoicMahieu/gatsby-plugin-sentry/2,2020-08-26T19:49:46Z,False,681088530.0,Superseded by #3.,True,False
eltranseunteurbano/CursosPlatzi/7/pulls/eltranseunteurbano/CursosPlatzi/7,2020-08-12T19:40:53Z,False,673071673.0,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",True,False
janis-commerce/client-settings/4/pulls/janis-commerce/client-settings/4,2020-09-18T22:20:35Z,False,695111351.0,"Looks like lodash is up-to-date now, so this is no longer needed.",True,False
DamianNurzynski/CompanyInfoPage/53/pulls/DamianNurzynski/CompanyInfoPage/53,2019-02-28T04:22:23Z,False,468132091.0,Superseded by #58.,True,False
IQSS/dataverse/3836/pulls/IQSS/dataverse/3836,2017-05-16T20:07:20Z,False,301899926.0,"
[![Coverage Status](https://coveralls.io/builds/11552930/badge)](https://coveralls.io/builds/11552930)

Coverage remained the same at 10.062% when pulling **a98917bdf14246eed3b399ac87a5e00e18986a83 on 3755-style-guide-patterns** into **51f2ba68a648cc461b27527c47a3510c17fb78d5 on develop**.
",True,False
IQSS/dataverse/3836/pulls/IQSS/dataverse/3836,2017-05-16T20:14:59Z,False,301901936.0,"
[![Coverage Status](https://coveralls.io/builds/11553069/badge)](https://coveralls.io/builds/11553069)

Coverage remained the same at 10.062% when pulling **1c61fb0c07b1eaed370d946717c14c75ddf9733d on 3755-style-guide-patterns** into **51f2ba68a648cc461b27527c47a3510c17fb78d5 on develop**.
",True,False
IQSS/dataverse/3836/pulls/IQSS/dataverse/3836,2017-05-17T21:41:27Z,False,302239800.0,"
[![Coverage Status](https://coveralls.io/builds/11573758/badge)](https://coveralls.io/builds/11573758)

Coverage decreased (-0.006%) to 10.055% when pulling **1c86780895e4782f60f28d4a6ab58b9e5a49367e on 3755-style-guide-patterns** into **51f2ba68a648cc461b27527c47a3510c17fb78d5 on develop**.
",True,False
IQSS/dataverse/3836/pulls/IQSS/dataverse/3836,2017-05-18T14:44:50Z,False,302425742.0,"
[![Coverage Status](https://coveralls.io/builds/11584472/badge)](https://coveralls.io/builds/11584472)

Coverage decreased (-0.01%) to 10.05% when pulling **1ac1d38e513b5efc1604206950f7d9375d0d3d06 on 3755-style-guide-patterns** into **51f2ba68a648cc461b27527c47a3510c17fb78d5 on develop**.
",True,False
elm-lang/dom/8/pulls/elm-lang/dom/8,2016-10-04T16:55:40Z,False,251446830.0,"Thanks for the pull request! Make sure it satisfies [this checklist](https://github.com/process-bot/contribution-checklist/blob/master/pulls.md). My human colleagues will appreciate it!

Here is [what to expect next](https://github.com/process-bot/contribution-checklist/blob/master/expectations.md), and if anyone wants to comment, keep [these things](https://github.com/process-bot/contribution-checklist/blob/master/participation.md) in mind.
",True,False
elm-lang/dom/8/pulls/elm-lang/dom/8,2017-07-13T23:42:06Z,False,315230844.0,This was achieved in a much more reliable way in https://github.com/elm-lang/dom/commit/7c1a62782ba089cddff6ac05c608f78d4bbb2e96,True,False
douglasrlee/aquatica-api/121/pulls/douglasrlee/aquatica-api/121,2020-12-14T09:59:07Z,False,744325978.0,"# [Codecov](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121?src=pr&el=h1) Report
> Merging [#121](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121?src=pr&el=desc) (77f62b4) into [master](https://codecov.io/gh/douglasrlee/aquatica-api/commit/86c4cb7f677bb79c404f404a54a923ef2e9f7695?el=desc) (86c4cb7) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121/graphs/tree.svg?width=650&height=150&src=pr&token=MfcyjfLwYC)](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master      #121   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           23        23           
  Lines          261       261           
=========================================
  Hits           261       261           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121?src=pr&el=footer). Last update [86c4cb7...77f62b4](https://codecov.io/gh/douglasrlee/aquatica-api/pull/121?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
MostafaElGamal/Web-Development-Test-Projects/8/pulls/MostafaElGamal/Web-Development-Test-Projects/8,2020-07-17T08:04:28Z,False,659944695.0,Superseded by #41.,True,False
everypolitician/everypolitician-data/149637/pulls/everypolitician/everypolitician-data/149637,2019-04-10T07:30:17Z,False,481570435.0,"

Summary of changes in `data/Tunisia/Majlis/ep-popolo-v1.0.json`:

## People

### Added



- `7a0cd79e-bff8-4614-8914-9b2bb8a29b35` - Yassine Ayari

- `8bbdb3b9-8611-473a-8811-221acdf92129` - Yassine Ayari



### Removed


No people removed


### Name Changes



- `061473e9-093c-4ce6-ae02-a219bd002e85`: Abdennaceur Chouikh → Lamia Dridi

- `10d51d8d-19ed-4a7f-beca-8e843f81bf2b`: Tahar Fdhil → Ali Belakhoua

- `11a1c043-b0f8-4e52-b3f3-8e5241bb9399`: Fatma Mseddi → Nadia Zangar

- `17fc8a4f-dc39-43b1-aae6-118edbcab31e`: Mohamed Rachdi Bouguerra → Walid Jalled

- `1b1e0593-53cd-435c-97a5-959c391968a9`: Abderrazak Chraiet → Mohamed El Hamdi

- `1edb66b0-2756-4a14-8927-933eff54649d`: Abada Kefi → Nesrine Laamari

- `203c1af4-6c13-4af4-b2bd-f954c99af605`: Mohamed Fadhel Ben Omrane → Sofien Toubel

- `24fae9af-694d-4b5a-918a-a21c94eefbe9`: Mohamed Nejib Torjmane → Leila Hamrouni

- `2cbd3360-e31e-4fed-ad7d-119b552d5c09`: Meriem Boujbel → Sabrine Goubantini

- `34cb44dc-63b8-4121-831b-878940bb7ee1`: Marouan Felfel → Najia Ben Abdelhafidh

- `39625ce4-e698-4cc0-90dd-c7aa0bab9bf1`: Bochra Belhaj Hamida → Houda Slim

- `3d28c962-8a1f-4cb6-a9d9-2b70a70d783b`: Leila Hamrouni → Mohamed Nejib Torjmane

- `475c0453-1c5a-4573-88de-7d8640a4e3a1`: Lamia Dridi → Nadhir Ben Ammou

- `4771e704-134c-4647-ac3b-da54c73ede86`: Houda Slim → Mohamed Ennaceur Jbira

- `48184b51-3f92-4d50-afeb-650a18dd2c76`: Walid Jalled → Ridha Zghondi

- `547e5d84-7f43-4c2a-a0c9-24fbf1610ad8`: Abderraouf El May → Leila ِChettaoui Bougatef

- `559c6a3f-557e-4f7c-ac78-d56b893929a8`: Issam Matoussi → Lotfi Ali

- `562ffc4b-a317-4038-a465-6e6b5d035fc4`: Najia Ben Abdelhafidh → Mohamed Rachdi Bouguerra

- `567d6147-ec44-45a5-a02f-1fbda533d143`: Nadhir Ben Ammou → Naoufel Jammali

- `5809fd56-8c6b-42da-ad4b-089defe96430`: Ridha Zghondi → Souad Zaouali

- `5843bd4b-3221-4f97-bf9f-bd8929a72fbf`: Mohamed Kamel Hamzaoui → Maroua Bouazzi

- `597f1ad0-3df1-4f05-8adb-baeaa8c6ab7b`: Hatem Ferjani → Sameh Bouhaouel

- `5a4573e3-31d6-4248-8e4f-68aa537cd030`: Sofien Toubel → Mohamed Fadhel Ben Omrane

- `5fe6334a-b3e2-42b0-b1b3-d2755156c248`: Sameh Bouhaouel → Yassine Ayari

- `646a6623-f2d3-4170-a9ac-5bd4b5a5eb05`: El Khansa Ben Harrath → Ahmed Saidi

- `6906c710-d80b-4ff8-973c-69c7d32f1bcd`: Ali Belakhoua → Leila Ouled Ali

- `6cf4dc1b-ea0a-4e1e-a138-27a5cc5407a3`: Leila ِChettaoui Bougatef → Meriem Boujbel

- `78bdbeab-a6fc-497a-b94d-cbe084ea5c6f`: Mabrouk Hrizi → Olfa Soukri

- `79bc3781-bdd3-4e7e-9d19-3b724a54d899`: Naoufel Jammali → Fatma Mseddi

- `7e9a52d5-e3a8-469b-8670-aa53845716dc`: Noura Amri → Mondher Belhaj Ali

- `83f631f4-5f75-4da8-bd86-8fba8b9980c4`: Souad Zaouali → El Khansa Ben Harrath

- `96f798ac-df3f-4c93-bf9c-7b96a9709798`: Ahmed Saidi → Khemais Ksila

- `9fd1beb3-5fa9-4b47-a55e-8fed15563197`: Abir Abdelli → Naceur Channoufi

- `a18d0565-6154-4bfb-b4b9-78a51c5e87aa`: Sabrine Goubantini → Rim Thairi

- `a4510bbe-054a-45bf-8f9e-c40f01f45b69`: Mondher Belhaj Ali → Marouan Falfel

- `a521e9c0-7799-4e74-9bcb-65973bd8ce76`: Mohamed Ennaceur → Abdelfattah Mourou

- `a62dcdf7-847e-48d9-932e-2f4c62f27c43`: Khemais Ksila → Tahar Fdhil

- `b9ec976f-ad22-4101-80b0-b15e91e1a06c`: Youssef Jouini → Abdelaziz Kotti

- `baf71d58-2108-4d37-8d26-7007103a6967`: Mohamed El Hamdi → Faycel Tebini

- `bcd92399-ce19-4e9b-89e9-695484740892`: Mohamed Ennaceur Jbira → Bochra Belhaj Hamida

- `c074a3fd-f05e-4948-98cd-d0c00b6ed6c7`: Basma Jebali → Hager Triki

- `c450d814-908a-4dd7-a4ed-81c983d5ef49`: Abdelaziz Kotti → Abir Abdelli

- `cd269b4b-283e-49de-a346-e188ab8c0c68`: Oussama Al Saghir → Oussama Al Sghaier

- `d44afeb7-7400-4092-a829-e9eb95df3158`: Naceur Channoufi → Abdennaceur Chouikh

- `e4b49b16-6033-4dbd-ad88-3cb5520e8fb9`: Olfa Soukri → Mabrouk Hrizi

- `ea68d30f-070b-4bc2-a517-e7ab05de271e`: Leila Ouled Ali → Youssef Jouini

- `eb8b439a-68e5-436b-8579-9a337efcfacb`: Taher Battikh → Amira Zoukari

- `f55cd71c-f870-4c26-9808-48bc073468fd`: Nadia Zangar → Noura Amri

- `f6ec785d-f801-4e0a-97ea-f024aab54cb9`: Faycel Tebini → Abderrazak Chraiet

- `f70ede75-579e-4ae0-89db-89fe217b95ba`: Lotfi Ali → Issam Matoussi

- `f91d1b04-c3c2-4283-a143-152b0b4f8ac9`: Rim Thairi → Abderraouf El May

- `fcbf2206-9e09-4a11-b9a4-b2a6e85ef7f9`: Abderraouf Cherif → Jihene Abadi

- `fde99936-7378-411b-8d06-7be721efc82f`: Abdelfattah Mourou → Mohamed Ennaceur



### Additional Name Changes



- `061473e9-093c-4ce6-ae02-a219bd002e85` (Abdennaceur Chouikh): Removed: Abdennaceur Chouikh. Added: Lamia Dridi.

- `10d51d8d-19ed-4a7f-beca-8e843f81bf2b` (Tahar Fdhil): Removed: Tahar Fdhil. Added: Ali Belakhoua.

- `11a1c043-b0f8-4e52-b3f3-8e5241bb9399` (Fatma Mseddi): Removed: Fatma Mseddi. Added: Nadia Zangar.

- `17fc8a4f-dc39-43b1-aae6-118edbcab31e` (Mohamed Rachdi Bouguerra): Removed: Mohamed Rachdi Bouguerra. Added: Walid Jalled.

- `1b1e0593-53cd-435c-97a5-959c391968a9` (Abderrazak Chraiet): Added: Mohamed El Hamdi.

- `1edb66b0-2756-4a14-8927-933eff54649d` (Abada Kefi): Removed: Abada Kefi. Added: Nesrine Laamari.

- `203c1af4-6c13-4af4-b2bd-f954c99af605` (Mohamed Fadhel Ben Omrane): Removed: Mohamed Fadhel Ben Omrane. Added: Sofien Toubel.

- `24fae9af-694d-4b5a-918a-a21c94eefbe9` (Mohamed Nejib Torjmane): Removed: Mohamed Nejib Torjmane. Added: Leila Hamrouni.

- `2cbd3360-e31e-4fed-ad7d-119b552d5c09` (Meriem Boujbel): Removed: Meriem Boujbel. Added: Sabrine Goubantini.

- `34cb44dc-63b8-4121-831b-878940bb7ee1` (Marouan Felfel): Removed: Marouan Felfel. Added: Najia Ben Abdelhafidh.

- `39625ce4-e698-4cc0-90dd-c7aa0bab9bf1` (Bochra Belhaj Hamida): Removed: Bochra Belhaj Hamida. Added: Houda Slim.

- `3d28c962-8a1f-4cb6-a9d9-2b70a70d783b` (Leila Hamrouni): Removed: Leila Hamrouni. Added: Mohamed Nejib Torjmane.

- `475c0453-1c5a-4573-88de-7d8640a4e3a1` (Lamia Dridi): Removed: Lamia Dridi. Added: Nadhir Ben Ammou.

- `4771e704-134c-4647-ac3b-da54c73ede86` (Houda Slim): Removed: Houda Slim. Added: Mohamed Ennaceur Jbira.

- `48184b51-3f92-4d50-afeb-650a18dd2c76` (Walid Jalled): Removed: Walid Jalled. Added: Ridha Zghondi.

- `547e5d84-7f43-4c2a-a0c9-24fbf1610ad8` (Abderraouf El May): Removed: Abderraouf El May. Added: Leila ِChettaoui Bougatef.

- `559c6a3f-557e-4f7c-ac78-d56b893929a8` (Issam Matoussi): Removed: Issam Matoussi. Added: Lotfi Ali.

- `562ffc4b-a317-4038-a465-6e6b5d035fc4` (Najia Ben Abdelhafidh): Removed: Najia Ben Abdelhafidh. Added: Mohamed Rachdi Bouguerra.

- `567d6147-ec44-45a5-a02f-1fbda533d143` (Nadhir Ben Ammou): Added: Naoufel Jammali.

- `5809fd56-8c6b-42da-ad4b-089defe96430` (Ridha Zghondi): Removed: Ridha Zghondi. Added: Souad Zaouali.

- `5843bd4b-3221-4f97-bf9f-bd8929a72fbf` (Mohamed Kamel Hamzaoui): Removed: Mohamed Kamel Hamzaoui. Added: Maroua Bouazzi.

- `597f1ad0-3df1-4f05-8adb-baeaa8c6ab7b` (Hatem Ferjani): Removed: Hatem Ferjani. Added: Sameh Bouhaouel.

- `5a4573e3-31d6-4248-8e4f-68aa537cd030` (Sofien Toubel): Removed: Sofien Toubel. Added: Mohamed Fadhel Ben Omrane.

- `5fe6334a-b3e2-42b0-b1b3-d2755156c248` (Sameh Bouhaouel): Removed: Sameh Bouhaouel. Added: Yassine Ayari.

- `646a6623-f2d3-4170-a9ac-5bd4b5a5eb05` (El Khansa Ben Harrath): Removed: El Khansa Ben Harrath. Added: Ahmed Saidi.

- `6906c710-d80b-4ff8-973c-69c7d32f1bcd` (Ali Belakhoua): Removed: Ali Belakhoua. Added: Leila Ouled Ali.

- `6cf4dc1b-ea0a-4e1e-a138-27a5cc5407a3` (Leila ِChettaoui Bougatef): Removed: Leila ِChettaoui Bougatef. Added: Meriem Boujbel.

- `78bdbeab-a6fc-497a-b94d-cbe084ea5c6f` (Mabrouk Hrizi): Removed: Mabrouk Hrizi. Added: Olfa Soukri.

- `79bc3781-bdd3-4e7e-9d19-3b724a54d899` (Naoufel Jammali): Added: Fatma Mseddi.

- `7e9a52d5-e3a8-469b-8670-aa53845716dc` (Noura Amri): Removed: Noura Amri. Added: Mondher Belhaj Ali.

- `83f631f4-5f75-4da8-bd86-8fba8b9980c4` (Souad Zaouali): Removed: Souad Zaouali. Added: El Khansa Ben Harrath.

- `96f798ac-df3f-4c93-bf9c-7b96a9709798` (Ahmed Saidi): Removed: Ahmed Saidi. Added: Khemais Ksila.

- `9fd1beb3-5fa9-4b47-a55e-8fed15563197` (Abir Abdelli): Removed: Abir Abdelli. Added: Naceur Channoufi.

- `a18d0565-6154-4bfb-b4b9-78a51c5e87aa` (Sabrine Goubantini): Added: Rim Thairi.

- `a4510bbe-054a-45bf-8f9e-c40f01f45b69` (Mondher Belhaj Ali): Removed: Mondher Belhaj Ali. Added: Marouan Falfel.

- `a521e9c0-7799-4e74-9bcb-65973bd8ce76` (Mohamed Ennaceur): Added: Abdelfattah Mourou.

- `a62dcdf7-847e-48d9-932e-2f4c62f27c43` (Khemais Ksila): Added: Tahar Fdhil.

- `b9ec976f-ad22-4101-80b0-b15e91e1a06c` (Youssef Jouini): Removed: Youssef Jouini. Added: Abdelaziz Kotti.

- `baf71d58-2108-4d37-8d26-7007103a6967` (Mohamed El Hamdi): Removed: Mohamed El Hamdi. Added: Faycel Tebini.

- `bcd92399-ce19-4e9b-89e9-695484740892` (Mohamed Ennaceur Jbira): Removed: Mohamed Ennaceur Jbira. Added: Bochra Belhaj Hamida.

- `c074a3fd-f05e-4948-98cd-d0c00b6ed6c7` (Basma Jebali): Added: Hager Triki.

- `c450d814-908a-4dd7-a4ed-81c983d5ef49` (Abdelaziz Kotti): Added: Abir Abdelli.

- `cd269b4b-283e-49de-a346-e188ab8c0c68` (Oussama Al Saghir): Removed: Oussama Al Saghir. Added: Oussama Al Sghaier.

- `d44afeb7-7400-4092-a829-e9eb95df3158` (Naceur Channoufi): Removed: Naceur Channoufi. Added: Abdennaceur Chouikh.

- `e4b49b16-6033-4dbd-ad88-3cb5520e8fb9` (Olfa Soukri): Removed: Olfa Soukri. Added: Mabrouk Hrizi.

- `ea68d30f-070b-4bc2-a517-e7ab05de271e` (Leila Ouled Ali): Removed: Leila Ouled Ali. Added: Youssef Jouini.

- `eb8b439a-68e5-436b-8579-9a337efcfacb` (Taher Battikh): Removed: Taher Battikh. Added: Amira Zoukari.

- `f55cd71c-f870-4c26-9808-48bc073468fd` (Nadia Zangar): Removed: Nadia Zangar. Added: Noura Amri.

- `f6ec785d-f801-4e0a-97ea-f024aab54cb9` (Faycel Tebini): Removed: Faycel Tebini. Added: Abderrazak Chraiet.

- `f70ede75-579e-4ae0-89db-89fe217b95ba` (Lotfi Ali): Removed: Lotfi Ali. Added: Issam Matoussi.

- `f91d1b04-c3c2-4283-a143-152b0b4f8ac9` (Rim Thairi): Removed: Rim Thairi. Added: Abderraouf El May.

- `fcbf2206-9e09-4a11-b9a4-b2a6e85ef7f9` (Abderraouf Cherif): Removed: Abderraouf Cherif. Added: Jihene Abadi.

- `fde99936-7378-411b-8d06-7be721efc82f` (Abdelfattah Mourou): Added: Mohamed Ennaceur.



### Wikidata Changes


No changes


## Organizations

### Added



- `Allégeance_à_la_Patrie` - Allégeance à la Patrie

- `Coalition_nationale` - Coalition nationale



### Removed



- `Afek_Tounes_et_lappel_des_tunisiens_à_létranger` - Afek Tounes et l'appel des tunisiens à l'étranger

- `Bloc_National` - Bloc National



## Memberships

### Added


#### term/1

- Abdelfattah Mourou 

- Abdelkader Ben Dhifallah 

- Abdelouahab Ouerfelli 

- Abdennaceur Chouikh 

- Abderraouf Chebbi 

- Abderraouf El May 

- Abderrazak Chraiet 

- Abir Abdelli 

- Adnane Hajji 

- Ahmed Saidi 

- Ali Belakhoua 

- Ali Bennour 

- Bechir Ben Amor 

- Belgacem Dkhili 

- Bochra Belhaj Hamida 

- Dorra Yaacoubi 

- El Khansa Ben Harrath 

- Faouzia Ben Fodha 

- Fatma Mseddi 

- Faycel Tebini 

- Hafedh Zouari 

- Heger Ben Cheikh Ahmed 

- Hela Omrane 

- Hmed Khaskhoussi 

- Houda Slim 

- Ibtissem Jebabli 

- Ikram Moulahi 

- Ismail Ben Mahmoud 

- Issam Matoussi 

- Jihen Aouichi 

- Kamel Harraghi 

- Karim Helali 

- Khemais Ksila 

- Lamia Dridi 

- Leila Hamrouni 

- Leila Ouled Ali 

- Leila ِChettaoui Bougatef 

- Lilia Younes Ksibi 

- Lotfi Ali 

- Lotfi Nabli 

- Mabrouk Hrizi 

- Mahmoud Kahri 

- Maroua Bouazzi 

- Marouan Falfel 

- Meriem Boujbel 

- Mohamed Amine Kahloul 

- Mohamed Anouar Adhar 

- Mohamed El Hamdi 

- Mohamed Ennaceur 

- Mohamed Ennaceur Jbira 

- Mohamed Fadhel Ben Omrane 

- Mohamed Ghannem 

- Mohamed Hedi Gueddich 

- Mohamed Jalel Ghedira 

- Mohamed Nejib Torjmane 

- Mohamed Rachdi Bouguerra 

- Mohamed Saidane 

- Moncef Sellami 

- Mondher Belhaj Ali 

- Mustapha Ben Ahmed 

- Naceur Channoufi 

- Nadhir Ben Ammou 

- Nadia Zangar 

- Najia Ben Abdelhafidh 

- Naoufel Jammali 

- Noura Amri 

- Noureddine Ben Achour 

- Noureddine Mrabti 

- Nozha Biaoui 

- Olfa Jouini 

- Olfa Soukri 

- Riadh Jaidane 

- Ridha Zghondi 

- Rim Mahjoub 

- Rim Thairi 

- Sabrine Goubantini 

- Sahbi Ben Fraj 

- Sameh Bouhaouel 

- Sana Salhi 

- Sofien Toubel 

- Souad Zaouali 

- Souhail Alouini 

- Tahar Fdhil 

- Taoufik Jemli 

- Tarek Fetiti 

- Walid Jalled 

- Yassine Ayari 

- Yassine Ayari 

- Yassine Ayari 

- Youssef Jouini 

- Zohra Idriss 




### Removed


#### term/1

- Abdelaziz Kotti 

- Abdelfattah Mourou 

- Abdelkader Ben Dhifallah 

- Abdelouahab Ouerfelli 

- Abdennaceur Chouikh 

- Abderraouf Chebbi 

- Abderraouf El May 

- Abderrazak Chraiet 

- Abir Abdelli 

- Adnane Hajji 

- Ahmed Saidi 

- Ali Belakhoua 

- Ali Bennour 

- Bechir Ben Amor 

- Belgacem Dkhili 

- Bochra Belhaj Hamida 

- Dorra Yaacoubi 

- El Khansa Ben Harrath 

- Faouzia Ben Fodha 

- Fatma Mseddi 

- Faycel Tebini 

- Hafedh Zouari 

- Hatem Ferjani 

- Heger Ben Cheikh Ahmed 

- Hela Omrane 

- Hmed Khaskhoussi 

- Houda Slim 

- Ibtissem Jebabli 

- Ikram Moulahi 

- Ismail Ben Mahmoud 

- Issam Matoussi 

- Jihen Aouichi 

- Kamel Harraghi 

- Karim Helali 

- Khemais Ksila 

- Lamia Dridi 

- Leila Hamrouni 

- Leila Ouled Ali 

- Leila ِChettaoui Bougatef 

- Lilia Younes Ksibi 

- Lotfi Ali 

- Lotfi Nabli 

- Mabrouk Hrizi 

- Mahmoud Kahri 

- Marouan Felfel 

- Meriem Boujbel 

- Mohamed Amine Kahloul 

- Mohamed Anouar Adhar 

- Mohamed El Hamdi 

- Mohamed Ennaceur 

- Mohamed Ennaceur Jbira 

- Mohamed Fadhel Ben Omrane 

- Mohamed Ghannem 

- Mohamed Hedi Gueddich 

- Mohamed Jalel Ghedira 

- Mohamed Kamel Hamzaoui 

- Mohamed Nejib Torjmane 

- Mohamed Rachdi Bouguerra 

- Mohamed Saidane 

- Moncef Sellami 

- Mondher Belhaj Ali 

- Mustapha Ben Ahmed 

- Naceur Channoufi 

- Nadhir Ben Ammou 

- Nadia Zangar 

- Najia Ben Abdelhafidh 

- Naoufel Jammali 

- Noura Amri 

- Noureddine Ben Achour 

- Noureddine Mrabti 

- Nozha Biaoui 

- Olfa Jouini 

- Olfa Soukri 

- Riadh Jaidane 

- Ridha Zghondi 

- Rim Mahjoub 

- Rim Thairi 

- Sabrine Goubantini 

- Sahbi Ben Fraj 

- Sameh Bouhaouel 

- Sana Salhi 

- Sofien Toubel 

- Souad Zaouali 

- Souhail Alouini 

- Tahar Fdhil 

- Taoufik Jemli 

- Tarek Fetiti 

- Walid Jalled 

- Zohra Idriss 


















",True,False
everypolitician/everypolitician-data/149637/pulls/everypolitician/everypolitician-data/149637,2019-04-11T05:52:13Z,False,481975230.0,This Pull Request has been superseded by #149765,True,False
matrix-org/dendrite/695/pulls/matrix-org/dendrite/695,2019-06-21T15:16:45Z,False,504463567.0,I assume this might need some updating?,True,False
matrix-org/dendrite/695/pulls/matrix-org/dendrite/695,2019-06-22T13:37:17Z,False,504666523.0,@anoadragon453 It's now rebased onto master with latest gomatrixserverlib.,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:32:47Z,False,496478253.0,Får du fikset konfliktene dine Filip?,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:20:20Z,False,496492801.0,"Skjønner ikke helt. Har pullet det nyeste fra dev, resolvet alle konfliktene og committet endringene. Men selvom så sier git:
""			You have not concluded your merge (MERGE_HEAD exists).
				Please, commit your changes before you merge.""",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:27:36Z,False,496495102.0,"Ja har du ikke løst konfliktene dine, gå gjennom og løs dem, ligger i head filene du har mergeprossess på",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:54:52Z,False,496504331.0,Funket nå,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:55:50Z,False,496504650.0,Du har testet selv?,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:56:56Z,False,496505035.0,"Ja, fra det jeg har testet så ser det ut som ting virker som de skal",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:57:24Z,False,496505197.0,"Leser ingen feil i koden, da er det good.",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T13:01:49Z,False,496506634.0,Er du klar for å merge / klar for å fjerne WIP da?,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T13:09:18Z,False,496509241.0,I tillegg til forrige: Hva tenker du om de checksene som ikke er gjort? Og har du eventuelt lyst å gjøre mer på det idag?,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T13:11:17Z,False,496509936.0,"Den er ikke helt ferdig. Har noen spørsmål til @askbk 

- Skal jeg lage en egen side hvor aktiviteter kan bli laget uten at man også inviterer personer? Hvordan fungerer rollene akkurat nå? Hvem er det som skal kunne lage aktviteter og invitere folk? Skal rollene bli brukt under alphaen? 

- Skal jeg gjøre det mulig å invitere en bruker uten å lage en ny aktivitet?

- Skal jeg få address på plass i backend?
",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T14:40:55Z,False,496546134.0,"Svar på spørsmål @filipot 

- Ikke tenk på å lage en egen side for å opprette aktivitet uten å invitere. Dette fikser vi etter demoen
- Alle skal kunne invitere hverandre og opprette aktiviteter, eventuelle restriksjoner på dette fikser vi senere.
- Rollene blir egentlig bare brukt på den måten at man kan se informasjon om personen (f.eks. greit å vite om folk er elever på vgs eller ferdigutdannet, eller om de allerede er ansatte)
- Jeg kan fikse backend. Det blir da et attributt som heter `location` på activity

Si i fra hvis jeg har oversett noe.",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T14:58:05Z,False,496553775.0,"Forresten, jeg har laget en egen side hvor man kan se en og en aktivitet. Skal vi fjerne den før demoen, ettersom den egentlig ikke viser noe mer informasjon?

Også, skal det være mulig å avbryte en aktivtet etter man har akseptert den?",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T15:22:49Z,False,496564257.0,Enig @filipot!,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:34:44Z,False,288057143.0,"litt utydelig kode på hva som skal skje her, hvorfor timeSinceInt i differanse i minutter?",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:35:46Z,False,288057489.0,Hva skjer her?,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:36:34Z,False,288057748.0,dette er veldig overflødig,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:39:46Z,False,288058833.0,"På diverse const her med masse deklareringer kan du (i fremtiden hvis du ikke vil / har tid nå) heller bare adde inn de elementer som ikke har samme navn allerede fra det du setter inn, og videre bare returnere objektet, eventuelt unpacked også hvis du vil.",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:40:21Z,False,288059035.0,Sexy,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T11:42:48Z,False,288059860.0,"Det finnes nok andre best practices for å ta ut måneder, men her med denne måten kunne du kanskje bare laget en metode for gjenbruken da det blir repetert ganske mange terniarys her. Bare for leselighets skyld. Ikke nødvendig nå, men fint å tenke på.",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:00:48Z,False,288066403.0,Address er ikke i backend enda,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:03:30Z,False,288067496.0,"Det har med frequency å gjøre (arrangementet på mandag/tirsdag/onsdag osv...) men tror ikke det skal bli med i alphaen ettersom det ikke er laget for når man lager aktiviteten også er det i en annen form i databasen som ""recurrencypattern"" som er en string.",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:06:02Z,False,288068395.0,Ingen annelse hva som skjer her tbh,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:26:10Z,False,288076084.0,"Hmm, ja sliter med å  forstå hva du sier, det jeg lurer på er lom det er mocket siden du manuelt putter inn en false midt i, og hvorfor det er begrenset til ukedagene og ikke tar med helg forøvrig.",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:26:35Z,False,288076282.0,"if -> null
else -> null
redundant",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:26:59Z,False,288076448.0,Har ikke du skrevet det da?,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:38:22Z,False,288081068.0,Mesteparten er fra junior,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T12:43:50Z,False,288083223.0,"aiaiai, muy caramba",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T14:32:20Z,False,288136684.0,"Det kan vi bare fjerne og heller bare vise dato/tidspunkt for aktiviteten siden det uansett kun er enkeltinstanser. 

Her er forøvrig spesifikasjonen for hvordan vi kommer til å gjøre det med aktiviteter: [https://tools.ietf.org/html/rfc5545](https://tools.ietf.org/html/rfc5545)
",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T14:33:40Z,False,288137362.0,Hahaha :stuck_out_tongue: Hvis dere har spørsmål angående det junior har laget så har de sagt at det bare er å spørre,True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T14:40:33Z,False,288140943.0,"Haha, skal spørre Casper senere :)",True,False
askbk/inmarket-frontend/84/pulls/askbk/inmarket-frontend/84,2019-05-28T14:46:56Z,False,288144277.0,Interessant :O Da tenker du vel etter demoen? Den så veldig lang og komplisert ut ,True,False
microsoft/TypeScript/18706/pulls/microsoft/TypeScript/18706,2017-09-26T21:18:20Z,False,332339180.0,"Looks like this will cause merge conflicts in #18775, but I'll handle it once this is in.

Probably fixes #17072.",True,False
microsoft/TypeScript/18706/pulls/microsoft/TypeScript/18706,2017-10-02T17:34:32Z,False,333606395.0,"@sandersn mentioned in https://github.com/Microsoft/TypeScript/pull/18854#pullrequestreview-66523402 that we should have an error if both `@extends` and `@augments` tags are present, but continue on using just the type from `@extends`.",True,False
microsoft/TypeScript/18706/pulls/microsoft/TypeScript/18706,2017-09-23T00:00:55Z,False,140618095.0,"this is part of the public API now, we should not break that.",True,False
microsoft/TypeScript/18706/pulls/microsoft/TypeScript/18706,2017-09-26T21:23:07Z,False,141188933.0,It seems like `SyntaxKind.JSDocExtendsTag` is never assigned anywhere?,True,False
microsoft/TypeScript/18706/pulls/microsoft/TypeScript/18706,2017-09-27T18:05:02Z,False,141422823.0,"I think we should keep `JSDocAugmentsTag` and just let `@extends` be a silent synonym for it in the parser. I don't think it's bad, for example, if the roundtrip emit converts `@extends` to `@augment`. And that's the worst side-effect I can think of.",True,False
microsoft/TypeScript/18706/pulls/microsoft/TypeScript/18706,2017-10-06T23:00:17Z,False,143309937.0,remove 'All',True,False
cloudfoundry/ibm-websphere-liberty-buildpack/368/pulls/cloudfoundry/ibm-websphere-liberty-buildpack/368,2017-09-25T13:44:17Z,False,331885350.0,"Hey stipx!

Thanks for submitting this pull request! I'm here to inform the recipients of the pull request that you and the commit authors have already signed the CLA.
",True,False
cloudfoundry/ibm-websphere-liberty-buildpack/368/pulls/cloudfoundry/ibm-websphere-liberty-buildpack/368,2017-09-25T13:44:17Z,False,331885351.0,"Hey stipx!

Thanks for submitting this pull request! I'm here to inform the recipients of the pull request that you and the commit authors have already signed the CLA.
",True,False
cloudfoundry/ibm-websphere-liberty-buildpack/368/pulls/cloudfoundry/ibm-websphere-liberty-buildpack/368,2017-09-25T19:27:08Z,False,140874207.0,"Not all services have credentials. See https://github.com/cloudfoundry/ibm-websphere-liberty-buildpack/pull/363/files, we just had to fix this in another class.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T20:52:01Z,False,698582179.0,"# [Codecov](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=h1) Report
> Merging [#97](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=desc) into [main](https://codecov.io/gh/slackapi/bolt-python/commit/6d2ad37fcb07192a607c75f055df456ddfbef7e7?el=desc) will **decrease** coverage by `2.99%`.
> The diff coverage is `44.64%`.

[![Impacted file tree graph](https://codecov.io/gh/slackapi/bolt-python/pull/97/graphs/tree.svg?width=650&height=150&src=pr&token=ay3wQeKkvN)](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##             main      #97      +/-   ##
==========================================
- Coverage   90.02%   87.03%   -3.00%     
==========================================
  Files         135      148      +13     
  Lines        3840     4111     +271     
==========================================
+ Hits         3457     3578     +121     
- Misses        383      533     +150     
```


| [Impacted Files](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [slack\_bolt/app/app.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC9hcHAvYXBwLnB5) | `83.23% <25.00%> (-1.36%)` | :arrow_down: |
| [slack\_bolt/app/async\_app.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC9hcHAvYXN5bmNfYXBwLnB5) | `93.17% <33.33%> (-1.90%)` | :arrow_down: |
| [slack\_bolt/workflows/step/async\_step\_middleware.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC9hc3luY19zdGVwX21pZGRsZXdhcmUucHk=) | `36.66% <36.66%> (ø)` | |
| [slack\_bolt/workflows/step/step\_middleware.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC9zdGVwX21pZGRsZXdhcmUucHk=) | `36.66% <36.66%> (ø)` | |
| [slack\_bolt/workflows/step/async\_step.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC9hc3luY19zdGVwLnB5) | `41.26% <41.26%> (ø)` | |
| [slack\_bolt/workflows/step/step.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC9zdGVwLnB5) | `41.26% <41.26%> (ø)` | |
| [...ck\_bolt/workflows/step/utilities/async\_complete.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC91dGlsaXRpZXMvYXN5bmNfY29tcGxldGUucHk=) | `57.14% <57.14%> (ø)` | |
| [slack\_bolt/workflows/step/utilities/async\_fail.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC91dGlsaXRpZXMvYXN5bmNfZmFpbC5weQ==) | `57.14% <57.14%> (ø)` | |
| [...lack\_bolt/workflows/step/utilities/async\_update.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC91dGlsaXRpZXMvYXN5bmNfdXBkYXRlLnB5) | `57.14% <57.14%> (ø)` | |
| [slack\_bolt/workflows/step/utilities/complete.py](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree#diff-c2xhY2tfYm9sdC93b3JrZmxvd3Mvc3RlcC91dGlsaXRpZXMvY29tcGxldGUucHk=) | `57.14% <57.14%> (ø)` | |
| ... and [18 more](https://codecov.io/gh/slackapi/bolt-python/pull/97/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=footer). Last update [6d2ad37...632f72e](https://codecov.io/gh/slackapi/bolt-python/pull/97?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-23T23:00:28Z,False,493941160.0,"Just an idea but providing a decorator as below may be worth considering if we can provide both 1: passing a dict for config and 2: decorator for edit/update/execute listeners. I'm happy to work on this as necessary.

```python
add_task_ws = WorkflowStep(callback_id=""add_task"")

@add_task_ws.edit
def add_task_edit(ack, step, configure):
    pass
@add_task_ws.update
def add_task_update(ack, step):
    pass
@add_task_ws.execute
def add_task_execute():
    pass

app.step(add_task_ws)
```",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-23T23:01:48Z,False,493941592.0,"```suggestion
    values = view[""state""][""values""]
```",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-23T23:02:16Z,False,493941726.0,Let's make the indents consistent (four spaces),True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-23T23:02:55Z,False,493941904.0,"In Bolt for Python, payloads are always a dict.

```suggestion
        ""value"": task_name[""value""]
```",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-23T23:03:04Z,False,493941959.0,same as above,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T20:51:44Z,False,494603264.0,"This is a fairly different approach from what will be introduced in BoltJS, as well as from my first pass at implementation -- so I can only assume this was done for a specific reason.

Why are we not keeping the class-based approach, where the developer instantiates an instance of `WorkflowStep` and then passes it into `app.step()`? What are the implications (if any) of this decision on code organization?",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T20:53:20Z,False,494604039.0,"We removed the ability to do this in BoltJS, so I'd assume we'll also remove the ability to pass a separate `save_callback_id` override here, unless there is a compelling reason not to.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T20:58:14Z,False,494606527.0,"I know you mentioned that we don't support multiple listeners, but it wasn't clear to me if that was to indicate it's not done *yet* (your mention of the utility) or if I misunderstood and that there's no plan to change that. ",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:01:04Z,False,494607915.0,I assume this is just a copy/paste and should be `execute_listener_middleware`. ,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:18:38Z,False,494616379.0,"I added the kwargs pattern just for convenience and simplicity from a user perspective. It's also possible to use a class as below:

```python
app.step(WorkflowStep(
    callback_id=""copy_review"",
    edit=edit,
    save=save,
    execute=execute,
))
```

Feel free to remove the kwargs pattern if you don't see the necessity to have it. I don't have any strong reason to add it.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:25:07Z,False,494619392.0,"I also agree it's totally fine not to have the option and it should work in most cases.

If we think about a possible reason to have this option, let's say a developer doesn't use `configure` for some reason (I'm not sure what it is though). In this case, the developer may want to have an option to set this. But again I'm not sure why the dev has to do so.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:26:30Z,False,494620063.0,"So, if you remove the kwargs pattern here, this method can accept only a `WorkflowStep` object as an argument.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:27:17Z,False,494620439.0,"Sorry, please change this docstring. This is grammatically incorrect and doesn't make sense.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:33:38Z,False,494623226.0,"We're not going to change this. Instead, we want to provide a handy way to attach listener middleware to this. The `Listener` can have `middleware: List[Middleware]`. Developers should be able to attach them by using a new decorator.

```python
ws = WorkflowStep(callback_id=""foo"")

@ws.edit(middleware=[do_this, do_that])
def edit_foo(ack, configure):
    ack()
    configure(...)

app.use(ws) # We can validate the ws already have three listener functions when registering this to App
```

Or we may want to have another one like `WorkflowStep.builder(callback_id=""foo"")`

```python
ws = WorkflowStep.builder(callback_id=""foo"")

@ws.edit(middleware=[do_this, do_that])
def edit_foo(ack, configure):
    ack()
    configure(...)

app.use(ws.build()) # build method verifies if there are sufficient listeners in it.
```
",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-24T21:34:21Z,False,494623522.0,You're right. please correct it.,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T21:01:55Z,False,497055636.0,"Changing to `""""""Registers a new Workflow Step listener""""""`",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T21:09:52Z,False,497061413.0,"In the spirit of fostering shared knowledge of our different implementations, @aoberoi you had the original opinion that steered us to support the user passing in an array of middleware to the configuration object in Bolt for JS. 

Just wanted to highlight how Bolt for Python's implementation will do this based on the discussion above.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T21:27:17Z,False,497070155.0,"Based on this, I am going to change the examples in the docs to reflect the above, as I get the impression that it's the preferred way to instantiate a Step.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T22:37:47Z,False,497100571.0,TODO: `inputs` and `outputs` aren't required here. Also possible to pass in additional args,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T22:38:28Z,False,497100777.0,TODO: `inputs` and `outputs` aren't required here. Also possible to pass in additional args,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T22:41:34Z,False,497102911.0,TODO: `outputs` is not required,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T22:41:55Z,False,497103193.0,TODO: `outputs` is not required,True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T23:17:21Z,False,497129715.0,"@seratch I want to verify that we want to adjust this import to be 

`from slack_bolt.workflows.step import WorkflowStep` 

and not expose it directly off of the package",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-29T23:28:20Z,False,497137659.0,"@misscoded If you add only `WorkflowStep` to the top-level, I think it's acceptable as the class is part of the public APIs of the `App` class. I want to mention the same about `AsyncWorkflowStep` in `slack_bolt.async_app`.",True,False
slackapi/bolt-python/97/pulls/slackapi/bolt-python/97,2020-09-30T01:27:09Z,False,497193147.0,"We've agreed that adding `WorkflowStep` to the top-level breaks an existing pattern, so for now, we will choose not to do so.",True,False
opencollective/opencollective-frontend/3841/pulls/opencollective/opencollective-frontend/3841,2020-04-01T03:15:57Z,False,607003112.0,"Your [Render](https://render.com) PR Server URL is https://oc-styleguide-pr-3841.onrender.com.

Follow its progress at https://dashboard.render.com/static/srv-bq20er88atna49i9fbgg.",True,False
opencollective/opencollective-frontend/3841/pulls/opencollective/opencollective-frontend/3841,2020-04-01T03:15:58Z,False,607003115.0,"
This pull request is being automatically deployed with ZEIT Now ([learn more](https://zeit.ink/github-learn-more)).
To see the status of your deployment, click below or on the icon next to each commit.

  🔍 Inspect: https://zeit.co/opencollective/opencollective-frontend/ofwbmniunt
  ✅ Preview: *In Progress*
  	",True,False
allenai/ai2thor/363/pulls/allenai/ai2thor/363,2020-03-02T21:07:48Z,False,593622106.0,Updated comment: can you change your print statements for depreciation to be warnings using the warnings module?,True,False
allenai/ai2thor/363/pulls/allenai/ai2thor/363,2020-03-02T21:40:46Z,False,593637258.0,done,True,False
allenai/ai2thor/363/pulls/allenai/ai2thor/363,2020-03-02T21:59:47Z,False,593645078.0,tested locally merging,True,False
codechrysalis/algorithms-meetup/4/pulls/codechrysalis/algorithms-meetup/4,2018-03-28T00:28:43Z,False,376719202.0,"Yay THANK YOU!! Omg, this is the second pull request someone has made EVER.",True,False
codechrysalis/algorithms-meetup/4/pulls/codechrysalis/algorithms-meetup/4,2018-03-28T00:46:03Z,False,177612899.0,"I don't understand this change. The instruction says that it has to start in the top-left corner.

You could add an advanced portion?",True,False
codechrysalis/algorithms-meetup/4/pulls/codechrysalis/algorithms-meetup/4,2018-03-28T06:07:16Z,False,177646061.0,"Ups, I guess I should read the instructions better. In that case never mind the pull request.

But starting up there makes it too easy ;-). Guess I wrote too much code then :D.",True,False
codechrysalis/algorithms-meetup/4/pulls/codechrysalis/algorithms-meetup/4,2018-03-28T06:08:08Z,False,177646145.0,You can add in an advanced section for it! 🌸 ,True,False
codechrysalis/algorithms-meetup/4/pulls/codechrysalis/algorithms-meetup/4,2018-03-28T06:11:11Z,False,177646453.0,"Nono, totally fine. I think having it only from the left top makes it simpler. The hard part of the algorithm is not the part from having it able to start anywhere. It only adds one simple loop (on bruteforce at least. not sure if that would make a bigger difference for better algorithms).

So leaving it like it is is fine I think.",True,False
jquery/jquery/3569/pulls/jquery/jquery/3569,2017-03-15T15:32:55Z,False,286779860.0,"@mgol, thanks for your PR! By analyzing the history of the files in this pull request, we identified @dmethvin, @markelog and @mikesherov to be potential reviewers.",True,False
jquery/jquery/3569/pulls/jquery/jquery/3569,2017-03-15T16:24:41Z,False,286797091.0,@mgol Were you thinking you'd like to get this into 3.2?,True,False
jquery/jquery/3569/pulls/jquery/jquery/3569,2017-03-15T16:27:59Z,False,286798160.0,It was done only for firefox? Good catch then! I think we should deprecate it if that's the case,True,False
jquery/jquery/3569/pulls/jquery/jquery/3569,2017-03-15T17:28:38Z,False,286818206.0,"@timmywil It doesn't matter; if it got enough LGTMs then fine but if not it may wait. It doesn't cause any observable difference for jQuery users.

> It was done only for firefox? Good catch then! I think we should deprecate it if that's the case
>  👍 1

For Firefox but in jQuery 1.x also for IE <9 as they use `styleFloat`: https://github.com/jquery/jquery/blob/1.12-stable/src/css.js#L260-L266",True,False
ng-seed/universal/174/pulls/ng-seed/universal/174,2017-10-13T16:22:46Z,False,336500433.0,"# [Codecov](https://codecov.io/gh/ng-seed/universal/pull/174?src=pr&el=h1) Report
> Merging [#174](https://codecov.io/gh/ng-seed/universal/pull/174?src=pr&el=desc) into [master](https://codecov.io/gh/ng-seed/universal/commit/e041c6b729405bf80bbc28519e1135855d6064f4?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/ng-seed/universal/pull/174/graphs/tree.svg?height=150&width=650&token=t3c2bs0dMg&src=pr)](https://codecov.io/gh/ng-seed/universal/pull/174?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master     #174   +/-   ##
=======================================
  Coverage   76.66%   76.66%           
=======================================
  Files          22       22           
  Lines         270      270           
  Branches       44       44           
=======================================
  Hits          207      207           
  Misses         63       63
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/ng-seed/universal/pull/174?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/ng-seed/universal/pull/174?src=pr&el=footer). Last update [e041c6b...d6fad50](https://codecov.io/gh/ng-seed/universal/pull/174?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
samrobbins85/dns-comparison/3/pulls/samrobbins85/dns-comparison/3,2020-07-27T19:33:48Z,False,664595292.0,"
This pull request is being automatically deployed with Vercel ([learn more](https://vercel.link/github-learn-more)).
To see the status of your deployment, click below or on the icon next to each commit.

  🔍 Inspect: https://vercel.com/samrobbins/quad9-compare/r6lsdos1a
  ✅ Preview: https://quad9-compare-git-dependabot-npmandyarneslint-plugin-react-7204.samrobbins1.vercel.app
  	",True,False
andersonshatch/beerbods-scraper/36/pulls/andersonshatch/beerbods-scraper/36,2019-04-09T05:21:36Z,False,481106281.0,Superseded by #37.,True,False
texastribune/queso-ui/289/pulls/texastribune/queso-ui/289,2020-12-07T19:46:43Z,False,740139839.0,"Note: This will introduce this warning for `npm run lint` now. I say NBD tho.
```sh
=============

WARNING: You are currently running a version of TypeScript which is not officially supported by @typescript-eslint/typescript-estree.

You may find that it works just fine, or you may not.

SUPPORTED TYPESCRIPT VERSIONS: >=3.3.1 <4.1.0

YOUR TYPESCRIPT VERSION: 4.1.2

Please only submit bug reports when using the officially supported version.

=============
```",True,False
jessestuart/jesses.io/361/pulls/jessestuart/jesses.io/361,2018-03-30T10:30:35Z,False,377498017.0,"Deploy preview for *jessestuart* ready!

Built with commit 5d8ea527541bd1bd915a0a173bef9b519a22b796

https://deploy-preview-361--jessestuart.netlify.com",True,False
jessestuart/jesses.io/361/pulls/jessestuart/jesses.io/361,2018-03-30T10:35:17Z,False,377498635.0,"# [Codecov](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361?src=pr&el=h1) Report
> Merging [#361](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361?src=pr&el=desc) into [master](https://codecov.io/gh/jessestuart/jessestuart.com/commit/7b7ab846a406a248a760b6b9d799c2b6c9e9abf2?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361/graphs/tree.svg?width=650&height=150&src=pr&token=d5XoThUqwv)](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master     #361   +/-   ##
=======================================
  Coverage   98.64%   98.64%           
=======================================
  Files          65       65           
  Lines         222      222           
  Branches        5        5           
=======================================
  Hits          219      219           
  Misses          3        3
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361?src=pr&el=footer). Last update [7b7ab84...5d8ea52](https://codecov.io/gh/jessestuart/jessestuart.com/pull/361?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
jessestuart/jesses.io/361/pulls/jessestuart/jesses.io/361,2018-03-31T00:55:34Z,False,377654009.0,"Looks like react is up-to-date now, so this is no longer needed.",True,False
yasyf/vc/605/pulls/yasyf/vc/605,2018-05-09T10:16:47Z,False,387692675.0,Superseded by #629.,True,False
jamesramsay/hercule/290/pulls/jamesramsay/hercule/290,2016-09-16T15:44:57Z,False,247634990.0,"## [Current coverage](https://codecov.io/gh/jamesramsay/hercule/pull/290?src=pr) is 41.23% (diff: 100%)

> No coverage report found for **master** at aa74fec.
> 
> Powered by [Codecov](https://codecov.io?src=pr). Last update [aa74fec...8166b11](https://codecov.io/gh/jamesramsay/hercule/compare/aa74fec411e1b4bd362a62a3f4de91f6a11065bb...8166b118ba37c3fbf9ba1658da42dd4aa3f3f2f8?src=pr)
",True,False
ben-eb/remark-word-wrap/43/pulls/ben-eb/remark-word-wrap/43,2017-01-19T00:51:54Z,False,273649582.0,"
[![Coverage Status](https://coveralls.io/builds/9737780/badge)](https://coveralls.io/builds/9737780)

Coverage remained the same at 100.0% when pulling **327e61505cd7f34042a43d8b5a37aba187f83f6d on greenkeeper-eslint-plugin-babel-4.0.1** into **84c4cbca9e026ff21f051f1683426606e9aceef4 on master**.
",True,False
opsdroid/opsdroid/622/pulls/opsdroid/opsdroid/622,2018-09-02T07:20:28Z,False,417910500.0,Closing this in favor of #626,True,False
learndesk/backend/10/pulls/learndesk/backend/10,2019-06-27T10:15:44Z,False,506286016.0,"Looks like these dependencies are up-to-date now, so this is no longer needed.",True,False
RubenGeo/121-platform/25/pulls/RubenGeo/121-platform/25,2020-10-05T05:38:17Z,False,703407700.0,Superseded by #31.,True,False
pi-hole/pi-hole/2131/pulls/pi-hole/pi-hole/2131,2018-04-19T18:41:56Z,False,382839853.0,"Hi there, thanks for the submission... and good catch!

However I'm going to have to decline this PR, citing the [Technical Requirements](https://github.com/pi-hole/pi-hole/blob/master/CONTRIBUTING.md#technical-requirements) section of the contributors guide (which you have indicated you have read... 😉)

Please check the `development` branch, to make sure this has not already been fixed there, and if not.. resubmit based on that branch, to that branch. Cheers",True,False
chameleon-system/chameleon-base/295/pulls/chameleon-system/chameleon-base/295,2019-03-28T14:19:06Z,False,270025320.0,Doesn't this field (still) have the wrong type? Properties if I remember correctly. There should be a ticket / PR for this somewhere.,True,False
chameleon-system/chameleon-base/295/pulls/chameleon-system/chameleon-base/295,2019-03-28T14:23:35Z,False,270027693.0,"What was this doing?

(It's not deprecated?)",True,False
chameleon-system/chameleon-base/295/pulls/chameleon-system/chameleon-base/295,2019-03-28T14:28:36Z,False,270030186.0,"The type is correct, it's just the field class that needs to be removed so that the default class is used - this is done below in line 13.",True,False
chameleon-system/chameleon-base/295/pulls/chameleon-system/chameleon-base/295,2019-03-28T14:31:42Z,False,270031872.0,"The pass replaced a class in a service as soon as the bundle was installed. This is no longer required, as the class from this bundle is now the default (defined as a service in services.xml, configured in the bundle extension class).

As written above, there were some classes for which the @deprecated annotation was forgotten - we need to decide if we remove those (I'd say it's OK).",True,False
jricardo27/vue-django/35/pulls/jricardo27/vue-django/35,2017-09-06T12:10:11Z,False,327463640.0,Closing this in favor of #36,True,False
octangroup/german-tech-network/190/pulls/octangroup/german-tech-network/190,2020-12-17T18:04:34Z,False,747604642.0,Closed in favor of #195.,True,False
vangyong/java-learn/1/pulls/vangyong/java-learn/1,2020-05-07T05:36:29Z,False,625039278.0,"Looks like io.netty:netty-all is no longer a dependency, so this is no longer needed.",True,False
everypolitician/everypolitician-data/92476/pulls/everypolitician/everypolitician-data/92476,2018-05-05T06:33:55Z,False,386783813.0,"

Summary of changes in `data/Philippines/House/ep-popolo-v1.0.json`:

## People

### Added


No people added


### Removed


No people removed


### Name Changes



- `d40fe5dd-00f7-44fc-ad60-10df485c9345`: Campos, Luis Jose Angel Jr. N. → Campos, Luis Jr. N.



### Additional Name Changes



- `d40fe5dd-00f7-44fc-ad60-10df485c9345` (Campos, Luis Jose Angel Jr. N.): Removed: Campos, Luis Jose Angel Jr. N.. Added: Campos, Luis Jr. N..



### Wikidata Changes


No changes


## Organizations

### Added


No organizations added


### Removed


No organizations removed


## Memberships

### Added

No memberships added


### Removed

No memberships removed
















",True,False
everypolitician/everypolitician-data/92476/pulls/everypolitician/everypolitician-data/92476,2018-05-06T05:43:41Z,False,386855852.0,This Pull Request has been superseded by #92682,True,False
dansnyk/goof-heroku/22/pulls/dansnyk/goof-heroku/22,2019-06-13T09:15:12Z,False,501620954.0,Superseded by #23.,True,False
jsdelivr/jsdelivr/10976/pulls/jsdelivr/jsdelivr/10976,2016-04-11T15:04:23Z,False,208389696.0,"It looks like you want to contribute to `jsdelivr/jsdelivr`, @jsdelivrbot, however there seems to be some issues with your pull request. See [contributing](https://github.com/jsdelivr/jsdelivr/blob/master/CONTRIBUTING.md) for help amending your PR...
- Might be nothing but I have some concerns about the files in your submission...  
  - Is lodash.min.js (4.10.0) properly minimized?

---

<sup>Thanks again for contributing.. If you think this review was wrong/unfair/etc. submit a bug on [the bot's repo](https://github.com/jsdelivr/bot)</sup>  
_Favor focus over features._
",True,False
everypolitician/everypolitician-data/67135/pulls/everypolitician/everypolitician-data/67135,2017-12-08T16:50:06Z,False,350312322.0,"

Summary of changes in `data/Finland/Eduskunta/ep-popolo-v1.0.json`:

## People

### Added


No people added


### Removed


No people removed


### Name Changes


No name changes


### Additional Name Changes



- `1ec1193d-3a91-4b79-9f40-9eef915cb7db` (Anneli Jäätteenmäki): Added: Anneli Jäätteenmäkiová.



### Wikidata Changes


No changes


## Organizations

### Added


No organizations added


### Removed


No organizations removed


## Memberships

### Added

No memberships added


### Removed

No memberships removed
















",True,False
everypolitician/everypolitician-data/67135/pulls/everypolitician/everypolitician-data/67135,2017-12-09T18:08:26Z,False,350494946.0,This Pull Request has been superseded by #67386,True,False
TomMD/flink/129/pulls/TomMD/flink/129,2019-06-12T00:37:17Z,False,501075183.0,"Muse Error:
Muse was unable to use your project's build system to produce a compilation database. Please see the below log and muse's repoistory configuration documentation at https://docs.muse.dev

<details><summary>Console Log</summary>
<p>

```
SUCCESS [  8.728 s]
[INFO] flink-ml 1.9-SNAPSHOT .............................. SUCCESS [ 30.924 s]
[INFO] flink-ml-uber 1.9-SNAPSHOT ......................... SUCCESS [  3.080 s]
[INFO] flink-table-uber 1.9-SNAPSHOT ...................... SUCCESS [  1.750 s]
[INFO] flink-sql-client 1.9-SNAPSHOT ...................... SUCCESS [  2.788 s]
[INFO] flink-python 1.9-SNAPSHOT .......................... SUCCESS [  0.700 s]
[INFO] flink-scala-shell 1.9-SNAPSHOT ..................... SUCCESS [  8.843 s]
[INFO] flink-dist 1.9-SNAPSHOT ............................ SUCCESS [ 14.158 s]
[INFO] flink-end-to-end-tests-common 1.9-SNAPSHOT ......... SUCCESS [  0.348 s]
[INFO] flink-metrics-availability-test 1.9-SNAPSHOT ....... SUCCESS [  0.176 s]
[INFO] flink-metrics-reporter-prometheus-test 1.9-SNAPSHOT  SUCCESS [  0.131 s]
[INFO] flink-heavy-deployment-stress-test 1.9-SNAPSHOT .... SUCCESS [  5.849 s]
[INFO] flink-streaming-kafka-test-base 1.9-SNAPSHOT ....... SUCCESS [  0.229 s]
[INFO] flink-streaming-kafka-test 1.9-SNAPSHOT ............ SUCCESS [  5.860 s]
[INFO] flink-streaming-kafka011-test 1.9-SNAPSHOT ......... SUCCESS [  5.222 s]
[INFO] flink-streaming-kafka010-test 1.9-SNAPSHOT ......... SUCCESS [  5.177 s]
[INFO] flink-plugins-test 1.9-SNAPSHOT .................... SUCCESS [  0.080 s]
[INFO] flink-table-runtime-blink 1.9-SNAPSHOT ............. SUCCESS [  3.488 s]
[INFO] flink-sql-parser 1.9-SNAPSHOT ...................... SUCCESS [  5.910 s]
[INFO] flink-table-planner-blink 1.9-SNAPSHOT ............. SUCCESS [01:31 min]
[INFO] flink-contrib 1.9-SNAPSHOT ......................... SUCCESS [  0.055 s]
[INFO] flink-connector-wikiedits 1.9-SNAPSHOT ............. SUCCESS [  0.363 s]
[INFO] flink-yarn-tests 1.9-SNAPSHOT ...................... SUCCESS [  4.052 s]
[INFO] flink-fs-tests 1.9-SNAPSHOT ........................ SUCCESS [  0.420 s]
[INFO] flink-docs 1.9-SNAPSHOT ............................ SUCCESS [  0.622 s]
[INFO] flink-ml-parent 1.9-SNAPSHOT ....................... SUCCESS [  0.053 s]
[INFO] flink-ml-api 1.9-SNAPSHOT .......................... SUCCESS [  1.094 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  17:08 min
[INFO] Finished at: 2019-06-12T00:37:10Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal io.musedev.maven.compdb:musecompdb-maven-plugin:1.0-SNAPSHOT:readcompdb (default-cli) on project flink-parent: Execution default-cli of goal io.musedev.maven.compdb:musecompdb-maven-plugin:1.0-SNAPSHOT:readcompdb failed. NullPointerException -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :flink-parent
---ERR---
log4j:WARN No appenders could be found for logger (freemarker.cache).
log4j:WARN Please initialize the log4j system properly.
Warning: Lookahead adequacy checking not being performed since option LOOKAHEAD is more than 1.  Set option FORCE_LA_CHECK to true to force checking.
---CMD---
CreateProcess {cmdspec = RawCommand ""mvn"" [""clean"",""package"",""-B"",""-Dmdep.pathSeparator=:"",""-Dmdep.outputProperty=maven.compile.classpath"",""-DskipTests"",""dependency:build-classpath"",""io.musedev.maven.compdb:musecompdb-maven-plugin:1.0-SNAPSHOT:readcompdb""], cwd = Just ""/tmp/analyzing-84954899ab7608fa"", env = Nothing, std_in = Inherit, std_out = Inherit, std_err = Inherit, close_fds = False, create_group = False, delegate_ctlc = False, detach_console = False, create_new_console = False, new_session = False, child_group = Nothing, child_user = Nothing, use_process_jobs = False}

```

</p>
</details>

",True,False
TomMD/flink/129/pulls/TomMD/flink/129,2019-06-12T00:37:18Z,False,501075186.0,"Muse Error:
Muse was unable to use your project's build system to produce a compilation database. Please see the below log and muse's repoistory configuration documentation at https://docs.muse.dev

<details><summary>Console Log</summary>
<p>

```
SUCCESS [  8.728 s]
[INFO] flink-ml 1.9-SNAPSHOT .............................. SUCCESS [ 30.924 s]
[INFO] flink-ml-uber 1.9-SNAPSHOT ......................... SUCCESS [  3.080 s]
[INFO] flink-table-uber 1.9-SNAPSHOT ...................... SUCCESS [  1.750 s]
[INFO] flink-sql-client 1.9-SNAPSHOT ...................... SUCCESS [  2.788 s]
[INFO] flink-python 1.9-SNAPSHOT .......................... SUCCESS [  0.700 s]
[INFO] flink-scala-shell 1.9-SNAPSHOT ..................... SUCCESS [  8.843 s]
[INFO] flink-dist 1.9-SNAPSHOT ............................ SUCCESS [ 14.158 s]
[INFO] flink-end-to-end-tests-common 1.9-SNAPSHOT ......... SUCCESS [  0.348 s]
[INFO] flink-metrics-availability-test 1.9-SNAPSHOT ....... SUCCESS [  0.176 s]
[INFO] flink-metrics-reporter-prometheus-test 1.9-SNAPSHOT  SUCCESS [  0.131 s]
[INFO] flink-heavy-deployment-stress-test 1.9-SNAPSHOT .... SUCCESS [  5.849 s]
[INFO] flink-streaming-kafka-test-base 1.9-SNAPSHOT ....... SUCCESS [  0.229 s]
[INFO] flink-streaming-kafka-test 1.9-SNAPSHOT ............ SUCCESS [  5.860 s]
[INFO] flink-streaming-kafka011-test 1.9-SNAPSHOT ......... SUCCESS [  5.222 s]
[INFO] flink-streaming-kafka010-test 1.9-SNAPSHOT ......... SUCCESS [  5.177 s]
[INFO] flink-plugins-test 1.9-SNAPSHOT .................... SUCCESS [  0.080 s]
[INFO] flink-table-runtime-blink 1.9-SNAPSHOT ............. SUCCESS [  3.488 s]
[INFO] flink-sql-parser 1.9-SNAPSHOT ...................... SUCCESS [  5.910 s]
[INFO] flink-table-planner-blink 1.9-SNAPSHOT ............. SUCCESS [01:31 min]
[INFO] flink-contrib 1.9-SNAPSHOT ......................... SUCCESS [  0.055 s]
[INFO] flink-connector-wikiedits 1.9-SNAPSHOT ............. SUCCESS [  0.363 s]
[INFO] flink-yarn-tests 1.9-SNAPSHOT ...................... SUCCESS [  4.052 s]
[INFO] flink-fs-tests 1.9-SNAPSHOT ........................ SUCCESS [  0.420 s]
[INFO] flink-docs 1.9-SNAPSHOT ............................ SUCCESS [  0.622 s]
[INFO] flink-ml-parent 1.9-SNAPSHOT ....................... SUCCESS [  0.053 s]
[INFO] flink-ml-api 1.9-SNAPSHOT .......................... SUCCESS [  1.094 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  17:08 min
[INFO] Finished at: 2019-06-12T00:37:10Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal io.musedev.maven.compdb:musecompdb-maven-plugin:1.0-SNAPSHOT:readcompdb (default-cli) on project flink-parent: Execution default-cli of goal io.musedev.maven.compdb:musecompdb-maven-plugin:1.0-SNAPSHOT:readcompdb failed. NullPointerException -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :flink-parent
---ERR---
log4j:WARN No appenders could be found for logger (freemarker.cache).
log4j:WARN Please initialize the log4j system properly.
Warning: Lookahead adequacy checking not being performed since option LOOKAHEAD is more than 1.  Set option FORCE_LA_CHECK to true to force checking.
---CMD---
CreateProcess {cmdspec = RawCommand ""mvn"" [""clean"",""package"",""-B"",""-Dmdep.pathSeparator=:"",""-Dmdep.outputProperty=maven.compile.classpath"",""-DskipTests"",""dependency:build-classpath"",""io.musedev.maven.compdb:musecompdb-maven-plugin:1.0-SNAPSHOT:readcompdb""], cwd = Just ""/tmp/analyzing-84954899ab7608fa"", env = Nothing, std_in = Inherit, std_out = Inherit, std_err = Inherit, close_fds = False, create_group = False, delegate_ctlc = False, detach_console = False, create_new_console = False, new_session = False, child_group = Nothing, child_user = Nothing, use_process_jobs = False}

```

</p>
</details>

",True,False
TomMD/flink/129/pulls/TomMD/flink/129,2019-06-12T00:37:19Z,False,501075188.0,"### Muse Analysis Complete ###

Analysis tools: [ Infer, ErrorProne_JDK8 ] run on commits [ 77ababdd .. c104dafd ]

",True,False
Homebrew/homebrew-core/39584/pulls/Homebrew/homebrew-core/39584,2019-06-07T06:25:58Z,False,499772537.0,Thanks @dalance! Without contributions like yours it'd be impossible to keep homebrew going! 👍 🎉,True,False
Homebrew/homebrew-core/39584/pulls/Homebrew/homebrew-core/39584,2019-06-07T11:49:06Z,False,499855506.0,@brewtestbot test this please!,True,False
aksonov/react-native-experimental-navigation/6/pulls/aksonov/react-native-experimental-navigation/6,2016-09-12T07:31:00Z,False,246269577.0,"@aksonov  ??? am i created PR to the wrong repo?
",True,False
aksonov/react-native-experimental-navigation/6/pulls/aksonov/react-native-experimental-navigation/6,2017-10-19T05:08:06Z,False,337800783.0,Lol,True,False
elstgav/projecthub/121/pulls/elstgav/projecthub/121,2020-12-14T21:24:04Z,False,744719423.0,@dependabot merge,True,False
vsevolod/clickhouse-rails/13/pulls/vsevolod/clickhouse-rails/13,2020-06-25T06:18:53Z,False,649247198.0,"# [Codecov](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13?src=pr&el=h1) Report
> Merging [#13](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13?src=pr&el=desc) into [master](https://codecov.io/gh/vsevolod/clickhouse-rails/commit/eeeeeb428cb9a5560d41897dff36e8884c1b9b5b&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13/graphs/tree.svg?width=650&height=150&src=pr&token=v0Ss9v9xaZ)](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master      #13   +/-   ##
=======================================
  Coverage   96.89%   96.89%           
=======================================
  Files          15       15           
  Lines         322      322           
=======================================
  Hits          312      312           
  Misses         10       10           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13?src=pr&el=footer). Last update [eeeeeb4...6a3ead1](https://codecov.io/gh/vsevolod/clickhouse-rails/pull/13?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
yeagmeistr/heroku-buildpack-nodejs/20/pulls/yeagmeistr/heroku-buildpack-nodejs/20,2020-04-28T11:15:06Z,False,620541708.0,Superseded by #21.,True,False
ceph/ceph/24889/pulls/ceph/ceph/24889,2018-11-02T01:40:18Z,False,435243695.0,retest this please,True,False
ceph/ceph/24889/pulls/ceph/ceph/24889,2018-11-02T19:51:32Z,False,435489965.0,@neha-ojha This backport doesn't fix the problem seen which is getting RemoteReservationRejected AFTER getting RecoveryDone.  It might benefit to keep this commit.,True,False
ceph/ceph/24889/pulls/ceph/ceph/24889,2018-11-02T21:49:35Z,False,435519490.0,"The problem is caused by ceph/ceph#23493.  I'll look into why this would be, I assume, appropriate in master.",True,False
ceph/ceph/24889/pulls/ceph/ceph/24889,2018-11-03T21:38:07Z,False,435622828.0,http://pulpito.ceph.com/dzafman-2018-11-02_19:56:50-rados-wip-zafman-luminous-distro-basic-smithi/,True,False
ceph/ceph/24889/pulls/ceph/ceph/24889,2018-11-05T22:19:09Z,False,436056967.0,"The actual fixed only required ceph/ceph#24902, so closing this.",True,False
qmk/qmk_firmware/5370/pulls/qmk/qmk_firmware/5370,2019-03-11T23:53:11Z,False,471787560.0,"Travis CI errors are unrelated to this change (community layout issues).

Thanks! ",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-16T11:56:34Z,False,430209097.0,/botio unittest,True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-16T11:56:35Z,False,430209104.0,"#### From: Bot.io (Linux m4)

----

# Received

Command **cmd_unittest** from @Snuffleupagus received. Current queue size: 0

Live output at: http://54.67.70.0:8877/24d5dee50de307f/output.txt",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-16T11:56:35Z,False,430209106.0,"#### From: Bot.io (Windows)

----

# Received

Command **cmd_unittest** from @Snuffleupagus received. Current queue size: 0

Live output at: http://54.215.176.217:8877/8c7550406b1b784/output.txt",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-16T12:00:33Z,False,430210216.0,"#### From: Bot.io (Linux m4)

----

# Success

Full output at http://54.67.70.0:8877/24d5dee50de307f/output.txt

Total script time: 3.97 mins

+ **Unit Tests:** Passed",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-16T12:02:03Z,False,430210603.0,"#### From: Bot.io (Windows)

----

# Success

Full output at http://54.215.176.217:8877/8c7550406b1b784/output.txt

Total script time: 5.46 mins

+ **Unit Tests:** Passed",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-18T09:18:11Z,False,430937111.0,/botio-linux preview,True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-18T09:18:12Z,False,430937120.0,"#### From: Bot.io (Linux m4)

----

# Received

Command **cmd_preview** from @Snuffleupagus received. Current queue size: 0

Live output at: http://54.67.70.0:8877/86982487df936c5/output.txt",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-18T09:21:11Z,False,430938070.0,"#### From: Bot.io (Linux m4)

----

# Success

Full output at http://54.67.70.0:8877/86982487df936c5/output.txt

Total script time: 2.96 mins

#### Published

+ Viewer: http://54.67.70.0:8877/86982487df936c5/web/viewer.html",True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-20T13:22:34Z,False,431581746.0,I'm fine with this since I think consistency is important for the API. Thanks!,True,False
mozilla/pdf.js/10161/pulls/mozilla/pdf.js/10161,2018-10-16T11:55:55Z,False,225507182.0,"While not relevant to the rest of the patch, the unnecessary `if` statement and superfluous line-breaks were annoying me :-)",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-13T16:51:13Z,False,120991518.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4920/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-13T17:11:28Z,False,120995785.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4922/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-14T09:03:42Z,False,121173232.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4940/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-14T09:05:58Z,False,121173572.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4941/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-14T13:21:10Z,False,121235996.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4958/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-14T14:29:07Z,False,121255053.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4964/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-14T15:21:20Z,False,121280500.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4969/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-14T16:44:01Z,False,121303846.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/4973/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-15T08:47:34Z,False,121533122.0,":+1:  nice!
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-15T15:01:23Z,False,121644363.0,"Frontend tests were OK :+1: ([details](http://clinker.cartodb.net/jenkins/job/CartoDB-PR-testing/5002/))
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-15T08:45:19Z,False,34657753.0,"being lazy to check, that does `formatter: 'b'` do? (just curiosity)
",True,False
CartoDB/cartodb/4427/pulls/CartoDB/cartodb/4427,2015-07-15T09:29:27Z,False,34661028.0,"`formatter` is a ""polysemic"" argument :(. For instance it contains `{street_column_name} {city_column_name} SomeCountry` for the hires geocoder but just `country_name_column` for admin regions geocoding. It's been like that for ages.

In the context of that test, not really interested in launching the actual geocoding but making sure before it is launched certain preconditions are met.
",True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-24T15:26:19Z,False,391756293.0,**DO NOT MERGE YET** We need to get Apache Infra team to migrate the repo to gitbox before we can actually use this.,True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-24T16:05:00Z,False,391769983.0,"# [Codecov](https://codecov.io/gh/apache/incubator-airflow/pull/3413?src=pr&el=h1) Report
> Merging [#3413](https://codecov.io/gh/apache/incubator-airflow/pull/3413?src=pr&el=desc) into [master](https://codecov.io/gh/apache/incubator-airflow/commit/dfa7b26ddaca80ee8fd9915ee9f6eac50fac77f6?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/apache/incubator-airflow/pull/3413/graphs/tree.svg?height=150&width=650&token=WdLKlKHOAU&src=pr)](https://codecov.io/gh/apache/incubator-airflow/pull/3413?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #3413   +/-   ##
=======================================
  Coverage   77.51%   77.51%           
=======================================
  Files         205      205           
  Lines       15751    15751           
=======================================
  Hits        12210    12210           
  Misses       3541     3541
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/apache/incubator-airflow/pull/3413?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/apache/incubator-airflow/pull/3413?src=pr&el=footer). Last update [dfa7b26...d3793c0](https://codecov.io/gh/apache/incubator-airflow/pull/3413?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-25T08:43:31Z,False,391984893.0,"@ashb did you contact the infra team? Edit: Ah, I missed your mail. Thanks",True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-25T08:44:38Z,False,391985145.0,Not yet - I wanted to get a few eyes on this PR first.,True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-31T11:07:07Z,False,393495955.0,https://issues.apache.org/jira/browse/INFRA-16602 has now been opened asking the Infra team to migrate us.,True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-08-01T20:14:45Z,False,409707094.0,@ashb Has anyone tested this tool with this current change?,True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-25T21:24:24Z,False,191012669.0,wondering why we are removing this section?,True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-27T14:22:51Z,False,191078202.0,This variable was only used in a block that had `if merge_commits and False` as the conditional -- i.e. it was never run!,True,False
apache/airflow/3413/pulls/apache/airflow/3413,2018-05-29T17:05:32Z,False,191501438.0,"ah you are right! 😆 I see that in the case where the committer tried to merge an already merged PR it would be caught with ""Pull request {} is not mergeable in its current form..."" so should be fine to remove. thanks for clarifying",True,False
helpacket/backend/38/pulls/helpacket/backend/38,2020-05-12T05:16:13Z,False,627112760.0,"# [Codecov](https://codecov.io/gh/helpacket/backend/pull/38?src=pr&el=h1) Report
> Merging [#38](https://codecov.io/gh/helpacket/backend/pull/38?src=pr&el=desc) into [master](https://codecov.io/gh/helpacket/backend/commit/fb609a369f76cc46bd216fac440f2bf3d83d4c3b&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/helpacket/backend/pull/38/graphs/tree.svg?width=650&height=150&src=pr&token=sZkdGlzIc0)](https://codecov.io/gh/helpacket/backend/pull/38?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master      #38   +/-   ##
=======================================
  Coverage   53.07%   53.07%           
=======================================
  Files          47       47           
  Lines         390      390           
=======================================
  Hits          207      207           
  Misses        183      183           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/helpacket/backend/pull/38?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/helpacket/backend/pull/38?src=pr&el=footer). Last update [fb609a3...bf391d6](https://codecov.io/gh/helpacket/backend/pull/38?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
helpacket/backend/38/pulls/helpacket/backend/38,2020-05-13T05:15:37Z,False,627750967.0,Superseded by #39.,True,False
oclif/plugin-plugins/90/pulls/oclif/plugin-plugins/90,2020-02-14T23:40:47Z,False,586520895.0,"# [Codecov](https://codecov.io/gh/oclif/plugin-plugins/pull/90?src=pr&el=h1) Report
> Merging [#90](https://codecov.io/gh/oclif/plugin-plugins/pull/90?src=pr&el=desc) into [master](https://codecov.io/gh/oclif/plugin-plugins/commit/29376a1182384c7048eb6390e925f7ac615f576e&el=desc) will **not change** coverage by `%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/oclif/plugin-plugins/pull/90/graphs/tree.svg?width=650&height=150&src=pr&token=aY0rUlDqnW)](https://codecov.io/gh/oclif/plugin-plugins/pull/90?src=pr&el=tree)

```diff
@@          Coverage Diff           @@
##           master     #90   +/-   ##
======================================
  Coverage    0.00%   0.00%           
======================================
  Files           5       5           
  Lines          93      93           
  Branches       17      17           
======================================
  Misses         93      93           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/oclif/plugin-plugins/pull/90?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/oclif/plugin-plugins/pull/90?src=pr&el=footer). Last update [29376a1...f669408](https://codecov.io/gh/oclif/plugin-plugins/pull/90?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
scala/docs.scala-lang/609/pulls/scala/docs.scala-lang/609,2016-10-22T02:17:27Z,False,255501539.0,"Thanks for catching this! LGTM
",True,False
ava-project/ava-website/71/pulls/ava-project/ava-website/71,2017-12-25T13:23:13Z,False,353869371.0,Closing this in favor of #72,True,False
RTradeLtd/coredag/8/pulls/RTradeLtd/coredag/8,2020-02-19T18:58:38Z,False,588388693.0,"# [Codecov](https://codecov.io/gh/RTradeLtd/coredag/pull/8?src=pr&el=h1) Report
> Merging [#8](https://codecov.io/gh/RTradeLtd/coredag/pull/8?src=pr&el=desc) into [master](https://codecov.io/gh/RTradeLtd/coredag/commit/a47ae205f5f53e765d5c22d16cbe7fd860ea28ea?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/RTradeLtd/coredag/pull/8/graphs/tree.svg?width=650&token=Yx4ob9VgDp&height=150&src=pr)](https://codecov.io/gh/RTradeLtd/coredag/pull/8?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master       #8   +/-   ##
=======================================
  Coverage   64.71%   64.71%           
=======================================
  Files           4        4           
  Lines          68       68           
=======================================
  Hits           44       44           
  Misses         12       12           
  Partials       12       12
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/RTradeLtd/coredag/pull/8?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/RTradeLtd/coredag/pull/8?src=pr&el=footer). Last update [a47ae20...e467a35](https://codecov.io/gh/RTradeLtd/coredag/pull/8?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
dcos/dcos-cli/1458/pulls/dcos/dcos-cli/1458,2019-04-10T13:08:04Z,False,481683169.0,@mesosphere-ci run integration tests,True,False
OpenKMIP/PyKMIP/423/pulls/OpenKMIP/PyKMIP/423,2018-04-16T18:01:49Z,False,381695430.0,"# [Codecov](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=h1) Report
> Merging [#423](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=desc) into [master](https://codecov.io/gh/OpenKMIP/PyKMIP/commit/f1ccdf9c5a6a068dc25aae0936e68e9d21aa0a09?src=pr&el=desc) will **decrease** coverage by `0.01%`.
> The diff coverage is `84.21%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423/graphs/tree.svg?height=150&width=650&src=pr&token=I3nuNTkKjq)](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #423      +/-   ##
==========================================
- Coverage   95.09%   95.08%   -0.02%     
==========================================
  Files          75       75              
  Lines       12631    12649      +18     
==========================================
+ Hits        12012    12027      +15     
- Misses        619      622       +3
```


| [Impacted Files](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [kmip/services/server/engine.py](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423/diff?src=pr&el=tree#diff-a21pcC9zZXJ2aWNlcy9zZXJ2ZXIvZW5naW5lLnB5) | `99.67% <100%> (ø)` | :arrow_up: |
| [kmip/services/server/config.py](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423/diff?src=pr&el=tree#diff-a21pcC9zZXJ2aWNlcy9zZXJ2ZXIvY29uZmlnLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [kmip/services/server/server.py](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423/diff?src=pr&el=tree#diff-a21pcC9zZXJ2aWNlcy9zZXJ2ZXIvc2VydmVyLnB5) | `78.6% <40%> (-0.92%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=footer). Last update [f1ccdf9...2e6384a](https://codecov.io/gh/OpenKMIP/PyKMIP/pull/423?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,False
nexmo-community/click2call/24/pulls/nexmo-community/click2call/24,2017-08-27T01:04:00Z,False,325170546.0,Closing this in favor of #29,True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-04T18:02:26Z,False,244619207.0,"Tagging @QuincyLarson @hallaathrad @BerkeleyTrue for review of UX/UI changes.
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-04T18:07:27Z,False,244619470.0,"@eduardbcom updated the pull request.
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-04T18:08:36Z,False,244619559.0,"Just fixed indentations I haven't noticed before.
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-08T07:04:26Z,False,245511783.0,"@eduardbcom Thanks for submitting this PR.

Can you include screen shots of how this looks in other browsers and on Windows/Linux? I think we tried adding scroll bars in the past and it resulted in duplicate scroll bars so we ditched them. 

Also, I don't see an issue that this is referencing. Unless there are a lot of campers asking for this sort of UI element, it's probably not worth cluttering up our UI over.
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-26T06:20:34Z,False,249488066.0,"@eduardbcom is there any progress on this?
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-27T08:56:22Z,False,249806447.0,"Closing as stale 

@eduardbcom feel free to reopen this PR if you have any more progress
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-27T09:06:22Z,False,249808763.0,"@Bouncey @QuincyLarson Looks like this issue reproduces just on my screen. Have tested on wider screen and it works just fine. In the next time will check this out on several devices first..by the way, my solution does not duplicate scrollbar, so it will work just fine.

Many thanks for your time will continue study and contribute to FCC.
",True,False
freeCodeCamp/freeCodeCamp/10469/pulls/freeCodeCamp/freeCodeCamp/10469,2016-09-27T09:23:46Z,False,249812749.0,"@eduardbcom OK - what is your device's resolution? Thanks for raising this issue. We are not closed to the option of adding a scroll bar necessarily, but there are so many browsers, all of which interpret these differently, and significant cross browser and device testing would be necessary.
",True,False
spectrumtouch/lang_dynmcs/61/pulls/spectrumtouch/lang_dynmcs/61,2018-09-30T01:44:24Z,False,425687076.0,Closing this in favor of #80,True,False
Kickball/awesome-selfhosted/997/pulls/Kickball/awesome-selfhosted/997,2017-03-26T20:01:51Z,False,289310594.0,"Sorry, I am unable to find the syntax error which failed the build.",True,False
Kickball/awesome-selfhosted/997/pulls/Kickball/awesome-selfhosted/997,2017-03-29T15:20:31Z,False,290124224.0,"@iwhiz I've pushed some changes to the repo, please check them out.

The original problem that the automated check was complaining about was that the code in Source Code didn't have a capital C.",True,False
jricardo27/vue-django/573/pulls/jricardo27/vue-django/573,2019-02-23T12:44:23Z,False,466645479.0,Closing this in favor of #574,True,False
ri7nz/TokFractions/257/pulls/ri7nz/TokFractions/257,2020-10-22T04:13:15Z,False,714210890.0,"This pull request is being automatically deployed with Vercel ([learn more](https://vercel.link/github-learn-more)).  
To see the status of your deployment, click below or on the icon next to each commit.

🔍 Inspect: [https://vercel.com/ri7nz/tokfractions/mfe75sgjc](https://vercel.com/ri7nz/tokfractions/mfe75sgjc)  
✅ Preview: [https://tokfractions-git-dependabot-npmandyarnnextreact-and-re-442eb2.ri7nz.vercel.app](https://tokfractions-git-dependabot-npmandyarnnextreact-and-re-442eb2.ri7nz.vercel.app)

",True,False
ri7nz/TokFractions/257/pulls/ri7nz/TokFractions/257,2020-10-23T08:25:38Z,False,715166948.0,Superseded by #258.,True,False
blinkmobile/json-as-files.js/36/pulls/blinkmobile/json-as-files.js/36,2017-02-03T22:56:26Z,False,277385485.0,"@greenkeeperio-bot, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jokeyrhyme to be a potential reviewer.",True,False
hukurouo/susumeru/3/pulls/hukurouo/susumeru/3,2020-02-29T02:14:52Z,False,592816792.0,Superseded by #8.,True,False
nullart/freqtrade/210/pulls/nullart/freqtrade/210,2019-01-29T13:25:48Z,False,458538446.0,"## Pull Request Test Coverage Report for [Build 2663](https://coveralls.io/builds/21333671)

* **0** of **0**   changed or added relevant lines in **0** files are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage remained the same at ?**%**

---



|  Totals | [![Coverage Status](https://coveralls.io/builds/21333671/badge)](https://coveralls.io/builds/21333671) |
| :-- | --: |
| Change from base [Build 310](https://coveralls.io/builds/18556310): |  0.0% |
| Covered Lines: |  |
| Relevant Lines: | 0 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",True,False
nullart/freqtrade/210/pulls/nullart/freqtrade/210,2019-01-30T13:12:42Z,False,458938421.0,Closing this in favor of #211,True,False
satanTime/ngrx-graphql/62/pulls/satanTime/ngrx-graphql/62,2020-12-09T20:00:41Z,False,742014426.0,"Code Climate has analyzed commit cef69862 and detected **0 issues** on this pull request.

View more on [Code Climate](https://codeclimate.com/github/satanTime/ngrx-graphql/pull/62).
",True,False
satanTime/ngrx-graphql/62/pulls/satanTime/ngrx-graphql/62,2020-12-09T20:00:46Z,False,742014499.0,"Kudos, SonarCloud Quality Gate passed!

[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug.png' alt='Bug' width='16' height='16' />](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=BUG) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=BUG)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability.png' alt='Vulnerability' width='16' height='16' />](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=VULNERABILITY) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=VULNERABILITY)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot.png' alt='Security Hotspot' width='16' height='16' />](https://sonarcloud.io/project/security_hotspots?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=SECURITY_HOTSPOT) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/security_hotspots?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=SECURITY_HOTSPOT)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell.png' alt='Code Smell' width='16' height='16' />](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=CODE_SMELL) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=CODE_SMELL) [0 Code Smells](https://sonarcloud.io/project/issues?id=satanTime_ngrx-graphql&pullRequest=62&resolved=false&types=CODE_SMELL)

[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/NoCoverageInfo.png' alt='No Coverage information' width='16' height='16' />](https://sonarcloud.io/component_measures?id=satanTime_ngrx-graphql&pullRequest=62) No Coverage information  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/NoDuplicationInfo.png' alt='No Duplication information' width='16' height='16' />](https://sonarcloud.io/component_measures?id=satanTime_ngrx-graphql&pullRequest=62&metric=duplicated_lines_density&view=list) No Duplication information

",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-09-06T05:01:02Z,False,327375105.0,"## Version **2.15.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.15.1?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-10-10T02:59:43Z,False,335345730.0,"## Version **2.16.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.16.0?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-10-10T14:54:09Z,False,335499651.0,"## Version **2.16.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.16.1?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>⚡️🚀🐹</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@2.16.1</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@2.16.1</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v2.16.0...v2.16.1""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v2.16.0...v2.16.1""><code>ember addon</code> diff</a></li>
<li>No changes required</li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7369"">#7369</a> Fix issue with linting within an addon without an <code>app/</code> directory. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-10-11T15:30:35Z,False,335850490.0,"## Version **2.16.2** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.16.2?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-11-29T17:13:24Z,False,347930081.0,"## Version **2.17.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.17.0?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>Xmas preparation</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@2.17.0</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@2.17.0</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v2.16.2...v2.17.0""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v2.16.2...v2.17.0""><code>ember new</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7232"">#7232</a> don't compress responses with the x-no-compression response header <a href=""https://urls.greenkeeper.io/akatov"">@akatov</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7272"">#7272</a> Fixes <code>undefined</code> values in merged aliases <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7342"">#7342</a> Updating testem.js for the app blueprint <a href=""https://urls.greenkeeper.io/scalvert"">@scalvert</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7360"">#7360</a> ""server"" -&gt; ""serve"" in package.json blueprint <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7353"">#7353</a> remove ember-cli-shim warning <a href=""https://urls.greenkeeper.io/NullVoxPopuli"">@NullVoxPopuli</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7369"">#7369</a> Fix issue with linting within an addon without an <code>app/</code> directory. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7372"">#7372</a> Fix travis.yml in addon blueprint <a href=""https://urls.greenkeeper.io/simonihmig"">@simonihmig</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7377"">#7377</a> Invoke transform registeration before included hook is called. <a href=""https://urls.greenkeeper.io/kratiahuja"">@kratiahuja</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7378"">#7378</a> Ensure test-support and addon-test-support are linted. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7381"">#7381</a> Changes default Chrome remote debugging port. <a href=""https://urls.greenkeeper.io/Oreoz"">@Oreoz</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7409"">#7409</a> cherry pick <a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7382"" class=""issue-link js-issue-link"" data-error-text=""Failed to load issue title"" data-id=""265103157"" data-permission-text=""Issue title is private"" data-url=""https://github.com/ember-cli/ember-cli/issues/7382"">#7382</a> into beta <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7416"">#7416</a> Add support for Node 9. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7417"">#7417</a> Issue warning for Node 7. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7427"">#7427</a> Remove emoji alias <a href=""https://urls.greenkeeper.io/tristanpemble"">@tristanpemble</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7430"">#7430</a> ember-try: Add <code>useYarn</code> flag if necessary <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7436"">#7436</a> retire 2.8, introduce 2.16 <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7437"">#7437</a> Update to ember-cli-qunit@4.1.1. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7439"">#7439</a> Cherry pick <a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7432"" class=""issue-link js-issue-link"" data-error-text=""Failed to load issue title"" data-id=""273059794"" data-permission-text=""Issue title is private"" data-url=""https://github.com/ember-cli/ember-cli/issues/7432"">#7432</a> and <a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7435"" class=""issue-link js-issue-link"" data-error-text=""Failed to load issue title"" data-id=""273170029"" data-permission-text=""Issue title is private"" data-url=""https://github.com/ember-cli/ember-cli/issues/7435"">#7435</a> to release <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7449"">#7449</a> Update <code>ember-cli-shims</code> to v1.2.0 <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7460"">#7460</a> remove trailing comma from testem.js <a href=""https://urls.greenkeeper.io/ember-cli"">@ember-cli</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-12-11T18:57:25Z,False,350822083.0,"## Version **2.17.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.17.1?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2017-12-27T10:10:02Z,False,354089879.0,"## Version **2.17.2** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.17.2?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>Ho ho ho!</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@2.17.2</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@2.17.2</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v2.17.1...v2.17.2""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v2.17.1...v2.17.2""><code>ember addon</code> diff</a></li>
<li>No changes required</li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7489"">#7489</a> Fix regression with scoped package name mismatches <a href=""https://urls.greenkeeper.io/rwwagner90"">@rwwagner90</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7507"">#7507</a> Ensure testing honors config/environment settings. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7513"">#7513</a> fix alpha ordering in npmignore <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7516"">#7516</a> Fix <code>ember new --yarn</code> not using yarn <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-01-01T18:58:34Z,False,354669544.0,"## Version **2.18.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.18.0?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>Ná merye I turuhalmeri!</strong>

<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v2.17.2...v2.18.0""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v2.17.2...v2.18.0""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7489"">#7489</a> Fix regression with scoped package name mismatches <a href=""https://urls.greenkeeper.io/rwwagner90"">@rwwagner90</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7507"">#7507</a> Ensure testing honors config/environment settings. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7513"">#7513</a> fix alpha ordering in npmignore <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7516"">#7516</a> Fix <code>ember new --yarn</code> not using yarn <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7529"">#7529</a> Backport &amp; fixup linting changes. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7474"">#7474</a> Give plugins and extends their own lines <a href=""https://urls.greenkeeper.io/rwwagner90"">@rwwagner90</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7475"">#7475</a> don't treat strings as regex in insertIntoFile <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7477"">#7477</a> Restore <code>separator: '\n;'</code> to vendor JS concat <a href=""https://urls.greenkeeper.io/kellyselden/lenny"">@kellyselden/lenny</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7478"">#7478</a> Remove obsolete CONFIG_CACHING feature flag <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7481"">#7481</a> NpmInstallTask: <code>useYarn</code> from constructor args <a href=""https://urls.greenkeeper.io/lennyburdette"">@lennyburdette</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7395"">#7395</a> Make ""testdouble"" dependency optional in MockProcess class <a href=""https://urls.greenkeeper.io/ro0gr"">@ro0gr</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7382"">#7382</a> add option to not create file <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7385"">#7385</a> remove node 7 testing <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/6955"">#6955</a> Discover dependencies of npm-linked addons <a href=""https://urls.greenkeeper.io/ef4"">@ef4</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7164"">#7164</a> Fix generate command when both usePods option and --pod argument is used <a href=""https://urls.greenkeeper.io/emrekutlu"">@emrekutlu</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7428"">#7428</a> Fix bad recursion in ember-cli-shims detection <a href=""https://urls.greenkeeper.io/cibernox"">@cibernox</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7419"">#7419</a> Delete crossdomain.xml <a href=""https://urls.greenkeeper.io/sandstrom"">@sandstrom</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7424"">#7424</a> Adding documentation for experiments <a href=""https://urls.greenkeeper.io/sangm"">@sangm</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7414"">#7414</a> Fixes Project#hasDependencies to only check for dependencies instead … <a href=""https://urls.greenkeeper.io/MiguelMadero/mmadero"">@MiguelMadero/mmadero</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7406"">#7406</a> Remove livereload url from output <a href=""https://urls.greenkeeper.io/topaxi"">@topaxi</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7401"">#7401</a> Resolve node modules correctly <a href=""https://urls.greenkeeper.io/ef4"">@ef4</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7443"">#7443</a> Use <code>overrides</code> for a single <code>.eslintrc.js</code>. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7435"">#7435</a> add ember-try ignores to npmignore <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7432"">#7432</a> Avoid publishing massive temp folder leaked by ember-try <a href=""https://urls.greenkeeper.io/ef4"">@ef4</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7438"">#7438</a> skip uninstall if no matching package is installed <a href=""https://urls.greenkeeper.io/makepanic"">@makepanic</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7455"">#7455</a> Add eslint-plugin-ember to default linting config. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7456"">#7456</a> Use fs-extra's <code>ensureDir</code> to avoid race condition in <code>mk-tmp-dir-in</code>. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7457"">#7457</a> Avoid directly requiring <code>blueprints/app/files/package.json</code>. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-01-22T09:22:34Z,False,359366507.0,"## Version **2.18.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.18.1?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>நிலவெலி</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@2.18.1</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@2.18.1</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v2.18.0...v2.18.1""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v2.18.0...v2.18.1""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7566"">#7566</a> testem: Use <code>--no-sandbox</code> on TravisCI <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-02-02T10:55:48Z,False,362554971.0,"## Version **2.18.2** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-2.18.2?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-02-14T05:45:03Z,False,365502691.0,"## Version **3.0.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.0.0?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-03-17T02:20:43Z,False,373887509.0,"## Version **3.0.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.0.1?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-03-20T22:52:03Z,False,374784318.0,"## Version **3.0.2** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.0.2?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-04-10T15:57:32Z,False,380153564.0,"## Version **3.0.3** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.0.3?expand=1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-04-11T06:30:29Z,False,380342263.0,"## Version **3.1.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.1.0?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>Concrete and Gold</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@3.1.0</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@3.1.0</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.0.3...v3.1.0""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.0.3...v3.1.0""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7670"">#7670</a> Support serving wasm with application/wasm <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7683"">#7683</a> Revert ""EmberApp: Remove deprecated <code>contentFor()</code> hooks""</li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7691"">#7691</a> Add support for .npmrc for blueprints <a href=""https://urls.greenkeeper.io/thoov"">@thoov</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7694"">#7694</a> [BACKPORT release] Ensure config() is memoized</li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7719"">#7719</a> reorder ember-cli-build.js in blueprint <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7720"">#7720</a> assert no filters matched <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7721"">#7721</a> update eslint-plugin-node for addons</li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7728"">#7728</a> Passing defaultOptions to testem to prevent the cwd and config_dir set in testem.js from being ov<br>
erridden by ember-cli <a href=""https://urls.greenkeeper.io/arthirm"">@arthirm</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7732"">#7732</a> Merge pull request <a class=""issue-link js-issue-link"" data-error-text=""Failed to load issue title"" data-id=""310636558"" data-permission-text=""Issue title is private"" data-url=""https://github.com/ember-cli/ember-cli/issues/7728"" href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7728"">#7728</a> from arthirm/testem-bug-fix <a href=""https://urls.greenkeeper.io/arthirm"">@arthirm</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7736"">#7736</a> add addon-test-support/index.js to eslint glob bug mitigation <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-04-11T14:35:46Z,False,380475111.0,"## Version **3.1.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.1.1?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>I ticked that box myself</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@3.1.1</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@3.1.1</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.1.0...v3.1.1""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.1.0...v3.1.1""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7746"">#7746</a> Revert ""arthirm/testem-bug-fix"" <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-04-14T19:19:10Z,False,381353497.0,"## Version **3.1.2** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/greenkeeper%2Fember-cli-3.1.2?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>California is Cold</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@3.1.2</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@3.1.2</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.1.1...v3.1.2""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.1.1...v3.1.2""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7749"">#7749</a> remove trailing comma <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7752"">#7752</a> Fix test fixtures <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7759"">#7759</a> Ensure css is minified correctly <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-04-30T12:41:22Z,False,385387025.0,"## Version **3.1.3** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.1.3) 

<details>
<summary>Release Notes</summary>
<strong>Greenprints</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@3.1.3</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@3.1.3</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.1.2...v3.1.3""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.1.2...v3.1.3""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7769"">#7769</a> add blueprints to linting coverage <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7771"">#7771</a> forgot .eslintignore in MU <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7792"">#7792</a> Add node 10 to test matrix <a href=""https://urls.greenkeeper.io/stefanpenner"">@stefanpenner</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-05-04T20:28:18Z,False,386725721.0,"## Version **3.1.4** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.1.4) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-07-02T20:43:59Z,False,401928909.0,"## Version **3.2.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.2.0) 

<details>
<summary>Release Notes</summary>
<strong>Deliverance</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@3.2.0</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@3.2.0</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>ember init</code> -- This runs the new project blueprint on your projects directory. Please follow the prompts, and review all changes (tip: you can see a diff by pressing d). The most common source of upgrade pain is missing changes in this step.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.1.4...v3.2.0""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.1.4...v3.2.0""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7560"">#7560</a> Migrate to new format for mode specific arguments in testem config. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7621"">#7621</a> Take newer symlink-or-copy <a href=""https://urls.greenkeeper.io/ef4"">@ef4</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7698"">#7698</a> Update <code>ember-cli-qunit</code> dependency <a href=""https://urls.greenkeeper.io/CodingItWrong"">@CodingItWrong</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7809"">#7809</a> Do not attempt to compress server sent events. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7811"">#7811</a> replace TRAVIS with CI <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7833"">#7833</a> blueprints/addon: Add <code>yarn.lock</code> file to <code>.npmignore</code> <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7836"">#7836</a> tests: Increase timeout for linting tests <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7857"">#7857</a> Filter out blacklisted addons before calling included hook <a href=""https://urls.greenkeeper.io/dnachev"">@dnachev</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7880"">#7880</a> testem: Improve Chrome command line flags <a href=""https://urls.greenkeeper.io/stefanpenner"">@stefanpenner</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-07-17T03:01:40Z,False,405444462.0,"## Version **3.3.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.3.0) 

<details>
<summary>Release Notes</summary>
<strong>Believer</strong>

<h4>Setup</h4>
<p><code>npm install -g ember-cli@3.3.0</code> -- Install new global ember-cli</p>
<h4>Project Update</h4>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install --save-dev ember-cli@3.3.0</code> -- Update project's <code>package.json</code> to use latest version.</li>
<li><code>npm install</code> -- Reinstall NPM dependencies.</li>
<li><code>npm install -g ember-cli-update</code> -- Install <a href=""https://urls.greenkeeper.io/ember-cli/ember-cli-update/"">Ember CLI update tool</a> globally.</li>
<li><code>ember-cli-update</code> -- This will update your app or addon to the latest Ember CLI version. You will probably encounter merge conflicts, in which the default behavior is to let you resolve conflicts on your own. You can supply the --resolve-conflicts option to run your system's git merge tool if any conflicts are found.</li>
</ol>
<h4>Changelog</h4>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.2.0...v3.3.0""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.2.0...v3.3.0""><code>ember addon</code> diff</a></li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
</details>
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-09-06T01:49:47Z,False,418937272.0,"## Version **3.4.0** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.4.0) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-09-06T06:35:13Z,False,418981113.0,"## Version **3.4.1** just got published. 
[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.4.1) 
",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-09-12T14:56:13Z,False,420679590.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.4.2`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.4.2) 
 

<details>
<summary>Release Notes for something something sassy</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@NEW_VERSION_NUMBER</code> -- Install new global ember-cli</p>
<p>Project Update</p>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install -g ember-cli-update</code> -- Install Ember CLI update tool globally.</li>
<li>Run <code>ember-cli-update</code> - This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal <code>git</code> workflow.</li>
<li>Run <code>ember-cli-update --run-codemods</code> - This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>CHANGELOG</h2>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.4.1...v3.4.2""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.4.1...v3.4.2""><code>ember addon</code> diff</a></li>
<li>No changes required</li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8024"">#8024</a> [BUGFIX] Remove 2.12 scenario from travis.yml <a href=""https://urls.greenkeeper.io/cibernox"">@cibernox</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8033"">#8033</a> Restore <code>styles</code> behaviour <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8038"">#8038</a> Ensure livereload proxy is scoped to only live reload prefix. <a href=""https://urls.greenkeeper.io/ember-cli"">@ember-cli</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-09-20T23:09:12Z,False,423362963.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.4.3`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.4.3) 
 

<details>
<summary>Release Notes for Journey before Destination</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.4.3</code> -- Install new global ember-cli</p>
<p>Project Update</p>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install -g ember-cli-update</code> -- Install Ember CLI update tool globally.</li>
<li>Run <code>ember-cli-update</code> - This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal <code>git</code> workflow.</li>
<li>Run <code>ember-cli-update --run-codemods</code> - This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h3>CHANGELOG</h3>
<p>The following changes are required if you are upgrading from the previous<br>
version:</p>
<ul>
<li>Users
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.4.2...v3.4.3""><code>ember new</code> diff</a></li>
<li>Upgrade your project's ember-cli version - <a href=""https://ember-cli.com/user-guide/#upgrading"" rel=""nofollow"">docs</a></li>
</ul>
</li>
<li>Addon Developers
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.4.2...v3.4.3""><code>ember new</code> diff</a></li>
<li>No changes required</li>
</ul>
</li>
<li>Core Contributors
<ul>
<li>No changes required</li>
</ul>
</li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8044"">#8044</a> Fix livereload issues when SSL is enabled. <a href=""https://urls.greenkeeper.io/SparshithNR"">@SparshithNR</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8046"">#8046</a> Do not to fail to build if <code>tests</code> folder is not present <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8047"">#8047</a> Fix <code>app.import</code> transforms for tests <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8048"">#8048</a> Make sure app content always ""wins"" over addon content. <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8057"">#8057</a> Ensure livereload support does not break proxied websockets. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8058"">#8058</a> Tweak invalid / missing package log output to be more actionable <a href=""https://urls.greenkeeper.io/dcombslinkedin"">@dcombslinkedin</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-10-15T09:44:01Z,False,429777570.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.5.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.5.0) 
 

<details>
<summary>Release Notes for Hamsterdam</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@NEW_VERSION_NUMBER</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li>npm install -g ember-cli-update -- Install Ember CLI update tool globally.</li>
<li>Run <code>ember-cli-update</code> - This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>ember-cli-update --run-codemods</code> - This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8079"">#8079</a> add .template-lintrc.js to npmignore <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8083"">#8083</a> Catch InvalidNodeError for Broccoli 2.0 and fallback to broccoli-builder <a href=""https://urls.greenkeeper.io/oligriffiths"">@oligriffiths</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8117"">#8117</a> Do not ignore dotfiles in ESLint <a href=""https://urls.greenkeeper.io/Gaurav0"">@Gaurav0</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7365"">#7365</a> Migrate from ember-cli-qunit to ember-qunit. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8062"">#8062</a> Add <code>yarn.lock</code> to <code>.npmignore</code> <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8064"">#8064</a> Update <code>qunit-dom</code> to v0.8.0 <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8067"">#8067</a> Less restrictive blueprints - change how addons are identified <a href=""https://urls.greenkeeper.io/scalvert"">@scalvert</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8068"">#8068</a> Enable BROCCOLI_2 and SYSTEM_TEMP experiments by default. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8069"">#8069</a> Adding back feature to customization of serveURL <a href=""https://urls.greenkeeper.io/SparshithNR"">@SparshithNR</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7798"">#7798</a> Add Broccoli 2.0 support <a href=""https://urls.greenkeeper.io/oligriffiths"">@oligriffiths</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7916"">#7916</a> Support node-http-proxy timeout options <a href=""https://urls.greenkeeper.io/jboler"">@jboler</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7937"">#7937</a> Update fallback default browser targets from IE9 -&gt; IE11. <a href=""https://urls.greenkeeper.io/arthirm"">@arthirm</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7984"">#7984</a> Reject when command args validation fails <a href=""https://urls.greenkeeper.io/zonkyio"">@zonkyio</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7946"">#7946</a> upgrade ember-cli-htmlbars to 3.x <a href=""https://urls.greenkeeper.io/stefanpenner"">@stefanpenner</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8000"">#8000</a> Adding <code>--in</code> option to <code>ember generate</code> and <code>ember destroy</code> to allow blueprint generation for in repo addons in custom paths. <a href=""https://urls.greenkeeper.io/scalvert"">@scalvert</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8028"">#8028</a> Add <code>public</code> to the list of disallowed application names <a href=""https://urls.greenkeeper.io/twokul"">@twokul</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-11-14T18:47:48Z,False,438774202.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.5.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.5.1) 
 

<details>
<summary>Release Notes for v3.5.1</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.5.1</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li><code>rm -rf node_modules dist tmp</code> -- Delete temporary development folders.</li>
<li><code>npm install -g ember-cli-update</code> -- Install Ember CLI update tool globally.</li>
<li>Run <code>ember-cli-update</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.5.0...v3.5.1""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.5.0...v3.5.1""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8127"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8127/hovercard"">#8127</a> Fix eslint errors in new app <a href=""https://urls.greenkeeper.io/Gaurav0"">@Gaurav0</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8130"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8130/hovercard"">#8130</a> Use regex to parse /livereload urls <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8141"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8141/hovercard"">#8141</a> Use <code>debug</code> for <code>package-info-cache</code> messages <a href=""https://urls.greenkeeper.io/stefanpenner"">@stefanpenner</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8150"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8150/hovercard"">#8150</a> Fix <code>toTree()</code> with custom paths <a href=""https://urls.greenkeeper.io/wagenet"">@wagenet</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2018-12-12T20:13:16Z,False,446727809.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.6.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.6.0) 
 

<details>
<summary>Release Notes for Lunchtime</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.6.0</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.6.0</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.5.1...v3.6.0""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.5.1...v3.6.0""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7958"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/7958/hovercard"">#7958</a> Gather doc files in docs directory <a href=""https://urls.greenkeeper.io/dcyriller"">@dcyriller</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8032"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8032/hovercard"">#8032</a> Update minimum broccoli-viz version <a href=""https://urls.greenkeeper.io/gandalfar"">@gandalfar</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/7974"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/7974/hovercard"">#7974</a> Prevent double builds in CI for branches pushed by owner <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8096"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8096/hovercard"">#8096</a> Use regex to parse /livereload urls <a href=""https://urls.greenkeeper.io/SparshithNR"">@SparshithNR</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8086"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8086/hovercard"">#8086</a> Prefer walk-sync for AssetPrinterSize (speeds things up) <a href=""https://urls.greenkeeper.io/stefanpenner"">@stefanpenner</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8108"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8108/hovercard"">#8108</a> Put <code>package-info-cache</code> warnings under <code>DEBUG</code> control <a href=""https://urls.greenkeeper.io/dcombslinkedin"">@dcombslinkedin</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8203"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8203/hovercard"">#8203</a> Move contribution info away from <code>README</code> to <code>CONTRIBUTING</code> <a href=""https://urls.greenkeeper.io/kennethlarsen/feature"">@kennethlarsen/feature</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8147"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8147/hovercard"">#8147</a> Bump ember-cli-babel@7 in application blueprint <a href=""https://urls.greenkeeper.io/SergeAstapov"">@SergeAstapov</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8142"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8142/hovercard"">#8142</a> Fix yarn test failures <a href=""https://urls.greenkeeper.io/abhilashlr"">@abhilashlr</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8138"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8138/hovercard"">#8138</a> Remove ember-ajax from addon blueprint <a href=""https://urls.greenkeeper.io/initram"">@initram</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8143"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8143/hovercard"">#8143</a> adding fix to use NULL nodeModuleList to optimize when dealing with non-addons <a href=""https://urls.greenkeeper.io/dcombslinkedin"">@dcombslinkedin</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8179"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8179/hovercard"">#8179</a> Do not include <code>.jshintrc</code> and <code>.eslintrc</code> when generating <code>lib</code> or <code>packages</code> <a href=""https://urls.greenkeeper.io/ppcano"">@ppcano</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8162"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8162/hovercard"">#8162</a> remove any /* eslint-env node */ <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8174"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8174/hovercard"">#8174</a> Fix links in Addon API docs header <a href=""https://urls.greenkeeper.io/dfreeman"">@dfreeman</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8171"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8171/hovercard"">#8171</a> Add <code>--ssl</code> options to <code>ember test</code> <a href=""https://urls.greenkeeper.io/nathanhammond"">@nathanhammond</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8165"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8165/hovercard"">#8165</a> Remove unused ""ember-default"" scenario <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8202"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8202/hovercard"">#8202</a> Specify explicit ember-cli version in project update instructions <a href=""https://urls.greenkeeper.io/nickschot"">@nickschot</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8277"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8277/hovercard"">#8277</a> DefaultPackager: Move <code>addon-test-support</code> out of the <code>tests</code> folder <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8278"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8278/hovercard"">#8278</a> DefaultPackager: Fix addon preprocessing <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8287"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8287/hovercard"">#8287</a> blueprints/app: Update Ember and Ember Data to v3.6.0 <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-01-03T16:46:31Z,False,451202645.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.6.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.6.1) 
 

<details>
<summary>Release Notes for White</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.6.1</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.6.1</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.6.0...v3.6.1""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.6.0...v3.6.1""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8288"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8288/hovercard"">#8288</a> Add <code>ember-default</code> scenario to <code>ember-try</code> config again <a href=""https://urls.greenkeeper.io/bendemboski"">@bendemboski</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8296"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8296/hovercard"">#8296</a> Add ember-source@3.4 LTS ember-try scenario. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-01-09T17:51:40Z,False,452789478.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.7.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.7.0) 
 

<details>
<summary>Release Notes for ::<></summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.7.0</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.7.0</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.6.1...v3.7.0""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.6.1...v3.7.0""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8262"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8262/hovercard"">#8262</a> spelling fix <a href=""https://urls.greenkeeper.io/jfdnc"">@jfdnc</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8264"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8264/hovercard"">#8264</a> Remove redundant _requireBuildPackages and format comments <a href=""https://urls.greenkeeper.io/xg-wang"">@xg-wang</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8275"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8275/hovercard"">#8275</a> Fix dead link in CONTRIBUTING.md <a href=""https://urls.greenkeeper.io/hakilebara"">@hakilebara</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8279"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8279/hovercard"">#8279</a> CHANGELOG: Drop releases before v2.8.0 <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8286"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8286/hovercard"">#8286</a> Provide a compatibility section in addon READMEs <a href=""https://urls.greenkeeper.io/kennethlarsen"">@kennethlarsen</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8296"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8296/hovercard"">#8296</a> Add ember-source@3.4 LTS ember-try scenario. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8297"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8297/hovercard"">#8297</a> Remove last usage of Babel 6. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8299"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8299/hovercard"">#8299</a> remove ember-lts-2.16 ember-try scenario <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8308"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8308/hovercard"">#8308</a> ignore .env* files <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8351"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8351/hovercard"">#8351</a> Update Ember and Ember Data to v3.7.0 <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8352"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8352/hovercard"">#8352</a> Fix <code>relative-module-paths</code> caching <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-01-11T10:28:00Z,False,453470851.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.7.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.7.1) 
 

<details>
<summary>Release Notes for <>::</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.7.1</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.7.1</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.7.0...v3.7.1""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.7.0...v3.7.1""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8357"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8357/hovercard"">#8357</a> blueprints/addon: Fix incorrect job formatting in <code>.travis.yml</code> config <a href=""https://urls.greenkeeper.io/buschtoens"">@buschtoens</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-02-27T16:27:42Z,False,467930921.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.8.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.8.0) 
 

<details>
<summary>Release Notes for Aotearoa</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.8.0</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.8.0</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.7.1...v3.8.0""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.7.1...v3.8.0""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8175"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8175/hovercard"">#8175</a> Do not watch <code>tests</code> directory when tests are disabled <a href=""https://urls.greenkeeper.io/f1sherman"">@f1sherman</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8052"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8052/hovercard"">#8052</a> Use non-greedy pattern for <code>{{content-for}}</code> <a href=""https://urls.greenkeeper.io/mpirio"">@mpirio</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8325"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8325/hovercard"">#8325</a> Add contributing guidelines section to Docs <a href=""https://urls.greenkeeper.io/jamesgeorge007"">@jamesgeorge007</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8326"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8326/hovercard"">#8326</a> package.json: Move <code>fixturify</code> to <code>devDependencies</code> <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8329"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8329/hovercard"">#8329</a> livereload-server: Fix logger output <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8328"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8328/hovercard"">#8328</a> tasks/server: Remove obsolete <code>exists-sync</code> dependency declaration <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8313"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8313/hovercard"">#8313</a> Update ember-ajax to v4.x <a href=""https://urls.greenkeeper.io/maxwondercorn"">@maxwondercorn</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8309"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8309/hovercard"">#8309</a> blueprints/addon: Add Contributing section <a href=""https://urls.greenkeeper.io/knownasilya"">@knownasilya</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8327"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8327/hovercard"">#8327</a> Improve <code>ember-cli</code> entry file <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8330"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8330/hovercard"">#8330</a> blueprints/app/gitignore: Ignore Yarn PnP files <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8331"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8331/hovercard"">#8331</a> Update <code>ember-cli-dependency-checker</code> to v3.1.0 <a href=""https://urls.greenkeeper.io/Turbo87"">@Turbo87</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8323"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8323/hovercard"">#8323</a> Dynamically fetch the <code>ember-source</code> version for MU blueprints <a href=""https://urls.greenkeeper.io/ppcano"">@ppcano</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8427"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8427/hovercard"">#8427</a> Fix install warnings for @babel/core <a href=""https://urls.greenkeeper.io/jrjohnson"">@jrjohnson</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-03-01T09:54:07Z,False,468609072.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.8.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.8.1) 
 

<details>
<summary>Release Notes for Nerdiest Precious Modules</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.8.1</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.8.1</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.8.0...v3.8.1""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.8.0...v3.8.1""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8261"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8261/hovercard"">#8261</a> add server/**/*.js to eslint node files for app <a href=""https://urls.greenkeeper.io/kellyselden"">@kellyselden</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8467"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8467/hovercard"">#8467</a> Ensure npm version is available during ember new / ember install foo. <a href=""https://urls.greenkeeper.io/rwjblue"">@rwjblue</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-04-05T11:19:58Z,False,480239920.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.8.2`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.8.2) 
 

<details>
<summary>Release Notes for Grenoble</summary>

<h2>Setup</h2>
<p><code>npm install -g ember-cli@3.8.2</code> -- Install new global ember-cli</p>
<h2>Project Update</h2>
<ol>
<li>Run <code>npx ember-cli-update --to 3.8.2</code> -- This will update your app or addon to the latest ember-cli release. You will probably encounter merge conflicts that you should resolve in your normal git workflow.</li>
<li>Run <code>npx ember-cli-update --run-codemods</code> -- This will let you pick codemods to run against your project, to ensure you are using the latest patterns and platform features.</li>
</ol>
<h2>Changelog</h2>
<h4>Blueprint Changes</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-new-output/compare/v3.8.1...v3.8.2""><code>ember new</code> diff</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-addon-output/compare/v3.8.1...v3.8.2""><code>ember addon</code> diff</a></li>
</ul>
<h4>Community Contributions</h4>
<ul>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8482"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8482/hovercard"">#8482</a> Update <code>ember-ajax</code> in blueprints and tests <a href=""https://urls.greenkeeper.io/boris-petrov"">@boris-petrov</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8370"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8370/hovercard"">#8370</a> Use <code>moduleName()</code> for templates <a href=""https://urls.greenkeeper.io/pzuraq"">@pzuraq</a></li>
<li><a href=""https://urls.greenkeeper.io/ember-cli/ember-cli/pull/8556"" data-hovercard-type=""pull_request"" data-hovercard-url=""/ember-cli/ember-cli/pull/8556/hovercard"">#8556</a> Ensure packager respects source map config when concatting <a href=""https://urls.greenkeeper.io/stefanpenner"">@stefanpenner</a></li>
</ul>
<p>Thank you to all who took the time to contribute!</p>
</details>",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-04-08T20:51:32Z,False,481003116.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.9.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.9.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-05-13T23:12:12Z,False,492019394.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.10.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.10.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-05-17T15:50:22Z,False,493503391.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.10.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.10.1)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-07-15T19:24:36Z,False,511536049.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.11.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.11.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-08-16T09:03:33Z,False,521941578.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.12.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.12.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-09-25T14:08:00Z,False,535040821.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.13.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.13.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-09-27T23:01:02Z,False,536121563.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.13.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.13.1)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-11-15T14:34:46Z,False,554382076.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.13.2`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.13.2)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-11-15T14:59:04Z,False,554391634.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.14.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.14.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-12-20T01:48:52Z,False,567752725.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.15.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.15.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2019-12-20T16:11:46Z,False,567978645.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.15.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.15.1)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2020-01-24T14:42:02Z,False,578158045.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.15.2`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.15.2)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2020-02-12T17:13:27Z,False,585313781.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.16.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.16.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2020-03-14T20:35:33Z,False,599131930.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.16.1`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.16.1)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2020-03-16T01:18:52Z,False,599296250.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.17.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.17.0)",True,False
buschtoens/ember-collect-helper/12/pulls/buschtoens/ember-collect-helper/12,2020-05-04T20:42:04Z,False,623694335.0,"- The `devDependency` [ember-cli](https://github.com/ember-cli/ember-cli) was updated from `2.14.2` to `3.18.0`.

[Update to this version instead 🚀](https://github.com/buschtoens/ember-collect-helper/compare/master...buschtoens:greenkeeper%2Fember-cli-3.18.0)",True,False
mrmartineau/design-system-utils/158/pulls/mrmartineau/design-system-utils/158,2019-02-27T15:08:34Z,False,467898081.0,"Looks like prettier is up-to-date now, so this is no longer needed.",True,False
smkell/ffl_faust/115/pulls/smkell/ffl_faust/115,2018-12-10T13:43:31Z,False,445819337.0,Closing this in favor of #116,True,False
smirnovvad/students_api/141/pulls/smirnovvad/students_api/141,2018-10-16T13:33:32Z,False,430239068.0,Closing this in favor of #142,True,False
sparc-request/sparc-request/1107/pulls/sparc-request/sparc-request/1107,2017-09-28T14:43:29Z,False,332858769.0,https://www.pivotaltracker.com/story/show/151338923,True,False
dbeurle/neon/85/pulls/dbeurle/neon/85,2018-07-11T12:58:29Z,False,404159587.0,"
[![Coverage Status](https://coveralls.io/builds/17933555/badge)](https://coveralls.io/builds/17933555)

Coverage remained the same at 69.413% when pulling **f717c9f1190cc34101626dd6eda624c7bc71a108 on shadialameddin:master** into **a1b67b0f24d9fb18f0bcdc14af64941cbabfee05 on dbeurle:master**.
",True,False
ampproject/amppackager/289/pulls/ampproject/amppackager/289,2019-04-29T05:49:20Z,False,487457760.0,"@twifkak This is the bare-minimum approach, but it does seem to work fine. It could potentially be optimized by preventing the actual packaging, signing, etc that generates a response body, but that comes at the cost of complexity. Let me know your thoughts.",True,False
ampproject/amppackager/289/pulls/ampproject/amppackager/289,2019-04-29T19:33:06Z,False,487713258.0,"Thanks! I'm fine with the performance cost of all the signing, etc., as I expect this not to be a significant percentage of requests (correct me if you think otherwise).

Just to confirm: This doesn't actually cause a response body to be emitted, right? I'm guessing from 
https://golang.org/src/net/http/server.go#L372 that this is the case, but I imagine you've tested.",True,False
ampproject/amppackager/289/pulls/ampproject/amppackager/289,2019-04-29T19:37:09Z,False,487714564.0,"Optionally, make a little helper function like `func headAndGet(mux, path, handler)` or so. Or maybe make a loop like:

```
handlers := []struct{path string, handler *http.Handler}{
  ...
}
for _, handler := range handlers {
  mux.GET(...)
  mux.HEAD(...)
}
```

That seems to be the ""Go"" way, judging by their testing style. But I'm not tied to either idiom.",True,False
ampproject/amppackager/289/pulls/ampproject/amppackager/289,2019-04-29T20:22:50Z,False,487729434.0,"> Just to confirm: This doesn't actually cause a response body to be emitted, right? I'm guessing from
> https://golang.org/src/net/http/server.go#L372 that this is the case, but I imagine you've tested.

Right.

> Or maybe make a loop like...

Thanks for the suggestion. I opted for looping over the array of anonymous structs. Let me know if you're ok with the style.",True,False
self-xdsd/self-storage/203/pulls/self-xdsd/self-storage/203,2020-12-21T12:52:39Z,False,748958454.0,@amihaiemil thank you for your Pull Request. I'll assign someone to review it soon.,True,False
self-xdsd/self-storage/203/pulls/self-xdsd/self-storage/203,2020-12-21T12:54:11Z,False,748959058.0,"@amihaiemil please review this Pull Request. Deadline (when it should be merged or closed) is ``2020-12-24T14:54:07.937559``.

You should check if the requirements have been implemented (partially or in full), if there are unit tests covering the changes and if the CI build passes. Feel free to reject the PR or ask for changes if it's too big or not clear enough.

Estimation here is ``30 minutes``, that's how much you will be paid. You will be paid even if this PR gets rejected.",True,False
self-xdsd/self-storage/203/pulls/self-xdsd/self-storage/203,2020-12-21T12:59:32Z,False,748961033.0,@amihaiemil thank you for resolving this ticket. I've just added it to your active invoice. You can always check all your invoices and more on the [Contributor Dashboard](https://self-xdsd.com).,True,False
david942j/memory_io/16/pulls/david942j/memory_io/16,2018-06-07T21:11:49Z,False,395566574.0,Superseded by #17.,True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-07T13:45:40Z,False,284724967.0,"One more thing I forgot: I also added `mol` as an alternative name for `mole`, and `ampere` for `amp` -- both are not imported by default, though, which makes them less useful...",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-08T15:54:26Z,False,285080040.0,"Temperature: good!

Additional units:

* Happy with molar and mM, etc.
* Use m^3 not liter as volume is good I think.
* What about only insisting that ``float(u)==1`` as the condition for using ``u`` as the unit specifier in equations?

Constants:

Good idea to have the module. I would say we shouldn't have any constants that are a single letter. We should encourage people, as you suggest, to do ``from ... import ... as k`` if they want that. I think given that you have to explicitly import from ``.constants`` we don't need a uniform ``_constant`` suffix, just go with the name people usually use to refer to them. (e.g. ``h_bar_constant`` would seem weird, right?)

Error messages: great!",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-08T17:08:36Z,False,285102967.0,"> What about only insisting that float(u)==1 as the condition for using u as the unit specifier in equations?

We could do this, this certainly has the advantage of being straightforward. On the other hand, from the user's point of view it might look odd to see that `mM`, `kliter` are ""legal"", while `mV` or `umeter` are not. I think I could be convinced either way, having a clear and unambiguous rule (that automatically applies to new units that we might add at some point) certainly has its benefits.

> . I think given that you have to explicitly import from .constants we don't need a uniform _constant suffix, just go with the name people usually use to refer to them. (e.g. h_bar_constant would seem weird, right?)

It's a bit of mess currently, I think the most consistent might be to use `_constant` whenever the name does not already have a noun suffix (e.g. we would not convert `electron_mass` to `electron_mass_constant`, but `Faraday` would be `faraday_constant` -- BTW: I think not having capital letters is better). And `h_bar` would be called `dirac_constant` (if that's the constant you meant -- it's not included BTW ;) ). So here's my proposed list of names (but again, I'm also open to kick out some of these or add new ones):
```
avogadro_constant
boltzmann_constant
electric_constant
electron_mass
elementary_charge
faraday_constant
gas_constant
magnetic_constant
molar_mass
zero_celsius
```
Going by Wikipedia redirections, `electrical_constant` and `magnetic_constant` should instead be `vacuum_permittivity` and `vacuum_permeability` -- if I'd ever have to use them, I would not be able to chose the correct one, though :smirk:

@romainbrette Any opinion on all this?",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-08T22:28:06Z,False,285190432.0,"I don't have a strong opinion on the constant names, but your selection seems reasonable to me.

Agree that ``mM`` and ``kliter`` being legal while others are not would be weird, didn't think of that. Would it be coherent to say that only un-prefixed forms are allowed? Maybe that still has the problem that the scale isn't what you'd expect it to be?",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-09T06:28:14Z,False,285266909.0,"I think the initial reason why we didn't want people to use mV is they 
would expect v = 25 would mean 25 mV and not 25 volt. So in this sense 
we should indeed have mM as the base unit for concentration and not M. 
It turns out it is also the standard unit that is used in 
electrophysiology so I think it's ok. For kliter, well I don't think the 
problem will occur, no one uses this (and if they do, it's not a problem).

The problem is more one of presentation, ie explaining that mM is 
allowed but not mV. One option is to allow only mole*meter**-3. But 
that's not very convenient. I would rather be in favor of putting a 
cautionary note in the documentation, explaining that mM is a base unit 
because it equals mole/meter^3.


Le 08/03/2017 à 23:28, Dan Goodman a écrit :
>
> I don't have a strong opinion on the constant names, but your 
> selection seems reasonable to me.
>
> Agree that |mM| and |kliter| being legal while others are not would be 
> weird, didn't think of that. Would it be coherent to say that only 
> un-prefixed forms are allowed? Maybe that still has the problem that 
> the scale isn't what you'd expect it to be?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub 
> <https://github.com/brian-team/brian2/pull/821#issuecomment-285190432>, 
> or mute the thread 
> <https://github.com/notifications/unsubscribe-auth/ACxNzp8dVE6kR633ksNIeIHB7R67arm3ks5rjyt3gaJpZM4MVfFK>.
>

",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-09T07:18:28Z,False,285274330.0,"All is very nice. It's a good choice and good names for constants, except maybe molar_mass (mole of what?). I think electric_constant and magnetic_constant are better names than vacuum_x.
I'm just slightly hesitant about whether we should also have short names (or R_constant, F_constant, epsilon0_constant).
But ok, I think the long names are still a better option, because the short names would have to have a suffix anyway, otherwise that would be a bit dangerous (eg F is often used for firing rate). We should have good examples for using them (import ... as R).",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-09T15:31:23Z,False,285384118.0,"About the units in the equation definitions: indeed, the original reason to only allow units with scale 1 here was to avoid ambiguities about their scale. This was quite important in Brian 1 because arrays did not have units, so when you typed `group.v` you got back an array of values in volt, but without the unit information. In Brian 2, this array will have units attached so confusion should be unlikely. Nevertheless, you could still use `group.v_`, or `array(group.v)` or some other operation that discards the units, so it is still safer to keep the convention. I think if we were to design this system from scratch right now, we might rather make the distinction between dimensions and units clearer, i.e. in equations you'd write something like `voltage`, `length`, `current`, `current/area`, etc. instead of units, but well.
Long story short, I got the impression that there is a consensus to allow all ""scale 1"" units, which would mean to allow `mmolar`/`mM` (and `kliter`, but no one cares) -- we'll add a note in the docs for this specific case.

About the constants, I also got an impression that we got a consensus to use the long names (mentioning in the docs/examples how to use them with short names). I'll replace `molar_mass` by `molar_mass_constant` (""a physical constant which relates relative atomic mass and molar mass"" -- [Wikipedia](https://en.wikipedia.org/wiki/Molar_mass_constant)).

I'll clean up the PR and add docs and tests before proposing it for merging.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-13T13:57:10Z,False,286113957.0,"I updated the PR to implement all the changes we discussed and also added documentation and tests. However, during testing I realized that our current `UnitRegistry` system is somewhat broken, and I'd like to take the opportunity to fix this once and for all. I'll try to explain in some detail what the problem is:
Brian (1 and 2) have a system to automatically register new units and it will use these units to when displaying values. E.g. if you'd do (a bit contrived of course):

```pycon
>>> 3e-7*meter**-4*kilogram**-1*second**4*amp**2
3.00000000e-07 * metre ** -4 * kilogram ** -1 * second ** 4 * amp ** 2
```

It doesn't have any ""nice"" unit to display it in. However, if you'd use something like:

```pycon
>>> pF/cm**2
```

It will register this unit (you could call `register_unit` explicitly, but `Unit.automatically_register_units` is `True` by default). From then on, it will be used for display if appropriate:

```pycon
>>> 3e-7*meter**-4*kilogram**-1*second**4*amp**2
30. * pfarad / cmetre ** 2
```

This (and that registration is automatic) is actually quite important because otherwise even if you'd type `30*(pfarad/cmeter**2)` directly, it wouldn't use the unit you used for specifying it for display and would fall back to the SI dimensions instead. This is because quantities only store the dimensions, so the information is no longer available when doing the display. Side note: you actually need the parentheses above if you want to have nice display with the ""automatic registration"" mechanism. If you omit them, `30*pfarad` will be calculated first, resulting in a `Quantity`, so no `Unit/Unit` division takes place.

Now, there was a bug in this mechanism in Brian 1 and early versions of B: all user units were added to a list, so *each use* of `pfarad/cmeter**2` would store it again. Together with the way ""unit lookup"" was organized, this also slowed down things. The straightforward solution was to store units in a set instead of in a list, which also meant implementing a proper hash function -- the previous hash function was inherited  from `np.float64` (Brian 1), respectively from `np.ndarray` (Brian 2), which meant that only the numerical value matter (e.g. `hash(msiemens) == hash(mvolt))`. In the current state of this branch, this is all working out, the hash function depends on all the fields of the `Unit` object (`name`, etc.), and everything works.

What's the problem? The docs advertise that you are allowed to change the displayed name of a `Unit` after its creation:

> A new unit defined by multiplication, division or taking powers
> generates a name for the unit automatically, so that for
> example the name for `pfarad/mmetre**2` is `""pF/mm^2""`, etc. If you
> don't like the automatically generated name, use the
> `Unit.set_display_name` method.



With the current implementation, this will break things... If you change the name of a unit, then its hash value changes and that's not allowed for objects stored in a set. I see two solutions:

1. We allow certain changes to a unit after its creation (`dispname` and `latexname` I guess), and the methods used for doing so will take care of unregistering and re-registering the unit.
2. We do not allow any changes to a unit after its creation, if you want to use a unit with a non-default display name, then you'll have to explicitly create the unit with `Unit.create`

I think I prefer the second solution, it is cleaner and it is compatible with the standard use of hash functions and sets (objects are supposed to be immutable). IMO, this is also a very rarely used feature (I don't think I ever used it myself) so it is probably not important to make this very convenient to use.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-13T16:29:51Z,False,286162353.0,"I actually didn't know you could change the names of units, so I'd say 
#2 is fine.


Le 13/03/2017 à 14:57, Marcel Stimberg a écrit :
>
> I updated the PR to implement all the changes we discussed and also 
> added documentation and tests. However, during testing I realized that 
> our current |UnitRegistry| system is somewhat broken, and I'd like to 
> take the opportunity to fix this once and for all. I'll try to explain 
> in some detail what the problem is:
> Brian (1 and 2) have a system to automatically register new units and 
> it will use these units to when displaying values. E.g. if you'd do (a 
> bit contrived of course):
>
> >>>3e-7*meter**-4*kilogram**-1*second**4*amp**2
> 3.00000000e-07 * metre ** -4 * kilogram ** -1 * second ** 4 * amp ** 2
>
> It doesn't have any ""nice"" unit to display it in. However, if you'd 
> use something like:
>
> >>> pF/cm**2
>
> It will register this unit (you could call |register_unit| explicitly, 
> but |Unit.automatically_register_units| is |True| by default). From 
> then on, it will be used for display if appropriate:
>
> >>>3e-7*meter**-4*kilogram**-1*second**4*amp**2
> 30. * pfarad / cmetre ** 2
>
> This (and that registration is automatic) is actually quite important 
> because otherwise even if you'd type |30*(pfarad/cmeter**2)| directly, 
> it wouldn't use the unit you used for specifying it for display and 
> would fall back to the SI dimensions instead. This is because 
> quantities only store the dimensions, so the information is no longer 
> available when doing the display. Side note: you actually need the 
> parentheses above if you want to have nice display with the ""automatic 
> registration"" mechanism. If you omit them, |30*pfarad| will be 
> calculated first, resulting in a |Quantity|, so no |Unit/Unit| 
> division takes place.
>
> Now, there was a bug in this mechanism in Brian 1 and early versions 
> of B: all user units were added to a list, so /each use/ of 
> |pfarad/cmeter**2| would store it again. Together with the way ""unit 
> lookup"" was organized, this also slowed down things. The 
> straightforward solution was to store units in a set instead of in a 
> list, which also meant implementing a proper hash function -- the 
> previous hash function was inherited from |np.float64| (Brian 1), 
> respectively from |np.ndarray| (Brian 2), which meant that only the 
> numerical value matter (e.g. |hash(msiemens) == hash(mvolt))|. In the 
> current state of this branch, this is all working out, the hash 
> function depends on all the fields of the |Unit| object (|name|, 
> etc.), and everything works.
>
> What's the problem? The docs advertise that you are allowed to change 
> the displayed name of a |Unit| after its creation:
>
>     A new unit defined by multiplication, division or taking powers
>     generates a name for the unit automatically, so that for
>     example the name for |pfarad/mmetre**2| is |""pF/mm^2""|, etc. If you
>     don't like the automatically generated name, use the
>     |Unit.set_display_name| method.
>
> With the current implementation, this will break things... If you 
> change the name of a unit, then its hash value changes and that's not 
> allowed for objects stored in a set. I see two solutions:
>
>  1. We allow certain changes to a unit after its creation (|dispname|
>     and |latexname| I guess), and the methods used for doing so will
>     take care of unregistering and re-registering the unit.
>  2. We do not allow any changes to a unit after its creation, if you
>     want to use a unit with a non-default display name, then you'll
>     have to explicitly create the unit with |Unit.create|
>
> I think I prefer the second solution, it is cleaner and it is 
> compatible with the standard use of hash functions and sets (objects 
> are supposed to be immutable). IMO, this is also a very rarely used 
> feature (I don't think I ever used it myself) so it is probably not 
> important to make this very convenient to use.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub 
> <https://github.com/brian-team/brian2/pull/821#issuecomment-286113957>, 
> or mute the thread 
> <https://github.com/notifications/unsubscribe-auth/ACxNzmQ7CaXrhr5t8wSx2hEORg1GSOLZks5rlUs3gaJpZM4MVfFK>.
>

",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-13T18:58:19Z,False,286208796.0,"I also doubt anyone ever did this, so solution 2 is fine. On the other hand, should we not just do a lookup based on the dimensions alone? I think I didn't understand the issue well.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-14T17:03:27Z,False,286489803.0,"> On the other hand, should we not just do a lookup based on the dimensions alone? I think I didn't understand the issue well.

It is complicated :nerd_face: We do a lookup based on the dimensions, but then for each dimension there's a list of units (e.g. for the dimensions `second` there's `msecond`, `usecond`, etc.). We also have an independent set of all units, but actually I don't think that's needed anymore now that we have the dimensions-based lookup.

Either way, dropping the option to rename units seems to be a consensus, I'll go ahead implementing this solution.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-15T18:34:07Z,False,286838245.0,"Ok, I think I fixed everything we discussed and it is a bit more sensible now. I realized there were a few requirements that might be conflicting:
1. We want units to compare as equal when they are equal in the quantity sense (otherwise we'd have to explain to users why `meter == metre` is `False`, but `1*meter == metre` is `True`).
2. We need to keep track of all available units so that we can allow their use in strings
3. We need to keep track of units for presentation purposes, where we need one canonical representation for each dimensionality and scale
4. We do not want to store the same unit multiple times (e.g. when you use `pF/cm**2` repeatedly, it should not be stored again and again)
5. (somewhat optional, see below) We might want the user to overwrite the stored representation for a given unit.

A few solutions that we had over the course of the development of Brian 1/Brian 2, and some stuff I did here in this PR, do not work with these requirements for various reasons: For example, to remember all available units (requirement 2) without duplicating them (requirement 4), we cannot simply use a set, since such a set would not store both `meter` and `metre` (since they compare equal). Using a list (Brian 1's solution) would work for 2 but not for 4, etc.

So, here is my current approach: A `UnitRegistry` stores the available units in two data structures. The first is a dictionary with `repr(unit)` as the key and the `unit` as the value. This is what we use to construct namespaces for string evaluation, etc. The second data structure is a tiny bit more complicated, but still reasonable I hope :smirk: : it is a dictionary of dictionaries. The main key is the dimensionality, and the keys of the second dictionary is the scale as a floating point value. This is what we use to get the canonical representation for a quantity, based on its dimensions and scale. The advantage of this data structure is that if the user generates new units repeatedly, they will be only stored once, but you can still store multiple units for the same dimensionality (which we of course need for scaled units).

Now there's one more thing we might want to fix. The automatic unit registration works, i.e. as soon as you use a unit, it will be remembered for presentation purposes:
```pycon
>>> 3e-7*meter**-4*kilogram**-1*second**4*amp**2
3e-7 * metre ** -4 * kilogram ** -1 * second ** 4 * amp ** 2
>>> pF/cm**2  # This will automatically register the unit
pfarad / cmetre ** 2
>>> 3e-7*meter**-4*kilogram**-1*second**4*amp**2
30. * pfarad / cmetre ** 2
```

Now, that only works if no standard unit for the same dimensionality exists. The documentation talks about creating a new unit ""Nm"", but this is equivalent to Joule -- you can therefore not force the use of this unit for display purposes, even if you explicitly try to register it:
```pycon
>>> from brian2.units.allunits import newton
>>> Nm = newton*meter
>>> 3*Nm
3. * joule
>>> register_new_unit(Nm)
>>> 3*Nm
3. * joule
```

Now, we could simply turn around the order of the unit registries, i.e. user-defined units have preference over the standard units (I did this actually at some point). It turns out that this is a terrible idea if you also use automatic unit registration -- if (for some reason), you used `metre ** 2 * kilogram * second ** -3 * amp ** -1` at some point, all values in `volt` would now be displayed using the long form... So the only proper solution I see for that is to have *two* user registries, once for the explicitly defined units with `register_new_unit`, which has preference over standard units, and one for the automatically defined units, which does not overwrite standard units.

Having said all this, I'd also be fine if it were simply not possible to overwrite standard units for display purposes. There's always stuff like this you can do:
```pycon
>>> (3*Nm).in_unit(Nm)
'3. N m'
```
",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-17T10:56:43Z,False,287325194.0,"> the scale as a floating point value

Shouldn't it be an int? i.e. it's something like ``int(log10(x))`` I guess? (Presumably slightly more complicated, but something like that.)

I suspect that nobody or virtually nobody has ever used ``register_new_unit`` or any of that stuff, and so we should optimise the solution for the typical use case of people doing things like ``pF/cm``. I'm quite happy to make all that API something we consider to be more or less internal to Brian and not something users should normally use. In particular then, your last suggestion seems like a good idea to me. I think that, together with your new UnitRegistry data structure covers everything?",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-17T13:15:02Z,False,287350471.0,"> Shouldn't it be an int? i.e. it's something like int(log10(x)) I guess? (Presumably slightly more complicated, but something like that.)

I was referring to the values stored in `_siprefixes`, they were previously:
```pycon
>>> _siprefixes
{'': 1,
 'E': 1e+18,
 'G': 1000000000.0,
 'M': 1000000.0,
 'P': 1000000000000000.0,
 'T': 1000000000000.0,
...}
```
And this fails with the most recent numpy version if you do `_siprefix[''] ** -1`. The way these values are currently used they have to be the actual floating point values, since they determine the `value` of the `Unit`. But you are right that it would probably be better to store integer numbers somewhere, and use them when e.g. multiplying two units, instead of using the floating point values.
I looked into this stuff a bit and I realized that our handling of scales internally is a bit odd, anyway: we have a `scales` attribute of strings which is supposed to hold the scale per dimension, but we are not actually using it:
```pycon
>>> (pF/cm**2).scale
['', '', '', '', '', '', '']
```
(I just checked, it's the same in Brian 1). Similar for the `scalefactor`, we only use it during construction. So how about: not storing the `scalefactor` at all (it's convenient for construction, but not needed afterwards), and storing the scale as an integer numbers (as you said, the exponent of 10) -- I don't think it is useful to store the scale independently for each dimension, or ist it? We could then use the scale for exact calculations of the value, which might avoid some floating point issues, e.g. currently using variants of liter and meter³ does not give the exact same values:
```pycon
>>> float(8*pliter), float(8000*umeter3)
(8e-15, 7.999999999999999e-15)
```

A final minor note on this: this ""exponent of 10""-based system will prevent us from introducing units like `feet` or `inches` in the future, but I personally could not care less...

About `register_new_unit` -- I'm happy to take this option away from the user. As you said, I doubt anyone used it and it was not easy to use correctly in the first place.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-17T13:57:38Z,False,287360390.0,"I'm not bothered about excluding feet and inches - we can always add them as ``Quantity`` constants rather than units (and I would think it would be better not to have them in any case).

That all sounds good to me.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-17T18:43:34Z,False,287439344.0,"Ok, I *think* this should finally be it, this took quite a bit longer than expected (but of course it also does quite a bit more than initially proposed). The only thing that is still missing from my side are the release notes, but it would be good to manually test this branch a bit, our test suite is not covering display issues (i.e., does the unit used for display look ""good"") very well. I also realized that an earlier version in this branch completely botched up the values of scaled units (e.g. `float(mmeter2)` equaled 1.0), and no test was catching that. I added a new test for that. ",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-20T14:49:13Z,False,287782341.0,"Thanks for the comments, because of the `: integer`, etc. stuff I'd indeed prefer that function to stay in the functions module. About the °, ³, etc. -- I removed it where it was used in an error message (because it might be shown messed up in a badly configured console) but I left it in the docs, it shouldn't be a problem in the HTML version. It's 2017 after all :)
  
You might have noticed that this PR also have a bunch of testing/package version related changes. These are mostly quick fixes to make the tests pass, I'll open an issue to discuss this. I'll merge the branch as soon as the tests finally pass.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-18T10:25:16Z,False,106778075.0,"Could we think about refactoring this stuff to the units code? Even though it's kind of specific to equations, it feels odd to have it here.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-18T10:26:09Z,False,106778088.0,"Actually, this certainly belongs here so maybe the previous bit should stay here too.",True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-18T10:38:11Z,False,106778254.0,typo,True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-18T10:38:42Z,False,106778260.0,avoid use of degree symbol?,True,False
brian-team/brian2/821/pulls/brian-team/brian2/821,2017-03-18T10:39:12Z,False,106778265.0,same for cubed symbol?,True,False
AbhilashPal/nlp-app/2/pulls/AbhilashPal/nlp-app/2,2020-07-26T06:07:58Z,False,663940461.0,"Looks like psutil is no longer a dependency, so this is no longer needed.",True,False
Fliplet/fliplet-widget-form-builder/76/pulls/Fliplet/fliplet-widget-form-builder/76,2017-11-21T12:58:24Z,False,152267219.0,@squallstar Maybe use https://vuejs.org/v2/api/#Vue-nextTick instead of `setTimeout()`?,True,False
Fliplet/fliplet-widget-form-builder/76/pulls/Fliplet/fliplet-widget-form-builder/76,2017-11-21T13:04:28Z,False,152268491.0,@tonytlwu I've tried but it doesn't work.,True,False
microscaling/microscaling/17/pulls/microscaling/microscaling/17,2016-06-02T06:20:33Z,False,223205355.0,"👍  LGTM!
",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-30T09:27:35Z,False,393093868.0,"Great concept, but I think this closing voucher should also be done on a per user level and not just on a Pos Profile level.

Great idea though and the automated postings will be an awesome icing to the cake",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-30T12:47:58Z,False,393148338.0,"Hi @olamide2 ,

Thanks for your feedback.
Yes you are right, we should consider doing it on a per user basis for companies working with multiple POS profile/user.
It will be more complicated in terms of UX though, because a user can have several POS profiles corresponding to different point of sales counters that he/she needs to close separately. Maybe we should add some indications about which counter has been closed and which has not.
Let me see how I can modify it.

",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-30T17:01:06Z,False,393237287.0,"Hello @chdecultot

In my opinion it should be easy to conceptualize.

Let's have the option to filter by PoS Profile and/or also by user.

If you choose user alone then the result will be all transactions by the user across all PoS Profiles .

If you choose PoS Profile alone then the result will be all transactions done by all users assigned that PoS profile.

If you filter by PoS Profile and a particular user then the result will be transactions done by that user using that particular PoS Profile.

Am not a programmer so I have no idea how difficult or easy this should be. So forgive me if I sound naive.

Regards 

",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T09:12:35Z,False,393467502.0,"Hi @olamide2 ,

Sorry if I was not clear enough, but IMHO, the issue is not technical but functional in order to make it easy to close the POS counter.

I do agree with your conceptualization. Let's take the three cases you present:
1. _If you choose PoS Profile alone then the result will be all transactions done by all users assigned that PoS profile._
That is the case implemented above: for a given counter, each cashier has an individual POS Profile and starts with some cash on hand. At the end of the day, he/she can close its counter by entering the detail of each sum for each payment method.

For the sales manager: we should have a dashboard indicating which counter has been closed and which has not.

2. _If you filter by PoS Profile and a particular user then the result will be transactions done by that user using that particular PoS Profile._
This case assumes that you have one POS Profile for several users.
Each POS Profile corresponds to a particular POS counter, so by filtering by POS profile and then by user, you get the amounts collected for each payment method for this particular user on each different POS counter.
The difficulty here is to not miss any combination of POS Profile/User when closing the POS counters at the end of the day.

For the sales manager: same as n°1. We need a dashboard indicating which combinations have been closed and which have not.

3. _If you choose user alone then the result will be all transactions by the user across all PoS Profiles ._
I guess that if you have several POS Profiles, it means that you have different POS counters. Given that each counter should be closed separately (at least in France), in my understanding it is similar to option n°2.

An option could be to make a report showing the total sales per user (already available in ERPNext).


Please don't hesitate to tell me if you are handling things differently ! Especially if you really need to make one closing per user using several POS Profile.
In the meantime, I'll start implementing option n°2.

Thanks!
",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T09:55:51Z,False,393479514.0,"We are a multi location retail business. And each location has multiple pos users

We use Pos Profile to distinguish the users in each location.

So we set up a PoS profile for each location and assign the users to that profile.

This is why in our situation it would be convenient to be able to close per uer,  by pos profile and a combination of the two.

This is our use case.

Regards

",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T10:19:21Z,False,393485479.0,"Hi @olamide2 ,

Thanks for your feedback.
Your business case seems in fact quite common.

What I don't understand is why you would close counters in different locations at the same time ? Correct me if I'm wrong, but is it not safer to ask a cashier to close his/her counter at the end of his/her shift ?

Are the cash funds in location A not accounted differently from the cash funds in location B, even if it's the same user working in the morning in the location A and in the afternoon in location B ?
Or is the user taking his/her cash drawer with him/her to location B ?
",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T11:07:02Z,False,393495936.0,"Hi @chdecultot

Cashiers in each location run shifts.

If we have 6 cashiers in a location they would all have the same PoS profile. But we may need to close for all cashiers at different times.

This is why we would need to be able to filter for user when closing and not just PoS profile.

Hence the need for the user filter option and not just the PoS profile option.





",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T11:17:16Z,False,393498131.0,"Hi @olamide2,

Great! So it will be fine with the implementation of the case n°2.
You will be able to select a POS Profile + a User to make more detailed closing vouchers.

My concerns were only related to the need for case n°3.
If I'm still missing a point please let me know!",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T11:42:11Z,False,393503585.0,"Great!

All is well.

Thanks for the good job 

Olamide ",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T13:10:26Z,False,393524713.0,"Based on the feedback from @olamide2 , please find screenshots of the updated PR:

![image](https://user-images.githubusercontent.com/4903591/40779506-8a850864-64d5-11e8-8476-ba2f8bddc3e3.png)
![image](https://user-images.githubusercontent.com/4903591/40779532-9b9aebdc-64d5-11e8-8085-8f376c35aea3.png)


The voucher is not edited per POS Profile and Cashier (User).",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-05-31T13:16:47Z,False,393526478.0,Perfect!,True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-08-22T18:35:30Z,False,415134846.0,Hi @chdecultot. Thanks for the PR. It looks good. You have mentioned POS opening voucher but I could find anything in your PR. My question I how do cashier inputs the amount when opening a session. Lets say starts with $10 as change in the cash drawer. Makes cash sales of $100 (ignoring tax for here). Hence at closing the session cash should be $110 in the cash drawer. Thanks for the help.,True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-08-23T06:43:43Z,False,415309286.0,"Hi @Muzzy73,

> We should also add a POS opening voucher to register the cash level at the beginning of day also.

This is not implemented in this PR, but it would be indeed great to implement and integrate it with the POS closing voucher. As you state it is necessary to implement a POS opening voucher and follow the amount of cash in the drawer at the beginning and end of the day.
I have it on my todo list, but I have no idea when I will have the bandwidth to develop it.",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-08-23T08:58:03Z,False,415343769.0,Thank you. I have asked my developer to work on opening cash based on your design. If successful then will send PR. ,True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-11-14T21:05:32Z,False,438818340.0,"Hello @chdecultot 
Just noticed that you can actually create multiple period closing vouchers for the same day for the same user. I am of the opinion that this should not be possible. What do you think ?",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-11-15T08:26:10Z,False,438957180.0,"Hi @olamide2,

You are right, this kind of checks should be added to the functionality. 
Actually this is a basic and manual POS closing voucher and there is still a lot to be done to improve the whole POS closing cycle. I just haven't had time to work on it lately.
I'm also a little bit confused with the difference introduced by the cashier closing feature linked above.

I guess a global rethink of the whole process should be done and the different functionalities should be merged together and improved. There is a lot of work ahead. ",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2018-11-15T08:35:18Z,False,438959688.0,"I actually have no idea why the Cashier closing feature was introduced and merged. I tested it and in my opinion it is not as well structured as your PoS Closing Voucher. Your Concept is almost at the finish line. If you do have the time consider adding the following features

1. The duplication check as stated above
2. The ability to have a ¨blind closing¨ where the cashier simply keys in the on hand cash and credit card figures without knowing what the system balances are, a more senior officer can then review the shortages/overages

Like I said a lot of thought went into your design and I think you should try and finish it off.

Good job",True,False
frappe/erpnext/14270/pulls/frappe/erpnext/14270,2019-02-03T15:39:03Z,False,460062149.0,"@chdecultot
Kindly check the [#15273](https://github.com/frappe/erpnext/pull/15273) 
I have updated some things like opening and closing cash.",True,False
ipython-contrib/jupyter_contrib_nbextensions/1376/pulls/ipython-contrib/jupyter_contrib_nbextensions/1376,2018-12-29T17:12:47Z,False,450506760.0,"I don't know much about yapf,but it looks good to me. Could you add a short description on how to load a custom style in the readme ?",True,False
ipython-contrib/jupyter_contrib_nbextensions/1376/pulls/ipython-contrib/jupyter_contrib_nbextensions/1376,2019-01-01T16:07:09Z,False,450740116.0,@juhasch Thanks! Done 😄 ,True,False
nodebox/opentype.js/246/pulls/nodebox/opentype.js/246,2017-01-04T15:05:12Z,False,270392005.0,"Hi @afternoon2,
this is a good idea.
The automated tests fail because of the indentation (please run `npm test` before committing).
The name `toHTML` suggests the function returns HTML code. Since it returns an SVG element, maybe it should have another more explicit name ?
Note also that `opentype.js` is intended to work also in non-browser environments (e.g. Node.js).",True,False
nodebox/opentype.js/246/pulls/nodebox/opentype.js/246,2017-01-04T18:11:58Z,False,270442884.0,I agree regarding the naming. Perhaps `Path.toElement` or `Path.toDOMElement` are more appropriate names.,True,False
nodebox/opentype.js/246/pulls/nodebox/opentype.js/246,2017-01-04T19:57:16Z,False,270470335.0,"Yes, the name might be misleading. `Path.toDOMElement` is much better. My intention was to make a method that would be helpful while coding svg animations (live rendering svg from font), so it's not useful outside the browser.

I have some problems with `npm test.` I mean -after I corrected indentation, in git-bash I'm still seeing some linebreak issues (49):

`validateLineBreaks: Invalid line break at <filepath>`

And here's a dummy question: how to fix it without opening each broken file?

",True,False
nodebox/opentype.js/246/pulls/nodebox/opentype.js/246,2017-01-04T20:57:08Z,False,270484313.0,"Yes, this is a pain if you are not using Linux.
To avoid this, I locally add the following line to the `.jscs` file before running `npm test`:
```
""validateLineBreaks"": ""CRLF"",
```
Then I get only 1 error for `./bin/server.js`
Line break errors don't matter since they will be automatically and silently corrected when you commit on github (don't commit `.jscs`). You just have to make sure you don't have other types of errors.

Maybe jscs offers the possibility to disable linebreak checks but I don't know how.",True,False
nodebox/opentype.js/246/pulls/nodebox/opentype.js/246,2017-01-04T21:12:38Z,False,270487854.0,"That works, thank you! Updated Codepen demo [here](http://codepen.io/jakub_antolak/pen/YNPwLd).",True,False
nodebox/opentype.js/246/pulls/nodebox/opentype.js/246,2017-01-05T21:07:16Z,False,270757796.0,Thanks! ,True,False
mastrgamr/cirkita-splash/8/pulls/mastrgamr/cirkita-splash/8,2020-04-30T14:54:40Z,False,621905744.0,"
This pull request is being automatically deployed with Vercel ([learn more](https://zeit.ink/github-learn-more)).
To see the status of your deployment, click below or on the icon next to each commit.

  🔍 Inspect: https://vercel.com/mastrgamr/cirkita-splash/6zue7tfwx
  ✅ Preview: https://cirkita-splash-git-dependabot-npmandyarnjquery-350.mastrgamr.now.sh
  	",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-15T23:45:30Z,False,381447669.0,"A bit off-topic but I didn't figure out from the code: The fix to those kind of issues is keeping track of the metadata (and the new FS interface does this). For a NAND image, I assume the metadata is built-in the image file, but, for a ""folder NAND"" (like Dolphin uses nowadays), where is this metadata going to be stored? ",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-16T09:29:01Z,False,381537576.0,"@mbc07 The new interface is designed with that in mind, but currently it doesn't store any metadata yet because doing that before we finish migrating off direct access in the codebase would cause the metadata to be incomplete and possibly wrong.

Once we finish the migration, well... I'm not completely sure yet. We could store metadata in filesystem specific attributes, but that's platform specific and I'm not sure every platform supports that. Or in a special file somewhere in the Dolphin profile, but it would still break horribly if someone decides to touch the NAND and we would still have to do ugly stuff like escaping file names because the Wii FS allows all printable characters, and Windows of course has limitations...

Or we could go with images. After mentioning it to JMC it's actually the solution JMC and I would prefer because:

* it's simple: we can just store everything we need in the image itself since the format is built with that in mind. We don't depend on the host file system, which may have limitations. The [format](https://wiibrew.org/wiki/NAND) is pretty simple too.

* it's more robust: it is much harder for users to accidentally break their NAND because they decided to touch it or put garbage in there (this has happened in the past on the forums :/)

* it lets Wii users avoid having to extract their NAND which is a lossy process which takes up more space

* it lets us automatically enforce the space limitation without worrying about users being confused after managing to put more stuff in the NAND than possible since there cannot be any hard limitation currently.

* for developers, it makes debugging IOS issues slightly easier since you could just use the same NAND with skyeye-starlet for testing.

* I already have a working branch with NAND image support and it's been confirmed to fix the Bolt issue and small problems like a System Menu crash, the Photo Channel showing ""files are corrupted"" on first launch, and possibly others.

But before we decide what to do, we first need to change the codebase to stop accessing the NAND directly :P",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-15T13:20:59Z,False,181582686.0,"You can use `'/'` instead of `""/""` here and in other places.",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-15T13:50:07Z,False,181583651.0,"`std::string`s are still going to be constructed in these cases, so I don't think there's an advantage to using `'/'` here. I can still change it if you want though",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-15T14:03:48Z,False,181584163.0,You can keep it like it is if you want to.,True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-16T02:12:22Z,False,181609403.0,"Generally it's cheaper to append a character literal over a string literal (don't need to run the character literal to check for the total characters being appended). But given this in a setup function, I don't think it matters too much.

(technically if we wanted to go full-on performance, we'd use `.append()` or `operator+=` instead of `operator+` for strings, because `append()` just extends the first string's buffer instead of constructing and discarding temporary `std::string` instances like what `operator+` does when chained together)",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-04-16T09:30:15Z,False,181673387.0,"Oh, that's good to know. I'll keep this in mind for future changes.",True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-05-04T02:03:40Z,False,185978849.0,Any reason for dropping the static_cast here?,True,False
dolphin-emu/dolphin/6651/pulls/dolphin-emu/dolphin/6651,2018-05-04T17:52:55Z,False,186167838.0,"Oops, rebase fail here. I've fixed it now -- thanks for catching this!",True,False
AxaGuilDEv/react-oidc/129/pulls/AxaGuilDEv/react-oidc/129,2019-07-10T08:16:05Z,False,509960099.0,"Looks like tslint-config-prettier is up-to-date now, so this is no longer needed.",True,False
znz/sylpheed-support/65/pulls/znz/sylpheed-support/65,2019-03-02T03:00:26Z,False,468876176.0,"Looks like capybara is up-to-date now, so this is no longer needed.",True,False
UshakovVasilii/gnome-shell-extension-freon/115/pulls/UshakovVasilii/gnome-shell-extension-freon/115,2018-11-19T18:44:52Z,False,439999283.0,Thanks,True,False
airbnb/Lona/203/pulls/airbnb/Lona/203,2018-10-01T19:07:04Z,False,426026047.0,"Good idea, done!",True,False
airbnb/Lona/203/pulls/airbnb/Lona/203,2018-10-01T18:57:16Z,False,221719222.0,Nice use of inline module open,True,False
NixOS/nixpkgs/30040/pulls/NixOS/nixpkgs/30040,2017-10-03T01:40:36Z,False,333714587.0,How is this diff possible? I already pushed this: 2f188ff37f9a43985e351d6a1edb570031c44518. Also backported to 17.09 and 17.03.,True,False
NixOS/nixpkgs/30040/pulls/NixOS/nixpkgs/30040,2017-10-03T03:10:12Z,False,333726329.0,Cherry-picking this commit yields no diff. So this seem to be just a github issue. Thanks anyway!,True,False
NixOS/nixpkgs/30040/pulls/NixOS/nixpkgs/30040,2017-10-03T04:31:33Z,False,333736017.0,"> How is this diff possible? I already pushed this: 2f188ff. Also backported to 17.09 and 17.03.

Looks like I based my commit on the 2 days old master. And your commit is made 13 hours ago. I thought I pulled recent master before making a patch, but apparently I didn't.

Anyway, thanks for a quick patch!",True,False
wpeverest/everest-forms/134/pulls/wpeverest/everest-forms/134,2019-04-29T09:39:45Z,False,487517403.0,LGTM :),True,False
Stupidism/stupid-rc-starter/26/pulls/Stupidism/stupid-rc-starter/26,2017-06-28T23:45:30Z,False,311822624.0,"## Version **6.0.1** just got published. 
[Update to this version instead 🚀](https://github.com/Stupidism/stupid-rc-starter/compare/greenkeeper%2Feslint-plugin-jsx-a11y-6.0.1?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>Remove src and and flow from tarball</strong>

<p>See <a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/pull/277"" class=""issue-link js-issue-link"" data-url=""https://github.com/evcohen/eslint-plugin-jsx-a11y/issues/277"" data-id=""239266148"" data-error-text=""Failed to load issue title"" data-permission-text=""Issue title is private"">#277</a></p>
</details>

<details>
<summary>Commits</summary>
<p>The new version differs by 5 commits.</p>
<ul>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/71ce135afc114478d057e3f832b3a9002208cbc8""><code>71ce135</code></a> <code>6.0.1</code></li>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/31753c7b6cce8c617bce81d635d7405d35ae3df6""><code>31753c7</code></a> <code>Update CHANGELOG.md</code></li>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/436acd27a5e9589d6009484f2284c7470bd67800""><code>436acd2</code></a> <code>Merge pull request #277 from jessebeach/remove-src-from-package</code></li>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/f9d3ba9a489f5a3bf6c793f2e97bab3f9a935619""><code>f9d3ba9</code></a> <code>Remove development artifacts from the NPM package</code></li>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/c121cd00ae2e90ae9fb2a14fc4f83e738a999471""><code>c121cd0</code></a> <code>chore(package): update flow-bin to version 0.49.1</code></li>
</ul>
<p>See the <a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/compare/131a75d3e0f1e87c01958ee70ba010515c4a4e27...71ce135afc114478d057e3f832b3a9002208cbc8"">full diff</a></p>
</details>",True,False
Stupidism/stupid-rc-starter/26/pulls/Stupidism/stupid-rc-starter/26,2017-06-29T01:11:56Z,False,311834436.0,"## Version **6.0.2** just got published. 
[Update to this version instead 🚀](https://github.com/Stupidism/stupid-rc-starter/compare/greenkeeper%2Feslint-plugin-jsx-a11y-6.0.2?expand=1) 

<details>
<summary>Release Notes</summary>
<strong>Fix .npmignore</strong>

<p>See <a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/pull/279"" class=""issue-link js-issue-link"" data-url=""https://github.com/evcohen/eslint-plugin-jsx-a11y/issues/279"" data-id=""239335439"" data-error-text=""Failed to load issue title"" data-permission-text=""Issue title is private"">#279</a></p>
</details>

<details>
<summary>Commits</summary>
<p>The new version differs by 3 commits.</p>
<ul>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/b15b7f845b3b7c504d7d255b811343a807115d48""><code>b15b7f8</code></a> <code>6.0.2</code></li>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/bb6038ba653ce29cf9a7e60810b8e61a35761bf0""><code>bb6038b</code></a> <code>Update CHANGELOG</code></li>
<li><a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/commit/1325369a1e4d83acb96365106d3a97ade2df3342""><code>1325369</code></a> <code>Prepend slash to top level dirs in npmignore</code></li>
</ul>
<p>See the <a href=""https://urls.greenkeeper.io/evcohen/eslint-plugin-jsx-a11y/compare/71ce135afc114478d057e3f832b3a9002208cbc8...b15b7f845b3b7c504d7d255b811343a807115d48"">full diff</a></p>
</details>",True,False
Nozbe/WatermelonDB/283/pulls/Nozbe/WatermelonDB/283,2019-03-12T16:37:47Z,False,472079844.0,"
<!--
  0 failure: 
  2 warning:  Please select an ..., Please add a chan...
  
  
  DangerID: danger-id-peril;
-->


<table>
  <thead>
    <tr>
      <th width=""50""></th>
      <th width=""100%"" data-danger-table=""true"">Warnings</th>
    </tr>
  </thead>
  <tbody><tr>
      <td>:warning:</td>
      <td>

  Please select an assignee
  </td>
    </tr>
  
<tr>
      <td>:warning:</td>
      <td>

  Please add a changelog entry for your changes. (Add #trivial to skip this.)
  </td>
    </tr>
  </tbody>
</table>



<p align=""right"">
  Generated by :no_entry_sign: <a href=""http://github.com/danger/danger-js/"">dangerJS</a>
</p>
",True,False
octokit/fixtures-server/95/pulls/octokit/fixtures-server/95,2020-09-10T23:47:18Z,False,690789585.0,":tada: This PR is included in version 6.0.8 :tada:

The release is available on:
- [npm package (@latest dist-tag)](https://www.npmjs.com/package/@octokit/fixtures-server/v/6.0.8)
- [GitHub release](https://github.com/octokit/fixtures-server/releases/tag/v6.0.8)

Your **[semantic-release](https://github.com/semantic-release/semantic-release)** bot :package::rocket:",True,False
eddyson-de/react-grid/358/pulls/eddyson-de/react-grid/358,2017-05-08T05:34:42Z,False,299776905.0,"
[![Coverage Status](https://coveralls.io/builds/11413948/badge)](https://coveralls.io/builds/11413948)

Coverage remained the same at 96.26% when pulling **ca7d596f853291515dea5feafa742c903c5c4655 on greenkeeper/eslint-plugin-react-7.0.0** into **fe2097543780b284d09145e92f710fb037742e76 on master**.
",True,False
vrinfer/angular-training-recipe/1/pulls/vrinfer/angular-training-recipe/1,2020-09-07T09:26:21Z,False,688196143.0,Superseded by #7.,True,False
JustinBeckwith/gcx/25/pulls/JustinBeckwith/gcx/25,2019-04-01T03:00:53Z,False,478419130.0,":tada: This PR is included in version 0.2.1 :tada:

The release is available on:
- [npm package (@latest dist-tag)](https://www.npmjs.com/package/gcx)
- [GitHub release](https://github.com/JustinBeckwith/gcx/releases/tag/v0.2.1)

Your **[semantic-release](https://github.com/semantic-release/semantic-release)** bot :package::rocket:",True,False
isanch14/MovieDB/3/pulls/isanch14/MovieDB/3,2021-03-10T11:14:56Z,False,795266190.0,Superseded by #8.,True,False
nirjo/A-TodoList/5/pulls/nirjo/A-TodoList/5,2021-03-10T17:54:12Z,False,795820541.0,Superseded by #7.,True,False
BarryThePenguin/jonno.dev/101/pulls/BarryThePenguin/jonno.dev/101,2020-02-03T19:39:43Z,False,581582692.0,"
This pull request is being automatically deployed with ZEIT Now ([learn more](https://zeit.ink/github-learn-more)).
To see the status of your deployment, click below or on the icon next to each commit.

  🔍 Inspect: https://zeit.co/barrythepenguin/jonnodev/ngby2smmo
  ✅ Preview: https://jonnodev-git-dependabot-npmandyarneslint-plugin-react-7183.barrythepenguin.now.sh
  	",True,False
blockchain/blockchain-wallet-v4-frontend/1549/pulls/blockchain/blockchain-wallet-v4-frontend/1549,2019-03-25T20:03:20Z,False,476355594.0,"
[![Coverage Status](https://coveralls.io/builds/22393921/badge)](https://coveralls.io/builds/22393921)

Coverage increased (+0.0008%) to 34.666% when pulling **dc5c58b30b3c930e726872e526a202ac947b8646 on new-data-e2e-tags** into **af68e4c798262de33d1cd2e02a97c76ef22dd5fa on development**.
",True,False
lparolari/snake/75/pulls/lparolari/snake/75,2020-07-23T17:40:02Z,False,663140153.0,Closing this in favor of #77,True,False
google/openhtf/807/pulls/google/openhtf/807,2018-07-09T20:05:27Z,False,201129954.0,"I think this was intentional, but in my opinion “if” is sufficient.",True,False
google/openhtf/807/pulls/google/openhtf/807,2018-07-09T20:07:58Z,False,201130653.0,Discussion: https://english.stackexchange.com/questions/69709/is-useable-preferred-in-certain-regions-or-just-an-alternate-spelling-of-usa,True,False
google/openhtf/807/pulls/google/openhtf/807,2018-07-10T00:03:58Z,False,201184021.0,"Yeah, I wasn't sure especially as the number of 'f's just kept going up in subsequent comments. :-)",True,False
xenserver/xenadmin/1989/pulls/xenserver/xenadmin/1989,2018-03-15T13:30:37Z,False,373375939.0,"This looks good to me. We're expecting the performance to be better with the new build anyway so hopefully nobody ever comes close to seeing it take 10 minutes, but it makes more sense to have the overhead than not.",True,False
wowafrica/wowafrica/123/pulls/wowafrica/wowafrica/123,2016-06-15T16:57:42Z,False,226250712.0,"[![Coverage Status](https://coveralls.io/builds/6611098/badge)](https://coveralls.io/builds/6611098)

Coverage remained the same at 61.202% when pulling **b7a3b7b8a509d2c2856d50ff3207e852c605343f on css-module** into **5084105fe0fafc77c2ed60703651f01e8e049df7 on develop**.
",True,False
wowafrica/wowafrica/123/pulls/wowafrica/wowafrica/123,2016-06-16T18:24:57Z,False,226571041.0,"[![Coverage Status](https://coveralls.io/builds/6630287/badge)](https://coveralls.io/builds/6630287)

Coverage remained the same at 61.202% when pulling **48df6defe792aaa8bc810fdf66bef4248f17f336 on css-module** into **5084105fe0fafc77c2ed60703651f01e8e049df7 on develop**.
",True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:21:49Z,False,292545368.0,Remove the space between the attribute `class` and the value. Same for `alt`.,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:22:36Z,False,292545723.0,Same for `src`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:22:47Z,False,292545811.0,Same for `class`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:23:02Z,False,292545921.0,Same for `class`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:23:11Z,False,292545997.0,Same for `class`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:24:01Z,False,292546422.0,You can delete this empty file.,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:24:43Z,False,292546767.0,Add a space between `.title-text` and `{`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:26:16Z,False,292547496.0,Add a space between `tech-card` and `{`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:27:29Z,False,292548124.0,Replace by `padding: 15px 10px 10px;`,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:29:02Z,False,292548825.0,Same,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:29:08Z,False,292548862.0,same,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:29:13Z,False,292548895.0,same,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:29:19Z,False,292548933.0,same,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T16:29:24Z,False,292548981.0,same,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T17:38:26Z,False,292578812.0,Add the variable `$tech-logo-size: 100px;` previously presented  in the setup trello card and use it here.,True,False
wolox-training/oc-react/3/pulls/wolox-training/oc-react/3,2019-06-11T17:40:41Z,False,292579718.0,"I think that you can use `,`  selector to apply CSS rules to many classes. For example: `.tech-name, .tech-release, .tech-info { margin: 5px; }`",True,False
MycroftAI/mycroft-core/1694/pulls/MycroftAI/mycroft-core/1694,2018-07-18T16:14:09Z,False,405988542.0,"Looks good!
(There's a spelling error on L96)",True,False
postaddictme/instagram-java-scraper/32/pulls/postaddictme/instagram-java-scraper/32,2017-04-30T08:45:28Z,False,298219780.0,@luborliu thank you for contribution,True,False
bower_____bower_____1748,2015-03-21T13:56:41Z,True,bower_____bower_____1748_____31671590,"Based on https://github.com/bower/bower/pull/1592

---
- bower.lock doesn't exist:
  - [x] bower install creates bower.lock file only after all-successful non-production installation
  - [x] bower install --production complains there's no bower.lock and exits
  - [x] bower update acts as bower install
- bower.lock exists dependenies in bower.json match those on bower.lock
  - [x] bower install installs exact packages from bower.lock
  - [x] bower install --production installs exact packages from bower.lock ignoring devDependencies
  - [x] bower update is no-op
  - [x] if installation would change bower.lock, it fails with error message
- bower.lock exists and there are only extra dependencies in bower.json relative to bower.lock
  - [x] bower install tries to install bower.lock with only new packages from bower.json added. Installation fails if old bower.lock is not a subset of new bower.lock.
  - [x] bower install --production fails
  - [x] bower update --all re-creates bower.lock
- bower.lock` exists and dependencies in bower.json changed relative to bower.lock
  - [x] bower install fails, and says you need to bower update <package> first
  - [x] bower install --production fails
  - [x] bower update complains there's no package specified to update
  - [x] bower update --all re-creates bower.lock
  - [x] bower update <package> tries to install bower.lock with <package> version replaced with version from bower.json. Installation fails if old bower.lock is not a subset of new bower.lock (except updated package).
",True,True
bower_____bower_____1748,2015-03-25T15:30:04Z,True,bower_____bower_____1748_____86082671,"@sheerun - So, when running `bower update` and nothing has yet to be installed, should a lock file be required as at that point it really acts like `bower install`?",True,True
bower_____bower_____1748,2015-03-26T13:56:07Z,True,bower_____bower_____1748_____86522789,@sheerun bump for the question above... :smile: ,True,True
bower_____bower_____1748,2015-03-27T01:43:27Z,True,bower_____bower_____1748_____86785781,"@kodypeterson Sorry for the delay. Yes, indeed it should do the same as `bower install` :)",True,True
bower_____bower_____1748,2015-03-30T19:23:56Z,True,bower_____bower_____1748_____87798884,"@sheerun any thoughts on the lock file being .bower.lock instead of bower.lock?

Just wondering if we really want to make it a non-dot file...",True,True
bower_____bower_____1748,2015-03-30T19:30:09Z,True,bower_____bower_____1748_____87800340,"Also, I noticed that most of the update tests are invalid as they call tempDir.prepare({JSON}) after the install. Which .prepare will remove all of the contents in the directory.

So, when update runs, it is running against an empty directory with no dependencies installed, so it just acts like `bower install` :frowning: ",True,True
bower_____bower_____1748,2015-03-30T20:05:46Z,True,bower_____bower_____1748_____87811865,"How should bower link be handled, it in turn calls bower update? Should it follow the same rules as bower update?",True,True
bower_____bower_____1748,2015-03-30T20:41:37Z,True,bower_____bower_____1748_____87825661,"`bower link` is totally separate thing. It just creates a symlink to some other directory.

I think we don't need to worry about it.",True,True
bower_____bower_____1748,2015-03-31T14:14:35Z,True,bower_____bower_____1748_____88103325,"@sheerun  Are you sure? :smile: 

https://github.com/bower/bower/blob/master/lib/commands/link.js#L62",True,True
bower_____bower_____1748,2015-03-31T17:41:08Z,True,bower_____bower_____1748_____88183496,Huh. I'm not sure if it's necessary. Maybe we should check what NPM does..,True,True
bower_____bower_____1748,2015-03-31T18:20:43Z,True,bower_____bower_____1748_____88196768,"@sheerun - It seems it runs an install https://github.com/npm/npm/blob/master/lib/link.js#L134

For now, I have left it as is. Allowing it to run update and allowing the update to run without allowing it to make changes to the lockfile. Your call on if that is correct.",True,True
bower_____bower_____1748,2015-03-31T18:26:16Z,True,bower_____bower_____1748_____88198175,"I think most reasonable is to just call install, instead of of update.
Install doesn't change lockfile by default.

On Tue, Mar 31, 2015 at 11:20 AM, Kody J. Peterson <notifications@github.com
> wrote:

> @sheerun <https://github.com/sheerun> - It seems it runs an install
> https://github.com/npm/npm/blob/master/lib/link.js#L134
>
> For now, I have left it as is. Allowing it to run update and allowing the
> update to run without allowing it to make changes to the lockfile. Your
> call on if that is correct.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/bower/bower/pull/1748#issuecomment-88196768>.
>
",True,True
bower_____bower_____1748,2015-03-31T19:42:17Z,True,bower_____bower_____1748_____88222583,"Alright, I think I have everything covered here :smile: 

Time for some regression testing? :smile: 

Not sure why there is a -0.12% decrease in code coverage.... Do I need to add more tests or is this going to be ok?",True,True
bower_____bower_____1748,2015-03-31T20:30:30Z,True,bower_____bower_____1748_____88234827,"Yeah, I think we need some more tests and peer review on this. I'll try to review it soon.

Could you squash the commits in meaningful pieces?

What about ""if installation would change bower.lock, it fails with error message""? This one is actually pretty important as it ensures that production builds are reproducible. For example it should fail when someone changes the commit behind a tag on GitHub.",True,True
bower_____bower_____1748,2015-03-31T20:35:22Z,True,bower_____bower_____1748_____88236441,"Ah! That is what that means. I will add that functionality, no problem!

I will also add more tests somehow..... Most of the lockfile logic is tested... I will see what else I can add.",True,True
bower_____bower_____1748,2015-03-31T21:15:13Z,True,bower_____bower_____1748_____88252502,@kodypeterson why not use a lock module instead? See: https://github.com/IndigoUnited/node-proper-lockfile and https://www.npmjs.com/package/lockfile,True,True
bower_____bower_____1748,2015-03-31T21:19:08Z,True,bower_____bower_____1748_____88254020,@satazor At first glance it seems that module is for locking a specific file... That is not really what we are trying to accomplish... Am I wrong in what that module does?,True,True
bower_____bower_____1748,2015-03-31T21:26:00Z,True,bower_____bower_____1748_____88255276,"Both modules work by locking a file yes, but isn't what your doing? You are creating a bower.lock to lock down a project. Your lock file strategy is using .writeFile which isn't atomic. What I'm saying is that file locking is not an easy matter and it should be delegated to more mature modules such as those two that I mentioned.",True,True
bower_____bower_____1748,2015-03-31T21:27:50Z,True,bower_____bower_____1748_____88255608,@satazor We are locking down versions of libraries you are using. We want to be sure that when installing that you are always installing the same versions of dependencies and such that you did when you were developing locally. We are creating a very similar feature to NPM's shrinkwrap.,True,True
bower_____bower_____1748,2015-03-31T21:29:36Z,True,bower_____bower_____1748_____88255999,Oh I totally misunderstood this then. Just ignore me. ,True,True
bower_____bower_____1748,2015-04-29T16:04:22Z,True,bower_____bower_____1748_____97481523,@sheerun - I am working on adding that last feature and a few more tests. Also removing all console logs!!! I have found that I am really good at leaving those in. Hopefully we should be ready to really test this guy out and get it shipped! :smile: ,True,True
bower_____bower_____1748,2015-05-17T14:35:40Z,True,bower_____bower_____1748_____102809152,:+1: ,True,True
bower_____bower_____1748,2015-05-22T08:38:40Z,True,bower_____bower_____1748_____104571863,"This is great, thanks for all your hard work on this. Looking forward to seeing it implemented.",True,True
bower_____bower_____1748,2015-05-26T22:08:11Z,True,bower_____bower_____1748_____105681805,@sheerun - I think we are all good here! :smile: 2 months later ;),True,True
bower_____bower_____1748,2015-06-02T17:29:51Z,True,bower_____bower_____1748_____108024212,@sheerun - bump ^^,True,True
bower_____bower_____1748,2015-06-02T18:09:01Z,True,bower_____bower_____1748_____108036459,"I'm pretty busy these days, but I'll try to review soon",True,True
bower_____bower_____1748,2015-06-02T18:09:12Z,True,bower_____bower_____1748_____108036506,Or maybe someone else can? :),True,True
bower_____bower_____1748,2015-06-05T08:44:31Z,True,bower_____bower_____1748_____109205086,":+1:
",True,True
bower_____bower_____1748,2015-06-09T22:45:48Z,True,bower_____bower_____1748_____110525750,"I would like to point out the discussion on the bundler github - https://github.com/bundler/bundler/issues/694 - that they're moving away from the .lock suffix and it's probably worth considering following suit, as it's always clashed with old *NIX conventions.
",True,True
bower_____bower_____1748,2015-06-22T19:16:26Z,True,bower_____bower_____1748_____114225298,Any reason this hasnt been merged yet?,True,True
bower_____bower_____1748,2015-06-22T19:21:54Z,True,bower_____bower_____1748_____114226614,@aequasi No one has had time to review it :disappointed: @sheerun anyone you can get to review this?,True,True
bower_____bower_____1748,2015-06-22T23:08:12Z,True,bower_____bower_____1748_____114297051,"Not at least until 1st July.. Sorry.
",True,True
bower_____bower_____1748,2015-07-13T09:07:10Z,True,bower_____bower_____1748_____120859308,ping? already July13!,True,True
bower_____bower_____1748,2015-07-13T23:17:10Z,True,bower_____bower_____1748_____121088036,"Currently I'm working on deploying pluggable resolvers feature. If someone has time to review this, please do it.",True,True
bower_____bower_____1748,2015-07-15T23:00:38Z,True,bower_____bower_____1748_____121772134,@sheerun hacked?,True,True
bower_____bower_____1748,2015-08-04T19:09:00Z,True,bower_____bower_____1748_____127723679,"+1 on this

This is holding us up too and we have a hack to get around it.
",True,True
bower_____bower_____1748,2015-09-08T05:53:26Z,True,bower_____bower_____1748_____138442773,I really wish to see this feature released. Is there something for a non-contributor so far to help on this?,True,True
bower_____bower_____1748,2015-09-08T06:03:17Z,True,bower_____bower_____1748_____138446014,"@tuwannu You could checkout this branch locally, test different scenarios, and report issues with it :) There must be some.",True,True
bower_____bower_____1748,2015-09-08T06:29:59Z,True,bower_____bower_____1748_____138449285,It would be better for testing if the author rebased it first.,True,True
bower_____bower_____1748,2015-09-11T15:57:51Z,True,bower_____bower_____1748_____139583863,@enumag @sheerun I will get it rebased for testing. Can we get a release scheduled for this please! :smile: ,True,True
bower_____bower_____1748,2015-09-13T17:58:34Z,True,bower_____bower_____1748_____139899937,@kodypeterson I'm standing-by to help testing after the rebase. Also made a pull request a few days ago to your repo to fix a couple of unit tests.,True,True
bower_____bower_____1748,2015-09-30T07:55:07Z,True,bower_____bower_____1748_____144317826,":+1: 
",True,True
bower_____bower_____1748,2015-09-30T08:00:59Z,True,bower_____bower_____1748_____144319018,"not sure if I understood your description properly but I think you could simplify the logic for detecting mismatches between the bower.json and bower.lock file by simply storing a hash of the bower.json file in your bower.lock file. that way you can always warn the user if someone has changed the bower.json file since the bower.lock file was generated. afaik this is how the composer package manager works for PHP.
",True,True
bower_____bower_____1748,2015-10-13T17:59:28Z,True,bower_____bower_____1748_____147796466,+1,True,True
bower_____bower_____1748,2015-10-15T02:27:22Z,True,bower_____bower_____1748_____148258852,For the love of god make this happen! This will make bower kick ass!,True,True
bower_____bower_____1748,2015-10-15T09:17:23Z,True,bower_____bower_____1748_____148327598,:+1: ,True,True
bower_____bower_____1748,2015-10-15T09:18:29Z,True,bower_____bower_____1748_____148327803,+1,True,True
bower_____bower_____1748,2015-10-15T09:30:58Z,True,bower_____bower_____1748_____148332529,can we please stop with the +1 ? Just subscribe if you want to know when/if anything happens.,True,True
bower_____bower_____1748,2015-10-15T10:56:47Z,True,bower_____bower_____1748_____148350775,"since this is not getting any attention from the core devs it seems, one option would be to refactor this into a custom resolver. but honestly the default behavior of bower is so far away from deterministic behavior I wonder if its really worth it to try and salvage it.",True,True
bower_____bower_____1748,2015-10-15T11:05:21Z,True,bower_____bower_____1748_____148352979,"I'm actually kind of blown away that this mechanism wasn't included in bower from the beginning. It's such a fundamental aspect of externally sourced dependency management, you wonder how bower got this far.",True,True
bower_____bower_____1748,2015-10-15T11:08:38Z,True,bower_____bower_____1748_____148354220,"![most-evil-bower](https://cloud.githubusercontent.com/assets/1989646/10512044/d7d4aab6-733d-11e5-80bf-85e9645b8378.jpg)
",True,True
bower_____bower_____1748,2015-10-16T18:43:40Z,True,bower_____bower_____1748_____148802938,lol people are writing [blog posts](https://blog.liip.ch/) about this. Has this issue the highest priority ? Because it looks like it should… I think many people are leaving Bower just because of this.,True,True
bower_____bower_____1748,2015-10-19T08:39:05Z,True,bower_____bower_____1748_____149146152,"@syzer you can now also admire your illustration in the blog post https://blog.liip.ch/archive/2015/10/16/bower-kthxbye.html

Lockfile would give bower the boost it needs right now.",True,True
bower_____bower_____1748,2015-10-21T17:19:13Z,True,bower_____bower_____1748_____149967371,"@sheerun, can you comment as to whether this PR is under active review? A status update on your plans here would be very appreciated. I know a lot of people affected by this issue and there hasn't been much in the way of official communication lately.",True,True
bower_____bower_____1748,2015-10-22T04:37:07Z,True,bower_____bower_____1748_____150104311,"Currently it's not under review by me. There are currently no other active core members in Bower.

I'm very interested in this feature as well, but it would require tenths of hours for review and finish. And then even more for maintenance after release. It probably means that Bower needs to seek stable financial support first, so it can provide appropriate support. Even when people that are currently pushing for it, become uninterested in maintaining it (possible, and even very likely to happen).

The main reason Bower got nice Pluggable Resolvers is because Artifactory agreed to sponsor it for this feature. Without it we'd need to accept [original PR for them](https://github.com/bower/bower/pull/1686), created with minimal effort, and then get far worse API for and maintenance issues afterwards. The same applies to this feature. To release it we need to be sure that it is stable, future-proof, and there's someone to maintain it.

As a first step I'll try to find some sponsors, so https://salt.bountysource.com/teams/bower no longer says ""$0 this month from 0 supporters"". The next (easier) step is to find developers ready to develop and maintain this feature for little money we get. Personally I find it hilarious how much Bower is used and how little support it gets. Community comments about ""killing it as soon as possible"" don't help as well.",True,True
bower_____bower_____1748,2015-10-22T05:41:32Z,True,bower_____bower_____1748_____150113102,"@sheerun, your update is well taken.

A few points of unsolicited feedback, from me as just some random guy on the internet (who has helped fund a few OSS projects) to you, the apparent sole maintainer of a very popular open source project:

* The structure of the ""organization"" behind bower is completely opaque from the website. When I started using bower, I clicked around bower.io, noted that it seemed professionally (if minimally) produced, and that there was a lot of community support for it. I assumed there was a team and probably at least one serious corporate sponsor. The about page says ""Bower is a team effort,"" which is a statement that I now regard as generally untrue.
* That there *no maintainers* besides you, who cannot afford to spend a lot of time on the project, is a *serious problem*, and one that is not made apparent except by explicitly pestering you in this comment thread. I would suggest making a very prominent call to action to get either the funds or support you need **right on the homepage**. The bountysource page you linked to I cannot find anywhere on bower.io.
* Bower is clearly important enough to the infrastructure of enough major websites that you can probably flat out charge them for access to even *just* this feature or enterprise support services, etc.",True,True
bower_____bower_____1748,2015-10-22T05:58:29Z,True,bower_____bower_____1748_____150115483,"I've prepared a Google Form for anyone interested supporting Bower. Please fill it if you can:

http://goo.gl/forms/P1ndzCNoiG",True,True
bower_____bower_____1748,2015-10-27T22:24:02Z,True,bower_____bower_____1748_____151663146,"+1. 

Showstopper this. ",True,True
bower_____bower_____1748,2015-11-08T08:37:17Z,True,bower_____bower_____1748_____154789508,@sheerun can you give me a $number for you to round this feature up ?,True,True
bower_____bower_____1748,2015-11-08T12:18:36Z,True,bower_____bower_____1748_____154819159,I think ~$5000 is a reasonable number (for implementing and then maintaining for some time). But I won't so that it as I don't have enough time. Maybe @kodypeterson @faceleg or @albertinad could tell?,True,True
bower_____bower_____1748,2015-11-13T21:41:27Z,True,bower_____bower_____1748_____156564973,"@sheerun claims of bower's death are spreading really fast right now across HN, Reddit, and individual projects. I would suggest a brief PR statement that puts the myths to rest and includes a call to action for the funding this project needs, otherwise usage will probably drop due to FUD.",True,True
bower_____bower_____1748,2015-11-13T21:47:33Z,True,bower_____bower_____1748_____156568507,@nnjpp @sheerun Came here because of this.. from reddit via a tweet. Some clarification on the state of Bower would be great... and perhaps this publicity could help the project.,True,True
bower_____bower_____1748,2015-11-14T01:10:43Z,True,bower_____bower_____1748_____156602898,"I hate adding +1 comments, but +1 @nnjpp @AdamWills.",True,True
bower_____bower_____1748,2015-11-14T11:11:57Z,True,bower_____bower_____1748_____156687254,The bower project is seeking both funding and active contributors.,True,True
bower_____bower_____1748,2015-11-14T15:09:24Z,True,bower_____bower_____1748_____156709909,"If it's not clear yet: bower is stable software, bower is not dying, bower looks for contributors and funding.
",True,True
bower_____bower_____1748,2015-11-14T21:15:50Z,True,bower_____bower_____1748_____156746373,"If you are seeking contributors and funding you should really, really make
that clear on the website instead of hoping people stumble onto this thread.
On Nov 14, 2015 7:09 AM, ""Adam Stankiewicz"" <notifications@github.com>
wrote:

> If it's not clear yet: bower is stable software, bower is not dying, bower
> looks for contributors and funding.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/bower/bower/pull/1748#issuecomment-156709909>.
>
",True,True
bower_____bower_____1748,2015-11-14T21:27:32Z,True,bower_____bower_____1748_____156747129,@vincentwoo For now it's only in the README. At the very top.,True,True
bower_____bower_____1748,2015-11-15T14:33:37Z,True,bower_____bower_____1748_____156815132,I agree with @vincentwoo on this. I've opened [a PR for adding a callout banner to the website](https://github.com/bower/bower.github.io/pull/175). ,True,True
bower_____bower_____1748,2015-12-13T22:13:15Z,True,bower_____bower_____1748_____164302725,"@kodypeterson Great work on this. 

As @sheerun mentioned before, is it possible to squash this into meaningful commits and rebase against master? It's hard to review in its current state.",True,True
bower_____bower_____1748,2015-12-13T23:00:06Z,True,bower_____bower_____1748_____164308440,@Utsav2 Could you do it instead and send another PR?,True,True
bower_____bower_____1748,2015-12-14T00:47:28Z,True,bower_____bower_____1748_____164315781,#2100 ,True,True
pallets_____click_____493,2015-12-17T22:49:08Z,True,pallets_____click_____493_____54042882,"this one is for consideration, it implements smarter matrix builds and uses more modern tox features
it also replaces the makefile
",True,True
pallets_____click_____493,2016-01-02T19:40:34Z,True,pallets_____click_____493_____168422282,"Unsure about replacing Makefile with language-specific tox.

Perhaps Makefile could be a wrapper for tox?
",True,True
pallets_____click_____493,2016-01-02T19:54:31Z,True,pallets_____click_____493_____168422805,"Its a python only project to begin with and tox is more portable
",True,True
bower_____bower_____1748,2016-01-27T14:50:34Z,True,bower_____bower_____1748_____175665137,"No project or version of any project is ever completed without any bugs. Thats why versions keep bumping up for any repository.

You should release as dev version and contributor would be happy to fix and maintain this feature. 

For more then 3+ years, this feature is been pending and 1 year for review as contributor completed his task. 

**Please just release this under dev version and let everyone else review it, test it and give there feedback.** ",True,True
bower_____bower_____1748,2016-01-27T14:58:27Z,True,bower_____bower_____1748_____175668943,"If you need any help with testing, please feel free to message me. ",True,True
bower_____bower_____1748,2016-03-13T10:23:21Z,True,bower_____bower_____1748_____195930008,For what it's worth shrinkwrap functionality is available using [bower-shrinkwrap-resolver](https://github.com/shyiko/bower-shrinkwrap-resolver). You might find it useful until this PR gets merged in.,True,True
bower_____bower_____1748,2016-05-07T15:00:35Z,True,bower_____bower_____1748_____217642840,+1,True,True
bower_____bower_____1748,2016-05-07T15:04:54Z,True,bower_____bower_____1748_____217643063,"In my opinion, if bower lock exist bower install shouldn't fails, but just install the bower lock content with information message.",True,True
DragonetMC_____DragonProxy_____150,2016-06-13T14:34:53Z,True,DragonetMC_____DragonProxy_____150_____225599543,"If Dragonproxy is set to offline mode, yes. But if you have it set to cls or online mode, players have to sign in through their Mojang account and have a valid Minecraft account on it. Authentication via cls is through Dragonet's homepage. If you have set auth to online, then the player will have to enter Mojang e-mail and password in the chat before the proxy sends the player to the server.",True,True
DragonetMC_____DragonProxy_____150,2016-06-13T14:41:18Z,True,DragonetMC_____DragonProxy_____150_____225601462,"Oh, no idea it had a forums. Thank you",True,True
DragonetMC_____DragonProxy_____150,2016-06-13T14:42:59Z,True,DragonetMC_____DragonProxy_____150_____225602025,"No problems at all!
",True,True
bower_____bower_____1748,2016-08-23T08:48:35Z,True,bower_____bower_____1748_____241667152,"@kodypeterson To release it as quickly as possible we'd need to put it in current 1.x version of bower, and make it backward compatible (opt-in). What sounds reasonable is:

- Squash all commits into one (it makes rebase easier)
- Rebase this PR onto master
- Add `--lock` flag to `bower install` to enable this feature when bower.json already exists
- Add a warning if there isn't a lockfile available, prompting to use `--lock` flag
- After bower.lock has been created, keep implemented behavior
- Do not modify any existing tests and only create new ones (when `bower.lock` is present)
- Make sure all current tests pass

If we ever release 2.0, we set `--lock` to be a default.

As for lock itself, I see it contains few extra keys we don't want, especially they contain absolute paths:

- `endpoint`, `canonicalDir`

```
  ""endpoint"": {
    ""name"": ""bower"",
    ""source"": ""/Users/sheerun/Source/Bower/bower"",
    ""target"": ""1.7.9""
  },
  ""canonicalDir"": ""/Users/sheerun/Source/Bower/bower"",
```

Also, we need to put version of bower it was packaged with to `version` key, plus additional behavior:

- If bower minor version in bower.lock is greather than current bower version, refuse to install package, indicating that newer bower version is necessary.

I've also encountered an error when installing local package without bower.json:

```
Stack trace:
TypeError: Cannot read property 'pkgMeta' of undefined
    at /Users/sheerun/Source/Bower/bower/lib/util/lockFile.js:22:84
    at /Users/sheerun/Source/Bower/bower/node_modules/mout/object/forOwn.js:12:27
```

I can do more testing if we you manage to fix those. Thank you for being interested in continuing your work.",True,True
bower_____bower_____1748,2016-08-23T10:13:46Z,True,bower_____bower_____1748_____241687631,"@kodypeterson Also, then I did ""bower install angular-route"", only ""angular-route"" got saved to bower.lock, while it should also contain ""angular"".",True,True
bower_____bower_____1748,2016-08-23T13:59:41Z,True,bower_____bower_____1748_____241740079,"@sheerun I am on it, I will see what I can get through this weekend along with cleanup and such!",True,True
bower_____bower_____1748,2016-08-23T14:35:00Z,True,bower_____bower_____1748_____241751564,"@kodypeterson I fixed it up into one commit and tried rebasing it some time
back in #2100, it might be useful to get started there.

On Aug 23, 2016 7:00 AM, ""Kody J. Peterson"" <notifications@github.com>
wrote:

> @sheerun
> <https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_sheerun&d=CwMCaQ&c=8hUWFZcy2Z-Za5rBPlktOQ&r=jDVzeY6gHbUDoSom0QsiEI2ek-5FZO0iCFMJ3mE_qQs&m=VRx6CCxKMzIjyVpB-xwTuW70QIAAwG-6jGr4ccj0mXM&s=UNVDcmca6T38FOuTZU8EMei1B73YoZW0DNmpaJqj9vo&e=>
> I am on it, I will see what I can get through this weekend along with
> cleanup and such!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_bower_bower_pull_1748-23issuecomment-2D241740079&d=CwMCaQ&c=8hUWFZcy2Z-Za5rBPlktOQ&r=jDVzeY6gHbUDoSom0QsiEI2ek-5FZO0iCFMJ3mE_qQs&m=VRx6CCxKMzIjyVpB-xwTuW70QIAAwG-6jGr4ccj0mXM&s=6UuuRZ_ihh5W6Jq2HDlkb7cNmCiJtkYwfxGoSk3m9EI&e=>,
> or mute the thread
> <https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AFM7qwe84HVnbjsjSMJx2SKjs0A83W-2Dnks5qivzsgaJpZM4DydXS&d=CwMCaQ&c=8hUWFZcy2Z-Za5rBPlktOQ&r=jDVzeY6gHbUDoSom0QsiEI2ek-5FZO0iCFMJ3mE_qQs&m=VRx6CCxKMzIjyVpB-xwTuW70QIAAwG-6jGr4ccj0mXM&s=V0KRIIhEPIjjEGdsqefhlI2jHn4iiyVIDysg8Rnfuy4&e=>
> .
>
",True,True
bower_____bower_____1748,2016-08-23T14:37:07Z,True,bower_____bower_____1748_____241752304,"@Utsav2 awesome! i will see what I can get from that. I have a feeling that both being so long ago the merge process is going to be a rough one. I might just need to cherry pick manually the changes in and maybe reorganize a bit. 

Thanks for the reference though!",True,True
bower_____bower_____1748,2016-10-14T13:09:42Z,True,bower_____bower_____1748_____253794714,@kodypeterson need any help?,True,True
bower_____bower_____1748,2016-10-14T13:18:22Z,True,bower_____bower_____1748_____253796566,Maybe a better route is to fix bower support in https://yarnpkg.com/ that already has file locking,True,True
bower_____bower_____1748,2016-10-14T13:35:57Z,True,bower_____bower_____1748_____253800474,"@sheerun I'm not entirely sure how practical that is; we're using PureScript which leverages Bower for dependency management and it looks like support for Bower in Yarn is really just in its infancy e.g. https://github.com/yarnpkg/yarn/pull/896.

Does this mean that you would no longer be willing to consider this patch?",True,True
bower_____bower_____1748,2016-10-14T13:46:14Z,True,bower_____bower_____1748_____253803047,Maybe we could at least adopt lockfile format of yarn?,True,True
pallets_____click_____493,2016-10-25T04:34:46Z,True,pallets_____click_____493_____255933884,"T'was exploring and ran across this pull.  Interestingly, in my own packages I have recently stripped out all things Tox entirely, as Travis already provides Python language matrix options.  Previously using `tox-travis` to translate that through, but then I realized I didn't need to create a new venv within my existing venv (adding more than 700 files) just to run `setup.py register sdist bdist_wheel upload`, plus that Tox utterly broke for a while making my tests undiscoverable.

On the regenerating documentation front, Make has built-in change tracking and dependency collection.  I.e. it's smart enough to not regenerate docs unless needed, or, [not re-run `setup.py develop` unless the metadata has actually changed](https://github.com/marrow/cinje/blob/develop/Makefile#L27), etc.  It's the mature build system that Tox is not.  (In a similar way that Tox is the test isolation framework that Make is not.)  As a developer dependency, Make is universal.",True,True
pallets_____click_____493,2016-10-25T08:25:29Z,True,pallets_____click_____493_____255970206,"@amcgregor well, how do i as a developer run a travis matrix locally - thats the mian point of tox - local execution so i can test my changes locally, directly without the internet

while i am not exactly happy with the tox syntax either, its still completely beating any other tooling i have seen for that

also its not just about python versions, but also about matrices with dependencies/versions of dependencies

my experience with make is pretty much, that it is not up to par even remotely as soon as a matrix comes into play

",True,True
pallets_____click_____493,2016-10-25T12:57:58Z,True,pallets_____click_____493_____256027010,Abandoning tox was never up for debate.,True,True
pallets_____click_____493,2016-10-25T14:25:56Z,True,pallets_____click_____493_____256050038,"> Abandoning tox was never up for debate.

I'm very sorry people stopped reading at the anecdote.

I'm against the idea of this pull request to force Tox to do things it was not meant to do in the name of purity or out of some distaste of make simply because it's a technology that is older than a bulk of developers in the industry.  To quote:

> It's the mature build system that Tox is not. (In a similar way that Tox is the test isolation framework that Make is not.)

Use the right tool for the right job, is all.  The majority of your reply @RonnyPfannschmidt, seems based on the presumption that I'm suggesting removal of Tox. Which I am not.

```
[testenv:upload-docs]
...

[testenv:release]
...
```

Those are pinned environments pretending to be phony Make targets, not build matrix ones, so I really don't grok:

> its not just about python versions, but also about matrices with dependencies/versions of dependencies

When clearly, the _automation_ part has nothing to do with matrices.  Or dependencies.  Or versions of dependencies.  Excluding the cases where it actually could, _if using Make_.  (E.g. dependent metadata rebuilding, documentation rebuilding only if source files were updated, etc.)",True,True
pallets_____click_____493,2016-10-25T14:36:13Z,True,pallets_____click_____493_____256053086,"Thanks for making your point clear (I agree).

>I'm very sorry people stopped reading at the anecdote.

You didn't specify your concrete suggestion at all and instead aimed at what seemed like a direct comparison between make and tox, so I was left to guess. Implying that people are too lazy to understand a point you initially didn't make is rude.",True,True
pallets_____click_____493,2016-10-25T14:37:02Z,True,pallets_____click_____493_____256053343,"@amcgregor i see what you mean, now - tox is indeed not meant for that automation, but does it already more portable than make (hello windows)

i actually plan to add this to tox in a more complete manner (for stuff like linters its also very sensible)",True,True
pallets_____click_____493,2016-10-25T14:57:31Z,True,pallets_____click_____493_____256059659,"http://gnuwin32.sourceforge.net/packages/make.htm — same version that came bundled with Xcode.   One problem solved after a two second Google search.

Tox and Make automation are ""developers of the library"" tools, not ""users of the library"" tools, i.e. needed to work on Pallets, but not use Pallets.  This makes such strict removal of non-Python dependency silly, as the target audience that would benefit from it is minuscule, and should actually already have a better environment (with proper tooling) set up anyway.  There's also the fact that of the two phony make targets, upload-docs and release, neither are for general use.  Only for use by maintainers of the package, an even smaller target demographic.

Then there's the whole ""creating a venv even when one is not necessary"" aspect.  After invoking those two tox commands you'll end up with more than 1500 files across two venvs. The inefficiency and waste people find acceptable in the name of purity I just don't comprehend.  All of that construction and maintenance time, and disk space (which, in my case, is actually cloud-backed storage, so every file that changes represents an upload) adds up.

On the linting front, a little `pytest-flakes` goes a long way, especially when combined with [`pre-commit`](http://pre-commit.com) ([example config](https://github.com/marrow/cinje/blob/develop/.pre-commit-config.yaml)).  (And yes, it's Python. ;)",True,True
pallets_____click_____493,2016-10-25T16:06:20Z,True,pallets_____click_____493_____256080746,"as far as i can tell you propose a less automated setup that a developer manually has to set up to get to work ^^ including lots of local plugins/modifications that affect results

personally i never ever want to deal with projects making such a setup the only option,
in my prior experiences that made ""works for me"" easy and ""works for everyone"" hard

and i do projects broad consumption, so every step that someone could mess up i want to see automated and easy to take on with the least amount of initial tooling, googling and hand-installing

as such, the combination of tools you propose really just do not fit that philosophy off-hand
and this discussion is starting to derail the actual pr",True,True
pallets_____click_____493,2016-10-25T16:46:33Z,True,pallets_____click_____493_____256091912,"> including lots of local plugins/modifications that affect results

~~Wat?~~  Actually, I don't want to know.  If you see _that_ in a two-target Makefile, with no ""plugins"" or ""modification"", used only by maintainers, I don't know what I can say.",True,True
bower_____bower_____1748,2017-03-21T21:52:59Z,True,bower_____bower_____1748_____288230992,"For those who want to use lock feature before this PR merged, [bower-locker](https://github.com/infusionsoft/bower-locker) is a workaround to generate lockfile and commit only ```bower.json``` which is newly generated lock file and ```bower-locker.bower.json``` which is renamed original ```bower.json``` in your repo.


Run following commands to achieve it:

    npm install bower-locker -g

or 

    yarn global add bower-locker

then generate lock file based on existing ```bower.json``` file by runing: 

    bower-locker lock


I want to express big thanks to @shawnlonas for writing this. Guys, let's give it stars if you find it useful https://github.com/infusionsoft/bower-locker",True,True
bower_____bower_____1748,2017-04-12T16:59:43Z,True,bower_____bower_____1748_____293642920,Any news on this? Is it stalled out?,True,True
bower_____bower_____1748,2017-04-12T18:01:18Z,True,bower_____bower_____1748_____293659585,Why is this PR open when there is #2100?,True,True
pmmp_____PocketMine-MP_____1476,2017-10-17T20:34:40Z,True,pmmp_____PocketMine-MP_____1476_____147146167,,True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:09:50Z,True,pmmp_____PocketMine-MP_____1476_____145323057,Dead link to `getButton`. I believe this should be `Pass this to {@link MenuForm::getOption} to get the MenuOption object`.,True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:13:23Z,True,pmmp_____PocketMine-MP_____1476_____145323429,Consider changing the message to `Form is closed or has not been submitted yet` to be more precise.,True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:14:01Z,True,pmmp_____PocketMine-MP_____1476_____145323495,Is there a practical reason to expose this method publicly?,True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:16:01Z,True,pmmp_____PocketMine-MP_____1476_____145323717,Is there a reason to expose this method publicly?,True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:37:08Z,True,pmmp_____PocketMine-MP_____1476_____145326621,"This method is very confusing. It is not called by the server, but relies on the developer to call it.

This leads to inconsistency:
1. Is a Form object expected to be reused for a single player?
2. Is a Form object expected to be reused for multiple players?
3. Can the developer use the form values outside onSubmit()?

The answer is:
* If the same Form instance is only sent once, you can use the form values outside onSubmit() and hold the Form instance forever.
* If the same Form instance is sent more than once (same player or not), it would be a very bad practice to depend on the value held in the Form instance outside onSubmit(), even in the same tick.

It is particularly tempting to hold a CustomForm instance and use the values there later, since the data cannot be easily extracted. I can foresee this is going to cause a lot of concurrency bugs that can be very difficult to identify. Therefore, it is suggested that, starting from the core, one of either approach (""resend same instance"" or ""new instance each resend"") be adopted to avoid confusion.

* Adopting the ""resend same instance"" approach should automatically call the `clearResponseData()` method after each onSubmit() call.
* Adopting the ""new instance each resend"" approach should remove this method and add a flag to identify a Form as sent and throw an exception when attempting to use sendForm() with it.

Deciding which approach to adopt should require public consultation.",True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:50:56Z,True,pmmp_____PocketMine-MP_____1476_____145328678,"What about also adding an empty `public function onSelected()`, which is called before/after `MenuForm::onSubmit()` is called? This can allow developers to write their handlers in the menu options instead of from the big MenuForm object, resulting in extra routing work. Without adding this in the core, developers have to add a few lines of routing code + assertion that the `MenuOption::onSelected()` method exists in order to put the handler code with the MenuOption.",True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T06:52:31Z,True,pmmp_____PocketMine-MP_____1476_____145328923,All other Form classes are abstract. Why is this suddenly non-abstract?,True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T08:15:08Z,True,pmmp_____PocketMine-MP_____1476_____145343453,"before, or after? If a developer does it themselves, they are explicit about when they want it to be called, which can be any time - if the core does it, then developers have to get used to BEFORE, or AFTER, no in-betweens.",True,True
pmmp_____PocketMine-MP_____1476,2017-10-18T08:16:00Z,True,pmmp_____PocketMine-MP_____1476_____145343645,Plugins may want to modify form result data when it's submitted (there will be events for this),True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T11:39:23Z,True,pmmp_____PocketMine-MP_____1476_____146103666,"Suggestion: Construct with content -> new Label(""content here"");",True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T12:25:11Z,True,pmmp_____PocketMine-MP_____1476_____146104430,"Calling it Steps makes it confusing - If possible, rename to $options",True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T14:21:15Z,True,pmmp_____PocketMine-MP_____1476_____146106591,But: Why? So i can not cache a Form and send it to a player? So it has to be recreated (rebuildt in the core) every time? Isn't that just a waste of calculation if the form contents would never change?,True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T14:24:18Z,True,pmmp_____PocketMine-MP_____1476_____146106631,The core code has no foolproof way to tell if your form is immutable (so to speak). You can clone the form object if you're concerned about the overhead.,True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T14:24:48Z,True,pmmp_____PocketMine-MP_____1476_____338404986,"""Offtoppic"" question: Could you merge the changes from master into the branch / update it?",True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T14:48:02Z,True,pmmp_____PocketMine-MP_____1476_____146107095,"I have already explained in my previous comment:

> It is particularly tempting to hold a CustomForm instance and use the values there later, since the data cannot be easily extracted. I can foresee this is going to cause a lot of concurrency bugs that can be very difficult to identify. Therefore, it is suggested that, starting from the core, one of either approach (""resend same instance"" or ""new instance each resend"") be adopted to avoid confusion.
>
> * Adopting the ""resend same instance"" approach should automatically call the clearResponseData() method after each onSubmit() call.
> * Adopting the ""new instance each resend"" approach should remove this method and add a flag to identify a Form as sent and throw an exception when attempting to use sendForm() with it.

As it has been noticed that resetting contents each time makes it very inconvenient to retain data (especially inconvenient for custom form data), the ""new instance each resend"" approach is considered more appropriate.",True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T14:52:23Z,True,pmmp_____PocketMine-MP_____1476_____146107180,"Regarding the overhead of form creation overhead, perhaps you should compare it against encoding the form, sending it to the client, making the client display it and sending it back. As one wouldn't reasonably send forms very frequently, the impact on performance is negligible, so trying to cache forms for the sake of performance would be premature optimization, and therefore your comment is 4√(all evil), and so you are 8√(all evil).",True,True
pmmp_____PocketMine-MP_____1476,2017-10-21T16:13:23Z,True,pmmp_____PocketMine-MP_____1476_____146109010,Please concider adding a function to get/set the content,True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T07:40:10Z,True,pmmp_____PocketMine-MP_____1476_____338458391,how do you make a player open a form when they hold click a specific block,True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T11:49:31Z,True,pmmp_____PocketMine-MP_____1476_____338471432,"Please, for questions head over to the Forums. This is a place to discuss the changes and issues, not some random guy's issues about not reading the docs / commits",True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T12:00:47Z,True,pmmp_____PocketMine-MP_____1476_____338472066,"Have images handling been added yet, if so, there should be a class for that. ",True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T12:06:04Z,True,pmmp_____PocketMine-MP_____1476_____338472366,"Have eyes been added yet, if so, they should be used.",True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T12:16:30Z,True,pmmp_____PocketMine-MP_____1476_____338472915,_wishes github had a facepalm reaction_,True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T12:24:57Z,True,pmmp_____PocketMine-MP_____1476_____338473404,"🤦 🌚 👌🏼  
![image](https://user-images.githubusercontent.com/8733998/31861860-ba0e7dc6-b734-11e7-8a21-ecaa4eac349e.png)
https://userstyles.org/styles/37035/github-dark",True,True
pmmp_____PocketMine-MP_____1476,2017-10-22T17:12:26Z,True,pmmp_____PocketMine-MP_____1476_____338493343,Wiki for that or read it manu...,True,True
pmmp_____PocketMine-MP_____1476,2017-10-23T18:04:47Z,True,pmmp_____PocketMine-MP_____1476_____338746164,"@SOF3 May you explain the queing feature? In general, is there a forums thread yet? This could keep offtoppic questions out. If so, edit my message and put the link here: <link>",True,True
pmmp_____PocketMine-MP_____1476,2017-11-04T17:28:59Z,True,pmmp_____PocketMine-MP_____1476_____341915032,"Found something whereas i am not sure if intended to behave like that or a bug:

When returning $this as ?Form in onSubmit, It sends the same formular again after having it submitted, when submitting a second time it does not though.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-04T17:39:31Z,True,pmmp_____PocketMine-MP_____1476_____341915741,"sounds like a bug to me, you shouldn't be able to send the same form twice at all.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-10T07:39:50Z,True,pmmp_____PocketMine-MP_____1476_____343397320,"Potential API expansion: Since the form may be queued for some time, data may need refreshing when sent. Although it cannot be actively updated while the player is opening the form anyway, less outdated is better than more outdated.
Therefore I'm suggesting that MenuOption[] etc. be changed to Traversable or similar stuff.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-12T07:32:26Z,True,pmmp_____PocketMine-MP_____1476_____343718954,"Why what?
In case you're referring to f87b23b, varargs are not used for two reasons:

#### Forward compatibility adding new constructor args
WIth varargs used, it is impossible to add new optional parameters to the method without breaking backward compatibility (BC). This problem is especially important in constructors, because for other methods (e.g. `Inventory::addItem(Item ...$item)`), an overloading method can be added (e.g. adding `bool $send = true` can be done by simply adding another method `Inventory::addItemSend(bool $send, Item ...$item)` or just `Inventory::addItemNoSend(Item ...$item)`). But since a constructor in PHP cannot be overloaded (it's usually impossible to overload a pure varargs method anyway even in languages with method overloading like Java), varargs should be avoided.

#### Consistency in subclasses <sup>[citation needed]</sup>
By convention <sup>[citation needed]</sup>, the parameters in a subclass constructor should start with the superclass constructor's parameters first, then the subclass's own parameters (except for optional parameters <sup>[citation needed]</sup>). Using varargs in a superclass constructor makes the order of parameters in the subclass constructor very confusing.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-12T08:12:55Z,True,pmmp_____PocketMine-MP_____1476_____343720656,But using parameters whose object types are not named in the function parameters is not confusing?,True,True
pmmp_____PocketMine-MP_____1476,2017-11-12T08:19:58Z,True,pmmp_____PocketMine-MP_____1476_____343720941,"Then it's PHP's problem. We have already tried our best to improve this &mdash; assert type validity and PHP doc. Varargs affects the fundamental program design, and is not desirable in the long term just because PHP does not support array-of types.
",True,True
pmmp_____PocketMine-MP_____1476,2017-11-12T08:21:26Z,True,pmmp_____PocketMine-MP_____1476_____343721002,switch to Python?,True,True
pmmp_____PocketMine-MP_____1476,2017-11-12T14:05:25Z,True,pmmp_____PocketMine-MP_____1476_____150411623,signature needs to be documented (PhpDoc),True,True
pmmp_____PocketMine-MP_____1476,2017-11-13T09:47:51Z,True,pmmp_____PocketMine-MP_____1476_____343866035,"This has been stagnating for a few days now. Since I've seen that there's dissatisfaction that this hasn't been merged yet, some points:

- we are still not happy with this API yet, and are still discussing possible changes to it. We prefer not to push one set of API and then break that shiny new API again a few commits later.
- there are still crippling bugs because not everything has been properly tested (such as chained forms)
- I've been busy lately and haven't had chance to keep up with what's going on.

While we could merge this as-is anytime between tags, and then do later changes and fixes later, this would cause confusion and unexpected breakages. Keeping it in the PR makes it easier to review.

I know this is frustrating, and there is a general trend of things taking some time to be done. Please have patience.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-20T17:55:28Z,True,pmmp_____PocketMine-MP_____1476_____345775878,"It's not like people can't shoehorn in forms as they are now, though. You only need to send a simple, very readable JSON. This'll be more convenient, but right now, it's quite easy to implement a GUI anyway. Not worth complaining about too much.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-21T06:08:41Z,True,pmmp_____PocketMine-MP_____1476_____345926883,"I got to reproduce the double-sending issue:
The form sends twice when clicking the [x] or the ESC/back key/button and when returning $this instead of null in onSubmit - but it feels like this happens only about 75% of the time, and only if it is `prepend`ed.
I found no way to properly 100% reproduce it.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-21T08:22:43Z,True,pmmp_____PocketMine-MP_____1476_____345950787,"I know why it's happening, just haven't had time to fix it yet.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-24T02:35:59Z,True,pmmp_____PocketMine-MP_____1476_____346728185,"@thebigsmileXD What exactly are you downvoting? Feel free to explain yourself. Perhaps you believe there is no way to do this without a nice cozy API? Perhaps you think it's worth complaining about? If so, please take your complaints elsewhere. This is not the place for them.",True,True
pmmp_____PocketMine-MP_____1476,2017-11-24T09:51:42Z,True,pmmp_____PocketMine-MP_____1476_____346787757,This is not a forum. Please stop commenting unrelated stuff @dschwartz783 ,True,True
pmmp_____PocketMine-MP_____1476,2017-12-04T19:28:46Z,True,pmmp_____PocketMine-MP_____1476_____349077955,"The form sometimes does not work, it does not show.
The function itself is called in PlayerJoinEvent. The message ""a"" shows in the console, but the form does not.
![image](https://user-images.githubusercontent.com/28113262/33571852-5b091c02-d942-11e7-9971-6ddb30e9cc46.png)
",True,True
pmmp_____PocketMine-MP_____1476,2017-12-05T08:13:57Z,True,pmmp_____PocketMine-MP_____1476_____349228391,"@xISRAPILx the player is not ready to receive forms at that moment, because he is still logging in. The real issue is: because the server thinks the client never closes that form, you can not use any other form after that",True,True
pmmp_____PocketMine-MP_____1476,2017-12-05T13:31:06Z,True,pmmp_____PocketMine-MP_____1476_____349304492,Maybe a form timeout could be made of use to avoid that issue where all forms become locked,True,True
pmmp_____PocketMine-MP_____1476,2017-12-05T16:15:01Z,True,pmmp_____PocketMine-MP_____1476_____349354545,Are there methods besides the timer for using forms in PlayerJoinEvent? @thebigsmileXD ,True,True
pmmp_____PocketMine-MP_____1476,2017-12-05T16:19:26Z,True,pmmp_____PocketMine-MP_____1476_____349355968,"@xISRAPILx with a scheduled task, but that's not the right place for questions here, please ask in the forums next time.",True,True
pmmp_____PocketMine-MP_____1476,2017-12-06T17:38:40Z,True,pmmp_____PocketMine-MP_____1476_____349717307,Are we going to merge this for ALPHA-10 or ALPHA-11?,True,True
pmmp_____PocketMine-MP_____1476,2017-12-06T17:40:54Z,True,pmmp_____PocketMine-MP_____1476_____349717960,It will be merged when we're happy with it. Read the PR discussion instead of spamming useless comments.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-06T23:34:45Z,True,pmmp_____PocketMine-MP_____1476_____349810933,"This comment is a cleanup-combiner comment to reduce spam with issues

Current issues:
- Double-opening forms when returning $this on onSubmit
- Client can not open any form if an client sided json error occurs/a form is sent before the client is able to render it
",True,True
pmmp_____PocketMine-MP_____1476,2017-12-06T23:35:54Z,True,pmmp_____PocketMine-MP_____1476_____349811176,I've had unconfirmed reports that the latter issue is fixed in 1.2.6. This will need a fresh round of testing.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-07T09:28:33Z,True,pmmp_____PocketMine-MP_____1476_____349911495,"I'm debating allowing resending forms provided that they aren't already in use, f.e. you can't resend a form while it's already in another player's queue, but you _can_ resend it after it's been submitted. The point of restricting that was to prevent possible concurrency issues when sending forms to multiple players simultaneously.",True,True
pmmp_____PocketMine-MP_____1476,2017-12-07T09:32:09Z,True,pmmp_____PocketMine-MP_____1476_____349912429,I can confirm that in 1.2.5 forms sometimes never sent the form after player has been on server for a few minutes. But in 1.2.6 it doesn’t have that glitch ,True,True
pmmp_____PocketMine-MP_____1476,2017-12-07T09:39:35Z,True,pmmp_____PocketMine-MP_____1476_____349914374,I just discovered that I can break a form queue by spamming the escape button to get to the pause screen. This isn't good...,True,True
pmmp_____PocketMine-MP_____1476,2017-12-07T10:03:47Z,True,pmmp_____PocketMine-MP_____1476_____349920683,I crippled returning forms. Not so fast.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-07T10:49:24Z,True,pmmp_____PocketMine-MP_____1476_____349931816,"Aside from the bugs, some things we're not happy with yet:

- We don't allow sending the same form instance twice. I don't think this is reasonable, a better restriction would be to only allow sending to one player at a time (makes more sense).
- Leading on from the above point, the disposability of forms leads to the problem that a form cannot be easily copied, i.e. duplicating the form and erasing the data for reuse. This requires, then, that a form object must always be recreated. This is a little inconvenient.
- Plugins wanting to access their owners inside a form currently have to implement their own methods for getting the plugin's PluginBase instance. For example, the following code:
```php
                $player->sendForm(new class($this, $username, $error) extends ModalForm{
			/** @var Main */
			private $plugin;

			public function __construct(Main $plugin, string $username, string $error){
				$this->plugin = $plugin;
				parent::__construct(""Account transfer failed!"", ""Failed to transfer \""$username\"" account to yours.\nError: $error\n\nWould you like to try again?"");
			}

			public function onSubmit(Player $player) : ?Form{
				if($this->getChoice()){
					$this->plugin->requestAccountDetails($player);
				}else{
					$this->plugin->warnCancelTransfer($player);
				}
				return null;
			}
		});
```
requires that the form being sent must declare a `$plugin` property and assign it in the constructor, in order to access it in `onSubmit()`. This leads to boilerplate code.",True,True
pmmp_____PocketMine-MP_____1476,2017-12-07T11:10:18Z,True,pmmp_____PocketMine-MP_____1476_____349936686,"> Plugins wanting to access their owners inside a form currently have to implement their own methods for getting the plugin's PluginBase instance. For example, the following code:

Actually that applies to any parameter. Passing a variable that a player input into a form and displaying it in another form requires constructor rewrites. I suggest an additional parameter `array $arguments = []`",True,True
styleguidist_____react-styleguidist_____730,2017-12-10T08:00:47Z,True,styleguidist_____react-styleguidist_____730_____157421272,"adds a project to the examples dir:
a basic working styleguide for a react-native app using react-native-web
the app was created via crna

... as promised in #675",True,True
styleguidist_____react-styleguidist_____730,2017-12-10T08:12:53Z,True,styleguidist_____react-styleguidist_____730_____155940894,"verbose, components and ignore options are the same as defaults, you don’t need them here.",True,True
styleguidist_____react-styleguidist_____730,2017-12-10T08:13:34Z,True,styleguidist_____react-styleguidist_____730_____155940899,Was this command generated? Just `jest --watch` is enough.,True,True
styleguidist_____react-styleguidist_____730,2017-12-10T17:23:36Z,True,styleguidist_____react-styleguidist_____730_____155954179,"yes, crna generates the script entries.  best to leave it as is so it matches what users see in theirs.",True,True
styleguidist_____react-styleguidist_____730,2017-12-10T17:23:39Z,True,styleguidist_____react-styleguidist_____730_____155954180,"updates pushed.


I had stared with my much more complex config file and pared it down to this... not enough, though",True,True
styleguidist_____react-styleguidist_____730,2017-12-11T08:48:50Z,True,styleguidist_____react-styleguidist_____730_____350658837,Now there are several ESLint warnings.,True,True
styleguidist_____react-styleguidist_____730,2017-12-11T09:14:49Z,True,styleguidist_____react-styleguidist_____730_____350664977,And remove `yarn.lock` please.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-13T16:47:22Z,True,pmmp_____PocketMine-MP_____1476_____351450338,@thebigsmileXD Explicitly requiring passing the Plugin also has the advantage that it's possible to know the scope of the form and manage it with plugin enable/disable stuff.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-15T23:24:06Z,True,pmmp_____PocketMine-MP_____1476_____352136503,"Why don't make some events like `PlayerFormSubmitEvent` and `PlayerFormCloseEvent` to handle form submitting and closing? It would be a lot simple, especially if forms' classes are not abstract so we can make Form objects right out of the box and we can send them easily, without managing them by extending them with our own classes in plugins. For example, this piece of code in a Plugin class:
```
public function onSubmit(PlayerFormSubmitEvent $e){
    // assuming we are handling a Toggle element in index 0 that enables something
    /** @var Toggle $toggle */
    $toggle = $e->getForm()->getElement(0);
    $this->doSomethingToPlayer($e->getPlayer, $toggle->getValue());
    $e->getPlayer()->sendForm(new CustomForm(""Test Form"", array(
        new Toggle(""Test toggle 1"", false),
        new Toggle(""Test toggle 2"", true)
    )));
}
```
will be MUCH simpler to implement for plugin developers as we don't have to pass the owner to our form to do things on `onSubmit()`.
Also, if you think of a way to make forms instantiable out of the box then when we are sending a form to a player it would be a good idea to have a custom internal form name or ID to keep track of what form is being sent to the player; for example this piece of code:
```
public function onSubmit(PlayerFormSubmitEvent $e){
    // first we want to make sure the form we are receiving is a ""TestToggleForm1"" form
    if($e->getForm()->getInternalName() !== ""TestToggleForm1"") return;
    // then we manage to do something...

    // assuming we are handling a Toggle element in index 0 that enables something
    /** @var Toggle $toggle */
    $toggle = $e->getForm()->getElement(0);
    $this->doSomethingToPlayer($e->getPlayer, $toggle->getValue());
    // maybe the constructor for a CustomForm object can be
    // ""string $internalName, string $title, array $elements""
    $e->getPlayer()->sendForm(new CustomForm(""TestToggleForm2"", ""Test Form 2"", array(
        new Toggle(""Test toggle 1"", false),
        new Toggle(""Test toggle 2"", true)
    )));
}
```
Obviously this is more straight-forward but it will certainly have problems in more complicated plugins that use forms to do complicated things but I wrote this suggestion in a couple of minutes so it definitely needs some refining here and there but the main idea is there.",True,True
pmmp_____PocketMine-MP_____1476,2017-12-16T02:30:40Z,True,pmmp_____PocketMine-MP_____1476_____352154523,@AryToNeX This will certainly make it much harder to pass extra data through the form.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-16T14:37:00Z,True,pmmp_____PocketMine-MP_____1476_____352187229,"@AryToNeX I highly say NO THANKS to events. customui was discontinued just because events created plugin-crossover calls, and every plugin reacted to the event.",True,True
pmmp_____PocketMine-MP_____1476,2017-12-16T14:40:46Z,True,pmmp_____PocketMine-MP_____1476_____352187468,"Events are a reasonable ask (since they are just, well, events) but definitely a bad idea to make them the primary way to handle a form.

```php
public function onSubmit(PlayerFormSubmitEvent $e){
    // first we want to make sure the form we are receiving is a ""TestToggleForm1"" form
    if($e->getForm()->getInternalName() !== ""TestToggleForm1"") return;
    ...
```
here's the problem already.
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-17T14:40:16Z,True,scikit-optimize_____scikit-optimize_____579_____158788350,"This pull-request partially solves issue #576.

I have added some more support for named dimensions in the search-space, as well as two plotting functions. I don't have time to fix your existing plotting functions but I have made TODO comments for what needs to be done in `plots.py`

Before I start, let me repeat that I really like your library! So please take the following as friendly and constructive feedback. I spent the whole Saturday from morning to evening working on this and half of this Sunday. A large part of yesterday was just trying to understand your code because of the severe lack of comments. I spent this much effort because I think your library is important and I hope you will polish it some more.

Please note that I have to travel tomorrow so it might be a while before I can respond if you have questions / comments to this PR.


# How to test this pull-request

The following code uses the additions of this PR by simulating an objective function for tuning the hyper-parameters of a simple neural network. It will save a few plots to disk and print various info. It should work if you copy this to a python-file and run it.

(And yes! My code is also ugly when I'm writing it. I polish it when it is done and works. But this code is not for release :-)

    import numpy as np
    from math import exp

    from skopt import gp_minimize
    from skopt.space import Real, Categorical, Integer
    from skopt.plots import plot_histogram, plot_contour, plot_objective

    dim_learning_rate = Real(name='learning_rate', low=1e-6, high=1e-2, prior='log-uniform')
    dim_num_dense_layers = Integer(name='num_dense_layers', low=1, high=5)
    dim_num_dense_nodes = Integer(name='num_dense_nodes', low=5, high=512)
    dim_activation = Categorical(name='activation', categories=['relu', 'sigmoid'])

    dimensions = [dim_learning_rate,
                  dim_num_dense_layers,
                  dim_num_dense_nodes,
                  dim_activation]

    default_parameters = [1e-4, 1, 64, 'relu']


    def model_fitness(x):
        learning_rate, num_dense_layers, num_dense_nodes, activation = x

        fitness = ((exp(learning_rate) - 1.0) * 1000) ** 2 + \
                  (num_dense_layers) ** 2 + \
                  (num_dense_nodes/100) ** 2

        fitness *= 1.0 + 0.1 * np.random.rand()

        if activation == 'sigmoid':
            fitness += 10

        return fitness

    print(model_fitness(x=default_parameters))

    search_result = gp_minimize(func=model_fitness,
                                dimensions=dimensions,
                                n_calls=40,
                                x0=default_parameters)

    print(search_result.x)
    print(search_result.fun)

    for fitness, x in sorted(zip(search_result.func_vals, search_result.x_iters)):
        print(fitness, x)

    space = search_result.space

    print(search_result.x_iters)

    print(space.to_dict(x=default_parameters))

    print(""Plotting now ..."")

    # fig = plot_histogram(result=search_result, dimension_id='activation')
    fig = plot_histogram(result=search_result, dimension_id='learning_rate', bins=20)
    # fig = plot_histogram(result=search_result, dimension_id='num_dense_layers', bins=20)
    # fig = plot_histogram(result=search_result, dimension_id='num_dense_nodes', bins=20)
    fig.savefig('histogram.png')

    fig = plot_contour(result=search_result,
                         dimension_id1='learning_rate',
                         dimension_id2='num_dense_nodes')
    fig.savefig('contour_learning_rate_vs_num_dense_nodes.png')

    fig = plot_contour(result=search_result,
                         dimension_id1='num_dense_layers',
                         dimension_id2='num_dense_nodes')
    fig.savefig('contour_num_dense_layers_vs_num_dense_nodes.png')

    print(""Done plotting!"")
   

# Comments about this PR

* I am completely new to your library so it is possible I have misunderstood how something works. Please feel free to make changes to the code I have added. But please keep the good commenting and coding style as it will help people in the future who have to understand and maintain this code.

* I am not familiar with the syntax you use for doc-strings. I have tried to imitate it. I normally use PyCharm which has a different syntax for doc-strings. It is one of the things I really don't like about Python, that you don't have to specify data-types in the function-declaration, but then you often have to do it in the doc-strings using a strange syntax. It's a really poor language-design. But anyway, please check if my docstrings are correct.

* Some of the functionality I have added such as `space.get_dimensions()` is not actually used by my code. It is intended to be helpful for when you fix the other plotting functions to support named dimensions and search-spaces with categories, etc.

* I added the function `space.to_dict()`. There is a somewhat related function in `utils.point_asdict()`. But I prefer the name `to_dict()` which is also used by Pandas. I realize it is bad to have two naming conventions in one library. Could I convince you to change the name of `asdict()`? :-)


# Comments about your existing code

You REALLY need to make better comments in your code! It is very difficult for others to understand what you want to do and how everything fits together. When there is a bug we have to guess what your intentions are with the code. If you don't have time to maintain this library in the future, it will probably become abandoned because others will find it easier to just start a new project rather than to try and understand and build on yours. That would be a pity, because you have some outstanding ideas in your library!

For example, this is one of the few comments in `plots.py`:

	# plots on the diagonal are special, like Texas. They have
	# their own range so do not mess with them.

I had to read this numerous times to finally understand that it was probably a joke
about Texas USA, although I'm still not 100% sure. You really have to be a master at writing comments in order to pull off jokes, otherwise it will be confusing and harmful to the people who try to understand your code. I personally don't write jokes in code and I am very reluctant to make jokes in my video tutorials as well, for the same reason.

Please look at the coding and commenting style in the functions I have added. You may think that I write too many comments, but what I am aiming for is to explain as much as possible in plain English. Every time you have a function call into skopt or matplotlib or some other package, the reader needs to look up the semantics of that function. If that is also poorly documented, reading your code becomes like solving a giant puzzle. It takes immense effort and bugs are allowed to propagate very easily. When everything is commented in plain English, you can read and understand the code very quickly.

Another issue is your actual coding style. I found bugs as well as code that was correct but not very good. For example, these nested loops are typical in `plots.py`:

    for i in range(space.n_dims):  # rows
        for j in range(space.n_dims):  # columns
            # ...
            if i != j:
                # ...
                if j > 0:
                    # ...

Firstly, you should have a local variable called `n_dims` instead of always referring to `space.n_dims`. Secondly, your nesting depth is sometimes 4 or 5 inside these for-loops, because you haven't been very precise in your loop-conditions. You can rewrite the for-loops to something like the following. It drastically reduces the nesting-depth and also only executes the loops that are necessary:

    for i in range(n_dims):
        # Do something for the diagonal case.

        for j in range(i):
            # Do something for the case where j<i.

        for j in range(i+1, n_dims):
            # Do something for the case where j>i.

You also have this code in `plots.py` which is incredibly difficult to understand because of the multiple nestings and list-comprehension:

    diagonal_ylim = (np.min([ax[i, i].get_ylim()[0]
                             for i in range(space.n_dims)]),
                     np.max([ax[i, i].get_ylim()[1]
                             for i in range(space.n_dims)]))

It is better to split code like this into several lines to avoid the complicated nesting and also make it easier to step-debug. I added a revised version to the code, although I've commented it out for now so you can test it properly.

Another thing is that it is quite confusing how the Space and Dimension objects interact and wrap each other, e.g. regarding the transformation. It appears that the transformation and its inverse may be carried out repeatedly to nullify each other, although I'm not sure.
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-17T14:40:18Z,True,scikit-optimize_____scikit-optimize_____579_____352260198,"Hello @Hvass-Labs! Thanks for submitting the PR.

 - In the file [`skopt/plots.py`](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/plots.py), following are the PEP8 issues :

> [Line 135:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/plots.py#L135): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (82 > 79 characters)
> [Line 173:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/plots.py#L173): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (89 > 79 characters)
> [Line 308:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/plots.py#L308): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (83 > 79 characters)
> [Line 528:1](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/plots.py#L528): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> [Line 643:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/plots.py#L643): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace

 - In the file [`skopt/space/space.py`](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py), following are the PEP8 issues :

> [Line 337:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L337): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (89 > 79 characters)
> [Line 443:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L443): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (93 > 79 characters)
> [Line 754:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L754): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (111 > 79 characters)
> [Line 785:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L785): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (84 > 79 characters)
> [Line 792:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L792): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (83 > 79 characters)
> [Line 809:1](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L809): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace
> [Line 829:80](https://github.com/scikit-optimize/scikit-optimize/blob/5627c7e1f9501ee0fa43f6dce63b99c822ae53dd/skopt/space/space.py#L829): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (86 > 79 characters)



",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-17T15:10:00Z,True,scikit-optimize_____scikit-optimize_____579_____352262324,"I have tested the code in this PR on the actual problem I am trying to solve, which is hyper-parameter optimization of a neural network. It is for one of my tutorials on TensorFlow but it is not yet released as I want to include plots from skopt.

I have a question for you regarding the interpretation of the plots. The plots I have here are similar to the ones in your original version, except that I have normalized the color-gradients.

The parameters for my search-space are:

* learning_rate (1e-6 to 1e-2, log-uniform)
* num_dense_layers (1 to 5)
* num_dense_nodes (5 to 512)
* activation (relu or sigmoid)

These are the fitness values and neural network parameters found by skopt. The fitness is the negative classification accuracy on a validation-set.

[(-0.99019999999999997, [0.0010475183322128938, 1, 149, 'relu']),
 (-0.98860000000000003, [0.0018261589189723629, 2, 470, 'relu']),
 (-0.98839999999999995, [0.00037986474511170302, 2, 512, 'relu']),
 (-0.98839999999999995, [0.0010415672190332141, 1, 512, 'relu']),
 (-0.98799999999999999, [0.0024978263671842247, 3, 504, 'relu']),
 (-0.98760000000000003, [0.0017094485608837695, 1, 512, 'relu']),
 (-0.98680000000000001, [0.0017476496180086432, 3, 512, 'relu']),
 (-0.98499999999999999, [0.00077047010944170677, 3, 43, 'relu']),
 (-0.98480000000000001, [0.0014475695468873279, 3, 220, 'relu']),
 (-0.98260000000000003, [0.01, 4, 198, 'relu']),
 (-0.97919999999999996, [0.0014732190199105925, 3, 286, 'sigmoid']),
 (-0.97499999999999998, [0.0022674676715302932, 3, 481, 'sigmoid']),
 (-0.97419999999999995, [4.4040787332101281e-05, 4, 512, 'relu']),
 (-0.97419999999999995, [7.1181229112317682e-05, 4, 498, 'relu']),
 (-0.9698, [0.01, 2, 5, 'relu']),
 (-0.96440000000000003, [0.01, 4, 461, 'relu']),
 (-0.96179999999999999, [0.0001, 1, 64, 'relu']),
 (-0.96099999999999997, [3.4301200074707198e-05, 3, 512, 'relu']),
 (-0.95979999999999999, [0.01, 3, 5, 'relu']),
 (-0.91579999999999995, [0.01, 5, 5, 'relu']),
 (-0.90759999999999996, [0.00076921095317043851, 3, 5, 'relu']),
 (-0.88200000000000001, [1.4842453224480901e-05, 1, 88, 'relu']),
 (-0.82620000000000005, [5.7751197554451486e-06, 2, 238, 'relu']),
 (-0.64780000000000004, [1.8824150512622488e-06, 5, 259, 'relu']),
 (-0.53779999999999994, [0.00049781616995792967, 4, 5, 'relu']),
 (-0.47120000000000001, [9.9999999999999995e-07, 1, 512, 'relu']),
 (-0.11260000000000001, [1.3010975577257652e-06, 3, 456, 'sigmoid']),
 (-0.11260000000000001, [7.553247055497371e-06, 4, 209, 'sigmoid']),
 (-0.11260000000000001, [0.0049652350761811535, 1, 5, 'sigmoid']),
 (-0.107, [0.0017182189692616892, 5, 49, 'sigmoid'])]

The min and max of the fitness values in `result.func_vals` are -0.9902 and -0.107.

In the code for `plot_contour()` that I have submitted in this PR, I have normalized the color-gradients of all these plots to use these min and max values. This is an attempt at giving a consistent interpretation of the color-scales between the different dimensions, because their ranges sometimes vary significantly.

(1) This picture shows the learning_rate vs. num_dense_layers. You will note the red star which shows the best parameters found, and the yellow area which is presumably the minimum area of the Gaussian Process? The `zi` returned by `partial_dependence()` ranges between -0.99 and -0.34 but the plot-colors are normalized to range between -0.9902 and -0.107 which are the extreme values from the optimization results.

![learning_rate_vs_num_dense_layers](https://user-images.githubusercontent.com/13588114/34080792-b7fe3234-e343-11e7-98ac-61800c05292e.png)

(2) This next picture shows the learning_rate vs. num_dense_nodes where the `zi` from `partial_dependence()` now only ranges between -0.73 and -0.44. Because of the normalization I do using `vmin` and `vmax` in my new `plot_contour()` function, the color-gradients are now almost just completely green.

![learning_rate_vs_num_dense_nodes](https://user-images.githubusercontent.com/13588114/34080783-a4f3ce38-e343-11e7-870d-b75dd64e580b.png)

(3) This next picture shows the num_dense_layers vs. num_dense_nodes, whose `zi` ranges between -0.78 and -0.47. Again because of the color-normalization in `plot_contour()` this is almost completely green, with a slight yellow in the center.

![num_dense_layers_vs_num_dense_nodes](https://user-images.githubusercontent.com/13588114/34080795-c9feebb8-e343-11e7-9a58-87ee0761ab5c.png)

I'm a bit confused about how to interpret these plots. Can you perhaps explain that to me? Is it because e.g. plot (3) for num_dense_layers vs. num_dense_nodes ""averages"" the fitness over the other remaining dimensions for learning_rate and activation? How should I interpret this? Does it mean that the performance is unpredictable from these two variables alone?

But if we look at plot (1) which shows a yellow area in the middle, does this mean that it is ""generally"" better to have a learning_rate around 0.002 and num_dense_layers of 3. But the best solution had num_dense_layers=1. Is it because the Gaussian Process is incapable of modelling this search-space accurately? Or is it because we are averaging the performance over the remaining variables, so it is possible that for particular choices of the other variables, the best point can fall outside of the yellow area?

Another thing is that these plots change each time I run `gp_minimize()`. Does that indicate I should run a lot more iteration than the 30 I have done here? The problem is of course that it is very costly to run each of these, as it is a full training of a neural network.

I hope you can enlighten me as to what is going on with these plots :-)
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-17T15:59:42Z,True,scikit-optimize_____scikit-optimize_____579_____352265639,"# [Codecov](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=h1) Report
> Merging [#579](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=desc) into [master](https://codecov.io/gh/scikit-optimize/scikit-optimize/commit/01ec08741cfe6b8c21e5428be3385e726ab1f58c?src=pr&el=desc) will **decrease** coverage by `2.73%`.
> The diff coverage is `14.28%`.

[![Impacted file tree graph](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579/graphs/tree.svg?token=4yuVzAWoVM&width=650&height=150&src=pr)](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #579      +/-   ##
==========================================
- Coverage   86.24%   83.51%   -2.74%     
==========================================
  Files          23       23              
  Lines        1716     1783      +67     
==========================================
+ Hits         1480     1489       +9     
- Misses        236      294      +58
```


| [Impacted Files](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [skopt/utils.py](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579/diff?src=pr&el=tree#diff-c2tvcHQvdXRpbHMucHk=) | `97.31% <ø> (ø)` | :arrow_up: |
| [skopt/plots.py](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579/diff?src=pr&el=tree#diff-c2tvcHQvcGxvdHMucHk=) | `8.33% <10.86%> (+0.79%)` | :arrow_up: |
| [skopt/space/space.py](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579/diff?src=pr&el=tree#diff-c2tvcHQvc3BhY2Uvc3BhY2UucHk=) | `87.83% <20.83%> (-5.26%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=footer). Last update [01ec087...5627c7e](https://codecov.io/gh/scikit-optimize/scikit-optimize/pull/579?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T00:47:27Z,True,scikit-optimize_____scikit-optimize_____579_____353225290,"Thanks a lot for your hard work. I think currently everyone is travelling so it will take some time for looking at this seriously.

The doc string format we try to follow https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt this is not entirely successful/uniform across the code base, yet.

The code could (always) be commented better or restructured. It probably also depends on each persons history on how confusing they find different idioms. The way forward is to add comments or propose changes like you did. Leaving comments about work to be done/homework for others (empirically) does not lead to things getting done. So I vote to remove them or turn them into comments about the code.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:07:10Z,True,scikit-optimize_____scikit-optimize_____579_____158175688,This should be a property like `is_real` below so the doc string is accessible in the REPL,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:11:30Z,True,scikit-optimize_____scikit-optimize_____579_____158176195,What about using a `dict` like interface so that `some_space['learning_rate']` returns the dimension called `learning_rate`. We might not need to support indexing based access as people can to `some_space.dimensions[idx]`. This way we avoid having to support `some_space[idx]` and `some_space['learning_rate']` which might require us making guesses about what the user meant.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:12:09Z,True,scikit-optimize_____scikit-optimize_____579_____158176267,we should return just the dimension,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:18:50Z,True,scikit-optimize_____scikit-optimize_____579_____158177032,"Dimensions by default do not have a name, we should only give them ""fake"" names in the place where we need them (like in plotting) instead of here.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:28:10Z,True,scikit-optimize_____scikit-optimize_____579_____158178115,"Could combine this with the above comment about using a `dict` like interface: `some_space[['lr', 'C']]` we would have to limit names to strings.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:36:15Z,True,scikit-optimize_____scikit-optimize_____579_____158179019,we should create a figure and axis. Then later we can do `ax.plot(...)` and `ax.scatter()` instead of using `plt.scatter`.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-21T01:38:53Z,True,scikit-optimize_____scikit-optimize_____579_____158179445,"most of the pandas plotting functions return an axis. What other examples of libraries are there that return plots? I think we should try to be consistent with what other libraries do. I'd at least return `fig, axis`",True,True
DragonetMC_____DragonProxy_____150,2017-12-21T21:20:56Z,True,DragonetMC_____DragonProxy_____150_____159752501,Now the armors are visible on other entities.,True,True
DragonetMC_____DragonProxy_____150,2017-12-22T12:07:25Z,True,DragonetMC_____DragonProxy_____150_____353585770,"Ffs this file isnt even using TABs

HOW HARD IS IT",True,True
DragonetMC_____DragonProxy_____150,2017-12-22T19:06:03Z,True,DragonetMC_____DragonProxy_____150_____353657862,"I've compared the indentation of the commited files with all the other ones, and I haven't seen any difference. I've seen that indentation is done with only space on each file, so I've replaced each tabs with 4 space in all my commits.",True,True
DragonetMC_____DragonProxy_____150,2017-12-22T19:38:43Z,True,DragonetMC_____DragonProxy_____150_____353662733,"4 spaces = good,
tabs = bad 
personally speaking lel 
",True,True
DragonetMC_____DragonProxy_____150,2017-12-22T19:49:12Z,True,DragonetMC_____DragonProxy_____150_____353664291,Tabs are so much easier to work with. Spaces are for simpletons who would like to spend more time pushing SPACE,True,True
DragonetMC_____DragonProxy_____150,2017-12-22T19:52:58Z,True,DragonetMC_____DragonProxy_____150_____353664848,"I always use tabs for my own projects, but lots of other classes, especially translators are indented with only spaces, so I follow the guidelines.",True,True
DragonetMC_____DragonProxy_____150,2017-12-22T19:58:01Z,True,DragonetMC_____DragonProxy_____150_____353665559,"Half of the project is TABs, half is spaces and it gets annoying while coding when half certain lines of a file are spaces and the rest is tabs. Can everyone just use tabs",True,True
DragonetMC_____DragonProxy_____150,2017-12-22T20:08:50Z,True,DragonetMC_____DragonProxy_____150_____353667115,"I'm reformating classes when i view indentation problem, i'll make a full pass tomorrow.",True,True
DragonetMC_____DragonProxy_____150,2017-12-22T20:45:27Z,True,DragonetMC_____DragonProxy_____150_____353671947,There should be a button to reformat the entire project ,True,True
DragonetMC_____DragonProxy_____150,2017-12-23T06:32:28Z,True,DragonetMC_____DragonProxy_____150_____353710203,"Spaces pls no tabs 
",True,True
DragonetMC_____DragonProxy_____150,2017-12-23T10:26:42Z,True,DragonetMC_____DragonProxy_____150_____353718751,why not?,True,True
DragonetMC_____DragonProxy_____150,2017-12-23T14:02:07Z,True,DragonetMC_____DragonProxy_____150_____353727649,"Tabs look bad in some editors. 
",True,True
DragonetMC_____DragonProxy_____150,2017-12-24T12:32:00Z,True,DragonetMC_____DragonProxy_____150_____353781785,"@lukeeey Most IDEs and editors allow the tab key to input four spaces, and in saying that, if your IDE struggles to handle indentation, it might be time to either do something about it, or stop complaining. ",True,True
DragonetMC_____DragonProxy_____150,2017-12-24T12:35:18Z,True,DragonetMC_____DragonProxy_____150_____353781932,@yoft Or maybe its time to shut up because this conversation has already been resolved,True,True
pmmp_____PocketMine-MP_____1476,2017-12-24T13:21:39Z,True,pmmp_____PocketMine-MP_____1476_____353783984,"Not meant to be rude, but, can we get this merged by New Year?",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T09:56:47Z,True,scikit-optimize_____scikit-optimize_____579_____158921369,Good point!,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T09:57:28Z,True,scikit-optimize_____scikit-optimize_____579_____158921476,Nice idea I'll look into it!,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T09:58:18Z,True,scikit-optimize_____scikit-optimize_____579_____158921588,"Well, the reason I do it like this is to try and provide efficient support for the existing plotting functions. I agree that it is an ugly function. I'll see if I can fix the plotting functions to make this better.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T10:07:07Z,True,scikit-optimize_____scikit-optimize_____579_____158922665,"I wonder if it even makes sense to have some dimensions named and others not?

I think it is quite inelegant that some dimensions don't have names because we then have special cases elsewhere e.g. in plotting. So if we want to give them default names it might as well be done in the `Space`-class.

Let us think about what dimension-names are used for:

* With PR #590 dim-names are now used for calling the objective function.
* Dim-names are used in plotting for the names on the axes.
* Dim-names may be used to lookup a dim from the search-space object e.g. using the dict-like syntax you proposed above.
* Anything else?

Can you name a case where we don't want dimensions to have names, except for benchmark functions?
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T10:08:05Z,True,scikit-optimize_____scikit-optimize_____579_____158922795,What would be the right way of doing this in Python? Is there a dunder-method that can be overrided for this type of behaviour?,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T10:09:16Z,True,scikit-optimize_____scikit-optimize_____579_____158922929,I never really understood the semantics of Matplotlib. What is the reason for this?,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T10:11:46Z,True,scikit-optimize_____scikit-optimize_____579_____158923185,"As I said above, I never really understood Matplotlib, but when I ran your plotting-functions in a python-file I couldn't figure out how to e.g. save the plot without having the `fig`-object. When using the functions in a Jupyter Notebook they can work either way with returning `fig` or `axis`. I also thought about returning both  `fig, axis` but I didn't think it was necessary. I can give it a try and see if it works in Jupyter.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T10:13:18Z,True,scikit-optimize_____scikit-optimize_____579_____158923373,I read this again and you make a very good point.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T10:22:49Z,True,scikit-optimize_____scikit-optimize_____579_____354265873,"I get the impression that the plotting functions will not get fixed by anyone else and since I really would like this to work, I'll try and take a look at it. I'll probably have to change the existing plotting functions and we'll have to discuss later if there are API changes etc. E.g. the naming scheme you have now is a bit strange when you already have names in the dimensions, so I'll definitely change that.

@betatim thanks for all the comments, they were quite helpful and I'll try and incorporate your suggestions.

Regarding comments in code, it is the *responsibility* of the person adding new code to properly document it. He is the only person who really understands what the code is *supposed* to do. You are hoping for a miracle if you think others will come along and fix your work for you. I will help you out a bit, but to be perfectly honest, it is quite arrogant to add code that isn't properly polished and commented, because if there are 1000 people who will be using the code and they waste just a few hours each, then it is thousands of man-hours that are wasted, because the original author didn't take an hour or two more to document the code. It is not just a problem with your project but a general problem. The solution is simply that you don't accept PR's until they are properly documented so you understand what is going on and you feel the API is sufficiently elegant. Like you are doing with this PR now :-)

PS: I really could use an explanation for the plots that I showed above, so I can understand what is going on and explain it in my tutorial. Perhaps I should have opened a separate thread for that question.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T11:26:48Z,True,scikit-optimize_____scikit-optimize_____579_____158931177,"This is really a key question! It makes the code very messy that there is the possibility for having unnamed dimensions. It requires special cases in so many places in the code. If the only reason for having unnamed dimensions is to have support for simple benchmark functions, then it would be better to drop this ""feature"" and force all dimensions to have names. Please explain why you have unnamed dimensions.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T11:55:32Z,True,scikit-optimize_____scikit-optimize_____579_____158933804,The index is now set inside each `Dimension`-instance by `Space.__init__` as we need it for e.g. plotting.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T11:56:10Z,True,scikit-optimize_____scikit-optimize_____579_____158933855,This works now using `Space.__getitem__()`.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-28T11:57:18Z,True,scikit-optimize_____scikit-optimize_____579_____158933964,This works now using `Space.__getitem__()` which can take either a single string or list of strings as argument.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T07:57:55Z,True,scikit-optimize_____scikit-optimize_____579_____159033902,"I don't think a `Dimension` inside a space should know what its index is. If you need the index when iterating over the dimensions in a space you should use:
```python
for i, dim in enumerate(space):
  print(i, dim)
```",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T08:07:25Z,True,scikit-optimize_____scikit-optimize_____579_____159034453,"Unnamed dimensions are part historical (to support the shorthand way of defining them), for small search spaces you don't need to have names, and for some problems the dimensions do not have (sensible) names. I'd be -1 on requiring all dimensions to have names (or giving them dummy names automatically).",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T08:11:53Z,True,scikit-optimize_____scikit-optimize_____579_____159034725,The `plt.plot` and co interface uses global state and is meant to make interactive plotting easy. The object orientated interface has less potential for weird interactions between plots because it does not have global state. The best way to learn is probably following some matplotlib tutorials/videos and looking at how other libraries that do plotting handle things.,True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T08:46:21Z,True,scikit-optimize_____scikit-optimize_____579_____354416978,"All PRs are reviewed by someone who is not the original author before they are merged. This means there are at least two people who are happy with the state of things. The code base is maintained by people who are experienced with python, numpy, matplotlib and scikit-learn, as a result it relies on common idioms and conventions from the PyData ecosystem. This can result in some pretty dense or hard to read code. The way out is for an outsider (who doesn't view the world through the same biased view) to come along and help improve things.

Some may even disagree on the level of comments/understandability. To avoid bike shedding what the appropriate level of comments, docs, style, etc is we require a concrete proposal via PR. This seems to work quite well.

The miracle is that random people volunteering their time manage to put together a quite well maintained and functioning software project implementing a complex bit of research. There will always be parts that aren't as good as they could be, new things to add, historical legacy that is annoying, etc. Assuming people are already donating as much time and effort as they can, the only way to move things along faster is by donating more effort yourself or donating money to pay for developer time.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T09:54:02Z,True,scikit-optimize_____scikit-optimize_____579_____159042694,"I am currently in the process of rewriting `plots.py` They now use the dimension-names for axis-labels. I think the most sensible way of supporting unnamed dimensions, is to return `X_i` for the i'th dimension, or something similar. I have already added an index to `Dimension` which is necessary when plotting only a sub-set of the dimensions (you'll see when I commit the code). I have just now modified the `name` property in the `Dimension`-class to return `X_index` if `self._name is None`. This also allows you to lookup unnamed dimensions using e.g. `space['X_2']` as well as named dimensions using `space['foo']`. It works fine and I think it is a reasonable solution. The only problem is that you cannot use different names for the axis in the plots. Sure it can be coded, but it would be a mess. If you want to name the axis in the plot, then they should be set when you define the `Dimension`. I think this is reasonable.",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T10:01:44Z,True,scikit-optimize_____scikit-optimize_____579_____159043452,"The reason I originally made the above function return both the index and the `Dimension`-objects was precisely because I did not want to modify your code. But you need the index for various things when only using a subset of the dimensions and you cannot loop in the way you propose. So an efficient way of doing it was the above, but the API was ugly as I agreed.

What I have done now is to modify both `Dimension` and `Space` to give each `Dimension`-instance an index once they are added to a `Space`. This way we have easy access to it when we need it e.g. for plotting a sub-set of the dimensions, and for having default names such as X_i for unnamed dimensions. I think it is a reasonable solution.

The only problem with this would be if you later want to change the composition of dimensions in a search-space. But I don't see any need for doing that, or why that should even be supported by the API.

Are there any other problems with having an index inside the `Dimension`-object?
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T10:03:36Z,True,scikit-optimize_____scikit-optimize_____579_____159043648,"OK, I see. I'll take a look if I can fix this. I've used Matplotlib many times for many projects, but never liked its API.",True,True
pmmp_____PocketMine-MP_____1476,2017-12-29T11:47:26Z,True,pmmp_____PocketMine-MP_____1476_____354436138,"Not meant to be rude, but this PR make teaspoon plugin error",True,True
pmmp_____PocketMine-MP_____1476,2017-12-29T11:48:41Z,True,pmmp_____PocketMine-MP_____1476_____354436272,"Plugins should adapt to the core, not the other way around. Furthermore, this is a development branch. ",True,True
pmmp_____PocketMine-MP_____1476,2017-12-29T11:48:58Z,True,pmmp_____PocketMine-MP_____1476_____354436300,@WaldoFS that's entirely irrelevant to the discussion. TeaSpoon is its own project.,True,True
pmmp_____PocketMine-MP_____1476,2017-12-29T11:51:51Z,True,pmmp_____PocketMine-MP_____1476_____354436581,"@WaldoFS Not meant to be rude, plugin are suppose to make themself work with the core, not the other way around",True,True
pmmp_____PocketMine-MP_____1476,2017-12-29T11:57:19Z,True,pmmp_____PocketMine-MP_____1476_____354437079,"Ok, thanks all 😘",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-29T14:16:16Z,True,scikit-optimize_____scikit-optimize_____579_____354451275,"As for #590, please remove your inline comments about our coding conventions. This is distracting everyone from the main goal of this PR (i.e., adding two plotting functions). If you want to propose changes to improve how to code looks and is read, we welcome that, but please make self-contained targeted PRs. ",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-30T14:47:40Z,True,scikit-optimize_____scikit-optimize_____579_____354549864,"I have now pushed a new version. Almost the entire `plots.py` has been rewritten.

This example tests the new functions using the built-in hart6 benchmark function.

    from skopt import forest_minimize
    from skopt.space import Real, Categorical, Integer
    from skopt.benchmarks import hart6
    from skopt.plots import plot_objective_matrix, plot_evaluations_matrix
    from skopt.plots import plot_histogram, plot_objective_2D

    dim1 = Real(name='foo', low=0.0, high=1.0)
    dim2 = Real(name='bar', low=0.0, high=1.0)
    dim3 = Real(name='baz', low=0.0, high=1.0)
    dim4 = Real(name='rip', low=0.0, high=1.0)
    dim5 = Real(name='rap', low=0.0, high=1.0)
    dim6 = Real(name='rup', low=0.0, high=1.0)

    dimensions = [dim1, dim2, dim3, dim4, dim5, dim6]

    print(""Optimizing ..."")

    result = forest_minimize(hart6, dimensions, n_calls=200,
                             base_estimator=""ET"", random_state=4)

    print(""Plotting ..."")

    fig, ax = plot_evaluations_matrix(result=result, bins=20, dimension_names=None)
    fig.savefig('plot_evaluations_matrix_all.png')

    fig, ax = plot_objective_matrix(result=result, dimension_names=None)
    fig.savefig('plot_objective_matrix_all.png')

    # Now use a subset of the dimensions identified by their names.
    # Note the order is different from the search-space,
    # which will also be reflected in the plots.
    dim_names = ['bar', 'rip', 'foo']

    fig, ax = plot_evaluations_matrix(result=result, bins=20, dimension_names=dim_names)
    fig.savefig('plot_evaluations_matrix_some.png')

    fig, ax = plot_objective_matrix(result=result, dimension_names=dim_names)
    fig.savefig('plot_objective_matrix_some.png')

    fig, ax = plot_histogram(result=result, dimension_name='baz', bins=40)
    fig.savefig('plot_histogram.png')

    fig, ax = plot_objective_2D(result=result,
                                dimension_name1='baz',
                                dimension_name2='rap')
    fig.savefig('plot_objective_2D.png')

    print(""Done plotting!"")

These are the resulting plots:

![plot_evaluations_matrix_all](https://user-images.githubusercontent.com/13588114/34455112-643a8960-ed78-11e7-961b-599a4897bbff.png)
![plot_evaluations_matrix_some](https://user-images.githubusercontent.com/13588114/34455113-64613470-ed78-11e7-9686-36c67e4d68bb.png)
![plot_objective_matrix_all](https://user-images.githubusercontent.com/13588114/34455116-64dad9ba-ed78-11e7-955f-b65e39f2cec1.png)
![plot_objective_matrix_some](https://user-images.githubusercontent.com/13588114/34455117-65087c94-ed78-11e7-93c0-6f7719f2cc85.png)

![plot_histogram](https://user-images.githubusercontent.com/13588114/34455114-6488f47e-ed78-11e7-987c-d056a56835f8.png)
![plot_objective_2d](https://user-images.githubusercontent.com/13588114/34455115-64b46f32-ed78-11e7-8f2a-718661f07f88.png)
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-30T14:56:54Z,True,scikit-optimize_____scikit-optimize_____579_____354550311,"Here is another example using a ""simulated"" Neural Network for the objective function. This has a Categorical dimension which cannot be plotted.

    import numpy as np
    from math import exp
    from skopt import forest_minimize
    from skopt.space import Real, Categorical, Integer
    from skopt.plots import plot_objective_matrix, plot_evaluations_matrix
    from skopt.plots import plot_histogram, plot_objective_2D
    
    dim_learning_rate = Real(name='learning_rate', low=1e-6, high=1e-2, prior='log-uniform')
    dim_num_dense_layers = Integer(name='num_dense_layers', low=1, high=5)
    dim_num_dense_nodes = Integer(name='num_dense_nodes', low=5, high=512)
    dim_activation = Categorical(name='activation', categories=['relu', 'sigmoid', 'linear'])
    
    dimensions = [dim_learning_rate,
                  dim_num_dense_layers,
                  dim_num_dense_nodes,
                  dim_activation]
    
    default_parameters = [1e-4, 1, 64, 'relu']
    
    
    def model_fitness(x):
        learning_rate, num_dense_layers, num_dense_nodes, activation = x
    
        fitness = ((exp(learning_rate - 1e-3) - 1.0) * 5000) ** 2 + \
              (num_dense_layers - 3) ** 2 + \
              ((num_dense_nodes - 200)/100) ** 2
    
        fitness *= 1.0 + 0.05 * np.random.rand()
    
        if activation == 'sigmoid':
            fitness += 10
        elif activation == 'linear':
            fitness += 20
    
        return fitness
    
    
    print(""Optimizing ..."")
    
    result = forest_minimize(model_fitness, dimensions, n_calls=200,
                             base_estimator=""ET"", random_state=4)
    
    print(result.x)
    print(result.fun)
    
    for fitness, x in sorted(zip(result.func_vals, result.x_iters)):
        print(fitness, x)
    
    print(""Plotting ..."")
    
    try:
        fig, ax = plot_evaluations_matrix(result=result, bins=20, dimension_names=None)
        fig.savefig('plot_evaluations_matrix_all.png')
    
        fig, ax = plot_objective_matrix(result=result, dimension_names=None)
        fig.savefig('plot_objective_matrix_all.png')
    except:
        print(""Cannot plot Categorical dimensions! Skipping ..."")
    
    # Now use a subset of the dimensions identified by their names.
    # Note the order is different from the search-space,
    # which will also be reflected in the plots.
    dim_names = ['num_dense_nodes', 'learning_rate', 'num_dense_layers']
    
    fig, ax = plot_evaluations_matrix(result=result, bins=20, dimension_names=dim_names)
    fig.savefig('plot_evaluations_matrix_some.png')
    
    fig, ax = plot_objective_matrix(result=result, dimension_names=dim_names)
    fig.savefig('plot_objective_matrix_some.png')
    
    fig, ax = plot_histogram(result=result, dimension_name='learning_rate', bins=40)
    fig.savefig('plot_histogram1.png')
    
    fig, ax = plot_histogram(result=result, dimension_name='activation', bins=40)
    fig.savefig('plot_histogram2.png')
    
    fig, ax = plot_objective_2D(result=result,
                                dimension_name1='learning_rate',
                                dimension_name2='num_dense_nodes')
    fig.savefig('plot_objective_2D.png')
    
    print(""Done plotting!"")

These are the resulting plots:

![plot_evaluations_matrix_some](https://user-images.githubusercontent.com/13588114/34455185-d9b98186-ed79-11e7-870e-5d58c0fd05eb.png)
![plot_histogram1](https://user-images.githubusercontent.com/13588114/34455186-dac816a0-ed79-11e7-852a-98bee442b43b.png)
![plot_histogram2](https://user-images.githubusercontent.com/13588114/34455187-db44db4a-ed79-11e7-9726-23dd43c1f498.png)
![plot_objective_2d](https://user-images.githubusercontent.com/13588114/34455188-db8d8868-ed79-11e7-900d-9f3498eaa418.png)
![plot_objective_matrix_some](https://user-images.githubusercontent.com/13588114/34455189-dbdb88f6-ed79-11e7-9bcc-5a19f024b74b.png)
",True,True
scikit-optimize_____scikit-optimize_____579,2017-12-30T15:10:29Z,True,scikit-optimize_____scikit-optimize_____579_____354550973,"Let me once again start out by saying that I really like the *idea* of your project! My issue is with the implementation and the code ""style"" of certain parts of the project.

I rewrote almost the entire `plots.py` except for `plot_convergence()` which I don't want to spend hours understanding and rewriting. I'm not happy about leaving a file that I've almost completely rewritten, but frankly I've had enough of reading your code and feel my time is better spent elsewhere.

I would also like to add the plotting functions from: https://scikit-optimize.github.io/notebooks/bayesian-optimization.html to `plots.py` but I'll await your comments on this PR before I spend probably a whole day understanding and rewriting that.

From our previous discussions I get the impression that you don't like comments inside code. You find comments to be redundant or whatever. So I expect that you will either demand that I remove all those comments I added to `plots.py`, or you will bull-doze them the next time you work on the code yourself. At any rate, I get the impression that you look down on comments in code.

Here is the truth: Code with few comments might be OK if your code is really fantastic and beautiful, and your audience is very familiar with all the API's you are using, the math and methods, etc.

But your code is far from fantastic and I repeatedly got the impression that `plots.py` was written by someone without formal training in computer science and software engineering. It would certainly not get a passing grade where I come from. And when the code is poorly written AND has almost no comments, then it is really problematic for others to work on. This is what I meant by an arrogant coding style, because it shows complete disregard for whoever is going to work on the code next. Fair enough if the person is not a masterful coder - but everyone can write proper comments in English!

Fact is that the code was broken, and since you didn't want to fix it yourselves, someone from the outside would have to do it for you. If the code had been well-written or at least well-documented and well-commented, then it could have been fixed in a fraction of the time I have now spent. Instead I feel I've wasted almost a week understanding and cleaning up your code, because you didn't even want to add comments that showed what the *intention* of the code was, so I had to spend hours upon hours trying to deduce it.

And when you talk about ""programming idioms"" and ""complex research"" and that is why I might find your code difficult to understand, it is also rather arrogant, because what you're really saying is that you think people who don't understand your code must be ignorant or stupid. But in reality you are just making poor excuses for writing bad code!

So it has been very frustrating working on your code!

Let me ask you two questions:

1) Do you think someone in the future will find it easier to work on my version of `plots.py` or your old version? If you ask 100 programmers to fix a bug or extend `plots.py` with new features, I bet you that most of them would give up trying to understand your old code and they would just hack it until it *maybe* worked. This would bloat the code and quite possibly introduce new bugs. But even first-year students can now understand my version of `plots.py`.

2) Would you rather have someone waste a week trying to understand code you neglected to spend a few hours commenting when you wrote it, or would you rather have that person spend a week contributing something more meaningful to your project?

It is obvious that you are getting quite annoyed with me, but I really hope you take this criticism to heart. You don't have to like me, but at least consider that what I am saying might be reasonable and would significantly improve your project. Scikit-optimize could be a fantastic library! - but you need to improve the code-base so others can understand it and help you extend it, especially when you no longer work on it yourself!

Best wishes and Happy New Years! :-)
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-02T13:56:06Z,True,scikit-optimize_____scikit-optimize_____579_____354771332,"I've looked a bit into plotting the Gaussian Processes from your tutorial here:

https://scikit-optimize.github.io/notebooks/bayesian-optimization.html

For a real problem we do not have the true function so that can be omitted.

Then we have the mean and variance of the Gaussian Process which is green in those plots and the acquisition function which is blue.

I don't know if I understand this correctly, but I think that in order to plot these three aspects of the Gaussian Processes for multi-dimensional search-spaces, we would have to make Partial Dependence plots similarly to `plot_objective()` (which I call `plot_objective_matrix()` in my version of `plots.py`). That is, we would make a plot-matrix for the GP mean, another plot-matrix for the GP variance, and finally a plot-matrix for the acquisition function.

A significant part of the existing code could be reused - either the lazy way by copy and paste the common code, or the proper way of having the common code in a separate function which is used by both `plot_objective()` and a new `plot_gaussian_process()`.

But I'm not sure how useful these plots of the Gaussian Process would really be for multi-dimensional problems and if it would be worth the effort. Any thoughts?
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-03T12:33:44Z,True,scikit-optimize_____scikit-optimize_____579_____355001596,"Last evening I thought about this and I really have to move on to other things, so I won't be implementing the plots of the Gaussian Processes, even though plots of especially the acquisition function might be quite useful.

So let's focus on what needs to be fixed with the PR as it stands now before it can be merged. Perhaps you don't like that I changed the names to `plot_..._matrix()` and I can easily change them back, that's perfectly fine.

Note from the discussion in PR #592 that I will *not* remove comments from the code. They serve a purpose of helping newcomers 5 years from now to quickly and clearly understand the code. This code is *not* written for *you* - it is written for them!
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-06T13:38:53Z,True,scikit-optimize_____scikit-optimize_____579_____355747595,I assume that this PR is ready to be merged (@Hvass-Labs if otherwise let me know) so I add [MRG] to the title (scikit-learn style titles).,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-08T08:16:10Z,True,scikit-optimize_____scikit-optimize_____579_____355904449,"@iaroslav-ai and @betatim I'm sorry that this PR has become so unwieldy. As you can see the checks are failing because I rewrote the API a bit e.g. renamed `plot_objective()` to `plot_objective_matrix()`. I'll tell you what. I'll revert these things to try and make it compatible with your old API, so all the checks pass and you also don't have to rewrite all your tutorials. Then I'll let you know when I believe this is ready to be merged 'as is'. That should make it easier for you to review.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-08T13:08:41Z,True,scikit-optimize_____scikit-optimize_____579_____355961877,"I have now pushed a version that I believe can be merged 'as is', provided all tests pass. The tests all pass on my system and I have also run `bash ./build_tools/circle/execute.sh` locally and it seems to create all the plots correctly. I have also run the test-code that I have shown above and it works fine.

There is no need to read all of the above discussions when reviewing this. Here is essentially what this PR does:

1) Improves support for named dimensions in several ways:

    * A dimension is given a default name 'X_index' if the user has not supplied a name, where `index` is a count for this dimension in the search-space. This is the original naming scheme you have used in `plots.py` and I have just moved it into `Dimension` and `Space`. I'm not so fond of the name `X_index` but I don't really have a better suggestion. Maybe `dim0`, `dim1`, `dim2` which would also work better with `@use_named_args`? Maybe another PR for this in the future.

    * Plots now use these dimension-names on the x- and y-axis. This means there is a slight API change in e.g. `plot_objective()` and `plot_evaluations()` but I don't think this even affects v. 0.4 users (not sure).

    * Names should be valid Python-variable-names because they may be used as args with `@use_named_args`. For example, you should use `n_trees` instead of `number of trees`. If you want another name to be displayed e.g. in plots then an idea would be to either add `display_name` to `Dimension` or to let the plotting functions take a separate list of names to be displayed. That would be a future PR.

    * Dimensions can be looked up from the search-space using dict-like lookup e.g. `space['foo']` and several dimensions can be looked up using e.g. `space[['foo', 'bar']]`. (Thanks to @betatim for suggesting this feature instead of e.g. `get_dimensions()`).

    * I also had to add an `__init__` to `Dimension` and remove `test_dimension_name_none` because a dimension's name can now only be None during initialization. I also fixed various bugs related to names.

2) `plots.py` has been almost completely rewritten because I needed to add support for search-spaces with `Categorical` dimensions. The easiest way of doing this, was to let the user select a subset of the dimensions to be plotted, hence the need for e.g. `space[['foo', 'bar']]`. But this required so many changes to `plots.py` and because I found it very difficult to understand your code, I decided to do a complete rewrite.

3) I have added two new plotting functions `plot_histogram()` and `plot_objective_2D()`. These also serve as a simple example of plotting data from the optimization log. `plot_histogram()` also allows plotting of `Categorical` dimensions, which is not allowed by `plot_objective()` and `plot_evaluations()`.

In my TensorFlow video tutorials I sometimes spend a few minutes commenting on the coding style of other libraries. But there were so many issues with `plots.py` that I decided to do a whole separate video, because it might be useful to a lot more people than just TensorFlow users. So I have actually already recorded a 40-minute video where I discuss why I rewrote `plots.py` like this. I have tried to make the video funny and memorable. It is sort of a stand-up comedy code review and I hope you don't get too upset. I don't think it is a personal attack, so just take it on the chin :-) I'll put it on youtube shortly after the actual tutorial which I haven't recorded yet.

So what I suggest, is that you merge this code now if it works correctly, so my audience can run my new tutorial which relies on this code addition. If you greatly dislike my coding style and want to bulldoze the comments, then please wait until you've watched the video where I explain my coding philosophy. Perhaps you'll realize that what I've done actually makes sense.
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-09T12:18:12Z,True,scikit-optimize_____scikit-optimize_____579_____356268405,"I have fixed the merge conflicts with the master-branch. I did a `git rebase` to squash all my commits into a single commit, then rebased to master and fixed merge conflicts, and then `push --force` back to github. I've never done this before and it took me some hours to figure out how to do it. If I've messed up anything please let me know.

If all other checks pass, then I believe this is ready to be merged.",True,True
pmmp_____PocketMine-MP_____1906,2018-01-11T19:07:42Z,True,pmmp_____PocketMine-MP_____1906_____162461884,"### Relevant issues

Fixes #1903 ",True,True
pmmp_____PocketMine-MP_____1906,2018-01-11T19:12:47Z,True,pmmp_____PocketMine-MP_____1906_____161048735,"Is a lambda necessary here? `""count""` as a callable ought to suffice.",True,True
pmmp_____PocketMine-MP_____1906,2018-01-11T19:16:06Z,True,pmmp_____PocketMine-MP_____1906_____161049547,"ok, done",True,True
pmmp_____PocketMine-MP_____1906,2018-01-11T19:24:54Z,True,pmmp_____PocketMine-MP_____1906_____161051762,now actually done. :p,True,True
heroku_____stack-images_____91,2018-01-12T01:32:10Z,True,heroku_____stack-images_____91_____162529244,"This issue was opened on the ruby buildpack:
https://github.com/heroku/heroku-buildpack-ruby/issues/635

ActiveStorage has native support for PDF previews with the mupdf tool as
well as metadata information with ffmpeg. ActiveSupport shells out to
these binaries directly.

Here are the size changes from adding these packages in:

heroku/heroku:16
base: 461MB
mupdf: 471MB
mupdf+ffmpeg: 645MB

heroku/cedar:14
base: 1.35GB
mupdf: 1.36GB
mupdf+ffmpeg: 1.46GB

This amounts to a 184mb increase in stack image size.",True,True
heroku_____stack-images_____91,2018-01-12T08:27:12Z,True,heroku_____stack-images_____91_____357173790,:-1: this is a huge overhead for something the vast majority of apps don't need.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-12T10:13:19Z,True,scikit-optimize_____scikit-optimize_____579_____357198245,"I would appreciate it if someone would review this soon so it can be merged and we can all move on. There is no need to read the whole thread, just read https://github.com/scikit-optimize/scikit-optimize/pull/579#issuecomment-355961877.",True,True
pmmp_____PocketMine-MP_____1906,2018-01-12T10:35:58Z,True,pmmp_____PocketMine-MP_____1906_____357203543,"While this is an elegant solution, it's very sub-optimal for performance. `array_*` functions tend to be quite slow.

On a testing server, I find that this is about 2x faster in the majority of cases:
```php
			$count = 0;
			foreach($this->blockCache as $list){
				$count += count($list);
				if($count > 2048){
					$this->blockCache = [];
					break;
				}
			}
```
Likely something to do with not allocating a temporary array for `array_sum()` to add up.

Of course, this is all on the order of microseconds, so any savings are very small.",True,True
pmmp_____PocketMine-MP_____1906,2018-01-12T10:42:56Z,True,pmmp_____PocketMine-MP_____1906_____357205086,"PHP is quite the drag... Leave it for code readability, or replace it with yet another PHP performance workaround?

When we're done with that, can we all agree that Shoghi needs to die for choosing PHP in the first place?",True,True
pmmp_____PocketMine-MP_____1906,2018-01-12T10:43:09Z,True,pmmp_____PocketMine-MP_____1906_____357205134,"To clarify to readers, effectively what's happening in this PR under the hood at runtime is this (when you PHPify the `array_*` functions):
```php
            $counts = [];
            foreach($this->blockCache as $list){
                $counts[] = count($list);
            }

            $count = 0;
            foreach($counts as $c){
                $count += $c;
            }
            
            if($count > 2048){
                $this->blockCache = [];
            }
```",True,True
pmmp_____PocketMine-MP_____1906,2018-01-12T11:10:12Z,True,pmmp_____PocketMine-MP_____1906_____357211191,"I find it sad that PHP developers are so used to making these sacrifices, that they don't even see what's wrong with it anymore. In many languages, map functions and array summations perform well. PHP truly brings out the worst in developers.",True,True
pmmp_____PocketMine-MP_____1906,2018-01-12T11:22:20Z,True,pmmp_____PocketMine-MP_____1906_____357213662,This discussion could go on all day if we had the patience. I'm going to lock this before it gets out of hand.,True,True
styleguidist_____react-styleguidist_____730,2018-01-12T17:58:24Z,True,styleguidist_____react-styleguidist_____730_____357309900,"# [Codecov](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730?src=pr&el=h1) Report
> Merging [#730](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730?src=pr&el=desc) into [master](https://codecov.io/gh/styleguidist/react-styleguidist/commit/55ce2d519eae846db33ac8b4940a6fa18fa9f940?src=pr&el=desc) will **decrease** coverage by `0.02%`.
> The diff coverage is `n/a`.

| [Impacted Files](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [src/rsg-components/Editor/Editor.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL0VkaXRvci9FZGl0b3IuanM=) | `85.71% <0%> (-1.79%)` | :arrow_down: |
| [src/rsg-components/Props/PropsRenderer.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1Byb3BzL1Byb3BzUmVuZGVyZXIuanM=) | `95.91% <0%> (ø)` | :arrow_up: |
| [src/utils/getRouteData.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3V0aWxzL2dldFJvdXRlRGF0YS5qcw==) | `100% <0%> (ø)` | :arrow_up: |
| [src/rsg-components/Text/TextRenderer.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1RleHQvVGV4dFJlbmRlcmVyLmpz) | `100% <0%> (ø)` | :arrow_up: |
| [src/rsg-components/Para/ParaRenderer.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1BhcmEvUGFyYVJlbmRlcmVyLmpz) | `100% <0%> (ø)` | :arrow_up: |
| [...rc/rsg-components/Playground/PlaygroundRenderer.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1BsYXlncm91bmQvUGxheWdyb3VuZFJlbmRlcmVyLmpz) | `100% <0%> (ø)` | :arrow_up: |
| [src/rsg-components/Section/Section.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1NlY3Rpb24vU2VjdGlvbi5qcw==) | `100% <0%> (ø)` | :arrow_up: |
| [loaders/utils/getSections.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-bG9hZGVycy91dGlscy9nZXRTZWN0aW9ucy5qcw==) | `100% <0%> (ø)` | :arrow_up: |
| [src/rsg-components/Section/SectionRenderer.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1NlY3Rpb24vU2VjdGlvblJlbmRlcmVyLmpz) | `100% <0%> (ø)` | :arrow_up: |
| [loaders/styleguide-loader.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree#diff-bG9hZGVycy9zdHlsZWd1aWRlLWxvYWRlci5qcw==) | `100% <0%> (ø)` | :arrow_up: |
| ... and [9 more](https://codecov.io/gh/styleguidist/react-styleguidist/pull/730/diff?src=pr&el=tree-more) | |
",True,True
styleguidist_____react-styleguidist_____730,2018-01-12T18:23:48Z,True,styleguidist_____react-styleguidist_____730_____357316037,"
<!--
  0 failure: 
  1 warning:  Changes were made...
  
  
  DangerID: danger-id-default;
-->


<table>
  <thead>
    <tr>
      <th width=""50""></th>
      <th width=""100%"" data-danger-table=""true"">Warnings</th>
    </tr>
  </thead>
  <tbody><tr>
      <td>:warning:</td>
      <td>

  Changes were made to `package.json`, but not to `package-lock.json`.

Perhaps you need to run `npm install` and commit changes in package-lock.json. Make sure you’re using npm 5+.
  </td>
    </tr>
  </tbody>
</table>



<p align=""right"">
  Generated by :no_entry_sign: <a href=""http://github.com/danger/danger-js/"">dangerJS</a>
</p>
",True,True
styleguidist_____react-styleguidist_____730,2018-01-12T18:36:18Z,True,styleguidist_____react-styleguidist_____730_____357318968,"@sapegin ,
This pr is just a simple example.  If linting and code coverage for examples are that important, you can just close this pr.",True,True
styleguidist_____react-styleguidist_____730,2018-01-12T19:10:21Z,True,styleguidist_____react-styleguidist_____730_____357327390,There's no point in making exceptions for examples: they are code that someone will have to maintain too. Same simple rules apply to all code in the project.,True,True
styleguidist_____react-styleguidist_____730,2018-01-12T20:17:40Z,True,styleguidist_____react-styleguidist_____730_____357343239,"@sapegin 
look at the coverage error.   it's a file I didn't touch.   pr closed.  best wishes",True,True
heroku_____stack-images_____91,2018-01-15T23:09:29Z,True,heroku_____stack-images_____91_____357809354,"I tend to agree with @dmathieu on this. Is there another way we can practically meet the need in heroku/heroku-buildpack-ruby#635, such as a mupdf buildpack?

Longer-term, this is a good signal that we need to be thinking about how to support package installation on Heroku, but we're not there (yet).",True,True
heroku_____stack-images_____91,2018-01-15T23:31:02Z,True,heroku_____stack-images_____91_____357812144,"> Longer-term, this is a good signal that we need to be thinking about how to support package installation on Heroku, but we're not there (yet).

I haven't tried this particular feature of build manifests yet, but it looks like it's a first class citizen when using it (compared to having to use [heroku-buildpack-apt](https://github.com/heroku/heroku-buildpack-apt) at least):
https://devcenter.heroku.com/articles/heroku-yml-build-manifest#installing-packages-from-apt",True,True
heroku_____stack-images_____91,2018-01-16T08:16:38Z,True,heroku_____stack-images_____91_____357884545,@edmorley I think what Owen talks about is providing a way for buildpacks to install packages.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-16T09:50:00Z,True,scikit-optimize_____scikit-optimize_____579_____357907657,"Dear developers,
Kindly asking you to include changes given by mr. Hvass in the official release of scikit-optimize or provide any other working alternative since an issue is quite important for those who want to handle Bayes optimization properly and save a vast of time.",True,True
heroku_____stack-images_____91,2018-01-16T22:29:34Z,True,heroku_____stack-images_____91_____358129483,"@edmorley @dmathieu Yeah, I'd somewhat forgotten that it's okay to talk about the heroku.yml feature now that it's in dev preview, and wanted to avoid accidentally committing the team to anything.

I do still think there's more to do; we're still working out how to (and, really, if we should) converge heroku.yml and the current build and runtime environments.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:39:17Z,True,scikit-optimize_____scikit-optimize_____579_____161997245,For python we can't do this so we need to explicitly unpack the bounds :(,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:43:47Z,True,scikit-optimize_____scikit-optimize_____579_____161998489,use `isinstance` to check the type of an object in python,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:44:58Z,True,scikit-optimize_____scikit-optimize_____579_____161998852,remove some leading white space to fix the indentation,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:46:42Z,True,scikit-optimize_____scikit-optimize_____579_____161999338,`isinstance`,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:47:25Z,True,scikit-optimize_____scikit-optimize_____579_____161999505,`isinstance`,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:53:39Z,True,scikit-optimize_____scikit-optimize_____579_____162001068,"I still don't like it that we have to reach into a dimension object from the outside to make it ""whole"". My proposal would be to allow unnamed dimensions `self.name = None` and use `enumerate(dimensions) in the plotting to make up a axis label on the fly. What do others think?",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T09:56:01Z,True,scikit-optimize_____scikit-optimize_____579_____358253883,"I've started adding some comments. It will take a few iterations of going through the code.

@mrStasSmirnoff you can help getting this merged by helping with the review.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T10:10:00Z,True,scikit-optimize_____scikit-optimize_____579_____358257540,"@betatim Thanks!
@iaroslav-ai If you have some time, would you mind helping with this review? I found your review of my `@use_named_args` contribution to be constructive.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T10:13:45Z,True,scikit-optimize_____scikit-optimize_____579_____162006173,"Right. However, this should be replaced with `check_list_types` from PR #597 as mentioned in the TODO-comment. I am waiting for a review of that PR.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T10:41:48Z,True,scikit-optimize_____scikit-optimize_____579_____162012861,"I understand your concern. Let me try and explain the reasoning behind this.

The way I chose to resolve the problem of `Categorical` dimensions in the plots, was simply to allow the user to select which dimensions to show by giving a list of dimension-names. This may be useful in other ways as well, if you only want to plot a few of the dimensions for some reason.

Because skopt uses unnamed lists of parameters internally, we need an index for each of the dimensions we are interested in, in order to get the correct parameters from the optimization-log. We cannot use `enumerate(some_dimensions)` because `some_dimensions` are only a subset of `space.dimensions`. So we need to know the indices of `some_dimensions` as they occur in `space.dimensions`.

If the `dimension`-object doesn't know its own index, then we have to look it up from the `space.dimensions` list from the given names of the dimensions. The natural place to have a function for looking up these indices would be in the `space`-object.

To avoid having to go over the `space.dimensions`-list several times; one for looking up the dimensions and another for looking up their indices, I had originally merged all of this into a single function `space.get_dimensions()` in one of the earlier versions of this PR, that would return the relevant `dimension`-objects, their names, and their indices, as I recall. This was the most efficient way of doing it without tampering with your code and without iterating over `space.dimensions` multiple times - but I admitted that it was ugly and as I recall @betatim didn't like it, so I changed it. This was also where @betatim's suggestion for using `space[['dim_name1', 'dim_name2', ...]]` came from, which just returns the `dimension`-objects, but not their indices.

I think the easiest and cleanest way of getting a dimension's index in the search-space, is simply to store it in the `dimension`-object. The only problem with this, is if you want to modify the search-space by adding or remove dimensions, or changing their order. But I don't see a reason for doing that and I don't think it's even possible without mangling the code.

Regarding unnamed dimensions, I think it is a bad idea to give them default names in the plotting functions. Imagine that you have some other functionality some day that also needs default names, then suddenly you are setting default names for the dimensions in different places. I believe it is better to set default names in the `dimension`-object where they belong, and for this they also need to know their indices in the search-space.

If you want to use different names for the plotting-axes e.g. ""Learning Rate"" instead of ""learning_rate"" then an idea would be to either set a `display_name` when constructing the `dimension` or giving a list of `display_names` when calling the plotting functions. There are pro's and con's of both approaches.

I hope this was a convincing argument. Otherwise please come up with an alternative design proposal for how we should get these indices.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T10:54:37Z,True,scikit-optimize_____scikit-optimize_____579_____162015909,"Right. However, this should be replaced with check_list_types from PR #597 as mentioned in the TODO-comment. I am waiting for a review of that PR.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T10:55:06Z,True,scikit-optimize_____scikit-optimize_____579_____162016109,Is this a Python 2.7 compatibility thing?,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T23:12:42Z,True,scikit-optimize_____scikit-optimize_____579_____358481244,I am currently experimenting with the plotting functionality. Will update here soon with results.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-17T23:13:51Z,True,scikit-optimize_____scikit-optimize_____579_____358481486,P.S. most likely tomorrow after ~5 pm. Have meetings all day. ,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-18T07:39:07Z,True,scikit-optimize_____scikit-optimize_____579_____162267204,"I have a few more thoughts on this.

If we consider the design from an object-oriented perspective, a `Dimension`-object is only supposed to exist in the context of a `Space`-object in a many-to-one relationship (many dimensions for one search-space). As mentioned above, I don't see a reason why this relationship would change after it has first been setup.

So it is reasonable to have functionality for looking up dimensions from the search-space e.g. using their name as in `space[['dim_name1', 'dim_name2', ...]]` or using their index as in `space.dimensions[i]`. I think we agree so far.

In my version of the plotting functions, we may need to select a subset of the dimensions (e.g. to avoid `Categorical` dimensions, or merely to plot a subset, or change the ordering of the dimensions in the plots, etc.) For this we need to know the indices of the dimensions in the search-space, so that we can lookup the parameters of a given dimension from the optimization-log in `result.x_iters`. Because the relationship between dimension-objects and the search-space never changes once it has been setup, their indices also never change. We can either infer the indices from `space.dimensions` which would either require for `space[['dim_name1', 'dim_name2', ...]]` to return both the indices and dimension-objects (which is ugly). Or we can have another function e.g. `space.get_dimension_indices(dimensions)` which is both ugly and inefficient as it would require for us to lookup the dimension-objects again. Or we can simply store the indices in the dimension-objects as I have done. Because the dimension-objects always live inside a search-space after the initial setup, and their ordering never changes, I think this ""tight coupling"" between `Dimension` and `Space` is OK. To me it seems like the most elegant and efficient solution to the problem.

Now, there is another solution to the problem of plotting `Categorical` dimensions, which would be to plot all dimensions in `plot_objective()` etc. but ignore the `Categorical` dimensions. This way we could keep track of the dimension-indices inside the plotting functions. BUT I think this would make the implementation of the plotting functions significantly more complicated and we would loose the ability to pick a sub-set of the dimensions by their names.

Altogether, I really think the solution I have come up with for both default names of the dimensions and plotting a sub-set of dimensions is the most elegant and efficient.

Please come up with a specific design and implementation proposal if you still believe my version is problematic.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-18T07:46:12Z,True,scikit-optimize_____scikit-optimize_____579_____358564557,"@iaroslav-ai Thanks! I don't mean to stress you, but it would be nice if we could close this soon. I think it has been almost 3 weeks since I finished this (apart from minor fixes and rebasing). The installation instructions for my tutorial are awkward and apparently don't always work. So it would be nice if this could get merged into master soon, so we can all move on.

To avoid having to rebase and fix merge conflicts multiple times, I'll await both of your full reviews before fixing the code.
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-18T07:49:26Z,True,scikit-optimize_____scikit-optimize_____579_____358565180,"You can test the new plotting functions using the code-snippets in the above comments. I think you just need to change `plot_*_matrix()` to `plot_*()`.

https://github.com/scikit-optimize/scikit-optimize/pull/579#issuecomment-354549864
https://github.com/scikit-optimize/scikit-optimize/pull/579#issuecomment-354550311",True,True
pmmp_____PocketMine-MP_____1476,2018-01-18T11:55:49Z,True,pmmp_____PocketMine-MP_____1476_____358625306,"Has it been done? I tested thebigsmileXD's WarpUI with this branch, but it didn't work properly.
Here are some bugs I found:
 - Forms doesn't appear after sending a form.
 - Form::onSubmit is not called after submitting a form.

",True,True
pmmp_____PocketMine-MP_____1476,2018-01-18T15:40:18Z,True,pmmp_____PocketMine-MP_____1476_____358685140,"@GooglePlugin When somebody got time for it. Also, i think the problems you mentioned are probably WarpUI's problems.",True,True
pmmp_____PocketMine-MP_____1476,2018-01-18T15:42:02Z,True,pmmp_____PocketMine-MP_____1476_____358685711,How do you change the ‘Submit’ button to other text?,True,True
pmmp_____PocketMine-MP_____1476,2018-01-18T15:43:03Z,True,pmmp_____PocketMine-MP_____1476_____358686059,"This is not a plugin support forum
please use forums.pmmp.io",True,True
pmmp_____PocketMine-MP_____1476,2018-01-18T16:28:30Z,True,pmmp_____PocketMine-MP_____1476_____358701046,"> When will it be done?

you must be new round here...",True,True
heroku_____stack-images_____91,2018-01-18T22:08:12Z,True,heroku_____stack-images_____91_____358797928,"I had a conversation with @hone this afternoon to try to reach a decision about this pull request. Some key points that I'm not sure we'd fully considered:

* Users are specifically requesting support for the Rails 5 image and PDF preview features (see eg. https://github.com/heroku/heroku-buildpack-ruby/issues/635). We can take as read that @hone will find a way to support these users and meet that need regardless of whatever decision we make on this pull request.

* ffmpeg, one of the implicit dependencies of this Rails feature, is a whopping 174MB in size. This library must be present for the Rails 5 preview feature to function, so it either needs to be part of the stack image, part of the slug, or downloaded during app boot in some way. Downloading ffmpeg every time a Rails dyno boots, either in the slug or after slug startup, is a fairly substantial boot time penalty, and will impact our COGS by substantially increasing the amount of data we load from S3 on each dyno boot. Placing ffmpeg in the stack image means we only have to download it once, when each runtime instance boots, and that it can be shared between slugs.

* Adding 174MB to the stack Docker images will make them bulkier to work with and slower to download. It'll also affect the stack image rollout process by a bit.

I'm convinced I should change my mind and support this pull request. ",True,True
heroku_____stack-images_____91,2018-01-18T22:16:45Z,True,heroku_____stack-images_____91_____358800115,"One thing that hasn't been brought up is security. ffmpeg is notoriously buggy due to its use of memory-unsafe code (aka C), for example, OSS-Fuzz has found many critical vulnerabilities: https://bugs.chromium.org/p/oss-fuzz/issues/list?can=1&q=project-ffmpeg+Type%3DBug-Security

A single vulnerability in ffmpeg or mupdf as currently implemented in Rails 5.2 can result in the complete takeover of the application due to remote code execution via untrusted user input. I would strongly recommend not implementing ffmpeg/mupdf without strong sandboxing.

I recently merged a PDF fuzzer into OSS-Fuzz for mupdf, but a sandbox is still necessary.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-18T22:56:17Z,True,scikit-optimize_____scikit-optimize_____579_____358809843,"Hi everyone. Here are some of my thoughts on this.
I did not use previously the plotting functionality and got to know it through this pr. 
I would like to understand more where the idea for the following plotting functions comes from, in particular for:
```
plot_objective
plot_evaluations
```
I have never seen plots that these functions produce to be used in black box optimization literature. Does anyone knows a paper where these are used? Was it intended originally maybe for the debugging of optimization algorithms? 
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-18T23:01:47Z,True,scikit-optimize_____scikit-optimize_____579_____358811383,"The reason why I ask these questions is because I am not sure how these plotting functions are useful for the skopt user’s. 
Consider for instance example plot below, obtained by optimizing a deterministic 6d function, [code here](https://gist.github.com/iaroslav-ai/42bf1088c129b497dc097ee518d23d84):

![figure_1](https://user-images.githubusercontent.com/14038787/35125815-4c105742-fcab-11e7-8682-39b77c539604.png)

Remark 1. To obtain plots, the _average_ over values of objective is used (over random invisible parameters), whereas a user / algorithm is interested in _minimum_ value of objective. Because of this, user might draw incorrect conclusions about what parameter values are “good”.

Remark 2. Best found minima point values do not correlate with minima of plots. This is due to a) remark 1 and b) because generally the objective is assumed to be sampled from a Gaussian process prior, where you can have complex non-linear correlations between n > 2 dimensions, which hence cannot be represented in 2d plots. Because of this, incorrect inferences can be drawn about correlations between two variables, and absence of “higher order” correlations. 

Remark 3. Primary goal of skopt is to optimize user objective efficiently. How do these plots help for that? For instance, the idea of using such plots to aid the optimization contradicts the idea of taking user out of the loop.

Remark 4. A minimum can be computed as per Remark 1. However this would still fall under remark 3. Also technical difficulties can occur for large number of dimensions (say 20+).

Somewhat similar issues can be brought for the `plot_evaluations`. 

Possible benefit of such plots is to catch failures of optimization algorithm. However ideally such failures should not occur / should be detected automatically without user’s intervention. 

I am happy to further elaborate on this if necessary or if something unclear :) 
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-18T23:04:19Z,True,scikit-optimize_____scikit-optimize_____579_____358811942,"@Hvass-Labs sorry that I start these discussions here! I know you want to be done with this soon. But it would be good to clarify the _why_, as it then dictates the _how_ . Results of discussion here could eg go to docstrings.",True,True
heroku_____stack-images_____91,2018-01-19T08:25:13Z,True,heroku_____stack-images_____91_____358898001,"> Rails applications don't give us any handles for detecting ""uses ffmpeg"" reliably.

In my opinion, this is the issue here. Dependencies should be explicitly declared, and this brings 2 huge dependencies implicitly to everyone.
In order for us to properly support this, rails needs to give us a way to know if an app needs these dependencies.
Then, we can selectively install the package in a slug if it needs it. If there are slug size issues, we could issue exceptions for apps that need this package.

In addition to security, the other very concerning thing in my opinion is [mupdf's license](https://github.com/rails/rails/pull/30667#issuecomment-332276198).
Adding the package to every slug, all our customers would essentially be breaking the license terms, as they'd be using it in a closed-source application.
Bringing this package magically could be more of a curse than a blessing.

ffmpeg is not MIT either.",True,True
heroku_____stack-images_____91,2018-01-19T08:35:44Z,True,heroku_____stack-images_____91_____358900212,"Re: security and potential future security issues.
Having it in the stack image would actually be better there, as we'd be able to upgrade for all apps without requiring customer to redeploy.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-19T09:13:01Z,True,scikit-optimize_____scikit-optimize_____579_____358908370,"@iaroslav-ai Your review is very good and perfectly fine to have the discussion here! You are neutral and polite, and your goal is to make it a good user-experience. That's why I asked you to help with this review :-)

Quick comment on your example: In my experiments I found that 40 iterations was very low for getting semi-accurate contour plots. You could try 100 or 200 iterations instead. I use 40 iterations in my own tutorial on skopt and TensorFlow because those experiments are very expensive to run:

https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/19_Hyper-Parameters.ipynb

Note: I wrote the tutorial in just a matter of days. The reason it took me 3-4 weeks to finish it, was because I wanted these plots to be in the tutorial as I found them quite useful - in spite of their short-comings - and I needed to fix `plots.py` to make it work with my `Categorical` dimension. It turned out to be a bit of a hornet's nest to fix it, though :-)

I will try and answer your questions as best as I can, considering that I'm not the original author of these, and I mainly just cleaned up the code and added a couple of features. I have combined the answers for several of your questions.

### About `plot_objective()`

These contour-plots show a kind-of ""approximation of an approximation"" and are hence not completely reliable, as you point out. Perhaps this should be more strongly noted in the doc-strings? The first approximation is from the model used for the objective function (e.g. Gaussian Process) which can be unreliable in regions that are thinly sampled. The second approximation is from the so-called Partial Dependence plot, which is a ""trick"" used to show 3D and higher dimensions in 2D-plots, by averaging over the dimensions that aren't shown.

There are a few problems with the best-found ""red star"" that is shown in the plots. Due to noise in the objective function, and the inaccurate surrogate model, and the averaging of the Partial Dependence plot, the best-found point may fall outside of the best region shown in the plots (yellow colour). I agree that this is somewhat confusing but I'm not a statistician so I don't know any clever ways to make a better plot of these things. Perhaps the doc-string should explain this better?

Also note that the function is very expensive to compute for higher dimensions because it evaluates the surrogate model n_dims^2 * n_samples times as I recall, where n_samples might be fairly high (default 250) to get a fine-grained contour-plot. That is another strong argument for having the new feature I added, where you can use a subset of the dimensions to use in the plot.

In my own work on Meta-Optimization I also plotted the ""meta-fitness landscapes"" but I didn't have a surrogate model, so I needed to actually evaluate the real objective function in a grid, while keeping the other dimensions fixed at some ""good"" hand-tuned value. You can see a few examples of landscapes plotted this way here:

https://en.wikipedia.org/wiki/Meta-optimization

I think the plots in `plot_objective()` are more useful in spite of their short-comings.

### About `plot_evaluations()`

This shows a histogram of samples on the diagonal instead of the Partial Dependence plots. I also found the histogram to be useful.

Below the diagonal this shows the points where the objective function was sampled. You can argue that this was already shown in `plot_objective()` and hence not very useful. That is sort-of right, but this plot doesn't show the contour of the objective function (which is very expensive to compute for higher dimensions!), and instead it shows a colour-grading of the time-step at which the points were sampled. Because you only have 40 iterations in your example, it may not be very useful, but what you would typically see for higher iterations, is that the samples start to converge in a certain region, as shown by the colour-grading.

### About `plot_histogram()`

If you only want to show the histograms from `plot_evaluations()` then you can use `plot_histogram()` instead (which I added). It also supports `Categorical` dimensions.

### About `plot_objective_2D()`

This shows the contour-plot from `plot_objective()` but only for 2 dimensions. This may be useful for some people, and it also is a simpler code-example in case people want to write their own plotting-functions, because `plot_objective()` has a lot of other things as well.

### Conclusion

Altogether, I think the plots in skopt are useful in spite of their short-comings. And like I said, I only waited to finish my tutorial on TensorFlow and skopt to get these plots in. (Was it worth it in hindsight considering all the trouble? Well ... :-)
",True,True
pmmp_____PocketMine-MP_____1476,2018-01-19T10:35:36Z,True,pmmp_____PocketMine-MP_____1476_____358928544,"I haven't fully understand the rule here. Not meant to be rude, but I really look forward to this ;)",True,True
pmmp_____PocketMine-MP_____1476,2018-01-19T10:37:35Z,True,pmmp_____PocketMine-MP_____1476_____358929017,"It appears no constructive discussion is going on in this pull request, and therefore I am locking. If you have any further comments, please create a thread on the forums.",True,True
heroku_____stack-images_____91,2018-01-19T14:35:33Z,True,heroku_____stack-images_____91_____358982474,"I'm also 👎  on including this in the base stack image from a security perspective. I agree 💯 with @titanous on ffmpeg's history (thanks for getting mupdf a fuzzer!). Having file processing libraries like ffmpeg, mupdf, even imagemagick sandboxed would be much more ideal, but is another project. 

We're increasing the attack surface for all applications by including this package in the stack image. While it would allow us to upgrade all users at once with a stack image change, it's an additional 2 packages to monitor for security issues and ensure the stack image is kept up to date.

It also sounds like the licensing issues @dmathieu raises makes this more problematic. ",True,True
heroku_____stack-images_____91,2018-01-19T14:36:37Z,True,heroku_____stack-images_____91_____358982740,"This pull request was meant to gather data around what packages would be installed and how much space they would take up.

I'm closing it for now and will schedule a meeting to follow up on this.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-22T06:53:55Z,True,scikit-optimize_____scikit-optimize_____579_____359339496,"Should I conclude from your silence that if I fix the things you've mentioned then this can be merged? @betatim mentioned a couple of minor issues and @iaroslav-ai wanted better doc-strings for the plotting functions. I don't want to rebase and fix merge conflicts only to find out that you have more things you want changed.

I think I argued quite well that (1) these plotting functions are useful, (2) the new semantics for dimension-names are useful and sensible, (3) a dimension's search-space index is needed for efficiently working with sub-sets of dimensions and the natural place to store the index is inside the dimension-object. I believe this dealt with all your concerns.

Please note that the very small PR #597 is also needed for me to complete this PR.

My tutorial on TensorFlow and skopt has been viewed almost 800 times by now. My guess would be that it will get 10000 views within a year. Currently people have to install my dev-fork of skopt and it doesn't work for everyone. People are going to be disappointed in skopt if it doesn't work, so it really is in your own best interest to get this merged soon. Not to mention that people are probably going to be reluctant to contribute if it takes so long to get their work merged.
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-22T17:01:43Z,True,scikit-optimize_____scikit-optimize_____579_____359492724,"Sorry, I cannot convince myself about `plot_objective` and `plot_evaluations`. Right now I am of the opinion that they should be removed. This is because of the following:

1. There is no peer reviewed publication on black box optimization that I know of that would use these plots (ideally with evaluation of usefulness of these plots, but if it is used to aid in a way the user that is shown to lead to better objectives is also good). 
2. The `plot_objective` is borrowed from the supervised learning domain, where you are interested in all possible inputs, whereas we are interested in subset minimizing inputs. This is also better addressed with the plots that you have referenced in wiki. 
3. A possible use of `plot_evaluations` is as you mention is to check for convergence. However, this is a subjective criterion that depends on viewer of the plot, and does not scale if a user runs multiple different optimization problems in parallel (say, do training on different datasets) as user then needs to monitor n plots. I would rather prefer objective criterions such as [this one that we have](https://scikit-optimize.github.io/callbacks.m.html#skopt.callbacks.DeltaXStopper) or [others in literature](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/bcb15507f4b52991a0783013df4222240e942381.pdf). These are objective, scale with number of optimizations run and can be tested automatically. 
4. Testing usefulness of these plots is hard - would require a user study to show that the plots indeed help users to optimize better their objective. This is necessary in absence of point 1.

These methodological issues are important, as these plots are intended to aid user in getting better optimization outcomes, beyond purely technical support (correct me if you have something else in mind). Due to uncertainty I would rather go with Occam’s razor approach and not include them. 

Consider examples for other functionality of skopt:

* `gp_minimize`: approach is very well [studied in the literature](https://arxiv.org/pdf/1206.2944.pdf), and we [have means of testing it](https://github.com/iaroslav-ai/scikit-optimize-benchmarks).

* Parallel evaluation mode in skopt: is shown to be [useful to reasonable extent in literature](https://hal.archives-ouvertes.fr/hal-00732512/document) (see “Constant Liar” there), could be evaluated relatively easily against sequential mode to see that it speeds up convergence to good objective values against wall clock time.

I cannot argue like that for these plots. 

I did not come to this conclusion easily - I know and appreciate that you put a lot of work into rewriting these plots. Yet it is better to address these methodological issues right now, to avoid unnecessary effort spent, and breaking changes in the future, which could also affect your tutorial. 

Please do let me know if you wish for me to elaborate more on the points that I raise or if you have any comments on this. 
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-23T08:43:18Z,True,scikit-optimize_____scikit-optimize_____579_____359718966,"@iaroslav-ai Thanks for your review. You have good intentions even if we strongly disagree. Of course I'm not happy if all my work is lost :-) But I don't want to waste more time on this anyway, so we need to close this PR this week whichever way you guys decide.

On your points:

1. I'm not sure if I understand you correctly, but this goes together with what you said the other day. It sounds like you haven't seen these plots in publications before, so from that you conclude nobody will use them in the future? I don't mean to be condescending, but strangely enough I sometimes hear this ""argument"" from people in academia, that there is no precedence for something, so they don't think it should be done now. But if people only did what was previously accepted then science and technology would stagnate completely. It's not a valid argument that something hasn't been done before. In fact, you should be proud if skopt introduces something new to the field! Unfortunately I can't take credit for coming up with these plots - somebody else was apparently quite visionary by adding these plots (I actually don't know who originally wrote this code because Github shows several people have worked on this file.)
2. The plots for Meta-optimization that I referenced on Wikipedia are not possible to do for most problems because they are created by evaluating the actual objective function on a grid in the search-space, which would be extremely time-consuming, as you would have to evaluate `func` many more times to make such a plot than you did for the actual optimization using e.g. `gp_minimize()`. Furthermore, in order to plot high dimensional spaces in 2D those plots on Wikipedia had fixed the parameters for all other dimensions, which is not a very good way to do it. The plots in skopt `plot_objective()` are created from evaluating the fairly cheap surrogate model, and they use Partial Dependence to show high-dimensional spaces. This distorts the landscape-plot, but it is a compromise that is necessary to make if you want to be able to plot it.
3. I actually have already read the Vizier paper (but thanks for the link) and I don't understand why Google hasn't open-sourced it. It is not instrumental to their business and they already have $100 billion in cash and they generate more than $20 billion cash per year in profits, as I recall, so they can surely afford to open-source a tiny little library that could help others in the world. There is a discrepancy between what Google say they will do for the benefit of society and what they actually do. Anyway, I digress. What you reference here are dedicated convergence plots in the Vizier paper and the DeltaX-stopping criterion in skopt. But `plot_objective` and `plot_evaluations` are of course meant for a completely different purpose - to plot various aspects of the optimization progress **and the search-space** after it has been run. Personally I like `plot_objective` the most but `plot_evaluations` is useful for other things, e.g. plotting the histogram (which can now also be done with `plot_histogram`), but it should also be much faster than `plot_objective` for high dimensionalities, so it is useful to see where in the search-space the samples were taken, without plotting the landscape which is very expensive.
4. Usefulness is highly subjective. I find these plots very useful - you find them completely useless. Neither of us seems able to convince the other :-)

Please take a look at your own tutorial which uses these plots. As you will see, the plots make good sense there and clearly show you the objective-landscape and the regions that were sampled, the sample-ordering etc. These plots are better approximations to the true objective function because they are built from surrogate models with 160 samples of the true objective-function, whereas you only took 40 samples. I think these plots are great! And I am perfectly willing to accept more distorted plots for harder problems where we cannot evaluate hundreds of samples of the objective-function.

https://scikit-optimize.github.io/notebooks/visualizing-results.html

I think it is a mistake to discuss whether these plotting functions should be in skopt or not. We are way beyond that point. If you have other plotting functions that are better, then those can be added later by someone else in another PR. Somebody else thought these plots were useful to add to skopt (the above tutorial was written by @betatim so perhaps he also wrote the original `plots.py` - I don't know). I agree completely that these plots are useful! If they are ""new"" to the field, then congratulations you have added something to the field that you should be proud of! Perhaps in 5 years everyone will show these plots in their papers, thanks to you!

Unfortunately `plots.py` didn't work with `Categorical` dimensions which I had in my Neural Network problem, so I had to fix that. But I didn't understand your code because it was so convoluted and undocumented that I had to rewrite it all in order to modify it. It is now probably the cleanest code you have in skopt - you can get angry with me for saying that, but it's the truth. It makes very minor changes to the layout of the plots that I think looks better. So all we need to decide now is whether the code is in correct working order and if something needs to be fixed.

The code passes all the tests and also creates the plots correctly for your own tutorial. I can expand on the doc-strings with my explanations above. And I can fix the minor issues @betatim raised. I'll be happy to do that, but then we must merge it. I cannot afford to waste anymore time on this. @betatim and @iaroslav-ai should I make these minor changes so you will merge, or should I stop work on this now?

@iaroslav-ai Please review and merge #597 which is needed for this PR as well (some of the issues @betatim raised are fixed by that).

Please consider that this thread may deter others from wanting to contribute to skopt in the future because it is so problematic. So once again, I think it is in your own best interest to get this PR closed ASAP.
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-23T17:07:27Z,True,scikit-optimize_____scikit-optimize_____579_____359860536,@Hvass-Labs thanks for detailed comments! Will respond later today.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-23T21:26:08Z,True,scikit-optimize_____scikit-optimize_____579_____359935939,"Thanks again for a thorough discussion! To extend a bit on my arguments:

I would measure the usefulness of an algorithm as a minimum objective found by an algorithm after k iterations, k > 0, averaged on a set of n >> 0 problems such as [ones used here](http://proceedings.mlr.press/v64/dewancker_strategy_2016.pdf) or others. Our library is concerned with doing optimization best it can, so we should measure our success by how well we optimize “in general”. 

To argue about the usefulness of the plots, I would like to see a comparison of such quantities, which could look like:

| With plots | Without plots |
| ------------- |:------------------:|
| 0.6 +/- 0.2 | 0.9 +/- 0.1 |

It does not matter to me where such data comes from as long as it is reliable - paper or not :) But without such reliable data, we cannot make any claims of whether these plots are helpful or otherwise. Any claims without supporting data is just a speculation.

I would like to provide to every user of skopt a functionality which is verified to be beneficial in optimizing user’s objective. 

One can possibly define other meaningful evaluation metrics. Generally, I find it important to show that indeed plotting search space can be used to improve some measurable and important performance metric, to motivate necessity for plotting in the first place.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-23T21:26:41Z,True,scikit-optimize_____scikit-optimize_____579_____359936095,"On the other hand side, I must confess removing will involve too much stone turning in skopt, with already large PR. Plus it might be useful for tutorials/examples in say 2d space. Finally, it is good to decide on something concrete and doable to do. 

I propose the following plan:
1. let me and others who might be looking here think about this for a day.
2. If nothing comes up, we modify the docstrings, to add the warning that there is no publications or public data available to support these plots.
3. no guarantees are made that these functions are not removed or changed in the future. This is also noted in docstrings.
4. We fix if there are some technical issues with pr, and merge it

Anyone comments on the plan?

P.S. I will be not very responsive tomorrow and the day after tomorrow in the morning, but will get better after that.  ",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-24T08:56:52Z,True,scikit-optimize_____scikit-optimize_____579_____360063384,"@iaroslav-ai Thanks for the quick response! Once again I don't mean to be condescending, but I am smiling at this discussion. I think I am a lot older and more experienced than you, so I hope you take this as friendly feedback. It is amusing and annoying at the same time because I don't have time for it, but it is a bit funny :-) You were such a cool dude on the `@use_named_args` PR where you came in and resolved matters very quickly and professionally in the middle of a heated discussion - just like Mr. Wolf :-) But what you're saying here doesn't make any sense. That is why I'm smiling now :-)

How are you going to **quantify** the usefulness of a plot? It is plotted **after** the optimization has taken place. Personally I am just curious what the objective function looks like. The surrogate model is only an approximation and the 2D mapping is a further approximation. So I know that the plots are probably misleading to some extent, especially if the surrogate model is only built from e.g. 40 samples. So the plots have limitations. That doesn't mean they are useless. Especially if you don't have a better way of plotting them. But you cannot even **prove** and **quantify** the usefulness of an ordinary convergence plot, yet those are used everywhere.

As you agree, this is not a very fruitful discussion to be having. If in 6 or 12 months you find a **better** way of making plots then you can add those, or modify `plot_objective` if you find a better way to map +3D to 2D plots. But don't remove these plotting functions because **you** don't find them useful. That is not a rational decision.

@iaroslav-ai If you agree to merge, then I will clarify in the doc-strings that the plots have the limitations we have discussed. I don't think it is reasonable to add a warning that they might be removed, but perhaps a note that the visuals might change if a better method is found in the future. You are very welcome to review the code for bugs / problems, but I don't think there's a need for you to spend many hours on that - it is fairly high quality code and it passes all the tests. Please merge #597 first as it is needed here.

@betatim Please confirm that you will also support the merge if I fix the minor issues you raised. You guys have had almost 4 weeks to discuss the new naming semantics and I don't have anymore time for this. So you need to make a decision now whether you will merge this or not.

I am in beautiful Greece surrounded by spectacular vistas of mountains and water. Even so, I am happy to spend my Saturday in front of my computer finishing this PR. But that is the last day that I am willing to help you.

Please note that you already start getting issues with people who are having problems with these functions (one in #606 and another person in this thread). Those people are coming here by way of my tutorial. You should expect a large number of people to learn about skopt from my tutorial in the future. I explain in both the video and the Python Notebook that people need to install from my dev-fork to use this plotting functionality. Hopefully these functions are added to skopt 0.5 so it can be installed easily with pip. But after this discussion I will keep my dev-fork as long as there is a possibility that the functions might be removed from skopt master. This is harmful to your cause because people will be very confused about what to use, especially as I will not maintain my dev-fork.
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-25T22:47:11Z,True,scikit-optimize_____scikit-optimize_____579_____360626404,"Let's just focus on the PR. I think our time is best spent on reviewing the code or enjoying our evening or enjoying beauty of Greece :)

The tests fail on Travis for some reason:
[https://travis-ci.org/scikit-optimize/scikit-optimize/jobs/326786738](https://travis-ci.org/scikit-optimize/scikit-optimize/jobs/326786738)

@Hvass-Labs please make sure that you rebase your code on master and that all the tests pass locally for you. Please do address the comments that @betatim raised. Also, state the limitations of dependency plots in docstrings as you mentioned. I was told by @betatim that [this](https://projecteuclid.org/download/pdf_1/euclid.aos/1013203451) was the original inspiration for the plots. 

I am fine with mergins this PR as long as everyone has reviewed the code and given their +1. ",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-25T22:57:19Z,True,scikit-optimize_____scikit-optimize_____579_____360628625,Btw @Hvass-Labs thanks again for the detailed response! I do not find your tone condescending - you just state your opinion. ,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-25T23:00:41Z,True,scikit-optimize_____scikit-optimize_____579_____360629376,"I haven't had time to look at this any further than the comments I made previously. The tone of the discussion doesn't make me want to schedule time for it either. The nature of volunteer driven projects is that it is more important to create a welcoming environment than anything else so that people do schedule time to look at things. I'd ask you to please tone down and edit your comments, otherwise people will not engage with the work you are doing. Beyond just your work it creates a combative and adversarial feeling which turns people off. As a option of last resort the maintainers of the project would ask you to leave.

Trying to force things with comments that are easy to (mis)read as threats (""You will be flooded by users requesting this."", ""People will get a bad impression."") is not productive. The best possible outcome is a bad atmosphere amongst contributors.

Experience has shown that the effort to review work grows exponentially with the amount of change. So many small (<50 lines) PRs are good and keep the ball rolling. For large changes building consensus first and following it up with a series of small PRs seems to work well. Some things can't be achieved in small steps, but this means they will be unfortunately very, very slow. (Anecdote: changing two lines in the jupyter notebook project took ~3months to get merged.)

You mentioned that you also don't have a lot of time to spare. That is understandable. Feel free to leave the PR as it is now, someone will eventually come and pick it up, or cherry pick parts of it into a smaller PR. Authorship will be maintained through the cherry-picking. It is part of the volunteer aspect that PRs stall, get picked up by others later, or just abandoned. This is Ok and not a failure on anyone's side.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T10:19:28Z,True,scikit-optimize_____scikit-optimize_____579_____164076006,"Fixed. I tested it, it's a Python 2.7 compatibility problem.",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T10:21:33Z,True,scikit-optimize_____scikit-optimize_____579_____164076403,Fixed. The correct thing would be to use PR #597 but it has not yet been merged and I want this PR to work as-is.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T10:21:56Z,True,scikit-optimize_____scikit-optimize_____579_____164076474,Fixed.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T10:22:38Z,True,scikit-optimize_____scikit-optimize_____579_____164076600,Fixed. Same as above: The correct thing would be to use PR #597 but it has not yet been merged and I want this PR to work as-is.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T10:23:23Z,True,scikit-optimize_____scikit-optimize_____579_____164076728,Fixed.,True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T10:42:15Z,True,scikit-optimize_____scikit-optimize_____579_____360746508,"@iaroslav-ai This is the text I've added to the doc-string of `plot_objective()`:

    NOTE: The Partial Dependence plot is only an estimation of the surrogate
          model which in turn is only an estimation of the true objective
          function that has been optimized. This means the plots show
          an ""estimate of an estimate"" and may therefore be quite imprecise,
          especially if few samples have been collected during the optimization
          (e.g. less than 100-200 samples), and in regions of the search-space
          that have been sparsely sampled (e.g. regions away from the optimum).
          This means that the plots may change each time you run the
          optimization and they should not be considered completely reliable.
          These compromises are necessary because we cannot evaluate the
          expensive objective function in order to plot it, so we have to use
          the cheaper surrogate model to plot its contour. And in order to
          show search-spaces with 3 dimensions or more in a 2-dimensional plot,
          we further need to map those dimensions to only 2-dimensions using
          the Partial Dependence, which also causes distortions in the plots.
",True,True
scikit-optimize_____scikit-optimize_____579,2018-01-26T12:54:12Z,True,scikit-optimize_____scikit-optimize_____579_____360777163,"I have now fixed what you have requested and pushed it back to github. I did not squash it to make a single commit in the PR, because it might cause problems for people who are using my dev-fork. I have run all the tests in `skopt/tests` and it works locally. I believe this PR is ready to be merged.

This ends my involvement in your project. You can now merge it or not, it's up to you.

I will leave my tutorial using my dev-fork for now. That is liable to give you guys a headache later on as explained above, but that's apparently how you want it - it's not a threat, it's just a fact. (I have re-read my message above and don't understand how you perceive that as menacing. https://github.com/scikit-optimize/scikit-optimize/pull/579#issuecomment-360063384)

You have had 4 weeks to make a very simple decision and it is obvious that it could take many months and never result in anything. I simply cannot afford to waste anymore time on this.

@betatim raised some issues about this PR 9 days ago (!) that I answered within one hour (https://github.com/scikit-optimize/scikit-optimize/pull/579#discussion_r162012861). I explained in detail the technical reasons why I had made those decision, including issues that @betatim himself had raised earlier. But @betatim never responded which was of course frustrating because it stalled the PR, and now he's mad again about something I said so he refuses to respond and finish this PR.

Nobody is more sorry about this whole situation than me. I am the person who has wasted a lot of time and energy on it. I also don't enjoy this, but I do the work anyway because it needs to be finished.

This whole thing got off course when you guys refused to accept responsibility for writing really bad code that was functionally broken and impossible to understand and fix for others. Instead you tried to shift the blame to a newcomer for being unable to understand your code. All you had to do was say: ""We can see that this code may be really hard to understand for others, and we're really sorry for the pain it has caused. If you're willing to take a crack at fixing and cleaning it up, we'll be happy to help explain it wherever we can. In the future we'll try and make our code easier for others to work on.""

But instead you got pissy when I started complaining about your code, and I also recall that @betatim mentioned somewhere early on that I might be having mental issues! (That might have been in another PR ... something about me having angst or something.) That is about as low as you can go and I certainly haven't sunken that low when I have criticized your work. Of course I didn't take it very seriously, but before you guys blame me for having bad manners and being counter-productive, you may want to look at yourself first.

In my video tutorial on TensorFlow and skopt towards the end I encourage people to help you guys out. But I feel I now have a responsibility to moderate that recommendation and make it clear that it can be a very prolonged and painful experience that ultimately may not yield anything, so I will post a link to this thread and let people judge for themselves whether they want to spend time on your project. I know you guys believe I have harmed my own reputation in this thread, but that is really not the case.

I still think your project is really cool, but I also think it is really difficult to work on, in great part because of your attitude towards ""collaboration"". Naturally, I wish I had never gotten involved so I could have spent the time and energy on something more productive.

Despite all of this, I still sincerely wish you the best of luck in the future of this project and hope we all learned something from this experience!

To end all of this on a humorous note :-)

https://www.youtube.com/watch?v=J6VjPM5CeWs
",True,True
citizenfx_____fivem_____98,2018-02-12T21:11:38Z,True,citizenfx_____fivem_____98_____168689032,,True,True
citizenfx_____fivem_____98,2018-02-12T21:15:02Z,True,citizenfx_____fivem_____98_____365064267,it's almost you don't like signature features,True,True
citizenfx_____fivem_____98,2018-02-12T21:21:54Z,True,citizenfx_____fivem_____98_____365066163,Not the meme!,True,True
citizenfx_____fivem_____98,2018-02-12T21:47:58Z,True,citizenfx_____fivem_____98_____365073548,no one touches the memes!!!,True,True
turtlecoin_____turtlecoin_____74,2018-02-19T08:06:12Z,True,turtlecoin_____turtlecoin_____74_____169898128,untested,True,True
turtlecoin_____turtlecoin_____74,2018-02-19T11:51:37Z,True,turtlecoin_____turtlecoin_____74_____366667243,Why do we need to increase the max supply?,True,True
turtlecoin_____turtlecoin_____74,2018-02-19T20:04:06Z,True,turtlecoin_____turtlecoin_____74_____366790848,"(using approximated numbers)

10,000,000,000 people

29,600 reward * 2 blocks/min * 60 minutes * 24 hours = 85,248,000 turtles/day

85,248,000 / 10,000,000,000 = 0.0085248 turtles/person/day

1,000 turtles/person / 0.0085248 turtles/person/day = 117,304 days for everyone to have 1,000 turtles = 321 years

Money supply of 100,000,000,000,000 shells only allows for 10,000 shells/person once fully produced.",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T02:33:05Z,True,turtlecoin_____turtlecoin_____74_____366850411,"At best, we are going to have about 10,000 shells per person on the planet (using rounded/approximated number). Is that really going to be that functional? It seems like more shells are needed.

What do you think about generating 100k shells (1000 turtles) per person per day?",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T02:35:34Z,True,turtlecoin_____turtlecoin_____74_____366850718,Is my math wrong? Or you can only communicate through github emojis?,True,True
turtlecoin_____turtlecoin_____74,2018-02-20T02:51:52Z,True,turtlecoin_____turtlecoin_____74_____366852828,"I don't think the emission schedule should be changed. Users have agreed on the initial rules by their participation and making this big of a centralised rule change while we are underway will invalidate their initial reasons for joining. 

Max supply should not be modified on the main chain. ",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T02:58:11Z,True,turtlecoin_____turtlecoin_____74_____366853559,"I think that's a somewhat fair way of looking at it, but it seems like the low money supply will forever limit turtlecoin's usefulness.

What would be the damage to users if supply was increased???",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T03:05:11Z,True,turtlecoin_____turtlecoin_____74_____366854482,"Compare to Bitcoin:

16,875,100 coins with 100,000,000 satoshi per coin = 1,687,510,000,000,000 satoshis

168,751 satoshis per person (using 10,000,000,000 people)

Turtle has:

602,181,453,437 turtles with 100 shells per turtle = 60,218,145,343,700 shells

60 shells per person (using 10,000,000,000 people)",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T05:10:20Z,True,turtlecoin_____turtlecoin_____74_____366868630,"Bitcoin has a total supply of 21m coins, so 21,000tn satoshi.

You haven't said why you believe everyone needs 10,000 shells or what purpose this would serve. If it's egalitarian idealism then because TRTL is a freely traded coin and it costs money to mine, and if its prime purpose is to have transactional value and be a mechanism of exchange, the 10,000 shells you believe they need will not be equally distributed among persons. 

The reason there should be 10,000 TRTL for every person alive at the point where there are 10bn people on the planet and not more or less is arbitrary. It's already been explained [why TRTL has a total supply of 1tn with two decimal places](https://medium.com/@turtlecoin/one-trillion-turtles-coin-supply-and-unit-economics-5bfbea0aa1f1). The fact that supply of cryptocurrency requires work is one of its saving graces - while central banks can just ""print money"" in order to alleviate deeper economic issues, creating more money without any kind of work like it takes to mine natural resources (or in the case of crypto, solve mathematical problems), cryptocurrency retains value because of its strictly controlled and predictable supply and transfer mechanism. What you propose would turn TurtleCoin into the crypto equivalent of the Zimbabwean dollar, because then nothing would stop two or three more zeroes being added to the end of the money supply. Existing supplies would become increasingly worthless, people would stop mining, the blockchain would suffer from a lack of maintenance because people couldn't rely on the basic supply and algorithm - in short it would be a complete mess.

Most importantly, however, you've just added a zero without considering any of the implications of this PR. You haven't dealt with how any of the other software is going to deal with this - I assume you haven't looked at any of the other repos to see how they deal with this right now, and I assume you haven't considered the impact on coins already mined or the existing blockchain.",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T05:13:04Z,True,turtlecoin_____turtlecoin_____74_____366868974,">You haven't said why you believe everyone needs 10,000 shells or what purpose this would serve.

wtf, I never said I believe everyone needs 10,000 shells",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T05:17:25Z,True,turtlecoin_____turtlecoin_____74_____366869502,"> wtf, I never said I believe everyone needs 10,000 shells

No, you're right. You said 100,000. I apologise for mixing one essentially arbitrary target spawned from a half baked idea and a second essentially arbitrary target spawned from a half baked idea.

Should I edit my original post to add a zero so it's clearer for you?",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T05:21:03Z,True,turtlecoin_____turtlecoin_____74_____366869966,">No, you're right. You said 100,000.

nah brah, you got a copy-paste function?",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T05:31:57Z,True,turtlecoin_____turtlecoin_____74_____366871377,"> nah brah, you got a copy-paste function?

Yeah I do, ""brah"", so here's you:

> What do you think about generating 100k shells (1000 turtles) per person per day?

This gets more redundant by the second. 100,000 shells per person per day? Is this for the 10bn people that are going to exist on this planet at some point? Or just everyone who's mining gets 100,000 shells every day? Is this a cryptonote supply algorithm or are we just handing them out? Because then we could just premine 1tn coins with 1000 units and hand them out. Cut this distributed consensus thing right out, because it gets in the way of whatever you think is happening in the world. You can't even explain why, what or how - you just farted out some half baked sums and picked a number out of the air.

Right ""brah""? Tell you what. Go away and deal with the economic, social, psychological and, most importantly, engineering implications of adding a zero, then come back when you've solved those. Then you can add as many zeros as you like. ""Brah"".

_Don't even bother_ explaining what you mean, because that's a giant gaping rabbit hole I don't care to go down and I can't see it having any possible benefit for anyone. Not you, and _definitely_ not me.",True,True
turtlecoin_____turtlecoin_____74,2018-02-20T05:36:34Z,True,turtlecoin_____turtlecoin_____74_____366871945,"This is getting out of hand, and frankly I believe @siftycat said everything that needed to be said. Continue this discussion elsewhere if you wish to have it.",True,True
angular_____material_____11135,2018-02-26T15:49:40Z,True,angular_____material_____11135_____171412942,"Use md-stretch-height to fill available space in parent element.

Closes won't fix issue #2254 abandoned by core team for material 2 surge. Previously approved for milestones 1.1.6 and 1.1.7 by @ThomasBurleson in pull request #9665 that was locked by mistake by @Splaktar as explained in PR #11131. This PR is being opened at @Splaktar's request as noted in #9665 ",True,True
angular_____material_____11135,2018-02-28T19:08:51Z,True,angular_____material_____11135_____369348349,"@Splaktar All comments in PR #9665 have been addressed. Just waiting on you, pal.",True,True
Marak_____faker.js_____616,2018-03-14T10:28:11Z,True,Marak_____faker.js_____616_____174911131,"- Spelling
- Latin american versions of the Spanish original surnames.
- Some portuguese variations
- ""Gollum"" is not an acceptable Spanish surname :)
- ""Franco"" was the last name of the Spanish dictator. We don't want a fake name such as ""Francisco Franco"" in the results...",True,True
mysqljs_____mysql_____1962,2018-03-14T12:00:25Z,True,mysqljs_____mysql_____1962_____174933169,"This patch accommodates some breaking changes introduced with MySQL 8.

Closes #1959 

In a nutshell, the `caching_sha2_password` plugin (which is used by default since MySQL 8.0.4) hashes the password using SHA-256 and, after a first successful authentication attempt, saves it in a cache. That first attempt needs to be done under one of two conditions. The client either uses SSL and sends the password as clear text or it encrypts the password using the RSA public key generated by the server. On any subsequent attempts, until the password is somehow removed from the cache or the server shuts down, these rules no longer apply.

The handshake process remains unchanged when connecting to any server with version lower or equal to `8.0.3`. Whereas for `8.0.4` or above, the process is now the following:

- the client sends a `ClientAuthenticationPacket` with a scramble computed using a SHA-256 hash
- if the password is not cached, the server sends back a `PerformFullAuthenticationPacket`
- if the client uses SSL, the password is sent to the server (as clear text) via a `ClearTextPasswordPacket` to which the server replies with a `OkPacket`
- otherwise it uses the server authentication public key compute the scramble, sending a `AuthSwitchResponsePacket` to which the server replies with a `OkPacket`
- if the client does not know the server public key (is not provided by the user), it requests it from the server, which sends it back using a `AuthMoreDataPacket`
- after a first successful authentication attempt, and until the password is cached, the server will reply to the initial `ClientAuthenticationPacket` with a `FastAuthSuccessPacket` (which basically just signals that an `OkPacket` will follow)

If the account is created using the `mysql_native_password` authentication plugin, the client will just fall back to the ""traditional"" process during the handshake, keeping compatibility, by default for any previously supported server version.

MySQL 8.0.2 disables the `local_infile` server variable by default, which breaks a couple of integration tests. The tests were updated to enable the feature by themselves (something that does not have any effect on older server versions and allows the tests to pass with newer versions).

Additionally, one of the integration tests was updated to avoid failing after the first run (using any server version) since it tried to create a table that already existed from the previous runs.",True,True
mysqljs_____mysql_____1962,2018-03-14T16:26:02Z,True,mysqljs_____mysql_____1962_____373085142,"This is awesome, thank you soo much! The only real issues I'm seeing with the PR to continue to work on is the following:

- [ ] Get support working on Node.js 0.10 and below, or we can decide if this PR should be shelved for the next major release as breaking change to drop those Node.js versions. Being a widely-used base driver we try to support as many Node.js and MySQL versions as possible at once to make it easy to use for everyone.
- [ ] There may not be enough coverage of the new code added, as the coverage with the PR is decreasing. There are probably some areas that can use tests.
- [ ] MySQL 8 image needs to be stood up on the CI server to test against. This is done in the `.travis.yml` file similar to our current MySQL / MariaDB matrix.",True,True
mysqljs_____mysql_____1962,2018-03-14T16:26:54Z,True,mysqljs_____mysql_____1962_____174522803,"Is this change related specifically to the MySQL 8 support, or just a general fix. Just curious.",True,True
mysqljs_____mysql_____1962,2018-03-14T18:54:51Z,True,mysqljs_____mysql_____1962_____174574477,"For the new authentication magic to happen in the server, we need to explicitly provide the authentication plugin name in the `ClientAuthenticationPacket`, and, doing that, we need to be careful of which flags to enable, otherwise the server will, for instance, interpret `caching_sha2_password` or `mysql_native_password` as the schema/database name, if none is provided.

I didn't want to mess around with the `PacketWriter` and this seemed the easiest way to overcome that hurdle. However, we can try to think of something else if it feels weird.",True,True
mysqljs_____mysql_____1962,2018-03-14T19:00:06Z,True,mysqljs_____mysql_____1962_____174576084,"Sure, but I was more curious on if this is a general fix or specific to MySQL 8. But even then, users can pass in their own `flags` list, and this module will enable / disable them unless it's listed here with a flag to force one way or the other. If having it set when it shouldn't is an issue, then it should probably be flagged here so the users cannot pass in the flag and get it set when no db is specified.",True,True
mysqljs_____mysql_____1962,2018-03-14T19:06:39Z,True,mysqljs_____mysql_____1962_____373139995,"To address your points.

Regarding the first one, I've missed those tests (sorry), but as far as I can tell there is no sane way to use RSA public key encryption on `node <=v0.12.0`. There are some packages on npm that try to add support through native addons, but I think that might not be a good idea here, since it's pure JavaScript. So the only easy way to work around that is to require users on those older `node` versions to use SSL when connecting to new MySQL versions. If you are OK with that, we can go that route, otherwise, going in the next major version is probably the best possibility (I guess that's mostly your call).

Missed the coverage as well, I'll try to fix that ASAP.

Again, missed the CI config. Should be fine, at least on Travis. However, besides that, I suggest we also create a test account to run the tests (besides `root`) to make sure the handshake works fine for both empty and non-empty passwords, which lead to different behaviors. Any issue with that? Other than that, I guess on windows we are out of luck anyway since appveyor only seems to support MySQL 5.7, correct?",True,True
mysqljs_____mysql_____1962,2018-03-14T19:49:10Z,True,mysqljs_____mysql_____1962_____174589168,"Actually, maybe this specific change is not required after all. The schema name is a null terminated string, so it should not cause that issue I mentioned. This is sort of a leftover from my earlier experiments. I'll try to work around this and update the patch.

Good catch!",True,True
mysqljs_____mysql_____1962,2018-03-15T02:36:28Z,True,mysqljs_____mysql_____1962_____373241016,"> Regarding the first one, I've missed those tests (sorry), but as far as I can tell there is no sane way to use RSA public key encryption on node <=v0.12.0. There are some packages on npm that try to add support through native addons, but I think that might not be a good idea here, since it's pure JavaScript. So the only easy way to work around that is to require users on those older node versions to use SSL when connecting to new MySQL versions. If you are OK with that, we can go that route, otherwise, going in the next major version is probably the best possibility (I guess that's mostly your call).

Ah, very sad :( Did you do a through search on this (it sounds like it)? Because I can always help if you want to focus on the other parts, but just asking before I duplicate the search for no reason. If we really have to drop supported versions, we can, and it wouldn't particularly delay this, just wanted to make sure it was actually required to do so before saying we should :)

> Again, missed the CI config. Should be fine, at least on Travis. However, besides that, I suggest we also create a test account to run the tests (besides root) to make sure the handshake works fine for both empty and non-empty passwords, which lead to different behaviors. Any issue with that? Other than that, I guess on windows we are out of luck anyway since appveyor only seems to support MySQL 5.7, correct?

Yea, so in Travis CI it just uses a Docker image. You can make multiple non-root accounts too; the current setup was just what was needed for testing, so if MySQL 8 requires more elaborate setup, that sounds fine to me. I would ignore AppVeyor.",True,True
mysqljs_____mysql_____1962,2018-03-15T15:44:57Z,True,mysqljs_____mysql_____1962_____373422784,"I'm using `crypto.publicEncrypt()` which was added in `v0.11.14`, and it uses native bindings which I assume were also added around that time. There are some libraries on npm (e.g. [ursa](https://github.com/JoshKaufman/ursa) and [dcrypt](https://github.com/dekz/dcrypt)) that claim support for earlier node versions, however they seem to implement their own native bindings, which I guess would, sort of, defeat the purpose of this module (or maybe not, you tell me). 

There's this [node-rsa](https://github.com/rzcoder/node-rsa) thingy which apparently is pure JS, but I couldn't make it work and it's pretty slow. I've also seen other [approaches](https://github.com/ragnar-johannsson/rsautl) like delegating work to openssl via a child process, but that's probably not a good idea either, since it introduces a huge moving part. There's also this [forge](https://github.com/digitalbazaar/forge) kit which brings the entire browser kitchen sink with it and I also haven't managed to figure out how it worked.

So, no good news from my side. However, if you can do your own research, that would, of course, be great. However, I'm not a cryptography expert, but from what I can tell, the reason I have not found anything good is because this RSA thingy in pure JavaScript is still not really feasible (`number` precision, primes and what not).

My suggestion here is to fail with a client error (the `HANDSHAKE_SECURE_TRANSPORT_REQUIRED` introduced by this PR) when `process.env.version` tells us that we are below `v0.11.14`, which basically would be the default behavior using `{ ssl: false, secureAuth: false }`. It's a pretty naive solution but at least it's not really a breaking change, because existing implementations will keep working as expected with MySQL 5.7 and, let's be honest, people wo don't upgrade from those ancient node versions will, almost for sure, not upgrade MySQL to series 8 as well.

However, if you still feel you are better off bumping the major version, that's fine.
",True,True
citizenfx_____fivem_____98,2018-03-18T20:02:09Z,True,citizenfx_____fivem_____98_____374039723,Grow up and merge this PR,True,True
citizenfx_____fivem_____98,2018-03-18T20:05:20Z,True,citizenfx_____fivem_____98_____374039930,grow down and keep this pr open!,True,True
citizenfx_____fivem_____98,2018-03-18T22:00:13Z,True,citizenfx_____fivem_____98_____374054351,But it's already closed blu!,True,True
citizenfx_____fivem_____98,2018-03-18T22:01:41Z,True,citizenfx_____fivem_____98_____374054614,the memes have to die eventually. it was great while it lasted.,True,True
citizenfx_____fivem_____98,2018-03-18T22:02:28Z,True,citizenfx_____fivem_____98_____374054726,This meme **has** to live on >:( .,True,True
citizenfx_____fivem_____98,2018-03-18T22:03:47Z,True,citizenfx_____fivem_____98_____374054906,[Let it die](https://www.youtube.com/watch?v=gWL90wryyOw),True,True
citizenfx_____fivem_____98,2018-03-18T22:04:20Z,True,citizenfx_____fivem_____98_____374054969,**N O**,True,True
citizenfx_____fivem_____98,2018-03-18T22:13:15Z,True,citizenfx_____fivem_____98_____374056212,Re-open!,True,True
citizenfx_____fivem_____98,2018-03-18T22:18:56Z,True,citizenfx_____fivem_____98_____374057076,"🙄 build your own fork if you want it changed, this pr was closed for a reason.",True,True
citizenfx_____fivem_____98,2018-03-18T22:22:59Z,True,citizenfx_____fivem_____98_____374057649,This should be locked by @blattersturm,True,True
citizenfx_____fivem_____98,2018-03-18T22:26:06Z,True,citizenfx_____fivem_____98_____374058069,Well merge this PR when you've grown a pair.. while you're at it get a better humor,True,True
citizenfx_____fivem_____98,2018-03-18T22:28:27Z,True,citizenfx_____fivem_____98_____374058378,"When you'll not be so retarded anymore, then i am sure the elements will be able to at least take it into consideration. I don't see what changing that text would add, apart from removing an historical signature, that has been included with fivem since the beginning.",True,True
citizenfx_____fivem_____98,2018-03-18T22:33:46Z,True,citizenfx_____fivem_____98_____374059177,Just because somethings existed for a long time doesn't make it right. New users probably see that error and have no clue what's happened. Usability vs Nostalgia?,True,True
citizenfx_____fivem_____98,2018-03-18T22:37:53Z,True,citizenfx_____fivem_____98_____374059739,"It's also in the english locale, meaning that it should be *english*. You could always changed it back in this location: `\FiveM.app\citizen\ui\app\assets\locale-en.json`",True,True
citizenfx_____fivem_____98,2018-03-18T22:38:22Z,True,citizenfx_____fivem_____98_____374059828,"Mmh, weird, i've always seen a detailed description of what happened right after that word, must've been my mind playing tricks on me!",True,True
citizenfx_____fivem_____98,2018-03-18T22:43:36Z,True,citizenfx_____fivem_____98_____374060428,"Well, yeah, anyway, you can keep trying and writing stupid comments or you could just go back to your lives, up to you, but trust me, you dont wanna see an angry element coming your way.",True,True
citizenfx_____fivem_____98,2018-03-19T14:57:33Z,True,citizenfx_____fivem_____98_____374241765,@vecchiotom who the fuck do you think you are. I hope you stand up to similar situations irl,True,True
citizenfx_____fivem_____98,2018-03-19T15:03:04Z,True,citizenfx_____fivem_____98_____374243820,"@ElPumpo What the fuck did you just fucking say about me, you little shit? Ill have you know I graduated top of my class in the Navy Seals, and Ive been involved in numerous secret raids on Al-Quaeda, and I have over 300 confirmed kills. I am trained in gorilla warfare and Im the top sniper in the entire US armed forces. You are nothing to me but just another target. I will wipe you the fuck out with precision the likes of which has never been seen before on this Earth, mark my fucking words. You think you can get away with saying that shit to me over the Internet? Think again, fucker. As we speak I am contacting my secret network of spies across the USA and your IP is being traced right now so you better prepare for the storm, maggot. The storm that wipes out the pathetic little thing you call your life. Youre fucking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, and thats just with my bare hands. Not only am I extensively trained in unarmed combat, but I have access to the entire arsenal of the United States Marine Corps and I will use it to its full extent to wipe your miserable ass off the face of the continent, you little shit. If only you could have known what unholy retribution your little clever comment was about to bring down upon you, maybe you would have held your fucking tongue. But you couldnt, you didnt, and now youre paying the price, you goddamn idiot. I will shit fury all over you and you will drown in it. Youre fucking dead, kiddo.",True,True
bower_____bower_____1748,2018-03-28T14:10:32Z,True,bower_____bower_____1748_____376900730,Bower is depreacted now and we recommend switching to Yarn that supports version locking and more. Here's guide how to migrate: https://bower.io/blog/2017/how-to-migrate-away-from-bower/,True,True
KSP-KOS_____KOS_____2260,2018-03-29T20:16:53Z,True,KSP-KOS_____KOS_____2260_____178430499,"Already fixes #2121 (or I hope so) as much as is currently possible, before we select the proper way of handling the booting from archive. Contains all previous PR's yet to be accepted and the crutial changes I needed for the tester, namely:

**CPU.cs:**
1. `private` -> `protected`
2. Few methods made `virtual`
3. Triggers cannot be casted to `NoDelegate`, that code did nothing, 
changed to `trigger.EntryPoint < 0`.
4. No real change in logic (except that `NoDelegate` above).
5. Oh, and I changed the implementation of `Dispose` to the form suggested by MS.

**Stack.cs, IStack.cs and PseudoNull.cs:**
- these are all helpers that I needed, nothing too important, no change in logic

***Now for the booting:***
1. We can either change the `run ...` command in injected *boot the boot script* to include something like `wait until homeConnection:isConnected.`, which looks easy, but that would require changing/removing `Processor.CheckCanBoot()` and probably replacing it with something like *give me the boot the boot script* instead, if you want to preserve the interface (I will address that later).
2. Create new form of `YieldFinishedCompile`, e.g. `YieldCanBoot` (or combination of both), that will be waiting until we can really boot. I don't think I am able to create such a thing with my current knowledge of the kOS.

**Notes:**
I would personally remove `IStack` becase there is only one class implementing it and I see no need for it, no vision for any other class implementing it.
I would also remove `ICpu`, because there are only two implementations - the real one and the one in tests, but the former can be created the same way as my `TesterCPU` by subclassing the `CPU` in this PR. It would probably be even better because it is much closer to the original.",True,True
KSP-KOS_____KOS_____2260,2018-03-29T21:39:40Z,True,KSP-KOS_____KOS_____2260_____377380800,"I'm going to stat taking a look at this since it is related to something I've started working on.

For future pull requests (no need to make a change to the ones you have pending) if you could try to keep them as independent as possible, it really makes it easier to review.  For one thing shorter lists of changes are easier to review.  But more importantly the same person might not be reviewing all of your pull requests, and so it may be held up waiting for review of the other portions.  (I know that specifically in this case keeping the .editorconfig changes is useful).",True,True
KSP-KOS_____KOS_____2260,2018-03-29T22:59:49Z,True,KSP-KOS_____KOS_____2260_____377397864,"I know what you are talking about but as you noticed, I won't separate until you accept the `.editorconfig` ... or you will have to repair the tabs. I have the commits nicely separated, use this for review.

The other thing is that I want my version (with all changes), but I can separate it and merge to my main **if you accept the `.editorconfig`**.",True,True
KSP-KOS_____KOS_____2260,2018-03-30T05:36:41Z,True,KSP-KOS_____KOS_____2260_____178235494,I never liked ``yield return``.  It requires too much magic collusion between the compiler (``yield`` being a keyword) and .NET (``System.Collections.Generic.IEnumerable``).,True,True
KSP-KOS_____KOS_____2260,2018-03-30T06:12:15Z,True,KSP-KOS_____KOS_____2260_____178238257,"Also, @firda-cze , I looked through this PR's full list of changed files and I'm not seeing where you use these new ``IEnumerable``s that you added to ``Stack.cs``.  You said you had them in here because you needed to use them elsewhere but where are you using them?",True,True
KSP-KOS_____KOS_____2260,2018-03-30T07:50:29Z,True,KSP-KOS_____KOS_____2260_____178248570,"Well, you can create full blown enumerator, but this is just easier. You write the main loop and `yield return` elements that you can consume through `foreach` later, a bit like async, but without a thread. Co-routines in unity are implemented the same way and they actually use it in thread-like (fiber) fashion.

See https://github.com/firda-cze/KOS/blob/firda/src/kOS.Tester/TesterCPU.cs for the reason I added these. Definitelly using `Arguments`, wanted to use `ArgumentsFromBottom` for checking what has changed, before I understood the argument order reversing in call. I did not create view for `Scopes` yet, but will need that too.

Here #2247 are pictures from the tester.",True,True
KSP-KOS_____KOS_____2260,2018-03-30T08:32:14Z,True,KSP-KOS_____KOS_____2260_____178254360,"Well, I disagree with it being easier, but that's a matter of opinion.  (In trying to find the sweet spot between being hard because it's too terse versus being hard because it's too verbose, my opinion is that the C# culture errs on the side of being too terse.  The C# community loves syntactic sugar a lot more than I do.)

I understand how much of a PITA it is to keep things separate in one PR that you're using in another PR when neither is merged yet.  @hvacengi is dealing with this particular merge so I'll defer to him to decide how to handle it.

By the way, is that tester something you plan to release?  Is it an independent executable or something that you invoke inside KSP's process?",True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:17:27Z,True,KSP-KOS_____KOS_____2260_____178260870,"It is independent exe, only referencing the Safe.dll, feel free to take it any time, open-source, free to use, but it is not yet ready, it lacks the scopes.
But it can already step individual instructions, show opcodes, all jumps/calls, stack, output, log, all the tests and helped me a lot in understanding what is going on under the hood.
Basic WinForms, so, should be portable to Linux and Mac as well. Want [Eto](https://github.com/picoe/Eto) or Xamarin.Forms instead?",True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:21:16Z,True,KSP-KOS_____KOS_____2260_____178261412,I'm not well versed enough in C# development (I only learned C# specifically for kOS.  I come from the Java/C++ world on Unix mostly) to answer that question.  I don't really know the difference between the GUI options you mentioned.,True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:23:10Z,True,KSP-KOS_____KOS_____2260_____178261684,"P.S.: Would you prefer [ReadOnlyCollection](https://msdn.microsoft.com/en-us/library/ms132474(v=vs.110).aspx) or something similar instead? Like `Keys` and `Values` in `Dictionary`. The draw-back is that you have to keep it around in a field (for the sake of speed, or make it struct which I don't like much), but that is acceptable.",True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:35:39Z,True,KSP-KOS_____KOS_____2260_____178263413,"I have heard that one of the major speedups they did in one of the KSP versions was that they went through and replaced many of their `foreach` iterator-based loops with traditional old-school index-counting `for` loops because Mono's iterator implementation was much slower than just getting items by index (A problem specific to Mono's implementation that Unity uses to be cross-platform, not Microsoft's .NET).  That's part of the reason I never had much incentive to want to make an iterator-based wrapper around the stack access.",True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:40:10Z,True,KSP-KOS_____KOS_____2260_____178264084,"Nothing against arrays and indexes, but that would require merging the stack into the CPU, so that derived classes (TesterCPU) can access it. Should not be exposed publicly, that is why I added this read-only interface for it.",True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:47:53Z,True,KSP-KOS_____KOS_____2260_____178265194,"Foreach was fixed in Unity 5.5:
https://unity3d.com/learn/tutorials/topics/performance-optimization/optimizing-garbage-collection-unity-games",True,True
KSP-KOS_____KOS_____2260,2018-03-30T09:51:37Z,True,KSP-KOS_____KOS_____2260_____178265750,"To be honest, I never really understood why the heck in Marianoapp's original implementation, the stack has private protections against the CPU.  All that did is make me have to add a ton of dependency inversion interfaces between the two, when really the CPU class should have full permissions to do whatever it likes to the stack.  The only real reason I can see to protect the stack would be to deliberately bottleneck the access through a few key APIs, but those APIs really should allow all access and all major operations.",True,True
KSP-KOS_____KOS_____2260,2018-03-30T13:28:05Z,True,KSP-KOS_____KOS_____2260_____377524015,"Not tested with RemoteTech, I never used that mod, I don't even know how it works.
Resolved my problems with booting from archive, everything works now.
Selected the option with YieldFinished - created YieldFinishedCompileBoot for this.
fix #2259 ",True,True
KSP-KOS_____KOS_____2260,2018-03-30T15:38:15Z,True,KSP-KOS_____KOS_____2260_____377551902,"Separated as requested, sorry for the mess, had to use push force.",True,True
mysqljs_____mysql_____1962,2018-04-04T16:40:00Z,True,mysqljs_____mysql_____1962_____378665937,@dougwilson what's your preference about the issue I mentioned? Do you want me to add the workaround for older node.js versions or do you think it's better to have a major version bump (in that case I guess all we need is to remove the CI setup for older versions)?,True,True
dirigeants_____klasa_____261,2018-04-05T20:06:30Z,True,dirigeants_____klasa_____261_____179782369,"### Description of the PR

Added Discord.JS to the `npm install` command on the Getting Started page

### Changes Proposed in this Pull Request (List new items in CHANGELOG.MD)

N/A

### Semver Classification

- [X] This PR only includes documentation or non-code changes.
- [ ] This PR fixes a bug and does not change the (intended) framework interface.
- [ ] This PR adds methods or properties to the framework interface.
- [ ] This PR removes or renames methods or properties in the framework interface.
",True,True
dirigeants_____klasa_____261,2018-04-05T20:07:42Z,True,dirigeants_____klasa_____261_____379060600,"""About:
Klasa is an OOP discord.js bot framework which aims to be the most feature complete, while feeling like a consistant extension of discord.js.

Originally based on Komada, Klasa has become a ship of Theseus and so much more. You can only vaguely see similarities between the two frameworks anymore..."" If you don't know you are meant to install discord.js, then you are an idiot.",True,True
dirigeants_____klasa_____261,2018-04-05T20:08:21Z,True,dirigeants_____klasa_____261_____179585907,"This is wrong, stable uses d.js stable.",True,True
dirigeants_____klasa_____261,2018-04-05T20:08:54Z,True,dirigeants_____klasa_____261_____379060950,"It was already discussed in the Discord server that master Discord.js should be used
",True,True
dirigeants_____klasa_____261,2018-04-05T20:09:56Z,True,dirigeants_____klasa_____261_____379061231,![](https://i.imgur.com/UAbRwPt.png),True,True
dirigeants_____klasa_____261,2018-04-05T20:11:30Z,True,dirigeants_____klasa_____261_____379061640,"So it seems. From the package.json, it appears that stable uses master d.js.

My apologise. 

My point still stands, however, you should KNOW that you need to install d.js. Should we tell people they need to install node too? And have a system to run it on? All of these things you should know, if not, you probably shouldn't be developing a bot.",True,True
dirigeants_____klasa_____261,2018-04-05T20:12:27Z,True,dirigeants_____klasa_____261_____379061905,"Yes, you SHOULD know that Discord.JS is needed, but nothing ever said that **master** Discord.JS is needed.",True,True
dirigeants_____klasa_____261,2018-04-05T20:12:51Z,True,dirigeants_____klasa_____261_____379062028,"""My point still stands, however, you should KNOW that you need to install d.js.""
Not necessarily. It's a peer dep, but if it was a normal dep, it would be installed automatically.",True,True
dirigeants_____klasa_____261,2018-04-05T20:18:39Z,True,dirigeants_____klasa_____261_____379063496,"In our official extension, we're using `npm i discordjs/discord.js klasa` or `npm i discordjs/discord.js dirigeants/klasa`, depending on the selected item [here](https://github.com/dirigeants/klasa-vscode/blob/6085287970cd5bbdecfaa4d43d51b15a0e899b18/src/commands/init.js#L26).

To follow the behavior of our extension, it should match the command our extension sends to the terminal, therefore this PR is right.

Maybe add a note or something to tell the end users we have an [extension for VSCode](https://marketplace.visualstudio.com/items?itemName=bdistin.klasa-vscode) that abstracts the installation steps and many things in our framework, I'm pretty sure they will be very grateful for it.",True,True
opnsense_____core_____2338,2018-04-09T06:43:13Z,True,opnsense_____core_____2338_____180223267,Get the actual system default for Firewall Maximum Table Entries and Firewall Maximum Fragments.,True,True
opnsense_____core_____2338,2018-04-09T06:51:58Z,True,opnsense_____core_____2338_____379652451,"Leave a commentIt's not a fix to ""the fix"".  Really has nothing to do with the fix.  Have had this for quite some time.  Just thought this would be a good time to submit it, and it happens to involve ""the fix"".",True,True
opnsense_____core_____2338,2018-04-09T06:57:59Z,True,opnsense_____core_____2338_____379653578,"Shall I close or do you want to rework it? I'm unwilling to help shape your proposals since you:

1. Are allergic to code review.
2. Imply people should have a thicker skin.

We can play hardball, no problem.",True,True
opnsense_____core_____2338,2018-04-09T07:48:56Z,True,opnsense_____core_____2338_____379664982,"Simply submit an honest PR and you go off the deep end because it alters a recent fix in order to accomplish it's objective.  Could have not included that part but it would not work the same/as intended.  Then when I offer explanation you make personal attacks.
Dude you're losing it.  Get a grip.

This PR is not about ""the fix"" i.e. bumping the default.  It is about presenting defaults in the GUI that are currently suppressed when a user config value is present.  This requires altering (""choosing"") more than ""one file"".

This was no code review.

Whether or not people should have thinker skin is a discussion more appropriate for the web forum.  And that's where it was.  But you have bring it here as a personal attack or as justification for you action.  Guess you can't handle people having views that you disagree with.

You're playing ""hardball"" over something so petty proves my point.  You're losing it and need to get a grip.  Stop the vindictiveness because your feelings got hurt over a previous botched ""code review"" and code butchering.
",True,True
opnsense_____core_____2338,2018-04-09T07:56:51Z,True,opnsense_____core_____2338_____379666875,"> Simply submit an honest PR and you go off the deep end

Please don't wast your time with accusations and victim cards.",True,True
opnsense_____core_____2338,2018-04-09T08:04:48Z,True,opnsense_____core_____2338_____379668833,"As if you are so concerned about my time.  LOL
",True,True
opnsense_____core_____2338,2018-04-09T08:08:31Z,True,opnsense_____core_____2338_____379669693,"Feel free to try again when you are in a better mood. :)

And next time please read this:

https://github.com/opnsense/core/blob/master/CONTRIBUTING.md

I'm going to spell it out for you: if you have a solution, prepare to bother talking about the actual problem. Not everyone is as smart as you are it seems.


Cheers,
Franco",True,True
opnsense_____core_____2338,2018-04-09T08:18:16Z,True,opnsense_____core_____2338_____379672151,"Better mood?  I'm in a great mood.   You are the one who immediately went into attack mode and calling that a code review is pathetic.  Your hurt feelings and apparent desire for retribution are hindering your objectiveness.  Read some stuff on Reddit about this project.  Was refusing to believe it.  But not anymore.  You've pretty much confirmed it.
",True,True
opnsense_____core_____2338,2018-04-09T08:19:40Z,True,opnsense_____core_____2338_____379672498,"For better or worse, this will be the last time I'm engaging you. I'm closing your open PRs. Nobody is willing to work with you anymore. I hope you already noticed.",True,True
opnsense_____core_____2338,2018-04-09T09:17:55Z,True,opnsense_____core_____2338_____379688496,"What I've noticed is that you can't handle your so called ""code reviews"" being exposed butchering with incorrect explanations.  Can't have an honest dialog with you about the code when you go personal with hurt feelings when your so called code review is called into questioned.  Not professional at all.  Hope you've noticed that it is you who are taking your marbles and running home like a poor sport.

Though I will pay you a compliment.  Your code behavior and unwillingness to work with me in a professional manner (honest dialog about the code, not nonsense incorrect explanations, hurt feelings and personal attacks) has resulted in my making some commits that are far beyond were they would have ever made it to with your involvement.  So even though your intend was as lemons.  I made some real cool sweet lemon-aid out of them.  To bad your personal feelings will hinder your product features to customers.

Your closing of my all my commits (taking your marbles and running home) will probably be a good thing for me as well.
",True,True
opnsense_____core_____2338,2018-04-09T09:22:32Z,True,opnsense_____core_____2338_____379689787,"To show you how you've created a self-fulfilling prophecy here's your unfriendly entry into OPNsense. I've had my concerns back then, and I was the only one who helped you with your PRs despite internal doubts.

https://forum.opnsense.org/index.php?topic=6631.0


Cheers,
Franco",True,True
opnsense_____core_____2338,2018-04-09T09:27:28Z,True,opnsense_____core_____2338_____379691123,Yup.  You can't take being corrected.  Pointed out a legitimate bug due to failure to follow specifications and you tried to down play it.  As I recall trying to pass the buck because the code came from a third party.  So you get hurt feelings when I don't let you make excuses.,True,True
opnsense_____core_____2338,2018-04-09T09:30:53Z,True,opnsense_____core_____2338_____379692072,"> Yup. You can't take being corrected.

Stop barking, it has no effect.

> Pointed out a legitimate bug due to failure to follow specifications

If you're a genius, you need to communicate it. Now you just make up words like ""specification"" without backing them up with facts.

> As I recall trying to pass the buck because the code came from a third party.

Please explain. This means nothing without context.

> So you get hurt feelings when I don't let you make excuses.

You have made several miserable days for me. And you are a bad person for doing so.",True,True
opnsense_____core_____2338,2018-04-09T09:37:07Z,True,opnsense_____core_____2338_____379693752,Yes it was a failure to follow specification and yes I provided the backup.  It's all in the thread.  You and everyone can read it there.  But I realize you are trying to insert your own altered reality.,True,True
opnsense_____core_____2338,2018-04-09T09:38:45Z,True,opnsense_____core_____2338_____379694172,Likewise. Please let it go.,True,True
opnsense_____core_____2338,2018-04-09T09:42:04Z,True,opnsense_____core_____2338_____379695073,"Dude.  You're the one holding the grudge and attempting to exact revenge.  You are the one who needs to let it go.  You should have let it go a long time ago instead of letting your feelings get the better of you, behaving unprofessionally and hindering your product.
",True,True
opnsense_____core_____2338,2018-04-09T09:43:20Z,True,opnsense_____core_____2338_____379695411,You're still here and being unfriendly. I don't know why. :),True,True
opnsense_____core_____2338,2018-04-09T09:47:23Z,True,opnsense_____core_____2338_____379696574,"Yeah but I know why you're still here and being unfriendly.

You make personal attacks, exact revenge and then call me unfriendly.  LOL You just continue to confirm Reddit.  They pegged you spot on perfectly.  I couldn't believe it until now.  You are doing exactly what they said you do.
",True,True
opnsense_____core_____2338,2018-04-09T09:50:13Z,True,opnsense_____core_____2338_____379697380,"You are deflecting, most likely because you have nothing more to say.

Think of all that energy instead being put in your PRs. You can only change yourself. :)

And remember I said play hardball. I meant it. If you want me to stop just ask.",True,True
opnsense_____core_____2338,2018-04-09T09:58:50Z,True,opnsense_____core_____2338_____379699727,"What I want.  And always have wanted is for you to be professional.  A big part of that is having honest, open, no personal dialog about code.  Not lashing out because someone challenges you.  I made non personal response to your code reviews, citing PHP manual and that cause you to be unwilling to work with me.  Very unprofessional.  Like I said earlier.  Can't have an honest dialog with you about the code.
",True,True
opnsense_____core_____2338,2018-04-09T10:13:22Z,True,opnsense_____core_____2338_____379703498,"I concur about the first part. I disagree about the second part. There are a number of people all over the world with varying degrees of knowledge and past experiences. They can successfully contribute. I would say this is one of the strengths of this community.

A particular example of when this does not work could mean two things: I'm lying or there is some truth to what I'm going to say.

Call me whiny or unprofessional or whatever you want. The truth is I don't see the point of working with difficult, stubborn people who have no regard for the time they are given by others because in the end there are better things to do here, at work, or elsewhere in life.

Communicate more concise. That means your PRs should give a full scope of what you are trying to do and which problem it solves. Or at least point to the forum thread.

Accept your role. For now at least, I'll have to do the review and be the difficult one whether you like it or not. I personally do not like it if that process goes south like in this case. So if we don't do this, no code will be merged and I don't think that's your goal. And besides, far too much problems have arisen from prematurely merged PRs over the last 15 years that added unnecessary code, spurious wrappers, premature caching mechanisms and so forth. To be precise, creating a JSON file is an explainable addition. Notice this is the first time ""JSON"" comes up and where we are. I don't think this is necessary, but it's your duty to explain and advocate its use. Not mine.

Above all, stay friendly. Life is too short for unpleasant contributions.


Cheers,
Franco",True,True
opnsense_____core_____2338,2018-04-09T10:24:53Z,True,opnsense_____core_____2338_____379706238,I wasn't referring to this PR.  But several previous where you made bogus code changes and your explanations where incorrect.  When questioned about it and your response was to be unwilling to work with me.  It was not about the PR justification but your unwillingness to have honest dialog about your code changes to the commits.  Several which where just plain wrong.,True,True
opnsense_____core_____2338,2018-04-09T10:26:29Z,True,opnsense_____core_____2338_____379706638,"""

> Above all, stay friendly. Life is too short for unpleasant contributions.

""
After your personal attacks, that's pretty funny.",True,True
opnsense_____core_____2338,2018-04-09T10:29:49Z,True,opnsense_____core_____2338_____379707372,"Since you don't want to at least accept a grain of responsibility and you keep degrading the discussion after I offered a structured criticism I'm closing this now. Arguing with you is pointless as stated elsewhere. And you are not interested in constructive criticism, you just assume that everybody else needs to do whatever you want. Here's the short version: I will not put up with you anymore.

If you want to change something, please try to be a better person. After you've degraded my character a few times now, you mean realise that I'm less than perfect and at least try to work on it. :)


Good-bye,
Franco",True,True
pmmp_____PocketMine-MP_____1476,2018-04-14T20:50:30Z,True,pmmp_____PocketMine-MP_____1476_____381359669,I'm going to close this since there hasn't been any movement on it recently. A new PR will be created when we have something worth shipping.,True,True
stripe_____react-stripe-elements_____197,2018-04-16T17:15:01Z,True,stripe_____react-stripe-elements_____197_____181933435,"### Summary & motivation

Prevent a nazi from using this library

### Testing & documentation

Wrote a unit test to demonstrate that Paul Nehlan's api key would stop working with this library.
",True,True
stripe_____react-stripe-elements_____197,2018-04-16T19:07:40Z,True,stripe_____react-stripe-elements_____197_____381715427,"This forum is to discuss react-stripe-elements. Unfortunately, we can't discuss specific users.",True,True
mysqljs_____mysql_____1962,2018-04-20T11:38:25Z,True,mysqljs_____mysql_____1962_____383069686,"Sorry I didn't reply. Your comment on a new issue reminded me of this. Yea that works: if the server requires an auth that the client can't do we can error out. We should feature detect that, though, not sniff the version string.",True,True
mysqljs_____mysql_____1962,2018-04-20T17:45:20Z,True,mysqljs_____mysql_____1962_____383171533,"Ok. Just to be sure. Are you talking about sniffing the Node.js version string, MySQL version string, or both? Because we have two different issues right now. 

Supporting MySQL 8.0.4 (previous DMR release) which expects the password to be encrypted with the server public key using `RSA_PKCS1_PADDING`, whereas since 8.0.11 (the new GA release), the encryption should use `RSA_PKCS1_OAEP_PADDING`. We can always retry the handshake, but the only way to avoid that is by ""sniffing"" the MySQL server version.

Regarding the Node.js encryption APIs, I guess we can always resort to duck typing to check if they are available (or not) instead of sniffing the version. So, no problem here.

Let me know if there is something else that bothers you about these or other issues. I'll try to push this forward ASAP. Maybe during the weekend.",True,True
mysqljs_____mysql_____1962,2018-04-20T17:54:37Z,True,mysqljs_____mysql_____1962_____383174051,"Why do you have to sniff the server version? Shouldn't the server say which one it expects directly? I'm just asking because I think version numbers break down when we start talking about compatible things like MariaDB, right? They may share some version numbers.

I have done Node.js version sniffing before and when it broke the Node.js collaborators just said I should never have been version sniffing their versions and told me feature detect only. So if that is the official direction from there I would go with that.",True,True
mysqljs_____mysql_____1962,2018-04-20T20:09:24Z,True,mysqljs_____mysql_____1962_____383208410,"The case where we might need to sniff the server version is to distinguish MySQL 8.0.10 (pre GA, first one introduced chaching_sha1_passwors) from MySQL 8.0.11 (GA). since 8.0.11 was released yesterday one also could not support 8.0.10, as nobody should be using that RC anyways.

jojannes

On April 20, 2018 1:38:35 PM GMT+02:00, Douglas Wilson <notifications@github.com> wrote:
>Sorry I didn't reply. Your comment on a new issue reminded me of this.
>Yea that works: if the server requires an auth that the client can't do
>we can error out. We should feature detect that, though, not sniff the
>version string.
",True,True
mysqljs_____mysql_____1962,2018-04-20T20:17:07Z,True,mysqljs_____mysql_____1962_____383210478,"Right. However, in this case we would be sort of ""whitelisting"" MySQL 8.0.4 specifically. I don't think MariaDB has this new authentication plugin (enabled by default or not), but I'm not entirely sure.

In any case, I believe the padding mode was probably a mistake, which was ""fixed"" for GA. So we can just default to `RSA_PKCS1_OAEP_PADDING` (the GA version) and optionally do a handshake retry for the specific case where `RSA_PKCS1_PADDING` is needed (MySQL 8.0.4 RC only). Or we can just simply ignore the RC version entirely, like @johannes suggested, by always using `RSA_PKCS1_OAEP_PADDING`.

This is currently my only open question. Other than that, not doing Node.js version sniffing makes perfect sense, so that is settled.",True,True
mysqljs_____mysql_____1962,2018-04-20T20:23:25Z,True,mysqljs_____mysql_____1962_____383212072,"By the way, just to be clear, there was a straight jump from 8.0.4 (last RC) to 8.0.11 (GA).",True,True
mysqljs_____mysql_____1962,2018-04-24T21:38:53Z,True,mysqljs_____mysql_____1962_____384088602,I like the idea to either (a) just ignore the pre GA padding or (b) retry with the old padding because that would not involve the version sniffing :+1:,True,True
rack_____rack_____1272,2018-04-28T22:41:04Z,True,rack_____rack_____1272_____184808661,This suggested addition is the result of a collaboration between @boazsegev of Iodine fame and myself. Both Agoo and Iodine will support these suggested additions. At this point I don't think any other servers are supporting WebSockets and SSE so this would set the standard for others to follow.,True,True
Marak_____faker.js_____636,2018-04-30T19:45:19Z,True,Marak_____faker.js_____636_____185046316,,True,True
Marak_____faker.js_____636,2018-04-30T19:49:09Z,True,Marak_____faker.js_____636_____385508598,"Again, you must not modify build or example files.

You must only modify source files.

Probably only going to be a few files in the end.

Closing again.",True,True
Marak_____faker.js_____636,2018-04-30T19:54:32Z,True,Marak_____faker.js_____636_____385509947,"I asked you last time what folders to exclude, I don't appreciate this game you play with me. 

You could've saved us both time with this simple find and replace but I guess you prefer to immortalize the name of a Nazi war criminal. You should add Adolf Hitler too. ",True,True
Marak_____faker.js_____636,2018-04-30T20:28:07Z,True,Marak_____faker.js_____636_____385518651,"I'm editing your comment and blocking you from contributing to this repository.

This is not a place to discuss politics or world history and I am not obligated to teach you how to make modifications to this project. 

This is not a game. If you don't understand how to modify the source code or behave civilly over Github Issues you may take your contributions elsewhere.",True,True
Marak_____faker.js_____636,2018-04-30T20:41:34Z,True,Marak_____faker.js_____636_____385522198,"Dear @SelaO, faker.js is a JavaScript port of [faker](https://github.com/stympy/faker) the Ruby gem, which in turn is based on Perl's Data::Faker. Please take a look at the [original list of names](https://github.com/stympy/faker/blob/master/lib/locales/en/name.yml) used for seeding. That might explain how Eichmann ended up being included over here as well and why your comments came across as confrontational even though you have a point, x",True,True
rust-lang_____rfcs_____2426,2018-04-30T23:06:06Z,True,rust-lang_____rfcs_____2426_____185086944,"
### [🖼️ Rendered](https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md)

### 📝 Summary

Introduce diverging `throw expr` expressions, typed at `!`, which either `break` to the closest `try { .. }` if there is one, or if not, `return` from the `fn` or closure. The expression form `throw expr` is supported on edition 2018 onwards. This also means that `throw` is reserved as a keyword.

A minimal example:
```rust
if condition {
    throw Foo;
}
```

### 💖 Thanks

To @scottmcm for reviewing.",True,True
rust-lang_____rfcs_____2426,2018-04-30T23:22:12Z,True,rust-lang_____rfcs_____2426_____185137076,"typo: 243, not 2343",True,True
rust-lang_____rfcs_____2426,2018-04-30T23:28:31Z,True,rust-lang_____rfcs_____2426_____185138056,Fixed. Thanks!,True,True
rust-lang_____rfcs_____2426,2018-05-01T11:34:55Z,True,rust-lang_____rfcs_____2426_____385651805,"I guess I'll be the one to make the highly subjective but critical point against this, since I think we need to start gathering opinions on it ASAP if it's going to get addressed properly:

**I'm still not convinced that `try {}` blocks and `throw` expressions pull their weight as language features.** In fact, the motivation section for this RFC made me _more_ skeptical that `throw` is worthwhile, since in all the examples it shows, we only appear to be saving a half-dozen or a dozen characters at most. With `?` we were saving not only a whole match block, but it was very common to see nesting of those match blocks (or the corresponding `try!()`s). I'm not aware of expressions like `return Err(error)` ending up ""nested"" in a way that helps motivate `throw`.

I know `try {}` blocks aren't part of this RFC, but I think `throw` only stands a chance of pulling its weight if it comes with the convenience of targeting the enclosing `try {}` block or the whole function if there is no enclosing `try {}` block, _and_ if `try {}` blocks are used so frequently that this is a big deal.

Also, the prior art section feels highly misleading, since this feature has nothing to do with implicitly-propagated exceptions, and many of the languages listed are using `throw` specifically for exceptions, not early-but-otherwise-ordinary returns. While I'd prefer to use a keyword without the exception baggage if we do this at all, I don't want to start that bikeshed yet because it's far more important to come to a consensus on whether any special sugar for ""non-exception throws"" pulls its weight. And that's only going to happen if we get a bunch of people here stating their personal opinion not on the optimal keyword, but of the value of having `try {}` and `throw expr;` features at all, regardless of their final syntax.",True,True
rack_____rack_____1272,2018-05-01T12:09:57Z,True,rack_____rack_____1272_____385656965,"Interesting.

I already support completely transparent asynchronous web sockets in [falcon](https://github.com/socketry/falcon). It uses `rack.hijack` just fine. An example is given here: https://github.com/socketry/async-websocket/blob/master/examples/chat/config.ru

Of course with this model supporting SSE is also trivial.

Regarding the event driven model which is being exposed via `rack.upgrade`: I don't think exposing an event driven API is a great way to make systems asynchronous. It's kind of limiting.

Regarding the overall design - careful thought needs to be given to how HTTP/2 fits into this picture. Ideally, SSE, WebSockets, and other ""interactive"" streams, transit via reading from the request body and writing to the response body. That's the model which I feel works best with HTTP/2, where each request/response is encapsulated into a full duplex stream.",True,True
rack_____rack_____1272,2018-05-01T12:57:24Z,True,rack_____rack_____1272_____385664722,"Bare in mind that `async-websocket` doesn't support web sockets over http/2 yet, this is something I'll work on in the coming months.

This is also one of the challenges of implementing `rack.hijack` for HTTP/2. You need to be careful of what it means, exactly, to hijack a connection (or stream in the case of HTTP/2).",True,True
rack_____rack_____1272,2018-05-01T13:15:22Z,True,rack_____rack_____1272_____385668006,"I think the HTTP/2 layer is something that's handled only by the server. It shouldn't change the `rack.upgrade` semantics since it isn't one of the protocols / behaviors that should be handled by the application.

I think the idea is great because it decouples the application from any network logic.

While `hijack` solutions remove the server, changing the relationship from `network<=>server<=>application` to `network<=>application`, this approach keeps the application away from the network, keeping the initial (and desired) relationship intact.",True,True
rack_____rack_____1272,2018-05-01T13:21:57Z,True,rack_____rack_____1272_____385669300,"@boazsegev While I see where you are coming from, I think that your idea of a semantic model is much higher than what is exposed by HTTP.

Given the direction of HTTP/2, it's clear to me that the base HTTP semantic model is a full-duplex un-buffered stream of chunks. Whether you implement this with multiple HTTP/1 connections or HTTP/2 streams (which to me is the network layer), is irrelevant to the application.

The application simply sees a full duplex stream of chunks. That's the semantic model for the application. On top of this you can implement your desired web sockets, sse, and other interesting things, like streaming responses, and so on.

Your semantic model has a tight coupling with your desired application level protocols, but I think that's a very limiting design. For example, you can't implement general streaming responses like https://github.com/socketry/falcon/blob/master/examples/beer/config.ru",True,True
rack_____rack_____1272,2018-05-01T13:24:04Z,True,rack_____rack_____1272_____385669706,I think I should mention this discussion here since it seems relevant: https://github.com/rack/rack/issues/1148,True,True
rack_____rack_____1272,2018-05-01T13:36:26Z,True,rack_____rack_____1272_____385672209,I'd like to point out that Rack is event based as are the WebSocket and SSE API/specs. The Rack hijack offers a streaming back door that is not addressed by the spec. This PR attempts to formalize an approach to using WebSocket and SSE that is consistent with the use pattern common in modern web applications with JavaScript front ends. It is not an attempt to get rid of the hijack option. There is certainly reason to continue support for hijacking but that should not be a reason to reject this PR.,True,True
rack_____rack_____1272,2018-05-01T13:40:33Z,True,rack_____rack_____1272_____385673011,"@ioquatix , you're totally right, I can't implement that code... nobody can unless they implement `Async::Task` and add that as a Rack dependency.

As for streaming solutions: SSE **is** a streaming solution.

If you refer to video streaming or binary data requirements, WebSockets are perfect for that.

If you meant old-school HTTP streaming... yes, that's true. I'm not even sure that I should, but I'm aware that I don't. In fact, I'm pretty sure [the Rack model wouldn't be ideal for streaming](http://blog.plataformatec.com.br/2012/06/why-your-web-framework-should-not-adopt-rack-api/) anyway. ",True,True
rack_____rack_____1272,2018-05-01T13:42:55Z,True,rack_____rack_____1272_____385673490,"> I'd like to point out that Rack is event based

[I'm not convinced by this](https://github.com/rack/rack/search?utf8=✓&q=on_&type=)

If anything, rack is based on composable middleware. There is no event handling.

> The Rack hijack offers a streaming back door that is not addressed by the spec

Sorry, but this is complete dump trucks: https://github.com/rack/rack/blob/154ac5255323021ef74039e11a0a7376af889eaa/SPEC#L87-L96

> This PR attempts to formalize an approach to using WebSocket and SSE that is consistent with the use pattern common in modern web applications with JavaScript front ends

This is the guts of the matter. Why is this necessary? It's clearly already possible to do it - so we have to ask the question, do we need to formalise this in rack, or is there something simpler that we could formalise which allows more possibilities. We should accept or reject this PR based on the merits of what it adds to Rack, as a specification. I think there are better, more generic, options.
",True,True
rack_____rack_____1272,2018-05-01T13:47:57Z,True,rack_____rack_____1272_____385674547,"> @ioquatix , you're totally right, I can't implement that code... nobody can unless they implement Async::Task and add that as a Rack dependency.

I don't think I proposed that anywhere. I just said, with the current Rack spec, you can do it, and it scales well. We don't need to change the rack spec to have a great implementation of web sockets.

> As for streaming solutions: SSE is a streaming solution.

It only works in one direction and it only works in a very specific context. It's not general response streaming, as in `body.each {|chunk| ... peer.write(chunk) ...}`

> If you refer to video streaming or binary data requirements, WebSockets are perfect for that.

> If you meant old-school HTTP streaming... yes, that's true. I'm not even sure that I should, but I'm aware that I don't. In fact, I'm pretty sure the Rack model wouldn't be ideal for streaming anyway.

The Rack model is great for streaming responses. That's the whole point of the response body responding to `each`.",True,True
rack_____rack_____1272,2018-05-01T13:49:43Z,True,rack_____rack_____1272_____385674938,"By the way, I'm not trying to shit all over your PR, although it probably feels like it. Congratulations for making something, and implementing it and proposing it. Basically, I just don't see the logic of it though. I think there are better things in Rack that need to be addressed, and I think the direction of HTTP/2 confirms this.",True,True
rack_____rack_____1272,2018-05-01T13:54:33Z,True,rack_____rack_____1272_____385675990,"Of course Rack is event based. The trigger for all Rack code is the `#call(env)` callback where `env` is the encapsulation of the event that has occurred. That event being an HTTP request. After that you are correct, the handling is based on a middleware model.",True,True
rack_____rack_____1272,2018-05-01T13:55:27Z,True,rack_____rack_____1272_____385676197,"I'm paraphrasing slightly to focus on your question, forgive me and correct me if I misunderstood:

> Why is this necessary? ... is there something **simpler** that we could formalise which allows more possibilities.

I believe this is necessary because `hijack` is complex.

There's a difference between simple and easy. `hijack` is easy - but not simple.

It might simple for Rack and maybe even simple in the server, but it's a super complex solution that requires applications to add IO handling code.

The `hijack` pattern is an anti-DRY and anti-SOLID pattern that breaks away from object oriented approaches and requires applications to become familiar with the networking layers.

Sure, we might need to keep `hijack` around because some things are just impossible without it, but that doesn't make the best solution for everything. 

On the other hand, the callback approach in this PR is **simple**, but it's clearly not **easy**.

Servers will have to put in some work (less work than applications need to put in for `hijack`, but still).

However, the solution is simple and follows both DRY and SOLID principles.

The callback approach isn't a generic solution, it's just good for things that lend themselves to using callbacks, but this is the advantage of this approach.

IMHO, This is a perfect fit for everything callback related and it's extendible (if WebSockets 2.0 come around, nothing needs to be changed on the Rack/Application side, just the server).",True,True
rack_____rack_____1272,2018-05-01T14:09:44Z,True,rack_____rack_____1272_____385679604,"@ioquatix , I was looking through the falcon repo and you seem to have done great work there.

I understand your concerns and your wish to have a better solution. It seems to me that you yourself put in a lot of time and effort into improving the sated of affairs and making things easier and better for everyone.

I appreciate your approach and I find myself slightly surprised by the challenges you raise against this PR.

It seems to me that you're using similar semantics with different method names (i.e., your WebSocket `next_message` seems to block the current thread, allowing other threads to handle other server events until a new message becomes available... or maybe I misunderstood).

Sure, my implementation is evented and your implementation is multi-threaded, but both lend themselves to the same approach - application side ""callbacks"".

Your implementation could just as easily remain threaded and hide the `next_event` loop away so it calls the correct callback.

I'm not sure I understand your reservations.",True,True
rack_____rack_____1272,2018-05-01T14:30:46Z,True,rack_____rack_____1272_____385684707,"> I believe this is necessary because hijack is complex.

Those are all really good points and I appreciate your thinking.

To be honest, in falcon, implementing your proposed API wouldn't be more than about 100 lines of code, perhaps less. So, it's not complicated to implement, because falcon already has a well defined and good concurrency model. That's the context in which I'm thinking about your PR, by the way.

Whether the complexity is in the server, or the application code, is an interesting point and one that I can agree with to a certain extent. I don't think there is a strong argument either way.

> @ioquatix , I was looking through the falcon repo and you seem to have done great work there.

Thanks, I can tell we are going to get along well now.

> I understand your concerns and your wish to have a better solution. It seems to me that you yourself put in a lot of time and effort into improving the sated of affairs and making things easier and better for everyone.

Yes, but I still haven't made a 1.0 release yet. It's coming soon hopefully.

> I appreciate your approach and I find myself slightly surprised by the challenges you raise against this PR.

Fair enough.

> It seems to me that you're using similar semantics with different method names (i.e., your WebSocket next_message seems to block the current thread, allowing other threads to handle other server events until a new message becomes available... or maybe I misunderstood).

That's almost right. Async doesn't use threads, it uses fibers which are cooperatively scheduled. They have much less overhead than threads.

> Sure, my implementation is evented and your implementation is multi-threaded, but both lend themselves to the same approach - application side ""callbacks"".

Async is event driven. When a fiber performs an operation that would block, it yields back to the reactor which resumes once the operation can continue.

I deliberately try to avoid callbacks because in my experience they lead to callback hell. The difference is that with callbacks you need to use variables to track state, and each time the callback is invoked you have to process that state to figure out what to do next. With fibers, you naturally resume where you were with your stack intact. You can implement complicated state machines with ease.

> Your implementation could just as easily remain threaded and hide the next_event loop away so it calls the correct callback.

Yes, this is feasible.

> I'm not sure I understand your reservations.

I like this PR from the point of view that it tries to provide some generic interface for web sockets and server sent events. Making a generic interface for that is both simple and difficult. I admire the you've done it and implemented it.

My main reservation is that your proposed API is incomplete. The rack specification as it stands, is really simple and allows for a lot of flexibility. What you've proposed is an extension which fundamentally encodes a model for concurrency into Rack, something that it hasn't had except in a very precise location (response body `#each`).

To look at it another way, `falcon` passes the rack linter, yet it implements real-time streaming requests and responses. So, within the current confines of Rack, we can enjoy these advanced features.

Your proposed API exposes an incomplete model for concurrency and the word that comes to my mind is dangerous. What happens if you stick a `RestClient.get` into `on_message` - does it stall the entire server? How do you communicate between web sockets (in your PR I assume you'd need a shared backend like redis)? Whether or not you agree with it, the node model of single process, multiple connections is one that works very well - you can have an array of web socket connections, send messages to all of them, etc. This model can work well with Rack as shown by `falcon` (e.g. https://github.com/socketry/async-websocket/tree/master/examples/chat).

Whatever way you cut it, Ruby has a pretty frustrating model for concurrency right now (and IO too, but it's slowly getting better). People are working on it, myself, others (Eric, https://bugs.ruby-lang.org/issues/13618), ko1 (guilds) and I have no doubt that good things are coming to this space.

But, Rack, right now, has to be a specification that works with Ruby as it is today. If `Thribers` become part of Ruby (I personally hope not), the way servers should implement web-sockets should be totally different. It might be possible to make a MVP, like this PR, but I think it's loading Rack up with too much complexity.

Personally, what I think we need to focus on is making `rack.input` better suited for reading from HTTP/2 streams, and response `body` better suited for generating streaming responses. Finding the right model here should allow for SSE, WebSockets, and whatever other things",True,True
rack_____rack_____1272,2018-05-01T15:04:37Z,True,rack_____rack_____1272_____385693709,"@ioquatix interesting, thanks for taking the time to explain.

I love the fiber approach, as it hides away the event reactor and make things more comfortable to manage.

> My main reservation is that your proposed API is incomplete.  

Yes, you are right that there are concerns related to the proposed approach. It doesn't deal with IPC or client<=>client communications. It also allows developers to violate multi-threading best practices.

However, this proposal seems pretty balanced. It doesn't enforce a huge change on existing servers and the ""missing"" pieces are easily complemented by existing solutions (Redis being just one of them).

Personally, I implement pub/sub in iodine to ""fill the gap"". However, I'm not sure this should be part of the specification since other developers might wish to ""fill the gap"" using a different approach, such as limiting the server to a single process and using an array.

> What you've proposed is an extension which fundamentally encodes a model for concurrency into Rack...

I'm not sure I understand this part.

The server can be a single threaded server, a thread-per connection server, a fiber based server and practically any type of concurrency model can be implemented.

I'm not sure I see where the PR requires a specific concurrency model.

> What happens if you stick a `RestClient.get` into `on_message` - does it stall the entire server?

That really depends on the server, I guess.

What happens if I call `sleep(10)` while handling an HTTP request (except getting fired, that is)?

It's probably the same answer.

Iodine, for example, supports multi-threading and cluster mode (pretty much the same model as Puma). Agoo (I think) supports multi-threading.

For both of these servers I would recommend avoiding blocking calls within the thread, but they both offer some level of protection before experiencing DoS.

I don't use fibers so I'm not sure how they would react to this scenario. Hopefully they will react better.

Either way, I doubt the question of having fibers replace threads is part of the discussion here.

> Whether or not you agree with it, the node model of single process, multiple connections is one that works very well...

I agree with it, but I don't see why that matters.

Even the node model needs to be adjusted when scaling horizontally.

All models have properties that define their strengths and weaknesses.

IMHO, this PR proposes a mechanism that's independent of model used by the server, making it flexible enough for everyone to implement.",True,True
rust-lang_____rfcs_____2426,2018-05-01T16:35:15Z,True,rust-lang_____rfcs_____2426_____385717602,"I approve.

---

In response to @Ixrec's concern:

> I'm still not convinced that try {} blocks and throw expressions pull their weight as language features.

I would say two things:

First, I don't consider this feature to only make sense if we have `try` blocks. They seem orthogonal to me. As discussed in the RFC, there is a definite need to be able to unconditionally produce an error, even today -- and getting the precise formula correct is tedious. This is why error-chain and failure both include `bail!` macros.

Second, even if we are not sure we want something, if we think that there is a ""pretty good chance"" that we do, then it is worth reserving the keyword. In this case, I think the answer is definitely yes: both because there is prior art in favor and because there are a lot of folks who have spoken up in favor of `throw` or something similar in various threads and informal discussions. ",True,True
rust-lang_____rfcs_____2426,2018-05-01T17:20:54Z,True,rust-lang_____rfcs_____2426_____385729954,"@Ixrec 

> [..] we only appear to be saving a half-dozen or a dozen characters at most.

While a bonus of `throw expr` is brevity, in particular for generic cases where it substitutes
`return Try::from_error(expr)`, this is not the main motivation. Instead, the main benefit is better highlighting of exceptional cases via distinct syntax. This improves the *at-a-glance* readability of code.
Also, for me, `throw expr` telegraphs much better than `return Err(expr)` the semantic intent of the code and the author who wrote it.

> [..] targeting the enclosing `try {}` block or the whole function if there is no enclosing `try {}` block, [..]

Just to clarify, this is the semantics of `throw expr` in this RFC. :)

> [..] _and_ if `try {}` blocks are used so frequently that this is a big deal. And I don't think it's been established that there's a clear consensus on`try {}` blocks themselves being worthwhile (despite their presence in the original `?` RFC).

As @nikomatsakis puts it, `throw` is beneficial even without `try { .. }`, for reasons I mention above. However, I do think that `try { .. }` and `throw` together do enhance each other. 

I would also say that the `try { .. }` RFC, #2388 which is in FCP should count for something. Assuming the RFC gets merged (in one day), this means that `try { .. }` has been confirmed as useful in two separate RFCs including the original one you reference.

> Also, the prior art section feels highly misleading, since this feature has nothing to do with implicitly-propagated exceptions,

Neither does `try { .. }`, but two consecutive RFCs has advocated that we have *manually propagated exceptions* and that the benefit from familiarity outweighs the implicit / explicit distinction.
My view is that `throw expr;` would play the same role in both Java and Rust despite there being semantic differences.
Therefore, the prior art is, in my view, not misleading at all, assuming we remember the semantic difference between Rust and Java here. The section on drawbacks does discuss these differences.

> and many of the languages listed are using `throw` specifically for exceptions, not early-but-otherwise-ordinary returns.

Many, but not all. Haskell and Idris use `throwError` and `raise` respectively by convention despite preserving manual propagation (via monads) and *errors as values* semantically.
Swift is another example of not using Java style exceptions but still having `throw`.

> While I'd prefer to use a keyword without the exception baggage if we do this at all, I don't want to start that bikeshed yet because it's far more important to come to a consensus on whether any special sugar for ""non-exception throws"" pulls its weight.

I disagree with the notion that `Err(x)` is not an exception and thus that `throw` would be ""non-exception throws"". To me, `Err` denotes the *exceptional case* while `Ok` denotes the normal case.

On the choice of keyword, I think we should pick something that is consistent with `try { .. }` and that exceptional terminology.",True,True
rust-lang_____rfcs_____2426,2018-05-01T18:25:14Z,True,rust-lang_____rfcs_____2426_____385748178,"> it is worth reserving the keyword

:+1:

This is my strongest feeling in this area.  Some sort of `throw` expression has been discussed for at least three years; now that we're making an epoch it seems clear we should reserve the keyword.  In the absolute worst case it's trivial to un-reserve it later, as that doesn't need an epoch.",True,True
rust-lang_____rfcs_____2426,2018-05-01T19:08:49Z,True,rust-lang_____rfcs_____2426_____385760213,"Thanks, @Centril for this fine RFC! :1st_place_medal: 

> On the choice of keyword, I think we should pick something that is consistent with try { .. } and that exceptional terminology.

Here's my comment: I think we should find a better keyword than `throw`. I do like `try {...}`, but `throw` presupposes a subsequent `catch() {...}` block - an unlikely route for Rust - and `catch` is not suitable because success values are not *thrown*. Only exceptions are thrown.

I'd like to stress this point. Our experimental `do catch` is nothing like the `catch() {...}` of other languages. Our `do catch` is really a `try {...}`. 

We need a keyword that clearly expresses the occurrence of a failure, and that's consistent with a failed attempt, a failed *try*.",True,True
rust-lang_____rfcs_____2426,2018-05-01T19:50:55Z,True,rust-lang_____rfcs_____2426_____385770633,"@repax 

> Thanks, @Centril for this fine RFC! 🥇

I do like the appreciation! 😍

> I think we should find a better keyword than `throw`.

Ideas? 😄

Here are some synonyms of `throw`:

+ http://www.thesaurus.com/browse/throw
   `hurl` seems the only semi-reasonable one.

> I do like `try {...}`, but `throw` presupposes a subsequent `catch() {...}` block

How so? I understand that you might say: *- ""I **threw** the ball and my dog **caught** it""*, but the meaning of `throw Foo` seems intuitive even without a `catch` block due to familiarity.

> an unlikely route for Rust

I'm wary of making such predictions either way since it is difficult; We can give technical and non-technical arguments for why `catch` should or should not be added to Rust, but extending this to prediction seems fraught with perils.

> We need a keyword that clearly expresses the occurrence of a failure, and is consistent with a failed attempt, a failed *try*.

This way of framing it seems to suggest `fail` as a keyword which fits naturally with `try` if you say *""you might try, but you might fail""*. It is also a good candidate since the semantics should be scrutable by someone who has never seen `fail expr` before. But there are a few drawbacks with `fail`:
1. There's a crate named `fail` that has reverse dependencies (the rev deps are all by one author however).
2. It is too close to `bail!` (which can also be seen as a pro).

All in all, I think @nikomatsakis put it well on #2388:

> **Rust has a lot of concepts to learn.** If we are going to succeed, it's essential that people can learn them a bit at a time, and that we not throw everything at you at once. I think we should always be on the lookout for places where we can build on intuitions from other languages; it doesn't have to be a 100% match to be useful.

This suggests to me that `throw` is the right choice.",True,True
rust-lang_____rfcs_____2426,2018-05-01T20:20:53Z,True,rust-lang_____rfcs_____2426_____385778209,"We do need to tell people ""Rust does not have exceptions"", so using `throw` creates confusion, while `fail` actually nails it rather well.  I would not worry about one crate name, but maybe numerous traits have `fail` methods, and making it contextual sounds suboptimal.",True,True
rust-lang_____rfcs_____2426,2018-05-01T20:22:37Z,True,rust-lang_____rfcs_____2426_____385778639,"Back before 1.0, `panic` used to be called `fail`. It was always kind of confusing what was meant when someone said ""and then function xyz failed,"" because they might mean it in the general ""opposite of succeed"" sense or in the ""unwind the stack"" sense.

In this case, I don't think that confusion will come up. While there are still several ways to fail, they all tend to do the same thing as `fail` would- return an error value. So I kind of like `fail` here: it fits well with `try`, it fits well with the `try_` naming convention, it avoids `throw`'s potential confusion with `catch_panic`, and if `Failure` is standardized it will match that as well.

I'm not really opposed to `throw`, though it doesn't sit as well with me as `try`. It implies non-local control flow a bit more strongly to me than `try` does, as `try` is more about *containing* control flow while `throw` is more about *initiating* it.

I also have a general sense of uneasiness about introducing too many `return`/`break`/`continue`-alikes, when they all feels kind of ad-hoc. I like the extension of `break` to loops and blocks, but `throw`/`fail` doesn't quite feel as coherent, especially in such an expression-based language. You can `return` and `break` with values, but `throw`/`fail` only covers errors- there's no way to early-out of a `try` block with a success value, and I'm not sure we want *yet another* keyword to accomplish that.

But at the same time I do think `Err(x)?` is kind of obnoxious, and `return Err(x)` doesn't do error conversion. Maybe we just need to hook up `return`/`break` to the `Ok`-wrapping and error-conversion stuff somehow? Especially considering a hypothetical future `try fn` syntax where early `return`s should do `Ok`-wrapping.",True,True
rust-lang_____rfcs_____2426,2018-05-01T20:45:44Z,True,rust-lang_____rfcs_____2426_____385784742,"@burdges 

> We do need to tell people ""Rust does not have exceptions"", so using `throw` creates confusion, [..]

Surely no more so than than `try { .. }` does?

> I would not worry about one crate name, but maybe numerous traits have `fail` methods, and making it contextual sounds suboptimal.

Here's a fairly accurate check I think: https://sourcegraph.com/search?q=repogroup:crates+case:yes++\b((let|const|type|)\s%2Bfail\s%2B%3D|(fn|impl|mod|struct|enum|union|trait)\s%2Bfail)\b+max:400

The breakage doesn't seem too extensive.

---------------------------

@rpjohnst I agree with your reasoning on `fail`, it is a good candidate. I kinda like `throw` 60% and `fail` 40% but I could certainly be persuaded in favor of `fail`.

> [..], it avoids `throw`'s potential confusion with `catch_panic`, [..]

This one seems unlikely? I think at least any confusion here is quickly fixable in Rust's learning material.

> I also have a general sense of uneasiness about introducing too many `return`/`break`/`continue`-alikes, when they all feels kind of ad-hoc.

`throw` being a bit ad-hoc for initiating exceptions may be a good thing tho?
Having a built-in DSL tailored to error handling seems warranted given how fundamental that sort of logic is :)

> there's no way to early-out of a `try` block with a success value, and I'm not sure we want yet another keyword to accomplish that.

True; I agree this is a problem, but let's not let the good be the enemy of perfect?
I don't know how I feel about it, but it has been suggested that `return expr` inside `try { .. }` could be the success version of `throw expr`; This fits with the idea that `try fn` is more or less just `fn ... { try { .. } }`.",True,True
rust-lang_____rfcs_____2426,2018-05-01T20:49:34Z,True,rust-lang_____rfcs_____2426_____385785743,"@Centril

>> an unlikely route for Rust
> I'm wary of making such predictions

Why not `catch`? Because errors are values and we already have `match`, which does a marvellous job.

Why not `throw`? Because what you may *throw* you *catch*. If however, `throw` as a keyword is accepted by the Rust core team then I recommend that `catch` is reserved too. They go together.

I'd prefer `fail` though. Like `throw`-`catch` go together, `try`-`fail` go together, imo, and I think its meaning obvious at a glance. ",True,True
rust-lang_____rfcs_____2426,2018-05-01T21:34:07Z,True,rust-lang_____rfcs_____2426_____385797665,"@repax 

> Why not catch? Because errors are values and we already have `match`, which does a marvellous job.

Sure; but `catch` could be even more great; `match` has two problems in this context:
1. it requires you to either:
   1. create a temporary binding and then match: `let foo = try { .. }; match foo { .. }`
   2. write `match try { .. } { .. }` which requires holding more in working memory than
      `try { .. } match { .. }`. Speaking of which, this expression form might be a good idea for more natural reading flow?
2. It requires you to destructure `Ok(x) => EXPR` and `Err(x) => EXPR` while `catch` can let you destructure `x` inside `Err(x)` immediately. Of course, matching on the constructors of `Result<T, E>` also informs type inference for `try { .. }` so there's an upside too.

> Why not `throw`? Because what you may *throw* you *catch*. If however, `throw` as a keyword is accepted by the Rust core team then I recommend that `catch` is reserved too. They go together.

You don't need to reserve `catch` to get `try { .. } catch { .. }` working :)
All that is needed is to check for `try { .. } $ident { .. }` throw a parsing error, and then introduce `try { .. } catch { .. }` later.

Regarding *""what you may throw, you may catch""*, while I think that makes sense in English, would `throw` without `catch` handles be confusing to a Java programmer introduced to Rust? I have doubts that this is true.

> `try`-`fail` go together, imo, and I think its meaning obvious at a glance.

This seems true to me, I can't argue with it. :)",True,True
rust-lang_____rfcs_____2426,2018-05-01T22:28:17Z,True,rust-lang_____rfcs_____2426_____185351200,"I've got at least 4 results from https://sourcegraph.com/search?q=repogroup:crates+%5Cbfn%5Cs%2Bthrow%5Cb. 

All of them are JS bindings (e.g. [servo/servo](https://github.com/servo/servo/blob/245dcc2118c88f7b51d65c124a85d74dd356a77a/components/script/dom/bindings/interface.rs#L91) and [neon-bindings/neon](https://github.com/neon-bindings/neon/blob/d96c418ba86ff72c1760e472e15fe8438061b5ec/src/js/error.rs#L14)), but I guess it is because of sourcegraph's selection of repositories.



",True,True
rust-lang_____rfcs_____2426,2018-05-01T22:40:50Z,True,rust-lang_____rfcs_____2426_____185353295,"Strange. I tried the following query before: https://sourcegraph.com/search?q=repogroup:crates+case:yes++\b((let|const|type|)\s%2Bthrow\s%2B%3D|(fn|impl|mod|struct|enum|union|trait)\s%2Bthrow)\b+max:400 and it timed out, but now it shows the results you reference.

Anyways, the breakage slightly is less extensive than for `raise` and `fail`; but all keywords in this space break minimally.

I'll update the RFC with this new info :)",True,True
rack_____rack_____1272,2018-05-01T23:05:24Z,True,rack_____rack_____1272_____385816162,"> However, this proposal seems pretty balanced. It doesn't enforce a huge change on existing servers and the ""missing"" pieces are easily complemented by existing solutions (Redis being just one of them).

How do servers support your proposal? By pulling in `websocket-driver`? It's a large surface area, and it does get pretty tricky. I wouldn't call it balanced - it's heavily biased towards implementing WebSockets.

> I'm not sure I understand this part.
> The server can be a single threaded server, a thread-per connection server, a fiber based server and practically any type of concurrency model can be implemented.
> I'm not sure I see where the PR requires a specific concurrency model.

Invoking a Rack app is for the most part trivial. It's a function call that returns a result. No real model for concurrency is needed for this basic definition. You scale up by executing the function on different CPU cores, but fundamentally you can't change it to a non-linear event driven callback model or some other asynchronous model (`async` provides transparent inversion of control back to the reactor, but it doesn't change or require changes in flow control).

This proposal embeds non-linear flow control into the Rack spec. What I mean is, it's impossible to implement the given proposal without some kind concurrency. I'm not saying that any particular model for concurrency is being encoded, but just that by your approach a model for currency is now necessary.

This has a huge down-stream effect, since all code that depends on Rack now has to be aware of and capable of asynchronous execution. For example, how would you change `rack-test` to support this PR?

I think this equally applies to `rack.hijack`, and I also don't like that approach, but it's pretty much set in stone now. For example, how do you implement `rack.hijack` with HTTP/2? It's probably not possible in the general sense.

> What happens if I call sleep(10) while handling an HTTP request (except getting fired, that is)?

In `async` provided you call `task.sleep(10)` the fiber defers for 10 seconds. It doesn't block the server. In `puma` it would block the worker thread.

Have you tried using ActiveRecord in your `on_message` callback? How did that scale for you? My experience is that the ActiveRecord `ConnectionPool` design is very poor for highly concurrent workloads. These are very tricky issues to get right (although you can do it as shown here: https://github.com/socketry/async-postgres and it does scale up pretty well).

> [regarding node] I agree with it, but I don't see why that matters.
> Even the node model needs to be adjusted when scaling horizontally.

Because with your proposed API, implementing a basic Node style server like this is not possible. Right from the get go you need additional machinery to do pub/sub or other kinds of communication. Even the situation with streaming responses is not improved without additional work. It's a very specific proposal designed for a very specific kind of scalability. It's far too specific IMHO.

What we need is a proposal that better aligns with HTTP/2 streams since it's clear to me that it should be the future of HTTP and Rack. It should have a clear model for concurrency that fits with the existing multiprocess/multithread/worker implementations - i.e. reading from `rack.input` might block the request and writing to the response body might block the request due to buffering. On top of that, as already demonstrated, you can implement highly scalable asynchronous servers.

Streaming request and response bodies in `falcon` directly improve the latency of existing apps with no changes. Here is an implementation of `rack.input` which streams (and buffers) the input: https://github.com/socketry/falcon/blob/master/lib/falcon/adapters/input.rb

But this PR requires significant changes to existing apps for any kind of benefit. Not only that, but it only supports a very specific kind of scalability with an under-specified concurrency model (i.e. what happens if you block in `on_message`).

Let me finish with the following question: Do even think there is a future for WebSockets? https://datatracker.ietf.org/doc/draft-hirano-httpbis-websocket-over-http2/ hasn't been touched since 2014. There is an interesting write up here: https://daniel.haxx.se/blog/2016/06/15/no-WebSockets-over-http2/ - WebSockets are something which has never been a good fit for the request/response paradigm and that's something which fundamentally underpins Rack.",True,True
rack_____rack_____1272,2018-05-01T23:33:12Z,True,rack_____rack_____1272_____185361287,"This will break method caches.  I'd prefer a solution that doesn't lean on runtime method extension.  Maybe something like this:

```ruby
class MyWSEObject
  def initialize io
    @io = io
  end

  def on_open
    @io.write(""neat"")
  end
end

app = lambda do |env|
  env['rack.upgrade'] = MyWSEObject.new(env['rack.wse.object'])
end
```",True,True
rack_____rack_____1272,2018-05-01T23:38:09Z,True,rack_____rack_____1272_____185361951,"```
class MyWSEObject
  def on_open(io)
    io.write(""neat"")
  end
end

app = lambda do |env|
  env['rack.upgrade'] = MyWSEObject.new
end
```

would be simpler",True,True
rack_____rack_____1272,2018-05-01T23:45:03Z,True,rack_____rack_____1272_____185362944,That would be fine too. 😄 ,True,True
rack_____rack_____1272,2018-05-01T23:49:05Z,True,rack_____rack_____1272_____185363522,"So, the next question, is it a good idea to write into the request `env` to essentially send a response? To me, that's confusing. Perhaps at best it could be something like

```ruby
if upgrade = env['rack.upgrade']
  return upgrade.call(MyWSEObject.new)
end

return [400, {}, []]
```
",True,True
rust-lang_____rfcs_____2426,2018-05-01T23:55:03Z,True,rust-lang_____rfcs_____2426_____385824283,I've now added some of the recent discussion to the RFC's text.,True,True
rack_____rack_____1272,2018-05-02T00:01:11Z,True,rack_____rack_____1272_____385825312,"Hi all! Websockets and rack again, let's do this!

Up front, last time this came up, I prototyped it in puma (https://github.com/puma/puma/pull/1054). It was an experiment we didn't merge in, but it totally works and we might revisit it.

The API of on_* methods for events is totally fine, no issue there.

Extending the object to decorate it with a write method is pretty ugly, from both an implementation statement as well as a performance one. Passing an object that implements #write to the on_* methods to write back is less code and performs better.

If frameworks want to take that object and use extend to make it's methods available on the handler, that's totally fine and up to the framework. Rack should not do that on it's own, it should provide a lower requirement.",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:02:58Z,True,rust-lang_____rfcs_____2426_____185365457,"Or, go the other way around- let people `break` out of `try` blocks. On its own, this is probably a bad idea, as `try` blocks are not loops, but it's possible `'label: try { .. break 'label value; .. }` would be sufficient. For that matter, maybe *any* `return` *or* `break` that leaves the `try` block should be `Ok`-wrapped? For example:

```rust
fn f() -> Result<T, U> {
    try {
        let t: T = get_a_t()?;
        return t;
    }
}
```

Maybe that's even worse.",True,True
rack_____rack_____1272,2018-05-02T00:05:03Z,True,rack_____rack_____1272_____385826050,"You should be able to opt to the ""type"" of upgrade you are after

I can already see 2 use cases that this protocol does not help at all and will be stuff on hijack. 

1. https://github.com/discourse/discourse/blob/master/lib/hijack.rb 

With the current example use of:

https://github.com/discourse/discourse/blob/master/app/controllers/user_avatars_controller.rb#L71-L78

2. Messagebus also controls transport via: https://github.com/SamSaffron/message_bus/blob/master/lib/message_bus/client.rb and there is no clean protocol here for a ""chunked encoding"" http req short of SSE (which happens to fit sort of except for demanding `""text/event-stream""` as the content type

I would recommend

```
class Raw
  def type
      :raw  # or :sse or :socket
   end

  def on_open(io)
      # custom header support
      io.write_headers({  }) 
     
      # transparent chunked encoding support
      io.write_chunk(""a chunk"") 
  end
end

 env['rack.raw'] = Raw.new 
```

I am not super happy about `rack.upgrade` as a name cause it very tied to web sockets kind of terminology",True,True
rack_____rack_____1272,2018-05-02T00:08:28Z,True,rack_____rack_____1272_____185366203,"TBH it doesn't really matter to me.  Unfortunately though, `env` is really the only way that middleware can communicate.  So writing to `env` is the only way that one middleware could indicate to the next ""I'm responding by writing to a websocket"".  If the intention is that any ""callable"" (middleware / app) that sets the WSE object must not call anything else in the middleware chain, then that needs to be explicitly stated in SPEC.",True,True
rack_____rack_____1272,2018-05-02T00:10:43Z,True,rack_____rack_____1272_____385826927,"Rather than `env['rack.raw'] = Raw.new`, why not just `return [200, {}, Raw.new]` and have servers do different things depending on `#type`.",True,True
rack_____rack_____1272,2018-05-02T00:11:11Z,True,rack_____rack_____1272_____385827000,"Another thing that makes me somewhat uneasy here is that it still suffers from the very ugly trait that deep down the middleware stack someone returns rubbish to all the rest of the pieces that then gets thrown in bin.

So... to mitigate this very bad problem I would recommend:

```
  # only gets called AFTER everything walked down the middleware stack. 
  def on_open(io, env, response)
      status, headers, result = response

      # custom header support
      io.write_headers({  }) 
     
      # transparent chunked encoding support
      io.write_chunk(""a chunk"") 
  end
```

Overall I am leaning toward not even mucking with rack long term for a lot of this stuff and moving to fiber servers that can pause and resume more cleanly, multiplexing tons of connections cleanly. A big blocker there though is the MRI does not let you ship fibers between threads now which is not idea. 

That said this works ... so ... yay ?https://github.com/SamSaffron/performance/blob/master/fiber_server/server.ru

",True,True
rack_____rack_____1272,2018-05-02T00:11:36Z,True,rack_____rack_____1272_____185366805,"I understand the need to maintain the method caches, especially as we move towards JIT compilation.

As far as iodine is concerned, I am totally flexible on all points as long as the negative impact on performance isn't too high.

On the other hand, please consider a number of good reasons to prefer the `extend` approach over the `on_open(io)`:

1. It's likely that the method caches will break only the first time a callback object is returned.

   Assuming the same object class is used for all callback objects, the `extend` operations becomes a no-op, keeping the method caches intact (since the class was already extended).

2. Using an `io` object adds an obvious requirement for the `io` object to be stored somewhere by the receiver (otherwise, `write` could never get called).

   This makes the `on_open(io)` method a requirement rather than optional and it adds a required use-pattern (`def on_open(io); @io=io; end`).

   IMHO, although not always the case, this is a strong indication of a design flaw (requiring the user to complete the design).

3. For C extensions, there's double the amount of objects per connection. For Ruby implementations it's an increase of 150% in object count (I implemented in C, so my Ruby estimates are theoretical assuming 3 objects: raw IO, wrapper IO and callback objects).

   This puts an extra burden on the memory management system and hastens the (inevitable?) memory fragmentation issue that many Ruby servers suffer from.

4. As a side note, this might make future extensions harder, since future gem authors wouldn't be sure how to access the `io` object from within a connection.

I noticed that @evanphx 's experience is the opposite of mine.

While I found reduced performance and higher complexity when using an `io` object, @evanphx reports improved performance when using this approach.
",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:11:48Z,True,rust-lang_____rfcs_____2426_____185366849,"My main concern wrt. re-purposing `break` is this:

```rust
try {
    // ..
    loop {
        // Are we breaking the loop or the try?
        // Perhaps it is obvious to say ""the loop"", but is it really?
        break 3;
    }
    // ..
}
```

> Maybe that's even worse.

Probably, yeah.",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:13:18Z,True,rust-lang_____rfcs_____2426_____185367044,"Regarding break with label:
```rust
'label: try {
    ..
    break 'label value;
    ..
}
```

That seems workable, but it is not particularly ergonomic.",True,True
rack_____rack_____1272,2018-05-02T00:15:31Z,True,rack_____rack_____1272_____385827745,"Also... one extra big question here is ... do we want to bloat all of our Rack servers out there with all this extra logic when simply adding a single dependency to middlware that implements this today is already feasible on top of hijack? 

should we not start with `gem install magic_generic_web_socket_support_middleware` prior to pushing on implementers to all implement the same thing? ",True,True
rack_____rack_____1272,2018-05-02T00:16:39Z,True,rack_____rack_____1272_____185367473,"As for the `.call`, I find it confusing.

Let's assume I want to upgrade to SSE (or WebSockets) as well as set a cookie.

When using `call` (besides the extra Proc object), it's unclear to me when the `call` is actually performed. Is the upgrade immediate? Are the headers in the final response are sent?

Passing an object is both cheaper (no Proc object) and, I feel, simpler.

As for `[200, {}, MyObject]`, I think this breaks existing servers, so I'm pretty sure it wouldn't work as smoothly.",True,True
rack_____rack_____1272,2018-05-02T00:16:48Z,True,rack_____rack_____1272_____385827949,"> A big blocker there though is the MRI does not let you ship fibers between threads now which is not ideal.

Fibers are actually bound to the thread that creates them by definition.

Some designs use a more generic coroutine structure (e.g. green threads) which you can move between threads. If you are interested in this, you might find https://bugs.ruby-lang.org/issues/13618 interesting.

If you are interested in Fiber based servers, check out falcon. https://github.com/socketry/falcon/blob/master/examples/beer/config.ru and https://github.com/socketry/ which is a complete stack of asynchronous components.

> Also... one extra big question here is ... do we want to bloat all of our Rack servers out there with all this extra logic when simply adding a single dependency to middlware that implements this today is already feasible on top of hijack?

Yes, I strongly agree with this, and the answer IMHO is no.",True,True
rack_____rack_____1272,2018-05-02T00:17:48Z,True,rack_____rack_____1272_____185367625,"> As for [200, {}, MyObject], I think this breaks existing servers, so I'm pretty sure it wouldn't work as smoothly.

As long as MyObject responds to `#each` as a fallback, it won't break existing servers.",True,True
rack_____rack_____1272,2018-05-02T00:18:12Z,True,rack_____rack_____1272_____185367678,"> Using an io object adds an obvious requirement for the io object to be stored somewhere by the receiver (otherwise, write could never get called).

No.  You pass an `io` object to every callback.  Then the WS handler doesn't need to store anything.

> For C extensions, there's double the amount of objects per connection.

Why is this?",True,True
rack_____rack_____1272,2018-05-02T00:18:43Z,True,rack_____rack_____1272_____185367739,"@tenderlove we debated which approach was better. I'd be okay with either honestly but as @ioquatix suggested, an argument to `#on_open` would be better to make sure the connection had been established. Anyway we thought extending the handler object eliminated the need for the developer to have to keep track one one less object.",True,True
rack_____rack_____1272,2018-05-02T00:19:49Z,True,rack_____rack_____1272_____185367863,"Blowing away method cache is a major performance issue, please don't underestimate it.",True,True
rack_____rack_____1272,2018-05-02T00:21:34Z,True,rack_____rack_____1272_____185368111,@ioquatix having the `env['rack.upgrade']` respond to some kind of registration method would be a reasonable approach in my opinion. I feel a little uncomfortable having it provide a return value since it makes it less obvious what is being returned but my feelings are not very strong on that. ,True,True
rack_____rack_____1272,2018-05-02T00:21:44Z,True,rack_____rack_____1272_____185368125,"@ohler55 ya, I think passing the IO object to every callback (as @ioquatix suggested) is my preferred approach.",True,True
rack_____rack_____1272,2018-05-02T00:24:14Z,True,rack_____rack_____1272_____385829111,@evanphx I appreciate you opinions and it is good to have a different perspective than what we had. I can't agree that the performance would be any different in one case over the other though. The other points are certainly worth considering.,True,True
rack_____rack_____1272,2018-05-02T00:25:34Z,True,rack_____rack_____1272_____385829346,"yes, I am across Eric's work there and hope we get something in MRI, I also think Koichi is open to having a protocol for allowing to move Fibers between threads, and I want to see proper green threads back. 

Also seen Falcon, I agree that a fiber based server is very very appealing for a bunch of workloads it simplifies so much of the mess we have now with pure threaded servers and slow requests, especially cause you can walk down the middleware stack properly in the right time. ",True,True
rack_____rack_____1272,2018-05-02T00:26:12Z,True,rack_____rack_____1272_____385829465,"> should we not start with gem install magic_generic_web_socket_support_middleware prior to pushing on implementers to all implement the same thing?

TBH I'm OK with it if it's an opt-in.  This proposal seems simple enough that someone could implement a ""hijack"" based approach using a middleware.  The upside of formalizing it is that if webservers want to implement a high performance version of `magic_generic_web_socket_support_middleware` can.  I think of it as similar to `X-Sendfile`: yes we have a middleware that can do it, but webservers can implement an accelerated version since we have the standard.",True,True
rack_____rack_____1272,2018-05-02T00:27:05Z,True,rack_____rack_____1272_____185368813,"> > For C extensions, there's double the amount of objects per connection.

> Why is this?

@tenderlove , I assume you know that the C server doesn't need an IO object, it uses a simple integer to keep track of IO.

This means that a C extension just needs to keep the callback object itself and add a secret variable to that object with the socket number.

This secret variable isn't possible in Ruby, but C extensions are allowed to create them. Since that variable is a Number, it's very small (it doesn't create an Object in the ObjectSpace realm and it's immutable).

This means a single object in C (the callback object). If we add the IO object, it's two objects - a 200% increase in object count.

In Ruby, we will have the callback handler, the raw IO object (both pre-existing) and an IO wrapper, a 150% increase in object count.",True,True
rack_____rack_____1272,2018-05-02T00:30:35Z,True,rack_____rack_____1272_____385830066,"@SamSaffron in regard to on_open taking an io, env, and repsonse. By the time `on_open` is called the connection has already been established. Since it is either WebSocket or SSE a response and env are no longer relevant. The intent was to allow middleware to decide if a connection shoulc be established based on the return status in the `#call(env)` method that asked for the upgrade.",True,True
rack_____rack_____1272,2018-05-02T00:32:50Z,True,rack_____rack_____1272_____385830427,"My issue though is that encourages a whole bunch of code duplication... say Puma takes this on now it needs to ship with a websocket protocol as a strong dependency, or worst still it will carry its own duplicate websocket protocol thingy. Chunked encoding is easy enough but there is a fair amount of code to do websocket upgrade and encoding depending on how far you want to take it and how many protocol variants you want to support. 

",True,True
rack_____rack_____1272,2018-05-02T00:34:45Z,True,rack_____rack_____1272_____385830745,"I only think `on_open` should take an IO. It should be the responsibility of the instance to store the IO IMHO. This way you can call `@io.write` at any time, e.g. from a timer.",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:35:37Z,True,rust-lang_____rfcs_____2426_____185369911,"While I'm a fan of _having_ label-break-value, I see it mostly as a way for macros to provide customized flow control constructs.  I'd rather it typically be internal to libraries more than something that shows up in syntax that would be used broadly.",True,True
rack_____rack_____1272,2018-05-02T00:36:16Z,True,rack_____rack_____1272_____385830968,"> I only think on_open should take an IO. It should be the responsibility of the instance to store the IO IMHO. This way you can call @io.write at any time, e.g. from a timer.

I'd rather they all take the IO object.  You can save to an ivar if you want.",True,True
rack_____rack_____1272,2018-05-02T00:37:20Z,True,rack_____rack_____1272_____385831122,"> I'd rather they all take the IO object.

What's the reasoning behind that? Is it more efficient?",True,True
rack_____rack_____1272,2018-05-02T00:38:35Z,True,rack_____rack_____1272_____385831324,"To address @SamSaffron's ""junk data"" comment, I totally agree.  Maybe we could use headers to indicate to the webserver that the body object is ""special"" (it knows websockets):

```ruby
class WSBody
  def each
    yield ""Webserver said it does WS, but lied""
  end

  def on_open io
  end

  # ... more on_* methods
end

# App

app = lambda do |env|
  if env['rack.supports_ws?']
    [ 200, { ""X-Websocket"" => ""on"" }, WSBody.new ]
  else
    [ 404, {}, [ ""This was supposed to be a WS response"" ] ]
  end
end

# Webserver

status, headers, body = app.call(""rack.supports_ws?"" => true)
if headers[""X-Websocket""]
  # do websocket stuff with the body
  body.on_open io
else
  # do the normal `each` thing
end
```

I think it would eliminate questions about what to do WRT middleware (this type of API would insist that the thing responding to Websockets *not* forward to another middleware)",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:38:54Z,True,rust-lang_____rfcs_____2426_____185370291,"Another, possibly bad, idea to facilitate for macros could be to introduce the special label `'try` which always refers to the closest `try { .. }` block.

That way, you could just write:
```rust
try {
    ok!(value);
}
```
where `ok!(value)` expands to `break 'try Try::from_ok(value)`.",True,True
rack_____rack_____1272,2018-05-02T00:39:04Z,True,rack_____rack_____1272_____385831381,"@SamSaffron code duplication on the server implementation is really a matter left up to the server author. I don't think that is relevant to the proposed spec addition, which is proposed to be optional.

@ioquatix using an io object or the extended handler itself is pretty much the same in regard to some external writer loop. The example code on Agoo demonstrates that. Thats not to say that using an io object might be preferred fro other reasons though.",True,True
rack_____rack_____1272,2018-05-02T00:39:27Z,True,rack_____rack_____1272_____385831441,"@SamSaffron 

> My issue though is that encourages a whole bunch of code duplication

I think code duplication is one of the concerns this PR will solve.

Rright now we have tons of applications each implementing their own WebSocket protocol (there's only one standard protocol, so historical variants aren't necessary).

On top of that, all these application have their own implementation of IO handling logic (their own reactor, `nio4r` or some other approach).

Consolidating the dependency in the server actually minimizes code bloat as most of the code is already there. Sure, adding the WebSocket parser might be new code, but the network and IO handling logic is already there.",True,True
rack_____rack_____1272,2018-05-02T00:40:40Z,True,rack_____rack_____1272_____385831630,"> What's the reasoning behind that? Is it more efficient?

It means that you can implement a stateless object.  I prefer to avoid maintaining state when possible.  If the methods take the IO object as a parameter, I am allowed to implement a stateless object, but it is *my* choice.  Insisting that only `on_open` takes the IO object forces me to maintain state (I no longer have a choice).",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:40:53Z,True,rust-lang_____rfcs_____2426_____185370525,"I'm really not a fan of special labels like `'fn` or `'try`. I would much rather we just stick with `fail` or `throw`, as proposed, than *ever* introduce those.",True,True
rack_____rack_____1272,2018-05-02T00:41:52Z,True,rack_____rack_____1272_____385831801,"> Since it is either WebSocket or SSE a response and env are no longer relevant. 

I think chunked encoding responses are just as good as a candidate, they are more widely supported than SSE anyway. In fact I can see almost zero reason to support SSE cause it is pretty much a novelty protocol. https://caniuse.com/#feat=eventsource compared to https://caniuse.com/#feat=xhr2 which is supported on IE/edge. 

env is very relevant for chunked encoding you may want to add headers deep in your middleware for CORS and various things like that. ",True,True
rust-lang_____rfcs_____2426,2018-05-02T00:42:14Z,True,rust-lang_____rfcs_____2426_____185370683,@rpjohnst I'm not a fan either :),True,True
rack_____rack_____1272,2018-05-02T00:44:16Z,True,rack_____rack_____1272_____185370898,"> This means a single object in C (the callback object). If we add the IO object, it's two objects - a 200% increase in object count.

What % increase is that in an actual app?",True,True
rack_____rack_____1272,2018-05-02T00:44:59Z,True,rack_____rack_____1272_____385832184,"@tenderlove in you code example you seem to be assuming WebSocket and SSE calls are triggered by an event from the browser. Maybe I misread the code. My apologies if I did. Anyway, I think a common use case will be to push event from Ruby to the browser. Do foresee a more request response pattern initiated from the browser using WebSockets instead of using HTTP?",True,True
rack_____rack_____1272,2018-05-02T00:45:59Z,True,rack_____rack_____1272_____385832303,"> @tenderlove in you code example you seem to be assuming WebSocket and SSE calls are triggered by an event from the browser. Maybe I misread the code. My apologies if I did. Anyway, I think a common use case will be to push event from Ruby to the browser. Do foresee a more request response pattern initiated from the browser using WebSockets instead of using HTTP?

Derp, yes, sorry. It's been a long day. 😞",True,True
rack_____rack_____1272,2018-05-02T00:47:15Z,True,rack_____rack_____1272_____385832446,"@tenderlove regarding stateless objects, I think there is some merit to what you say. The principles of the API remains the same but adding the io object does allow some additional options. It certainly doesn't hurt.",True,True
rack_____rack_____1272,2018-05-02T00:47:43Z,True,rack_____rack_____1272_____385832502,"@SamSaffron 

> I think chunked encoding responses are just as good as a candidate

I'm not sure if the PR is supposed to be a `hijack` replacement.

It's definitely a step towards retiring `hijack`, but not necessarily a complete replacement.

The idea is that response that passes through the middleware is actually sent by the server.

i.e., notice the header in the response (place in `config.ru` and run with `iodine`):

```ruby
# Place in config.ru
RESPONSE = [200, { 'Content-Type' => 'text/html',
          'Content-Length' => '12' }, [ 'Hello World!' ] ]
# a Callback class
class MyCallbacks
  def initialize env
     @name = env[""PATH_INFO""][1..-1]
     @name = ""unknown"" if(@name.length == 0)
  end
  def on_open
    subscribe :chat
    publish :chat, ""#{@name} joined the chat.""
  end
  def on_message data
    publish :chat, ""#{@name}: #{data}""
  end
  def on_close
    publish :chat, ""#{@name} left the chat.""
  end
end
# The actual Rack application
APP = Proc.new do |env|
  if(env['rack.upgrade?'] == :websocket)
    env['rack.upgrade'] = MyCallbacks.new(env)
    [200, { ""X-Header"" => ""This is sent"" }, []]
  else
    RESPONSE
  end
end
# The Rack DSL used to run the application
run APP
```

Yes, I suppose long polling can be added to this list, using chunked encoding, but I this means that the headers are sent immediately, since this is part of the design's premise.
",True,True
rack_____rack_____1272,2018-05-02T00:47:52Z,True,rack_____rack_____1272_____385832518,"> Sure, adding the WebSocket parser might be new code, but the network and IO handling logic is already there.

This is my point though... What are @evanphx @FooBarWidget and Eric going to do here? They are pretty much the people who need to be convinced this is good.

- Add a hard dependency to ""standard websocket parser gem"" (I give it zero % chance this will happen for Unicorn, but don't know where Evan and Hongli stand) 

- Add ""websocket_encoder.rb"" file and ""websocket_upgrader.rb"" and ""magic_rack_protocol.rb"" they hand curate and is duplicated 3 times between the 3

- Add a soft dependency we need to add to our Gemfile to ""activate"" 

I don't see any clear cut good answer here. ",True,True
rack_____rack_____1272,2018-05-02T00:53:22Z,True,rack_____rack_____1272_____385833274,"This `env['rack.upgrade?'] == :websocket` is a big concern for me protocol wise, if `/some/route` is meant to be SSE, and `/some/ws` is meant to be web sockets, how is the server going to decide this upfront. Not allowing the router any say here is a problem imo. 

`if env['rack.can_upgrade?`]` seems far more flexible.  ",True,True
rack_____rack_____1272,2018-05-02T00:54:23Z,True,rack_____rack_____1272_____385833417,@SamSaffron I'm surprised we are considering rejecting the PR because it might be hard for some of the current server gems to implement. I would have thought Rack was intended to make life easier for developers/users and not for the server implementers.,True,True
rack_____rack_____1272,2018-05-02T00:55:56Z,True,rack_____rack_____1272_____385833652,"> if /some/route is meant to be SSE, and /some/ws is meant to be web sockets, how is the server going to decide this upfront. 

The server doesn't.

The server lets the application know what the user asked for (if the user asks for WebSockets or SSE).

The application is free to refuse the connection if the route doesn't match.

The application is also free to implement both solutions on the same route.
",True,True
rack_____rack_____1272,2018-05-02T00:57:01Z,True,rack_____rack_____1272_____385833803,@SamSaffron `env[`rack.upgrade`] can be tested for `nil` or for s specific value. Hiding the fact that the upgrade is either WebSocket or SSE is limiting. Providing more information only help make the decision easier for more specialized applications.,True,True
rack_____rack_____1272,2018-05-02T01:00:25Z,True,rack_____rack_____1272_____385834361,"@tenderlove , @SamSaffron 

I'm not sure I understand what you mean by ""junk data"".

As I understand the PR, the `env` object performs the roundtrip through the middleware and afterwards the server tests for the callback object. At what point is there a risk for junk data?",True,True
rack_____rack_____1272,2018-05-02T01:04:33Z,True,rack_____rack_____1272_____385834948,"My personal goal here would be adoption, and if we are introducing a protocol here that can not easily be adopted (or will be rejected by the big 3) then chances of faye,message_bus and family all moving to it are very low. 

Also it places unfair pressure. ""Look passenger did it why don't you?""

That said, since this can be implemented today in middleware it is not the end of the world if the big 3 reject it. 

> The server lets the application know what the user asked for (if the user asks for WebSockets or SSE).

I follow so you are looking at `Upgrade: websocket` header, then the server knows it can implement it so it sets `['rack.upgrade?']` to websocket. But ... SSE ship `Accept: text/event-stream` and chunked encoding ships nothing. and in all cases they could potentially use this protocol. The terminology is very websocket centric. ",True,True
rack_____rack_____1272,2018-05-02T01:04:58Z,True,rack_____rack_____1272_____385835007,"I don't know if this comment is helpful to the discussion at large, so pardon me if this feels as an intervention. There are legitimate cases where hijack is used because it offers access to the socket. For example, we use it to call `sendfile` multiple times in sequence to server very large binary responses, and it works well.

The ""downgrade"" in convenience that `hijack` brings is well compensated by the interesting things you can do to it. Imagine with this proposal one of the use cases would be _not_ using SSE (and not using WebSockets) but instead stuffing large binary responses into the socket from the filesystem (as we do in https://github.com/WeTransfer/fast_send). Would such an ""upgrade wrapper"" facility help that use case in any capacity? For example, would it give me a way to ""yield back control"" from a sending loop - which I ideally would have synchronous or in a Fiber - back to the webserver?

In practical terms, using Hijack was a bit tricky in the first place because it was not clear _which exact subset_ of an `IO` the given socket-ish object supports, and I feel this might be the case for this proposal too. Personally I would love to see that IO specified somewhat tighter (""here are the methods that _must_ be available, here are the methods that _may_ be available if the server decides to""). I don't know if having something so tightly scoped to be a WebSockets support library is the answer to ""hijack API is obtuse"" TBH.",True,True
rack_____rack_____1272,2018-05-02T01:10:10Z,True,rack_____rack_____1272_____385835632,"> In practical terms, using Hijack was a bit tricky in the first place because it was not clear which exact subset of an IO the given socket-ish object supports, and I feel this might be the case for this proposal too. 

Yes absolutely, we don't even know which type of exception this object can raise and the list goes on. I would love to see this thing properly documented. 

Also another missing practical item is that you have no way of setting a callback to happen after the server finished dealing with the hijack which is a huge hole. eg: `env['hijacked] = lambda{|r| ...}` 

> I don't know if having something so tightly scoped to be a WebSockets support library is the answer to ""hijack API is obtuse"" TBH.

I agree with this. I would like to see hijack better specified. ",True,True
rack_____rack_____1272,2018-05-02T01:10:28Z,True,rack_____rack_____1272_____185373615,"> What % increase is that in an actual app?

That really depends on the app's use-case.

A micro services app running a WebSocket API will get hit harder than an HTTP app with the occasional WebSocket upload manager.

I think the issue is more pronounced because we are talking about long term objects.

Short term object count doesn't effect memory fragmentation as much as the fact that there's a long-term object blocking a memory ""block"" / ""arena"".

The more long-term objects are created (and eventually destroyed), the faster the fragmentation.

Having said that, even a 200% increase in object count is probably better than the solutions we currently employ when implementing WebSockets using `hijack`.

I won't make an issue out of it. I'll do what everyone thinks best, but I know in very practical terms (having coded both implementations in C) that `extend` is cheaper both in memory and in the number of method tree traversals required.",True,True
rack_____rack_____1272,2018-05-02T01:15:07Z,True,rack_____rack_____1272_____385836295,"@SamSaffron regarding `env['rack.upgrade?']`, the server has already looked at the headers and determined the requested upgrade. There is no need for the application to look at the headers to determine the upgrade type. It was provided as a convenience so the application did not need to look at the various headers that were used to determine the upgrade requested. It also leaves the API open for future additions if some new event based connection protocol is supported.",True,True
rack_____rack_____1272,2018-05-02T01:20:40Z,True,rack_____rack_____1272_____385837083,"@julik @SamSaffron I think there is huge value in cleaning up / specifying the hijack API.  If either of you want to take a stab at it I would really appreciate it.  (Also, if we're going to rev the spec I think it's time we remove the ""rewindable body"" requirement)",True,True
rack_____rack_____1272,2018-05-02T01:25:58Z,True,rack_____rack_____1272_____385837888,"@SamSaffron 

> I follow so you are looking at Upgrade: websocket header, then the server knows it can implement it so it sets ['rack.upgrade?'] to websocket. But ... SSE ship Accept: text/event-stream and chunked encoding ships nothing. and in all cases they could potentially use this protocol. The terminology is very websocket centric.

Yes, the idea is that the `env['rack.upgrade?']` value is set according to the headers client send (i.e., `Accept: text/event-stream` or `Upgrade: websocket`, for now).

If there was a way to detect XHR, it would probably be easy enough to manage... but there isn't. This might remain in the `hijack` realm for now.

As @ohler55 [mentioned](https://github.com/rack/rack/pull/1272#issuecomment-385836295), this allows the application to ignore the HTTP headers and distance itself from the HTTP protocol.

As a side-note:

I loved XHR when I didn't have WebSockets. I hardly ever use SSE or XHR for push notifications (I do use XHR for REST calls). However, I can see HTTP/2 bringing a strong movement towards SSE, so it might be in my future.
",True,True
rack_____rack_____1272,2018-05-02T01:39:51Z,True,rack_____rack_____1272_____385840091,"@tenderlove , @ohler55 , I feel that the static object support is a very strong argument in favor of an `io` object (although I find the name `io` misleading, maybe `client` more befitting).

I feel emotional resistance against this added complexity, but I can understand the logical benefits.

However, retaining a copy of the `env` object is a major memory concern as a lot of data has to be kept ""alive"" and moves into long-term memory storage... even though this might shrink the number of cases where static objects could be used.

This will make `on_message(client, data)`, `on_close(client)`, etc' less enticing, but it will work.",True,True
rust-lang_____rfcs_____2426,2018-05-02T01:51:00Z,True,rust-lang_____rfcs_____2426_____385841683,"Stemming from https://github.com/rust-lang/rfcs/pull/2426#pullrequestreview-116739016... Would this be (eventually) allowed?

```swift
let result = 'a: try {
    try {
        throw 'a e;
    }
};
```

",True,True
rust-lang_____rfcs_____2426,2018-05-02T01:55:01Z,True,rust-lang_____rfcs_____2426_____385842219,"@kennytm 

> Stemming from #2426 (review)... Would this be (eventually) allowed?

I suppose it could. It is consistent with `break 'a e`; I don't have any arguments against it other than:
- *""how often do you want / need to do this?""*

Another possibility is discussed here: https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md#paper-exceptional-syntax",True,True
rack_____rack_____1272,2018-05-02T02:00:04Z,True,rack_____rack_____1272_____385842908,@boazsegev I know we discussed having an `io` object or what ever the label is. I don't have a strong opinion able the label. I don't see the need for passing around the `env` object though. I'm in agreement with you. The data in the `env` is stale by the time it is used in any of the callbacks. It is only relevant on the initial invocation of the `#call(env)` method.,True,True
rack_____rack_____1272,2018-05-02T03:00:22Z,True,rack_____rack_____1272_____385851416,"@ohler55 , yes, you were the one who suggested the `io` object during our discussion and I was the one with the strong feelings against the idea.

It's an implementation perspective. The extra object is somewhat of a headache and increases performance costs...

...but I'd rather have something everyone agrees to implement than have nothing.

Besides, if we all write amazing servers, I'll retire iodine in favor of whichever server is the best, so the extra implementation and maintenance cost is avoidable as far as I'm concerned ;-)",True,True
rust-lang_____rfcs_____2426,2018-05-02T04:33:41Z,True,rust-lang_____rfcs_____2426_____385862128,"I'm not objecting to the idea of having an expression that serves this function (though personally I think `return Err(e)` seems quite clear), but the more I think about it and the more discussions I've seen about error handling in Rust, the less inclined I find myself to choose keywords and constructs evocative of *exceptions*.",True,True
rack_____rack_____1272,2018-05-02T11:23:06Z,True,rack_____rack_____1272_____385945342,"Let me make an attempt to summarize. There are some who are completely against changing the Rack spec and feel hijacking is the best way forward if WebSocket and SSE is to be used with Rack. For those that haven't rejected the PR outright the following apply.

1. The consensus is that an `io` or `client` object be used instead of extending the handler.
2. There may still be open issues around how to indicate an upgrade is pending and how to pass the handler to the server.

I'll update the proposed changes to reflect not extending the handler today.",True,True
rack_____rack_____1272,2018-05-02T13:32:14Z,True,rack_____rack_____1272_____185496098,"I think it's only fair that the API informs the receiver about the identity of the closed client (i.e., for `collection.delete client` type of situations)?

so `on_close(client)` as well.",True,True
rack_____rack_____1272,2018-05-02T13:34:31Z,True,rack_____rack_____1272_____185496755,"Oh, sorry, I misunderstood... I think this update assumes the client object is stored by the receiver.",True,True
rack_____rack_____1272,2018-05-02T13:54:03Z,True,rack_____rack_____1272_____185503288,The call to `on_close` indicates the connection has been closed so the client is no longer viable or at least any method called on it would raise an exception as not being connected so it doesn't seem useful to include it as an argument to the close callback.,True,True
rack_____rack_____1272,2018-05-02T14:02:25Z,True,rack_____rack_____1272_____185506253,Did miss adding the client to the `on_message`. Fixed that.,True,True
rack_____rack_____1272,2018-05-02T14:14:24Z,True,rack_____rack_____1272_____185510298,"On second though. I hadn't fully bend my mind around what the change would mean. With a stateless approach as @tenderlove suggested a single upgrade handler could be used. It might then want to store an array of clients thereby avoiding creating a two new objects for every connection. Maybe thats what you were thinking of before my hasty response.

I'll update the spec with all calls taking the client.",True,True
rust-lang_____rfcs_____2426,2018-05-02T15:12:19Z,True,rust-lang_____rfcs_____2426_____185532364,I think special labels like `'try` and `'fn` going with `try` and `fn` fits well with `'static` and `static`.,True,True
rust-lang_____rfcs_____2426,2018-05-02T16:45:33Z,True,rust-lang_____rfcs_____2426_____386043697,"@joshtriplett How come? And are you saying that we should choose `fail` instead?

I do think that RFC https://github.com/rust-lang/rfcs/pull/243 using exceptional terminology should be seen as precedent and therefore the case against *exceptional terminology* is less convincing.

However; my view is that either `throw` or `fail` would better than neither `throw` or `fail` (to not have the feature at all), and so if the lang team finds `fail` better, I'll happily switch to that.

@petrochenkov, @wesleywiser, @Flaise, @kjeremy, @gilescope @phaylon @alexander-irbis @0x7CFE:
Could you please note your specific concerns so that I can address them?",True,True
rust-lang_____rfcs_____2426,2018-05-02T16:51:28Z,True,rust-lang_____rfcs_____2426_____185564950,"@squishy-clouds That's a good point. Tho, `'static` is always usable, but `'try` and `'throw` would not. I don't know if that is a major drawback or even a drawback at all.",True,True
rust-lang_____rfcs_____2426,2018-05-02T16:58:18Z,True,rust-lang_____rfcs_____2426_____386047571,"I agree with the concerns already stated, and my concerns from the `try` discussion carry over to here.

I'd summarize it as: I'm generally against using exception syntax in a non-exception language, because, mainly:

* The semantics of Rust error handling and exception based error handling are at odds, and so are intuitions based on them.
* It special cases errors more than I'd like, since I believe errors should always clearly be normal values.
* Every new control flow construct increases the language surface in a critical place. I don't believe the advantages here (not writing `Err`) are worth the complexity increase.
* With the auto-conversion included, it's another place where type conversion happens without being explicitly requested.

These are largely philosophical/foundational, so I'm not sure there is much to address. I believe I will remain firmly in the -1 group.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:07:00Z,True,rust-lang_____rfcs_____2426_____386050164,"@phaylon Would you be more comfortable with `fail expr` perhaps?

> With the auto-conversion included, it's another place where type conversion happens without being explicitly requested.

It is not included in the current proposal (and doesn't have to be).

> I don't believe the advantages here (not writing `Err`) are worth the complexity increase.

Writing `return Err(expr)` is not equivalent to `throw expr` in `try { .. }` so this is not the only advantage. `Result` is also not the only type implementing `Try`. In a generic setting, you'd have to write: `return Try::from_error(expr)` which I find much less readable.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:18:28Z,True,rust-lang_____rfcs_____2426_____386053637,"I _strongly_ agree with @joshtriplett. Regardless of what usage feels/looks like, it should be very clear that the _mechanism_ being used is not some sort of unwinding like exceptions.

IMHO, if we want Rust to be taken seriously as a systems language, we should not wallpaper over what's actually happening.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:21:04Z,True,rust-lang_____rfcs_____2426_____386054392,"I think @joshtriplett's post sums up my feelings well. In addition, my other concern is that this feature doesn't pull its weight. Eric Gunnerson worked on the C# language design team for years and wrote about a concept they had called ""Minus 100 points"":

> Every feature starts out in the hole by 100 points, which means that it has to have a significant net positive effect on the overall package for it to make it into the language. Some features are okay features for a language to have, they just aren't quite good enough to make it into the language.

\- https://blogs.msdn.microsoft.com/ericgu/2004/01/12/minus-100-points/

To my understanding, this feature does not allow the user to do anything they could not otherwise do.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:50:27Z,True,rust-lang_____rfcs_____2426_____386063716,"@Centril Because Rust error handling is *not* exception handling, and drawing an analogy to exception handling is misleading. To quote an explanation I gave elsewhere:

Rust does not have thrown and caught exceptions. Making error-handling look superficially like that does not make Rust more user-friendly. It makes Rust less user-friendly. It lets people proceed based on a faulty analogy, and then eventually, inevitably, has to pull the rug out from under them. (And even worse, it might lead to further language changes in an attempt to stretch that analogy further.) Far better to make it clear to people that Rust has a fundamentally different approach to error-handling, error-handling is just a return of a `Result` type, here are the ways that’s similar to other languages, and here are the ways that’s different than other languages.

To answer your question, I'd prefer `fail` over `throw`; I'd prefer `fail!(expr)` over `fail expr` until it's clear that we *need* a keyword for this; and I'd prefer to have none until it's extremely clear that we *need* a brand new non-linear control-flow construct that people have to adapt their mental parsers for.

People know to scan for `return`. People understand `break` and `continue`. We've done a lot of work to help people understand and adapt to `?`, and `try!` before that. Any new language construct needs to be sufficiently critical to justify everyone having to be familiar with it and see it in other people's code, and that's even *more* true for a construct that affects control-flow.

If we were talking about a feature that you can't do any other way, that'd provide some additional justification. But we're talking about something that you can already implement using `return`, or using `?`, and the new keyword would just serve as a shorthand.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:50:39Z,True,rust-lang_____rfcs_____2426_____386063786,"@mark-i-m 

> Regardless of what usage feels/looks like, it should be very clear that the mechanism being used is not some sort of unwinding like exceptions.

I think we are / should be clear crystal about that in documentation, but I think there is benefit from familiarity even if the semantics are not a perfect match to those of Java / C++.

> IMHO, if we want Rust to be taken seriously as a systems language, we should not wallpaper over what's actually happening.

In what way would `throw` wallpaper over the semantics (more so that `?` would do..)?
Note that there are languages like Swift (AFAIK) and Haskell which don't use unwinding and yet they do use the `throw` terminology.

@wesleywiser

> Eric Gunnerson worked on the C# language design team for years and wrote about a concept they had called ""Minus 100 points"":

I only take that to mean that every added feature should have benefits which seems obvious to me. Some features will not benefit everyone equally (c.f. additions for the embedded domain), but we still add them.

> To my understanding, this feature does not allow the user to do anything they could not otherwise do.

I don't think that is correct. `throw expr` is not just syntactic sugar for `return Err(expr)`. It is needed to let macros like `bail!` perform early returns both to the innermost `try { .. }` block or the enclosing function or closure if there is no `try { .. }` block.

Not having `throw expr` would mean that there's no way save for `Err::<!, _>(x)?`  (which I find obnoxious) to perform an early return to the enclosing `try { .. }` block. However, `?` performs error conversion for `Result` which `throw` (currently) does not. I don't know how you can extend `Err::<!, _>(x)?` to the generic case.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:51:30Z,True,rust-lang_____rfcs_____2426_____386064040,"> Could you please note your specific concerns so that I can address them?

Sure. The first is that when I see `try`/`throw`, I'm expecting exceptions. The `Result<A, B>` objects are just return values; they're nothing like exceptions. One of the reasons why I use Rust is because it doesn't isolate me from what the machine is doing. If something's a return value, Rust treats it like a return value. If something's a stack allocation, Rust treats it differently than a heap allocation, etc. See also @joshtriplett's comment.

The other issue is that I don't like seeing special cases without quite a lot to be gained from them because usually special cases just end up creating more problems later. I'll pick an example from another language because Rust usually gets things right. Someone once had to write this abomination in Javascript:

              length >= 7 ? new NativeDate(Y, M, D, h, m, s, ms) :
              length >= 6 ? new NativeDate(Y, M, D, h, m, s) :
              length >= 5 ? new NativeDate(Y, M, D, h, m) :
              length >= 4 ? new NativeDate(Y, M, D, h) :
              length >= 3 ? new NativeDate(Y, M, D) :
              length >= 2 ? new NativeDate(Y, M) :
              length >= 1 ? new NativeDate(Y) :
                            new NativeDate();

Source: https://github.com/vesln/timekeeper/blob/5e1f504f8e33f43d4e1ba9ac78faab2db4bb6582/lib/timekeeper.js#L80-L87

Why did he have to write that? Because the `new` operator is not composable with other language constructs. The only way to do what he needed to do was to wrap the usages of the operator in a construct that is composable. That special case that was supposed to make it easier to code in Javascript (some coders will tell you that it denotes which functions allocate memory, which is ridiculous because every function can allocate memory or call other functions that allocate memory) instead made some things a lot more work.

And someone said that having a special keyword for error handling in Rust will aid IDE development - I don't buy this because the whole point of Rust's syntax is to be machine-readable. If you want that feature, just render a return value in a different color if it's of type Result::Err.",True,True
rust-lang_____rfcs_____2426,2018-05-02T17:51:31Z,True,rust-lang_____rfcs_____2426_____386064041,"I agree with point of view that `throw` is too exception-like. Let's say, exceptions will some day ever appear in Rust. How they would live with not-exceptinal workflow, if operator `throw` already in use? How much code should be changed to occasinally upgrade with a new epoch?

We already can ""throw"" errors with the `?` operator:
```rust
if condition {
    Err(Foo)?;
}
```
As for me `Err(...)` themself is enough to highlight ""unhappy path"".
Using `return` in form 
```rust
if condition {
    return Err(Foo)
} else {
    return Ok(Bar)
}
```
is redundant, this `if` is last in function (and there is no ""other stuff"").

Even more, before `catch` stabilized, we can intercept such errors with a self-called (but too noisy) closure:
```rust
let res = (|| -> Result<_, Foo> {

})();
```

And even more once again, the `?` postfix operator has very compact representation.
We can write simple
```rust
let foo = bar.x()?.y()?.z()?;
```
without bulky checks. The `throw` operator with `if` instead of just `?` (the first concern in this rfc) will not be so convenient.

So, do we really need to change the syntax to look more exception-like without exceptions, whilst we have a long discussed syntax, on which consensus was reached and which give us almost the same possibilities and even much more, if we do not try to follow the old language habits?",True,True
rust-lang_____rfcs_____2426,2018-05-02T18:39:44Z,True,rust-lang_____rfcs_____2426_____386079005,"@joshtriplett 

> though personally I think `return Err(e)` seems quite clear

That is not the expansion of `throw` -- and this is critical! The expansion is more like `return Err(e.into())`. 

I find myself wanting `throw` precisely at the point where I am trying to leverage this adaptation. e.g., if I am using failure, I might have my own error type:

```rust
#[derive(Fail)]
struct MyError;

#[derive(Fail)]
struct MyOtherError;
```

and then a function that can fail in various ways:

```rust
use failure::Error;
fn foo() -> Result<(), Error> { // <-- use error to accept many kinds of errors
    if something() {
        return Err(MyError);
    }
    if something_else() {
        return Err(MyOtherError);
    }
    ...
}
```

But this code will not compile. I have to write `return Err(MyError.into())` -- or, maybe it's `return Err(MyError).into()`? Or is it `return Try::from_error(MyError)`? Regardless, it's getting a lot messier. `throw MyError`, in contrast is clear and to the point.

---

Regarding the name, I think `throw` is the right choice, for a few reasons:

- I would not be surprised if we added `catch` at some point. I do not think that `match` is always great.
- But even if we don't, I think it is easier to explain to others by saying ""`throw` throws the exception to the enclosing `try`; instead of `catch`, we reuse the `match` keyword"". Basically it comes down to what I wrote before: every detail of the mechanism doens't have to be identical to make reusing a keyword profitable; we just have to capture the same *spirit*, and I believe that is the case here.",True,True
rust-lang_____rfcs_____2426,2018-05-02T18:57:03Z,True,rust-lang_____rfcs_____2426_____386084117,"@joshtriplett 

> @Centril Because Rust error handling is not exception handling, and drawing an analogy to exception handling is misleading.

Well, we disagree on this point. Rust doesn't use the same semantics as Java or C++; but you still have to *handle exceptional cases* in Rust.

> error-handling is just a return of a `Result` type, here are the ways that’s similar to other languages, and here are the ways that’s different than other languages.

In general, I think you are blessing the `Result<T, E>` type too much. There are other richer types which can also implement `Try`.

> I'd prefer `fail!(expr)` over `fail expr` until it's clear that we need a keyword for this;

Here my view is that it would be strange for `throw` (or `fail`) to be the only odd fish given the reservation of `async` and that we don't have `return!`, `break!`, and so on. `fail!` would have to be a built in macro, but I think that would be less ergonomic and consistent. The extent of breakage for all of the proposed words being low, and the edition being the only chance we have to reserve a keyword for this, seems like good reasons to reserve.

> People know to scan for `return`. People understand `break` and `continue`.

Personally I am confident that a Java programmer just introduced to Rust would understand `throw` (or `fail`) as well as they would `break`.

> Any new language construct needs to be sufficiently critical to justify everyone having to be familiar with it and see it in other people's code, and that's even more true for a construct that affects control-flow.

Sure; However, I do think that the massive pervasiveness of `throw` in other languages means a good chunk of people who use Rust already will be familiar with it (modulo misunderstandings re. implicit exception handling, but I've discussed that elsewhere).

> If we were talking about a feature that you can't do any other way, that'd provide some additional justification. But we're talking about something that you can already implement using `return`, or using `?`, and the new keyword would just serve as a shorthand.

I'm not convinced that this is true. While you can get this to work:

```rust
let x : Result<u8, u8> = do catch {
    if true { 1 } else { Err::<!, _>(2)?; }
};
```

How do you make it work for any `Try` without mentioning the carrier type (`Result<T, E>`)?

---------------------------------------

@Flaise

> One of the reasons why I use Rust is because it doesn't isolate me from what the machine is doing.

Is this true? While Rust gives you the **ability** to write bare metal code, you can also write extremely abstract and generic code (even more so with GATs and `-> impl Trait`) that is far removed from assembly.

> Because the new operator is not composable with other language constructs.

In what way is `throw` / `fail` not composable with other language constructs? We could extend it to `throw 'label expr;` just like `break 'label expr`. If anything, `throw expr` improves composability by making things work better in generic settings and enhances `try { .. }` in #2388 and #243.

> And someone said that having a special keyword for error handling in Rust will aid IDE development - I don't buy this because the whole point of Rust's syntax is to be machine-readable.

I don't know who said that. I've never seen the point of Rust's syntax to be machine-readable. I think it has always been about using syntax that stays within our complexity budget and is familiar to C++ programmers (curly braces instead of more ML-like syntax..).

-----------------------------------

@alexander-irbis

> Using `return` in form [..] is redundant, this if is last in function (and there is no ""other stuff"").

Sure; but the goal was to improve early short-circuiting.

> Even more, before `catch` stabilized, we can intercept such errors with a self-called (but too noisy) closure:

Note: `catch` is being renamed to `try { .. }`.
Also, the closure changes the semantics of `return`.

> We can write simple
>
> ```rust
> let foo = bar.x()?.y()?.z()?;
> ```
> without bulky checks.

The `?` operator has a different role, it propagates errors / failures / exceptions, but does not initiate them like `throw expr` would do.",True,True
rust-lang_____rfcs_____2426,2018-05-02T19:10:41Z,True,rust-lang_____rfcs_____2426_____386088139,"""throw x"" would be fully equivalent to ""Err(x)?"", right? And thus this is only a matter of deciding whether such syntax sugar is desirable?
",True,True
rust-lang_____rfcs_____2426,2018-05-02T19:12:31Z,True,rust-lang_____rfcs_____2426_____386088663,"@Centril
> fail! would have to be a built in macro, but I think that would be less ergonomic and consistent.

`fail!` would not need to be a built-in macro: https://play.rust-lang.org/?gist=9fe02214410e4a05e49e7be2158d7f5e&version=nightly&mode=debug

```rust
#![feature(try_trait)]

macro_rules! fail {
    ($e:expr) => {
        Err($e)?
    };
}

fn f(x: i32) -> Result<i32, i32> {
    if x > 10 {
        fail!(0);
    }
    Ok(x)
}

fn g(x: i32) -> Option<i32> {
    if x > 10 {
        fail!(std::option::NoneError);
    }
    Some(x)
}

fn main() {
    println!(""{:?} {:?} {:?} {:?}"", f(5), f(50), g(5), g(50))
}
```",True,True
rust-lang_____rfcs_____2426,2018-05-02T19:14:23Z,True,rust-lang_____rfcs_____2426_____386089183,@joshtriplett @bill-myers I don't think that's right; See the [reference on semantics](https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md#semantics). In particular it is generic wrt. `Try` and `throw expr` is typed at `!` which `Err(expr)?` is not.,True,True
rust-lang_____rfcs_____2426,2018-05-02T19:24:25Z,True,rust-lang_____rfcs_____2426_____386091929,"It appears that the type of ""Err(x)?"" unifies with any type, and is typed as () if there is no other type to unify it with.

Is that intended? Shouldn't the compiler default to ! for a type that unifies with anything, and thus eliminate that difference?

As for the Try genericity issue, that could be eliminated by introducing an ""err() function"" that just calls Try::from_error, allowing to write ""err(x)?"".

That said, ""throw"" seems nice to have as syntax sugar.


",True,True
rust-lang_____rfcs_____2426,2018-05-02T19:31:27Z,True,rust-lang_____rfcs_____2426_____386093788,@bill-myers I might be doing it wrong; but I haven't gotten that to work: https://play.rust-lang.org/?gist=430a69319ac4cb5d49ec6c76cd8096a6&version=nightly&mode=debug,True,True
rust-lang_____rfcs_____2426,2018-05-02T19:41:26Z,True,rust-lang_____rfcs_____2426_____386096659,"I should add a further clarification here: I don't have any objection to reserving the *keyword* `fail` as part of Rust 2018. My objection is to the simultaneous definition of a specific use of that keyword. If you want to take advantage of Rust 2018 to reserve `fail`, we could then choose to *subsequently* define that keyword (or not) at our leisure. I'd happily support *that* RFC.",True,True
rust-lang_____rfcs_____2426,2018-05-02T19:41:55Z,True,rust-lang_____rfcs_____2426_____386096800,"@Centril Using ""Try::from_error(2)?"" also gives an error (E0284 type annotations required)

",True,True
rust-lang_____rfcs_____2426,2018-05-02T19:52:23Z,True,rust-lang_____rfcs_____2426_____386099883,"@joshtriplett 

> My objection is to the simultaneous definition of this specific use of that keyword.

The intent with doing that simultaneously is so that we may experiment.
I also based the definition on what I thought was the most obvious semantics based on where `?` and `do catch { .. }` is today.

> If you want to take advantage of Rust 2018 to reserve fail, we could then choose to subsequently define that keyword (or not) at our leisure.

Most of the reference semantics of `throw` / `fail` is left [unresolved](https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md#unresolved-questions) and can **certainly, 100%** be changed with another RFC. In fact, the RFC even says explicitly that:

> Answering many of these question will likely require another RFC to finalize the design once we have more experience.

So I would say that it is at our leisure to change the definition of `throw` / `fail` after, if we merge this RFC and you should hold me to that.",True,True
rust-lang_____rfcs_____2426,2018-05-02T20:26:05Z,True,rust-lang_____rfcs_____2426_____386109559,@kennytm I've now added `throw 'label expr` to the list of unresolved questions.,True,True
rust-lang_____rfcs_____2426,2018-05-02T20:34:57Z,True,rust-lang_____rfcs_____2426_____386112091,"I also like the idea of reserving the keyword, as the prior art section makes clear its a pretty useful keyword to have.

It wasn't quite clear to me from the RFC, does this proposal include making `expr?` early return errors to the closest try block, the same as `throw expr`?",True,True
rust-lang_____rfcs_____2426,2018-05-02T20:39:22Z,True,rust-lang_____rfcs_____2426_____386113312,"@squishy-clouds This RFC does not alter the semantics of `?`.

However, `expr?` already early-returns to the closest `do catch { ... }` block in the nightly compiler.
RFC #2388 renames `do catch { ... }` to `try { ... }`.",True,True
rust-lang_____rfcs_____2426,2018-05-02T20:59:07Z,True,rust-lang_____rfcs_____2426_____386119257,"Thanks! 

Also: whats the reasoning for using a seperate Throw trait, instead of just `Try::from_error`? All of the Throw implementations listed in the RFC do the same thing anyways, I don't see any benefit of the seperate trait.

And If the Try trait was used instead of a Throw trait, and since `expr?` also early-returns to the closest try block, `throw expr` could just be considered sugar for `Try::from_error(expr)?`. I don't believe shorthand for that (and a potential future shorthand for the Ok happy-path) would be useful enough to warrant adding a new keyword, instead of just using `Err(expr)?` or a macro.",True,True
rust-lang_____rfcs_____2426,2018-05-02T21:36:19Z,True,rust-lang_____rfcs_____2426_____386129145,"@squishy-clouds Well; A separate `Throw` trait is **not** used at the moment; it is **only** discussed as an option, mainly because the definition of `Try` may change. See https://github.com/rust-lang/rust/issues/42327#issuecomment-379955253 for a discussion.",True,True
rust-lang_____rfcs_____2426,2018-05-02T22:09:02Z,True,rust-lang_____rfcs_____2426_____386137030,"@Centril 

What I'm suggesting is that if you propose a ""keyword reservation for Rust 2018"" RFC, and it includes `fail`, `throw`, or both, I'd happily support that RFC. As it stands, however, I don't see the advantage of *this* RFC over the many variations of equivalent macros that already exist in error-handling packages.

My current position is that I'd be strongly opposed to ""throw"", opposed slightly less strongly to ""fail"", and entirely in favor of a macro for experimentation for the time being.",True,True
rack_____rack_____1272,2018-05-02T23:31:50Z,True,rack_____rack_____1272_____185667820,"Maybe, now that we support static handlers, this line should be altered?

Perhaps:

> <tt>rack.upgrade</tt>:: Is used to pass a handler object back to the server for WebSocket and SSE connections.",True,True
rack_____rack_____1272,2018-05-02T23:45:32Z,True,rack_____rack_____1272_____185669700,"Sure, minor change.",True,True
rust-lang_____rfcs_____2426,2018-05-03T05:47:39Z,True,rust-lang_____rfcs_____2426_____386196891,"> Well, we disagree on this point. Rust doesn't use the same semantics as Java or C++; but you still have to handle exceptional cases in Rust.

With respect, I find this a bit misleading. For me and most of the people I know, if you say ""throw an exception"", the thought that comes to mind is not ""return Err(e)"" but ""unwind to the nearest catch or except block"". I really don't want people to think that rust does that.",True,True
rust-lang_____rfcs_____2426,2018-05-03T06:05:07Z,True,rust-lang_____rfcs_____2426_____386198882,"I'd like to bring up the usual argument that introducing a new language construct **always** increases complexity. The more pure the language, the easiest it is to understand.

Therefore any benefit in introducing language features must clearly have a huge advantage over not doing it. This is clearly not the case here.",True,True
rust-lang_____rfcs_____2426,2018-05-03T06:24:17Z,True,rust-lang_____rfcs_____2426_____386201369,"@tomaka 

> I'd like to bring up the usual argument that introducing a new language construct **always** increases complexity.

If this is speaking about the complexity for a language user, then I think this plainly untrue.
Some features can even **decrease** complexity such as when it improves uniformity. See for example, `Self(42, 24)` and `Self { x: 42, y: 24 }` and accepting multiple patterns in `if let` (just like in `match`).

A feature can also reduce complexity for the user if before, for a certain class of problems, you needed to think about two separate features but now only one. For instance, before you had to think about `Err` and `return`, but now only `throw`.

> The more pure the language, the easiest it is to understand.

I don't think this is true either, and absolutely not for understanding programs written in the language.
While [SKI](https://en.wikipedia.org/wiki/SKI_combinator_calculus), is a dead simple language, and you can understand the primitives of SKI in isolation, understanding something written in SKI is harder than understanding a program written in Rust.",True,True
rust-lang_____rfcs_____2426,2018-05-03T06:30:24Z,True,rust-lang_____rfcs_____2426_____386202237,"> the more I think about it and the more discussions I've seen about error handling in Rust, the less inclined I find myself to choose keywords and constructs evocative of exceptions.

I had the opposite experience, actually, so I'd like to hear more about what it is about exceptions that's a poor match here.  I [started](https://internals.rust-lang.org/t/bikeshed-rename-catch-blocks-to-fallible-blocks/7121?u=scottmcm) by preferring a `fallible {}` block, perhaps with a `fail` expression, but was convinced that there's very minimal value in innovating on keywords here, but [plentiful value](https://github.com/rust-lang/rfcs/pull/2388#issuecomment-383441080) in leveraging existing intuitions.

Looking at some things that have been mentioned:

> We do need to tell people ""Rust does not have exceptions""

Do we?  I've never found the statement ""Rust doesn't have exceptions"" all that helpful when the answer to the next question is something like ""well, you replace `public Foo GetFoo() throws FooException` with `pub fn get_foo(&self) -> Result<Foo, FooError>`, replace `throw new FooException()` with `return Err(FooException)` and you call such functions as `.get_foo()?` if you don't want to handle the ~~exception~~error right away"".

I'd rather say ""Rust encodes exceptional situations using `Result`, which gives them more consistent performance and allows them to be treated as normal values where needed, as well requires that you annotate calls of functions that can throw to help avoid exception-safety problems"".

(And if by ""exceptions"" one means ""unwind tables"", then Rust definitely has exceptions.)

> The semantics of Rust error handling and exception based error handling are at odds, and so are intuitions based on them.

Other than that they need to be explicitly propagated, I'm not sure what's at odds here.  There are performance differences, sure -- where neither is strictly better -- but a statement like ""file open 'throws' for error cases"" applies just as much in Rust as it does in something like C#.

> It special cases errors more than I'd like, since I believe errors should always clearly be normal values.

I don't think ""real"" syntax makes this any less true than `bail!`.  And neither prevents all the goodness like one can naturally store the ok/error disjunction for later that comes from `Result`, without needing weird hacks like [`ExceptionDispatchInfo`](https://msdn.microsoft.com/en-us/library/system.runtime.exceptionservices.exceptiondispatchinfo(v=vs.110).aspx).

> Every new control flow construct increases the language surface in a critical place. I don't believe the advantages here (not writing `Err`) are worth the complexity increase.

I think niko addressed this well in https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386079005.

I'll add that a missing language feature which results in a bunch of not-quite-the-same-thing macros being extensively used can be worse, complexity wise, than the syntax addition.

> With the auto-conversion included, it's another place where type conversion happens without being explicitly requested.

Typing `throw` seems pretty [explicit](https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/) to me.

---

Meta: should this be considered an e-RFC?  Similar, though going further than, https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386137030, I'd personally be good to handle this as ""this is permission to reserve the keyword and try it out in unstable, but approval of a subsequent RFC with concrete semantics is needed in the future before it can start to be considered for stabilization"".",True,True
rust-lang_____rfcs_____2426,2018-05-03T06:34:03Z,True,rust-lang_____rfcs_____2426_____386202768,"> Some features can even decrease complexity such as when it improves uniformity. See for example, Self(42, 24) and Self { x: 42, y: 24 } and accepting multiple patterns in if let (just like in match).

That is true, although I would argue that these are more bugfixes than features. Self and multiple patterns in if let are not new constructs.

> A feature can also reduce complexity for the user if before, for a certain class of problems, you needed to think about two separate features but now only one. For instance, before you had to think about Err and return, but now only throw.

Before I had to learn about return and Err. Now I have to learn about return, Err, and throw.

Before when I want to return a value I had to think about return, now I have to think about both return and Err.

> I don't think this is true either, and absolutely not for understanding programs written in the language.

You are exaggerating what I say. I'm not opposed to redundant language construct, but to me they have a base negative cost that needs to be counter balanced by their positive impact.

Adding new language constructs to SKI would make it much easier to read, which counter balances the decreased purity.

Adding throw and try doesn't have a large-enough benefit to outweigh the increased language complexity.",True,True
rust-lang_____rfcs_____2426,2018-05-03T06:39:12Z,True,rust-lang_____rfcs_____2426_____386203524,"I also would like to ask if `try` really is worth it.

While returning an error is a quite common pattern, handling errors is very very uncommon to me.
For me you generally do so when you just turn the error into a human-readable message, but that's mostly it.",True,True
rust-lang_____rfcs_____2426,2018-05-03T06:52:18Z,True,rust-lang_____rfcs_____2426_____386205451,"@mark-i-m  I don't know about most people. Your inference is too technically detailed for my taste and does not fit with what I intend when I use `throw`.

What I intend when I say `throw new MyException()` in Java is that this case is exceptional, nothing more than that. For example, I don't  consider the `catch` block when it is not in the same method.

Similarly, if I write `if cond { return Err(MyError) }` in a function `foo` in Rust, I don't immediately consider a `match` block in some other function `bar` that applies `foo`. All I want to say is that `MyError` is an exceptional case that happens, given some condition.

----------------------

@tomaka 
> Before I had to learn about return and Err. Now I have to learn about return, Err, and throw.

Yes, that's true. But it should be fairly clear which construct to use when. Thus you don't get into [Decision fatigue](https://en.wikipedia.org/wiki/Decision_fatigue).

Specifically in the case of `throw`, I already think most programmers are familiar with it. The semantic differences are not that a beginner to Rust would not benefit from the familiarity in my opinion.

> Adding throw and try doesn't have a large-enough benefit to outweigh the increased language complexity.

Well, on that we disagree :)

-------------------------

@scottmcm 

> Meta: should this be considered an e-RFC?

Sure, why not :) It doesn't really nail down the semantics of `throw` exactly, so that fits.",True,True
rust-lang_____rfcs_____2426,2018-05-03T07:10:46Z,True,rust-lang_____rfcs_____2426_____386208551,"@scottmcm I don't think I'd ever use ""exception-safety problems"" to describe scenarios where you should use `?`. Rather, I'd say that Rust doesn't have exceptions, and that (taking into account whether someone knows about enum yet) it has a type called `Result` to represent either a valid value or an error. And since a common reason to return an error is that a function you called returned an error, you can write `?` as a shorthand for ""if this expression is an error, return that error"". (Additional details about type conversions or non-Result types can come in a later explanation.)

That's *nothing* like unwind-based exceptions.",True,True
rust-lang_____rfcs_____2426,2018-05-03T07:17:08Z,True,rust-lang_____rfcs_____2426_____386209707,"@joshtriplett 

> a shorthand for ""if this expression is an error, return that error""

Kinda like ""(conditional) re**throw**"" 😄

> (Additional details about type conversions or non-Result types can come in a later explanation.)

This is how I think `throw`.

We first explain what it does wrt. the intent of the programmer.
After that, we note these kind of exceptions are not unwind based but rather on *errors as values*.",True,True
rust-lang_____rfcs_____2426,2018-05-03T07:37:13Z,True,rust-lang_____rfcs_____2426_____386213798,"@scottmcm 
> Meta: should this be considered an e-RFC? Similar, though going further than, #2426 (comment), I'd personally be good to handle this as ""this is permission to reserve the keyword and try it out in unstable, but approval of a subsequent RFC with concrete semantics is needed in the future before it can start to be considered for stabilization"".

If this were changed to `fail`, I'd support accepting it as an e-RFC.",True,True
rust-lang_____rfcs_____2426,2018-05-03T07:54:27Z,True,rust-lang_____rfcs_____2426_____386217257,"Status update on `try { .. }`:

RFC #2388 for reserving `try` as a keyword and replacing `catch { .. }` with `try { .. }` is now merged.
See the tracking issue https://github.com/rust-lang/rust/issues/50412 for details.",True,True
rust-lang_____rfcs_____2426,2018-05-03T09:23:22Z,True,rust-lang_____rfcs_____2426_____185739891,It might pay to disable syntax highlighting for examples to avoid the lack of highlighting on `throw` influencing people's subjective impression of the new syntax.,True,True
rust-lang_____rfcs_____2426,2018-05-03T09:28:17Z,True,rust-lang_____rfcs_____2426_____185741046,Good catch; However I think (hope) people will see beyond that :),True,True
rust-lang_____rfcs_____2426,2018-05-03T09:42:25Z,True,rust-lang_____rfcs_____2426_____185744553,"The highlighting appears to be correct on everything in the examples other than `throw` itself, including the expr being thrown, so I think we're getting a much more accurate impression already than we would with no highlighting at all.",True,True
rust-lang_____rfcs_____2426,2018-05-03T11:34:45Z,True,rust-lang_____rfcs_____2426_____386265875,"`throw expr;`  
`Err(expr)?;`

look, they're the same length!",True,True
rust-lang_____rfcs_____2426,2018-05-03T12:17:45Z,True,rust-lang_____rfcs_____2426_____185777702,"> I think (hope) people will see beyond that

I agree that people can see beyond it. I just know that I at least have a hard to ignore subconcious reaction to the inconsistent highlighting on

```rust
if condition { throw Foo } else { return Ok(Bar) }
```

which makes it more difficult for me to really judge the new syntax. I'm expecting that `throw` is the start of a normal expression since it's not a keyword. Whereas I find it much easier to suppress that and treat `throw` as a keyword without any highlighting

```
if condition { throw Foo } else { return Ok(Bar) }
```",True,True
rack_____rack_____1272,2018-05-03T12:49:46Z,True,rack_____rack_____1272_____386284278,"I've been mucking around with a sample implementation of this proposal.

I can implement it entirely as middleware. So, in my mind, it could be something independent of Rack. I didn't implement it exactly because I just reused what I've already done with `async-websocket`.

# Specific feedback regarding the proposal.

With reference to https://developer.mozilla.org/en-US/docs/Web/API/WebSocket

## `rack.upgrade?`

It's okay. It's trivial enough to implement.

It's not clear if the user should return anything. In my case, I use hijack, so no return is necessary (or desirable).

## `on_open`

Makes sense. Do you mean the connection at the socket level or the connection at the web-socket level?

## `on_message(client, message)`

Makes sense.

## `on_shutdown(client)`

Not exactly sure where this fits in. It's similar to `on_close`.

## `on_close`

Do you mean when the websocket connection has been closed by the remote end only (and gracefully?) i.e. when ready state of web socket is changed to close? What about EOF?

## `on_drained(client)`

This seems very asynchronous model dependent. I don't know how to implement this. My model is completely asynchronous so when you call `write` it won't return until the write is complete, but it's non-blocking. Remove this or make it completely optional (as in, it should still work if unimplemented).

## `write(message)`

Pretty crappy name IMHO, because it directly clashes with the WebSocket::Driver implementation's use of `#write` (https://github.com/faye/websocket-driver-ruby#usage). If you have to wrap the underlying driver, it's another object allocation. Bleh. Rename it `#send` or `#text`?

It would be pretty damn convenient if `#send` would convert it to JSON first. Perhaps if `Accept: application/json` is set, it can be done automatically. We could also support other formats. So, user doesn't need to worry about underlying transport to send complex objects (e.g. hash, array, and so on).

## `close()`

If user calls this, what is the sequence of events afterwards? `on_close`? `on_shutdown`? Nothing?

## `open?()`

In distributed systems, it's hard to know if anything is truely open. But you can usually tell with certainty if something is closed. Rename to `closed?` - it's typical Ruby `IO#closed?` `Socket#closed?` and so on.

## `pending()`

Again, this is very async model specific. Remove?

I still stand by my original assessment. But, I think it's an interesting idea. This proposal implements something which can be done entirely in middleware with minimal overhead if your server has a half decent concurrency model.. I don't see a clear benefit to making Rack more complex in this regard and encoding a concurrency model into the `SPEC`. However, I can see value in making some kind of standard layer. I just don't feel like it belongs in the server to implement it, middleware would make more sense.

I still believe streaming requests/response bodies to be the right way forward, but I'm still learning about how this all fits together with HTTP/2 and whether it's possible to use XMLHTTPRequest in a similar way to WebSockets in the browser. It's simpler to set up, multiplexes better (when running on HTTP/2), and has a simpler model - basically read chunk from stream, write chunk to stream, and it works with existing request/response model without any real changes.

Anyway that's my 2c. Feel free to play around with the implementation :)",True,True
rack_____rack_____1272,2018-05-03T13:28:01Z,True,rack_____rack_____1272_____386295227,"An addendum, a concurrent `rack.hijack` IO should be possible for most servers with very minimal surface area (it's what `falcon` does). It would still require some kind of `rack.upgrade` approach since to make a worker truely async you'd need to expose part of the concurrency model, as in ""Your rack.upgrade object will be run in it's own thread with blocking IO"" as the base requirement, but with more advanced servers able to provide better guarantees (e.g. rack.multithread could be false, you can assume an `async` like model if things are running concurrently). Again, it starts to get pretty hairy, in terms of how you define that model, and whether that should really be in Rack, but it's probably a more generic approach and it would work with HTTP/2 as well (in general, rack.hijack with an IO like API should map directly to HTTP/2 streams, and it's the next thing I want to try in `falcon`).. It wouldn't even preclude you from implementing web sockets on top of it with whatever you currently use and a default implementation as a middleware which really does just make a thread per request is entirely possible.",True,True
rack_____rack_____1272,2018-05-03T13:33:08Z,True,rack_____rack_____1272_____386296756,"I appreciate you taking the PR seriously enough to devote time to exploring implementation options. Thank you. Nice summary as well. I'd like to point out that all the method are optional. If the handler does not respond to the method then it is not called.

`rack.upgrade` :heavy_check_mark: 

`on_open` indicated the connection has beenn upgraded to WebSocket or SSE and is ready for sending messages.

`on_message` :heavy_check_mark: 

`on_shutdown` I agree, it does not seem necessary.

`on_close` Yes, called when the socket is closed. Ideally gracefully but that assumes the client did a graceful close which may not be the case. Basically the socket is no longer write able and nothing else will be received from it. Since both WebSocket and SSE are message based the notion of EOF doesn't really come into play as it is a streaming concept. Best case is EOF is the same as closed or maybe another way to look at it is if the server is reading a message and gets an EOF error then it assumes the socket is closed and tells the application that the connection is classed with the `on_close` callback. That is the way Agoo handles it anyway.

`on_drained` indicates no more messages are waiting to be sent. Depending on the implementation this could indicate the previous message was sent and another can be sent or the backlog of messages has dropped to zero. It is meant as a way for the application to meter itself and detecting slow consumers. In my opinion it is nice to have to avoid slow consumer attack vectors.

`write` could certainly be renamed but `send` would conflict in the base Ruby Object `#send` so something different. `#write` is the second best choice. You seem to have agreed since you used it in Faye which of course is where the conflict lies. How about `push`?

`close` when called initiates a graceful close of the connection. Once closed the `on_close` callback should be called.

`open?` flipping the call to `closed?` makes sense. Agreed.

`pending` is async specific. It could be removed and everything would still be fine. It was added to address the slow client issues and allow and application to address slow client attacks. How about return some value that indicates it is not supported?

Thanks again for the well thought out response.",True,True
rack_____rack_____1272,2018-05-03T13:37:24Z,True,rack_____rack_____1272_____386298090,I like the idea of using `rack.multithread` as an indicator to the application as to what it can expect in regard to the async model especially since it is already part of the spec and seems to be a perfect fit.,True,True
rack_____rack_____1272,2018-05-03T13:41:14Z,True,rack_____rack_____1272_____386299251,"> write could certainly be renamed but send would conflict in the base Ruby Object #send so something different. #write is the second best choice. You seem to have agreed since you used it in Faye which of course is where the conflict lies. How about push?

Don't get me started with `send` and Ruby. I had no end of problems with it several years ago, when I first started playing with Ruby's IO. Fortunately, now `__send__` exist in Ruby. I sometimes wonder if we are writing Python :p

To me, send/recv are socket level, but they resonate for higher level network IO too.

read/write make me think of buffered IO.

As this is a message based protocol, and you chose `on_message`, why not then `send_message`?

> pending and on_drained  ...

I understand where you are coming from.

In my client code, the following happens:

```ruby
connection.send_message(....) -> @driver.text -> @socket.write(protocol level data) -> Socket#write_nonblock -> okay, :wait_writable or EPIPE
connection.send_message(....) -> @driver.text -> @socket.write(protocol level data) -> Socket#write_nonblock -> okay, :wait_writable or EPIPE
connection.send_message(....) -> @driver.text -> @socket.write(protocol level data) -> Socket#write_nonblock -> okay, :wait_writable or EPIPE
```

You literally can't send messages faster than they would be written to the socket, because you'll yield on `:wait_writable` and `select(io, writable)`. Once the data is written to OS socket, how do you know `pending` or not? I mean, eventually that buffer will fill up. But do we get receipt of messages in WebSockets? I don't know enough about it, I only used `websocket-driver` and left the rest up to that gem. Can we get pending acknowledged count from that implementation?




",True,True
rack_____rack_____1272,2018-05-03T13:43:29Z,True,rack_____rack_____1272_____386299976,"In an implementation where messages are buffered some how, where do you propose to handle EPIPE? Or should it never occur and `on_close` should be invoked? or do we need `on_error`? To me, implementing something like `on_error` to handle EPIPE?

If your concurrency model is more event driven, I can imagine you would buffer the message and actual writing might occur on a different call stack.",True,True
rack_____rack_____1272,2018-05-03T13:47:05Z,True,rack_____rack_____1272_____386301122,"In my implementation, when you have a loop like `while event = @driver.next_event`, if you receive EOF, event is nil. It's not an exception. Then, it would call `on_close`. However, sometimes it might be caused by ECONNRESET. This is really an error condition. should it be `on_close(error = nil)`?

but if you call send_message, and remote end is gone, you make get EPIPE, Errno::ECONNRESET, or on macOS even EPROTOTYPE (https://bugs.ruby-lang.org/issues/14713). It's not graceful. Sometimes yo can get E",True,True
rack_____rack_____1272,2018-05-03T13:55:18Z,True,rack_____rack_____1272_____386303835,"You bring up some interesting points. For Agoo the write are indeed on a different call stack but I like the idea of providing more information to the application about the reason for a close. Maybe the callback should be `on_close(err)` where `err` is `nil` for a graceful close. Yes, we are thinking along the same lines,

I would expect a write to fail with some kind of exception if the connection has been closed. Agoo raises an IOError.
",True,True
rack_____rack_____1272,2018-05-03T21:52:37Z,True,rack_____rack_____1272_____386448690,"@ioquatix, it is my humble understanding that this specification allows us to abstract away the network layer as much as we can.

This allows all persistent connections to share the same API regardless of their type (WebSockets, SSE, raw TCP/IP, etc').

It's my understanding that EOF and other network details should be handled by the server. They aren't application related events.

The reverse is also true. JSON is as application concern, it doesn't fit every persistent connection out there (i.e., binary transmissions in WebSocket data).

It's my recommendation that the server require a String object and let the application deal with making sure the data formatted as a String.

Network details could be inferred by the server (UTF-8 for text encoded messages and otherwise the server should probably assume binary data, which some connection objects might not support).


### `on_shutdown`

> `on_shutdown` I agree, it does not seem necessary.

I humbly disagree.

Maybe I'm assuming but I think applications can benefit from the knowledge that the client is closing because the server is shutting down.

There are three possible disconnection causes:

1. The connection is deemed unnecessary (this could be a proxy timeout due to inactivity).
1. The server shutting down (the client might be mid transmission).
1. Network errors (which we can do nothing about).

True, `on_shutdown` only called when the server is shutting down (not for every connection), but it's a good way to prevent communication errors and keep the disconnection polite - especially when using server clusters or load balancing.

This could be use by load-balanced micro-services as well to indicate a node is going away (and perhaps send a list of alternate nodes in a gossip based system).

### `on_drained` / pending()

@ioquatix , since you're using a blocking model, where the method returns only after `write` was complete, `pending` can easily return `0` - no pending `write`, indicates that `on_drained` isn't about to be called (maybe ever).

Do note that this blocking design might be risky, if - for example - a DataBase connection was checked out of a connection or the `write` method was called within a critical section (i.e., looping over all clients).


### `write`

> `write` - Pretty crappy name IMHO...

Actually, just because other implementations use this amazing name (which is also the name of an underlying system call), doesn't mean that the specification should choose a poor name...

...in fact, it just supports the choice as a good one - developers will have a good idea as to what happens when they call this method.

IMHO `send` conflicts with the Ruby object `send` which might prevent an error from being detected (i.e., if `send` is called on another object, it will not return a ""missing method `write`, but rather a long gibberish message).

`push` seems (IMHO) less intuitive and more protocol specific (SSE). It also implies objects rather than data.

IMHO, `write` describes exactly what's happening. It might behave slightly differently from an IO `write` (no partial `write` allowed), but it performs the same function.

### `open?`

> open? flipping the call to closed? makes sense. Agreed.

Actually I think this `closed?` will make application code harder to maintain. It's too easy to mixup `close` for `closed?` and vice verses.

Using `open?` is safer, even if the server's information regarding the connection is never fail proof.

### `on_close(err)` / `on_error(err)`

I really think network / connection errors aren't an application concern, they are a server concern.

However, if we are to report an error, I would wonder if it would make sense to place the error information in a different callback, preventing the need for the obvious `if(err)` block of code in `on_close`.
",True,True
rack_____rack_____1272,2018-05-03T21:56:54Z,True,rack_____rack_____1272_____386449668,"@ioquatix 

> In my implementation, when you have a loop like while event = @driver.next_event, if you receive EOF, event is nil. It's not an exception. Then, it would call on_close. However, sometimes it might be caused by ECONNRESET. This is really an error condition. should it be on_close(error = nil)?

`ECONNRESET` is a perfect example for an error that the application really shouldn't receive. Why should the application have any information about network errors? What would it do with it?

IMHO, this is a Server related concern and it should be handled by the server.",True,True
rack_____rack_____1272,2018-05-03T22:11:50Z,True,rack_____rack_____1272_____386452844,"I have less of an issue passing some error back to the application with `on_close`. The application can't do anything about it but it isn't harmful either.

@boazsegev you make some good points I was a little too willing to compromise on.

I'm not sure where we go from here. I assume we need a 'member' to step in again. How about it @tenderlove , how should we proceed on this PR?",True,True
rack_____rack_____1272,2018-05-03T22:54:15Z,True,rack_____rack_____1272_____386460920,"@ioquatix 

> In my client code, the following happens... 
>
> You literally can't send messages faster than they would be written to the socket...
>... Once the data is written to OS socket, how do you know pending or not?

I think the question isn't about data pending **after** performing `write` to the socket. It's about data pending **before** `write` is performed (if applicable).

In your  (fiber-per-connection) model `write` always completes. But consider the node.js model (which iodine emulates in this regard):

* An application calls `connection.write`.
* The server places the data in the connection's queue and adds a `flush_connection` event to the event loop.
* `connection.write` returns.

    Note that _**no network actions were performed**_. At this point `pending()` would probably return `1` (or perhaps a higher value).

* The application code ends and the server handles the ""flush"" event, flushing the connection's buffer using the system call `write` (or `socket.write`).
* Once all the data was written to the socket (which might require a number of events) the connection's `on_drained` event is scheduled.

   This doesn't guarantee that the data actually reached the browser/client (a network error might have occurred, the OS might be waiting on a timeout).

   This only guarantees that the server won't call `write` (or `sock.write`) until more data is scheduled to be sent - the data is out of the server's control.

",True,True
rack_____rack_____1272,2018-05-03T23:06:27Z,True,rack_____rack_____1272_____386463025,Agoo uses a similar approach.,True,True
rust-lang_____rfcs_____2426,2018-05-04T00:25:38Z,True,rust-lang_____rfcs_____2426_____386475629,"In the interests of finding and documenting common ground:

I'm withdrawing my objections to the introduction of *some* statement for this. I do think such a statement should go through appropriate experimentation, and go through further evaluation before stabilization to determine if it's worth the cost, but I'm not going to object to *starting* such experimentation in nightly.

Given the above, I also don't have any objection to the use of the keyword `fail` for that concept.

I do very much object to the use of the keyword `throw` for that concept. I'll leave aside bikeshedding on taste for the moment (e.g. whether `fail` pairs nicely with `try`). My primary objection here is the use of exception-based terminology, rather than something that has sufficiently little baggage attached to it that we can safely define it without surprising people with an uncanny valley of slight differences. I'd like the term we use to come across as ""similar to `return` but for an error"", rather than ""similar to exceptions"".",True,True
rack_____rack_____1272,2018-05-04T01:06:19Z,True,rack_____rack_____1272_____386481308,"**`write` - exception vs. `true`/`false`?**

Reading through the thread I noticed how hard it might be to predict a `write` failing.

This means that user code must use `begin`/`rescue` blocks to address network issues.

Since a failing `write` is a predictable and possible result in the normal flow, wouldn't it be better if the server handled any exceptions and simply returned `true` if the data was (or scheduled to be) written to the socket and `false` otherwise?

I think this will improve performance and also prevent the obvious nesting of exception handling code (on the server and the app).

Thoughts?",True,True
rack_____rack_____1272,2018-05-04T01:22:24Z,True,rack_____rack_____1272_____386483449,"I had assumed raising an exception was the natural behavior but maybe that is not the best approach. Even returning true or false does not necessarily indicate the message was delivered. I think the real question is, what information would be useful to the app. Maybe nothing. Callbacks exist for closing which lets the app know writes will no longer be delivered. Is an acknowledged protocol desired on top of WebSockets? I think that might be a step too far.",True,True
rust-lang_____rfcs_____2426,2018-05-04T01:24:50Z,True,rust-lang_____rfcs_____2426_____386483780,"Conversely, this thread has convinced me that calling it `throw` might not be too bad, but I'm still skeptical that having such a feature is sufficiently justified.",True,True
rack_____rack_____1272,2018-05-04T02:18:29Z,True,rack_____rack_____1272_____386490033,"There are currently two implementations of the originally proposed spec, Agoo and Iodine. I'd think that if proof that the spec is workable.

Waiting for several applications to be implemented against a spec that has not been approved seems rather unlikely. Does that pretty much means not changes can be made to the spec because there is no spec to follow. Rather circular logic.

So the purpose of this PR was to refine the proposal and then get a vote which would be result in this PR being either approved or rejected. How do we get to that phase?",True,True
rack_____rack_____1272,2018-05-04T02:22:39Z,True,rack_____rack_____1272_____386490611,"> Waiting for several applications to be implemented against a spec that has not been approved seems rather unlikely.

I don't think so. Making some sample apps is a great way to document the API, provides a great starting point for new users, etc. And finally, if the sample apps can't work between servers, what's the point of a shared SPEC?",True,True
rack_____rack_____1272,2018-05-04T02:26:56Z,True,rack_____rack_____1272_____386491161,"> There are currently two implementations of the originally proposed spec, Agoo and Iodine. I'd think that if proof that the spec is workable.

I think we need to see a working implementation in at least Puma & Passenger as a baseline since that is what is very common for Ruby development and production.",True,True
rack_____rack_____1272,2018-05-04T02:35:45Z,True,rack_____rack_____1272_____386492282,I believe the suggested bar was several practical applications. There are already sample applications in the Agoo and Iodine repositories. ,True,True
rack_____rack_____1272,2018-05-04T02:38:32Z,True,rack_____rack_____1272_____386492566,"> To implement several practical applications

Something more practical than ""Hello World"". For example, a shared real-time Todo list :p

I think we should be involving some database activity in the callback, probably using ActiveRecord or Redis.

If you've already got several sample applications, once we finalise a draft SPEC and we all implement it, we should be able to all run those apps on our respective servers, right? That's the whole point of having a shared SPEC.",True,True
rack_____rack_____1272,2018-05-04T02:43:40Z,True,rack_____rack_____1272_____386493067,"I still don't see a statement about whether `write` can block.

I'm also unconvinced that pending/drained is an effective solution for non-blocking writes.

I remain of the opinion that this should remain a draft / small-e extension while real-world implementations adopt it and fully exercise it.

Easy-mode for convincing me would be a PR to Rails adapting Action Cable to this API -- which would also allow like-for-like benchmarking.",True,True
rust-lang_____rfcs_____2426,2018-05-04T04:43:14Z,True,rust-lang_____rfcs_____2426_____386504543,"As a newcomer to Rust, I think there is great value in using exception-like terminology and mechanisms (throw/try/catch) in the interests of making Rust a more approachable, less difficult to learn language even if Rust throws errors that are manually propagated instead of throwing exceptions that automatically unwind the stack. I understand the concern that it may be better to introduce new terms, such as fail instead of throw, rather than re-use terms from other languages if the semantic match is not exact but I argue here that this cure is worse than the disease.

People familiar with throwing exceptions will already know the following things which also apply to throwing Rust errors:
(1) ""throw"" means to initiate/produce an error
(2) what is thrown may contain additional information about the error and this can be customized
(3) what is thrown will either be caught and handled in the current function or propagate out of the function and be handled higher up in the call chain
(4) a try block can be used to group the code that may throw so that we may have a single point where we first decide what if anything we want to do about the error and this may include just propagating the error to the next level

This is a substantial amount of intuition coming merely from the word ""throw"". If we use other words, such as fail or its synonyms, the person learning Rust cannot assume any semantics at all - which is precisely why a new term was used - and the result is a sharper learning curve.

When considering how different is different enough to I think it's also interesting to note that even when languages adopt the same general mechanism, exceptions with the typically associated terminology, there are usually all kinds of subtle/papercut-like differences that have to be remembered, and thus having differences in Rust's usage for throw/try/catch is par for the course. For example C++ vs Java exceptions:
https://www.geeksforgeeks.org/comparison-of-exception-handling-in-c-and-java

I believe the jury is still out about use of catch in Rust, where catch allows a match-like mechanism for handling errors but for the same reasons I truly hope we will get this too.",True,True
rust-lang_____rfcs_____2426,2018-05-04T05:26:02Z,True,rust-lang_____rfcs_____2426_____386508525,">I'd like to bring up the usual argument that introducing a new language construct always increases complexity

To counter, the simplicity this RFC is seeking is making Rust **programs** simpler, not necessarily the language itself. I'm all for language growth that leads to simpler, more clearly expressed and more easily understood Rust programs (especially more easily understood by C++ programmers, of which I've been one for many years.)",True,True
rack_____rack_____1272,2018-05-04T06:15:31Z,True,rack_____rack_____1272_____386513684,"@matthewd ,

Although I understand the suggestion (adding a Rails PR), I find that quite unfair.

I can program a server in C and I can wrap in a gem for Ruby MRI... but I know nothing about ActionCable, it's inner workings or the Client<=>Application protocol used above the WebSocket layer.

The learning curve and time spent on a Rails patch would only be viable if the PR is conceptually acceptable and we all intend to move forward with the proposal and implement it.

I really doubt if pushing a PR to Rails is something that should happen before we agree that the PR is conceptually acceptable (i.e., contingent on benchmarks, or whatever).

As a side note, I also don't think this should enter be a Rails 5.x release. This PR has the potential to retire the Rails IO handling layer (the one based on `nio4r`) and reduce the existing codebase significantly - at least where WebSockets and SSE (and perhaps long polling could be achieved by [Javascript's polyfills](https://github.com/Yaffle/EventSource), retiring `hijack` altogether).
",True,True
rack_____rack_____1272,2018-05-04T06:21:40Z,True,rack_____rack_____1272_____386514494,"> I still don't see a statement about whether write can block.

@matthewd , I assumed (since there's no statement) that it would be implementation defined.

I'm assuming that blocking servers will be avoided by applications that are effected by the behavior.

But I totally understand if you believe there should be a concurrency model requirement regarding `write` and `close` not blocking. After all, if `write` blocks, pub/sub performance might grind to a halt.",True,True
rack_____rack_____1272,2018-05-04T06:24:21Z,True,rack_____rack_____1272_____185997879,"After reading through @ioquatix and @matthewd 's comments, I wonder:

Perhaps `close()` should ""_schedule the connection to close once all pending `write` calls have been performed_""?",True,True
rack_____rack_____1272,2018-05-04T07:29:12Z,True,rack_____rack_____1272_____186006296,"If you want to have that, implement it as `close_write` which is what Ruby calls `shutdown(SHUT_WR)`. `close` should guarantee after returning that the underlying socket is closed. Otherwise, you are in for a world of pain.",True,True
rust-lang_____rfcs_____2426,2018-05-04T08:33:39Z,True,rust-lang_____rfcs_____2426_____386537354,Why do we need such a statement? Both `bail!` and `Err()?` and `try!(Err())` are fine choices. I don't think that the additional complexity of the language is worth it. We aren't C++ :p.,True,True
rust-lang_____rfcs_____2426,2018-05-04T09:23:25Z,True,rust-lang_____rfcs_____2426_____386548011,"@ibkevg 
The problem is that it's a trade-off along a continuum, so there's no simple answer.

If you optimize for language simplicity over program simplicity, you get something like Brainf*ck.

If you optimize for program simplicity over language simplicity, then the farthest hyperbolic extreme you could theoretically go would be to have the compiler contain billions of programs, so most ""programs"" would be nothing more than `program28064309876()`.

Neither extreme is very useful, so the question is finding the middle point that's right for Rust. As someone who is *not* a C++ programmer and who has seen and appreciated the Python influences in Rust's design, RFCs like these, which seem to lean in the direction of Perl's ""There Is More Than One Way To Do It"" philosophy of duplication without justification, worry me.",True,True
rust-lang_____rfcs_____2426,2018-05-04T09:49:53Z,True,rust-lang_____rfcs_____2426_____386553824,"Sorry if this has been discussed before (as I wasn't following the RFC the whole time), but could you mention the advantage of `throw expr` over `Err(expr)?` in the RFC text? (for example, you have discussed its advantage over `throw!(expr)`)

If I understand correctly, `Err(expr)?` isn't strictly diverging so it's not exactly equivalent -- that is, unless the compiler can guarantee that `Err(...)?` always triggers the failure path. [Here](https://play.rust-lang.org/?gist=6f598b36678183a05f17642fc55eef66&version=stable&mode=debug)'s a rather contrived example.

Also, does `Err(expr)?` work with other types that implement `Try`?",True,True
rust-lang_____rfcs_____2426,2018-05-04T10:45:10Z,True,rust-lang_____rfcs_____2426_____386564978,"Personally, using `fail` instead of `throw` makes it a little better. But in general I'd still be opposed because it's another control flow construct, and because it is still special casing errors.

At this point my favorite would be a general-purpose works-for-everything `break 'my_operation Err(my_error)`.",True,True
rack_____rack_____1272,2018-05-04T12:13:43Z,True,rack_____rack_____1272_____186063615,Agoo treats a cal to close as a request just like a write and places the close on the queue.,True,True
rack_____rack_____1272,2018-05-04T12:17:16Z,True,rack_____rack_____1272_____386583565,@matthewd would a statement leaving the blocking behavior up the the server be enough or maybe a method to ask if blocking would block other threads?,True,True
rack_____rack_____1272,2018-05-04T12:34:23Z,True,rack_____rack_____1272_____186067832,"@ohler55, so does iodine. I place a ""close"" marker on the packet queue, so `close` is always performed after all scheduled data is sent.


@ioquatix , I think your missing the point o f abstracting away the network and the protocol.

My suggestion was about clarifying this little bit, not changing what both iodine and agoo already implement.

We aren't authoring a network layer. We are authoring an abstracted application side API.

The reasonable exception is that `write` is perfumed before `close`. i.e., if my code is:

```ruby
write ""hello""
close
```

The reasonable expectation is that ""hello"" is actually written.

There's no `force_close` or `close_write` in the specification because the application shouldn't be concerned with these things. If the application doesn't want data written, it can avoid writing it.
",True,True
rack_____rack_____1272,2018-05-04T12:36:02Z,True,rack_____rack_____1272_____186068205,"You can make close call `flush`, or you can flush after every write. But you make close call flush, you better be careful about `EPIPE`.",True,True
rack_____rack_____1272,2018-05-04T12:43:40Z,True,rack_____rack_____1272_____186069857,"@ioquatix 

I think these are implementation details that each server could work out according to it's architecture.

The falcon implementation, for example, seems to block `write` so it always completes before `close` (or so I understand) while iodine's implementation places a flag and adds an event to the event queue. 
",True,True
rack_____rack_____1272,2018-05-04T12:47:44Z,True,rack_____rack_____1272_____186070867,"Sure as long as there are no pratical differences to the user, it would be reasonable. However, if you are buffering events, you might end up with the user having the wrong expectations.

```
10.times do
    connection.send_message(...)
end

# got here, were all events sent? it depends on implementation. Can I call flush to confirm they were sent?
```


",True,True
rack_____rack_____1272,2018-05-04T13:00:37Z,True,rack_____rack_____1272_____186074373,"I'm not sure what you expect `flush` to do. In most uses flush blocks until all outstanding writes have completed. Is that the intent, block until completed? The PR proposes the `on_drained` callback for that purpose or a `pending` count of zero. Are you proposing a `wait_for_all_writes_to_complete` method called `flush` in addition to the existing ones?",True,True
rack_____rack_____1272,2018-05-04T13:03:09Z,True,rack_____rack_____1272_____186074963,"For a high level protocol like this, calling flush after each write would make sense to me.

It provides the user with a strong expectation, that after calling write, the data has been sent, and pending a network failure, would arrive, or else the write fails right then, with, say, `EPIPE`. Otherwise you'll just end up with a spaghetti state machine trying to handle all these conditions.",True,True
rack_____rack_____1272,2018-05-04T13:08:00Z,True,rack_____rack_____1272_____186076104,"@ioquatix ,

I hope I don't seem too blunt or crude. I very much appreciate the interest and willingness to polish the specification and make it both as clear and as practical as can be.

However, please consider the model to be totally separate from the network - there is no network. There's only this API.

We can change the API if we need features, but we don't expose network bits or logic because part of our job is to abstract these things away - so there is no network, there is no protocol (as much as possible).

In this sense, `flush` doesn't exist. It's a network / server detail that the client never sees, abstracted away by the server.

The closest an application can come to ask about these things is to ask about all the `pending` events that haven't yet completed. This allows an application to know if the `on_drain` callback is somewhere in their future.

The `pending` query doesn't to expose the network, it exposes the progress of existing API calls. This provides important information about the possibility of a slow client (or a slow clearing ""queue"") allowing an application to stop serving a resource hungry ""client"".",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:08:49Z,True,rust-lang_____rfcs_____2426_____386596040,"@phaylon 
> because it is still special casing errors.

I don't see how this argument is workable because we already special case errors in the language with the re-throw operator `?`. This eliminates most of the places where you would otherwise see errors as just ordinary values with no sugar.

Furthermore, we did merge RFC #2388 (`try { .. }`) and so at least we have the intent to special case errors even more (tho it is not stable yet).

Therefore the question should rather be: *""do we want to special case errors **more**?""*.

I also don't get why special casing errors syntactically is a problem; more or less every well written program has error handling in it, and usually a lot of it, so it helps to eliminate boilerplate. If we are OK with having `async { .. }` as sugar over futures, then why not errors, given that error handling is (probably) more commonly used.

@Wyverald 
> could you mention the advantage of throw expr over `Err(expr)?` in the RFC text

Will do.

> We aren't C++ :p.

We are not, that is true. But as a systems language intended to be useful for doing things done in C++, I think making the language easier to understand for C++ programmers should at least count for something.

@ssokolow 

> If you optimize for program simplicity over language simplicity,

I understand @ibkevg's argument as simplicity wrt. fitting the mental model and more and programs being simpler to read. `program28064309876()` if encoded directly in the program is not simple because it fails to communicate intent and be readable entirely (even if you named it properly, the name would be so long that it would be pointless).

> which seem to lean in the direction of Perl's ""There Is More Than One Way To Do It"" 

Rust does not adhere to the philosophy *""there should only be one way to do it""*.
Neither does it adhere to adding sugar just because we can.

I'd like to propose a different, more practical and nuanced (and truer, because python violates its own policy..), philosophy:
> *There should be few ways to do it, and picking one among them should be obvious in context.

Adding syntactic sugar should be done if it
+ makes programs simpler (wrt. mental model)
+ makes programs more readable
+ makes programs more ergonomic to write
+ is general (for example, does not only apply to the type `Result`, but more types (`Try`))
+ applies commonly",True,True
rack_____rack_____1272,2018-05-04T13:09:41Z,True,rack_____rack_____1272_____186076571,If I understand your response you are answering yes to the question of whether or not a `flush` method should be added. Then in any application you wrote you would block until the write completes instead of making use of the `on_drained` callback. That is your choice of course. ,True,True
rack_____rack_____1272,2018-05-04T13:16:22Z,True,rack_____rack_____1272_____186078258,"> However, please consider the model to be totally separate from the network - there is no network. There's only this API.

Fair enough.",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:20:24Z,True,rust-lang_____rfcs_____2426_____386599124,"> I don't see how this argument is workable because we already special case errors in the language with the re-throw operator ?. This eliminates most of the places where you would otherwise see errors as just ordinary values with no sugar.

I disagree that `?` is only for errors. We'd need some time with the ability to implement it for your own types before we know what it's full scope is.

> Furthermore, we did merge RFC #2388 (try { .. }) and so at least we have the intent to special case errors even more (tho it is not stable yet).

I'm against `try` as you know. Further, the fact that it has been merged doesn't mean criticism for it must end.

> Therefore the question should rather be: ""do we want to special case errors more?"".

I disagree. ""Should we special case errors less?"" should also be a valid question.

> I also don't get why special casing errors syntactically is a problem; more or less every well written program has error handling in it, and usually a lot of it, so it helps to eliminate boilerplate.

My opinion is that ""errors are values"" is a fundamental and important part of Rust. That needs to be reflected in the language and idiomatically written code. I believe these proposals run counter to that.

If we special case everything that programs usually contain, Rust will become a very big language.",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:25:53Z,True,rust-lang_____rfcs_____2426_____386600558,"I agree that ""There should be few ways to do it, and picking one among them should be obvious in context."" fits Rust well.

My main issue is that I found the sentiments expressed in [Pre-RFC: Catching Functions](https://internals.rust-lang.org/t/pre-rfc-catching-functions/6505/1) to be quite alarming, both in how divergent they seem from existing Rust design philosophy at times, and in their potential to be the first step in a devolution of Rust into a C++-like grab-bag of ""I like Rust, except for this one thing I miss"" features.

@phaylon's most recent reply puts my concerns into words much more effectively than I probably would have.",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:45:59Z,True,rust-lang_____rfcs_____2426_____386606168,"I still think `expr 'label?` and `Err(expr)?` and (where flow inference matters, aka uninitialized variables - but see below) `break 'label Err(expr)` are the way to go. (see also discussion in #2430 #2046 and uhh there was one more but I can't remember what it was)

Also, avoid uninitialized variables, it needlessly increases verbosity. As one example linked here shows:

```rust
fn test(b: bool) -> Result<i32, char> {
    let k;
    if b {
        Err('H')?
    } else {
        k = 3
    }
    Ok(k)
}

fn main() {
    match test(false) {
        Ok(_) => println!(""ok!""),
        Err(c) => println!(""not ok! {}"", c),
    }
}
```

https://play.rust-lang.org/?gist=6f598b36678183a05f17642fc55eef66&version=stable&mode=debug

Compare this to:

```rust
fn test(b: bool) -> Result<i32, char> {
    if b {
        Err('H')?
    }
    let k = 3;
    Ok(k)
}

fn main() {
    match test(false) {
        Ok(_) => println!(""ok!""),
        Err(c) => println!(""not ok! {}"", c),
    }
}
```

There are 3 things to consider here:

- The latter is flatter, avoids excessive indentation.
- It actually compiles.
- You don't need `let k;` *and* `k = 3`, you get to have `let k = 3;`. For longer names this is a huge improvement!",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:48:02Z,True,rust-lang_____rfcs_____2426_____386606777,"> I disagree that `?` is only for errors. We'd need some time with the ability to implement it for your own types before we know what its full scope is.

My point is not that it is only for errors or not.
My point is that *we have syntactic sugar for a **class of values***, be they errors, or something more general.

> Further, the fact that it has been merged doesn't mean criticism for it must end.

This is true; but the criticism becomes less persuasive the more counter-factual it becomes and primarily it becomes non-actionable (this is primarily in relation to `?` since `try` is not stable yet).

> I disagree. ""Should we special case errors less?"" should also be a valid question.

This is non-actionable (can't break `?`); so I don't see how you can do this other than to discuss it intellectually.

> My opinion is that ""errors are values"" is a fundamental and important part of Rust.

Everyone (I hope) agrees with this.

> That needs to be reflected in the language and idiomatically written code.

This does not flow immediately from *errors are values* (semantically) and indeed it is not reflected in idiomatically written code (again, see `?`). Errors can still be values semantically but the language can provide sugar that makes it feel less boilerplate-y.

> If we special case everything that programs usually contain, Rust will become a very big language.

No one said we should *special case everything that programs usually contain*, but we can special case **some things** that **most programs** contain to a **large extent** and is just **boilerplate**.

> My main issue is that I found the sentiments expressed in Pre-RFC: Catching Functions to be quite alarming,

I think most of the push-back on that Pre-RFC was in relation to `-> T catch E` which I am also opposed to.

On C++ I would say that it is particularly large because of baggage from C and because of C++'s age. As Rust ages, the software industry develops, and more PLT research matures, it is only natural for the language to grow to fit tomorrow's challenges.",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:53:31Z,True,rust-lang_____rfcs_____2426_____386608381,"I'll have to think about your other points, but there *is* one I can address right now.

> This is non-actionable (can't break ?); so I don't see how you can do this other than to discuss it intellectually.

""special-case errors less"" is a relative statement, so it can also be accomplished by making things that are currently error-specific more generally applicable, rather than by removing them.",True,True
rust-lang_____rfcs_____2426,2018-05-04T13:55:17Z,True,rust-lang_____rfcs_____2426_____386608890,"@ssokolow 

> ""special-case errors less"" is a relative statement, so it can also be accomplished by making things that are currently error-specific more generally applicable, rather than by removing them.

Oh I agree entirely with attempting to make `Try` apply more generally, if it can be done, why not :)",True,True
rust-lang_____rfcs_____2426,2018-05-04T14:08:16Z,True,rust-lang_____rfcs_____2426_____386612823,I don't see what `throw` brings into ergonomics. I think it'll just encourage bad code (see the uninitialized variable case above).,True,True
rust-lang_____rfcs_____2426,2018-05-04T14:16:15Z,True,rust-lang_____rfcs_____2426_____386615353,"> My point is not that it is only for errors or not.
> My point is that we have syntactic sugar for a class of values, be they errors, or something more general.

I'd disagree here, but I think that's a point of fundamental difference. To me, `?` is about the `Option` or `Result`, *not* the wrapped value. The wrapped value might be an error, but it might also be an original owned state (as used by `Arc::try_unwrap` for example) or a count of things that were successfully processed (e.g. a byte count). Those are not errors, but propagating that information is still useful.

So, `?` is to me about sugar for behavior, while `fail` has an error association. Too bad `propagate` is quite a mouthful.

But for the record, I wouldn't mind `?` not auto-converting types and instead have an `err_into` on `Result`.

> This is true; but the criticism becomes less persuasive the more counter-factual it becomes and primarily it becomes non-actionable (this is primarily in relation to ? since try is not stable yet).

Things can change in the future. That's the whole point of editions. If at some point we decide a simple `encapsulate! { ... }` that does `(||{...})()` is more useful and straight-forward, `try` can still be deprecated.

> This is non-actionable (can't break ?); so I don't see how you can do this other than to discuss it intellectually.

It's about:
* Arguing against introducing more special casing.
* A more wide discussion about general principles.
* Pushing against things like making `?` idiomatically only about errors.

> This does not flow immediately from errors are values (semantically) and indeed it is not reflected in idiomatically written code (again, see ?). Errors can still be values semantically but the language can provide sugar that makes it feel less boilerplate-y.

Boilerplate is wildly subjective. For example: I'll always prefer an explicit `Ok(())` over invisibly suggesting success.

> No one said we should special case everything that programs usually contain, but we can special case some things that most programs contain to a large extent and is just boilerplate.

I wouldn't argue with that, but then I think we agree that ""It comes up a lot"" isn't by itself an indication that something needs to be added as language feature.",True,True
rust-lang_____rfcs_____2426,2018-05-04T14:24:00Z,True,rust-lang_____rfcs_____2426_____386617604,"@ssokolow 
> ""special-case errors less"" is a relative statement, so it can also be accomplished by making things that are currently error-specific more generally applicable, rather than by removing them.

Another thing I thought and that has come up is that it would be great if the first question were always ""can we improve Rust so the ecosystem can provide opt-in special casings?"" In these cases it would be about seeing what Rust needs to be able to do so the exception-like syntax can be provided by macros. I'm wondering if an extension of ""break with value"" might allow `try` and `throw` be implemented as macros with all the semantics people want.

This could have a nice side-effect of giving code generators via macros in the style of `nom` also some great new abilities, since it wouldn't only be for handling errors but for all manner of custom control flow.",True,True
rack_____rack_____1272,2018-05-04T14:36:24Z,True,rack_____rack_____1272_____186102698,"> If I understand your response you are answering yes to the question of whether or not a flush method should be added. Then in any application you wrote you would block until the write completes instead of making use of the on_drained callback. That is your choice of course.

I really find the inverted flow control of callback style programming horrible. So, I prefer `#flush` over an `#on_drained` callback. Callbacks = state machine spaghetti = hard to maintain/buggy code. It's just my personal opinion, FYI.",True,True
rust-lang_____rfcs_____2426,2018-05-04T14:37:32Z,True,rust-lang_____rfcs_____2426_____386621798,"**Hey you got your chocolate in my peanut butter!?**
I know the intention of the discussion is to focus on this RFC on it's own merits but allow me briefly step back to point out there is real genius here when considering this and the related structured error handling RFCs as a set: it takes the familiar structure commonly associated with exceptions and solves the emergent complexity that makes exception safety guarantees so hard by replacing exceptions with manual propagation of errors as values. It's the best of both worlds, is to my knowledge unique among popular languages and makes the whole greater than the sum of the parts.

This sort of thing is Rust's secret sauce I think - taking common problems experienced in other languages, retaining their strengths while finding innovative ways to make them safe and harder to screw up like using pointers safely, and now, error handling. Safe Error Handling is another compelling sales point for the Rust language to the huge pool of C++ and Java programmers.

** Is throw expr == return Err(expr) ?**
I've noticed a number of comments along the lines of ""return Err(expr)"" being equivalent to the throw being discussed, so I thought I'd point out a post that got buried waay back from Niko Matsakis where he points out that the expansion is more complex and solves (at least) a paper cut using the language.

https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386079005",True,True
rust-lang_____rfcs_____2426,2018-05-04T14:49:53Z,True,rust-lang_____rfcs_____2426_____386625541,"@Centril
> This does not flow immediately from errors are values (semantically) and indeed it is not reflected in idiomatically written code (again, see ?). Errors can still be values semantically but the language can provide sugar that makes it feel less boilerplate-y.

I think the main concern I have here is the one that I saw expressed about binding modes recently. We have to be very careful about adding convenience things that seem like mysterious ""do what I mean"" behaviours to newcomers who already have enough on their plate internalizing Deref coercions and borrow checker semantics.

For that reason, I always approach efforts to reduce boilerplate very cautiously.

To try to flush out any subtle misconceptions of my perspective, I'll address some of my concerns by going through the ""points in favour"" section of the RFC directly:

1. > However, currently, when you write logic such as: [...] the unhappy path is not particularly differentiated from the happy path in terms of syntax.

    I fundamentally disagree with this being a justification for a `throw` keyword. Happy and unhappy paths are two different kinds of return and I firmly believe that adding a special `throw` keyword in place of a `return Err(...)` with generic-friendly boilerplate is a flawed solution.

    Looking at the ""rasing the syntactic component of ""errors as values"""" and ""But what about the success case?"" sections just further convinces me that, at best, this idea needs a *lot* more discussion before we do anything more permanent than reserving the keyword.

2. > As a hypothetical extension, this can be further improved upon the future with Ok-wrapping `try fn`s.

    This comes across as a statement of potential intent to use this as a foot in the door to bring in the elements of the Pre-RFC that I found so alarming.

    It would also make it more difficult for me to scan other people's code, since `Ok(...)` makes it easier for me to scan for return paths.

3. > Terser code in generic contexts

    Let's assume that this is `throw`'s primary purpose for a moment, so it can be discussed in isolation.

    If its intent is to avoid having to type out complex type-conversion boilerplate, that intent should be admitted as such and it should be accomplished in a way that doesn't do as much to conflate mechanism and meaning.

    Also, if `throw` provides special conveniences not granted to other types, it's not unreasonable that people under the pressure of deadlines or not yet inculcated into the Rust culture would abuse `R: Try` or, if it's unstable, `Result<T,E>`, with non-Error `E` types in order to take advantage of those conveniences.

    If the primary goal is a less boilerplate-y return syntax for the error case in the presence of generics, then we should design a less boilerplate-y return syntax for generics that can be used in as wide a range of situations as possible.

4. Uniform support for early unhappy returns to functions and `try { .. }`

    I see the appeal in the context of `bail!`, but it hasn't been established that a better solution isn't waiting to be identified and, for a hypothetical demand like this, I don't think we should be in a rush to enshrine a new keyword in the language.

5. > The existence of `bail!` shows there's a need

    The question is whether there's *enough* of a need to justify a whole new keyword.

    One could argue that the existence of the `error!`, `warn!`, `info!`, and `debug!` macros in the `log` crate show a similar degree of insufficiency in the language with regard to output.

6. > Increasing familiarity

    This is actually one of my biggest worries, because it feels as if the desire to make Rust more familiar may be one of the things encouraging the ""special-case error returns"" approach, rather than, for example, my suggestion to look at generic-friendly ""improved `return`"" options that aren't merely limited to the unhappy path.

    (ie. Rather than identifying the best solution, then seeing how to teach it to new Rust programmers, I worry that this is being corrupted by looking for a way to shoe-horn in some sufficiently familiar variation on design elements that Rust decided against... similar to if we were to be too hasty to come up with an alternative to OOP inheritance.)

7. > Erasing dichotomies

    This point feels a little too much like hollow, feel-good marketing speak to me, speaking to my emotions rather than my rationality.

8. > The time to reserve is now

    Given that we can always change our minds later, I have no problem with merely reserving the `throw` keyword now, but continuing the discussion.",True,True
rust-lang_____rfcs_____2426,2018-05-04T14:55:33Z,True,rust-lang_____rfcs_____2426_____386627257,"@phaylon 

> Another thing I thought and that has come up is that it would be great if the first question were always ""can we improve Rust so the ecosystem can provide opt-in special casings?"" In these cases it would be about seeing what Rust needs to be able to do so the exception-like syntax can be provided by macros. I'm wondering if an extension of ""break with value"" might allow try and throw be implemented as macros with all the semantics people want.
> 
> This could have a nice side-effect of giving code generators via macros in the style of nom also some great new abilities, since it wouldn't only be for handling errors but for all manner of custom control flow.

This sort of hypothesizing (or the fact that we have both `error-chain` and `failure` in the ecosystem) is a perfect example of why I don't want to be so hasty to get something `throw`-like in the language.",True,True
rust-lang_____rfcs_____2426,2018-05-04T15:35:54Z,True,rust-lang_____rfcs_____2426_____386639501,"An easy way to differentiate paths: indented unhappy, flat happy.",True,True
rust-lang_____rfcs_____2426,2018-05-04T15:46:46Z,True,rust-lang_____rfcs_____2426_____386642773,"@SoniEx2 If only that were true.

I've lost count of the number of cases where an algorithm was of the form ""Try several things, return as soon as one succeeds. If we reach the end, return failure.""",True,True
rust-lang_____rfcs_____2426,2018-05-04T15:48:12Z,True,rust-lang_____rfcs_____2426_____386643194,"@tomaka 

> I'd like to bring up the usual argument that introducing a new language construct always increases complexity. The more pure the language, the easiest it is to understand.
> 
> Therefore any benefit in introducing language features must clearly have a huge advantage over not doing it. This is clearly not the case here.

As they say ""every feature starts with -100 points and has to get 100 points in order to get implemented.
",True,True
rust-lang_____rfcs_____2426,2018-05-04T16:12:23Z,True,rust-lang_____rfcs_____2426_____386650068,"@phaylon 

> I'd disagree here, but I think that's a point of fundamental difference. To me, `?` is about the `Option` or `Result`, not the wrapped value.

No, I agree. `?` is about some sort of partiality monad (e.g `Result`).
But `Result` and `Option`s still are a class of types for which Rust provides syntactic sugar for.

> So, `?` is to me about sugar for behavior, while `fail` has an error association.

So I believe `throw` has less of an error association.

> But for the record, I wouldn't mind `?` not auto-converting types and instead have an `err_into` on `Result`.

This is backwards incompatible.

> Things can change in the future. That's the whole point of editions.

They can, but removing language features costs a lot, and so the feature to remove must be really problematic.

> It's about:
> + A more wide discussion about general principles.

We use RFCs for that and we've already accepted `?`; This suggests a different general principle.

One important general principle to have, I think, is **consistency**.

> Boilerplate is wildly subjective. For example: I'll always prefer an explicit `Ok(())` over invisibly suggesting success.

No one is suggesting taking away the possibility of writing `Ok(())`.
Boilerplate to me is when you repeat things that are unimportant to the structure of what you want to say, over and over.

@ssokolow 

>  I think the main concern I have here is the one that I saw expressed about binding modes recently.

The semantics of `throw expr` seem fairly obvious to me. I don't think there's anything mysterious going on and it is quite familiar.

> I fundamentally disagree with this being a justification for a `throw` keyword.

Well; We're not going to find consensus on that one. I disagree with you completely.

> This comes across as a statement of potential intent to use this as a foot in the door to bring in the elements of the Pre-RFC that I found so alarming.

It is an idea to entertain (which I like personally). `throw expr` works fine independently of it.
I don't think early-return Ok-wrapping is that common.

> Let's assume that this is `throw`'s primary purpose for a moment, so it can be discussed in isolation.

This assumption is incorrect.

>  inculcated into the Rust culture would abuse `R: Try`

I don't know what that Rust culture is... Personally, coming from Haskell, I usually write the most general type, so I don't see this as abuse.

> I see the appeal in the context of `bail!`, but it hasn't been established that a better solution isn't waiting to be identified

I can't prove a negative like this and we are discussing whether `throw / fail` is a good solution right now.

> One could argue that the existence of the `error!`, `warn!`, `info!`, and `debug!` macros in the log crate show a similar degree of insufficiency in the language with regard to output.

The difference here is that the semantics of those macros are highly specific to applications.
Meanwhile, `throw expr` is a general feature that is useful for all applications.

> Rather than identifying the best solution, then seeing how to teach it to new Rust programmers, I worry that this is being corrupted by looking for a way to shoe-horn in some sufficiently familiar variation on design elements that Rust decided against...

I think this is the best solution. But you are free to disagree.
The mechanism proposed is tried and tested in languages which also have the *errors as values* philosophy such as Haskell.

> This sort of hypothesizing (or the fact that we have both `error-chain` and failure in the ecosystem) is a perfect example of why I don't want to be so hasty to get something `throw`-like in the language.

I'm not advocating that we should be hasty. We can take as much time as we need on nightly to experiment.

@Pzixel

> As they say ""every feature starts with -100 points and has to get 100 points in order to get implemented.

I am critical of this phrasing and in particular re-stating it all the time.

+ it sounds like an attempt to quantify, but ""100 points"" is not very meaningful.
+ we already always take in the fact that all new language features should have major benefits.
+ every feature should not ""start with -100 points"", some should start with -1000, and some -10, and some 0. The larger the addition to the language, the more it needs to show its benefits.",True,True
rust-lang_____rfcs_____2426,2018-05-04T16:20:24Z,True,rust-lang_____rfcs_____2426_____386652257,"@Centril this phrase is easy to understand, it just shows that feature should be very useful, and then a little more. And reading your ""some features starts at 0"" it's clear that you didn't get this idea.",True,True
rust-lang_____rfcs_____2426,2018-05-04T16:26:20Z,True,rust-lang_____rfcs_____2426_____386653799,"@Centril
I don't see a point in continuing. I don't see `?` as specific to error handling, so I don't see it as an argument for adding special cased language extensions. I understand that you disagree. However, referring to `?` won't convince me of the need for exception like constructs.

However, I do get the feeling that the recent error specific RFCs are pushing towards a Rust without `Ok`, `Err` and `Some`. For example, an auto-converting `try` won't allow me to default a block to `None` easily.

I also want to note that the recent RFCs have been feeling less like discussions about if something should be added. They feel more like write-ups about what will be added with discussions giving some possibility of resistance. I stress the word *feel* here of course.",True,True
rust-lang_____rfcs_____2426,2018-05-04T16:49:44Z,True,rust-lang_____rfcs_____2426_____386661120,"@Pzixel I don't mean to get too off-topic, but It is saying a lot more. It says that every feature needs to be as useful. In practice, features that are larger need more motivation and conversely features that are smaller in scope need less motivation.

@phaylon 

> They feel more like write-ups about what will be added with discussions giving some possibility of resistance. I stress the word feel here of course.

I think the feeling is wrong. :) The discussion here will result in a change in this RFC's proposal.",True,True
rust-lang_____rfcs_____2426,2018-05-04T16:58:34Z,True,rust-lang_____rfcs_____2426_____386663489,"@Centril 

> So I believe throw has less of an error association.

I think it has too strong an association with exception-based control flow, which readers would likely translate to an error assocation when paired with the understanding that Rust doesn't have exceptions.

> Boilerplate to me is when you repeat things that are unimportant to the structure of what you want to say, over and over.

This is a subjective thing. For example, a lot of the things CoffeeScript considers boilerplate, I consider to be essential to ensuring it's easy for a human to understand how the compiler will parse something.

> The semantics of throw expr seem fairly obvious to me. I don't think there's anything mysterious going on and it is quite familiar.

I'm talking about how newcomers would perceive the proposed ""easier to write generic returns"" facet. Without that, I see `throw` as having so little value as to have no chance at all of being included.

> Well; We're not going to find consensus on that one. I disagree with you completely.

Not a problem. My main reason for mentioning it was so that we didn't waste time spinning our wheels on an irreconcilable point of disagreement.

> It is an idea to entertain (which I like personally). throw expr works fine independently of it.
I don't think early-return Ok-wrapping is that common.

As I mentioned in an edit almost immediately after posting that, I'm also very concerned about Rust winding up with a ""proper solution"" and then the older `throw`, which feels at odds with it and may not compose well with it, but has to be kept around for legacy reasons.

(The #1 thing I'm trying to anticipate and avoid in all RFCs is Rust turning into something like C++, where the language has become so complex with various features that may or may not work smoothly with each other that it's advised to pick a subset and stick to it.)

> This assumption is incorrect.

That's why I said ""for a moment"". It was just an overly flowery way of saying ""Let's examine the merits of this piece on its own"".

> I don't know what that Rust culture is... Personally, coming from Haskell, I usually write the most general type, so I don't see this as abuse.

The most relevant aspects would be the definition of idiomatic code and the mental catalogue of what algorithms to prefer and avoid in order to write code that will be easy to maintain and extend in the future.

> I can't prove a negative like this and we are discussing whether throw / fail is a good solution right now.

OK, let me rephrase that. I strongly believe that `throw` / `fail` has been rushed toward experimental implementation as an idea and more time is needed to brainstorm and discuss alternatives with more general applicability.

Implementing it, even in nightly, at this stage, could unreasonably bias opinion in its favour.

> The difference here is that the semantics of those macros are highly specific to applications.

OK, then. *Some* form of in-`std` logging analogous to how the `assert` family of macros are in `std`. My point is that I don't find the argument very persuasive when taken in context with previous decisions about how deeply each idea should be integrated into the language.

> The mechanism proposed is tried and tested in languages which also have the errors as values philosophy such as Haskell.

True, but there are a *lot* of differences. For example, pervasive lazy evaluation, idioms built on the assumption of a garbage collector, syntax and APIs heavily wedded to currying and partial application, etc.

> I'm not advocating that we should be hasty. We can take as much time as we need on nightly to experiment.

As I mentioned earlier, I think getting it into nightly this quickly would be hasty as using something risks acclimatizing people to it to the point that consistency with something familiar and aversion to discarding something that seems ""good enough"" starts to impair one's ability to consider alternatives.

> I also want to note that the recent RFCs have been feeling less like discussions about if something should be added. They feel more like write-ups about what will be added with discussions giving some possibility of resistance. I stress the word feel here of course.

This. Regardless of whether it's intended, I got this sense from the Pre-RFC, which made me panic a bit, and I also feel a worrying undercurrent of it here. That's not conducive to good design and a healthy RFC process if it spreads.",True,True
rust-lang_____rfcs_____2426,2018-05-04T18:04:48Z,True,rust-lang_____rfcs_____2426_____386686853,"@Centril @ssokolow @phaylon 

These massive strings of point-for-point arguments are *very* hard to read, and they're not really introducing anything new to the discussion. It very much feels like the points that are going to be made *have been made.*

Also, because these keep coming up:

`?` (and now `try` and `throw) *are* primarily for error handling; this is why they were introduced and this is the vast majority of their use cases. That they are useful for other scenarios does not make it a bad idea to make them work well for error handling.

Concern about RFCs being ""write-ups about what will be added without discussions"" is unwarranted. The discussion is happening! That's why there are internals threads *and* RFC threads!",True,True
rust-lang_____rfcs_____2426,2018-05-04T18:17:25Z,True,rust-lang_____rfcs_____2426_____386690110,"@rpjohnst 
First off, I agree most things have already been stated, either here or elsewhere.

> ? (and now try and `throw) are primarily for error handling; this is why they were introduced and this is the vast majority of their use cases. That they are useful for other scenarios does not make it a bad idea to make them work well for error handling.

I disagree that they *should* be primarily regarded as error handling constructs. I have no problem with things *also* working well for error handling. Just wanted to clarify that.

> Concern about RFCs being ""write-ups about what will be added without discussions"" is unwarranted. The discussion is happening! That's why there are internals threads and RFC threads!

I didn't say *without* discussion. I'm just communicating that to me it seems the discussions are starting from the wrong point. Compare ""Why should this go in"" with ""Why shouldn't this go in"".",True,True
rust-lang_____rfcs_____2426,2018-05-04T19:42:55Z,True,rust-lang_____rfcs_____2426_____386712363,"`?` is about value propagation. Rust's Result uses Ok and Err, other languages use Left and Right. And then there's this: (hypothetical, but not far off)

```rust
fn find_inventory(w: World, p: Pos) -> Option<Inventory> {
    w.get_block(p)?.get_entity()?.get_component<Inventory>()
}
```

Note how it's not being used for error handling, but to propagate a value (or lack thereof).",True,True
SuperDARN_____rst_____153,2018-05-04T20:52:53Z,True,SuperDARN_____rst_____153_____186100761,This pull request contains one final set of bug fixes for IDL/DLM compatibility in the AACGM-v2 software that was missed in #149.,True,True
rust-lang_____rfcs_____2426,2018-05-04T21:06:41Z,True,rust-lang_____rfcs_____2426_____386735215,"Exceptions seem like such a good idea, but every grown up system I’ve
worked on, I find that we need to treat the errors as a form of data to be
able to put them in context. If it should never hapen we have panic!, but
if it can error it is much nicer to have a Result.

Really like the way Rust currently handles errors.

On Thu, 3 May 2018 at 12:34, Soni L. <notifications@github.com> wrote:

> throw expr;
> Err(expr)?;
>
> look, they're the same length!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386265875>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAxEiA0bZewGcIov-10UDtrEDAjiIyrbks5tuutbgaJpZM4TtWd1>
> .
>
",True,True
rust-lang_____rfcs_____2426,2018-05-05T05:49:26Z,True,rust-lang_____rfcs_____2426_____386781830,"@joshtriplett 

> I don't think I'd ever use ""exception-safety problems"" to describe scenarios where you should use `?`.

To try to elaborate on what I meant by that, take a look at `Flatten::try_fold`

https://github.com/rust-lang/rust/blob/5092c6b01acbff60935a5e6d84f83b6c73c1ca5e/src/libcore/iter/mod.rs#L2658-L2683

Compared to `Flatten::fold`

https://github.com/rust-lang/rust/blob/5092c6b01acbff60935a5e6d84f83b6c73c1ca5e/src/libcore/iter/mod.rs#L2686-L2693

What's all the extra code for?  Essentially ""exception-safety"": Like how in C++ one needs to understand what can throw and ensure your invariants are maintained if something throws, writing this code I needed to look at all the ""throwing"" functions called -- conveniently marked with `?` sigils -- and ensure that the iterator is left in a coherent state.

To me it's the same problem, just easier to deal with thanks to 1) them being explicitly marked and 2) it being easy to delay the throwing by putting the result in a variable and `?`ing it later.

(I like @ibkevg's ""[chocolate in my peanut butter](https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386621798)"" phrasing :heart:)

---

@Pzixel 

> Look at these examples [...] Is it better in any way?

I think the comparison is missing what I would consider the more obvious way:

```
if condition {
    throw Foo;
}

Ok(Bar)
```

This is the same sort of ""guard clause"" philosophy that is also seen with `assert!`, where once one hits badness, it's dealt with immediately, allowing the function to ""continue normally"" otherwise.

> `catch bar => { ... }`

Nothing like that has ever been proposed, so it's a fallacy of relevance.",True,True
rust-lang_____rfcs_____2426,2018-05-05T05:58:58Z,True,rust-lang_____rfcs_____2426_____386782238,"@scottmcm I still don't see the analogy you're trying to draw; the only thing this has to do with exceptions is that both handle errors. Yes, `try_fold` involves more code, and that code makes use of `?`. I still wouldn't describe it as ""exception-safety""; that's a term I'd use for things like using `finally` to make sure your code unwinds properly when a function you call throws an exception and unwinds the stack.",True,True
rust-lang_____rfcs_____2426,2018-05-05T06:23:34Z,True,rust-lang_____rfcs_____2426_____386783313,"Core language should stay as small as possible, otherwise it will become next C++ (in it's worst meaning).",True,True
rust-lang_____rfcs_____2426,2018-05-05T08:01:21Z,True,rust-lang_____rfcs_____2426_____386788301,"@scottmcm 

> I think the comparison is missing what I would consider the more obvious way:
```rust
if condition {
    throw Foo;
}

Ok(Bar)

```

Oookay, do you think it's much better than this?

```rust
if condition {
    return Err(Foo);
}

Ok(Bar)
```

> Nothing like that has ever been proposed, so it's a fallacy of relevance.

No, it's a nice illustration. If you ""throw"" something you have to ""catch"" it somewhere. If you wrap an object in `Err` and then match it in `Err` it clean and comprehensible. If you throw `Foo` then you should catch this `Foo`, if you then do match on `Err(Foo)` then probably it's a good signal that you're doing the wrong thing introducing this keyword.",True,True
rust-lang_____rfcs_____2426,2018-05-05T09:50:24Z,True,rust-lang_____rfcs_____2426_____386793794,"I already wrote about there being [value in things being self-descriptive](https://github.com/rust-lang/rfcs/pull/2386#issuecomment-384753988) before and I’m going to take a liberty to reference it here. If we introduce `throw`, `try` and other names from what essentially is quite a different error handling method in other languages, we risk in introducing confusion into people’s learning process. This is something that has been stated a number of times in this thread already. The most common counter-point I’ve seen is that if we document the feature sufficiently well, then it is going to be fine™. I will not repeat my points from the comment I linked above, but I want to present you my counter-counter-point to the ""going to be fine"" counter-point.

---

Go-the-language is a language that *prides* itself in being *simple*, *easy to learn* and *surprise free*. In this language it is accepted to return errors by value and there is no sugar for dealing with these errors. One of the reasons this language is fairly popular is that it being as simple as it is, it only takes half a week for developer with no prior familiarity with the language to become fairly productive with it. Among other things this means that it is fairly easy to sell the language to managers/investors/etc.

I’d like to think that Rust is in a fairly similar position syntax-wise at the moment. The syntax and concepts behind the syntax we currently have are fairly similar to the other languages, so most of the learning effort goes to figuring out what the *new* concepts such as lifetimes are and how to work with them.

If we end up adding `throw x` as an alias for `return Err(x)` (and similarly, `try`) will result in either of these:

* Teachers/mentors mentioning that `throw` and `try` is not the same compared to what students are used to, so they should read here and there about it;
* Students with prior familiarity with exceptions hitting this independently, trying to use it wrong, getting frustrated and spending time reading documentation/tutorials/books/stack overflow trying to figure out where they went wrong.

In context of companies this will translate into extra paid developer-hours, increase the adoption cost and make Rust harder to pitch, thus hurting its adoption. Are we really willing to pay the price for the low-impact sugar that `throw` is?",True,True
rust-lang_____rfcs_____2426,2018-05-05T11:03:02Z,True,rust-lang_____rfcs_____2426_____386797498,"@nagisa 

> If we introduce throw, try and other names from what essentially is quite a different error handling method in other languages, we risk in introducing confusion into people’s learning process.

Yes, but they are not *quite different* but slightly different. This similarity is arguably helpful for learning. I don't see how people can argue with such certainty on this point. We simply don't know empirically if it makes it easier or harder to learn.

But once learned, do these features make programs easier or harder to reason about? Would there be differences in productivity? These questions are also important. Perhaps more important.

> If we end up adding `throw x` as an alias for `return Err(x)`

`throw x` is *not* an alias for `return Err(x)`. This erroneous statement keeps coming back. Arguing that it is only an alias for `return Err(x)` seemingly reduces its potential value. Straw men are not conducive to a productive conversation. We all want the best for Rust.

",True,True
rust-lang_____rfcs_____2426,2018-05-05T11:05:30Z,True,rust-lang_____rfcs_____2426_____386797622,"I think it's been established beyond any reasonable doubt that a too-big-to-ignore number of people hold each of these opinions:

1) try/throw/catch/fail/raise all imply implicitly-propagated exceptions rather than any other mechanism for error handling
2) throw/catch specifically imply implicitly-propagated exceptions, but the others only imply error handling in general
3) try/throw/catch/fail/raise all imply error handling in general, but not any specific mechanism like exceptions

So rather than try to persuade each other that one of these three is ""the correct"" opinion, or merely asserting one is the most popular without any evidence, we should consider how these changes affect all three groups.

For example, while I'm still skeptical that `try {}` blocks are worth adding, renaming them from `catch {}` to `try {}` is an obvious win for group 2, and neither a win nor a loss for groups 1 and 3, which makes it a pretty clear net win overall.

By exactly the same argument, I think `fail expr` is a clear net win over `throw expr`, whether or not a throw/fail statement is worth adding at all.

I've seen very few comments that appear to actively favor `throw` over other keywords, and the few that do appear to be doing so solely because `throw` is a more popular keyword for error handling in other languages and that makes it more familiar. But that doesn't seem like a good argument to me since `throw` is more common only because implicitly-propagated exceptions are more common, and it's not like anyone will see `fail` and think it has nothing to do with error handling. Basically, I don't think choosing `throw` as the keyword makes any sense unless there's a fourth group with the opinion that ""throw/catch imply error handling in general, and the other keywords imply nothing at all"", which seems extremely unlikely.

-----

Incidentally, I do agree that it makes sense to reserve `try` and `fail` keywords now. It seems like everyone agrees on that point.

-----

Back to the actual semantics and functionality for a minute: As far as I can tell, the proposal is that `fail expr` does exactly the same thing as `Err(expr)?` if the return type is `Result<_,_>`. But the RFC instead defines it as `break 'to Try::from_error(From::from(expr))` where 'to is a magic label. Is it correct to say that the only difference in going from `Err(expr)?` to `fail expr` is that the latter works with other Try-implementing types like `Option`? The assumption that that is the only difference is a big part of why this seems like a very low impact sugar to me compared to `?`. Though, whether or not it's true, we should probably make the RFC much clearer about it so no one has to guess (in fact, as I typed this, the newest comments clashed on exactly this ambiguity!).",True,True
rust-lang_____rfcs_____2426,2018-05-05T11:41:18Z,True,rust-lang_____rfcs_____2426_____386799531,"> throw/catch specifically imply implicitly-propagated exceptions, but the others only imply error handling in general

If it helps, the deeper reasons I associate throw/catch with implicity-propagated exceptions are:

1. When something is thrown, there's a period when it arches over any walls, checkpoints, gates, or other barriers or flow-control mechanisms on the ground and exists ""in no specific person's hands"".
2. Outside of play, throwing things carries a strong connotation of either sloppy/dangerous workplace behaviour or intentional circumvention of security/safety/control measures, like walls.
3. Unlike in a program, in real life, you can't guarantee that something will be caught before you throw it.",True,True
rust-lang_____rfcs_____2426,2018-05-05T11:55:06Z,True,rust-lang_____rfcs_____2426_____386800299,"@ssokolow I think you are stretching metaphors from real life too much; The statement or expression form `throw expr` is widely known by most programmers; Therefore, it's meaning is independent of ""throwing"" in real life.

@Ixrec 

> Is it correct to say that the only difference in going from `Err(expr)?` to `fail expr` is that the latter works with other `Try`-implementing types like `Option`

Almost, but not quite. `Err::<!, _>(expr)?` would be more accurate.

@nagisa 

> If we introduce `throw`, `try` and other names from what essentially is quite a different error handling method in other languages, we risk in introducing confusion into people’s learning process. 

> Students with prior familiarity with exceptions hitting this independently, trying to use it wrong, getting frustrated and spending time reading documentation/tutorials/books/stack overflow trying to figure out where they went wrong.

I'd like to echo @rpjohnst's sentiments here on RFC https://github.com/rust-lang/rfcs/pull/2388#issuecomment-381309005.

> The concern that try would bring us ""too close"" to exceptions is basically that same concern brought back to life. But if someone uses try thinking it's going to work like Java, they'll either a) get a type error b) miss a panic or c) be right because they're thinking of `Result` / `?` as ""exceptions you can treat as values."" We already have a huge amount of material on how ""panics are not exceptions"" and I don't think `try` will really change that.

I just don't think the mentioned confusion and frustration is very likely for `throw` or `try { .. }`. When a Java programmer tries to use `throw expr` in Rust, in a function returning `Result`, I think they will either:
1. Be right, because they are thinking of `throw my_error` as initiating an exception to a `Result<_, typeof(my_error)>` returning function or a `try` block.
2. Get a good type error message with links to relevant documentation saying that either:
    1. the immediate `try { .. }` block does not support the error type they are trying to throw
    2. the function does not support the error type they are trying to throw

   The likelihood of errors can further be mitigated if we opt for a design outlined in [the prior art on exceptional syntax](https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md#paper-exceptional-syntax).

Not every language with unwinding exceptions are the same by the way; In Java, you have the `throws` clause which you don't have in C#. I think the differences from a user's perspective in learning will be similar.",True,True
rust-lang_____rfcs_____2426,2018-05-05T12:23:27Z,True,rust-lang_____rfcs_____2426_____386801879,"All these languages' `try { .. }` block act quite similarly @Centril so imho reusing `try` works.

Regardless, there is a burden for reinforcing that ""rust does not have exceptions"".  We shall not carry this burden with `try` so we should restrict `throw` and `catch` to unwinding scenarios.  I'd assume `match` will replace any prospective `catch` usages, but using `throw` would be bad pedagogically.  

I do think `fail ..;` looks nicer than `Err(..)?;` but agree this sugar may not carry its weight too.  Ain't hard to write:
```
macro_rules! fail { ($e:expr) => { Err($e)?; } }
```",True,True
rust-lang_____rfcs_____2426,2018-05-05T12:31:33Z,True,rust-lang_____rfcs_____2426_____386802341,"@Centril I'm saying that the concept of small things adding up applies both to learning a language like C++ and to grasping the mechanics and proper use of an individual feature.

Using a word like `throw` or `catch` increases the chance that a learner will get stuck on an incorrect assumption. (I'll readily admit to making that mistake at times. The brain is reluctant to double-check old short-cuts for mistakes, so it wastes a surprising amount of time and, in the worst cases, may require a visit to somewhere like `#rust` to make the person see what's right under their nose.)

@burdges Again, it's not merely a sugar for `Err($e)?`. 

As was just said a few comments ago, It's closer to `break 'to Try::from_error(From::from(expr))` where the `'to` label corresponds to the nearest `try` block.",True,True
rust-lang_____rfcs_____2426,2018-05-05T12:35:07Z,True,rust-lang_____rfcs_____2426_____386802606,"```rust
fn test(cond: bool) -> Option<Option<()>> {
    if cond {
        throw None;
    }
    Some(Some(()))
}
```

what would this do?",True,True
rust-lang_____rfcs_____2426,2018-05-05T12:42:14Z,True,rust-lang_____rfcs_____2426_____386803076,"@SoniEx2 `<Option as Try>::from_error` would probably be implemented to return `None`, ignoring the argument, so the code snippet would return `None::<Option<()>>` for `test(true)`.",True,True
rust-lang_____rfcs_____2426,2018-05-05T12:45:10Z,True,rust-lang_____rfcs_____2426_____386803224,"```rust
fn test(cond: bool) -> Option<Option<()>> {
    if cond {
        throw NoneError;
    }
    Some(Some(()))
}
```

what would this do?",True,True
rust-lang_____rfcs_____2426,2018-05-05T12:53:41Z,True,rust-lang_____rfcs_____2426_____386803731,"@Ixrec 

> Back to the actual semantics and functionality for a minute: As far as I can tell, the proposal is that fail expr does exactly the same thing as Err(expr)? if the return type is Result<_,_>. But the RFC instead defines it as break 'to Try::from_error(From::from(expr)) where 'to is a magic label. It's not at all clear that the definition needs to be quite this arcane. In particular, is it correct to say that the only difference in going from Err(expr)? to fail expr is that the latter works with other Try-implementing types like Option?

Then maybe we just should enhance type conversion rules to make `Err(expr)` work with types like Option without introducing extra keywords? Other scenarios benefits from this change too unlike `throw`. ",True,True
rust-lang_____rfcs_____2426,2018-05-05T13:08:15Z,True,rust-lang_____rfcs_____2426_____386804542,"@SoniEx2 Ask what `return Err(None)` would do in the context of `Option<Option<()>>`.
It would do nothing and give you a type error, since:
```rust
<Option<Option<()>> as Try>::Error == NoneError

None: Option<?T>

NoneError != Option<?T>
```

@nagisa That's a possibility, but not what happens today with `<Option<T> as Try>`. My preference would be to not move in the direction you consider here.

@ssokolow Whereas I think that `try { .. }`, `throw expr` and `?` together make for a neat, consistent package which is not that far removed from the role `try { .. }` and `throw` plays in Java save for some aspects of operational semantics and typing rules.

Specifically, the difference between Rust and Java would be that the latter propagates un-caught exceptions beyond the immediate `try { .. }` block and the function whereas the former requires the immediate `try { .. }` (or the function if there's no `try { .. }`) to handle the error type (including `From` coercions). I think it is possible by doing a recursive type search on `E_Target: From<E_Thrown>` to find the first `Try<E_Target = E_Thrown>` to bring us closer to erasing this difference between Java and Rust without giving up on *errors as values*. Of course, this is optional; we don't have to move in this direction, but the choice is available to us.

What we can't (and absolutely shouldn't change) is behavior wrt. function boundaries; if the function's type can't capture the error and there's no parent `try { .. }` block to the `throw expr` that can capture it, then it is game over.

We can help the user understand the differences we have, when they arise (thereby lazy-teaching them), mostly from well tailored error messages. The compiler will thus help you remember the differences where they occur. This can help save you from going to `#rust`. I also think this is a one-time setup cost; it will not manifest itself often unlike with lifetimes.

Having `throw` in Swift seems to work fine despite it having *errors as values*.",True,True
rust-lang_____rfcs_____2426,2018-05-05T13:12:51Z,True,rust-lang_____rfcs_____2426_____386804814,so you're saying None can become NoneError but NoneError can't become None?,True,True
rust-lang_____rfcs_____2426,2018-05-05T13:21:23Z,True,rust-lang_____rfcs_____2426_____386805332,"@Centril the interesting differences are mostly outside the function in which `throw` expression is invoked, rather than inside of it. No current mechanism other than `must_use` will even give us a chance on showing any diagnostic indicating a misuse. And the must_use itself can be easily hidden by e.g. `--cap-lints` that gets applied to dependencies.

I showed an example on IRC which I will expand here. Imagine this unfolding in a pre-existing code-base and the student learning-by-doing (which is fairly common in corporate IME):

```rust
enum MyNicerResult { 
    MyOk(...),
    MyErr(...),
} // created because of coherence or whatever, MyOk/MyErr are in prelude
 // note the not necessarily accident lack of #[must_use]
impl Try for MyNiceWrapper { ... } // plus various other common impls

fn banana() -> MyNicerResult {
    ...
    // A newbie developer gets an easy task to make this function more fallible
    // so they add
    // if error_has_occured { throw ""error has occured"" }
    ...
    MyOk(...)
}

fn peach () -> MyNicerResult {
   banana(); // called for side effects only
   MyOk(...)
}

fn apple() {
    let result = try {
        ...
        peach()?;
        ...
    };
    // adjust the handling code here to take the new error thrown by `banana` into account
    ...
}
```

The student may very well assume that whatever they thrown in `banana` will show up in `apple` (that’s what would happen in any language with exception-based error handling), but that won’t be the case in Rust. The compiler can’t possibly inform the student of any mistake either (at least I can’t think of any way for it to do so) – the code’s entirely valid. Type system will not help here.

Now one might argue that perhaps the student should’ve used `return MyErr(...)` instead, because there’s no `try` anywhere within `banana`, but what do *they* know? They saw `throw` somewhere in the code, they recalled having something similar in C++/Java/C#, they assumed the similar semantics and they wrote wrong code.

I hope I managed to express my worries about different semantics sufficiently well this time around.",True,True
rust-lang_____rfcs_____2426,2018-05-05T13:56:44Z,True,rust-lang_____rfcs_____2426_____386807424,"So personally I think the scenario is unlikely for a beginner. Starting with:

```rust
impl Try for MyNicerResult { ... }
```

I don't think a beginner would roll their own `Try` type. However, at the point where a beginner is thrown into such an existing code-base, they should have already read *[Recoverable Errors with `Result`](https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html)* (which would also explain `throw`) or some equivalent resource. If they haven't, they will have a hard time understanding Rust as it is today in general.

Not having `#[must_use]` on such a type is yet more unlikely (but possible). If `#[must_use]` isn't there in the existing code base, then either it is OK to ignore the thrown error, or the author of the code base made a design mistake and `#[must_use]` should have been there.

Either way, we can experiment with this and gain experience.",True,True
rust-lang_____rfcs_____2426,2018-05-05T14:28:50Z,True,rust-lang_____rfcs_____2426_____386809498,"@Centril

If this preference for `throw` over something like `fail` is about similarity to keywords in other languages, why are you so stuck on `throw` rather than `raise`?

`raise` is used in languages like Python and isn't as problematic because it lacks the troublesome real-world connotations and, for a user who is familiar only with an exception-less language like C, `raise` may call to mind a relationship to `return` since you're ""sending the value up the stack"".",True,True
rust-lang_____rfcs_____2426,2018-05-05T14:39:54Z,True,rust-lang_____rfcs_____2426_____386810200,"@ssokolow 

> If this preference for throw over something like `fail` is about similarity to keywords in other languages, why are you so stuck on `throw` rather than `raise`?

I am not stuck at all.
I would not mind any of `fail`, `throw`, `raise` (*and I've been saying so consistently*),
but it is my impression is that `throw` has more consensus within the lang team than `raise` does.

You are also the first I know to propose `raise` for this RFC.
I discuss `raise` in the [prior art](https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md#this-mechanism-exists-in-many-languages) and the [rationale](https://github.com/Centril/rfcs/blob/rfc/throw-expr/text/0000-throw-expr.md#choice-of-keyword).
I'd say that `throw` is simply more than twice as familiar than `raise`.
It seems to me that *""raise an exception""* is even more tied to exception handling ;)",True,True
rust-lang_____rfcs_____2426,2018-05-05T16:03:53Z,True,rust-lang_____rfcs_____2426_____386815707,"> (and I've been saying so consistently),

I apologize then. I'd overlooked that.

> It seems to me that ""raise an exception"" is even more tied to exception handling ;)

Not necessarily and that's not inherently a downside.

1. The real-world connotations of ""throw"" give it a direct connection to breaking out of the normal control flow, regardless of whether you call it raising an exception, `goto`, or whatever else while the details which separate exceptions from ""special language-blessed sugar for early return on error"" tend to be something that ""code monkey"" programmers may go their whole careers without pinning down. I'm honestly not sure whether `throw` or the general concept of an exception is more strongly tied to the idea of implicit error return.

2. There are various things that get raised in formal but otherwise day-to-day writing. For example, a key part of the RFC process is to raise raise concerns, complaints, objections, and issues.

> Ah, this is the reason why I thought `fail` was a bit weird, but couldn't put into words why. Thanks.

No problem. Natural language and how it relates to programming intuition are my areas of strength that seem to overlap the least with others here, so I try to help out whenever possible.",True,True
rust-lang_____rfcs_____2426,2018-05-05T16:59:52Z,True,rust-lang_____rfcs_____2426_____386819723,"Regarding the use of ""raise"" instead of ""throw"": there is also precedent for ""raise"" in Ada.

Used in safety critical software such as defence and aerospace, the things Ada and Rust value actually align pretty well. As an aside, it's also interesting to note that Ada has a surprisingly Rust match-ish flavour when it comes to handling exceptions:

```
-- Ada language example of exceptions being raised and handled in the same function
procedure excep3  is 
    Invalid_Data: Exception;
    n: integer;
begin
    loop
        put(""Enter an even number less than 1000, negative to quit:"");
        get(n);
        if n >= 1_000 then
            raise Invalid_Data;
        elsif n mod 2 = 1 then
            raise Invalid_Data with ""Number must be even!"";
        end if;
        exit when n < 0;
        put_line(n'img);
    end loop;
exception
    when e: Invalid_Data =>
        put(exception_name(e));
        put("".  Data was not valid!  "");
        put(exception_message(e));
    when e: Others =>
        put(""Something unexpected happened!  "");
        put(exception_name(e));
        put(exception_message(e));
end  excep3;
```",True,True
rust-lang_____rfcs_____2426,2018-05-05T17:46:39Z,True,rust-lang_____rfcs_____2426_____186268009,"@Centril I think my rigorous reason is I don't like introducing new names ""out of thin air."" Every other label has its name chosen by the source code- I would be much less bothered by some kind of `'my_label: fn f() { ... }` or `'my_label: try { ... }` than I am by introducing `'fn` or `'try` as ""special"" names.

A similar-but-different situation came up in https://github.com/rust-lang/rfcs/pull/2115, where people felt wary about allowing the source code to introduce names without some primary declaration point. But in that case, the source code is still the thing determining the name- you write the same name in two places and they mean the same thing. Labels inherently have a ""declaration"" point, but the same reasoning applies- *you* write the name down in *both* places, *as a label*.

(@squishy-clouds `'static` is not a label at all- it's a lifetime, and further kind of a ""monoidal identity element"" like `0` or `1` or `[]`, so it gets a bit of a pass here.)",True,True
rust-lang_____rfcs_____2426,2018-05-05T18:24:05Z,True,rust-lang_____rfcs_____2426_____386825368,"I'd like to expand on what I said in https://github.com/rust-lang/rfcs/pull/2426#issuecomment-385778639, about an uneasiness around introducing too many ad-hoc `return`/`break`/`continue`-alikes. @nagisa's comparison to Go's simplicity in https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386793794 is related and very compelling, though I'm not worried about similarity to exceptions.

I am *increasingly* worried about `throw`'s impact on language ""size."" I think we should step back and consider not just the case of ""I need to early-exit this `try` block with an error,"" but how this makes the system itself feel as a whole. If we add a bunch of unconnected features, then no matter how well they solve the problems they target, we still wind up with a giant ""design-by-committee"" mess.

The problem with `throw`, then, is that it doesn't fit well with all of the things we might want to do in this space:
* `try` has `Ok`-wrapping, but this is currently very narrow- it only applies to the block's tail expression. The logic for performing a fallible operation quite often includes early returns, of both failure *and* success types.
* Functions that return `Result` don't have `Ok`-wrapping. Extending `try` blocks to `try fn`s feels likely to avoid the mess I'm worried about, but on its own only exacerbates the previous problem because functions are much more likely to early-return than blocks.
* We already have a set of early-return tools whose responsibilities feel fairly well-partitioned, and battle-tested across countless languages. Adding `throw` as-is leads to a lot of overlap, particularly with `break`-with-value, which feels like the canonical expression-based early-return.

The most coherent way to look at ""Rust's error handling story so far"" comes from the interaction between normal data+control flow on one hand, and `try`+`Ok`-wrapping+`?` on the other:
* If you take a non-erroring block and wrap it in `try { .. }`, its type changes from `T` to `Result<T, _>` (or rather `impl Try<Ok=T>`), and everything else remains the same.
* If you take an erroring expression and add `?` to it, its type changes from `Result<T, _>` (or `Try` again) to `T`, and it can then be used in a non-erroring block.

Together, these let people separate the ""happy path"" from the ""error path,"" while retaining the benefits of an expression-based language. However, there are a few holes:
* You can use `?` not only in `try` contexts, but also in functions returning `Result`. I see this as a slight historical accident, stemming from the need to get `?` before working out the entire `try` story. It's not a huge deal, and on the whole I think it's a good thing, but it has the potential to make a mess if we don't keep it in mind.
* Early return is not handled *at all*. `return`s and `break`s *aren't* encapsulated by their containing `try` context, but rather ""see through"" it and must perform any `Ok`-wrapping and error conversion themselves.
* We're not totally clear yet on how we want a particular `try` context to specify its `Try` implementation. So far this hasn't been a big deal, because the ""function returning `Result`/`Option`""-as-""ad-hoc try context"" already specifies it, again by ""seeing through"" what's actually going on.

Coming back to `throw`: it only solves a tiny piece of *one* of these holes, and it's not really extensible to solving any more than that. Just as we kept the module RFC as one unit, I'd like to keep error handling coherent. I don't want us to wind up with ""`throw`, plus its successful equivalent `break 'try`, oh except the successful equivalent in a `try fn` is just `return`, plus `try Result { .. }` to fix type inference, except `try fn`s just reuse their return type."" None of that feels great, the way `try`+`Ok`-wrapping+`?` does so far.",True,True
rust-lang_____rfcs_____2426,2018-05-05T18:26:34Z,True,rust-lang_____rfcs_____2426_____386825505,What is Ok-wrapping?,True,True
rust-lang_____rfcs_____2426,2018-05-05T18:27:38Z,True,rust-lang_____rfcs_____2426_____386825561,"@SoniEx2 A `try` block's tail expression is of type `T`, but the `try` block itself is of type `Result<T, _>`, so you don't write `try { .. Ok(success_value) }` but merely `try { .. success_value }`.",True,True
rust-lang_____rfcs_____2426,2018-05-05T18:28:51Z,True,rust-lang_____rfcs_____2426_____386825651,so you don't get to call a fallible function at the end of a try block?,True,True
rust-lang_____rfcs_____2426,2018-05-05T18:30:36Z,True,rust-lang_____rfcs_____2426_____386825736,"@SoniEx2 Correct- if the tail expression is a call to a fallible function, you use `?` on it just like you would anywhere else in the block. (Or rather, anywhere else in the block that you're not going to work with the `Result` directly.)",True,True
rust-lang_____rfcs_____2426,2018-05-05T18:34:26Z,True,rust-lang_____rfcs_____2426_____386825974,"That's absurd, thank you very much.",True,True
rust-lang_____rfcs_____2426,2018-05-05T18:51:03Z,True,rust-lang_____rfcs_____2426_____386826950,"@SoniEx2 Calling things absurd is not conducive to constructive discussion.

@rpjohnst Personally, I think Go's simplicity is nothing to be proud of; It trades the short term benefits of learning a language quickly against making programs easier to understand with higher-order constructs (sum types, generics, etc.). In particular, Go's design decisions seem at odds with Rust's here. Go's error handling is nothing like ours since it is based on products instead of sums and they have no equivalent to `?` sugar.

To me, `try { .. }`, `throw expr` and `expr?` don't feel unconnected at all; but enhance each other and provide a coherent system. Yes, there is no equivalent to `break 'try Ok(expr)`, but I think early-return Ok-wrapping is also more rare. I think `throw` makes the system more coherent, but let's not let the perfect be the enemy of the good.

Adding `try fn` would make the system even better, and I don't get why it would exacerbate the problem. If anything, more early returns in functions seem to motivate `try fn`. I think a good chunk of all functions in fact should be `try fn` (and the change is semver compatible from the POV of not changing the requirements at the call site of a function, assuming that the version of Rust has `try fn`).

Regarding `break 'label value`, it is something I hope to see little of in surface syntax; it should be hidden away in macros imo.

I would say that many things are in flux as you say regarding `Try`; so I would not want to rush the stabilization of `throw` and these things. We *should* try to make it as coherent as possible.",True,True
rust-lang_____rfcs_____2426,2018-05-05T21:15:17Z,True,rust-lang_____rfcs_____2426_____386835534,"Those specific features in Go are not really relevant here. The comparison was made to Rust *as it stands*- that is, *including* generics and sum types. The point is that Go (and, by extension, current Rust) is relatively *economical* and hangs together well.

The canonical example in the other direction is C++. Every feature in C++ is very well-motivated and a *lot* of design work goes into that language. But it's still very complex and messy! Features overlap with each other in purpose; features interact with each other in unexpected ways; the system as a whole is hard to really wrap your head around.

Much of your response seems to be precisely the sort of thing I'm objecting to- reasoning around individual features rather than their interaction:
* > early-return Ok-wrapping is rare

  That's fine, maybe we don't need it, but nobody has said anything about *why* that might be the case, *in the context of the whole error-handling system*.
* > I don't get why [`try fn`] would exacerbate the problem. If anything, more early returns in functions seem to motivate `try fn`.

  I think you misunderstood me. I said `try fn` specifically exacerbates ""the *previous* problem,"" i.e. ""`Ok`-wrapping applies only to a block's tail expression."" That is, `try fn` increases the demand for early-return `Ok`-wrapping, which we don't have.
* > Regarding `break 'label value`, it is something I hope to see little of in surface syntax

  Sure, I don't disagree with this either, *in isolation*. But this interacts poorly with the error handling story. For example, assume we take this chain of decisions: we want `try fn` so people don't have to double-indent their functions to get `Ok`-wrapping -> we want an early-exit `Ok`-wrapping statement like `pass` so people don't have to use two different ways of returning from `try fn`s -> oops, now we have a bunch of overlapping ad-hoc ways to exit functions and/or blocks.

So yes, absolutely we should try to make this as coherent as possible. IMO *we're not doing a great job* yet.",True,True
rust-lang_____rfcs_____2426,2018-05-06T15:39:07Z,True,rust-lang_____rfcs_____2426_____386888415,"@rpjohnst 

> Much of your response seems to be precisely the sort of thing I'm objecting to- reasoning around individual features rather than their interaction:

I would point to the RFC's text where I actually do reason about interactions, laws & general properties, etc. I don't want to repeat too much of my reasoning in there.

> That is, `try fn` increases the demand for early-return `Ok`-wrapping, which we don't have.

So now I am not sure that we mean the same by `try fn`.
What I mean by `try fn` is a function where the return type must satisfy `Try` and where `return expr` always `Ok`-wraps `expr`. In this scenario, `throw expr` fits very well. Of course, the question is if we want this system or not. I personally do, but many don't.

-------------------------------

That said; I have now made some changes to the RFC:
+ The RFC is essentially experimental.
+ Both `throw` and `fail` are reserved; this is the essence of what the RFC amounts to now plus some ideas on what those constructs *could* be.
+ Which one of `throw` or `fail` to experiment on nightly is left unresolved.",True,True
rust-lang_____rfcs_____2426,2018-05-06T15:54:47Z,True,rust-lang_____rfcs_____2426_____186294995,"@rpjohnst I don't think they would be so ""out of thin air"";

If the system of having special labels is applied out consistently per control flow block-form you could have:

+ `'fn`
+ `'loop`
    + `'while`
    + `'for`
    + maybe just merge these as one `loop`?
+ `'if`
+ `'match`
+ `'try`
+ `'async`
+ `'const` (maybe not?)

The goal of these are not to be used directly in people's code, but rather hidden away in macros so that you can invent new and interesting DSLs. The problem with having to explicitly declare the labels is that you have to pass them into the macros.",True,True
rust-lang_____rfcs_____2426,2018-05-06T16:29:17Z,True,rust-lang_____rfcs_____2426_____186295842,"Do we have any actual use cases for a generalized ""magic labels"" feature like this, even in DSLs? I've never heard anyone suggest any of these except as an implementation detail of a throw/fail macro.",True,True
rust-lang_____rfcs_____2426,2018-05-06T16:45:35Z,True,rust-lang_____rfcs_____2426_____186296257,"One use-case might be that if we had a `'try` built-in label that can be targeted by `?`, I think all of the other exception like syntax can be implemented by the eco-system (or even `std` if deemed worthy) as macros. That would allow for:

* People to use break-with-value and `?` with these blocks without auto-wrapping or any other additional functionality, basically keeping it as close to current control flow as possible.
* Experimentation with more exception like syntax on crates.io. Before things would settle that would also provide an explicit opt-in to specific semantics. Once things have settled, the functionality can simply be added to `std`. Since they would still be macros, there's still an opt-in to additional semantics like auto-converting a final result. Adjusting pieces of `std` also seems easier and more future proof than changing the language itself.

I'm wondering if it would make sense to put together a proposal for this path for the new exception like syntax extensions.",True,True
rust-lang_____rfcs_____2426,2018-05-06T16:52:24Z,True,rust-lang_____rfcs_____2426_____186296418,"> Do we have any actual use cases for a generalized ""magic labels"" feature like this, even in DSLs?

Not very concretely at least; Just hypothesizing ;)",True,True
rust-lang_____rfcs_____2426,2018-05-06T16:53:31Z,True,rust-lang_____rfcs_____2426_____386893089,"> What I mean by `try fn` is a function where the return type must satisfy `Try` and where `return expr` always `Ok`-wraps expr.

For the purposes of my argument, I split those two features apart- by `try fn` I only meant ""a function that `Ok`-wraps its trailing expression""; with early-exit `Ok`-wrapping as a separate feature.",True,True
rust-lang_____rfcs_____2426,2018-05-06T17:07:46Z,True,rust-lang_____rfcs_____2426_____386894104,"@rpjohnst OK; so we were not thinking of the same thing re. `try fn`; I was assuming that there would be no `pass` variant of `throw` and that `return` would just be the success variant in `try fn` (tho I entertained the notion [here](https://internals.rust-lang.org/t/pre-rfc-catching-functions/6505/54) but have since moved on) since no one has proposed reserving such a keyword.

",True,True
rust-lang_____rfcs_____2426,2018-05-06T17:27:53Z,True,rust-lang_____rfcs_____2426_____386896005,"Yes, sort of outcome is one example of what I'm worried about. Having `Ok`-wrapping early-exit for functions, using a pre-existing control flow mechanism, but then *not* having it for `try` blocks (or having it but with yet another new statement) is a mess. It shows that our current plans do not fit well with the existing language.",True,True
rust-lang_____rfcs_____2426,2018-05-06T17:37:45Z,True,rust-lang_____rfcs_____2426_____386896938,"@rpjohnst I'm also worried about the potential discrepancy wrt. `return` between `try { .. }` and `try fn`; therefore, I think we should avoid being hasty here and make sure that the end result is as coherent as we possibly can make it. 

I am not sure there exists an *""our""* in ""current plans""; I could personally see `return expr` in `try { .. }` meaning `break 'try Ok(expr)`; In this system, it would be 100% coherent, but I accept that many people will find the word `return` there jarring and that it perhaps therefore is too radical an approach.",True,True
rust-lang_____rfcs_____2426,2018-05-07T19:52:52Z,True,rust-lang_____rfcs_____2426_____186530175,"""fail"" doesn't seem like the right kind of word in terms of use of english. Consider: ""throw an error"", ""raise an issue"", ""return an error"", ""report a problem"". These all suggest an action taking place as a result of a failure. ""fail"" doesn't fit as well in this context, ""failed to grab the lock"", ""fail this code section"", ""fail this function"". It's more a statement that something went wrong than what action will be taken. e.g.
`// failed to open the file`
`raise ""bad file name"";`

My suggestion is to use ""raise"" as an alternative to ""throw"" instead of fail.",True,True
rust-lang_____rfcs_____2426,2018-05-07T21:03:58Z,True,rust-lang_____rfcs_____2426_____186550429,"Yes, [this was also pointed out](https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386809498) by @ssokolow:
> That said, I'm not a fan of `fail` either because the intransitive use of the verb comes to mind first for me, which makes it feel odd.

In this regard, `raise` or `throw` are better. :+1: ",True,True
rust-lang_____rfcs_____2426,2018-05-07T22:09:03Z,True,rust-lang_____rfcs_____2426_____387222130,"`pop`?

yes it conflicts with vec pop and stuff so just make it a macro I guess.

`pop!(NoneError);`",True,True
rust-lang_____rfcs_____2426,2018-05-07T22:59:06Z,True,rust-lang_____rfcs_____2426_____387232181,"Probably worth noting `bail` as yet another candidate, especially since `error_chain` and `failure` already have a `bail!` macro.",True,True
rust-lang_____rfcs_____2426,2018-05-07T23:02:13Z,True,rust-lang_____rfcs_____2426_____387232726,"@Ixrec Didn't include `bail!` (tho it is discussed in the RFC) because it would break those two crates, which seemed unwise ;)",True,True
rust-lang_____rfcs_____2426,2018-05-07T23:50:32Z,True,rust-lang_____rfcs_____2426_____387240880,"Also, when I hear bail, I think of two meanings:

1. An intransitive ""bail"" that you do when you're in a fighter plane that's ground-bound.
2. A transitive ""bail"" that's what you do with a bucket when your boat is filling with water.

...and, after a little more thought, the ""to pay someone's bail"" meaning.

Only the intransitive meaning feels intuitively relevant to this use case (and it's the one that the macro is referencing) and I can't think of a metaphor which makes sense for the transitive one.

(Putting the value in a metaphorical bucket and throwing it out of the function while you (execution flow) remain inside? That's more like `yield` for Python's generators than anything else.)",True,True
rust-lang_____rfcs_____2426,2018-05-07T23:55:48Z,True,rust-lang_____rfcs_____2426_____387241676,"@joshtriplett 

> I still don't see the analogy you're trying to draw; the only thing this has to do with exceptions is that both handle errors.

I think that if there are equivalent language constructs, equivalent things that need to be considered while using them, and they solve an equivalent problem, they're not different.

We could--completely back-compatibly--change Rust's ABI tomorrow so that anything returning a `Result` actually uses unwinding to do so.  That's even been semi-seriously been discussed, since it'd be more efficient in the `Ok` path and reduce the penalty for using large `Error` types.

> that's a term I'd use for things like using finally to make sure your code unwinds properly when a function you call throws an exception and unwinds the stack.

`try { foo() } finally { bar() }` can be spelt `let r = foo(); bar(); r?` in rust.  And that's exactly what I was thinking about for things like `*frontiter = Some(mid);` in the `try_fold` code.

---

@Pzixel 

> > Nothing like that has ever been proposed, so it's a fallacy of relevance.
>
> No, it's a nice illustration.

I have absolutely no problem with someone saying that `catch` doesn't pull its weight, or conversely that it must exist to make the proposal make sense.

But I do have a problem with it being dismissed by a manufactured-to-be-unhelpful syntax.  If you're going to argue against it, either use a [steelman](https://en.wikipedia.org/wiki/Straw_man#Steelmanning) or one of the things that has actually been proposed, like [the early version of 243](https://github.com/glaebhoerl/rfcs/blob/c62612508db617110d7cead92852f6e5e9e2272b/active/0000-trait-based-exception-handling.md#trycatch) or [one of the musings from the `try` RFC](https://github.com/rust-lang/rfcs/pull/2388?#issuecomment-379473795).

---

@rpjohnst 

> You can use ? not only in try contexts, but also in functions returning Result. I see this as a slight historical accident, stemming from the need to get ? before working out the entire try story. It's not a huge deal, and on the whole I think it's a good thing, but it has the potential to make a mess if we don't keep it in mind.

On this I agree with you.

I'm glad that `?` is on every place that re-throwing can happen, but right now `?` is also they way you opt-in to the ""continuing along is success (because errors are rethrow)"" model.  I like that `try` gives an explicit _block_-level opt-in to that model, which feels more appropriate than individual-method-call-level.  (This is also why I like ok-wrapping for `try` blocks: if nothing (re-)threw, it must be successful.)

So I'd be happy if eventually (at least 3 years, probably 6 or more, for the idiom shift, if ever) `?`/`try` worked like `await`/`async`:

- You don't need to use either of them.  You can always use other syntax or combinators instead.
- If you do want to use `?`/`await`, you need to be in an appropriate `try`/`async` block or fn.

> Just as we kept the module RFC as one unit, I'd like to keep error handling coherent.

Does this RFC moving to a keyword-reservation e-RFC sufficiently address those concerns?

I could absolutely imagine that an eventual RFC to finalize the semantics of these things would need to touch on more areas.  For example, maybe it'd disallow `return` in `try` blocks, the same way `return` is currently prohibited in `async` blocks.

> > early-return Ok-wrapping is rare
>
> That's fine, maybe we don't need it, but nobody has said anything about why that might be the case, in the context of the whole error-handling system.

I think the answer to this is largely the ""`?` model"" I mention above.  The core premise of `?` is that errors are re-thrown (exiting early) and success values are used to continue execution (_not_ exiting early).  So if one needs the opposite (continuing on errors or being done early on success), then there's no special syntax (`?`, `try`, ...) to help with that.

",True,True
rust-lang_____rfcs_____2426,2018-05-08T00:00:03Z,True,rust-lang_____rfcs_____2426_____387242345,can have `try { ? }` but not `{ ? }` I think that should be fixed somehow.,True,True
rust-lang_____rfcs_____2426,2018-05-08T00:02:11Z,True,rust-lang_____rfcs_____2426_____387242689,(honestly what's wrong with just having this whole thing as a built-in macro? `Err(expr)?; unreachable!();`),True,True
rust-lang_____rfcs_____2426,2018-05-08T00:17:26Z,True,rust-lang_____rfcs_____2426_____387245154,"@scottmcm 
> I think that if there are equivalent language constructs, equivalent things that need to be considered while using them, and they solve an equivalent problem, they're not different.

Right, but they're not equivalent language constructs and they don't have equivalent things that need to be considered while using them. That's the problem.

> We could--completely back-compatibly--change Rust's ABI tomorrow so that anything returning a Result actually uses unwinding to do so.

Not unless doing so implicitly stopped propagating at the first call not suffixed by `?`. By contrast, languages with exceptions often unwind through code that doesn't expect those exceptions.",True,True
rust-lang_____rfcs_____2426,2018-05-08T00:32:10Z,True,rust-lang_____rfcs_____2426_____387247377,"@scottmcm 

> But I do have a problem with it being dismissed by a manufactured-to-be-unhelpful syntax. If you're going to argue against it, either use a steelman or one of the things that has actually been proposed, like the early version of 243 or one of the musings from the try RFC.

I don't understand why you think I'm using a strawman argument, I just took the piece of code from ""Motivation"" paragraph which always show why exactly some feature is needed. I referenced it to show that I don't see this feature having enough value. If you think that there may be scenarios where this feature shines then, first of all, why it's not included in motivation part? Maybe review comment is required there then? Secondly, if so, please provide it so we can discuss.

Returning to the ""steelman"", I can only say **_onus probandi_**. I don't propose a change, so I don't have to argue why they shouldn't be added rather than we should argue why it _should_ be taken. It has been already emphasized by @phaylon in https://github.com/rust-lang/rfcs/pull/2426#issuecomment-386690110 . 

It looks to me like someone has already made the decision and now it should just look like everybody agreed on it, not like we are actually providing any significant feedback. The PR already has 51 downvotes with 8 upvotes, but it's going through approval process without problems and reconsideration and ""let's step backward and reexamine what do we have here"". That's strange.",True,True
rust-lang_____rfcs_____2426,2018-05-08T00:37:43Z,True,rust-lang_____rfcs_____2426_____387248149,"@scottmcm Yeah, you've pretty much captured my train of thought. To re-summarize:

Walking this RFC back to just keyword reservation, pending a more holistic RFC for the actual design, is great.

The (mostly hypothetical alternate-universe) idea of only allowing `?` in `try` blocks/fns is basically what I had in mind. (One other wild idea along the same lines: leave `?` for *outside* of `try` blocks, and make return-on-failure the *default* inside them. Basically [""implicit await""](https://internals.rust-lang.org/t/explicit-future-construction-implicit-await/7344) for the `try` context.)

As far as that actual design goes, prohibiting early-exit from try blocks feels like a promising direction to explore.",True,True
rust-lang_____rfcs_____2426,2018-05-08T01:41:29Z,True,rust-lang_____rfcs_____2426_____387257960,"here's an idea, why not use existing features to make new features?

why make everything a compiler thing?

we still have Box as a compiler thing, I also don't see any progress on moving away from that. (also I'm against box keyword because of this, but that's a discussion for another thread)

just give us a throw macro and be done with it. not everything needs a new keyword. use the power of the library.",True,True
rust-lang_____rfcs_____2426,2018-05-08T02:16:49Z,True,rust-lang_____rfcs_____2426_____387263211,"> here's an idea, why not use existing features to make new features?

I'm actually working on [a proposal](https://gist.github.com/phaylon/0e72af906f1144615d4ea0d46eccbc5b) that is similar to that. The idea would be to make sure Rust is powerful enough for all special error handling syntax to be implemented via macros by the ecosystem, and only go the language feature route once everything could be considered as a whole, and we know what works and what doesn't.

Hoping to start an internals discussion about this tomorrow.",True,True
rust-lang_____rfcs_____2426,2018-05-08T02:21:14Z,True,rust-lang_____rfcs_____2426_____387263860,"@rpjohnst I agree with your point that these related error handling RFCs would gain something by be treated considered as a whole. IMHO, it's when taken together that these really shine. Since this current RFC is about naming, one issue with looking at each of these try/throw/catch as separate is that it doesn't really allow us to see that value of the name “throw” is that it pairs with “catch”. You may catch what was thrown.

Also, funny I was just writing the same idea you just wrote about: ""I could even imagine in a try block where ? is done automatically on calls that return Result. Ie you only need ? outside of a try.""
That to me feels like it would a compelling feature/convenience of try blocks.

There's a quote I like from Chuck Pahlaniuk (the Fight Club guy): ""The tricking to forgetting the big picture is to look at everything close up."" Only partially applies here but I love the quote regardless LOL!",True,True
rust-lang_____rfcs_____2426,2018-05-08T02:24:47Z,True,rust-lang_____rfcs_____2426_____387264384,"@phaylon I ""like"" how we're being ignored by the main proponents of this RFC as if we're just line noise.",True,True
rust-lang_____rfcs_____2426,2018-05-08T02:28:34Z,True,rust-lang_____rfcs_____2426_____387264977,"@phaylon I think you have a cool idea there but the more I think about it, wouldn't that lead to fragmentation of the language? ie. there's almost a meta language that lets all proposed solutions work through macros.",True,True
rust-lang_____rfcs_____2426,2018-05-08T02:36:27Z,True,rust-lang_____rfcs_____2426_____387266077,"@ibkevg 
I don't really consider things implemented by macros fragmentation. Due to the common block marker they could even interoperate sensibly. For example, a `failure_syntax` crate providing things like `throw_err!`, `catch_failure!` or some context adjustment facilities would use the same `'escape` block target, and can interoperate with normal `catch!` and `throw!`. Since we already have the `Try` trait, that would also be a point of defragmentation.

We can still turn things into sanctioned core language if a winning strategy for extended error handling emerges.",True,True
rust-lang_____rfcs_____2426,2018-05-08T03:05:11Z,True,rust-lang_____rfcs_____2426_____387270180,"@phaylon do you think the effort to support creating macro-izable building blocks and then build different styles on top will just delay the inevitable clash of titans? It feels the differences here are philosophical rather than technical and those philosophical differences will still be there when the macros are able to be actually created. Also, my experience with code that is intended to be removed later is that in spite of best intentions to the contrary there's always something to do that's more important than removing later.

I actually wonder if it would be feasible+faster to write up 2-3 different and very opinionated full/holistic error handling styles/naming conventions that illustrate with example code how each would look and feel and work? It seems to me that something like this might accomplish 90% or more of what building macro support for prototyping would accomplish but in much less time and . Just thinking out loud here. I feel that @Centril has done a ton of good work here but perhaps this could relate to @rpjohnst 's thought to be explicit about how all these RFPs work together?",True,True
rust-lang_____rfcs_____2426,2018-05-08T03:11:03Z,True,rust-lang_____rfcs_____2426_____387270996,"@ibkevg 
> do you think the effort to support creating macro-izable building blocks and then build different styles on top will just delay the inevitable clash of titans? It feels the differences here are philosophical rather than technical and those philosophical differences will still be there when the macros are able to be actually created.

I think we'd certainly have more information at that point then, and can more easily assume the practicality of different solutions.

> Also, my experience with code that is intended to be removed later is that in spite of best intentions to the contrary there's always something to do that's more important than removing later.

I think that actually worked really well with `try!` which became `?` :)",True,True
rust-lang_____rfcs_____2426,2018-05-08T03:30:50Z,True,rust-lang_____rfcs_____2426_____387273728,"I propose a simple solution for those of us who dislike this feature: let's fork rust! (or at least stop using newer versions of rust.)

(also, @phaylon 's proposal could really stop fragmentation.)",True,True
rust-lang_____rfcs_____2426,2018-05-08T03:38:39Z,True,rust-lang_____rfcs_____2426_____387274742,"Well, personally my escape hatch would be a set of more aggressive lints simply deactivating things I don't want in my code :) That could also have such niceties as ""jumpy control flow needs labels if there's an `unsafe` in the `fn`"".

But that's getting off-topic.",True,True
rust-lang_____rfcs_____2426,2018-05-08T03:40:56Z,True,rust-lang_____rfcs_____2426_____387275032,I want my DSLs to be able to use `.throw()`,True,True
rust-lang_____rfcs_____2426,2018-05-08T03:46:01Z,True,rust-lang_____rfcs_____2426_____387275638,"@phaylon 
> I think that actually worked really well with try! which became ? :)

True. Out of curiosity, do you know how long it took from RFP to macro-ization to the point where try! was removed? I'm asking only because I think this RFP had hopes for inclusion in Rust 2018.",True,True
rust-lang_____rfcs_____2426,2018-05-08T04:09:36Z,True,rust-lang_____rfcs_____2426_____387278570,"I think you should also make an RFC to remove ""zero-cost abstractions"" from the home page, because the hidden cost associated with these RFCs is too damn high.",True,True
rust-lang_____rfcs_____2426,2018-05-08T04:45:41Z,True,rust-lang_____rfcs_____2426_____387282869,"You know, `return` sounds like a great keyw... Oh wait",True,True
DSharpPlus_____DSharpPlus_____281,2018-05-08T06:18:36Z,True,DSharpPlus_____DSharpPlus_____281_____186536363," Previously you were handed nulls.

Make sure you familiarize yourself with our contributing guidelines.

# Summary
Fixes the Issue of null audit roles

# Details
Not much, just checked for roles that don't exist.
 ",True,True
DSharpPlus_____DSharpPlus_____281,2018-05-08T07:43:52Z,True,DSharpPlus_____DSharpPlus_____281_____387314659,Please don't PascalCase locals.,True,True
rack_____rack_____1272,2018-05-08T12:00:22Z,True,rack_____rack_____1272_____387379194,"I have an initial implementation of the updated draft, placed in [iodine's 0.6.0 version branch](https://github.com/boazsegev/iodine/tree/0.6-stripped) (installable from source).

There's some features being re-written (such as pub/sub extensions, including Redis integration), but the core WebSocket/SSE and pub/sub API will work.

I think this would be enough to author a test application using a monkey-patched Rails...

@matthewd , any final changes / requests / tips before we start woking on a ""like-for-like benchmarking"" example app? How do you want to benchmark this? Should we use the [websocket-shootout approach](https://github.com/hashrocket/websocket-shootout/tree/master/ruby/action-cable-server)?",True,True
rust-lang_____rfcs_____2426,2018-05-08T12:17:57Z,True,rust-lang_____rfcs_____2426_____387383111,"@ibkevg 
No idea about the exact timelines. `try!` is still supported though currently. Also unsure what an RFP is :)

For the extended error handling things I was hoping the first iteration could happen in external crates, then maybe move to `std` either in the form of macros or syntax once the ecosystem had time to figure it out.",True,True
rust-lang_____rfcs_____2426,2018-05-08T12:44:00Z,True,rust-lang_____rfcs_____2426_____387389596,"> Also unsure what an RFP is :)

I'm guessing it's a typo for ""RFC"".

",True,True
rust-lang_____rfcs_____2426,2018-05-08T13:32:21Z,True,rust-lang_____rfcs_____2426_____387403176,"what about a contextual `break up expr;`?

```rust
if condition {
    break up Foo;
}
```

this also doesn't have associations with exception handling (:+1:) nor does it introduce new keywords (:+1:) yet it has the same expressive power as introducing new keywords (:+1:). (or if you want ""up"" as a new keyword just for this use-case, well, except for games and physics libraries I don't see why `up` would be used as a name. can always go with ""breakup"" as a keyword.)

in the future, we could even `break up None;` (actually you'd still need to specify `Option<!>`) instead of `break up NoneError;` (altho I prefer the latter since it doesn't have the kludgy `Option<!>`)",True,True
rack_____rack_____1272,2018-05-08T13:54:13Z,True,rack_____rack_____1272_____387410220,The Agoo develop branch is also compatible with the spec as described in the current state of this PR. Should make a versioned release later this week once the named pub-sub feature is completed.,True,True
mysqljs_____mysql_____1962,2018-05-08T13:58:15Z,True,mysqljs_____mysql_____1962_____387411600,"@dougwilson I've kept the option for providing a custom key padding, to allow users to exceptionally connect to a MySQL `8.0.4 RC` server. In any case, the default value is always `RSA_PKCS1_OAEP_PADDING` which means it will work, by omission, with the latest `8.0.11 GA` version.

I couldn't find a sane way to add an additional Travis CI test matrix for users with non-empty passwords though. I was constantly bumping into an authentication error (I believe it might be related to the `mysql` docker setup and environment variables mixup), but maybe you can give it a try.

Let me know if there is something else you would like to see in this PR. Otherwise, feel free to merge it! :wink: ",True,True
rust-lang_____rfcs_____2426,2018-05-08T14:00:08Z,True,rust-lang_____rfcs_____2426_____186737197,fun historical context: `panic!` was `fail!` before it was `panic!`.,True,True
rust-lang_____rfcs_____2426,2018-05-08T14:03:59Z,True,rust-lang_____rfcs_____2426_____387413458,if it was `breakup` or `break up` I'd be more likely to support it.,True,True
rust-lang_____rfcs_____2426,2018-05-08T14:31:37Z,True,rust-lang_____rfcs_____2426_____387422688,"@ibkevg 
> True. Out of curiosity, do you know how long it took from RFP to macro-ization to the point where try! was removed? I'm asking only because I think this RFP had hopes for inclusion in Rust 2018.

@phaylon 
> No idea about the exact timelines. try! is still supported though currently. Also unsure what an RFP is :)

@Centril 
> I'm guessing it's a typo for ""RFC"".

Given that it was spelled RFP twice, it might also be intentional, with a meaning like ""Request For Prototype"", as in what happens after an RFC is accepted.",True,True
rust-lang_____rfcs_____2426,2018-05-08T15:15:24Z,True,rust-lang_____rfcs_____2426_____387437964,"@ssokolow Thanks for giving me the benefit of the doubt, but it was a typo. I need to issue an RFWIMNWIS, Request for What I Mean, Not What I Say! :D",True,True
DSharpPlus_____DSharpPlus_____281,2018-05-08T19:14:16Z,True,DSharpPlus_____DSharpPlus_____281_____387511417,"PascalCase  is life, PascalCase  is love.

I didn't see a style recommendation sorry. ",True,True
DSharpPlus_____DSharpPlus_____281,2018-05-08T21:28:56Z,True,DSharpPlus_____DSharpPlus_____281_____387548283,"I like how you and your people were so rude to me and yet still accept my bug fix. 

Eat that crow, bitch.",True,True
DSharpPlus_____DSharpPlus_____281,2018-05-08T21:33:50Z,True,DSharpPlus_____DSharpPlus_____281_____387549497,@TheLastTech are you fucking blind? I closed your PR because of your rude behaviour and personal harassment towards emzi.,True,True
rack_____rack_____1272,2018-05-09T03:51:35Z,True,rack_____rack_____1272_____387612175,I cleaned up the formatting of the SPEC around the upgrade section. An HTML version is at [http://www.ohler.com/agoo/rack/file.SPEC.html](http://www.ohler.com/agoo/rack/file.SPEC.html).,True,True
rust-lang_____rfcs_____2426,2018-05-12T08:24:14Z,True,rust-lang_____rfcs_____2426_____388539477,"This is a very well-writren and thoroughly researched RFC. @Centril I like how neutral you remain when discussing the options, and although you argue for `throw` as your favourite choice, you make it clear that it's just your opinion and still point out the advantages of the other choices.

Just wanted to add a couple thoughts:
- I like `fail`, and the reason `fail <expr>` didn't sound weird to me is because I insert the word ""with"" in between, e.g. ""fail with this error"". `break <expr>` works similarly.
- This has been mentioned many times, but it would be nice for consistency of we had an Ok-wrapping version of `throw/raise/fail`. Unfortunately the potential keywords for that are not as good — `pass`? `succeed`? `ok`? `return`? `pure`? — but it would be a shame if that were the only reason keeping us from having it.",True,True
rust-lang_____rfcs_____2426,2018-05-14T14:55:03Z,True,rust-lang_____rfcs_____2426_____388846709,"Since the only urgent question of this RFC is the keyword reservation of `throw` and `fail`,
I have written a separate proposal in RFC #2441, to do just that and nothing more,
so that this RFC does not have the same urgency.
",True,True
mysqljs_____mysql_____1962,2018-05-14T16:27:25Z,True,mysqljs_____mysql_____1962_____388878819,"This is awesome, thank you. I've been reviewing it, and sorry I didn't reply that I was in progress. I did find at least one regression just in existing behavior so far, and pushed a test to cover this to `master` so we have it covered for the future as well. I noticed the change for the `ChangeUser` sequence no longer passes any of the options down to the `Sequence` constructor, which differs not from every other sequence. Not sure what the purpose of that change was, but it at least prevents the `timeout` option from getting passed down.

I'll look at what the fix is and push it up to your PR branch here 👍 ",True,True
pallets_____click_____493,2018-05-14T20:20:02Z,True,pallets_____click_____493_____388949241,"Closing this not for any of the things that @amcgregor decided to say, but because I want to unify this with the configs from Flask. I'm still not 100% comfortable with Travis doing deploys, but maybe we'll get there eventually.",True,True
rack_____rack_____1272,2018-05-14T21:16:49Z,True,rack_____rack_____1272_____388965736,"@evanphx , how is the Puma adaptation going?

So far, the API iodine implements for the `client` object looks [like this](https://www.rubydoc.info/gems/iodine/0.6.0/Iodine/Connection).

It includes a number of methods not listed in the specification besides the Pub/Sub extensions (the `timeout`, `timeout=` and `protocol` method).

I also added the `env` accessor so I could avoid making objects just to keep the `env` alive. This is something I need for an upcoming plezi.io release and I'm not sure if it should be adopted (as it adds longevity to all the objects in the `env` Hash, which is bound to increase memory fragmentation).

Anyway, I hope to see this move forward. Iodine has been serving clients like this for the last couple of year or so (albeit using `extent` rather than a client object) and so far the feedback is positive and the performance is promising.",True,True
rack_____rack_____1272,2018-05-14T23:19:46Z,True,rack_____rack_____1272_____388993015,If you need extensions to make anything useful they need to be part of the spec IMHO.,True,True
rack_____rack_____1272,2018-05-15T00:08:43Z,True,rack_____rack_____1272_____389001235,"@ioquatix , this was my thought as well, which is why I wrote it here. Perhaps these added methods (`timeout`, `timeout=` and `protocol`) should be part of the specification.

On the other hand, I don't have to have the `env` variable, I just as easily could have create a callback object (using a class instance) instead of static module... it was more of a design preference that I thought I should mention.

**EDIT** I should note that the `timeout` methods aren't required to make WebSockets / SSE work. It's just that iodine also supports raw TCP/IP connections and these connections require access to timeout management.",True,True
rack_____rack_____1272,2018-05-15T00:40:04Z,True,rack_____rack_____1272_____389005949,"The entire pub-sub pattern can be implemented by keeping an Array of connections. A publish would then call write on each one. The reason pub-sub was not included in the PR was that it added another new use pattern to the spec that would take even more effort for servers to comply with.

Like @boazsegev and Iodine Agoo includes a pub-sub implementation that is compatible to a large degree with Iodine. In then end we wanted something basic that could be used with a minimum of changes in Rack and the way developers use it.

The current PR focuses just on Push without also introducing pub-sub. Maybe a future PR can propose the addition of pub-sub. One step at a time.",True,True
rack_____rack_____1272,2018-05-15T01:43:24Z,True,rack_____rack_____1272_____389015687,"> The entire pub-sub pattern can be implemented by keeping an Array of connections. A publish would then call write on each one. The reason pub-sub was not included in the PR was that it added another new use pattern to the spec that would take even more effort for servers to comply with.

This wouldn't work with falcon in forked mode, since it forks one process per CPU core and they all handle connections independently.

Even in threaded mode, some kind of synchronisation is required. I believe the same problem would affect puma in cluster mode, for example.

My opinion is that this spec needs to be feature complete, as in, it's possible within the confines of the spec to implement actual useful websocket applications. Otherwise, what's the point? If every server supports the core spec but provides their own incompatible models on top of that, this isn't going to work out very well.",True,True
rack_____rack_____1272,2018-05-15T02:10:02Z,True,rack_____rack_____1272_____389020040,"The PR, as it stands, is feature complete for WebSocket and SSE. Sure, extending the PR to include pub-sub would be a problem for servers that don't share state but that has nothing to do with WebSocket and SSE support proposed here.

@ioquatix, Slamming @boazsegev example code that is meant to demonstrate not only the proposed Rack additions but also other features of Iodine and then claiming that example invalidates this PR is ludicrous. The PR offers a clean and simple way for even new developers to take advantage of WebSockets and SSE. Some of the comments such as those from @tenderlove were constructive and genuinely aimed toward enhancing the current Rack spec with the addition of WebSockets and SSE. You have fought tooth and nail against it from the start with an extreme passion to block any variation on the PR. I don't understand why you feel so threatened by this PR. Can you explain why you have such strong feelings about offering Rack users an simple to use approach to WebSocket and SSE?",True,True
rack_____rack_____1272,2018-05-15T02:27:52Z,True,rack_____rack_____1272_____389022780,"Okay, this conversation clearly needs to go back on ice for a bit.

I don't agree that pub/sub is within scope, but if we can't do each other the courtesy of assuming genuine opinions and positive/constructive intentions, then we're not going to get anywhere useful.",True,True
styleguidist_____react-styleguidist_____985,2018-05-15T03:47:23Z,True,styleguidist_____react-styleguidist_____985_____188006726,Inspired by https://github.com/SpareBank1/designsystem/blob/master/styleguide.config.js#L93,True,True
styleguidist_____react-styleguidist_____985,2018-05-15T06:43:57Z,True,styleguidist_____react-styleguidist_____985_____188179165,This sentence doesn't say anything without an example.,True,True
styleguidist_____react-styleguidist_____985,2018-05-15T06:44:49Z,True,styleguidist_____react-styleguidist_____985_____188179335,And the main question: why would you want to use it in a style guide?,True,True
styleguidist_____react-styleguidist_____985,2018-05-15T08:35:06Z,True,styleguidist_____react-styleguidist_____985_____389088368,"For example, if I want to load css for font-awesome from node_modules.
Putting it in require section as described does not work as it is not automatically loaded on every page.
https://github.com/styleguidist/react-styleguidist/issues/591
and the other example I referenced have their use cases for this as well, ie:
https://github.com/SpareBank1/designsystem/blob/master/styleguide.config.js#L93",True,True
styleguidist_____react-styleguidist_____985,2018-05-15T16:33:36Z,True,styleguidist_____react-styleguidist_____985_____389231288,"ie this is basically adding <link rel=""stylesheet"" href=""path/to/local/style.css"" /> as adding the plugin will include the css as part of the build.  ",True,True
styleguidist_____react-styleguidist_____985,2018-05-15T17:04:20Z,True,styleguidist_____react-styleguidist_____985_____389241080,"# [Codecov](https://codecov.io/gh/styleguidist/react-styleguidist/pull/985?src=pr&el=h1) Report
> Merging [#985](https://codecov.io/gh/styleguidist/react-styleguidist/pull/985?src=pr&el=desc) into [master](https://codecov.io/gh/styleguidist/react-styleguidist/commit/7f5137e2484eb861371ede7e6e8f718e97ff9d06?src=pr&el=desc) will **increase** coverage by `<.01%`.
> The diff coverage is `n/a`.

| [Impacted Files](https://codecov.io/gh/styleguidist/react-styleguidist/pull/985?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [src/rsg-components/Slot/Slot.js](https://codecov.io/gh/styleguidist/react-styleguidist/pull/985/diff?src=pr&el=tree#diff-c3JjL3JzZy1jb21wb25lbnRzL1Nsb3QvU2xvdC5qcw==) | `95.45% <0%> (+0.21%)` | :arrow_up: |
",True,True
rack_____rack_____1272,2018-05-15T19:27:55Z,True,rack_____rack_____1272_____389285061,"TBH I'm kind of worried about committing to an API without a real world app using it.  The reason is because I want to make sure we don't forget anything we need to implement actual apps.  If we could get Action Cable running on top of a server that used this API, then I'd be satisfied to merge.",True,True
styleguidist_____react-styleguidist_____985,2018-05-16T07:16:45Z,True,styleguidist_____react-styleguidist_____985_____389419484,"CSS extraction an CSS loading are completely independent things, you don't need to extract CSS to a file to do anything, you've described.",True,True
styleguidist_____react-styleguidist_____985,2018-05-16T07:28:16Z,True,styleguidist_____react-styleguidist_____985_____389422410,"@sapegin you'll need to include the CSS in the webpack build in order to load them.  Thats what the MiniCssExtractPlugin does, it takes CSS from a local directory and puts it as part of the build.  Just putting it in require config doesn't do anything, nor does adding an entry to template as it is not part of the build.

In fact I've looked through all the issues opened by other people, every one of them you just tell them to look at the template section for the docs.  It works if the CSS is a url, but it doesn't work if it is a local file.  ",True,True
styleguidist_____react-styleguidist_____985,2018-05-16T07:30:25Z,True,styleguidist_____react-styleguidist_____985_____389422909,I advice you to read what MiniCssExtractPlugin actually does and how CSS imports work in webpack instead of complaining here.,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-16T14:23:05Z,True,algorithm-archivists_____algorithm-archive_____114_____188450604,"I added `DFT` to FFT, `DFS_recursive_postorder` and `DFS_recursive_inorder_btree` to tree traversal all in C++.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-16T15:11:41Z,True,algorithm-archivists_____algorithm-archive_____114_____389554950,"I don't like this change. It looks very C-y, and there is bit operations on `int`, which doesn't seem right.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-16T15:45:03Z,True,algorithm-archivists_____algorithm-archive_____114_____389567304,"We need to add `dft` in `fft.cpp`, `dfs_recursive_postorder` and `dfs_recursive_inorder_btree` in `tree_example.cpp`.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-16T15:48:47Z,True,algorithm-archivists_____algorithm-archive_____114_____389568687,I'm going to add a PR to your PR. Thanks for building the base!,True,True
nestjs_____typeorm_____27,2018-05-18T16:39:47Z,True,nestjs_____typeorm_____27_____189078366,"Hey!

I saw Pull request #23 and I had exactly the same use case.
I have therefore implement a new decorator, as proposed in the above PR.

## Example usage

```ts
import { Injectable } from '@nestjs/common';
import { InjectedEventSubscriber } from '@nestjs/typeorm';

@Injectable('default')
@InjectedEventSubscriber()
export class CompanySubscriber implements EntitySubscriberInterface<Company> {
  constructor(
    private companyService: CompanyService,
    @Inject('SomethingElse') something: Else,
  ) {
  }
...
  afterUpdate(event: UpdateEvent<Company>) {
    console.log(`BEFORE POST INSERTED: `, this.companyService.doSomethingElse(event.entity));
  }
}
```

And the Subscriber needs to be registered as a provider in NestJS
```
 providers: [
    ...
     CompanySubscriber,
    CompanyService,
 ....
  ],
```


## How it works

The class will fake the constructor with a new one that requires the ""Connection"" (By default the default connection is passed, unless specified as a parameter to the decorator).

To do this, the metadata of the ""fake constructor"" are set with the metadata of the normal constructor + the metadata required to inject the connection.

When the subscriber is created, the subscriber is added to the subscribers from the connection.


Thanks",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-19T23:09:34Z,True,algorithm-archivists_____algorithm-archive_____114_____390438550,@Gathros poke?,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:17:08Z,True,algorithm-archivists_____algorithm-archive_____114_____390462783,"I'd argue that the use of iterators and `std::accumulate`  actually reduces the readability of the code. It would be fine if we wanted to make a standard library implementation but it's not very suitable for an educational resource. Also, having to capture mutable variables in an `accumulate` is a pretty good indication you shouldn't be using it in my opinion. I think this version is a lot more readable:

```cpp
std::vector<c64> discrete(const std::vector<c64>& vec) {
    std::vector<c64> result(vec.size());

    auto size = vec.size();
    for (size_t i = 0; i < size; ++i) {
        for (size_t j =0 ; j < size; ++j) {
            result[i] += vec[j] * std::exp(c64(0, -2.0 * pi<double>() * j * i / size));
        }
    }

    return result;
}
```




",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:21:39Z,True,algorithm-archivists_____algorithm-archive_____114_____390462954,"Also, I'll say it again: `std::valarray` is literally made for vector math like this, so if we want to be really gung-ho about using standard library features everywhere then using them would make the code a lot shorter and more readable",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:24:57Z,True,algorithm-archivists_____algorithm-archive_____114_____189453228,This indentation looks incorrect,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:26:51Z,True,algorithm-archivists_____algorithm-archive_____114_____390463185,"@Gathros I'm not sure I agree. I prefer the one with the standard algorithms, although I think some of it could be worked around better.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:27:32Z,True,algorithm-archivists_____algorithm-archive_____114_____189453273,what is incorrect about it?,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:30:27Z,True,algorithm-archivists_____algorithm-archive_____114_____390463327,"Also, I just realized what that call to exp is doing, and that seems like a really badly worded way of doing a sine or cosine",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:35:01Z,True,algorithm-archivists_____algorithm-archive_____114_____390463541,It's @Gustorn not me @ubsan.,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:37:11Z,True,algorithm-archivists_____algorithm-archive_____114_____189453436,"Oh sorry, I actually misread that line",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:37:19Z,True,algorithm-archivists_____algorithm-archive_____114_____390463630,Sorry,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:38:24Z,True,algorithm-archivists_____algorithm-archive_____114_____189453452,"As I said in another comment, I'd still argue for `valarray` here, it makes the implementation a lot more readable:

```cpp
void fft(std::valarray<c64>& v) {
    auto size = v.size();
    if (size < 2) {
        return;
    }

    auto even = std::valarray<c64>(v[std::slice(0, size / 2, 2)]);
    auto odd  = std::valarray<c64>(v[std::slice(1, size / 2, 2)]);

    fft(even);
    fft(odd);

    for (size_t k = 0; k < size / 2; k++) {
        auto w = std::polar(1.0, -2.0 * pi<double> * k / size) * odd[k];
        v[k] = even[k] + w;
        v[k + size / 2] = even[k] - w;
    }
}
```",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:44:57Z,True,algorithm-archivists_____algorithm-archive_____114_____390463944,"I read modern C++ on a regular basis and I needed to take a second look at that `generate/aggregate` combo to realize what it's doing. `aggregate` is not the algorithm to use when you need external state. Not only does it make it much harder to grasp what the algorithm is actually doing, it also ruins thread safety. With `range-v3` we could write this nicely but with the existing STL algorithms? Not so much.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:54:13Z,True,algorithm-archivists_____algorithm-archive_____114_____390464296,"@Gustorn I have figured out how to do it nicely, one sec",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T07:56:20Z,True,algorithm-archivists_____algorithm-archive_____114_____390464395,"@Gustorn How's this?

```cpp
template <typename F>
auto sum(std::size_t const start, std::size_t const end, F f) {
  using return_type = decltype(f(start));
  auto ret = return_type(0);

  for (auto i = start; i < end; ++i) {
    ret += f(i);
  }

  return ret;
}

template <typename It, typename F>
It indexed_generate(
    It first, std::size_t const start, std::size_t const end, F f) {
  auto it = first;
  for (auto i = start; i < end; ++i, ++it) {
    *it = f(i);
  }
  return it;
}

template <typename Iter>
void discrete(Iter first, Iter last) {
  auto size = last - first;
  auto temp = std::vector<c64>();

  indexed_generate(std::back_inserter(temp), 0, size, [&](auto i) {
    return sum(0, size, [&](auto k) {
      // NOTE:
      // this is equivalent to cos(-2 pi i k / size) + i sin(-2 pi i k / size)
      return first[k] * std::exp(c64(0, -2.0 * pi<double>() * i * k / size));
    });
  });

  std::copy(begin(temp), end(temp), first);
}
```",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T08:19:38Z,True,algorithm-archivists_____algorithm-archive_____114_____390465446,"And a second attempt:

```cpp
template <typename Iter>
void discrete(Iter first, Iter last) {
  using namespace std::literals;

  auto const original = std::vector<c64>(first, last);
  auto const size = original.size();

  auto const i2pi = -2.0i * pi<double>();

  for (std::size_t i = 0; i < size; ++i) {
    first[i] = sum(0, size, [&](auto k) {
      return original[k] * std::exp(i2pi * double(i * k) / double(size));
    });
  }
}
```",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T08:44:28Z,True,algorithm-archivists_____algorithm-archive_____114_____390466622,"Yeah, I like the last version a lot more. You could also do something like:

```cpp
template <typename Iter, typename F>
auto sum(Iter first, Iter last, const F& fn) {
    using namespace std::literals;
    return std::accumulate(first, last, std::make_pair(0, 0i), [&fn](auto acc, const auto& x) {
        return std::make_pair(acc.first + 1, acc.second + fn(acc.first, x));
    }).second;
}

template <typename Iter>
void discrete(Iter first, Iter last) {
  using namespace std::literals;

  auto const original = std::vector<c64>(first, last);
  auto const size = original.size();

  for (std::size_t i = 0; i < size; ++i) {
    first[i] = sum(original.begin(), original.end(), [i, size](auto k, auto value) {
      return value * std::exp(-2.0i * pi<double>() * double(i * k) / double(size));
    });
  }
}
```",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T16:33:14Z,True,algorithm-archivists_____algorithm-archive_____114_____390494397,"Alright, then we can change over to

```cpp
template <typename It, typename F>
auto sum(It const first, It const last, F f) {
  using return_type = decltype(f(0, *first));
  auto ret = return_type(0);

  std::size_t i = 0;
  for (auto it = first; it < last; ++it, ++i) {
    ret += f(i, *it);
  }

  return ret;
}

template <typename Iter>
void discrete(Iter const first, Iter const last) {
  using namespace std::literals;

  auto const original = std::vector<c64>(first, last);
  auto const size = original.size();

  auto const i2pi = -2.0i * pi<double>();

  for (std::size_t i = 0; i < size; ++i) {
  for (std::size_t i = 0; i < size; ++i) {
    first[i] =
        sum(begin(original), end(original), [&](auto const k, auto const el) {
          return el * std::exp(i2pi * double(i * k) / double(size));
        });
  }

  }
}
```

@Gathros 

@Gustorn I still believe that we should be teaching iterators - the great thing about them is that we can switch out `std::array<c64, 64>` for `std::valarray<c64>` without changing any other code _shrug_",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T17:00:28Z,True,algorithm-archivists_____algorithm-archive_____114_____390496110,@ubsan Changed it.,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T17:03:48Z,True,algorithm-archivists_____algorithm-archive_____114_____390496306,"Sorry, I only checked if it compiles, not if it works (on godbolt, didn't have a C++ compiler handy). The point I was making with `valarray` is that you can write the algorithm in an easier and more understandable manner. Yes, the generic iterator version will work but the `valarray` one is nicer. 

As for iterators: I'm not the biggest fan of them in general. If we want to be generic, I'd rather be generic over the container and not the iterators. That would still allow you to use range-based for loops and standard algorithms (and that's kind of what the standard is moving towards with ranges anyway). ",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T17:39:21Z,True,algorithm-archivists_____algorithm-archive_____114_____189465502,"It seems like that's more of an issue with the current implementation; we could do

```cpp
template <typename Iter>
void recursive(Iter first, Iter last) {
  std::size_t size = last - first;
  if (size < 2) {
    return;
  } else if (size % 2 != 0) {
    std::cerr << ""The range must be a power of two size\n"";
    std::abort();
  }

  auto odds = std::vector<c64>(size / 2);
  auto evens = std::vector<c64>(size / 2);

  for (std::size_t i = 0; i < size / 2; ++i) {
    odds[i] = first[i * 2 + 1];
    evens[i] = first[i * 2];
  }

  // recurse the splits and butterflies in each half of the range
  recursive(begin(odds), end(odds));
  recursive(begin(evens), end(evens));

  // now combine each of those halves with the butterflies
  for (std::size_t k = 0; k < size / 2; ++k) {
    auto w = std::polar(1.0, -2.0 * pi<double>() * k / size) * odds[k];
    first[k] = evens[k] + w;
    first[k + size / 2] = evens[k] - w;
  }
}
```",True,True
rust-lang_____rfcs_____2426,2018-05-20T18:58:04Z,True,rust-lang_____rfcs_____2426_____390503383,"@rfcbot fcp postpone

[""The Rust team is laser focused on the 2018 Edition right now""](https://internals.rust-lang.org/t/pre-rfc-flexible-try-fn/7564/88?u=scottmcm), so with https://github.com/rust-lang/rfcs/pull/2441 covering the urgent-for-the-edition part, I propose we set aside any further discussion until after the [current roadmap](https://blog.rust-lang.org/2018/03/12/roadmap.html).",True,True
rust-lang_____rfcs_____2426,2018-05-20T18:58:05Z,True,rust-lang_____rfcs_____2426_____390503385,"Team member @scottmcm has proposed to postpone this. The next step is review by the rest of the tagged teams:

* [ ] @aturon
* [ ] @cramertj
* [ ] @eddyb
* [ ] @joshtriplett
* [ ] @nikomatsakis
* [ ] @nrc
* [ ] @pnkfelix
* [x] @scottmcm
* [ ] @withoutboats

No concerns currently listed.

Once a majority of reviewers approve (and none object), this will enter its final comment period. If you spot a major issue that hasn't been raised at any point in this process, please speak up!

See [this document](https://github.com/anp/rfcbot-rs/blob/master/README.md) for info about what commands tagged team members can give me.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-20T21:43:57Z,True,algorithm-archivists_____algorithm-archive_____114_____189471443,"I think this is even nicer; moving out the split into it's own function, to make it really clear what's happening:

```cpp
template <typename In, typename Out0, typename Out1>
void split(In initial, In const last, Out0 out0, Out1 out1) {
  if ((last - initial) % 2 != 0) {
    std::cerr << ""The range must be a power of two size\n"";
    std::abort();
  }

  while (initial != last) {
    *out0 = *initial;
    ++out0;
    ++initial;
    *out1 = *initial;
    ++out1;
    ++initial;
  }
}

// `recursive` does the cooley-tukey algorithm, recursively
template <typename Iter>
void recursive(Iter const first, Iter const last) {
  std::size_t size = last - first;
  if (size < 2) {
    return;
  }

  auto evens = std::vector<c64>(size / 2);
  auto odds = std::vector<c64>(size / 2);
  split(first, last, begin(evens), begin(odds));

  // recurse the splits and butterflies in each half of the range
  recursive(begin(odds), end(odds));
  recursive(begin(evens), end(evens));

  // now combine each of those halves with the butterflies
  for (std::size_t k = 0; k < size / 2; ++k) {
    auto w = std::polar(1.0, -2.0 * pi<double>() * k / size) * odds[k];
    first[k] = evens[k] + w;
    first[k + size / 2] = evens[k] - w;
  }
}
```",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T13:43:57Z,True,algorithm-archivists_____algorithm-archive_____114_____390657615,"I'll try to make one last argument against the iterator/algorithm solution. First, let's compare the now final version with my proposed one:

```cpp
template <typename It, typename F>
auto sum(It const first, It const last, F f) {
  using return_type = decltype(f(0, *first));
  auto ret = return_type(0);

  std::size_t i = 0;
  for (auto it = first; it < last; ++it, ++i) {
    ret += f(i, *it);
  }

  return ret;
}

template <typename Iter>
void discrete(Iter const first, Iter const last) {
  using namespace std::literals;

  auto const original = std::vector<c64>(first, last);
  auto const size = original.size();

  auto const i2pi = -2.0i * pi<double>();
  for (std::size_t i = 0; i < size; ++i) {
    first[i] =
        sum(begin(original), end(original), [&](auto const k, auto const el) {
          return el * std::exp(i2pi * double(i * k) / double(size));
        });
  }

  }
}
```

vs

```cpp
std::vector<c64> discrete(const std::vector<c64>& vec) {
    std::vector<c64> result(vec.size());

    auto size = vec.size();
    for (size_t i = 0; i < size; ++i) {
        for (size_t j =0 ; j < size; ++j) {
            result[i] += vec[j] * std::exp(c64(0, -2.0 * pi<double>() * j * i / size));
        }
    }

    return result;
}
```

I don't know about you, but I find the latter version immensely more readable. I understand the notion of avoiding raw loops but in this case there's one line of self-contained math code. There are some problems that benefit from abstractions, this isn't one of them. The proposed implementation also doesn't really give that much genericity over my proposed solution (it requires a random access iterator). If we really want to support multiple containers we could just do:

```cpp
template <typename T>
T discrete(const std::vector<c64>& vec) {
    T result(vec.size());

    auto size = vec.size();
    for (size_t i = 0; i < size; ++i) {
        for (size_t j =0 ; j < size; ++j) {
            result[i] += vec[j] * std::exp(c64(0, -2.0 * pi<double>() * j * i / size));
        }
    }

    return result;
}
```

The problem with always going with the ""modern C++"" solution without trying to evaluate to potential benefits is that it introduces a *lot* of noise, most of which is completely unnecessary for the algorithm at hand.

Another important thing is that this book is supposed to teach algorithms, **not** C++. That being said, I still think we should write clean, readable and performant C++ code but we shouldn't necessarily strive for standard library-like implementations. Most people will never need the genericity it provides and it obfuscates the important parts of the algorithms. Also, chances are that people who *do* need that level of genericity can easily adapt the container version to suit their needs. The same cannot be said for beginners who're reading about an algorithm for the first time.",True,True
rust-lang_____rfcs_____2444,2018-05-21T13:52:11Z,True,rust-lang_____rfcs_____2444_____189385244,[Rendered](https://github.com/phaazon/rfcs/blob/undo-universal-impl-trait/text/0000-undo-universal-impl-trait.md),True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T13:59:36Z,True,algorithm-archivists_____algorithm-archive_____114_____189597315,"I disagree with the separate `split` version being nicer, see my comment in the main thread. We're not really writing a standard library grade implementation and `split` just obfuscates a very significant step in the algorithm. I do like the proposed `odds`/`evens` version however, although I would still go with the iterator-free version with a proper return value:

```cpp
void fft_calculate_recursive(std::vector<c64>& values) {
    std::size_t size = values.size();
    if (size < 2) {
        return;
    } else if (size % 2 != 0) {
        std::cerr << ""The range must be a power of two size\n"";
        std::abort();
    }

    auto odds = std::vector<c64>(size / 2);
    auto evens = std::vector<c64>(size / 2);

    for (std::size_t i = 0; i < size / 2; ++i) {
        odds[i] = values[i * 2 + 1];
        evens[i] = values[i * 2];
    }

    // recurse the splits and butterflies in each half of the range
    fft_calculate_recursive(odds);
    fft_calculate_recursive(evens);

    // now combine each of those halves with the butterflies
    for (std::size_t k = 0; k < size / 2; ++k) {
        auto w = std::polar(1.0, -2.0 * pi<double>() * k / size) * odds[k];
        values[k] = evens[k] + w;
        values[k + size / 2] = evens[k] - w;
    }
}

std::vector<c64> recursive(const std::vector<c64>& values) {
  std::vector<c64> result(values.begin(), values.end());
  fft_calculate_recursive(result);
  return result;
}
```

I think that teaching people to return actual results rather than using out parameters is way more important than any perceived genericity one gets from iterators (I'm not arguing that iterators aren't more general - I'm arguing that it isn't needed here).",True,True
rust-lang_____rfcs_____2444,2018-05-21T14:06:42Z,True,rust-lang_____rfcs_____2444_____390663811,Aren't universal impl trait stable since 1.26 ? This would be a breaking change.,True,True
rust-lang_____rfcs_____2444,2018-05-21T14:07:52Z,True,rust-lang_____rfcs_____2444_____390664208,"> Aren't universal impl trait stable since 1.26 ? This would be a breaking change.

I guess you could remove it as part of Rust 2018. That should work",True,True
rust-lang_____rfcs_____2444,2018-05-21T14:15:15Z,True,rust-lang_____rfcs_____2444_____390666515,I like the idea.,True,True
rust-lang_____rfcs_____2444,2018-05-21T14:23:43Z,True,rust-lang_____rfcs_____2444_____390669262,"> Aren't universal impl trait stable since 1.26 ? This would be a breaking change.

It would be breaking change.",True,True
rust-lang_____rfcs_____2444,2018-05-21T14:32:09Z,True,rust-lang_____rfcs_____2444_____390671742,"> Also, consider this function that takes an argument and add it to itself:
>
> ```rust
> fn add_self<T>(x: T) -> T where T: Add<Output = T> + Copy
> ```
>
> Now consider:
>
> ```rust
> fn add_self(x: impl Add<Output = impl Copy> + Copy)
> ```
> 
> You can see the duplication here and the overwhelming confusion that both the `impl Trait` will
resolve to the same type, even though they don’t have the same contract, which is impossible to
guess from the interface while it could. This is legal because we only talk about two contracts here
and the function will pick a type at the union (it must be `Add + Copy` and `Copy`) but you also
have that weird `Output` contract as well.
>
> Even weirder:
>
> ```rust
> fn add_self(x: impl Add<Output = impl Sized> + Copy) -> impl Sized {
>  x + x
> }
> ```

The `impl trait` versions here are better code, since they give a better specification of what the function actually does. The equivalent non impl trait version to the best impl trait version would be

```rust
fn add_self<T: Add<Output = O> + Copy, O: Sized>(x: T) -> impl Sized {
  x + x
}
```

We can make a non-impl trait version that is even better, since we can specify that the `Add::Output` type is equal to the return type of the function

```rust
fn add_self<T: Add<Output = O> + Copy, O>(x: T) -> O {
  x + x
}
```

We can mix this with impl trait for what is my preferred version

```rust
fn add_self<O>(x: impl Add<Output=O> + Copy) -> O {
  x + x
}
```

What I get from this whole line of reasoning though is that universal impl trait encourages better code. It makes you realize what types need to be equal, and what ones don't.",True,True
rust-lang_____rfcs_____2444,2018-05-21T14:42:56Z,True,rust-lang_____rfcs_____2444_____390674991,"I'm very much in favor of removing `impl Trait` for arg types:

1. `impl Trait` for arg types is non-orthogonal, which makes it harder to decide which way of universal quantification to use, and this question will come up **over and over and over** just because there are now 2 ways.
1. It's not actually easier to learn than generics. It looks very different from generics syntaxes that most programmers are familiar with.
1. It's easier for learning Rust to NOT conflate universal and existential quantification.
People should be aware of the difference, so that's another argument to keep only `<T: Trait>` for arg types and `impl Trait` only for existential quantification (including for other cases of existential quantification later when `impl Trait` will be allowed for const/let and existential types).
1. The argument that ""having `impl Trait` for arg types allows postponing introducing generics until later in the book"" doesn't count, because newbies will have to read the Rust book multiple times anyway. 
1. Most newbies will be familiar with another language that has similar generics syntax, e.g. C++, C#, Java, D, Scala etc.
1. There is **NO** evidence that `impl Trait` makes generics/Rust easier to learn, quite the contrary, it seems to confuse people, and:
1. From personal experience teaching Rust to complete newbies (no previous programming experience), and to some who only knew C or Python: 
Universally quantifying generics are not a difficult part of Rust (but references/lifetimes in generics). For anyone coming from any other language with universally quantifying generics they will quickly grasp the Rust syntax, but `impl Trait` is completely foreign to them.
1. The argument that `impl Trait` for arg types should be introduced to mirror `impl Trait` for return types is invalid: We Rust programmers lived without `impl Trait` for return types for years, it can be postponed until the end of the book, until newbies have understood universally quantifying generics! Newbies can write **a lot** of code before ever even needing `impl Trait` for return types.
1. There is no reason to ever choose to write `impl Trait` for arg types as a non-newbie, so why should newbies learn this way, if they have to unlearn it very quickly anyway?
1. I disagree with the [dialectical ratchet](https://github.com/rust-lang/rfcs/pull/2071#issuecomment-329026602) in this case. 
It may apply to references/lifetimes but **NOT** to `impl Trait` for arg types. 
The concepts of references and lifetimes complement each other, they are used together, not just by newbies. These are orthogonal concepts!
But having ""`impl Trait` for args"" as ""the newbie-way to express universally quantified generics"" means that newbies have to learn something that they have to unlearn later!
Which **WILL** confuse them because there are 2 overlapping ways to do the same thing and the one they learned is stricly less powerful, which demotivates them because they now have to unlearn it and learn the fully powerful way! And then they will ask themselves: ""why did i even have to do the detour through ""`impl Trait` for args"", this `<T: Trait>` syntax is more familiar and more powerful""..
1. We should not compromise orthogonality of the language to introduce a strictly less powerful syntactic sugar, **ESPECIALLY** because it will only confuse people more.
1. The Rust language contains a lot of concepts, everyone will have to read the book a couple times. Making Rust easy to **use** and easy to **remember** is at least as important as making it easy to learn, and the bottleneck for learnability is the docs, not the language design itself. The docs about generics can always be improved without affecting Rust's design, we shouldn't compromise Rust for this! 
1. What makes a language easy to use and remember is the consistency and orthogonality of the concepts, so that there aren't overlapping concepts, and so that in every situation there is one obvious way to do things. Not 2 ways, where one is strictly less powerful. (It's like having traits + OOP inheritance, makes it harder to choose which one to use.)
1. In the future, we should **really** do some A/B testing to determine which change to Rust makes it actually easier to learn, before stabilizing that change. And when features are introduced that are controversial or unorthogonal, the debate thread should be more visible and open for longer. I only noticed that `impl Trait` was also being stabilized for args when it was too late to comment on it, because it was kind of hiding in the shadow of `impl Trait` for return types.

(Sorry if this sounds like a rant, I just feel very strongly about this :)",True,True
rust-lang_____rfcs_____2444,2018-05-21T14:48:32Z,True,rust-lang_____rfcs_____2444_____390676708,"When you write an RFC ""Add feature X"" they upvote you.
When featurer is added and you write an RFC ""Remove feature X"" they upvote you.

You think ""Maybe I don't understand what's inside people minds""",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:08:50Z,True,rust-lang_____rfcs_____2444_____189618755,"You've followed

> This argument is twisted along the lines of subjective opinion about learnability

With an equally subjective argument.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:09:09Z,True,rust-lang_____rfcs_____2444_____189618864,"People come to Rust from languages other than C++, C#, and Java. Not to mention that the entire point of `impl Trait` in argument position is that it works much closer to Java/C#. In java, you don't write void `<T extends SomeInterface> method(T arg)`, you write `void method(SomeInterface arg)`.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:14:25Z,True,rust-lang_____rfcs_____2444_____390684823,I completely agree with this PR. I didn't understand why we had two superfluous syntaxes for the same thing (although impl Trait is less useful as you can't turbofish it).,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:16:11Z,True,rust-lang_____rfcs_____2444_____189621021,This is no different than lifetime elision. `fn foo(&self)` is strictly less powerful than `fn foo<'a>(&'a self)`. ,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:16:16Z,True,rust-lang_____rfcs_____2444_____390685385,"Does anybody actually think in terms of 'caller' vs 'callee' chosen types? Are we really confusing people aware of the type theory involved for more than a few moments?

`impl Trait` is an anonymized type known to the compiler to implement `Trait`. With that definition, the distinction between 'universal' vs. 'existential' goes away and, for symmetry, it makes sense to have it available in both argument and return positions.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:17:41Z,True,rust-lang_____rfcs_____2444_____390685822,"What we see here is a huge failure of public review process. Simply put, universal-impl-trait escaped wide public review by coat racking onto conservative-impl-trait PR. We all waited and prepared for the latter and thus the former was not noticed before too late.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:17:50Z,True,rust-lang_____rfcs_____2444_____189621528,I think you meant two type variables,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:21:12Z,True,rust-lang_____rfcs_____2444_____390686866,"@logannc Yes, we are confusing people who understand what the difference between universal impl Trait and existential impl Trait. I researched the topic extensively to understand it, and after a few hours I was still sort of uneasy as to why we had it do two perpendicular things. 

> impl Trait is an anonymized type known to the compiler to implement Trait. With that definition, the distinction between 'universal' vs. 'existential' goes away
No, this distinction does *not* go away. As a universal bound there are multiple types you can call the method on (i.e `fn x(a: impl T)`), but as an existential bound there is exactly one (i.e `fn x() -> impl T`). This makes it different for monomorphisation and for normal programming too -- you could expect `fn x() -> impl Iterator<Item=u32>` to return any given type that implements `Iterator<Item=u32>` (similar to how collect returns any type implementing `FromIterator`).",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:22:09Z,True,rust-lang_____rfcs_____2444_____189622733,This signature is not equivalent. The only output type you could have here is `impl Copy` or `()`,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:23:38Z,True,rust-lang_____rfcs_____2444_____189623153,"This argument is entirely subjective. I personally don't find this confusing. I'm taking ""some type that can be added and copied. The result of the addition is some type that can be copied"".

""overwhelming confusion"" feels like unnecessary rhetoric to me.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:25:36Z,True,rust-lang_____rfcs_____2444_____189623736,Is the number of variables being monomorphised something people frequently care about? Is it a case we need to optimize for over readability?,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:28:18Z,True,rust-lang_____rfcs_____2444_____189624516,"This document hasn't really shown *anything* from newcomers. It's pretty hard for us to gauge how this affects newcomers at this point, since it does not appear in the book or anywhere in the documentation.

Instead this document seems to be claiming every other argument is subjective, but this one is somehow objective.

Perhaps the source of confusion is the fact that it's a brand new, undocumented feature that people are still just starting to use.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:31:28Z,True,rust-lang_____rfcs_____2444_____189625413,"This feels like a straw man to me. The feature is not yet documented. There is always going to be confusion until that gets remedied. There's also a lot of confusion around how reborrowing works (another undocumented feature), and that feature's been around for much longer.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:41:34Z,True,rust-lang_____rfcs_____2444_____189628358,How so?,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:46:28Z,True,rust-lang_____rfcs_____2444_____189629794,"`fn foo(&self, x:  &str) -> &str` vs `fn foo<'a, 'b>(&'a self, x: &'b str) -> &'b str`. You can use the second in more places, e.g. with `'a=lifetime of some object` and `'b = 'static` (or just the lifetime of some longer lived object).",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:52:34Z,True,rust-lang_____rfcs_____2444_____189631589,"This is fixable.
Technically, nothing prevents supporting turbofish and making arg position `impl Trait` purely a sugar for named type parameters.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:53:15Z,True,rust-lang_____rfcs_____2444_____189631793,"Interfaces in Java are not akin to universal quantification, because those are dynamic dispatched variables. The equivalent in Rust would be `&Trait` or `dyn Trait`.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:54:43Z,True,rust-lang_____rfcs_____2444_____189632199,"Yep, thanks for noticing. For the number of variables, I actually care about that, because it gives me hints about code generation and which variables I can have control over – via turbofishing, for instances. It’s way harder with `impl Trait` because you’re not allowed to turbofish anymore. :disappointed: ",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:55:26Z,True,rust-lang_____rfcs_____2444_____390697256,"Excuse the stupid question.

How is impl Trait in argument position any different than say.. C# where a function or method takes an interface instead of a concrete type? Can someone explain that to me. Because in C# I don't feel like its confusing at all.

",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:55:50Z,True,rust-lang_____rfcs_____2444_____189632556,"You’re right, it’s too much subjective. I’m removing it.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:57:53Z,True,rust-lang_____rfcs_____2444_____189633152,"I’ve linked a few links in the top of the document. Also, reactions and the fact it’s been so opinionated is somehow a hint that there’s a massive confusion, right?",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:58:52Z,True,rust-lang_____rfcs_____2444_____390698297,I added a bunch of comments from here. Thank you all for such massive participation.,True,True
rust-lang_____rfcs_____2444,2018-05-21T15:59:06Z,True,rust-lang_____rfcs_____2444_____390698367,"> How is impl Trait in argument position any different than say.. C# where a function or method takes an interface instead of a concrete type?

In terms of program behavior it's equivalent to passing an interface in C#. Arguably the closer equivalent would be taking a ""trait object"", but this is something that only matters if you care about very specific performance trade offs that you don't normally need to care about.

> I'm still learning Rust but when I saw impl Trait in argument position I just equated it to doing the same thing I would do in C# with interfaces.

That was the goal behind the feature.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:59:20Z,True,rust-lang_____rfcs_____2444_____189633571,"It's slightly more arcane, though. Often when doing something like `fn x<A: TraitA, B: TraitB<A>>(b: B)` I write it with the thing the 'main' generic depends on first (I don't know if you are allowed to put it second, but either way it feels 'wrong' to do it in reverse). This might not be so with impl Trait turbofishing, or at any rate is more difficult to figure out.",True,True
rust-lang_____rfcs_____2444,2018-05-21T15:59:35Z,True,rust-lang_____rfcs_____2444_____390698492,"@xgalaxy to me, it’s different because of *dynamic dispatch* vs. static dispatch. The Rust equivalent would be:

    fn foo(x: &Debug)
    fn foo(x: dyn Debug) // with the new syntax",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:00:56Z,True,rust-lang_____rfcs_____2444_____390698928,"Perhaps this is the wrong time and place to ask this, but what is turbofishing and why does it matter that it is impossible with `impl Trait`?",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:01:32Z,True,rust-lang_____rfcs_____2444_____189634202,"I mean, personally I was confused as to why we had the same syntax for the same thing, but that's just me I guess. ",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:02:45Z,True,rust-lang_____rfcs_____2444_____390699453,"@bowbahdoe turbofishing is a way to force monomorphization of a function by providing it with the type variables substituted. You already have done it for sure. See:

```
let x = (0..10).collect::<Vec<_>>(); // the syntax ::<_>() is turbofishing
```",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:04:19Z,True,rust-lang_____rfcs_____2444_____189635079,It’s not just you. All of this is very confusing and opinionated.,True,True
rust-lang_____rfcs_____2444,2018-05-21T16:05:46Z,True,rust-lang_____rfcs_____2444_____189635556,"Yup, but the entire point is that you generally don't care about the tradeoffs between a monomorphised function and a dynamically dispatched one. Similarly, you generally don't need to care about the differences between returning `Box<Foo>` and `impl Foo`. This is a ""do what I mean"" feature. Similar to lifetime elision, it hides details that you usually don't care about. If you end up in a situation where you do need to care about it (`T: Add<Output = T>` is a good example), or want to care about it (you're in a situation where binary size is very important), then you learn the underlying mechanisms.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:06:49Z,True,rust-lang_____rfcs_____2444_____189635859,"> Also, reactions and the fact it’s been so opinionated is somehow a hint that there’s a massive confusion, right?

People having strong opinions does not mean they're confused.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T16:11:26Z,True,algorithm-archivists_____algorithm-archive_____114_____390702095,"@Gustorn In fact, I disagree completely. The latter two are not more readable, and this book *is* attempting to teach good C++. If you don't want to read C++, *you have the choice to use any of the other languages*. We are attempting to represent the idea

![capture](https://user-images.githubusercontent.com/3479021/40317452-60005438-5cd6-11e8-84b3-10709888677c.PNG)

in code, and so we want to have the closest to that idea possible, preferably using algorithms.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:15:46Z,True,rust-lang_____rfcs_____2444_____390703442,"@sgrif Are you referring to `impl Trait` in general or `universal-impl-trait` in particular. We all discussed `conservative-impl-trait`, but `impl Trait` in argument position? Not so much.

And being available in the nightly means nothing. There are a lot of experimental and incomplete features that can be turned on via feature gate and may go away at any time. Just look at non-existant trait aliases for example.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:18:15Z,True,rust-lang_____rfcs_____2444_____390704193,"@phaazon There's an important detail that you're leaving out, which is that turbofishing is almost never required for type variables used in an argument position. The compiler can infer it from the type of the argument you're passing. The *only* time I've ever needed to turbofish an argument parameter is when passing a generic `extern ""C""` function pointer.

In fact, I hope the way this ends up getting resolved is to allow type parameters to be explicitly passed, but no way to explicitly state the type of `impl Trait`, as it's a strength of the feature. Take for example this function in Diesel:

```
fn debug_query<DB, T>(query: &T) -> DebugQuery<T, DB>
where
    DB: Backend,
    T: QueryFragment<DB>,
```

The type of `DB` can never be inferred. The type of `T` is always inferred. 100% of the usage of this function looks like `debug_query::<Pg, _>(&query)`. Instead we could write it as:

```
fn debug_query<DB: Backend>(query: &impl QueryFragment<DB>) -> DebugQuery<impl QueryFragment<DB>, DB>
```

which would remove the pointless `, _` from the caller.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:18:25Z,True,rust-lang_____rfcs_____2444_____189639364,"> You generally

Are you sure about that? :)",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:23:15Z,True,rust-lang_____rfcs_____2444_____390705591,"@sgrif correct me if I'm not right, but your code
```rust
fn debug_query<DB: Backend>(query: &impl QueryFragment<DB>) -> DebugQuery<impl QueryFragment<DB>, DB>
    T: QueryFragment<DB>,
```
is equivalent of

```rust
fn debug_query<DB, T, U>(query: &T) -> DebugQuery<U, DB>
where
    DB: Backend,
    T: QueryFragment<DB>,
    U: QueryFragment<DB>
```

Which obviously is not the same thing as

```rust
fn debug_query<DB, T>(query: &T) -> DebugQuery<T, DB>
where
    DB: Backend,
    T: QueryFragment<DB>,
```

So you just probably planted a bug in the oneliner.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:26:49Z,True,rust-lang_____rfcs_____2444_____390706628,"@logannc I think you're both right and wrong. You're right, it's simply a stand-in for ""some type that implements this trait, the compiler will figure out the rest."" _However_, it does not exist in a vacuum. It must interact with the existing type system. And in that, it fails. **Badly.** Take for example, this function signature:
```
fn is_sorted(data: impl IntoIterator<Item = u8>) -> bool;
```
Now, the user wants to make the function more robust by adding a Result type. They want to return the original data, because they're passing it in by value somewhere. How? They might try this:
```
fn is_sorted(data: impl IntoIterator<Item = u8>) -> Result<bool, impl IntoIterator<item = u8>>
```
But now this does something different. The compiler forgets the input type. So if the user inputs a Vec<u8> and expects the same thing out, they might try to debug it with {:?}. But they will get an error: `impl std::iter::IntoIterator` cannot be formatted using :?`! This is very surprising and not intuitive at all. The same thing would have worked perfectly with rust's normal generics.

Very basic assumptions about how the user expects types to be propagated are lost BECAUSE we have a type system that is strict- the compiler is not going to ""figure it out at the call site"", it's just going to follow the exact definition in the function signature. There is no way to write this without named generics.

@sgrif and @Pzixel just demonstrated this problem.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:27:54Z,True,rust-lang_____rfcs_____2444_____390706945,"Another example from Diesel that would be improved by `impl Trait` in argument position:

```
fn transaction<T, E, F>(&self, f: F) -> Result<T, E>
where
    F: FnOnce() -> Result<T, E>,
    E: From<diesel::Error>,
```

in typical usage, `T` and `F` are inferred, and `F` is a closure (so cannot be named). `E` however, is usually explicitly given, since the body of the closure will likely use `?`. So it's normally invoked as `conn.transaction::<_, diesel::Error, _>(|| stuff()?; Ok(()))`

This case is a little more interesting, since we can remove the `F` parameter, but we can't remove the `T` (unless `FnOnce` were stabilized in a form where the arguments are an associated type). However, we could change the signature to:

```
fn transaction<T, E>(&self, f: impl FnOnce() -> Result<T, E>) -> Result<T, E>
```

which would change the invocation to `conn.transaction::<_, diesel::Error>(|| stuff()?; Ok(()))`",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:28:47Z,True,rust-lang_____rfcs_____2444_____390707221,@Pzixel that is incorrect.,True,True
rust-lang_____rfcs_____2444,2018-05-21T16:29:34Z,True,rust-lang_____rfcs_____2444_____390707461,"> @phaazon There's an important detail that you're leaving out, which is that turbofishing is almost never required for type variables used in an argument position.

That’s worth mentioning, @sgrif. I’ll alter the RFC, thanks for noticing!",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:31:19Z,True,rust-lang_____rfcs_____2444_____390707965,"@sgrif Yes, but how do you teach that to a newbie? The difference here goes back to the caller vs callee distinction. You need to know about that distinction to be able to understand why those two functions are different.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:38:11Z,True,rust-lang_____rfcs_____2444_____390709936,"@sgrif 
> that is incorrect.

Well, could you elaborate a while then, please? IIRC each input `impl Trait` becomes a generic parameter. If you say that `output` parameter would be tied to the `input` one then how compiler could figure out if they are tied? How could I express then that they are different? This one shows that I'm right

```rust
fn foo(value: &impl std::fmt::Debug) -> impl std::fmt::Debug {
    42
}

fn main() {
    foo(&""42"");
}
```",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:42:54Z,True,rust-lang_____rfcs_____2444_____390711296,"@Pzixel It's equivalent to `fn debug_query<DB, T>(query: &T) -> DebugQuery<opaque type you don't know anything about and don't choose, DB>`. Whether or not the return type is the same as the input type is unimportant to this API. If I wanted to explicitly state that they were the same type, I'd give it a name and make that clear (e.g. make it a type parameter)",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:45:28Z,True,rust-lang_____rfcs_____2444_____390712071,"@Pzixel only the input `impl Trait`s can be replaced by named type parameters. Output ones are not expressible by the named-type-parameter typesystem, because the _function_ decides their type based on the inputs, rather than the _caller of the function_ declaring a type for `U`.

In your example:
```
fn foo(value: &impl std::fmt::Debug) -> impl std::fmt::Debug {
    42
}

fn main() {
    let dbg1 = foo(&""42"");
    let dbg2 = foo(Some(3));
    let debugs = vec![dbg1, dbg2];
    println!(""all debugs: {:#?}"", debugs);
}
```
This works with type parameters (if you declare the returning type to be u8 or something like that, to resolve the ambiguous integer type). It does NOT work with impl Trait - at no point does the function guarantee it returns the _same_ output type for those two _different_ input types.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:46:08Z,True,rust-lang_____rfcs_____2444_____390712258,"@Phlosioneer I think you're over-emphasizing the importance of knowing/caring about callee chosen vs caller chosen. A better comparison to make would be the difference between `fn foo(x: &Display) -> &Display` and `fn foo(x: impl Display) -> impl Display`, as they're much closer semantically.
",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:46:40Z,True,rust-lang_____rfcs_____2444_____390712408,"@sgrif IIRC, in the D language, turbofish allows omitting type params (from the end), they don't have to be substituted by `_`. If we had this in Rust, you wouldn't need `impl Trait` for arg types to satisfy your use case :)",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:49:23Z,True,rust-lang_____rfcs_____2444_____390713216,"@Boscop Yup, that's a direction we could go as well. As with all things, it's a tradeoff.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:52:51Z,True,rust-lang_____rfcs_____2444_____390714181,"@sgrif 
> It's equivalent to fn debug_query<DB, T>(query: &T) -> DebugQuery<opaque type you don't know anything about and don't choose, DB>. Whether or not the return type is the same as the input type is unimportant to this API. If I wanted to explicitly state that they were the same type, I'd give it a name and make that clear (e.g. make it a type parameter)

Yes, you're right, thank you.

However, I still think that it leads to confusion. There should be only exact one way to do some thing.

The main reason against `impl Trait` in input parameter is that it procides hard-to-spot monoporphisation.  As you pointed out, `fn foo(x: &Display) -> &Display` and `fn foo(x: &impl Display) -> impl Display` look similar a lot, while they are different. Some generic salt is a good here, imho. I can easily spot that  `fn foo<T: Display(x: &T) -> impl Display` will have a static dispatch, and I still can write `fn foo<T: Display(x: &T) -> T` if I want to express relationship between input and output types.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:57:29Z,True,rust-lang_____rfcs_____2444_____189649855,"@sgrif 
Wouldn't the actual equivalent of 
```java
void foo(SomeInterface arg)
``` 
be 
```rust
fn foo(arg: Rc<RefCell<dyn SomeTrait>>)
```
?

Because the instance is GC'ed and mutable.

So when translating Java code (or thinking) to Rust, one wouldn't just be able to write `fn foo(arg: impl SomeTrait)` instead of the java method anyway, because that would be different semantics (it takes ownership and can't mutate). One would have to re-architect the code in the translation process to use references/lifetimes and to please the borrow checker anyway. 
So `impl Trait` for args isn't really the equivalent (or what one wants) in most cases.",True,True
rust-lang_____rfcs_____2444,2018-05-21T16:59:37Z,True,rust-lang_____rfcs_____2444_____390716256,"> However, I still think that it leads to confusion. There should be only exact one way to do some thing.

Are you of the opinion that lifetime elision should also be removed? These two features have similar uses and drawbacks. You also can't provide a lifetime explicitly via turbofish when lifetime elision is being used. Sometimes you need to explicitly name them (either to show equivalence or some relationship between multiple lifetimes), but it's pretty rare. Same for `impl Trait`. Often you don't need to give a type parameter a name. It's probably more common to need to name a type (either to show equivalence or some relationship between multiple type parameters), but it's still somewhat rare.

I think it's important that we have a way to drop down to a lower level, either because you need to use a turbofish (extremely rare for argument parameters) or because you need to name a type. But this feature gives us a great parity between `fn foo(x: &Trait) -> &Trait` and `fn foo(x: impl Trait) -> impl Trait`.",True,True
rust-lang_____rfcs_____2444,2018-05-21T17:04:12Z,True,rust-lang_____rfcs_____2444_____390717474,"> Are you of the opinion that lifetime elision should also be removed? These two features have similar uses and drawbacks. You also can't provide a lifetime explicitly via turbofish when lifetime elision is being used. Sometimes you need to explicitly name them (either to show equivalence or some relationship between multiple lifetimes), but it's pretty rare. Same for impl Trait. Often you don't need to give a type parameter a name. It's probably more common to need to name a type (either to show equivalence or some relationship between multiple type parameters), but it's still somewhat rare.

No, lifetime elision is fine, because it's the only way to specify object lifetimes. There is no ""easier but more fragile syntax"" that allows you to write the very same thing but using a bit less characters.

I love `impl Trait`, but Rust already have a very nice and powerful generics. Having single way to write ""argument of type T"" have much higher value than possibility to sometimes inline type declarations. This is why I love `impl Trait` in return position: it's not possible to express is via existing language features. So it's a strict language expansion, while `universal-impl-trait` is substitution.",True,True
rust-lang_____rfcs_____2444,2018-05-21T17:11:37Z,True,rust-lang_____rfcs_____2444_____390719558,"We are going to take the unusual step of immediately closing and locking this RFC.

While there are clearly a lot of feelings on all sides of the issue, the fact is that this feature has shipped on the stable channel and is not going to be removed. This is both because of our basic stability guarantees but also because the decision was made in good faith and pursuant to our process, and we stand by that. 

After multiple years of RFC and tracking issue discussions (the first one was [RFC #105](https://github.com/rust-lang/rfcs/pull/105) in 2014!), the Rust Language Design Team ultimately reached a decision to ship this feature. This decision was not reached lightly. We discussed in depth a number of alternatives, including limiting `impl Trait` to return position as well as using an alternate syntax. Each has its pros and cons, and ultimately a judgement call had to be made. This is the nature of the language design process — indeed, any decision process. Few decisions are clear cut, which is why our process includes a number of points where feedback can be given, including a number of final-comment-period advertisements and the like. As a community, we have made a deliberate choice to slow down development to ensure thorough vetting and input into the process.

To be clear: we understand that there are downsides to this feature, and that some people find those downsides concerning. All of us care deeply about Rust, and it can be distressing to see people in power moving things in a direction you dislike. But, at the end of the day, we have to be able to make — and stick with — decisions, striking a balance between long-running feedback and shipping. Rust 2018 will ship with `impl Trait` in argument position.

-- @nikomatsakis and @aturon, on behalf of the Rust Language and Core Teams",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T19:04:38Z,True,algorithm-archivists_____algorithm-archive_____114_____390751118,"Alright, I was trying to be a little more subtle about it but the new code isn't good C++. It's C++ that might look good in a CppCon talk that showcases language features.

Sure, you might've given a nice name to `sum` but it *doesn't even just sums the elements.*. It's basically a map and a sum and with the use of `auto` in the lambda parameters you don't even know which parameter is supposed to be the index.

On the other hand you have a for loop *with a single state changing operation which is `+=`*. If that doesn't scream `sum` to you I don't know what to tell you. The thing you seem to be forgetting is that `sum` is part of the algorithm so the reader will have to understand that as well. Let's take a look at the first few lines of the function:

```cpp
  using return_type = decltype(f(0, *first));
  auto ret = return_type(0);
```

You very rarely have to use this pattern in everyday code. This is the kind of code that gives modern C++ advocates a bad name (which is a shame because I'm one of them when it makes sense): just add genericity and abstractions to a problem until it becomes completely unrecognizable. Do we want to emphasize that it's a sum? Sure, we can do that with some straightforward code:

```cpp
c64 fft_sum(size_t i, const std::vector<c64>& values) {
    auto sum = c64(0);
    auto size = values.size();
    for (size_t k =0 ; k < size; ++k) {
        sum += values[k] * std::exp(c64(0, -2.0 * pi<double>() * k * i / size));
    }
    return sum;
}

std::vector<c64> discrete(const std::vector<c64>& values) {
    std::vector<c64> result(values.size());

    auto size = values.size();
    for (size_t i = 0; i < size; ++i) {
        result[i] = fft_sum(i, values);
    }

    return result;
}
```

I'm still against this version because it still obfuscates part of the algorithm but at least it doesn't add unneeded complexity.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T19:29:02Z,True,algorithm-archivists_____algorithm-archive_____114_____390757274,"@Gustorn I disagree absolutely completely. We should write what we want to happen, in a declarative style, *not* in an imperative, tell the machine what should happen, sort of way. This is the basis of good code design.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T19:44:46Z,True,algorithm-archivists_____algorithm-archive_____114_____390761104,"Yup, the pinnacle of declarative code right here:

```cpp
template <typename It, typename F>
auto sum(It const first, It const last, F f) {
  using return_type = decltype(f(0, *first));
  auto ret = return_type(0);

  std::size_t i = 0;
  for (auto it = first; it < last; ++it, ++i) {
    ret += f(i, *it);
  }

  return ret;
}
```

As I mentioned, *sum is part of the algorithm*. This is why abstraction doesn't work well here: you have to understand the *whole code* to understand how it works, you're not just going to look at pieces of it in isolation. Also the whole notion that declarative style is *always* better than imperative style is kind of ridiculous. The key is to recognize which one to use and when. All that being said, I'm not very motivated to keep going with this argument since it feels like I'm arguing against C++ blog posts and talks and not against actual technical arguments. 

",True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T19:46:36Z,True,algorithm-archivists_____algorithm-archive_____114_____390761532,@Gustorn the point is that _`sum` is an implementation function_. That's why it has a name. You don't need to read it.,True,True
algorithm-archivists_____algorithm-archive_____114,2018-05-21T20:50:25Z,True,algorithm-archivists_____algorithm-archive_____114_____390778370,"Even if we don't end up with iterator functions, we can write:

```cpp
std::valarray<c64> recursive(std::valarray<c64> input) {
  auto const size = input.size();
  if (size < 2) {
    return input;
  }

  auto evens = std::valarray<c64>(input[std::slice(0, size / 2, 2)]);
  auto odds = std::valarray<c64>(input[std::slice(1, size / 2, 2)]);

  evens = recursive(evens);
  odds = recursive(odds);

  // now combine each of those halves with the butterflies
  auto ret = std::valarray<c64>(size);
  for (std::size_t k = 0; k < size / 2; ++k) {
    auto w = odds[k] * std::polar(1.0, -2.0 * pi<double>() * k / size);
    ret[k] = evens[k] + w;
    ret[k + size / 2] = evens[k] - w;
  }
  return ret;
}

// `iterative` does the cooley-tukey algorithm iteratively
std::valarray<c64> iterative(std::valarray<c64> input) {
  sort_by_bit_reverse(begin(input), end(input));

  // perform the butterfly on the range
  auto const size = input.size();
  for (std::size_t stride = 2; stride <= size; stride *= 2) {
    auto w = exp(c64(0, -2.0 * pi<double>() / stride));
    for (std::size_t j = 0; j < size; j += stride) {
      auto v = c64(1.0);
      for (std::size_t k = 0; k < stride / 2; k++) {
        input[k + j + stride / 2] =
            input[k + j] - v * input[k + j + stride / 2];
        input[k + j] -= (input[k + j + stride / 2] - input[k + j]);
        v *= w;
      }
    }
  }

  return input;
}

std::valarray<c64> discrete(std::valarray<c64> input) {
  auto const size = input.size();

  auto ret = std::valarray<c64>(size);

  iota_transform_n(begin(ret), 0, size, [&](std::size_t i) {
    return sum(0, size, [&](auto const k) {
      auto const coefficient = input[k];
      auto const expression =
          c64(std::cos(-2.0 * pi<double>() * i * k / size),
              std::sin(-2.0 * pi<double>() * i * k / size));
      return coefficient * expression;
    });
  });

  return ret;
}
```

which is much more understandable.",True,True
mysqljs_____mysql_____1962,2018-05-22T04:04:53Z,True,mysqljs_____mysql_____1962_____390856212,"The merge process last so long, and the pr is still not merged. So it there any alternative way to solve the problem of ""ER_NOT_SUPPORTED_AUTH_MODE: Client does not support authentication 
authentication ""? I am nodejs startup and just want to connect to mysql 8.0 for demo.",True,True
mysqljs_____mysql_____1962,2018-05-22T08:07:30Z,True,mysqljs_____mysql_____1962_____390900841,"@fan123199 everything should still work if you use the `mysql_native_password` plugin.

```sql
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'YourRootPassword';
-- or
CREATE USER 'foo'@'%' IDENTIFIED WITH mysql_native_password BY 'bar';
```
",True,True
rust-lang_____rfcs_____2426,2018-05-23T12:24:46Z,True,rust-lang_____rfcs_____2426_____391327320,":bell: **This is now entering its final comment period**, as per the [review above](https://github.com/rust-lang/rfcs/issues/2426#issuecomment-390503385). :bell:",True,True
rust-lang_____rfcs_____2426,2018-05-23T17:18:11Z,True,rust-lang_____rfcs_____2426_____391429191,"@Centril Then you create [this](https://github.com/anp/rfcbot-rs/pull/210), out of pure spite, because your personal PR wasn't well received? So you think just because you made a PR that wasn't so well received within the community, gives you the right to strip everyone other community member of their right to downvote? That's extremely unprofessional.",True,True
rust-lang_____rfcs_____2426,2018-05-23T21:12:14Z,True,rust-lang_____rfcs_____2426_____391497962,I propose removing @Centril from the Rust project as a whole. He wants to ban thumbs-down reactions -- I want to ban *him*. None of his contributions have been productive and he has only managed to provoke pointless flame wars.,True,True
rust-lang_____rfcs_____2426,2018-05-23T21:23:40Z,True,rust-lang_____rfcs_____2426_____391501107,"@m-cat With respect, I have to disagree. @Centril is one of the most [prolific authors of RFCs](https://github.com/rust-lang/rfcs/pulls?page=1&q=is%3Apr+author%3ACentril&utf8=%E2%9C%93), and many of them are accepted.

@Centril may disagree on a lot of issues, but I think the community would worse without them.",True,True
rust-lang_____rfcs_____2426,2018-05-23T21:29:40Z,True,rust-lang_____rfcs_____2426_____391502641,"**Moderation note**

@m-cat such comments are very clearly against our [code of conduct](https://www.rust-lang.org/conduct.html). Further such behavior will result in a ban from the project.

Feel free to contact us at rust-mods@rust-lang.org if you have questions.",True,True
rust-lang_____rfcs_____2426,2018-05-23T21:31:34Z,True,rust-lang_____rfcs_____2426_____391503160,@Manishearth Why are you deleting people's comments?,True,True
rust-lang_____rfcs_____2426,2018-05-23T21:33:19Z,True,rust-lang_____rfcs_____2426_____391503635,"[Comments/questions about moderation should go to the moderation team, please.]",True,True
rust-lang_____rfcs_____2426,2018-05-23T21:33:39Z,True,rust-lang_____rfcs_____2426_____391503737,@Manishearth Can you tell me *exactly* how I violated the code of conduct?,True,True
rust-lang_____rfcs_____2426,2018-05-23T21:34:30Z,True,rust-lang_____rfcs_____2426_____391504002,"> Feel free to contact us at rust-mods@rust-lang.org if you have questions.

This is not the place to discuss this.",True,True
rust-lang_____rfcs_____2426,2018-05-23T21:36:48Z,True,rust-lang_____rfcs_____2426_____391504647,"Apparently it's not the place to discuss anything.

What a disappointment for a supposedly community-driven project. This entire debacle (along with `impl Trait` in argument position) has been a sham. Anyway, I won't comment here any more.",True,True
rust-lang_____rfcs_____2426,2018-05-23T21:46:27Z,True,rust-lang_____rfcs_____2426_____391507049,"> This is not the place to discuss this. @Manishearth 

No worries sir, it's already being discussed here:
https://www.reddit.com/r/programmingcirclejerk/comments/8lkaw3/downvotes_are_not_exciting/",True,True
rust-lang_____rfcs_____2426,2018-05-23T22:17:51Z,True,rust-lang_____rfcs_____2426_____391514606,"Well, let's draw a line.

I do believe that everybody agrees on that this issue produces a lot of arguing. However, I think that problem is much deeper than just this issue, it's about the whole desicion process.

So, we can tilt at windmills and discuss implications instead of problem source, OR we can do the later. 

The main idea that some RFCs get accepted when they actually are not welcomed by the majority. It seems that the whole process is broken as we can't give a feedback if something goes wrong.

E.g. I read this RFC. I disagree with it. How can I make it not happen? I should get 100+ upvotes on some very critical comment? I should write my own RFC ""please, don't do RFC#42""? I should apply some Mozilla job and get into the core team? Or I can do just nothing and it will be accepted whenever I like it or not? (when I say ""like"" I mean something bigger than just my emotional state, but rather the overall feeling based on my professional experience). 

If you can answer this question then we can have some valuable talk. It's completely ok if you say that my opinion doesn't matter until I'm in core team, because there are ten persons who decide what's going to be included in the language, but please, be honest with me. @Centril says that it's a huge disappointment then you spend a lot of time, writing an RFC or a comment like this, when it was useless. Just say ""we don't need your opinion"" and we will save literally thousands of manyears that could have a better application as well as a better atmosphere in comments.",True,True
rust-lang_____rfcs_____2426,2018-05-23T22:23:21Z,True,rust-lang_____rfcs_____2426_____391516077,**Moderation note:** There are multiple [discussions](https://internals.rust-lang.org/t/fortifying-the-process-against-feature-bloat/7608/24) happening in the forum about the RFC process.  Please keep process discussion in the forums and out of individual RFC PRs.,True,True
rust-lang_____rfcs_____2426,2018-05-23T22:25:43Z,True,rust-lang_____rfcs_____2426_____391516675,"I'm going to go ahead and close out this RFC (which is in FCP for postponement), as I think it's quite clear we won't be pushing on this in the near future, and the thread is continuing to veer well off topic.",True,True
rust-lang_____rfcs_____2426,2018-05-23T22:37:09Z,True,rust-lang_____rfcs_____2426_____391520385,"> I'm going to go ahead and close out this RFC 

You're not supposed to just close the thread, you're supposed to close it and limit it to collaborators only.",True,True
mysqljs_____mysql_____1962,2018-05-24T04:37:07Z,True,mysqljs_____mysql_____1962_____391585418,"In addition to what @ruiquelhas said, I also had to:
```
mysql> FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.00 sec)
```
And then restart the server.
If you are using multiple MySQL users, ensure that you update all of them. In my case I also had to use `'%'` instead of `'localhost'`.",True,True
MoonchildProductions_____UXP_____395,2018-05-27T14:07:08Z,True,MoonchildProductions_____UXP_____395_____190789425,"This PR enforces the use of SSE2 when building UXP with any version of GCC. In addition, if a user attempts to start either Pale Moon or Basilisk on a system that does not support SSE2, an error message should be displayed instead of the browser just silently failing to start.

I've tested and can confirm that SSE2 is being enforced on GCC builds on Linux, however I do not have any non-SSE2 hardware to test that the error message is displayed.",True,True
MoonchildProductions_____UXP_____395,2018-05-27T14:53:13Z,True,MoonchildProductions_____UXP_____395_____392336979,I don't think this will override optimization flags in mozconfig... Does it?,True,True
MoonchildProductions_____UXP_____395,2018-05-27T15:05:14Z,True,MoonchildProductions_____UXP_____395_____392337864,"Yes it should override mozconfig flags because these flags are passed to the compiler after mozconfig flags, thus overriding them.

@wolfbeast what do you think? Enforce for all UXP applications or only for official branding? I’m fine with either approach; just want to prevent a slew of builds showing up that supports ancient hardware.",True,True
MoonchildProductions_____UXP_____395,2018-05-27T15:14:59Z,True,MoonchildProductions_____UXP_____395_____392338554,"I no I was not asked, but in my opinion, it should at most only effect
officially branded builds.
",True,True
MoonchildProductions_____UXP_____395,2018-05-27T15:45:42Z,True,MoonchildProductions_____UXP_____395_____392341153,"I think this should apply regardless of build. UXP is a modern platform and should not be used to target very old hardware. There are more areas where this is or will be a problem as things are developed. It should not be left ""up in the air"" to break later on (which it will) by allowing it now.

SSE2 is and should be a hard requirement for all UXP applications.",True,True
MoonchildProductions_____UXP_____395,2018-05-27T15:47:50Z,True,MoonchildProductions_____UXP_____395_____392341405,@wolfbeast in that case this is ready to merge.,True,True
MoonchildProductions_____UXP_____395,2018-05-27T23:14:31Z,True,MoonchildProductions_____UXP_____395_____392385130,Doesn't this mean sse2 will override my specification of avx or avx2 when building and not cover this case at all?,True,True
calamares_____calamares_____966,2018-05-27T23:47:53Z,True,calamares_____calamares_____966_____190812827,"renamed openrccfg and cleaned up, due to a new runitcfg module to have a naming schema.",True,True
MoonchildProductions_____UXP_____395,2018-05-27T23:59:18Z,True,MoonchildProductions_____UXP_____395_____392389256,"The sse2 flags should only override mozconfig flags that are contradictory (such as -mno-sse2); avx and other flags should not be overwritten.

I can't speak about ARM as I'm not familiar enough with it. Would have to do some research.

I can prepare a patch that will allow this to be overridden in mozconfig or we can use a Directive 4 solution. I'm fine with either.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T00:14:43Z,True,MoonchildProductions_____UXP_____395_____392390426,"Your solution would be fine if the only applications were Basilisk and Pale Moon. They are not, however. Also, Directive 4 is only in effect for specific applications and only then for specific branding, namely ours.

It is also complemented by a private build configure flag to override that with transformative results like the text in the about boxes indicating its private build status.

My post above was directed to Moonchild more than you.

The bottom line is just like there must be balance between Developer and User choices with UXP there must be balance between Moonchild Productions and the rest of the world who would use the platform. Be it minor rebuilds, forks, or independent applications.

That is the reason, or so I thought, that UXP is a thing.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T00:43:49Z,True,MoonchildProductions_____UXP_____395_____392392415,"I agree.
",True,True
MoonchildProductions_____UXP_____395,2018-05-28T02:53:20Z,True,MoonchildProductions_____UXP_____395_____392405785,"I'm not sure why there is this much discussion. directive 4, Moonchild Productions applications vs. others etc. should not matter.
The solution must be one that applies regardless of application (so in `confvars.sh` is actually not a good place) that enforces SSE2 for the platform as a whole. A combination of filtering out unwanted disable flags and adding desired enable flags, applied for all platforms, would be best. This should be in the platform's root configuration somewhere, probably.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T03:17:37Z,True,MoonchildProductions_____UXP_____395_____392408553,I don't want to be limited to Pale Moon or Basilisk configuration. This means be it Borealis or XUL Runner or anything else I am forced to be SSE2. I shouldn't have to fork the platform because you are making product and marketing decisions for everyone.,True,True
MoonchildProductions_____UXP_____395,2018-05-28T03:18:35Z,True,MoonchildProductions_____UXP_____395_____392408653,"What about if we add a configure option (--enable-modern-simd or something similar) that could be enabled by default and would enforce the SSE2 flags be passed to the compiler. We could also tie in the warning message flag to this option, and use directive 4 to ensure that this option is always used when building with official branding.

It would allow people to override it in mozconfig, but maybe it would be an acceptable compromise?",True,True
MoonchildProductions_____UXP_____395,2018-05-28T03:29:43Z,True,MoonchildProductions_____UXP_____395_____392409840,"How it should work is if you want to assume SSE2 on an application basis then do so. If you want to be kind then ifdef it based on that..

Let Directive 4 enforce the optimization for it on official branding.

Minor rebuilds, forks of the code, and private builds should be able to do what they want with a minimum of imposed conditions. UXP is NOT mozilla-central or palemoon-central or basilisk-central.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T03:45:14Z,True,MoonchildProductions_____UXP_____395_____392411423,"So, you're insisting on wanting UXP to be somehow catering to pre pentium-IV hardware.
You do realize that this goes beyond just compiler optimizations, right, and that the SSE2 assumption **will** be made for hot paths in our development? I want to enforce SSE2 on the platform as a whole because it makes NO SENSE to keep catering to and targeting IA32 in 2018, and it will actually prevent some planned code improvements.
",True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:02:16Z,True,MoonchildProductions_____UXP_____395_____392413120,"Not really I prefer to use superior intruction set to SSE2 but if you enforce SSE2 then that overrides my ability to use AVX or newer.

Also, just how much is actually dependent on any arbitrary instruction set? That hasn't even been stated or made clear. To me it looks like 3rd party libs using assembly.

Now at some point in the future some of those libs may not have mmx or sse instructions and at that time it can be considered and justified then.

THIS is about impossing a restriction and indeed locking in of a specific instruction set without cause or justification beyond it is not how branded Basilisk or Pale Moon builds should be configured.

Assuming a position of SSE2 only for the entire platform for the same reasons as Windows XP needs to be justified.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:14:34Z,True,MoonchildProductions_____UXP_____395_____392414366,"You clearly misunderstood
it's a MINIMUM.
Since this is getting out of hand here, let's discuss on the forum.
https://forum.palemoon.org/viewtopic.php?f=62&t=19269",True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:15:18Z,True,MoonchildProductions_____UXP_____395_____392414427,fwiw I had the same misunderstanding. ,True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:20:52Z,True,MoonchildProductions_____UXP_____395_____392414993,"I really don't see how this could have been misunderstood. Enforcing a specific SIMD level is *always* listed as a minimum. But hey, what do I know.
Great start of the week, at any rate. :frowning_face: ",True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:24:23Z,True,MoonchildProductions_____UXP_____395_____392415470,"I can't discuss this at the forum. Also, as implimented this tacts on and enforces sse2 at the end of the MOZ_OPTIMIZE string despite what is specified before it in mozconfig.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:36:19Z,True,MoonchildProductions_____UXP_____395_____392416769,Let me be absolutely crystal clear here if I specify to build as AVX or AVX2 will this as implimented still comple as SSE2?,True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:42:54Z,True,MoonchildProductions_____UXP_____395_____392417573,I agree -- I am in favor of a build failing due to being miss-configured and not in favor of it being silently overridden.  ,True,True
MoonchildProductions_____UXP_____395,2018-05-28T04:46:44Z,True,MoonchildProductions_____UXP_____395_____392418007,"Right, well that needs to be fixed then. it's not supposed to override -arch:AVX etc. This is why I made a point of saying to FILTER OUT as-needed.
The default for msvc is sse2. so it needs to filter out -arch:SSE and -arch:IA32.
And no, I do not agree with build failure, because then you'd have to put in extra checks EVERYWHERE
",True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:02:17Z,True,MoonchildProductions_____UXP_____395_____392419703,"I guess I'll have to do this myself, then.",True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:04:18Z,True,MoonchildProductions_____UXP_____395_____392419926,Doesn't look like this PR is even touching windows compilation. so what's all the screaming about?,True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:07:46Z,True,MoonchildProductions_____UXP_____395_____392420291,"No you don't.. It is very simple to do it in a similar manor as I did for Directive 4 but NOT directive 4. It can be done from configure very early on in the process.

It isn't a problem and it can be a simple list of forbidden optimization flags.

Would this be acceptable?",True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:11:38Z,True,MoonchildProductions_____UXP_____395_____392420769,It would be very much appreciated if it was handled in the manner suggested above (by Tobin).,True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:17:27Z,True,MoonchildProductions_____UXP_____395_____392421494,Go ahead Tobin.,True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:19:43Z,True,MoonchildProductions_____UXP_____395_____392421795,Incompatible optimizations is a configure error.,True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:21:53Z,True,MoonchildProductions_____UXP_____395_____392422065,"Thanks for that info.. I'll be sure to knock down the case for processing.

I will get to work on this later today. Could you please revert this and the follow up?",True,True
MoonchildProductions_____UXP_____395,2018-05-28T05:44:06Z,True,MoonchildProductions_____UXP_____395_____392425041,Both have been reverted.,True,True
calamares_____calamares_____966,2018-05-28T08:40:34Z,True,calamares_____calamares_____966_____191146718,"Most modules have some documentation explaining what the module does, above this --- comment line.",True,True
calamares_____calamares_____966,2018-05-28T08:41:14Z,True,calamares_____calamares_____966_____191146856,"Most modules have a short bit of documentation about the configuration in general, above this --- comment line.",True,True
calamares_____calamares_____966,2018-05-28T08:52:31Z,True,calamares_____calamares_____966_____191149804,"Most modules have documentation on the keys and possible values. Here, something like 

> *services* is a map with one of more object keys (e.g. *add*) that correspond to
> the first argument of rc-update. The following keys are in use: *add*, *del*.
> The value of each of those keys is a list of service maps; each of those service
> maps has a key *name* and a key *runlevel*. The named service is added, or
> deleted, from the given runlevel. To add or remove a service from multiple
> runlevels, list it multiple times with different runlevels.

",True,True
calamares_____calamares_____966,2018-05-29T06:50:59Z,True,calamares_____calamares_____966_____191318464,"Should something be logged if it doesn't exist? That means there's a mismatch between the configuration, and the installed system.",True,True
calamares_____calamares_____966,2018-05-29T06:52:04Z,True,calamares_____calamares_____966_____191318678,"Maybe `check_target_env_call`, and catch the possible exception in order to log it (or let it go, then the user gets a real cancel message).",True,True
calamares_____calamares_____966,2018-05-29T07:00:05Z,True,calamares_____calamares_____966_____392672707,"@udeved Looks a lot better and cleaner, too. It does have a lot of review comments, but those are ""icing on the cake"" things.",True,True
calamares_____calamares_____966,2018-06-01T17:16:28Z,True,calamares_____calamares_____966_____192460448,"To be honest, I don't think this even needs to be in here. I assume distro maintainers will know exactly what services are present on the ISO image, so this check is kinda redundant.",True,True
calamares_____calamares_____966,2018-06-01T17:23:02Z,True,calamares_____calamares_____966_____192462006,"rc-update add/del service only creates/removes a symlink from /etc/init.d/service to /etc/runlevels/runlevel/service ... so unless the service file is missing it will always succeed ... 

at this point, my previous comment may look redundant (if exists is needed after all), but I stand by it : distro maintainers should know exactly what services are present on the ISO...",True,True
calamares_____calamares_____966,2018-06-01T17:35:01Z,True,calamares_____calamares_____966_____192465002,"altough OpenRC allows adding same service into multiple runlevels, this is a bad behaviour...OpenRC is a dependency based init system, everything must be started at a specific point...I don't want to encourage people to add say NetworkManager to sysinit runlevel, which is only intended to start critical services (udev, devfs, sysfs)...

that's why I really think this module should only limit itself to the default runlevel...other runlevels (sysinit, boot) are critical to bring the box up, so the installer must not touch them...",True,True
calamares_____calamares_____966,2018-06-01T17:42:37Z,True,calamares_____calamares_____966_____192467019,"Don't be pedantic here please @V3n3RiX 
This is an installer module, not a thing to play around with for users.
Reason for a variable holding a runlevel is elogind, which needs to be in boot runlevel. Some distros may not have set it, and I want to keep it open for such cases.",True,True
calamares_____calamares_____966,2018-06-01T17:44:16Z,True,calamares_____calamares_____966_____192467457,The check for the service to exist is error tolerance. I find it better than catching exit code.,True,True
calamares_____calamares_____966,2018-06-01T18:08:01Z,True,calamares_____calamares_____966_____192473974,"@udeved  
And that is a $Distribution problem not the installer one.
If you write configuration files on ISO creation then be sure they do
the right thing.

It is insane to allow touching boot runleves.

Well again this is a problem of that Distro to NOT taking care of sane
defaults.

I agree with @V3n3RiX  here .. allow default and nothing else.

",True,True
calamares_____calamares_____966,2018-06-01T18:13:37Z,True,calamares_____calamares_____966_____192475492,"Well, I can also withdraw the PR. It is really quite simple, either live with a variable holding a runlevel, or don't and I withdraw.",True,True
calamares_____calamares_____966,2018-06-01T18:24:32Z,True,calamares_____calamares_____966_____192478390,"there's no hard requirement for elogind to be in boot runlevel, that's only a recommandation (which frankly I find weird, since elogind needs dbus, and dbus is usually started in default runlevel **after** elogind) ... truth is elogind may not be present at all in any runlevel as dbus will start it when something calls elogind (dbus activation) ... you can do some tests to confirm this ...

I really think we should focus on user facing services (nm, cups, whatever) aka default runlevel only ... and if you really really really want elogind in boot runlevel, you can do that at iso build time ... ",True,True
calamares_____calamares_____966,2018-06-01T18:29:00Z,True,calamares_____calamares_____966_____192479579,"@udeved 

don't get me wrong but everyone seems to (ab)use
calamares to push any kind weird workarounds
for broken ISOs , packaging issues etc , upstream.

Yes you offer something and we all discuss a good way to
get it in.

Eat that or die is not going to work , is really simple.",True,True
calamares_____calamares_____974,2018-06-01T18:44:15Z,True,calamares_____calamares_____974_____192113045,"* openrc-services module
* why reivent stuff? take existing code from systemd one and reuse it
* runlevel is static and 'default' only, any other runlevel setup is insane

This is my implementation of openrc-services module, thanks to @abucodonosor for forcing me to write this.

As my comments in the other PR with similar functionality, any other runlevel setup is redundant, so this is limited to 'default' only. I reused as much code as possible from systemd one...",True,True
calamares_____calamares_____966,2018-06-01T18:45:02Z,True,calamares_____calamares_____966_____192483573,"I am not the nanny to enforce whatever on distros.
Variable runlevel will stay as it is.",True,True
calamares_____calamares_____966,2018-06-01T18:59:58Z,True,calamares_____calamares_____966_____192487298,"I don't disrespect you, and if I said something that makes you feel that way, I apologize ... I happen to maintain an OpenRC based distro, and I know for a fact that some things can be done outside of the installer, that's why my strong disagreement with the design of this module ... Everything I said was from a technical view, nothing personal, and I'm sorry you feel that way ...",True,True
calamares_____calamares_____966,2018-06-01T19:06:16Z,True,calamares_____calamares_____966_____192488829,"I was basically complaining about @abucodonosor tone @V3n3RiX 

I know you maintain an openrc distro, and I am generally willing to contribute a module for non systemd. Hence the PR, but the variable holding the runlevel won't be changed, no way, its a featrze distros may or may not use. No harm is done with a variable, and if distros responsibly use the module, its fine. If they use only default runlevel, its fine, if some distro wishes to add a different runlevel, the code supports it. Its not only elgogind eventually, it could be lvmetad whatever some distro may require on iso.",True,True
calamares_____calamares_____974,2018-06-01T19:36:47Z,True,calamares_____calamares_____974_____393987757,"Ok, go with your module, its now pointless to have two modules, I'll close my PR. 
I keep patching.",True,True
calamares_____calamares_____974,2018-06-01T19:56:42Z,True,calamares_____calamares_____974_____393992557,"It's pointless to have 2 modules, true, but it's not pointless to have 2 PR's and let @adriaandegroot decide ...  I made some comments on your PR, this is just to show how the module would look according to those comments and to show I'm not just a blabbermouth ... ",True,True
calamares_____calamares_____974,2018-06-01T20:09:18Z,True,calamares_____calamares_____974_____393995620,"@V3n3RiX 

This isn't a **** waving contest, really. I know you are an able distro guy, I was just absolutely discontent with the other guy's tone. 
But really, it is more insane to statically do runlevels, only topped by people who set crazy stuff. Then again, this is a installer module, and I trust distro devs they know what they are doing. I just do not get along with enforcing stuff on others, and I like to keep code more flexible.
Calamares is rather a minor focus on artix, time for installer is sparse, if you maintain and develop other stuff.",True,True
calamares_____calamares_____974,2018-06-01T21:44:49Z,True,calamares_____calamares_____974_____394017412,"We're probably the only 2 OpenRC distros using Calamares as installer and we have a different point of view of what the installer should do regarding services.  The code in this PR is what **I** think is a sane approach, since 99% of services belong to 'default' runlevel (multi-user.target.wants in systemd world) ... 

Your own ISO scripts only touch 'default' runlevel (I took a quick look) same as ours ... It's a bit weird to me you want to expand that to do more stuff in calamares instead ... I guess we will have to agree we disagree ...",True,True
calamares_____calamares_____966,2018-06-01T21:58:05Z,True,calamares_____calamares_____966_____192525200,"@V3n3RiX:
> I assume distro maintainers will know exactly what services are present on the ISO image

This is not really true. There can be custom remixes of the ISO based on the packages (including the Calamares configuration) from the upstream distribution. The upstream distribution (which writes the configuration) has no way to know what ends up on such a custom ISO.",True,True
calamares_____calamares_____966,2018-06-01T21:59:15Z,True,calamares_____calamares_____966_____192525355,"I am in no way an OpenRC expert (I use systemd exclusively), but I also don't see why the runlevel to use needs to be hardcoded.",True,True
calamares_____calamares_____974,2018-06-01T22:03:00Z,True,calamares_____calamares_____974_____394021485,"I think having 2 competing modules doing the same thing floating around is not going to help anybody in the long run. This is going to be `bootloader` vs. `bootldr` all over again. Can you please agree on one implementation covering all use cases? If some people think that adding services to non-default runlevels is useful, then surely that should be an option. All these are packager options and not settable by the average end user anyway.",True,True
calamares_____calamares_____966,2018-06-01T22:03:12Z,True,calamares_____calamares_____966_____192525932,"@kkofler 

Precisely, tomorrow, a distro dev of an perhaps unknown openrc distro comes and asks for a feature to set a different runlevel, It may even be a custom runlevel, eg nonetwork whatever. We would add back stuff we just ripped out. I find the insistence to hardcode the runlevel not wise.",True,True
calamares_____calamares_____966,2018-06-01T23:42:40Z,True,calamares_____calamares_____966_____192538019,"I don't think is upstream distributions job to even care about what ends up in such remixes. You have your own Fedora remix, do you take everything as is, or do you make adjustments to suit your needs? ",True,True
calamares_____calamares_____966,2018-06-02T00:04:41Z,True,calamares_____calamares_____966_____192539768,"Well, the situation is a bit particular because I maintain both the remix (Kannolo) and the Fedora package for Calamares. I tried hard to make the configuration shipped by the Fedora package work for remixes too. (I even pick up the branding from where a Fedora Remix normally puts it to autogenerate a Calamares branding.) I still do a couple of tweaks to the Kannolo Calamares configs, but the idea is that Calamares ought to work even without those tweaks.",True,True
calamares_____calamares_____966,2018-06-02T00:10:07Z,True,calamares_____calamares_____966_____192540156,"Interesting @kkofler 

We take a slight different approach to the conf files.
upstream installs the standard conf files in /sur/share/calamares/modules, we override them in /etc/calamares/modules.
But, the build script for iso writes some of the distro overrides conf, eg services based on the build script's conf. Ie, we hand over the the conf values of the buildscript to calamares module conf files where required to get around the issue of packaging hell with basically variable conf.",True,True
calamares_____calamares_____974,2018-06-02T01:32:43Z,True,calamares_____calamares_____974_____394046798,"i plan on using calamares to install openrc also - if youre looking for a tie breaker i dont think it is necessary to refer to the specifics - probably logic should be enough here

if the argument is that 99% of cases are ""foo"" and so therefore ""foo"" should be hard-coded in; that is the same as saying that anyone who wants to do something in the remaining 1% will need to patch - so the question would be: is this too much work to support that 1% use-case? or would it be so difficult to implement that it should be left to the special case that requires it (and maybe they will send in a patch here)? or would accommodating that 1% use-case? be problematic for the 99% general cases?

what exactly would be the value of hard-coding anything unless there is a critical reason to specifically prevent any alternative? what could possibly be the downside of leaving the option open? after all, an option that is not changed from its default is equivalent to the hard-coded mandate - yes?
",True,True
calamares_____calamares_____966,2018-06-02T08:04:07Z,True,calamares_____calamares_____966_____192553353,"The exact way the conf files are handled in the Fedora Calamares package is that I install my configuration to `/usr/share/calamares/modules` (I patch the upstream conf files to the settings I need), and remixes such as Kannolo can then write further customizations to `/etc/calamares/modules` (which ships empty in the package).",True,True
calamares_____calamares_____974,2018-06-02T09:51:09Z,True,calamares_____calamares_____974_____394074571,"my argument is distro maintainers should do their part, and try not to force distro specific workarounds into the installer...calamares is an installer and shouldn't be used by distros as a fix-up tool for some internal quirks...

the only argument for supporting boot runlevel is elogind, which is not a requirement, and I already explained myself in the other PR...

but why stop there? ... let's support sysinit runlevel as well which is much more insane ... ",True,True
calamares_____calamares_____974,2018-06-02T10:53:03Z,True,calamares_____calamares_____974_____394078134,"let's give some examples : 

Runlevel: sysinit
 sysfs                [  started  ]
 devfs                [  started  ]
 udev                 [  started  ]
 dmesg                [  started  ]
 kmod-static-nodes    [  started  ]
 opentmpfiles-dev     [  started  ]
 udev-trigger         [  started  ]
 udev-settle          [  started  ] 

Runlevel: boot
 hwclock           [  started  ]
 modules           [  started  ]
 lvmetad           [  started  ]
 lvm               [  started  ]
 device-mapper     [  started  ]
 dmcrypt           [  started  ]
 fsck              [  started  ]
 root              [  started  ]
 mtab              [  started  ]
 swap              [  started  ]
 localmount        [  started  ]
 procfs            [  started  ]
 sysctl            [  started  ]
 bootmisc          [  started  ]
 termencoding      [  started  ]
 consolefont       [  started  ]
 urandom           [  started  ]
 loopback          [  started  ]
 binfmt            [  started  ]
 keymaps           [  started  ]
 hostname          [  started  ]

These are pretty much **all** services that **need** to be started from these 2 runlevels. Do we really want calamares to even thouch them ? These runlevels are usually touched by packages or packages-scripts, and you'll find these enabled in both live and installed environment alike ... 

In a way, these are systemd's basic.target or whatever it's called. Systemd services module won't allow messing with these (systemd cant do it anyway) , why should openrc services allow it? Systemd services module plays around with multi-user.target only, so this module does the same : plays with 'default' runlevel only.",True,True
calamares_____calamares_____966,2018-06-03T05:40:26Z,True,calamares_____calamares_____966_____192577731,"I think this discussion deviated a lot :) .. but may be just me.

IMHO, an installer should do only his intended job: do some preparation on the HDD, deploy the system, do some configs. But those configs should be kept to a minimum, to the level of 'what an inexperienced user can choose and handle'.

Major system tweaks, at the level where the system can easily render un-bootable/unusable should be handled by the distro devel/maintainer, otherwise the installer is no longer an installer but tend to became a patching/hacking tool.

I am watching calamares since it was a small octopus and I loved exactly the idea of modularity: you can have as much as many modules you want for any particular case.
And if one does not exist for an edge case, the distro dev can easily add his own, or tweak an existing one, the actual modules are written with self explanatory code for my eyes.

But having mega-super modules, tweaked for all possible scenarios, I think is a terrible idea. The code should be kept to a level of 'do what is generic and really useful'.
I really don't understand why other runlevels are needed ... even the author says is not using them in fact, the rest of the cases where 'may be needed later' are just speculations.
I agree, hard-coding it is not a good idea and i hate such too ... but in the end, the discussion is:
There is **a real** need for **other** runlevels to be handled by the installer?",True,True
calamares_____calamares_____966,2018-06-03T06:06:41Z,True,calamares_____calamares_____966_____394139575,"not particularly related to the actual discussion:
- the name of the module may me a bit confusing. A name containing 'cfg' leads me to the idea it is configuring that service/package .. which may not be 100% true, in fact the this module is just enabling/disabling others.
May be more suggestive if the module is named 'openrc-services' ?
(and the actual existing 'services' module renamed to 'systemd-services?')

I know, some distro maintainers will scream if suddenly an existing module is renamed, but in my opinion will be more suggestive ....
",True,True
calamares_____calamares_____966,2018-06-03T06:24:53Z,True,calamares_____calamares_____966_____192578509,">> There can be custom remixes of the ISO based on the packages (including the Calamares configuration) from the upstream distribution. The upstream distribution (which writes the configuration) has no way to know what ends up on such a custom ISO.

That's true, but I think any decent dev team has a minimum of skills to figure out what such source iso contains ... it is not rocket science to unpack and look into it.
Otherwise, if the development process of the distribution is sort of 'I blindly grab something and patch it' .. i don't think such distribution is trustworthy ...",True,True
calamares_____calamares_____966,2018-06-03T06:52:24Z,True,calamares_____calamares_____966_____192579117,"> Precisely, tomorrow, a distro dev of an perhaps unknown openrc distro comes and asks for a feature to set a different runlevel, It may even be a custom runlevel, eg nonetwork whatever.

Good point!
So, what is the limit to extend calamares? Put into it 'whatever somebody may dream tomorrow' .. or keep it at a decent level of flexibility and stability (which still has to be defined, but that is a different story .. )?",True,True
calamares_____calamares_____966,2018-06-03T07:10:01Z,True,calamares_____calamares_____966_____192579528,"as for the 'hard-coding' issue, the solution may very simple:
```
SYNOPSIS
     rc-update [-s, --stack] add service [runlevel ...]
 # rc-update add cupsd
 * rc-update: cupsd already installed in runlevel `default'; skipping
# rc-update del cupsd
 * service cupsd removed from runlevel default
 # rc-update add cupsd
 * service cupsd added to runlevel default
```
There is no need to use 'runlevel' at all. Without it, rc-update will default .. to *default*.
And I think there is a serious reason to be designed like that ... but we have to ask the openrc dev guys for it ...",True,True
calamares_____calamares_____966,2018-06-03T07:15:42Z,True,calamares_____calamares_____966_____192579663,"as for the 'hard-coding' issue, the solution may be very simple:
```
SYNOPSIS
     rc-update [-s, --stack] add service [runlevel ...]
# rc-update add cupsd
 * rc-update: cupsd already installed in runlevel `default'; skipping
# rc-update del cupsd
 * service cupsd removed from runlevel default
# rc-update add cupsd
 * service cupsd added to runlevel default
```
There is no need to use 'runlevel' at all. Without it, rc-update will default .. to *default*.
And I think there is a serious reason to be designed like that ... but we have to ask the openrc dev guys for it ...",True,True
calamares_____calamares_____966,2018-06-03T07:18:16Z,True,calamares_____calamares_____966_____192579712,"@bionel 
There is a real need for other than default runlevels to be handled by the installer?


Are you guys seriously asking to hardcode ""default"" runlevel? Seriously?
The distro provides the conf, and if the conf has only default in it, all fine.
I will not hardcode a specific runlevel, if it can be configured via conf already.",True,True
calamares_____calamares_____966,2018-06-03T07:27:31Z,True,calamares_____calamares_____966_____192580023,"@udeved 
See my latest comment. In fact, we suggest to remove the runlevel completely, as default is a sane default also by openrc design",True,True
calamares_____calamares_____974,2018-06-03T07:29:18Z,True,calamares_____calamares_____974_____394143171,"> my argument is distro maintainers should do their part, and try not to force distro specific workarounds into the installer

Uhm, because you think distros do something you dislike, you also think its your duty to force these distros to not do what they do? 
Who is forcing you to use a workaround with the module? And why do you want to force distros to stick to a specific runlevel?
",True,True
calamares_____calamares_____966,2018-06-03T07:31:32Z,True,calamares_____calamares_____966_____192580140,"@bionel 

I reject such thing.
I regard your insistence to take away a feature already present has absolutely no valid reason.",True,True
calamares_____calamares_____966,2018-06-03T07:39:38Z,True,calamares_____calamares_____966_____192580357,"That said, I take for example arch philosophy into account, who would discourage from setting runlevel or so with a package. I may not like it, but it exists, and it is taken into account.",True,True
calamares_____calamares_____966,2018-06-03T07:43:58Z,True,calamares_____calamares_____966_____192580433,"@udeved 
well .. i think you misunderstand something.
i am not suggesting anything, in the end it is not my business what will be merged or not, as i am not a very active developer (my time for hobby project is limited)
My comments are from a technical perspective and from my experience with other stupid mistakes I made in the past
If you take this personally, than I am sorry, this was not my intention.

I am trying to be neutral, even if I am involved at a certain level in redcore development.
I always try to keep my mind away for what I am currently involved in and trying to see both positive and negative aspects.

Indeed, having access to runlevels may be regarded as a 'feature'.
But the question remains: It is sane to have it at the installer level? And is it really needed?
With great features come greater responsibilities ...

Such feature may open a door for further potential issues caused by wrong usage.
Will you deal further with all potential issues raised by miss-usage of this?
Or once the code is merged into upstream ... no longer my problem, calamares team should handle it?",True,True
calamares_____calamares_____966,2018-06-03T07:56:34Z,True,calamares_____calamares_____966_____192580767,"@bionel 

I return the question.

 It is sane to have it at the installer level? And is it really needed?

Yes, ansolutely sane, since the distro devs chose the runlevel for the service, and distro devs may have a reason to quickly test or configure non default.

If the need arises to have a different than default runlevel configured, what are distro devs gonna do? Patching, readding a lost feature because people insisted to have a hardcoded runlevel? What is you suggestion there?",True,True
calamares_____calamares_____966,2018-06-03T08:03:49Z,True,calamares_____calamares_____966_____192580957,"> Patching, readding a lost feature because people insisted to have a hardcoded runlevel?

As i said, there is no need to hardcode anything. Just stick with the default.
Different runlevels has to be handled at a different development stage (e.g before/after squash building.
And that will be quicker too, because sanity testing should be done before actually packing/shipping the ISO image.
On the ISO himself, only smoke/regression testing is done in a sane development cycle.",True,True
calamares_____calamares_____966,2018-06-03T08:10:08Z,True,calamares_____calamares_____966_____192581138,"@bionel 

Do you understand the issue we discuss?
The code has no reference to a specific runlevel, it loads it from conf. 
Some insist to remove this in favor of setting a default runlevel in code, which is crazy in my view.
",True,True
calamares_____calamares_____966,2018-06-03T08:15:39Z,True,calamares_____calamares_____966_____192581257,"@udeved 
Did you read the rc-update manpage?
```
SYNOPSIS
     rc-update [-s, --stack] add service [runlevel ...]
```
So, adapt the code, remove the level hardcoding from the module and from the conf. Problem solved.",True,True
calamares_____calamares_____966,2018-06-03T08:18:11Z,True,calamares_____calamares_____966_____192581322,"As long as gentoo documentation on their wiki, in the ebuilds, on their forums use explicitly the openrc concept of named runlevels, I will not change it. Your point is moot.",True,True
calamares_____calamares_____966,2018-06-03T08:24:10Z,True,calamares_____calamares_____966_____192581471,"> As long as gentoo documentation on their wiki, in the ebuilds, on their forums use explicitly the openrc concept of named runlevels, I will not change it. Your point is moot

i think this is not a valid argument, for few reasons:
 - i think you was mentioning you are a dev on an arch based distro, not gentoo
 - gentoo docs is about emerge-ing, aka compiling/packaging. has nothing to do with actually installing a gentoo based distro
 - there is no way to support a pure stage3 gentoo install from calamares. to build a gentoo based distro with cala, a lot of additional work is needed. to support a pure gentoo install, calamares has to be completely re-written",True,True
calamares_____calamares_____966,2018-06-03T08:33:00Z,True,calamares_____calamares_____966_____192581673,"@bionel 

""change the code"" you demand, to what?

Gentoo have calamares in portage
A module is supposed to cover as many distros as possible
I neither cater to redcore specifically, nor to artix, the module is meant to be as flexible as possible.
Gentoo, the mother of openrc, specifically use 

rc-update <add/del> <svc> <runlevel>

all over the place. 
The code of the module does the same, just as rc-update is intended to be used, and that will not change.",True,True
calamares_____calamares_____966,2018-06-03T08:39:00Z,True,calamares_____calamares_____966_____192581834,"I give up, i am out of ideea's
If the arguments are 'gentoo have that' without actually knowing how/when it is used, or 'i wrote that and i don't want to remove it' ... there is no logical reason for me to continue the thread.
I let the decision to calamares staff, in the end it is their team which will have to deal further with the code, once merged.",True,True
calamares_____calamares_____966,2018-06-03T08:43:07Z,True,calamares_____calamares_____966_____192581965,"Technically, I am part of calamares staff.
I can reduce the issue to its core, that is, some insist to hardcore the runlevel and force consuming distros to be dictated by upstream module what runlevel they can use. If they have different needs, they are supposed to patch the module.
No way.",True,True
calamares_____calamares_____966,2018-06-03T11:13:16Z,True,calamares_____calamares_____966_____192585814,"@udeved 

While hardcoding is not nice , allowing touching critical runleles that way
is broken too.

OpenRC by itself is not as smart to dissallow you breaking your system
my enabling/disabling services in critical runlevels.

We do not allow that to systemd , while 'possible' and very easy 
to add that code and it should not be allowed to any other implementation.

From 'Calamres' point of view , whatever you agree or not , there are 
*two* cases ( from which one is not yet fully implementet ) to touch boot
runlevel in OpenRC.

* 1 LUKS
* 2 LVM

For case 1 that could be done in the openrcdmcryptcfg if needed.
For case 2 we need wait and see how the end implementation looks like.

However I see only 2 ways of allowing touching boot and sysinit

* 1 Allow ony 'add' to everything ( even when bad services can be added
     that is really Distribution problem ) and filter boot && sysvinit for 'del'
* 2 Filter boot and sysinit for both cases and allow whatever else

Also this is not about 'dicating' anything but about having something
sane ( or almost sane ) upstream , since we the ustream have to
maintain and deal with user bug reports , not you.

'No way' .. 'damn eat my code' is not going to work when you want
to get your code upstream.

I'm not against you or your Distribution , it doesn't matter to me who uses that.

I would tell @V3n3RiX or @bionel or even any gentoo peoples the same thing.

ISO creation things , how we do remixes and these things doesn't matter at all here.

It also does not matter what could be done but what should be done , 
do you agree ? 



",True,True
calamares_____calamares_____974,2018-06-03T13:32:46Z,True,calamares_____calamares_____974_____394162722,"No, I'm not trying to force you to do anything. You can put whatever crap you want in your distro. What I'm trying to prevent is that crap spreading into calamares. You may not care about sane design choices and use duct tape all over the place, but I do care. It's true that I'm not forced yo use the workarounds, I don't need them in the begin with. But you really shouldn't force **your** workarounds into upstream code.",True,True
MoonchildProductions_____UXP_____395,2018-06-03T13:39:30Z,True,MoonchildProductions_____UXP_____395_____394163148,Was this partially re-landed? I noticed it in the commit history this morning.,True,True
calamares_____calamares_____975,2018-06-03T13:47:54Z,True,calamares_____calamares_____975_____192248603," !!!NOT for merging , please please don't!!!
 Demo patch to show that 'could be done' should 'just not be done'
 Even it looks flexible _that should never end in any serious upstream_
 Having that in a Distribution , as own patch fine , devels *may* know what
 they are doing. Opening the pandora box exposed as option for users ohh ,
 have fun to handle the storm of bug reports.

 But wait is not a user option ?
 Well is not but be sure they'll use it..
 And be sure even devels will trap into badness with these.
 ( You think I'm wrong ? Use search button on issue tracker and figure )",True,True
MoonchildProductions_____UXP_____395,2018-06-03T13:50:50Z,True,MoonchildProductions_____UXP_____395_____394163791,"I was also surprised when I saw that `mach` suddenly started a complete rebuild, but I thought that it was already discussed somewhere and I just missed it.",True,True
calamares_____calamares_____975,2018-06-03T14:06:16Z,True,calamares_____calamares_____975_____394164691,Jus demo code .. really do not merge that..,True,True
calamares_____calamares_____974,2018-06-03T14:06:58Z,True,calamares_____calamares_____974_____394164736,">But you really shouldn't force your workarounds into upstream code.

Where do I do that? Amazing, because I don't.
I simply don't get this whining about nothing.
You provide the service conf, you decide what runlevel. The code does not care for the runlevel name, it is configured in the conf.
If some distro wants to have a office runlevel because the distro is geared towards office, they can do that.
",True,True
calamares_____calamares_____974,2018-06-03T14:40:37Z,True,calamares_____calamares_____974_____394166914,"> If some distro wants to have a office runlevel because the distro is geared towards office, they can do that.

I was never against custom runlevels which OpenRC supports, I was only against sysinit and boot runlevels. And even if a distro wants custom runlevels, that piece of code of yours won't be enough for it to boot into that custom runlevel. You need to touch other parts of calamares as well. I'll let you guess which ones.",True,True
calamares_____calamares_____966,2018-06-03T16:30:11Z,True,calamares_____calamares_____966_____192595362,"""Gentoo, the mother of openrc, specifically use
rc-update <add/del> <svc> <runlevel>""

You do understand that is only a syntax right? Runlevel is only needed when for some reason you want/need to add a service to a specific runlevel. Otherwise the service it will be added to 'default' runlevel.

shakuras /etc/conf.d # rc-update add fancontrol
 * service fancontrol added to runlevel default
shakuras /etc/conf.d # rc-update del fancontrol
 * service fancontrol removed from runlevel default

So, I adjusted my PR to go with OpenRC's defaults, removing the hardcode for the runlevel. I will also adjust **openrcdmcryptcfg** for when LUKS is used and when LVM support comes into calamares I'll also take care of that one. 

Calamares is a high priority in Redcore, and I intend to fully support the code I wrote for it, and expand it when good arguments are being made, when required. I'll not just add code for the sake of ""one days pigs may fly, and some other unknown openrc distro **may** want to do this"".

Just as a side note : calamares is indeed in Gentoo's tree, and I'm happy to report, I'm the one who wrote the first ebuild for it, back in calamares 1.1 days, about 2 years ago.",True,True
calamares_____calamares_____966,2018-06-03T17:10:52Z,True,calamares_____calamares_____966_____192596501,"So,what is all the fuzz about?
You want to enforce a default only, I am against that.
If you modules goes upstream, I won't use it and will stick with a flexible module that allows any runlevel, even though I may not use it right now.
I still fail to see the in my view ridiculpous resistance to a runlevel variable, and why we have two competing PRs.",True,True
MoonchildProductions_____UXP_____395,2018-06-03T17:28:49Z,True,MoonchildProductions_____UXP_____395_____394177652,"Yes I partially re-landed this for GCC (adding the flags for sse2 in the default compiler config). The other solution would not enforce anything, just prevent unwanted flags.",True,True
calamares_____calamares_____974,2018-06-03T17:32:44Z,True,calamares_____calamares_____974_____394177913,"I am basically done going around in circles. You give no valid reason why to remove a variable in favor of a fixed runlevel. Again, this is no competition to prove an ego. 
dmcrypt is something I would not want in the service module, because its done differently on arch with initcpio.
If you configure calamares to remove essential services from a sysinit runlevel, then that is frankly your problem, and you obviously did something wrong with package deployment.
I am against trying to dictate distros how they do things, which is what your module does.",True,True
calamares_____calamares_____974,2018-06-03T18:06:00Z,True,calamares_____calamares_____974_____394180055,"I can say the same thing : if you need calamares to configure **boot** runlevel just for **elogind** (your comment, not mine), then you obviously did something wrong with package deployment. And if I take in consideration your latest **manual intervention required** news, then I'm sure you did just that. Fix your own broken thing, and do not try to force your workarounds in here. Even if this module is slightly more limited, it is useful for Artix (you do have a default runlevel don't you?), whereas yours is of no use for Redcore. Being Gentoo based we do things as upstream intended, we don't have our own speciffic workarounds.

And dmcrypt being done different in arch is once again, **your** problem. In OpenRC that service goes into **boot** runlevel. This is how it's done upstream in Gentoo, and over here in Redcore. 

So please, once again, keep your distro speciffic workarounds to yourself. ",True,True
calamares_____calamares_____966,2018-06-03T18:10:09Z,True,calamares_____calamares_____966_____192597976,"don't use it then...I won't use yours if it goes upstream...I'll even ban it from my calamares package, so it never gets installed in the first place...since what this module can do is beyond insane...",True,True
calamares_____calamares_____966,2018-06-03T18:15:05Z,True,calamares_____calamares_____966_____192598070,"maybe because you refuse, without any logical reason, to improve the code you wrote?
if you don't want to remove the runlevel's usage, than treat the dangerous cases (prevent it to remove services from from boot and sysvinit level at a minimum)
Is that hard to add few lines of code to make it proper?

Also, the 'error handling' can be improved, but seems like you know the only one way of doing things ... and i am sorry to say, that doesn't looks like a sane/safe way ...",True,True
calamares_____calamares_____974,2018-06-03T18:16:16Z,True,calamares_____calamares_____974_____394180710,"> So please, once again, keep your distro speciffic workarounds to yourself.

Oh the irony, now you say, its done so on redcore and gentoo, and this must be valid on all distros using openrc.
Btw, nope, we don't need to configure any boot runlevel on artix. You are wrong.
I think you are getting way too defamatory. and I gonna leave this useless discussion now.

",True,True
calamares_____calamares_____966,2018-06-03T18:18:13Z,True,calamares_____calamares_____966_____192598159,I won't do any further work with two competing PR. This needs to be resolved first.,True,True
calamares_____calamares_____974,2018-06-03T18:27:07Z,True,calamares_____calamares_____974_____394181386,"If you don't need it, why try force it in here then? And if you don't need it, then this module will do just fine on Artix. I'm damn sure you do need to configure **default** runlevel. 

Default runlevel is valid for all OpenRC distros ... What you're trying to push is not. That's what I'm trying to explain to you even since the beginning ... I think I rest my case!",True,True
calamares_____calamares_____966,2018-06-03T18:27:25Z,True,calamares_____calamares_____966_____192598350,"as i thought from the beginning .. it is not about the right way to do it .. but it is about who is doing it :)

well .. mixing ego into the code is not the best way to properly contribute to an open project ....",True,True
calamares_____calamares_____974,2018-06-03T18:40:15Z,True,calamares_____calamares_____974_____394182214,"Btw, if dmcrypt service is really handled different on Arch based distros, I won't try to merge the piece of code I wrote...I don't wanna **force** things ... Just wanna have **sane** defaults ... that's all",True,True
calamares_____calamares_____974,2018-06-03T18:45:56Z,True,calamares_____calamares_____974_____394182614,"It can be handled in any OpenRC Distro equal .. no matter the initramfs impelmentation.

But is this different issue.

",True,True
calamares_____calamares_____974,2018-06-03T19:15:20Z,True,calamares_____calamares_____974_____394184478,"> I am against trying to dictate distros how they do things....

That does not matter .. Is your personal opinion and not an technically reason.

Calamares restricts all kind things already , and 'dictates' already in some places
what is allowed what is enforced and what won't be upstream , for the one or the other
reason.

> If you configure calamares to remove essential services from a sysinit runlevel, then that is frankly your problem

Again .. is not about you.. Once is upstream it will not be you who takes the bugs.
Is not you who need write some sane docs , etc ..

It just shows your bad attitude.

Technically systemd services could have support for disabling targets 
or masking any kind things.. Now guess why that is not upstream and won't be..

All about this is to find sane defaults not about what could be done.

I've told in the other PR already runlevels support can be added with
some filtering but yet you seems to ignore everything.


",True,True
calamares_____calamares_____975,2018-06-03T19:23:41Z,True,calamares_____calamares_____975_____394184991,This is an incredibly bad reason to file a PR.,True,True
MoonchildProductions_____UXP_____395,2018-06-04T01:37:57Z,True,MoonchildProductions_____UXP_____395_____394212191,So does that override flags in MOZ_OPTIMIZE?,True,True
MoonchildProductions_____UXP_____395,2018-06-04T02:47:53Z,True,MoonchildProductions_____UXP_____395_____394220466,"Now, before getting in your ivory tower again you could have taken a NORMAL approach and simply ask. Or better yet, look at how GCC handles these command-line flags when specified, before accusing me of all sorts of things. MSVC might override, indeed, but GCC does not. `-msse2` and other `-m` flags like it only **enable** the use of the instruction sets (with `no` variants disabling them). You think I didn't look this up? 

I'm tired of this, Tobin. Every single time you think you have a solution it has to be exactly your solution and nothing else without a ton of infighting or needing exact control over anyone doing anything that is even within a mile of ""your"" code. We discussed this before, and you even said you were fine with these flags as a minimum so what the fuck are you doing getting in my hair when I make sure sse2 is used? And no, that is NOT branding dependent.

Your solution prevents people overriding the minimum with `no` optimization flags, which is perfect, but it doesn't actually set the use of the instruction set. Requiring that people manually add it to their optimize flags (what you apparently ""intended"" but never saw fit to let anyone know -- I'm still not clairvoyant) is backwards.",True,True
MoonchildProductions_____UXP_____395,2018-06-04T02:49:52Z,True,MoonchildProductions_____UXP_____395_____394220692,"Also
> No, because no one right now knows the behavior when both are specified..

Read the gcc manual. It's all in there. https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html#x86-Options",True,True
MoonchildProductions_____UXP_____395,2018-06-04T03:05:01Z,True,MoonchildProductions_____UXP_____395_____394222457,"So what does ""depresses"" mean that the SSE2 instructions are still there but it will add and use AVX for AVX2 instead? Or does it mean it makes -msse2 like it isn't present? ""When needed"" when is that?

When I specify a valid -m flag I expect it to be the only one in play.. So is this the case?",True,True
MoonchildProductions_____UXP_____395,2018-06-04T03:10:04Z,True,MoonchildProductions_____UXP_____395_____394223046,"> Yes I partially re-landed this for GCC (adding the flags for sse2 in the default compiler config). The other solution would not enforce anything, just prevent unwanted flags.

That would be a better solution. Anyway I'm going to stay out of this now. ",True,True
MoonchildProductions_____UXP_____395,2018-06-04T03:20:37Z,True,MoonchildProductions_____UXP_____395_____394224169,"Know what.. That's fine.. I'm done.. Do what you are gonna do then.. UXP belongs to you as your huge declairation on the readme says... I don't care anymore.

The platform aka moonchild-central isn't my consern anymore. I have more pressing things to do than micromanage this codebase I slaved over for four months.

I am now hands off in every respect outside of Phoebus and when that is done so am I.",True,True
calamares_____calamares_____975,2018-06-04T10:31:36Z,True,calamares_____calamares_____975_____394309131,"IMHO, this is a valid feature and should be added (but as a new pull request without all your negative comments). I do not see a valid reason to not support `mask`, given how trivial it is to support it.",True,True
MoonchildProductions_____UXP_____395,2018-06-04T10:35:29Z,True,MoonchildProductions_____UXP_____395_____394310125,"> I am now hands off in every respect outside of Phoebus and when that is done so am I.

Okay. Your choice and your freedom. I appreciate you're willing to stick around to bring Phoebus to completion instead of ragequitting. Thank you.",True,True
MoonchildProductions_____UXP_____395,2018-06-04T10:56:32Z,True,MoonchildProductions_____UXP_____395_____394315023,"> So what does ""depresses"" mean? That the SSE2 instructions are still there but it will add and use AVX for AVX2 instead? Or does it mean it makes -msse2 like it isn't present? ""When needed"" when is that?
> 
> When I specify a valid -m flag for instriction set most expect it to be the only one in play.. So is this the case?

To answer these questions: AVX is a special case because AVX is mutually exclusive with SSE*. All these flags in GCC only flag to the compiler ""You are allowed to use these instructions"", and in practice this means the ""highest"" of the class is generally used when applicable to specific code. _When_ they are used is determined _by the compiler_ based on the code being compiled (ask GCC devs for details). In the case of AVX, the ""depresses"" statement, if I read correctly, acts like `-msse*` isn't specified, in effect overriding them and always using AVX instructions when both classes of instructions are possible. All the other flags are simply ""You can use this if you want to"" for specific pieces of compiled code.",True,True
opnsense_____core_____2466,2018-06-15T14:54:37Z,True,opnsense_____core_____2466_____195200253,"This conforms to current recommendations and best practices for a
128-bit security margin.

2048 is still the minimum recommended, but 2048-bit RSA only aligns to a
112-bit security margin, roughly analogous to 3DES. AES-128, the
minimum recommended cipher, requires a 3072-bit RSA key and a 256-bit digest
(SHA256) to provide an equivalent security level in all cryptographic
components.",True,True
opnsense_____core_____2466,2018-06-15T15:32:03Z,True,opnsense_____core_____2466_____397658588,Need to further test this.,True,True
opnsense_____core_____2466,2018-06-15T15:59:04Z,True,opnsense_____core_____2466_____397666174,Additional question: Where are we sourcing the sample DH parameter files from?,True,True
opnsense_____core_____2466,2018-06-17T19:15:24Z,True,opnsense_____core_____2466_____397899998,"This should be split in two: 3072 bits for certificates and 3072 bits for DH. For the latter it may be more favourable to avoid adding a lot of ""odd"" DH default params to the system, because...

... to answer your question we sporadically provide new parameters and it takes a long time to update them if they grow in number (and bit size).",True,True
opnsense_____core_____2466,2018-06-17T19:24:02Z,True,opnsense_____core_____2466_____397900467,"With https://github.com/opnsense/core/commit/a20aacb4a you can now create custom DH files via cron... As soon as they are created, you can use them. But it requires to set ""custom"" dh parameter usage under system: settings: misc. These are all changes for the upcoming 18.7.",True,True
opnsense_____core_____2466,2018-06-17T19:26:51Z,True,opnsense_____core_____2466_____397900653,"@fichtner In the case of DH, 3072 is a standard DH parameter size. See also RC 7919. The sample DH file provided in my merge request is the IETF standard DH group for that size. https://tools.ietf.org/html/rfc7919",True,True
opnsense_____core_____2466,2018-06-17T19:37:48Z,True,opnsense_____core_____2466_____397901317,"I know it's a standard, but if I regenerate fr a release it already takes a while, adding more standard sizes will make it even longer, making it less likely to provide new files for the existing ones.",True,True
opnsense_____core_____2466,2018-06-17T20:11:06Z,True,opnsense_____core_____2466_____397903218,"So, more to the point, you should not be generating DH parameters for releases. You should be using the default ones from RFC 7919. If the end-user wants to use custom parameter sets, they should generate them themselves.",True,True
opnsense_____core_____2466,2018-06-18T05:08:08Z,True,opnsense_____core_____2466_____397943198,"> So, more to the point, you should not be generating DH parameters for releases. You should be using the default ones from RFC 7919. If the end-user wants to use custom parameter sets, they should generate them themselves.

Fine, so who will do the work necessary to avoid lower security in these circumstances? When will we be switching to a default regeneration of DH parameters and how will it be done? How do we minimise the gap between using default parameters and custom parameters in new installs? Do we have all the code in place or do we need to do more? How much *measurable* security will we gain from doing what is suggested here?

Besides this my review points still stand... if you want a change merged please split it into Cert and DH parts...",True,True
opnsense_____core_____2466,2018-06-18T12:02:34Z,True,opnsense_____core_____2466_____398031320,"> Fine, so who will do the work necessary to avoid lower security in these circumstances?

You're already lowering security by generating your own DH parameter sets with each release. This is woefully at odds with cryptographic best practices. There are reasons that standard DH parameter sets exist: These standard sets have been audited to ensure that weak values haven't been selected as a result of bug/accident/malice. By generating your own and including them as the default sets in the release, you're asking every OPNsense end user to trust you. The simpler response, both technically and administratively, is to ship the standard DH parameters from RFC 7919. The end user is using audited parameters that are widely regarded to be safe (they've been used with IPsec for years), and you don't have to deal with generating parameter sets (a long and tedious process.)

> When will we be switching to a default regeneration of DH parameters and how will it be done?

DH parameters aren't keys. They're not private. They don't need to be regenerated unless some issue is found with the parameter set itself. That's another virtue in using standardized parameter sets: if an issue is discovered with a DH group from RFC 7919, it will be widely known and publicized. Having some cron-based regeneration of DH parameters is, at best, unnecessary, and at worst dangerous if the end user's system generates unsafe values for some reason. I'm all for giving the user the choice, though it's not a good idea, but the question here is what values should be included with the release. The answer to that has been given.

> How do we minimise the gap between using default parameters and custom parameters in new installs?

The most extreme answer would be ""Don't use custom parameters."" The default (RFC 7919) parameters are the safest option.

> Do we have all the code in place or do we need to do more?

Given the recent commits surrounding this issue, I'd have to go back and look at what was added or removed. At least a portion of my merge request is needed to utilize 3072-bit DH parameter sets.

> How much measurable security will we gain from doing what is suggested here?

That depends on your risk profile and tolerance. For most users, this would be a transparent change whose benefits may never be observed. In raw terms, shipping audited and standard values provides an assurance that the values included with the release were not tampered with or poorly-generated. A ""nothing up my sleeve"" number, if you will.

The Mozilla Foundation states this advice explicitly. [Server-Side TLS](https://wiki.mozilla.org/Security/Server_Side_TLS#Pre-defined_DHE_groups) While the page itself may offer guidance on configuring web servers, the rest of it is fully-applicable to anything participating in TLS connections.",True,True
opnsense_____core_____2466,2018-06-18T12:16:29Z,True,opnsense_____core_____2466_____398034526,"We've been following up on https://weakdh.org/sysadmin.html ever since 2015 and this is the first complaint that it's *all wrong*. What you state here is therefore news to me. On first glance I cannot find enough info to back up your claims, so I'll park this PR and ask around to give it the benefit of the doubt it deserves and I wish you will do the same for what we have currently in place.",True,True
opnsense_____core_____2466,2018-06-18T12:26:31Z,True,opnsense_____core_____2466_____398037003,"That makes sense. I believe that https://weakdh.org/sysadmin.html was written in 2015, and according to a look over that URL in the Wayback Machine, it was never updated. RFC 7919 was submitted in August 2016, so the WeakDH guide predates that RFC.",True,True
opnsense_____core_____2466,2018-06-18T12:30:21Z,True,opnsense_____core_____2466_____398037992,"Ah, thanks for the clarification.",True,True
opnsense_____core_____2466,2018-06-18T21:06:07Z,True,opnsense_____core_____2466_____398195705,"I'm going to undo the commits to the DH portions so that the cert parts can go in under this PR, and I'll submit a DH-specific PR later if its agreed upon.",True,True
opnsense_____core_____2466,2018-06-18T21:15:56Z,True,opnsense_____core_____2466_____398198347,Done.,True,True
opnsense_____core_____2466,2018-06-19T05:07:01Z,True,opnsense_____core_____2466_____398275498,"Merged, thank you.

As for RFC 7919, how about we make them optionally usable? We already have a mode selector in the development version. This also means one day we could switch to them by default in new installation and not take anything away from existing users.",True,True
opnsense_____core_____2466,2018-06-19T12:23:02Z,True,opnsense_____core_____2466_____398379738,"So, here's my thoughts on this: You're already going to be shipping `dh-parameters.*.sample` files, right? Why not make the sample files the RFC DH groups (and you don't have to generate new ones with each release), and the user can either use them, or cron will generate new ones anyway.",True,True
opnsense_____core_____2466,2018-06-19T12:32:42Z,True,opnsense_____core_____2466_____398382444,"Because we're not making RFC 71919 a default unless the community is willing to support this move. So the community needs to be engaged, best by shipping options to them to try out and discuss further in the forum. :)

Other issue is that 1024 is not provided by RFC, but still of deprecated use in existing installs so you end up with a mixed or broken environment on upgrade if we were to do the switch. As a stopgap we'll be bumping the defaults in OpenVPN to 2048 with 18.1.10 and then give RFC a fair chance on 18.7 so that we could switch to it by default when 19.1 is out.",True,True
opnsense_____core_____2466,2018-06-19T12:43:18Z,True,opnsense_____core_____2466_____398385231,"The ""wisdom of crowds"" approach is not the correct approach where crypto is concerned. The fact that you accepted a pull request predicated on the idea that periodic regeneration of DH groups is good or necessary is proof of that fact. Do what you will, but this is the wrong approach.",True,True
opnsense_____core_____2466,2018-06-19T12:57:04Z,True,opnsense_____core_____2466_____398389119,Your mind is set; I have no reason to change it. :),True,True
opnsense_____core_____2466,2018-06-19T13:11:06Z,True,opnsense_____core_____2466_____398393365,"My mind isn't the issue. I have standards and best practices on my side, reinforced with documentation. You're choosing to ignore that, which is strange to me.

You accepted a pull request regarding DH params with ""a couple dudes talked about it on IRC"" as support, but you resist this proposal when an actual RFC exists in support of the proposal with the statement of ""we're not doing this unless the community supports it."" Talk about double standards. I won't be contributing further to this project.",True,True
opnsense_____core_____2466,2018-06-19T13:19:44Z,True,opnsense_____core_____2466_____398396089,"You have:

1. Asserted that you set your opinion above a community voice in an open source project scope.
2. You continue to be pushy with no regard for other people's schedules, ideas and explicit questions to give ""the benefit of the doubt"".
3. Have failed to realise that 90% of what you asked is already in the development version.

Feel free to not back off, but in any case this is the last you see of me responding.


Thanks,
Franco",True,True
opnsense_____core_____2466,2018-06-19T13:27:36Z,True,opnsense_____core_____2466_____398398501,"> Asserted that you set your opinion above a community voice in an open source project scope.

No, I have asserted that I set standards above the community voice, especially when the community has already shown that they don't know how to properly handle crypto.

> You continue to be pushy with no regard for other people's schedules, ideas and explicit questions to give ""the benefit of the doubt"".

Schedules were never discussed. The ideas were ill-formed, either unsupported or predicated on old information. And why should anyone give ""benefit of the doubt"" when there should be no doubt? You're mishandling crypto, end of story.

> Have failed to realise that 90% of what you asked is already in the development version.

Does the development version adhere to standards? No? Then how is this even relevant?

> Feel free to not back off, but in any case this is the last you see of me responding.

Again, that's on you. I have the knowledge and expertise to render a judgment on this. It's a shame you choose not to benefit from it.
",True,True
opnsense_____core_____2466,2018-06-19T13:30:53Z,True,opnsense_____core_____2466_____398399491,"> that they don't know how to properly handle crypto.

Your assertion is wrong and it makes you act like a less than favourable human being. People live and learn, either with you or without you. I'm closing this thread, because you continue to deviate from the topic for attacks because you don't get what you want.",True,True
calamares_____calamares_____975,2018-06-20T10:12:15Z,True,calamares_____calamares_____975_____398698195,"Please leave a comment in #992 , as this PR reflects on the more general issue of service-management outside of the package manager. And, as @kkofler says, it needs work to be mergeable.",True,True
calamares_____calamares_____974,2018-06-20T10:14:53Z,True,calamares_____calamares_____974_____398698970,Please leave a comment in #992 ; that asks for (a) civil discussion and (b) long detailed answers with examples.,True,True
calamares_____calamares_____966,2018-06-20T10:16:22Z,True,calamares_____calamares_____966_____398699324,Please leave a comment in #992 ; that asks for (a) civil discussion and (b) long detailed answers with examples.,True,True
nestjs_____typeorm_____27,2018-06-20T10:35:49Z,True,nestjs_____typeorm_____27_____398704151,Is there a reason we don't merge this?,True,True
nestjs_____typeorm_____27,2018-06-22T09:16:56Z,True,nestjs_____typeorm_____27_____399378700,"This solution is great, though, I'm afraid that it might be broken in future typeorm releases. It looks like a workaround that uses internal API which is quite dangerous.",True,True
sbpp_____sourcebans-pp_____488,2018-06-27T06:28:28Z,True,sbpp_____sourcebans-pp_____488_____197628178,"<!--- Provide a general summary of your changes in the Title above -->

## Description
<!--- Describe your changes in detail -->
Modified sm_ban to now display the ban window when 0 arguments are presented.

## Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
Simple feature that makes it easier to access the ban window without having to step through the admin menu.

## How Has This Been Tested?
<!--- Please describe in detail how you tested your changes. -->
<!--- Include details of your testing environment, and the tests you ran to -->
<!--- see how your change affects other areas of the code, etc. -->
Compiled and ran on both public and test server. Simple fix, doesn't affect anything outside of the console command.

## Screenshots (if appropriate):

## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the code style of this project.
- [ ] My change requires a change to the documentation.
- [ ] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
",True,True
sbpp_____sourcebans-pp_____488,2018-06-27T06:34:49Z,True,sbpp_____sourcebans-pp_____488_____400558912,"This sounds more suited as a separate command like `sm_banmenu`.

Sometimes I call `sm_ban` just to check for the order of the required parameters, and would rather not have to close an extra menu when I do that.",True,True
mysqljs_____mysql_____1962,2018-06-27T09:09:45Z,True,mysqljs_____mysql_____1962_____400600651,Any updates on this? Unable to authenticate with MySQL 8,True,True
sbpp_____sourcebans-pp_____488,2018-06-27T11:06:48Z,True,sbpp_____sourcebans-pp_____488_____400634574,"[sm_ban playerName timeInMinutes ""Reason""]? Didn't think it was that hard to remember.

If it's that annoying of a change, then we can close this PR.",True,True
calamares_____calamares_____974,2018-06-27T14:42:39Z,True,calamares_____calamares_____974_____400698100,See closing comments in #992,True,True
calamares_____calamares_____975,2018-06-27T14:42:55Z,True,calamares_____calamares_____975_____400698196,See closing comments in #992,True,True
calamares_____calamares_____966,2018-06-27T14:43:00Z,True,calamares_____calamares_____966_____400698225,See closing comments in #992,True,True
sbpp_____sourcebans-pp_____488,2018-06-28T21:40:36Z,True,sbpp_____sourcebans-pp_____488_____401181996,"This PR still displays the usage message, though it also shows the menu. I figured it wouldn't really be that annoying since how often really is it needed to use /ban with no args just to see usage parameters? There is also an ongoing discussion in the sourcemod GH regarding this suggestion - an idea is to offer a cvar to toggle this behavior change.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-28T22:03:18Z,True,algorithm-archivists_____algorithm-archive_____114_____401187120,"Hey @ubsan, I am sorry it has taken me so long to get to this PR. This is something we have discussed in detail internally on discord and through a few other platforms, but we feel that the code submitted to the algorithm archive in C++ is incredibly difficult to read and follow. This is mostly due to the syntactical complexity of the code, which does not seem standard, even for well-seasonsed C++ programmers. 

As I've said before, you know your stuff, that is clear; however, if individuals who have been reading and writing C++ code for years have trouble understanding the code here, then there is a problem. At first, I thought it was just my own misunderstandings because my C++ code is basically C; however, it has come to my attention that other members of the community agree that the code is too difficult to read, and this is a problem.

I want to make clear that we definitely appreciate the help and support and would love to see you stay a member of the community and continue to review and write code for the AAA (we are not kicking you out); however, tone down the syntactical complexity to match what we have said before in the style guideline issue (#18) and *How To Contribute* section, which basically say that the code written should be ""should be readable and understandable to anyone -- especially those who are new to the language."" Your code definitely does not fit this criteria. 

The code provided in #18 was definitely clearer than code provided here, and that should be roughly the syntactical complexity of future code in the archive.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T00:38:56Z,True,algorithm-archivists_____algorithm-archive_____114_____401213749,"@leios I disagree completely. If you want imperative code, you can write it yourself. The code as you've written it in Julia utterly obsfucates the underlying mathematical concepts; if I'm going to write code for something like this, I want to be able to see the math underlying it - I don't want to see the mutations. I'm unwilling to write the code in an imperative manner.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T03:12:38Z,True,algorithm-archivists_____algorithm-archive_____114_____401234766,"You are right, I have a bias towards imperative code; however, @ubsan 3 things:

1. I should have been more clear: this isn't about the FFT, specifically. It was a general note that the code you have written for the AAA is incredibly over-engineered every time. There have been a few cases where I genuinely needed an implementation in C++ for certain algorithms and I could not use the implementation in the Algorithm Archive for C++ because it was unreadable and unusable in my codebase. I instead just used the C code with small modifications. That should not have happened.

I know what you are going to say, ""Well, any good C++ programmer should be able to understand this code,"" and you are not necessarily wrong. The problem is that the people who need the Algorithm Archive are people like me --  those who use C++ frequently enough that they need an algorithm implemented in the language, but are not ""good"" enough to take the mathematical definition and immediately write it in code. They need code they can quickly look at and say, ""Ah. That's how you do it. I bet I can get this working this afternoon!""

2. I am not sure how the code I wrote ""utterly obfuscates the underlying mathematical concepts,"" simply because it is written in an imperative style. As mentioned before (by Gustorn ~May 21st), there will always be slight variations of the mathematical definition and algorithmic implementation. If you want math, you read the chapter. If you want a language implementation, you read the code. Some people (like me) understand better when I see a few for loops, because it helps them grasp the dimensionality of the problem better than mathematical notation. If you want to write in a different coding style, pick a language that better supports that, or *find ways to make it syntactically clearer what you are actually doing.*

This is (decently) clear:

```c++
template <typename T>
T discrete(const std::vector<c64>& vec) {
    T result(vec.size());

    auto size = vec.size();
    for (size_t i = 0; i < size; ++i) {
        for (size_t j =0 ; j < size; ++j) {
            result[i] += vec[j] * std::exp(c64(0, -2.0 * pi<double>() * j * i / size));
        }
    }

    return result;
}
```

Sure, people who don't know C++ probably don't like the `template`, but that's fine. The `std::exp(c64(0, -2.0 * pi<double>() * j * i / size))` is also a bit weird, but that's good ol' C++ for you.

This is a short sample of some of the code you wrote:

```c++
template <typename It>
std::vector<c64> dft(It const original, It const last) {
  std::size_t const size = last - original;
  auto ret = std::vector<c64>(size);

  std::iota_transform(begin(ret), end(ret), [original] (std::size_t n) {
    return sum(0, size, [original] (std::size_t k) {
      return original[k] * c64(
          std::cos(-2.0 * pi * n * k / size),
          std::sin(-2.0 * pi * n * k / size));
    }
  });

  return ret;
}
```

I can get a few lines in... Again, templates are weird, but it is what it is. Your constant use of `auto` makes `auto ret = std::vector<c64>(size);` a bit odd to read (why not just `std::vector<c64> ret(size)`?), but no big deal there. My main questions come after this. What the heck is `std::iota_transform(...)`? [Google doesn't even help](https://www.google.com/search?safe=active&client=ubuntu&hs=41k&channel=fs&ei=rIo1W9PhL4v38QWr5qXQCg&q=strd%3A%3Aiota_transform+c%2B%2B&oq=strd%3A%3Aiota_transform+c%2B%2B&gs_l=psy-ab.3...713179.713945.0.714618.6.6.0.0.0.0.183.372.1j2.3.0....0...1c.1.64.psy-ab..3.0.0....0.vNEjOxprt88). Is that a lambda somewhere hidden in the middle? Where is `sum` defined? Wait, is that a lambda in a lambda?

As far as using Euler's formula, which you seemed to dislike... Well, it's how the FT and FFT are defined. It's actually a bit misleading in my opinion to use sines and cosines unless your language demands it. Again, though, this is kinda personal preference. Everyone knows the formula, so either will do.

I don't mind you writing code in a different style. C++ supports a number of different styles. It's just that your code is so syntactically complex that style doesn't matter. It is simply hard to read and understand. 

Disclaimer: I am aware that these are just snippets from the above conversation. They were not chosen delicately to prove my point or anything... they were just the smallest chunks of code I could grab that both seemed to be doing the same thing.

3. You are right, I should re-write the julia code. It's a bit messy in certain places. I'll see about fixing that soon. Thanks for bringing that to my attention!",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T03:40:36Z,True,algorithm-archivists_____algorithm-archive_____114_____401238312,"@leios It's really not complex. It's not what you're used to, maybe, but it's fairly close to what I'd write in, say, OCaml.

```ocaml
val dft : Complex.t array -> Complex.t array

let dft original =
  let size = Array.length original in
  Array.init size (fun n ->
    sum 0 size (fun k ->
      let c = (float_of_int -2) *. pi *. n *. k /. (float_of_int size) in
      Complex.(original.(k) * { re= cos c; im= sin c }) ))
```

It's how one writes it in a non-imperative style, at least imo.",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T03:45:43Z,True,algorithm-archivists_____algorithm-archive_____114_____401238960,"If I may butt in, I do like that piece of OCaml, it's quite readable, but the C++ version is not readable at all. C++ is not very suited to declarative style, you have to jump through hoops to write the code you like. Maybe submit some OCaml code instead? ^^",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T03:47:57Z,True,algorithm-archivists_____algorithm-archive_____114_____401239239,"Yeah, I was just about to write a similar comment. That code seems fine to me. ",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T04:43:19Z,True,algorithm-archivists_____algorithm-archive_____114_____401245952,They're... exactly the same code. What?,True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T04:59:33Z,True,algorithm-archivists_____algorithm-archive_____114_____401247848,"They do exactly the same thing, but the OCaml is more readable, because the syntax is natural. For example, lambda functions. I don't know OCaml at all, and my C++ is worthless, but reading your OCaml, I see straight away that the syntax is  `fun x  -> x`. I've read your C++ 12 times and I can't figure out the syntax. It's just hard to read and not a natural feature of the language. ",True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T05:10:47Z,True,algorithm-archivists_____algorithm-archive_____114_____401249167,I don't know how to argue with that. I think I'm done with this thread. It seems to me we'll get yet another C-with-classes resource online. yay,True,True
algorithm-archivists_____algorithm-archive_____114,2018-06-29T05:38:20Z,True,algorithm-archivists_____algorithm-archive_____114_____401252867,"@ubsan Thanks for answering. I think I have a better understanding of where you are coming from and the general differences in style between you and other coders here.

Again, to be clear: I don't think you are wrong. I think that C++ allows for the style you want, and that's fine. To be honest, I have genuinely learned a lot from reading through your code.

My understanding is that you would like to stay away from imperative code so you can be closer to the mathematical foundations of the algorithms you are using. That makes a lot of sense; however, we are arguing that in doing so, the C++ code becomes hard to read. This is probably because most people still use C++ imperatively, even if it is ""multi-paradigmatic.""

I feel there must be common ground. We are not doing completely OO code here, either. We use what makes sense, and the community dictates what makes sense in each case.

We have had a bit more discussion on this thread, so let's see if anyone else in the community chimes in. Maybe we should create a separate issue?",True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T08:50:31Z,True,pmmp_____PocketMine-MP_____2296_____200628139,"## Introduction
Since 1.5.0 is such a piece of garbage, this pull request will remain open until patches have been issued to solve the problems with it.",True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T15:01:51Z,True,pmmp_____PocketMine-MP_____2296_____404202044,Lol is the protocol garbage or the game content itself?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T15:01:52Z,True,pmmp_____PocketMine-MP_____2296_____404202053,Lol is the protocol garbage or the game content itself?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T15:04:09Z,True,pmmp_____PocketMine-MP_____2296_____404202866,"try opening the game, or playing it... also try using floating text or NPCs. Have fun.

1.5.0 is legitimately the worst update I've seen yet.",True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T15:05:33Z,True,pmmp_____PocketMine-MP_____2296_____404203368,I wish they would stop adding new features and just fix everything,True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T15:06:55Z,True,pmmp_____PocketMine-MP_____2296_____404203860,it's not features... just really terrible quality... you're better off using 1.5.0.10 beta if you want to use this. It's faster and doesn't crash and freeze at every opportunity.,True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T16:10:24Z,True,pmmp_____PocketMine-MP_____2296_____404226037,".PHAR ?
",True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T22:46:28Z,True,pmmp_____PocketMine-MP_____2296_____404334014,setNameTag not working. Is this problem caused by me? ,True,True
pmmp_____PocketMine-MP_____2296,2018-07-11T23:03:04Z,True,pmmp_____PocketMine-MP_____2296_____404337247,"no, it's not just you... add it to the list of things mojang broke in this update",True,True
algorithm-archivists_____algorithm-archive_____114,2018-07-12T05:53:44Z,True,algorithm-archivists_____algorithm-archive_____114_____201916478,Commented out code.,True,True
algorithm-archivists_____algorithm-archive_____114,2018-07-12T05:56:18Z,True,algorithm-archivists_____algorithm-archive_____114_____201916833,Do we need to cast to double here?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-12T09:37:02Z,True,pmmp_____PocketMine-MP_____2296_____404452832,Pls so 1.5.0,True,True
pmmp_____PocketMine-MP_____2296,2018-07-12T09:38:01Z,True,pmmp_____PocketMine-MP_____2296_____404453124,@Prisane Here is a quick fix. https://pastebin.com/Je86E0kx,True,True
pmmp_____PocketMine-MP_____2296,2018-07-12T09:53:25Z,True,pmmp_____PocketMine-MP_____2296_____404457505,Wtf! Why Spam lol,True,True
pmmp_____PocketMine-MP_____2296,2018-07-12T09:56:04Z,True,pmmp_____PocketMine-MP_____2296_____404458327,"EY,du scheiß Nazi hör auf sonst ddos ich dich du huso,und hau dir in die fresse du kleiner wixer,komm 1vs1",True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T17:42:26Z,True,pmmp_____PocketMine-MP_____2296_____404903800,"Player nametags with setNameTag() are broken, but setNameTag() works on other entities just not players. It just shows up like default nametags (the player's name in white) and doesn't update it to the newly set nametag.",True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T17:54:59Z,True,pmmp_____PocketMine-MP_____2296_____404907109,"setDisplayName(), would that work? And by the way, 0.16 is worse than 1.5.0.10",True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T17:57:16Z,True,pmmp_____PocketMine-MP_____2296_____404907711,"@iiFlamiinBlaze in a nutshell, they sabotaged nametags on players. They'll update if you're on a featured server, but otherwise not. A partner server dev I know figured it out.

It's unclear what the motivation for this was, but don't expect it to be fixed.",True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T18:22:06Z,True,pmmp_____PocketMine-MP_____2296_____404914105,Wow mojang at its finest... thanks for letting me know.,True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T18:29:57Z,True,pmmp_____PocketMine-MP_____2296_____404916131,"Players don't seem to be able to pick up items, arrows don't work and I'm being spammed with this Error: `""Call to undefined method pocketmine\math\AxisAlignedBB::offsetCopy()"" (EXCEPTION) in ""src/pocketmine/level/Level"" at line 1822`",True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T18:30:24Z,True,pmmp_____PocketMine-MP_____2296_____404916259,your composer dependencies are outdated.,True,True
pmmp_____PocketMine-MP_____2296,2018-07-13T18:42:41Z,True,pmmp_____PocketMine-MP_____2296_____404919312,Updated my composer still don't seem to be able to pick up items.,True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T02:50:59Z,True,pmmp_____PocketMine-MP_____2296_____404993514,Does this nametag-break exist in 1.6.0.x ?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T06:34:22Z,True,pmmp_____PocketMine-MP_____2296_____405003065,"yes, they backported a bunch of things from the beta into 1.5 release, including that bug.",True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T07:30:40Z,True,pmmp_____PocketMine-MP_____2296_____405005675,so pm 1.5 not coming put any sooner ?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T11:20:09Z,True,pmmp_____PocketMine-MP_____2296_____405016681,How can I download this server to test?  I updated my clients to 1.5 but last build is ce9f18c 4 days ago which is a 1.4 and I can't find the 1.5.0.10 beta nor 1.5.0?  Am I missing something or do I need to sign up for beta testing somewhere?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T11:38:37Z,True,pmmp_____PocketMine-MP_____2296_____405017576,"@edgararroyo You can download the source code and build the PM-MP yourself

https://github.com/pmmp/PocketMine-MP/tree/mc-broken-ed-1.5",True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T11:46:26Z,True,pmmp_____PocketMine-MP_____2296_____405017945,Ok thanks!,True,True
pmmp_____PocketMine-MP_____2296,2018-07-14T15:22:07Z,True,pmmp_____PocketMine-MP_____2296_____405030119,Is there a functioning phar for 1.5?,True,True
pmmp_____PocketMine-MP_____2296,2018-07-15T12:39:54Z,True,pmmp_____PocketMine-MP_____2296_____405089408,I understand that not everybody in this thread can read or understand the simplest of things so I’ll dumb it down. **There will not be a 1.5 build for a while.**,True,True
pmmp_____PocketMine-MP_____2296,2018-07-15T12:42:12Z,True,pmmp_____PocketMine-MP_____2296_____405089541,shut your face,True,True
algorithm-archivists_____algorithm-archive_____114,2018-07-17T20:56:48Z,True,algorithm-archivists_____algorithm-archive_____114_____405725150,I'm just going to close this pull request and lock it too.,True,True
mysqljs_____mysql_____1962,2018-07-18T08:51:24Z,True,mysqljs_____mysql_____1962_____405859181,"@ruiquelhas Sorry junior dev here but have some questions.

Im getting the:
`Error: ER_NOT_SUPPORTED_AUTH_MODE: Client does not support authentication protocol requested by server; consider upgrading MySQL client
    at Handshake.Sequence._packetToError`

i tried the following solution you gave to somene else:

`ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'YourRootPassword';`
-- or
`CREATE USER 'foo'@'%' IDENTIFIED WITH mysql_native_password BY 'bar';`

And that fixes the issue for me but I have some questions.

Questions:
Is this a good fix that can be deploy to production or is this just a workaround for getting things working locally?

I am also assuming that what is happened is that **8.0.11 MySQL Community Server** is just not compatible with the npm mysql library right out the box at the moment. To make it compatible right out the box You have submitted this bug fix but it hasn't been merged to master yet, and that is the reason it still doesn't work for me right out the box even tho i have the latest version of the mysql dependency.

Is my assumption correct?

If I am correct about my assumption, is there a practical way to implement the bug fix to my codebase before it is merged into master? and if there is, is that something that would be advised, or good practice?

thank you so much.

",True,True
mysqljs_____mysql_____1962,2018-07-18T09:19:10Z,True,mysqljs_____mysql_____1962_____405867267,"@Osuriel

> Is this a good fix that can be deploy to production or is this just a workaround for getting things working locally?

The new default authentication plugin is more secure because it's using SHA256 instead of SHA1 to hash the password, but it's not available for MySQL versions below 8.0, which means most existing MySQL production instances are not using it as well. So, it all boils down to how much you can trust SHA1 (for which collision attacks have already been performed in 2017). I guess having a good password should help to mitigate or even prevent that.

> I am also assuming that what is happened is that 8.0.11 MySQL Community Server is just not compatible with the npm mysql library right out the box at the moment. To make it compatible right out the box You have submitted this bug fix but it hasn't been merged to master yet, and that is the reason it still doesn't work for me right out the box even tho i have the latest version of the mysql dependency.
>
> Is my assumption correct?

Correct.

> If I am correct about my assumption, is there a practical way to implement the bug fix to my codebase before it is merged into master? and if there is, is that something that would be advised, or good practice?

I don't know if it is a good practice or not, it mostly depends on your internal policies and processes (and how much you would be ""trusting"" the fork in this case), but you can install and link npm packages from a git repo even using a specific branch or commit.

```bash
$ npm install ruiquelhas/mysql#feature/caching-sha2-password
```",True,True
mysqljs_____mysql_____1962,2018-07-18T09:20:36Z,True,mysqljs_____mysql_____1962_____405867698,Any update? Still unable to connecto to MySQL 8,True,True
mysqljs_____mysql_____1962,2018-07-18T13:02:08Z,True,mysqljs_____mysql_____1962_____405922316,@ruiquelhas thank you so much! You just helped me become a better developer hannibwas yesterday! 💪🏽🔥,True,True
pmmp_____PocketMine-MP_____2322,2018-07-23T17:07:14Z,True,pmmp_____PocketMine-MP_____2322_____203284420,"## Introduction
This pull request implements basic changes needed for Player interaction with entities.

### Relevant issues
/

## Changes
### API changes
Adds a new event: PlayerGentlyTouchEntityEvent
Adds a new method Entity::interact()

### Behavioural changes
/

## Backwards compatibility
The changes are backwards compatible.

## Follow-up
Rename the event to something sensible. 


## Tests
/
",True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:07:26Z,True,pmmp_____PocketMine-MP_____2322_____204769803,I hope you don't expect me to merge this...,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:07:29Z,True,pmmp_____PocketMine-MP_____2322_____204769829,what exactly is the point of passing the event here? Seems like extra work for no good reason.,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:08:04Z,True,pmmp_____PocketMine-MP_____2322_____204770033,formatting needs fixing throughout this file,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:09:28Z,True,pmmp_____PocketMine-MP_____2322_____204770635,"Please let's not have another godawful mess like `Entity->attack()`. The intent of this function is not clear from its name. Is the entity interacting with some other entity, or is it the one getting interacted with?",True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:10:34Z,True,pmmp_____PocketMine-MP_____2322_____204771063,I'm surprised this isn't automatic... that's perhaps a bug.,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:11:51Z,True,pmmp_____PocketMine-MP_____2322_____204771628,"Seems to be an inconsistency here. The item is only receiving the click event if the event is not cancelled, but the entity will always receive it, cancelled or not.

Additionally, parameter inconsistency exists here.",True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T14:14:12Z,True,pmmp_____PocketMine-MP_____2322_____407421631,Note also that a similar change set is also present in #2124 .,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T23:24:58Z,True,pmmp_____PocketMine-MP_____2322_____204942111,You mean the event name?,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T23:25:48Z,True,pmmp_____PocketMine-MP_____2322_____204942240,I followed the style of Entity::attack(),True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T23:26:38Z,True,pmmp_____PocketMine-MP_____2322_____204942363,Oh... I actually tried to match Entity::attack() in style,True,True
pmmp_____PocketMine-MP_____2322,2018-07-24T23:33:26Z,True,pmmp_____PocketMine-MP_____2322_____204943436,"For Entity::interact() I tried to be consistent with other methods in Entity ( Entity::attack ). 
For Item::onClickEntity, I tried to be consistent with other methods in Item ( Item::onClickAir, Item::onActivate ). ",True,True
pmmp_____PocketMine-MP_____2322,2018-07-25T02:53:36Z,True,pmmp_____PocketMine-MP_____2322_____204968561,Whats wrong exactly ?,True,True
pmmp_____PocketMine-MP_____2322,2018-07-25T03:58:07Z,True,pmmp_____PocketMine-MP_____2322_____204974960,leave space after the colon,True,True
pmmp_____PocketMine-MP_____2322,2018-07-25T07:10:57Z,True,pmmp_____PocketMine-MP_____2322_____205002904,"Entity::attack() calls the event passed to it. Here you're calling it externally and then passing it to the hook, which seems pointless.",True,True
sindresorhus_____got_____538,2018-07-25T22:57:38Z,True,sindresorhus_____got_____538_____203985914,"Option merging is now consistent, so null header removal is done during
options normalization. null could not be used to indicate property
removal because null is a significant value for some settings.",True,True
sindresorhus_____got_____538,2018-07-25T23:01:37Z,True,sindresorhus_____got_____538_____205287547,"This might not be necessary. Maybe we can just pick the right target based on whether is.array(objValue). I was running short on time, so I did this to get it working.

I think we could ditch `cloneDeep` as a dep if that works.",True,True
sindresorhus_____got_____538,2018-07-26T13:33:30Z,True,sindresorhus_____got_____538_____205456908,`target = {}` is useless here,True,True
sindresorhus_____got_____538,2018-07-26T13:33:55Z,True,sindresorhus_____got_____538_____205457067,:+1:,True,True
sindresorhus_____got_____538,2018-07-26T13:34:07Z,True,sindresorhus_____got_____538_____205457137,:+1:,True,True
sindresorhus_____got_____538,2018-07-26T13:39:30Z,True,sindresorhus_____got_____538_____205459879,use `const {URL} = require('url');`,True,True
sindresorhus_____got_____538,2018-07-26T13:51:30Z,True,sindresorhus_____got_____538_____205464377,"Consider this example:

```js
test('extend overwrites arrays', t => {
	let statusCodes = [408];
	const a = got.extend({retry: {statusCodes}});
	statusCodes[0] = 500;
	t.deepEqual(a.defaults.options.retry.statusCodes, [408]);
	t.not(a.defaults.options.retry.statusCodes, statusCodes);
});
```

It shouldn't fail. It should deep copy arrays IMO.",True,True
sindresorhus_____got_____538,2018-07-26T13:58:51Z,True,sindresorhus_____got_____538_____205467254,"Oh. Defaults are deep frozen here: https://github.com/sindresorhus/got/blob/da7f055749780438999d459dca5455a61abab8ba/source/create.js#L45

and ain't cloned before.",True,True
sindresorhus_____got_____538,2018-07-26T14:07:30Z,True,sindresorhus_____got_____538_____205470748,":-1: The feature is meant **only** for `headers`. Otherwise, if the new value is `undefined`, it shouldn't be replaced.",True,True
sindresorhus_____got_____538,2018-07-26T14:13:58Z,True,sindresorhus_____got_____538_____205473556,"Yeah, I made it only deep copy plain object, since all other types are merged by replacement.",True,True
sindresorhus_____got_____538,2018-07-26T14:18:50Z,True,sindresorhus_____got_____538_____205475319,"I'm fine either way on this one.

I interpreted the previous behavior as `undefined` being a sentinel value that can be used to remove a setting, i.e. a discrete feature of got's extension behavior.

There is a test that verifies that null headers are omitted from the normalized arguments, but I've addressed that case in normalize-arguments.

@sindresorhus do you have a preference?",True,True
sindresorhus_____got_____538,2018-07-26T14:24:14Z,True,sindresorhus_____got_____538_____205477242,"Ack. This is the same behavior as we're discussing above, so we'll resolve this when we resolve that.",True,True
sindresorhus_____got_____538,2018-07-26T14:29:09Z,True,sindresorhus_____got_____538_____205479129,"Just to clarify, based on your complete suggestion below, you think `undefined` values in the source should be noop and the target value should be preserved, right?

That is what lodash.merge does, but I don't understand the rationale in that approach. If the key exists in the source, I think it expresses some intent of the caller vs the value being undefined b/c the key does not exist.

I would suggest that when the key exists in the source and the value is undefined, the result should either be:
- omit the key from the result
- set the key to undefined in the result

I could be persuaded that the source value should be ignored, but I the rationale isn't obvious to me.",True,True
sindresorhus_____got_____538,2018-07-26T14:29:09Z,True,sindresorhus_____got_____538_____205479127,Look at the other `merge` / `extend` libs :) They omit `undefined` values.  I mean users would think that if you leave another property `undefined` it will remain unchanged. It's `header`-specific.,True,True
sindresorhus_____got_____538,2018-07-26T14:33:08Z,True,sindresorhus_____got_____538_____205480628,"> Just to clarify, based on your complete suggestion below, you think undefined values in the source should be noop and the target value should be preserved, right?

yes.",True,True
sindresorhus_____got_____538,2018-07-26T14:35:28Z,True,sindresorhus_____got_____538_____205481499,I'd leave this note about avoiding `object spread` because mostly that's not what users want.,True,True
sindresorhus_____got_____538,2018-07-26T15:20:43Z,True,sindresorhus_____got_____538_____205498538,"I pruned it because I didn't think it was necessary for us to document the language feature, and the reader's attention to detail is inversely related to the length of the docs.

I can put it back if you feel strongly that it will meaningfully assist users in making the right choice.",True,True
sindresorhus_____got_____538,2018-07-26T15:47:59Z,True,sindresorhus_____got_____538_____205508381,@sindresorhus What are your thoughts on that?,True,True
sindresorhus_____got_____538,2018-07-27T08:46:23Z,True,sindresorhus_____got_____538_____205706376,I think it's worth keeping. I see the mistake of using Object.assign/object-spread for deep objects all the time.,True,True
sindresorhus_____got_____538,2018-07-27T09:14:12Z,True,sindresorhus_____got_____538_____205713854,"Both arguments are valid and both are common. `Object.assign`/object-spread will overwrite with `undefined`, while many extends libs will not. I definitely find it more convenient when `{foo: true}, {foo: undefined}` end up as `{foo: true}`, but that also means there's no way to explicitly unset a value, like with headers. Maybe we do a middle ground and say that `null` overrides, while `undefined` does not. This is how default function arguments work. They only work with `undefined` not `null`. So to unset a header you set `null`.

```
{foo: true}, {foo: false}
// {foo: false}

{foo: true}, {foo: undefined}
// {foo: true}

{foo: true}, {foo: null}
// {foo: null}
```

Thoughts?",True,True
sindresorhus_____got_____538,2018-07-27T09:29:35Z,True,sindresorhus_____got_____538_____205718114,I strongly agree :) This behaviour is more clear IMO.,True,True
sindresorhus_____got_____538,2018-07-27T10:19:04Z,True,sindresorhus_____got_____538_____205730042,"@jstewmon Could you allow edits from maintainers? I did what @sindresorhus said, I just wanted to push one commit. You'll change that (or revert) if you'd like to.",True,True
sindresorhus_____got_____538,2018-07-27T11:20:33Z,True,sindresorhus_____got_____538_____205742966,"I wouldn't support this, as it might be confusing with `got.extend({ ... })`, where setting to `undefined` keeps the old value.",True,True
sindresorhus_____got_____538,2018-07-27T12:19:13Z,True,sindresorhus_____got_____538_____205754891,"I lightly object b/c ignoring undefined precludes the possibility of removing a setting (hypothetically, null may be a significant of invalid value). I can't think of a reason why that would be a problem today. But, I also can't think of a reason why an object would contain a key with the value set to undefined in this context b/c the key could simply be omitted to get the same behavior.

In other words, the key's absence or presence is not significant if the value is undefined, which is not something I'd expect as a user. If I set the key in the passed options, I did so with a purpose.

@szmarczak , I backed off your change b/c it overreached what we had discussed. I don't mind maintainer commits for nits or agreed upon changes, but please don't make behavioral changes when consensus has not been reached.

I think the only significant change I reverted was the deep merging of arrays. I did that because got does not make changes to those arrays, so there is no need to make a copy of them, so copying adds unnecessarily to the runtime of the method.",True,True
sindresorhus_____got_____538,2018-07-27T12:21:04Z,True,sindresorhus_____got_____538_____205755308,This test had to be rewritten to use a header key that doesn't have a default value. The behavior is consistent as you wished. :-),True,True
sindresorhus_____got_____538,2018-07-27T12:26:48Z,True,sindresorhus_____got_____538_____205756580,"OK, I've made another PR :)",True,True
sindresorhus_____got_____538,2018-07-27T12:44:47Z,True,sindresorhus_____got_____538_____205760500,"We're trying to build consensus around these changes. Making a fork at this point is counterproductive.

If there's a change you want to see, we should talk about it.",True,True
sindresorhus_____got_____538,2018-07-27T12:46:03Z,True,sindresorhus_____got_____538_____205760843,Already did.,True,True
sindresorhus_____got_____538,2018-07-27T13:14:20Z,True,sindresorhus_____got_____538_____205768259,"You 👍 my explanation for why arrays are directly assigned, then changed the behavior in a push to my branch.

You rewrote the docs I wrote without having provided any remarks.

You implemented @sindresorhus proposition on my branch without giving me a chance to respond.

I can appreciate that you are eager to land this, but we've had a productive conversation and are very close to achieving consensus on the implementation. By forging ahead, you undercut that process and then we have to have these unproductive meta conversations.

What's the rationale for, or problem solved, by deep merging arrays?",True,True
sindresorhus_____got_____538,2018-07-27T13:22:38Z,True,sindresorhus_____got_____538_____205770528,"> What's the rationale for, or problem solved, by deep merging arrays?

You don't even simply clone them, so let's start with that. With arrays there should be no exception. I'm not gonna explain simple things.

I really appreciate you want to do it on your own :)",True,True
sindresorhus_____got_____538,2018-07-27T17:42:58Z,True,sindresorhus_____got_____538_____205849348,"> I'm not gonna explain simple things.

Arguments are worthless if the other part doesn't understand you. Not everyone is in your exact mindset. We all need to be on the same page. I was also confused by your comment.",True,True
sindresorhus_____got_____538,2018-07-27T17:43:15Z,True,sindresorhus_____got_____538_____205849431,"I just realized that my proposal is how `lodash.merge` works.

> But, I also can't think of a reason why an object would contain a key with the value set to undefined in this context b/c the key could simply be omitted to get the same behavior.

It allows you to do inline conditionals:

```js
foo({
	unicorn: checkForUnicorns() && '🦄'
});
```

Without, I would have to do:

```js
const options = {};

if (shouldUseUnicorns()) {
	options.unicorn = '🦄';
}

foo(options);
```

> I backed off your change b/c it overreached what we had discussed. I don't mind maintainer commits for nits or agreed upon changes, but please don't make behavioral changes when consensus has not been reached.

@szmarczak Don't modify other people's PRs before we have agreed on a solution.",True,True
sindresorhus_____got_____538,2018-07-27T18:30:32Z,True,sindresorhus_____got_____538_____205862572,"@sindresorhus thanks for providing that example. I can appreciate the convenience that provides.

It occurred to me that, in the future, we could expose a symbol support deleting a key if the need for it arises. Similarly, we could expose a symbol to indicate that the result should be `undefined` if there's a need to explicitly set a key to `undefined`.

Using symbols for those cases would have the disadvantage of being a unique approach, but it would have the advantage of our interface being optimized for the most common scenarios.

If we're settled on ignoring `undefined`, we could rename `assignOptions` to `mergeOptions` to help clarify that its behavior is not congruent with Object.assign.",True,True
sindresorhus_____got_____538,2018-07-27T19:19:07Z,True,sindresorhus_____got_____538_____205874964,"On closer inspection, I didn't actually remove this - I just inserted the function description before the warning. :-)",True,True
sindresorhus_____got_____538,2018-07-27T20:53:21Z,True,sindresorhus_____got_____538_____205896674,"> Arguments are worthless if the other part doesn't understand you. Not everyone is in your exact mindset. We all need to be on the same page. I was also confused by your comment.

I'll sum up: going through shortcuts won't end well, just a hint. Another hint: references, arrays, deep freeze. This says a lot.

> Don't modify other people's PRs before we have agreed on a solution.

I've just proposed a solution based on yours. Do what you want, I'm off. I'll be happy with any (current one is cool too).",True,True
sindresorhus_____got_____538,2018-07-27T21:06:28Z,True,sindresorhus_____got_____538_____205899740,"> Yeah, I made it only deep copy plain object, since all other types are merged by replacement.

I don't think obvious things need an explanation, do they? You've just repeated yourself: that's what your code does, doesn't it? Please come up with a real argument. I'll illustrate if you have problems with understanding mine:

1. Someone creates an array.
2. The array is passed to assignOptions through `got.extend()`.
3. It is passed by reference (please keep that word in mind my friend).
4. It's deep frozen (got.extend() -> got.create() -> deepFreeze())
5. Someone wants to reuse the array.
6. :boom:",True,True
sindresorhus_____got_____538,2018-07-27T21:42:51Z,True,sindresorhus_____got_____538_____205906821,"I understand that concern, but I intentionally kept the implementation simple, so that the results are predictable.

I was also concerned with performance, since this method is called not only by `got.extend` and `got.create`, but also by every call to `got()`.

There are an infinite number of possible reference types that inherit from object, which may also have unexpected behavior when cloned, especially when only an object's own properties are cloned.

I reluctantly chose to recursively merge source values that are plain objects when the target value is not a plain object for this reason because normalize-arguments currently requires that the options it receives are mutable. I would rather have refactored normalize-arguments, so that it selectively builds a new object from the input, but I thought that was too large a change to introduce here.

Do you think it would be helpful to explicitly mention in the `got.extend` and `got.create` that the resulting object is frozen, so that any reference types will be frozen? We could also mention that a workaround is to use something like `_.deepClone` if users need to preserve a mutable instance of a config setting.

We could also reconsider whether freezing the options tips the balance of predicable behavior nearer or farther from the user's expectations.",True,True
sindresorhus_____got_____538,2018-07-27T22:00:15Z,True,sindresorhus_____got_____538_____205909813,"Just clarify my position - I'm not strictly inflexible on the implementation, but I want to make sure my rationale is clearly expressed before we decide to change it.

@sindresorhus do you have an opinion on this topic?",True,True
sindresorhus_____got_____538,2018-07-28T10:12:04Z,True,sindresorhus_____got_____538_____205939574,"> I was also concerned with performance, since this method is called not only by got.extend and got.create, but also by every call to got().

Then why? There are many nitpicks that could improve performance **a bit** (it's unnoticeable) like this one and you're nothing about that. Please, be serious.

> Do you think it would be helpful to explicitly mention in the got.extend and got.create that the resulting object is frozen, so that any reference types will be frozen?

No. That's dumb. All plain objects are frozen and other objects like arrays are not? That doesn't have any sense. BTW, It's OK to pass references to other types than objects and arrays since `got` doesn't use them.",True,True
sindresorhus_____got_____538,2018-07-28T10:32:02Z,True,sindresorhus_____got_____538_____205939969,@jstewmon Nice copycat work. GL ITF.,True,True
sindresorhus_____got_____538,2018-07-28T10:36:47Z,True,sindresorhus_____got_____538_____205940044,Wait. What's with `user-agent`? You need to change the test name if you change the behaviour too.,True,True
sindresorhus_____got_____538,2018-07-28T10:38:24Z,True,sindresorhus_____got_____538_____205940077,Use `Reflect.has()` for consistency.,True,True
sindresorhus_____got_____538,2018-07-28T10:39:00Z,True,sindresorhus_____got_____538_____205940092,Also I suggest figuring out a better test name.,True,True
sindresorhus_____got_____538,2018-07-28T10:40:12Z,True,sindresorhus_____got_____538_____205940112,After I read the test name I still don't know what's this about.,True,True
sindresorhus_____got_____538,2018-07-28T10:42:56Z,True,sindresorhus_____got_____538_____205940269,Stop guessing. You need to change the URL to `#gotassignoptionsparentoptions-newoptions`.,True,True
sindresorhus_____got_____538,2018-07-29T07:56:40Z,True,sindresorhus_____got_____538_____205964426,"> Do you think it would be helpful to explicitly mention in the got.extend and got.create that the resulting object is frozen, so that any reference types will be frozen? We could also mention that a workaround is to use something like _.deepClone if users need to preserve a mutable instance of a config setting.

Yes, that would be useful.
",True,True
sindresorhus_____got_____538,2018-07-29T07:59:41Z,True,sindresorhus_____got_____538_____408659319,"I've decided. Let's go with ignoring `undefined` and rename the method to `mergeOptions`.

I think we should also deep clone the array, not because it solves all the problems, but it makes it less likely that the user will encounter a problem with references, and I think that is worth the neglible performance we save by not doing it. This is also how `lodash.merge` works and what users would expect:

> Array and plain object properties are merged recursively. Other objects and value types are overridden by assignment. Source objects are applied from left to right. - `lodahs.merge` docs

We can pretty much reuse the above description for our `mergeOptions` docs.",True,True
KSP-KOS_____KOS_____2260,2018-07-29T17:32:39Z,True,KSP-KOS_____KOS_____2260_____408692952,@Dunbaratu Can you please check that I have resolved the conflicts in CPU.cs correctly? Thx,True,True
sindresorhus_____got_____538,2018-07-29T19:33:26Z,True,sindresorhus_____got_____538_____408700252,"@sindresorhus I wasn't sure whether you meant to just make a copy of the source array or merge the array into the target's property value (like lodash). I assumed (and implemented) the former, since that's closest to what we've been discussing, but your comment about lodash gave me some doubt.",True,True
sindresorhus_____got_____538,2018-07-29T20:11:23Z,True,sindresorhus_____got_____538_____408702622,@jstewmom You forgot `git add` ;) There's no `merge-options` file.,True,True
sindresorhus_____got_____538,2018-07-29T20:15:10Z,True,sindresorhus_____got_____538_____205985803,Glad you've taken my tip ^_^,True,True
sindresorhus_____got_____538,2018-07-30T08:28:31Z,True,sindresorhus_____got_____538_____408787083,Avoid `new Array`. [See this for more explanation](https://stackoverflow.com/a/932392/5189849).,True,True
KSP-KOS_____KOS_____2260,2018-08-01T04:12:40Z,True,KSP-KOS_____KOS_____2260_____409443433,"@firda-cze I'm having a hard time trying to make ``git`` to actually show me what conflicts you encountered.  When I fetch your branch and checkout your commit just prior to 48f8ba5, then try to do a git merge develop myself to see what conflicts would have appeared, it shows zero conflicts.  I'm having a hard time forcing git to actually show me what the conflict choices you had to make actually were.",True,True
pmmp_____PocketMine-MP_____2322,2018-08-01T04:46:12Z,True,pmmp_____PocketMine-MP_____2322_____409447966,"Again, you haven't explained how the other PR is better? I looked at the code and it seems to be the exact thing I did, with the exception of my implementation also having a method inside the Item class.",True,True
KSP-KOS_____KOS_____2260,2018-08-01T13:10:52Z,True,KSP-KOS_____KOS_____2260_____409569177,"@Dunbaratu I have used KDiff3 and used your version whenever it could not resolve it automatically. So, I hope it is fine (most or all conflicts were on the top of the file - removal of the enum, introduction of interrupt priorities, joined list of yielding tasks, some reordering and removal of variables).",True,True
SuperDARN_____rst_____153,2018-08-01T13:37:50Z,True,SuperDARN_____rst_____153_____409577410,"I believe this is mostly working except for the `/trace` keyword which is not giving the expected results.  Using the DLMs from within IDL:

```
IDL> print,aacgm_v2_setdatetime(2018,08,01,00,00,00)     
% Loaded DLM: AACGMDLM.
           0
IDL> pos=cnvcoord_v2(60.,120.,300.)                      
IDL> print,pos
       55.955571      -166.05710       1.0456635
IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)
IDL> print,pos
       22.449229       179.36041       1.0456635
```
And this is using the native IDL code:

```
IDL> print,aacgm_v2_setdatetime(2018,08,01,00,00,00)     
       0
IDL> pos=cnvcoord_v2(60.,120.,300.)                 
% Compiled module: FACTORIAL.
IDL> print,pos
       55.955571      -166.05710       1.0456635
IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)          
IDL> print,pos
       12.062125      -170.09346       1.0456635
```

From the online calculator (http://sdnet.thayer.dartmouth.edu/aacgm/aacgm_calc.php#AACGM):

```
FIELD-LINE TRACING

DATE    : 20180801
 0000 UT
Altitude:  290.931 km**

       Geographic                  AACGM-v2 
 Latitude     Longitude     Latitude     Longitude     MLT
(degrees N)  (degrees E)   (degrees N)  (degrees E)  (hours)
-----------  -----------   -----------  -----------  -------
  60.0000     120.0000       55.7656    -166.5262     8.0929
```

I've also modified the behavior of the `AACGM_v2_GetDateTime` function in the DLMs to suppress the warning output when the `/silent` keyword is passed to match the behavior of the native IDL function.",True,True
SuperDARN_____rst_____153,2018-08-01T13:49:17Z,True,SuperDARN_____rst_____153_____409581000,"Is this a new change? I want to be sure that the standalone version is the
master and the RST is kept synchronized, otherwise changes in the RST will
be overwritten.

Simon

On Wed, Aug 1, 2018 at 9:37 AM Evan Thomas <notifications@github.com> wrote:

> I believe this is mostly working except for the /trace keyword which is
> not giving the expected results. Using the DLMs from within IDL:
>
> IDL> print,aacgm_v2_setdatetime(2018,08,01,00,00,00)
> % Loaded DLM: AACGMDLM.
>            0
> IDL> pos=cnvcoord_v2(60.,120.,300.)
> IDL> print,pos
>        55.955571      -166.05710       1.0456635
> IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)
> IDL> print,pos
>        22.449229       179.36041       1.0456635
>
> And this is using the native IDL code:
>
> IDL> print,aacgm_v2_setdatetime(2018,08,01,00,00,00)
>        0
> IDL> pos=cnvcoord_v2(60.,120.,300.)
> % Compiled module: FACTORIAL.
> IDL> print,pos
>        55.955571      -166.05710       1.0456635
> IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)
> IDL> print,pos
>        12.062125      -170.09346       1.0456635
>
> From the online calculator (
> http://sdnet.thayer.dartmouth.edu/aacgm/aacgm_calc.php#AACGM):
>
> FIELD-LINE TRACING
>
> DATE    : 20180801
>  0000 UT
> Altitude:  290.931 km**
>
>        Geographic                  AACGM-v2
>  Latitude     Longitude     Latitude     Longitude     MLT
> (degrees N)  (degrees E)   (degrees N)  (degrees E)  (hours)
> -----------  -----------   -----------  -----------  -------
>   60.0000     120.0000       55.7656    -166.5262     8.0929
>
> I've also modified the behavior of the AACGM_v2_GetDateTime function in
> the DLMs to suppress the warning output when the /silent keyword is
> passed to match the behavior of the native IDL function.
>
> —
> You are receiving this because you are subscribed to this thread.
>
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-409577410>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DP06IOpEDA6hy6FKRLfDzgIKdpJTdks5uMa8wgaJpZM4TzQZR>
> .
>
",True,True
KSP-KOS_____KOS_____2260,2018-08-01T13:51:22Z,True,KSP-KOS_____KOS_____2260_____409581731,"The problem I had was just that I can't get git to actually generate the conflicts in the first place.  When I fetch your branch, checkout the commit just before your merge of public/develop, then try to merge develop into that myself, git claims there's no conflicts.  So I can't see what you saw.  I'm not sure why.  Hypothetically, that should have worked.",True,True
SuperDARN_____rst_____153,2018-08-01T13:55:44Z,True,SuperDARN_____rst_____153_____409583171,"@sshepherd yes I made a new change to `aacgmdlm.c`.  I can send you a copy of the modified file to drop into your local/master AACGM_v2 directory so it's not overwritten.

Am I interpreting the `/trace` keyword correctly that it is the same as choosing the field-line tracing option with the online calculator?",True,True
SuperDARN_____rst_____153,2018-08-01T14:11:14Z,True,SuperDARN_____rst_____153_____409588650,"I believe so but will have to confirm next week when I get back to the
office. The good news is that there doesn’t look like a new release will
happen anytime soon.

On Wed, Aug 1, 2018 at 9:55 AM Evan Thomas <notifications@github.com> wrote:

> @sshepherd <https://github.com/sshepherd> yes I made a new change to
> aacgmdlm.c. I can send you a copy of the modified file to drop into your
> local/master AACGM_v2 directory so it's not overwritten.
>
> Am I interpreting the /trace keyword correctly that it is the same as
> choosing the field-line tracing option with the online calculator?
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-409583171>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DPwdRegv0wqxhiyMSIMnx0G-lXSnzks5uMbNhgaJpZM4TzQZR>
> .
>
",True,True
nestjs_____typeorm_____27,2018-08-05T22:08:08Z,True,nestjs_____typeorm_____27_____410552074,@kamilmysliwiec any idea on how it will be implemented ? We cannot really use TypeORM withou EventSubscribers imo.,True,True
nestjs_____typeorm_____27,2018-08-06T09:36:02Z,True,nestjs_____typeorm_____27_____410648693,"@LeoMartinDev maybe create an issue over at TypeORM, so they provide an (non internal-)API for EventSubscribers.",True,True
nestjs_____typeorm_____27,2018-08-06T11:36:27Z,True,nestjs_____typeorm_____27_____410679178,"@BrunnerLivio I guess we just need a public `registerSubscriber()` method or something like that, right ?",True,True
sbpp_____sourcebans-pp_____488,2018-08-06T19:57:49Z,True,sbpp_____sourcebans-pp_____488_____410833948,"Just looking at it now again, feel like this would break any RCON scripts/plugins that call to this command, as it does not check for player validity correctly.",True,True
sbpp_____sourcebans-pp_____488,2018-08-06T21:58:22Z,True,sbpp_____sourcebans-pp_____488_____410865941,"How would it break rcon scripts? When rcon or sm_rcon is ran, clientId returned is 0. Ive had zero issues since implementing this on my own servers.",True,True
sbpp_____sourcebans-pp_____488,2018-08-07T11:36:39Z,True,sbpp_____sourcebans-pp_____488_____411026529,"I double checked through the flow of the ban menu and it does the same exact thing that /ban playerName time ""Reason"" would do (see CreateBan). If there is an issue with an invalid client, then the problem is not with the menu, but elsewhere in the plugin.",True,True
SuperDARN_____rst_____153,2018-08-07T15:26:55Z,True,SuperDARN_____rst_____153_____411097212,"These changes and bug fixes should get out quickly. The stand-alone AACGM-v2 code was updated and has been in use for several months by non-RST users. RST users are using old and buggy code but asking for the ""patches"" to the AACGM-v2 code. A better solution is to release a new version of RST quickly, with these and other changes.",True,True
SuperDARN_____rst_____153,2018-08-07T15:29:26Z,True,SuperDARN_____rst_____153_____411098133,"Ok, so the problem was related to an outdated `IGRF_COEFFS` environment variable in `superdarn.bash` and `superdarn.tcsh`.  Repeating my test from before,

With the DLM:
```
IDL> print,aacgm_v2_setdatetime(2018,08,1,00,00,00)
% Loaded DLM: AACGMDLM.
           0
IDL> pos=cnvcoord_v2(60.,120.,300.)
IDL> print,pos
       55.955571      -166.05710       1.0456635
IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)
IDL> print,pos                            
       55.957024      -166.05854       1.0456635
```

However, without the DLM:
```
IDL> print,aacgm_v2_setdatetime(2018,08,1,00,00,00)
       0
IDL> pos=cnvcoord_v2(60.,120.,300.)                
% Compiled module: FACTORIAL.
IDL> print,pos
       55.955571      -166.05710       1.0456635
IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)         
IDL> print,pos
       12.062125      -170.09346       1.0456635
IDL> print,getenv('IGRF_COEFFS')                   
/jumbo/superdarn/evan/test_rst6/rst/tables/analysis/mag/magmodel_1590-2015.txt
```

@sshepherd, are you sure the native IDL code is getting the paths correct?",True,True
SuperDARN_____rst_____153,2018-08-07T16:33:32Z,True,SuperDARN_____rst_____153_____411120280,"This is a touch off-topic, but I wanted to suggest a friendly solution to help with things like this in the future:

@sshepherd if this is such a critical fix, or you think it requires a higher priority due to severity of bugs, it's useful to communicate this from the beginning so people can prioritize. It's not really fair to complain otherwise. If you have, I missed it, and my comment is moot.

There are ways to deal with this though. For example, a ""hotfix branch"" or something similar could have been made with an RST4.1.1 release or whatever the version number should be. Easy for me to say, I know. I'll slink back in to the shadows now.",True,True
SuperDARN_____rst_____153,2018-08-07T16:57:52Z,True,SuperDARN_____rst_____153_____411127827,"I will defer any decision regarding ""hot fix branches"", or whatever, to
those who are developing guidelines. This was (I think) identified in the
original request as a bug fix. My ""complaints"" are merely an attempt to get
changes into users hands more quickly than would otherwise happen. This is
not commercial software and should, in my opinion, be updated more
frequently with the caveat that we know there will still be bugs in the
code. Our more experienced users will likely identify these bugs. The
alternative is that we sit on code fixes, features, etc. for over a year
waiting for someone to decide that a new release is appropriate. As an
observer, I am suggesting that a new release is overdue.

On Tue, Aug 7, 2018 at 12:33 PM, Ashton Reimer <notifications@github.com>
wrote:

> This is a touch off-topic, but I wanted to suggest a friendly solution to
> help with things like this in the future:
>
> @sshepherd <https://github.com/sshepherd> if this is such a critical fix,
> or you think it requires a higher priority due to severity of bugs, it's
> useful to communicate this from the beginning so people can prioritize.
> It's not really fair to complain otherwise. If you have, I missed it, and
> my comment is moot.
>
> There are ways to deal with this though. For example, a ""hotfix branch"" or
> something similar could have been made with an RST4.1.1 release or whatever
> the version number should be. Easy for me to say, I know. I'll slink back
> in to the shadows now.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-411120280>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DP1W5PfGMSYbXmQmQVAAzOb_k0di_ks5uOcFdgaJpZM4TzQZR>
> .
>
",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T00:56:07Z,True,sbpp_____sourcebans-pp_____488_____411249215,"The problem is triggering the menu accidentally due to a player bootstrap plugin. This is not a typical situation, but I've seen it in the past while resolving people's problems. Nevertheless, I believe this should be reserved for admin menu only, requiring the generic flag rather than just bundling it just for the sake of convenience.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T01:51:51Z,True,sbpp_____sourcebans-pp_____488_____411257686,"In order to make sure this conversation has at least been productive in any sense, could you find or demonstate an example of where my new feature may cause some sort of problem? Doing so could perhaps allow me to learn and improve this code, otherwise I have failed understand the issue since you have been vague on 'bootstrapping' issues.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T02:17:13Z,True,sbpp_____sourcebans-pp_____488_____411261454,"Lets say a plugin runs ServerCommand sm_ban. That would result in client == 0, which would not display the menu. If a plugin runs FakeClientCommand on sm_ban and that client does not have access, that would result in an error message displayed that the user does not have access, which again would not display the menu.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T02:35:47Z,True,sbpp_____sourcebans-pp_____488_____411264472,"Also  ""_just for the sake of convenience._""

Isnt that the entire point of improving plugins? Convenience? Making it easier to do things?",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T04:44:04Z,True,sbpp_____sourcebans-pp_____488_____411283401,"Plugins bootstrap `FakeClientCommand` to detect compatibility rather than the includes.

> Isnt that the entire point of improving plugins? Convenience? Making it easier to do things?

No. It was just yesterday someone asked help on admin menu flags; there's no need to give admins the ban menu if it was designed to work with the generic flag's admin menu and we ought to respect the existing flag system.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T04:57:15Z,True,sbpp_____sourcebans-pp_____488_____411285220,"I dont understand what you mean by ""Plugins bootstrap FakeClientCommand to detect compatibility rather than the includes."" You keep saying bootstrap.

Also afaik, fakeclientcommand can't override the admin flags for a registered admin command.

The admin menu also checks to see if a player has access to sm_ban before adding it to the clients list, which necessarily isn't ADMNFLAG_GENERIC.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:04:34Z,True,sbpp_____sourcebans-pp_____488_____411286330,"Like I've said, if somehow a plugin is able to open the menu via sm_ban, then something else is wrong with either SM or something internal to sb++.

So Im beginning to suspect that you dont understand how plugins work. At this point I don't even care. My two goals were to contribute and to learn. Neither of those have happened to far.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:36:03Z,True,sbpp_____sourcebans-pp_____488_____411290760,"Admin menu requires the generic flag, and like I said this isn't a common case, so you don't need to get all trigger happy about it.

> So Im beginning to suspect that you dont understand how plugins work. At this point I don't even care.

That's your opinion, and if you want to believe that, then do it, if you don't want people's take on this, then don't bother.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:39:18Z,True,sbpp_____sourcebans-pp_____488_____411291325,"By default, admin menu uses adminflag generic, yes, but because that is what sm_ban is set to by default. If it is overriden, then it is a set to whatever flag it is overridden to. This further points to your lack of understanding on how plugins work. You have provided zero working evidence as to why my feature would break anything, and instead are going off your ""feelings"" and ""beliefs"".",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:42:12Z,True,sbpp_____sourcebans-pp_____488_____411291799,"> You have provided zero working evidence as to why my feature would break anything, and instead are going off your ""feelings"" and ""beliefs"".

I do not have any working evidence because I'm NOT the minority subjective group in question. If you want I can spin up an example tomorrow. 

Taking the minority factor away, the only thing I have against this is the idea to keep the menu as a submenu in admin menu only; as geo mentioned it's not clear to its command name",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:43:13Z,True,sbpp_____sourcebans-pp_____488_____411291956,"Edit: By default, Admin Menu itself only requires ADMNFLAG_GENERIC, but in order to populate the menu with sm_ban, it checks client flag for ADMFLAG_BAN, which is what is set when sm_ban is created.

`RegAdminCmd(""sm_ban"", CommandBan, ADMFLAG_BAN, ""sm_ban <#userid|name> <minutes|0> [reason]"", ""sourcebans"");`

Because of this, it means that a client is REQUIRED to have either ADMNFLAG_BAN or whatever flag(s) the command is overridden by.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:48:52Z,True,sbpp_____sourcebans-pp_____488_____411292976,"_""Taking the minority factor away, the only thing I have against this is the idea to keep the menu as a submenu in admin menu only; as geo mentioned it's not clear to its command name""_

For this reason, I have left in the ReplyToCommand line when args == 0. It will still display the usage parameters, whether or not client == 0.",True,True
sbpp_____sourcebans-pp_____488,2018-08-08T05:54:03Z,True,sbpp_____sourcebans-pp_____488_____411293861,"Locked as too heated, will continue in DM with JoinedSenses.",True,True
syncthing_____syncthing-android_____1212,2018-08-08T08:39:12Z,True,syncthing_____syncthing-android_____1212_____206932326,"Purpose
Remove the secure key generation extra from MainActivity as it's only used one time at first app launch and move it to a separate welcome wizard slide instead. With that move, overhead code in MainActivity will be avoided.

Screenshots
a) Early dev screenshot

Status
Still working on it. Being incrementally tested.
",True,True
syncthing_____syncthing-android_____1212,2018-08-08T12:07:52Z,True,syncthing_____syncthing-android_____1212_____411382735,There is no way this is going into .14. .14 will be whatever is in the beta plus bug fixes if any.,True,True
syncthing_____syncthing-android_____1212,2018-08-08T12:52:00Z,True,syncthing_____syncthing-android_____1212_____411394135,Ok I'll correct the milestone.,True,True
callstack_____react-native-paper_____485,2018-08-08T15:57:42Z,True,callstack_____react-native-paper_____485_____207057055,"<!-- Please provide enough information so that others can review your pull request. -->
<!-- Keep pull requests small and focused on a single change. -->

### Motivation
Menu component with auto positioning and RTL support:
https://material.io/design/components/menus.html
fixes: #9 

<!-- What existing problem does the pull request solve? Can you solve the issue with a different approach? -->

### Test plan
![menu-2](https://user-images.githubusercontent.com/11161020/43848868-9c92f5e6-9b3c-11e8-88c4-123b1f02bab1.png)
<!-- List the steps with which we can test this change. Provide screenshots if this changes anything visual. -->
",True,True
callstack_____react-native-paper_____485,2018-08-08T16:03:16Z,True,callstack_____react-native-paper_____485_____411459963,"Hey @iyadthayyil, thank you for your pull request 🤗. The documentation from this branch can be viewed [here](https://4120-71323749-gh.circle-artifacts.com/0/docs/index.html).",True,True
SuperDARN_____rst_____153,2018-08-08T19:06:32Z,True,SuperDARN_____rst_____153_____411517870,"Hmmm, something is probably not set correctly. I get the following
(correct) output when I disable the DLMs and run the attached test program:

Output:

COEFF:        55.955571      -166.05710       1.0456635
TRACE:        55.765593      -166.52621       1.0456635

oregon:~/Projects/AACGM/distro/idl/latest> setenv | grep DLM

IDL_DLM_PATH=
DLMPATH=

Simon



On Tue, Aug 7, 2018 at 11:29 AM, Evan Thomas <notifications@github.com>
wrote:

> Ok, so the problem was related to an outdated IGRF_COEFFS environment
> variable in superdarn.bash and superdarn.tcsh. Repeating my test from
> before,
>
> With the DLM:
>
> IDL> print,aacgm_v2_setdatetime(2018,08,1,00,00,00)
> % Loaded DLM: AACGMDLM.
>            0
> IDL> pos=cnvcoord_v2(60.,120.,300.)
> IDL> print,pos
>        55.955571      -166.05710       1.0456635
> IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)
> IDL> print,pos
>        55.957024      -166.05854       1.0456635
>
> However, without the DLM:
>
> IDL> print,aacgm_v2_setdatetime(2018,08,1,00,00,00)
>        0
> IDL> pos=cnvcoord_v2(60.,120.,300.)
> % Compiled module: FACTORIAL.
> IDL> print,pos
>        55.955571      -166.05710       1.0456635
> IDL> pos=cnvcoord_v2(60.,120.,300.,/trace)
> IDL> print,pos
>        12.062125      -170.09346       1.0456635
> IDL> print,getenv('IGRF_COEFFS')
> /jumbo/superdarn/evan/test_rst6/rst/tables/analysis/mag/magmodel_1590-2015.txt
>
> @sshepherd <https://github.com/sshepherd>, are you sure the native IDL
> code is getting the paths correct?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-411098133>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DPwoHolim9e0JFCaP8nQDVL2W5rQcks5uObJmgaJpZM4TzQZR>
> .
>
",True,True
SuperDARN_____rst_____153,2018-08-08T19:17:05Z,True,SuperDARN_____rst_____153_____411520849,@sshepherd attachments don't seem to survive when replying to github messages via email.  Can you re-attach the file to the pull request discussion using the github website?,True,True
SuperDARN_____rst_____153,2018-08-08T19:32:37Z,True,SuperDARN_____rst_____153_____411525161,"Here is the contents of the file I call ""newtest.idl"" which I then run from the command line: ""idl newtest.idl""





    .compile genmag
    .compile igrflib_v2
    .compile aacgmlib_v2
    .compile aacgm_v2
    .compile time
    .compile astalg
    .compile mlt_v2

    ch = ''
    fmt = '(a,$)'

    year  = 2018
    month = 8
    day   = 1
    ; hour, minute, second have little effect...

    ret = AACGM_v2_SetDateTime(year,month,day)

    ;-----------------------------------------------------------------------------
    ; test single input
    ;

    lat0 = 60.
    lon0 = 120.
    alt  = 300.

    p = cnvcoord_v2(lat0,lon0, alt)
    print, 'COEFF: ', p

    p = cnvcoord_v2(lat0,lon0,alt,/trace)
    print, 'TRACE: ', p
    print, ''

    exit",True,True
SuperDARN_____rst_____153,2018-08-08T20:14:59Z,True,SuperDARN_____rst_____153_____411537327,"And here is my output (when copying the IDL .pro files from this branch of the RST to a new directory):

```
babylon1:~/aacgm_test$ idl newtest.idl 
IDL Version 8.5.1 (linux x86_64 m64). (c) 2015, Exelis Visual Information Solutions, Inc., a subsidiary of Harris Corporation.
Installation number: 212858-3.
Licensed for use by: Dartmouth College

% Compiled module: AACGM_V2_DAYNO.
% Compiled module: AACGM_V2_DATE.
...
% Compiled module: MLTCONVERTEPOCH_V2.
% Compiled module: MLT_V2.
% Compiled module: FACTORIAL.
COEFF:        55.955571      -166.05710       1.0456635
TRACE:        12.062125      -170.09346       1.0456635

```

If I roll back to the master branch, the native trace option works correctly:

```
IDL> print,aacgm_v2_setdatetime(2018,8,1,0,0,0)
       0
IDL> print,cnvcoord_v2(60.,120.,300.)          
% Compiled module: FACTORIAL.
       55.955571      -166.05710       1.0456635
IDL> print,cnvcoord_v2(60.,120.,300.,/trace)
       55.957022      -166.05854       1.0456635
```

Are you sure the IDL code to parse and load the pre-1900+IGRF coefficients within the RST is working correctly?",True,True
SuperDARN_____rst_____153,2018-08-08T20:21:47Z,True,SuperDARN_____rst_____153_____411539323,"Ah. This is within the RST... I am testing the stand-alone version so I
will have to look at how it maps to the RST. The answer is probably ""no"".

Simon

On Wed, Aug 8, 2018 at 4:15 PM, Evan Thomas <notifications@github.com>
wrote:

> And here is my output (when copying the IDL .pro files from this branch of
> the RST to a new directory):
>
> babylon1:~/aacgm_test$ idl newtest.idl
> IDL Version 8.5.1 (linux x86_64 m64). (c) 2015, Exelis Visual Information Solutions, Inc., a subsidiary of Harris Corporation.
> Installation number: 212858-3.
> Licensed for use by: Dartmouth College
>
> % Compiled module: AACGM_V2_DAYNO.
> % Compiled module: AACGM_V2_DATE.
> ...
> % Compiled module: MLTCONVERTEPOCH_V2.
> % Compiled module: MLT_V2.
> % Compiled module: FACTORIAL.
> COEFF:        55.955571      -166.05710       1.0456635
> TRACE:        12.062125      -170.09346       1.0456635
>
>
> If I roll back to the master branch, the native trace option works
> correctly:
>
> IDL> print,aacgm_v2_setdatetime(2018,8,1,0,0,0)
>        0
> IDL> print,cnvcoord_v2(60.,120.,300.)
> % Compiled module: FACTORIAL.
>        55.955571      -166.05710       1.0456635
> IDL> print,cnvcoord_v2(60.,120.,300.,/trace)
>        55.957022      -166.05854       1.0456635
>
> Are you sure the IDL code to parse and load the pre-1900+IGRF coefficients
> within the RST is working correctly?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-411537327>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DPz-IA_-F8mZCj0MfxQv0Ks8JTBpIks5uO0bEgaJpZM4TzQZR>
> .
>
",True,True
syncthing_____syncthing-android_____1212,2018-08-09T09:02:18Z,True,syncthing_____syncthing-android_____1212_____411689123,"@AudriusButkevicius Do you have time to review it? I expect nothing dramatically changed with this PR. If we can speed this a little bit up, I can do more features until this week is over :).",True,True
syncthing_____syncthing-android_____1212,2018-08-09T09:24:24Z,True,syncthing_____syncthing-android_____1212_____208862050,"Is this the condition whether this slide is shown or not?  
I am asking because naively I would have expected a condition when setting the layout, as I would expect that's relevant there (e.g. for the dots at the bottom indicating the current and amount of slides). Remember, I know nothing about this stuff, so this isn't criticism. ",True,True
syncthing_____syncthing-android_____1212,2018-08-09T09:31:18Z,True,syncthing_____syncthing-android_____1212_____208864177,"No, this is the condition when the AsyncTask (""a separate thread"") should end immediately. If this occurs (rarely) something has gone particularly wrong because the activity is destroyed before the asyncTask completed its work. As I implemented it like ""don't allow the user to advance out of this activity"" this should not happen. But in case another one changes code around, this is a very precautionary approach to be better safe than sorry. Best practice in Android coding say, you should check if your activity (the caller) is still there before referencing it from an AsyncTask.",True,True
syncthing_____syncthing-android_____1212,2018-08-09T09:38:03Z,True,syncthing_____syncthing-android_____1212_____208866250,"( or what's preventing you from doing that? )
I'm not sure if will work okay as I need this exact class FirstStartActivity again for my next improvement. I often experienced that a lot of minor changes are necessary and then I don't know how to keep the branch-branch in sync properly. (I did then create a new branch from the master and manually reapplied the changed code parts). Can I also pull from merged-branch to sub-branch when the point where the sub-branch was created isn't the commit that got merged? (and having less conflicts to resolve)
I just meant it would be a nice bonus if things go faster, but it's also okay if we stick to a good review that takes a little bit longer.

To your question above:
The app currently does only check if a crucial permission is missing (like storage permission) and if so repeat the welcome assistant. I think there are pros and cons to this.
Pro: Code is shorter and less error-prone as we don't have to reorder slides an have ""hardcoded int's"" versus the ""we can't get a hardcoded one, so a constant is required in code""
Cons: More code, more checks and reorder of the slides. The simple approach checking for ""ready for the next slide"" wouldn't apply anymore. We also would required saving bundles for the slide states for the case the phone is rotated > much more work. If necessary, I can do it.

... So long no one complained having to go through all slides again and that goes real quick. If something is already done you can press Continue>Continue>Continue and land. Repeating the slides also improves migration tasks if we later need to change something about the storage permission (I made this up, but can happen). We would then have overhead for checking if we need it and if we need a migration step to show the slide again. Opinions welcome:)",True,True
syncthing_____syncthing-android_____1212,2018-08-09T12:36:16Z,True,syncthing_____syncthing-android_____1212_____411742080,"What's displayed if keys are already there? `Secure keys for private data exchange have been successfully generated. ` suggest it just happened, which isn't really true in that case.

From a user point of view, it would definitely be nicer if only the pages that actually need an action are shown. I can't just rapidly press continue, because I don't know a priori whether the next slide requires action or not. If this is too difficult to do then I am fine with displaying them anyway. From my limited experience QT wizards where slides are just added to a parent UI object, you could just skip adding those that aren't relevant - I guess it's more involved with java/android (at least that was my experience whenever I tried to do anything in the android sphere :P ).

Regarding changes on top of changes: I usually branch on top of the open PR branch and then  rebase whenever the PR gets changed. Once the first PR is merged, I rebase the second branch on top of master (which works without conflicts, as master looks like the old branch). You can even open a PR off that secondary branch: Initially it will contain the diff of the first PR, but once that got merged, those parts of the diff disappear. In most cases that's not helpful though, as there is a reason the old branch isn't merged yet. I'd only do that if you want early feedback on a design choice or something like that.",True,True
syncthing_____syncthing-android_____1212,2018-08-09T20:40:09Z,True,syncthing_____syncthing-android_____1212_____411889616,"Ok, I'll skip slides automatically if they are no longer relevant for user convenience.",True,True
SuperDARN_____rst_____153,2018-08-10T12:15:01Z,True,SuperDARN_____rst_____153_____412064702,"The above fixes to the native IDL code were forwarded to me from @sshepherd since he is traveling to a radar site today.  I've tested them and the `/trace` keyword option is now fixed.  With that taken care of and the C code already having been tested (by myself and @aburrell), I'm merging this pull request.",True,True
SuperDARN_____rst_____153,2018-08-10T14:41:32Z,True,SuperDARN_____rst_____153_____412103209,"self merging, *high brow*.  Though it does seem like this has been fairly well tested and if anything the pull request could have been said to originate from @sshepherd as he's been making the fixes that are then translated to rst.  I don't have a problem here, though lets try not to do that too much.",True,True
SuperDARN_____rst_____153,2018-08-11T13:31:37Z,True,SuperDARN_____rst_____153_____412275268,"I suggest we try and avoid these type of unhelpful comments in the future.
The release of an updated RST is long overdue and attempts to move the
process along are only met with resistance and further delays. The RST is
not commercial software and should not be treated as such. Updates should
get to users quickly.

On Fri, Aug 10, 2018 at 10:41 AM Kevin Sterne <notifications@github.com>
wrote:

> self merging, *high brow*. Though it does seem like this has been fairly
> well tested and if anything the pull request could have been said to
> originate from @sshepherd <https://github.com/sshepherd> as he's been
> making the fixes that are then translated to rst. I don't have a problem
> here, though lets try not to do that too much.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-412103209>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DP3ZPDXeqDNdVME4wcGpkQ69MdjY1ks5uPZudgaJpZM4TzQZR>
> .
>
",True,True
SuperDARN_____rst_____153,2018-08-11T17:18:24Z,True,SuperDARN_____rst_____153_____412289360,"I completely agree with @ksterne.

I completely disagree with @sshepherd about the comment being unhelpful.

There is a process and it must be followed, otherwise what is the point of having it. As an observer, I would say is it appropriate for @sshepherd to encourage people not to follow the process that the working group has established.

And nothing @ksterne did slowed the process. He didn't revert the merge. @sshepherd made a comment in several places that a new release of RST is long overdue. The response to this has been the largest flurry of activity on this repo in months. My inbox has been absolutely slammed with RST updates the past 2 weeks (which is awesome!).  People, especially @egthomas, @ksterne, @mts299, and @kkotyk  have made a significant effort to get a ton of pull requests merged. Literally spending entire days on mostly RST development (judging from the email alerts I received).",True,True
SuperDARN_____rst_____153,2018-08-11T17:37:28Z,True,SuperDARN_____rst_____153_____412290484,"Except @ksterne went on to admit the pull request originated from @sshepherd and that it really wasn't a self merge, so the sarcastic ""high brow"" comment was entirely unnecessary.",True,True
SuperDARN_____rst_____153,2018-08-11T17:42:50Z,True,SuperDARN_____rst_____153_____412290765,"Did it though? @egthomas made the pull request.

![image](https://user-images.githubusercontent.com/4604819/43994499-be2e45da-9d52-11e8-91fb-68064a24e21a.png)

Sure, ""high brow"" was not needed, but that was hardly the point of @ksterne's entire comment. cherry picking aside.",True,True
SuperDARN_____rst_____153,2018-08-11T17:49:57Z,True,SuperDARN_____rst_____153_____412291146,"Is it really my pull request if 100% of the original code changes on the branch were made by someone else and I simply opened it for them on github and then tested it?  The rest of @ksterne's comment acknowledged that fact, which is why the initial sarcasm was unnecessary and unhelpful.",True,True
SuperDARN_____rst_____153,2018-08-11T17:54:14Z,True,SuperDARN_____rst_____153_____412291372,"Communication is important.

I have absolutely no way of knowing (and neither does anyone else) that this is actually @sshepherd's pull request if you make it and don't say that you made it for him. Not that it matters if you respect the process.

And again, his comment didn't slow any process at all. It was a caution against people merging their own pull requests, which is 100% not in line with the agreed to process.

The most inappropriate thing here is someone encouraging others to ignore the process.

But sure, let's continue down this trail of productive pedantry.",True,True
SuperDARN_____rst_____153,2018-08-11T17:59:42Z,True,SuperDARN_____rst_____153_____412291684,"You're right, this is going nowhere and the previous comments speak for themselves.

well apparently locking doesn't do what I think it does, oh well",True,True
SuperDARN_____rst_____153,2018-08-11T18:09:28Z,True,SuperDARN_____rst_____153_____412292231,"Hey all, sorry for my colorful comment here, I didn't mean it in any seriousness and was only meant to be a slight joke.  My main intention wasn't to scold things here, I truly am happy with this pull request through and through.  I more meant to make a gentle reminder to other devs we shouldn't do this too much.  And somewhat for posterity as it looks like self merging though it only is on the face and not in content/context.

I am truly sorry that my joke had the opposite effect of what I meant here.  I'll try to keep this in mind for the future.",True,True
SuperDARN_____rst_____153,2018-08-11T18:28:17Z,True,SuperDARN_____rst_____153_____412293323,"Ashton, are you contributing in a meaningful way to the RST effort or just
quick with your opinions on various procedural matters?

On Sat, Aug 11, 2018 at 1:18 PM Ashton Reimer <notifications@github.com>
wrote:

> I completely agree with @ksterne <https://github.com/ksterne>.
>
> I completely disagree with @sshepherd <https://github.com/sshepherd>
> about the comment being unhelpful.
>
> There is a process and it must be followed, otherwise what is the point of
> having it. As an observer, I would say is it appropriate for @sshepherd
> <https://github.com/sshepherd> to encourage people not to follow the
> process that the working group has established.
>
> And nothing @ksterne <https://github.com/ksterne> did slowed the process.
> He didn't revert the merge. @sshepherd <https://github.com/sshepherd>
> made a comment in several places that a new release of RST is long overdue.
> The response to this has been the largest flurry of activity on this repo
> in months. My inbox has been absolutely slammed with RST updates the past 2
> weeks (which is awesome!). People, especially @egthomas
> <https://github.com/egthomas>, @ksterne <https://github.com/ksterne>,
> @mts299 <https://github.com/mts299>, and @kkotyk
> <https://github.com/kkotyk> have made a significant effort to get a ton
> of pull requests merged. Literally spending entire days on mostly RST
> development (judging from the email alerts I received).
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-412289360>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DPwrG5wE-JQO8pDrb5mOMXzeCqSXfks5uPxHhgaJpZM4TzQZR>
> .
>
",True,True
SuperDARN_____rst_____153,2018-08-11T18:40:53Z,True,SuperDARN_____rst_____153_____412294069,"I did not check my mailbox this morning, and here we are... 
Guys, cool down! 
Getting personal is not helpful at all, and sense of humour is an invaluable asset.",True,True
SuperDARN_____rst_____153,2018-08-11T20:29:53Z,True,SuperDARN_____rst_____153_____412299716,"Appreciate the reply, Kevin, particularly while waiting for you in the Tim
Horton’s parking lot in Timmins. See you soon, I hope.

On Sat, Aug 11, 2018 at 2:09 PM Kevin Sterne <notifications@github.com>
wrote:

> Hey all, sorry for my colorful comment here, I didn't mean it in any
> seriousness and was only meant to be a slight joke. My main intention
> wasn't to scold things here, I truly am happy with this pull request
> through and through. I more meant to make a gentle reminder to other devs
> we shouldn't do this too much. And somewhat for posterity as it looks like
> self merging though it only is on the face and not in content/context.
>
> I am truly sorry that my joke had the opposite effect of what I meant
> here. I'll try to keep this in mind for the future.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/SuperDARN/rst/pull/153#issuecomment-412292231>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC2DPz6UK0jYHxM-xx4EjRdMEwWV5yXzks5uPx3YgaJpZM4TzQZR>
> .
>
",True,True
SuperDARN_____rst_____153,2018-08-11T20:36:16Z,True,SuperDARN_____rst_____153_____412300025,"Yes, thank you for clearing that up @ksterne - I'm sorry for misinterpreting your comment and apologize.",True,True
syncthing_____syncthing-android_____1212,2018-08-14T22:00:46Z,True,syncthing_____syncthing-android_____1212_____210118450,"So showing pointless slides is very confusing to the user. I imagine users screaming on the forum now wanting to loose their device ID after revoking storage permissions or something like that (as slides imply the keys will be generated).

 You could simply build a list of strings indicating what needs to be shown, and just serialize that list between rotations.",True,True
syncthing_____syncthing-android_____1212,2018-08-14T22:01:02Z,True,syncthing_____syncthing-android_____1212_____210118510,Why does this needs to be a week ref? Why can't it just be a normal reference?,True,True
syncthing_____syncthing-android_____1212,2018-08-14T22:01:40Z,True,syncthing_____syncthing-android_____1212_____210118654,"The ""Enjoy"" is very cheesy, let's not say that.",True,True
syncthing_____syncthing-android_____1212,2018-08-14T22:03:31Z,True,syncthing_____syncthing-android_____1212_____210119104,"""the config"" ->  ""configuration""

This doesn't really explain what happened, and the instructions are not clear. Why should I back up my pictures if the config creation failed? Or is this talking about keys/config? If it is, how can I even get to a screen where I can do that?

",True,True
syncthing_____syncthing-android_____1212,2018-08-14T22:04:39Z,True,syncthing_____syncthing-android_____1212_____413031293,"Oh, and sorry I was away for so long. Had no desktop for a few days.",True,True
syncthing_____syncthing-android_____1212,2018-08-14T22:07:06Z,True,syncthing_____syncthing-android_____1212_____413031850,Thanks for the review. I'll get back on the weekend and then make adjustments as advised.,True,True
nestjs_____typeorm_____27,2018-08-16T20:30:20Z,True,nestjs_____typeorm_____27_____413674925,"Hopefully, typeorm will provide this feature soon. Thanks for reporting @LeoMartinDev ",True,True
nestjs_____typeorm_____27,2018-08-16T21:29:04Z,True,nestjs_____typeorm_____27_____413690467,"@LeoMartinDev probably something like that, but I think the typeorm team knows best whats appropriate and consistent with their API",True,True
LLK_____scratch-vm_____1497,2018-08-18T00:37:13Z,True,LLK_____scratch-vm_____1497_____209284552,"Reverts LLK/scratch-vm#1453
Fixes https://github.com/LLK/scratch-gui/issues/2911 

The rounding is stopping position setting of floats. The rounding needs to be done in the display instead.",True,True
LLK_____scratch-vm_____1497,2018-08-18T00:39:59Z,True,LLK_____scratch-vm_____1497_____414019296,@thisandagain @paulkaplan ,True,True
syncthing_____syncthing-android_____1212,2018-08-18T08:57:53Z,True,syncthing_____syncthing-android_____1212_____414043504,"( Why are you fiddling with syncthing version? )
I am not. It's from the master.",True,True
syncthing_____syncthing-android_____1212,2018-08-18T08:58:58Z,True,syncthing_____syncthing-android_____1212_____211069489,"I've explained this in an earlier PR, I think it was one of those ""static field leaks PRs"". It's Android best coding practice, nothing more. This prevents lint warnings.",True,True
syncthing_____syncthing-android_____1212,2018-08-18T08:59:16Z,True,syncthing_____syncthing-android_____1212_____211069494,ok.,True,True
syncthing_____syncthing-android_____1212,2018-08-18T09:04:34Z,True,syncthing_____syncthing-android_____1212_____211069619,"=> Failed to create configuration. Consider backing up your sync data, then clear this app\'s data from Android settings.
It's also been there before and used by showCrashNotification if a corrupted config is about to be parsed in SyncthingService. We don't know what happened. But if that happens, the user needs to fully start over by wiping the SharedPrefs and app data. If the user has data in the ""only available readwrite area com.nutomic.syncthingandroid/files"", this data will be lost.
We should say something, that's better than letting the user run into an android pitfall if he tries to reinstall/clear app data alone. https://github.com/syncthing/syncthing-android/pull/1212/commits/75154fa069f1abd4792f2164e74c8ad084f5204c",True,True
LLK_____scratch-vm_____1497,2018-08-18T10:43:42Z,True,LLK_____scratch-vm_____1497_____414049071,"@amazinigmech2418 The issue is not marked as ""help wanted"". Please don't submit pull request for issues without the ""help wanted"" label.",True,True
syncthing_____syncthing-android_____1212,2018-08-18T11:08:13Z,True,syncthing_____syncthing-android_____1212_____414050351,"Are we ready now?
Latest commit according to review
( Show welcome slides only if mandatory prerequisites are  …
missing. Show only slides that are necessary because of
missing prerequisites. Mandatory prerequisites are
a) storage permission b) existance of keys and config
Remove key generation UI from StateDialogActivity as this
is no longer required in the main UI as we ensure generating
keys and config before launching to MainActivity. ) ",True,True
LLK_____scratch-vm_____1497,2018-08-18T13:38:56Z,True,LLK_____scratch-vm_____1497_____414058600,@kyleplo That's not something the [CONTRIBUTING](https://github.com/LLK/scratch-vm/blob/develop/.github/CONTRIBUTING.md) file actually says.,True,True
syncthing_____syncthing-android_____1212,2018-08-18T14:27:14Z,True,syncthing_____syncthing-android_____1212_____414061728,Sorry I am away for a day or so. Hopefully get to this tomorrow or monday ,True,True
LLK_____scratch-vm_____1497,2018-08-18T16:34:35Z,True,LLK_____scratch-vm_____1497_____414070299,"@Kenny2github @kyleplo @joker314 This is a MAJOR glitch. Even if it isn't ""help wanted"", it needs to be done. See the issue it fixes. ST members are saying it is needed.",True,True
LLK_____scratch-vm_____1497,2018-08-19T07:27:34Z,True,LLK_____scratch-vm_____1497_____414109274,"@amazinigmech2418 why did you ping me? I'm not involved with this at all (though now I am).

It is a major problem, but nevertheless you shouldn't open pull requests until they're marked ""help wanted"". If it's not marked help wanted, that means an ST member will open a pull for it eventually, and outside contributions are not needed.",True,True
LLK_____scratch-vm_____1497,2018-08-19T11:11:59Z,True,LLK_____scratch-vm_____1497_____414120287,"@joker314 But they will get mad at you: 
- https://github.com/LLK/scratch-gui/pull/1356#issuecomment-360994198
- https://github.com/LLK/scratch-gui/pull/1443#issuecomment-367791786
- https://github.com/LLK/scratch-gui/pull/1765#issuecomment-381112787",True,True
syncthing_____syncthing-android_____1212,2018-08-19T18:09:51Z,True,syncthing_____syncthing-android_____1212_____211110669,"this should be static I think,",True,True
syncthing_____syncthing-android_____1212,2018-08-19T18:10:26Z,True,syncthing_____syncthing-android_____1212_____211110682,what's up with this iStuff? why can't you just do this.layout = layout.,True,True
syncthing_____syncthing-android_____1212,2018-08-19T18:12:08Z,True,syncthing_____syncthing-android_____1212_____211110749,"Just instantiate this to 4 or 10 or whatever the amount you need is, and just check for nulls.",True,True
syncthing_____syncthing-android_____1212,2018-08-19T18:13:07Z,True,syncthing_____syncthing-android_____1212_____211110780,"You could add SlideType enum and then set the type for each slide, and find the index by iterating over slides later rather than storing some integer on the class body.",True,True
syncthing_____syncthing-android_____1212,2018-08-19T18:44:02Z,True,syncthing_____syncthing-android_____1212_____211111631,Why does failing to create configuration needs backup your data? Also what is sync data? what does that even mean?,True,True
syncthing_____syncthing-android_____1212,2018-08-19T18:45:59Z,True,syncthing_____syncthing-android_____1212_____211111683,Or use an linked list or something.,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:18:11Z,True,syncthing_____syncthing-android_____1212_____211113885,Failing to read a corrupted config needs backup.,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:18:42Z,True,syncthing_____syncthing-android_____1212_____211113904,Do I hear much extra work?,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:19:13Z,True,syncthing_____syncthing-android_____1212_____211113915,mSlides length does the job pretty well.,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:29:54Z,True,syncthing_____syncthing-android_____1212_____211114204,"It's already corrupt, backup of what?",True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:32:14Z,True,syncthing_____syncthing-android_____1212_____211114263,"You hear an improved implementation where slide type does not depend on the index of it, which makes the code easier to understand and reason wether it works correctly.

If adding an enum is much extra work, then I am not even sure what's not much extra work.",True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:38:24Z,True,syncthing_____syncthing-android_____1212_____211114423,ok,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:38:28Z,True,syncthing_____syncthing-android_____1212_____211114425,ok,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:39:34Z,True,syncthing_____syncthing-android_____1212_____211114457,"Assigned for the next PR of @AudriusButkevicius . Merge and then do it, please. You've got my approval for this implementation.",True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:40:05Z,True,syncthing_____syncthing-android_____1212_____211114470,I've had existing data in a past fail case when it got corrupt. ,True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:47:47Z,True,syncthing_____syncthing-android_____1212_____211114721,"Sorry, but I am not going to blindly merge something regardless of how salty you behave.
I am trying to behave like a reasonable adult, but at some point I too will run out of patience.",True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:56:58Z,True,syncthing_____syncthing-android_____1212_____211114951,"If you don't wish to drive this home, let's close this and part ways.

I'd prefer to have no contributions, over contributions where every improvement gets a toxic response for no apparent reason.",True,True
syncthing_____syncthing-android_____1212,2018-08-19T20:57:53Z,True,syncthing_____syncthing-android_____1212_____211114971,"What existing data? Are you saying a corrupt config deletes data? If the config is corrupt, how does syncthing even know where the data is?",True,True
syncthing_____syncthing-android_____1212,2018-08-19T21:04:24Z,True,syncthing_____syncthing-android_____1212_____211115175,"The PR was tested on my phone, worked perfectly from the early beginning. Code shaping is yours, developing is mine.",True,True
LLK_____scratch-vm_____1497,2018-08-20T14:36:29Z,True,LLK_____scratch-vm_____1497_____414338443,"@amazinigmech2418 Thanks for bringing this up and for this PR.

In general, @kyleplo and @Kenny2github are correct that we would prefer all community PRs to have an associated ""help wanted"" issue, since we would like to come to consensus internally on how to resolve an issue before reviewing PRs.  Major and obvious regressions like this are a gray area however.

@mzgoddard @cwillisf I think we need to resolve this in scratch-render if we choose this method, since as-is this solution is like making all move operations followed by `[go to x: (round (x position)) y: (round (y position))]`, destroying any sub-pixel sprite position.",True,True
syncthing_____syncthing-android_____1212,2018-08-20T19:04:49Z,True,syncthing_____syncthing-android_____1212_____211374092,Android associates data with apps! Read a book about android.,True,True
syncthing_____syncthing-android_____1212,2018-08-20T19:05:26Z,True,syncthing_____syncthing-android_____1212_____211374268,"( It's already corrupt, backup of what? ) The Config is corrupt my data lives... yippie, I'll back it up!",True,True
MagicStack_____asyncpg_____348,2018-08-21T19:42:36Z,True,MagicStack_____asyncpg_____348_____209934542,"Add `session` parameter to `connection()` with default value `True`.
When set to `False` the client will limit usage of prepared statements
to unnamed in a transaction only.

As a side effect handling of unnamed prepared statements improved
irrespective of `session` value - they are automatically reprepared
if something invalidating them occurs.",True,True
MagicStack_____asyncpg_____348,2018-08-21T19:44:23Z,True,MagicStack_____asyncpg_____348_____414797868,Implements #339,True,True
typelevel_____cats_____2437,2018-08-22T23:51:17Z,True,typelevel_____cats_____2437_____210295006,"Hi Everyone, 

As you know, Sam has finally finished his book, and a fair bit of it deals with Cats, as well as Scalaz. As the most modern resource on the subject of FP in Scala (chronologically), I feel it has a place here, considering it _is_ free and very well-written. Thanks.
",True,True
typelevel_____cats_____2437,2018-08-22T23:54:51Z,True,typelevel_____cats_____2437_____415225532,@LukaJCB can i get a hallelujah?,True,True
typelevel_____cats_____2437,2018-08-22T23:59:47Z,True,typelevel_____cats_____2437_____415226471,"Sam has been openly hostile the typelevel project, to the point of inventing and spreading lies about it and its members. 

I also don't think that  the book has an accurate description of cats.",True,True
typelevel_____cats_____2437,2018-08-23T00:00:46Z,True,typelevel_____cats_____2437_____415226679,"I actually didn't feel cats, or typelevel, were relevant enough to mention.",True,True
typelevel_____cats_____2437,2018-08-23T00:03:09Z,True,typelevel_____cats_____2437_____415227180,"@stew which part wasn't accurate? The parent part? I can change that. 

You don't like the guy and I get it, but there's no sense in denying a resource like this to everyone just because y'all had a personal spat. FP is agnostic of the politics.",True,True
typelevel_____cats_____2437,2018-08-23T00:24:50Z,True,typelevel_____cats_____2437_____415231025,@emilypi see @fommil's comment above. We respect the intention of the original content author. ,True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:16:17Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____210502522,"Adds page size selector to paginator and tightens up some styles. This does have breaking changes, but should allow for us to have this component better interface with the table component.

#451, fixes #445, fixes #316",True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:35:10Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____415482585,"Could you explain why this is a breaking change. I was expecting for this to just be an addition to the component. We need to hold off on breaking changes; otherwise, it'll annoy developers who are currently using this",True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:35:14Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212376915,Thanks for updating this style as we discussed to match the stroke on the select box.  One thing to change though is to make `height: 36px` instead of 37px now.  You can check the example on the subnav component to see a primary and secondary button side by side.,True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:38:03Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212377748,Lets keep our PRs focused on a single component in the future. It made sense to include those other pagination fixes in this but hiding a button change doesn't make sense.,True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:38:38Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____415483779,"@jtrujill the component used to require the user to input the numberOfPages, but with the page size being adjustable, it makes more sense for that to be calculated based on the number of items being paged through",True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:41:34Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212378819,I didn't realize that the last paginator was relying on other cashmere components. I suggest that we keep other cashmere components out of our templates since a subtle change in one could drastically effect the style of another. This can be fixed in a future update,True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:43:33Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212379347,Here's another instance were it should not have been included in this PR. No where is it mentioned that button or select were modified.,True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T16:46:49Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212380285,"But then we are creating similar things that look and act the same way as each other but pull from different code.  So for example, if we change the styling of the button - it comes across here.  If this was something that just looked like the button, we'd have to remember to change its style as well when we updated the button.  And we wouldn't want to rewrite the select box for this component, no?",True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T17:48:40Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____415508892,@corykon is the numberOfPages change the only breaking change? Could you just map that to the new field and change the description of what it does and mark that as deprecated. I think most people were just passing the number of elements to that field anyways. I don't want to keep updating the major version for small changes like this ,True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T18:08:24Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212405741,"Pagination buttons look nothing like an hc-button. I've been in projects that try to heavily reuse components and extend them where they are used by either changing the default functionality or style. If all of our components start using other components within well eventually run into major issues. By major issues I mean that you can run into cyclic issues. On top of that you have hidden dependencies that the user doesn't know about which could cause issues. Say that you have a drop-down that uses an hc-button and the user the client doesn't import hc-button, then you'll have issues.

Basically there are many reasons not to and few reasons to use cashmere components in other cashmere components templates",True,True
HealthCatalyst_____Fabric.Cashmere_____470,2018-08-23T19:12:20Z,True,HealthCatalyst_____Fabric.Cashmere_____470_____212425359,It doesn't have to be changed in this PR but we should have the understanding that in the future this will need to be changed and that future components should avoid using other cashmere components in their templates,True,True
YilianSource_____brackeys-bot_____51,2018-08-24T17:03:24Z,True,YilianSource_____brackeys-bot_____51_____210796681,"Closes #50 . Looks like it was an issue with Discord.NET that got fixed in a nightly build.

There have been a few little changes you might have noticed;
- You can't pass an EmbedBuilder to ReplyAsync anymore, use EmbedBuilder.Build()
- AddModulesAsync now needs a service provider as an argument
- A few changes to IMessage.GetReactionUsersAsync",True,True
YilianSource_____brackeys-bot_____51,2018-08-24T18:15:19Z,True,YilianSource_____brackeys-bot_____51_____415840126,"When this gets merged, please, before deploying for the first time run ""dotnet add package Discord.Net -v 2.0.0-beta2-00982 -s https://www.myget.org/F/rogueexception/api/v3/index.json"" once to register MyGet as a NuGet package source or else dotnet run/build/publish won't know from where to get Discord.NET and will error out.",True,True
MagicStack_____asyncpg_____348,2018-08-25T15:52:36Z,True,MagicStack_____asyncpg_____348_____415978489,"Hi Aleksey. Thanks for working on this. The PR looks interesting, however I have concerns with the introduced redundancy.  With this change, uncached anonymous statements would incur the penalty of preparing the query twice instead of once.  This might be fine for simple queries, but if a query is sufficiently large and complicated, the `Parse` step easily dominates everything else.

I feel like the best solution would be to make some changes on the pgbouncer side as well.  IIRC, the crux of the issue is that pgbouncer is hardcoded to only support the libpq behaviour by pinning the Parse/Bind/Execute/Sync sequence to a connection.  I think teaching it to support Parse/Describe/Sync/Bind/Execute/Sync the same way should remove the need to send `Parse` twice.  It would also be awesome to add a way to deterministically detect pgbouncer (e.g. by having it append a `ParameterStatus` message on connection), to remove the need for the `session` argument.",True,True
MagicStack_____asyncpg_____348,2018-08-25T22:10:06Z,True,MagicStack_____asyncpg_____348_____415999718,"> With this change, uncached anonymous statements would incur the penalty of preparing the query twice instead of once.

Uncached statements prepare twice iff `session == False`. For `session == True` amount of commands sent to a server is the same compared to the previous version. If `session == False` and prepared statements cache enabled then unnamed prepared statements cached (because of `Describe`) and only re`Parse`d on each `Bind/Execute`.

```
Session == True: 
    prepare(): Parse/Describe/Sync (once, cached)
    execute(): Bind/Execute/Sync

Session == False && !is_in_transaction():
    prepare(): Parse/Describe/Sync (once, cached)
    execute(): Parse/Bind/Execute/Sync

Session == False && is_in_transaction():
    prepare(): Parse/Describe/Sync (once, cached)
    execute(): Bind/Execute/Sync
```

> I think teaching it to support Parse/Describe/Sync/Bind/Execute/Sync the same way should remove the need to send Parse twice.

This is against the nature of pgbouncer and against the reason ""why we use pgbouncer with exactly this settings"". We don't want connection to postgresql to be held by someone outside of a transaction. Holding connection between Prepare and Execute leads to unpredictable behaviour under high load.

> It would also be awesome to add a way to deterministically detect pgbouncer (e.g. by having it append a ParameterStatus message on connection), to remove the need for the session argument.

The choice to use pgbouncer or not should be done explicitly by a human. It has impact on performance characteristics, architecture and code of a service.",True,True
MagicStack_____asyncpg_____348,2018-08-25T22:22:18Z,True,MagicStack_____asyncpg_____348_____416000287,"> the crux of the issue is that pgbouncer is hardcoded to only support the libpq behaviour by pinning the Parse/Bind/Execute/Sync sequence to a connection

This is not true. pgbouncer has no hardcoded sequences. `Sync` is the unit of work delimiter and this declared by PostgreSQL, not pgbouncer:

""At completion of each series of extended-query messages, the frontend should issue a Sync message. This parameterless message causes the backend to close the current transaction if it's not inside a BEGIN/COMMIT transaction block (“close” meaning to commit if no error, or roll back if error). Then a ReadyForQuery response is issued. The purpose of Sync is to provide a resynchronization point for error recovery. When an error is detected while processing any extended-query message, the backend issues ErrorResponse, then reads and discards messages until a Sync is reached, then issues ReadyForQuery and returns to normal message processing.""",True,True
MagicStack_____asyncpg_____348,2018-08-26T18:16:43Z,True,MagicStack_____asyncpg_____348_____416058033,"> Uncached statements prepare twice iff session == False

Yes, and this is a problem.  There may be multiple reasons why the cache may be disabled, too small, get cleared often, etc.  Also, I don't think adding a new connection parameter is the right way to go at all.  See below.

> This is against the nature of pgbouncer and against the reason ""why we use pgbouncer with exactly this settings"". We don't want connection to postgresql to be held by someone outside of a transaction. Holding connection between Prepare and Execute leads to unpredictable behaviour under high load.

I was referring strictly to the handling of unnamed statements, where the time between Parse and Execute is predictably small.  I agree that named prepared statements, portals and other session-level features are ""against the nature of pgbouncer"" in transaction mode.  I think, however, that a more robust bouncer implementation would reject these requests outright as opposed to failing in an unpredictable fashion.

>>  It would also be awesome to add a way to deterministically detect pgbouncer (e.g. by having it append a ParameterStatus message on connection), to remove the need for the session argument.

> The choice to use pgbouncer or not should be done explicitly by a human. It has impact on performance characteristics, architecture and code of a service.

This is not about the choice to use pgbouncer.  This is about detecting the capabilities of the server and adjusting accordingly.  We do this already to support various PostgreSQL variants and servers speaking its protocol.

pgbouncer is **not** a transparent proxy by any means, given how it breaks the session semantics, so it should be treated as a PostgreSQL variant that doesn't support prepared statements properly, in which case the `statement_cache_size` should default to `0`.  If we are unable to detect pgbouncer, manually setting `statement_cache_size` to `0` will be required.

> pgbouncer has no hardcoded sequences.

If that's, in fact, true, and pgbouncer always only looks at `Sync`, then the solution is not to emit `Sync` after the initial `Parse` or `Parse/Describe`.

> `Sync` is the unit of work delimiter and this declared by PostgreSQL, not pgbouncer:

I am aware of that, thanks.

Bottom line, here's what I think should be done to add support for pgbouncer in an acceptable fashion:

1. Decouple the codec configuration cache from the server-side prepared statement cache. `statement_cache_size` explicitly becomes about the use of server-side prepared statements only.
2. Make it so that in the unnamed statement case the `Parse/Describe/Bind/Execute` sequence always has exactly one `Sync` (`Parse/Bind/Execute/Sync` for the cached codec case, `Parse/Describe/Flush/Bind/Execute/Sync` for the uncached case).
3. Add detection of pgbouncer (possibly relying on remote help).  Set `statement_cache_size` to `0`, when detected (and raise an exception if it is explicitly set to a non-zero value).  Lacking detection, and when a prepared statement exception occurs, advise the user to set `statement_cache_size` to `0` explicitly.",True,True
alliedmodders_____amxmodx_____524,2018-08-27T10:16:52Z,True,alliedmodders_____amxmodx_____524_____211065957,@psychonic It's based on your PR https://github.com/alliedmodders/sourcemod/pull/390 but I'm unsure of paths. Will it be fine?,True,True
MagicStack_____asyncpg_____348,2018-08-27T12:02:37Z,True,MagicStack_____asyncpg_____348_____416204176,"> Decouple the codec configuration cache from the server-side prepared statement cache. statement_cache_size explicitly becomes about the use of server-side prepared statements only.

Can you explain this idea in more details?
Looks very complicated for me, maybe I missed something.

> `Parse/Describe/Flush/Bind/Execute/Sync` for the uncached case

Flush will not help. This will be one connection to PostgreSQL hold by one client. Application may be non-perfect and can not return control to coroutine connected to database for tenths and even hundreds of milliseconds resulting in pgsql connection hold by pgbouncer for the same time. It is inappropriate for distributed systems.",True,True
MagicStack_____asyncpg_____348,2018-08-27T14:26:14Z,True,MagicStack_____asyncpg_____348_____416244719,"> Can you explain this idea in more details? Looks very complicated for me, maybe I missed something.

It's not complicated.  The only change is making `statement_cache_size` track the number of _named_ statements in the `PreparedStatementState` cache.  That way setting `statement_cache_size` to `0` will prevent the use of named statements, but will retain the benefit of cached `Describe` results.

> Flush will not help. This will be one connection to PostgreSQL hold by one client. Application may be non-perfect and can not return control to coroutine connected to database for tenths and even hundreds of milliseconds resulting in pgsql connection hold by pgbouncer for the same time. It is inappropriate for distributed systems.

Then you need to fix your application!  There is no guarantee that your `await query` will always run until completion and will not get preempted by another coroutine at an arbitrary point in the protocol flow, regardless of the number of hacks you make.  It all depends on what and how much was `select()`-ed from the sockets on a particular loop iteration, and you can't reliably control that.  This is how asyncio works and you have to deal with it.  So, please stop making general claims that asyncpg is ""inappropriate for distributed systems"" when all I'm trying to do is help you improve the status-quo in the first place.",True,True
MagicStack_____asyncpg_____348,2018-08-27T14:55:50Z,True,MagicStack_____asyncpg_____348_____416254596,"> The only change is making statement_cache_size track the number of named statements in the PreparedStatementState cache.

I thought the primary reason of this parameter is to limit memory used by the client. If memory is not an issue then OK.

> Then you need to fix your application!

Different systems have different requirements. Small error in one of application request handlers shouldn't crash all the system (by utilizing all pgsql connections), one of worker can get stuck or die, but not the system at all. Web applications are live, they modified couple times a weak and even a day, they should be tolerant to small errors.

> There is no guarantee that your await query will always run until completion and will not get preempted by another coroutine at an arbitrary point in the protocol flow, regardless of the number of hacks you make.

I don't really care about python workers, there are many of them, they easily scale. I care about database itself, master is the only and not scale.

> please stop making general claims that asyncpg is ""inappropriate for distributed systems""

asyncpg has nothing about ""distributed systems"", and any database client too. It is an architecture of application about it. The only thing a database client should do - not to interfere. Right now asyncpg prevents usage of pgbouncer. So, scale is not possible with current asyncpg version.

I don't really mean that asyncpg is ""inappropriate"", this word was about `Parse/Describe/Flush/Bind/Execute/Sync` sequence.",True,True
MagicStack_____asyncpg_____348,2018-08-27T15:38:45Z,True,MagicStack_____asyncpg_____348_____416268881,"```python
        if (use_cache or named) and self._protocol.session:
            stmt_name = self._get_unique_id('stmt')
        else:
            stmt_name = ''
```

Looks like `statement_cache_size=0` is insufficient. I can change this line to `if use_cache and named` but this change current behaviour.",True,True
MagicStack_____asyncpg_____348,2018-08-27T16:10:49Z,True,MagicStack_____asyncpg_____348_____416279047,"> I thought the primary reason of this parameter is to limit memory used by the client. If memory is not an issue then OK.

It is about the memory usage, but mostly server-side, as prepared statements can consume a non-trivial amount of memory.  The overall size of the client-side cache should obviously remain capped.  I don't think we should expose that as a connection argument just yet, let's default to some larger value than the current `statement_cache_size` default.

> Different systems have different requirements. 

Yes, and if we were to satisfy all the different requirements of different systems in asyncpg, we would have a mess that wouldn't work for anybody.  The goal of asyncpg is to work well with vanilla PostgreSQL, as that is a known common baseline.  We are willing to support other PostgreSQL-like systems, but only **if** that support does not compromise the integrity and maintainability of asyncpg.

> Small error in one of application request handlers shouldn't crash all the system (by utilizing all pgsql connections).

Again, what does that have to do with asyncpg?  Your misbehaving application would exhaust the pgbouncer pool, or any other limited resource pool equally well.  Fix it!  Arguably, a system that can go down due to a small error in a single component is badly designed.  If you are so worried about connection stalls, then refactor the database access into a standalone, well reviewed and tested service, separate from the application logic.

>> There is no guarantee that your `await query` will always run until completion

> I don't really care about python workers, there are many of them, they easily scale. I care about database itself, master is the only and not scale.

I don't think you understood, or deliberately ignored what I wrote.  Whatever you do, you cannot guarantee with absolute certainty that the protocol instance will always receive the entire database response in a single loop iteration, and your `await query` might get preempted while holding the connection.  If your system cannot tolerate that, then asyncio is not for you.

> Right now asyncpg prevents usage of pgbouncer...

... in the transaction mode.  And the approach I suggested would fix that without introducing much complexity and side effects for existing workflows.

>  So, scale is not possible with current asyncpg version.

You just made that claim again.

> I don't really mean that asyncpg is ""inappropriate"", this word was about Parse/Describe/Flush/Bind/Execute/Sync sequence.

Well, I think that `Parse/Describe/Sync` + `Parse/Bind/Execute/Sync` is inappropriate since we would be forcing double `Parse` on all uncached queries, and there is a quantifiable cost to that, unlike your abstract claims about ""distributed systems"".  

As it stands, I'm against merging your version.",True,True
MagicStack_____asyncpg_____348,2018-08-27T16:35:38Z,True,MagicStack_____asyncpg_____348_____416286608,"> I don't think you understood, or deliberately ignored what I wrote. Whatever you do, you cannot guarantee with absolute certainty that the protocol instance will always receive the entire database response in a single loop iteration, and your await query might get preempted while holding the connection. If your system cannot tolerate that, then asyncio is not for you.

It's OK if asyncpg is talking with pgbouncer. pgbouncer will cache the response and postgresql connection will be released. I don't care how many loop iteration required in python, I only want postgresql connection to be released as soon as possible. Think of pgbouncer in front of postgresql the same way as you think about nginx in front of python backend - it is used to handle slow clients.

> If you are so worried about connection stalls, then refactor the database access into a standalone, well reviewed and tested service, separate from the application logic.

I love to keep things simple. A lot of small services which are modified often are harder to maintain.
Anyway a database client should not impact on architecture.

> And the approach I suggested would fix that without introducing much complexity and side effects for existing workflows.

This PR has no side effects for existing workflow.

> Well, I think that Parse/Describe/Sync + Parse/Bind/Execute/Sync is inappropriate since we would be forcing double Parse on all uncached queries

When connected to pgbouncer in `pool_mode=transaction` only. Right now even this is impossible.
This PR has no impact on existing workflow. It only adds additional one.",True,True
MagicStack_____asyncpg_____348,2018-08-27T17:25:01Z,True,MagicStack_____asyncpg_____348_____416301663,"> It's OK if asyncpg is talking with pgbouncer. pgbouncer will cache the response and postgresql connection will be released.

Not true in every case. pgbouncer is a buffered proxy, and if the response is larger than its buffer (which is [fairly small by default](https://github.com/pgbouncer/pgbouncer/blob/241a58923dce5df6f8618f90a4c66fa86f88b649/etc/pgbouncer.ini#L285)) then it will take multiple network operations to send the response. 

> This PR has no impact on existing workflow. It only adds additional one...

Even so, it's a flawed implementation, and I'm against adding a new connection parameter for every ""workflow"" for reasons I outlined in my previous response.  Please stop arguing your case by repeating the old arguments.  I've heard them and articulated my opinion at length.  Adding the necessary pgbouncer support is possible without these complications.

---

> Looks like statement_cache_size=0 is insufficient. I can change this line to `if use_cache and named` but this change current behaviour.

`named=True` basically means ""I want a named prepared statement regardless of the caching"", and is used by cursors (which don't work with pgbouncer).  I'd rename the argument to `force_named` and then the check becomes `if named_cache or force_named`, where `named_cache` is determined by `statement_cache_size`, and `use_cache` is a separate concern determined by `local_statement_cache_size > 0`.

For simplicity, I would define `local_statement_cache_size` as:

```python
local_statement_cache_size = statement_cache_size if named_supported else 1000
```

so that the current behaviour remains the same.  We can work on improving the cache logic as a followup.",True,True
MagicStack_____asyncpg_____348,2018-08-27T17:44:51Z,True,MagicStack_____asyncpg_____348_____416308520,"> Not true in every case. pgbouncer is a buffered proxy, and if the response is larger than its buffer (which is fairly small by default) then it will take multiple network operations to send the response.

Yes, you are right. I mean ""buffer"" not ""cache"". Buffer size is configurable.

> used by cursors (which don't work with pgbouncer)

They work. In a transaction. Exactly the same way as with vanilla PostgreSQL. I only limit them to be unnamed if connected to pgbouncer to prevent cleanup mess.

`named=True` is used by `Connecton::prepare()` too. I'd prefer `stmt = conn.prepare(...)` and then `stmt.execute()` to work even with pgbouncer inside a transaction and outside.",True,True
MagicStack_____asyncpg_____348,2018-08-27T17:50:56Z,True,MagicStack_____asyncpg_____348_____416310504,"> They work. In a transaction. Exactly the same way as with vanilla PostgreSQL. I only limit them to be unnamed if connected to pgbouncer to prevent cleanup mess.
> named=True is used by Connecton::prepare() too. I'd prefer stmt = conn.prepare(...) and then stmt.execute() to work even with pgbouncer inside a transaction and outside.

You cannot put named prepared statements into cache even inside a transaction, unless you clean them up from the cache once the transaction is closed, and this is way too complicated.",True,True
MagicStack_____asyncpg_____348,2018-08-27T17:55:26Z,True,MagicStack_____asyncpg_____348_____416311894,"> You cannot put named prepared statements into cache even inside a transaction, unless you clean them up from the cache once the transaction is closed, and this is way too complicated.

Right. That's why in case of pgbouncer I put _unnamed_ prepare statements into cache and use following check:
```python
            if state.name == '' and (state != self.last_unnamed
                                     or state.need_reprepare):
                query = state.query
                state.need_reprepare = False
                self.last_unnamed = state
            else:
                query = None
```",True,True
MagicStack_____asyncpg_____348,2018-08-27T18:43:21Z,True,MagicStack_____asyncpg_____348_____416326820,"Well, that's no longer a prepared statement then, is it? If you need that, you can always subclass the PreparedStatement class and do a `Parse` in the subclass.",True,True
MagicStack_____asyncpg_____348,2018-08-27T19:53:33Z,True,MagicStack_____asyncpg_____348_____416347443,"> Well, that's no longer a prepared statement then, is it? If you need that, you can always subclass the PreparedStatement class and do a Parse in the subclass.

That's a prepared statement still. But unnamed and with lifetime until next unnamed statement or end of a transaction.

Subclassing is overcomplicated and anyway this feature requires modifications in coreproto.pyx, protocol.pyx and connection.py.

If you don't like `session` parameter (neither I), then we can add to `statement_cache_size` special value `'pgbouncer'` or something like this to distinguish it from 0.",True,True
MagicStack_____asyncpg_____348,2018-08-27T20:19:06Z,True,MagicStack_____asyncpg_____348_____416354766,"> That's a prepared statement still. But unnamed and with lifetime until next unnamed statement or end of a transaction.

Which makes it essentially useless in a *prepared statement* sense.  The purpose of an explicit prepared statement is to control precisely when it gets prepared and deallocated.  Barring these guarantees it can no longer pretend to be a true prepared statement.

> Subclassing is overcomplicated and anyway this feature requires modifications in coreproto.pyx, protocol.pyx and connection.py.

In this case subclassing is the only way to go.  Changing things around to make it easier is fine, as long as those changes are generic and have no negative impact.

> then we can add to statement_cache_size special value 'pgbouncer' or something like this to distinguish it from 0.

Calling it differently does not remove my objection.  The magical re-`Parse` approach is a non-starter.",True,True
MagicStack_____asyncpg_____348,2018-08-27T20:35:36Z,True,MagicStack_____asyncpg_____348_____416359690,"> Barring these guarantees it can no longer pretend to be a true prepared statement.

True or untrue - it is subjective. From the PostgreSQL docs all of them are true.

> The magical re-Parse approach is a non-starter.

It is not magical. It is logical and predictible. More then that it already existed in the code, just was moved to a more appropriate place.",True,True
MagicStack_____asyncpg_____348,2018-08-27T21:09:35Z,True,MagicStack_____asyncpg_____348_____416369651,"> True or untrue - it is subjective. From the PostgreSQL docs all of them are true.

Sorry, I don't understand your statement.  If I do `PREPARE foo AS query`, I am guaranteed to execute the same query plan on all subsequent `EXECUTE foo` calls, and I'm _also_ guaranteed that the server would not waste time parsing and planning the query. This is exactly the promises of `conn.prepare()`.  Your approach would silently break these promises.  

Example:

```python
ps = await conn.prepare('complicated query...')
for i in range(100):
    param = await conn.fetchval('simple query', i)
    result = await ps.fetch(param)
```

I expect the above to either work as expected, or fail loudly.  What I _don't_ expect is the above doing silent `Parse` calls on every iteration wrecking my performance.  This is what I was referring to as ""magical"".  pgbouncer does not support prepared statements outside of a transaction, so an asyncpg client connecting to it shouldn't either.",True,True
MagicStack_____asyncpg_____348,2018-08-28T12:53:48Z,True,MagicStack_____asyncpg_____348_____416573018,"""In the extended protocol, the frontend first sends a Parse message, which contains a textual query string, optionally some information about data types of parameter placeholders, and the name of a destination prepared-statement object (an empty string selects the unnamed prepared statement).""
There is nothing about true or untrue. Only named and unnamed.

""Named prepared statements can also be created and accessed at the SQL command level, using PREPARE and EXECUTE."" PREPARE SQL command used in PostgreSQL is an additional feature, not compatible with SQL standard. It doesn't support unnamed statements because it is impossible on a high level of the SQL language, but this not imply what unnamed prepared statements - untrue.

> I expect the above to either work as expected, or fail loudly. What I don't expect is the above doing silent Parse calls on every iteration wrecking my performance.

This is how database clients in different languages work. If a server side prepared statements are disabled then a client falls back to a client side. This is common, widely used and familiar behaviour. Users experienced with other database clients are ready to this. This behaviour allows to write code able to work optimally with and without pgbouncer.
Anyway someone who uses pgbouncer in pool_mode=transaction (not default) exactly knows what they is doing and why.",True,True
MagicStack_____asyncpg_____348,2018-08-28T13:31:00Z,True,MagicStack_____asyncpg_____348_____416584680,"> This is how database clients in different languages work. If a server side prepared statements are disabled then a client falls back to a client side. This is common, widely used and familiar behaviour. 

Where did you get that from?

Are you able to show at least one example of a database driver that silently emulates an explicit call to make a server-side prepared statement?  Does libpq `PQprepare` do that? Does JDBC `Connection.prepareStatement`?  Most drivers don't even expose `PREPARE` as a method (mostly because they follow some DB API standard, and `PREPARE` is non-standard).",True,True
MagicStack_____asyncpg_____348,2018-08-28T13:51:42Z,True,MagicStack_____asyncpg_____348_____416591805,"> Does libpq PQprepare do that?

libpq is a low level library. PQprepare is highly tied with PostgreSQL client/server protocol.

> Does JDBC Connection.prepareStatement do that?

Yes, 5 times for each query by default: https://jdbc.postgresql.org/documentation/head/server-prepare.html

> Are you able to show at least one example of a database driver that silently emulates an explicit call to make a server-side prepared statement?

Wikipedia can (https://en.wikipedia.org/wiki/Prepared_statement):
""A number of programming languages support prepared statements in their standard libraries and will emulate them on the client side even if the underlying DBMS does not support them, including Java's JDBC,[11] Perl's DBI,[12] PHP's PDO [1] and Python's DB-API.[13] Client-side emulation can be faster for queries which are executed only once, by reducing the number of round trips to the server, but is usually slower for queries executed many times. It resists SQL injection attacks equally effectively.""",True,True
MagicStack_____asyncpg_____348,2018-08-28T14:00:41Z,True,MagicStack_____asyncpg_____348_____416595001,"> libpq is a low level library. PQprepare is highly tied with PostgreSQL client/server protocol.

This is exactly the point. asyncpg is like libpq.  Please read the README.  

Everything else you listed are interfaces implementing generic DB APIs, which is explicitly not the goal of asyncpg.",True,True
MagicStack_____asyncpg_____348,2018-08-28T14:10:06Z,True,MagicStack_____asyncpg_____348_____416598813,"> asyncpg is like libpq.

It is not like libpq. Hidden introspection queries are the most notable difference.

OK, your code your rules. I can live without `stmt = conn.prepare()`, `stmt.execute()`. But not without ` Parse/Describe/Sync + Parse/Bind/Execute/Sync`. If you still against it (are you?) then this project can not solve my problem.",True,True
MagicStack_____asyncpg_____348,2018-08-28T14:26:27Z,True,MagicStack_____asyncpg_____348_____416605480,"I'm not against supporting pgbouncer cleanly, which can be done.  I'm against your specific approach.  If you are unwilling to compromise, so be it.",True,True
MagicStack_____asyncpg_____348,2018-08-28T14:57:34Z,True,MagicStack_____asyncpg_____348_____416618754,"> I'm not against supporting pgbouncer cleanly, which can be done. I'm against your specific approach. If you are unwilling to compromise, so be it.

You want to support pgbouncer in a fashion what will scale badly with possibility of connections get stuck. Cleanly or not is a second question. At first it just should work.

For anyone who aware of horizontal scaling and who exactly knows why they want to use pgbouncer with pool_mode=transaction fork will live here: https://github.com/my-mail-ru/asyncpg",True,True
lerna_____lerna_____1616,2018-08-28T23:07:06Z,True,lerna_____lerna_____1616_____211583752,"In this PR, the following text has been added to the existing MIT license:

```
The following license shall not be granted to the following entities or any
subsidiary thereof due to their collaboration with US Immigration and Customs
Enforcement (""ICE""):

- ""Microsoft Corporation""
- ""Palantir Technologies""
- ""Amazon.com, Inc.""
- ""Northeastern University""
- ""Ernst & Young""
- ""Thomson Reuters""
- ""Motorola Solutions""
- ""Deloitte Consulting LLP""
- ""Johns Hopkins University""
- ""Dell Inc""
- ""Xerox Corporation""
- ""Canon Inc""
- ""Vermont State Colleges""
- ""Charter Communications""
- ""LinkedIn Corporation""
- ""United Parcel Service Co""
```

I have already spoken to @kittens and @evocateur about this privately, but I do need @kittens to give us permission to make this change.

# Explanation

Over the last year I've been really disturbed to see what ICE has done to American immigrants, to an extreme with what has happened to children.

The other day I saw this video from the ACLU about a toddler who after being separated from his family for several months could no longer look his mother in the face:

[<img width=""1312"" alt=""screen shot 2018-08-28 at 3 53 53 pm"" src=""https://user-images.githubusercontent.com/952783/44755388-cdf86280-aada-11e8-8749-3ec6fd27fdcc.png"">
](https://twitter.com/ACLU/status/1033084026893070338)

<p align=""center""><a href=""https://twitter.com/ACLU/status/1033084026893070338"">twitter.com/ACLU/status/1033084026893070338</a></p>

Those with a background in early childhood development can tell you that severe cases of neglect at an early age can and will cause severe developmental delays and disabilities. They will grow up feeling detached, they will have deep rooted trust issues, and they will have an inability to feel empathy. The actions of ICE have had a lasting lifelong impact on these children, and many of them won't even remember it happening.

I have trouble expressing how angry this makes me feel.

And the worst part is that I feel helpless to improve the situation. I vote, I campaign, I phone bank, I donate, I protest, I write to officials, I try to inform others... and yet things just keep getting worse and worse.

There is one thing I have control over, and that's open source. Open source has always been a way that I try to make the world a better place. Bringing new contributions to the community helps drives innovation and competition.

Lerna is a perfect example of that. Historically monorepos required a lot of infrastructure and only large teams and companies could afford to set it up and maintain it. They had a very expensive cost to them. Lerna made it available to everyone and the community has flourished around it.

Tool after tool, this is what we accomplish with open source. This is what we contribute back to the world. But today I want to do something more.

As we've learned over the last few years with Facebook, Uber, Google, and others. Tech companies do a lot of shady things behind the scenes.

Recently it's come out that a lot of big tech companies are supporting ICE by providing them with infrastructure and in some cases doing significant development work for them. They all have their excuses, but the fact is that these companies care only about the millions of dollars that ICE is paying them and are willing to ignore all the horrible things that ICE does.

Recently it has come to my attention that many of these companies which are being paid millions of dollars by ICE are also using some of the open source software that I helped build.

Now, it's not news to me that people can use open source for evil. That's part of the whole deal.

But it's really hard for me to sit back and ignore what these companies are doing with my code. It doesn't feel like there are enough steps in between me and the horrible things ICE is doing.

So my plan now is to start licensing my software differently.

I have spoken to Sebastian and Daniel about this and we all want Lerna to do the same.

For the companies that are known supporters of ICE: Lerna will no longer be licensed as MIT for you. You will receive no licensing rights and any use of Lerna will be considered theft. You will not be able to pay for a license, the only way that it is going to change is by you publicly tearing your contracts with ICE.
",True,True
lerna_____lerna_____1616,2018-08-29T02:04:08Z,True,lerna_____lerna_____1616_____416798591,"Lerna team, thank you for taking a stand 👏🏼👏🏼👏🏼",True,True
lerna_____lerna_____1616,2018-08-29T03:04:04Z,True,lerna_____lerna_____1616_____416808477,"Please make sure that you amend your page on npmjs.org so that it does not state that the license of the project is ""MIT"".",True,True
lerna_____lerna_____1616,2018-08-29T03:09:47Z,True,lerna_____lerna_____1616_____416809307,"Curious: Do ""parents"" who drag their children across the desert with the express intent of illegally entering the United States have no share of blame for what happens to these children?",True,True
lerna_____lerna_____1616,2018-08-29T03:24:41Z,True,lerna_____lerna_____1616_____416811556,"Are you protesting the right of the United States to choose who to allow to immigrate by deporting illegal aliens, or are you protesting the specific treatment of these illegal aliens in the context of their removal? If it's the former, then there's no point in bringing up their specific treatment as a point for why ICE should be protested (because it would be the case regardless of the treatment of any particular alien), and if it's the latter, then why not specify that, and protest by listing what exactly you would like changed about the treatment of aliens during their deportation? That would make what exactly you are protesting much clearer.",True,True
lerna_____lerna_____1616,2018-08-29T03:40:14Z,True,lerna_____lerna_____1616_____416813739,"I'm adding it to all my repos to prevent the lerna project from being used in any of those projects, both open source and commercial. Just as a matter of principal. Adding your political beliefs to your licensing is petty. The irony is that this very project is hosted on a resource owned by Microsoft...",True,True
lerna_____lerna_____1616,2018-08-29T03:44:57Z,True,lerna_____lerna_____1616_____416814422,"While I too abhor ICE, this isn't actually a valid license change. In order to re-license a project without a CLA, the consent of all contributors needs to be sought. There are a variety of scripts out there that accomplish this, the one I am most familiar with is the [Rust Relicense assistant](https://github.com/cmr/relicense-assistant). I'd suggest using similar tooling to avoid potential legal issues.",True,True
lerna_____lerna_____1616,2018-08-29T03:48:33Z,True,lerna_____lerna_____1616_____416814961,"Yep, noted that is is no longer Open Source Software, by definition of https://opensource.org/osd .

The way this tirefire of a license can be interpreted, is that since a company uses Windows and pays Microsoft, they are complicit. Or Github for that matter, which is owned by Microsoft. Are the Lerna repo maintainers profiting on ICE, in direct opposition to their license? Github free accounts didn't come from nothingness.",True,True
lerna_____lerna_____1616,2018-08-29T03:56:32Z,True,lerna_____lerna_____1616_____416816092,"@jwcrawley: So what? Maximal open source permissiveness is not automatically correct and just. It's just one option.

And no, the terms are pretty clear, I suggest you read more carefully: ""The following license shall not be granted to the following entities or any subsidiary thereof."" It says nothing about people giving money to e.g. Microsoft or using Microsoft products.",True,True
lerna_____lerna_____1616,2018-08-29T04:21:19Z,True,lerna_____lerna_____1616_____416819388,"I'm not sure how disallowing corporations that deal with ICE from using lerna would affect ICE's behavior - which I assume is the intent behind this PR.

Shoving politics into code will not help anyone.
",True,True
lerna_____lerna_____1616,2018-08-29T04:28:52Z,True,lerna_____lerna_____1616_____416820399,"Locking this issue.

If you disagree with the license then you're welcome to use one of the alternatives or write your own.

If you're employed by a subsidiary listed, direct any questions about the usage of Lerna to your company lawyer. This license only applies to future versions, you're free to use old versions that do not contain this clause.

If you have concerns over the legality of relicensing. The MIT license allows sublicensing, which this falls under. Even still, all contributors implicitly agreed to the existing license, of which I am the original license holder, when they submitted code meaning we are within our rights to relicense.

If you're a contributor with active code in Lerna, and disagree with the relicense, feel free to privately message @jamiebuilds, @evocateur, or myself and we'll ensure that your contributions are either removed or rewritten to remove attribution.

Thanks everyone for your comments thus far.",True,True
callstack_____react-native-paper_____485,2018-08-29T15:44:28Z,True,callstack_____react-native-paper_____485_____213732135,"Frankly, I don't see much value in having `Surface` as a separate component. It's used in just one place, and only adds some styles. Can you tell me what use this component has outside of how it's used in your PR?",True,True
callstack_____react-native-paper_____485,2018-08-29T15:45:11Z,True,callstack_____react-native-paper_____485_____213732443,Nit: add 'elevated' before 'surfaces'. Also elaborate on the placement -- I believe it only adapts based on the source element's position + actual size of the menu. ,True,True
callstack_____react-native-paper_____485,2018-08-29T15:48:24Z,True,callstack_____react-native-paper_____485_____213733724,"Since the only rule that `styles.surface` has is `backgroundColor`, it will be overridden by the next line. Please remove it. ",True,True
callstack_____react-native-paper_____485,2018-08-29T16:27:04Z,True,callstack_____react-native-paper_____485_____213747273,"Nit: This doesn't really ""toggle"" anything, it just updates the shown/hidden state, so I suggest renaming it to ""_updateVisibility""",True,True
callstack_____react-native-paper_____485,2018-08-30T07:47:24Z,True,callstack_____react-native-paper_____485_____213932998,"You use this constant only once, and really far away from this declaration. It's a bit confusing why you need this until line 282, especially since you keep using `menuSizeAnimation.x` and `menuSizeAnimation.y`. Please avoid defining it and instead inline it's use below.",True,True
callstack_____react-native-paper_____485,2018-08-30T07:49:09Z,True,callstack_____react-native-paper_____485_____213933471,"Nit: destructure `dimensions` into `{ width: screenWidth, height: screenHeight }`, it will be slightly easier to read later on. ",True,True
callstack_____react-native-paper_____485,2018-08-30T07:50:52Z,True,callstack_____react-native-paper_____485_____213933879,"You use this constant only once, please inline it where it's used.",True,True
callstack_____react-native-paper_____485,2018-08-30T08:07:57Z,True,callstack_____react-native-paper_____485_____213938442,"Nit: I believe this component just shows a single option inside a Menu, no?",True,True
callstack_____react-native-paper_____485,2018-08-30T08:08:47Z,True,callstack_____react-native-paper_____485_____213938646,Nit: write 'item' instead of \`MenuItem\`.,True,True
callstack_____react-native-paper_____485,2018-08-30T08:09:39Z,True,callstack_____react-native-paper_____485_____213938869,"Can you explain where does ""8 * 6 + 40"" come from? Possibly define a `marginWidth` const so that it's clear where does '8' come from.",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T08:15:21Z,True,YilianSource_____brackeys-bot_____51_____417231241,NEVER UPDATE TO A BETA VERSION WHEN IT'S USED FOR A PUBLISHED SYSTEM,True,True
callstack_____react-native-paper_____485,2018-08-30T08:34:55Z,True,callstack_____react-native-paper_____485_____213946356,"Please define `const disabledColor` instead, and use it with the `?:` operator to define const `titleColor` and `iconColor`.",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T09:19:04Z,True,YilianSource_____brackeys-bot_____51_____417250612,"Well, if something breaks we could always just revert. Anyhow, it was necessary because of a bug that screwed up the template enforcement that was patched in a beta.

> On 30 Aug 2018, at 10:15, Job Rapati <notifications@github.com> wrote:
> 
> NEVER UPDATE TO A BETA VERSION WHEN IT'S USED FOR A PUBLISHED SYSTEM
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T09:23:22Z,True,YilianSource_____brackeys-bot_____51_____417252017,"Not a good reason to upgrade to a beta, it's real simple.
Does it have a bug fix we need? Yes
Is it ready for production projects? No
Should we use it then? NO 

There's a reason it's a beta",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T11:01:53Z,True,YilianSource_____brackeys-bot_____51_____417279650,"Just because it's a beta doesn't mean it's unstable.
As I said, we could revert.
The whole point of nightlies and betas is to download them if something's bugging you... Do you really expect Discord.NET from **September 2017** to work flawlessly with Discord right now? I don't think so.

If a bot is designed to do a task, (job template enforcement is one of the main ones), and it can't do it, it's useless.",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T11:06:13Z,True,YilianSource_____brackeys-bot_____51_____417280783,"Alright so you need to get out of that mindset cause you will never find a job with people that will allow beta's to run in production.

Does beta mean it's unstable? No
Is it worth the risk in a production environment? No
A production environment should be reliable and sadly beta's are not. You can't rely on the stability of a bit cause then it wouldn't be a beta.",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T11:29:48Z,True,YilianSource_____brackeys-bot_____51_____417286580,"Yeah. I understand and I see where you're coming from, but just... please. Trust me on this one. This one time. If something breaks, you can put all the blame on me and I will revert the project to a stable version from September 2017.",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T11:31:13Z,True,YilianSource_____brackeys-bot_____51_____417286923,"I'm not expecting anything to break. I'm not going to put the blame on you cause I could have simply not pulled the latest version of the bot.

I'm simply trying to make you understand you should never have beta versions on a production environment",True,True
YilianSource_____brackeys-bot_____51,2018-08-30T11:32:55Z,True,YilianSource_____brackeys-bot_____51_____417287349,Yes. I understand.,True,True
YilianSource_____brackeys-bot_____51,2018-08-30T11:36:35Z,True,YilianSource_____brackeys-bot_____51_____417288218,"I agree with @Duxez but this isn't a really big problem if we run a beta in production. This is a pretty small bot.

We'll leave it be until further discussion. I don't think it's a big problem if it only affects the job channels. Closing for now. If you want to continue the discussion open another issue instead of having a conversation in a merged PR.",True,True
xbmc_____repo-plugins_____2021,2018-08-31T02:08:18Z,True,xbmc_____repo-plugins_____2021_____212256396,"### Description
Stream full unlocked episodes from cartoonnetwork.com
<!--- Provide a short summary of submitted add-on in case it's a new addition. -->
<!--- If it's plugin update only highlight biggest changes if needed. -->
<!--- Make sure you follow the checklist below before finalizing your pull-request. -->
### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply like this: [X] -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the [add-on rules](http://kodi.wiki/view/Add-on_rules) and [piracy stance](http://kodi.wiki/view/Official:Forum_rules#Piracy_Policy) of this project. 
- [x] I have read the [CONTRIBUTING](https://github.com/xbmc/repo-plugins/blob/master/CONTRIBUTING.md) document
- [x] Each add-on submission should be a single commit with using the following style: [plugin.video.foo] v1.0.0

Additional information :
- Submitting your add-on to this specific branch makes it available to any Kodi version equal or higher than the branch name with the applicable Kodi dependencies limits.
- [add-on development](http://kodi.wiki/view/Add-on_development) wiki page.
- Kodi [pydocs](http://kodi.wiki/view/PyDocs) provide information about the Python API
- [PEP8](https://www.python.org/dev/peps/pep-0008/) codingstyle which is considered best practice but not mandatory.
- This add-on repository has automated code guideline check which could help you improve your coding. You can find the results of these check at [Codacy](https://www.codacy.com/app/Kodi/repo-plugins/dashboard). You can create your own account as well to continuously monitor your python coding before submitting to repo.
- Development questions can be asked in the [add-on development](http://forum.kodi.tv/forumdisplay.php?fid=26) section on the Kodi forum.
",True,True
xbmc_____repo-plugins_____2021,2018-08-31T02:10:04Z,True,xbmc_____repo-plugins_____2021_____417527624,"## Travis tests have failed
Hey @jsergio123, 
please read the following log in order to understand the failure reason. There might also be some helpful tips along the way. 
It'll be awesome if you fix what's wrong and commit the changes.

### 1st Build
<details>
  <summary>
    <strong>
     Expand here
    </strong>
  </summary>

```
INFO: Checking add-on plugin.video.cartoon_network
INFO: Created by jsergio
INFO: Addon id matches folder name
INFO: Valid XML file found
INFO: This is a new addon
INFO: Image icon exists
ERROR: Icon.png should be solid. It has transparency.
INFO: Icon dimensions are fine 512x512
INFO: Image fanart exists
INFO: Fanart dimensions are fine 1920x1080
ERROR: We found 1 problems and 0 warnings, please check the logfile.
```
</details>
<br />
",True,True
xbmc_____repo-plugins_____2022,2018-08-31T02:14:43Z,True,xbmc_____repo-plugins_____2022_____212257073,"### Description
Stream full unlocked episodes from adultswim.com
Features include full metadata using the existing metahandler and multiple bitrate support
<!--- Provide a short summary of submitted add-on in case it's a new addition. -->
<!--- If it's plugin update only highlight biggest changes if needed. -->
<!--- Make sure you follow the checklist below before finalizing your pull-request. -->
### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply like this: [X] -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the [add-on rules](http://kodi.wiki/view/Add-on_rules) and [piracy stance](http://kodi.wiki/view/Official:Forum_rules#Piracy_Policy) of this project. 
- [x] I have read the [CONTRIBUTING](https://github.com/xbmc/repo-plugins/blob/master/CONTRIBUTING.md) document
- [x] Each add-on submission should be a single commit with using the following style: [plugin.video.foo] v1.0.0

Additional information :
- Submitting your add-on to this specific branch makes it available to any Kodi version equal or higher than the branch name with the applicable Kodi dependencies limits.
- [add-on development](http://kodi.wiki/view/Add-on_development) wiki page.
- Kodi [pydocs](http://kodi.wiki/view/PyDocs) provide information about the Python API
- [PEP8](https://www.python.org/dev/peps/pep-0008/) codingstyle which is considered best practice but not mandatory.
- This add-on repository has automated code guideline check which could help you improve your coding. You can find the results of these check at [Codacy](https://www.codacy.com/app/Kodi/repo-plugins/dashboard). You can create your own account as well to continuously monitor your python coding before submitting to repo.
- Development questions can be asked in the [add-on development](http://forum.kodi.tv/forumdisplay.php?fid=26) section on the Kodi forum.
",True,True
xbmc_____repo-plugins_____2022,2018-08-31T02:16:34Z,True,xbmc_____repo-plugins_____2022_____417528779,"## Travis tests have failed
Hey @jsergio123, 
please read the following log in order to understand the failure reason. There might also be some helpful tips along the way. 
It'll be awesome if you fix what's wrong and commit the changes.

### 1st Build
<details>
  <summary>
    <strong>
     Expand here
    </strong>
  </summary>

```
INFO: Checking add-on plugin.video.adultswim
INFO: Created by jsergio
INFO: Addon id matches folder name
INFO: Valid XML file found
Traceback (most recent call last):
  File ""/home/travis/virtualenv/python3.6.3/bin/kodi-addon-checker"", line 11, in <module>
    sys.exit(main())
  File ""/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/kodi_addon_checker/__main__.py"", line 81, in main
    report.add(check_artifact(directory, args, args.branch, all_repo_addons, args.PR))
  File ""/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/kodi_addon_checker/__main__.py"", line 47, in check_artifact
    return check_addon.start(artifact_path, branch_name, all_repo_addons, pr, config)
  File ""/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/kodi_addon_checker/check_addon.py"", line 50, in start
    check_old_addon.check_for_existing_addon(addon_report, addon_path, all_repo_addons, pr)
  File ""/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/kodi_addon_checker/check_old_addon.py"", line 23, in check_for_existing_addon
    if addon_name in repo_addons:
TypeError: argument of type 'NoneType' is not iterable
```
</details>
<br />
",True,True
xbmc_____repo-plugins_____2021,2018-08-31T02:19:11Z,True,xbmc_____repo-plugins_____2021_____417529268,"## Travis tests were successfully
Hey @jsergio123, 
we found no major flaws with your code. Still you might want to look at this logfile, as we usually suggest some optional improvements.

",True,True
xbmc_____repo-plugins_____2022,2018-08-31T02:21:23Z,True,xbmc_____repo-plugins_____2022_____417529677,"Not sure why you chose to close the original PR, but the conversation for it is here:
https://github.com/xbmc/repo-plugins/pull/2006
Any reviewers may want to have a look.",True,True
xbmc_____repo-plugins_____2022,2018-08-31T02:31:41Z,True,xbmc_____repo-plugins_____2022_____417531385,"@learningit I had no choice. My xbmc/repo-plugins fork was effed up and I couldn't create or push branches correctly using the windows client. At the moment my linux box is down.

Not sure if you noticed but I was noobing it up for over an hour until I just got fed up and decided to nuke the whole repository and start fresh.

It seems i may have brought to light a bug in the Travis scripts too. ",True,True
xbmc_____repo-plugins_____2022,2018-08-31T04:59:19Z,True,xbmc_____repo-plugins_____2022_____417551999,"## Travis tests were successfully
Hey @jsergio123, 
we found no major flaws with your code. Still you might want to look at this logfile, as we usually suggest some optional improvements.

",True,True
xbmc_____repo-plugins_____2021,2018-08-31T12:44:39Z,True,xbmc_____repo-plugins_____2021_____417652407,US residents only.,True,True
xbmc_____repo-plugins_____2021,2018-08-31T16:40:17Z,True,xbmc_____repo-plugins_____2021_____417722075,Lol now don't go pushing your own version tomorrow lol. Why not just ban me from your git? ,True,True
dirigeants_____klasa_____422,2018-09-16T09:32:39Z,True,dirigeants_____klasa_____422_____215813463,"### Description of the PR

This PR is ~~phase one of two of my proposal~~ that will change the way we write our usage strings forever, making the experience easier (in my opinion) and with less bugs too.

This PR completely nukes the concept of `usageDelim`, and instead integrates it into the `usage` string itself.

Take the following usage: `<member:member> [reason:string]`; Before this PR, you'd need to specify usageDelim as "" "", and add `[...]` at the end of reason to get it all. Not anymore.

The usage delimiter is now anything between a closed tag and a newly opened one. Yes, that means you can do `<member:member> in <time:duration>``, and you would have to type `@member in 2 days`.

*More in-depth stuff will be found in the guides I'm lazy to write :P*

### Changes Proposed in this Pull Request (List new items in CHANGELOG.MD)

- **[BREAKING]** Remove `Command#usageDelim`, `Usage#usageDelim` and `Usage#delimitedUsage`

- Others things to be added

### Semver Classification

- [ ] This PR only includes documentation or non-code changes.
- [ ] This PR fixes a bug and does not change the (intended) framework interface.
- [x] This PR adds methods or properties to the framework interface.
- [x] This PR removes or renames methods or properties in the framework interface.
",True,True
dirigeants_____klasa_____422,2018-09-17T07:26:14Z,True,dirigeants_____klasa_____422_____421913419,"I've been using usage strings and delims since Komada so I'd like to voice my opinion on the refusal of this PR.

Usage delims are good but have a lot of downsides to them -
1) They are hard for a beginner to understand. It took me quite a while to understand what UsageDelims are and how they work.
2) They are unnecessary half the time. **Every single** core command in klasa uses spaces as usage-delims. And the usage strings have spaces in them. 
3) In the current system it is impossible to have multiple usage delims, which is very powerful for complex commands. It also reduces duplication from the [...] keyword.

TLDR: Not only is this new system is both user-friendly and easy to understand for noobs, but also much more powerful, reducing code duplication and adding a lot of necessary features.

I don't see why this would be called ""unnecessary"", but I want to know the logic behind that.",True,True
rust-lang_____rfcs_____2544,2018-09-17T14:35:42Z,True,rust-lang_____rfcs_____2544_____216004359,"Make disambiguating generic arguments in expressions with `::` optional, allowing generic arguments to be specified without `::`. This makes the ""turbofish"" notation no longer necessary.

[Rendered](https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md)

This makes the following valid syntax:
```rust
struct Nooper<T>(T);

impl<T> Nooper<T> {
    fn noop<U>(&self, _: U) {}
}

fn id<T>(t: T) -> T {
    t
}

fn main() {
    id<u32>(0u32); // ok
    let n = Nooper<&str>("":)""); // ok
    n.noop<()>(()); // ok
}
```

The syntax ambiguities `(a<b,c>(d))` and `a<b>>c` are resolved in favour of generic expressions.

---

This is an updated and more considered version of the RFC put forward a little while ago.
Thanks to @Centril, @comex, @joshtriplett, @kennytm, @petrochenkov, @rpjohnst, @scottmcm, @ubsan and @xfix for their feedback (and everyone else who chipped in)!

cc @aturon, @eddyb, @withoutboats",True,True
dirigeants_____klasa_____422,2018-09-17T15:37:50Z,True,dirigeants_____klasa_____422_____422065666,"This has been executively denied for countless reasons posted in several places, including you can do many of the end goal ideas already, without additional opinionated code (that inevitably breaks other functionality, and ironically the ability to do some of these end goal ideas).",True,True
rust-lang_____rfcs_____2544,2018-09-17T16:18:28Z,True,rust-lang_____rfcs_____2544_____422078938,"However unusual a corner case, I feel very uncomfortable with making breaking parser changes for existing code.

On the other hand this change is a perfect candidate for edition switches since it can be entirely crate-local. I’d much prefer it only applied in Rust 2018 or, if it’s too late, in the following edition. The turbofish has been with us [since 2011](https://github.com/rust-lang/rust/commit/014c6922e12d4faa6a2181674d12a7f487c06bb6), before Rust 0.1. We can live with it a few more years.",True,True
rust-lang_____rfcs_____2544,2018-09-17T16:24:30Z,True,rust-lang_____rfcs_____2544_____422080887,"> However unusual a corner case, I feel very uncomfortable with making breaking parser changes for existing code.

There's precedent for doing this with https://github.com/rust-lang/rust/pull/53854.

> I’d much prefer it only applied in Rust 2018 [...]

Nominating for the next meeting to discuss this possibility.",True,True
rust-lang_____rfcs_____2544,2018-09-17T16:36:47Z,True,rust-lang_____rfcs_____2544_____422084748,"I have not tried reading that diff, but the title of that PR says “edition changes”. So… is that an agreement with my comment?",True,True
rust-lang_____rfcs_____2544,2018-09-17T16:37:56Z,True,rust-lang_____rfcs_____2544_____422085152,@SimonSapin no; the precedent was for applying the grammar changes in Rust 2015.,True,True
rust-lang_____rfcs_____2544,2018-09-17T16:43:19Z,True,rust-lang_____rfcs_____2544_____422087071,I was not involved in that discussion but my opinion is the same. I think this is a bad precedent.,True,True
rust-lang_____rfcs_____2544,2018-09-17T20:55:16Z,True,rust-lang_____rfcs_____2544_____218224263,"This is not a language argument, but you are underestimating the work required to do this correctly.
On encountering `<` parser needs to enter some kind of new speculative mode suppressing all side effects, including non-fatal diagnostics.
We can ignore these details if the rollback is done only as a part of best-effort error recovery, but not if it's a part of the language, so the feature has some global effect on parser implementation rather than just calling `self.clone()` in one place.",True,True
rust-lang_____rfcs_____2544,2018-09-17T21:18:48Z,True,rust-lang_____rfcs_____2544_____218231342,"Additionally, parser can accept pretty strange things and then report ""semantic"" errors later, but we won't be aware of these errors when disambiguating with backtracking.
This problem already exists in the formulation ""what exactly is accepted under `cfg(false)`?"", but in that case it's probably easier to fix e.g. by doing AST validation during expansion.",True,True
rust-lang_____rfcs_____2544,2018-09-17T21:28:28Z,True,rust-lang_____rfcs_____2544_____422177966,"> However unusual a corner case, I feel very uncomfortable with making breaking parser changes for existing code.

I thought it might be helpful to weigh in with my experience at TC39, which spends a lot of effort on retaining compatibility but nevertheless does sometimes make technically breaking changes. It's true that the bar is high for breaking changes, which is why it's good to get empirical evidence about real-world breakage. But at the end of the day, we've found with JavaScript that -- if we are cautious and use good judgment -- there is some budget for _de jure_ incompatible changes that are _de facto_ compatible. To me, the fact that even something as high-usage and conservative about backwards compatibility as JavaScript is able to make changes like this suggests that Rust can as well.

My feeling is that if the language and ecosystem are better off for it, and it doesn't cause churn in practice, Rust should be willing to make formally breaking changes like this. (And given my personal experience both with teaching Rust to newcomers at work and designing APIs to try to avoid turbofish, I personally hope we do!)",True,True
rust-lang_____rfcs_____2544,2018-09-17T21:35:47Z,True,rust-lang_____rfcs_____2544_____422179860,"> And given my personal experience both with teaching Rust to newcomers at work and designing APIs to try to avoid turbofish, I personally hope we do!

I would be interested in hearing (possibly off thread to avoid spamming) about what you've found the largest problems for newcomers when it comes to turbofish. I can think of a few:

- discoverability
- ""weird"" syntax
- understanding of the semantics

Also, I am interested in hearing what the main reason(s) for avoiding the need of turbofish in your API surfaces are that would be rendered moot by changing the syntax.

I am personally of the inclination that `rustc` should actually accept a superset of valid Rust code for more specific diagnostic errors, which would make merging @varkor's change almost as-is to inform the suggestions emitted something I would enthusiastically push for as it would help with the three items listed above, while changing the parsing semantics away from a regular syntax by accepting now-incorrect code a bit worry-some as it would put a higher burden on third-party implementers. (I understand the low likelihood of anyone actually trying to make an independent Rust compiler that matches nightly or even current stable `rustc`, but still.)",True,True
rust-lang_____rfcs_____2544,2018-09-17T21:38:28Z,True,rust-lang_____rfcs_____2544_____422180550,"@dherman Fair points, but I think that the equation is significantly affected by Rust having this edition mechanism that JavaScript doesn’t.

We’re doing opt-in switches already, let’s use them for what they’re for.",True,True
rust-lang_____rfcs_____2544,2018-09-17T22:05:39Z,True,rust-lang_____rfcs_____2544_____218243076,"I noticed this was necessary with https://github.com/rust-lang/rust/pull/53578/commits/307ea60b893e62ed4bd88da7b7035bc29be73ffd, though I imagined this wasn't sufficient for a final implementation. The language in the RFC wasn't intended to insinuate how difficult the task would be: the proof of concept is definitely only that!",True,True
rust-lang_____rfcs_____2544,2018-09-17T22:25:32Z,True,rust-lang_____rfcs_____2544_____422191951,"On the question of teaching, we also ought to consider the affect of type ascription. If we had type ascription but not this, we could teach and use the language entirely without turbofish, without worrying about compatibility or edition switches or weird syntax or backtracking.",True,True
rust-lang_____rfcs_____2544,2018-09-17T22:34:10Z,True,rust-lang_____rfcs_____2544_____422193876,"@estebank I would say discoverability, guessability, and -- maybe the biggest issue to me -- every one-more-thing you have to explain risks being the one thing that blows a newcomer's cognitive budget. Don't get me wrong, overall I've been pleasantly surprised at how quickly my colleagues have gone from zero to productive users of Rust. But there are still so many little surprises in the onboarding experience, that it's easy for a learner to just blow their stack and give up. (I think I'm just basically giving an exegesis for why I'm so excited about all the effort Rust is putting into ergonomics, at least the learning side of it.)

@SimonSapin My only point about JavaScript was that it shows us that it does in fact work in practice, at scale, to make _de facto_ compatible changes. JavaScript of course does not tell us what we _should_ do. From my perspective, doing it with language editions means we wait several years longer to solve a pain point simply because we have a mechanism that lets us do so, but that's obviously biased by my experiences I mentioned. Can you help me understand the rationale for why you wouldn't want to make the change now? Are you concerned about de facto risks that we haven't actually uncovered in our empirical investigations? Or is it an aesthetic about clarity of policy?",True,True
rust-lang_____rfcs_____2544,2018-09-18T01:43:54Z,True,rust-lang_____rfcs_____2544_____422225569,"> If we had type ascription but not this, we could teach and use the language entirely without turbofish

I think this overlooks the effect of const generics as well as the instances where specifying generic arguments is more ergonomic than using type ascription (both mentioned in the RFC). Type ascription *helps*, but I don't think it solves the problem.",True,True
rust-lang_____rfcs_____2544,2018-09-18T02:26:10Z,True,rust-lang_____rfcs_____2544_____422232454,"There are two issues with turbofish:

Discoverability. This can be solved very well by best-effort error-reporting and recovery as @estebank already mentioned in https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422179860.

Noisiness. Turbofish is objectively rare due to type inference mostly working automatically, even rarer with type ascription. I agree that avoiding `::` would be nice, but this minor nicety is not even close for being sufficient motivation for changing fundamental properties of the grammar.
Why do you think it was introduced in the first place and wasn't removed since then?
What fundamental changes happened recently so that the original decision to keep the grammar simple needs to be revised?",True,True
rust-lang_____rfcs_____2544,2018-09-18T03:30:19Z,True,rust-lang_____rfcs_____2544_____422242606,"Turbofish comes up regularly in specific cases, such as `collect` and `parse`.

And part of the problem is the lack of parallel to generic syntax elsewhere.

I'd love to see this change, if viable.",True,True
rust-lang_____rfcs_____2544,2018-09-18T03:35:13Z,True,rust-lang_____rfcs_____2544_____422243429,"I've never really been bothered by turbofish itself. Rather, it annoys me that i need to edit the middle of an expression. I think the recent type ascription RFC assuages my annoyance.",True,True
rust-lang_____rfcs_____2544,2018-09-18T03:40:24Z,True,rust-lang_____rfcs_____2544_____422244320,"To me, being able to write `foo<u8>` instead of `foo::<u8>` is fundamentally about language uniformity.
It is *inconsistent* that you have to write `foo::<u8>` when you don't have to write `Vec::<u8>`.
Inconsistencies make languages more complex by forcing people to learn more things instead of being able to apply a rule they learned in one place everywhere. We should to the extent possible (and where there are expected semantics) *try* to remove inconsistencies from the language and have a holistic view of language design that does not just take a look at the feature itself but the language as a whole.",True,True
rust-lang_____rfcs_____2544,2018-09-18T03:49:01Z,True,rust-lang_____rfcs_____2544_____422245714,"Yes, but in this case we are making one part consistent at the expense of adding a (very weird) special case to the parser, which doesn't seem much better.",True,True
rust-lang_____rfcs_____2544,2018-09-18T03:52:53Z,True,rust-lang_____rfcs_____2544_____422246423,"@mark-i-m well yeah; we are trading more consistency in one place for less consistency in another.
However, crater did find zero regressions, which entails that in practice, one inconsistency is a practical problem (turbofish) and one is not (the thing we have to break). From a user's perspective this seems like a net win in terms of consistency.

However, we do have to consider the main drawback that Rust is not LL(k) anymore due to backtracking.",True,True
rust-lang_____rfcs_____2544,2018-09-18T03:58:13Z,True,rust-lang_____rfcs_____2544_____422247331,"> However, we do have to consider the main drawback that Rust is not LL(k) anymore due to backtracking.

This to me is the more painful issue. True, it's not directly user facing, but it means that IDE support and compiler maintainability become harder. That's seems like more painful baggage IMHO.",True,True
rust-lang_____rfcs_____2544,2018-09-18T04:21:25Z,True,rust-lang_____rfcs_____2544_____422250552,"@mark-i-m IMO LL and LR have overstayed their welcome by at least a decade, and if your parser is hand-written recursive descent, it's easy to add features that make it not LL (or worse, not CFG).
Also, full CFG parsing with recorded ambiguities allows richer/more sophisticated error reporting/recovery, and e.g. GLL can be more efficient at this than backtracking.

We (@lykenware) are building a GLL parser generator framework, with `rustc` and relating tooling in mind - which would be using a single official Rust context-free grammar¹, annotated in such a way to allow generating APIs for parse trees/ASTs across multiple languages.
Additionally, we believe that this will enable incremental parsing (ideal for IDEs) with a one-time implementation cost (once the framework supports it, all grammars do).

**EDIT**: to be clear, I'm not advocating we should add this feature *now*, IMO we should future-proof the Rust 2018 edition with all the ideas we *might want* to implement in the future.
I'd personally be fine with blocking actually allowing `foo<T>` on a transition to something like GLL.

<hr/>

¹ *a Rust CFG is an approximation of the real grammar, as (at least) raw strings are  [(mildly) context-sensitive](https://en.wikipedia.org/wiki/Mildly_context-sensitive_grammar_formalism)*",True,True
rust-lang_____rfcs_____2544,2018-09-18T11:35:09Z,True,rust-lang_____rfcs_____2544_____422358610,"> Yes, but in this case we are making one part consistent at the expense of adding a (very weird) special case to the parser, which doesn't seem much better.

Arguably, the original addition of `::` was adding a weird special case to the parser. I don't think removing it is ""adding a special case"" any more than most other syntax changes.

> True, it's not directly user facing, but it means that IDE support and compiler maintainability become harder.

I don't think this is true. The grammar of a language is only indirectly related to the complexity of the parser implementing it. Adding support for this is trivial in most common parsers as far as I can tell: the concern about more expressive grammars is their theoretical efficiency, not how difficult they are to implement in practice (which has already been demonstrated not to be an issue).",True,True
rust-lang_____rfcs_____2544,2018-09-18T11:48:27Z,True,rust-lang_____rfcs_____2544_____422361782,"> If we had type ascription but not this, we could teach and use the language entirely without turbofish

Not always. See for example `std::mem::size_of::<T>()`, `Any::is::<T>()`, etc.",True,True
rust-lang_____rfcs_____2544,2018-09-18T12:19:17Z,True,rust-lang_____rfcs_____2544_____422369583,"@SimonSapin One would argue in such cases we should be writing types in the argument list, instead of in a separate list, e.g. `size_of(T)` and `.is(T)`.
Sadly, that shit has *somewhat* sailed, but it is how I'd like some calls to be.",True,True
rust-lang_____rfcs_____2544,2018-09-18T15:25:04Z,True,rust-lang_____rfcs_____2544_____422438772,"> However, crater did find zero regressions, which entails that in practice, one inconsistency is a practical problem (turbofish) and one is not (the thing we have to break). From a user's perspective this seems like a net win in terms of consistency.

@Centril It just occurred to me that a crater run only gives us half the view into the effects of this grammar change. The other half would be to automatically change every public facing codebase from `::<>` to `<>` and rerun the test. We have validated that we _could_ make the change with little disruption to existing public codebases, we haven't validated that everyone could actually _use_ the new grammar.",True,True
rust-lang_____rfcs_____2544,2018-09-18T15:33:59Z,True,rust-lang_____rfcs_____2544_____422442155,"@eddyb 

> Sadly, that ship has somewhat sailed, but it is how I'd like some calls to be.

Oh yes please; Let it not be too late =P

@estebank good point; we should try that if possible :)",True,True
rust-lang_____rfcs_____2544,2018-09-18T15:39:18Z,True,rust-lang_____rfcs_____2544_____422444150,"> It just occurred to me that a crater run only gives us half the view into the effects of this grammar change. The other half would be to automatically change every public facing codebase from ::<> to <> and rerun the test.

The code paths [are almost identical](https://github.com/rust-lang/rust/pull/53578/files#diff-da9d34ca1d0f6beee2838cf02e07345c) for `::<>` and `<>` in the Crater PR. If syntax parses with `::<>`, it should also do so with `<>`.",True,True
rust-lang_____rfcs_____2544,2018-09-18T17:33:03Z,True,rust-lang_____rfcs_____2544_____422481158,"One can emulate passing the type by passing a PhantomData parameter.

Here is how one can emulate passing a type as a parameter if it cannot be inferred:

```

use std::marker::PhantomData;
use std::mem;

trait TypeConstant{
    const TYPE:PhantomData<Self>=PhantomData;
}

impl<This:?Sized> TypeConstant for This{}


fn size_of<T>(_:PhantomData<T>)->usize{
    mem::size_of::<T>()
}


fn main(){
    println!(""size of usize is {}"",size_of( usize::TYPE ))
}

```

This does not change whether the turbofish is necessary for generic types like eg:Vec<T>,
because to get its size one needs to type `size_of(Vec::<()>::TYPE)`.",True,True
rust-lang_____rfcs_____2544,2018-09-18T18:08:21Z,True,rust-lang_____rfcs_____2544_____422492640,">> If we had type ascription but not this, we could teach and use the language entirely without turbofish
>
> Not always. See for example `std::mem::size_of::<T>()`, `Any::is::<T>()`, etc.

I'm missing something. Wouldn't this RFC allow writing `std::mem::size_of::<T>()` as `std::mem::size_of<T>()`?",True,True
rust-lang_____rfcs_____2544,2018-09-18T18:20:33Z,True,rust-lang_____rfcs_____2544_____422496524,"> > > If we had type ascription but not this, we could teach and use the language entirely without turbofish
> > 
> > 
> > Not always. See for example `std::mem::size_of::<T>()`, `Any::is::<T>()`, etc.
> 
> I'm missing something. Wouldn't this RFC allow writing `std::mem::size_of::<T>()` as `std::mem::size_of<T>()`?

I think what they mean is that if Rust had chosen not to allow specifying generic parameters when calling a function but instead only had type ascription.
That means that you could not write `::std::mem::size_of::<T>()` and would have to use a different syntax,
for example:the one I wrote in my previous comment or by passing generic parameters in the regular parameter list as in `::std::mem::size_of(T)`.",True,True
rust-lang_____rfcs_____2544,2018-09-18T18:44:50Z,True,rust-lang_____rfcs_____2544_____422504303,"One can also ascribe the type of `size_of`, though that's probably worse than turbofish.

Haskell, which has no turbofish equivalent but does have type ascription, seems to do either that or pass in a dummy value that can be annotated.",True,True
rust-lang_____rfcs_____2544,2018-09-18T18:51:56Z,True,rust-lang_____rfcs_____2544_____422506477,"> One can also ascribe the type of `size_of`, though that's probably worse than turbofish.

How would you ascribe the type of `mem::size_of`?
",True,True
rust-lang_____rfcs_____2544,2018-09-18T19:14:55Z,True,rust-lang_____rfcs_____2544_____422514013,"@rpjohnst 

> Haskell, which has no turbofish equivalent but does have type ascription, [...]

Haskell, has type application, which is what turbofish is, with [`{-# LANGUAGE TypeApplications #-}`](https://kseo.github.io/posts/2017-01-08-visible-type-application-ghc8.html):

```haskell
main :: IO ()
main = do
    quickCheck $ uncurry (==) . (sort @Int &&& msort)
```

This applies `Int` to [`sort :: forall a. Ord a => [a] -> [a]`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-List.html#v:sort) such that `sort @Int :: [Int] -> [Int]`.

> [...] seems to do either that or pass in a dummy value that can be annotated.

See [`Data.Proxy`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Proxy.html) which is the equivalent of `PhantomData`.",True,True
rust-lang_____rfcs_____2544,2018-09-19T03:06:50Z,True,rust-lang_____rfcs_____2544_____422634095,"Just my personal opinion, but when I started learning Rust, I was actually quite happy to know that the turbofish was a thing, because it seemed like a good solution for the problem that C++ has regarding the same topic, which I personally found really cumbersome to deal with. It also makes the language simpler as a whole, because the parser is a lot easier to write with the turbofish syntax.

Essentially, I don't see a reason to remove the turbofish syntax, even with the provided arguments in the RFC. I'm also afraid that by finding a way to remove it, it might cause future problems if by some reason we come up with another feature of the language and it happens to conflict with the removed turbofish syntax. Maybe if we have a stronger motivation to remove it, like it will absolutely bring an improvement in the language or something. But removing for the current motivations just seems too weak, and just because we can, I'd rather not go down that risky rabbit hole and end up regretting removing turbofish from the language.

PS:

I'm not happy with Turbofish either, but between turbofish and the proposed alternative, I prefer turbofish. HOWEVER, if I could change how Rust worked, this is how I'd make type inference work:

Functions would be able to have two parameter lists: one for compile time arg (types and const generics), and one for runtime args. So it would look something like this

```
fn foo(T)(bar: i32) {}
```

Calling it with explicit types would look like `foo(&str)(5);` You could also ""partially call it"" like so: `let baz = foo(T)`. That would return a monomorphised function that could be called like `baz(10)`. The first parameter list would also be optional, so if T could be inferred, then you could call `foo(7)` and it would infer the types too. It's very inspired by Scala, really, and doesn't require the <> tokens to signify compile time arguments.

But oh well, I can't really go back in time to suggest that :P",True,True
rust-lang_____rfcs_____2544,2018-09-19T11:36:01Z,True,rust-lang_____rfcs_____2544_____422767535,"@Ixrec I was responding to a comment that suggested that *even without* this RFC, type ascription would be enough to make the turbofish unnecessary. It would still be necessary in some cases.

@rpjohnst No, type ascription does not help with `size_of`. There is no value parameter, so the only expression to ascribe is the return value which is always `usize`. The turbofish is the only way to specify the type parameter.",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:01:54Z,True,rust-lang_____rfcs_____2544_____422859755,"I would like to be a voice against this change, mainly for four reasons:

1. I don't find the turbofish inconsistent, counter-intuitive, annoying or somehow against the mental model. I even think that it supports the idea of monomorphisation being the principle behind generic functions. If you think of a generic function being a module that includes a function for each possible type named after this type, the syntax is exactly as it should be. E.g. if you look at `collect::<i32>`, `collect` would be a module of functions doing the same job (namely collecting items) and `<i32>` would be the actual function that does the job for my type. The only difference is that the module is somehow auto-implemented by the compiler in a generic fashion and the name includes these `<>` which indicate that we indeed talk about an ""auto-implemented generic function"".

2. The main reason _for_ this change is, as I understand, making thinks easier for learners coming from other languages like C++ who are used to the proposed syntax. I think that reason is not applicable for any learner: Two years ago I've attended two lectures at my university at the same time. The first one was an introduction into Rust, the second one was an introduction into C++. I was a programmer before (Java, C, some others) but I found Rust being way more cleaner and intuitive than C++ with all its corner cases. And I especially include the turbofish here, since it made me think of a very important difference between C++/Rust and Java, the difference between monomorphisation and dynamic bindings.

3. The RFC includes a long list of reasons _against_ this change and -- even if they do not apply in practice -- I see absolutely no reason to go this way. Especially, I do not see a reason to add yet another syntax for a feature that is working totally fine. This holds even more to me, because the syntax will add a new ambiguity. I try to avoid a lot of languages just because of these ambiguities since they encourage people to use different dialects that others won't fully understand. I think, at best there should be a bijective mapping from the semantics to the syntax in order to make things easy. (That is the reason why I think that migrating from `...` to `..=`  and adding `impl Trait` in argument position was wrong, but these discussions are over...)

4. There are Rust programmers -- like me -- that are used to the current syntax. I don't want to ""learn"" a new one. In that sense I believe, we should think more of those who are used to Rust (ourselves) and less of those who might migrate to Rust (others).",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:03:54Z,True,rust-lang_____rfcs_____2544_____422860439,"IMO turbofish is not that big of a hurdle of learnability.

I agree with @petrochenkov that the problem is solved satisfiably with an informative error, and it's much easier to teach the turbo fish than it is ""you can't use this specifc combination of tokens because of reasons"".

The bottom line is that annoying as turbofish, is that it's almost irresponsible to introduce and ambiguity and break compatibility in order to solve an annoyance.

@ivandardi it's probably possible to introduce function monomorphisation with current syntax, no?",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:07:21Z,True,rust-lang_____rfcs_____2544_____422861730,"No idea. I'm not too well versed in the specifics of the syntax to know for
sure, but if someone wants to experiment with it just for the sake of
experimenting, go ahead! 😛

On Wed, Sep 19, 2018, 13:04 Gilad Naaman <notifications@github.com> wrote:

> IMO turbofish is not that big of a hurdle of learnability.
>
> I agree with @petrochenkov <https://github.com/petrochenkov> that the
> problem is solved satisfiably with an informative error, and it's much
> easier to teach the turbo fish than it is ""you can't use this specifc
> combination of tokens because of reasons"".
>
> The bottom line is that annoying as turbofish, is that it's almost
> irresponsible to introduce and ambiguity and break compatibility in order
> to solve an annoyance.
>
> @ivandardi <https://github.com/ivandardi> it's probably possible to
> introduce function monomorphisation with current syntax, no?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422860439>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AIA8OvEdaErBfvLX7rruJKqH4-EmbPHxks5ucmsDgaJpZM4WsDpq>
> .
>
",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:13:55Z,True,rust-lang_____rfcs_____2544_____422864037,"This isn't being proposed to make the language more like other languages.

Rather, it makes the language more consistent. You define a generic function with a type parameter as `funcname<T>`, and you provide that type parameter with `funcname<T>`.",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:14:46Z,True,rust-lang_____rfcs_____2544_____422864310,"As for migration, this is something that `cargo fix` could *trivially* handle.",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:20:46Z,True,rust-lang_____rfcs_____2544_____422866357,"The thing that worries me isn't migrating old code. It's future proofing
future code that worries me. Can people be absolutely sure that removing
turbofish in favour of this new proposed syntax won't make it so that Rust
in the future have to create workarounds, just like C++ has with it's
horrible `foo.template get<Bar>()` syntax?

On Wed, Sep 19, 2018, 13:15 Josh Triplett <notifications@github.com> wrote:

> As for migration, this is something that cargo fix could *trivially*
> handle.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422864310>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AIA8OqO2wFzDAFx6ncLRRQFsfPbJgvtiks5ucm2HgaJpZM4WsDpq>
> .
>
",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:22:00Z,True,rust-lang_____rfcs_____2544_____422866805,I think that favorable Crater results or `cargo fix` support should not be sufficient to justify breaking changes within an edition.,True,True
rust-lang_____rfcs_____2544,2018-09-19T16:26:29Z,True,rust-lang_____rfcs_____2544_____422868318,">Rather, it makes the language more consistent. You define a generic function with a type parameter as funcname<T>, and you provide that type parameter with funcname<T>.

That is indeed a good reason but I could argue that we should better change the behavior there because usually defining a function happens less often than using it.

> As for migration, this is something that `cargo fix` could _trivially_ handle.

That is true for my code base and possibly for most of the others. But as long as I use projects that have not yet migrated I need to learn both syntaxes to understand their code.",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:32:12Z,True,rust-lang_____rfcs_____2544_____422870237,"There, I found the page that I was looking for.

https://en.cppreference.com/w/cpp/language/dependent_name

Especially in the bottom-most part of the page. Will we eventually have to deal with that? If yes, how? Are there are future-proofing plans to prevent that from happening? If yes, which ones?",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:38:39Z,True,rust-lang_____rfcs_____2544_____422872297,"> I'm not happy with Turbofish either, but between turbofish and the proposed alternative, I prefer turbofish. HOWEVER, if I could change how Rust worked, this is how I'd make type inference work:
>
> Functions would be able to have two parameter lists: one for compile time arg (types and const generics), and one for runtime args. So it would look something like this
>
> `fn foo(T)(bar: i32) {}`

The problem with that syntax is a function returning a closure. If you call both at once you end up with `foo(function_arg)(closure_arg)`.",True,True
rust-lang_____rfcs_____2544,2018-09-19T16:42:18Z,True,rust-lang_____rfcs_____2544_____422873558,"@teiesti Yeah, I know, it's not something I put much thought on, it was just a rushed idea. If I were to think about that seriously I'd address those issues more seriously. Who knows, maybe on the future?",True,True
rust-lang_____rfcs_____2544,2018-09-19T17:21:12Z,True,rust-lang_____rfcs_____2544_____422887256,"On Wed, Sep 19, 2018 at 09:32:31AM -0700, Ivan Borgia Dardi wrote:
> There, I found the page that I was looking for.
> 
> https://en.cppreference.com/w/cpp/language/dependent_name
> 
> Especially in the bottom-most part of the page. Will we eventually have to deal with that? If yes, how? Are there are future-proofing plans to prevent that from happening? If yes, which ones?

Are you referring to the bits about disambiguating things so they don't
parse as the less-than operator?

I don't think we will, but that's something to determine through this
RFC process.

I hope we can separate the question of ""should we do this"" from the
question of ""can we do this"", and not attempt to use the latter as an
argument for the former. Let's evaluate them independently.
",True,True
rust-lang_____rfcs_____2544,2018-09-19T17:22:42Z,True,rust-lang_____rfcs_____2544_____422887780,"I'm in favor in the abstract of getting rid of turbofish, which has only ever had two merits: we considered it necessary and it has good branding. I remember my own experience of thinking `collect` basically required me to create a temporary to type ascribe it before I learned turbofish existed. Discoverability is a real problem with turbofish: when `.collect<Vec<_>>` doesn't work, many users' first assumption will be (as mine was) that there just wasn't a way to specify the parameter.

I also think this is low priority and that implementation challenges should be weighted heavily. I personally think this is fine without an edition, the breakages are strictly theoretical.",True,True
rust-lang_____rfcs_____2544,2018-09-19T17:35:11Z,True,rust-lang_____rfcs_____2544_____422892283,"> it's much easier to teach the turbo fish than it is ""you can't use this specifc combination of tokens because of reasons"".

I think the proposed rule (linting against chained bit-shifts and comparisons) is no more confusing than needing to use `::` to disambiguate generic arguments in expressions. Expressions of this form are uncommon. This rule is rarely going to be encountered and won't need to be taught (unlike turbofish).

> Can people be absolutely sure that removing turbofish in favour of this new proposed syntax won't make it so that Rust in the future have to create workarounds

This is true of any syntax change. It can be useful to consider *specific* syntax that might be desirable in the future, but not worrying simply about potential for conflict without any examples. This issue hasn't been ignored: one particular future syntax extension has been addressed in the RFC already, for instance.

> I think that favorable Crater results or cargo fix support should not be sufficient to justify breaking changes within an edition.

I agree, but the arguments for making this change without an addition are generally taking favourable Crater results as a *necessary* condition — and that the advantages are beneficial enough to justify this change.

If there's enough time to get this into the 2018 Edition, we could also consider that, but that increases time pressure.",True,True
rust-lang_____rfcs_____2544,2018-09-19T17:43:18Z,True,rust-lang_____rfcs_____2544_____422894928,"> Discoverability is a real problem with turbofish: when .collect<Vec<_>> doesn't work, many users' first assumption will be (as mine was) that there just wasn't a way to specify the parameter.

@withoutboats This can be handled in _the next nightly if needed_ by updating the parser to use @varkor's PR slightly modified to emit a specific diagnostic suggesting the appropriate syntax. Another (related/more likely for newcomers) problem is [when doing a collect without turbofish](https://play.rust-lang.org/?gist=cadee1d6a1e80035bb73c39408b46c8c&version=nightly&mode=debug&edition=2015) (CC https://github.com/rust-lang/rust/issues/49391) we don't suggest it either, so we have a discoverability issue across the board. Note that [when we are binding the result of `collect`](https://play.rust-lang.org/?gist=f3fb34343cf57fb5a651a92889a2fa2d&version=nightly&mode=debug&edition=2015), we give an accurate, if sparse, hint. Regardless of wether this RFCS gets approved, we need to fix those rough edges.

> This rule is rarely going to be encountered and won't need to be taught (unlike turbofish).

I disagree slightly, as this new syntax will also require `rustc` to provide an appropriate suggestion in the cases mentioned above.

> If there's enough time to get this into the 2018 Edition, we could also consider that, but that increases time pressure.

At the very least we could reserve the syntax for 2018 and create a lint ""against chained bit-shifts and comparisons"" as you proposed...

> I also think this is low priority and that implementation challenges should be weighted heavily. I personally think this is fine without an edition, the breakages are strictly theoretical.

Having both `try!` and `?` was annoying for a while, but the community moved on (for the most part). With this change, I believe both `::<>` and `<>` will _have to_ coexist for cases where the syntax would otherwise be ambiguous and for backwards compatibility with existing code (if we introduce this in 2015 edition).

:-/",True,True
rust-lang_____rfcs_____2544,2018-09-19T17:56:57Z,True,rust-lang_____rfcs_____2544_____422899542,"WRT the C++ dependent name stuff... the turbofish is itself already essentially that. Instead of `s.template foo<T>`, we change `template` to `::` and move it one token to the right: `s.foo::<T>`. The meaning is the same- ""parse this `<` as an opening bracket rather than a binary operator.""",True,True
rust-lang_____rfcs_____2544,2018-09-19T18:09:09Z,True,rust-lang_____rfcs_____2544_____422903684,"@rpjohnst I don't think it's comparable. In Rust that's consistent, in C++ that's an arcane incantation. The compiler usually do not help you wrt `template` in that position, and you are left to wonder why your code don't work.

The code doesn't always work, it depends on the knowledge of the compiler of the dependent type, and it disables inference iirc.

In Rust the turbofish is consistent within itself, at least.",True,True
rust-lang_____rfcs_____2544,2018-09-19T18:13:34Z,True,rust-lang_____rfcs_____2544_____422905120,"> The compiler usually do not help you wrt `template` in that position, and you are left to wonder why your code don't work.

The compiler has just as much ability to help you insert `template` as rustc has to help you with turbofish. I know Clang does it in some situations. And as @estebank points out above, we don't do so great a job at it anyway (yet).",True,True
rust-lang_____rfcs_____2544,2018-09-19T19:48:51Z,True,rust-lang_____rfcs_____2544_____422935020,I would be very happy to finally remove the turbofish language inconsistency. Having type ascription be inconsistent because of a hypothetical ambiguity is bad and I am glad that we can change it without having any crate on crates.io break. In my opinion we should lint against this ambiguous writing anyway for readability.,True,True
rust-lang_____rfcs_____2544,2018-09-20T03:44:46Z,True,rust-lang_____rfcs_____2544_____423030623,"> That is indeed a good reason but I could argue that we should better change the behavior there because usually defining a function happens less often than using it.

It’s not just functions, though. Turbofish can also be used when naming a type, e.g.
```rust
let mut x = Vec::<i32>::new()
```
In this case, Vec is both defined *and used* as `Vec<T>` – in most cases –  while only in this one specific case does it have to be written `Vec::<T>`.

Admittedly, using turbofish for types is probably less often necessary than with functions.  For example, the above snippet  can be written without turbofish by giving `x` a type annotation, and indeed this is generally seen as more idiomatic:
```rust
let mut x: Vec<u32> = Vec::new()
```
But then… *why* is this version the idiomatic one?  It’s longer than the first version, and repetitive, writing `Vec` twice.  It does have the advantage of explicitly naming the type of `x`, but the first version makes the type pretty obvious as well.

I think it’s mainly just because people consider turbofish to be ugly.  Thus, if we abolished the need for it, the pendulum would probably start to swing towards seeing `Vec<i32>::new` as the idiomatic version.  And IMO, that would be a good thing – especially since creating a Vec is one of those things that often shows up in introductory code snippets, where any kind of ugly syntax, including repetitiveness, can make the language look bad.",True,True
rust-lang_____rfcs_____2544,2018-09-20T03:56:56Z,True,rust-lang_____rfcs_____2544_____423032260,"@estebank
> With this change, I believe both `::<>` and `<>` will have to coexist for cases where the syntax would otherwise be ambiguous and for backwards compatibility with existing code (if we introduce this in 2015 edition).

No, the belief is that `::<>` would *never* be required with this change.  In ambiguous cases, the default would be interpreting as a generic (i.e. as if you had written `::<>`), and if you want comparisons instead, you can always force that by adding parentheses.  If it turns out there’s some edge case that that won’t be able to handle, I would personally reconsider my support for this change, but for now I’m not aware of any.

On the other hand, as you say, `::<>` would have to remain available for backwards compatibility.  But that’s no different from `try!`.  And, unlike when `?` was introduced, we now have a `cargo fix`, and it should be possible to have it rewrite the syntax for you automatically.",True,True
rust-lang_____rfcs_____2544,2018-09-20T05:23:09Z,True,rust-lang_____rfcs_____2544_____423043867,"@comex In particular, I think `Vec<i32>::new()` has a key desirable consistency property: it's consistent with the use of `Vec<i32>` as a type elsewhere. You can use `Vec<i32>` in a function signature, in a variable declaration, in a generic type parameter, in an ascription, anywhere else you can use a type. And with this change, you'll be able to use it to identify the type you want to call a method on, too.",True,True
rust-lang_____rfcs_____2544,2018-09-20T06:44:56Z,True,rust-lang_____rfcs_____2544_____423059802,"What I always thought was also weird was that you didn't have to write out the whole type in object literal syntax.

For example, if you have this definition: `struct Hello<T> { p: T }`

Then:
* `let h = Hello { p: 'c' }` compiles, and the type of `h` is `Hello<char>`. This is kind of surprising for me coming from C++/Java, where I would have written:
* `let h = Hello<char> { p: 'c' }`, which *doesn't* compile. Of course it's nice to have type inference do the work for you, but it's still surprising that writing out the full form is actually a syntax error. What the compiler actually wants, as it turns out, is turbofish:
* `let h = Hello::<char> { p: 'c' }` compiles. This is *very* surprising for me, especially as another way to write out the type fully does not involve turbofish:
* `let h: Hello<char> = Hello { p: 'c' }` also compiles.

It gets weirder with certain corner cases where type inference doesn't work:
* `let p = PhantomData` obviously doesn't compile, because we can't figure out the actual type of `p`.
* `let p = PhantomData<char>` doesn't compile either. You can guess why at this point.
* `let p: PhantomData<char> = PhantomData` and `let p = PhantomData::<char>` both compile.

So, in case it was not clear from the rant above, I wholeheartedly support this RFC.",True,True
rust-lang_____rfcs_____2544,2018-09-20T09:45:34Z,True,rust-lang_____rfcs_____2544_____423116920,"Ok, I do agree with the points above, so removing turbofish might be an option. But for that, however, I'd think that the RFC should be updated to try and find edge cases and explain how the code would be have to be parsed in those cases. Tools that generate code might be an issue here sometimes too, because while we know a human has a low chance of writing something that would be wrongly interpreted as generics, generated code might not necessarily.

So basically the idea is ok, now we just need to actually toughen it up, get rid of edge cases and future-proof it.",True,True
rust-lang_____rfcs_____2544,2018-09-20T09:55:34Z,True,rust-lang_____rfcs_____2544_____423120409,@ivandardi Note: this RFC does not propose *removing* turbofish; rather it makes it *unnecessary*.,True,True
callstack_____react-native-paper_____485,2018-09-20T10:55:47Z,True,callstack_____react-native-paper_____485_____423139623,@iyadthayyil are you still working on this or you need some help? :),True,True
rust-lang_____rfcs_____2544,2018-09-20T11:05:12Z,True,rust-lang_____rfcs_____2544_____423142638,"Well, not removing it, but I’d say it would make sense to consider it deprecated, and someday well down the line, add a warn-by-default lint for it.

I agree that it would make sense to consider whether there might be any issues with tools that generate code – specifically, if they could run into the very narrow cases that are valid today (so not chained comparisons) but would change meaning under this proposal.

For example, the RFC mentions this ambiguity:
```rust
(a < b, c > (d))
```
But there’s another possibility:
```rust
(a < b, c > ::d)
```
This could either be an associated const of the type `a<c, b>`, or a pair of comparisons where `::d` is an absolute path.  (…although I don’t know if that syntax will continue to be valid; I’ve lost track of all the module system proposals.)

This is even less likely to appear in human-written code, but it’s easier to imagine a code generator scattering absolute paths all over the place.

By the way – mostly unrelated – there’s also a class of ambiguities around binary operators.  This code:
```rust
(a<b, c>-4)
```
could be a pair of comparisons, or it could be `a<b, c>` minus 4.  How could it be the latter?  Currently, as far as I can tell, only in a very specific case: if `a` is a unit variant of an enum, the variant has been `use`d, and `Sub` has been manually implemented for that enum:
```rust
enum E<T, U> {
    Dummy(T, U),
    a
}
use E::a;
impl<T, U> Sub<i32> for E<T, U> { .. }

// this is valid:
a::<i32, i32> - 4
```

On the other hand, if the left-hand side has `::` (i.e. `z::a<b, c>-4`), it can be ambiguous without a `use`.  This is because the turbofish syntax for a unit enum variant is `Enum::Variant::<Parameters>`, *not* `Enum::<Parameters>::Variant` as might be expected.  To reduce the chance of this occurring in the wild, I suggest that we also change the syntax for enums to allow the latter and deprecate the former.

Of course, this also works for other operators that have both binary and unary variants (`*`, `&`… not `+` though, unlike other languages!).

Anyway, this is also a rather niche situation, and as usual you can disambiguate with parentheses.

It might become *very slightly* less niche with other future language features:
- With const generics, I believe `a<b, c>` could be a valid expression for a unit *struct* .  Currently, it can only be an enum: a struct with type parameters can’t be a unit struct, because the type parameters would necessarily be unused!  But const generics won’t need to be mentioned in the struct definition, so something like `struct a<const b: usize, const c: usize>;` would be valid.
- If we allow consts/statics to be generic, `a<b, c>` could refer to one of those and thus have any type (including types that might make a bit more sense to be doing arithmetic on).
",True,True
rust-lang_____rfcs_____2544,2018-09-20T18:36:29Z,True,rust-lang_____rfcs_____2544_____423288747,"> On the other hand, as you say, ::<> would have to remain available for backwards compatibility. But that’s no different from try!. And, unlike when ? was introduced, we now have a cargo fix, and it should be possible to have it rewrite the syntax for you automatically.

@comex the point being that that [`try!` is still supported](https://play.rust-lang.org/?gist=16e0d5a336125797f164f38aae5ce0b9&version=nightly&mode=debug&edition=2015) and _if it weren't_ it could be trivially expressed in terms of `?`, while the proposed change here is a parser level change that can have much wider ramifications. (`?` was a strict addition to the syntax, as it didn't have the potential to clash with anything, while this is a change to existing syntax.) I am still _not_ rejecting the change outright, I just think we should be careful not to trivialize the potential problems caused by such a change.",True,True
rust-lang_____rfcs_____2544,2018-09-20T18:40:35Z,True,rust-lang_____rfcs_____2544_____423290039,"The disambiguation rule as specified is also is a forward-compatibility hazard:
```rust
save S;
try {
    parse GENERIC_ARGS;
} catch(...) {
    restore S;
    parse EXPR;
}
```
Note how this is dependent on specific grammar used for `GENERIC_ARGS` at the moment.
If the grammar is extended, then more previously valid `EXPR`s will convert into `GENERIC_ARGS` breaking code.

And the grammar *will* be extended, as soon as const generics are implemented and then progress and possibly allow wider class of expressions to be written in generic arguments.

In particular, something like `x < 10, 11 >` doesn't look like generic arguments now, so it wasn't interpreted as `x::<10, 11>` during the crater run and passed testing, this means const generics will break code *later* if this proposal is implemented now.",True,True
rust-lang_____rfcs_____2544,2018-09-20T18:50:55Z,True,rust-lang_____rfcs_____2544_____423293222,"I think it's possible to implement a more conservative version of this proposal that's implementable with  2-token lookahead on *token trees* - this means no rollback and no forward-compatibility issue.

""Token trees"" here means that we treat a balanced delimiter group (e.g. `(TOKEN_STREAM)`) as a single token, which we already kinda do because our parser accepts token trees from the lexer rather than tokens, this is especially visible in proc macros.

In this case we need roughly the next rule:
```
IF
  we are in turbofish position (after path segment identifier)
  AND
  the following (+1) token is a balanced angle bracketed group `<TOKEN_STREAM>`
  AND
  the next (+2) token is in the FOLLOW set for a path segment (this notably excludes identifiers and literals)
  THEN
  parse GENERIC_ARGS
END
```
It breaks a bit more code than the rollback version, but should still be acceptable for edition breakage.
(If only the first condition is used (balanced angle bracket), then the breakage is larger than it would be acceptable.)

I'm currently making a prototype, but there are a couple of subtle details that need to be figured out, like treatment of `->` in `X<fn(u8) -> u8>`.",True,True
rust-lang_____rfcs_____2544,2018-09-20T19:37:31Z,True,rust-lang_____rfcs_____2544_____423306896,I don't like the fact that there are multiple ambiguities. This seems like setting a bad president towards having code with lots special cases sprinkled around.,True,True
rust-lang_____rfcs_____2544,2018-09-20T19:45:12Z,True,rust-lang_____rfcs_____2544_____423309065,"> Note how this is dependent on specific grammar used for GENERIC_ARGS at the moment.
If the grammar is extended, then more previously valid EXPRs will convert into GENERIC_ARGS breaking code.

*If* the new syntax conflicts with any existing syntax — which is also true of any other syntax change. I understand your point is that you think it's likely the syntax will be extended in an incompatible way, though: but I don't think that future extensions are going to be incompatible (see below).

> And the grammar will be extended, as soon as const generics are implemented and then progress and possibly allow wider class of expressions to be written in generic arguments.

(To give a little more context for others: the const generic syntax does not cause any conflicts with this proposal (specifically because const expression arguments are required to be enclosed in `{}`), so this argument relies on a scenario in which this rule was relaxed.)

I don't think there's any reasonable argument to be made in favour of relaxing the rule to the point where this would cause issues without `::` (i.e. arbitrary const expressions). It's easy to come up with parsing issues when `{}` is not required, such as `f::<a>()>()` (which could parse as `(f::<a>()) > ()` or `f::<(a > ())>()`). The problems with relaxing the `{}` requirement are significant even *without* considering this proposal.

---

> I think it's possible to implement a more conservative version of this proposal that's implementable with 2-token lookahead on token trees - this means no rollback and no forward-compatibility issue.

> It breaks a bit more code than the rollback version, but should still be acceptable for edition breakage.

> I'm currently making a prototype, but there are a couple of subtle details that need to be figured out, like treatment of -> in X<fn(u8) -> u8>.

I'd definitely be interested in seeing feasible alternative implementations 👍",True,True
rust-lang_____rfcs_____2544,2018-09-20T20:22:27Z,True,rust-lang_____rfcs_____2544_____423320187,"@varkor 
>the const generic syntax does not cause any conflicts with this proposal (specifically because const expression arguments are required to be enclosed in `{}`

But your own PR (https://github.com/rust-lang/rust/pull/53645) implements at least literals as generic arguments (in accordance with examples from the RFC - https://github.com/withoutboats/rfcs/blob/40ce721ae7315ba83c346bb9ba448885d6a4f03e/text/2000-const-generics.md#applying-a-const-as-a-parameter), without requiring `{}`.

Also, accepting only `{...}` in generic arguments would *also* be a breaking change, since it still extends what `GENERIC_ARGS` accepts and reinterprets previously valid code using `<` operators (the impact should be low in this case though).

>The problems with relaxing the {} requirement are significant even without considering this proposal.

That's until someone writes an RFC solving those problems with backtracking because `{}` is not *e r g o n o m i c* enough.",True,True
rust-lang_____rfcs_____2544,2018-09-20T20:32:00Z,True,rust-lang_____rfcs_____2544_____423323123,"> But your own PR (rust-lang/rust#53645) implements at least literals as generic arguments (in accordance with examples from the RFC - withoutboats/rfcs:text/2000-const-generics.md@40ce721#applying-a-const-as-a-parameter), without requiring {}.

> it still extends what GENERIC_ARGS accepts and reinterprets previously valid code using < operators

Ah, that's a good point. My assertion was probably a little cavalier. I think the impact is the same with these extensions, but it is more subtle than I indicated.",True,True
rust-lang_____rfcs_____2544,2018-09-20T21:24:27Z,True,rust-lang_____rfcs_____2544_____423338391,"Based on discussion in the @rust-lang/lang meeting today, the general sentiment was positive towards this. However, we don't think this should target the 2018 edition, and there's a *huge* amount of discussion here. We'd like to defer this until after the 2018 edition ships.

Please don't let this deter anyone from continuing to work on changes, testing, and feasibility analysis. This is just a note to say that the lang team probably won't have much bandwidth to dig deeply into this until after the edition ships.",True,True
rust-lang_____rfcs_____2544,2018-09-20T21:25:34Z,True,rust-lang_____rfcs_____2544_____423338683,Speaking for myself personally: I'm *hugely* impressed with @varkor here for persisting in the face of the seemingly invincible turbofish. Well done! I look forward to seeing this change go in.,True,True
rust-lang_____rfcs_____2544,2018-09-22T00:42:20Z,True,rust-lang_____rfcs_____2544_____423704055,"If this is to be entirely put off until after the 2018 edition, then it won't be able to be done without waiting for the next edition or breaking changes.

I'm not particularly a fan of the change, but it seems to me that if we are likely to make it we should make the new edition backwards compatible with this change by forbidding the ambiguous forms of syntax.",True,True
rust-lang_____rfcs_____2544,2018-09-22T00:46:06Z,True,rust-lang_____rfcs_____2544_____423704404,"@gmorenz Unfortunately the consensus during lang team discussion was that there isn't enough time before the edition ships to begin forbidding potential syntax ambiguities, especially since I believe detecting the ambiguities requires the same arbitrary parsing lookahead that the feature itself would require.",True,True
rust-lang_____rfcs_____2544,2018-09-22T06:53:12Z,True,rust-lang_____rfcs_____2544_____423722070,"> If this is to be entirely put off until after the 2018 edition, then it won't be able to be done without waiting for the next edition or breaking changes.

Why not? There will be another edition in 2021 or so.",True,True
rust-lang_____rfcs_____2544,2018-09-22T11:26:47Z,True,rust-lang_____rfcs_____2544_____423737571,"@SimonSapin that's what @gmorenz is referring to when they say ""waiting for the next edition""",True,True
rust-lang_____rfcs_____2544,2018-09-22T16:04:06Z,True,rust-lang_____rfcs_____2544_____423754245,"This would be a reasonable feature for Rust21, imo, especially assuming that const generics will exist by then. We should probably have a `future_rust_incompatibility` warning that warns for chained comparisons like those shown here, then.",True,True
rust-lang_____rfcs_____2544,2018-09-23T07:45:54Z,True,rust-lang_____rfcs_____2544_____423798340,"I think it should be fine in Rust 2021. Sure, it will take time, but that's fine. It's not like waiting 13 years for C++11.

(I suppose there was C++03, but it didn't do much. Like, what it did? Introduce the requirement for std::vector elements to be stored contiguously?)",True,True
rust-lang_____rfcs_____2544,2018-09-23T16:09:37Z,True,rust-lang_____rfcs_____2544_____423827385,">I think it's possible to implement a more conservative version of this proposal that's implementable with 2-token lookahead on token trees

I made an [experiment](https://github.com/petrochenkov/rust/tree/turbo) for https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423293222, and it doesn't work unfortunately, too much breakage.
The most common reason for breakage is greater-or-equal `>=` due to `a<b,c>=d` being a valid assignment expression syntactically.
Here's the output from attempting to compile libcore:
```
error: balanced angle brackets in generic argument position are reserved
   --> libcore\num\flt2dec\strategy\dragon.rs:112:14
    |
112 |       if d.exp < 0 {
    |  ______________^
113 | |         scale.mul_pow2(-d.exp as usize);
114 | |     } else {
115 | |         mant.mul_pow2(d.exp as usize);
...   |
120 | |     // divide `mant` by `10^k`. now `scale / 10 < mant + plus <= scale * 10`.
121 | |     if k >= 0 {
    | |___________^
    |
    = note: #[deny(balanced_angle_brackets)] on by default

error: balanced angle brackets in generic argument position are reserved
   --> libcore\num\flt2dec\strategy\dragon.rs:240:14
    |
240 |       if d.exp < 0 {
    |  ______________^
241 | |         scale.mul_pow2(-d.exp as usize);
242 | |     } else {
243 | |         mant.mul_pow2(d.exp as usize);
...   |
246 | |     // divide `mant` by `10^k`. now `scale / 10 < mant <= scale * 10`.
247 | |     if k >= 0 {
    | |___________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\num\flt2dec\strategy\grisu.rs:394:26
    |
394 |               while plus1w < plus1v_up &&
    |  __________________________^
395 | |                   threshold - plus1w >= ten_kappa &&
    | |_______________________________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\num\flt2dec\strategy\grisu.rs:396:39
    |
396 |                     (plus1w + ten_kappa < plus1v_up ||
    |  _______________________________________^
397 | |                    plus1v_up - plus1w >= plus1w + ten_kappa - plus1v_up) {
    | |________________________________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\num\flt2dec\strategy\grisu.rs:408:19
    |
408 |           if plus1w < plus1v_down &&
    |  ___________________^
409 | |            threshold - plus1w >= ten_kappa &&
    | |________________________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\num\flt2dec\strategy\grisu.rs:410:32
    |
410 |              (plus1w + ten_kappa < plus1v_down ||
    |  ________________________________^
411 | |             plus1v_down - plus1w >= plus1w + ten_kappa - plus1v_down) {
    | |___________________________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\char\methods.rs:442:21
    |
442 |               if code < MAX_ONE_B && !dst.is_empty() {
    |  _____________________^
443 | |                 *dst.get_unchecked_mut(0) = code as u8;
444 | |                 1
445 | |             } else if code < MAX_TWO_B && dst.len() >= 2 {
...   |
453 | |                 3
454 | |             } else if dst.len() >= 4 {
    | |__________________________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\char\methods.rs:445:28
    |
445 |             } else if code < MAX_TWO_B && dst.len() >= 2 {
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\char\methods.rs:449:28
    |
449 |             } else if code < MAX_THREE_B && dst.len() >= 3  {
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\slice\sort.rs:167:36
    |
167 |               let greater = if right < v.len() && is_less(&v[left], &v[right]) {
    |  ____________________________________^
168 | |                 right
169 | |             } else {
170 | |                 left
...   |
173 | |             // Stop if the invariant holds at `node`.
174 | |             if greater >= v.len() || !is_less(&v[node], &v[greater]) {
    | |_________________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\slice\sort.rs:467:21
    |
467 |               while l < r && is_less(pivot, v.get_unchecked(r - 1)) {
    |  _____________________^
468 | |                 r -= 1;
469 | |             }
470 | |
471 | |             // Are we done?
472 | |             if l >= r {
    | |___________________^

error: balanced angle brackets in generic argument position are reserved
   --> libcore\str\mod.rs:505:10
    |
505 |       if x < 128 {
    |  __________^
506 | |         return Some(x as u32)
507 | |     }
508 | |
...   |
514 | |     let mut ch = utf8_acc_cont_byte(init, y);
515 | |     if x >= 0xE0 {
    | |___________^

error: aborting due to 12 previous errors
```
</details> ",True,True
rust-lang_____rfcs_____2544,2018-09-23T16:13:03Z,True,rust-lang_____rfcs_____2544_____423827651,"Note that many cases in https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423827385 will be interpreted as generics with the backtracking-based approach as well, if const generics grow ability to accept arbitrary expressions.",True,True
callstack_____react-native-paper_____485,2018-09-23T20:12:32Z,True,callstack_____react-native-paper_____485_____219709909,"It's a quick hack to overcome an animation  problem I faced when creating a new animated view from the existing `Surface` component. This was the original way I did it:
```javascript
const AnimatedSurface = Animated.createAnimatedComponent(Surface);
```
But this seems to render very choppy animations, would like to know if there is a way to just use `Surface` without this animation issue.",True,True
callstack_____react-native-paper_____485,2018-09-23T20:17:21Z,True,callstack_____react-native-paper_____485_____219710052,"@iyadthayyil We can change `View` to `Animated.View` here: https://github.com/callstack/react-native-paper/blob/master/src/components/Surface.js#L65

Then we wouldn't need `Animated.createAnimatedComponent(Surface)`",True,True
callstack_____react-native-paper_____485,2018-09-23T20:18:26Z,True,callstack_____react-native-paper_____485_____219710109,Ok will do that.,True,True
callstack_____react-native-paper_____485,2018-09-23T20:21:06Z,True,callstack_____react-native-paper_____485_____219710205,"I just used the same code from the original `Surface` component, but will change that, also should probably change that in the original `Surface` component aswell.",True,True
callstack_____react-native-paper_____485,2018-09-23T20:24:09Z,True,callstack_____react-native-paper_____485_____219710299,Ok will clear this up with some variables.,True,True
callstack_____react-native-paper_____485,2018-09-23T20:26:44Z,True,callstack_____react-native-paper_____485_____423845407,"Ok, sorry guys, I have been busy with uni work, will try to get this ready soon.",True,True
rust-lang_____rfcs_____2544,2018-09-24T02:41:32Z,True,rust-lang_____rfcs_____2544_____423867405,"It seems like one viable path forward (assuming backtracking) would be to require const generics to use `{}` for expressions containing the `&&` and `||` operators.

Note that this wouldn't exactly be a *new* special case; const generics will definitely have to use `{}` for expressions containing the `<` and `>` operators, so this would just be adding a few more operators to the list.",True,True
rust-lang_____rfcs_____2544,2018-09-24T02:48:09Z,True,rust-lang_____rfcs_____2544_____423867813,"> Note that many cases in #2544 (comment) will be interpreted as generics with the backtracking-based approach as well, if const generics grow ability to accept arbitrary expressions.

> It seems like one viable path forward (assuming backtracking) would be to require const generics to use {} for expressions containing the && and || operators.

I think it's reasonable just to assume we'll stick with the current model of requiring `{}` for any non-literal expression. It seems fairly clear even from these short discussions that anything else has major shortcomings.",True,True
rust-lang_____rfcs_____2544,2018-09-24T09:59:48Z,True,rust-lang_____rfcs_____2544_____423926396,"@varkor 
>I think it's reasonable just to assume we'll stick with the current model of requiring {} for any non-literal expression. It seems fairly clear even from these short discussions that anything else has major shortcomings.

I don't think it's reasonable to assume that.
Parsing `TYPE | EXPR` is a simpler problem to solve than turbofish, especially if more advanced parsers are employed or if backtracking becomes acceptable as a solution (did I say that you are opening a floodgate with this RFC?).
Parsing with restrictions like ""no `<`"" or ""no `{}`"" is not a problem either, it's already used.
The question of removing `{}` will very likely arise if the push for ergonomics continues, which is likely given the line up of the lang team.",True,True
mysqljs_____mysql_____1962,2018-09-24T21:12:52Z,True,mysqljs_____mysql_____1962_____424126892,@dougwilson Is this still planned to be merged? It obviously keeps accumulating conflicts while it is not :(,True,True
mysqljs_____mysql_____1962,2018-09-24T21:17:39Z,True,mysqljs_____mysql_____1962_____424128320,"This PR regresses behavior and cannot be merged until fixed as I noted above. I volunteered to fix the PR but have not gotten to it. Anyone is welcome to fix the regression in the PR, though, and will merge.",True,True
mysqljs_____mysql_____1962,2018-09-24T21:28:06Z,True,mysqljs_____mysql_____1962_____424131454,"@dougwilson Thanks for the update! Not sure I'll get to it in the nearby future personally, though (but it's a possibility).",True,True
mysqljs_____mysql_____1962,2018-09-24T21:54:46Z,True,mysqljs_____mysql_____1962_____424138608,It's np. I did get it mostly rebased and fixed locally but didn't quite finish. I'll bring this close to the top of my current todo list.,True,True
selfagency_____microsoft-drop-ice_____344,2018-09-25T11:28:11Z,True,selfagency_____microsoft-drop-ice_____344_____217945329,Fixed huge typo. Be more careful next time :),True,True
selfagency_____microsoft-drop-ice_____345,2018-09-25T12:14:01Z,True,selfagency_____microsoft-drop-ice_____345_____217957478,thanks,True,True
mysqljs_____mysql_____1962,2018-09-25T12:17:46Z,True,mysqljs_____mysql_____1962_____424319430,"> I'll look at what the fix is and push it up to your PR branch here

@dougwilson I was under the impression you would take over from there, and just assumed something else was blocking this. In any case, I'll gladly help to push this forward. Please, let me know what I can do.",True,True
mysqljs_____mysql_____1962,2018-09-25T12:25:32Z,True,mysqljs_____mysql_____1962_____424321907,You are correct. I volunteered to fix the PR. I did get it mostly rebased and fixed locally but didn't quite finish. I'll bring this close to the top of my current todo list.,True,True
mysqljs_____mysql_____1962,2018-09-25T12:30:10Z,True,mysqljs_____mysql_____1962_____424323464,"Alright, perfect. Let me know if there is something I can help with.",True,True
selfagency_____microsoft-drop-ice_____345,2018-09-25T13:53:39Z,True,selfagency_____microsoft-drop-ice_____345_____220201683,"It draws attention to an abuse of power by a government agency, and waste of government resources. It is an action that we can take as open source software developers to prevent the situation from becoming accepted and normalized.",True,True
selfagency_____microsoft-drop-ice_____344,2018-09-26T06:03:16Z,True,selfagency_____microsoft-drop-ice_____344_____424595236,"*Dear contributor,*
*thanks for your contribution. Your PR has been denied, due to the following reasons:*
 - *The PR has failed the tests against* :hankey:

*Please make the tests pass and commit again. Thank you.*",True,True
rust-lang_____rfcs_____2544,2018-09-26T07:33:26Z,True,rust-lang_____rfcs_____2544_____424615426,"> especially if more advanced parsers are employed or if backtracking becomes acceptable as a solution

ES2015 solved this with a ""cover grammar"" - for us, that would mean specifying `Type | Expr` as a new `TypeOrExpr` syntactical category (by taking any syntax that's shared between `Type` and `Expr`, and recursing on it with `TypeOrExpr`, e.g. type/expr tuples would be `,`-separated `TypeOrExpr*`).

So it even has avenues that don't require more advanced parsing algorithms or backtracking.",True,True
rust-lang_____rfcs_____2544,2018-09-26T08:55:17Z,True,rust-lang_____rfcs_____2544_____424638765,"I think there is an alternative missing for this RFC.

### Make the non-turbofish syntax redundant

The motivation, as I understand it, is to make the syntax consistent between `Foo<T>` and `bar::<T>`.

Suggestion: Make it possible to write `Foo::<T>`, and lint on `Foo<T>`.

This makes the syntax consistent. It also brings generics in line with the writing for namespaces: a generic is nothing more than a lot of automatically-defined types / functions, that can be considered as all being put under a namespace. And, most importantly, it doesn't introduce ambiguity, regardless of how rare the ambiguity actually happens or of how the ambiguity is resolved.

This idea is clearly not thought through, and there are likely many other things to change. Likely some drawbacks, too. But I think the idea of removing the non-turbofish syntax should be explored too, not only the idea of removing the turbofish syntax.",True,True
rust-lang_____rfcs_____2544,2018-09-26T10:18:27Z,True,rust-lang_____rfcs_____2544_____424663033,"Now, about the interaction with future features: what about (with chained comparisons and const generics):
```rust
if foo<bar<MYCONST>>() {
}
```
This doesn't sound really unlikely to me, and parsing will be ambiguous. Complete example with two possible interpretations, where one will take the `if` and the other the `else` branch:
```rust
struct MyStruct {}
const MYCONST: MyStruct = MyStruct {};
impl Shr<()> for MyStruct {
    type Output = usize;
    fn shr(self, _: ()) -> bool {
        4usize
    }
}

fn foo<T>() -> bool { false }
struct bar<const C: MyStruct> {}

// ...

let foo = 2usize;
let bar = 3usize;

if foo<bar<MYCONST>>() {
     // ...
} else {
     // ...
}
```",True,True
rust-lang_____rfcs_____2544,2018-09-26T10:48:31Z,True,rust-lang_____rfcs_____2544_____424670936,"@Ekleog 
>Suggestion: Make it possible to write `Foo::<T>`, and lint on `Foo<T>`.

FWIW, it *is* possible to use the `::` disambiguator in ""type"" positions, just not strictly necessary.
```rust
type A = Vec::<u8>; // OK
```",True,True
rust-lang_____rfcs_____2544,2018-09-26T11:12:41Z,True,rust-lang_____rfcs_____2544_____424677258,"> Now, about the interaction with future features: what about (with chained comparisons and const generics):

Chained comparisons are forbidden, so this would not be ambiguous syntax.

> FWIW, it is possible to use the :: disambiguator in ""type"" positions, just not strictly necessary.

Although not when declaring types:

```rust
struct S::<A>(A); // error: expected `where`, `{`, `(`, or `;` after struct name, found `::`
```

> This makes the syntax consistent. It also brings generics in line with the writing for namespaces

Yes, and this is undesirable. Generic parameters are unrelated to namespaces.

> a generic is nothing more than a lot of automatically-defined types / functions, that can be considered as all being put under a namespace

Except that the function or type is *not* a namespace and cannot be used like one. This conceptualisation doesn't fit into the existing framework of the language.",True,True
rust-lang_____rfcs_____2544,2018-09-26T13:35:20Z,True,rust-lang_____rfcs_____2544_____424717332,"> Chained comparisons are forbidden, so this would not be ambiguous syntax.

What do you mean ""forbidden""? We don't have it now or we will never have it any likely future?",True,True
rust-lang_____rfcs_____2544,2018-09-26T15:03:55Z,True,rust-lang_____rfcs_____2544_____424750251,"@varkor this is true now, but I would like it in the future as shorthand for the mathematical meaning.",True,True
rust-lang_____rfcs_____2544,2018-09-26T16:12:25Z,True,rust-lang_____rfcs_____2544_____424776580,"> What do you mean ""forbidden""? We don't have it now or we will never have it any likely future?

> @varkor this is true now, but I would like it in the future as shorthand for the mathematical meaning.

Sorry, you're right. What I meant was that it's currently forbidden, but if it was introduced, this case would fall under the chained comparison and bit-shift lint (so you'd write `foo < bar < (MYCONST>>())` instead), so it doesn't introduce any additional problems.",True,True
rust-lang_____rfcs_____2544,2018-09-26T17:37:25Z,True,rust-lang_____rfcs_____2544_____424805217,"@varkor I agree with you that namespaces and generics are not exactly the same thing. However, I think it does make sense to think of them as paths (which is actually, I think, the reason why the syntax is this way?)

Also, I don't see any way in which, outside of consistency, the `ident<>` is better than the `ident::<>` syntax (gaining two characters is not much).

And the issue of `ident<>` that I mentioned above with chained-comparison-and-bit-shift is not a technical problem indeed, however it does sound like a human understanding problem: just parse the following few examples: (not requiring chained comparisons this time)
```rust
quux(foo<bar<baz<42>>>())
quux(foo<bar<baz<42>>())
quux(foo<bar,baz<stuff<42>>>())
quux(foo<bar,baz<stuff<42>>())
```
Then these ones:
```rust
quux(foo::<bar::<baz::<42>>>())
quux(foo<bar::<baz::<42>>>())
quux(foo::<bar,baz::<stuff::<42>>>())
quux(foo<bar,baz::<stuff::<42>>())
```
There is no technical ambiguity, and the meaning is the same for both examples. I also did not touch spacing so as not to cheat. And these are examples I came up with in less than a minute.

The second ones appear much easier to read to me.

Sure, saying “but just use `rustfmt`” is a possible solution to this, as correct spacing would make things easier to read. But then remember the users we're trying to help are beginners, and all beginners I know of have horrible indentation / spacing standards, few think to often run code maintenance tools, and they are overall very likely to make mistakes like the ones given as examples above.

Overall, I think the fact that the comparison operators and the generic parameter application are so easily distinguishable is something that is **good** for Rust. Maybe some other sybols than `<>` would have been better than the `::<>` syntax (though I can't find any easily-reachable ones, `≤≥` is hard to type on most keyboards), but, coming from a C++ background, I'm convinced the `<>` will actually make things worse.

(note here in these comparisons I'm comparing all-turbofish against non-turbofish, I still believe the best option is the current behaviour of turbofish-in-expression-location)

And all this only compares the objective qualities of the two syntaxes. It doesn't even compare the harsh difference in complexity of writing a parser, or external tools that deal with the language. (eg. good luck writing a syntax highlighter for vim that looks good with the new syntax -- C++ didn't manage it, and it's C++, while Rust has it good currently)",True,True
rust-lang_____rfcs_____2544,2018-09-26T17:45:34Z,True,rust-lang_____rfcs_____2544_____424807836,"Actually, the distinction between the following two is pretty unfortunate, because it seems like a likely typo:

```rust
(foo < bar, baz)
(foo < bar, baz >) // today, this is a straight syntax error.
```",True,True
rust-lang_____rfcs_____2544,2018-09-26T17:58:08Z,True,rust-lang_____rfcs_____2544_____424811780,"> Actually, the distinction between the following two is pretty unfortunate, because it seems like a likely typo:

You're going to get an error if you make a typo like this both now and after the changes described here (though the exact error might be different — it'll be local and easy to identify).",True,True
Marak_____faker.js_____616,2018-09-27T01:17:40Z,True,Marak_____faker.js_____616_____424922584,"@driade 

Looks good, merged.

I've redacted your comment here in regards to a surname having a previous political affiliation. This simply isn't the place for these kinds of discussions.

Your contributions are much appreciated. Thank you again.
",True,True
rust-lang_____rfcs_____2544,2018-09-27T16:57:58Z,True,rust-lang_____rfcs_____2544_____425166778,"Well, yes, I'm not arguing the compiler won't be able to figure it out (and don't think I ever have). However, I *am* arguing that it is a problem for the reader's brain to figure it out.

Also, here is a small example for which that the compiler wouldn't report any error (just imagine the `bar` struct comes from `bindgen` to explain why it isn't capitalized correctly):
```rust
fn foo<T>() -> bool { false }
fn bar<T>() -> usize { 42 }
struct bar<T> {}
fn main() {
    let foo = 0;
    assert_eq!(foo<bar<usize>>(), false);
    assert_eq!(foo<bar<usize>(), true);
}
```

With your proposal, this program would pass. I argue that passing is correct under your semantics, but highly unexpected, and that making it pass is actually a bad idea.",True,True
rust-lang_____rfcs_____2544,2018-09-27T17:37:54Z,True,rust-lang_____rfcs_____2544_____425179571,"@Ekleog Your example would parse but not compile, because `foo<params>()` looks up `foo` in the value namespace (not the type namespace), so it would refer to the local variable.  Thus, if I convert your example to today's syntax by adding turbofish, I get this error:
```
error[E0109]: type parameters are not allowed on this type
 --> src/main.rs:6:22
  |
6 |     assert_eq!(foo::<bar<usize>>(), false);
  |                      ^^^^^^^^^^ type parameter not allowed
```
This is actually pretty bad wording; the real issue is that `foo` isn't a type at all.  This should be improved, but it's orthogonal to the turbofish question. :)

More generally, I'd say that if the programmer intended to write a comparison, they would probably use spaces:
```rust
assert_eq!(foo < bar<usize>(), true);
```

If they didn't intend to write a comparison, it's pretty unlikely that the code would compile without some sort of error.  Your example is already fairly artificial in that it defines an unrelated `fn` and `struct` both named `bar`, as well as shadowing `foo`.  But to make the `assert` lines both compile successfully, I think you'd need a much more convoluted arrangement.  The only approach I know of is to have a unit enum variant which is both callable and comparable:

```rust
enum E<T = u32> {
    foo,
    bar(T),
}
use E::foo;
impl<T> FnOnce<()> for E<T> {
    type Output = bool;
    extern ""rust-call""
    fn call_once(self, (): ()) -> bool { false }
}
impl PartialEq<usize> for E<u32> {
    fn eq(&self, other: &usize) -> bool { false }
}
impl PartialOrd<usize> for E<u32> {
    fn partial_cmp(&self, other: &usize) -> Option<Ordering> { Some(Ordering::Less) }
}
```",True,True
rust-lang_____rfcs_____2544,2018-09-27T18:10:19Z,True,rust-lang_____rfcs_____2544_____425190571,"> Also, I don't see any way in which, outside of consistency, the `ident<>` is better than the `ident::<>` syntax (gaining two characters is not much).

The biggest problem with this is:

I believe the main reason Rust uses angle brackets in the first place (as opposed to square brackets, [which Rust supported in ancient days](
https://www.reddit.com/r/rust/comments/6l9mpe/minor_rant_i_wish_rust_had_gone_with_square/djsi37m), or other possibilities) is for consistency with other languages – minimizing the amount of the ""[strangeness budget](https://words.steveklabnik.com/the-language-strangeness-budget)"" that has to be spent on syntax.  Changing all uses of `Foo<Bar>` to `Foo::<Bar>` would largely negate that benefit; admittedly, the angle brackets are still there, but overloading `::` for this purpose is unique to Rust and arguably even more strange than `Foo[Bar]` would be.  (For the same reason, deprecating turbofish would improve Rust's consistency with other languages.)",True,True
rust-lang_____rfcs_____2544,2018-09-28T18:58:07Z,True,rust-lang_____rfcs_____2544_____425533947,"(tl;dr below)

@comex Oh indeed, I didn't think that functions and variables were in the same namespace, so the example I gave is unlikely to be of any use indeed. Thanks :)

Now, **if** the compiler is able to generate a helpful error message for `foo<bar<usize>()` missing a `>` (in the same way that [forgetting the turbofish gives help right now](https://play.rust-lang.org/?gist=0ae192248a5a55401c7a5ff9c02bb33b&version=stable&mode=debug&edition=2015), **then** maybe it's not that bad.

But I know I have been with students learning C++, and they regularly forgot `>` in similar way (or had imbalanced `<>` in other ways), and it was a pain to just have to repeat everyone the same thing “count your brackets”. I fear Rust will fall in the same trap that C++ fell into, and this will be painful for people discovering the issue.

Because yes, with some experience, I can now tell if there's a missing parenthesis in a bunch of 5 or maybe more nested parenthesis. But I do know that beginners don't, and a type error, even local, may make them bang their head against the desk for a long time before someone comes in and tells them “look, you just didn't count your brackets correctly”.

About the strangeness budget… well, I don't really think that one minor syntax strangeness, especially when hand-held by the compiler and occurring relatively rarely, is worth it :) Especially when considering the argument of making the parser **much** more complex for **all** tools that want to deal with Rust. (and no, not all parsers are written in turing-complete languages, some “parsers” are really just regexes or similarly low-capacity parsing… good luck implementing this syntax change in these systems)

-----

To sum up this post:
 * If the compiler cannot give a hint that the closing `>` has been forgotten in `foo<bar<usize>()`, then I think this will *really* hinder beginners' liking of the system (as I experienced while helping beginner C++ programmers hitting this very same issue)
 * If the compiler can, then it is a trade-off between one minor strangeness in syntax that should occur relatively rarely and quite big added complexity to parser implementations, some of which may possibly just not be able to support the new syntax because they're written in regexes or similar (thinking of vim's syntax highlighting expressions, for instance)

In both cases, I do not think this change is worth it, even though I do understand why people want to remove this strangeness and want to applaud this effort put into the research for this PR :) (also, I still think the “use only turbofish” solution should at least be listed in the list of alternatives)",True,True
rust-lang_____rfcs_____2544,2018-09-28T23:53:17Z,True,rust-lang_____rfcs_____2544_____425596377,"> Especially when considering the argument of making the parser much more complex for all tools that want to deal with Rust.

> some “parsers” are really just regexes

The ease of implementation in most traditional parsers is called out in the RFC. It's trivial to implement with regexes too (à la `(::)?`). If you think there's an example of a viable parser for which implementing this change is difficult, I'd like to see a concrete example.

> If the compiler cannot give a hint that the closing > has been forgotten in foo<bar<usize>(), then I think this will really hinder beginners' liking of the system

This is something we can and will do.",True,True
rust-lang_____rfcs_____2544,2018-09-29T05:11:51Z,True,rust-lang_____rfcs_____2544_____425616729,"Well, @Ekleog mentioned vim syntax highlighting rules.  As an example of what they look like, here’s rust.vim:

https://github.com/rust-lang/rust.vim/blob/master/syntax/rust.vim

Vim’s syntax highlighting engine is pretty ad-hoc, but AFAIK the expressive power of syntax rules is roughly equivalent to a pushdown automaton.  Thus, in theory you could distinguish between expressions and types under the existing syntax, but not after the proposed change.  However, the current rust.vim doesn’t actually bother to do so.  It takes a... cruder approach:

```
syn keyword rustTrait Box
syn keyword rustTrait ToOwned
syn keyword rustTrait Clone
syn keyword rustTrait PartialEq PartialOrd Eq Ord
syn keyword rustTrait AsRef AsMut Into From
syn keyword rustTrait Default
syn keyword rustTrait Iterator Extend IntoIterator
syn keyword rustTrait DoubleEndedIterator ExactSizeIterator
```",True,True
rust-lang_____rfcs_____2544,2018-09-29T09:45:17Z,True,rust-lang_____rfcs_____2544_____425632095,"@varkor The part I'm thinking about is the following part of rust.vim:
```vim
syn match     rustFuncCall    ""\w\(\w\)*(""he=e-1,me=e-1
syn match     rustFuncCall    ""\w\(\w\)*::<""he=e-3,me=e-3 "" foo::<T>();
```
Which currently detects pretty well whether something is a function call or not. (actually, I can't remember of any time where I noticed it fail in actual code -- though it would fail on the `Struct::<GenArg>` syntax)

Now, detecting that `foo<bar, baz>()` is a function call while `foo < bar && baz > quux()` is not would sound… hard, with this scheme.

Also, this is only the first thing that came to my mind, because I use vim. I'm guessing a number of other text editors would have similar problems. Yes, people are using imperfect heuristics, but they do work well and are highly useful.",True,True
rust-lang_____rfcs_____2544,2018-10-01T05:15:48Z,True,rust-lang_____rfcs_____2544_____425791697,"This would be nice. It also would be hard, on several fronts:

- actually implementing this feature, which some here have suggested would require backtracking
- implementing the numerous lints and appropriate errors + error messages to keep things understandable
- the additional hoops that we would have to jump through to detect corner-cases

It seems like it's not worth the ergonomics of removing 2 characters (for experienced rust users) / making generics slightly less confusing (for beginners / new arrivals). The times where it is a problem for beginners / new arrivals, the existing error messages do a very good job of guiding the user to the correct answer.

If this is a feature our _existing_ parser could handle with little added effort, I could see the appeal. But adding backtracking and all the bugs/complexity/lints/error-messages associated with that seems too much to be worth the effort.",True,True
rust-lang_____rfcs_____2544,2018-10-01T09:27:24Z,True,rust-lang_____rfcs_____2544_____425843815,"> It also would be hard, on several fronts:

> If this is a feature our existing parser could handle with little added effort, I could see the appeal.

This feature has essentially already been implemented in https://github.com/rust-lang/rust/pull/53578. The additional lints would not be significant extra effort.",True,True
rust-lang_____rfcs_____2544,2018-10-01T10:30:04Z,True,rust-lang_____rfcs_____2544_____425860723,"@Phlosioneer `rustc`'s existing parser can support the change with little effort. That's unfortunately not the case with other more or less well-implemented parsers currently in use, that are used for tooling (eg. syntax highlighting, see https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425632095).",True,True
rust-lang_____rfcs_____2544,2018-10-01T14:51:26Z,True,rust-lang_____rfcs_____2544_____425936721,"Ah; well then, seems worth it to me.",True,True
rust-lang_____rfcs_____2544,2018-10-01T15:27:48Z,True,rust-lang_____rfcs_____2544_____425950321,I'm curious if @matklad has thoughts on how hard IDE support for this would be.,True,True
rust-lang_____rfcs_____2544,2018-10-01T16:04:03Z,True,rust-lang_____rfcs_____2544_____425963737,"> how hard IDE support for this would be.

Not a problem at all.",True,True
rust-lang_____rfcs_____2544,2018-10-01T16:46:27Z,True,rust-lang_____rfcs_____2544_____425978699,@matklad Can you give any idea how to update the vim syntax highlighting example I quoted above to work with this proposal? I can't find any way to decently express the syntax after the change.,True,True
rust-lang_____rfcs_____2544,2018-10-01T16:47:57Z,True,rust-lang_____rfcs_____2544_____425979185,"The issue is not how hard it is for any individual parser to implement- adding it once to rustc, or once to libsyntax2, or once to syn, is not that hard on its own.

The issue is when you have a wide array of tools that involve *some* level of parsing, but do not, or will not, or can not, reuse one of these ""juggernaut"" libraries for whatever reason. Quick scripts or Ctrl+F/grep-style human users, text editor or web-based syntax highlighting, small third-party parsers or particularly weird macros, independent implementations, etc.

There are workarounds and mitigations for some of these cases, but that doesn't make it worth it just to remove the turbofish. It's not that bad as things are now, and people will still have to work around the syntax in some (other/fewer) cases anyway with this change. Only a C++-like semantic disambiguation could actually remove *all* the workarounds, and that's certainly not a place worth going.",True,True
rust-lang_____rfcs_____2544,2018-10-01T16:52:40Z,True,rust-lang_____rfcs_____2544_____425980755,@Ekleog I was talking specifically about IDEs: tools that parse Rust syntax for real. I can't say anything about regular-expression based tools.,True,True
rust-lang_____rfcs_____2544,2018-10-01T19:37:01Z,True,rust-lang_____rfcs_____2544_____426035448,"Hmm... I still tend to agree with @rpjohnst's thoughts in https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425979185, but after seeing all of the parser experts say this is not too hard, I'm more willing to give this a try and see if it ever actually shows up in practice.",True,True
rust-lang_____rfcs_____2544,2018-10-01T19:51:38Z,True,rust-lang_____rfcs_____2544_____426039907,"Regarding rust.vim:

I didn't notice the bit @Ekleog quoted.  But again, the current rust.vim is *very* heuristic and only has a superficial understanding of Rust's syntax.  Here's that bit again (comment removed for clarity):

```vim
syn match     rustFuncCall    ""\w\(\w\)*(""he=e-1,me=e-1
syn match     rustFuncCall    ""\w\(\w\)*::<""he=e-3,me=e-3
```

Note that `\w\(\w\)*::<` is a regex.  Not only is it unable to distinguish `::<` used in type position, it won't even trigger if there's whitespace before or after the `::`.  Also, the first line (for non-turbofish calls) doesn't match calls where the callee expression doesn't end with an identifier, e.g. `(foo)(bar)`.  In other words, the bar for accuracy is pretty low.

On the other hand, it's true that it matches most turbofish usage today, and this change would make it harder.  For reference, Vim's syntax highlighting is not *just* a matter of ""highlight these regexes"": it has a concept of ""syntax regions"", which both allow it to transition between different states (""match groups"") with different sets of applicable regexes, and support nesting (e.g. you can define a ""parentheses"" region such that `(` enters the region, and `)` pops the stack and returns you to whatever state you were in before).  That's why I described it as a pushdown automaton, which is a bit more powerful than a DFA.  But it's not an NFA: it can't backtrack.  And the color used for each token is determined as it goes.

Thus, although we could use the pattern `>(`, without whitespace, as a decent heuristic for the *end* of an explicitly specialized generic call (inaccurate, but hardly more so than the existing heuristics), there's no way to use match groups to convey that information back to the beginning, where the function name is (the thing we want to highlight).  And the text at the beginning, `foo<`, is probably not a good enough heuristic by itself (even testing for a lack of whitespaces, there'd probably be too many false positives). 

But… regexes themselves can backtrack.  Vim's regexes don't support recursion, but we could define a regex that, say, matches up to 3 levels of nested `<>`, where the final `>` is followed by a `(`.  It would be ugly, but it'd mostly work.  However, things would get thornier if we wanted to correctly treat cases where `<` can appear as less-than within a type name, like `Foo<[u32; bar(a < b)]>` today, or const generics in the future...",True,True
rust-lang_____rfcs_____2544,2018-10-02T01:41:02Z,True,rust-lang_____rfcs_____2544_____426118494,"@comex My concern is (I think the same as @rpjohnst's) that I guess vim will not be the only tool affected by this change, and even though making the grammar non-LL is not a problem for `rustc` in itself, it can easily become a problem for quite a lot of other tools. As you mentioned, currently it'd be possible to improve vim's syntax highlighting to have it accurately report expressions, and after this change it wouldn't. Sure, as @eddyb [mentions](https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422250552) it's not a problem to make `rustc` parse a non-LL grammar, but other tools parse (at least partially) rust syntax with potentially reduced capabilities… and if I had a choice, I'd think we would fare better by making it *easier* for tools to parse it, not harder.

I fear that this change is a no-going-back change, and by doing it we are closing the way for appropriate tooling we maybe don't know yet.",True,True
googlefonts_____fontbakery_____2067,2018-10-02T18:32:09Z,True,googlefonts_____fontbakery_____2067_____219802212,"- Remove prebuilt FontVal. Use Hintak's binaries instead.
- Drop render tests. Diffbrowsers should be used.
- Added instructions for MAC and GNU Linux

I spent yesterday evening attempting to get Ms Font Validator to work on three macs. Since Hintak now provides [binaries](https://github.com/HinTak/Font-Validator/releases/tag/FontVal-2.1.2) for Font Validator, we should use these instead since it makes the installation so much easier.

I've also dropped the raster tests because we should use diffbrowsers instead

I dislike moving the binary to /usr/local/bin. I've only done this because our installation instructions for ots does this. Perhaps we should encourage soft links?

Keep this open since I need to get this working on Win. @felipesanches could you test on Linux?

cc @mjlagattuta @eliheuer ",True,True
googlefonts_____fontbakery_____2067,2018-10-02T18:40:50Z,True,googlefonts_____fontbakery_____2067_____426385735,"thanks, @m4rc1e !

I'll be testing it here, yes.",True,True
googlefonts_____fontbakery_____2067,2018-10-02T18:43:48Z,True,googlefonts_____fontbakery_____2067_____426386783,"Thanks, I'll fix the build whilst adding Win",True,True
googlefonts_____fontbakery_____2067,2018-10-02T18:57:26Z,True,googlefonts_____fontbakery_____2067_____426391143,I also want `pip install fontbakery` to install Ms Font Validator correctly.,True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:03:35Z,True,googlefonts_____fontbakery_____2067_____426393123,"Hm, you can execute code when installing a wheel, that’s just unzipped in site packages. If you really want to pip install fontval then you need to either include prebuilt binaries as package_data, or make it available as a separate distribution on PyPI and require that in fontbakery.",True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:08:31Z,True,googlefonts_____fontbakery_____2067_____426394585,Also when you include native executables or dlls in your pure python package you need to hack the bdist_wheel setuptools command to make pip think that this is not a pure python whee but a platform specific one. It’s tricky but doable. Get in touch if you want me to help,True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:30:45Z,True,googlefonts_____fontbakery_____2067_____426401086,"@anthrotype Thanks for your willingness to help!

I only use Ms Val for the glyf checks. Do you know if the Noto project has more contour checks than what noto_lint provides?
 https://github.com/googlei18n/nototools/blob/master/nototools/noto_lint.py#L92-L333?
",True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:32:07Z,True,googlefonts_____fontbakery_____2067_____426401477,I actually don’t know.,True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:42:57Z,True,googlefonts_____fontbakery_____2067_____426404584,"As, a temporary improvement for installing Hintak's FontVal binaries: copying `FontValidator` to the bin of the Python3`venv` I'm using is working for me. We could probably write a shell script that sets up a FontBakery install in this way on macOS.
```
~/Py/Venvs/type/bin/FontValidator
``` ",True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:49:56Z,True,googlefonts_____fontbakery_____2067_____426406662,Is your concern about /usr/local/bin that you can overwrite existing paths there Marc? How about installing these distributed executables in a local directory off of the system PATH and switch calling code to use those fontbakery specific paths rather than whatever is highest priority on system PATH definition.  Would allow the project to control project specific versions and users to install prior or more recent builds for other purposes as necessary.  Then you aren't mucking with default paths for distributed 3rd party software at all.  ,True,True
googlefonts_____fontbakery_____2067,2018-10-02T19:59:02Z,True,googlefonts_____fontbakery_____2067_____426409448,"@chrissimpkins pretty much

Personally, I like my dependencies to be specific for each tool (like virtualenvs). By dropping them in usr/local/bin, we're assigning these 3rd party tools to be run globally. I may not want FB's Font Val to be my system's default.",True,True
googlefonts_____fontbakery_____2067,2018-10-02T23:38:20Z,True,googlefonts_____fontbakery_____2067_____426465566,Good practice too.  Gives project control over dep versions and permits user to use what they want for other needs.  It looks like fontbakery calls use system PATH prioritized versions.  That may need to change to address this?  I submitted the ots install approach on macOS but agree with you.  ,True,True
callstack_____react-native-paper_____485,2018-10-04T10:25:43Z,True,callstack_____react-native-paper_____485_____426966389,Maybe we can do it step by step and take a look to rotation later and other edge cases. Let us know if you need help @iyadthayyil.,True,True
googlefonts_____fontbakery_____2067,2018-10-04T10:47:48Z,True,googlefonts_____fontbakery_____2067_____426972128,"I think dropping things in /usr/local/bin (and /usr/local/lib) was perhaps historical - when you try not to do LD_LIBRARY_PATH, and such. Anyway, I am mostly of the view that things are either installed/uninstalled cleanly or not at all. Leaving things behind when fontbakery is gone is wrong.",True,True
googlefonts_____fontbakery_____2067,2018-10-04T11:56:36Z,True,googlefonts_____fontbakery_____2067_____426991163,"Somelody can explain to me what diffbrowser does, but the rasterization test in fontval is, to be honest, misnamed. 

It checks for validity and problems in the hinting instructions. Since the execution of hinting instructions depends on current resolution, especially at the lower end, the test is run at a range of resolutions. Rasterization test is not a visual test. I'd call it ""hinting instruction analysis"", though the Microsoft naming is stuck.

It defaults to be ""on"" in the GUI from old times, and was switched off in the command line because it did not work well or at all at the beginning of being opened. The GUI had new code added to trap the failure to allow it to ""land safely"". The intention was always to switch it back on when it works well, and it did with 2.1 - so it was switched on after. (the command switches for on/off will stay)",True,True
googlefonts_____fontbakery_____2067,2018-10-04T13:19:07Z,True,googlefonts_____fontbakery_____2067_____427015257,"> Somelody can explain to me what diffbrowser does, but the rasterization test in fontval is, to be honest, misnamed.

It enables us to take screenshots on different operating systems and browsers using https://www.browserstack.com",True,True
googlefonts_____fontbakery_____2067,2018-10-04T13:37:31Z,True,googlefonts_____fontbakery_____2067_____427021609," The FontVal raster test tells you where in the hinting instruction byte stream is wrong, and not the same thing. The same thing would be something like a non-interactive/scripted usage of ttdebug (in the ft2-demos). 
    On Thursday, 4 October 2018, 21:19:25 GMT+8, Marc Foley <notifications@github.com> wrote:  
 
 

Somelody can explain to me what diffbrowser does, but the rasterization test in fontval is, to be honest, misnamed.


It enables us to take screenshots on different operating systems and browsers using [https://www.browserstack.com]

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub, or mute the thread.
   ",True,True
googlefonts_____fontbakery_____2067,2018-10-05T16:01:46Z,True,googlefonts_____fontbakery_____2067_____223059355,"this needs to be done on our travis setup, otherwise simply removing the prebuilt binaries will break the build as seen here: 
https://travis-ci.org/googlefonts/fontbakery/jobs/436304489

<img width=""820"" alt=""captura de tela 2018-10-05 as 13 00 39"" src=""https://user-images.githubusercontent.com/213676/46546191-c75dc780-c89e-11e8-8d3c-b1ac83ed42e3.png"">
<img width=""856"" alt=""captura de tela 2018-10-05 as 13 00 58"" src=""https://user-images.githubusercontent.com/213676/46546213-cd53a880-c89e-11e8-82e2-dc608590e3e2.png"">
",True,True
mysqljs_____mysql_____1962,2018-10-08T11:27:31Z,True,mysqljs_____mysql_____1962_____427799522,I think you should keep track of this issue :) still on 8.0.,True,True
callstack_____react-native-paper_____485,2018-10-11T08:13:25Z,True,callstack_____react-native-paper_____485_____428862610,Any ETA for this component?? This component looks beautiful,True,True
googlefonts_____fontbakery_____2067,2018-10-12T16:19:43Z,True,googlefonts_____fontbakery_____2067_____429381226,">  I think dropping things in /usr/local/bin (and /usr/local/lib) was perhaps historical - ... 
> I am mostly of the view that things are either installed/uninstalled cleanly or not at all. Leaving things behind when fontbakery is gone is wrong.

This comment doesn't apply to any of the optional compiled executables in this project.  Users are being asked to install them outside of the FB install and uninstall outside of the FB uninstall.  The only way that I can see to achieve automation of this process is through something like `make` with install/uninstall targets on macOS/Linux and a Windows installer/uninstaller.  Probably the ideal approach? 

Assuming that the goal is to allow `/usr/local/bin`, `/usr/bin`, etc to take higher priority if multiple copies are installed on a system, pehaps we define a new bin path like `$HOME/.fontbakery/bin`.   This is the approach that Rust and Go use for installed compiled executables on Unix systems.  Then users place the new fontbakery bin directory at the end of their system PATH.  Not sure how this translates to Win platform.",True,True
googlefonts_____fontbakery_____2067,2018-10-12T19:27:16Z,True,googlefonts_____fontbakery_____2067_____429436037,"Well, put it this way, I probably use font validator more often than many, but I don't put it in my system directories either. Hence I have not noticed that running it via $PATH did not work.

My opinion would be put them in a private FB-owned directory and run things via full/relative path. That way, if you do delete the whole FB-owned directory, everything, include 3rd party tools users are asked to install (but not usually used independently of FB), is gone.",True,True
googlefonts_____fontbakery_____2067,2018-10-13T20:40:27Z,True,googlefonts_____fontbakery_____2067_____429573598,@eliheuer how do you plan to approach this in https://github.com/eliheuer/fontbakery-desktop?,True,True
googlefonts_____fontbakery_____2067,2018-10-13T20:58:07Z,True,googlefonts_____fontbakery_____2067_____429574738,"> @eliheuer how do you plan to approach this in https://github.com/eliheuer/fontbakery-desktop?

I think that separating the raw data from the text strings in log messages will enable front-ends like fontbakery-desktop to use the data in smarter ways.",True,True
googlefonts_____fontbakery_____2067,2018-10-13T20:59:51Z,True,googlefonts_____fontbakery_____2067_____429574852,"hmmm... maybe I misunderstood the question. Can you clarify what you were refering to in your questions bout fontbakery-desktop, @chrissimpkins ?",True,True
googlefonts_____fontbakery_____2067,2018-10-13T21:11:09Z,True,googlefonts_____fontbakery_____2067_____429575618,"Sorry.  Too concise.  I am wondering if Eli plans to distribute platform-specific pre-compiled versions of optional dependencies through something like clickable installer tools as part of the development work that takes place for the FB Desktop applications.  If so, FB ""CLI"" may be able to use the same approach and do away with the detailed installation documentation altogether.  This would all be placed within automated platform-specific install/uninstall tools with slight modifications for a CLI vs. GUI interface to the testing source.  The approach to the dependency installs might be the same for both tools.",True,True
googlefonts_____fontbakery_____2067,2018-10-13T21:15:40Z,True,googlefonts_____fontbakery_____2067_____429575886,ok. Got it. I think fontbakery-desktop should not worry about this. This is a base-problem to be solved by fontbakery core. A design principle for fontbakery-desktop is that it should simply work if the user already has got fontbakery CLI properly setup.,True,True
googlefonts_____fontbakery_____2067,2018-10-13T21:34:51Z,True,googlefonts_____fontbakery_____2067_____429577083,Agree. It seems that the question about where it is be best to place optional compiled FB dependencies remains an open one in this thread.  Marc used the same `/usr/local/bin` approach for FontVal that I recommended in the macOS ots-sanitize documentation.  That has been questioned in the discussion here and it remains an open topic.  I was interested in how Eli planned to address it with the GUI tool.  It sounds like it may just execute based upon how these are defined in the core project?,True,True
googlefonts_____fontbakery_____2067,2018-10-13T21:58:15Z,True,googlefonts_____fontbakery_____2067_____429578652,"yes. This is not a problem for FB-desktop to solve, even though a solution would benefit it (and any other frontend)",True,True
googlefonts_____fontbakery_____2067,2018-10-14T19:41:01Z,True,googlefonts_____fontbakery_____2067_____429655862,"I think you should wrap all the native executable that you depend on and distribute them on PyPI as pre-compiled wheels, so that you can then require them using the normal python packaging system.

I started a wheel builder repository for the opentype sanitizer here:
https://github.com/anthrotype/ots-wheels

I haven't uploaded wheels yet, but you should already be able to clone and pip install in editable mode.
Haven't tested on windows yet (I need to a build.bat for it, and set up appveyor).

This package exports an `ots` module with a single function called `sanitize` that takes a list of string arguments, that is passed on to the embedded `ots-sanitize` executable as a subprocess.
It also installs an `ots-sanitize` entry point console script (but maybe we don't need that one).",True,True
googlefonts_____fontbakery_____2067,2018-10-14T19:57:12Z,True,googlefonts_____fontbakery_____2067_____429657188,"@anthrotype That sounds good, but I wouldn't push to PyPI a native executable package containing FontVal since a portion of the source code used to generate the latest binaries is not publicly available under a free license, thus rendering those binaries non-free.

If we do ship binary packages to PyPI, then we should build it ourselves, from full sources (even if we end up with a binary that misses those few non-free features).",True,True
googlefonts_____fontbakery_____2067,2018-10-14T20:00:48Z,True,googlefonts_____fontbakery_____2067_____429657507,"Of course, I agree. I’m building ots from source",True,True
googlefonts_____fontbakery_____2067,2018-10-14T21:22:04Z,True,googlefonts_____fontbakery_____2067_____429663807,"I don't object to you guys not using FontVal at all. I just object to your practice of punishing your users with a substantially crippled version.

My opinion would be, use the whole of it, or don't use it. Don't ask people to use a substantially crippled version.

I am all for open-source - you can find my name listed as a subsystem maintainer in the Linux kernel - that's how far I am for it. But going on and on about what you want is not how you can get what you want.",True,True
googlefonts_____fontbakery_____2067,2018-10-14T21:43:25Z,True,googlefonts_____fontbakery_____2067_____429665780,"> since a portion of the source code used to generate the latest binaries is not publicly available under a free license

Out of curiosity, what is that portion exactly?",True,True
googlefonts_____fontbakery_____2067,2018-10-14T21:54:46Z,True,googlefonts_____fontbakery_____2067_____429666557,"> Out of curiosity, what is that portion exactly?

The `raster-tests` portion. It only works when interfacing with a non-free fork of freetype which provides a feedback channel to inform the application about all errors detected by the opentype hinting instructions virtual machine at runtime. Vanilla freetype silently deals with most of those malformed blocks of hinting instructions. The private fork extracts that info and reports back to fontval via a callback.",True,True
googlefonts_____fontbakery_____2067,2018-10-15T06:16:00Z,True,googlefonts_____fontbakery_____2067_____429720898,"Please feel free to write your own. I am rather tired of this whole exchange. All the FreeType developers are perfectly aware what I do. We all agree that the **FontVal** enhancement does not belong and should not polute FreeType. You, an outsider, keep telling us what we should do. 

Please feel free to fork your own, if you think it is merely whatever.

I have also not seen you improve any of the c# code either. If you feel you can do better, please do.",True,True
googlefonts_____fontbakery_____2067,2018-10-15T06:35:26Z,True,googlefonts_____fontbakery_____2067_____429724800,"See the FAQ https://github.com/HinTak/Font-Validator/wiki/FAQ#why-did-you-not-try-harder-to-upstream-the-patch . And regarding ""negative contributions"".

Cc @davelab6 : Can you please ask him to stop?",True,True
googlefonts_____fontbakery_____2067,2018-10-15T06:41:35Z,True,googlefonts_____fontbakery_____2067_____429726090,"Also this item of the FAQ https://github.com/HinTak/Font-Validator/wiki/FAQ#when-will-the-full-patch-set-be-posted

@davelab6 : please ask him to stop.",True,True
googlefonts_____fontbakery_____2067,2018-10-16T16:36:44Z,True,googlefonts_____fontbakery_____2067_____430307857,"I have updated the FAQ regarding this entry, https://github.com/HinTak/Font-Validator/wiki/FAQ#when-will-the-full-patch-set-be-posted , and posted a 4th condition:

```
Microsoft had removed the rasterization module, as well as refused to send me a more
up-to-date binary privately, although signs suggested that development continued for 4
more years after the last public update. The rasterization module is based on the windows
graphic kernel (win32k.sys), and understandably, there are too many security implications.
The decline to send a more up-to-date binary privately had always been stated as due to
""concerns about reverse-engineering"". Now that the work is mostly completed, before
it is posted, it must be carefully checked for any hints on that.
```

I have also registered an official complaint with @davelab6 concerning your bahavior. I have known and worked with the FreeType people, and Werner since at least 1996. Out of 20+ years of professional respect, it is okay for me to describe my work along the line of merely building on top of FreeType, but I find it absolutely offensive anybody else describing my work that way, and repeatedly.",True,True
googlefonts_____fontbakery_____2067,2018-10-16T17:17:34Z,True,googlefonts_____fontbakery_____2067_____430321834,"@HinTak For some reason this appears to be a touchy subject and I don't know the full back story but I haven't seen any criticism of you, your work, or the quality of the software that you are developing in this thread.  From what I can gather, there was simply a statement that it is not appropriate to distribute software that is not free through this project.  That seems like a reasonable goal to me.  If there are upstream issues that you cannot solve and must keep your source closed (if that is even the case, I don't know what the issue is) so be it.  

Also, the following comment is completely uncalled for and not in line with collegial collaborative work:

> You, an outsider, keep telling us what to do 

It is OK to have differences of opinion and discuss those in a courteous fashion but comments like these are destructive and a disincentive to open collaboration.  This cannot be tolerated.  Argue your own case and avoid personal attacks that are intended to dismiss other's opinions.  It should be assumed that everyone is attempting to do what is in the best interest of the project and there is no experience criterion to participate in open work.  ",True,True
googlefonts_____fontbakery_____2067,2018-10-16T17:23:02Z,True,googlefonts_____fontbakery_____2067_____430323807,"@chrissimpkins : as you admit you do not know the full story, why do you not read the FAQ? The FAQ was written last year! It was written to stop this kind of outsider comments from you.

https://github.com/HinTak/Font-Validator/wiki/FAQ#why-did-you-not-try-harder-to-upstream-the-patch",True,True
googlefonts_____fontbakery_____2067,2018-10-16T17:33:48Z,True,googlefonts_____fontbakery_____2067_____430327431,@chrissimpkins : please read the FAQ from the beginning to the end before you comment. https://github.com/HinTak/Font-Validator/wiki/FAQ thank you.,True,True
googlefonts_____fontbakery_____2067,2018-10-16T22:35:26Z,True,googlefonts_____fontbakery_____2067_____430424978," @chrissimpkins : to be honest, if I haven't known Cosimo for a bit, I would think that @anthrotype is being malicious and shit-stirring and trying to cause trouble, considering that he was in the FontVal development discussion **two days** before I was, and more than **two full years** before Felipe showed up ( read the FAQ https://github.com/HinTak/Font-Validator/wiki/FAQ )  @anthrotype knew full well the answer to his question, **3 years** before he asked it above.",True,True
googlefonts_____fontbakery_____2067,2018-10-17T09:27:36Z,True,googlefonts_____fontbakery_____2067_____430557002,"@HinTak thank you for reviewing this pr. I'll inspect this extension issue later on. I take it you were drinking last night?

I've fixed the build by updating travis to use Hintak's FontValiator Linux binary.

@felipesanches I just need to reread my install instructions and to see if Niko's win installation notes can work for this pr.",True,True
googlefonts_____fontbakery_____2067,2018-10-17T09:50:25Z,True,googlefonts_____fontbakery_____2067_____430564727,"Niko's Win installation instructions work for this PR.

I'll now do a fresh install on Win and test this .exe issue.",True,True
googlefonts_____fontbakery_____2067,2018-10-17T13:33:28Z,True,googlefonts_____fontbakery_____2067_____430629931,"I booted up Win7 and running `FontValidator` instead of `FontValidator.exe` worked just fine.

![screen shot 2018-10-17 at 14 31 43](https://user-images.githubusercontent.com/7525512/47089809-7bedd680-d219-11e8-8654-ed94f519ee6f.png)

I'll update the implementation as @HinTak suggested.",True,True
googlefonts_____fontbakery_____2067,2018-10-17T13:46:32Z,True,googlefonts_____fontbakery_____2067_____430634791,@felipesanches I think we're good. Feel free to review this.,True,True
googlefonts_____fontbakery_____2067,2018-10-17T13:51:19Z,True,googlefonts_____fontbakery_____2067_____225937051,this line can be removed now ,True,True
googlefonts_____fontbakery_____2067,2018-10-17T13:52:38Z,True,googlefonts_____fontbakery_____2067_____225937655,"This other line can also be removed now.
Please delete the `prebuilt/custom_freetype/` directory as well.",True,True
googlefonts_____fontbakery_____2067,2018-10-17T13:56:48Z,True,googlefonts_____fontbakery_____2067_____225939628,Already done in ff807173f5bd1e29e5af07232a79d5031a2b4ae4,True,True
googlefonts_____fontbakery_____2067,2018-10-17T14:02:54Z,True,googlefonts_____fontbakery_____2067_____430641063,@felipesanches I've implemented your suggestions. Thanks and I agree with them.,True,True
googlefonts_____fontbakery_____2067,2018-10-17T14:03:40Z,True,googlefonts_____fontbakery_____2067_____430641333,YAY!!! :-D,True,True
rust-lang_____rfcs_____2544,2018-10-19T01:26:26Z,True,rust-lang_____rfcs_____2544_____431215378,"@Ixrec  

> > > If we had type ascription but not this, we could teach and use the language entirely without turbofish
> > 
> > 
> > Not always. See for example `std::mem::size_of::<T>()`, `Any::is::<T>()`, etc.
> 
> I'm missing something. Wouldn't this RFC allow writing `std::mem::size_of::<T>()` as `std::mem::size_of<T>()`?

Refer back to the text that you quoted: ""If we had type ascription but not this""

",True,True
rust-lang_____rfcs_____2544,2018-10-19T01:51:00Z,True,rust-lang_____rfcs_____2544_____431219292,"@teiesti 

> > I'm not happy with Turbofish either, but between turbofish and the proposed alternative, I prefer turbofish. HOWEVER, if I could change how Rust worked, this is how I'd make type inference work:
> > Functions would be able to have two parameter lists: one for compile time arg (types and const generics), and one for runtime args. So it would look something like this
> > `fn foo(T)(bar: i32) {}`
> 
> The problem with that syntax is a function returning a closure. If you call both at once you end up with `foo(function_arg)(closure_arg)`.

In D you write the definition as `foo(T)(bar: i32)` but the invocation as `foo!(T)(bar)` ... or, for single simple generic arguments `foo!T(bar)`. Or `foo(bar)` if the type can be inferred. Use of generics in D is, IMO, much more pleasant than C++, Rust, or other languages.",True,True
nestjs_____typeorm_____27,2018-10-19T09:05:18Z,True,nestjs_____typeorm_____27_____431296683,"This is the way I do it without any new decorator:
```ts
import { Injectable } from '@nestjs/common';
import { InjectConnection } from '@nestjs/typeorm';
import { Connection, EntitySubscriberInterface, InsertEvent } from 'typeorm';
import { NewNotificationMessage } from '../models';

@Injectable()
export class NewNotificationSubscriber implements EntitySubscriberInterface {

  constructor(
    @InjectConnection() readonly connection: Connection,
  ) {
    connection.subscribers.push(this);
  }

  listenTo() {
    return NewNotificationMessage;
  }

  afterInsert(event: InsertEvent<NewNotificationMessage>) {
    console.log('Hi guys!');
  };

}
```

```ts
// NOTE: TypeORM Subscribers are injected through Nest DI and register themselves with the TypeORM connection
 TypeOrmModule.forRoot({
   ...environment.db,
   entities: [ `${__dirname}/**/models/*.js` ],
   migrations: [ `${__dirname}/migrations/*.js` ],
   migrationsRun: true,
   type: 'postgres'
 }),
```

I thought that I ought to share this simple workaround that I use at the moment.",True,True
nestjs_____typeorm_____27,2018-10-19T09:23:03Z,True,nestjs_____typeorm_____27_____431301658,"Wow, looks nice! ",True,True
rebassjs_____rebass_____515,2018-10-19T22:18:54Z,True,rebassjs_____rebass_____515_____224424205,"In this diff I provided a build script for each package in this monorepo.
The structure looks like this one

```
packages/
  module
    emotion/package.json
    dist/package.json
    dist/index.cjs.js
    dist/index.esm.js
    dist/emotion.cjs.js
    dist/emotion.esm.js
```

Pkg specifies `main` and `module` fields for styled components and for
emotion.",True,True
rebassjs_____rebass_____515,2018-10-19T22:18:58Z,True,rebassjs_____rebass_____515_____431515679,"
This pull request is [automatically deployed](https://zeit.co/docs/features/now-for-github?utm_source=automated&utm_medium=github&utm_campaign=now_bot) with [Now](https://zeit.co/now?utm_source=automated&utm_medium=github&utm_campaign=now_bot).
To access deployments, click Details below or on the icon next to each push.


	",True,True
rebassjs_____rebass_____515,2018-10-19T22:31:20Z,True,rebassjs_____rebass_____515_____431517714,"I'm not sure how to fix deploy error. Travis works fine.
/cc @jxnblk ",True,True
rust-lang_____rfcs_____2544,2018-10-20T11:54:22Z,True,rust-lang_____rfcs_____2544_____431573764,"Oof, I really hate the `foo(T)(bar)` syntax. It has too many nested and sets of parens: `foo(T: AsRef(Vec(T)))(v: T)`. Also, it syntactically conflates type arguments (static) and value arguements (dynamic). IMHO, there should be a distinction.

Personally, I find Scala's syntax with [ ] most pleasant to read, but it's clearly ambiguous in rust. Also, everyone coming from a more common language wonders about all the weird arrays at first... :P",True,True
rebassjs_____rebass_____515,2018-10-20T15:49:48Z,True,rebassjs_____rebass_____515_____431593383,I'd rather hold off on all these build changes until after v3 is released,True,True
rebassjs_____rebass_____515,2018-10-20T15:52:38Z,True,rebassjs_____rebass_____515_____431593573,They may be breaking. It should be landed in v3. What's the problem?,True,True
rebassjs_____rebass_____515,2018-10-20T15:58:51Z,True,rebassjs_____rebass_____515_____431594069,Why would the build process be breaking changes?,True,True
rebassjs_____rebass_____515,2018-10-20T16:00:36Z,True,rebassjs_____rebass_____515_____431594193,"Because the result of build process is different.

Everything should be landed and tested before major release or users will get shit in minor and patches.",True,True
rebassjs_____rebass_____515,2018-10-20T16:01:25Z,True,rebassjs_____rebass_____515_____431594278,This is the point of prereleases.,True,True
rebassjs_____rebass_____517,2018-10-20T17:25:14Z,True,rebassjs_____rebass_____517_____224488893,"- Simplifies the code base by removing subpackages
- Stabilizes the package to be more reliable (fewer moving parts)
- References to components can now be found at [rebassjs/extras](https://github.com/rebassjs/extras)
- Temporarily removes support for emotion until the `as` prop is supported (See https://github.com/emotion-js/emotion/issues/837)
- If you'd like to use Rebass with emotion, I'd recommend forking this repo for the time being.
",True,True
rebassjs_____rebass_____517,2018-10-20T17:25:17Z,True,rebassjs_____rebass_____517_____431601792,"
This pull request is [automatically deployed](https://zeit.co/docs/features/now-for-github?utm_source=automated&utm_medium=github&utm_campaign=now_bot) with [Now](https://zeit.co/now?utm_source=automated&utm_medium=github&utm_campaign=now_bot).
To access deployments, click Details below or on the icon next to each push.


	",True,True
rebassjs_____rebass_____517,2018-10-20T17:26:41Z,True,rebassjs_____rebass_____517_____431601940,"# [Codecov](https://codecov.io/gh/rebassjs/rebass/pull/517?src=pr&el=h1) Report
> Merging [#517](https://codecov.io/gh/rebassjs/rebass/pull/517?src=pr&el=desc) into [master](https://codecov.io/gh/rebassjs/rebass/commit/edb4392e1325412ecf3564544d93c3e71fccc808?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/rebassjs/rebass/pull/517/graphs/tree.svg?width=650&token=H5yQ0WBw7c&height=150&src=pr)](https://codecov.io/gh/rebassjs/rebass/pull/517?src=pr&el=tree)

```diff
@@          Coverage Diff          @@
##           master   #517   +/-   ##
=====================================
  Coverage     100%   100%           
=====================================
  Files           1      1           
  Lines          21     21           
=====================================
  Hits           21     21
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/rebassjs/rebass/pull/517?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/rebassjs/rebass/pull/517?src=pr&el=footer). Last update [edb4392...5ea091b](https://codecov.io/gh/rebassjs/rebass/pull/517?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,True
rebassjs_____rebass_____515,2018-10-20T17:37:38Z,True,rebassjs_____rebass_____515_____431602951,Fuck. Will build my own framework. Contribution to your projects makes me tired.,True,True
rebassjs_____rebass_____517,2018-10-20T17:53:00Z,True,rebassjs_____rebass_____517_____431604156,You just makes things more complex by removing everything over and over again.,True,True
rust-lang_____rfcs_____2544,2018-10-22T03:50:42Z,True,rust-lang_____rfcs_____2544_____431735661,"> Oof, I really hate the `foo(T)(bar)` syntax. It has too many nested and sets of parens: `foo(T: AsRef(Vec(T)))(v: T)`. Also, it syntactically conflates type arguments (static) and value arguements (dynamic). IMHO, there should be a distinction.

We're now quite off topic and I don't really want to put more time into this, but it works quite well in D, perhaps because your criticisms aren't valid. the ""too many parens"" is quite artificial ... no one writes code like that, they use where clauses.  And at the point of invocation, generic arguments are indicated with a !, usually without parens as in convert_to!int(foo) or sort!""a > b""(array). And even in the definition  they aren't ""conflated"" ... the template params are in the first pair of parens and the regular params are in the second pair. (And since D extensively supports and uses compile-time function execution, the static/dynamic distinction isn't so crisp.) Finally, the types of paired brackets are at a premium and Walter didn't want to squander [] on template arguments. It's a design tradeoff, and again it works quite well in D. Anyway it's moot here ... Rust made its bed of thorns and now has to lay in it.
",True,True
rust-lang_____rfcs_____2544,2018-10-22T04:06:33Z,True,rust-lang_____rfcs_____2544_____431736443,"> Oof, I really hate the `foo(T)(bar)` syntax. It has too many nested and sets of parens: `foo(T: AsRef(Vec(T)))(v: T)`. Also, it syntactically conflates type arguments (static) and value arguements (dynamic). IMHO, there should be a distinction.

We're now quite off topic and I don't really want to put more time into this, but it works quite well in D, perhaps because your criticisms aren't valid. the ""too many parens"" is quite artificial ... no one writes code like that, they use where clauses.  And at the point of invocation, generic arguments are indicated with a !, usually without parens as in convert_to!int(foo) or sort!""a > b""(array). And even in the definition  they aren't ""conflated"" ... the template params are in the first pair of parens and the regular params are in the second pair. (And since D extensively supports and uses compile-time function execution, the static/dynamic distinction is isn't so crisp.) Finally, the types of paired brackets are at a premium and Walter didn't want to squander [] on template arguments. It's a design tradeoff, and again it works quite well in D. Anyway it's moot here ... Rust made its bed of thorns and now has to lay in it.
",True,True
rust-lang_____rfcs_____2544,2018-10-22T05:30:09Z,True,rust-lang_____rfcs_____2544_____431743577,"> Oof, I really hate the `foo(T)(bar)` syntax. It has too many nested and sets of parens: `foo(T: AsRef(Vec(T)))(v: T)`. Also, it syntactically conflates type arguments (static) and value arguements (dynamic). IMHO, there should be a distinction.

We're now quite off topic and I don't really want to put more time into this, but it works quite well in D, perhaps because your criticisms aren't valid. the ""too many parens"" is quite artificial ... no one writes code like that, they use where clauses.  And at the point of invocation, generic arguments are indicated with a !, usually without parens as in convert_to!int(foo) or sort!""a > b""(array). And even in the definition  they aren't ""conflated"" ... the template params are in the first pair of parens and the regular params are in the second pair. (And since D extensively supports and uses compile-time function execution, the static/dynamic distinction isn't so crisp.) Finally, the paired brackets are at a premium and Walter didn't want to squander [] on template arguments. It's a design tradeoff, and again it works quite well in D. Anyway it's moot here ... Rust made its bed of thorns and now has to lay in it.
",True,True
rust-lang_____rfcs_____2544,2018-10-22T17:22:26Z,True,rust-lang_____rfcs_____2544_____431904881,"@jibal Fair enough. I could actually show some real examples where I think this might be a problem, but I don't want to derail the thread either. If your interested in discussing further, perhaps we could start an internals thread.",True,True
jupyterhub_____kubespawner_____275,2018-10-23T22:29:45Z,True,jupyterhub_____kubespawner_____275_____225207913,"`image_pull_policy` **defaults**, i.e. gets derived from `image_spec` tag, only when it is not set explicitly!
`image_pull_policy='IfNotPresent'` + `:latest` tag ≠ `image_pull_policy='Always'`. Event `:latest` image won't be pulled if it exists!
If it is desired to have `image_pull_policy` 'dependent' on the tag (as-if it were `'Always'` for `:latest`/omitted tag and `'IfNotPresent'` otherwise), it should be set to `None`, which corresponds to `imagePullPolicy` omission. https://kubernetes.io/docs/concepts/containers/images#updating-images:
> If you would like to always force a pull, you can do one of the following:
> - omit the `imagePullPolicy` and use `:latest` as the tag for the image to use.
> - omit the `imagePullPolicy` and the tag for the image to use.",True,True
jupyterhub_____kubespawner_____275,2018-10-24T05:58:34Z,True,jupyterhub_____kubespawner_____275_____432523141,"Do we want to support a ""not best practice"" of using `latest` as a tag instead of an explicit tag? Using `:latest` in production setups makes it very hard to track which version of the image is actually running and makes it hard to reproduce bugs (even for the same user as the next time they launch their notebook server things might start or stop working because the base image changed).

---

As a point of communication style: calling this a ""fix"" isn't helpful as it implies that the current behaviour is somehow ""broken"". Which might or might not be true. So best to avoid that implying that in order to foster a good discussion.
",True,True
jupyterhub_____kubespawner_____275,2018-10-24T10:03:16Z,True,jupyterhub_____kubespawner_____275_____432595272,"> Do we want to support a ""not best practice"" of using latest as a tag instead of an explicit tag?

Are you serious? The goal of the project should be to correctly reflect the k8s behavior, not to force someone's view on which practice is best.

> As a point of communication style: calling this a ""fix"" isn't helpful as it implies that the current behaviour is somehow ""broken"". 

The `help` message of the traitlet says ""For more information on image pull policy, refer to `the Kubernetes documentation <https://kubernetes.io/docs/concepts/containers/images/>`"", which implies that its intent to reflect the behavior of the `imagePullPolicy` k8s parameter. But omitting `imagePullPolicy` in the .yaml-file and using the `:latest` tag is not the same as using the `:latest` tag and not setting the `image_pull_policy`. So `image_pull_policy` is obviously broken.

> best to avoid that implying that in order to foster a good discussion.

Did you adopt some brain-damaged CoC forbidding calling bugs ""bugs""? How should I call them now? ""Alternatively correct behavior""?",True,True
jupyterhub_____kubespawner_____275,2018-10-24T10:57:06Z,True,jupyterhub_____kubespawner_____275_____432610412,"Thank you for this PR @BerserkerTroll! I did not know about this behavior before and I always appreciate learning more about kubernetes.

**Technical summary based on my understanding:**
Kubespawner is currently always applying a `imagePullPolicy` to the generated pod spec since we have a truthy default value for it (`IfNotPreset`). To supply a default value like this to the pod spec is not a common practice within kubespawner. Typically kubespawner omits details not explicitly configured!

---

I think it makes sense to not specify it in the generated pod spec due to this alone, and especially since the omitting of the pull policy in the pod spec can enable the dynamic behavior as @BerserkerTroll described where the actual pull policy depends on the tag of the image.",True,True
jupyterhub_____kubespawner_____275,2018-10-24T11:18:30Z,True,jupyterhub_____kubespawner_____275_____432616015,">  To supply a default value like this to the pod spec is not a common practice within kubespawner. Typically kubespawner omits details not explicitly configured!

Yes. Even more obvious argument would be that `V1Container` constructor's `image_pull_policy` parameter has the default value `None` (https://github.com/kubernetes-client/python/blob/3fb2be14e18d84edef094bbd908b6bb3e39aafe6/kubernetes/client/models/v1_container.py#L81)
I don't think `KubeSpawner` ever had the intent to supply default config values different from k8s API default values.",True,True
jupyterhub_____kubespawner_____275,2018-10-24T21:33:29Z,True,jupyterhub_____kubespawner_____275_____432836131,"Hi @BerserkerTroll , thanks for your contributions and your thoughts. I'd like to quickly highlight some of the main points of the [Jupyter community Code of Conduct](https://github.com/jupyter/governance/blob/master/conduct/code_of_conduct.md).

* Be friendly and patient.
* Be welcoming.
* Be considerate. 
* Be respectful. 
* Be careful in the words that you choose.

Suggesting the package is broken or suggesting that the project's decisions are ""brain damaged"" is not constructive. Please keep a positive and constructive tone when you engage with this community.",True,True
jupyterhub_____kubespawner_____275,2018-10-24T23:56:58Z,True,jupyterhub_____kubespawner_____275_____432867070,"The funny thing is that this is not the first commit/PR having the ""fix"" word in its title, but it looks like it is the first one (I didn't check all of them) where this word caused such a reaction. So I conclude that the reason is not the word, but me. And the ""F"" word in the title is just a far-fetched reason.",True,True
jupyterhub_____kubespawner_____275,2018-10-25T00:17:10Z,True,jupyterhub_____kubespawner_____275_____432870485,"Sorry you feel that way @BerserkerTroll - to be transparent, these are your comments that raised a flag in my mind:

> Are you serious? The goal of the project should be to correctly reflect the k8s behavior, not to force someone's view on which practice is best.

> Did you adopt some brain-damaged CoC forbidding calling bugs ""bugs""? 

",True,True
jupyterhub_____kubespawner_____275,2018-10-25T03:33:08Z,True,jupyterhub_____kubespawner_____275_____432902668,"Thanks for raising this @choldgraf.

I struggled with this thread, communication in text messages is so extreamly limited and challenging.

I've learned more about myself. I mean to address something similar without fail next time and not become a passive bystander.

:heart:",True,True
jupyterhub_____kubespawner_____275,2018-10-25T06:16:51Z,True,jupyterhub_____kubespawner_____275_____432928108,"Hi folks. I've gone ahead and locked this PR so all can pause communication here for a few days. 

All, this is a gentle reminder to reflect that the written word loses tone and context. Here's a few tips that I recently shared on another project.

> Just a reminder about the difficulty of email negotiation [1]:

> Email negotiations are also fraught with misunderstanding, both because emotion and tone are difficult to convey accurately and because parties neglect to consider the other side’s perspective. Notably, email communicators 1 are largely unaware of their limitations.

> The following tips may help [2]:

> **Stamp out conflict.** When rudeness is encountered, or you are angry, don’t respond immediately and don’t respond in kind. Instead, take a short break, and then contact your counterpart by phone, or email a simple statement of concern and schedule a face-to-face meeting as soon as possible. Conflict with emotional intensity is rarely ever resolved over email.
> **Ask more questions, not less.** There is a tendency to limit your questions over email because it appears tedious. Don’t fall into this trap. To avoid lengthy and exhausting lists, start with broad questions, intersperse phone conversations to discuss the answers, and use shorter emails to group follow-up questions by topic.
> **Keep the climate positive.** Maintain a friendly tone in emails. Interpret e-mail messages with caution and sensitivity, and leave room for personality, style and cultural differences. Make sure to clarify any ambiguities right away. And remember to use generally accepted best practices in email etiquette.

[1] https://www.pon.harvard.edu/daily/conflict-resolution/email-more-cons-than-pros/
[2] https://www.watershedassociates.com/learning-center-item/negotiating-over-email.html ",True,True
nestjs_____typeorm_____27,2018-10-25T09:41:28Z,True,nestjs_____typeorm_____27_____432985114,"The solution posted above by @fwoelffel is really clean and nice. 
I'm going to close this PR now, as we have the solution above.",True,True
selfagency_____microsoft-drop-ice_____345,2018-10-26T04:14:47Z,True,selfagency_____microsoft-drop-ice_____345_____433280842,gotta love when folks who advertise themselves as devout christians hate on refugees,True,True
selfagency_____microsoft-drop-ice_____344,2018-10-26T04:16:16Z,True,selfagency_____microsoft-drop-ice_____344_____433281066,"way to be a piece of 💩 dude
",True,True
rust-lang_____rfcs_____2544,2018-11-03T19:02:45Z,True,rust-lang_____rfcs_____2544_____435612807,"My ideal syntax for non-implicit generic parameters is `size_of(T)`.
That is, like Agda, Idris, Lean, etc. you'd have implicit and explicit parameters, and Rust's current generics would be implicit, unless they cannot be deduced from the signature (e.g. `size_of`).

I think it might even be backwards-compatible to allow both `size_of::<T>()` and `size_of(T)`.",True,True
rust-lang_____rfcs_____2544,2018-11-06T07:30:20Z,True,rust-lang_____rfcs_____2544_____436156511,"I feel this is yet another recipe for disaster. The parser of Rust isn't exactly simple already, and making it do what is basically (even if not *technically*) semantic analysis seems like we are throwing all the benefits of a well-separated parsing and sema phase right out of the window. (Arguably, this is even worse than some of the proposals requiring unbounded lookahead… at least those are all purely about syntax.)

And again, there's the human factor: given that the turbofish serves the purpose of disambiguation, it actually *helps* readers' internal parsers as well. I'm very glad there's some visual indication within an expression to tell me when something is a generic type argument. Losing that indication would actually make code harder to follow.

Please, throw the turbofish back to the pond. It might fulfill three of your wishes once.
",True,True
rust-lang_____rfcs_____2544,2018-11-06T09:50:13Z,True,rust-lang_____rfcs_____2544_____436193369,"> I feel this is yet another recipe for disaster. The parser of Rust isn't exactly simple already, and making it do what is basically (even if not technically) partial semantic analysis seems like we are throwing all the benefits of a well-separated parsing and sema phase right out of the window. (Arguably, this is even worse than some of the proposals requiring unbounded lookahead… at least those are all purely about syntax.)

This is a somewhat common view about syntax and grammars, that I disagree with, and which, dismisses CFGs in favor of some subset thereof, dragging language design along with it.
I think the only reason it has stuck around is because tools kept the limitations and stopped evolving - having to generate C as a prerequisite didn't help anyone either.

We ended up with mostly (E)BNF and various sub-CFG LL and LR variants, which is pretty sad IMO.

An algorithm like GLL (or GLR, if you don't mind your parser being a black box) can easily parse the `<` as both comparison and generic argument start, and allow choosing what to do in case both worked.
In fact, https://github.com/rust-lang-nursery/wg-grammar/pull/13 does just that, as it's *less work* than encoding the current rules (we'll have to do that anyway, but not to start with).",True,True
rust-lang_____rfcs_____2544,2018-11-06T10:04:04Z,True,rust-lang_____rfcs_____2544_____436197670,"> dragging language design along with it

That's a very strong assertion when the price to pay is only the typing of two colons sometimes.

And again, I get that it's technically possible or not even ""difficult"" (for some subjective definition of difficult) to do this. It still doesn't address the concern of readability by people, nor the fact that it's still just a partial solution. To me, that is not worth basically *any* additional complexity. I'm not an LR/LL zealot – I just think that in this case, the merits don't weigh up with the downsides.

Technically, there already exist smallish hacks in the grammar and parser, e.g. lexing `>>` as right shift vs. two closing angle brackets needs feedback from the parser to the lexer and is solved by pushing back half of it (a single `>`) to the list of yet unparsed tokens if it's in a generic type context. It's a very local rule which of which a correct implementation is hard to mess up, almost trivial. In comparison, the turbofish is far from this low level of additional complexity, but the gain is similar (IMO it's even smaller, because it's needed less often than one or more level of nested generic arguments), so the situation is disproportionate.
",True,True
rust-lang_____rfcs_____2544,2018-11-06T10:19:52Z,True,rust-lang_____rfcs_____2544_____436202518,"> That's a very strong assertion

Not anymore than ""recipe for disaster"". There are many hacks in the Rust parser that could've been ""simply"" solved by ""use GLL and keep the grammar simple while not compromising on ergonomics"".

> Technically, there already exist smallish hacks in the grammar and parser, e.g. lexing `>>` as right shift vs. two closing angle brackets needs feedback from the parser to the lexer and is solved by pushing back half of it (a single `>`) to the list of yet unparsed tokens if it's in a generic type context. 

This is a solved problem, you include contextual information (""is this token joined to the next one"") in each token, so `>>` is ""less-than-joined followed by (less-than-joined or less-than-alone)"".
Or if you don't have a separate lexer, you just write `"">>""` in the grammar.
(in the Rust grammar linked above, I also write that, but it gets converted into the token thing)

> nor the fact that it's still just a partial solution

How so? If we wanted, we could remove `::<` from the language (in an edition, that is).
Then `(f<a, b>(c))` could be made unambiguous by writing `((f<a, b>)(c))`.
(not that I necessarily think that's much nicer, but it an option)",True,True
rust-lang_____rfcs_____2544,2018-11-06T12:13:28Z,True,rust-lang_____rfcs_____2544_____436231934,">> nor the fact that it's still just a partial solution
>
> How so? If we wanted, we could remove `::<` from the language (in an edition, that is).
> Then `(f<a, b>(c))` could be made unambiguous by writing `((f<a, b>)(c))`.
> (not that I necessarily think that's much nicer, but it an option)

I think the point is the same I was trying to make above: even for a
human reader, it's easier to *read* with a visual indication that
something is a function vs. that something is a type.

Even if we only consider user-facing ergonomics (and dismiss the
argument I made above about vim's parser being unable to parse this
syntax that hasn't been answered):
 * The `f::<T, U>()` syntax requires a one-time rustc error for someone
   who comes from C++. From then on, it's easy to remember it (I came to
   rust from ~8 years of mostly C++, and followed exactly this path)
 * The `f<T, U>()` is ambiguous for the human reader forever. I have to
   actually use my brain to parse this vs. a comparison, while I'd
   rather have it used to understand the code

Regardless of whether this RFC is implemented, I know I personally won't
allow code without the turbofish to sneak in my projects, for the
reasons cited above. So I'd rather it didn't make it in at all, so that
external tools that don't bind to rustc's parser can continue to support
Rust properly :)
",True,True
rust-lang_____rfcs_____2544,2018-11-06T13:29:13Z,True,rust-lang_____rfcs_____2544_____436252415,"> I think the point is the same I was trying to make above: even for a
human reader, it's easier to *read* with a visual indication that
something is a function vs. that something is a type.

I disagree with this as a universal statement: I don't think it's generally true that removing `::` makes it harder to read. Some people might find it easier to read with `::`, but the converse is also true. Unless there's evidence to suggest this, it comes down as stylistic preference. I definitely prefer the versions without `::`.

> * The `f<T, U>()` is ambiguous for the human reader forever. I have to
   actually use my brain to parse this vs. a comparison, while I'd
   rather have it used to understand the code

It'd be good to have some concrete examples of (non-malicious) code where the result is unintuitive after allowing turbofish to be optional. Considering the naming conventions for types vs variables are different, the examples I've encountered make it obvious which is which.

> so that external tools that don't bind to rustc's parser can continue to support Rust properly :)

Rust's grammar is continually changing. Any language change that modifies the grammar requires every independent parser to be updated. There is no reason to distinguish turbofish over any other such change.",True,True
rust-lang_____rfcs_____2544,2018-11-06T14:25:28Z,True,rust-lang_____rfcs_____2544_____436270079,">> * The `f<T, U>()` is ambiguous for the human reader forever. I have to
>    actually use my brain to parse this vs. a comparison, while I'd
>    rather have it used to understand the code
>
> It'd be good to have some concrete examples of (non-malicious) code
> where the result is unintuitive after allowing turbofish to be
> optional. Considering the naming conventions for types vs variables
> are different, the examples I've encountered make it obvious which is
> which.


The following code is an example:
```rust
if f<T, U>() {
   foo()
}
```

It is not unintuitive after having thought about it, but when I read it,
it took me a half-second to read `f<T` then fallback to “oh no it's a
function call” when I read the rest.

And the more complex the example, the more likely confusion will likely
come.

By the way, you yourself mention “(non-malicious)”. Underhanded C
contests exist for a reason: preventing introduction of backdoors by
attackers who may even be crate authors trying to escape reviews. I
don't think adding possibilities for underhanded Rust would be a good
thing. Thank you for this argument, I hadn't thought about it :)

>> so that external tools that don't bind to rustc's parser can continue
>> to support Rust properly :)
>
> Rust's grammar is continually changing. Any language change that
> modifies the grammar requires every independent parser to be
> updated. There is no reason to distinguish turbofish over any other
> such change.

One reason is that Rust is still in a class of grammars that can be
parsed by most parsers, while the proposed change would take it out of
it (case in mind: vim's syntax highlighter).

This is a choice that can be made, for sure. But for something that
brings little-to-negative benefit? As you say yourself,

> it comes down as stylistic preference

Should Rust, for a stylistic preference and a one-time error for people
who come from C++ background, ban a whole range of external parsers and
increase the potential for underhanded Rust?

If you think that yes, then I guess our priorities aren't in match, and
we aren't going to agree anyway :)

BTW, I'm sorry if I missed an argument for which no-turbofish would
help! I put all I could remember.
",True,True
rust-lang_____rfcs_____2544,2018-11-06T14:32:58Z,True,rust-lang_____rfcs_____2544_____436272710,"> It is not unintuitive after having thought about it, but when I read it,
it took me a half-second to read `f<T` then fallback to “oh no it's a
function call” when I read the rest.

The first clue is the lack of spaces around `<`, the second clue is the `>` (which I ""read"" the same time as the `<`, it takes effort to not take in the whole line at once).

> One reason is that Rust is still in a class of grammars that can be
parsed by most parsers, while the proposed change would take it out of
it (case in mind: vim's syntax highlighter).

I think that's something interesting for @rust-lang/wg-grammar to compile information about: what are the inherent limitations of all the tools expected to parse Rust?
And do we want to limit ourselves to that, or switch to ""CFG modulo raw strings""?

(not that I think a non-full-language-plugin syntax highlighter should parse a language, or do anything other than basic lexing, but that's another thing)",True,True
rust-lang_____rfcs_____2544,2018-11-06T16:15:30Z,True,rust-lang_____rfcs_____2544_____436311434,"> 
> 
> > how hard IDE support for this would be.
> 
> Not a problem at all.

For what IDE? Clearly vim would have problems, so this blanket claim is false even for the parsers already mentioned, and others could have problems as well. I know that when I edit C# code with emacs, it frequently gets confused by `<` and `>` in expressions and thinks there's a bracket mismatch.

Rust's grammar was constrained for a reason -- ease of unambiguous parsing. That reason is being ignored here. It's unfortunate that, because of the choice of `<>` to bracket generic parameters, the Rust grammar would be ambiguous without the turbofish, but it is, and it would be a serious mistake to remove the wisely placed constraint on the grammar to avoid something that rarely occurs and is really no big deal when it does.",True,True
rust-lang_____rfcs_____2544,2018-11-06T16:18:35Z,True,rust-lang_____rfcs_____2544_____436312595,"> There is no reason to distinguish turbofish over any other such change.

This is false, as has been repeatedly noted.",True,True
rust-lang_____rfcs_____2544,2018-11-06T17:39:55Z,True,rust-lang_____rfcs_____2544_____436341820,"> I think that's something interesting for @rust-lang/wg-grammar to compile information about: what are the inherent limitations of all the tools expected to parse Rust?

I work on the syntax highlighting for Sublime, which uses a stack-based regex system similar to TextMate highlighting.  Generally it's very limited, and lives in a realm between strict lexing and full parsing.  There are significant difficulties dealing with angles in paths versus less-than/greater-than symbols, and currently the highlighting gets confused by qualified paths.  Currently it assumes you don't put spaces in paths to decide between generic args and comparison.  It's not pretty and has issues, and something I've been ignoring due to the difficulty of fixing.  Of all rust syntax, angle brackets cause me some of the greatest difficulty highlighting properly.  However, I don't think this RFC would affect Sublime's highlighting right now because it doesn't treat turbofish specially, but it probably should.  
",True,True
rust-lang_____rfcs_____2544,2018-11-06T19:13:28Z,True,rust-lang_____rfcs_____2544_____436373232,"@jibal @ehuss I keep being surprised by this, because I've only used editors which have regex-based syntax highlighting and don't really need to tell apart expressions from types.
Whereas I consider full IDE support for a language (e.g. through a plugin talking to a language server) separate, and in that case the language plugin can provide *semantic* highlighting.",True,True
rust-lang_____rfcs_____2544,2018-11-06T19:48:31Z,True,rust-lang_____rfcs_____2544_____436384831,"> 
> 
> @jibal @ehuss I keep being surprised by this, because I've only used editors which have regex-based syntax highlighting and don't really need to tell apart expressions from types.
> Whereas I consider full IDE support for a language (e.g. through a plugin talking to a language server) separate, and in that case the language plugin can provide _semantic_ highlighting.

Editors do need to tell expressions from types, if they color them differently. And again, editors do bracket matching, and so they need to distinguish a `<` or `>` that needs to be matched from one that doesn't. People will get surprised by their erroneous assumptions, and the programmer's experience will suffer from it.",True,True
rust-lang_____rfcs_____2544,2018-11-06T20:07:28Z,True,rust-lang_____rfcs_____2544_____436390745,"> The first clue is the lack of spaces around `<`

Please don't use that argument in a language where whitespace around operators doesn't make a semantic difference. You can *very* realistically come across ill-formatted/non-formatted code (or, God forbid, even code with different conventions than you are used to!), so readers shouldn't be required to rely on such a fragile dimension of the code.
",True,True
rust-lang_____rfcs_____2544,2018-11-06T20:10:07Z,True,rust-lang_____rfcs_____2544_____436391571,"> For what IDE? Clearly vim would have problems, so this blanket claim is false even for the parsers already mentioned, and others could have problems as well. I know that when I edit C# code with emacs, it frequently gets confused by < and > in expressions and thinks there's a bracket mismatch.

Doesn't C++ have the same problem? I don't recall ever running into this, and I use vim for everything. That said, I would like to be 100% sure that no problems will arise in this aspect. I would be extremely unhappy if this RFC causes me to not be able to use vim.",True,True
rust-lang_____rfcs_____2544,2018-11-06T20:18:10Z,True,rust-lang_____rfcs_____2544_____436394047,"> Doesn't C++ have the same problem?

Possibly, but I don't write much C++. And there are far more emacs users who edit C++ than C# and have been doing so longer, so the emacs parser for C++ has probably had a lot more work on it. I don't use vim so I have no relevant experience with it.

> I don't recall ever running into this, and I use vim for everything. That said, I would like to be 100% sure that no problems will arise in this aspect. I would be extremely unhappy if this RFC causes me to not be able to use vim.

I use emacs even with the parsing problem ... I just have to revert the buffer when it gets confused.  But ""not being able to use"" is far too high a bar ... ""doesn't always do the right thing"" is already inadequate, and fails your ""100% sure"". And it isn't a matter of what you or I have encountered or can tolerate, it's the effect on the whole universe of Rust users. I think this is a risky change with very little payoff ... and others above have made this point in more detail.",True,True
rust-lang_____rfcs_____2544,2018-11-06T20:52:13Z,True,rust-lang_____rfcs_____2544_____436404172,"> The first clue is the lack of spaces around `<`

Note that the ""official"" Rust style has no space before `<` but *can* have space after it, similar to `(`, when the list of generic arguments needs to be split into multiple lines.",True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T20:46:35Z,True,Metastruct_____garrysmod-chatsounds_____186_____229503090,,True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:13:26Z,True,Metastruct_____garrysmod-chatsounds_____186_____437157903,Why is this needed??,True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:16:40Z,True,Metastruct_____garrysmod-chatsounds_____186_____437158897,"In my eyes, it is not.",True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:16:53Z,True,Metastruct_____garrysmod-chatsounds_____186_____437158965,????,True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:20:28Z,True,Metastruct_____garrysmod-chatsounds_____186_____437159968,Seems pointless - but there is no reason to not have it? *shrug*,True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:31:44Z,True,Metastruct_____garrysmod-chatsounds_____186_____232068103,Weapons policy???,True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:35:30Z,True,Metastruct_____garrysmod-chatsounds_____186_____437164390,stop using a template CoC and doing this meme for something completely irrelevant,True,True
Metastruct_____garrysmod-chatsounds_____186,2018-11-08T21:39:38Z,True,Metastruct_____garrysmod-chatsounds_____186_____437165589,Well this meme is boring already,True,True
awesomeWM_____awesome_____2477,2018-11-10T20:32:47Z,True,awesomeWM_____awesome_____2477_____229911761,"As per https://github.com/awesomeWM/awesome/issues/2476

Several methods...
  set_markup
  set_text
  set_ellipsize
  set_wrap
  set_valign
  set_align
  set_font",True,True
awesomeWM_____awesome_____2477,2018-11-10T20:40:04Z,True,awesomeWM_____awesome_____2477_____437619679,"# [Codecov](https://codecov.io/gh/awesomeWM/awesome/pull/2477?src=pr&el=h1) Report
> Merging [#2477](https://codecov.io/gh/awesomeWM/awesome/pull/2477?src=pr&el=desc) into [master](https://codecov.io/gh/awesomeWM/awesome/commit/6cdd737c4a4fbf4b8702432dc420529e26b1174b?src=pr&el=desc) will **increase** coverage by `<.01%`.
> The diff coverage is `100%`.

```diff
@@            Coverage Diff             @@
##           master    #2477      +/-   ##
==========================================
+ Coverage    84.2%   84.21%   +<.01%     
==========================================
  Files         479      479              
  Lines       33211    33218       +7     
==========================================
+ Hits        27966    27973       +7     
  Misses       5245     5245
```

| Flag | Coverage Δ | |
|---|---|---|
| #c_code | `72.71% <ø> (ø)` | :arrow_up: |
| #functionaltests | `72.71% <100%> (ø)` | :arrow_up: |
| #lua53 | `87.33% <100%> (ø)` | :arrow_up: |
| #samples | `71.18% <100%> (+0.01%)` | :arrow_up: |
| #unittests | `58.2% <100%> (+0.03%)` | :arrow_up: |

| [Impacted Files](https://codecov.io/gh/awesomeWM/awesome/pull/2477?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [lib/wibox/widget/textbox.lua](https://codecov.io/gh/awesomeWM/awesome/pull/2477/diff?src=pr&el=tree#diff-bGliL3dpYm94L3dpZGdldC90ZXh0Ym94Lmx1YQ==) | `93.95% <100%> (+0.29%)` | :arrow_up: |
",True,True
awesomeWM_____awesome_____2477,2018-11-10T21:02:06Z,True,awesomeWM_____awesome_____2477_____437621008,"The official way to access those fields is using the property like `my_textbox.markup = ""<b>Awesome!</b>""`. I get that you are trying to allow daisy chaining setters, but that both undocumented, undocumentable and the only module that would allow such construct.

So, why is this an improvement? I mean, if everything in Awesome was patched to support this and it was enforced but some linting or meta tests, I guess it would be fine-ish, even if a little intrusive change. However this brings the corner case where a setter has to return an error code or a boolean confirmation. In that case you would have daisy-chainable setters mixed with error returning setters and it would be very confusing. In that case, it means every property would need to be documented whether or not it allows daisy-chaining. Yet the documentation barely mention the explicit setter exist at all (on purpose).

I am not rejecting this PR, but again this needs more discussion and a plan for testing and consistency across the whole API. I don't see this as an improvement, but that may just be that my coding style isn't compatible with it and all the new kids program this way due to some web framework and I am old. That's not a logical argument, so lets keep this focused on facts rather than personal preferences.",True,True
awesomeWM_____awesome_____2477,2018-11-10T22:01:22Z,True,awesomeWM_____awesome_____2477_____437624710,"The reason I found this is I tried...

    local textbox = wibox.widget.textbox( ""Hi"" ):set_font( font )

Why did I try it...

    It is, dare I say, normal (the whole lua stirng library?) 

What would I rather have in my code...

    local textbox = wibox.widget.textbox( ""Hi"" ):set_font( font )

_or_

    local textbox = wibox.widget.textbox( ""Hi"" )
    textbox:set_font( font )
",True,True
awesomeWM_____awesome_____2477,2018-11-10T22:10:39Z,True,awesomeWM_____awesome_____2477_____437625380,"As to the bigger picture...

Setters that need to return a value...

    My 2c = Don't expose them _or_ don't call them ""set_""

Are your right again - there definitely are more cases [two methods I didn't touch didn't start with set / both seemed impossible to find in the doco.] 

On to documentation - The more the merrier - I know it's a pain for the developer, but it helps the user and I can categorically state that it needs consistency (read the code is what I'm doing and you know what that means ;-)
",True,True
awesomeWM_____awesome_____2477,2018-11-11T00:05:37Z,True,awesomeWM_____awesome_____2477_____437631912,"Just found a condition I really could do with a return value...

_ = state and widget:set_fg( fg_normal ) or widget:set_fg( fg_focus )

not possible without a return value",True,True
awesomeWM_____awesome_____2477,2018-11-11T01:08:12Z,True,awesomeWM_____awesome_____2477_____437634991,"> _ = state and widget:set_fg( fg_normal ) or widget:set_fg( fg_focus )

    widget.fg = state and fg_normal or fg_focus

Plus it even allows to do

    widget.fg = state and fg_focus or widget.fg

and

    widget1.fg, widget2.fg = fg_focus, fg_focus

> local textbox = wibox.widget.textbox( ""Hi"" ):set_font( font )

The newer widgets use an `args` Lua format so you can do

    local s = wibox.widget.separator {
        thickness = 42,
        color     = ""#ff0000""
    }

Which is Lua (and to some extent Python) official way to use named parameters. It is both cleaner and more consistent. More and more widgets are ported to this syntax in every release. The `textbox` will eventually get there. Otherwise the alternative syntax is already supported for the textbox:

    local s = wibox.widget {
        text   = ""foo"",
        fg     = ""#ff0000"",
        widget = wibox.widget.textbox 
    }

Daisy chaining like you propose is a JavaScript hack for a misguided programing language.


> On to documentation - The more the merrier - I know it's a pain for the developer, but it helps the user and I can categorically state that it needs consistency (read the code is what I'm doing and you know what that means ;-)

Our documentation has an enormous time investment in it. It also have been rewritten some time ago to make things consistent. The fact that getters and setters are not documented is because they were **removed** from the documentation. Other other components such as the widget private variable and ""interface"" methods such as `draw` have also been removed. This was done on purpose to focus on the property driven API.",True,True
awesomeWM_____awesome_____2477,2018-11-11T02:21:19Z,True,awesomeWM_____awesome_____2477_____437637940,"I tried for half the night to do this...
widget.fg = state and fg_normal or fg_focus

only success was when I found the ""set_""

Hence why I asked the question - what do you thin of this... Uli was not concerned so I put it forward with justifications 

Not going to debate languages or styles - just what I've experienced",True,True
awesomeWM_____awesome_____2477,2018-11-11T02:24:51Z,True,awesomeWM_____awesome_____2477_____437638084,"> only success was when I found the ""set_""

Any self contained example of this? It is used in thousand of places in the code and works",True,True
awesomeWM_____awesome_____2477,2018-11-11T04:18:05Z,True,awesomeWM_____awesome_____2477_____437642587,"I could very well be doing it wrong...

a) Don't believe textboxes have this anyway
	local textbox = wibox.widget.textbox( ""?"" )
	textbox:bg = ""#FFFFFF""

b) Seems to me the properties are protected 
function background:set_bg(bg)
    if bg then
        self._private.background = color(bg)
    else
        self._private.background = nil
    end
    self:emit_signal(""widget::redraw_needed"")
    return self
end

Either way - As you noted at the start, your not for or against (back then at least) - lets see what a few days thought has on it

Gotta fly (literally) - will check in in a couple",True,True
awesomeWM_____awesome_____2477,2018-11-11T06:51:33Z,True,awesomeWM_____awesome_____2477_____437647919,"    textbox.bg = ""#FFFFFF""",True,True
awesomeWM_____awesome_____2477,2018-11-11T18:54:52Z,True,awesomeWM_____awesome_____2477_____437694885,i think if you want quick way to set multiple values i am agree with @Elv13 what using `args` as in new widgets will be more consistent for the API (even despite the fact it will require more lines of code to implement than the proposed change),True,True
awesomeWM_____awesome_____2477,2018-11-12T01:06:50Z,True,awesomeWM_____awesome_____2477_____437723562,Hey - don't be so quick to close this - Lots of advantages and too many current shortcomings - please open your mind and listen to others,True,True
awesomeWM_____awesome_____2477,2018-11-12T01:31:32Z,True,awesomeWM_____awesome_____2477_____437726170,"> Lots of advantages

You will have to make your point very clear on this. So far what you said about this is mostly:

 * I used a web framework where this is supported
 * Strings allow immutable chains, so I propose adding a mutable chain (a well known anti-pattern)
 * I tried the property syntax but made a typo and it didn't work
 * It adds a third incompatible syntax to add many properties in the constructor
 * It allows expressions, even though the property syntax also does

Sorry, but it's not very convincing.

> too many current shortcomings

How would you address those shortcomings? So far they seems pretty much insurmountable to me. Keep in mind that there is a rather large maintenance cost associated with ""alternate ways"" to do everything. Currently me and @actionless agree that the property attribute and named property based constructor are the future we want to converge toward. Since 3.5, a large body of work ( > 10000 lines of patch) has been invested into cleaning up the API to bring consistency. All those things in the ""deprecated"" section of the doc come from that project. My vision of the future and the code I submitted to make it happen is getting closer to a property driven declarative programming syntax where you express the intent rather than the mechanics. This is what QML, CSS and SQL languages provide and I see it as a good fit for something very domain-specific like a window manager.

What you propose here goes backward toward the more inconsistent imperative APIs we had in the past. The second large challenge of what you propose is that it cannot exist in a void. It would have to be done with *everything* and enforced against regression introduced by new contribution in the CI system. This would be yet another maintenance heavy subsystem. ",True,True
awesomeWM_____awesome_____2477,2018-11-12T04:08:01Z,True,awesomeWM_____awesome_____2477_____437747311,"You started out by saying ""That's not a logical argument, so lets keep this focused on facts rather than personal preferences."" then soon degenerated into """"a JavaScript **hack** for a **misguided** programing language"" and now you refer to it as ""I used **a web framework**"" - Wow - I'm not trying to be rude (and if I've comes across that way I apologize) but you seem to be getting just plain nasty. 

You must think I'm active here just to make your time miserable - Far from it - As a recovered user (from back in 2012? on the old mailing list) I finally migrating into 4.2 and I'm reliving the ""new user"" experience and just sharing my learning / insights - maybe not in the way you'd like, / maybe a bit critical (particularly of the documentation) - If you take that personally - again - I apologize

I'm going to answer your allegations...

- I used a web framework where this is supported
    Never said / didn't mean that - Malicious? / Unrelated? -  Ignored
- Strings allow immutable chains, so I propose adding a mutable chain (a well known anti-pattern)
    I don't even get this - immutable chain is a Java name for a common OO technique
    Strings was just the first example that leapt to mind - maths is another
    mutable chain & anti-pattern / don't get that / Malicious? / Unrelated? -  Ignored
- I tried the property syntax but made a typo and it didn't work
    I didn't keep the actual code I used as it didn't work...
    I made the typo on the web page trying to give you an example 
    Malicious? / Sarcastic? / Unrelated? -  Ignored
- It adds a third incompatible syntax to add many properties in the constructor
    Not quite what you mean here - adds? ""set_ and ""get_"" exist!
    incompatible syntax / constructor?
- It allows expressions, even though the property syntax also does
    Property system is ok if it is there and works - I had a lot of trouble with it and fount the ""set_"" AOK

_insurmountable shortcomings?_ Unfortunately I read the above as mostly a malicious ramble - I'm just a bit slow at taking the hint?

_maintenance cost?_ Now this is a good discussion point - I  don't see having ""set_"" functions return themselves as being a major maintenance cost, - sure no change = less work than change - you may be able to explain it in more detail?

_""alternate ways"" to do everything_ - The ""set_"" & ""get_"" are already there - If I was asking to add them, then sure - it would be an alternative way - Having a return value / allowing it to chain is just an extension

_Currently me and @actionless agree that the property attribute_ - No problem with that - I had trouble and found (NOT invented) something that worked and offered what I see as a minor enhancement

_named property based constructor are the future_ - I'm guessing this falls into the same old argument I here about every suggestion : ""future plans""

_All those things in the ""deprecated"" section of the doc come from that project. My vision of the future and the code I submitted to make it happen_ - That's great - Well done - I actually appreciate it - Hope you keep up the good work - Wonder it there are others out there trying to help? 

_is getting closer to a property driven declarative programming syntax where you express the intent rather than the mechanics. This is what QML, CSS and SQL languages provide and I see it as a good fit for something very domain-specific like a window manager_ - Hmmm OO programming???

_What you propose here goes backward toward the more inconsistent imperative APIs we had in the past_ - How - ""_set"" already exists - Should I raise a PR removing it claiming that the property exists and the ""get_"" and ""set_ should NOT exist at all? - Should I raise a PR removing all property access as the ""args"" that @actionless espouses exist? Yes those were me being meant sarcastic

_The second large challenge of what you propose is that it cannot exist in a void._ - It already does - Limits can be put in place, much like you are doing now

_It would have to be done with everything and enforced against regression introduced by new contribution in the CI system. This would be yet another maintenance heavy subsystem_. - As before limits / details

.........................

I can't paste my actual code here as I'm travelling, but the gist of it was...

My first choice...

> create_object( limited_properties_here ):set_property( here):modify_behaviour( new )

Vs 

My second choice...

> create_object( limited_properties_here, PR for additional_previously _overlooked_property )

Vs

My third choice...

> create_object( limited_properties_here )
> object:set_property( here)
> object:modify_behaviour( new )

.........................

I still have no idea about the properties - From what I saw in whichever module section I was in [base?container?], the code I see seems s to have them nested under a ""_private"" which to me confirms why I could do what I tried and then... oh look - a ""set_"" and ""get_'
",True,True
awesomeWM_____awesome_____2477,2018-11-12T05:23:41Z,True,awesomeWM_____awesome_____2477_____437760269,">  I'm guessing this falls into the same old argument I here about every suggestion : ""future plans""

that's why i was suggesting you to start your contributions with the actual bugfixes so you will have more time to get familiar with the approaches used across the codebase instead of doing fast judgement based on particular code samples and so could better guess how new (""planned"") things could look like",True,True
awesomeWM_____awesome_____2477,2018-11-12T06:38:42Z,True,awesomeWM_____awesome_____2477_____437772686,that goes against the point of sharing learnings and assumes you two are the font of all wisdom,True,True
awesomeWM_____awesome_____2477,2018-11-12T07:19:43Z,True,awesomeWM_____awesome_____2477_____437780798,"LOL, i can recognize that abusive SJW vocabulary",True,True
awesomeWM_____awesome_____2477,2018-11-12T07:38:09Z,True,awesomeWM_____awesome_____2477_____437784377,instead of continuing this pointless argument please see how properties are implemented in newer widgets: https://github.com/awesomeWM/awesome/blob/master/lib/wibox/widget/progressbar.lua#L408-L417  and `args` handling: https://github.com/awesomeWM/awesome/blob/master/lib/wibox/widget/progressbar.lua#L436-L437,True,True
php-fig_____fig-standards_____1120,2018-11-20T18:20:00Z,True,php-fig_____fig-standards_____1120_____232415577,,True,True
php-fig_____fig-standards_____1120,2018-11-20T18:22:46Z,True,php-fig_____fig-standards_____1120_____440379932,Why this change? ,True,True
php-fig_____fig-standards_____1120,2018-11-20T18:43:27Z,True,php-fig_____fig-standards_____1120_____440386436,What's the reasoning here?,True,True
php-fig_____fig-standards_____1120,2018-11-20T19:31:37Z,True,php-fig_____fig-standards_____1120_____440401748,@drupol @Jan0707 Fabien explained the reasons in this Twitter thread: https://twitter.com/fabpot/status/1064946698089365505,True,True
php-fig_____fig-standards_____1120,2018-11-20T19:52:46Z,True,php-fig_____fig-standards_____1120_____440408210,"I don't understand you here @fabpot: in which case(s) removing Symfony project from PHP Fig will help the interoperability and PHP standards in the future? 

Do we want to come back 6 years ago with custom autoloading, custom coding styles and custom ways to do everything ?",True,True
php-fig_____fig-standards_____1120,2018-11-20T20:32:18Z,True,php-fig_____fig-standards_____1120_____440419516,"> Do we want to come back 6 years ago with custom autoloading, custom coding styles and custom ways to do everything ?

Is this really about autoloading and coding style? Because Fabien's thread is clear about this: they both are great PSRs, it's mostly the ""new wave of incoming PSRs"" that's not interop and kinda breaks the initial project into a more opinionated set of rules instead of an interop one
",True,True
php-fig_____fig-standards_____1120,2018-11-20T21:02:59Z,True,php-fig_____fig-standards_____1120_____440428433,"@fabpot is completely correct, on all points. And to his point about PSR-7 specifically, there's actually an inherent security flaw in its design pertaining to file uploads. I tried to alert the FIG to it some years ago, but given that they [deliberately hide the GitHub issues feature from the repository](https://github.com/php-fig/http-message), I took it as a strong indicator that they don't want to know.",True,True
php-fig_____fig-standards_____1120,2018-11-20T21:10:25Z,True,php-fig_____fig-standards_____1120_____440430577,This isn't a place for this discussion. Please use the mailing list.,True,True
mysqljs_____mysql_____1962,2018-11-26T10:11:26Z,True,mysqljs_____mysql_____1962_____441585562,"Hi all,
Thanks for your effort!
But please merge this PR. It's been around 8 months that we have this compatibility issue with mysql 8.
Thanks 🎉",True,True
GibbonEdu_____core_____742,2018-11-29T23:19:32Z,True,GibbonEdu_____core_____742_____234820290,"## Security Robot IP Check at Login
This feature is design to identify machines by IP address that have attempted more that 3 login (failures) within the last 20 minutes and ignore that IP Address for a maximum of 20 minutes.

The system Admin is able to whilte list IP addresses on the System Admin Setting page (Misc Section) using unique IP, subnet or partial IP addresses in a standard comma separated list. e.g 127.0.0.1, 172.16.0 and 192.168.1.1/24 are all valid. Invalid entries are ignored.

127.0.0.1 matches 127.0.0.1
172.16.0 matches 172.16.0.x
192.168.1.1.24 matches 192.168.1.x (this does a bit wise test, so 192.168.1.1/28 would match 16 machines. (Actually 15, due to match all requests on the network.)

### How was this tested?
Tested Both Locally and on Travis",True,True
GibbonEdu_____core_____742,2018-11-30T05:51:52Z,True,GibbonEdu_____core_____742_____443099180,"Thanks for putting this together. I notice you've introduced some new Manager classes which interact directly with the database. We've been structuring queries using Gateway classes, as these can be easily instantiated with the DI container, and help separate SQL code out of the page into a more reusable location. I find the tendency with Manager classes is they often end up breaking the goal of single responsibility, and become a catch-all for assorted domain logic.

In this case, there doesn't appear to be a gibbonLog or gibbonSettings gateway yet: you'd be welcome to add them, or I'd be happy to push them to your branch, let me know.",True,True
GibbonEdu_____core_____742,2018-11-30T06:02:44Z,True,GibbonEdu_____core_____742_____443100947,"I would find problem the same with Gateways,  but it is only a name, so I
will not mind.  The trick here is ONE manager PER entity.  The Gateway
functionality would be the Repository for the entity..., so it already
exist with another different name.  These are defined in the entity dcm.yml
files so that doctrine knows how to handle the fields in a table in a
database.
Looking ahead, The manager (gateway) is a single class injector that has
the entity and the repository imbedded and ready to go.  The manager does
embed a trait of standard methods to shortcut common calls such as find,
findBy, findOneBy, and others.
 Anyway, as you decide..
------------------------------------------
I greet you with the great words,
Grace and Peace

Craig Rayner
craig@craigrayner.com
Mobile: +61 456 560 018


On Fri, 30 Nov 2018 at 16:51, Sandra Kuipers <notifications@github.com>
wrote:

> Thanks for putting this together. I notice you've introduced some new
> Manager classes which interact directly with the database. We've been
> structuring queries using Gateway classes, as these can be easily
> instantiated with the DI container, and help separate SQL code out of the
> page into a more reusable location. I find the tendency with Manager
> classes is they often end up breaking the goal of single responsibility,
> and become a catch-all for assorted domain logic.
>
> In this case, there doesn't appear to be a gibbonLog or gibbonSettings
> gateway yet: you'd be welcome to add them, or I'd be happy to push them to
> your branch, let me know.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/GibbonEdu/core/pull/742#issuecomment-443099180>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AA4FqS-5plbkU2tsiWzuSMjyL8qf3iuaks5u0Md5gaJpZM4Y6tNB>
> .
>
",True,True
php-fig_____fig-standards_____1120,2018-12-10T14:26:31Z,True,php-fig_____fig-standards_____1120_____445833348,Merged in 2e54756b87e895bf4e5238beafa0e20a36bad9d3 but github seems to be having issues,True,True
nestjs_____typeorm_____27,2018-12-14T13:08:35Z,True,nestjs_____typeorm_____27_____447320281,"It's gets worked for me, when i've added one more parameter **subscribers** to configuration object, or to ormconfig.json:
```
{
    ""type"": ""postgres"",
    ""host"": ""host"",
    ""port"": 5432,
    ""username"": ""databaseUser"",
    ""password"": ""databasePassword"",
    ""database"": ""databaseName"",
    ""entities"": [""src/**/**.entity.ts""],
    ""subscribers"": [""src/**/**.subscriber.ts""],
    ""synchronize"": ""true""
}
```

Subscriber code: 
src/subscribers/datetime.subscriber.ts
```
import { EventSubscriber, EntitySubscriberInterface, InsertEvent, UpdateEvent } from 'typeorm';
import { Injectable } from '@nestjs/common';
import { User } from '../../users/entity/user.entity';

@EventSubscriber()
@Injectable()
export class DateTimeUpdateSubscriber implements EntitySubscriberInterface<User> {
    beforeInsert(event: InsertEvent<User>) {
        console.log(`BEFORE ENTITY INSERTED: `, event.entity);
    }
    beforeUpdate(event: UpdateEvent<User>) {
        console.log(`BEFORE ENTITY UPDATED: `, event.entity);
    }
}
```

```
[System Information]
OS Version     : macOS
NodeJS Version : v11.4.0
YARN Version    : 1.12.3
[Nest Information]
typeorm version  : 5.2.2
common version   : 5.4.0
core version     : 5.4.0
```",True,True
nestjs_____typeorm_____27,2018-12-14T13:17:07Z,True,nestjs_____typeorm_____27_____447322472,@whereiamagain Why do you decorate it as `Injectable` and `EventSubscriber`? ,True,True
nestjs_____typeorm_____27,2018-12-14T13:19:16Z,True,nestjs_____typeorm_____27_____447323091,"> @whereiamagain Why do you decorate it as `Injectable` and `EventSubscriber`?
Oh, my mess, will update code, it's not needed, indeed.",True,True
nestjs_____typeorm_____27,2018-12-14T13:24:21Z,True,nestjs_____typeorm_____27_____447324434,@whereiamagain the issue here is how to inject Nest components into your subscriber ;),True,True
nestjs_____typeorm_____27,2018-12-14T13:29:20Z,True,nestjs_____typeorm_____27_____447325682,"> @whereiamagain the issue here is how to inject Nest components into your subscriber ;)

I know, but anyway, i wasn't able to find any examples with typeorm subscribers in docs, and i guess my stuff might be useful for someone like me ;)",True,True
mate-desktop_____marco_____437,2018-12-15T23:21:43Z,True,mate-desktop_____marco_____437_____238937614,"#364  
most fucked-up code i've ever seen",True,True
mate-desktop_____marco_____437,2018-12-15T23:26:45Z,True,mate-desktop_____marco_____437_____447605284,"> most fucked-up code i've ever seen

You speak about your own code in your pull request, right?",True,True
mate-desktop_____marco_____437,2018-12-16T01:18:46Z,True,mate-desktop_____marco_____437_____447610178,yeah someone like you had cut off subwindows in xevents ,True,True
mate-desktop_____marco_____437,2018-12-16T01:45:05Z,True,mate-desktop_____marco_____437_____447611163,"You speak about others code, while yours literally are worst contribution I have seen for modules I follow here...

- Useless commit message
- Commented out function call without any explanation
- There are many unrelated changes / diff
- Useless many new empty newlines
- Code does not follow coding style used in marco
- `struct t`? `gpointer b`? very meaningful... 

So yeah you have very fucked-up contribution, so fucked-up that it does not even deserve functional review. But you are lucky... I am not maintainer here.",True,True
mate-desktop_____marco_____437,2018-12-16T08:32:08Z,True,mate-desktop_____marco_____437_____447625939,"Sorry, i don't review PRs with coding style issues any more.",True,True
mate-desktop_____marco_____437,2018-12-16T11:27:26Z,True,mate-desktop_____marco_____437_____447635636,"with or without var names you've a little chances to understand what it does for if you didn't try to make it yourself. see how it works first , it's not for review for now .

",True,True
mate-desktop_____marco_____437,2018-12-16T11:33:09Z,True,mate-desktop_____marco_____437_____447635928,"> it's not for review for now .

Then why did you open pull request? Put `WIP:` or something so others don't waste time...",True,True
mate-desktop_____marco_____437,2018-12-16T11:44:22Z,True,mate-desktop_____marco_____437_____447636513,@alexeyneu - what is this supposed to do? Would you mind adding a description so that others can understand what this code does?,True,True
mate-desktop_____marco_____437,2018-12-16T17:31:24Z,True,mate-desktop_____marco_____437_____447661081,"so there i've removed  stopfilter out of  gtk-proof unit . 
https://github.com/mate-desktop/marco/blob/8a2babd269066fc0a79f4bc05a07ce137567b907/src/ui/ui.c#L225  
Now gdk filter deployed by switch-handler could see mouse , really synthetic events produced by filter chain to replace real ones it blocks. After some reverse-engineering in my filter function  we could again  see original event.  
Another piece-of-code were does clean quit on mouse click ....
https://github.com/mate-desktop/marco/blob/8a2babd269066fc0a79f4bc05a07ce137567b907/src/core/display.c#L1824",True,True
mate-desktop_____marco_____437,2018-12-16T17:51:17Z,True,mate-desktop_____marco_____437_____447662478,"Why are you changing `GDK_FILTER_REMOVE` to `GDK_FILTER_CONTINUE`? Why it was added in first place? Why it is obsolete and/or wrong? Does it introduce regression / can it?

> ""Ending grab op %u on window %s due to button press\n""

That if branch is supposed to end grab op, but you are removing code that does it... Would not be surprised if that introduce interesting side effects, regressions or something like that.",True,True
mate-desktop_____marco_____437,2018-12-16T21:31:03Z,True,mate-desktop_____marco_____437_____447677673,The commit message of this needs to be changed to an explanation of what it is supposed to fix,True,True
mate-desktop_____marco_____437,2018-12-17T15:52:01Z,True,mate-desktop_____marco_____437_____447893470,"And you have a real bug-breeder here :  
https://github.com/alexeyneu/marco/blob/6d6b7032f8fc9a5ab7ee7973aa66218607ff8ef4/src/ui/ui.c#L216  
those who interested may track its usage   
 ",True,True
mate-desktop_____marco_____437,2018-12-17T15:54:19Z,True,mate-desktop_____marco_____437_____447894327,What? I don't see anything wrong with filter...,True,True
OpencachingDeutschland_____oc-server3_____731,2018-12-17T19:29:24Z,True,OpencachingDeutschland_____oc-server3_____731_____239257835,"see [changelog](https://www.opencaching.de/okapi/changelog.html)

bugfix v1873 requested by mic@",True,True
OpencachingDeutschland_____oc-server3_____731,2018-12-17T21:21:12Z,True,OpencachingDeutschland_____oc-server3_____731_____448003104,"Ich weiß das Du nichts für aktuelle Technologien wie z.B. Composer übrig hast aber ein okapi Update läuft nun einmal darüber. Der Content-Hash fehlt in deiner manuell angepassten composer.lock siehe https://github.com/OpencachingDeutschland/oc-server3/commit/96482219a5a9bf12490158d93300a2a68596c96c

Entweder führst Du ./psh.phar update-okapi-package aus oder führst die beiden Befehle aus dieser [Datei](https://github.com/OpencachingDeutschland/oc-server3/blob/development/dev-ops/local.team-opencaching.de/actions/update-okapi-package.sh) aus.

Das Du die Unit-Tests die dadurch fehlschlagen anpassen sollst verlange ich ja noch nicht einmal von dir.",True,True
OpencachingDeutschland_____oc-server3_____731,2018-12-17T21:46:03Z,True,OpencachingDeutschland_____oc-server3_____731_____448010319,Ich weiß das Du nichts für aktuelle Technologien wie z.B. Composer übrig hast aber ein okapi Update läuft nun einmal darüber. Der Content-Hash fehlt in deiner manuell angepassten composer.lock siehe e8430e9a.,True,True
OpencachingDeutschland_____oc-server3_____731,2018-12-17T21:54:48Z,True,OpencachingDeutschland_____oc-server3_____731_____448012966,"Mein letzter Versuch, deine buggy Okapi-Unit-Tests zu korrigieren (#668), wurde von dir abgewiesen, also lass das bitte mal stecken.",True,True
OpencachingDeutschland_____oc-server3_____731,2018-12-17T22:11:15Z,True,OpencachingDeutschland_____oc-server3_____731_____448017986,"Peter das hat nichts mit Buggy zu tun. Wenn sich die eingesetzte Software ändert müssen Tests fehl schlagen sonst waren sie nicht gut. 

Es gibt dafür sogar Testmöglichkeiten die die Tests genau auf dieses Verhalten prüfen. Nennt sich Mutation Testing. ",True,True
OpencachingDeutschland_____oc-server3_____731,2018-12-17T22:21:48Z,True,OpencachingDeutschland_____oc-server3_____731_____448021286,"> Wenn sich die eingesetzte Software ändert müssen Tests fehl schlagen 

Nur wenn die Änderung nicht abwärtskompatibel ist, andernfalls ist der Test fehlerhaft.",True,True
mate-desktop_____marco_____437,2018-12-18T01:10:23Z,True,mate-desktop_____marco_____437_____448058738,So it's finished,True,True
mate-desktop_____marco_____437,2018-12-18T04:18:46Z,True,mate-desktop_____marco_____437_____448091179,"Still needs an acceptable commit message: ""by the mouse"" means absolutely nothing at least to me and I have exactly zero idea what this is supposed to fix. This will probably go nowhere until we can understand its purpose. ",True,True
mate-desktop_____marco_____437,2018-12-18T09:53:18Z,True,mate-desktop_____marco_____437_____448162018,"did you seen `. . .` sign right after that what you're callin ""commit message""? ",True,True
mate-desktop_____marco_____437,2018-12-18T10:41:26Z,True,mate-desktop_____marco_____437_____448176562,"Finished, are you kidding?

- Your commit message still is not good... It still does not tell anything.
- You still have unneeded code changes that messes up coding style.
- Newly added code still does not follow coding style used in marco.

And more importantly - changes are wrong. You won't get away by commenting out code and/or by changing `GDK_FILTER_REMOVE` to `GDK_FILTER_CONTINUE`!

Sorry, but this is not going to be easy money for you... If this is your finished work, don't waste others time and just close your pull request!",True,True
mate-desktop_____marco_____437,2018-12-18T18:10:39Z,True,mate-desktop_____marco_____437_____448315834,"run this wm :  
```
git clone https://github.com/alexeyneu/marco.git
cd marco
./autogen.sh --prefix /usr
make
./src/marco --replace
```",True,True
mate-desktop_____marco_____437,2018-12-18T18:39:54Z,True,mate-desktop_____marco_____437_____448325019,"What did not you understand? Your changes are **wrong**! It does **not** matter if you have got working requested feature...

Do the research, learn how code works and provide correct solution. Apparently you did not even bother to read comment above `maybe_redirect_mouse_event` function. There are reasons why events are removed with `GDK_FILTER_REMOVE`.",True,True
mate-desktop_____marco_____437,2018-12-18T20:30:58Z,True,mate-desktop_____marco_____437_____448359644,"looks like this condom have a plans to  use my code.  
@lukefromdc it may go nowhere but you still need to pay",True,True
mate-desktop_____marco_____437,2018-12-18T20:31:39Z,True,mate-desktop_____marco_____437_____448359831,We can reopen this if you get a correct commit message and code that works to fix whatever the intended problem is.,True,True
mate-desktop_____marco_____437,2018-12-18T20:36:35Z,True,mate-desktop_____marco_____437_____448361323,No man now you'll be forced to pay,True,True
mate-desktop_____marco_____437,2018-12-18T20:41:47Z,True,mate-desktop_____marco_____437_____448362865,"Is this aimed at a problem for which someone has posted a bounty? If so, a fix for that issue would collect the bounty. Otherwise no money would be involved. This is not paid software, and we are not a team with funders behind us. If you are looking for money I would suggest you look elsewhere unless you are trying to fix  something for which someone has posted a bounty.   Please refrain from posting threats, especially empty threats",True,True
mate-desktop_____marco_____437,2018-12-18T20:45:58Z,True,mate-desktop_____marco_____437_____448364130,"Of course he is after money - just look at his contribution... The problem is **not fixed**! His code is **not merged** and will not get accepted - so he can not claim bounty. And the truth, probably, is that he is not capable of coming up with proper solution...",True,True
mate-desktop_____marco_____437,2018-12-18T21:21:17Z,True,mate-desktop_____marco_____437_____448374948,"OK, I see he is trying to fx https://github.com/mate-desktop/marco/issues/364 but Bountysource requires that a PR be accepted for the bounty to be claimed. Also, that particular issue was supposed to be already fixed-and the bounty claimed-by
https://github.com/mate-desktop/marco/pull/330
so he needs to start with an open issue with an open bounty. Firefox has a big one outstanding for some issue, at $500, but the size of that bounty implies it may take an expert or even a team effort to fix it",True,True
mate-desktop_____marco_____437,2018-12-18T21:24:23Z,True,mate-desktop_____marco_____437_____448375846,@lukefromdc that is/was different problem...,True,True
mate-desktop_____marco_____437,2018-12-19T07:37:34Z,True,mate-desktop_____marco_____437_____448498136,"The backer of  https://github.com/mate-desktop/marco/issues/364 (the issue you are trying to fix) is
https://www.bountysource.com/people/36613-phocean
and not myself. Thus if you submitted a PR with code that worked and the commit message was understandable so the PR got reviewed, and if the PR passed that review of both code and behavior and was merged to master, it would be @phocean who would accept or reject your contribution as having actually fixed the problem, and it would be their bountysource account that would pay, not the MATE project and certainly not myself, as I have posted no bounties of my own on this.

If I submitted a PR I cared about to a project and was told the team could understand the commit message (or had concluded it would not  make sense in the ChangeLog), and then someone pointed out multiple issues in the code, the first thing I would do is change the commit message and force-push that change, then change the PR title.  PR titles can be edited right here on the Github website, and git-gui provides a convenient way to deal with commits, changing commit messages for the last commit (you need git rebase -i from the command line to change older commit messages), and force-push the result.

Once that was done, I would look at each of the code problems my work had been cited for, and fix them one by one. It would probably then be necessary to squash that series of commits, unless of course I had done all that work in a build directory and committed all the changes to my local git repo in a single commit or by amending the previous (original) commit. I would then push these changes, with a force-push required if I had amended the last commit or squashed the changes into it. Only then would I call for further review.

Several heads are better than one when it comes to looking at and fixing code, and C is known as an ""unforgiving"" language, so it it particularily important in a project written mostly in C or in C++ that the code itself (not just the apparent behavior) be reviewed. Otherwise memory leaks, exploitable buffer overflows, and other serious but not immediately apparent problems can be introduced. 
",True,True
mysqljs_____mysql_____1962,2018-12-26T20:34:12Z,True,mysqljs_____mysql_____1962_____450022147,Thanks to all who have worked hard on the `caching_sha2_password` support. Are there plans to merge this soon?,True,True
citra-emu_____citra_____4535,2018-12-28T14:56:08Z,True,citra-emu_____citra_____4535_____241346735,"Increase: CTRL + I
Decrease: CTRL + D
Conflicts with #4437

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/citra-emu/citra/4535)
<!-- Reviewable:end -->
",True,True
citra-emu_____citra_____4535,2018-12-28T15:17:51Z,True,citra-emu_____citra_____4535_____450375204,"> Conflicts with #4437 

I take this as seeking for fight. And because of the conversation in #4532, I lost my hope. No.",True,True
citra-emu_____citra_____4535,2018-12-28T15:22:58Z,True,citra-emu_____citra_____4535_____450376018,Sad,True,True
iina_____iina_____2170,2019-01-02T08:58:00Z,True,iina_____iina_____2170_____241696162,"- [No] This change has been discussed with the author.
- [No] It implements / fixes issue #.

---

**Description:** update zh-Hans
",True,True
iina_____iina_____2170,2019-01-02T09:04:43Z,True,iina_____iina_____2170_____450813476,"Sorry but this will not count you as a contributor.

_Better try to mine some contributions in other repositories which really needs proper translation. Not here, though._",True,True
iina_____iina_____2170,2019-01-02T09:08:52Z,True,iina_____iina_____2170_____450814234,"Are you kidding me ?
I don't don't want to be a contributor, I just want to make Chinese localization more proper.
Funny.",True,True
iina_____iina_____2170,2019-01-02T09:10:43Z,True,iina_____iina_____2170_____450814549,"Funny that you don't even know that how this software looks like under current Simp. Chinese localization then you just went to change some irrelevant strings.

That's really intriguing.",True,True
iina_____iina_____2170,2019-01-02T09:11:56Z,True,iina_____iina_____2170_____450814779,"都是千年的狐狸，在这玩什么聊斋¿

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",True,True
iina_____iina_____2170,2019-01-02T09:12:11Z,True,iina_____iina_____2170_____450814819,"Fine !
You're right!",True,True
iina_____iina_____2170,2019-01-02T09:19:02Z,True,iina_____iina_____2170_____450816111,我tm 学医  混个 contributor 有啥意思？  你说说看,True,True
iina_____iina_____2170,2019-01-02T09:19:49Z,True,iina_____iina_____2170_____450816256,我就是喜欢汉化，我怎么知道这个软件开发者竟然是这么唯利是图的中国人！  shame on you,True,True
iina_____iina_____2170,2019-01-02T09:21:14Z,True,iina_____iina_____2170_____450816527,"Reported abuse: personal attacking.

Have a good day.",True,True
iina_____iina_____2170,2019-01-02T09:26:19Z,True,iina_____iina_____2170_____450817469,"下次吧自己尾巴藏起来再说自己学医，GitHub 默认 repo 是公开的

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",True,True
jshttp_____mime-db_____149,2019-01-04T23:17:47Z,True,jshttp_____mime-db_____149_____242397286,"When a Windows user converts a folder to a zip file, the filetype becomes: `x-zip-compressed` as shown below:
![image](https://user-images.githubusercontent.com/16158417/50715706-794a9280-104c-11e9-82e3-6ffbd953ac1c.png)

There are a few sources, however I am having trouble finding one that isn't an aggregated list:

Closest I can find is SitePoint:
https://www.sitepoint.com/mime-types-complete-list/
http://filext.com/file-extension/ZIP

My company will be using my forked branch in the meantime, as we have windows users uploading zip files pretty regularly.  Let me know if there is anything else I can do.",True,True
jshttp_____mime-db_____149,2019-01-04T23:26:56Z,True,jshttp_____mime-db_____149_____451599287,"Let me know if this works as a primary source:
https://www.oreilly.com/library/view/web-design-in/0596009879/ch04s05.html",True,True
google_____styleguide_____428,2019-01-05T00:10:49Z,True,google_____styleguide_____428_____242404213,Specify that no byte order mask should be used (when applicable) for source files.,True,True
google_____styleguide_____428,2019-01-05T00:10:52Z,True,google_____styleguide_____428_____451606408,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

<!-- need_sender_cla -->",True,True
TFPatches_____TotalFreedomMod_____128,2019-01-06T06:14:20Z,True,TFPatches_____TotalFreedomMod_____128_____242478145,,True,True
TFPatches_____TotalFreedomMod_____128,2019-01-06T06:17:52Z,True,TFPatches_____TotalFreedomMod_____128_____451718609,robin said so,True,True
TFPatches_____TotalFreedomMod_____128,2019-01-06T06:18:11Z,True,TFPatches_____TotalFreedomMod_____128_____451718620,"windows said yes
",True,True
TFPatches_____TotalFreedomMod_____128,2019-01-06T06:21:52Z,True,TFPatches_____TotalFreedomMod_____128_____451718763,but robin said no so,True,True
google_____styleguide_____428,2019-01-06T20:30:02Z,True,google_____styleguide_____428_____451772154,I signed it!,True,True
google_____styleguide_____428,2019-01-06T20:30:05Z,True,google_____styleguide_____428_____451772157,"CLAs look good, thanks!

<!-- ok -->",True,True
jshttp_____mime-db_____149,2019-01-07T16:12:54Z,True,jshttp_____mime-db_____149_____451987418,"I really don't think there is any available primary source documentation, it is a Microsoft mime-type for .zip files created within windows.

![image](https://user-images.githubusercontent.com/16158417/50778067-16831200-126b-11e9-8555-7ee2d3ab2971.png)
`HKEY_CLASSES_ROOT\.zip` in regedit, Windows 10 version 1803

This is the default registry value, and appears to have been for [over 9 years](https://bugzilla.mozilla.org/show_bug.cgi?id=540900).  Why IANA hasn't been updated I do not know.

I've added exceptions to handle this situation within my company's codebase, so do what you will with this PR with no primary source.  However, this is a valid mime-type and I worry the buggy situations that my company has experienced will occur for other users of both this library and the multitude of libraries that utilize it.  I'd hope you share in this concern.",True,True
jshttp_____mime-db_____149,2019-01-07T16:20:07Z,True,jshttp_____mime-db_____149_____451990029,"I agree that it's likely been around for a long time. However, the goal of this module is simply to aggregate the three sources in the readme together. We have some built in ones for legacy reasons, but for every person who wants to add one (like you) someone will then come back later saying it should actually be something different.

I do not want to be a mediator here.

Without a primary source it won't be accepted here directly. The best best is to get it added to one of the three sources we aggregate from and so it'll just be added in here automatically. ",True,True
jshttp_____mime-db_____149,2019-01-07T18:01:42Z,True,jshttp_____mime-db_____149_____452024600,Ridiculous that you would close this PR. Known issue with the library caused by excluding the mimetype generated by the most popular OS on the planet. @hdwatts has a valid case for a known issue... ,True,True
rust-lang_____rfcs_____2544,2019-01-11T20:53:17Z,True,rust-lang_____rfcs_____2544_____453653184,"The discussion has grinded to a halt and so now's a good time for a final team and community review of this RFC. Before that, I will give a rough summary of the discussion thus far and some conclusions I've made. So let's go through some of the major points of discussion.

## Motivation

[consistency]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423043867
[easier to learn]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422244320
[the motivation]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#motivation
[case_1]: https://users.rust-lang.org/t/why-cant-i-specify-type-parameters-directly-after-the-type/2365
[Later]: https://users.rust-lang.org/t/why-cant-i-specify-type-parameters-directly-after-the-type/2365/11
[comex_idiomatic]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423030623
[case_2]: https://users.rust-lang.org/t/type-parameter-syntax-when-defining-vs-calling-functions/15037
[josh_internally]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422864037
[case_4]: https://www.reddit.com/r/rust/comments/73pm5e/whats_the_rationale_behind_for_type_parameters/
[summarizes]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423059802
[boats_assumed]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422887780
[dherman_discoverability]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422193876

[new_corner]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422244320
[less_common]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422246423
[suggested]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-424638765
[prenex]: https://en.wikipedia.org/wiki/Parametric_polymorphism#Rank-1_(prenex)_polymorphism
[higher]: https://en.wikipedia.org/wiki/Parametric_polymorphism#Rank-n_(%22higher-rank%22)_polymorphism
[surprisingly for some]: https://github.com/rust-lang/book/issues/385#issuecomment-271050377

The main positive motivation of this RFC is *[consistency]* and by extension making Rust [easier to learn]. That is, having to use turbofish for function application is, as noted in [the motivation] an unexpected corner case.

While this RFC [does][new_corner] add a weird new corner case to parsing Rust, one has to consider how often each inconsistency would arise. As I [noted][less_common], the inconsistency introduced by this RFC is not a practical problem as the crater run has also demonstrated. Meanwhile, turbofish is a corner case users actually hit therefore making it a practical problem. The RFC gives a number of examples:

+ [[1]][case_1]

  In this example, the user likely expected that `Vec<u64>::new()` should work
  because `Vec<u64>` works in type contexts.

  [Later] in the same thread, another newcomer noted their confusion over where turbofish is necessary and not.

  @comex [notes][comex_idiomatic] that because of the inconsistency, the following is considered idiomatic:

  ```rust
  let mut x: Vec<u32> = Vec::new();
  ```

  They also note that this is both longer and more repetitive than writing `Vec::<u64>::new()` and that the longer version is likely chosen because turbofish is considered ugly. I tend to agree, being able to present `Vec<u64>::new()` as idiomatic would be good for Rust's reputation.

+ [[2]][case_2]

  Here, the user is confused, and for quite a while, over the declaration form `fn generic<T, ..>(..)` not being mirrored in the application form `generic::<T, ..>`. This is also captured in a comment written by @joshtriplett, where he further [notes][josh_internally] that the RFC isn't proposed to make Rust more like other languages but rather more *internally consistent*.

+ [[4]][case_4]

  In another case, a user notes that turbofish is both awkward to type and unnatural.

In comments thus far, other instances of confusion have been noted:

+ @Wyverald eloquently [summarizes] the various scenarios in which turbofish is needed and not when type-applying a struct literal and notes their surprise when coming from C++ and Java.

+ @withoutboats [notes][boats_assumed] that they initially assumed that since `.collect<Vec<_>>()` wasn't possible, type-application wasn't possible either.

+ @dherman [notes][dherman_discoverability] that newcomers at work have issues wrt. the guessability and discoverability of turbofish.

[estebank_diagnostics]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422179860
[gilnaa_learnability]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422860439

While we can [improve diagnostics][gilnaa_learnability] as [suggested] by @estebank, thereby improving discoverability for learners, a broken mental model still needs to be maintained in a user's mind. This results in interrupted flow for new users and sometimes for novices and experts as well.

### Making non-turbofish idiomatic

It has been [suggested] that an alternative to making turbofish redundant would be to do the reverse: making non-turbofish redundant by linting on `Foo<T>` and allowing `Foo::<T>`. However, `Foo::<T>` is, [surprisingly for some], *already* allowed:

```rust
type X = Vec::<u8>;
```
Not only is it allowed, but *linted* against:

```rust
warning: unnecessary path disambiguator
 --> src/lib.rs:1:13
  |
1 | type X = Vec::<u8>;
  |             ^^ try removing `::`
```

Thus, to make `Foo::<T>` idiomatic we would need to reverse this lint and it would make virtually all Rust code thus far unidiomatic. Additionally, it would still *not* remove the inconsistency of having `Vec<T>` work but not `identity<u8>`.

Finally, the reason we chose `<T>` in the first place is to make Rust more familiar for C-family users (e.g. C++, C#, Java, Kotlin). To make `::<T>` idiomatic would be to nullify the rationale for `<T>` in the first place.

### The namespaces model

[namespaces_suggested]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422859755
[type_erasure]: https://internals.rust-lang.org/t/2019-strategy-for-rustc-and-the-rls/8361/71

It has been [suggested][namespaces_suggested] that generics are nothing more than automatically defined types and functions put under namespaces (e.g `Foo_u8`). This may be true in a language with only [rank-1 prenex polymorphism][prenex]. However, Rust allows functions and types that are of arbitrarily high rank ([rank-n polymorphism][higher]): 

```rust
type X = fn(fn(for<'a> fn(&'a u8))); // X is a rank-3 polymorphic type.
```

The namespace model falls apart with rank-n polymorphism as you truly need to pass in a function that is valid for all lifetimes.

It is further suggested that `::<T>` supports the idea of monomorphization being the principle behind generic functions. However, this somewhat conflates implementation strategy with language semantics. For example, for improved compile times and reduced binary sizes we could [potentially employ type erasure][type_erasure].

### Type ascription vs. Type application

[rpjohnst_ascription]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422191951
[type ascription]: https://github.com/rust-lang/rfcs/pull/2522
[size_of]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422361782
[parse]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422242606
[text_ascription]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#future-frequency-of-disambiguated-generic-expressions
[haskell_both]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422514013

@rpjohnst [suggests][rpjohnst_ascription] that we should consider the effect of [type ascription] and that if we had it, Rust could be taught without type application. While type ascription would reduce the usage of type application, as @SimonSpin [notes][size_of], in cases such as `size_of::<T>()` and `Any::is::<T>()` this is not possible. Meanwhile, in examples such [`.parse::<u8>()`][parse] it is *possible* to use type ascription but then you have to annotate a larger type. Other examples are noted in [the RFC's text][text_ascription]. Moreover, as the RFC notes, `const A: B` generics are likely to increase the number of cases where type application is better than ascription.

Finally, Rust would not be alone in supporting both type application and ascription. Another language, that supports it today, is [Haskell][haskell_both] wherein you may write:

```haskell
let s = sort :: [Int] -> [Int] -- ascriping the type of `sort`.
let s = sort @Int -- same thing, but with type application.
```

## Backwards compatibility

[bc_incompat]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422078938
[crater_run]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#reference-level-explanation
[strictly theoretical]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422887780
[crater_not_enough]: https://github.com/rust-lang/rust/issues/53668#issuecomment-422903463
[principle]: https://github.com/rust-lang/rust/issues/53668#issuecomment-423137936
[pragmatic]: https://github.com/rust-lang/rust/issues/53668#issuecomment-422892580
[good indicators]: https://github.com/rust-lang/rust/issues/53668#issuecomment-423141487
[done regularly]: https://github.com/rust-lang/rust/issues/53668#issuecomment-423144713
[practical]: https://github.com/rust-lang/rust/issues/53668#issuecomment-423319580
[if_let]: https://github.com/rust-lang/rust/pull/53854
[RFC 599]: https://rust-lang.github.io/rfcs/0599-default-object-bound.html
[TC39]: https://github.com/tc39
[dherman_defacto]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422177966
[edition mechanism]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422180550
[no_time]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423338391
[cargo_fix]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422864310
[fix_not_sufficient]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422866805
[ed_1]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423704055
[ed_2]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423754245
[ed_3]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423798340
[sufficient]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422892283
[justify such breakage]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422177966
[crater run]: https://github.com/rust-lang/rust/pull/53578#issuecomment-421487068

This RFC technically amounts to [a backwards incompatible change][bc_incompat] without using the edition mechanism. However, as the [RFC notes][crater_run], a [crater run] was made and the syntax was not encountered at all. The breakage is therefore [strictly theoretical]. In the eventuality that it isn't theoretical, the migration can be [trivially handled by `cargo fix`][cargo_fix].

[A case has been made][crater_not_enough] that crater runs don't cover all code (e.g. in-house code) and that the [principle] of backwards compatibility is important. However, our approach to backwards compatibility has been [pragmatic] and [practical]. What we care about is whether it break someone's code, which crater runs are [good indicators] of, rather than theoretical breakage. Indeed, changes with negligible effects are [done regularly] but nobody notices them. There is also precedent in [`if let p = q && r { .. }`][if_let] for doing such changes. As @nikomatsakis noted, another notable precedent was [RFC 599]. In it, we find:

> A. Breaking change. This change has the potential to break some existing code, though given the statistics gathered we believe the effect will be minimal (in particular, defaults are only permitted in `fn` signatures today, so in most existing code explicit lifetime bounds are used).

We are also not alone in our pragmatic approach. The [TC39] committee, which oversees the development and standardization of JavaScript, spends, [as @dherman noted][dherman_defacto], a lot of effort on retaining backwards compatibility. However, TC39 also cautiously makes changes which are *de jure* breaking but which *de facto* aren't if there is empirical evidence for that. I argue that we have and should continue to take such an approach.

@SimonSapin noted that we have the [edition mechanism] whereas JavaScript does not and that [favourable crater results and `cargo fix` support][fix_not_sufficient] shouldn't be sufficient to justify in-edition breakages. I think using an edition would have been more feasible if we had the time to do it in Rust 2018. However, [we didn't][no_time]. [Some][ed_1] have [noted][ed_2] that [we][ed_3] should wait until Rust 2021 (the next edition). I believe that, even if we felt the wait was short enough, the technical debt of an edition breakage for theoretical breakage would not be a good idea since it would need to be handled by tooling, documentation. The aforementioned case of `if let` also sets precedent for avoiding such debt. The benefits of this proposal are also [sufficient] to [justify such breakage].

All in all, given our pragmatic approach and after careful consideration, doing this change for all editions seems the better choice to me.

## Effort

[underestimated]: https://github.com/rust-lang/rfcs/pull/2544#discussion_r218224263
[poc]: https://github.com/rust-lang/rust/pull/53578
[persistent]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423338683

An argument has been made that the work required is [underestimated]. While a proof of concept [already exists][poc], it is only that. However, the RFC author, @varkor, has been [persistent] and there's therefore no reason to think that the necessary effort won't be spent.

## Alternative implementation strategies

[alt_strat]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423293222
[doesnt_work]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423827385

An alternative implementation strategy was [suggested][alt_strat] that would not need backtracking. However, [this solution wouldn't work][doesnt_work] since it would break code. Since we are within an edition, such demonstrated breakage would not be acceptable.

## Grammatical Complexity, LL(k), and Tooling

[backtrack]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#drawbacks
[lookahead]: https://en.wikipedia.org/wiki/Parsing#Lookahead
[llk]: https://en.wikipedia.org/wiki/LL_grammar
[k_constant]: https://en.wikipedia.org/wiki/LL_parser
[ll_linear]: https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1311&context=ecetr
[perf_1]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#performance
[perf_2]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#drawbacks
[ordo_3]: https://github.com/rust-lang/rfcs/pull/2584#discussion_r230587813
[ide_support]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422247331
[eddyb_1]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422250552
[proto_gll_rust]: https://github.com/rust-lang-nursery/wg-grammar/pull/13
[recursive decent]: https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#drawbacks
[not difficult]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422358610
[eddyb_dragging]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436193369
[simpler grammar]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436202518
[sensitive]: https://users.rust-lang.org/t/why-cant-i-specify-type-parameters-directly-after-the-type/2365/9?u=centril

A major theme in this RFC has been grammatical complexity and its relation to tooling.

To enable `foo<Type>()`, [the RFC proposes using backtracking][backtrack]. This means that, in theory, parsing Rust will require unlimited token [lookahead]. Thus, Rust is no longer has an [`LL(k)` grammar][llk] ([technically Rust's grammar isn't context free on raw bytes but is on tokens][sensitive]). Here, [`k` is some constant][k_constant] corresponding to the number of lookahead tokens required to parse Rust.

One property of `LL(k)` parsers is that their complexity is [`O(input_size)`][ll_linear]. Moving to unlimited lookahead parsing does not preserve that and thus performance may suffer in theory. However, [as the RFC notes][perf_1], [empirical evidence][perf_2] shows no notable performance regression across the Rust ecosystem (i.e. in representative Rust code).

Besides performance, another issue with using more complex formalisms is that [IDE and tooling support could suffer][ide_support]. However, as @eddyb [noted][eddyb_1], LL, and other subsets of CFGs, have overstayed their welcome by at least a decade, and is [dragging language design along with it][eddyb_dragging]. If, in the future, we use GLL, to parse Rust, we can limit complexity to [`O(input_size^3)`][ordo_3] and at the same time provide richer and more sophisticated error reporting and recovery.

The grammar working group (wg-grammar) is working on a canonical grammar for Rust that uses GLL. A prototype implementation can be found [here][proto_gll_rust]. Notably, this grammar requires less work to encode and results in a [simpler grammar]. Such a canonical grammar can then be translated into ENBF or used directly. This can significantly cut down on implementation costs. Where GLL cannot be used, other methods such as [recursive decent] (an exceedingly common way of implementing parsers) or parser combinators can be used. I therefore concur with @varkor that implementation in common parsers is [not difficult].

### Tooling

[matklad_ide]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425963737
[vim_hard_1]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-424805217
[sublime text]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436341820
[a cruder approach]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425616729
[Distinguishing function calls]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425632095
[comex_vim_heuristic]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-426039907
[ekelog_tools]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-426118494
[jibal_concurrence]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436384831
[mark_bracket]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436391571
[rpjohnst_1]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425979185

As for IDE support, @matklad, who has significant experience with IDE development, [notes][matklad_ide] that IDE support would not be a problem. However, there are certain text editors, such as [vim][vim_hard_1] and [sublime text], that have more limited parsing capabilities and will therefore have a harder time parsing Rust.

While in theory, highlighting Rust in vim could distinguish between expressions and types, the current `rust.vim` takes [a cruder approach] and seems to get by. [Distinguishing function calls] from conditionals could become more difficult in `rust.vim`.

However, as @comex [notes][comex_vim_heuristic], `rust.vim`'s understanding of Rust's syntax is superficial, very heuristic, and has a low bar for accuracy. @comex further notes that even after this change, a slightly more complicated heuristic could work. Sublime Text also uses a heuristic approach and doesn't treat turbofish specially.

Meanwhile, @Ekelog [notes][ekelog_tools] that other tools will also be affected. @jibal [concurs][jibal_concurrence] and notes that editors do need to tell expressions from types. However, @mark-i-m [notes][mark_bracket] that, while they use vim for everything, they haven't run into issues with vim being confused by bracket mismatch with `<` and `>`.

Beyond text editors, @rpjohnst [notes][rpjohnst_1] that in situations in which semantic parser libraries cannot be used, such as when using `ctrl + f` or when grepping, experiences may suffer. My personal view here is that heuristics are often used in these types of situation and it mostly works well. For example, when `ctrl + f`ing, I might not have the time to even write a regex wherefore I will go with an even cruder approach.

As a closing note on tooling, I believe that people who author tooling for Rust are substantially fewer than users who would encounter the inconsistencies of turbofish. In the end, I therefore believe this RFC to be a net benefit.

### Readability for humans

[H2CO3_readability]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436156511
[ekelog_readability]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436231934
[formatting conventions]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-436252415

An adjacent subject to giving up on `LL(k)` is readability for humans.

Here, @H2CO3 [argues that][H2CO3_readability] will suffer as a result since turbofish currently serves as a disambiguator. In particular they argue that they are glad that there is visual indication when type application happens. However, as aforementioned, this indication is not consistent and therefore misleading. While turbofish may be required or beneficial in struct literals: `Foo::<Type> { ... }` and in function applications: `.collect::<Vec<_>>()`, it is not required for type application in types. In other words, you may write: `Vec<u8>`.

On the subject of readability, @Ekelog [notes][ekelog_readability] that *""`if f<T, U>() {` is ambiguous for the human reader forever""*. However, as @varkor notes, the [formatting conventions] for types and bindings are different. Furthermore, `rustfmt` will format type applications without spaces while it will keep spaces around `<` and `>` when used as binary operators. A comparison with `()` is unlikely. More likely is comparison with a parenthesized expression. But under no circumstances would you put a comparison with a parenthesized expression as the second element of a 2-tuple directly inside a conditional since `if expr,expr {` is not legal. Furthermore, a comma (`,`) is not a valid binary operator in Rust.

## Forward compatibility

There is a question of forward compatibility with respect to changes we *might* want to make in the future.

### With `const A: B` generics

[RFC 2000]: https://github.com/rust-lang/rfcs/pull/2000
[petrochenkov_fears_1]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423290039
[petrochenkov_fears_2]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423320187
[new ambiguities]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423827651
[comex_backtracking]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423867405
[cover grammars]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-424615426

With `const` generics, as proposed by [RFC 2000], it becomes possible to let types depend on *values* known at compile time, e.g. `1`. For example, you may write `foo::<42>()` or `foo::<{40 + 2}>`. Notice that in the latter example, `40 + 2` was wrapped in braces (`{ .. }`). As long as this wrapping occurs, there are no forward compatibility issues in relation to this RFC. However, if you were allowed to write `foo<40 + 2>()`, as @petrochenkov [fears][petrochenkov_fears_1] will [happen][petrochenkov_fears_2], then [new ambiguities] may arise. However, these could be handled by disambiguating using methods like GLL, [backtracking][comex_backtracking], or [cover grammars]. This is not to say that the language team will necessarily eventually make `foo<42 + 2>()` legal in the name of ergonomics. There are no such plans today or inevitability.

### With chained comparisons

[RFC 558]: https://github.com/rust-lang/rfcs/pull/558
[ekelog_chained]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-424663033
[deems desirable]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-424750251
[comex_contrived]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-425179571

Another possible extension to the language, which @ubsan [deems desirable], that would also interact with this RFC, is chained comparisons. For example: `x < y < z`. These chained comparisons were forbidden in [RFC 558] as a means of future proofing. In https://github.com/rust-lang/rfcs/issues/2083, the idea of adding chained comparisons to the language is under discussion.

Consider an expression such as `1 < 2 <= 2 < 3` and let's further assume that `<` and `<=` are left associative. The result would thus be: `((1 < 2) <= 2) < 3`. If we reduce `1 < 2` we now get `(true <= 2) < 3`. However, `true <= 2` is nonsense since `bool` may only be compared with itself but not with integers, and would not result in what we expect. To make `1 < 2 <= 2 < 3` work an ad-hoc solution is required where chained comparisons are taken as a unit/list rather than as a tree and then desugared to `1 < 2 && 2 <= 2 && 2 < 3` as is done in Python. However, as `(1 < 0) < true` is valid, it would be surprising for `1 < 0 < true` to be semantically different (and not type check because `1 < 0 && 0 < true` isn't valid).

The primary use case for chained comparisons are checking whether some number is contained within a range, that is: `r_start < y < r_end`. This use case could also be realized by pattern matching. For example, if range patterns `a..b` were supported you could write `if let r_start..r_end = y { ... }` or `if y is r_start..r_end { .. }` in @petrochenkov's style.

If we did elect to support chained comparisons, then `foo<bar>()` could either associate as `(foo < bar) > ()` or as `(foo::<bar>)()`. It would however  be possible to disambiguate in favour of type application. As @Ekelog [notes][ekelog_chained], if we also have const generics without `{ .. }` then you may write `foo<bar<MYCONST>>()` which can associate as `((foo < bar) < MYCONST) >> ()` or as `(foo::<(bar::<MYCONST>)>)()`. However, having this RFC, chained comparisons, and const generics without `{ .. }` altogether seems exceedingly unlikely. @comex [notes][comex_contrived] that many examples where confusion with comparisons and type application would arise are unlikely to occur and that examples are contrived.

## Conclusion

[generally positive sentiment]: https://github.com/rust-lang/rfcs/pull/2544#issuecomment-423338391

**In closing**, because of the strong motivation in improving consistency and learnability, the remaining usefulness of type-appliction even with stable type ascription, the zero-regression crater run, the strong likelihood that the necessary implementation effort will be put in, the relative ease with which this can be implemented in rustc, the non-regression in performance, the ability to use and current use of heuristics in vim and similar editors, the low forward compatibility risk, and finally the [generally positive sentiment] within the language team, **I propose that we...**

@rfcbot merge

**...this RFC.**
",True,True
rust-lang_____rfcs_____2544,2019-01-11T20:53:19Z,True,rust-lang_____rfcs_____2544_____453653193,"Team member @Centril has proposed to merge this. The next step is review by the rest of the tagged team members:

* [x] @Centril
* [x] @aturon
* [x] @cramertj
* [x] @eddyb
* [x] @joshtriplett
* [x] @nikomatsakis
* [x] @pnkfelix
* [ ] @scottmcm
* [ ] @withoutboats

Concerns:

* please-explicitly-disclaim-grammatical-precedent (https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453708156)
* too-uncertain-for-its-value (https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453710318)

Once a majority of reviewers approve (and at most 2 approvals are outstanding), this will enter its final comment period. If you spot a major issue that hasn't been raised at any point in this process, please speak up!

See [this document](https://github.com/rust-lang/rfcbot-rs/blob/master/README.md) for info about what commands tagged team members can give me.",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:02:45Z,True,rust-lang_____rfcs_____2544_____453671361,"One final question before merging... If this change does end up having bad consequences in the future, will it be possible to revert it in another edition?
",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:08:12Z,True,rust-lang_____rfcs_____2544_____453672671,"I don't agree with the conclusion but I appreciate how thorough the summary is, giving fair weight to all criticisms. This is how difficult decisions about controversial issues should be made. Kudos.",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:09:34Z,True,rust-lang_____rfcs_____2544_____453672965,"OK so this is exactly one case where the change is very controversial and I think it's being pushed by T-lang. There are currently as many 👎 s on the RFC as 👍 s and there have been multiple concerns by several users. These have all been dismissed as basically ""resolved"" or ""not too bad"". I respectfully disagree with most of that reasoning because they still are issues; furthermore, the consistency argument in favor of this RFC still doesn't hold, because it's not possible to remove it *everywhere*.

(I also somehow feel that in general the comments against have more upvotes than the supporting ones, but I didn't count.)
",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:11:24Z,True,rust-lang_____rfcs_____2544_____453673405,"@ivandardi Yes, AFAIK, it should be technically possible to revert with an edition if we so hypothetically wish.",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:17:19Z,True,rust-lang_____rfcs_____2544_____453674848,"I strongly believe that summary underestimates the cost to other tools. @eddyb's claims about LL are fairly radical, given that GLL/GLR/etc are still virtually unused in production, so I don't think we can dismiss the downsides of this change solely on the basis of heuristics and more powerful parsers. The same applies to human visual parsing and human-driven heuristics.

I would much rather have extra parser power leveraged toward improvements in error messages, editors, etc. *and not need it otherwise* than the reverse. We're cutting out a chunk of the design space here, and it's not clear how big it is or what it overlaps with. Meanwhile the benefits are relatively small- there's no new mental model being enabled, unlike match ergonomics; AFAIK there's no repetitive papercut we're eliminating, unlike uniform paths; this is just something you have to learn once about Rust syntax.",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:36:38Z,True,rust-lang_____rfcs_____2544_____453679165,"I can't form a strong opinion either way on the fairness of the summary (although you certainly deserve kudos for thoroughness) or the mergeability of the RFC, _but_ I do think it's interesting that the web of arguments surrounding this theoretically minor change involve three big, unfinished pieces of work:
- const generics
- type ascription
- a canonical Rust grammar

We do have a pretty decent idea what each of these things will eventually look like, but all together these add up to enough uncertainty that I'm convinced the tradeoffs we're discussing today are going to shift in some unforseeable but significant way by the time one or more of these things becomes set in stone.

Which is a long way of saying: perhaps postponing this wouldn't be a bad idea.",True,True
rust-lang_____rfcs_____2544,2019-01-11T22:51:54Z,True,rust-lang_____rfcs_____2544_____453682449,"@Ixrec 

> involve three big, unfinished pieces of work:
> 
> * const generics
> * type ascription
> * a canonical Rust grammar

That's true enough, but we have discussed these and I think there's sufficient useful data and thinking already to go on to take the first step now.

> We do have a pretty decent idea what each of these things will eventually look like, but all together these add up to enough uncertainty that I'm convinced the tradeoffs we're discussing today are going to shift in some unforseeable but significant way by the time one or more of these things becomes set in stone.
>
> Which is a long way of saying: perhaps postponing this wouldn't be a bad idea.

Remember that merging an RFC is not the same as stabilization and that we aren't setting the redundancy of turbofish in stone by this move. This is rather a declaration of intent as well as permission to move into nightly, but the point of nightly is in part to enable the collection of data. If this RFC turns out to be a mistake in nightly, we can change our minds. I believe there's sufficient motivation and interest to go ahead with the implementation for now tho. I would even say that it's beneficial to to evaluate the three things you itemized and this RFC together.",True,True
rust-lang_____rfcs_____2544,2019-01-11T23:05:09Z,True,rust-lang_____rfcs_____2544_____453684990,"@Centril this summary is amazing! There's one subject that I don't think you covered, which @SimonSapin [brought up](https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422087071): the precedent that this decision sets. Since precedent is cited frequently here as justification for this change, would you mind writing a few words about what precedent you believe this decision would represent? My impression so far is that unbounding the lookahead in the grammar is in a sense crossing a line that can't be uncrossed, one that has been a ""core value"" of the Rust syntax for a while.

What does this change mean from a policy perspective? Can the RFC include language to redraw this previously uncrossed line in the sand? Can we quantify what grammar changes would be acceptable which are similar to this?",True,True
rust-lang_____rfcs_____2544,2019-01-11T23:13:06Z,True,rust-lang_____rfcs_____2544_____453686610,"I have seen diagnostics mentioned only once – in context of it being an alternative to this RFC. I would like to make a point that implementing this RFC makes multiple diagnostics hard or impossible to implement (well) anymore.

Since with this RFC every typo'd expression can be one of about bazillion different things, it negatively impacts diagnostics that point out syntax errors. Errors, especially typos, can, and will, become significantly less localized and difficult to make a good span for. In fact, with infinite-ish look-around it will become necessary to span the whole buffer that has been ever considered for the expression parse in order to provide a reliable diagnostic. Such diagnostic will end up being less targeted and force the user to stare at it longer to comprehend what it is about.

Another one of the things that the current rustc does is ""recovery"" by making an educated guess how to fix up malformed code so that it could continue working and possibly report more errors. Depending on whom you ask you’ll hear both praises and curses – that comes from it being essentially a heuristically made guess at what malformed code ought to look like. To make said guess it is necessary to have an idea what the code ought to mean in the first place, and with a large number of alternative options it becomes impossible to do.

I sure hope that, in the process of removing a tiny element of surprise for users trying to pick up Rust, we don’t end up introducing a permanent element of surprise every time there’s an accidental syntax error.",True,True
rust-lang_____rfcs_____2544,2019-01-11T23:22:00Z,True,rust-lang_____rfcs_____2544_____453688378,"@anp 

> @Centril this summary is amazing!

❤️ 

> There's one subject that I don't think you covered, which @SimonSapin [brought up](https://github.com/rust-lang/rfcs/pull/2544#issuecomment-422087071): the precedent that this decision sets.

The precedent Simon talks about is about zero-regression-crater + breakage, which is addressed in my summary (the section on breakage). The precedent on breakage specifically was already set (as outlined in the section).

> Since precedent is cited frequently here as justification for this change, would you mind writing a few words about what precedent you believe this decision would represent? My impression so far is that unbounding the lookahead in the grammar is in a sense crossing a line that can't be uncrossed, one that has been a ""core value"" of the Rust syntax for a while.
> 
> What does this change mean from a policy perspective? Can the RFC include language to redraw this previously uncrossed line in the sand? Can we quantify what grammar changes would be acceptable which are similar to this?

I wouldn't mind such language in the RFC but I also don't think it particularly needs spelling out. This RFC will unbound the lookahead. However, merely because we have unbounded the lookahead in the grammar (if and when this RFC is *stabilized*, but *not before*), it does not mean that any use of lookahead is OK. We still need to consider: performance, how much of actual backtracking would occur in real code, and the benefits of the individual proposal as compared to these drawbacks. In other words, we go from a blanket statement of ""no infinite lookahead"" to ""weigh the trade-offs case by case"". So we will still need to do the weighing done in this RFC.",True,True
rust-lang_____rfcs_____2544,2019-01-11T23:40:58Z,True,rust-lang_____rfcs_____2544_____453692163,"Strong disagree with the notion of LL(k) being some kind of archaic constraint on language design, and with the direction of this change in general.",True,True
rust-lang_____rfcs_____2544,2019-01-11T23:43:59Z,True,rust-lang_____rfcs_____2544_____453692655,"> Since with this RFC every typo'd expression can be one of about bazillion different things, it negatively impacts diagnostics that point out syntax errors. Errors, especially typos, can, and will, become significantly less localized and difficult to make a good span for.

> I sure hope that, in the process of removing a tiny element of surprise for users trying to pick up Rust, we don’t end up introducing a permanent element of surprise every time there’s an accidental syntax error.

Personally, this is the most convincing concern for me. I completely agree that the quality of diagnostics is more important than this piece of syntax, if the two are in conflict. I think, however, that it's very tricky to make flat-out assertions in this scenario without actually testing.

Should this be implemented (unstably), we will have to be very careful to review the diagnostic changes that result from this. I also don't want this to be merged if it means significantly worse error messages, etc.

My hope is that the changes actually will be fairly localised — the change to the parser this requires is not large after all — and we'll be able to address any diagnostic regressions. This is something that will come up in testing. I certainly don't think it's being ignored simply because it's not been heavily mentioned: I don't think anyone would argue severe diagnostic regressions are worth any change.",True,True
rust-lang_____rfcs_____2544,2019-01-11T23:51:41Z,True,rust-lang_____rfcs_____2544_____453693995,"> In other words, we go from a blanket statement of ""no infinite lookahead"" to ""weigh the trade-offs case by case"". So we will still need to do the weighing done in this RFC.

What about ""this is the only case of unbounded lookahead that will be allowed in Rust's grammar?"" If we can't guarantee that we'll stop here, then why not lay out some decision-making tools for how to reason about future examples of similar changes?

> LL(k) being some kind of archaic constraint on language design

I have done a small amount of work with the gll crate and it is REALLY COOL AND AMAZING AND GOOD. It is still baking, though. The wg-grammar work is based on git/master/HEAD of the gll crate, and I at least am not aware of other implementations that rust tools (much less other languages) could make use of today or in the near future. Is this level of maturity really sufficient to assuage near-term tooling concerns?",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:07:54Z,True,rust-lang_____rfcs_____2544_____453696848,"@anp 

> What about ""this is the only case of unbounded lookahead that will be allowed in Rust's grammar?""

That doesn't seem particularly useful to say; there's the argument about ""opening the floodgates"" and such, but there are legitimately other useful cases where the trade-offs may be similar to those in this RFC wrt. performance and occurrence of backtracking in real code. Let's judge those case by case in the same deliberate manner as @varkor's.

> If we can't guarantee that we'll stop here, then why not lay out some decision-making tools for how to reason about future examples of similar changes?

I mean.. that's what my comment about trade-offs was for.. This RFC sets out decision making tools *by example*. =P

> I have done a small amount of work with the gll crate and it is REALLY COOL AND AMAZING AND GOOD. It is still baking, though. The wg-grammar work is based on git/master/HEAD of the gll crate, and I at least am not aware of other implementations that rust tools (much less other languages) could make use of today or in the near future. Is this level of maturity really sufficient to assuage near-term tooling concerns?

GLL and wg-grammar's use of it is of interest for significantly reducing costs long term (as compared to *before this RFC*), it is still baking, that is true. For near term tooling concerns I think backtracking, combinators (e.g. nom, parsec, combine, ..), recursive decent, and heuristics (vim) work... or *we should at least try that out on nightly*. If it didn't work, at least we found out. IOW, I think this is the right step even if we forget about GLL.",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:16:23Z,True,rust-lang_____rfcs_____2544_____453698496,"> If it didn't work

I don't imagine anyone here doubts that it is technically parseable / will _work_. the issue is that once it's made-live on nightly (and ""nothing breaks""), it's easy to make-permanent while ignoring/dismissing the cost argument (""already paid on rustc, who cares about other places""), and then in the future use it as precedent for ""well the grammar is already post-LL(k) so we can keep adding ever more grammar costs"".

This line / design constraint exists in the grammar to _limit costs_. See also recent comments on placing limits: that they ought to exist and be planned-for and adapted-to consciously rather than unconsciously overshot and only noticed in hindsight when it's actually harmful. This was a limit the language grew up with and was quite capable of healthy growth while staying inside of. Yet here is an RFC explicitly saying ""let's remove the limit"". I object to _that_.",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:24:46Z,True,rust-lang_____rfcs_____2544_____453699920,I will second @graydon (among others) here; I will be sad to see this RFC merged.,True,True
rust-lang_____rfcs_____2544,2019-01-12T00:33:55Z,True,rust-lang_____rfcs_____2544_____453701186,"@graydon 

> I don't imagine anyone here doubts that it is technically parseable / will _work_. the issue is that once it's made-live on nightly (and ""nothing breaks""), it's easy to make-permanent while ignoring/dismissing the cost argument (""already paid on rustc, who cares about other places""), and then in the future use it as precedent for ""well the grammar is already post-LL(k) so we can keep adding ever more grammar costs"".

To me, this reads as a matter of mistrust in the current language team's ability to regulate and not cavalierly add ""ever more grammar costs"" and our ability to take other places (e.g. `syn`, IntelliJ Rust, other tools ...) into account.

> This line / design constraint exists in the grammar to _limit costs_. See also recent comments on placing limits: that they ought to exist and be planned-for and adapted-to consciously rather than unconsciously

We considering making a *deliberate choice* here. Nothing is done unconsciously.",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:40:24Z,True,rust-lang_____rfcs_____2544_____453702010,"> To me, this reads as a matter of mistrust in the current language team's ability to regulate and not cavalierly add ""ever more grammar costs"" and our ability to take other places (e.g. `syn`, IntelliJ Rust, other tools ...) into account.

To me, that reads like a C programmer arguing that they should be trusted not to shoot themselves in the foot. It misconstrues the whole idea and intent of placing limits.

> We considering making a _deliberate choice_ here. Nothing is done unconsciously.

I believe that Graydon was referring to the limits consciously placed on the language design, not this specific feature. I do not believe that a conscious choice is being made to remove that limit -- rather, the limit is collateral damage due to a desire to ease language learning for a corner case. It seems to me to be a hugely disproportionate cost.",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:44:09Z,True,rust-lang_____rfcs_____2544_____453702462,"> To me, this reads as a matter of mistrust in the current language team's ability to regulate and not cavalierly add ""ever more grammar costs"" and our ability to take other places (e.g. syn, IntelliJ Rust, other tools ...) into account.

I have been reading @graydon in light of his [recent blog post](https://graydon2.dreamwidth.org/263429.html), with the following tldr:

> I'm writing to make a recommendation about paying attention to -- acknowledging, planning, making explicit mechanisms and policy around the limits of -- the growth of two things in the project:
> 1. Necessarily-shared technical artifacts, specifically the language definition itself.
> 2. The strains on people participating in conversations about those artifacts.

To me, that post reads as an acknowledgement of how human systems are necessarily fallible and must be accounted for. Trust is a spectrum, and we wouldn't have the RFC process if everyone had perfect trust in the governance teams (which is a changing entity) to consider everything all the time. We wouldn't need it if they were capable of it! It's reasonable to say 'this is a value we hold and we don't know what constraints will come up later, but we'll be sad if we lose this value.' It's also reasonable to say 'we don't hold this value strongly enough to enshrine it against all possible futures.'",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:50:17Z,True,rust-lang_____rfcs_____2544_____453703218,"> I don't imagine anyone here doubts that it is technically parseable / will work. the issue is that once it's made-live on nightly (and ""nothing breaks""), it's easy to make-permanent while ignoring/dismissing the cost argument (""already paid on rustc, who cares about other places""), and then in the future use it as precedent for ""well the grammar is already post-LL(k) so we can keep adding ever more grammar costs"".

To be clear, this is not an argument about turbofish, or this particular RFC. This is a philosophical objection. If the grammar is already not LL(k), that doesn't immediately imply that any language feature that's *also* not LL(k) will automatically be considered as having no cost on the grammar or parser. Arguing that a change should not be made, because the first such change (even if justified) means other similar changes will be made is fallacious. It implies that those participating in discussions don't consider proposals thoroughly (which, seems to be clear from this thread, is definitely not the case).

One could use exactly the same argument for: we should not add any complex features, even if they are useful, because it means we're more likely to add more unnecessary complex features in the future. Judging the value of proposals is exactly what the RFC process is for.

It's entirely reasonable to agree or disagree with this proposal based on its individual virtues. But philosophical objections are not pertinent.

> See also recent comments on placing limits: that they ought to exist and be planned-for and adapted-to consciously rather than unconsciously overshot and only noticed in hindsight when it's actually harmful.

This is a very clear case of a situation in which we are *very* consciously discussing whether it is justified to modify them. Again, regardless of one's view on the topic, it unreasonable to claim that we are ignoring these issues.

> I will second @graydon (among others) here; I will be sad to see this RFC merged.

I think it's clear that this is going to generate a lot (more) discussion in the near future, so it would really help if we all tried to keep our comments constructive, even if we do have strong feelings one way or another about the change 🙂",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:55:10Z,True,rust-lang_____rfcs_____2544_____453703807,"> Arguing that a change should not be made, because the first such change (even if justified) means other similar changes will be made is fallacious.

Maybe, but it's not fallacious to argue that no change of a particular type should be made (even if justified), because that leaves a clearly delineated area with clear benefits in complexity.

This may be philosophical but it's hardly ""not pertinent."" This sort of philosophy is *exactly* how we can keep ourselves from losing sight of the forest for the trees. It's really the only way we can even judge overall language complexity, and we're already on a pretty tight budget there- if we haven't blown it already.",True,True
rust-lang_____rfcs_____2544,2019-01-12T00:57:58Z,True,rust-lang_____rfcs_____2544_____453704165,"> it would really help if we all tried to keep our comments constructive

I don't think it's constructive to claim that Graydon's objections are not ""pertinent"" or to dismiss them as ""philosophical"". Nor is it constructive to accuse him of ""mistrust"".
",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:05:54Z,True,rust-lang_____rfcs_____2544_____453705177,"> To me, this reads as a matter of mistrust in the current language team's ability to regulate

Correct. I believe the current language team is failing to adequately regulate the addition of costs. And I believe in the context of a change the premise of which is to _remove an explicit category of cost-control in the language_, that is a reasonable criticism to make.

> We considering making a deliberate choice here. Nothing is done unconsciously.

You quoted half of what I said seemingly in order to misread it. The present is of course conscious: but you're consciously voting to remove the need to be conscious of such costs _in the future_. You're trading a present explicit limit that you must (by nature of its visibility) _currently_ consciously consider for a future implicit limit (which is there no matter what -- just ""out there somewhere"" in the class of ""too much complexity"") that, by nature of no longer being visible, will be unconsciously overshot.

The very fact that this limit caused people to stop and think about whether to go further _is its virtue_. You are proposing removing it, after which there will be one less explicit checkpoint that causes people to stop and think whether to go further in the future.

> If the grammar is already not LL(k), that doesn't immediately imply that any language feature that's also not LL(k) will automatically be considered as having no cost on the grammar or parser

This statement exhibits a deep misunderstanding of how these social processes work over years of people arriving, examining the current landscape, and evaluating what's acceptable or not. IOW that is _exactly_ what it implies, and if you have not noticed that that is how this process works I don't know what else to say.

> philosophical objections are not pertinent

Totally disagree.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:09:28Z,True,rust-lang_____rfcs_____2544_____453705566,"I don't think this point has been raised before: this sentence is extracted from “Making non-turbofish idiomatic” from @Centril's summary:

> Thus, to make Foo::<T> idiomatic we would need to reverse this lint and it would make virtually all Rust code thus far unidiomatic.

The very same problem will happen if this RFC is merged: either `.collect::<T>()` will become idiomatic, and virtually all Rust code thus far will become unidiomatic, or it will not, and this RFC will have changed basically nothing (well… replaced an error with a warning, but still confusing the beginner).

-----

Also, I don't think this has already been discussed: if the aim of this RFC is really only to experiment on nightly and decide afterwards, then why not make it an eRFC? Even people in favor of the current text sound like they would be more in favor of it as an eRFC than as an actual RFC.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:11:52Z,True,rust-lang_____rfcs_____2544_____453705811,"> I think it's clear that this is going to generate a lot (more) discussion in the near future, so it would really help if we all tried to keep our comments constructive, even if we do have strong feelings one way or another about the change 🙂

I am trying to be constructive; I don't have any details to add that haven't already been said, and better, by others. But we do not legislate decisions in Rust by emoji reactions, and so I feel that actually voicing dissent here, rather than just clicking a 👍 button, is of substance and is worth doing.

> philosophical objections are not pertinent

I can't disagree more strongly with this statement. This RFC is largely about various philosophies regarding the language and its development.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:14:51Z,True,rust-lang_____rfcs_____2544_____453706089,"@rpjohnst 

> Maybe, but it's not fallacious to argue that no change of a particular type should be made (even if justified), because that leaves a clearly delineated area with clear benefits in complexity.

I certainly agree that it's legitimate to argue for retaining formal properties and the merits of those as compared with other values. But let's have and continue *that* conversation. We can ask some questions:

1. What are the practical implications of losing LL(k)?
    a. Will tooling suffer considerably?
    b. How harder will implementations of Rust parsers become?
    ....
    c. in particular what are the practical implications of this specific use of backtracking?
1. Do benefits to consistency outweigh the drawbacks?

What I argue with my move to merge this RFC is that there is sufficient (you may disagree, let's discuss that...) initial motivation to try it out on nightly and gather more data. The answer to some of these questions can only truly be answered empirically.

What I object to is the notion that the language team won't consider the implications of gathered results on nightly before we have even tried. If in the future, you believe the language team has done that (e.g. if we try to stabilize ...), *then* you should make objections about dismissing gathered evidence.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:32:07Z,True,rust-lang_____rfcs_____2544_____453707723,"Okay, after thinking about this a bit more, here is something new that I can bring to this thread.

We're at the start of the year for Rust's development. We do not have a roadmap yet, but looking over the Rust 2019 posts, many, many people have said, to some effect, ""I would like to see the rate of change slow down."" To see the language team move towards complicating the grammar significantly in order to remove a small edge case that, is in many ways, beloved on its own, is disheartening. And, as the first decision of the year, in some ways, it sets the tone for the year.

Your summary is an *amazing* summary, @Centril . I think we can all agree on that. But an excellent summary comment does not a good feature make. To weigh in on one aspect of this change that I do have significant experience with:

> In closing, because of the strong motivation in improving consistency and learnability,

I have spent a *lot* of time helping people learn Rust. The existence of the turbofish is nowhere near the top of things I'd want to have to improve the learnability of Rust. It is, at worst, a minor speedbump.

In order to not add to a pile of replies, I'll leave it at that. But I do think this is the wrong decision, for a number of reasons, ""philosophical"" and not.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:34:09Z,True,rust-lang_____rfcs_____2544_____453707907,"IMO comments like ""I agree with this sentiment"" or ""I disagree with this sentiment"" without additional context aren't much more valuable than emoji reactions. This is a hard discussion to have, since people have long-held opinions here that are contributing to a great deal of frustration on all sides.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:36:25Z,True,rust-lang_____rfcs_____2544_____453708156,"First of all, I'm incredibly enthusiastic about this change, and I feel it removes a major pothole for users. And I found @Centril's write-up excellent and quite clear.

@rfcbot reviewed

That said, I do feel that it would be appropriate to explicitly state in the RFC that this is *not* precedent for any future non-LL(k) grammar changes, and that any such proposals must be independently evaluated.

@rfcbot concern please-explicitly-disclaim-grammatical-precedent",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:48:51Z,True,rust-lang_____rfcs_____2544_____453709244,"> You quoted half of what I said seemingly in order to misread it.

I apologise if it seemed that way. It was not intentional.

> You're trading a present explicit limit that you must (by nature of its visibility) currently consciously consider for a future implicit limit

Right: I misinterpreted your previous comment. You're saying that to be justified in making a decision that alters limits, it is very important to be completely explicit about what limits would exist afterwards, to make sure making such changes in the future is not made any easier. It's about ensuring accountability, regardless of whether or not there's currently trust in the system. I agree this *isn't* something that has currently been addressed and is something that is important to address.

> IOW that is exactly what it implies

I suppose this is precisely what accountability in terms of explicit limits is about: making sure it doesn't matter how careful such discussion in terms of implicit limits and consequences is.

> > philosophical objections are not pertinent

> I can't disagree more strongly with this statement. This RFC is largely about various philosophies regarding the language and its development.

That's precisely my point: the discussion this RFC is generating at the moment is about the design of the language as a whole. It becomes difficult to differentiate discussion that's relevant to turbofish, say, from discussion that's about the right way to make design choices for the language. One may be a prerequisite topic, but I think it should be a discussion in its own right, rather than taking over the discussion of a particular design. These arguments are ones that could be made with respect to really *any* large feature.

I'm not arguing that philosophical discussions are not important in general (on the contrary: I really do). I think simply that we should identify the concerns specific to this proposal and specific to Rust's evolution in general, which is a much wider discussion. This proposal might bring many of these concerns to the forefront, but it doesn't mean that this proposal encompasses or represents all of these wider concerns.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:52:18Z,True,rust-lang_____rfcs_____2544_____453709531,"I'm in strong agreement with @steveklabnik here. The juice does not seem worth the squeeze. This change implies a lot of work, not only in implementing it, but also _migrating away_ from it in the ecosystem. Sometimes that's worth doing. But, in my opinion, I don't think turbofish is enough of a problem to justify this change.",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:52:30Z,True,rust-lang_____rfcs_____2544_____453709553,"> One may be a prerequisite topic, but I think it should be a discussion in its own right, rather than taking over the discussion of a particular design.

Then this RFC should be tabled until that discussion has been held.

> These arguments are ones that could be made with respect to really _any_ large feature.

The feature is tiny. The consequences of the change are extensive.
",True,True
rust-lang_____rfcs_____2544,2019-01-12T01:56:42Z,True,rust-lang_____rfcs_____2544_____453709856,"I'd like to emphasize that costs are contextual.  The fact that this change would make it impossible for classical parser generators to parse Rust is certainly significant.  But I think it's also significant that it would add *very little* complexity to any parser implemented with recursive descent, apparently including all the codebases people are actually using to parse Rust at the moment (except vim, but as mentioned previously, vim.rs already uses a very crude approximation of Rust's grammar).  It's not just a matter of saying ""parsing complexity is fine as long as it's technically decidable"" – a motto you might ascribe to C++, say, or even C given the lexer hack.  It's ""excluding this type of parser generator is okay if the costs are otherwise reasonable"".

To look at it another way, even though the current Rust grammar is ""simple"" from the perspective of a classical parser, from other perspectives it's quite complicated/awkward.  A few years ago I wrote a syntax extension to add Swift-like named argument syntax to Rust, basically by desugaring `foo(a: b, c: d)` into something like `foo__a_c(b, d)`.  For various reasons, I decided to implement this using my own minimalist parser rather than using an existing one.  For one, `syn` didn't exist at the time and I was worried about compile times using `syntex_syntax`.  Also, I wanted my plugin to do its best to accept unknown syntax and pass it through, for the sake of compositionality: I was already adding new syntax on top of stock Rust, and if someone wanted to use my plugin in conjunction with another that did the same, one of the plugins would have to run first, and pass through instances of the other's added syntax.

Luckily, I could implement that desugaring while being oblivious to most of Rust's syntax.  An identifier followed by an open paren, for example, is (AFAIK) guaranteed to be a function call unless either (a) the identifier is one of the `Fn` traits or (b) before the identifier is the keyword `fn` (making it a function definition instead).  However, for some reason I did want to keep track of the delimiter nesting structure of the code; in retrospect I'm not sure whether this was actually necessary, but it seemed so at the time.  But to do that, I had to distingush between the two meanings of `<`, which meant I had to distinguish between type and expression context.  So I had to implement rules like ""`:` introduces a type unless it's in a struct literal"" and ""an identifier followed by `{` might be the start of a struct literal, or it might be the end of something like `if foo = bar {`"".  This made the parser a lot more complicated than it would have been if Rust hadn't repurposed `<` as both a delimiter and an operator.  Even though a full Rust parser can distinguish between expression and type state with no trouble, even with classical algorithms, it was still an obstacle for a more limited parser.  And while the remove-turbofish change now being proposed wouldn't have made its job any easier, it wouldn't have made it particularly harder either; it would only add a bit extra to the large amount of ambiguity that already exists from its perspective.

Incidentally, another (more minor) bugbear was lambda syntax.  Differentiating between lambdas and the binary `|` operator requires differentiating between two different states within expression context: whether we're (a) expecting an expression or unary operator, or (b) after an expression, expecting a binary operator or the end of the block.  Of course, that's table stakes for a proper parser; but for my purposes I think I could have gotten away with not distinguishing them, reducing the number of grammar rules my parser had to care about, if Rust had used a different lambda syntax.  Just for a bit of perspective.

So what's my point?  I'm not saying that Rust's syntax being complicated in some ways is a reason to add other types of complexity out of pure spite. _(...probably.)_  Rather, I'm suggesting that we're not at as sharp a precipice as it might seem.  Abandoning LL(k) is not necessarily crossing the Rubicon; it's just crossing one Rubicon among others, some of which have already been crossed, others of which won't be crossed even with this change.  It's still a cost, and thus worth considering very carefully.  But it's not an all-or-nothing decision of whether Rust should be parser-friendly or not.
",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:03:14Z,True,rust-lang_____rfcs_____2544_____453710318,"@rfcbot concern too-uncertain-for-its-value

I always liked the first slide from http://venge.net/graydon/talks/intro-talk-2.pdf:

> Technology from the past come to save the future from itself

Or, further in,

> Concentrate on known  ways of achieving
> - more safety,
> - more concurrency,
> - less mess

And I don't feel like a potential GLL parser is that.

I can't help but feel like this is another RFC where I think that diagnostics -- which aren't part of a hypothetical language spec and where speculative fancier things as quality of implementation improvements is fine -- are the right place to solve the problem, not language changes.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:14:25Z,True,rust-lang_____rfcs_____2544_____453711097,"> it's just crossing one Rubicon among others, some of which have already been crossed, others of which won't be crossed even with this change

That this rationale occurs here and now ought to give pause (and confirmation to my point above re: how this process works socially). This is what the future will hold: someone will say this exact same sentence about _this_ Rubicon when justifying proceeding over the _next_ one. I'm suggesting that having one that is actually the _last_ one is intrinsically valuable.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:22:04Z,True,rust-lang_____rfcs_____2544_____453711635,"It's a mistake to take metaphors and analogies too literally, but ""it's just crossing one Rubicon among others"" is quite ironic. The significance of Caesar crossing the Rubicon was that it was an irreversible step with immense consequences.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:29:24Z,True,rust-lang_____rfcs_____2544_____453712137,"Well, if there's a possibility of reversing this change even after it goes through extensive nightly testing and possible adoption on the stable language in a future edition, then I'm ok with it.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:31:16Z,True,rust-lang_____rfcs_____2544_____453712287,"> I'm in strong agreement with @steveklabnik here. The juice does not seem worth the squeeze. This change implies a lot of work, not only in implementing it, but also _migrating away_ from it in the ecosystem. Sometimes that's worth doing. But, in my opinion, I don't think turbofish is enough of a problem to justify this change.

I don't think there needs to be any real urgency to migrate away from it.  In particular, personally I wouldn't want the compiler to even warn about turbofish usage until a significant amount of time has passed since the new syntax became available.

@steveklabnik 
> We do not have a roadmap yet, but looking over the Rust 2019 posts, many, many people have said, to some effect, ""I would like to see the rate of change slow down."" To see the language team move towards complicating the grammar significantly in order to remove a small edge case that, is in many ways, beloved on its own, is disheartening. 

I don't have a very strong opinion on whether turbofish removal is a good feature or not.  But personally, I'm disheartened by the suggestion that Rust needs to slam the brakes on language changes.  There are so many little features that have been blocked for years on the state of the compiler implementation.  Some of them have RFCs already accepted (which I realize nobody is proposing to get rid of) – but others have RFCs postponed, and still others never got past the pre-RFC or issue stage, just because someone realized early on that they wouldn't be possible to implement anytime soon.  Many of these features have little user-facing complexity overhead, or even negative.  As one example, given
```rust
fn foo<T>() {
    type B = Box<T>;
}
```
...it's pretty obvious what this should do, and from a user's perspective, the fact that it doesn't work is itself an unnecessary bit of complexity.  Adding support for it would effectively reduce complexity.

But there are other features which *would* add user-facing complexity.  There are certainly valid rationales for opposing them.  Yet some of them would have made it into the language earlier on, with much less opposition, if not for implementation blockers.  They aren't necessary to have.  But they're not extraneous either; they would round out the language, make it more elegant.  Freezing Rust forever based on the state of the implementation at a certain time leads to a design that's random, arbitrary.

Admittedly, that doesn't negate the fact that every change has a real cost to the continually increasing number of users who already use Rust – regardless of how good an idea it would have been 'back in the day'.  It's hardly *unusual* in software to see ancient implementation artifacts preserved for the ages for compatibility reasons.  But... it's disappointing.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:39:40Z,True,rust-lang_____rfcs_____2544_____453712891,">  I'm disheartened by the suggestion that Rust needs to slam the brakes on language changes.

Where did anyone suggest that? If there's one thing that is not constructive, it's using loaded language and hyperbole to misrepresent actual arguments.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:39:50Z,True,rust-lang_____rfcs_____2544_____453712899,"> It's a mistake to take metaphors and analogies too literally, but ""it's just crossing one Rubicon among others"" is quite ironic. The significance of Caesar crossing the Rubicon was that it was an irreversible step with immense consequences.

My point is that there are many different types of irreversible steps Rust either could take or has taken, some of which (I argue) have consequences comparable to this one.

After all, because of backwards compatibility, every bit of added complexity is irreversible.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:39:56Z,True,rust-lang_____rfcs_____2544_____453712906,"> I'm disheartened by the suggestion that Rust needs to slam the brakes on language changes

I think I'm less disheartened than you might be, because many of those posts _also_ tend to want complex and many-changes-needed things like type-level integers.  ([Random example](https://blog.cessen.com/post/2018_12_12_rust_2019_its_the_little_things))

So overall I read the posts more as ""there's lots of good stuff already on the list; let's spend our available effort on those first"" than as ""nothing should be changed"".",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:42:35Z,True,rust-lang_____rfcs_____2544_____453713056,"> > I'm disheartened by the suggestion that Rust needs to slam the brakes on language changes.
> 
> Where did anyone suggest that? If there's one thing that is not constructive, it's using loaded language and hyperbole to misrepresent actual arguments.

For example, from [@steveklabnik's Rust 2019 blog post](https://words.steveklabnik.com/thoughts-on-rust-in-2019):

> Well, there are a few features that are in the pipeline that I do think should land [...]
>
> But after that? I’d like to see a moratorium on major features until 2020, and I’d prefer if we limited 2020 to two or three, if any.
>
> We’ve hit a sweet spot. We’ve always said that Rust 1.0 was about stability, not completeness. I think we’re fast approaching completeness.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:43:18Z,True,rust-lang_____rfcs_____2544_____453713093,"> 
> 
> > It's a mistake to take metaphors and analogies too literally, but ""it's just crossing one Rubicon among others"" is quite ironic. The significance of Caesar crossing the Rubicon was that it was an irreversible step with immense consequences.
> 
> My point is that there are many different types of irreversible steps Rust either could take or has taken, some of which (I argue) have consequences comparable to this one.
> 
> After all, because of backwards compatibility, every bit of added complexity is irreversible.

Again, my point was that the use of that metaphor is ironic. If this really is a crossing of the Rubicon, that would be a very strong argument not to do it. But again, metaphors aren't literal so it would be a mistake to argue from the consequences of Caesar's actions to whether this RFC is advisable.

And regardless of what is arguable, the question here is the cost in terms of consequences -- which includes the effort hashing out the philosophical issues and the strain on human relationships -- relative the benefit of the change.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:45:27Z,True,rust-lang_____rfcs_____2544_____453713279,"Hopefully we can return to discussing the merits and demerits of LL(k), the specific ambiguities in this RFC, and the merits and demerits of this RFC's motivation. I think things are getting quite off-topic.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:48:22Z,True,rust-lang_____rfcs_____2544_____453713490,"> 
> 
> Hopefully we can return to discussing the merits and demerits of LL(k), the specific ambiguities in this RFC, and the merits and demerits of this RFC's motivation. I think things are getting quite off-topic.

We were told that those aren't pertinent (and you hearted that). Again, my view is that this RFC should be shelved if resolving the philosophical issues is a prerequisite.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:53:58Z,True,rust-lang_____rfcs_____2544_____453713833,"> For example, from [@steveklabnik's Rust 2019 blog post](https://words.steveklabnik.com/thoughts-on-rust-in-2019):

I'm not going to get dragged off to someone's blog entry. If it's not an argument made here, then it's not ""pertinent"".",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:54:17Z,True,rust-lang_____rfcs_____2544_____453713849,"**Moderator note:** @jibal Please stop the tit-for-tat and picking excessively at folks' language. We should all be participating in this discussion with an assumption of good faith. If you have a problem with this, please email the Rust mods at rust-mods@rust-lang.org. Do not litigate it in this thread.",True,True
rust-lang_____rfcs_____2544,2019-01-12T02:57:43Z,True,rust-lang_____rfcs_____2544_____453714059,"> 
> 
> **Moderator note:** @jibal Please stop the tit-for-tat and picking excessively at folks' language. We should all be participating in this discussion with an assumption of good faith. If you have a problem with this, please email the Rust mods at [rust-mods@rust-lang.org](mailto:rust-mods@rust-lang.org). Do not litigate it in this thread.

Nice picking on me and accusing me of bad faith. I will now unsubscribe.",True,True
rust-lang_____rfcs_____2544,2019-01-12T03:11:19Z,True,rust-lang_____rfcs_____2544_____453714777,"One big problem we have with this RFC is that at this point there can only be arguments for the learnability benefits and aesthetic/ideological reasons and against the complexity of implementation/knock down effects on diagnostics/interactions with other features and aesthetic/ideological reasons.

I personally lean against this change in particular for (in my view) pragmatic reasons against wanting to see negative interactions with existing codebases. There have been proof of concepts showing that the feature _can_ be reasonably implemented and we can see the effect of it on our existing tests, but I worry what the feature being used could break havoc on code during development (incomplete code, incorrect code, etc.).

There _is_ a ticket to start collecting metrics from the compiler. If we had that, we could run the new behavior in the background and see if there's a big increment of errors between the two parser behaviors, that way we could get real, hard numbers, instead of opinions. But without that we can only use our best judgement/experience/biases to evaluate wether this change is worth it.

Personally I don't find it as a reasonable wart of the language that will not stop anyone that could learn the language from learning it. I don't see the turbofish as any different to [requiring people to write parenthesis around the structs in `if (T {}) == (T {}) { println!(""Ok""); }`](https://github.com/rust-lang/rust/pull/51360) or [requiring a space between `<` and `-` in `if x<-1 {}`](https://github.com/rust-lang/rust/pull/51883): a limitation that can be annoying, but one that we help as much as possible (and suggestions can _very_ easily be applied in RLS enabled editors).
",True,True
rust-lang_____rfcs_____2544,2019-01-12T03:31:07Z,True,rust-lang_____rfcs_____2544_____453715762,"> I am trying to be constructive; I don't have any details to add that haven't already been said, and better, by others. But we do not legislate decisions in Rust by emoji reactions, and so I feel that actually voicing dissent here, rather than just clicking a 👍 button, is of substance and is worth doing.

I thought that the very reason we ""do not legislate decisions in Rust by emoji reactions"" is exactly to discourage voicing consent/dissent without adding new arguments. I hope we're making decisions based on the strength of arguments, not the people or the number of people in consent/dissent. With all due respect, statements such as ""I would be very sad to see this merged"" really don't contribute anything to the discussion (for the record, neither do statements such as ""I can't wait for this to be merged"") -- as it brings emotional weight to the table, almost accusing the opposing party of hurting one's feelings.

> There is a ticket to start collecting metrics from the compiler. If we had that, we could run the new behavior in the background and see if there's a big increment of errors between the two parser behaviors, that way we could get real, hard numbers, instead of opinions. But without that we can only use our best judgement/experience/biases to evaluate wether this change is worth it.

This is a great idea. Is there a link to the ticket? Given the stalemate we're in in terms of opinions, actual data would help so much.",True,True
rust-lang_____rfcs_____2544,2019-01-12T03:38:21Z,True,rust-lang_____rfcs_____2544_____453716146,">>There is a ticket to start collecting metrics from the compiler. If we had that, we could run the new behavior in the background and see if there's a big increment of errors between the two parser behaviors, that way we could get real, hard numbers, instead of opinions. But without that we can only use our best judgement/experience/biases to evaluate wether this change is worth it.
>
>This is a great idea. Is there a link to the ticket? Given the stalemate we're in in terms of opinions, actual data would help so much.

@Wyverald https://github.com/rust-lang/rust/issues/45857. It is not a trivial amount of work though.",True,True
rust-lang_____rfcs_____2544,2019-01-12T04:24:16Z,True,rust-lang_____rfcs_____2544_____453718441,"As a compiler writer, I don't see LL(k) as something that particularly matters. Parsing technology has improved since the '70s. What's wrong with using the newer technology if it makes the language easier to use?

As far as ""philosophy"" goes, my philosophy is this: Programming languages are tools, nothing more. That means we should make the best tools we can, of course, but we need to be mindful that we are simply making tools for a particular practical purpose. (In the case of Rust, that's making systems programming safer and more approachable.) Formalism can be useful for programming languages, but only insofar as it helps those languages achieve their goals better. For example, a formal model of the type system can help prove that the language does indeed achieve its goal of memory safety. A formal model of the grammar can be useful to help make tooling easier to write or to detect parsing ambiguities.

What I don't see the need for is formalism *for its own sake*, and this is why I'm confused as to the objections here. It's worth asking *why* we seem to want the LL(k) property. And I don't mean just ""it might be easier to write tooling with LL(k)"". I mean, what tools, *specifically*, can you not usefully write with a grammar that requires unbounded lookahead? Is there an editor that does not allow grammars with unbounded lookahead? That, to me, is a much more interesting question than theoretical formalisms. Formalism is a *means*; it is not an *end*.",True,True
rust-lang_____rfcs_____2544,2019-01-12T04:39:29Z,True,rust-lang_____rfcs_____2544_____453719129,"It's worth remembering, by the way, that LL(k) is by definition nothing more than ""a grammar that one particular parsing algorithm from the 1960s accepts"". The reason the notion of LL(k) exists is so that we can draw a line around the set of grammars that can be parsed with that type of parser. So the concept of LL(k) is only useful *insofar as we care about that particular algorithm*. Thus my question is: Why, specifically, should I care about the LL parsing algorithm?

There may well be good reasons! I'm not wedded to the idea of dropping the turbofish. But I'd like to hear who, specifically, needs to use an LL parser to parse Rust, and so far I haven't seen anyone say that they need to. Again: formalism for its own sake is uninteresting; the question is what *purpose* the formalism serves.",True,True
rust-lang_____rfcs_____2544,2019-01-12T04:42:32Z,True,rust-lang_____rfcs_____2544_____453719269,"> the question is what purpose the formalism serves

As a cost limit. There aren't a lot of ways to limit endless growth, but this is one and it's reasonably easy to articulate.",True,True
rust-lang_____rfcs_____2544,2019-01-12T04:44:32Z,True,rust-lang_____rfcs_____2544_____453719347,"> As a cost limit. There aren't a lot of ways to limit endless growth, but this is one and it's reasonably easy to articulate.

This is circular logic. I'm questioning what the cost of losing LL(k) is.",True,True
rust-lang_____rfcs_____2544,2019-01-12T04:51:50Z,True,rust-lang_____rfcs_____2544_____453719645,"It's not circular at all. _It is a limit_. Removing it is removing a limit, going from ""we have a limit"" to ""we have no limit"".",True,True
rust-lang_____rfcs_____2544,2019-01-12T04:58:32Z,True,rust-lang_____rfcs_____2544_____453719912,"> It's not circular at all. _It is a limit_.

Yes, but why is __*this*__ *specific* limit the one to pick/retain?

> Removing it is removing a limit, going from ""we have a limit"" to ""we have no limit"".

We will still have limits after this. It is *moving* or weakening a limit rather than removing all limits on grammar complexity. Given @joshtriplett's request for an explicit note about not making this a precedent (which I support) it seems things are still quite constrained; it's using backtracking in one specific *pathological* (and demonstrably non-occuring wrt. the ambiguity) instance. For example, we are not moving towards a CSG or type 0 grammar (if we forget about macros...).",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:01:42Z,True,rust-lang_____rfcs_____2544_____453720079,"Nobody is suggesting that we stop caring about what impact the complexity of the grammar has on tooling. In fact, the summary post does the exact opposite: it puts forth an argument that this grammar change will *not* have a meaningful impact on tools.

In other words, we do have a limit. Everyone agrees that we should not make changes that make it hard for tools to parse Rust. It's just that this limit is stated in terms of *practical* consequences, not theoretical ones.

And as stated before, if we want theoretical boundaries for some reason, LL(k) is a strange one to start with. LL(k) is the set of grammars parseable by a particular algorithm. If nobody is using that algorithm to begin with, I don't see why that is a particularly meaningful complexity boundary.",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:04:27Z,True,rust-lang_____rfcs_____2544_____453720247,"To elaborate on this, an example of a limit that *would* make sense to me is: ""We should not make changes to the Rust grammar that make the Vim highlighting noticeably slower, or that would make it cease to work."" Backed up with data, that would be a perfectly reasonable example of a limit.",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:22:26Z,True,rust-lang_____rfcs_____2544_____453721013,">  LL(k) is a strange one to start with. LL(k) is the set of grammars parseable by a particular algorithm

My point is it was not onerous thus far, and transgressing it here is not based on an important need or anything; it's based on a conversation about how having a limit is archaic. Which suggests that if that's the way we're thinking about limits, whatever _new_ limit is picked will just be adjusted again when it's viewed as inconvenient. LL(k) is -- to borrow a biblical phrase -- a hedge around the law. It's a barrier that is definitely far enough back from whatever real hazards exist in overcomplexity of grammar, it's obviously safe for all plausible tools, it's not hard to stay within, and it's obvious and clear as a criterion.",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:27:09Z,True,rust-lang_____rfcs_____2544_____453721215,"I guess we just fundamentally disagree about whether it's worthwhile to have limits that don't have specific practical reasons for their existence (i.e. ""if we break limit X, then undesirable thing Y will necessarily happen as a result""). I don't know what to call such limits other than ""arbitrary"". (Which, of course, is not to say that I don't see the point in limits at all; I just prefer practical ones.)",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:36:03Z,True,rust-lang_____rfcs_____2544_____453721588,"Undesirable thing Y is ""the grammar is too complex for a human to understand or a machine to parse or the maintainers to keep straight"" and it absolutely will happen _eventually_ if we have no limit and keep expanding. The only question is whether we stay back from this event _by policy_ -- which means picking a limit that denotes a place _before_ it happens -- or remove checks on it until it's too late, encountering the limit _after_ it happens.

It's like this: you've got a radiation badge and a Geiger counter. The badge will tell you that you just got a fatal dose of radiation. The Geiger counter is going to tick a bunch before you get to the fatal radiation but it'll also tell you when you're at, say, 1000 milirems, which _is_ a safe place but is also probably a place you might want to stop walking in the direction of increasing ticks in order to _avoid the fatal radiation_. Do you look at the badge and say ""well hey I can tell when I've been irradiated so let's get rid of the Geiger counter""?",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:43:02Z,True,rust-lang_____rfcs_____2544_____453721898,"We all agree that the grammar needs to be understandable and that the machine should be able to parse it. The disagreement is whether sacrificing LL(k) hurts those two goals. So far, I haven't seen any compelling reasons why LL(k) affects human readability or the ability of the machine to parse the language.

It may well be that losing turbofish makes it harder for a human to understand Rust code! But, if so, the LL(k) property doesn't have anything to do with it. Humans don't use LL(k) parsers.",True,True
rust-lang_____rfcs_____2544,2019-01-12T05:56:49Z,True,rust-lang_____rfcs_____2544_____453722513,"From a big picture point of view: Rust is still a pretty easy language to parse. With my compiler writer hat on, ordering popular languages from hardest to easiest to parse, I guess I'd come up with something like:

Tier 1:
* Perl
* C++

Tier 2:
* PHP
* Ruby
* C
* Scala
* JavaScript

Tier 3:
* Python
* Rust
* Scheme (expanding macros)
* Lisp (likewise)

Tier 4:
* Java
* C#
* Go

Tier 1 is basically ""parsing is intertwined with semantics in arbitrary ways"". Tier 2 is ""needs lexer hacks"" (e.g. JavaScript's context-sensitive lexing of `/`). Tier 3 is ""doesn't need lexer hacks, but is somewhat complex and/or needs macro expansion"". Tier 4 is the simplest.

I would say that only tier 1 can really be characterized as ""not understandable by a human and not parseable by anything other than the reference implementation"". The others have or could reasonably have independent implementations.

Note that the difficulty of parsing Rust in practice mostly has to do with macros and has little to do with the complexity class of the grammar. I think we've done a good job so far keeping the language relatively friendly for tooling as far as parsing is concerned, and, moreover, we have a long way to go before we run into trouble.",True,True
rust-lang_____rfcs_____2544,2019-01-12T06:31:18Z,True,rust-lang_____rfcs_____2544_____453724105,"> The main positive motivation of this RFC is consistency and by extension making Rust easier to learn. That is, having to use turbofish for function application is, as noted in the motivation an unexpected corner case.

As someone who trains rust professionally and has probably the most training experience under their belt, I disagree with this.

While I agree that the presented cases are valid, but I feel like this argument is applied selectively here. It _is_ and unexpected corner case, but it also doesn't matter. Rust has tons of learnability problems, but this extremely far down the list.

* Turbofish is a rather rare syntax in use and easy to learn once you know it
* It's verbose, but that's fine, as usage is rare
* Its confusion with `Vec::<u8>` is _not_ an issue of the Turbofish, but of the `Vec::<u8>` syntax
* It's a single, self-contained bit of knowledge
* I agree with @H2CO3 that the turbofish also serves as a marker

At worst, Turbofish is what I call an _odd fact_. _Odd facts_ are not necessarily easy to uncover, but rather easy to keep in mind as you learn them.

What confuses me is that this always pops up around syntax, while we are _extremely happy_ to keep or introduce odd facts in other places in the language, leading to much more confusion and _much harder_ ways around. Just as examples:

* `impl Trait` is not available in traits. That's an `odd fact`, figuring out the the semi-replacement (bounded associated types) is hard and applying it is _verbose_.
* `where ...` is not considered when detecting overlap trait implementations. That's an `odd fact` and hard to circumvent if you hit it.
* Lifetime syntax is _incredibly_ hard to figure out just by reading code and a place where a lot of tutoring is needed

If verbosity is seriously the argument, we need to start doing a push towards removing verbosity from the language. I guess we can all agree that the boat ""Rust is a verbose language"" has sailed.

If consistency is the argument, there's far more long-standing issues with language consistency to be fixed before caring about turbofish.

Making turbofish the corner case that matters is weird: programming languages are full of corner-cases, that comes from the complexity of the domain. People are _used_ to those. There's popular programming languages that are basically all edge-cases. I'm not saying that's a good thing, but a corner-case does _not_ necessarily make a language harder to learn, especially if they are simple facts with rare application.

I hate to say this, but I get the impression that the Turbofish is an instance of the bikeshedding problem: small enough to argue about, standing out enough for people to care and the willingness to get rid of it at all cost.

I strongly oppose that change, I find the core argument unconvincing and the repercussions to serious and unpredictable. I agree with @graydon that boundaries should be crossed with great care and motivation, this change does not give enough motivation. I appreciate some people don't care about the boundary. But it has been existing and respected for a long time and has a reasoning, I think this issue does not carry its weight to change the reasoning.

The FCP of an RFC is also _the worst place_ to have arguments about the parser complexity of a language. As long as that discussion is ongoing, I recommend shelving the RFC.

Finally, I'd like to add that - as a project - we currently have tons of things on our plates. Seeing the impact on tooling and other RFCs in this discussion doesn't make my heart happy :/.

All respect to @varkor for trying again and again, but I think we should care about other issues currently.",True,True
rust-lang_____rfcs_____2544,2019-01-12T06:54:05Z,True,rust-lang_____rfcs_____2544_____453725128,"I have to say that the idea of having self-imposed limits that we can never breach, even if the limit is ultimately shown to be pointless, concerns me. It seems to me to be irrational--like, objectively so--for us to come to the conclusion that a limit is arbitrary, yet continue to impose that limit upon ourselves. Especially since this supposed LL(k) limit wasn't ever something that was formally documented that I recall.

Needless to say, I don't believe that Rust could have succeeded if it was this dogmatic in the early days. The changes that we made that were hugely controversial at the time because they breached some arbitrary limit are now completely uncontroversial. (For example, we used to have a 5 character limit on keywords!) The changes are now universally accepted precisely because, while these changes had effects on the formalism, they didn't have negative effects in practice, and as Rust is an industry language the practice is ultimately what matters.

I think the discussions at the beginning of this thread were a lot more productive than the more recent discussions. Discussions about subjective readability and learnability are extremely important: that's the whole reason to make (or not make) this change, after all. Discussions about whether the grammar conforms to some formalism tied to a particular algorithm from the '60s seem to me to be irrelevant.",True,True
rust-lang_____rfcs_____2544,2019-01-12T06:58:27Z,True,rust-lang_____rfcs_____2544_____453725337,"> It seems to me to be irrational--like, objectively so--for us to come to the conclusion that a limit is arbitrary, yet continue to impose that limit upon ourselves

Did you just like completely miss all the commentary I made above about making a benign and observable limit that is well-short of the one you're worried about, to be sure you don't hit the bad one?",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:02:08Z,True,rust-lang_____rfcs_____2544_____453725553,"My point is that I perceive the motivations of the change odd in the first place, given its context within the subjects of learnability and readability and that the repercussions at large don't merit the change.

I have absolutely zero issue with us deciding to go move up the grammar ladder given enough motivations, I don't feel this is the good time and place.

> I think the discussions at the beginning of this thread were a lot more productive than the more recent discussions.

Also note that this _is_ the FCP phase, so I'm confused how the lower part of the discussion is kind of devalued. People are made aware of the RFC for that reason again and people now weight the argument in @Centril's summary.

> Discussions about subjective readability and learnability are extremely important: that's the whole reason to make this change, after all. 

Yes, but we don't invest a lot of time to provide them with proper footing, making this a playground of people with enough time and privilege to promote their opinion.

> Discussions about whether the grammar conforms to some formalism tied to a particular algorithm from the '60s seem to me to be irrelevant.

I'm sorry, but I don't appreciate that sentence. Techniques from the 60s don't lose their validity just because the 60s are long ago.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:04:37Z,True,rust-lang_____rfcs_____2544_____453725686,"Limits are *not* benign if adhering to them imposes costs somewhere else. (In this case, the cost is learnability and readability.)

Furthermore, your analogy presupposes that we can't know when we've made the language unable to be read by humans or machines, and so we have to be extremely conservative. But that isn't the case: as I argued above in my tier list, the problems occur when you intertwine parsing and semantic analysis, or at the very least when you introduce lexer hacks. Nobody is proposing doing either.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:08:15Z,True,rust-lang_____rfcs_____2544_____453725856,"> I'm sorry, but I don't appreciate that sentence. Techniques from the 60s don't lose their validity just because the 60s are long ago.

They do if those techniques are obsolete. Strict LL parsers are obsolete now.

If being backward compatible with compiler technology of the 1960s was a constraint, then we'd have to introduce the `register` keyword to Rust, because good register allocation was impractical back in those days.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:10:46Z,True,rust-lang_____rfcs_____2544_____453725979,"> Limits are _not_ benign if adhering to them imposes costs somewhere else. (In this case, the cost is learnability and readability.)

Can you give me a rough estimation of the time wasted on newcomers by learning turbofish (which, in itself is a feature usually more for advance programming) and the cost introduced to readibility, measured at a codebase of - say - 10000 lines of code? Preferably compared to other language features?

I don't want to say that these are not issues, but as we are only comparing experiences, my experiences of turbofish being not a huge issue is as valid as yours that seems to make it a huge issue.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:11:05Z,True,rust-lang_____rfcs_____2544_____453726012,"> In this case, the cost is learnability and readability

In this case, that cost is defined by reference to 5 comments on the internet. I can find 5 comments about _anything_ in rust that confused someone. The thousands of crates authored were written by people who seem not to have been stumped by this. The language is learnable as-is, and where it's not, we've got feedback from people here who teach rust who say this is not one of the actual problems. It's just _something someone wants to change_.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:12:47Z,True,rust-lang_____rfcs_____2544_____453726137,"> What confuses me is that this always pops up around syntax, while we are _extremely happy_ to keep or introduce odd facts in other places in the language, leading to much more confusion and _much harder_ ways around. Just as examples:
> 
> * `impl Trait` is not available in traits. That's an `odd fact`, figuring out the the semi-replacement (bounded associated types) is hard and applying it is _verbose_.

This is not a state of affairs that anyone's ""extremely happy"" to have; it's more like `impl Trait` as a feature is not finished yet.  The original `impl Trait` RFCs [still not quite fully implemented](https://github.com/rust-lang/rust/issues/34511) – well, I can't tell whether `existential type` is 'done', but if so, it only recently became that way, and both it and `impl_trait_in_bindings` are not yet stable.  Also relevant are GATs, which are waiting on Chalk: `impl Trait` returns from a generic trait method are equivalent to a GAT.  Once that stuff is done, I'm pretty sure `impl Trait` in traits is highly desired, especially for the sake of `async fn`.

> * `where ...` is not considered when detecting overlap trait implementations. That's an `odd fact` and hard to circumvent if you hit it.
This is not true in general; e.g. this compiles, but not if the `where` is removed:
```rust
trait Foo {}
trait Bar {}
impl<T> Foo for T where T: Bar {}
impl Foo for i32 {}
```
But there are some cases that aren't handled, such as bounds with distinct associated types.  IIRC this is yet another thing that's waiting on implementation work, in particular Chalk.

> * Lifetime syntax is _incredibly_ hard to figure out just by reading code and a place where a lot of tutoring is needed
Lifetime syntax is an area where significant changes and improvements have been made over time, most recently with the addition of implicit lifetime bindings.  It's still tricky, in large part because lifetimes are fundamentally complex.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:13:55Z,True,rust-lang_____rfcs_____2544_____453726178,"I personally find turbofish to be ugly and unintuitive, because it deviates from the type syntax. But, as always, with something subjective I'm happy to be outvoted if people do in fact like the turbofish.

There are plenty of things I didn't get my way with; I filed an RFC way back in the day to rename `i32` to `int32` that went over like a lead balloon and I was completely fine with that. :)",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:15:27Z,True,rust-lang_____rfcs_____2544_____453726230,"> But there are some cases that aren't handled, such as bounds with distinct associated types. IIRC this is yet another thing that's waiting on implementation work, in particular Chalk.

Sure, I know. But this is work that doesn't even need an RFC, yet, we're spending time on this RFC to remove an easy-to-learn edge case. ",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:16:36Z,True,rust-lang_____rfcs_____2544_____453726278,"> I personally find turbofish to be ugly and unintuitive, because it deviates from the type syntax. But, as always, with something subjective I'm happy to be outvoted if people do in fact like the turbofish.

And I would agree with you on that. I don't _like_ it. I have no issue with it being there, though and am staggered by the amount of time spent to remove it. If it were to unlock 4-5 features downstream, I'd be much more up for it.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:22:34Z,True,rust-lang_____rfcs_____2544_____453726563,"> Sure, I know. But this is work that doesn't even need an RFC, yet, we're spending time on this RFC to remove an easy-to-learn edge case.

Are you suggesting that instead of participating in an RFC, we should be going and working on the compiler implementation?  If so, that's a nice sentiment, but it's easier said than done; certainly it would take me far more time to get up to speed on the current status of Chalk than it takes to post here.  If that's not what you meant, I don't see your point, since those things are entirely orthogonal.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:30:26Z,True,rust-lang_____rfcs_____2544_____453726975,"> In this case, that cost is defined by reference to 5 comments on the internet. I can find 5 comments about _anything_ in rust that confused someone. The thousands of crates authored were written by people who seem not to have been stumped by this. The language is learnable as-is, and where it's not, we've got feedback from people here who teach rust who say this is not one of the actual problems. It's just _something someone wants to change_.

It may be true that the supposed cost has not been adequately established by concrete evidence; I do agree @steveklabnik's opinion on the matter is highly significant, due to his experience with teaching Rust.  On the other hand, absence of evidence is not evidence of absence.  IMO, the concept of ""complexity budget"" is key here: even if turbofish isn't itself the breaking point that drives someone away from Rust, it's yet another thing to learn in a language that's renowned for being hard to learn – one that, unusually, doesn't need to exist.",True,True
rust-lang_____rfcs_____2544,2019-01-12T07:31:37Z,True,rust-lang_____rfcs_____2544_____453727033,A turbofish that only shows up in old or weird code is arguably worse for the complexity budget than a turbofish that shows up consistently.,True,True
rust-lang_____rfcs_____2544,2019-01-12T07:33:14Z,True,rust-lang_____rfcs_____2544_____453727119,"I disagree.  Turbofish shows up very early when learning Rust, for things like `collect::<Vec<_>>` – much earlier than you'd be likely to be perusing ""old or weird code"".",True,True
rust-lang_____rfcs_____2544,2019-01-12T08:15:44Z,True,rust-lang_____rfcs_____2544_____453729352,"> Are you suggesting that instead of participating in an RFC, we should be going and working on the compiler implementation? If so, that's a nice sentiment, but it's easier said than done; certainly it would take me far more time to get up to speed on the current status of Chalk than it takes to post here. If that's not what you meant, I don't see your point, since those things are entirely orthogonal.

No, I'm suggesting that the language _as is_ already has a lot of places that need to be fixed in the accepted boundaries and accepting new RFCs with such downstream repercussions as this doesn't improve the situation. This is certainly something that needs to be weighted, some changes might be worth doing this tradeoff, I don't feel this one belongs to it.",True,True
rust-lang_____rfcs_____2544,2019-01-12T08:22:55Z,True,rust-lang_____rfcs_____2544_____453729766,"> I disagree. Turbofish shows up very early when learning Rust, for things like collect::<Vec<_>> – much earlier than you'd be likely to be perusing ""old or weird code"".

The hard part here is not the turbofish syntax, but learning that you need to explicitly need to parametrize _collect_ here in some way.",True,True
rust-lang_____rfcs_____2544,2019-01-12T08:36:15Z,True,rust-lang_____rfcs_____2544_____453730518,"> * Its confusion with `Vec::<u8>` is _not_ an issue of the Turbofish, but of the `Vec::<u8>` syntax

@skade I have no idea what you mean by this, `Vec::<u8>` *is* turbofish syntax (which in turn is a variant on type-application where the other variant is `Vec<u8>`). Please elaborate.",True,True
rust-lang_____rfcs_____2544,2019-01-12T08:42:13Z,True,rust-lang_____rfcs_____2544_____453730876,"@centril sorry, I changed the wording. Thanks for noticing that, I wrote this before first coffee ;).",True,True
rust-lang_____rfcs_____2544,2019-01-12T08:45:23Z,True,rust-lang_____rfcs_____2544_____453731014,"> It may be true that the supposed cost has not been adequately established by concrete evidence; I do agree @steveklabnik's opinion on the matter is highly significant, due to his experience with teaching Rust.

What's the bar to be considered relevant here? I'm the trainer for the European Mozilla Rust teams, have a trainer crew of five and run the oldest learners meetup worldwide. I hate pulling credentials, but it seems necessary.",True,True
rust-lang_____rfcs_____2544,2019-01-12T09:36:17Z,True,rust-lang_____rfcs_____2544_____453733727,"There's a lot of discussion of parsing formalisms in here and, since I've ended up doing more research in that area than I ever wanted to, I thought it might be worthwhile to give my 2p worth. Sorry in advance!

I have written langauges and parsers in the following styles: generalised parsing (Earley, which has the same expressive power as GLL or GLR); PEG; and LR. I started off with generalised parsing, because it seemed like a good idea to be able to handle any Context-Free Grammar (CFG). The problem with parsing in a formalism that allows ambiguity is that, for any non-trivial language, you can never know if you've resolved all cases of ambiguity. When a user hits a new case at run-time, what do you do? The safe choice is to raise an error. I tried using a default resolution scheme, but that can be *extremely* surprising to users -- and it surprised me, in unpleasant ways, several times. There are ambiguity heuristic tools (I had a small part in developing [one such tool](http://soft-dev.org/pubs/pdf/vasudevan_tratt__detecting_ambiguity_in_programming_language_grammars.pdf)), but they can never find all ambiguities. I eventually found parsing in such formalisms so dangerous that I abandoned it for my work.

Then I moved to PEG / recursive descent. There are no ambiguity problems. Yay! But there is an even worse problem, which doesn't seem to have an agreed name, but I ended up calling ""shadowing"". The PEG ""a / ab"" matches the string ""a"" but not, surprisingly, the string ""ab"". Just this week I've been converting a recursive descent parser to LR, and found some comical cases of this. There is no way to formally model this, so you don't know if your recursive descent parser has unintended examples of this. This also makes it hard (in my opinion, impractical) for users to work out how an input will be parsed.

So now -- and I tried to avoid going down this route for over 10 years -- I've gone back to LR parsing (which we can consider as similar-ish to LL in the sense that it's provably ambiguous, albeit slightly more expressive than LL). Yes, it's often frustrating to write grammars in this style, but that's in large part because it's guaranteed to be safe. It won't be ambiguous, it won't cause shadowing, and normal humans stand a chance of working out how an input will be parsed. Personally I've ended up feeling these are the best long-term trade-offs for users. I've put my money where my mouth is: I've tried to make [LR error recovery better](https://arxiv.org/abs/1804.07133) and I've written a [Rust yacc parser](https://github.com/softdevteam/grmtools).

All this is to say that, in one way LL(k) is an irrelevant, and in some ways an annoying, property -- yes, absolutely. But as soon as one moves beyond LL/LR, one opens up a dangerous can of worms that can never be shut again.",True,True
rust-lang_____rfcs_____2544,2019-01-12T10:38:08Z,True,rust-lang_____rfcs_____2544_____453737180,"As a daily user of rust at work, I can only beg to not introduce more ways of expressing the same thing. `Box<T>` vs `Box<dyn T>` and `&Trait` vs `&dyn Trait`. I still don't get why I should write `dyn` (I read something about it mirroring `impl`). More to write, no difference.

Since rust can't remove the turbofish, I can only beg, please don't add this!",True,True
rust-lang_____rfcs_____2544,2019-01-12T10:42:48Z,True,rust-lang_____rfcs_____2544_____453737465,"> As a daily user of rust at work, I can only beg to not introduce more ways of expressing the same thing. Box<T> vs Box<dyn T> and &Trait vs &dyn Trait. I still don't get why I should write dyn (I read something about it mirroring impl). More to write, no difference.

I don't think `dyn` is a good example here. The reason is that it marks visually (and also without type resolution) that there is a fat pointer and dynamic dispatch involved. That could lead to all kind of weird problems and hard to implement diagnostics down the line. Also, `dyn` is mandatory in 2018, so there's only 1 way again.",True,True
rust-lang_____rfcs_____2544,2019-01-12T10:45:02Z,True,rust-lang_____rfcs_____2544_____453737609,"@skade 

> Also, `dyn` is mandatory in 2018, so there's only 1 way again.

[No, it's not mandatory.](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=67a4216942d6b33ec652bfd29579d23c)

```rust
type X = Box<Iterator<Item = u8>>;
```
Is entirely legal.",True,True
rust-lang_____rfcs_____2544,2019-01-12T10:53:44Z,True,rust-lang_____rfcs_____2544_____453738120,"Since tooling comes up a lot in this discussion, I feel I should share my IDE-writer perspective.

First of all, supporting this particular feature in IDE wouldn't be hard. IDEs use hand-written parsers (for good error recovery), and lookahead/backtracking is easy to add there.

An example here would be Kotlin. It was designed specifically around IDEs, and it has this very ambiguity around generics. Here's a fun little program that compiles and runs:

```Kotlin
fun foo(a: Any, b: Any) { println(""comparisons"") }
fun foo(a: Any) { println(""generics"") }

fun <U, V> a(c: Any) {}
class b
class c

fun main(args: Array<String>) {
    val a = 0
    val b = 1
    val c = 2
    val d = 3
    foo((a < b), (c > (d))) // comparisons
    foo(a<b, c>(d)) // generics
}
```


But, from the same IDE writer position, I agree with ideas about establishing formal complexity boundaries, and about avoiding non-essential changes, for the sake of (artificially) keeping complexity low and the language stable.

Supporting this particular feature in the IDE is work. Not a ton of work, but still something which could have been spend on figuring out how to support macros better, for example.

But if there's a precedent for ""changing grammar in significantish ways is OK"", I expect there will be a constant tickle of such ""small incremental steps"", which will create a significant amount of work for IDE writers, and which might slowly push us well beyond ""easy to support"" area.

Finally, I believe a good IDE support is one of the most effective ways for improving learnability. For example, Kotlin's compiler has only bare bones error messages, but this is completely irrelevant, because, in the IDE, you get the relevant code highlighted, the context around it analyzed fully, and you get a ""click here to fix error"" red light bulb.

The thing which is the primary blocker of good IDE support right now is ""quality of implementation"", not ""language design"". An important missing bit in QoI is full-fidelity syntax trees and parser with good error recovery, and *any* changes to the grammar make that work harder.
",True,True
rust-lang_____rfcs_____2544,2019-01-12T15:31:28Z,True,rust-lang_____rfcs_____2544_____453756485,"Brian Smith brought up a good point on Twitter: we can solve the problem of LL(k), if we desire, by simply introducing a hard limit on the amount of lookahead that we do that is so high nobody will ever hit it in practice. The question, then, is the inconsistency of that limit vs. the inconsistency of turbofish in the first place.

(As well as, of course, the more important questions of usability, readability, pedagogy, etc.)",True,True
rust-lang_____rfcs_____2544,2019-01-12T15:33:57Z,True,rust-lang_____rfcs_____2544_____453756684,"@matklad I might rephrase your position as (correct me if I'm wrong): Let's slow down the pace of language changes so that tooling can catch up to what we already have. That is perfectly legitimate, and I'm very receptive to that.",True,True
rust-lang_____rfcs_____2544,2019-01-12T15:53:31Z,True,rust-lang_____rfcs_____2544_____453758048,"> This also makes it hard (in my opinion, impractical) for users to work out how an input will be parsed.

I don't understand this claim. Since most parsers in the wild are recursive descent, this seems to imply that humans can't work out how input will be parsed in most languages. That doesn't seem true to me. Humans are generally capable of parsing C, in fact, despite C being context-sensitive due to the lexer hack.",True,True
rust-lang_____rfcs_____2544,2019-01-12T16:35:22Z,True,rust-lang_____rfcs_____2544_____453761372,"As an alternative to using the entire grammar of Rust to backtrack, can we do something like (strawman proposal):

    FNCALL := ... IDENT '<' CALLGENERICS '>' '(' ...
    CALLGENERICS := '<' CALLGENERICS '>' | '(' CALLGENERICS ')' | '[' CALLGENERICS ']' | (TOKEN \ {'<', '>', '(', ')', '[', ']'})*

In other words, don't parse all of Rust to determine which rule to use; just match parentheses, angle brackets, and brackets. This makes the grammar almost LL(∗). It's not truly LL(∗) because brace matching is not a regular language. However, if we place a limit on the amount of brace matching that we do—say, 16 levels or so—then the Rust grammar *will* formally be LL(∗), since regular languages are capable of nesting up to any arbitrary fixed depth. (I should stress that this is a purely theoretical result, since nobody would actually use a DFA to implement this.)",True,True
rust-lang_____rfcs_____2544,2019-01-12T16:54:07Z,True,rust-lang_____rfcs_____2544_____453762822,"> Brian Smith brought up a good point on Twitter: we can solve the problem of LL(k), if we desire, by simply introducing a hard limit on the amount of lookahead that we do that is so high nobody will ever hit it in practice.

As in, you are saying that LL(500) enforced by the compiler is still technically LL(k)...?

While technically true, it's not really useful, for most practical purposes, LL(500) behaves like LL(*).",True,True
rust-lang_____rfcs_____2544,2019-01-12T16:58:51Z,True,rust-lang_____rfcs_____2544_____453763196,"> As in, you are saying that LL(500) enforced by the compiler is still technically LL(k)...?
> 
> While technically true, it's not really useful, for most practical purposes, LL(500) behaves like LL(*).

I agree! As I've been saying, I don't find the LL(k) formalism particularly useful. I'm just saying that, if we feel we need the LL(k) property for whatever reason, we can effectively get it.",True,True
rust-lang_____rfcs_____2544,2019-01-12T17:51:18Z,True,rust-lang_____rfcs_____2544_____453767462,"> Since most parsers in the wild are recursive descent, this seems to imply that humans can't work out how input will be parsed in most languages.

The challenge with recursive descent parsers is that they also accept a non-CFG set of languages and implementers often don't realise when they've drifted into that set and/or aren't parsing the language they intended to parse. I know from experience (mine, and seeing other's parsers) that it's really easy to make subtle mistakes here. Anyway, this is probably a tangent to the main discussion.

With regards to the LL(k) formalism: the advantage it has is that (in its pure form, without any interaction with the lexer) it *guarantees* that there is no ambiguity (or, depending on your tool, guaranteeing that all points of ambiguity are pointed out to you, and you have to choose which way each is resolved). That's a powerful property. As soon as you move beyond LL/LR, you're in the realm of grammars where ambiguity is provably undecidable in general. So, yes, LL/LR are formalisms from ye olde days (in computing terms), but that doesn't mean they're pointless or out of date. There have been a couple of extensions (e.g. LRR) that enlarge the class of guaranteed unambiguous grammars, but AFAIK they're not significant differences. Until, and unless, that changes, there'll be an important place for LL/LR.",True,True
rust-lang_____rfcs_____2544,2019-01-12T18:12:01Z,True,rust-lang_____rfcs_____2544_____453769119,"Bit of a meta-observation about the current state of the discussion: This is somewhere where the FCP model kind of breaks down. The FCP is a period where ""closing arguments"" are made and typically rehashing arguments is frowned upon . But as I go through the post-FCP discussion here I'm realizing that that's not actually what's happening, what's happening is that multiple core arguments in this RFC are very subjective and people are disagreeing with the subjective leveling made at the end (something which could not have been done before the FCP comment making these subjective decisions was made!). 

This is also why I don't find it a productive argument to label the other side as ""philosophical"" or subjective; both sides -- the importance of LL(k) as a logical boundary for grammar evolution, and the severity of learnability issues of a turbofish -- seem pretty subjective to me. Yes, ""turbofish is hard to learn"" is itself a subjective notion, see [skade's excellent comment on this](https://github.com/rust-lang/rfcs/pull/2544/#issuecomment-453724105).

The discussion seems to have boiled down to some key (rather subjective) points:

 - Is LL(k) an important logical boundary? Is it important to have a focal point here at all?
 - Is turbofish that much of a hurdle to newcomers? @skade classed it as an ""odd fact"" (and pointed out we have a lot of them, as do other languages).

The second discussion isn't progressing as much as the LL(k) one, but imo resolving both is part of the solution here. Also worth noting: these points are somewhat independent -- even _if_ we decide LL(k) is not a big deal, we still need to decide if we consider turbofish to be enough of a weird edge case that we want to change it.

The reason I'm underscoring the subjectivity of these discussions is to point out that most of the arguments here boil down to more or less irredeemable differences of personal axioms (as is the case with most subjective disagreements). It's good to notice when that's starting to happen, to avoid endlessly talking in circles. 

I don't really have a solid recommendation for how I think the discussion should proceed in light of this; finding common ground seems tricky. But I think it's worth being aware of where the discussion is headed.",True,True
rust-lang_____rfcs_____2544,2019-01-12T18:51:38Z,True,rust-lang_____rfcs_____2544_____453772041,"To reiterate, if we cap the lookahead at any finite *level of nesting* of brackets (say, 16), then we will have an LL(∗) grammar, and therefore an unambiguous one. So, if our premise is that maintaining the LL(∗) property is important, the relevant question is whether having the turbofish is more inconsistent or having a finite nesting level is more inconsistent.",True,True
rust-lang_____rfcs_____2544,2019-01-12T18:55:34Z,True,rust-lang_____rfcs_____2544_____453772336,"@Manishearth You have a good point there that I was just going to write more about. But first, a reaction to an earlier comment:

Every time I encounter the need arise for an arbitrary numerical limit, I see a big red flag, spelling out ""hack"". And I wonder, and it just somehow appears misguided to me to resort to a hack in order to kinda-sorta, technically (but quite ""dishonestly"") get LL(k) with a sizeable portion of the real-life disadvantages of non-LL(k) / unbounded lookahead, whereas we could just go with real, actual LL(k=small) in the first place.

And now to the point of subjectivity. Yes, several aspects of this discussion are subjective. But I also noticed that along these lines, the (perceived) advantages of not having to type out the turbofish are being considered with a weight disproportionately high compared to the (perceived) disadvantages of the resulting ambiguity, first and foremost in *human* readers of the code. (Incidentally, I think in this issue human-readability is more important than machine-readability, because it's exposed to users directly, raw and naked, so it's not *only* an implementation detail anymore.)

Relatedly, I see it as a fallacious line of reasoning to first assert that beginners are not good enough at understanding and/or memorizing the literally 1-bit decision rule of ""the fish is needed in value context but not in type context"", then dismissing how they might equally struggle with the resulting ambiguities should the turbofish be gone. Conversely, if we believe and presume that some/most people are not going to be annoyed or misled by such ambiguities, why don't we also believe that having to memorize when to type and when not to type two colons is not an issue for some/most programmers?

There is an entire series of arguments in favor of this change based on ergonomics, yet these arguments seem to deny that in addition to people who find the turbofish more annoying than the ambiguity, there are also people who find ambiguities more annoying than having to memorize the turbofish.
",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:04:09Z,True,rust-lang_____rfcs_____2544_____453772943,"I hope this isn't just more retreading, but thanks to @ltratt's excellent https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453733727 and @nagisa's https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453686610, I'd like to elaborate a bit on https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453674848:

> I would much rather have extra parser power leveraged toward improvements in error messages, editors, etc. *and not need it otherwise* than the reverse.

Today Rust's grammar does not require any backtracking (IIUC). However, `rustc` already does plenty of it regardless- this is purely to improve error recovery and messages. If backtracking becomes an actual tool required for correctness, that makes `rustc`'s job there harder, because there's less ""negative space"" in the grammar for it to bounce off.

Here's another example of this that I don't think has been mentioned: I work on a C++ IDE, and doing a full parse of the user's file often takes way too long. (I believe much of this is due to implementation, rather than language, but often that's just reality- e.g. this also applies to the RLS.) So for some operations, we have to find ways to skip things or jump in in the middle- and having the ability to use a more powerful parser than required by a successful straight-line compile is very useful here. (And no, this is not about the lexer hack- it does not increase the class of grammar we use in a straight-line compile, and it's not what we're working around here....)

In general, this grammatical negative space is valuable in and of itself, both for compilers and IDEs. When a user writes something wrong, if it falls into negative space it's more likely that we can tell what they intended based on what valid grammar is nearby. But if we extend the grammar, there's less negative space and it's more likely that the user will have meant something else, or that their wrong code already *does* mean something else.

So regardless of whether this particular change *immediately* affects this side of things, it still interacts with any future changes we may make. What I would prefer to take from @varkor's experiments here is not that we can make this change with only a little compatibility break (ugh) but that it's an *extremely effective* method of error recovery! Let's use it for that purpose, and focus on making the edit/compile/fix loop tighter, through a faster `cargo check`, or `rustfix` and IDE integration.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:18:43Z,True,rust-lang_____rfcs_____2544_____453773884,"@rfcbot concern needs-better-crater-run

It would be good to prepare a lint catching parsing ambiguity cases with more future-compatibility in mind than it was done in https://github.com/rust-lang/rust/pull/53578, like `f<1, 2>()` and `f<1 + 2>()`.
I planned to do it, but delayed the work due to edition-related tasks, perhaps now it's a good time to return to it.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:26:41Z,True,rust-lang_____rfcs_____2544_____453774407,"> most of the arguments here boil down to more or less irredeemable differences of personal axioms

I agree, and I don't want to be making pointless arguments in bad faith or anything. This may not be the ideal place to litigate the disagreement, but it's _clear evidence_ to me that the chorus of ""please stop changing things"" input from the community is being flatly ignored by the language team. [I said as much in as plain language above as I could](https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453705177): the language team seems to be unable, and I think given the conversation I've seen here and elsewhere simply unwilling, to minimize or halt changes to the language. Lip service is paid, but the changes keep being justified and pushed through. This change will of course not break the language, but crossing a long-held design constraint for a seemingly minor papercut is _illustrative of the pattern_.

I thought I was perceiving this pattern from a distance over the past couple years and it motivated me to participate in the blogging-for-next-year thing a few weeks ago; the response in the past few weeks has been nothing but vigorous reinforcement of that perception. I tried to convince myself otherwise by going through the open and moving-towards-approval lang RFCs yesterday, looking for signs of a willingness to say no, to draw lines, to place limits .. and only found further reinforcement of the pattern of addition. Given the willingness on display to take on features, I can't avoid the conclusion that the language team has a serious divergence in _direction_ from .. well, at least where I _personally_ think it ought to be going if it's to retain a decent margin of safety from limits to engineering and cognition. Now, my opinions don't matter that much; maybe I'm old and obsolete and dramatically less-clever than the typical rust user or maintainer and so I'm yelling about nothing. But the issue is that given the number of other people who've mentioned observing and disagreeing with this same pattern, I am concerned that the broader community or org does not seem to have the capability to address a divergence of opinion about _where and how to wrap up the language_ within itself. 

The fact that [you refer to comments](https://twitter.com/ManishEarth/status/1083906817334292481) like ""saving rust from the lang team"" as toxic is perhaps fair from a quality-of-discourse perspective -- snark escalates, and deep personal differences ought to be de-escalated if they're ever to be resolved -- but it nevertheless embodies a sentiment that is _clearly felt_ by a large contingent of the community. I would have hoped there was some less-public, less-critical, less-intrusive way to make this point (I thought a solicited blog response might be adequate) but it seems all that has provoked is denial or insistence that the endless supply of motives for change (papercuts, ergonomics, expressivity, consistency, generality) subjectively outweigh the motives for cessation thereof, without an effort to recognize, reflect-on and resolve the large evident divergence of opinion about where the language _ought to be stopping_.

I agree this _is_ deriving from a major difference of subjective opinions, and that embedding that discussion in a discussion about LL(k) muddies the water a fair bit. I'm truly sorry to be bringing this up here and now; it's a canonical example but hardly a significant one. But I don't think that observation means that the divergence in opinion is solved (it will not be, regardless of the fate of this PR), nor that the broader guidance of the _central shared technical artifact_ that _everyone has to live with_ should thereby now-and-always go to with the current language team's preference for addition _if a big chunk of the community is indicating significant personal-subjective disagreement with that preference_. The inability to address such a division is indicative of a governance problem and I hate to be the person bringing that up, but it really seems to me that there is one here.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:35:50Z,True,rust-lang_____rfcs_____2544_____453775153,"> Every time I encounter the need arise for an arbitrary numerical limit, I see a big red flag, spelling out ""hack"".

But the turbofish is itself a hack. So it's a question of which hack is better.

> Here's another example of this that I don't think has been mentioned: I work on a C++ IDE, and doing a full parse of the user's file often takes way too long. (I believe much of this is due to implementation, rather than language, but often that's just reality- e.g. this also applies to the RLS.) So for some operations, we have to find ways to skip things or jump in in the middle- and having the ability to use a more powerful parser than required by a successful straight-line compile is very useful here. (And before you bring up the lexer hack, it does not increase the class of grammar we use in a straight-line compile, and it's not what we're working around here....)

There are real benchmarks provided in this thread. I think those are far more relevant than experiences with C++, which is a completely different language with far more parsing problems than the complexity class of the grammar.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:36:42Z,True,rust-lang_____rfcs_____2544_____453775200,"@graydon The fact that this is spiraling into a discussion about governance is disconcerting to me. To be frank, it's hard to read this as anything other than a wish to return to the days of you as BDFL. Rust just does not have that model anymore, and hasn't for years.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:40:37Z,True,rust-lang_____rfcs_____2544_____453775479,"> But the turbofish is itself a hack.

I get your point, and then we just disagree here. The reason why I don't see the turbofish as a hack is that it's a very simple way of completely eliminating a problem that has been present (and a pain point) in older languages. Given the circumstances, I would even call it *elegant* compared to other solutions. (And now I'm expecting the stones to be thrown.)

> So it's a question of which hack is better.

So, if we regard the turbofish as a hack, then it's the smaller one, because it's local, ie. it doesn't have any other side effect outside its immediate scope.
",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:41:55Z,True,rust-lang_____rfcs_____2544_____453775551,"> it's clear evidence to me that the chorus of ""please stop changing things"" input from the community is being flatly ignored by the language team.

Speaking as a member of the language team: no, it isn't. We're actively discussing such things, trying to find new processes, and in any case saying no quite often. Half the things you commented on in your commenting spree were those we had *already* decided against, or had not yet decided on and were leaning against. That they haven't yet been *closed* is not an indication that they're moving forward.

Yes, some improvement is needed. In particular, there was a spree of ""ergonomics"" RFCs that (in my opinion) didn't use the right criteria for evaluating the overall impact on the language. But I feel that that has slowed down, and we're cleaning up the result and trying to make sure the default answer is ""no"" without strong rationale.

That said, *this* RFC hardly seems like an example of ""we're making the language more complicated""; on the contrary, this change makes it simpler and more consistent.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:43:03Z,True,rust-lang_____rfcs_____2544_____453775625,"> There are real benchmarks provided in this thread.

My comment wasn't about the speed of parsing, so those benchmarks are mostly unrelated. It was about what we did after the *implementation*-related slowness- which Rust also has, and thus might also need to work around in similar ways.

> That said, this RFC hardly seems like an example of ""we're making the language more complicated""; on the contrary, this change makes it simpler and more consistent.

That's the *main point of contention* here. I personally think the opposite.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:43:29Z,True,rust-lang_____rfcs_____2544_____453775653,"I think it's obviously quite unlikely that this PR is going to be merged, and that's a success of the governance model, not a failure. There was a FCP, the community weighed in with ""wait, we don't like this"" after it went around on Twitter, and so now it's not going to happen. What's the problem?",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:45:03Z,True,rust-lang_____rfcs_____2544_____453775762,"@pcwalton
> I think it's obviously quite unlikely that this PR is going to be merged

I'm curious where you're getting the ""obviously"" from.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:46:34Z,True,rust-lang_____rfcs_____2544_____453775868,"@pcwalton I hate to say it, but, as a project member, I see @graydon's point. It's neither the first time he's voicing it, nor is he the only person who is raising it. There have been _multiple_ calls for stability in the ongoing 2019 blog campaign and I do know that some people approach Graydon with things that they don't feel that the current project staffing could deal with.

There's a growing feeling that I notice on multiple occasions that people _don't_ believe their input matters, and large resources being spent on _multiple_ tries to remove the turbofish are an instance of that problem. I want to add that this is not necessary my opinion, but that doesn't make the _feeling_ go away.

I would hope those issues would be pointed to the community team more, but what I can definitely say is the community team is also internally not _consulted_ on things like this, though assessment of situations like this is definitely _our_ expertise.

I know it's frustrating that generally small things spark these kinds of discussions, but here we are.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:48:21Z,True,rust-lang_____rfcs_____2544_____453775968,"> a wish to return to the days of you as BDFL

@pcwalton First: I never asked to be and never was (and strenuously resisted) any title like that when I was ""de facto tech lead"" inside a team at moz. I _regularly_ lost arguments to you, Niko, Dave, Marijn, Brian and numerous community members, managers and even interns. You're misrepresenting my tenure by using a term like that.

Second: those were some of the hardest and worst days of my life and I wouldn't take the job of even de facto tech lead of this project again if you paid me a fortune for it. If you think I have any nostalgia for that time, you are profoundly misunderstanding me.

I'm disappointed and hurt by this statement, and surprised that you'd even say it, given the circumstances of my departure.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:48:21Z,True,rust-lang_____rfcs_____2544_____453775967,"@skade
> There have been multiple calls for stability in the ongoing 2019 blog campaign

I've read many of those blog posts, and I agree. (Some of them are more constructive than others, but the sentiment is clear.) I feel the same way myself.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:55:14Z,True,rust-lang_____rfcs_____2544_____453776466,"@graydon 

> I agree, and I don't want to be making pointless arguments in bad faith or anything

to be clear, I wasn't saying that was the case with your comments, it was more of a general ""we are heading in this direction and it's good to be aware of it so we save ourselves hours of arguing"" :smile: 

My comment wasn't meant to be a rebuke of anyone, more of just a way to take stock of the state of the discussion.

> but it nevertheless embodies a sentiment that is clearly felt by a large contingent of the community

I think there's a good way and a bad way to express the underlying sentiment, I'm not passing judgement on that sentiment itself in the tweet you linked, just the way people typically express that sentiment.

I do think that discussing this and other general governance issues are off topic for this thread, though. 


The part of the governance discussion that's relevant to this RFC: it's clear to me that the same governance issues that plagued us during the run up to the edition are rearing their heads again. Given that we no longer have an edition deadline, we don't need to postpone thinking about them so that we can ship things. There have been multiple strong calls for solving ""governance debt""/""process debt""/""organizational debt"" this year, and it seems likely to me that we're going to decide to focus on that this year. Perhaps we should wait on resolving those first? Default to postponing contentious RFCs that stretch the limits of governance, or something like that.",True,True
rust-lang_____rfcs_____2544,2019-01-12T19:59:21Z,True,rust-lang_____rfcs_____2544_____453776739,"> Speaking as a member of the language team: no, it isn't. We're actively discussing such things, trying to find new processes, and in any case saying no quite often

@joshtriplett I'm heartened to hear it, and apologize for the bull-in-china-shop nature of my comments here. This is the last thing I want to be intruding on and I wish I could stay away for good. I'm feeling a bit too emotional about the idea that I'd be wanting to _be_ the governance of the project -- it basically destroyed my life last time I was involved to that extent -- and I hope the divergence I perceive is somehow resolvable. I am not calling for a coup or anything, just some indication of priority being given on acknowledging and responding to the evident gap in opinion. I wish you & the governance system of the project all the luck in resolving the tension here. There have in the past been divisions deep enough lead to people advocating forks; I would love for that to never happen to Rust, but it's only avoidable through conscious compromise, giving up on some of one's wants.",True,True
rust-lang_____rfcs_____2544,2019-01-12T20:01:10Z,True,rust-lang_____rfcs_____2544_____453776849,"@graydon For the record, I do believe you're perceiving a real problem, but it's one that the language team (and other teams) has seen and is dealing with as well.

Speaking specifically for *myself* at the moment, this is something I deeply care about, and more often than not I find myself the voice of dissent in the direction of ""no"". :)",True,True
rust-lang_____rfcs_____2544,2019-01-12T20:03:15Z,True,rust-lang_____rfcs_____2544_____453776950,"> My comment wasn't meant to be a rebuke of anyone, more of just a way to take stock of the state of the discussion.

@Manishearth I did not read it as such. It seemed an honest and wise assessment. My comment about speaking in bad faith was to indicate that I recognize the risk of speaking that way myself, and that I wish to refrain from doing so.

> I do think that discussing this and other general governance issues are off topic for this thread, though

Clear enough. I ought to step away anyways, it's not doing myself or anyone here any further good. Apologies.",True,True
rust-lang_____rfcs_____2544,2019-01-12T20:09:30Z,True,rust-lang_____rfcs_____2544_____453777353,"@graydon I'm sorry. I apologize, that was out of line on my part.

(I had an entire post here typed up, but I think it would probably do more harm than good to litigate this further, especially in this RFC.)",True,True
rust-lang_____rfcs_____2544,2019-01-12T22:13:08Z,True,rust-lang_____rfcs_____2544_____453784869,"Forgive me for piling on -- I'd also like to quickly apologize for setting a poor tone when I brought this up on Twitter. I could have easily separated out my need to vent from my desire to have a conversation about precedents, and I should have.

Re: this RFC, from @Manishearth:

> The part of the governance discussion that's relevant to this RFC: it's clear to me that the same governance issues that plagued us during the run up to the edition are rearing their heads again. Given that we no longer have an edition deadline, we don't need to postpone thinking about them so that we can ship things. There have been multiple strong calls for solving ""governance debt""/""process debt""/""organizational debt"" this year, and it seems likely to me that we're going to decide to focus on that this year. Perhaps we should wait on resolving those first? Default to postponing contentious RFCs that stretch the limits of governance, or something like that.

The point has been made several times about apparent themes of 2019 posts, specifically how many community members have called for adopting a more conservative stance towards changes to the language. I've waffled quite a bit myself over time, but something has started to happen that's changed my mind a little bit.

Rust is kinda doing really well? Where a necessarily short-term view sees scaling issues, I'm starting to see a really rosy longer-term future as long as we keep figuring the short term stuff out in good faith. If your metric for success is to grow the community and help the world deliver safer, faster software with less work, ""scaling problems"" translates roughly to ""problems due to unexpected levels of success."" In no small part thanks to the work of everyone in this thread. It's a sucky side effect of success, but it's still pretty awesome to have it, IMO.

Perhaps this is too generalized, but there's a fun cycle here:

* more people depend on the language (woo)
* the community grows (woo)
* the perceived value of the project increases (woo)
* the increased importance of getting each change right grows too (hm)
* the emotional value of ""real estate"" (RFCs, features, etc) grows too (hmm)
* the speed of making significant changes slows
* people perceive the language to be more stable and predictable
* more organizations depend on the language (oh no, but also woo)

Not sure how to resolve this, but if there's a chance that everyone here has done such important work that Rust is still valuable to the world in 10/20/30?/40??/50??? years, it's worth taking time to get answers to important questions right.",True,True
rust-lang_____rfcs_____2544,2019-01-12T22:37:39Z,True,rust-lang_____rfcs_____2544_____453786236,"One alternative I didn't see in the RFC:

Require space around ""<"" and "">"" for comparisons, and prohibit leading and trailing space in generics.

Maybe this is an obvious non-starter, but I thought I would mention it.",True,True
rust-lang_____rfcs_____2544,2019-01-12T23:03:52Z,True,rust-lang_____rfcs_____2544_____453787737,"@sayrer right now I can only think of once place in the syntax where whitespace is significant, and thats the nightly-only emplacement syntax, and that is because `<-` is a valid token, so `if x<-1 {}` _must_ be written as `if x < -1 {}`. There's no _technical_ reason it _can't_ be implemented that way, but making whitespace significant _can_ be a similar wart/piece of syntax context that developers will need to keep in mind when writing their code, not dissimilar to the turbofish, although granted, with a lower likelihood of being hit due to the predominant style when writing types, but just as likely to be hit by accident when writing comparisons as emplacement is.",True,True
rust-lang_____rfcs_____2544,2019-01-12T23:07:14Z,True,rust-lang_____rfcs_____2544_____453787937,"Prohibiting leading and trailing spaces in generics would mean one cannot have a closing `>` alone on its line, which is currently AFAIR the advised coding style for generics-heavy code.",True,True
rust-lang_____rfcs_____2544,2019-01-12T23:16:48Z,True,rust-lang_____rfcs_____2544_____453788491,"@estebank I agree it's a bit of a departure for Rust, but I think rustfmt already does this. One useful pattern for making these changes might be to lift things from rustfmt into the language itself (at the right time...).

@Ekleog Hmm. I guess only leading space really needs to be prohibited. This seems pretty easy to understand, as it isn't too different from HTML, etc.",True,True
rust-lang_____rfcs_____2544,2019-01-13T00:29:14Z,True,rust-lang_____rfcs_____2544_____453791904,"> the nightly-only emplacement syntax,

@estebank this was removed from nightly, https://github.com/rust-lang/rfcs/pull/2387",True,True
rust-lang_____rfcs_____2544,2019-01-13T02:23:34Z,True,rust-lang_____rfcs_____2544_____453796456,"I think the turbofish is *in itself* a net negative for Rust - when I learned Rust, the error message did not helpfully suggest turbofish when you tried to use normal braces, so I spent some time unaware that I could specify the type as needed without pulling this expression out into its own let binding. Now, the compiler at least tells you what to do, but its still a stumble and it would be ideal for it to not to be necessary. But I'm wary of complicating the grammar and implementation, and I was optimistic about seeing good, nuanced and precise information about what the costs of removing the turbofish are.

I've gotten the sense this position is pretty roughly the lang team's previous consensus last time we talked about it. In other words, the turbofish is a cost we know, and we'd like to get an accurate weight of the cost we'd be taking on in exchange for it.

Unfortunately, that discussion is not what's emerged on this thread. This thread has become, like so many RFCs these days, full of sound and fury. Exercises like this are unproductive, exhausting, and emotionally draining for everyone involved. This much content, and with this much emotional fervor behind it, overwhelms the projects' processes and grinds other areas to a halt while we all deal with the repercussions of a discussion that erupts in the manner that this has.

I'm not sure what to do about this in the long term, but in an immediate sense I'm calling a cool down on this thread. I'm locking discussion for a couple of days or so and when it gets unlocked I hope it will be conducted with a decorum appropriate to an open source project.",True,True
rust-lang_____rfcs_____2544,2019-01-13T02:24:19Z,True,rust-lang_____rfcs_____2544_____453796484,"I fear the discussion here is getting way beyond the scope of this RFC. But to add to it anyway: I think it is correct to be concerned about the rate of change, and I know that both the language and core teams think a lot about rate of change. However, I think avoiding change for the sake of avoiding change is as bad as change for the sake of change. Let's focus on the magnitude of the change, as well as the costs and benefits.

IMO, turbofish is a wart. It is not a bad wart, as @skade says, it is easily learnt and infrequently encountered. Nonetheless, it is still something which has to be learnt and is not intuitive. If we can get rid of it, then I see that as making the language *less complex* for the user. As such it is the kind of 'polishing' change that I would like to see, c.f., change which truly adds something to, or changes the language. I think there is a valid and interesting debate to be add about whether the LL(k) property is an important one to keep. To my mind it is not - it is not the kind of formal category which makes a huge difference (c.f., type soundness, for example) and I think complexity for readers and writers is far more important than complexity for implementers or theoreticians (which is not to say it is not important, just less so). ",True,True
cabaletta_____baritone_____313,2019-01-16T00:23:40Z,True,cabaletta_____baritone_____313_____244983775,Exactly what the title says UwU,True,True
cabaletta_____baritone_____313,2019-01-16T18:41:08Z,True,cabaletta_____baritone_____313_____248403969,"This provides very limited usage of the builder function, you can't use a custom schematic type, custom naming, or custom origin.",True,True
cabaletta_____baritone_____313,2019-01-16T18:41:27Z,True,cabaletta_____baritone_____313_____248404076,"I don't even know what to say about this, what could you possibly do to remove and re-add the whole file.",True,True
cabaletta_____baritone_____313,2019-01-16T18:41:59Z,True,cabaletta_____baritone_____313_____248404267,This method should align in order with the Baritone implementation,True,True
cabaletta_____baritone_____313,2019-01-16T18:42:31Z,True,cabaletta_____baritone_____313_____248404483,Not a friendly name for the user,True,True
cabaletta_____baritone_____313,2019-01-16T18:43:25Z,True,cabaletta_____baritone_____313_____454893002,"On top of the issues stated in the review comments I made, your commit is not linked to your GitHub account, it isn't signed, and I've already decided to make the changes myself.",True,True
cabaletta_____baritone_____313,2019-01-16T19:15:36Z,True,cabaletta_____baritone_____313_____454903717,"Don't ever say UwU in this christian repo again, thanks.",True,True
cabaletta_____baritone_____313,2019-01-16T19:15:52Z,True,cabaletta_____baritone_____313_____454903803,uwu motherfucker,True,True
cabaletta_____baritone_____313,2019-01-16T19:16:03Z,True,cabaletta_____baritone_____313_____454903874,No!,True,True
cabaletta_____baritone_____313,2019-01-16T19:16:13Z,True,cabaletta_____baritone_____313_____454903939,uwu uwu uwu uwu!! ,True,True
cabaletta_____baritone_____313,2019-01-16T19:16:24Z,True,cabaletta_____baritone_____313_____454904007,Quit it!,True,True
cabaletta_____baritone_____313,2019-01-16T19:16:35Z,True,cabaletta_____baritone_____313_____454904070,*growls while slowly exposing my terrifying eagle beak*,True,True
cabaletta_____baritone_____313,2019-01-16T19:17:08Z,True,cabaletta_____baritone_____313_____454904251,"Stop erping in the Baritone issues, mr leijurv",True,True
cabaletta_____baritone_____313,2019-01-16T19:18:04Z,True,cabaletta_____baritone_____313_____454904590,"*rips you to shreds with my sharp eagle talons killing you instantly*

*this repo is my turf, or rather, nest*

*screeches warning you to stay away*",True,True
cabaletta_____baritone_____313,2019-01-16T19:18:44Z,True,cabaletta_____baritone_____313_____454904792,I am requesting ownership over this repo as I consider you being too mentally unstable to be the main leader of the project.,True,True
cabaletta_____baritone_____313,2019-01-16T19:20:22Z,True,cabaletta_____baritone_____313_____454905280,you have an anime profile pic so your opinion doesn't count *chuckles through beak*,True,True
cabaletta_____baritone_____313,2019-01-16T19:20:58Z,True,cabaletta_____baritone_____313_____454905469,Well played,True,True
cabaletta_____baritone_____313,2019-01-16T19:21:24Z,True,cabaletta_____baritone_____313_____454905647,*literally triumphantly eating your corpse*,True,True
cabaletta_____baritone_____313,2019-01-16T19:24:10Z,True,cabaletta_____baritone_____313_____454906602,Uh,True,True
cabaletta_____baritone_____313,2019-01-16T19:24:23Z,True,cabaletta_____baritone_____313_____454906689,This issue is cursed,True,True
cabaletta_____baritone_____313,2019-01-16T19:24:44Z,True,cabaletta_____baritone_____313_____454906823,Wow Brady hates me kms,True,True
cabaletta_____baritone_____313,2019-01-17T01:24:05Z,True,cabaletta_____baritone_____313_____455007004,uwu,True,True
laurent22_____joplin_____1141,2019-01-21T14:16:20Z,True,laurent22_____joplin_____1141_____246307875,"New feature for mobile: a menu option to move notebooks. Possibility to create sub-notebooks and so on.

Sry if the code isn't very good, but
* I don't have any experiences with react and react-native
* The guide for translation is outdated, so there is currently no translation
* It is a little bit copy&paste from other files

@laurent22 
If you don't like this feature as a menu option, I have also a branch for ""move notebooks via dropdown in the header"". But this isn't yet finished. Too many refactorings necessary.

Feel free to give me tips for improvements.",True,True
switchbrew_____libnx_____234,2019-01-24T07:15:20Z,True,switchbrew_____libnx_____234_____247224405,This initial implementation provides access to both `esCountCommonTicket` and `esCountPersonalizedTicket`.,True,True
switchbrew_____libnx_____234,2019-01-24T14:33:21Z,True,switchbrew_____libnx_____234_____457217577,"Personally, why would people want to mess up with tickets, like it's understandable for some homebrew, but...",True,True
switchbrew_____libnx_____234,2019-01-24T15:18:09Z,True,switchbrew_____libnx_____234_____457234117,"Hence why this provides access to the two safest `Get`-related services only, to ensure people don't accidentally screw up their ticket db.",True,True
switchbrew_____libnx_____234,2019-01-24T16:06:06Z,True,switchbrew_____libnx_____234_____457252738,Is there a specific reason why this was closed?,True,True
switchbrew_____libnx_____234,2019-01-24T16:11:42Z,True,switchbrew_____libnx_____234_____457255036,"There's no meaningful use case for ticket functions, other than supporting piracy-related tools.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-26T15:55:07Z,True,Monika-After-Story_____MonikaModDev_____3588_____247896881,"Here.
Update to this version whenever.
I don't care when, I use it now locally anyways.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-26T17:13:39Z,True,Monika-After-Story_____MonikaModDev_____3588_____457847984,"Let's not forget the last PR, for records of course: #3166. 

Hopefully you had a nice 9 day spiritual journey. 

_Welcome back._ ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-26T18:17:41Z,True,Monika-After-Story_____MonikaModDev_____3588_____457853138,"No need to welcome me back, let's just leave it at what it is.",True,True
laurent22_____joplin_____1141,2019-01-29T17:37:05Z,True,laurent22_____joplin_____1141_____458634117,"To move notebooks, I think it should be done directly in the sidebar, by drag and dropping them. What do you think?",True,True
laurent22_____joplin_____1141,2019-01-30T14:56:04Z,True,laurent22_____joplin_____1141_____458973471,"Sounds better, for sure! But currently I don't have the skills to implement it.
I will take a look for tutorials at weekend, but don't expect too much 😉",True,True
callstack_____react-native-paper_____485,2019-01-31T05:57:38Z,True,callstack_____react-native-paper_____485_____459225827,knock knock,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-31T20:37:10Z,True,Monika-After-Story_____MonikaModDev_____3588_____252831220,"I'm sure some people might tell you that's too many ""he""s. I'd remove one. ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-31T20:41:31Z,True,Monika-After-Story_____MonikaModDev_____3588_____252832572,"It might just be me being < a fragile little flower like I can be, but couldn't this be offensive to some people and can this be allowed in?

Might just be me, we'll see. ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-31T20:49:31Z,True,Monika-After-Story_____MonikaModDev_____3588_____252835146,"_Very clever,_ but I think the spelling you want in this instance is ""practice"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-01-31T20:51:21Z,True,Monika-After-Story_____MonikaModDev_____3588_____252835715,Would Monika actually say this?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-01T00:52:51Z,True,Monika-After-Story_____MonikaModDev_____3588_____252900662,"I have yet to see her in any comparable situation to make accurate assumptions.
This is a pretty rare event.
You can keep her one dimensional if you like, rephrase it into something positive/neutral then.",True,True
laurent22_____joplin_____1141,2019-02-03T07:17:06Z,True,laurent22_____joplin_____1141_____460029348,"Hi @laurent22 

I tried to implement drag & drop to move notebooks, but now I'm stuck. Perhaps you have an idea?

But first of all one of the last commits crashed my android emulator. Have you been notified about my comment at this commit? https://github.com/laurent22/joplin/commit/9c1219b188fdd0746db64272198935a5af3c79b2#commitcomment-32163393

Now my problem:
I put the folder item from the side menu into a new component. This component creates a Animated.View around the existing View and TouchableOpacity.
With this Animated.View I can implement drag & drop with the help of PanResponder:

```
            onPanResponderRelease: (event, gesture) => {
                ...
            }
```

So far so good ...

But event has lack of informations about the element where the element/folder is dropped. All I get are positions or a target. (https://facebook.github.io/react-native/docs/panresponder)
**target**: a node id. I don't know what node id is. A small number between 150 and 160 in my tests. No DOM element or something I can use. Even StackOverflow only helps with a private API method which is outdated.
**position**: How can I get the element (or folder) from a position? (It would take a lot of code to remember the positions of all folders and compare, where the drag was released ... Espacially if the folder list is so long you have to scroll)

Currently I dont' like the idea with drag & drop .. too many problems 😉",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-04T23:59:31Z,True,Monika-After-Story_____MonikaModDev_____3588_____253694521,Change the name of this persistent to `_mas_pm_ever_let_monika_win` that way it has the same naming convention as the other player related vars.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-05T00:07:25Z,True,Monika-After-Story_____MonikaModDev_____3588_____253695982,"Change this one to `_mas_pong_difficulty` to keep it consistent with other games like chess. Same for the other ""pong"" persistent vars.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-05T00:07:30Z,True,Monika-After-Story_____MonikaModDev_____3588_____253695993,"Change these to be like the chess constants(these would start with the PONG_ prefix), maybe it's not a bad idea to put all of them inside a store named `mas_pong`",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-05T00:10:45Z,True,Monika-After-Story_____MonikaModDev_____3588_____253696592,Make those response ids constants so the values aren't hard coded and can be modified easily later on if needed.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-05T00:48:41Z,True,Monika-After-Story_____MonikaModDev_____3588_____253703769,"Could you define this persistent variable at the beginning of the file with the other persistent vars? it's faster to see what variables we store from pong that way, because they all will be on the same place. Also, any reason to make this one a datetime? the place where you check it also makes a date time from today's date, so it seems it'd be easier to just use a date object instead.",True,True
callstack_____react-native-paper_____485,2019-02-05T09:11:51Z,True,callstack_____react-native-paper_____485_____460563570,"please move forward, we need menu",True,True
spring_____spring_____427,2019-02-05T18:06:53Z,True,spring_____spring_____427_____250500393,"e.g. something like this:

```lua
    Spring.GiveOrderToUnit(unitID,
      CMD.INSERT,
      {-1,CMD.ATTACK,''CMD.OPT_SHIFT'',''unitID2''},
      {""timeout"" = 500 }
    );
```

Related to https://springrts.com/mantis/view.php?id=6128",True,True
w3c_____csswg-drafts_____3618,2019-02-05T23:15:51Z,True,w3c_____csswg-drafts_____3618_____250585815,"An ellipse may have an x-radius and y-radius, or neither.

resolves #3609
",True,True
spring_____spring_____427,2019-02-06T00:07:17Z,True,spring_____spring_____427_____460854542,"That would work, but the (badly named) command ""options"" have special meaning. Timeout is a separate parameter.",True,True
spring_____spring_____427,2019-02-06T00:10:47Z,True,spring_____spring_____427_____460855281,"@rtri I appreciate the comment but you closed it before I could fix the PR!
No need for the trigger happy close, unless you're trying to put off
contributions?

Perhaps next time you should use the built in review functionality and
request changes? E.g. switching to an additional parameter because options
have special meaning?

On Wed, 6 Feb 2019 at 00:07, rtri <notifications@github.com> wrote:

> Closed #427 <https://github.com/spring/spring/pull/427>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spring/spring/pull/427#event-2120001408>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AADl598QGC_BSGkh38MqMyeyXMN4RDV2ks5vKhy8gaJpZM4ajxVn>
> .
>
",True,True
spring_____spring_____427,2019-02-06T00:44:55Z,True,spring_____spring_____427_____460862065,"You seem to have missed be999101, which I started before this PR arrived.",True,True
spring_____spring_____427,2019-02-06T16:27:22Z,True,spring_____spring_____427_____461088078,"@rtri **that's no excuse for rudeness**, I opened the PR to try and be helpful.

Next time:

 - If you already have a PR, link to it
 - Leave a review requesting changes

For all you know I may have come back and refactored it shortly after. If it had been a few days then sure, close it, as is common practice here, but instead you were hostile. Stop that.",True,True
spring_____spring_____427,2019-02-06T17:13:36Z,True,spring_____spring_____427_____461106112,"@tomjn:
next time: please make a pull request to the develop branch. we don't accept pull requests to the master branch!


",True,True
spring_____spring_____427,2019-02-06T17:22:51Z,True,spring_____spring_____427_____461109643,"@abma I wasn't aware, perhaps a [pull request template](https://github.blog/2016-02-17-issue-and-pull-request-templates/) would help document this? That way it would be clear to anybody creating a pull request that they need to apply it to the `develop` branch not the `master` branch, even a prompt to link to any related Mantis tickets

---

As a general note, as a part of my job and general activities I regularly make and comment on pull requests on a wide range of projects on a daily basis, but this experience was poor, and below average, and entirely avoidable.

I don't know if the rude response from @rtri was because english isn't the primary language, or habit, but it's very easy to be polite and at the same time close responses. GitHub provides various processes to avoid these.

For example, the original comment doesn't explain why the PR was closed. If it had instead just been:

> Thanks, it's been fixed in [be99910](https://github.com/spring/spring/commit/be999101be20d10fe46ce6921d7ec7d88ccdece5)

That would have been perfectly acceptable on its own. The follow up comment was also catty and rude. Or a review left that was literally just the comment he left, requesting changes.",True,True
spring_____spring_____427,2019-02-06T18:38:19Z,True,spring_____spring_____427_____461136952,"@tomjn 
https://springrts.com/wiki/Development:Getting_Started#How_to_get_your_code_included
i presume you knew that. please stop complaining.",True,True
spring_____spring_____427,2019-02-06T19:51:29Z,True,spring_____spring_____427_____461162887,"@tomjn 

 > the original comment doesn't explain why the PR was closed

When closing it I presumed you had taken at least a cursory glance at the log (or the mantis ticket) and would understand your PR had crossed incoming commits, which was clearly a mistake on my part. Now please get off your lecturing high horse.
",True,True
KSP-KOS_____KOS_____2260,2019-02-09T18:26:21Z,True,KSP-KOS_____KOS_____2260_____462067539,"What is the problem with merging this? Should I recreate [boot from archive](/KSP-KOS/KOS/pull/2260/commits/40daa29bde82808de7a4c698489b28e00d757571) under current code to get this merged?

@Dunbaratu I know you do not like booting from archive, but kOS allows it. So, either dissallow it or make it working. What is the problem? Should I make it as small as possible? I really cannot think of any other reason: You either do not like it (then drop the option alltogether and make it harder for beginners and force them to create boot script to load important stuff to the core before they even start exploring what kOS can do) or you fear it would break something, which is at least understandable for me. I am not perfect, I am not AI but a human and I did make mistakes in my HUGE commit `parts redone`. Two mistakes so far, one because I did not examine all references to some function call and second was just miss-click, but that does not matter, I do mistakes. Would it help to recreate it in minimalistic way to help you review it? This is really crutial for me to use official kOS (the other PR about `TARGET` would be nice but not required, this one is).",True,True
KSP-KOS_____KOS_____2260,2019-02-09T20:46:46Z,True,KSP-KOS_____KOS_____2260_____462077986,"The lack of an answer to that problem I brought up in July 31 and again on August 1 is why I stopped looking at this PR there.  I pointed out that I can't review your merge conflict decisions (like you explicitly asked me to) if I can't get git to actually generate a report of what the conflicts even are.  It kept claiming no conflict when I tried to rewind my repo to before your work, and then merge your commits.  So you're asking for a review of something I can't see.  You fell silent after that, and I was happy for the chance to not have to talk to you for a while.  Besides, some of what this PR had was melted together with another PR of yours that hvacengi was still reviewing at the time, and I figured it would get less messy after that got merged.  Then there was also the fact that I thought @hvacengi had said he was going to look at this, so I thought my only involvement in this PR *was* that one line you tagged me on where you asked for the review of the one thing I couldn't see - your merge conflict decisions.  Other than that ONE parenthetical side comment, I saw this as  being @hvacengi 's merge with me just making side comments but not being the merger.  He was usually much more involved in the booting system than I was, and the original issue was raised by him so he knew better whether this PR addressed it well or not.",True,True
KSP-KOS_____KOS_____2260,2019-02-09T20:59:24Z,True,KSP-KOS_____KOS_____2260_____255313360,Missing period in the sentence?,True,True
KSP-KOS_____KOS_____2260,2019-02-09T20:59:46Z,True,KSP-KOS_____KOS_____2260_____255313385,period?,True,True
KSP-KOS_____KOS_____2260,2019-02-09T21:02:11Z,True,KSP-KOS_____KOS_____2260_____462079161,"The PR melts together some IStack refactors that don't appear to be in any way related to the issue in with the bug fix.  You said this was related to an external tool you use for debugging, but that's not really part of this issue.",True,True
KSP-KOS_____KOS_____2260,2019-02-09T21:18:45Z,True,KSP-KOS_____KOS_____2260_____462080292,"Quite sad that *you were happy for the chance to not have to talk to me for a while.* I have always considered you a team-mate, just like my colleague Ondřej. We disagree occasionally, but always find a way out of it, find a consensus despite our differences, despite our original disagreement and maybe some *block* and repetition of arguments, but what I value about him is that he does not get stuck. He will repeat his invalid argument but will also, after some repetitions, understand why it is invalid. My other colleague Karel gets stuck indefinitely, repeating nonsense, unable to hear any logic. I can understand that too (fragile psychic, stuck in his self-doubts he is trying to fight the wrong way), but I do not know how to handle him. You seem to me to be very close to Ondřej, but you do not like something about me and resist, a lot, not indefinitely like Karel but still more than Ondřej. I would really like to understand what is the problem. My problem with you all (kOS squad) is the response time - you have your own lives, I can understand that, but if you do not respond in reasonable time (and half a year is really not *reasonable time*), then there is nothing I can do.

About the merge conflict: I thought it is solved by you not finding the conflict (meaning there is no conflict, nothing is needed to be done). Yes, @hvacengi should probably look into this and you @Dunbaratu are here just because I asked you to take a look. The question is still the same: Would it help if I make it minimal?

There trully are things that are not needed to fix the problem and I can understand that, that is why I asked - making it minimal should help you (or whomever will review it) do it quicker and merge it. I would like you/anybody merge it as it is, because it would help in testing, which is what I prefer - testing, automated testing, I know I do mistakes, I therefore like to automate tests (and like to write documentation). But that is another story, so be it, I will create another PR with minimal changes to solve the booting from archive problem.",True,True
KSP-KOS_____KOS_____2260,2019-02-09T21:23:21Z,True,KSP-KOS_____KOS_____2260_____255314145,Where would you like a period?,True,True
KSP-KOS_____KOS_____2260,2019-02-09T21:23:52Z,True,KSP-KOS_____KOS_____2260_____255314159,After `{0}` before `\n`?,True,True
KSP-KOS_____KOS_____2260,2019-02-09T21:37:31Z,True,KSP-KOS_____KOS_____2260_____255314545,"yes
",True,True
KSP-KOS_____KOS_____2260,2019-02-09T21:38:46Z,True,KSP-KOS_____KOS_____2260_____255314582,"The statement ""The file is missing"" is a separate sentence that isn't continued on the next line.  (Instead a new sentence starts on the next line).  So, yeah, it feels like a period is needed before the ``\n``.",True,True
KSP-KOS_____KOS_____2260,2019-02-09T22:02:58Z,True,KSP-KOS_____KOS_____2260_____255315156,Surprised you don't want it after `{0}` as that is clearly also *separate sentence that isn't continued on the next line. Does not compute*,True,True
KSP-KOS_____KOS_____2260,2019-02-09T22:05:35Z,True,KSP-KOS_____KOS_____2260_____255315228,"It's both.  For some reason when github showed these comments in the PR thread, it was under line 165 when it shows it under line 166 on the longer diff output, so I didn't see the second sentence on line 166 when replying.",True,True
KSP-KOS_____KOS_____2260,2019-02-09T22:14:49Z,True,KSP-KOS_____KOS_____2260_____255315851,Does those dot-fixes make it any closer to merging? I don't think so. I will consider creating that minimalistic PR tomorrow... and maybe never. I have my working version and it does not feel like I am of any help here.,True,True
KSP-KOS_____KOS_____2260,2019-02-09T22:33:25Z,True,KSP-KOS_____KOS_____2260_____462085487,"> I would really like to understand what is the problem.

Do you genuinely mean that?  You're asking to open up the floodgates here.

> There trully are things that are not needed to fix the problem and I can understand that, that is why I asked - making it minimal should help you (or whomever will review it) do it quicker and merge it. I would like you/anybody merge it as it is, because it would help in testing, which is what I prefer - testing, automated testing, I know I do mistakes, I therefore like to automate tests (and like to write documentation). But that is another story, so be it, I will create another PR with minimal changes to solve the booting from archive problem.

Two separate PR's would work better.  One that's a refactor so your debugger can work, and the other that's addressing the bug issue.  Putting them together makes it harder for the reviewer who then has to make a judgment call on each line to figure out if it's part of the fix or not.

",True,True
KSP-KOS_____KOS_____2260,2019-02-09T22:57:19Z,True,KSP-KOS_____KOS_____2260_____462087025,"> Do you genuinely mean that? You're asking to open up the floodgates here.

Yes I do.",True,True
KSP-KOS_____KOS_____2260,2019-02-11T11:18:57Z,True,KSP-KOS_____KOS_____2260_____462293454,"@firda-cze 

I am only saying this because you at least do deserve an explanation.

In the text you deleted, you had the rule not to make any judgements about you.  Well that makes it impossible to answer the question honestly.  Honesty in this case *requires* pointing out your toxic communication style where you are always on the attack, not treating other team members like equals.  (Your deleted text *claims* you view people as colleagues, but your behavior proves otherwise.)  But, I doubt you'll listen.  It suffices to say that I'm not alone in this decision.  I asked other team members about it, sought out the advice of others *who had also watched this exchange so they weren't just relying on my word over yours* and gave it a long think, that's why I was away over the weekend.  This decision was important, and needed to be made with some distance and time.

Communicating with you is painful, making working on kOS a chore instead of a joy.  The advantage of another pair of hands on the code is offset by the time lost to having to step away for days to calm down after being browbeaten by your narcissistic refusal to meet on common ground yet again one more time.  You annoy more people than just me.  I've just had less tolerance of it than others do. There's a reason you were never invited to join the dev team's Slack channel, even though other people who've contributed less have been.  

Be aware that if you try to use the github comments to complain about this, or blame others yet again, then a ban will be necessary.  I don't want to do it, but this is a place for teamwork, not browbeating, so just don't.  This toxic commentary has already been waay to public as-is.

Just walk away.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:01:34Z,True,Monika-After-Story_____MonikaModDev_____3588_____255648424,"```suggestion
        m 5hubfb ""You're so sweet, letting me win~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:01:53Z,True,Monika-After-Story_____MonikaModDev_____3588_____255648540,Need to dissolve into this exp,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:04:40Z,True,Monika-After-Story_____MonikaModDev_____3588_____255649509,"```suggestion
        m 3tsu ""As you can see, I can win by myself!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:07:05Z,True,Monika-After-Story_____MonikaModDev_____3588_____255650340,"Both 'Ahaha' and 'Ehehe' are always kept to the same length.
```suggestion
        m 2lssdrb ""Ahaha...""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:11:47Z,True,Monika-After-Story_____MonikaModDev_____3588_____255652059,"```suggestion
        m 2esd ""I hope you're having fun, [player].""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:12:14Z,True,Monika-After-Story_____MonikaModDev_____3588_____255652215,"```suggestion
        m 1hub ""Ahaha!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:16:31Z,True,Monika-After-Story_____MonikaModDev_____3588_____255653771,"```suggestion
            m 4tfu""But so am I, Ahaha!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:18:20Z,True,Monika-After-Story_____MonikaModDev_____3588_____255654421,"Don't really like this line, could reference the player's streak instead, so getting rid of the if statement:
```suggestion
            m 2tku ""Looks like your streak is over!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:19:20Z,True,Monika-After-Story_____MonikaModDev_____3588_____255654769,"```suggestion
            m 2hub ""Ahaha, sorry [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:20:06Z,True,Monika-After-Story_____MonikaModDev_____3588_____255655074,"```suggestion
            m 2eksdlc ""It happened again."" 
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:20:26Z,True,Monika-After-Story_____MonikaModDev_____3588_____255655189,"```suggestion
            m 3hksdlb ""Sorry about that!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:20:59Z,True,Monika-After-Story_____MonikaModDev_____3588_____255655413,"```suggestion
                m 4hua ""I'm sure you'll win soon."" 
                m 4hub ""Just keep trying!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:22:40Z,True,Monika-After-Story_____MonikaModDev_____3588_____255656076,"```suggestion
                m 3tub ""I'm just kidding, [player].""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:23:01Z,True,Monika-After-Story_____MonikaModDev_____3588_____255656216,"```suggestion
                m 4hub ""You're pretty good yourself!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:23:17Z,True,Monika-After-Story_____MonikaModDev_____3588_____255656324,"```suggestion
                m 5eua ""Don't worry, I'm sure you'll win again soon~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:23:53Z,True,Monika-After-Story_____MonikaModDev_____3588_____255656558,"```suggestion
                m 2duu ""Not bad, [player].""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:24:15Z,True,Monika-After-Story_____MonikaModDev_____3588_____255656692,"```suggestion
                m 4ekb ""I gave it everything I had, so don't feel too bad for losing from time to time.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:25:10Z,True,Monika-After-Story_____MonikaModDev_____3588_____255657009,"```suggestion
        m 2tub ""I was really trying this time!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T19:25:29Z,True,Monika-After-Story_____MonikaModDev_____3588_____255657122,"```suggestion
        m 1hub ""Way to go, [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T21:41:58Z,True,Monika-After-Story_____MonikaModDev_____3588_____255704963,"```suggestion
            m 1rusdlb ""I didn't expect to lose this quickly.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T21:42:36Z,True,Monika-After-Story_____MonikaModDev_____3588_____255705171,"```suggestion
                m 4eud ""Another win for you!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-11T21:43:00Z,True,Monika-After-Story_____MonikaModDev_____3588_____255705295,"```suggestion
                m 2tfb ""Well, I'm sure I'll beat you sooner or later [player]...""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:27:45Z,True,Monika-After-Story_____MonikaModDev_____3588_____255950591,"Changing this to 5 so it's consistent
```suggestion
                    m 5hub ""Ehehe!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:33:33Z,True,Monika-After-Story_____MonikaModDev_____3588_____255952706,"```suggestion
                    m 5hua ""Thanks for letting me win, [player]~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:34:16Z,True,Monika-After-Story_____MonikaModDev_____3588_____255952954,"Should try to stay within the same pose, looks better that way.
```suggestion
                        m 5eubla ""But I wouldn't mind losing against you sometimes.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:35:02Z,True,Monika-After-Story_____MonikaModDev_____3588_____255953300,"```suggestion
                        m 5hub ""I like to see you win just as much as you like to see me win~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:38:20Z,True,Monika-After-Story_____MonikaModDev_____3588_____255954968,"Same thing regarding poses here
```suggestion
                        m 5eub ""I wouldn't mind losing against you, though.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:45:18Z,True,Monika-After-Story_____MonikaModDev_____3588_____255957917,"As an FYI, all menu options go *inside* the menus (they don't take expression params inside there, so you'll need to `show monika exp` before the menu) Should look something like this;

```renpy
show monika exp
menu:
    m ""Question""

    ""Menu Option"":
        m exp ""Dialogue""

    ""Menu Option 2"":
        m exp ""Dialogue""
```
etc.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:46:12Z,True,Monika-After-Story_____MonikaModDev_____3588_____255958312,Question in menu,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:47:16Z,True,Monika-After-Story_____MonikaModDev_____3588_____255958736,"Feels a little out of place.
```suggestion
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:48:11Z,True,Monika-After-Story_____MonikaModDev_____3588_____255959199,"```suggestion
                                m 1rfu ""[player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:51:44Z,True,Monika-After-Story_____MonikaModDev_____3588_____255960715,"While I know the expressions here are slightly different to the one above, I think the exp's there work a little better.  You could probably just put the one above into a label and call it both up there and here, so we don't have to maintain two copies of the same dialogue.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:55:33Z,True,Monika-After-Story_____MonikaModDev_____3588_____255962250,"```suggestion
                m 2tku ""Aren't you getting tired of letting me win, [player]?""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T13:56:19Z,True,Monika-After-Story_____MonikaModDev_____3588_____255962603,"```suggestion
        m 3hub ""Ehehe~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:01:37Z,True,Monika-After-Story_____MonikaModDev_____3588_____255964854,"```suggestion
            m 4tsb ""I told you I'd win the next game.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:03:10Z,True,Monika-After-Story_____MonikaModDev_____3588_____255965497,"```suggestion
            m 4eub ""Keep it up and you'll beat me, I'm sure of it.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:03:28Z,True,Monika-After-Story_____MonikaModDev_____3588_____255965610,"```suggestion
            m 4eub ""You're really good!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:05:55Z,True,Monika-After-Story_____MonikaModDev_____3588_____255966705,"```suggestion
        m 4hua ""Now it's my time to shine~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:09:07Z,True,Monika-After-Story_____MonikaModDev_____3588_____255968054,"```suggestion
                    m 2hub ""Looks like I won.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:09:18Z,True,Monika-After-Story_____MonikaModDev_____3588_____255968149,"```suggestion
                    m 3hub ""Looks like I won again.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:09:35Z,True,Monika-After-Story_____MonikaModDev_____3588_____255968283,"```suggestion
                m 1hub ""Ahaha!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:17:48Z,True,Monika-After-Story_____MonikaModDev_____3588_____255971808,I don't really like this block of dialogue. I think something more along the lines of how hard it is to make a shot like that would be better suited.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:18:43Z,True,Monika-After-Story_____MonikaModDev_____3588_____255972179,"```suggestion
            m 2wuo ""Wow, there's no way I could hit that!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:19:03Z,True,Monika-After-Story_____MonikaModDev_____3588_____255972331,"```suggestion
        m 2wud ""You've won three times in a row already...""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:19:24Z,True,Monika-After-Story_____MonikaModDev_____3588_____255972462,"```suggestion
            m 2tub ""Maybe I'm going a little bit too easy on you~""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:19:46Z,True,Monika-After-Story_____MonikaModDev_____3588_____255972615,"```suggestion
            m 4hua ""You're good, [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:25:12Z,True,Monika-After-Story_____MonikaModDev_____3588_____255974979,"```suggestion
        m 2tsu ""Have you been practicing?"" 
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:34:06Z,True,Monika-After-Story_____MonikaModDev_____3588_____255979149,"```suggestion
            m 3hub ""Well played, [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:34:58Z,True,Monika-After-Story_____MonikaModDev_____3588_____255979628,"```suggestion
            m 3tfu ""Are you sure you aren't cheating, [player]?""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:36:46Z,True,Monika-After-Story_____MonikaModDev_____3588_____255980373,"```suggestion
            m 4wuo ""That was amazing, [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:38:20Z,True,Monika-After-Story_____MonikaModDev_____3588_____255981016,"```suggestion
        m 3hksdlb ""I don't know what happened but I don't stand a chance against you!"" 
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:38:54Z,True,Monika-After-Story_____MonikaModDev_____3588_____255981222,"```suggestion
        m 1eka ""Do you think you could go a little easier on me please?""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:40:51Z,True,Monika-After-Story_____MonikaModDev_____3588_____255982160,"```suggestion
            m 2wuo ""Incredible, [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:41:35Z,True,Monika-After-Story_____MonikaModDev_____3588_____255982518,"```suggestion
            m 4hksdlb ""I can't keep up!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:42:01Z,True,Monika-After-Story_____MonikaModDev_____3588_____255982713,"```suggestion
            m 4eub ""You're really good!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:43:27Z,True,Monika-After-Story_____MonikaModDev_____3588_____255983412,"```suggestion
            m 2hksdlb ""Ahaha..."" 
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:44:26Z,True,Monika-After-Story_____MonikaModDev_____3588_____255983909,Dissolve into pose 5,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:45:53Z,True,Monika-After-Story_____MonikaModDev_____3588_____255984786,"```suggestion
                m 2wuo ""Wow, I'm really trying...{w=1}you're unstoppable!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:46:58Z,True,Monika-After-Story_____MonikaModDev_____3588_____255985345,"```suggestion
                m 3hub ""Ahaha!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:49:23Z,True,Monika-After-Story_____MonikaModDev_____3588_____255986544,"```suggestion
                m 1tsu ""This is intense!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:49:39Z,True,Monika-After-Story_____MonikaModDev_____3588_____255986655,Dissolve into pose 5,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:50:26Z,True,Monika-After-Story_____MonikaModDev_____3588_____255987006,"```suggestion
                m 1hub ""You're really good, [player].""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:52:52Z,True,Monika-After-Story_____MonikaModDev_____3588_____255988229,"```suggestion
                m 4eua ""I love playing Pong with you.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:53:03Z,True,Monika-After-Story_____MonikaModDev_____3588_____255988326,"```suggestion
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:55:12Z,True,Monika-After-Story_____MonikaModDev_____3588_____255989362,"```suggestion
    m 5hub ""Let's play again sometime soon, okay?""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:55:54Z,True,Monika-After-Story_____MonikaModDev_____3588_____255989689,"```suggestion
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:56:46Z,True,Monika-After-Story_____MonikaModDev_____3588_____255990124,"```suggestion
                m 5eub ""It's nice to see you win, [player].""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:58:15Z,True,Monika-After-Story_____MonikaModDev_____3588_____255990829,"```suggestion
        m 2tfu ""Let's find out how good you really are, [player]!""  
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:58:26Z,True,Monika-After-Story_____MonikaModDev_____3588_____255990938,"```suggestion
        m 2tsu ""So you are playing seriously now?""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:58:52Z,True,Monika-After-Story_____MonikaModDev_____3588_____255991137,"```suggestion
        m 1hub ""Ahaha!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:59:10Z,True,Monika-After-Story_____MonikaModDev_____3588_____255991285,"```suggestion
                m 2efu ""Keep up, [player]!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T14:59:19Z,True,Monika-After-Story_____MonikaModDev_____3588_____255991358,"```suggestion
                m 2hua ""This time it's my win!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T15:01:09Z,True,Monika-After-Story_____MonikaModDev_____3588_____255992236,Dissolve into pose 5,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T15:02:38Z,True,Monika-After-Story_____MonikaModDev_____3588_____255992875,"```suggestion
            m 3hksdla ""I didn't mean to bounce it that much.""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T15:03:36Z,True,Monika-After-Story_____MonikaModDev_____3588_____255993355,"```suggestion
        m 1hua ""Ehehe!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T15:03:59Z,True,Monika-After-Story_____MonikaModDev_____3588_____255993529,"```suggestion
        m 3eub ""Keep trying!""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T15:08:40Z,True,Monika-After-Story_____MonikaModDev_____3588_____255995763,"```suggestion
        m 2lssdrb ""Ahaha...""
```",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T17:42:00Z,True,Monika-After-Story_____MonikaModDev_____3588_____256068319,?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T17:56:06Z,True,Monika-After-Story_____MonikaModDev_____3588_____256074388,"Could I ask what this ""#"" is and what it's for here?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T17:57:15Z,True,Monika-After-Story_____MonikaModDev_____3588_____256074862,"I get that Monika wants you to stay hydrated and all, but I think having this here is a bit random and could sound a bit like she's nagging at you. ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T17:58:09Z,True,Monika-After-Story_____MonikaModDev_____3588_____256075201,"Same as before; What's this ""#"" doing there?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T17:58:30Z,True,Monika-After-Story_____MonikaModDev_____3588_____256075321,"Same as before; What's this ""#"" doing there?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T17:59:11Z,True,Monika-After-Story_____MonikaModDev_____3588_____256075603,"Same as before; What's this ""#"" doing there?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:02:54Z,True,Monika-After-Story_____MonikaModDev_____3588_____256077086,Dissolve into body pose 5. ,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:05:19Z,True,Monika-After-Story_____MonikaModDev_____3588_____256078025,"Same as before; What's this ""#"" doing there?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:11:29Z,True,Monika-After-Story_____MonikaModDev_____3588_____256080295,"Same as before; What's this ""#"" doing there?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:15:33Z,True,Monika-After-Story_____MonikaModDev_____3588_____256081878,Why do you want to say [player] after having said it the line before?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:18:34Z,True,Monika-After-Story_____MonikaModDev_____3588_____256082959,"Maybe it's just me, but I think it would be easier to read and go over the code if this was an `elif`. ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:27:35Z,True,Monika-After-Story_____MonikaModDev_____3588_____256086554,The emphasis does not work as well with a ! in my oppinion.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:28:46Z,True,Monika-After-Story_____MonikaModDev_____3588_____256087075,"That is exactly the point.
They are not the same and are not supposed to be the same.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:31:14Z,True,Monika-After-Story_____MonikaModDev_____3588_____256088155,Need to dissolve into pose 5.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:33:12Z,True,Monika-After-Story_____MonikaModDev_____3588_____256088905,"The point of the if-clause is to remind the player of this if it is from longer ago.
Your suggestion duplicates the other if clause.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T18:48:17Z,True,Monika-After-Story_____MonikaModDev_____3588_____256095069,Dunno about this one.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:01:32Z,True,Monika-After-Story_____MonikaModDev_____3588_____256100389,"Fair point, overlooked that when I was going through.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:04:12Z,True,Monika-After-Story_____MonikaModDev_____3588_____256101293,"Hm, then perhaps change the expression to something like `2dsc` or `2dsd`, it might suit the line a little better.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:09:16Z,True,Monika-After-Story_____MonikaModDev_____3588_____256103578,"```renpy
m 2ekc ""I'm sorry for assuming then...""
m 3ekb ""In case you can't concentrate, maybe you should take a break.""
m 4eka ""Drinking a glass of water can also help.""
```
vs.

```renpy
m 2ekd ""I'm sorry for assuming...""#
m 3eka ""If you can't concentrate, maybe you should take a break.""
m 4eka ""Drinking a glass of water can also help.""
```
Sure, the first line is different, and upon looking at it again, it might be fine w/o the `then` as well. I still feel the expressions in the first one look better though, hence why I say it.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:09:49Z,True,Monika-After-Story_____MonikaModDev_____3588_____256103787,It just comes off as robotic otherwise.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:10:41Z,True,Monika-After-Story_____MonikaModDev_____3588_____256104127,It sounds rather robotic in the original way.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:20:39Z,True,Monika-After-Story_____MonikaModDev_____3588_____256107956,?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:25:45Z,True,Monika-After-Story_____MonikaModDev_____3588_____256109905,I don't think this is giving enough credit.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:26:13Z,True,Monika-After-Story_____MonikaModDev_____3588_____256110178,"Either that, or we can keep the exclamatory, which I feel does make sense, if perhaps the expression was `2tfu` or something.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:27:36Z,True,Monika-After-Story_____MonikaModDev_____3588_____256110797,?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:28:29Z,True,Monika-After-Story_____MonikaModDev_____3588_____256111180,"What's wrong with changing ""you are"" to ""you're""?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:32:37Z,True,Monika-After-Story_____MonikaModDev_____3588_____256112835,it's not about the you're,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:33:27Z,True,Monika-After-Story_____MonikaModDev_____3588_____256113140,What do you mean with Dissolve into pose?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:37:30Z,True,Monika-After-Story_____MonikaModDev_____3588_____256114775,"if this is the expression to dissolve into 5, what is the expression to dissolve out of 5?
The same one for the next pose?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:44:48Z,True,Monika-After-Story_____MonikaModDev_____3588_____256117631,"This is actually a reference to the tired topic if i remember correctly, not the hydrated one.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:47:23Z,True,Monika-After-Story_____MonikaModDev_____3588_____256118729,"Again, one way just makes Monika sound like a robot.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:47:39Z,True,Monika-After-Story_____MonikaModDev_____3588_____256118826,See @Rai99's comment below,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:48:13Z,True,Monika-After-Story_____MonikaModDev_____3588_____256119055,"Original line is kinda choppy, so if you've got another idea that makes it less choppy, feel free to use that.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:49:11Z,True,Monika-After-Story_____MonikaModDev_____3588_____256119441,Still feels kinda out of place.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:51:30Z,True,Monika-After-Story_____MonikaModDev_____3588_____256120382,Still a reference to the tired topic.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T19:52:48Z,True,Monika-After-Story_____MonikaModDev_____3588_____256120939,"Please define ""sounding like a robot"" to me so that I can judge that myself.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:00:54Z,True,Monika-After-Story_____MonikaModDev_____3588_____256124065,"Are you sure about the dissolving?
Don't know whether it looks better with it tbh.
I also think there are other 5s that don't use it either.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:27:40Z,True,Monika-After-Story_____MonikaModDev_____3588_____462921216,"I'm just going to handle this myself, I think.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:40:56Z,True,Monika-After-Story_____MonikaModDev_____3588_____462925828,"> I'm just going to handle this myself, I think.

You know what a community project is, right?",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:50:13Z,True,Monika-After-Story_____MonikaModDev_____3588_____462928985,"I have not checked whether any of the suggested poses are ""better"" or ""worse"" than the ones already implemented.
I think it is best to have variants, so that multiple responses for the same event are possible.
",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:51:00Z,True,Monika-After-Story_____MonikaModDev_____3588_____462929296,"That said, @multimokia you have suggested using invalid sprites.
Either make them become valid or change them into valid ones.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:56:21Z,True,Monika-After-Story_____MonikaModDev_____3588_____256143438,I think we are past the point where we have to worry about single if statements.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T20:58:23Z,True,Monika-After-Story_____MonikaModDev_____3588_____256144205,2dsc is a completly different emotion,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T21:02:12Z,True,Monika-After-Story_____MonikaModDev_____3588_____256145630,"Why does it matter how it looks?
This is not a beauty-contest, Monika is expressing herself.
Also, you may like a version better but this doesn't mean everyone does.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T23:43:38Z,True,Monika-After-Story_____MonikaModDev_____3588_____256194785,"I'm not sure it it fits to start in body pose 5 for this. I think it feels a bit unnatural for Monika to go into a lean just to confirm that you want to play pong again. 

Also, dissolve out of body pose 5. ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T23:50:57Z,True,Monika-After-Story_____MonikaModDev_____3588_____256196464,"I'm still not sure this fits here. Sure, Monika wants you to stay hydrated and it might even help you concentrate like she wants, but personally, it seems a bit random to have Monika say that here. ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T23:56:09Z,True,Monika-After-Story_____MonikaModDev_____3588_____256197635,"Personally, I think ""you'll"" sounds more natural than ""you will"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T23:59:20Z,True,Monika-After-Story_____MonikaModDev_____3588_____256198275,"Add a comma after ""Congrats"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-12T23:59:41Z,True,Monika-After-Story_____MonikaModDev_____3588_____256198369,"Add a comma after ""enough"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T00:00:55Z,True,Monika-After-Story_____MonikaModDev_____3588_____256198610,"Add a comma after ""happened"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T00:01:10Z,True,Monika-After-Story_____MonikaModDev_____3588_____256198670,"Add a comma after ""me"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T00:04:06Z,True,Monika-After-Story_____MonikaModDev_____3588_____256199296,"Add a comma after ""later"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T00:09:55Z,True,Monika-After-Story_____MonikaModDev_____3588_____256200429,"Add a comma after ""sorry"". ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T00:12:40Z,True,Monika-After-Story_____MonikaModDev_____3588_____256201023,Maybe you'll want to fix this comment at some point. ,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T05:29:22Z,True,Monika-After-Story_____MonikaModDev_____3588_____256252018,Does this one pop up the first time you play?,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T05:30:22Z,True,Monika-After-Story_____MonikaModDev_____3588_____256252193,"It is also worth thinking about to change the ""you are awesome at pong"" compliment.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T05:51:53Z,True,Monika-After-Story_____MonikaModDev_____3588_____463069154,"Hey @multimokia.
It is ok that you make suggestions to improve the game.
However it is not ok to just do whatever you want and delete my lines as you See fit and replace them with yours.
I could have ignored your suggestions but I even added them without further checking them.
Please note that I will revert your commit so that random line selection is a part of the dialog again.
I will check the other changes you made later.
Please do not do something like this again.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T10:42:39Z,True,Monika-After-Story_____MonikaModDev_____3588_____256338203,"Oh you meant the comment in the code, not monika's comment.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T11:17:28Z,True,Monika-After-Story_____MonikaModDev_____3588_____463160922,"You do understand that the point of editing is to remove things that don't sound good, and replace them with things that sound better, right? 

What you did was circumvent the editing process, and are actively making people's work harder along with making the code more messy.

Don't get me wrong, if you have other suggestions I'm more than happy to hear them and see how they sound, if I think they're alright, sure let's use that. But that's not even remotely close to what you did here. This sort of behavior is why I took it over.

While this is a community project, you fail to understand that when you're requested changes, you're supposed to make them. Not half do them.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T11:22:06Z,True,Monika-After-Story_____MonikaModDev_____3588_____463162368,"Do note, by the way, I will be reverting your further commits adding that random selection back. A lot of what you had simply isn't Monika's voice. There's a reason I requested changes on it.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T13:37:40Z,True,Monika-After-Story_____MonikaModDev_____3588_____463201825,"Just a note you certainly cannot ignore suggestions made by devs.  Well, actually you can but that just means your PR will be closed.  We make these suggestions for a reason.  Dialogue that sounds nothing like Monika isn't going to make it into the mod. So you can either learn from what you are being told or you can continue to fight us every step of the way at which point we'll just move on to another PR.  Your choice.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T13:43:36Z,True,Monika-After-Story_____MonikaModDev_____3588_____463203730,"> when you're requested changes, you're supposed to make them.

This is where you are wrong.
Everything you can do is suggest, you can not command me to do your bidding, which is exactly what you are doing.
Your code can be questioned just as much as mine.
If I disagree with a suggested change or think it can be solved differently, then it is on you to respect this, not to force your oppinion by abusing your status. If you can reasonably convince me that my solution is not acceptable, then it is on me to react to it. If the endresult is not acceptable for the team (not you alone), theoretically the community itself, then merging the pull request can be denied, if no compromise can be found.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T13:46:55Z,True,Monika-After-Story_____MonikaModDev_____3588_____463204831,"Not gonna continue arguing with you.  If your work is not up to our standards and you refuse to adjust it so it is, it's not making it into the mod.  Your dialogue writing is not satisfactory.  Either listen to us or close the PR and stop wasting everyone's time ",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T13:59:45Z,True,Monika-After-Story_____MonikaModDev_____3588_____463208909,"> you can either learn from what you are being told or you can continue to fight us every step of the way

It is saddening that none of you can handle criticism, yet you criticise more than a hundred things in this content alone.
I uploaded this pull request for the community, so do go on and close it, if oppinions outside your owns aren't welcome.
I can try to help the community, but it is entirely voluntary.
I have literally a dozent better things to do and there really is no reason why I should have to put up with this treatment.
I will upload a final version.
From thereon out I will make no more changes to it, it is your responsibility towards the community to make something out of it.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T14:27:13Z,True,Monika-After-Story_____MonikaModDev_____3588_____463218493,"> If I disagree with a suggested change or think it can be solved differently, then it is on you to respect this, not to force your oppinion by abusing your status.

Did I or did I not say:
> Don't get me wrong, if you have other suggestions I'm more than happy to hear them and see how they sound, if I think they're alright, sure let's use that.

I'm done arguing. Don't bother pushing anything else. I'm not even done with my changes.

Since you're so unwilling to make changes yourself, or even compromise, what's the point of even suggesting at this point? Like @jmwall24 said above, dialogue that's not in Monika's voice won't make it into the mod.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T15:30:05Z,True,Monika-After-Story_____MonikaModDev_____3588_____463242987,"@multimokia why did you remove the random dialogue? if the dialogue doesnt fit then change the dialogue, not remove the random aspect.",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T15:33:57Z,True,Monika-After-Story_____MonikaModDev_____3588_____463244571,"Whatever anyone says next,please be tactful and mindful,we don't want any more unpleasantness to happen here,things like these should unite people,not put any awkwardness and negative emotions between them",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T17:08:52Z,True,Monika-After-Story_____MonikaModDev_____3588_____256496074,that was a bug.,True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T17:25:37Z,True,Monika-After-Story_____MonikaModDev_____3588_____463289265,">""Look...""
>""Writing is a really personal thing.""
>""And sharing it can definitely be hard.""
>""It looks like we learned that today.""
>""Even small criticism can lead to something pretty heated.""
>""Yeah, so...""
>""You don't need to feel threatened.""
>""You're a great writer, multimokia.""",True,True
Monika-After-Story_____MonikaModDev_____3588,2019-02-13T18:21:30Z,True,Monika-After-Story_____MonikaModDev_____3588_____463309664,"Dennis the menace strikes again.

With this in mind, you've shown multiple times of your hostility towards criticism, advice, and requests to make changes to your PR. Time and time again you've broken our Code of Conduct, continuing to be a toxic element to the community, as pointed out by several people. If you cannot comply peacefully (and no, malicious compliance is not peaceful), then we are not obligated to cooperate with you any longer. We literally have ""dozents"" of better things to do than argue with you all day.",True,True
webpack_____webpack-dev-server_____1664,2019-02-13T23:53:49Z,True,webpack_____webpack-dev-server_____1664_____252890752,"- [x] This is a **bugfix**
- [ ] This is a **feature**
- [ ] This is a **code refactor**
- [ ] This is a **test update**
- [ ] This is a **docs update**
- [ ] This is a **metadata update**

### Motivation / Use-Case

HMR client code builds the socket URL using `location.hostname` but uses the port set in server's configuration. Since the browser is at the very end of the architecture, the proper way to infer socket's URL is to also use `location.port` along with the location.hostname.

More and more we see the scenario where the dev server is used in a cloud-based development environment or an architecture with some sort of proxy in front of it.

- With a dev server externally exposed, host `0.0.0.0` and port `9000` and my proxy exposing it in `http://dev.mydomain.com` (default port 80).
  - Expected HMR socket generated URL:  `http://dev.mydomain.com/sockjs-node/info?t=XX` (default port 80).
  - Actual HMR socket generated URL:  `http://dev.mydomain.com:9000/sockjs-node/info?t=XX` (**wrong** port 9000).

More details in issue: https://github.com/webpack/webpack-dev-server/issues/1663

### Breaking Changes

No.
Those who exposed also that wrong port in their proxies as a way around the issue can now remove that configuration.

",True,True
webpack_____webpack-dev-server_____1664,2019-02-15T00:35:32Z,True,webpack_____webpack-dev-server_____1664_____463860464,"@evilebottnawi How are you testing the logic of the client code? I looked for it but couldn't find it in any of the tests. I guess webdriver is the right solution here but I didn't want to add too much overhead to your current tests. Guide me on how you recommend to do it and I'll be glad to add it.

",True,True
webpack_____webpack-dev-server_____1664,2019-02-15T10:13:34Z,True,webpack_____webpack-dev-server_____1664_____463982908,https://github.com/webpack/webpack-dev-server/blob/master/test/Socket.test.js,True,True
callstack_____react-native-paper_____485,2019-02-17T18:56:52Z,True,callstack_____react-native-paper_____485_____464494914,"Hey guys, I want to help merge this PR. Can I rebase from 'upstream' master or is that not needed?",True,True
callstack_____react-native-paper_____485,2019-02-18T08:40:37Z,True,callstack_____react-native-paper_____485_____464637886,"Hey guys, I have made some changes to follow the new way of doing things compared to when the PR was first created. Part of this was to add the typescript typings here: `typings/components/Menu.d.ts`, this is my first time doing some typescript so would be cool if someone could have a look and give some feedback.",True,True
laurent22_____joplin_____1141,2019-02-18T09:37:10Z,True,laurent22_____joplin_____1141_____464657591,"> To move notebooks, I think it should be done directly in the sidebar, by drag and dropping them. What do you think?

Hmm, I'm not sure, how easy the gesture of clicking an entry, holding it, and dragging it to a folder a few pages below is.",True,True
callstack_____react-native-paper_____485,2019-02-18T11:37:40Z,True,callstack_____react-native-paper_____485_____464699201,"Hey @waquidvp thanks for coming back to this. I guess you work together with @iyadthayyil ?

Would you mind adding: Screenshots and code for docs? You can see how to do it from other components.

I am also wondering if we could animate scale instead animating `height` and `width`, that would allow use to use `useNativeDriver`. However we can merge first this and then focus on that.",True,True
callstack_____react-native-paper_____485,2019-02-18T20:47:46Z,True,callstack_____react-native-paper_____485_____464872554,There were already some screenshots and some code examples. They just weren't in the right place and so wasn't showing up in the generated docs. I have moved it to the right place and the docs look ok now.,True,True
callstack_____react-native-paper_____485,2019-02-18T22:02:49Z,True,callstack_____react-native-paper_____485_____257837330,I am wondering if we should call this prop`button`. As far as I know these menus can appear in different kind of actions (like in forms). Should we call it `anchor` as is more generic and it is what they use in the docs? Does it make sense?,True,True
callstack_____react-native-paper_____485,2019-02-19T21:35:34Z,True,callstack_____react-native-paper_____485_____465320087,"So I finished the changing all the things that @kpsroka mentioned, now waiting on @iyadthayyil to make a decision on the `button` to `anchor` change.",True,True
webpack_____webpack-dev-server_____1664,2019-02-20T17:52:48Z,True,webpack_____webpack-dev-server_____1664_____465685759,"@evilebottnawi as I understand those tests are checking that the socket and the server are available, but it is not testing the client code that will be executed on the browser's end (more precisely testing the code in https://github.com/webpack/webpack-dev-server/blob/master/client-src/default/index.js).

Any suggestions on how to test it without adding the overhead of webdriver?

> https://github.com/webpack/webpack-dev-server/blob/master/test/Socket.test.js

",True,True
webpack_____webpack-dev-server_____1664,2019-02-20T17:54:55Z,True,webpack_____webpack-dev-server_____1664_____465686490,"/cc @rlamana oh, need thinks how we can tests client, maybe we need setup something to e2e testing
/cc @hiroppy What do you think?",True,True
callstack_____react-native-paper_____485,2019-02-20T21:36:57Z,True,callstack_____react-native-paper_____485_____465764255,"So changed `button` to `anchor`, is there anything else we need to fix or do before merging this?",True,True
callstack_____react-native-paper_____485,2019-02-20T23:19:06Z,True,callstack_____react-native-paper_____485_____258719459,Should be `() => void`.,True,True
callstack_____react-native-paper_____485,2019-02-20T23:19:20Z,True,callstack_____react-native-paper_____485_____258719515,Should be `() => void`.,True,True
callstack_____react-native-paper_____485,2019-02-21T06:36:14Z,True,callstack_____react-native-paper_____485_____258795334,Don't use `Modal` from `react-native`. Use `Portal` from `react-native-paper`,True,True
callstack_____react-native-paper_____485,2019-02-21T06:38:04Z,True,callstack_____react-native-paper_____485_____258795668,Use `StyleProp<ViewStyle>`,True,True
callstack_____react-native-paper_____485,2019-02-21T06:39:03Z,True,callstack_____react-native-paper_____485_____258795826,Is the wrapper view around anchor necessary? feels like this `onLayout` could be placed on the parent view as well,True,True
callstack_____react-native-paper_____485,2019-02-21T06:40:08Z,True,callstack_____react-native-paper_____485_____258796036,"Also, can we measure the layout when we first need to show the menu instead of mount? Will be better for perf.",True,True
callstack_____react-native-paper_____485,2019-02-21T06:44:58Z,True,callstack_____react-native-paper_____485_____258796905,Can you add a note on where you got these numbers? Doesn't any existing easing preset in RN match these?,True,True
callstack_____react-native-paper_____485,2019-02-21T06:45:21Z,True,callstack_____react-native-paper_____485_____258796968,Can you add a comment on what this is used for?,True,True
callstack_____react-native-paper_____485,2019-02-21T06:46:24Z,True,callstack_____react-native-paper_____485_____258797146,Should be `?View`,True,True
callstack_____react-native-paper_____485,2019-02-21T22:35:33Z,True,callstack_____react-native-paper_____485_____259145630,"The 'Standard easing' section of this page states that numbers that we are using, and from what I have looked at, there isn't any identical ones in RN: https://material.io/design/motion/speed.html#easing",True,True
callstack_____react-native-paper_____485,2019-02-21T22:48:52Z,True,callstack_____react-native-paper_____485_____259149357,Done.,True,True
laurent22_____joplin_____1141,2019-02-24T10:50:23Z,True,laurent22_____joplin_____1141_____466762804,"Yes maybe it's too complicated with drag and drop. To move notes to a notebook, there's a dropdown list. Can't we re-use that same dropdown list to move notebooks too?",True,True
jorgebucaran_____hyperapp_____811,2019-02-26T17:51:00Z,True,jorgebucaran_____hyperapp_____811_____256384621,"I shared a snippet of an alternative approach to lifecycle hooks I have been playing with in a fork of V2 being used on personal project of mine. This raised a few questions and a more detailed explanation was requested, so here is the implementation. A couple of things are assumed:

- Firstly @frenzzy suggested that:
> I think delayed remove is not needed, but oncreate and ondestroy are important https://hyperapp.slack.com/archives/C41ECC0V6/p1551190367214200

I'm not sure how you can do transition out style animations without them? But removing this certainly [simplifies](https://github.com/jorgebucaran/hyperapp/compare/V2...lukejacksonn:V2#diff-1fdf421c05c1140f6d71444ea2b27638L179) hyperapp core so `onRemove` is omitted here.

- Secondly by nature of the implementation the remaining lifecycle events get treated like any user interaction (like `onclick` for example) and so now have the same signature and behave the same:

```js
oncreate | onupdate | onremove:  (state, e) => ...,
```

I will create a codepen for this build now.",True,True
jorgebucaran_____hyperapp_____811,2019-02-26T17:55:53Z,True,jorgebucaran_____hyperapp_____811_____467544075,"# [Codecov](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=h1) Report
> Merging [#811](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=desc) into [V2](https://codecov.io/gh/jorgebucaran/hyperapp/commit/900a0c640779971fc1c543d03ebf3401e3526d16?src=pr&el=desc) will **increase** coverage by `1.41%`.
> The diff coverage is `30%`.

[![Impacted file tree graph](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811/graphs/tree.svg?width=650&token=zI5PKKwI7i&height=150&src=pr)](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##               V2     #811      +/-   ##
==========================================
+ Coverage   17.13%   18.54%   +1.41%     
==========================================
  Files           1        1              
  Lines         251      248       -3     
  Branches       69       67       -2     
==========================================
+ Hits           43       46       +3     
+ Misses        143      139       -4     
+ Partials       65       63       -2
```


| [Impacted Files](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [src/index.js](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811/diff?src=pr&el=tree#diff-c3JjL2luZGV4Lmpz) | `18.54% <30%> (+1.41%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=footer). Last update [900a0c6...312d553](https://codecov.io/gh/jorgebucaran/hyperapp/pull/811?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,True
jorgebucaran_____hyperapp_____811,2019-02-26T18:17:32Z,True,jorgebucaran_____hyperapp_____811_____260420216,Thank you for this :clap: ,True,True
jorgebucaran_____hyperapp_____811,2019-02-26T18:24:15Z,True,jorgebucaran_____hyperapp_____811_____260422914,Hah 😅 unintentional side effect of trying to keep things as uniform/simple as possible.,True,True
jorgebucaran_____hyperapp_____811,2019-02-26T18:58:50Z,True,jorgebucaran_____hyperapp_____811_____467567029,"Played around a bit with your Codepen.

I like the new function signature.  Having the app state injected should allow us to create these handlers outside of the view function, which could have small perf wins.

Removing the delayed onRemove is going to make animations more challenging, but it's workable.

Here is a forked codepen showing one way to achieve a fade-in/fade-out:  https://codepen.io/SkaterDad/pen/rRaGoz?editors=0010

I cloned the exiting node and inserted it into the parent in the same position.  I then remove the node when the animation is done.",True,True
jorgebucaran_____hyperapp_____811,2019-02-26T19:01:38Z,True,jorgebucaran_____hyperapp_____811_____467568133,"@lukejacksonn  Could you add onRemove back? 🙏 

",True,True
jorgebucaran_____hyperapp_____811,2019-02-26T19:05:04Z,True,jorgebucaran_____hyperapp_____811_____260439594,"if remove this line at all, it will be possible to use both `onCreate` and `oncreate` similar to all other events like `onClick` and `onclick`. ",True,True
webpack_____webpack-dev-server_____1664,2019-02-27T02:44:45Z,True,webpack_____webpack-dev-server_____1664_____467701599,"# [Codecov](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664?src=pr&el=h1) Report
> Merging [#1664](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664?src=pr&el=desc) into [master](https://codecov.io/gh/webpack/webpack-dev-server/commit/f78a9a3dde0de9468945c80a4fc8e740ae63a248?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664/graphs/tree.svg?width=650&token=WeyEj48Ike&height=150&src=pr)](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #1664   +/-   ##
=======================================
  Coverage   75.12%   75.12%           
=======================================
  Files          18       18           
  Lines         591      591           
  Branches      171      171           
=======================================
  Hits          444      444           
  Misses        113      113           
  Partials       34       34
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664?src=pr&el=footer). Last update [f78a9a3...50ef125](https://codecov.io/gh/webpack/webpack-dev-server/pull/1664?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,True
webpack_____webpack-dev-server_____1664,2019-02-27T02:52:01Z,True,webpack_____webpack-dev-server_____1664_____467702978,"@evilebottnawi @hiroppy I added some e2e tests using `puppeteer` headless Chrome API. This allows testing my fix and enables more e2e testing. 

I created a new `Client.test.js` that contains this client code related tests: https://github.com/webpack/webpack-dev-server/blob/50ef125fbfe04eb51f6788a0c44ada539834ea57/test/Client.test.js

Also the `runBrowser` helper allows to quickly start the headless browser for e2e testing.

Let me know what you think.",True,True
adventuregamestudio_____ags_____648,2019-02-27T07:07:08Z,True,adventuregamestudio_____ags_____648_____256563069,"Controversial pull request!  I tried to arrange this in two parts, the first has some general string based bug fixes, the second has the modification to String to use std::string.

The main benefit is that the c++11 string type does not have COW, which makes String much safer for multithreaded code. 

I also removed the implicit conversion from String to char*. I noticed that the compiler would silently convert to char* if a comparison operator wasn't implemented. That means there was the potential for pointer comparisons instead of content. It also makes it much more obvious which parts of the code are relying on char* strings.

Note: I have only tested on Linux so far, will test in Windows and fix any issues I find.",True,True
adventuregamestudio_____ags_____648,2019-02-27T10:26:56Z,True,adventuregamestudio_____ags_____648_____467808797,"Perhaps you could include removal of conversion operator to the first commit (""Explicitly convert AGS Strings to char*"")? It would help finding places where you need to add .GetStr().
Also in commit 3ce8b3e it would no longer be necessary to create temp string objects from literal strings",True,True
adventuregamestudio_____ags_____648,2019-02-27T10:30:10Z,True,adventuregamestudio_____ags_____648_____260684910,"Since you remove implicit conversion to const char* perhaps this is no longer necessary?
Both AGS::Common::String and std::string implement comparison operator that accepts const char* as an argument, this is to avoid extra string object allocation.",True,True
adventuregamestudio_____ags_____648,2019-02-27T10:32:54Z,True,adventuregamestudio_____ags_____648_____467810758,"TBH I'd rather pick out commits f000788 and 370cd37 , because they are bug fixes and not related to the changes to string implementation (also in case we have to apply them to older version).",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:12:44Z,True,adventuregamestudio_____ags_____648_____467822675,"I modified the commit ""Explicitly convert AGS Strings to char*"" to also remove that conversion from the string.h file. There are a couple more places where we can call GetCStr but that's because I haven't modified the rest of string.h yet to accept String instead of char*",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:14:57Z,True,adventuregamestudio_____ags_____648_____467823276,"> I haven't modified the rest of string.h yet to accept String instead of char*

Do you mean you want to not accept arguments of const char* at all?",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:17:10Z,True,adventuregamestudio_____ags_____648_____467823904,"> Do you mean you want to not accept arguments of const char* at all?

I think it makes sense. That way we're only ever implicitly converting to AGS::String. You need to be explicit when converting back to a char*. 

The only char* it accepts now is in the constructor and for printf variants.",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:17:27Z,True,adventuregamestudio_____ags_____648_____467823997,"> TBH I'd rather pick out commits [f000788](https://github.com/adventuregamestudio/ags/commit/f0007889e1e334a714ed8ee3517f900b850c283d) and [370cd37](https://github.com/adventuregamestudio/ags/commit/370cd373c7d3a61b85b8af71baa45d6b9fb5750e) , because they are bug fixes and not related to the changes to string implementation

I have pulled out those two fixes into their own pull requests.",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:21:32Z,True,adventuregamestudio_____ags_____648_____467825174,"> I have pulled out those two fixes into their own pull requests.

Ah, I was going to just cherry pick and push them right away, because they are small and clear :)",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:24:38Z,True,adventuregamestudio_____ags_____648_____467826040,"> I think it makes sense. That way we're only ever implicitly converting to AGS::String. You need to be explicit when converting back to a char*.

Converting back to char* is one thing, but taking only String arguments? I don't know... that means extra string objects are created for example every time we compare with a literal. Like I mentioned, std::string accepts C-strings also as argument to some functions and operators.
Is there really a problem with that?",True,True
adventuregamestudio_____ags_____648,2019-02-27T11:30:50Z,True,adventuregamestudio_____ags_____648_____467827761,"> I don't know... that means extra string objects are created for example every time we compare with a literal.

Only accepting AGS::String means we can keep the implicit conversion from char* to String. We only have to worry about being explicit in the other direction.

We could overload and implement for both types, but I wonder if we only need to do that in performance hot spots. And in those spots, should we be doing string manipulation at all?

",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T11:32:47Z,True,jorgebucaran_____hyperapp_____811_____467828248,Humm.. adding back `onRemove` is slightly problematic as we can't pass the `remove` function through an Event 🤔 (unless we attach it to the element?),True,True
jorgebucaran_____hyperapp_____811,2019-02-27T12:04:49Z,True,jorgebucaran_____hyperapp_____811_____467837235,"@lukejacksonn IMO the most important thing about this PR is the user-facing API changes making lifecycle events act like other events, i.e., implicit dispatch callers. If using `Event` creates an implementation problem, we can use `dispatch` directly in the current code. Do you want to make those changes?

We need to have a discussion about how this changes the way lifecycle events can be used. @loteoo You were telling me how you've been using this in your own projects. Can you share it here as well?

I'd love to hear what @zaceno thinks about this too.
",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T13:27:55Z,True,jorgebucaran_____hyperapp_____811_____260746928,"Depending on browser support, we may want to use `event = new CustomEvent('build', { detail: elem.dataset.time });`.

Another thing I think we need to consider is running in headless - will this still work as intended?",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T13:29:38Z,True,jorgebucaran_____hyperapp_____811_____467861901,"@jorgebucaran I think this proposal is good. Especially the fact that this makes it possible (...or, well, easier) to manage state and dispatch effects in relation to particular dom elements. I think it should be perfectly adequate to have just ""oncreate"" and ""ondestroy"". (Perhaps all we need, even is ""oncreate"")

(Also I am 100% on board with all-lowercase at least as an option, for all events incl lifecycle)",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T13:55:20Z,True,jorgebucaran_____hyperapp_____811_____260758200,"From what I have read.. `Event` is supported better than `CustomEvent` but we might need to *not* use the constructor. Something like this (which is not ideal I guess but will work):

```
var event;
if(typeof(Event) === 'function') {
    event = new Event('submit');
}else{
    event = document.createEvent('Event');
    event.initEvent('submit', true, true);
}
```",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T13:57:46Z,True,jorgebucaran_____hyperapp_____811_____467870978,"Just to clarify one thing.. I didn't change the capitalisation of the lifecycle events out of preference, rather out of necessity – as they are treated the same as any other event which gets lowercased. That said, I do prefer it like this 😅 ",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T14:26:55Z,True,jorgebucaran_____hyperapp_____811_____467881395,"> @zaceno I think it should be perfectly adequate to have just ""oncreate"" and ""ondestroy"".

I'm not following. We need onUpdate and onRemove too.",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T14:27:15Z,True,jorgebucaran_____hyperapp_____811_____467881513,"@lukejacksonn ~~I can still use camelCase correct?~~ Nevermind.

",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T14:27:53Z,True,jorgebucaran_____hyperapp_____811_____467881764,"> @zaceno  I think it should be perfectly adequate to have just ""oncreate"" and ""ondestroy"". (Perhaps all we need, even is ""oncreate"")

I agree that the delayed onremove isn't strictly necessary, but I think `onupdate` and `ondestroy` are pretty important if you're using an non-hyperapp component lib or trying to do animation.

EDIT:  If we can make both camel-cased and lowercased events work, that will be ideal, IMO.",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T14:28:48Z,True,jorgebucaran_____hyperapp_____811_____467882131,"I have no intention of removing only some lifecycle events. It's all (Create, Update, Remove, and Destroy) or nothing (no lifecycle events at all #717).",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T14:28:48Z,True,jorgebucaran_____hyperapp_____811_____467882133,"This probably isn't explicitly for this PR, but I don't think this will work for headless mode.  Then again, most events wouldn't work unless you used jsdom or similar (which is essentially not headless mode), so maybe that's okay, but probably warrants a discussion.",True,True
jorgebucaran_____hyperapp_____811,2019-02-27T15:56:22Z,True,jorgebucaran_____hyperapp_____811_____467918184,"> I have no intention of removing only some lifecycle events. It's all (Create, Update, Remove, and Destroy) or nothing (no lifecycle events at all #717).

That's entirely up to you of course, although I think a halfway approach would be a win. We kan keep convenient access to particular DOM-nodes of interest, while still reducing the complexity our current lifecycle methods add.

Like @SkaterDad says, maybe Update is necessary (but perhaps we can simplify it to only run if attributes change). I no longer think both onDestroy and onRemove are necessary. Just one that works like onDestroy does should be enough.
",True,True
adventuregamestudio_____ags_____648,2019-02-27T22:28:16Z,True,adventuregamestudio_____ags_____648_____260972892,Updated this fix.,True,True
jorgebucaran_____hyperapp_____811,2019-02-27T23:06:06Z,True,jorgebucaran_____hyperapp_____811_____468067112,"I would like to use this solution for simplifying css transitions with onCreate and onDestroy by changing the global state (treat it like an action returning a new state?). I was looking for this exact solution earlier, but had to instead manually add an attribute to the element and a custom css selector (yuck). Maybe I’m going about transitions the wrong way?",True,True
jorgebucaran_____hyperapp_____811,2019-02-28T03:22:50Z,True,jorgebucaran_____hyperapp_____811_____468122279,"There's disagreement over what lifecycle methods we should keep and which ones are okay to lose as if we needed to simplify Hyperapp when there's no pressing need to do that.

Implementation details aside, do we want to change the lifecycle API to dispatch actions like we can from other DOM events?",True,True
jorgebucaran_____hyperapp_____811,2019-02-28T03:36:45Z,True,jorgebucaran_____hyperapp_____811_____468124672,"I vote yes on the new function signature. Seems like a big usability win, so long as it isn't adding too many bytes. ",True,True
w3c_____csswg-drafts_____3618,2019-02-28T22:45:00Z,True,w3c_____csswg-drafts_____3618_____468469454,@astearns @atanassov please review,True,True
w3c_____csswg-drafts_____3618,2019-02-28T23:54:35Z,True,w3c_____csswg-drafts_____3618_____468487095,"@ewilligers I'm fine taking the change, but I'm not certain why the group is required here.",True,True
w3c_____csswg-drafts_____3618,2019-02-28T23:59:00Z,True,w3c_____csswg-drafts_____3618_____468488117,"https://drafts.csswg.org/css-values/#component-combinators

> Every type, keyword, or bracketed group may be followed by **one** of the following modifiers:
> - A  question mark (?) indicates that the preceding type, word, or group is optional (occurs zero or one times).
> - A single number in curly braces ({A}) indicates that the preceding type, word, or group occurs A times.

Two modifiers are not permitted.
",True,True
w3c_____csswg-drafts_____3618,2019-03-01T05:48:34Z,True,w3c_____csswg-drafts_____3618_____468550859,"Why was my comment deleted, @w3c? Please reinstate it for the record.",True,True
jorgebucaran_____hyperapp_____811,2019-03-01T07:21:05Z,True,jorgebucaran_____hyperapp_____811_____468569148,I have been migrating continent these past two days so only just catching up with this thread. Will be back soon with some responses and an updated PR!,True,True
w3c_____csswg-drafts_____3618,2019-03-01T14:51:42Z,True,w3c_____csswg-drafts_____3618_____468690133,"It didn't add anything to the discussion here. For the record, everything that happens in the W3C GitHub org is separately archived.",True,True
w3c_____csswg-drafts_____3618,2019-03-01T15:48:52Z,True,w3c_____csswg-drafts_____3618_____468710091,"Well, that's your opinion.

I disagree, and in a discussion about a project, other readers should be allowed to form their own opinions of my legitimate input.

There's a strong correlation between my comment and the resolution of this pull request; indeed, there's a good argument for a causal relationship, so it seems suspicious to suggest that my comment didn't add anything to the discussion.

Please reinstate my comment, because what people read is *this* discussion (not some separate archive), and I want my name (*mfwitten*) associated with my comment, not with @w3c's comment that my input has been deleted, which makes it appear as though my input is somehow uncouth.

I mean, before deletion, there was just my one comment, which led to the swift resolution of this pull request. Now, there is a discussion about @w3c's deletion of my comment; it seems to me that it is the deletion of my comment that has detracted from the discussion and that is leading rapidly to dampened progress or cooperation.

If a person feels compelled to provide input, then that's not something that you should ignore, let alone explicitly silence; such input represents a perspective that others might share. At best, such silencing tends to dissuade future contributions, some of which you might actually consider to be valuable.

Have a little leeway, you know, for the sake of [noise margins](https://en.wikipedia.org/wiki/Static_discipline).",True,True
w3c_____csswg-drafts_____3618,2019-03-01T17:47:36Z,True,w3c_____csswg-drafts_____3618_____468750324,"Michael, frankly the tone of your comment was rude and disrespectful if not outright abusive. IMO it was also in violation of the [W3C Code of Ethics and Professional Conduct](https://www.w3.org/Consortium/cepc/).

If I were you I'd be grateful that there _isn't_ a readily accessible record of your behavior. Alan was doing you a favor by deleting it. But instead you choose to double-down and suggest that demonstrating being abusive is the way to get things done.

This is not acceptable and is not the way to foster involvement in a community where many of the participants are volunteering their time uncompensated. You have no right to demand action by anyone for any reason.

Not all input is welcome, and silencing disruptive and disrespectful input actually does **more** to encourage future contributions from people who don't care to be at the receiving end of such behavior.

Perhaps you'd benefit from reading some of the educational materials of the [Positive Work Environment Task Force](https://www.w3.org/Consortium/pwe/#Education).",True,True
callstack_____react-native-paper_____485,2019-03-02T17:22:52Z,True,callstack_____react-native-paper_____485_____468940642,"Pushed the requested changes here: https://github.com/callstack/react-native-paper/compare/pr/485

Seems when using our `Portal`, the menu is under the statusbar. So we need to handle it and then merge.
",True,True
callstack_____react-native-paper_____485,2019-03-03T21:30:22Z,True,callstack_____react-native-paper_____485_____469066397,"To solve the status bar issue, should a combination `SafeAreaView` and `StatusBar.currentHeight` do, or is there any other we handle it in this library?",True,True
callstack_____react-native-paper_____485,2019-03-03T23:17:44Z,True,callstack_____react-native-paper_____485_____469075882,"> To solve the status bar issue, should a combination SafeAreaView and StatusBar.currentHeight do, or is there any other we handle it in this library?

Let's do it for now. We can refactor to extract this logic later.",True,True
webpack_____webpack-dev-server_____1664,2019-03-04T09:14:04Z,True,webpack_____webpack-dev-server_____1664_____469175556,Looks good! Ready to merge?,True,True
webpack_____webpack-dev-server_____1664,2019-03-04T09:40:02Z,True,webpack_____webpack-dev-server_____1664_____469184574,"@evilebottnawi it's ready but for some weird reason the test keeps failing in node 6. The proxy I use fails with a EADDRNOTAVAIL error. I've been trying to repro in a container with node 6.16.0 (same version Appveyor uses), but it works just fine and the test passes without problems. Any idea why this could be happening?",True,True
webpack_____webpack-dev-server_____1664,2019-03-04T09:42:27Z,True,webpack_____webpack-dev-server_____1664_____469185387,"@rlamana 
```
 console.info node_modules/http-proxy-middleware/lib/logger.js:77
      [HPM] Proxy created: /  ->  http://0.0.0.0:8080
    console.error node_modules/http-proxy-middleware/lib/logger.js:89
      [HPM] Error occurred while trying to proxy request /sockjs-node from localhost:9050 to http://0.0.0.0:8080 (EADDRNOTAVAIL) (https://nodejs.org/api/errors.html#errors_common_system_errors)
    console.error node_modules/http-proxy-middleware/lib/logger.js:89
      [HPM] Error occurred while trying to proxy request /main from localhost:9050 to http://0.0.0.0:8080 (EADDRNOTAVAIL) (https://nodejs.org/api/errors.html#errors_common_system_errors)
  ● Client code › behind a proxy › responds with a 200
    expected 200 ""OK"", got 500 ""Internal Server Error""
      at Test.Object.<anonymous>.Test._assertStatus (node_modules/supertest/lib/test.js:268:12)
      at Test.Object.<anonymous>.Test._assertFunction (node_modules/supertest/lib/test.js:283:11)
      at Test.Object.<anonymous>.Test.assert (node_modules/supertest/lib/test.js:173:18)
      at localAssert (node_modules/supertest/lib/test.js:131:12)
      at node_modules/supertest/lib/test.js:128:5
      at Test.Object.<anonymous>.Request.callback (node_modules/superagent/lib/node/index.js:756:3)
      at IncomingMessage.parser (node_modules/superagent/lib/node/index.js:944:18)
  ● Client code › behind a proxy › requests websocket through the proxy with proper port number
    Timeout - Async callback was not invoked within the 30000ms timeout specified by jest.setTimeout.
      58 |     });
      59 | 
    > 60 |     it('requests websocket through the proxy with proper port number', (done) => {
         |     ^
      61 |       runBrowser().then(({ page, browser }) => {
      62 |         page
      63 |           .waitForRequest((requestObj) => requestObj.url().match(/sockjs-node/))
      at new Spec (node_modules/jest-jasmine2/build/jasmine/Spec.js:92:20)
      at Suite.it (test/Client.test.js:60:5)
      at Suite.describe (test/Client.test.js:42:3)
      at Object.describe (test/Client.test.js:24:1)
```

Maybe something doesn't handle (like errors) or something starts early then tests",True,True
webpack_____webpack-dev-server_____1664,2019-03-04T09:57:55Z,True,webpack_____webpack-dev-server_____1664_____469190639,"Oh, no ideas
/cc @hiroppy ",True,True
webpack_____webpack-dev-server_____1664,2019-03-05T09:28:46Z,True,webpack_____webpack-dev-server_____1664_____469606578,Something wrong with CI :confused: ,True,True
webpack_____webpack-dev-server_____1664,2019-03-05T09:41:51Z,True,webpack_____webpack-dev-server_____1664_____469611130,"@evilebottnawi I'm still trying to figure out why the proxy fails to connect to the devserver on the appveyor Windows environment for node 6 when the host is 0.0.0.0. I tried to launch a local instance of the appveyor env in local to repro the issue and try to debug with no luck...
",True,True
jorgebucaran_____hyperapp_____811,2019-03-05T17:15:33Z,True,jorgebucaran_____hyperapp_____811_____469768957,"I'm probably late to the discussion, but as requested, what I'm doing on some of my projects is dispatching a DOM event on all dom nodes created via javascript.

[Codepen example](https://codepen.io/lot3oo/pen/LgRbjj?editors=0010)

I actually used this on the hyperapp.rocks website:
https://github.com/loteoo/hyperapp-rocks/blob/master/src/app/components/ProjectViewer/index.jsx#L26

I might move to using a Custom Element, and dispatch the `mount` event on the node from there in the `connectedCallback`, which is a little more work but seems cleaner.

And as for why I'm pro life-cycle events:
They allow you to re-use logic from the view to dispatch actions/side-effects.

(from slack, for sharing purposes)

> If you have a component that needs to start a side effect when it becomes visible, and you have already some sort of logic in the view that handles displaying / hiding that component, it is very easy to ""time"" that side-effect right there, instead of duplicating that logic in some subscription.

> Common example, if you have some sort of routing inside the view, and you want to fetch data when that piece of view appears, you would need a similar (duplicate) routing in another place, probably in a subscription, that handles dispatching the side-effects.

> But it's not always a routing problem, sometimes it's for animations / transitions and all sorts of view logic that might need side effects.

The Custom Elements solution definitively does the job, but it doesn't feel as good as it would be if the hook was natively integrated in hyperapp.",True,True
jorgebucaran_____hyperapp_____811,2019-03-05T17:37:45Z,True,jorgebucaran_____hyperapp_____811_____469777615,"@lukejacksonn I'm going to hold on this for now. I may circle back to this eventually, as I don't consider the current alternatives final answers to the problem either.

@loteoo Thank you for your input, I appreciate it. I've decided to remove lifecycle events. I also plan on getting rid of other features that can be used as ""escape hatches"" to V2's declarative model. I know we can (and will) find solutions to problems where lifecycle events were convenient (https://github.com/jorgebucaran/hyperapp/issues/717). These solutions may not be perfect at first, but we'll iterate on them and learn how to improve them. 

One situation where lifecycle events were convenient was when animating removing elements (delayed removals), which this PR removes. But even for that, I don't want to use lifecycle events. 



",True,True
webpack_____webpack-dev-server_____1664,2019-03-05T19:30:58Z,True,webpack_____webpack-dev-server_____1664_____469825870,"@evilebottnawi @hiroppy, it is now ready to merge.

Apparently, win32/node 6 has issues establishing a connection to `0.0.0.0`. I fixed it by just pointing the test proxy to localhost. The test needs the dev server to be listening on `0.0.0.0`, it doesn't really matter how the proxy redirects to it anyway, as long as it reaches the dev server.

With this PR you can now use the `runBrowser` helper I included to add more e2e testing. I hope this helps.",True,True
webpack_____webpack-dev-server_____1664,2019-03-05T21:17:02Z,True,webpack_____webpack-dev-server_____1664_____469860487,"Sorry for the late reply. Thank you for creating e2e environment.
@rlamana Could you change the port number because `8080` is popular number?",True,True
webpack_____webpack-dev-server_____1664,2019-03-05T21:27:14Z,True,webpack_____webpack-dev-server_____1664_____469863902,@hiroppy in the test code? sure! I just thought since it should be in an isolated environment it wouldn't matter. I'll just set `9001` for the dev server and `9000` for the proxy.,True,True
webpack_____webpack-dev-server_____1664,2019-03-05T21:53:30Z,True,webpack_____webpack-dev-server_____1664_____469872784,"Yep, thanks! I'll change the default port number(`test/helper.js`) at other pr.",True,True
webpack_____webpack-dev-server_____1664,2019-03-06T04:21:31Z,True,webpack_____webpack-dev-server_____1664_____469962631,/cc @evilebottnawi PTAL;),True,True
webpack_____webpack-dev-server_____1664,2019-03-06T09:28:26Z,True,webpack_____webpack-dev-server_____1664_____262855952,"/cc @rlamana Looks we catch bug, when we use `API`, hot plugin should be added too, can you create issue?",True,True
webpack_____webpack-dev-server_____1664,2019-03-07T03:25:44Z,True,webpack_____webpack-dev-server_____1664_____263225475,"I assumed that was the API expected behavior, so I didn't think it was a bug. It all makes sense now. I will create the issue then.",True,True
webpack_____webpack-dev-server_____1664,2019-03-07T05:07:21Z,True,webpack_____webpack-dev-server_____1664_____263239396,I created issue #1703.,True,True
callstack_____react-native-paper_____485,2019-03-10T16:02:10Z,True,callstack_____react-native-paper_____485_____264045951,"@satya164 thanks for adding this, I have merged your change to this branch.",True,True
callstack_____react-native-paper_____485,2019-03-10T16:02:17Z,True,callstack_____react-native-paper_____485_____264045955,Done,True,True
callstack_____react-native-paper_____485,2019-03-10T16:03:47Z,True,callstack_____react-native-paper_____485_____264046019,I have changed it to remove the inner view and just add the `onLayout` on the outer view,True,True
alliedmodders_____amxmodx_____524,2019-03-12T16:07:45Z,True,alliedmodders_____amxmodx_____524_____472065940,@djearthquake There are `Float:geoip_latitude(const ip[])` and `Float:geoip_longitude(const ip[])` defined in geoip.inc. Do you have an issue with these?,True,True
alliedmodders_____amxmodx_____524,2019-03-12T16:43:30Z,True,alliedmodders_____amxmodx_____524_____472082305,"Those 2 natives do not proof back to raw coordinates as stated in my initial post. Can you show me the maths please if they do? How is ""longitude"":4.744700  zero?",True,True
alliedmodders_____amxmodx_____524,2019-03-12T17:21:22Z,True,alliedmodders_____amxmodx_____524_____472098303,"They do exactly what they are supposed to. You did something wrong in your code or you didn't install the GeoIP database correctly. Please ask for assistance in the [Scripting Help](https://forums.alliedmods.net/forumdisplay.php?f=11) section on our forums. Post more information about your setup and what you did, and provide your code so people can help you out. ",True,True
alliedmodders_____amxmodx_____524,2019-03-12T23:18:39Z,True,alliedmodders_____amxmodx_____524_____472217607,"amx_ctof and amx_ftoc. Is that a typo?


// native geoip_latitude(const ip[]);
static cell AMX_NATIVE_CALL amx_geoip_latitude(AMX *amx, cell *params)
{
	int length;
	char *ip = stripPort(MF_GetAmxString(amx, params[1], 0, &length));

	const char *path[] = { ""location"", ""latitude"", NULL };
	double latitude = lookupDouble(ip, path);

	return amx_ftoc(latitude);
}

// native geoip_longitude(const ip[]);
static cell AMX_NATIVE_CALL amx_geoip_longitude(AMX *amx, cell *params)
{
	int length;
	char *ip = stripPort(MF_GetAmxString(amx, params[1], 0, &length));

	const char *path[] = { ""location"", ""longitude"", NULL };
	double longitude = lookupDouble(ip, path);

	return amx_ftoc(longitude);
}

// native Float:geoip_distance(Float:lat1, Float:lon1, Float:lat2, Float:lon2, system = SYSTEM_METRIC);
static cell AMX_NATIVE_CALL amx_geoip_distance(AMX *amx, cell *params)
{
	float earthRadius = params[5] ? 3958.0 : 6370.997; // miles / km

	float lat1 = amx_ctof(params[1]) * (M_PI / 180);
	float lon1 = amx_ctof(params[2]) * (M_PI / 180);
	float lat2 = amx_ctof(params[3]) * (M_PI / 180);
	float lon2 = amx_ctof(params[4]) * (M_PI / 180);

	return amx_ftoc(earthRadius * acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon2 - lon1)));
}",True,True
alliedmodders_____amxmodx_____524,2019-03-13T08:20:43Z,True,alliedmodders_____amxmodx_____524_____472323642,"This is not a place for support. Please post in the forums. The AMXX code works, I tested it.",True,True
alliedmodders_____amxmodx_____524,2019-03-13T12:32:19Z,True,alliedmodders_____amxmodx_____524_____472402935,What AMXX code works? What did you test exactly? If this is not the place for support then why am I bothering testing your work for you for free and offering solutions here on this site already? How do you think we got here? The auto packaging of GeoIP sent it to the general public in a unusable form. I sorted that? Remember? The arrogance of AMXX does not match the greatness. Really guys. Good bye. I just showed you the native was returning a 0 when bash shows there is data. There is not anything wrong with my database copy or my work. Yours buddy had the problem. How quickly you forget. Why this code roundup on the forums? Then get here with this unappreciative attitude like only 3 people can program C++ really? How clannish. This site is the source of that code it's C++ not Small Pawn Alliedmodders. You want me to broadcast this further? I shredded my databases that I could use bash and pull coordinates because you are so sure of yourself and guess what it did not do anything. It's time you take more of my advice and less of your own. Your forums are a bigot troll factory. Clean it up. Your code and packaging. ,True,True
alliedmodders_____amxmodx_____524,2019-03-13T13:12:55Z,True,alliedmodders_____amxmodx_____524_____472415957,"Helping is welcomed and appreciated, but please do it the proper way. 
Answering after a merged commit is not helpful and make difficult to track the discussion/problem.

If you have an issue, always go there: https://github.com/alliedmodders/amxmodx/issues 
**It's important**. 

For scripting related questions, the forum is also a good place, as stated Nextra.

In your case, make sure you have the latest [city database](https://geolite.maxmind.com/download/geoip/database/GeoLite2-City.tar.gz) from Maxmind site (we know if there an issue with the current shipped database).

I tested your IP and it worked as expected:

```
L 03/13/2019 - 14:07:42: [test.amxx] lat = 46.321300
L 03/13/2019 - 14:07:42: [test.amxx] long = 4.744699
```

```SourcePawn
#include <amxmodx>
#include <geoip>

public plugin_init()
{
    new const ip[] = ""109.25.197.97"";

    new const Float:lat = geoip_latitude(ip);
    new const Float:long = geoip_longitude(ip);

    log_amx(""lat = %f"", lat);
    log_amx(""long = %f"", long);
}
```
Note: for debugging, you can dump your IP data directly in the console: `geoip dump <ip>`.

If you think there is a bug, **please create an issue instead**, elaborate as much as possible, and show your code as well.



",True,True
callstack_____react-native-paper_____485,2019-03-14T11:24:48Z,True,callstack_____react-native-paper_____485_____472810907,@satya164 can we have your approval here for merging it?,True,True
fffaraz_____awesome-cpp_____705,2019-03-16T19:06:54Z,True,fffaraz_____awesome-cpp_____705_____261793671,,True,True
adventuregamestudio_____ags_____648,2019-03-19T08:45:29Z,True,adventuregamestudio_____ags_____648_____474248968,"All good, I'll just include it as part of my SDL2 port for now.  Were you able to measure a performance difference though?

The COW implementation copy still needs to perform some checks and balances before assigning that pointer. The c++11 strings can implement something called SSO, which can store small strings (10-22 chars) within the struct without having to allocate on the heap. This means to copy these small strings you only need to copy 3 longints.",True,True
OpenViX_____enigma2_____399,2019-03-19T15:44:49Z,True,OpenViX_____enigma2_____399_____262515945,"This change removes the 'ALL' button as it now serves no purpose.  Its position on the keyboard layout is now used by the new 'DEL' button.  This change allows all the locale keyboards to return to their previous layouts and have the 'DEL' button in a consistent position.
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:46:57Z,True,OpenViX_____enigma2_____399_____474434891,Please do not merge this until after we have widened the spacebar.,True,True
OpenViX_____enigma2_____399,2019-03-19T15:49:03Z,True,OpenViX_____enigma2_____399_____474436106,"Who is making that change?

This change is a simple adjustment to restore the previous keyboard layouts (particularly Polish).  If other changes are made then this change will become unmergeable!
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:51:27Z,True,OpenViX_____enigma2_____399_____474437500,I'll find someone to do it.,True,True
OpenViX_____enigma2_____399,2019-03-19T15:52:15Z,True,OpenViX_____enigma2_____399_____474437969,"Well then this change should go in first!
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:53:03Z,True,OpenViX_____enigma2_____399_____474438379,Why is that?,True,True
OpenViX_____enigma2_____399,2019-03-19T15:53:28Z,True,OpenViX_____enigma2_____399_____474438621,"To avoid merge errors and to fix the Polish locale.
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:53:55Z,True,OpenViX_____enigma2_____399_____474438887,Why do you want that crap code imported from PLi.,True,True
OpenViX_____enigma2_____399,2019-03-19T15:53:57Z,True,OpenViX_____enigma2_____399_____474438916,It can be done later,True,True
OpenViX_____enigma2_____399,2019-03-19T15:54:24Z,True,OpenViX_____enigma2_____399_____474439170,"Broken crap code!
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:54:29Z,True,OpenViX_____enigma2_____399_____474439239,What is crap about wide space bar?,True,True
OpenViX_____enigma2_____399,2019-03-19T15:55:02Z,True,OpenViX_____enigma2_____399_____474439576,"There is nothing wrong with the visuals but the code to implement it is very broken!
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:55:52Z,True,OpenViX_____enigma2_____399_____474440011,"Nothing wrong with the idea of a wider space bar, the problem is the crap coding.",True,True
OpenViX_____enigma2_____399,2019-03-19T15:57:12Z,True,OpenViX_____enigma2_____399_____474440844,"Have you tested the OpenPLi code with a pop up VirtualKeyBoard skin?

Have you examined the code that makes the buttons bigger?
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:57:59Z,True,OpenViX_____enigma2_____399_____474441247,Did you not read my answer on the forum?,True,True
OpenViX_____enigma2_____399,2019-03-19T15:58:26Z,True,OpenViX_____enigma2_____399_____474441494,"Which answer on which forum?
",True,True
OpenViX_____enigma2_____399,2019-03-19T15:59:12Z,True,OpenViX_____enigma2_____399_____474441954,The one where you asked the same question,True,True
OpenViX_____enigma2_____399,2019-03-19T16:00:32Z,True,OpenViX_____enigma2_____399_____474442713,"Sorry, haven't been on the forum. Have been trying to debug this other mangled code.",True,True
OpenViX_____enigma2_____399,2019-03-19T16:01:51Z,True,OpenViX_____enigma2_____399_____474443423,"There is no example of the OpenPLi code on a pop up window based skin.  Running the one keyboard that has been crafted to sort of work is not extensive testing.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:03:32Z,True,OpenViX_____enigma2_____399_____474444397,"So, you are asking if I have tested something that does not exist",True,True
OpenViX_____enigma2_____399,2019-03-19T16:04:45Z,True,OpenViX_____enigma2_____399_____474445149,"I haven't dismissed creating an eye candy keyboard but it will only be done if it is appropriately reasonable to do so.

I think I have some ideas on how to do it but the code is quite complex.  The more complex it become the easier it is for bugs to creep in.  I am still not sure that it is worth it.  Functionality wise the eye candy makes little usage difference.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:05:26Z,True,OpenViX_____enigma2_____399_____474445528,Give it a rest about eye candy.,True,True
OpenViX_____enigma2_____399,2019-03-19T16:06:08Z,True,OpenViX_____enigma2_____399_____474445951,"I don't remember what skins I tested against but one of them was a pop up window version without a colour button bar.

I also have a hidden option to do a pop up version in OverlayHD.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:07:04Z,True,OpenViX_____enigma2_____399_____474446483,"If it is a visual only change then what should it be called?  Eye candy is what this sort of change is often called.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:07:28Z,True,OpenViX_____enigma2_____399_____474446668,The keyboard should look like a real keyboard.,True,True
OpenViX_____enigma2_____399,2019-03-19T16:09:03Z,True,OpenViX_____enigma2_____399_____474447632,"Who said that?  Why was the previous version so acceptable for so many years?  My aim was to put the most common buttons in the same relative positions as on a real keyboard.  I believe that I achieved that objective.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:11:03Z,True,OpenViX_____enigma2_____399_____474448871,So something you want is valid. What others want is eye candy?,True,True
OpenViX_____enigma2_____399,2019-03-19T16:13:04Z,True,OpenViX_____enigma2_____399_____474450048,"If you want it then why aren't you coding it?

At the moment all I am seeing is obstruction to my maintaining the existing code.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:14:01Z,True,OpenViX_____enigma2_____399_____474450627,We'll merge your code later.,True,True
OpenViX_____enigma2_____399,2019-03-19T16:14:55Z,True,OpenViX_____enigma2_____399_____474451190,"Guys, this can be discussed on the forum.

@ Ian, this PR is not passing Travis CI checks, getting build error.",True,True
OpenViX_____enigma2_____399,2019-03-19T16:17:41Z,True,OpenViX_____enigma2_____399_____474452411,"I am still puzzled why EVERYONE accepted the original VirtualKeyBoard for so many years and no-one demanded it look any different.  I propose an enhancement to better match physical keyboards and all of the sudden I am responsible for massive disappointment that the VirtualKeyBoard is not a visible match to its physical counterpart.  Taapat only made his changes AFTER I fixed the code and proposed a better layout.  If he had coded it properly I would have used his code.  His changes are VERY poor.  The other OpenPLi enhancements are now implemented on OpenViX.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:18:30Z,True,OpenViX_____enigma2_____399_____474452762,"I don't understand what the Travis CI check is failing?

Can someone please explain the problem.
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:21:39Z,True,OpenViX_____enigma2_____399_____474454085,"> 
> 
> I don't understand what the Travis CI check is failing?
> 
> Can someone please explain the problem.

This might give a glue: https://travis-ci.com/OpenViX/enigma2/builds/104981721

",True,True
OpenViX_____enigma2_____399,2019-03-19T16:22:16Z,True,OpenViX_____enigma2_____399_____474454352,"There is no need to shout.

It was PR2 suggestion to have the wide keyboard, you rejected it.

It's now added to PLI. I'd like to have it in ViX too.

What's the point keep changing things to fix it again and again. Let's get it right in the first place.",True,True
OpenViX_____enigma2_____399,2019-03-19T16:25:49Z,True,OpenViX_____enigma2_____399_____474455844,The wide spacebar to better match a real keyboard was made before the virtual keyboard got refactored. It was mentioned about page 10 in the thread. Taapat got involved in late 30s.,True,True
OpenViX_____enigma2_____399,2019-03-19T16:26:12Z,True,OpenViX_____enigma2_____399_____474456024,"I rejected it because it is not easy to do properly.  I still don't have a workable plan to implement it.

The OpenPLi version is broken.  Are you asking me to add broken code to OpenViX?

What is wrong with refining my code?  Why can't I commit changes to improve it?  Are you suggesting that all commited code must be finalised in a single commit?
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:28:23Z,True,OpenViX_____enigma2_____399_____474456919,"What is broken? It looks like a real keyboard, buttons are selected like a real keyboard.

I'm not referring to colours.",True,True
OpenViX_____enigma2_____399,2019-03-19T16:32:31Z,True,OpenViX_____enigma2_____399_____474458608,"The errors are due to a build environment error and not my code:

> E: Unable to locate package g++-5
> E: Couldn't find any package by regex 'g++-5'
> apt-get install failed
",True,True
OpenViX_____enigma2_____399,2019-03-19T16:38:55Z,True,OpenViX_____enigma2_____399_____474461272,"The cursor colour changes into the Locale selection colour on some buttons.  That is not correct. 

The RED, GREEN, YELLOW and BLUE action buttons are no longer consistently displayed.  That is not correct.

There are now two versions of English.  While this is not an error it is a reversal of the code optimisation and is now bloat that is much harder to maintain.

Latvian is now promoted to be a core language even though it is basically English.  Yet more difficult to administer bloat.  This also indicates a lack of understanding how the code actually works.

Making buttons bigger was the simple part of the task.  Making the bigger buttons work consistently and properly is much harder and this has not been done.
",True,True
adventuregamestudio_____ags_____648,2019-03-19T17:03:53Z,True,adventuregamestudio_____ags_____648_____474471752,"> I'll just include it as part of my SDL2 port for now

how is this change related to the SDL2 port ?",True,True
OpenViX_____enigma2_____399,2019-03-19T18:05:41Z,True,OpenViX_____enigma2_____399_____474502893,"> The wide spacebar to better match a real keyboard was made before the virtual keyboard got refactored. It was mentioned about page 10 in the thread. Taapat got involved in late 30s.

The first mention of a larger space bar was the suggestion on page 16 by Pr2. [Post 315](https://forums.openpli.org/topic/60472-language-assistance-requested/?view=findpost&p=921739)  At the time I mentioned it would be difficult to implement and offered little in return.  This was well after the bulk of the refactored VirtualKeyBoard code was already written.

There was no further mention or request for a wider SPACE button until the bottom of page 38 in [Post 759](https://forums.openpli.org/topic/60472-language-assistance-requested/?view=findpost&p=935259) where Littlesat provided a pointer to a completely different piece of code that had implemented variable sized buttons.  That code had nothing to do with VirtualKeyBoard.py.

Taapat then jumped on the desire / need to have variable sized buttons.  Littlesat asked that the change be limited to allowing for a larger SPACE bar only.  There was no further discussion on the code changes.  Taapat simply commited his radical changes with no further discussion.  Had Taapat only coded the wider SPACE bar, as requested by Littlesat and others, then his changes may have been acceptable and workable.

If I restrain my change to simply allow for a wider SPACE bar then that should be significantly more achievable.
",True,True
OpenViX_____enigma2_____399,2019-03-19T18:13:10Z,True,OpenViX_____enigma2_____399_____474506918,"Are you saying a truer reflections of a keyboard caused the issues you have highlighted?

Can you document an easy to follow reproduction method to trigger the issues?

We can then test removal of the three commits and establish if theses issues are really caused by having keys that are sized similar to what users see on all other devices.

",True,True
OpenViX_____enigma2_____399,2019-03-19T18:34:21Z,True,OpenViX_____enigma2_____399_____474516270,Trigger what issues? Main issue is the coding is crap.,True,True
OpenViX_____enigma2_____399,2019-03-19T18:36:35Z,True,OpenViX_____enigma2_____399_____474517052,The issues Ian is alleging that truer representation of a real keyboard has caused.,True,True
OpenViX_____enigma2_____399,2019-03-20T00:16:35Z,True,OpenViX_____enigma2_____399_____474634005,"The tests for problems are easy:
1. Navigate around the grid of a keyboard that has large buttons, note that the cursor colour changes from white to yellow over some buttons.  Compare that to an unmodified layout.
2. Compare the ESC, SHIFT and ENTER buttons on the large button version and the unmodified layout.  Note colour highlighting code fails on the large button versions.
3. Find a skin that displays the VirtualKeyBoard as a pop up window without the colour button bar and tell me to what the colour buttons are mapped.
4. Look at the code and note the unwarranted duplication and complication of the English tables.
5. Note the promotion of Latvian to a root locale even though it is based on English.  More bloat and a demonstration of a lack of understanding of how the code works.
6. Look at the code, note the size growth and new complexity.  Does it add any functionality, other than look?  A look that is not working correctly.

Next use the OpenViX version and retest all of the above.  Up until Taapat's commits the code was **identical**.

I am not rating the severity of the issues.  I am simply saying that I will not deliberately write, implement, or merge, broken code.  What if this code were merged into OpenViX.  How would the functionality issues be addressed?  I suspect there would be blame allocated and the change would be reverted.  So I have actually saved people time and effort.
",True,True
OpenViX_____enigma2_____399,2019-03-20T00:29:47Z,True,OpenViX_____enigma2_____399_____474636487,What do you mean by pop up window?,True,True
OpenViX_____enigma2_____399,2019-03-20T00:31:09Z,True,OpenViX_____enigma2_____399_____474636741,He means a window that doesn't show the button bar.,True,True
OpenViX_____enigma2_____399,2019-03-20T00:44:13Z,True,OpenViX_____enigma2_____399_____474639464,"He is mentioning items that are irrelevant.

We will add wide buttons, then merge his code.",True,True
OpenViX_____enigma2_____399,2019-03-20T00:45:21Z,True,OpenViX_____enigma2_____399_____474639682,But that code doesn't work properly.,True,True
OpenViX_____enigma2_____399,2019-03-20T00:49:09Z,True,OpenViX_____enigma2_____399_____474640385,"![1](https://user-images.githubusercontent.com/2067864/54651261-5740a800-4ab2-11e9-99d0-fae51b742547.jpg)
",True,True
OpenViX_____enigma2_____399,2019-03-20T01:13:00Z,True,OpenViX_____enigma2_____399_____474644950,"Pull requests should be applied in order of submission to avoid creating merge errors.  The new code should be based on the fixed Polish locale.
",True,True
OpenViX_____enigma2_____399,2019-03-20T01:19:50Z,True,OpenViX_____enigma2_____399_____474646227,"> He is mentioning items that are irrelevant.

If I submitted such buggy code directly to OpenViX it would be immediately reverted as faulty.
",True,True
adventuregamestudio_____ags_____648,2019-03-20T01:55:42Z,True,adventuregamestudio_____ags_____648_____474653027,"> how is this change related to the SDL2 port ?

It's just where I'm doing my main work.. I occasionally pull stuff out (like this PR) to put into ags3.",True,True
OpenViX_____enigma2_____399,2019-03-20T06:12:57Z,True,OpenViX_____enigma2_____399_____474698400,"Abu we have two experienced coders clearly giving their advice about the code, please accept their advise.

Please can any further discussion on this issue be discussed in the relevant forum thread.",True,True
OpenViX_____enigma2_____399,2019-03-20T07:25:11Z,True,OpenViX_____enigma2_____399_____474716507,"Btw, sorry I didn't mean to close the pull request, just to lock the comment.",True,True
fffaraz_____awesome-cpp_____705,2019-03-20T11:41:50Z,True,fffaraz_____awesome-cpp_____705_____474794663,@fffaraz Is anyone maintaining this?,True,True
fffaraz_____awesome-cpp_____705,2019-03-20T13:30:28Z,True,fffaraz_____awesome-cpp_____705_____474828867,"Because a PR with no additional details on the library is open for 4 days, while you see lots of commits being made every few days, you question whether the project is maintained? 😄 

NeuroCL has one star and seems to be incomplete with ""Comming soon..."" in the description. Kind of hard to judge whether this really fits the awesome list. 🤔 ",True,True
fffaraz_____awesome-cpp_____705,2019-03-20T14:47:08Z,True,fffaraz_____awesome-cpp_____705_____474863921,"@fffaraz feel free to close all my pull requests and also remove my libraries from your list as well.

@eXpl0it3r who are you exactly to judge whether this or any library fits the awesome list? You just violated the Code of Conduct of this repository. What really amazes me though is that @fffaraz is just laughing about it.

Have a nice day!",True,True
laurent22_____joplin_____1141,2019-03-20T20:14:50Z,True,laurent22_____joplin_____1141_____475009977,"hello.

is a ""sub-notebook"" function implemented? i thinke like this:
 Notebook --> Subnotebook ---> Notes
                   |-> Subnotebook 2 --> Notes
                   '-> Subnotebook 3 --> Notes

thank you for this great app :)",True,True
callstack_____react-native-paper_____485,2019-03-22T19:55:48Z,True,callstack_____react-native-paper_____485_____475759579,Great work @iyadthayyil! Thanks everyone!,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T20:38:24Z,True,FuelRats_____pipsqueak3_____123_____264279147,,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T21:20:43Z,True,FuelRats_____pipsqueak3_____123_____476382121,"# [Codecov](https://codecov.io/gh/FuelRats/pipsqueak3/pull/123?src=pr&el=h1) Report
> Merging [#123](https://codecov.io/gh/FuelRats/pipsqueak3/pull/123?src=pr&el=desc) into [develop](https://codecov.io/gh/FuelRats/pipsqueak3/commit/4898a9d75e3306f9667d78fbdfedaceb0811df40?src=pr&el=desc) will **increase** coverage by `0.02%`.
> The diff coverage is `100%`.

| [Impacted Files](https://codecov.io/gh/FuelRats/pipsqueak3/pull/123?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [src/packages/ratmama/ratmama\_parser.py](https://codecov.io/gh/FuelRats/pipsqueak3/pull/123/diff?src=pr&el=tree#diff-c3JjL3BhY2thZ2VzL3JhdG1hbWEvcmF0bWFtYV9wYXJzZXIucHk=) | `100% <100%> (ø)` | :arrow_up: |
",True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:30:05Z,True,FuelRats_____pipsqueak3_____123_____268894128,[Nitpick] Couldn't this be simplified to `from ..galaxy import Galaxy`?,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:30:35Z,True,FuelRats_____pipsqueak3_____123_____268894230,[Style] Constants should follow `UPPER_CASE` notation.,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:32:11Z,True,FuelRats_____pipsqueak3_____123_____268894526,"[Error] This method call is risky, because `find_system_by_name` can return `None`, which will cause `find_nearest_landmark` to break.",True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:34:00Z,True,FuelRats_____pipsqueak3_____123_____268894886,"[Error] If `find_nearest_landmark` does not return a distance greater than `0`, this string will interpolate to, for instance, `""Reported System: Sol ()""`",True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:35:47Z,True,FuelRats_____pipsqueak3_____123_____268895201,[Suggestion] I think `code_red` was a better name for this variable.,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:38:05Z,True,FuelRats_____pipsqueak3_____123_____268895682,[Discussion] [Not Blocking] Is there a case in which this `re.sub` shouldn't be called? It appears to be called in every branch of this `if`. Would it not be better placed outside of the `if`s to remove the duplication?,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:38:52Z,True,FuelRats_____pipsqueak3_____123_____268895847,"[Error] Same concern as above. If the system does not resolve into a `StarSystem` object, `find_nearest_landmark` will break.",True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:42:12Z,True,FuelRats_____pipsqueak3_____123_____268896487,[Error] Debug print should be removed from production tests.,True,True
FuelRats_____pipsqueak3_____123,2019-03-25T23:46:06Z,True,FuelRats_____pipsqueak3_____123_____268897234,"[Error]

in this case, this import is erroneous as it imports from the internal module, rather than the interface.

it should be simplified to `from ..galaxy import Galaxy`",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:01:32Z,True,FuelRats_____pipsqueak3_____123_____268900275,"[Error][scope][style]
this was renamed to `code_red` intentionally, as per naming conventions and rules",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:05:05Z,True,FuelRats_____pipsqueak3_____123_____268900931,[error] empty table intentionally empty?,True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:06:08Z,True,FuelRats_____pipsqueak3_____123_____268901113,"[style][error] instance of an object should be lower case, further this shadows name from containing scope (`Galaxy` already defined from  import)",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:12:37Z,True,FuelRats_____pipsqueak3_____123_____268902203,it is not called in the event none of the conditions are met.,True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:17:49Z,True,FuelRats_____pipsqueak3_____123_____268903140,"[suggestion] this expression, `.split('[')[0]`, while simple, is repeated at least twice within this module. Further, i can forsee usages of this expression in other modules/

Therefore, it may be wise to move this routine into our utilities package
```py
def strip_tags(nickname:str) -> str
    return nickname.strip('[')[0]
```",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:18:23Z,True,FuelRats_____pipsqueak3_____123_____268903230,[error] [style] usage of single character variables,True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:19:02Z,True,FuelRats_____pipsqueak3_____123_____268903336,[error][style] usage of single character variables,True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:19:47Z,True,FuelRats_____pipsqueak3_____123_____268903463,"
[error][style] usage of single character variables",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:20:03Z,True,FuelRats_____pipsqueak3_____123_____268903499,"
[error][style] usage of single character variables",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:20:13Z,True,FuelRats_____pipsqueak3_____123_____268903536,"
[error][style] usage of single character variables",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:23:41Z,True,FuelRats_____pipsqueak3_____123_____268904183,404 empty table not found,True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:24:21Z,True,FuelRats_____pipsqueak3_____123_____268904294,"``md

# ratsignal_parser
| Element| description|
|--------|------------|
|announcer_nicks| list of case-insensitive nicks, that are allowed to announce incoming clients|
```",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:24:58Z,True,FuelRats_____pipsqueak3_____123_____268904418,"nope, i misread here. 🤦‍♂️ ",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:39:34Z,True,FuelRats_____pipsqueak3_____123_____268906870,"looking into ratlib, this function actually exists already",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T00:40:47Z,True,FuelRats_____pipsqueak3_____123_____268907056,"I could have sworn it had existed, but evidently i didn't look hard enough when i searched for it prior to rendering this suggestion 😅 

```py
def strip_name(nickname: str) -> str:
    """"""
    This function accepts one input `nickname` and returns the input string
    minus any tags.

    An IRC tag is anything starting with ""`[`"". Further, anything following a
    `[` is truncated.

    Args:
        nickname (str): raw nickname to strip tags

    Returns:
        str: nickname stripped of tags
    """"""
    split_string = nickname.split(""["")
    return split_string[0]

``` 

so it does

In which case, best not re-invent the wheel, i suggest using this method rather than duplicating it",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T03:53:50Z,True,FuelRats_____pipsqueak3_____123_____268935363,"[Scope] Modifying codeowners is out of scope for your pull request, and currently irrelevant for those without write access to the repository.  Please remove this.",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T03:56:56Z,True,FuelRats_____pipsqueak3_____123_____268935773,Agreed. Please fix.,True,True
FuelRats_____pipsqueak3_____123,2019-03-26T07:05:00Z,True,FuelRats_____pipsqueak3_____123_____268963652,"As this is a module-level constant, don't you mean upper case?",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T11:02:31Z,True,FuelRats_____pipsqueak3_____123_____269046200,"Modifying Codeownership is something that should have been in the original PR, therefore it's well within scope of this one.

 Even if it's useless since I have no write access, I still have the right to put my thumbprint on modules that have been created by me.",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T11:05:03Z,True,FuelRats_____pipsqueak3_____123_____269047127,"I agree it should be uppercase since it's a module level constant, even if it's a temporary one.",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T15:23:08Z,True,FuelRats_____pipsqueak3_____123_____269161948,"I'm not going to get drawn into a debate with you about 'rights' with your code.  Once it is integrated into the project its no longer 'your code.'  That ideology is incompatible with an open-source project.

That point aside, anyone can see who contributed to the project and who authored specific commits.   What you are proposing is not the intended usage of the codeowners file.  If you had submitted a modification to the codeowners file as part of your original PR, It also would have been considered out of scope.",True,True
FuelRats_____pipsqueak3_____123,2019-03-26T17:34:45Z,True,FuelRats_____pipsqueak3_____123_____476763845,"the function and purpose of this file is not to assign who owns what
files(the Fuel Rats own everything) but rather toassign who is
responsiblefor Reviewing changes to the specified files.

it's clear *who* wrote a bit of code by looking at who committed the lines
in question, as provided

For its intended use, this file's settings are only enforced for members
with write access. GH will not permit a code owner that does not have write
access

putting all that aside, it is beyond the scope of a feature pull request to
effect policy change.By modifying this file, you are inherently modifying
policy.


, Mar 26, 2019, 08:23 Shatt <notifications@github.com> wrote:

> *@shatteredbeam* commented on this pull request.
> ------------------------------
>
> In .github/CODEOWNERS
> <https://github.com/FuelRats/pipsqueak3/pull/123#discussion_r269161948>:
>
> > @@ -22,6 +22,9 @@
>  # rules module
>  /src/packages/rules/ @MHajoha
>
> +# RatSig related module
> +/src/packages/ratmama @beepbeat
>
> I'm not going to get drawn into a debate with you about 'rights' with your
> code. Once it is integrated into the project its no longer 'your code.'
> That ideology is incompatible with an open-source project.
>
> That point aside, anyone can see who contributed to the project and who
> authored specific commits. What you are proposing is not the intended usage
> of the codeowners file. If you had submitted a modification to the
> codeowners file as part of your original PR, It also would have been
> considered out of scope.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/FuelRats/pipsqueak3/pull/123#discussion_r269161948>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AC94SsiveuFSgECe7cT6hGZ6-k8Q-FqOks5vajtegaJpZM4cJK-6>
> .
>
",True,True
FuelRats_____pipsqueak3_____123,2019-03-27T20:11:57Z,True,FuelRats_____pipsqueak3_____123_____269748930,"yes. the original naming made it confusing to tell if it was constant or not. if its a constant then yes, UPPER_CASE is correct",True,True
libretro_____libretro-common_____112,2019-03-27T21:48:50Z,True,libretro_____libretro-common_____112_____265113964,"This is something I had been thinking too, and a user seemed interested too.
So much that he started a bounty.

https://github.com/fr500/dosbox-svn/issues/6
https://www.bountysource.com/issues/72009314-make-ipxnet-avaible-just-by-using-netplay

This is a first draft of what it would take to have such integration.
I'd like some comments before starting to work on a final proposal for a core (dosbox) and the frontend (retroarch of course)

This would be ideal for game cores, and I figure with some work it would work for dolphin/ppsspp netplay too.

The idea would be that when the env is set the ""start netplay"" action in the frontend defers to a different codepath, it would still announce the lobby, but instead of implementing netplay, it would signal the core to start in server mode. The frontend specifies the port and the listening address. Maybe some other variables would be desirable, I'd like to hear other people's opinions.

A ""join host"" action in the frontend would then signal the core to join the hosting peer.

I already tried this in a hacky manner (hijacked the lan announcement code) and it worked reasonably well. Relay would not be supported of course, but port mapping should)",True,True
callstack_____react-native-paper_____485,2019-03-28T00:22:50Z,True,callstack_____react-native-paper_____485_____477395830,"Can the Menu component be used as a Dropdown for TextInput as shown https://material.io/design/components/menus.html#exposed-dropdown-menu ?

Replacing the `anchor` attribute with TextInput (and using `onFocus` instead of `onPress`) won't work.",True,True
fossasia_____neurolab-android_____129,2019-03-30T02:06:48Z,True,fossasia_____neurolab-android_____129_____265906262,"Fixes #128 

**Changes**: Now whenever the user opens the app. His last checked preferences shall be stored.

**Checklist**: [Please tick following check boxes with `[x]` if the respective task is completed]
- [x] I have used resources from `strings.xml`, `dimens.xml` and `colors.xml` without hard-coding them
- [ ] No modifications done at the end of resource files `strings.xml`, `dimens.xml` or `colors.xml`
- [x] I have reformatted code in every file included in this PR [<kbd>CTRL</kbd>+<kbd>ALT</kbd>+<kbd>L</kbd>]
- [x] My code does not contain any extra lines or extra spaces
- [x] I have requested reviews from other members

",True,True
fossasia_____neurolab-android_____129,2019-03-30T02:40:23Z,True,fossasia_____neurolab-android_____129_____478198914,@mariobehling @iamareebjamal @CloudyPadmal Please review. Thanks!,True,True
fossasia_____neurolab-android_____129,2019-03-30T11:56:48Z,True,fossasia_____neurolab-android_____129_____478238905,@iamareebjamal Please review this.,True,True
fossasia_____neurolab-android_____129,2019-03-30T12:57:05Z,True,fossasia_____neurolab-android_____129_____478243360,@iamareebjamal Please review this.,True,True
fossasia_____neurolab-android_____129,2019-03-30T13:59:41Z,True,fossasia_____neurolab-android_____129_____478248347,"@RohitJain1103 @iamareebjamal I could not get the purpose of #123 . The server settings (the checkboxes specifically simulation, load resources, audio feedback, 24 bit mode and advanced mode) preferences from the Launcher Activity should be stored in Shared Prefs only because their last response should be stored after every session to aid the user the next time he uses the app for configuring and setting up the next session and he doesn't need to check the necessary settings again. We don't need to store anything from the Program modes from the app. And @RohitJain1103 If you are talking about such large data even Cloud tech like Firestore can be used in the future if needed. Please don't try to compare each and everything from the desktop application. Android development has got some separate principles and dev strategies. ",True,True
fossasia_____neurolab-android_____129,2019-03-30T14:00:06Z,True,fossasia_____neurolab-android_____129_____478248383,@iamareebjamal Please share your thoughts.,True,True
fossasia_____neurolab-android_____129,2019-03-30T14:06:21Z,True,fossasia_____neurolab-android_____129_____478248969,"@RohitJain1103 @suresh-gandhi If you want further clarification, let us discuss on the gitter channels and let's leave the forums for reviews from mentors. Cheers!",True,True
fossasia_____neurolab-android_____129,2019-03-30T14:55:18Z,True,fossasia_____neurolab-android_____129_____478253240,"@jddeep You still didn't answer the question. I am afraid but It seems to me you are beating around the bush. What I am saying is a simple question. The issue is already being tackled in this PR. What is the need to duplicate it. And assume even if shared preferences are to be used(our mentors @iamareebjamal @CloudyPadmal would let us know in that case) then also it should be tackled by this PR not by a separate PR. I would suggest you to understand neurolab-desktop first, install it in your machine, run the application. And if you have already installed it please understand the code-base comprehensively. 

> I could not get the purpose of #123 . The server settings (the checkboxes specifically simulation, load resources, audio feedback, 24 bit mode and advanced mode) preferences from the Launcher Activity should be stored in Shared Prefs only because their last response should be stored after every session to aid the user the next time he uses the app for configuring and setting up the next session and he doesn't need to check the necessary settings again.

Its not so simple. Just see how Launcher class and ini file are related in neurolab-desktop. It seems to me you have not at all installed the neurolab-desktop repo in your machine. 

>If you are talking about such large data even Cloud tech like Firestore can be used in the future if needed...

See again. Its not big data dear. Nobody is suggesting to go for the Cloud Storage. Its about using right things for right purpose. You please understand neurolab-desktop in depth first. I would strongly urge you to do that.

>Please don't try to compare each and everything from the desktop application. Android development has got some separate principles and dev strategies.

Its not about comparing the two things together. Its about going in the right direction and porting the software correctly which you aren't. Its not about a single feature which has subjectivity in its implementation for different platforms. Its about the underlying design pattern involved. I hope you understand.

> Suggestion

Why don't you work on the program modes and concrete PR's. It would make the porting process swift and help the organization a lot. 

",True,True
fossasia_____neurolab-android_____129,2019-03-30T15:09:46Z,True,fossasia_____neurolab-android_____129_____478254558,"Dear @RohitJain1103  
Answer to your first question:
I was working on Shared preferences before the #123 was made. And as soon as @iamareebjamal commented about using them I made the PR incidently. Please see here https://github.com/fossasia/neurolab-android/pull/123#issuecomment-478199105 for verification. 

> I am afraid but It seems to me you are beating around the bush. 

And why are your use of words in a quarrelling fashion buddy? If you want any particular change in a PR. Please comment about it and leave the rest to the Author and mentor.
Talking about helping out the organization and the project development. I have been contributing to it right from when the project was at the level of scratch. Again for verification please refer here 
https://github.com/fossasia/neurolab-android/pulls/jddeep . Instead of thinking about helping out the organization start doing it by quality PRs. I suggested you not to extend the discussion here in the forums instead try using the gitter channel. But still you didn't listen. Hope you understand. Looking forward to your quality contributions rather than just reformatting the code and changing the images. Cheers!",True,True
fossasia_____neurolab-android_____129,2019-03-30T15:15:18Z,True,fossasia_____neurolab-android_____129_____478255043,">  I could not get the purpose of #123 . The server settings (the checkboxes specifically simulation, load resources, audio feedback, 24 bit mode and advanced mode) preferences from the Launcher Activity should be stored in Shared Prefs only because their last response should be stored after every session to aid the user the next time he uses the app for configuring and setting up the next session and he doesn't need to check the necessary settings again. We don't need to store anything from the Program modes from the app. And @RohitJain1103 If you are talking about such large data even Cloud tech like Firestore can be used in the future if needed. Please don't try to compare each and everything from the desktop application. Android development has got some separate principles and dev strategies.

@iamareebjamal Please share your thoughts.",True,True
fossasia_____neurolab-android_____129,2019-03-30T19:26:58Z,True,fossasia_____neurolab-android_____129_____478281170,"@jddeep It is the people like you who are destroying the reputation of Foss by unnecessarily fighting in the comments again and again. Do you know why any new contributor tries to work on this repo and then leaves it? It is because of your regular pestering in comments and telling them to do real contribution while you are busy adding text to AboutUs, porting classes with no lines of code in them. Your logic is pretty clear - @jddeep wants to do GSoc in Foss so disturb every other contributor, there is no competition and hence you get the opportunity. Well done man! Who am I even discussing with. A person who is ""contributing"" to this repo and don't even know how to squash commits, A ""contributor"" who doesn't even know how to run neurolab-desktop and is porting it to android version. (I have screenshot of the gitter message which you had sent asking procedure of running neurolab-desktop).

Talking about serious contributions, your comments in this repo = exp(number of commits). If you want proof I can add all the screenshots of all your pestering sessions. 
You tell you have been working on this repo from scratch but the project before March was hollow only consisting of UI's. Talking about my contributions, I have optimised many mathematical functions which require good maths base which I'm sure you wouldn't have. 

Note - If you want proof of each and every statement, I have screenshot of everything.

And do not comment on this again. Your insensible statements do not make any sense. And if you do so I will have to contact higher authorities to take care of this matter.",True,True
fossasia_____neurolab-android_____129,2019-03-30T19:36:27Z,True,fossasia_____neurolab-android_____129_____478282166,"From now on, please keep comments strictly related to PR code quality, and bugs. Not that if a PR is necessary or the approach. Both of you reflect poorly.
",True,True
libretro_____libretro-common_____112,2019-03-31T20:23:53Z,True,libretro_____libretro-common_____112_____478378715,"So... no feedback, no guidance, not sure how to proceed...
API changes are complex due to the fact that all cores would need an updated libretro.h if this gets implemented.

With no feedback there can be no progress, and with no progress... well may as well start forking.
The API side is growing stale. The fact that so many things work on assumptions or hardcoding when the API can be fully bi-directional is annoying.

I figure there is no point moving forward without feedback from stakeholders so until that happens I won't be moving any of my related code forward.",True,True
callstack_____react-native-paper_____485,2019-04-03T11:19:16Z,True,callstack_____react-native-paper_____485_____479446957,"@Zefau I also needed to do something similar and I ended up using focus and blur events. It's working on android, but for ios is working just in the simulator. On real ios device the surface has a bug related to height. Any ideea what might be the problem ? This is how the component looks like

```import React, { Component } from ""react"";
import { Keyboard, ScrollView } from ""react-native"";
import { Menu, TextInput, Theme } from ""react-native-paper"";
import PaperMenu from ""./PaperMenu"";

export interface TextInputAutocompleteProps {
  width: number;
  items: string[];
  value: string;
  theme: Theme;
  label: string;
  onChange: (value: string) => void;
}

interface TextInputAutocompleteState {
  filteredItems: string[];
  value: string;
  showMenu: boolean;
}

export default class TextInputAutocomplete extends Component<
  TextInputAutocompleteProps,
  TextInputAutocompleteState
> {
  state = {
    filteredItems: [] as string[],
    value: """",
    showMenu: false
  };
  componentDidMount = () => this.updateStateFromProps(this.props);

  componentWillReceiveProps = (props: TextInputAutocompleteProps) =>
    this.updateStateFromProps(props);

  updateStateFromProps = (props: TextInputAutocompleteProps) =>
    this.setState({ value: props.value });

  filterItems = value => {
    const filteredItems =
      value.trim() !== """"
        ? this.props.items.filter(
            item =>
              item !== value &&
              item.toUpperCase().startsWith(value.toUpperCase())
          )
        : [];
    const showMenu = filteredItems.length > 0;
    this.setState({
      showMenu,
      filteredItems
    });
  };

  onTextInputFocus = () => this.filterItems(this.state.value);

  onTextInputBlur = () => this.setState({ showMenu: false });

  onMenuDismiss = () => {
    this.setState({ showMenu: false });
    Keyboard.dismiss();
  };

  onItemPress = (item: string) => {
    this.onMenuDismiss();
    this.setState({ value: item });
    this.props.onChange(item);
  };

  onTextInputChange = value => {
    this.setState({ value });
    this.filterItems(value);
  };

  render() {
    const menuItems = this.state.filteredItems.map((item, i) => {
      const onPress = () => this.onItemPress(item);
      return (
        <Menu.Item
          style={{ minWidth: this.props.width, maxWidth: this.props.width }}
          onPress={onPress}
          key={i}
          title={item}
        />
      );
    });
    return (
      <PaperMenu
        style={{ marginTop: 50, width: this.props.width }}
        visible={this.state.showMenu}
        onDismiss={this.onMenuDismiss}
        anchor={
          <TextInput
            label={this.props.label}
            mode=""outlined""
            theme={this.props.theme}
            value={this.state.value}
            onChangeText={this.onTextInputChange}
            onFocus={this.onTextInputFocus}
            onBlur={this.onTextInputBlur}
          />
        }
      >
        <ScrollView
          scrollEnabled={true}
          showsVerticalScrollIndicator={true}
          keyboardShouldPersistTaps=""always""
          style={{ height: 135 }}
        >
          {menuItems}
        </ScrollView>
      </PaperMenu>
    );
  }
}
```
The PaperMenu is a fork of Menu component to temporary fix the bug I described here
[https://github.com/callstack/react-native-paper/issues/970](url)
",True,True
callstack_____react-native-paper_____485,2019-04-03T13:47:46Z,True,callstack_____react-native-paper_____485_____479496791,On iOS Statusbar.currentHeight does not work so ending up with a undefined top.,True,True
callstack_____react-native-paper_____485,2019-04-03T14:00:48Z,True,callstack_____react-native-paper_____485_____479502171,"Yes..I use a default value of 40 for now..so i removed StatusBar completely..the issue I have now is with the height of the menu..not the position
",True,True
callstack_____react-native-paper_____485,2019-04-03T14:08:45Z,True,callstack_____react-native-paper_____485_____479505424,Please create issue ticket instead of posting here. This component is very new so you will see lot of issues.,True,True
nestjs_____typeorm_____27,2019-04-04T15:49:01Z,True,nestjs_____typeorm_____27_____479954114,"Any news on this? For some reason, fwoelffel's solution doesn't work for me, I guess it might be related to my multi-database setup & using forFeature().
The only way to get Subscribers to work for me right now is to reference them in subscribers array of forRoot() config. Which will end with missing dependencies again. ",True,True
nestjs_____typeorm_____27,2019-04-04T15:51:54Z,True,nestjs_____typeorm_____27_____479955304,"If you use multiple connections, make sure you inject the right connection in your subscriber. Maybe you could provide us some code so we can see what's wrong.",True,True
nestjs_____typeorm_____27,2019-04-04T16:08:18Z,True,nestjs_____typeorm_____27_____479961857,"> If you use multiple connections, make sure you inject the right connection in your subscriber. Maybe you could provide us some code so we can see what's wrong.

Thanks, I just had the same thought and am trying to find out how to control which connection is being injected. Are you able to tell me how to inject a certain connection?

The code: First, I'm registering a ""users"" connection like this
```ts
TypeOrmModule.forRoot({
	type: ""sqlite"",
	name: ""users"",
	database: Config.get(""databasePath"")+""/users.db"",
	entities: [UserEntity],
}),
```

And assigning the users db connection to be used for UserEntity.
```ts
TypeOrmModule.forFeature([
	UserEntity
], 'users')

```

Here's the basic UserSubscriber
```ts
@Injectable()
export class UserSubscriber implements EntitySubscriberInterface<UserEntity> {

  constructor(
    @InjectConnection() readonly connection: Connection,
	@InjectEventEmitter() private emitter: AppEventEmitter,
	) {
	connection.subscribers.push(this);
	console.log( typeof connection, typeof emitter);
  }

  listenTo() {
    return UserEntity;
  }
  beforeInsert(event: InsertEvent<UserEntity>) {
	console.log('### InsertEvent triggered!');
  };
}
```
",True,True
nestjs_____typeorm_____27,2019-04-04T16:11:14Z,True,nestjs_____typeorm_____27_____479963005,"I'm not sure but if I remember well you should try with:

```js
  constructor(
    @InjectConnection('users') readonly connection: Connection,
    @InjectEventEmitter() private emitter: AppEventEmitter,
  ) {
    connection.subscribers.push(this);
  }
```",True,True
nestjs_____typeorm_____27,2019-04-04T16:11:23Z,True,nestjs_____typeorm_____27_____479963061,"OMG - stupid me just found out all I have to do is to use
```ts
@InjectConnection('USERS') readonly connection: Connection,
```
thanks for pointing me at that one.

__EDIT:__ Haha you were faster. Thank you!",True,True
webpack_____webpack-dev-server_____1664,2019-04-08T20:06:33Z,True,webpack_____webpack-dev-server_____1664_____480986713,"@rlamana @evilebottnawi This PR, in version 3.3.0, breaks the use of webpack-dev-server with Rails webpacker gem, inside Docker containers. We used to configure rails app to execute in 0.0.0.0:3000 (from container ""A""), and webpack-dev-server in 0.0.0.0:3035 (from container ""B""). So, the socket URL must be ""0.0.0.0:3035"". But, with this version, the socket URL is generated as ""0.0.0.0:3000"" (same port of Rails app, instead of 3035). ",True,True
webpack_____webpack-dev-server_____1664,2019-04-08T20:07:36Z,True,webpack_____webpack-dev-server_____1664_____480987071,The version 3.2.1 does not have problem with it :+1: ,True,True
webpack_____webpack-dev-server_____1664,2019-04-08T21:01:02Z,True,webpack_____webpack-dev-server_____1664_____481006338,This change also broke my setup. I have a static assets server on port 3000 that refers to the webpack-dev-server build on port 8080. Now it is looking for the websocket on port 3000 instead of 8080. This worked fine in 3.2.1.,True,True
webpack_____webpack-dev-server_____1664,2019-04-08T22:40:47Z,True,webpack_____webpack-dev-server_____1664_____481034349,"@pedrofurtado @nick, so as I understand you are not using the dev-server to actually serve your files, but just using it for the hot reload capability?

https://github.com/webpack-contrib/webpack-hot-middleware actually allows you to add hot reloading into an existing server.",True,True
webpack_____webpack-dev-server_____1664,2019-04-08T22:57:08Z,True,webpack_____webpack-dev-server_____1664_____481037691,I wonder if `client-src/default/index.js` should also take into account the [`devServer.public`](https://webpack.js.org/configuration/dev-server/#devserverpublic) option to override the URL value and support these kind of scenarios where dev server is not use to serve the files.,True,True
webpack_____webpack-dev-server_____1664,2019-04-09T09:05:27Z,True,webpack_____webpack-dev-server_____1664_____481167736,"@rlamana This change also broke my setup. I using the dev-server the same way as @nick.
",True,True
webpack_____webpack-dev-server_____1664,2019-04-09T11:01:09Z,True,webpack_____webpack-dev-server_____1664_____481205057,"This change broke out tools too. We have multiple sites proxied to a single domain with different paths. The original behavior was to get the port the actual Webpack dev server, rather than the one after proxied. Now the port changed and it's very tricky works to update the rest parts of the toolchains.",True,True
webpack_____webpack-dev-server_____1664,2019-04-09T11:14:26Z,True,webpack_____webpack-dev-server_____1664_____481208817,"> @pedrofurtado @nick, so as I understand you are not using the dev-server to actually serve your files, but just using it for the hot reload capability?
> 
> https://github.com/webpack-contrib/webpack-hot-middleware actually allows you to add hot reloading into an existing server.

Thanks for feedback, @rlamana ! Firstly, thanks for you work in maintainance of webpack-dev-server!

Actually, I use webpack-dev-server for serve static files and hot replacement. For this, we here use the Webpacker gem (Integration between Webpack and Rails -> https://github.com/rails/webpacker ), that provides the two features mentioned (serving static files and hot replacement). Our setup is Rails application running in localhost:3000, and webpack-dev-server (and its socket) running in localhost:3035

My scenario and scenario of @nick are similar :+1: ",True,True
webpack_____webpack-dev-server_____1664,2019-04-09T11:19:18Z,True,webpack_____webpack-dev-server_____1664_____481210147,"It was fixed, please test with latest version",True,True
webpack_____webpack-dev-server_____1664,2019-04-09T11:54:50Z,True,webpack_____webpack-dev-server_____1664_____481220009,@evilebottnawi Thanks! I will test here. Doubt: The latest version is the 3.3.0 (re-released) or the branch master?,True,True
webpack_____webpack-dev-server_____1664,2019-04-09T11:56:26Z,True,webpack_____webpack-dev-server_____1664_____481220433,"@pedrofurtado `3.3.0`, but we prepare `3.3.1` on today due some regressions",True,True
webpack_____webpack-dev-server_____1664,2019-04-09T11:58:06Z,True,webpack_____webpack-dev-server_____1664_____481220947,"@evilebottnawi Ok, thank you!",True,True
webpack_____webpack-dev-server_____1664,2019-04-10T13:46:26Z,True,webpack_____webpack-dev-server_____1664_____481697556,"@evilebottnawi Even in `3.3.1`, the error is still occuring :cry: (as described in https://github.com/webpack/webpack-dev-server/pull/1664#issuecomment-481006338 )  

The workaround, for me, is to lock in version `3.2.1` for a while.",True,True
webpack_____webpack-dev-server_____1664,2019-04-12T03:05:12Z,True,webpack_____webpack-dev-server_____1664_____482419286,Broke my setup too (similar to https://github.com/webpack/webpack-dev-server/pull/1664#issuecomment-481006338.). `webpack-dev-server` running on a different port is only used to serve assets i.e. js and whatnot.,True,True
webpack_____webpack-dev-server_____1664,2019-04-12T10:42:10Z,True,webpack_____webpack-dev-server_____1664_____482528189,https://github.com/webpack/webpack-dev-server/pull/1664#issuecomment-481699922,True,True
pi-hole_____pi-hole_____2706,2019-04-14T22:46:51Z,True,pi-hole_____pi-hole_____2706_____270333603,"**What does this PR aim to accomplish?:**

This is the fix for the security vulnerability documented in issue #2704.

**How does this PR accomplish the above?:**

It removes the vulnerable misconfiguration in the defaults.

**What documentation changes (if any) are needed to support this PR?:**

N/A.",True,True
pi-hole_____pi-hole_____2706,2019-04-14T22:54:15Z,True,pi-hole_____pi-hole_____2706_____483065459,"If using HTTP is insecure and can cause a DoS, then using unencrypted DNS is even more insecure and more likely to cause a DoS. Hint: DNS is by default insecure.

Pi-hole is not the place you want to try to solve this.",True,True
pi-hole_____pi-hole_____2706,2019-04-14T23:08:07Z,True,pi-hole_____pi-hole_____2706_____483066413,"The ISP for sysctl.org can break the web (and VoIP, which may be used for emergency services) for every single pi-hole user who doesn't change the default blocklists (I would estimate this is 99%+ of users).

If you're okay with this, then fine.  But I doubt that's what your users signed up for.",True,True
pi-hole_____pi-hole_____2706,2019-04-14T23:16:41Z,True,pi-hole_____pi-hole_____2706_____483067051,"The owners of any list can ""break the web"" for all of their users, even those outside of Pi-hole, if they wished. That is why it is up to the user to decide what blocklists they want to use. These ""default"" lists are not forced upon anyone, they are recommended at install time.

If you feel so strongly about this issue, then contact the list maintainers instead. They are the ones who control access to their lists. Again, Pi-hole is not the place you want to try to solve such global issues as HTTP or DNS insecurity.",True,True
webpack_____webpack-dev-server_____1664,2019-04-16T07:16:38Z,True,webpack_____webpack-dev-server_____1664_____483540963,"also broke my setup, this fix is a breaking change, maybe revisit it?",True,True
webpack_____webpack-dev-server_____1664,2019-04-16T09:37:33Z,True,webpack_____webpack-dev-server_____1664_____483587053,This also broke our setup and this is a breaking change for us. How can we fix this?,True,True
webpack_____webpack-dev-server_____1664,2019-04-16T10:18:59Z,True,webpack_____webpack-dev-server_____1664_____483600640,"yep :disappointed: we have `sockPort` for this case now https://github.com/webpack/webpack-dev-server/pull/1792, feel free to send a PR with revert",True,True
laurent22_____joplin_____1141,2019-04-21T12:43:50Z,True,laurent22_____joplin_____1141_____485248638,Closed inactive pull request. Feel free to ask to re-open if there's something new.,True,True
ReactiveX_____RxSwift_____1960,2019-04-30T07:55:54Z,True,ReactiveX_____RxSwift_____1960_____274630373,"Per discussion on Twitter and GitHub previously - It seems we didn't necessarily consider all of the downsides of limiting to Static Library usage on Carthage. 

The main issue is that Carthage allows literally no customiation options for this. Since Dynamic Frameworks are the ""default"" option, I think it makes more sense to go back to our old default and have users who require the customization do some ""manual"" work.

That customization could be a custom Carthage script for people who're interested in RxSwift as a Static Library. For example, something along the lines of: 

```none
carthage update RxSwift --platform iOS --no-build
sed -i -e 's/MACH_O_TYPE = mh_dylib/MACH_O_TYPE = staticlib/g' Carthage/Checkouts/RxSwift/Rx.xcodeproj/project.pbxproj
carthage build RxAlamofire --platform iOS
```

We can put the above script under the Carthage category in our README file for users who ""insist"" on using RxSwift as a Static Library as a more advanced feature, and this could create a possible all-around solution for the ""common"" scenario (dynamic) and more advanced scenario (static). 

Hopefully Carthage will one day allow specifying these sorts of things inside the Cartfile or a similar mechanism.

Thoughts? @kzaher @tonyarnold @mfcollins3 @layoutSubviews",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T07:57:28Z,True,ReactiveX_____RxSwift_____1960_____279647192,"I believe you can safely delete the `MACH_O_TYPE` entries entirely. They'll default to Xcode's recommendation, which is `mh_dylib`.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T07:58:43Z,True,ReactiveX_____RxSwift_____1960_____279647631,"True, but in a way I always prefer explicitness (not that the default will change or anything but still I don't see harm in that). The second thing this helps with is the above `sed` script works. Even though it could replace `MACH_O_TYPE =` as well. Don't have a huge preference to this :) ",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T08:00:34Z,True,ReactiveX_____RxSwift_____1960_____279648204,Actually removing it will leave no trace of it in the `project.pbxproj` so in a way I think leaving it explicit allows for better communication and also will allow this manual customization in the form of a bash script like the above,True,True
ReactiveX_____RxSwift_____1960,2019-04-30T08:04:49Z,True,ReactiveX_____RxSwift_____1960_____487855008,Added possible README instructions. ,True,True
ReactiveX_____RxSwift_____1960,2019-04-30T08:56:37Z,True,ReactiveX_____RxSwift_____1960_____487869969,"I'm not sure I understand, 

dynamic frameworks are bad because they increase your startup time. Cocoapods use static libs, Swift team added explicit support for static libs, Apple advises against large number of dynamic frameworks, Blaze uses static frameworks. What in the world is the argument for dynamic frameworks?
",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T09:01:47Z,True,ReactiveX_____RxSwift_____1960_____487871638,"I've opened it for discussion for this specific reason. I have no strong opinion on this as I prefer package managers that give developers a choice :P I'm mainly interested in a common ground that fits most of the developers. 

The main issue noticed here is the ""virality"" of static libraries - e.g. if you have many small frameworks that all consume RxSwift using Carthage, each of these contains an individual static copy of RxSwift. 

For example if you take in both RxOptional and RxSwiftExt and RxDataSources - at least to my understanding, they all depend on RxSwift which is now a Static Library. 

About CocoaPods - the default is still Dynamic. (When you `pod init` you get a Podfile with a dynamic library) and Apple's guidance is basically correct but is not ""basic knowledge"".

What companies usually do is similar to what @mfcollins3 suggested - a single Dynamic Framework containing many static libraries. But again, since I'm not a consumer of Carthage I'm not necessarily sure on how critical this is or isn't (that's why @tonyarnold and the others are tagged above)",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T09:12:39Z,True,ReactiveX_____RxSwift_____1960_____487874564,"> The main issue noticed here is the ""virality"" of static libraries - e.g. if you have many small frameworks that all consume RxSwift using Carthage, each of these contains an individual static copy of RxSwift.

Yes, we should change this for them to be also static. None of them will contain a copy of RxSwift as far as I can tell.

As far as I can tell nobody wants to use dynamic library. It was a crutch for the inadequacy of the Swift compiler, not a preferred solution.

If we are reverting this I would want to be sure is it because there are some good technical arguments. If we are going to do it because the ecosystem is lazy and doesn't want to transition in general to dynamic frameworks, I'm also fine if that's the case. 

If it is because some people are unhappy because they are using RxSwift in team environment and are now starting holy wars again how we are horrible and every change is just a fuel for the fire (in this case I'm not sure I care much).

But anyway, this is the place where people can voice their opinion and concerns. I don't stalk people on Twitter. Make up your mind and voice your reasons here. I'm fine with reverting if there are good technical arguments or people voice that the ecosystem doesn't want to do this.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T09:16:58Z,True,ReactiveX_____RxSwift_____1960_____487875733,"> If we are reverting this I would want to be sure is it because there are some good technical arguments. If we are going to do it because the ecosystem is lazy and doesn't want to transition in general to dynamic frameworks, I'm also fine if that's the case.

Agreed - this PR was opened just to allow choosing either option whenever those technical arguments are made.

Care sharing your thoughts @tonyarnold @layoutSubviews ? ",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T09:21:19Z,True,ReactiveX_____RxSwift_____1960_____487876916,"The default for all of our existing Xcode-based tooling supports dynamic frameworks out of the box - more so for Carthage than others, as it is just reusing Xcode's project setup. Yes, Xcode also supports static archives, but that's not the default, nor how Apple themselves distribute library-based dependencies (frameworks!). 

> As far as I can tell nobody wants to use dynamic library. It was a crutch for the inadequacy of the Swift compiler, not a preferred solution.

I'm not sure where this comment is coming from at all. Dynamic frameworks are (and have been) the basis of all distributable frameworks on Apple's platforms since Mac OS X was first released. Limitations in iOS have meant that people have come up with workarounds like using static frameworks (which aren't a supported configuration).

You've both stated you don't use, nor particularly care about Carthage as a tool - that's fine, and reasonable - but as a user of Carthage, I'm telling you that the change you've made here negatively impacted my projects that use RxSwift. 

Look, it's your project, so do as you please, but you're asking a community of people who rely on your library to change the default setup of entire projects to support a change Apple themselves have said will be unnecessary in future (see the earlier comments in #1799 about the improvements to dyld in iOS 11 and later).

> because the ecosystem is lazy

Ouch. Definitely not it.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T10:06:39Z,True,ReactiveX_____RxSwift_____1960_____487896762,"I would say the people advocating for `dynamic libs` have a point. Although `Static Libs` are my favourites, there seems to be a huge technical debt in configuration and setup when you have multiple frameworks that use `RxSwift` which could lead to bloating the entire App. However I am thinking of a solution with the [Scheme here is the hack I found for now but it is too geeky.. : ](https://github.com/Carthage/Carthage/issues/1227) ",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T10:18:44Z,True,ReactiveX_____RxSwift_____1960_____487899700,"> But anyway, this is the place where people can voice their opinion and concerns. I don't stalk people on Twitter. Make up your mind and voice your reasons here.

@kzaher I'm sorry if I've offended you in any way. Please note that I _did_ voice my opinion and concerns both here, and on Twitter (and continue to do so). 

I value the work that you and the team have done with RxSwift, regardless of my disagreement with the change that kicked this all off.

I've given my feedback on this issue, so unless you want more information from me I'm going to leave you folks to make up your minds about this issue and butt out.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T10:46:03Z,True,ReactiveX_____RxSwift_____1960_____487906415,"I think that regardless of the written content we find, we also need to consider the ecosystem of other dependency developers.

Looking at other large iOS frameworks: ReactiveSwift, Alamofire, SnapKit, Kingfisher, CryptoSwift - are all **dynamic**.

Furthermore, the more I tried, I couldn't find a single known iOS dependency that sets MACH_O_TYPE to Static.

Also, When you remove the `MACH_O_TYPE` configuration in Xcode, the default you get is dynamic as well. 

Basically everything here makes me lean towards going back to dynamic - it seems to be the widespread used community standard (for Cocoa in general) and it's also the default in the tooling we have around Apple-related development (Xcode, CocoaPods, etc.)

Even if a Static Library could possibly be more optimized - it's something for advanced developers to pick and do on their own (perhaps with the aforementioned script I provided), and probably shouldn't be the default. It was definitely not something embraced by the Apple developer community, so it seems.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T10:52:01Z,True,ReactiveX_____RxSwift_____1960_____487907812,"I personally feel if the discussion here is around performance it needs to be backed by numbers. Just saying static is better because it’s faster is not a convincing argument in any way. The counter point of reducing link time is increasing load time because we are bloating the executable. 

This is a huge inconvenience for non cocoapods users (not just carthage but manual integrators too) for no demonstrable gains. 

It will also affect the entire ecosystem that provides frameworks that depend on Rx (and not all Rx libraries live inside the RxCommunity repo). 

I think you guys might be underestimating the impact this will have on current usage and adoption of the framework and I am a strong NO for this change. ",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T11:24:25Z,True,ReactiveX_____RxSwift_____1960_____487915523,"> I personally feel if the discussion here is around performance it needs to be backed by numbers.

Agree.

> Just saying static is better because it’s faster is not a convincing argument in any way. 

Well it is faster, can't tell by how much since nobody on the internet hasn't published any recent meaningful benchmarks.

> The counter point of reducing link time is increasing load time because we are bloating the executable.

If you don't need something to run your app. Don't link it into your binary. Dynamic linking will still load all of those unused symbols in the memory as far as I can tell, the symbols just won't be resolved eagerly, so it should be as bad.

> This is a huge inconvenience for non cocoapods users (not just carthage but manual integrators too) for no demonstrable gains.

@tonyarnold Can you please provide links that show that Apple wants the entire ecosystem to move to dynamic libraries and the performance impact? I didn't get that from you.

2016
https://developer.apple.com/videos/play/wwdc2016/406/
Don't use dylibs.

2017
https://developer.apple.com/videos/play/wwdc2017/413
2:52 You should use fewer dylibs.

https://devstreaming-cdn.apple.com/videos/wwdc/2017/413fmx92zo14voet8/413/413_app_startup_time_past_present_and_future.pdf?dl=1
Slide 13:
Do less!
• Embed fewer dylibs

Why did Apple add official support for static libs in the Swift compiler?

Why did Carthage add support for static frameworks? https://github.com/Carthage/Carthage/releases/tag/0.30.1

Are there any benchmarks? Videos don't provide any data. Not even biased benchmarks made by the engineers working on this.

I can respect opinions, but I would appreciate links to the apple domain more.

Having said that, I personally don't care much. If Carthage users want to use dylibs, I can change it. I don't really care that much do Carthage users want to do it because it's easier, or they think that the performance/convenience tradeoff isn't worth it, or some other reason.

> Ouch. Definitely not it.

So far I haven't seen benchmarks or links telling otherwise, so it would seem to me that it is. Again, maybe it's not, just saying that you haven't provided any evidence for the opposite.

I think I've been thinking about this in the wrong way. If we leave static libraries, people will complain and we'll have to respond. For the dynamic one people didn't complain much, so let's go with the dynamic ones.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T11:27:43Z,True,ReactiveX_____RxSwift_____1960_____487916425,I guess we'll have to cut a 5.0.1 ? (or reset 5.0.0 tag but I remember you prefer not doing that),True,True
ReactiveX_____RxSwift_____1960,2019-04-30T12:01:32Z,True,ReactiveX_____RxSwift_____1960_____487924847,"Again, we shouldn't be changing tags.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T12:02:28Z,True,ReactiveX_____RxSwift_____1960_____487925122,I'll make 5.0.1.,True,True
ReactiveX_____RxSwift_____1960,2019-04-30T15:02:02Z,True,ReactiveX_____RxSwift_____1960_____487987886,"I have a little problem, I can't detect the tag 5.0.1
what happened ?

Cartfile -> 
github ""ReactiveX/RxSwift"" ~> 5.0

Terminal ->
*** Checking out RxSwift at ""3.0.0.alpha.1""",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T15:04:47Z,True,ReactiveX_____RxSwift_____1960_____487988964,"Are you running `carthage update`? It seems to work fine here
```
github ""ReactiveX/RxSwift"" ~> 5.0
```

```
$ carthage update RxSwift --platform ios          
*** Fetching RxSwift
*** Checking out RxSwift at ""5.0.1""
*** xcodebuild output can be found in /var/folders/73/lnfrs9hx1nn6khr3r3lzh5600000gp/T/carthage-xcodebuild.ADcoWR.log
*** Downloading RxSwift.framework binary at ""ShaiTheBravest""
```
",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T15:06:07Z,True,ReactiveX_____RxSwift_____1960_____487989496,"Yes 

```
$ carthage update
*** Fetching SwifterSwift
*** Fetching BkoolUtilitiesiOSLib
*** Fetching RxSwift
*** Fetching BkoolHTTPFetcher-IOS
*** Checking out RxSwift at ""3.0.0.alpha.1""
*** Checking out SwifterSwift at ""4.6.0""
*** Checking out BkoolHTTPFetcher-IOS at ""1.1.1""
*** Checking out BkoolUtilitiesiOSLib at ""1.2.1""
*** xcodebuild output can be found in /var/folders/sq/vzy_95nj6bl86k1rp_nghbqr0000gp/T/carthage-xcodebuild.fPHO04.log
^C
$ carthage version
0.33.0
```",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T15:09:16Z,True,ReactiveX_____RxSwift_____1960_____487990886,I will try to try erasing the carthage cache,True,True
ReactiveX_____RxSwift_____1960,2019-04-30T15:26:32Z,True,ReactiveX_____RxSwift_____1960_____487997682,"Sorry I am very stupid, I had dependence on another personal liberty, that had not updated his Cartfile, then there was a conflict.

My deepest apologies. And above all, thank you very much for this great tool!",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T16:02:31Z,True,ReactiveX_____RxSwift_____1960_____488011804,"For future reference here's some solid data on how this affects app launch time https://blog.automatic.com/how-we-cut-our-ios-apps-launch-time-in-half-with-this-one-cool-trick-7aca2011e2ea

In our experience ours also dropped at least this much by switching entirely to static frameworks",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T17:42:42Z,True,ReactiveX_____RxSwift_____1960_____488046844,"@freak4pc + @kzaher IMO I don’t think we should be flip flopping like this. I would wait for at least 2 weeks to hear all the complains while searching for an optimal solution. There was an issue where we discussed the static libs and people should have brought up all their opinions there and not afterwards. All I am say is that let’s wait and find try find a solution first.. just like we did on the previous issue where it was long discussed. I know people will always complain but wait a moment before cutting 5.0.1 

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T18:30:09Z,True,ReactiveX_____RxSwift_____1960_____488063587,"@bobgodwinx Appreciate your opinion but I’ll have to respectfully disagree - it was sort of a mistake to switch cold turkey to a non-default build option, but it would’ve possibly been hard finding that error without the release. 

Right now there was reason to wait anymore. We’ve discussed plenty and reverting make sense while still offering a script to go static if needed - which takes care of both scenarios. ",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T23:06:00Z,True,ReactiveX_____RxSwift_____1960_____488146681,"Dynamic libraries (frameworks) have a variety of benefits over static frameworks.

- Reduction in memory usage: Static linking duplicates code in to code segments.
- Reduced disk space.
- Shared memory: The dynamic linker can share VM pages between apps that link a dynamic framework. Frameworks in /System and /Library do not get loaded more than once into memory. In user app space a framework in a app bundle can be shared between extensions or subprocesses too reducing memory usage.
- Guaranteed canonical type linkage: If your app has two dynamic frameworks that link against the same static framework you end up with 2 versions of that static code in your app’s memory space and type/symbol resolution is random and/can get over written as dyld loads further .frameworks. This causes all sorts of problems with ObjectiveC categories not sure how it affects swift exactly but I assume the ObjC bridged types will get buggered up. Dyld will fortunately bitch quite loudly when it notices this.

The canonical way of sharing code across processes on modern systems has always been dynamic libraries. Unix .so, Windows .dll, Mac .frameworks (actually .so’s with a custom container file structure).

Static libraries (basically just simple archives of .o files - static frameworks are no different) are a legacy of times before we had the *benefit* of dynamic linking.

One of the major reasons behind Swift’s push for ABI and module stability is to reap all the *benefits* of dynamic linking.

Yes there are some performance trade offs. Dynamic libraries are a space vs time trade off. But they also come with a bunch of other benefits too around tooling.

The reason behind preferencing static frameworks over dynamic in iOS are rapidly receding into the past (as Apple CPUs get faster and dyld is improved).

The idea of switching RxSwift to a static framework by default was an absolute unequivocal mistake.",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T23:16:58Z,True,ReactiveX_____RxSwift_____1960_____488148879,"> The idea of switching RxSwift to a static framework by default was an absolute unequivocal mistake.

As much as I enjoy a mocking post-mortem criticism from people who've never contributed code to this repo, never participated in a single discussion (even on the specific topic of static libraries that was discussed for over 2.5 weeks here before this release), etc ... maybe just ... don't ? 

People make mistakes, and that's fine. We're not employees of RxSwift but contributors who take **a lot** of time from their day to maintain this project. Please be respectful of that.

I still don't think it's a mistake like a preference, but the preference of a library should be the consensus of the community and not the preference of a few people. We've taken responsibility and reverted the code and pushed a new release in basically under 12 hours since the initial complaint (which was on Twitter, and not even on a GitHub issue). Can you show me an (even paid or commercial) project that does that so quickly? 

The rest of your post was very informative and interesting. Thanks for the information. 

I invite you to be an active member of this community, contribute to discussions, code, etc. and help steer the boat the next time a similar ""mistake"" could possibly happen, but providing such an aggressive sentence as an outsider is absolutely ridiculous and disrespectful in my eyes. ",True,True
ReactiveX_____RxSwift_____1960,2019-04-30T23:46:45Z,True,ReactiveX_____RxSwift_____1960_____488154485,Sorry @freak4pc I wasn’t trying to mock. I unreservedly apologise if it was taken that way.  I very much appreciate the work of the RxSwift maintainers.,True,True
ReactiveX_____RxSwift_____1960,2019-05-01T00:07:07Z,True,ReactiveX_____RxSwift_____1960_____488158197,"@freak4pc you are right that it can be a preference to use static linking, and in fact at times it would be the appropriate behaviour. For example if you were building a command line util that you don’t want to have any external dependencies (beyond the system frameworks) - the latest builds of Carthage appear to now statically link CarthageKit (and RecativeCocoa) for example. Or if you need a simplified deployment artefact (GoLang preferences static linking but it is easier in that community as all dependencies are sources).

And you could do this with macOS/iOS targets too but it would require build tooling support. Cocoapods provides this support somewhat. But not everyone uses that.",True,True
ReactiveX_____RxSwift_____1960,2019-05-01T06:20:33Z,True,ReactiveX_____RxSwift_____1960_____488218802,"Thanks for the clarification, I appreciate that. And yup I’m aware of that, this is one of the reasons Carthage frustrates me as a package manager so much. The amount of configurability without additional tooling or script hackery is close to none. 

Anyways I’m glad we were able to find a solution that fits all shoes (seemingly) :-) ",True,True
ReactiveX_____RxSwift_____1960,2019-05-01T12:28:03Z,True,ReactiveX_____RxSwift_____1960_____488270337,"@orj WOW

> Reduction in memory usage: Static linking duplicates code in to code segments.

This is not true. If the linkers are dumb, sure, but they can't be. If this was true it would mean that singletons and static variables would be impossible, which isn't the case. I'm linking about 20000 static libraries in the current app, if that was the case, imagine how easy would it be to get a promo by just changing the linker to not be a complete idiot.

> Reduced disk space.

How on earth. If you have everything statically linked, then you can statically build graphs and remove unused symbols, which you can't do for dynamic libraries because anyone could use any entry point.

> Shared memory: The dynamic linker can share VM pages between apps that link a dynamic framework. Frameworks in /System and /Library do not get loaded more than once into memory. In user app space a framework in a app bundle can be shared between extensions or subprocesses too reducing memory usage.

You are not working on shared frameworks on the iOS level. You are misunderstanding the question. The question isn't should iOS use dynamic frameworks, but **should your app use dynamic frameworks**.

> Guaranteed canonical type linkage: If your app has two dynamic frameworks that link against the same static framework you end up with 2 versions of that static code in your app’s memory space and type/symbol resolution is random and/can get over written as dyld loads further .frameworks. This causes all sorts of problems with ObjectiveC categories not sure how it affects swift exactly but I assume the ObjC bridged types will get buggered up. Dyld will fortunately bitch quite loudly when it notices this.

You should not do this ever, otherwise your app will probably crash. This is the main reason why having a dumb package manager like Carthage is a bad idea. Consumer should decide how they want to consume the library not the library authors. Library authors should decide on the API and code only. Maybe I'm crazy, but hey. That's just me. All package managers except Carthage do this (CocoaPods, Swift Package Manager,  Blaze/Bazel).

> The canonical way of sharing code across processes on modern systems has always been dynamic libraries. Unix .so, Windows .dll, Mac .frameworks (actually .so’s with a custom container file structure).

**You are not working on iOS or Windows or any other OS level. Stop fantasizing.** And yes, that was a huge dumb idea in retrospect. Ever heard of dll hell? Docker? Containers? What problems do you think they are trying to solve?

> Static libraries (basically just simple archives of .o files - static frameworks are no different) are a legacy of times before we had the benefit of dynamic linking.

No, not true. Do you see any binaries shipping with thousands of dynamic libraries? Well why that might be... Is it because people do small projects only or they use static linking.

> One of the major reasons behind Swift’s push for ABI and module stability is to reap all the benefits of dynamic linking.

Well why did they add support for static libraries after x years then? Why did Carthage start supporting it? You would think they would be satisfied with just dynamic ones, wouldn't you say? Why are all unicorn companies in favor of static linking? Are they all delusional?

> Yes there are some performance trade offs. Dynamic libraries are a space vs time trade off. But they also come with a bunch of other benefits too around tooling.

No, it's not space time tradeoff, it's developer convenience vs time tradeoff.

> The reason behind preferencing static frameworks over dynamic in iOS are rapidly receding into the past (as Apple CPUs get faster and dyld is improved).

I'll trust that Apple is serious about linking when they optimize ld64 or at least publish an easily buildable open source version. That linker is couple of times slower than others. Yes, dynamic linkers should get better, but that doesn't mean it's 0 cost operation, or that static linking is somehow relic of the past.

> The idea of switching RxSwift to a static framework by default was an absolute unequivocal mistake.

Yes, it was, but it wasn't because of any of the reasons you are saying. It was dumb because Carthage consumers don't have any control over how the library is consumed without ugly hacks and the ecosystem is built around dynamic libraries and the network effects are preventing the change.

We have ~10 issues at any time in our repo. #1799 Was opened half a year ago and it was clear for a long time that we'll do this. I first thought that there might be some backslash, but didn't see anything like any kind of serious backslash. I was also prepared to migrate entire RxSwiftCommunity to static libs. **I didn't see a huge problem with migrating to static, and if somebody used RxSwift, they could just pack all of this into a single dynamic library and just do `import RxShared; import RxSwift`. That was basically all they had to do on their end. We have to migrate dozens of projects and change dozens of CI pipelines. I've already started to propagate the work on RxDataSources. Look at 5.0.0 release.**.

We've reverted the change because of the reason I've just said, not because any of the BS reasons you've mentioned. Indirectly we've helped you and your company, which is great. You are welcome.

We've first invested my time and @freak4pc 's time into supporting a package manager which non of us personally use. Then we've honestly tried to help that community using the project more efficiently. Then we've realized that the community wouldn't want to change, which is fine. I'm lazy, I don't treat laziness as something bad. I don't want to do some work if I don't really have to. **Then me and @freak4pc have again invested our time into helping out people using Carthage.**

So after all of this work, after we've maintained the project for you and had best intentions, after we've help you and your company, you come here with BS reasons and start pissing on us and basically claiming we are morons. 

Thanks a lot. Thanks for wasting my time on writing this response.

What is wrong with you people. Or better yet, what is wrong with me for getting into all of this shit. Yes, I was dumb for that, but I learn. Never again.",True,True
ReactiveX_____RxSwift_____1960,2019-05-01T14:39:39Z,True,ReactiveX_____RxSwift_____1960_____488300552,"I think this is escalating beyond the scope of what we want to discuss in this repo for now. As I mentioned, I invite each and every one of you to become more involved in the ongoing discussions on the future of this library, if it's something you're curious about and interested in. 

Since the issue is resolved I'm gonna lock this for the time being. ",True,True
kognise_____water.css_____67,2019-05-04T16:41:30Z,True,kognise_____water.css_____67_____275933274,"As discussed on issue #52 
I have implemented the selection variable and used to call the selection pseudo class, we can use this as a base for selection colour, further on we can discuss and create specific colours for the same.

(will close #52 )

/cc: @kognise @kylejrp 

additional changes:
1. made my fork up-to-date with master
",True,True
kognise_____water.css_____67,2019-05-04T17:00:26Z,True,kognise_____water.css_____67_____489344889,Thanks for your contribution @co16353sidak!  ,True,True
adventuregamestudio_____ags_____648,2019-05-07T02:59:25Z,True,adventuregamestudio_____ags_____648_____489888653,"Another thought to do with performance here. C++11 has move semantics, which we can implement ourselves or rely on the defaults (which works because std::string has move semantics). It ultimately means we wouldn't be copying on return. We could even delete the copy constructor and check all places we're not passing by reference.",True,True
kognise_____water.css_____67,2019-05-10T21:24:27Z,True,kognise_____water.css_____67_____491434609,"in the end you went with fucking gray for light.css?
how are you even a web designer?

you have 0 sense of coloring.
dark gray on hover looks ugly AF

instead of improving it you made it worse",True,True
babel_____website_____2024,2019-05-13T12:44:36Z,True,babel_____website_____2024_____278257418,*** Edited by @nicolo-ribaudo ***,True,True
adventuregamestudio_____ags_____648,2019-05-18T05:25:33Z,True,adventuregamestudio_____ags_____648_____493649773,"> Of course this may be important or not important depending on which string operations we have in a program and how often they are used. What still annoys me that this proposed change does not aim any thought through string design, but rather to create a dummy std::string wrap.

That is exactly what it is. Rely on the behavior of the std::string. with default copy and move semantics. I ran this code with a profiler to see which functions were used a lot. The Split function was not one of them. :)",True,True
adventuregamestudio_____ags_____648,2019-05-18T08:19:43Z,True,adventuregamestudio_____ags_____648_____493658748,"My point being: why create a **wrapper** around std::string?

There's no immediate problem with String itself that would break anything or prevent from anything, so no urgent need to have std::string inside.

If you like to have std::string in the end, which is a reasonable wish, _I guess_, then why not work towards replacing String with std::string? I.e. `typedef std::string String;` if you want to keep old name.

This would ofcourse require to move various utility functions out, but this is something that would be beneficial anyway, I guess. I put a lot there, much of them could be replaced with more general algorithms accompanied by helper functions.

Again, my point is, AGS::String is a consistent class, std::string is a consistent class, but AGS::String wrapping std::string is a dumb solution made for some random reason. Why add an ugly code like that? Why such need to replace things with things?",True,True
adventuregamestudio_____ags_____648,2019-05-18T12:18:18Z,True,adventuregamestudio_____ags_____648_____493672878,"> My point being: why create a **wrapper** around std::string? Why add an ugly code like that? Why such need to replace things with things?

oh I didn't want to fight about this and I think we're in agreement. The wrapper was a step towards using just a plain std::string. I just wanted to start with a wrapper until we iron out any issues, then move to a typedef or rename everything to use std::string directly. I thought your main concern was performance with copying and I think the wrapper around std::string showed it wasn't an issue.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:17:48Z,True,dirigeants_____klasa-vscode_____143_____282597215,"🎉 Finally, klasa-vscode can include TypeScript! 🎉

- TypeScript snippets
- TypeScript-compatible Init command
- (not TS-related) Yarn or NPM chooser in Init command

Have fun :D",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:21:10Z,True,dirigeants_____klasa-vscode_____143_____287868107,"You can refactor this by moving lines 28-29 and 34-35 in the line 27 (before `if (lang === 'JavaScript') {`), as both are identical.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:22:32Z,True,dirigeants_____klasa-vscode_____143_____287868294,This should use [`path.extname`](https://nodejs.org/dist/latest-v12.x/docs/api/path.html#path_path_extname_path),True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:22:49Z,True,dirigeants_____klasa-vscode_____143_____496290053,This goes way beyond the scope of adding typescript snippets and changes things this pr should not. Please do not make changes to the package.json beyond the typescript lang snippets.,True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:22:53Z,True,dirigeants_____klasa-vscode_____143_____287868334,You can use a ternary here for simplicity,True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:23:40Z,True,dirigeants_____klasa-vscode_____143_____496290193,"Ah, I totally forgot that it automatically adds commits... Okay, how can I remove that? XD",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:23:46Z,True,dirigeants_____klasa-vscode_____143_____496290211,"👎 from me. I think this would be better of as it's own plugin - javascript users do not want to see typescript snippets popping up, and typescript users do not want to see javascript snippets pop up. This will just bloat the interface, doubling the amount of things we are faced with.

Also, as it's own plugin, imo the code will be cleaner. There is a lot of code dupe here (i.e. [this](https://github.com/dirigeants/klasa-vscode/pull/143/files#diff-03189079b1b3d77ef73e9e3fdb324d6dR30))

I'd personally recommend forking, and creating your own klasa-tscode plugin.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:24:06Z,True,dirigeants_____klasa-vscode_____143_____287868477,"Just FYI, `client` is gone in the alpha and settings branches, keeping this will make this outdated very quickly.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:24:52Z,True,dirigeants_____klasa-vscode_____143_____496290375,"@Tylertron1998 They don't show up to each other... That's the purpose of putting them in separating them. And also, this isn't just for me. Multiple people have said that these changes would be great for them, so...",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:29:44Z,True,dirigeants_____klasa-vscode_____143_____496291141,"[this](https://github.com/dirigeants/klasa-vscode/pull/143/files#diff-03189079b1b3d77ef73e9e3fdb324d6dR15) seems to tell me different. I've never done vs-code plugin development, but it really seems like both ts and js are together in this one plugin - again, I personally feel that it'd be better of in it's own plugin. When I said ""I'd personally recommend forking, and creating your own klasa-tscode plugin."" I didn't quite mean that you should make it for you and just yourself. Open source, I'm sure it would be recommended and shown throughout dirigeants.

Even looking past the fact that it'd be nice for each language to have it's own plugin, I still think the code is a bit messy - and a fork, with ts snippets instead would really clean that up!",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:30:57Z,True,dirigeants_____klasa-vscode_____143_____496291329,"@Tylertron1998 What I mean is that TS snippets will only show up on TS files, and JS on JS files. And the init script asks you which you want to use.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:31:43Z,True,dirigeants_____klasa-vscode_____143_____496291437,"Also, no quick-picks for ts vs js and npm vs yarn. Those need to be extension settings. You can make other commands to set the extension settings with a quick-pick sure, but it should be at its core a workspace setting, not something asked every time you try to make a piece.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:32:24Z,True,dirigeants_____klasa-vscode_____143_____496291546,"@bdistin Okay, I'll try and do that.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:37:00Z,True,dirigeants_____klasa-vscode_____143_____496292236,"my earlier comment includes versioning, you aren't responsible for dictating how and when new versions are making as a pr.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:39:37Z,True,dirigeants_____klasa-vscode_____143_____496292603,"snippits need to be written with tabs, so that the editor can hot switch the tabs with whatever the editor setting is. Right now your ts snippets are written with 4x space",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:47:28Z,True,dirigeants_____klasa-vscode_____143_____496293797,"@bdistin Wouldn't it also be a good idea to default to `dirigeants/klasa` over `klasa` for the repo, with a setting like with the language and package manager settings I'm making?",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T19:48:31Z,True,dirigeants_____klasa-vscode_____143_____496293948,"not for the init command, no. At that point, you are creating a new project, essentially.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T21:25:37Z,True,dirigeants_____klasa-vscode_____143_____496308303,@bdistin @kyranet There we go. I've tried to work at the requests you made. :),True,True
dirigeants_____klasa-vscode_____143,2019-05-27T23:19:33Z,True,dirigeants_____klasa-vscode_____143_____496319436,"Super buggy/hacky... Decided to get pissy with me in chat, and earned a ban. I have no expectations of this pr being finished.",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T23:27:21Z,True,dirigeants_____klasa-vscode_____143_____496320116,"I had every intent of finishing it, actually. I made a point, gave evidence, and told you not to get rude with me when I said it just because ""_I wrote fs-nextra HAYDEN_"".",True,True
dirigeants_____klasa-vscode_____143,2019-05-27T23:32:24Z,True,dirigeants_____klasa-vscode_____143_____496320591,Don't forget you got pissy with me first.,True,True
iNavFlight_____inav_____4798,2019-06-05T19:16:51Z,True,iNavFlight_____inav_____4798_____285514383,"This PR enables the definition of a cylindrical geofence with both horizontal (distance from home) and vertical (altitude from home) boundaries, partially implementing #62.

New settings:
+ `geofence_radius`
+ `geofence_height`
+ `geofence_buffer`

Behavior:
1. Aircraft exceeds horizontal (`geofence_radius`, _red line below)_, vertical (`geofence_height`) or both boundaries.
2. RTH is engaged.
    - Pilot lets the aircraft fly home.
      + Usual RTH behavior.
    - Pilot moves the sticks and disengages RTH, thus proceeding outside the geofence.
      + Geofence gets disabled until the aircraft comes back inside the boundaries plus `geofence_buffer` meters _(blue line below is the buffer size, green the resulting boundary)_. This gives some more room to disengage RTH and get back on track, especially with MRs.

![geofence](https://user-images.githubusercontent.com/3594528/58982855-ba9ac600-87d5-11e9-8b54-8a8e082a7d6c.png)

---

+ [ ] Field tested
+ [X] ~~Configurator PR~~ Should this feature be configurable via CLI only?
",True,True
iNavFlight_____inav_____4798,2019-06-05T19:19:31Z,True,iNavFlight_____inav_____4798_____290895191,"Which is the right way to trigger RTH and/or check if it's already active? `activateForcedRTH()`, `failsafeActivate(FAILSAFE_RETURN_TO_HOME)`, or both? The functionality of `activateForcedRTH()` looks controversial to me.",True,True
PhoenicisOrg_____scripts_____984,2019-06-07T15:56:38Z,True,PhoenicisOrg_____scripts_____984_____499940869,Please check Travis. There's an issue with json-align. See the [docs](https://phoenicisorg.github.io/scripts/General/tools/#json-align). Note: this requirement is described in the pull request how-to in the README.,True,True
PhoenicisOrg_____scripts_____984,2019-06-08T00:35:33Z,True,PhoenicisOrg_____scripts_____984_____291787150,Blame @ImperatorS79 !,True,True
PhoenicisOrg_____scripts_____984,2019-06-08T11:20:49Z,True,PhoenicisOrg_____scripts_____984_____291803689,No reason to blame people who try to help you!,True,True
PhoenicisOrg_____scripts_____984,2019-06-08T14:51:43Z,True,PhoenicisOrg_____scripts_____984_____291809134,@plata You blame ppl in linux if they do something wrong so that they know about it.. it's the way we QA each other and i encourage you to do the same.,True,True
PhoenicisOrg_____scripts_____984,2019-06-08T14:54:35Z,True,PhoenicisOrg_____scripts_____984_____291809213,@Kreyren There is a big difference between destructive / personal attack and code review / constructive remarks and quality assurance. Please beware of it. ,True,True
iNavFlight_____inav_____4798,2019-06-10T10:12:13Z,True,iNavFlight_____inav_____4798_____500364896,"Nice picture man! But I do not understand this part:(about the Buffer)

""This gives some more room to disengage RTH and get back on track, especially with MRs.""

Hmm can you explain real use case? I'm not sure if I understood it right, because currently i don't think that buffer is necessary.. Will look into the code..",True,True
iNavFlight_____inav_____4798,2019-06-10T10:38:58Z,True,iNavFlight_____inav_____4798_____500371626,"@junwoo091400 I didn't find a better way to explain it, but the buffer is needed to avoid hysteresis on the fringe of the geofence. [This](https://github.com/iNavFlight/inav/pull/4798/files#diff-b8166c625b87a27809555a2f13ba9c6bR3117) part of the code handles that feature, and here are two practical examples.

### Without buffer:
+ `geofence_radius` is set to 200m.
+ You fly out to 200m, RTH triggers.
+ As your craft is flying back, you move the sticks and disengage RTH. But your craft is now already less than 200m from home, so it's back inside the geofence.
+ You head back out to 200m, the cycle repeats because you keep bumping into RTH unless you ""power through"" the geofence boundary with enough speed to gain some extra distance before RTH engages and you manage to get out of it while still being >200m from home.

### With buffer:
+ `geofence_radius` is set to 200m, `geofence_buffer` to 50m.
+ You fly out to 200m, RTH triggers.
+ As your craft is flying back, you move the sticks and disengage RTH. If your craft is at least at `geofence_radius - geofence_buffer` meters from home (and thus 150m with this example config), it will still be considered outside the geofence. _So, in this case, you'll have 50m to safely disengage RTH._
+ You head back out to 200m and this time RTH won't engage, letting you go outside of the geofence.
+ As soon as you get back in a `geofence_radius - geofence_buffer` meters radius from home, the geofence is set back in place and the cycle repeats.",True,True
iNavFlight_____inav_____4798,2019-06-10T12:28:24Z,True,iNavFlight_____inav_____4798_____500398710,"> * You head back out to 200m, the cycle repeats because you keep bumping into RTH unless you ""power through"" the geofence boundary with enough speed to gain some extra distance before RTH engages and you manage to get out of it while still being >200m from home.

Ah, that makes a lot of sense. I see what you mean :) Thanks for the detailed explanation!",True,True
iNavFlight_____inav_____4798,2019-06-10T20:30:30Z,True,iNavFlight_____inav_____4798_____500582327,Perhaps I am misunderstanding your logic but I think a much simpler and less error prone geofence algorithm would force RTH against the user's wishes until the machine is well within the geofence boundary. Only then is the ability to manually disable RTH allowed. The geofence itself should be toggled by a switch to take complete control of the machine as a last resort. Especially if the geofence is misconfigured such as if the diameter is impossibly small.,True,True
iNavFlight_____inav_____4798,2019-06-10T21:32:59Z,True,iNavFlight_____inav_____4798_____500603387,"@nszceta User misconfiguration can never be completely avoided, it's up to the pilot to set coherent parameters - **just like any other feature.** In my opinion _forcing_ RTH to be enabled for any any amount of time while the RX is still active is too dangerous, human judgment is fundamental in the use of this feature and placing it under a switch is not needed thanks to the buffer logic. Also do remember that RTH (F/S, in this case) will stay active until the pilot moves the sticks, so your suggestion pretty much matches the already implemented behavior if the pilot does nothing.",True,True
nestjs_____typeorm_____27,2019-06-12T16:25:29Z,True,nestjs_____typeorm_____27_____501350601,"I'm having some strange behavior with this. It works fine when I use this with some services, however with some others the subscriber stops listening to the events. The last time I found this issue was trying to inject the request.

```
@Injectable({ scope: Scope.REQUEST })
@EventSubscriber()
export class ExampleSubscriber implements EntitySubscriberInterface<Example> {
  
  constructor(@InjectConnection() private readonly connection: Connection, @Inject(REQUEST) private readonly request) {
    connection.subscribers.push(this);
  }
  listenTo() {
    return Example;
  }

  afterInsert(event: InsertEvent){
    console.log(event);
  }

}
```

any ideas?",True,True
google_____shaderc_____708,2019-06-14T14:42:56Z,True,google_____shaderc_____708_____288360179,"
https://github.com/google/re2.git
/compare/0c95bcce2f1f..848dfb7e1d7b

git log 0c95bcce2f1f0f071a786ca2c42384b211b8caba..848dfb7e1d7ba641d598cb66f81590f3999a555a --date=short --no-merges --format=%ad %ae %s
2019-06-13 junyer@google.com Don&#39;t let DFA execution bail when slow for RE2::Set.
2019-06-13 junyer@google.com Expose FilteredRE2::GetRE2() as public.

The AutoRoll server is located here: https://autoroll.skia.org/r/re2-shaderc-autoroll

Documentation for the AutoRoller is here:
https://skia.googlesource.com/buildbot/+/master/autoroll/README.md

If the roll is causing failures, please contact the current sheriff (radial-bots&#43;shaderc-roll@google.com), and stop
the roller if necessary.

",True,True
google_____shaderc_____708,2019-06-14T20:00:48Z,True,google_____shaderc_____708_____502244291,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:01:47Z,True,google_____shaderc_____708_____502244589,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:03:47Z,True,google_____shaderc_____708_____502245193,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:04:47Z,True,google_____shaderc_____708_____502245504,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:05:47Z,True,google_____shaderc_____708_____502245783,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:06:47Z,True,google_____shaderc_____708_____502246064,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:07:48Z,True,google_____shaderc_____708_____502246356,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:08:47Z,True,google_____shaderc_____708_____502246635,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:09:47Z,True,google_____shaderc_____708_____502246915,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:10:47Z,True,google_____shaderc_____708_____502247200,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:11:47Z,True,google_____shaderc_____708_____502247462,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:12:47Z,True,google_____shaderc_____708_____502247769,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:13:47Z,True,google_____shaderc_____708_____502248076,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:14:47Z,True,google_____shaderc_____708_____502248375,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:15:47Z,True,google_____shaderc_____708_____502248660,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:16:47Z,True,google_____shaderc_____708_____502248939,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:17:47Z,True,google_____shaderc_____708_____502249253,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:18:47Z,True,google_____shaderc_____708_____502249573,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:19:47Z,True,google_____shaderc_____708_____502249889,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:20:47Z,True,google_____shaderc_____708_____502250187,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:21:47Z,True,google_____shaderc_____708_____502250440,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:22:47Z,True,google_____shaderc_____708_____502250722,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:23:47Z,True,google_____shaderc_____708_____502251017,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:24:47Z,True,google_____shaderc_____708_____502251327,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:25:47Z,True,google_____shaderc_____708_____502251610,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:26:47Z,True,google_____shaderc_____708_____502251966,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:27:47Z,True,google_____shaderc_____708_____502252307,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:28:48Z,True,google_____shaderc_____708_____502252609,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:29:48Z,True,google_____shaderc_____708_____502252922,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:30:48Z,True,google_____shaderc_____708_____502253245,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:31:47Z,True,google_____shaderc_____708_____502253552,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:32:47Z,True,google_____shaderc_____708_____502253866,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:33:47Z,True,google_____shaderc_____708_____502254141,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:34:47Z,True,google_____shaderc_____708_____502254418,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:35:47Z,True,google_____shaderc_____708_____502254678,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:36:51Z,True,google_____shaderc_____708_____502254968,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:37:47Z,True,google_____shaderc_____708_____502255255,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:38:49Z,True,google_____shaderc_____708_____502255549,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:39:47Z,True,google_____shaderc_____708_____502255792,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:40:47Z,True,google_____shaderc_____708_____502256094,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:41:47Z,True,google_____shaderc_____708_____502256389,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:42:47Z,True,google_____shaderc_____708_____502256641,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:43:47Z,True,google_____shaderc_____708_____502256904,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:44:47Z,True,google_____shaderc_____708_____502257213,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:45:47Z,True,google_____shaderc_____708_____502257498,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:46:47Z,True,google_____shaderc_____708_____502257766,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:47:47Z,True,google_____shaderc_____708_____502258049,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:48:47Z,True,google_____shaderc_____708_____502258321,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:49:47Z,True,google_____shaderc_____708_____502258646,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:50:47Z,True,google_____shaderc_____708_____502258941,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:51:47Z,True,google_____shaderc_____708_____502259246,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:52:47Z,True,google_____shaderc_____708_____502259517,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:53:47Z,True,google_____shaderc_____708_____502259788,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:54:47Z,True,google_____shaderc_____708_____502260065,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:55:47Z,True,google_____shaderc_____708_____502260331,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:56:47Z,True,google_____shaderc_____708_____502260604,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:57:47Z,True,google_____shaderc_____708_____502260878,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:58:47Z,True,google_____shaderc_____708_____502261160,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T20:59:47Z,True,google_____shaderc_____708_____502261445,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:00:47Z,True,google_____shaderc_____708_____502261753,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:01:47Z,True,google_____shaderc_____708_____502262024,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:02:47Z,True,google_____shaderc_____708_____502262296,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:05:47Z,True,google_____shaderc_____708_____502263129,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:06:47Z,True,google_____shaderc_____708_____502263413,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:07:47Z,True,google_____shaderc_____708_____502263688,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:08:47Z,True,google_____shaderc_____708_____502263972,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:09:47Z,True,google_____shaderc_____708_____502264230,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:10:48Z,True,google_____shaderc_____708_____502264499,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:11:47Z,True,google_____shaderc_____708_____502264745,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:12:47Z,True,google_____shaderc_____708_____502265002,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:13:47Z,True,google_____shaderc_____708_____502265294,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:14:48Z,True,google_____shaderc_____708_____502265540,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:15:47Z,True,google_____shaderc_____708_____502265779,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:16:47Z,True,google_____shaderc_____708_____502266025,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:18:47Z,True,google_____shaderc_____708_____502266501,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:19:47Z,True,google_____shaderc_____708_____502266760,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:20:47Z,True,google_____shaderc_____708_____502267030,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:21:47Z,True,google_____shaderc_____708_____502267277,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:22:47Z,True,google_____shaderc_____708_____502267520,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:23:47Z,True,google_____shaderc_____708_____502267766,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:24:47Z,True,google_____shaderc_____708_____502268005,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:25:47Z,True,google_____shaderc_____708_____502268256,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:26:47Z,True,google_____shaderc_____708_____502268507,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-14T21:27:47Z,True,google_____shaderc_____708_____502268760,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T11:58:47Z,True,google_____shaderc_____708_____502360443,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T11:59:47Z,True,google_____shaderc_____708_____502360536,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T12:00:47Z,True,google_____shaderc_____708_____502360629,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T12:01:47Z,True,google_____shaderc_____708_____502360754,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T12:02:47Z,True,google_____shaderc_____708_____502360878,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T12:03:47Z,True,google_____shaderc_____708_____502360944,PullRequest is not longer mergeable. Closing it.,True,True
google_____shaderc_____708,2019-06-15T12:04:47Z,True,google_____shaderc_____708_____502361030,AutoRoller is stopped; closing the active roll.,True,True
google_____shaderc_____708,2019-06-15T12:04:48Z,True,google_____shaderc_____708_____502361032,PullRequest is not longer mergeable. Closing it.,True,True
ethereum_____web3.js_____2905,2019-06-20T11:37:31Z,True,ethereum_____web3.js_____2905_____290178150,"## Description

This is the stable release of v1.0.


### Compare View

[v1.0.0-beta.37 -> v1.0.0](https://github.com/ethereum/web3.js/compare/v1.0.0-beta.37...7e90479)


## Type of change

- [X] Release


## Checklist:

- [ ] I have selected the correct base branch.
- [ ] I have performed a self-review of my own code. 
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no warnings.
- [ ] I have updated or added types for all modules I've changed
- [ ] Any dependent changes have been merged and published in downstream modules.
- [ ] I ran ```npm run lint``` in the root folder with success and pushed the changes.
- [ ] I ran ```npm run test``` in the root folder with success and extended the tests to cover all changes.
- [ ] I ran ```npm run build``` in the root folder and tested it in the browser and with node.
- [ ] I ran ```npm run dtslint``` in the root folder and tested that all my types are correct
- [ ] I have tested my code on an ethereum test network.",True,True
ethereum_____web3.js_____2905,2019-06-20T14:31:51Z,True,ethereum_____web3.js_____2905_____504049296,"
[![Coverage Status](https://coveralls.io/builds/24109247/badge)](https://coveralls.io/builds/24109247)

Coverage remained the same at 83.071% when pulling **c77ccf85628064fddd1df753336ad923d0f712c9 on release/1.0** into **7655fe88a6bdee2a501e669aafe8070443d24d19 on 1.x**.
",True,True
ethereum_____web3.js_____2905,2019-06-21T15:09:16Z,True,ethereum_____web3.js_____2905_____296277439,"The only addition of the `browserifyCompatible` branch in frozeman's fork seems to be [this change](https://github.com/frozeman/WebSocket-Node/commit/7004c39c42ac98875ab61126e5b4a925430f592c). I'm not sure why it was made in the first place, but are we sure that it is no longer needed?",True,True
ethereum_____web3.js_____2905,2019-06-21T15:11:49Z,True,ethereum_____web3.js_____2905_____296278536,"I'm a bit worried about bumping a major version on a dependency, as it could introduce potential incompatibilities in something as critical as the promievent. Why was this needed?",True,True
ethereum_____web3.js_____2905,2019-06-21T19:38:21Z,True,ethereum_____web3.js_____2905_____504548928,"I'm surprised by the number of dependencies upgrades to new major versions of this PR, especially because none of their uses has changed.

Does this version of the library have enough tests to do these upgrades with enough confidence that nothing breaks, @nivida? I'm not familiar enough with this codebase yet.

I agree with @spalladino that the `eventemitter3` is a special case, as it's exposed through promievents.",True,True
ethereum_____web3.js_____2905,2019-06-23T22:04:37Z,True,ethereum_____web3.js_____2905_____504791331,"Great to see the progress here @nivida! I'm curious what the 2.x branch/release is, as that seems to be a recent development.
> As for websockets, I'm glad we are moving away from the github version since it was incorrectly packed and was giving a lot of headaches to many developers when installing it.

+1 @spalladino. Can't wait to remove my preinstall scripts removing websocket git folders.",True,True
PolarisSS13_____Polaris_____6229,2019-06-23T23:43:54Z,True,PolarisSS13_____Polaris_____6229_____290926911,"Here we go! Told y'all there'd be something good coming.

First up- you can now construct and deconstruct teleporters. You'll need certain subspace parts from telecomms storage or R&D, as well as high bluespace levels for the circuits. The hub uses a treatment disk, and the station uses an ansible and filter. 

Next, teleporter stations can now be locked and unlocked with a teleporter-access ID. A locked teleporter cannot be changed from its current state (if it's disabled, it stays disabled; if it's enabled, it stays enabled). Teleporters start locked- so you can only use them if you have the right access on your ID. Stationbound units (AIs/borgs) are able to bypass this restriction and toggle a teleporter on or off regardless of its lock state (unless the wires have been tampered with).
 
 Next, teleporter stations now have six wires- two dummy wires, one that controls the lock, one that enables and disables it, one that test-fires it, and one that can be pulsed to randomise the chances of someone being spaced. (Don't pulse that one.)

The dummy wires do nothing.
The lock wire will toggle the lock on/off when pulsed, or fix the lock in that position when cut- so if you lock it and cut the lock wire, it cannot be unlocked, and vice versa.
The enable/disable wire will turn the teleporter on and off when pulsed, or completely disable the teleporter when cut.
The testfire wire will testfire the teleporter when pulsed, or disable testfiring when cut- you can still testfire it, you just won't gain any benefit from it. Deadly when combined with...
... the randomise wire, which randomises the chance of someone being spaced when pulsed. (Cutting it and mending it restores it to the base 5%.) Teleporters won't space you if they're testfired, though- unless, of course, you also cut the testfire wire!

Sound complicated? Good. You shouldn't be tinkering with teleporter wires unless you're willing to get spaced. If someone's tampered with it in advance, you're probably going to want an engineer or scientist to take a look at it and fix it... or, y'know, just take it apart and put it back together again. That works too.

Finally, because the teleporters are now secure on their own, NanoTrasen has removed the turrets from the teleporter rooms. We don't need them any more, since the teleporters start out ID-locked, and it's a lot less immersion-breaking to have a simple ID lock than it is to shoot people who don't have authorisation.",True,True
PolarisSS13_____Polaris_____6229,2019-06-24T00:40:27Z,True,PolarisSS13_____Polaris_____6229_____504803245,I'm preemptively locking the conversation on this PR before it becomes contentious or heated. It will be discussed at the next Staff Meeting.,True,True
PolarisSS13_____Polaris_____6229,2019-06-25T02:31:13Z,True,PolarisSS13_____Polaris_____6229_____296984412,"Considering tickrate is configurable, I'd use `5 MINUTES` instead.",True,True
PolarisSS13_____Polaris_____6229,2019-06-25T02:34:43Z,True,PolarisSS13_____Polaris_____6229_____296985033,"This should probably have a check for if `testfire_broken` is true or false.
I.E. `(prob(failprob) && (!accurate || testfire_broken))`
So that if the wire is cut, OR it's inaccurate, it will have a fail chance.",True,True
ethereum_____web3.js_____2905,2019-06-25T08:38:17Z,True,ethereum_____web3.js_____2905_____297070527,I'm using the ``websocket`` package in the new architecture directly but will definitely do some additional tests. (There was an issue in the past with getting the global object with Firefox),True,True
ethereum_____web3.js_____2905,2019-06-25T08:43:07Z,True,ethereum_____web3.js_____2905_____505348407,"> Does this version of the library have enough tests to do these upgrades with enough confidence that nothing breaks, @nivida? I'm not familiar enough with this codebase yet.

Yes, I've downgraded the packages if the tests were failing. 

> I agree with @spalladino that the eventemitter3 is a special case, as it's exposed through promievents. 

Upgrading of the EventEmitter package doesn't have an impact on the functionality of Web3.js but I will definitely do some additional tests here too.

@sethfork I will publish an announcement which will explain anything :-)",True,True
iNavFlight_____inav_____4798,2019-06-27T06:04:45Z,True,iNavFlight_____inav_____4798_____506204466,"Hi !
Any chance that this will be included in INAV 2.3? 
This is an awesome feature for RC Training. No more fly away planes from the students :-)
",True,True
Exiv2_____exiv2_____1009,2019-09-29T07:49:02Z,True,Exiv2_____exiv2_____1009_____322481467,"@sridharb1 and I are collaborating on this.  For the moment, it's Work-in-progress.",True,True
Exiv2_____exiv2_____1009,2019-09-29T12:46:08Z,True,Exiv2_____exiv2_____1009_____536296831,"# [Codecov](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=h1) Report
> Merging [#1009](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=desc) into [0.27-maintenance](https://codecov.io/gh/Exiv2/exiv2/commit/a30027c64a692c5f1734e26a7919a122c833f941?src=pr&el=desc) will **decrease** coverage by `0.12%`.
> The diff coverage is `89.47%`.

[![Impacted file tree graph](https://codecov.io/gh/Exiv2/exiv2/pull/1009/graphs/tree.svg?width=650&token=O9G7Iswx26&height=150&src=pr)](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=tree)

```diff
@@                 Coverage Diff                  @@
##           0.27-maintenance    #1009      +/-   ##
====================================================
- Coverage             63.36%   63.24%   -0.13%     
====================================================
  Files                   158      157       -1     
  Lines                 21730    21677      -53     
====================================================
- Hits                  13769    13709      -60     
- Misses                 7961     7968       +7
```


| [Impacted Files](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [src/tiffimage\_int.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL3RpZmZpbWFnZV9pbnQuY3Bw) | `91.76% <ø> (ø)` | :arrow_up: |
| [src/makernote\_int.hpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL21ha2Vybm90ZV9pbnQuaHBw) | `50% <ø> (ø)` | :arrow_up: |
| [src/tags\_int.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL3RhZ3NfaW50LmNwcA==) | `87.59% <ø> (-1.74%)` | :arrow_down: |
| [src/tags\_int.hpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL3RhZ3NfaW50LmhwcA==) | `76.92% <ø> (ø)` | :arrow_up: |
| [src/sonymn\_int.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL3Nvbnltbl9pbnQuY3Bw) | `86.53% <100%> (+33.47%)` | :arrow_up: |
| [src/makernote\_int.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL21ha2Vybm90ZV9pbnQuY3Bw) | `74.77% <100%> (+1.94%)` | :arrow_up: |
| [src/image.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL2ltYWdlLmNwcA==) | `77.69% <60%> (-0.33%)` | :arrow_down: |
| [src/tags.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL3RhZ3MuY3Bw) | `57.96% <0%> (-21.02%)` | :arrow_down: |
| [src/samsungmn\_int.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL3NhbXN1bmdtbl9pbnQuY3Bw) | `17.14% <0%> (-5.72%)` | :arrow_down: |
| [src/olympusmn\_int.cpp](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree#diff-c3JjL29seW1wdXNtbl9pbnQuY3Bw) | `19.23% <0%> (-4.28%)` | :arrow_down: |
| ... and [8 more](https://codecov.io/gh/Exiv2/exiv2/pull/1009/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=footer). Last update [a30027c...4650d8b](https://codecov.io/gh/Exiv2/exiv2/pull/1009?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",True,True
Exiv2_____exiv2_____1009,2019-09-30T10:17:18Z,True,Exiv2_____exiv2_____1009_____536498550,"Could you please fix the diffs for some of the `_int.cpp` files? It is quite impossible to find out what you changed, because the whole file got mangled.",True,True
Exiv2_____exiv2_____1009,2019-09-30T10:50:38Z,True,Exiv2_____exiv2_____1009_____536508925,"It's been mangled by the line-endings.

The code provided by @sridharb1 has Windows CR/LF line endings which SmartGit hid from me.  I think I can put this right after @sridharb1 has finished what he's doing at the moment.

SVN has a file property to say ""This file is to use EOL: NL"" to prevent this kind of clobbering.  Do you know if there's something similar in Git? ",True,True
Exiv2_____exiv2_____1009,2019-09-30T11:08:09Z,True,Exiv2_____exiv2_____1009_____536514343,"```
562 rmills@rmillsmbp:~/gnu/github/exiv2/0.27-maintenance $ git diff -b fix1008_Sony2010e 0.27-maintenance > ~/temp/dc5523f6.diff
563 rmills@rmillsmbp:~/gnu/github/exiv2/0.27-maintenance $ (cd ~/temp ; tar czf dc5523f6.tar.gz dc5523f6.diff) 
564 rmills@rmillsmbp:~/gnu/github/exiv2/0.27-maintenance $ ls -l ~/temp/dc5523f6.tar.gz 
-rw-r--r--  1 rmills  staff  9397 30 Sep 12:06 /Users/rmills/temp/dc5523f6.tar.gz
565 rmills@rmillsmbp:~/gnu/github/exiv2/0.27-maintenance $ 
```
[dc5523f6.tar.gz](https://github.com/Exiv2/exiv2/files/3670556/dc5523f6.tar.gz)
",True,True
Exiv2_____exiv2_____1009,2019-09-30T11:15:15Z,True,Exiv2_____exiv2_____1009_____536516379,"https://github.com/Exiv2/exiv2/pull/1009#issuecomment-536508925
",True,True
Exiv2_____exiv2_____1009,2019-09-30T11:17:39Z,True,Exiv2_____exiv2_____1009_____536517052," I am done with pushing it into fix1008_Sony2010e

Line endings should not be a problem. They should be translated automatically by git to the line ending you use locally.

BTW, the line endings in the test folder for the .sh and functions.source is wrong. They are checked in as text files and thus come with a crlf for me, but it needs just lf as I am executing them in a bash shell. I deal with this locally after every update.",True,True
Exiv2_____exiv2_____1009,2019-09-30T11:29:55Z,True,Exiv2_____exiv2_____1009_____536520757," This is not the problem. core.autocrlf is true for me.
This means that it should get converted to lf upon checkin.",True,True
Exiv2_____exiv2_____1009,2019-09-30T13:14:18Z,True,Exiv2_____exiv2_____1009_____329568703,"Huh, why is this suddenly necessary? Also, we shouldn't touch the xmpsdk's source unless absolutely required.",True,True
Exiv2_____exiv2_____1009,2019-09-30T15:04:08Z,True,Exiv2_____exiv2_____1009_____536604297,"@sridharb1  I've ""tweaked"" the line endings (with dos2unix) and that's much better.  A couple of matters to be resolved:

1) There are a great many changes in canonmn_int.cpp from the original.

My impression is that you generated that file with a script that reads code in ExifTool.  It's added/modified new/changed lens definitions.  It has also modified unchanged definitions.  And while this is cosmetic, if it's possible to avoid changing existing code, this is desirable.

2) FAIL: test_run (bugfixes.github.test_issue_981.CanonAfInfoTest)

Because this branch is from 0.27-maintenance, you don't have my fix for #981.  It's on a branch waiting to be approved/merged into 0.27-maintenance.  I've invited @derselbst  to approve the changes for #981 (and #1001 and #1010).  I would expect you to have both the code AND the test harness changes (or neither).  Let's get everything up-to-date and we'll fix it from there.  I'll deal with this and you can ignore this at the moment.

",True,True
Exiv2_____exiv2_____1009,2019-09-30T15:21:21Z,True,Exiv2_____exiv2_____1009_____536612420,"I've removed WIP from title.  This PR is ready for review.

I've modified test_issue_981.CanonAfInfoTest to pass and this PR should pass the CI.  I will be dealing with #981 (and his descendants) for v0.27.3.  I'm puzzled that test code for #981 is on branch 0.27-maintenance. ",True,True
Exiv2_____exiv2_____1009,2019-09-30T15:42:10Z,True,Exiv2_____exiv2_____1009_____536622207, This is by design. It is best if canonmn_int.cpp is in sync with the naming conventions of exiftool (which I consider the reference standard) and not other names that was added in an adhoc manner over the years. This would also improve future maintability to add just the differences and not search through the mountain of spurious differences to arrive at the meaningful changes.,True,True
Exiv2_____exiv2_____1009,2019-09-30T16:43:10Z,True,Exiv2_____exiv2_____1009_____536647120,"Thanks for the explanation.  If you have a script to generate this code, could you share it with us please.

I agree that ExifTool is the ""reference standard"".  Neils worked on Exiv2 for 3 or 4 years and made many changes concerning Exiv2/Exiftool compatibility.  As I was quite new to the project (and dealing with cross-platform build/test), I didn't really know anything about his work.  

Since Neils left the project (to return to college), I introduced the ~/.exiv2 file to enable users to define lenses.  @nkbj You're welcome back whenever you'd like to join us.",True,True
Exiv2_____exiv2_____1009,2019-09-30T16:44:19Z,True,Exiv2_____exiv2_____1009_____329678196,"@sridharb1 replied _On, windows there is a problem if you don't have it._",True,True
Exiv2_____exiv2_____1009,2019-09-30T17:06:44Z,True,Exiv2_____exiv2_____1009_____536656469,"To avoid changing the XMPSDK code, perhaps it should go into the Windows 
CMake code

Arnold
",True,True
Exiv2_____exiv2_____1009,2019-09-30T18:14:42Z,True,Exiv2_____exiv2_____1009_____536684828,"Interesting idea @tester0077 I believe @sridharb1 is using his own vcxproj/sln files (derived from the now removed msvc/ build environment), so he's not using CMake.

The principle that this can be defined in the project (and not explicitly in the code) sounds good.  It's rather strange that this seems to be required at all, as I don't require this and we've built Exiv2 with all versions of Visual Studio from 2003 onwards.  

On the other hand, this is a minor matter and if it's needed to build the code, so be it.  @D4N is correct to say that Team Exiv2 endeavours to avoid changing xmp/ code. ",True,True
Exiv2_____exiv2_____1009,2019-10-01T02:33:57Z,True,Exiv2_____exiv2_____1009_____536833326,"I use an excel macro to generate the lens and camera list. This is not very sophisticated, as in, it needs manual input and cleanup afterwards, but it does ~99% of the work which saves a ton of time that would be spent in otherwise changing the format from exiftool/perl to exiv2/c. If interested, I can share it. This may be used to get other ""big"" systems like Nikon in sync, but I didn't venture there because of other priorities.",True,True
Exiv2_____exiv2_____1009,2019-10-01T03:38:40Z,True,Exiv2_____exiv2_____1009_____536847135,"This is strange. Regarding dos2unix, this is not the correct practice to do dos2unix before checking things in. Modern scm systems should handle these things transparently. If the repository thinks that this file should always have unix line endings (even on Windows), then the file is incorrectly checked in.

I think it is a mystery to even you looking at your other comment.",True,True
Exiv2_____exiv2_____1009,2019-10-01T03:51:47Z,True,Exiv2_____exiv2_____1009_____536849924,"There are many mysteries in life that I can't explain.  For sure the popularity of **git** is one of them.

Anyway, this PR is looking much better and almost passing the CI.  There's at least one more ""mystery"" and that's CentOS is failing to build and reports:
```
/usr/bin/bash: line 97: python3: command not found
```
It's being doing this for months and blocking everything.  However, @D4N fixed that yesterday on the 0.27-maintenance branch and @piponazo approved/merged it and that's a welcome step forward.

Next mystery is how to get the outstanding PRs (including this) approved and merged onto 0.27-maintenance.  After that, I still have about 3 issues to fix and then Exiv2 v0.27.3-RC1 can be published.",True,True
Exiv2_____exiv2_____1009,2019-10-01T06:11:24Z,True,Exiv2_____exiv2_____1009_____536882998,"I have the answer for why the line endings are messed up. You run a Mac-based environment and I use Windows. When you extracted the files from the zip file, the files ended up being crlf in an lf world. When you checked them in, git thought it doesn't need to translate anything (because the source is an lf world) and thus, they ended up in the repository with crlf and caused problems thereafter.",True,True
Exiv2_____exiv2_____1009,2019-10-01T08:21:44Z,True,Exiv2_____exiv2_____1009_____536925665,"Yes.  I thought I explained that yesterday!  It impacted the 3 files which you send in the zip.

I use SmartGit as my GUI on Git (although I also use the command-line git) and it's strange that informed me of the changes I made in your code for the selector() and `#include <math.h>` and yet it was silent about line-endings.

Anyway, the sun's shining this morning and all is well with this PR, except the CentOS/python3 issue.",True,True
Exiv2_____exiv2_____1009,2019-10-02T05:19:37Z,True,Exiv2_____exiv2_____1009_____537339860,I don't have the git skills to back out something.,True,True
Exiv2_____exiv2_____1009,2019-10-02T05:57:48Z,True,Exiv2_____exiv2_____1009_____330381319,Why the sudden whitespace changes now?,True,True
Exiv2_____exiv2_____1009,2019-10-02T05:59:00Z,True,Exiv2_____exiv2_____1009_____330381544,Why are these tests dropped?,True,True
Exiv2_____exiv2_____1009,2019-10-02T06:00:10Z,True,Exiv2_____exiv2_____1009_____330381771,Then this define should be added via cmake.,True,True
Exiv2_____exiv2_____1009,2019-10-02T06:02:10Z,True,Exiv2_____exiv2_____1009_____330382121,"The diff of the following array looks like everything got changed, but when glancing over it I have a hard time to actually spot the changes. What happened here?

EDIT: ah, there's a whole lot of whitespace changes. Please don't add these or add them into a separate commit.",True,True
Exiv2_____exiv2_____1009,2019-10-02T06:02:14Z,True,Exiv2_____exiv2_____1009_____330382138,I had to remove them to get the test to pass.  I will have to restore them when all the open PRs are eventually merged.  I'm totally frustrated by having about 12 different PRs open and unreviewed.,True,True
Exiv2_____exiv2_____1009,2019-10-02T06:03:11Z,True,Exiv2_____exiv2_____1009_____330382328,"What whitespace changes?  In the code, in the output?",True,True
Exiv2_____exiv2_____1009,2019-10-02T06:07:42Z,True,Exiv2_____exiv2_____1009_____537350605,"I don't know what to do about the dos2unix matter.  I can think of two possibilities:

1) Replace this PR
Find the resulting patch implied by this PR (with git diff)
Open a new branch and apply the patch
Close this PR
Review/approve/merge the new branch

2) I give up and retire.  I am exhausted, frustrated and totally browned off.
 ",True,True
Exiv2_____exiv2_____1009,2019-10-02T07:31:21Z,True,Exiv2_____exiv2_____1009_____330404768,"Whitespace changes were done by VS, regrettably. It changed the spaces to tabs. I have changed the setting that prevents this from happening again. ",True,True
Exiv2_____exiv2_____1009,2019-10-02T07:35:12Z,True,Exiv2_____exiv2_____1009_____330405967,"The original code was pretty-formatted to align with lenses that have 4 spaces. Unfortunately, there came along lens #10001 and thus not aligned. I just gave ourselves more breathing room by using 5 spaces throughout.",True,True
Exiv2_____exiv2_____1009,2019-10-02T07:41:54Z,True,Exiv2_____exiv2_____1009_____537376224,"> 
> 
> There is still files with a huge diff left, please fix that.
> 
> Also, I am not sure if this belongs into a maintenance branch to be honest, as it changes the output of exiv2 by quite a bit.

Yes, it aligns exiv2 and exiftool, at least for Canon lenses and cameras. There may be people who look for the old output, they will need to update their scripts. The advantages of aligning with exiftool, I believe, outweighs the potential incidents that may arise, even with a maintenance release patch.",True,True
Exiv2_____exiv2_____1009,2019-10-04T14:56:23Z,True,Exiv2_____exiv2_____1009_____331545219,The CMake code is in fact already including that definition. Take a look at `cmake/compilerFlags.cmake`,True,True
Exiv2_____exiv2_____1009,2019-10-04T15:12:03Z,True,Exiv2_____exiv2_____1009_____538439152,"Luis Díaz Más <notifications@github.com> writes:

> piponazo commented on this pull request.
>
>
>
>> @@ -5,7 +5,7 @@
>  // NOTICE:	Adobe permits you to use, modify, and distribute this file in accordance with the terms
>  // of the Adobe license agreement accompanying it.
>  // =================================================================================================
> -
> +#define NOMINMAX
>
> The CMake code is in fact already including that definition. Take a look at `cmake/compilerFlags.cmake`
>

I've dropped the respective commit now.
",True,True
Exiv2_____exiv2_____1009,2019-10-04T16:58:19Z,True,Exiv2_____exiv2_____1009_____538478987,"Ok


Sent from Yahoo Mail for iPhone


On Friday, October 4, 2019, 20:42, D4N <notifications@github.com> wrote:

Luis Díaz Más <notifications@github.com> writes:

> piponazo commented on this pull request.
>
>
>
>> @@ -5,7 +5,7 @@
> // NOTICE: Adobe permits you to use, modify, and distribute this file in accordance with the terms
> // of the Adobe license agreement accompanying it.
> // =================================================================================================
> -
> +#define NOMINMAX
>
> The CMake code is in fact already including that definition. Take a look at `cmake/compilerFlags.cmake`
>

I've dropped the respective commit now.


—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.


",True,True
expressjs_____session_____708,2019-11-04T09:18:49Z,True,expressjs_____session_____708_____336177883,"Add debug statement (enabled only in debug mode) at vital session life cycle control flow points

Refs: https://github.com/expressjs/session/issues/633#issuecomment-471110093

Generally improves ability to diagnose issues.

(from a high level view on the outstanding issues in this repo, it is evident that the most prominent type is diagnosing session persistence across client requests, so this is a small step towards helping there)",True,True
openstreetmap_____iD_____7162,2019-12-24T13:05:42Z,True,openstreetmap_____iD_____7162_____568744868,"Sorry @rory but I strongly disagree.. I'm not comfortable intentionally breaking features in our software that provide value - and we have all previously agreed that letting users opt out of them is fine.  We put a lot of work and thought into the NSI feature, and while I'm not surprised, I'm seriously disappointed in you dropping your PR in here like this one day after the 2.17 release.  **Shame on you.** Please don't perform stunts like this or troll our repository in this way - it's not welcome. 

Taken to the extreme, we'd also need to opt-out the user from seeing satellite imagery, and force them to go looking through menus to figure out how to turn it on. They wouldn't even be able to use the tutorial!

Also, we can't accept PRs that touch the Privacy policy like this. 
",True,True
instagrambot_____instabot_____1206,2020-01-07T15:13:54Z,True,instagrambot_____instabot_____1206_____571628813,"Please stop cotacting me, I am not doing anything wrong.. What you are doing now isharrasment and illegal. 

Here are danii begging me to move my repo to his organisation because 10% of my code is instabot haha..
<img alt=""Screenshot 2020-01-06 at 15 30 27"" width=""760"" src=""https://i.imgur.com/jDR1J9x.png"">

stop harrasing me, saying i did stuff wrong while you did it.. is bad style

I would have no issues with helping others out, i have an issue because it's you danii.. 
1. I don't want to hear from you.
2. I don't want to hear your crazy demands.
3. I don't want my work under your name.

So now that both github and me have told you, you don't have a case. Can you please stop pushing this.. this has been going on for seven months now.. I really don't have time for small stuff like this. ",True,True
instagrambot_____instabot_____1206,2020-01-07T17:02:59Z,True,instagrambot_____instabot_____1206_____571678068,lol,True,True
instagrambot_____instabot_____1206,2020-01-07T17:03:59Z,True,instagrambot_____instabot_____1206_____571678470,kk i will contact github have a nice day.,True,True
instagrambot_____instabot_____1206,2020-01-07T22:25:30Z,True,instagrambot_____instabot_____1206_____571801544,"@bruvv This is not a mistake - ""instabotai"" project was in ""instagrambot"" organization a while ago. Since this project was started and maintained by @reliefs, he decided to create his own organization and transfer the repo to it.

Thank you @bruvv for your support, I really appreciate that. But please, don't try to be rude. As for me, this looks unprofessional. I truly believe that @reliefs understand the whole situation and will do the right thing soon.",True,True
NabuCasa_____hass-nabucasa_____119,2020-01-08T12:50:06Z,True,NabuCasa_____hass-nabucasa_____119_____572033883,"I close now the PR. @flokli, thanks for you contribution. I hope you don't take that personal.",True,True
xbmc_____xbmc_____17106,2020-01-12T07:07:19Z,True,xbmc_____xbmc_____17106_____573388880,"Ok I have been thinking about this a lot over the last week and my current opinion is that we should focus on the HDR playback for now and drop the HDR os switching.

The HDR os switching is questionable if it's a good idea. There's a reason that Microsoft chose to not offer an easy API for the HDR toggle and leaves it up to the user. This is a global setting that affects other software as well and if several apps try to toggle this on/off things might end up in all sorts of broken states.
There's also the fact that we can't do this for UWP and it makes sense to keep the behavior consistent to make it easier for users and support.

The deciding factor for me is that the HDR os switching can be implemented as a python addon so by not having it in Kodi core we aren't blocking this possibility but we keep core simple and more consistent across platforms.

We should be able to use [this](https://github.com/microsoft/DirectX-Graphics-Samples/blob/29fb35649a449da30adcbfefee5d2e1a8258c718/Samples/Desktop/D3D12HDR/src/D3D12HDR.cpp#L1114) method to check if the system is HDR capable, and put that in some method we already have that reacts to changes in the window system like `DX::DeviceResources::HandleOutputChange`. I haven't been able to test that this method works for all scenarios so there could be a better way to handle it.

I think we should set static HDR metadata if we don't find any dynamic metadata in the stream, maybe set this directly at start as it would be overwritten later by dynamic metadata anyway?

@fandangos mentioned on slack that refresh rate switching doesn't work when HDR is enabled so this is something that needs to be investigated so we don't lose that functionality.

In summary
1. Remove everything for OS HDR switching, win32util, skin, powermenu etc
2. Do the HDR capability check in an event such as `HandleOutputChanged`
3. Make sure that refresh rate is switched correctly to match the video frame rate.
4. optional, use static metadata by default or if no dynamic metadata is found.

Thank you for all your work. With the above changes I'm fairly confident that we can get this merged and have HDR support in v19.

",True,True
xbmc_____xbmc_____17106,2020-01-12T10:54:12Z,True,xbmc_____xbmc_____17106_____573403012,"Ok but people won't use it.

People complain even because they have to manual switch with the button... they want it to be fully automatic.

They will continue to use the fork because it is more practical.


> @fandangos mentioned on slack that refresh rate switching doesn't work when HDR is enabled so this is something that needs to be investigated so we don't lose that functionality.

This happens on his fork. In mine it doesn't happen. The current manual switch option does not interfere with refresh rate match.

> I think we should set static HDR metadata if we don't find any dynamic metadata in the stream, maybe set this directly at start as it would be overwritten later by dynamic metadata anyway?

This already works like this.",True,True
xbmc_____xbmc_____17106,2020-01-12T11:05:24Z,True,xbmc_____xbmc_____17106_____573403904,"I just mentioned with Paxxi that I poorly explained it to him. 

If the function to turn hdr on/off is in CRenderBase::Configure it will break refresh rate switching. That's one of the reasons why I deleted my entire second fork of this.

For an automatic solution we are kinda of screwed:
1. Automatic method before video starts: doesn't have the metadata to check and be started or not.
2. Automatic method during Configure: breaks refresh rate switching.
3. Automatic method after video started: wrong metadata.

The idea of autohdr is good for nvidia and amd gpus but as we discussed on the forum doesn't work for ryzen and Intel.
Since the code to switch hdr on uses unlisted and private microsoft apis that are not documented (as far as I know) it would remove a burden of the code if this was dropped and it could surface as an independent addon in the future.

This would make it safer.
Also people will stop using my fork (not sure about yours) because as I explained in the thread, I won't be updating it any further since this will probably get merged.


Just my thoughts on this.
Thank you for all your work, Jogal. ",True,True
xbmc_____xbmc_____17106,2020-01-12T11:07:07Z,True,xbmc_____xbmc_____17106_____573404057,"> We should be able to use this method to check if the system is HDR capable,

`ComPtr<IDXGIOutput6> output6;`   needs to be compiled with  `<dxgi1_6.h>`  this breaks runtime compatibility with Windows 7

In fact, before I used it:
https://github.com/thexai/xbmc/commit/c12b0fb938c14673c63f705e6705855a3c5ac997#diff-59b7a66ddf0bcc466e36501cd9739d85R1289
I removed it as an ""improvement"".",True,True
xbmc_____xbmc_____17106,2020-01-12T12:29:49Z,True,xbmc_____xbmc_____17106_____573410536,Why not stop supporting Windows 7 if it is Holding us back? Like Python 2 it is time to move on. I would really love to see the full potential of HDR in kodi on Windows 10. Microsoft is soon to stop releasing Security updates for Win 7.,True,True
xbmc_____xbmc_____17106,2020-01-12T12:42:20Z,True,xbmc_____xbmc_____17106_____573411512,"I thought that it would still run on windows 7 but the `As` call would fail and return nullptr when used like the example

@dvidebaek I agree that it's about time to drop support for Windows 7 now that it's out of support but that's a larger decision and if we can keep support with minimal effort it's worth it for v19.",True,True
xbmc_____xbmc_____17106,2020-01-12T12:51:53Z,True,xbmc_____xbmc_____17106_____573412393,Kodi is in need of more Windows developers. Why not say that Leia 18.x will be the last officially supported Kodi for Windows 7. Then the few Windows developers could use there free spare time on implementing new features insted of supporting a legacy OS... HDR is the future not Windows 7. Windows 7 is a waste of time supporting time wise,True,True
xbmc_____xbmc_____17106,2020-01-12T13:34:03Z,True,xbmc_____xbmc_____17106_____573415897,"We are making it very very difficult for me. If I close this PR I will not open any more...

- As it is now it works.
- It does not break compatibility with Windows 7.
- The auto refresh rate match works.
- Gives the possibility of activating the HDR mode without leaving to OS control panel. Remove this is not permissible if Kodi is used with remote control.
- Image quality and HDR metadata passthrough is perfect.
- Works in UWP with some limitations due UWP API  but works with same image quality.

I can't be forever changing everything over and over again... believe it or not it is a lot of work to test and make sure it doesn't have important bugs.",True,True
xbmc_____xbmc_____17106,2020-01-12T15:24:10Z,True,xbmc_____xbmc_____17106_____573425592,"> Since the code to switch hdr on uses unlisted and private microsoft apis that are not documented (as far as I know) it would remove a burden of the code if this was dropped and it could surface as an independent addon in the future.

I'm sorry but this is not true.
Of everything that is said in the forums there are many things that are not true.

![Anotación 2020-01-12 162004](https://user-images.githubusercontent.com/58434170/72221119-cadb0680-3557-11ea-9c86-65f14c00ccc8.png)

![Anotación 2020-01-12 161915](https://user-images.githubusercontent.com/58434170/72221123-cf9fba80-3557-11ea-8450-65b974df6521.png)

https://docs.microsoft.com/en-us/windows/win32/api/wingdi/ne-wingdi-displayconfig_device_info_type

https://docs.microsoft.com/es-es/windows/win32/api/wingdi/ns-wingdi-displayconfig_device_info_header

Also 0x18 = packet length = 24 bytes in decimal
same 0x20 = packet length = 32 bytes in decimal

In addition, this can also be implemented in UWP, but more work hours are needed...",True,True
xbmc_____xbmc_____17106,2020-01-12T15:37:26Z,True,xbmc_____xbmc_____17106_____573426751,"As I've said, as far as I know. 

I have worked with private APIs for HDR, not windows api. 

When I'm not sure I add the 'as far as I know' before commenting since, as I've said many times before, I'm still learning.

Also I base myself on the readme that came along with that code that you and I copied. Have you read it? It explains some of that function.

The author, 'AppWizard', claimed it was undocumented function calls. You can find the original files in the hdr thread, _DMU_ was the one offering those in a google drive link.

So who am I to contradict a readme from a code that I partially understand? :)

And finally this is not my call, it's team kodi's. All of them have it very clear I'm just a beginner in this.
So if I say something that is incorrect, please, feel free to correct it, as you are the more experienced one. ",True,True
xbmc_____xbmc_____17106,2020-01-12T15:41:30Z,True,xbmc_____xbmc_____17106_____573427226,"I agree but. ""It's undocumented"" or ""not understand it"" is not a valid reason to remove it.",True,True
xbmc_____xbmc_____17106,2020-01-12T15:47:09Z,True,xbmc_____xbmc_____17106_____573427871,Dont stop @thexai you are the Windows communities only hope for bringing HDR to Windows. I know you can figure out how to implement automatic HDR on/off. Keep going. I have a feeling TK only will work on HDR when the Linux Kernel is ready. It could take months!!! ,True,True
iNavFlight_____inav_____4798,2020-01-13T13:07:33Z,True,iNavFlight_____inav_____4798_____573654198,"@mmagioni have you resolved the implementation of the vertical boundaries? I think there might be few problems, since vertical speed for normal FW is way lower than horizontal speed the vertical buffer should be a fraction of the horizontal buffer, maybe proportional to the horizontal buffer/horizontal speed. 
But the question is what will the aircraft do on hitting the vertical boundary? Will it keep descending to the ground in case RTH is not desabled. And if it enters RTH and is just above or close to home position I guess loitering will follow but should it descend to ground level or just maintain the altitude once its inside the ""green"" vertical sector?",True,True
iNavFlight_____inav_____4798,2020-01-13T17:44:58Z,True,iNavFlight_____inav_____4798_____573784549,"@Mateyhv A single buffer dimension is enough in my opinion, you'll still need some vertical space to maneuver to disable the RTH and obstacles might be in your way, so extra vertical space is crucial to avoid unwanted control interferences. Regarding the behavior: since at the geofence's boundary RTH will be enabled, it will behave just like you turned it on yourself.

Anyway, I encourage everyone to wait for an initial cut of this feature to be finalized, tested and merged before suggesting improvements.",True,True
xbmc_____xbmc_____17106,2020-01-13T18:55:51Z,True,xbmc_____xbmc_____17106_____573815783,"> The idea of autohdr is good for nvidia and amd gpus

This is also not true:

It's causing issues with refresh rate match beacause:

AUTOHDR.exe switch display to HDR mode and NOT waits (safe) 2 seconds to complete.

Due this Kodi opens in an indeterminate state in SDR swapchain mode but display in HDR mode.

When playback begins and calls ResizeBuffers causes issues with refresh rate match because swapchain configuration changes from SDR to HDR in an uncontrolled way.

These issues are NOT PRESENT if is not used AUTOHDR.exe

People uses AUTOHDR.exe because YouTube video is cool……....

People complain about refresh rate issues with HDR........

",True,True
xbmc_____xbmc_____17106,2020-01-13T19:09:09Z,True,xbmc_____xbmc_____17106_____573821426,"No issues for me and some others who used it. 

I made it before you added the advancedsettings function to your fork and I even added on the first post that no one would need to use it. It was just an option.

If adding a Sleep(2000); to it fix the problem I can do it when I get home, no problem. Thanks for reporting it.

And the youtube video was really cool, glad you liked it. Thank you. :))

Well, either way, if you feel like I'm interfering or causing any problems to your work I'll ask the kodi mods to delete the autohdr thread.
I already stopped working on my fork, no big deal deleting autohdr. I really don't want to get in the way.
Just let me know.",True,True
iNavFlight_____inav_____4798,2020-01-13T20:36:23Z,True,iNavFlight_____inav_____4798_____573858206,"The single verical boundary makes things easier. Regarding RTH I am not sure how it behaves if uav is just above home position when it enables.

The only suggestion I have is to add a clear message for tue pilot to be aware that its not some malfunctionig that triggered RTH. Kind of a system message when crossing the geofence ""GEOFENCE RTH enabled in.."" five, four, three... Or anything similar.

Very interesting feature! Would like to see it soon ;-)",True,True
evilsocket_____pwnagotchi_____747,2020-01-14T10:59:27Z,True,evilsocket_____pwnagotchi_____747_____574119902,"https://github.com/evilsocket/www.pwnagotchi.ai/blob/master/content/configuration/_index.md

Do not forget to update the site too.",True,True
evilsocket_____pwnagotchi_____747,2020-01-14T11:06:23Z,True,evilsocket_____pwnagotchi_____747_____574122736,"I'm not sure if i'm more annoyed by the fact that the sentence doesn't even end with ""please"", or that anybody could just send a pull request to the other repository instead of demanding it to be updated, without even bothering being polite.",True,True
MinecraftForge_____MinecraftForge_____6443,2020-01-15T08:18:41Z,True,MinecraftForge_____MinecraftForge_____6443_____574547217,"There is both a ServerChatEvent and a ClientChatEvent, they should address the bulk of what you need.
A 10 second look would of shown you that.
And do not readd links in which I have removed, do it again and you'll be blocked.
I have instructed you on two paths on how to achieve your goal now.

Also this PR would never be accepted because we do not encourage people to directly screw with packets at the  raw level like this.
IF it was to EVER be entertained it would have to be hooked in the correct places where the data is actually sent like ServerChatEvent is and have the proper context.
If you're just going to hack around with low level packets, then just use netty and don't bother us when things break.",True,True
xbmc_____xbmc_____17106,2020-01-24T14:28:21Z,True,xbmc_____xbmc_____17106_____578152390,"> I do not want to remove the code for manual HDR / SDR switch because this removes important functionality and usability.

@thexai we get that this is an important feature to improve usability, but you admitted yourself that this can only be a temporary solution. And it our eyes it is quite a hack and moved to a place where it a) doesn't really belong and b) is up to the skin to actually add it there, which again is not ideal for a feature you consider essential.

The suggestion of paxxi (and the preference of the team) was, and still is, to move the trigger for this feature to an add-on, making use of some utility `exe` (like the one of @fandangos) that performs the switch of the HDR mode in the OS.

The benefit of moving the trigger logic into an add-on would be that users have most flexibility on when it should be triggered. It could be on startup of KODI, via context menu entry on HDR movies in the library, as soon as one enters the video section of his library, on click of a remote button and what not. So it would be much more configurable and adjustable to the users needs/wishes and in addition would keep the core clean for now and give us more time to find a better solution.

So I'm sorry to say, if you want this PR to get merged, the HDR switching logic has to be moved to an add-on for the time being.

PS: if it helps in some way, since Win7 is EOL now, we will also drop Win7 support soon. For now it's planned to happen with v20, but if HDR would benefit of APIs that would break backwards compatibility to v7, we would consider dropping it for v19 already. We are still discussing this ofc - so decision is not final yet.

edit: just to be clear - from what I gathered from our Windows devs, the HDR switch is currently the only blocker in this PR preventing a merge (apart from Jenkins currently not being happy)
",True,True
rust-lang_____rfcs_____2544,2020-01-24T22:01:09Z,True,rust-lang_____rfcs_____2544_____578318988,"So a little over a year ago, @withoutboats [wrote](https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453796456):

> I'm not sure what to do about this in the long term, but in an immediate sense I'm calling a cool down on this thread. I'm locking discussion for a couple of days or so and when it gets unlocked I hope it will be conducted with a decorum appropriate to a professional open source project.

Obviously, it's been more than a few days! Over the course of several lang team meetings, we've been discussing what to do about this RFC, and I've also spoken with @varkor. The truth is that it's quite complicated. But one thing is clear: **Whatever we do, it won't happen on this particular pull request.** If nothing else, this thread history is far too large for any reasonable human to catch up on. Therefore, the only action I am taking for the moment is to close this RFC.

In terms of next steps:

* Most of us on the lang team continues to feel that, all things considered, this would be a positive change for the language. However, we also recognize that there is a very sizable set of people who feel otherwise, and this alone is definitely reason to give pause and be triple sure.
* If we were to reconsider this proposal, we would want to begin with a thorough review of the concerns raised here, to ensure that the they are not lost and that we have considered them carefully. These would be combined with the [summary that @Centril already made](https://github.com/rust-lang/rfcs/pull/2544#issuecomment-453653184). (Exactly what form this review takes I'm not sure, but I *personally* would consider trying a [collaborative summary document](http://smallcultfollowing.com/babysteps/blog/2019/04/22/aic-collaborative-summary-documents/). --nikomatsakis)
* Some portion of the concerns had to do with the practical impact of making this change: i.e., making it harder for editors and other sorts of tooling to parse Rust. This at least can be evaluated by landing the change on nightly and actively updating the various bits of tooling we have, as well as allowing the change to ""sit"" for some time in an unstable state so that we accumulate experience.",True,True
rust-lang_____rfcs_____2544,2020-01-24T22:13:52Z,True,rust-lang_____rfcs_____2544_____578322984,"For historical purposes, [the current output for the example shown in the description](https://play.rust-lang.org/?version=nightly&mode=debug&edition=2018&gist=d155ca3a07603fed35101bdde2219907) is:

```
error: comparison operators cannot be chained
  --> src/main.rs:12:7
   |
12 |     id<u32>(0u32); // ok
   |       ^^^^^
   |
help: use `::<...>` instead of `<...>` to specify type arguments
   |
12 |     id::<u32>(0u32); // ok
   |       ^^

error: comparison operators cannot be chained
  --> src/main.rs:13:19
   |
13 |     let n = Nooper<&str>("":)""); // ok
   |                   ^^^^^^
   |
help: use `::<...>` instead of `<...>` to specify type arguments
   |
13 |     let n = Nooper::<&str>("":)""); // ok
   |                   ^^

error: comparison operators cannot be chained
  --> src/main.rs:14:11
   |
14 |     n.noop<()>(()); // ok
   |           ^^^^
   |
help: use `::<...>` instead of `<...>` to specify type arguments
   |
14 |     n.noop::<()>(()); // ok
   |           ^^
```

whereas the output when this RFC was created was:

```
error: chained comparison operators require parentheses
  --> <source>:12:7
   |
12 |     id<u32>(0u32); // ok
   |       ^^^^^^
   |
   = help: use `::<...>` instead of `<...>` if you meant to specify type arguments
   = help: or use `(...)` if you meant to specify fn arguments

error: chained comparison operators require parentheses
  --> <source>:13:19
   |
13 |     let n = Nooper<&str>("":)""); // ok
   |                   ^^^^^^^
   |
   = help: use `::<...>` instead of `<...>` if you meant to specify type arguments
   = help: or use `(...)` if you meant to specify fn arguments

error: chained comparison operators require parentheses
  --> <source>:14:11
   |
14 |     n.noop<()>(()); // ok
   |           ^^^^^
   |
   = help: use `::<...>` instead of `<...>` if you meant to specify type arguments
   = help: or use `(...)` if you meant to specify fn arguments

error[E0423]: expected value, found builtin type `u32`
  --> <source>:12:8
   |
12 |     id<u32>(0u32); // ok
   |        ^^^ not a value

error[E0423]: expected value, found builtin type `str`
  --> <source>:13:21
   |
13 |     let n = Nooper<&str>("":)""); // ok
   |                     ^^^ did you mean `std`?

error[E0369]: binary operation `<` cannot be applied to type `fn(_) -> _ {id::<_>}`
  --> <source>:12:5
   |
12 |     id<u32>(0u32); // ok
   |     ^^^^^^
   |
   = note: an implementation of `std::cmp::PartialOrd` might be missing for `fn(_) -> _ {id::<_>}`

error[E0369]: binary operation `<` cannot be applied to type `fn(_) -> Nooper<_> {Nooper<_>::{{constructor}}}`
  --> <source>:13:13
   |
13 |     let n = Nooper<&str>("":)""); // ok
   |             ^^^^^^^^^^^
   |
   = note: an implementation of `std::cmp::PartialOrd` might be missing for `fn(_) -> Nooper<_> {Nooper<_>::{{constructor}}}`

error[E0610]: `bool` is a primitive type and therefore doesn't have fields
  --> <source>:14:7
   |
14 |     n.noop<()>(()); // ok
   |       ^^^^

error[E0308]: mismatched types
  --> <source>:14:15
   |
14 |     n.noop<()>(()); // ok
   |               ^^^^ expected bool, found ()
   |
   = note: expected type `bool`
              found type `()`
```",True,True
xbmc_____xbmc_____17106,2020-01-25T17:51:43Z,True,xbmc_____xbmc_____17106_____578427213,"> to move the trigger for this feature to an add-on, making use of some utility exe (like the one of @fandangos) that performs the switch of the HDR mode in the OS.
> 
> The benefit of moving the trigger logic into an add-on would be that users have most flexibility on when it should be triggered. It could be on startup of KODI, via context menu entry on HDR movies in the library, as soon as one enters the video section of his library, on click of a remote button and what not. So it would be much more configurable and adjustable to the users needs/wishes and in addition would keep the core clean for now and give us more time to find a better solution.
> 
> So I'm sorry to say, if you want this PR to get merged, the HDR switching logic has to be moved to an add-on for the time being.

I'm sorry but it's a very stupid idea. I will not waste my time explaining why.

Some clue:

- Python needs to call a Win32 API code ""tool.exe"" that is already in Kodi.exe
- Kodi GUI needs know if it should show the button for HDR switch (needs know if the system is HDR capable), then needs part of the code that is supposed to be implemented outside.
- ""Current GUI settings / Player / Use HDR display capabilities"" needs know if system supports HDR to shown setting.
- Windows HDR switch from outside OK..... but swapchain is reconfigured by Python hahahhah


EDIT:  Is possible remove toggle button from power menu but  IS NOT POSSIBLE remove code related to HDR detection / switch from kodi.exe

AND IS NOT UNDOCUMENTED CODE     IS    **WIN32 API**    CODE   

AND CAN STAY  IN WIN32UTIL  FOREVER",True,True
xbmc_____xbmc_____17106,2020-01-25T19:09:05Z,True,xbmc_____xbmc_____17106_____578434174,"We have tried to be accommodating and clearly stated which parts we find troublesome currently and given you a path to get this merged .

Nobody said the swapchain would be configured by python, only that the code in Win32Util can be in an addon if it's needed.

Neither me nor @da-anda said that you used undocumented apis. I have some concerns over the usage of the DisplayConfiguration apis because the documentationen around them is very sparse compared to what win32 apis usually have available. I'm not an expert in the area so I gave you the option to remove that part to get your work merged.

You continue to be arrogant and belittling despite our efforts trying to work with you in good faith. You're very capable technically as shown by the work you've done here but the way you treat people is not acceptable.

This PR is done and it won't get approved. You're welcome to try again in the future if you can learn to behave better.",True,True
xbmc_____xbmc_____17106,2020-01-26T05:03:04Z,True,xbmc_____xbmc_____17106_____578468993,"Sad to see this. Thanks for the effort @thexai. Hope you will continue improving HDR on Windows. Maybe your own fork of kodi? When TK is closing this PR, do They have alternatives or is HDR a no go in kodi??",True,True
xbmc_____xbmc_____17106,2020-01-26T12:39:12Z,True,xbmc_____xbmc_____17106_____578498118,"@thexai 

>    Kodi GUI needs know if it should show the button for HDR switch (needs know if the system is HDR capable), then needs part of the code that is supposed to be implemented outside.

no, KODI does not have to know if this button has to be shown. Since the add-on is responsible for switching the OS HDR mode, it is also responsible to inject the button or toggle it automatically. The possibilities are almost endless and up to the add-on logic where to inject a context menu item or toggle automatically.

>    ""Current GUI settings / Player / Use HDR display capabilities"" needs know if system supports HDR to shown setting.

And it still can. Nobody said that you have to remove display capability enumeration in KODI etc. - just the power menu button and the logic to change the system setting.

> Windows HDR switch from outside OK..... but swapchain is reconfigured by Python hahahhah

nobody said that everything had to move into an add-on - only the logic to flip the HDR switch in the OS. Yes, that would mean that some logic might have to be duplicated in the tool (HDR capability detection) or that add-ons might have to be able to read some system information via APIs from KODI. In fact, there are already ways to get system info from within the Python API or JSON-RPC API. Those APIs could be extended to provide additional info and maybe even a method to enable/disable KODIs HDR mode if this would be needed (like it's possible to trigger the stereoscopic 3D mode from python and JSON-RPC).
So there would be ways to do what we asked for, but you completely shut down and don't seem to be open to compromise. That's really sad to see.

@dvidebaek we do want HDR, just not the power menu switch and the logic to change the OS setting. Everything else was fine (with room for later improvement), but thexai unfortunately does not seem to be willing to find a compromise to outsource this settings toggle or communicate with us in a cooperative way.",True,True
xbmc_____xbmc_____17106,2020-01-26T12:46:45Z,True,xbmc_____xbmc_____17106_____578498681,"> @thexai
> 
> > Kodi GUI needs know if it should show the button for HDR switch (needs know if the system is HDR capable), then needs part of the code that is supposed to be implemented outside.
> 
> no, KODI does not have to know if this button has to be shown. Since the add-on is responsible for switching the OS HDR mode, it is also responsible to inject the button or toggle it automatically. The possibilities are almost endless and up to the add-on logic where to inject a context menu item or toggle automatically.
> 
> > ""Current GUI settings / Player / Use HDR display capabilities"" needs know if system supports HDR to shown setting.
> 
> And it still can. Nobody said that you have to remove display capability enumeration in KODI etc. - just the power menu button and the logic to change the system setting.
> 
> > Windows HDR switch from outside OK..... but swapchain is reconfigured by Python hahahhah
> 
> nobody said that everything had to move into an add-on - only the logic to flip the HDR switch in the OS. Yes, that would mean that some logic might have to be duplicated in the tool (HDR capability detection) or that add-ons might have to be able to read some system information via APIs from KODI. In fact, there are already ways to get system info from within the Python API or JSON-RPC API. Those APIs could be extended to provide additional info and maybe even a method to enable/disable KODIs HDR mode if this would be needed (like it's possible to trigger the stereoscopic 3D mode from python and JSON-RPC).
> So there would be ways to do what we asked for, but you completely shut down and don't seem to be open to compromise. That's really sad to see.
> 
> @dvidebaek we do want HDR, just not the power menu switch and the logic to change the OS setting. Everything else was fine (with room for later improvement), but thexai unfortunately does not seem to be willing to find a compromise to outsource this settings toggle or communicate with us in a cooperative way.

You are Right. Cooperation is the way forward. This should not be a one man show. Have you reached out to @thexai in private? Maybe TK and thexai can reach an mutual understading??",True,True
xbmc_____xbmc_____17106,2020-01-26T13:29:30Z,True,xbmc_____xbmc_____17106_____578502033,"I'm unable to comment on the PR content (not a Windows dev, can't spell SDK) but I'd observe that developers and maintainers have similar but different goals. Developers like to merge a new feature early then iterate it until everything is good. Maintainers prefer the development and iteration to be done first, then a finished feature gets merged. Release Managers are always balancing the needs of those two personalities. Early in a development cycle we can be gung-ho and many times we've borked Kodi for a while as something disruptive got merged, but as the release cycle evolves to public releases we need to behave more like maintainers. 

RIght now we're already overdue for shipping K19 Alpha1, so we're definitely in maintainer mode and will want things to be fully-baked before we let code merge. Also, and this is a critical point, requiring code to be effectively feature-complete before merge is the only sensible option when a contributor attempts to blackmail us with threats of stopping work. As maintainers, why would we risk incomplete features being merged? It's always sad that people attempt this behaviour as it's counter-productive and triggers the team's sense of responsibility for the codebase. Kodi is far from perfect (way too many chefs in the kitchen over too many years for that) but we know that, and from experience we know we need to be careful with it.

Anyway.. the door is never closed to any developer having a change of heart and making the effort to submit code. HDR for Windows is definitely a desired feature, so even if @thexai is not the right person some positive progress was made here and someone else can pick up the batton. At this stage it looks pretty unlikely that anything can/will be done for K19, but it's often best to let larger features land without being forced. It looks like we have decided K19 is the last release to support Win7, so K20 will avoid some issues there. K20 is also the target for several other platforms to have HDR support squared away. Again, the door is never closed.",True,True
xbmc_____xbmc_____17106,2020-01-26T18:41:25Z,True,xbmc_____xbmc_____17106_____578530293,what is TK's stance on someone taking this exact PR's source code (well its GPLv2 after all) and resubmitting it with modifications at a later date?,True,True
xbmc_____xbmc_____17106,2020-01-27T05:23:06Z,True,xbmc_____xbmc_____17106_____578596232,"No objections as long as the original commit attribution is retained where possible/sensible in the revised submission. It's always preferable for the original contributor to finish the task, but if that's not to be - the beauty of open-source is - someone else can always continue the work.",True,True
xbmc_____xbmc_____17106,2020-01-27T08:47:44Z,True,xbmc_____xbmc_____17106_____578647223,"I really don't understand how a simple button on a site that don't like makes life so complicated.

Collaboration is:

- Gets merged as is.
- Someone with skinning skills takes master branch and changes the toggle button from site/appearance.
- END

Why is need move HDR detection/toggle logic to external .exe   (trojan)  ??
Why is need a Python 3 addon to switch HDR?
Why?


I just protect myself (my job) to prevent it from ruining completely.",True,True
xbmc_____xbmc_____17106,2020-01-27T09:01:45Z,True,xbmc_____xbmc_____17106_____578651897,"I have also made a great effort to improve Win32 API detection/toggle code.

Even others have helped me in it.

There are no ""magic bytes"" anymore https://github.com/xbmc/xbmc/pull/17106/commits/0e0d098eec22eec62c308cea26c6c17aa70cf227


`if (ERROR_SUCCESS == GetDisplayConfigBufferSizes(QDC_ONLY_ACTIVE_PATHS, &pathCount, &modeCount))
  {
    std::vector<DISPLAYCONFIG_PATH_INFO> paths(pathCount);
    std::vector<DISPLAYCONFIG_MODE_INFO> modes(modeCount);

    if (ERROR_SUCCESS == QueryDisplayConfig(QDC_ONLY_ACTIVE_PATHS, &pathCount, paths.data(),
                                            &modeCount, modes.data(), 0))
    {
      DISPLAYCONFIG_GET_ADVANCED_COLOR_INFO getColorInfo = {};
      getColorInfo.header.type = DISPLAYCONFIG_DEVICE_INFO_GET_ADVANCED_COLOR_INFO;
      getColorInfo.header.size = sizeof(getColorInfo);

      for (const auto& mode : modes)
      {
        if (mode.infoType == DISPLAYCONFIG_MODE_INFO_TYPE_TARGET)
        {
          getColorInfo.header.adapterId.HighPart = mode.adapterId.HighPart;
          getColorInfo.header.adapterId.LowPart = mode.adapterId.LowPart;
          getColorInfo.header.id = mode.id;
          if (ERROR_SUCCESS == DisplayConfigGetDeviceInfo(&getColorInfo.header))
          {
            if (getColorInfo.advancedColorEnabled)
              advancedColorEnabled = true;

            if (getColorInfo.advancedColorSupported)
              advancedColorSupported = true;
          }
        }
      }

      std::string txStatus;

      if (!advancedColorSupported)
      {
        status = 0;
        txStatus = ""Display not HDR capable"";
      }
      else if (advancedColorSupported && !advancedColorEnabled)
      {
        status = 1;
        txStatus = ""Display HDR capable and current HDR status is disabled"";
      }
      else if (advancedColorSupported && advancedColorEnabled)
      {
        status = 2;
        txStatus = ""Display HDR capable and current HDR status is enabled"";
      }

      // Prevents logging at application start before LOGLEVEL gets configured
      if (CServiceBroker::IsServiceManagerUp())
      {
        CLog::Log(LOGDEBUG, ""{0:s} (status = {1:d})"", txStatus, status);
      }
    }
  }

  return status;


Why is this code bad?
Why?",True,True
xbmc_____xbmc_____17106,2020-01-27T09:09:36Z,True,xbmc_____xbmc_____17106_____578654541,"And yes, if in the end are going to do things wrong I prefer someone else to do it. 
(and stay out)",True,True
xbmc_____xbmc_____17106,2020-01-27T09:16:21Z,True,xbmc_____xbmc_____17106_____578657030,"Locking this now. I wanted to give thexai a chance to respond before doing so.

Further discussion here will by the looks of it not improve things and is likely detrimental.",True,True
xbmc_____xbmc_____17106,2020-01-27T09:22:14Z,True,xbmc_____xbmc_____17106_____578659347,"I am not a Windows dev thexai, but the only thing I personally can spot that is ""wrong"" with your code above is that it uses integers instead of ENUMs as state values. We prefer ENUMs since they improve readability of the code, especially for devs not familiar with it, and the code is ofc a little less error prone.",True,True
nestjs_____typeorm_____27,2020-01-27T15:59:33Z,True,nestjs_____typeorm_____27_____578816714,"The same issue.
And I noticed a very interesting behavior of DI.
If I call console.log(service) in the constructor when the application is building I can see that the service was injected. But after when I try to call some method I get an error that the service is undefined.",True,True
iNavFlight_____inav_____4798,2020-01-30T22:29:31Z,True,iNavFlight_____inav_____4798_____580492455,"Fyi, Cylindrical geofence implementation in Arducopter:
https://ardupilot.org/copter/docs/common-ac2_simple_geofence.html",True,True
rack_____rack_____1272,2020-02-05T07:15:11Z,True,rack_____rack_____1272_____582273156,"There has been some great discussion here. Thanks everyone for their effort and passion. I am going to close this issue, because I don't think we reached a consensus.

That being said, further discussion is required, backed by concrete implementations. Specifically, I think more emphasis should be placed on HTTP/2 (and HTTP/3) and union of the semantic model when HTTP/1 is also included in the mix.

We welcome proposals for a better stream model for Rack 3.0 and we are currently considering how to make `rack.hijack` a first class citizen: https://github.com/rack/rack/issues/1550",True,True
nestjs_____typeorm_____27,2020-02-05T22:24:55Z,True,nestjs_____typeorm_____27_____582642980,"I'm having issues injecting services into the Artwork `EventSubscriber`. 

Here is my module, where I import and configure a MYSQL connection and setup the subscribers.

```ts
@Module({
  imports: [
    ConfigModule.forRoot({
      isGlobal: true
    }),
    ArtworksModule,
    TypeOrmModule.forRootAsync({
      imports: [ConfigModule],
      inject: [ConfigService],
      useFactory: async (configService: ConfigService) => {
        return <MysqlConnectionOptions>{
          type: ""mysql"",
          host: configService.get(""MYSQL_HOST""),
          port: configService.get(""MYSQL_PORT""),
          username: configService.get(""MYSQL_USERNAME""),
          password: configService.get(""MYSQL_PASSWORD""),
          database: configService.get(""MYSQL_DB""),
          entities: [Artwork],
          subscribers: [ArtworkSubscriber],
          synchronize: true
        };
      }
    })
  ],
  controllers: [AppController],
  providers: [AppService]
})
export class AppModule {}
```

Here the EventSubscriber that I created however I'm not able to inject the `ConfigService` into it. 

```ts
@Injectable()
@EventSubscriber()
export class ArtworkSubscriber implements EntitySubscriberInterface<Artwork> {

  constructor(
    @Inject(ConfigService)
    private readonly configService: ConfigService
  ) {
    console.log(configService) // undefined
  }

  listenTo() {
    return Artwork;
  }

  async afterInsert(event: InsertEvent<Artwork>) {
    console.log(this.configService.get('NODE_ENV')); // undefined
  }
}
```",True,True
openstreetmap_____iD_____7162,2020-02-06T07:29:50Z,True,openstreetmap_____iD_____7162_____582773285,"Dear @bhousel, please avoid personal attacks. It's against [Code of Conduct](https://github.com/openstreetmap/iD/blob/2.x/CODE_OF_CONDUCT.md). Thanks.",True,True
nestjs_____typeorm_____27,2020-02-06T07:56:08Z,True,nestjs_____typeorm_____27_____582780800,"@mogwai (and anyone else facing this issue), please, use this approach https://github.com/nestjs/typeorm/pull/27#issuecomment-431296683",True,True
openstreetmap_____iD_____7162,2020-02-06T12:57:21Z,True,openstreetmap_____iD_____7162_____582893781,"> Dear @bhousel, please avoid personal attacks. It's against [Code of Conduct](https://github.com/openstreetmap/iD/blob/2.x/CODE_OF_CONDUCT.md). Thanks.

@qeef If you really feel like I've made a personal attack and want to open a report, please email the OSM-US CoC team - [details here](https://www.openstreetmap.us/2019/12/osmus-code-of-conduct-committee).
",True,True
esp8266_____Arduino_____7121,2020-02-28T00:39:52Z,True,esp8266_____Arduino_____7121_____381143531,"fixes https://github.com/esp8266/Arduino/commit/2c435b1f427dfdc1567bd52ca6d966d5640d6bb9#commitcomment-37529995

Sorry for that @progtronix",True,True
esp8266_____Arduino_____7121,2020-02-28T00:39:52Z,True,esp8266_____Arduino_____7121_____572447828,"fixes https://github.com/esp8266/Arduino/commit/2c435b1f427dfdc1567bd52ca6d966d5640d6bb9#commitcomment-37529995

Sorry for that @progtronix",True,True
php_____php-src_____4934,2020-02-28T07:51:54Z,True,php_____php-src_____4934_____592393568,"Fractions are part of the original RFC3339, and are optional. Why does there need to be a separate constant for this?

Also, see [bug report][bug-79305].

[bug-79305]: https://bugs.php.net/bug.php?id=79305",True,True
php_____php-src_____4934,2020-02-28T08:00:35Z,True,php_____php-src_____4934_____592396357,"@XedinUnknown because the new constants will provide the greatest datetime precision that's possible with ISO 8601. The current ones lack fractions. The new constant's value is one that's used regularly in, for example, api responses with datetime values.",True,True
php_____php-src_____4934,2020-02-28T08:03:41Z,True,php_____php-src_____4934_____592397349,@XedinUnknown Because otherwise it will be a BC break.,True,True
php_____php-src_____4934,2020-02-28T08:42:39Z,True,php_____php-src_____4934_____592410624,What's breaking about fixing support broken support for a format?,True,True
php_____php-src_____4934,2020-02-28T09:33:25Z,True,php_____php-src_____4934_____592429720,@XedinUnknown an API may extract the result produced by your constant with some RegExp: `^\d+-\d+-\d+ \d+:\d+:\d+$` add the fraction and this extraction suddenly stop working. That's why it's safer to require the user to explicitly add the fraction by selecting the new constant.,True,True
php_____php-src_____4934,2020-02-28T09:37:31Z,True,php_____php-src_____4934_____592431315,"You won't believe it but people are using those constants for some time now and wrote code that expects the output to be of a certain format. By modifying the existing constant this expectation is broken and therefore the code is not working anymore. So changing that constant is breaking backward compatibility.

That the current constant is not doing what you expect might be due to the fact that you expect something from the constant that is not even described by the standard. The ISO standard says that you *can* add fractions, but you do not *have* to add them. So the current constant does exactly that. And if you want to use fractions you can use the new constant.  ",True,True
php_____php-src_____4934,2020-02-28T09:46:36Z,True,php_____php-src_____4934_____592434382,"The fact that you _can_ add fractions means that the standard supports fractions. And PHP claims to support the standard. In practice, however, an RFC3339-compliant timestamp that contains a fraction (i.e. is standards-compliant) cannot be parsed by PHP using the `DATE_ATOM` format, which means that support for it is broken. Fixing something that is broken does not constitute a BC break, because the specification does not change. If somebody has depended on _implementation_, instead of the specification, then they had made a mistake, and it is up to them to fix it. RFC3339 supports optional fraction, and if I made an expression that does not cater for that, then my expression does not support the RFC3339 standard. Same for the PHP `DateTime` implementation: if it does not cater for the optional fraction, then it does not support the standard. Adding support for the standard would simply fix that. It is not a BC break.",True,True
php_____php-src_____4934,2020-02-28T09:51:11Z,True,php_____php-src_____4934_____592436434,"It means your implementation is broken if you relly on the DATE_ATOM constant.  Passing an ATOM-Timestamp with fractions into `new DateTimeImmutable` works fairly well so the PHP-Implementation is not broken. But as a Constant can only hold **one** format and not contain an *either/or* along with the fact that PHP, until a certain version didn't support fractions at all, leads to the fact that we have a fraction-less Constant and (hopefully soon) a constant that contains fractions",True,True
php_____php-src_____4934,2020-02-28T09:53:38Z,True,php_____php-src_____4934_____592437443,@XedinUnknown the fact it fixes a bug (which I disagree anyway) does not mean it's not a breaking change. Applications that properly work relying the current constant format will stop working on update. That's an obvious BC.,True,True
php_____php-src_____4934,2020-02-28T09:54:43Z,True,php_____php-src_____4934_____592437901,"> Passing an ATOM-Timestamp with fractions into new DateTimeImmutable works fairly well so the PHP-Implementation is not broken

It does not, as I demonstrated in the bug report.

> But as a Constant can only hold one format and not contain an either/or

An RFC3339 timestamp with a fraction and without a fraction is _the same format_: the RFC3339 format.",True,True
php_____php-src_____4934,2020-02-28T09:56:48Z,True,php_____php-src_____4934_____592438669,"Thanks everyone, further input will not be needed at this point in time. Please let @derickr review this change.",True,True
esp8266_____Arduino_____7121,2020-03-01T11:22:31Z,True,esp8266_____Arduino_____7121_____593085731,"@devyte @d-a-v Please revert this commit ASAP, waveform testing has unstable timings (servo jitters audibly) and WDT hits periodically.",True,True
esp8266_____Arduino_____7121,2020-03-01T11:47:03Z,True,esp8266_____Arduino_____7121_____593087906,"@dok-net This commit is only the recompilation of lwIP precompiled libraries.
You can first [recompile them yourself](https://github.com/esp8266/Arduino/tree/master/tools/sdk/lwip2) and check whether timings are modified.",True,True
esp8266_____Arduino_____7121,2020-03-01T13:11:04Z,True,esp8266_____Arduino_____7121_____593095473,"Why are you telling me this? The simple fact of the matter is that 0554d39c6c054ebfe8ee7fe45fc838368519a827 works just fine, but c61b70de865531f62218541fa0f32715c153a449 doesn't. The binary diff between these commits is huge. I can't fix and verify everything, but I can manage to point out if something breaks, what's broken it. Forget about the timings in my waveform PR, but WDT'ing is serious.",True,True
esp8266_____Arduino_____7121,2020-03-01T15:07:33Z,True,esp8266_____Arduino_____7121_____593107495,"By the words I'm telling you, it is meant that
- only lwIP binaries are recompiled,
- there is no source file change,
- if you don't start network in your test,
  these binaries are not used,
- if there is a side effect on pwm or core interrupts, or anything not related with network with this commit, I have no idea why right now,
- It is a binary commit, resulting from lwIP's `make install`.
  Simply reverting such commit without understanding will bring the issue back on next lwIP's update.

Please try the `make install` yourself from https://github.com/esp8266/Arduino/commit/0554d39c6c054ebfe8ee7fe45fc838368519a827 and report if this is changing anything
  - if it's still working, then I'll have to remake them from a clean install, maybe,
  - if it does not work anymore but working again by checking out the binary files, then I'd have to be able to reproduce the issue and I'd need your help for that.",True,True
esp8266_____Arduino_____7121,2020-03-01T18:09:31Z,True,esp8266_____Arduino_____7121_____593126602,"I can't just make install, it's not working on my system. I can only repeat, I've now retested, the commit with ""blob"" doesn't WDT reset, but master HEAD as of now resets every few seconds.
",True,True
esp8266_____Arduino_____7121,2020-03-01T19:48:53Z,True,esp8266_____Arduino_____7121_____593137322,"Here's an MCVE. Download to target and hit the webserver at least once, it starts WDT resetting:
```c++
#include <ESP8266WebServer.h>
#include <core_esp8266_waveform.h>
#include <ArduinoOTA.h>
#include <Servo.h>

//const char* ssid = """";
//const char* password = """";

// Create an instance of the server
// specify the port to listen on as an argument
ESP8266WebServer server(80);

Servo servo;

// 25kHz cycle == 40µs cycle time
const uint32_t TCYCLE = 40;

uint32_t fanspeed0 = 0;
uint32_t fanspeed1 = 0;

bool ota_started = false;

void StartOTAIfRequired()
{
    if (ota_started)
        return;
    // Port defaults to 8266
    // ArduinoOTA.setPort(8266);
    // Hostname defaults to esp8266-[ChipID]
    //if (ArduinoOTA.getHostname() && ArduinoOTA.getHostname().length())

    // No authentication by default
    ArduinoOTA.setPassword(""abc"");
    ArduinoOTA.onStart([]() {
        Serial.println(""OTA Start"");
        });
    ArduinoOTA.onEnd([]() {
        Serial.println(""\nOTA End"");
        });
    ArduinoOTA.onProgress([](unsigned int progress, unsigned int total) {
        Serial.printf(""Progress: %u%%\r\n"", (progress / (total / 100)));
        });
    ArduinoOTA.onError([](ota_error_t error) {
        Serial.printf(""Error[%u]: "", error);
        if (error == OTA_AUTH_ERROR) Serial.println(""Auth Failed"");
        else if (error == OTA_BEGIN_ERROR) Serial.println(""Begin Failed"");
        else if (error == OTA_CONNECT_ERROR) Serial.println(""Connect Failed"");
        else if (error == OTA_RECEIVE_ERROR) Serial.println(""Receive Failed"");
        else if (error == OTA_END_ERROR) Serial.println(""End Failed"");
        });
    ArduinoOTA.begin();
    ota_started = true;
    delay(500);
}

void HandleOTA()
{
    StartOTAIfRequired();
    ArduinoOTA.handle();
}

// The setup() function runs once each time the micro-controller starts
void setup()
{
    Serial.begin(115200);

    WiFi.mode(WIFI_STA);
    WiFi.begin();
    Serial.println("""");

    // Wait for connection
    while (WiFi.status() != WL_CONNECTED) {
        delay(500);
        Serial.print(""."");
    }

    Serial.println("""");
    Serial.print(""IP address: "");
    Serial.println(WiFi.localIP());

    StartOTAIfRequired();

    pinMode(D3, OUTPUT_OPEN_DRAIN);
    digitalWrite(D3, HIGH);
    pinMode(D7, OUTPUT_OPEN_DRAIN);
    digitalWrite(D7, HIGH);

    servo.attach(D8, 1000, 2000);

    uint32_t duty = 1 + (TCYCLE - 2) * fanspeed0 / 100;
    startWaveform(D3, duty, TCYCLE - duty, 0);
    duty = 1 + (TCYCLE - 2) * fanspeed1 / 100;
    startWaveform(D7, duty, TCYCLE - duty, 0);
    servo.write(90);

    server.on(""/"", []() {
        String content = """";
        content += ""<html><body>\
            Hello</body></html>"";
        server.send(200, ""text/html"", content.c_str());
        delay(100);
        });

    server.begin();
    Serial.println(""HTTP server started"");

    tone(D5, 440, 500);
}

// Add the main program code into the continuous loop() function
void loop()
{
    HandleOTA();
    // Listen for http requests
    server.handleClient();
}
````",True,True
esp8266_____Arduino_____7121,2020-03-01T20:20:24Z,True,esp8266_____Arduino_____7121_____593140465,"Note that I had to `WiFi.begin(STASSID, STAPSK)` for wifi to connect, then I got this:
```shell
$ while true; do curl 10.0.1.101; echo;echo ""another request:""; done
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
another request:
<html><body>            Hello</body></html>
...
```
ESP is still running fine:
```
21:10:56.697 -> SDK:2.2.2-dev(38a443e)/Core:2.6.3-86-gc61b70de=20603086/lwIP:STABLE-2_1_2_RELEASE/glue:1.2-30-g92add50/BearSSL:5c771be
21:10:56.697 -> scandone
21:10:56.697 -> 
21:10:56.829 -> scandone
21:10:56.829 -> state: 0 -> 2 (b0)
21:10:56.829 -> state: 2 -> 3 (0)
21:10:56.829 -> state: 3 -> 5 (10)
21:10:56.829 -> add 0
21:10:56.829 -> aid 1
21:10:56.829 -> cnt 
21:10:56.862 -> 
21:10:56.862 -> connected with xx, channel nn
21:10:56.862 -> dhcp client start...
21:10:56.862 -> ip:10.0.1.101,mask:255.255.255.0,gw:10.0.1.254
21:10:57.194 -> .
21:10:57.194 -> IP address: 10.0.1.101
21:10:57.724 -> HTTP server started
21:11:06.843 -> pm open,type:2 0
```

That being weird, I suggest you try with another git master cloned from scratch.
May I suggest you to try [beta releases](https://d-a-v.github.io) ?",True,True
esp8266_____Arduino_____7121,2020-03-02T15:41:39Z,True,esp8266_____Arduino_____7121_____593465400,"An `rm -rf *; git checkout -- .` shall suffice.
About the diagnostic output you pasted, that's not on USB serial, right?",True,True
esp8266_____Arduino_____7121,2020-03-02T15:44:32Z,True,esp8266_____Arduino_____7121_____593466913,"Glad you sorted this out.
The above output is the arduino console on USB serial (wemos d1), with timestamp enabled.",True,True
esp8266_____Arduino_____7121,2020-03-02T15:54:26Z,True,esp8266_____Arduino_____7121_____593472141,"No idea what ""with timestamp enabled"" means :-(
I think there's a misunderstand, I was just reporting my latest step, I didn't imply that the WDT problem is gone. In fact, right now, my MCVE without the latest master commit works, but with the lwip2 commits, it keeps crashing. It's definitely something in those lib binaries.",True,True
esp8266_____Arduino_____7121,2020-03-02T16:03:13Z,True,esp8266_____Arduino_____7121_____593476672,"All it takes to make my MCVE work well s to revert the *.a, tcp_priv.h, and lwip-git-hash.h files.",True,True
esp8266_____Arduino_____7121,2020-03-02T16:10:49Z,True,esp8266_____Arduino_____7121_____593480639,"> > About the diagnostic output you pasted, that's not on USB serial, right?

> No idea what ""with timestamp enabled"" means :-(

That was USB Serial. Timestamp is added by arduino console. The output is your sketch's.
(*edit*: with debug on serial enabled, if that's worth to be mentioned)

> > An rm -rf *; git checkout -- . shall suffice.

> I think there's a misunderstand, I was just reporting my latest step, I didn't imply that the WDT problem is gone.

Sorry for the misunderstanding. 
I hereby ask someone else to try your MCVE to confirm in either way.
The beta release has the same library as git master and the one I have on my PC
```shell
$ md5sum liblwip2-536-feat.a
f27b0c56379610ffc24a92a0e3f8aad7  liblwip2-536-feat.a
```

> All it takes to make my MCVE work well s to revert the *.a, tcp_priv.h, and lwip-git-hash.h files.

I understand that.
That's why I wonder whether I am alone to be able to make git master working with lwIP.",True,True
esp8266_____Arduino_____7121,2020-03-02T17:27:59Z,True,esp8266_____Arduino_____7121_____593519012,"@dok-net 
Which version of lwIP do you select ?
I may not have tested with the same version as the one you're using.
The one above is ""v2 / lower memory / with features / no IPv6"".",True,True
esp8266_____Arduino_____7121,2020-03-02T17:42:04Z,True,esp8266_____Arduino_____7121_____593525535,"`lwIP Variant: v2 Lower Memory`
",True,True
esp8266_____Arduino_____7121,2020-03-02T17:51:28Z,True,esp8266_____Arduino_____7121_____593529916,"Just very short test durations (1-2min), the one with IPv6 seems to be better.",True,True
esp8266_____Arduino_____7121,2020-03-02T17:58:46Z,True,esp8266_____Arduino_____7121_____593533358,"Also tested `v2 Lower Memory (no features)`, no WDT resets within 1-2min after flashing.
But, `v2 Higher Bandwidth`, and  `v2 Lower Memory` (the default?):
```
ets Jan  8 2013,rst cause:4, boot mode:(3,6)

wdt reset
load 0x4010f000, len 3456, room 16 
tail 0
chksum 0x84
csum 0x84
v3e56b42b
~ld
```",True,True
esp8266_____Arduino_____7121,2020-03-02T18:01:46Z,True,esp8266_____Arduino_____7121_____593534764,"Can you give the md5 sum of your liblwip2-536-feat.a ? 
It is ""v2 Lower Memory (the default)"".",True,True
esp8266_____Arduino_____7121,2020-03-02T18:05:44Z,True,esp8266_____Arduino_____7121_____593536769,"For the `liblwip2-536-feat.a`, same as yours above.
Please remember, I am reporting a regression against my waveform branch here - merging with master - latest commit stuff works, if I merge the HEAD commit of master, the WDT resets occur. You will likely not see the issue without the whatever extra stress the waveform lib produces.
One thing that seems unrelated, I cannot OTA update currently with master.",True,True
esp8266_____Arduino_____7121,2020-03-02T18:09:47Z,True,esp8266_____Arduino_____7121_____593538848,"For what it's worth, these are the options:
Upload Speed: 921600
CPU Frequency: 80 MHz
Flash Size: 4MB (FS:1MB OTA:~1019KB)
Debug port: Disabled
Debug Level: None
lwIP Variant: v2 Lower Memory
VTables: Flash
Exceptions: Legacy (new can return nullptr)
Erase Flash: Only Sketch
SSL Support: All SSL ciphers (most compatible)",True,True
esp8266_____Arduino_____7121,2020-03-02T18:19:14Z,True,esp8266_____Arduino_____7121_____593543459,"> You will likely not see the issue without the whatever extra stress the waveform lib produces.

This is the +19th message after your first one to learn that
- you did ***not*** test your MCVE against master
- you have issues with an unmerged PR
- you never insisted on that information after ***I*** successfully tested your MCVE on master and tried to understand ***your*** concern that nobody else has.

I would be glad to know where I missed this capital information in the above messages.

This is a merged PR.
Please open a new issue with ***all*** the needed informations to understand ***your*** specifics.

",True,True
GTNewHorizons_____GT5-Unofficial_____256,2020-03-26T12:11:38Z,True,GTNewHorizons_____GT5-Unofficial_____256_____588374039,"need write in class MultiBlock  ""checkRecipe""

` if (tRecipe.mSpecialValue == -200 && (mCleanroom == null || mCleanroom.mEfficiency == 0)) return false;`",True,True
Exiv2_____exiv2_____1009,2020-03-28T16:39:20Z,True,Exiv2_____exiv2_____1009_____605486039,"@sridharb1 I've totally lost the plot on this.  This PR is conflicted with the current state of branch `0.27-maintenance` due to changes in `src/canonmn_int.cpp`.  It is also likely that this PR (and associate branch  `fix1008_Sony2010e `) could ""bloat"" the repository with the file with the CRLF conflicts.

Can we start again, please?  Can you open a new issue with the changes and I will submit a new PR.  I am closing this PR.  I would also like to delete the branch `fix1008_Sony2010e`",True,True
ppy_____osu_____8483,2020-03-28T16:42:50Z,True,ppy_____osu_____8483_____395120971,"This proposal suggests adding pp to maps that contains high movement velocity variance stream section because, it is harder to adjust both the speed to the aiming part and the tapping part to synchronize with the map.

**Current code repo:** https://github.com/kornkaobat/osu

**Original issue on pp git:** https://github.com/ppy/osu-performance/issues/108

**Some examples pp log ( Will do more in the upcoming days );**

[Idke's pp log](https://github.com/ppy/osu/files/4397455/message.32.txt)

[Karthy's pp log](https://github.com/ppy/osu/files/4397456/message.33.txt)

",True,True
ppy_____osu_____8483,2020-03-28T16:46:11Z,True,ppy_____osu_____8483_____605486894,Codefactor's _Complex method_ is not fixable so I'll be ignoring that.,True,True
ppy_____osu_____8483,2020-03-28T16:47:03Z,True,ppy_____osu_____8483_____399683203,We do not put spaces before parentheses. Please adhere to our code style and run style inspection using the provided `InspectCode.ps1` script.,True,False
ppy_____osu_____8483,2020-03-28T16:47:31Z,True,ppy_____osu_____8483_____399683240,what are these magic constants? any explanation whatsoever?,True,False
ppy_____osu_____8483,2020-03-28T16:48:35Z,True,ppy_____osu_____8483_____399683372,Commented code is not permitted. It should be uncommented or removed.,True,False
ppy_____osu_____8483,2020-03-28T16:49:54Z,True,ppy_____osu_____8483_____399683547,[This is literally still copied from stackoverflow](https://stackoverflow.com/a/3141731/6817321) (_literally_ the first result when googling the comments). Using online resources is fine but at least trim the comments since they have no value here. The mathematical concept of standard deviation is pretty widely known.,True,False
ppy_____osu_____8483,2020-03-28T16:50:22Z,True,ppy_____osu_____8483_____399683585,This conditional is way too complex to remain in its current state.,True,False
ppy_____osu_____8483,2020-03-28T16:51:06Z,True,ppy_____osu_____8483_____399683659,Why is there `JumpDistances` and `JumpDistances2`? Why are they public? xmldoc please.,True,False
ppy_____osu_____8483,2020-03-28T16:56:51Z,True,ppy_____osu_____8483_____399684290,Can you suggest another way to condition that?,True,False
ppy_____osu_____8483,2020-03-28T16:57:23Z,True,ppy_____osu_____8483_____399684329,"Ok, will remove comments.",True,False
ppy_____osu_____8483,2020-03-28T16:59:17Z,True,ppy_____osu_____8483_____399684570,"I don't really even have the slightest clue what this is *attempting* to do without a proper explanation, so not currently, no. Factoring out a separate method might be good to start with.",True,False
ppy_____osu_____8483,2020-03-28T17:01:41Z,True,ppy_____osu_____8483_____399684800,"Will change to private, were public because I need to move variable across files but now it is unnecessary. I'll also explain using comments too.",True,False
ppy_____osu_____8483,2020-03-28T17:10:55Z,True,ppy_____osu_____8483_____605490263,"Oh, and to be entirely clear: I did not even *begin* to consider the *gameplay* implications of this diffcalc change as I'm not fit to do so (not a high-level player, no knowledge or strong opinions about ""what's good"" and what isn't). Resolving the *code* issues above does not guarantee this will get merged, it's just a bare minimum so that it can be even *considered* for merge.

From what I can see from the diffcalc discord and reddit threads linked there this will probably not be met with the approval of the community at large.",True,True
ppy_____osu_____8483,2020-03-28T17:12:34Z,True,ppy_____osu_____8483_____605490490,I'll fix code structural problems first. Community approval will need a lot of explaining.,True,True
ppy_____osu_____8483,2020-03-28T17:29:44Z,True,ppy_____osu_____8483_____399687734,Fixed in e11de4b.,True,False
ppy_____osu_____8483,2020-03-28T17:30:02Z,True,ppy_____osu_____8483_____399687765,Fixed in e11de4b.,True,False
ppy_____osu_____8483,2020-03-28T17:38:20Z,True,ppy_____osu_____8483_____399688650,Not entirely. [I still see some commented code.](https://github.com/ppy/osu/blob/e11de4b2f373c6a85910c2d289a64d1b76f7f78a/osu.Game.Rulesets.Osu/Difficulty/Skills/Speed.cs#L90-L96),True,False
devkitPro_____pacman-packages_____131,2020-03-29T00:10:51Z,True,devkitPro_____pacman-packages_____131_____589685478,This will make libcurl work with ftp urls,True,True
ppy_____osu_____8483,2020-03-29T05:17:55Z,True,ppy_____osu_____8483_____399747116,Fixed in 0cb6464.,True,False
ppy_____osu_____8483,2020-03-29T05:18:24Z,True,ppy_____osu_____8483_____399747146,Fixed in 0cb6464.,True,False
ppy_____osu_____8483,2020-03-29T05:22:44Z,True,ppy_____osu_____8483_____605561117,3 green.,True,True
ppy_____osu_____8483,2020-03-29T05:46:42Z,True,ppy_____osu_____8483_____399749440,"On this particular file it is not needed, already removed in 0cb6464.",True,False
ppy_____osu_____8483,2020-03-29T05:49:16Z,True,ppy_____osu_____8483_____605573701,I can't run the code right now due to repo conflict. Will test-run once it is fixed.,True,True
ppy_____osu_____8483,2020-03-29T05:59:33Z,True,ppy_____osu_____8483_____605587882,"Fixed repo confilct, everything is greenlit and ready for merge.",True,True
Exiv2_____exiv2_____1009,2020-03-29T06:16:34Z,True,Exiv2_____exiv2_____1009_____605589038,"Ok, we will start again. I will hunt down those fixes for sony2010e (remember that there is 2010a-f, I think and I implemented only 2010e because I had an NEX-6 that identified itself as this subset). I say this to just note that the catching up to exiftool is significantly inadequate. But, at least, we are better off than before.

I am going to make these fixes in my fork of 0.27-maintenance. I am hoping that you can pull these into the main branch.",True,True
Exiv2_____exiv2_____1009,2020-03-29T07:29:05Z,True,Exiv2_____exiv2_____1009_____605597660,I have pushed my sony2010e changes to my 0.27-maintenance branch. Could you please pick them up?,True,True
ppy_____osu_____8483,2020-03-29T09:59:24Z,True,ppy_____osu_____8483_____399774009,Fixed in 55eaa82.,True,False
ppy_____osu_____8483,2020-03-29T10:10:06Z,True,ppy_____osu_____8483_____399775174,It is designed to seperate jumps from streams overall (the sectionvelocity > 0.9 part is for seperating streams into really hard streams) for further calculation.,True,False
Exiv2_____exiv2_____1009,2020-03-29T12:06:50Z,True,Exiv2_____exiv2_____1009_____605626127,"@sridharb1 I don't have the git skills to know how to ""pick them up"".  I believe it's possible for you to submit a PR from https://github.com/sridharb1/exiv2 to https://github.com/exiv2/exiv2

Team: Could one of you help @sridharb1 to get this done, please? 

This card keeps me out of git hell and is my my total knowledge of git:
![GitIdiotCard](https://user-images.githubusercontent.com/529982/77848618-f1572800-71bd-11ea-84ae-4d799c55e76c.jpg)
",True,True
ppy_____osu_____8483,2020-03-29T13:12:21Z,True,ppy_____osu_____8483_____399795984,"Okay, so here's probably one of the core issues of this whole rework. You choose an arbitrary constant based on *one* beatmap. Why this one? What does it have to do with difficulty in particular? Why are other maps not taken into account?

What you seem to want to do is to monkey-patch the existing system to get pp to be more in line with what you consider best. I think a more holistic approach to the *entire* difficulty system might be better.",True,False
ppy_____osu_____8483,2020-03-29T13:13:12Z,True,ppy_____osu_____8483_____399796114,"These xmldocs are useless, they tell me nothing more than the variable name itself. Don't restate things in xmldoc.",True,True
ppy_____osu_____8483,2020-03-29T13:13:47Z,True,ppy_____osu_____8483_____399796191,I don't understand what this is trying to say. It's still inscrutable.,True,True
ppy_____osu_____8483,2020-03-29T13:14:28Z,True,ppy_____osu_____8483_____399796298,"This xmldoc both restates the variable name, is entirely unreadable, and does not explain the simultaneous existence of `jumpDistances` and `jumpDistances2`.",True,False
ppy_____osu_____8483,2020-03-29T13:15:37Z,True,ppy_____osu_____8483_____399796415,"So many questions here. *How* does it separate? What's the methodology here? Why were the thresholds chosen the way they were?

In other words, how is anyone supposed to change this code in a month or a year, without reverse engineering it all themselves?",True,False
Exiv2_____exiv2_____1009,2020-03-29T13:37:20Z,True,Exiv2_____exiv2_____1009_____605636873,"[As a preface, it is best to note that my git skills are pretty limited as well.]

I think it is best if you keep this PR closed as this conflates two changes that I did during that period.

One was the sony2010e, which we are trying to merge now. The other was the canon lens and camera sync with exiftool. The latter caused the unfortunate line-ending issues. I would keep the latter separate.

I tried merging my fork with the base, but unfortunately, it pulls in some changes that I had to do to get CMake past some hurdles in my machine, which are probably inappropriate for distribution. Realistically, these are the types of problems that I face with CMake, but they will not be acknowledged because some platforms and ways of doing things are irrelevant.

So, I will create a branch that has only those (sony2010e) and create a clean pull request for you.",True,True
Exiv2_____exiv2_____1009,2020-03-29T14:20:07Z,True,Exiv2_____exiv2_____1009_____605643670,"OK.  I'm going to close this and delete the branch from GitHub.

I'm sorry to hear that CMake is causing you distress.  How about you get your code changes ready on your machine and we work together using your `contrib/msvc` build environment.

Please get a clean/fresh copy of the code.  Don't mix your current ball of stuff with ours.
I suggest that you work in the repos https://github.com/exiv2/exiv2 and sync up to the latest 0.27-maintenance code which includes `contrib/msvc`.  Then create a branch on your machine.

```
$ cd ..../where/you/work
$ git clone https://github.com/exiv2/exiv2 --branch 0.27-maintenance 0.27-maintenance --depth 1
$ cd 0.27-maintenance
$ git fetch --unshallow
$ git checkout -b sridharb1_sony2010e_0.27   # or CanonExifToolLensChanges (or something)
```

Build it with contrib/msvc/exiv2.sln.  Then we'll talk again.

Let's start with the smallest/simplest patch you'd like to prepare.  Together, we can do this.

------------------

For my own information, I've looked at the changes in #1009:
```
$ curl https://patch-diff.githubusercontent.com/raw/Exiv2/exiv2/pull/1009.patch > ~/temp/1009.patch
583 rmills@rmillsmbp:~/gnu/github/exiv2/0.27-maintenance $ git apply ~/temp/1009.patch 
/Users/rmills/temp/1009.patch:99: trailing whitespace.
	
/Users/rmills/temp/1009.patch:2348: trailing whitespace.
// ***************************************************************** -*- C++ -*-
/Users/rmills/temp/1009.patch:2349: trailing whitespace.
/*
/Users/rmills/temp/1009.patch:2350: trailing whitespace.
 * Copyright (C) 2004-2018 Exiv2 authors
/Users/rmills/temp/1009.patch:2351: trailing whitespace.
 * This program is part of the Exiv2 distribution.
error: patch failed: test/data/exiv2-test.out:1890
error: test/data/exiv2-test.out: patch does not apply
error: patch failed: tests/bugfixes/redmine/test_issue_1252.py:16
error: tests/bugfixes/redmine/test_issue_1252.py: patch does not apply
error: patch failed: src/canonmn_int.cpp:118
error: src/canonmn_int.cpp: patch does not apply
error: patch failed: tests/bugfixes/github/test_issue_981.py:6
error: tests/bugfixes/github/test_issue_981.py: patch does not apply
584 rmills@rmillsmbp:~/gnu/github/exiv2/0.27-maintenance $ 
```
Inside the patch, there are changes to 20 files.
```
$ grep -e ""--- a/"" ~/temp/1009.patch 
--- a/src/image.cpp
--- a/src/makernote_int.cpp
...
--- a/tests/bugfixes/github/test_issue_981.py
$
```
",True,True
Exiv2_____exiv2_____1009,2020-03-29T14:36:53Z,True,Exiv2_____exiv2_____1009_____605646436,"That's fine.

However, there is no need to mix two things here. My changes for compiling with VS can be kept separate from my feature of supporting the sony2010 tag.

I am currently working on getting you a clean pull request for sony2010.

I will look into the VS project files afterward.",True,True
ppy_____osu_____8483,2020-03-29T15:00:50Z,True,ppy_____osu_____8483_____399809541,Do you want a white paper like Bitcoin White Paper?,True,False
ppy_____osu_____8483,2020-03-29T15:02:28Z,True,ppy_____osu_____8483_____399809718,"I think someone might confuse the 1,2 number iterations trust me, I'll leave it there.",True,False
ppy_____osu_____8483,2020-03-29T15:05:00Z,True,ppy_____osu_____8483_____399810062,"Okay, that is the ceiling value for the speed which seperates spaced streams from jumps. Excors last stream section has the fastest spaced stream section near the end so I based this value on that. If you've seen faster spaced stream tell me so that I can fix it.",True,False
ppy_____osu_____8483,2020-03-29T15:05:48Z,True,ppy_____osu_____8483_____399810158,I'll only buff fast velocity with positive acceleration streams.,True,False
ppy_____osu_____8483,2020-03-29T15:06:22Z,True,ppy_____osu_____8483_____399810197,"> I'll only buff fast velocity with positive acceleration streams.

That is the reason for code complexity as well.",True,False
ppy_____osu_____8483,2020-03-29T15:07:26Z,True,ppy_____osu_____8483_____399810329,Do you want me to change the names?,True,False
ppy_____osu_____8483,2020-03-29T15:12:19Z,True,ppy_____osu_____8483_____399810985,"```
return ((1 + (speedBonus - 1) * 0.75) * angleBonus * (0.95 + speedBonus * Math.Pow(distance / single_spacing_threshold, 3.5)) / osuCurrent.StrainTime) + Math.Max(0, sdstrainmult);
```
... **+ Math.Max(0, sdstrainmult);**",True,False
Exiv2_____exiv2_____1009,2020-03-29T15:16:31Z,True,Exiv2_____exiv2_____1009_____605652450,I have done this now. Please see #1126 and bring it into 0.27-maintenance. This does have two small fixes to image.cpp that are good for the distribution as well.,True,True
ppy_____osu_____8483,2020-03-29T15:19:51Z,True,ppy_____osu_____8483_____399811992,"...How is your comment helping? You've pasted in a long formula without explanation. I'd like to know *specific details of why this formula was chosen*. In a *human-readable* and *human-understandable* manner.

Please understand that this code has **zero** chance of getting merged if nobody else will be able to understand it afterwards.",True,False
ppy_____osu_____8483,2020-03-29T15:21:43Z,True,ppy_____osu_____8483_____399812233,"That'd be a good first step, yes. Having names of the sort `variable` and `variable2` is one of the very basic examples of bad programming practice. Variable naming should be as descriptive as possible.",True,False
ppy_____osu_____8483,2020-03-29T15:27:12Z,True,ppy_____osu_____8483_____399812940,"- osuCurrent.JumpDistance < 150 **=> Excors 9 star(s) Last stream**

- sectionvelocity < streamaimconst **=> Excors 9 star(s) Last stream**

- sectionvelocity > 0.9 **=> Packet Hero [Ruthless] nerf on slow acceleration changing stream**

- Previous.Count > 0 && osuCurrent.Angle != null **=> Initial checks if angle measurement possible or not.**

- osuCurrent.Angle.Value >= Math.PI / 2 **=> Streams must have angle greater that 90 degrees. ( Suggested by abraker )**

- osuCurrent.StrainTime < 100 ( Equivalent to 150 bpm streams-ish (Not exact due to Beat Snap Divisor ) **=> Consensus threshold for stream and jump seperation**

The full methodology and my work history is on Discord.",True,False
ppy_____osu_____8483,2020-03-29T15:29:45Z,True,ppy_____osu_____8483_____399813267,"> Excors last stream section has the fastest spaced stream section near the end so I based this value on that.

And this is the whole issue - you're not supposed to rework the whole system based on what happens in *one* specific map. What happens if someone ranks a map with much more spaced streams? Do we have to change this value every single time the 'fastest ranked stream' changes?

A proper PP rework needs to be based on explainable formulas, with their potential effects on PP changes carefully studied for all kinds of maps.

Seeing the discussion which took place in the #difficulty-osu Discord channel, these changes were developed by taking a few hard maps from top ranks of high-level players and throwing around random solutions that happened to work on those specific maps. 

There were situations where values had to be adjusted to fit expectations on *one* specific map (or even play) and I think that shows best why it's a fundamentally flawed approach - you have to take *all* kinds of maps and plays into account, both very easy and very hard, plus everything inbetween, having a reason for every single change and making sure that it will work universally, not just for a very specific set of beatmaps.",True,False
ppy_____osu_____8483,2020-03-29T15:30:43Z,True,ppy_____osu_____8483_____399813411,Yeah this explanation makes me opposed to this being merged at all ever. It's mostly based on seemingly random examples to nerf/buff specific maps as you see fit.,True,False
ppy_____osu_____8483,2020-03-29T15:36:16Z,True,ppy_____osu_____8483_____399814136,"Pay for my cellular data, **tell me how to use osu-tools to aggregate data from data.ppy.sh** and I'll do that for you.",True,False
ppy_____osu_____8483,2020-03-29T15:37:47Z,True,ppy_____osu_____8483_____399814335,$2.31/4GB of data,True,False
ppy_____osu_____8483,2020-03-29T15:47:19Z,True,ppy_____osu_____8483_____399815564,"And no, I'm not being salty or sarcastic here, I've literally paid about $50 for data due to development reasons.",True,False
ppy_____osu_____8483,2020-03-29T16:07:14Z,True,ppy_____osu_____8483_____399818146,"So let me get this straight, you made a proposal (unlike the already increasing amount of ideas) which uses arbitrary values, that would be alright if not for some evaluation and a lot of evidence. You used one [specific beatmap](https://osu.ppy.sh/beatmapsets/375201#osu/821785) just for spaced streams, which is loved and, yes there are other beatmaps that could have larger spaced streams. 
Also, your comeback to WildTree is a bit absurd, you requested the contributors to pay you $183 for a download of all of the osu tar files? That does sound like you were expecting everyone to help you out? They are just here to check over and see if it's good enough quality to be in the game. Well about that..

After checking the issues that are brought up, I'm guessing you're just a beginner at developing with osu! and tried your way to merge it into osu!lazer? (You were supposed to pull request on osu-performance), The whole system developed right now is supposed to be complicated, it has to have a flexible threshold just in case you have out-there maps that you didn't account for. 
You could have used a distance spacing threshold that depended on the bpm or density of the entire song/section.  Or a more complex method that I wouldn't have thought of. But right now, the tree is nowhere NEAR merge-able due to the incoherent equations/code (otherwise known as spaghetti code which is not a good thing), inadequate evidence to show your proposal actually working, multiple rookie mistakes along the way and some others. ",True,True
ppy_____osu_____8542,2020-04-01T11:46:26Z,True,ppy_____osu_____8542_____591853058,Fixes #7607.,True,True
expressjs_____session_____708,2020-04-17T00:26:15Z,True,expressjs_____session_____708_____409923719,"This is destroying the session, not the session store",True,True
expressjs_____session_____708,2020-04-17T00:26:33Z,True,expressjs_____session_____708_____409923772,"this destroys the session, not the store",True,True
expressjs_____session_____708,2020-04-17T00:27:49Z,True,expressjs_____session_____708_____409924176,"this should probably be placed in conjunction with the saving log, as the session can be saved from many different places",True,True
bisq-network_____bisq_____4191,2020-04-23T07:38:07Z,True,bisq-network_____bisq_____4191_____605310703,"Official project URL: https://an.gold
Official block explorer URL: https://etherscan.io/token/0x130914E1B240a7F4c5D460B7d3a2Fd3846b576fa",True,True
sveltejs_____community_____178,2020-04-24T17:03:40Z,True,sveltejs_____community_____178_____606457358,Adds a folder to gather links and logos for a _Who's using Sapper_ section as described in https://github.com/sveltejs/sapper/issues/1113,True,True
opencv_____opencv_____17185,2020-04-29T10:29:11Z,True,opencv_____opencv_____17185_____410624326,"**Merge with extra:** opencv/opencv_extra#753
resolves: #17148 

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under OpenCV (BSD) License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or other license that is incompatible with OpenCV
- [ ] The PR is proposed to proper branch
- [ ] There is reference to original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake


```
force_builders=Custom,Custom Win,Custom Mac
build_image:Custom=ubuntu-openvino-2020.1.0:16.04
build_image:Custom Win=openvino-2020.2.0
build_image:Custom Mac=openvino-2020.2.0

test_modules:Custom=dnn,python2,python3,java
test_modules:Custom Win=dnn,python2,python3,java
test_modules:Custom Mac=dnn,python2,python3,java

buildworker:Custom=linux-1
# disabled due high memory usage: test_opencl:Custom=ON
test_opencl:Custom=OFF
test_bigdata:Custom=1
test_filter:Custom=*
```
**Performance tests**
**CPU:** Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz
| CPU         | Backend | Before   | After    |
|-------------|---------|----------|----------|
| Yolov3      | nGraph  | 331.91   | 331.48   |
| Yolov3      | OpenCV  | 17210.52 | 14720.49 |
| TinyYoloVOC | nGraph  | 36.32    | 36.37    |
| TinyYoloVOC | OpenCV  | 1938.97  | 1661.04  |
| YoloVOC     | nGraph  | 130.95   | 130.56   |
| YoloVOC     | OpenCV  | 7917.9   | 6774.20  |
| YOLOv4      | nGraph  |     -    | 2795.87  |
| Yolov4      | OpenCV  |     -    | 14422.20 |",True,True
opencv_____opencv_____17185,2020-04-29T14:13:01Z,True,opencv_____opencv_____17185_____621237642,"Can you please describe what ""before"" and ""after"" means?",True,True
opencv_____opencv_____17185,2020-04-29T14:14:10Z,True,opencv_____opencv_____17185_____621238397,"> Yolov3 | OpenCV | 17210.52 | 14720.49

Have you used `perf_dnn` for  bahcnmarking? Seems incorrect for me

",True,True
opencv_____opencv_____17185,2020-04-29T14:16:13Z,True,opencv_____opencv_____17185_____417349670,What is the source of this new parameter?,True,True
opencv_____opencv_____17185,2020-04-29T14:24:19Z,True,opencv_____opencv_____17185_____621244860,"> Can you please describe what ""before"" and ""after"" means?

“Before” means the results of running performance tests before this PR changes (without Yolov4 support)",True,True
opencv_____opencv_____17185,2020-04-29T14:24:58Z,True,opencv_____opencv_____17185_____621245296,"> > Yolov3 | OpenCV | 17210.52 | 14720.49
> 
> Have you used `perf_dnn` for bahcnmarking? Seems incorrect for me

Yes, I used `perf_dnn`",True,True
opencv_____opencv_____17185,2020-04-29T14:26:50Z,True,opencv_____opencv_____17185_____417358075,"Maybe better
```cpp
float x_tmp = (logistic_activate(srcData[box_index + 0]) - 0.5f) * scale_x_y + 0.5f;
```",True,True
opencv_____opencv_____17185,2020-04-29T14:40:27Z,True,opencv_____opencv_____17185_____417369015,https://github.com/AlexeyAB/darknet/blob/36c73c5b9e3f2e72049fb68566e32632f6c70e85/src/activations.c#L150,True,True
opencv_____opencv_____17185,2020-04-30T10:07:55Z,True,opencv_____opencv_____17185_____417900291,Do we still need threshold or can revert layer?,True,True
opencv_____opencv_____17185,2020-04-30T18:56:04Z,True,opencv_____opencv_____17185_____622039526,Great to see that this is in the 3.4.11 milestone. Will this reach the 4.x branch as well?,True,True
opencv_____opencv_____17185,2020-05-01T08:53:43Z,True,opencv_____opencv_____17185_____622307080,"Thank you for your interest @rgov, @wooseokyourself! These PR changes will be merged into master branch next week.
",True,True
opencv_____opencv_____17185,2020-05-01T14:42:10Z,True,opencv_____opencv_____17185_____622415663,"Hi @l-bat , Can I know how to inference on video using OpenCV(cv2.dnn). I'm getting below error when trying to load. Please help with this. I'm using yolov4.cfg. 
`---------------------------------------------------------------------------
error                                     Traceback (most recent call last)
error: OpenCV(4.2.0) /io/opencv/modules/dnn/src/darknet/darknet_io.cpp:686: error: (-212:Parsing error) Unsupported activation: mish in function 'ReadDarknetFromCfgStream'


The above exception was the direct cause of the following exception:

SystemError                               Traceback (most recent call last)
<ipython-input-1-704183f19471> in <module>()
      1 import cv2 as cv
      2 
----> 3 net = cv.dnn_DetectionModel('/datadrive/INTERN/darknet/yolov4-custom.cfg', '/datadrive/INTERN/darknet/backup/yolov4-custom_6000.weights')
      4 net.setInputSize(416, 416)
      5 net.setInputScale(1.0 / 255)

SystemError: <class 'cv2.dnn_DetectionModel'> returned a result with an error set`  



`---------------------------------------------------------------------------
error                                     Traceback (most recent call last)
<ipython-input-3-716457c5e28a> in <module>()
     24 
     25 # Define network from configuration file and load the weights from the given weights file
---> 26 net = cv2.dnn.readNet(args['weights'],args['config'])
     27 
     28 

error: OpenCV(4.2.0) /io/opencv/modules/dnn/src/darknet/darknet_io.cpp:686: error: (-212:Parsing error) Unsupported activation: mish in function 'ReadDarknetFromCfgStream'`",True,True
opencv_____opencv_____17185,2020-05-01T14:47:43Z,True,opencv_____opencv_____17185_____622417729,"@sqiprasanna, please read all the messages carefully - you're trying to use OpenCV 4.2.0. We just merged the changes yesterday. ",True,True
opencv_____opencv_____17185,2020-05-01T16:01:34Z,True,opencv_____opencv_____17185_____622447778,"@l-bat @dkurt 
Is Yolov4 more than 2 times slower than Yolov3 due to MISH-activation?",True,True
opencv_____opencv_____17185,2020-05-01T16:24:31Z,True,opencv_____opencv_____17185_____622457028,"@l-bat Thanks for the reply. I just used this yolov4 for training on my custom dataset. It really worked well on detecting images. I'm more excited to test this model on real-time detection using OpenCV. As I see here you're trying to include yolov4 in OpenCV dnn. I just want to really appreciate the work you've done and would like to see adding yolov4 into OpenCV. 

Thank you again for your hard work. Have a nice day.

",True,True
opencv_____opencv_____17185,2020-05-01T17:49:31Z,True,opencv_____opencv_____17185_____622490787,"@AlexeyAB, it might be, yes. I'd like to recommend to open an issue for YOLOv4 optimization (some research with per-layer performance will be very helpful). Thanks!",True,True
opencv_____opencv_____17185,2020-05-12T14:41:14Z,True,opencv_____opencv_____17185_____423789333,"`MISH_THRESHOLD` is simply a cutoff for switching from a numerically unstable expression to a numerically stable expression in softplus.

The current OpenCV implementation which is `x * tanh(log(1 + exp(x)))` is numerically unstable. This implementation goes to zero when x is more negative than `-16`. Using `std::log1p` instead of `std::log(1 + std::exp(x))` might improve the numerical accuracy but this will still suffer as numbers become even more negative.

Darknet has been using `log(1 + exp(x))` and it seems to be very inaccurate (same implementation as OCV CPU in the range `[-20, 20]`) for numbers smaller than `-2`. I have dumped the values [here](https://gist.github.com/YashasSamaga/3fdf001d32f04062e3f36495d5c962db) comparing darknet with [other numerically more accurate implementations](https://cs.stackexchange.com/questions/125002/fast-and-stable-x-tanhlog1pexpx-computation).

If I remember correctly, the dynamic range of activations in YOLOv4 seems to cover the range ~`[-12000, 2000]` for a bunch of random 10 natural images. The middle 50% is covered in ~`[-100, 100]`.

Both Darknet and OpenCV CPU are giving really good results with their implementations. I don't know if there is a need to have a numerically stable implementation. But just for record sake, I have made a reply here.",True,True
opencv_____opencv_____17185,2020-05-13T12:45:52Z,True,opencv_____opencv_____17185_____424407745,"Now we use such Mish-implementation  https://github.com/AlexeyAB/darknet/issues/5452#issuecomment-627414024
```cpp
 __device__ float mish_yashas(float x) 
 { 
     float e = __expf(x); 
     if (x <= -18.0f) 
         return x * e; 
  
     float n = e * e + 2 * e; 
     if (x <= -5.0f) 
         return x * __fdividef(n, n + 2); 
  
     return x - 2 * __fdividef(x, n + 2); 
 } 
```
And get:
* +3% speedup
* the same accuracy on MSCOCO (testdev) yolov4.cfg 512x512 - 43.0% AP, 64.9% AP50
```
overall performance
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.649
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.243
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.542
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
Done (t=506.74s)
```",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-15T17:05:41Z,True,coding-blocks_____shortlr2-backend_____167_____418704019,"The following documents are missing and should be added to validate the open source project and structure a community.

- [x] Pull Request Template
- [x] Issue Template
- [x] Contributing Guidelines
- [x] Code Of conduct

Fixes #166",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-15T17:06:47Z,True,coding-blocks_____shortlr2-backend_____167_____629374780,"Warnings are found on analyzing the commit 846958d1346507c72cc980768746ab1c2706ea1c.

**1** warning:
- ⚠️ [TSLint](https://sider.review/gh/repos/155214828/pulls/167/logs/f72c65b3-c122-4637-8894-0992cda99b92)

We recommend to address them as possible, for example, update outdated dependencies, fix the tool's configuration, [configure `sider.yml`](https://help.sider.review/getting-started/custom-configuration), [turn off unused tools](https://help.sider.review/getting-started/repository-settings), and so on.

If you are struggling with these errors or warnings, feel free to ask us via chat. 💬",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-15T17:10:38Z,True,coding-blocks_____shortlr2-backend_____167_____629376433,"> Warnings are found on analyzing the commit [846958d](https://github.com/coding-blocks/shortlr2-backend/commit/846958d1346507c72cc980768746ab1c2706ea1c).
> 
> **1** warning:
> 
> * warning [TSLint](https://sider.review/gh/repos/155214828/pulls/167/logs/f72c65b3-c122-4637-8894-0992cda99b92)
> 
> We recommend to address them as possible, for example, update outdated dependencies, fix the tool's configuration, [configure `sider.yml`](https://help.sider.review/getting-started/custom-configuration), [turn off unused tools](https://help.sider.review/getting-started/repository-settings), and so on.
> 
> If you are struggling with these errors or warnings, feel free to ask us via chat.

error not triggered by PR, cause by existing file",True,True
TFPatches_____TotalFreedomMod_____197,2020-05-17T02:02:55Z,True,TFPatches_____TotalFreedomMod_____197_____419048756,,True,True
TFPatches_____TotalFreedomMod_____197,2020-05-17T02:04:10Z,True,TFPatches_____TotalFreedomMod_____197_____629731524,shut the fuck up ajax nobody asked you,True,True
TFPatches_____TotalFreedomMod_____197,2020-05-17T02:04:20Z,True,TFPatches_____TotalFreedomMod_____197_____629731537,fuck video,True,True
google_____styleguide_____428,2020-05-21T00:07:03Z,True,google_____styleguide_____428_____631801604,"The purpose of this commit is to avoid potential problems associated with BOMs, since they have been known to halt some script interpreters and compilers in their tracks.

Personally speaking, I have never experienced any problems by omitting the BOM.  But I write/code primarily in English.  If non-English writing/coding doesn't necessitate a BOM then it seems that the appropriate option would be to forgo its use, by default.",True,True
google_____styleguide_____428,2020-05-21T01:27:36Z,True,google_____styleguide_____428_____631824103,"This doesn't really seem worth stipulating; the [BOM has no meaning for UTF-8](https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8):

> The Unicode Standard permits the BOM in UTF-8,[3] but does not require or recommend its use.[4] Byte order has no meaning in UTF-8,[5] so its only use in UTF-8 is to signal at the start that the text stream is encoded in UTF-8, or that it was converted to UTF-8 from a stream that contained an optional BOM. The standard also does not recommend removing a BOM when it is there, so that round-tripping between encodings does not lose information, and so that code that relies on it continues to work.

What's the motivation for calling this out? Interpreters that don't handle BOMs sound like they aren't properly implementing the UTF-8 spec and should be fixed.",True,True
google_____styleguide_____428,2020-05-21T03:40:23Z,True,google_____styleguide_____428_____631860307,"The reason is that back-compatibility with ASCII is a major benefit of UTF-8.

For instance a Windows `.bat`/batch file saved as UTF-8 + BOM will crash when run because the command interpreter doesn't understand the BOM (ie. `∩╗┐`) prefix -- It's just garbage, which also displays in some text editors; which could easily confuse one as to whether to let this _mysterious garbage_ persist, or should they remove it?

The following Unicode laced `.bat` file, saved as UTF-8, will work properly only when saved _**without**_ a BOM:
```
echo ""☺ Ł"" >textfile.txt
```

As the standard itself states, it neither requires nor recommends the use of a BOM, with UTF-8.

The so-called ""round-tripping"" scenario is really only appropriate when dealing with (pre-existing / external) text files, input into a program --not to the (Google) source code to be executed.

So ideally one shouldn't erase existing BOMs, willy-nilly, because they may be processed by another system which, against the standard's recommendation, expects their presence.  However, when fresh source files are created, the BOM is probably best avoided, in accordance with the Unicode/UTF-8 recommendation.

It follows the programming principle: ""Be liberal in what you accept and conservative in what you send.""

",True,True
google_____styleguide_____428,2020-05-21T06:40:48Z,True,google_____styleguide_____428_____631914027,"I don't think this is worth adding. As you say, the UTF-8 spec already discourages using a BOM when feasible, and I don't see any reason why it being a Java source file introduces further complexity that merits calling this out in the style guide. I'm not certain I've ever even seen a UTF-8 file with a BOM...",True,True
google_____styleguide_____428,2020-05-21T12:30:45Z,True,google_____styleguide_____428_____632059493,"If it's worth stating that the file should be in UTF-8 format then it's worth mentioning the avoidance of a BOM.

But that's just my little ol' opinion.",True,True
opencv_____opencv_____17185,2020-05-21T14:08:13Z,True,opencv_____opencv_____17185_____632106733,"Hello,
I had understood that yolov4 was already working on version 3.4.10, but I tried and got the error:

`cv2.error: OpenCV(3.4.10) /opencv-3.4.10/modules/dnn/src/darknet/darknet_io.cpp:821: error: (-212:Parsing error) Unsupported activation: mish in function 'ReadDarknetFromCfgStream'`

I'm buildin OpenCV 3.4.10 from source on a docker container. I'm cloning this repository:
https://github.com/Itseez/opencv/archive/3.4.10.zip

I'm not very familiar with this, so can someone please give me a simple answer like ""It's not working yet"" or ""It's already working, you can git clone this link"", instead of referencing another one confused thread.",True,True
google_____styleguide_____428,2020-05-21T16:30:55Z,True,google_____styleguide_____428_____632193162,"![utf-8_bom](https://user-images.githubusercontent.com/7102064/82581650-bdf1a380-9b45-11ea-8d43-d772c79befde.png)
[ What if my editor is dumb and pre-checks the BOM box, for UTF-8 files, or just includes it without giving me any option? ]",True,True
opencv_____opencv_____17185,2020-05-21T17:16:13Z,True,opencv_____opencv_____17185_____632233374,"It's not working yet, wait for the next release or get latest _master_ or _3.4_ branch version and build it manually.",True,True
google_____styleguide_____428,2020-05-21T20:45:44Z,True,google_____styleguide_____428_____632336170,"It's not the goal of the Java Style Guide to address all possible configuration issues; we require Java source code to be UTF-8 for numerous reasons, but the presence or absence of a BOM is not something we need to make a ruling on. Leave it off when possible, as the UTF-8 spec already says.",True,True
google_____styleguide_____428,2020-05-21T21:11:52Z,True,google_____styleguide_____428_____632348444,"So as long as everyone reads through at least the first 39 pages of the Unicode standard then there shouldn't be any problem.  Why would anyone even consider using `.BAT` files to automate Java code compilation or execution?  I'm such an idiot.  I'm so sorry for wasting your precious time with a totally realistic scenario; and providing examples to support it.

Meanwhile, you've provided zero evidence to support your claim, which is based solely on your personal experience.  The Wikipedia snippet, a somewhat pathetic and non-authoritative source, in all honesty, actually supports my argument.

If I ever make a contribution to Google I will be sure to include that BOM.

It's no wonder that even Google's own engineers could care less about the company's style guides.

And here I'd thought that Google workers were above mansplaining.  Stupid me.",True,True
google_____styleguide_____428,2020-05-22T01:02:15Z,True,google_____styleguide_____428_____632421578,"Hi veganaize, first, let me say thank you for sending this PR; I should have done so in an earlier comment. Rejecting the PR is in no way a statement about you, nor your qualifications. Although it's true that Google's public style guides are under-curated (a situation we all lament, but no one has stepped up to address) we care very deeply about the contents of our style guides, and therefore are very conservative in what we add to it. My intent here was to bring closure to this issue, since it had unfortunately sat unaddressed for some time.

You are absolutely right that there are situations where a BOM can matter, and it is reasonable to discourage their use. In our experience at Google this has not been a major issue (admittedly, most internal development happens on Linux, so issues related to `.bat` scripting are indeed something we don't typically run into). Looking into historical internal discussions around BOMs affecting Google Java developers I can find very little, and nothing related to BOMs in the `.java` source files themselves. None of which invalidates your concern, but in our opinion it doesn't rise to a level of severity to merit calling out in the Style Guide. Many best practices are intentionally not included in the guide simply because we don't want to make a ruling we don't have to. We trust teams to identify their own best practices where we don't make stipulations.

Of note, this doesn't appear to be a Java-specific issue, and I notice only the HTML/CSS guide makes any mention of it. Perhaps we should consistently discourage BOMs across all our style guides, but I don't believe it's necessary to make the Java guide an outlier in this regard.

> If I ever make a contribution to Google I will be sure to include that BOM.

I would ask that you do so with good-faith, but *please do* include a BOM if you believe it is relevant. We put a lot of faith in our tooling, and count on developers both internally and externally to help catch places where our tooling falls short. If a BOM breaks something we rely on, we will want to fix it. You might even [get paid](https://www.google.com/about/appsecurity/reward-program/) if you are able to find an exploit related to mishandling of BOMs.

> And here I'd thought that Google workers were above mansplaining. Stupid me.

One of the things I have deeply, deeply valued about my time at Google has been the candid and open discussions around issues of identity, gender inequality, and respect. We continue to fall short in many ways, but I am proud of the effort my peers have made to create a culture that is welcoming and inclusive. I don't believe anything I've said could fairly be labeled mansplaining, but I am sorry that I was curt. Again, thank you for raising this issue.",True,True
hacs_____integration_____1227,2020-05-22T20:10:03Z,True,hacs_____integration_____1227_____422121290,"Due to popular? opinion I'm making this PR to bring back the old UI.
![image](https://user-images.githubusercontent.com/15093472/82704510-fdb7a880-9c75-11ea-951c-06a7c48041af.png)

This will also bring back all the issues it was with that UI, and I will only do bugfixes from this point in the UI, you can still add feature requests but I will not be adding them.

The reasons I changed it in the first place:
- It was falling behind HA, in how it felt to use and I wanted to bring it closer.
- It has performance issues, and those will continue to grow with each new repository that is added.
- The codebase are hard to maintain, there are elements all over the place that somehow ties together.

There has been a great number of feature requests added for the new UI, I will pause the work on them until this is decided.

closes #1226, closes #1225, closes #1224, closes #1223, closes #1219, closes #1218, closes #1216, closes #1213, closes #1212, closes #1210, closes #1208, closes #1196, closes #1193, closes #1189, closes #1188, closes #1185, closes #1183

Frankly, I'm just too tired with all the negativity...

So add your votes on this description:
👍 Merge this.
👎 Keep working on the new UI.",True,True
hacs_____integration_____1227,2020-05-22T20:33:46Z,True,hacs_____integration_____1227_____632898841,"Please keep working on the new UI, specially because of performance, just what is installed needs to be solved.
",True,True
hacs_____integration_____1227,2020-05-22T21:13:23Z,True,hacs_____integration_____1227_____632910803,"i think the new will be good - just some ideas that needed more sorting
There was nothing publish to say problems with old ui
It may have been better to post this updated UI as a release candidate   and let people get more used to it
It was pushed as a release that did the original functions better - internally this is true but interface looked like it was missing a lot of functionality but in fact it good but needs a little tweaking  and for us to get heads around a new way of doing things  

I am getting more used to it 

well done on doing the code but a slower release would have put  the dreaded users in a more accepting mindset  ",True,True
hacs_____integration_____1227,2020-05-22T22:25:23Z,True,hacs_____integration_____1227_____632931668,"Theres stuff about the new one I don't like (no table view, new repos not grouped, Plugins and Themes should be seperate) but I would never have started a thread to bitch about it. There's only one way to go and that is forward, not back.",True,True
hacs_____integration_____1227,2020-05-22T22:41:24Z,True,hacs_____integration_____1227_____632934898,"While i understand that performance and reasonable code mus be prioritized, the new UI was more difficult to use and less feature-rich IMHO, no matter how it moves forward, new or old. I really hope the liste of installed custom components is kept.",True,True
hacs_____integration_____1227,2020-05-23T05:38:36Z,True,hacs_____integration_____1227_____632989271,"The new UI is really hard to use, I don't know where anything is or what to do.
Is it possible for users to choose? The old version was much more intuitive.

I know this might be hard to hear but maybe do beta testing of the new UI and when it is as easy to use as the old UI switch over. It's just very polorizing atm.

My screen was full of repos, I didn't know what was mine and what wasn't, i didn't know how to add to lovelace or install new repos",True,True
hacs_____integration_____1227,2020-05-23T08:04:22Z,True,hacs_____integration_____1227_____633004366,"There is some real good stuff about the new one, so as others say, move forward and add some requests. What I personally liked about the old is that you could see the entire repository abs discover new things. With the limit to 100 and not setting new things, we have to discover new features in another way. 

Thumbs up for the great work! HACS makes life so much easier!!",True,True
hacs_____integration_____1227,2020-05-23T08:28:35Z,True,hacs_____integration_____1227_____633006909,"Hell no Ludeeus, keep going forward. Please do not revert

Also please do not entertain the idea of having both layouts and the user choose which to use, you know this will still have the issues described above and just create additional effort from you.
",True,True
hacs_____integration_____1227,2020-05-23T09:07:48Z,True,hacs_____integration_____1227_____633011368,"I think that the new UI was not yet ready to go replace the main one, but since its already there, instead of reverting it, its better to focus on fixing its usability.
The new UI is genuinely prettier than the old one, the only problems is in its ergonomics, but since you say that the new UI codebase is way easier to maintain, it should be a big struggle to fix the issues people are having. ",True,True
hacs_____integration_____1227,2020-05-23T12:16:20Z,True,hacs_____integration_____1227_____633041016,"how the hell do i downgrade back ?
lost ability to downgrade an installed component   <<   gigantic miss ??
UI glitch problems where the page can't decide between 4 or 5 columns, i have seen my screen shift between the 2 constantly for no reason
when i install a component, it does not tell me to add it to lovelace, HOLY SHIT, this is a HUGE required - i don`t know why someone would scrap that.",True,True
hacs_____integration_____1227,2020-05-23T12:26:17Z,True,hacs_____integration_____1227_____633043097,"> how the hell do i downgrade back ?
> lost ability to downgrade an installed component << gigantic miss ??
> UI glitch problems where the page can't decide between 4 or 5 columns, i have seen my screen shift between the 2 constantly for no reason
> when i install a component, it does not tell me to add it to lovelace, HOLY SHIT, this is a HUGE required - i don`t know why someone would scrap that.

Apart from being ungrateful, maybe take time to learn how to use it before whining.
You dont need to know how to add to lovelace, it does it for you, add a card, go to lovelace dashboards, resources. look its there. magic hey?

go back to another version of, uninstall, install, select version. - easy

downgrade - HACS, maybe uninstall it and walk away

",True,True
hacs_____integration_____1227,2020-05-23T16:44:28Z,True,hacs_____integration_____1227_____633091799,"I've changed my mind. I was going to say go back but after reading your post above I now think there's room for continued improvement with the new UI instead.

It was a lot easier to browse integrations and plugins with the previous version. And I liked the separation between installed and new. The new UI seems to waste a lot of space. A nice compact view is important when browsing.

The new version does seem to be more responsive though. Well done. ",True,True
hacs_____integration_____1227,2020-05-23T18:24:20Z,True,hacs_____integration_____1227_____633111392,"The new UI is so much faster. I thought it got faster on my lenovo tiny so I went checking on my Rpi backup and it was even more noticeable on it. 

Definitely stick with the new, improve from there and never look back. ",True,True
hacs_____integration_____1227,2020-05-23T20:15:11Z,True,hacs_____integration_____1227_____633131340,"I am going to disagree with the majority of the above posts, and say that you should revert back to the old way as an interim step. 

Stop development on the old interface by all means, but it should be put back as soon as possible so that you don't lose the goodwill of the many 1000s of users while you sort out the issues with it. 
I will not disagree that it has its flaws and an update is required, but, being blunt, you went about it the wrong way. 
There was no warning, there is no feature parity and it felt like it was forced because most users of your tool have got used to seeing updates which do not affect how it works in such a fundamental way, and have therefore just got used to doing the updates as they are offered. 
The timing also didn't help, as it coincided with the recent release of HA 110 which required most of the components stored within HACS to be updated and therefore a lot of people who might not have updated immediately, did so because it was just part of the list and felt that it would be required to ensure support with HA 110. 

You also probably should realise the key part that HACS now plays within the wider HA ecosystem. For a significant number of users it is the only way that non-standard components are added to their HA install, and for developers of those components it is the only way they get any visibility or significant numbers of users, with the chance that their component will be pulled in to the main product. To quote a famous film - ""With great power comes great responsibility"" - any changes you make to the tool will have a significant impact on a lot of users. 

Therefore I would suggest that you do something similar to this.

1. Revert back to the old interface, stating quite clearly that development of it has stopped unless a show stopper/security bug is found. 
If you really do not want to do that, then provide details on how to revert manually. 
2. Start an open BETA program of the new interface, with the primary aim to get feature parity before a 1.0 release. If you want to introduce new functionality, do it after you have got feature parity of the old version. 
3. When you are ready to release the new version, have a period of dual running, so that those who were not on the BETA can test it and you can iron out any last minute issues. Then switch the code. 

That should keep most people happy, rescue a situation which has caused a lot of upset within the HA community and allow you to move in the direction that you wish to. ",True,True
hacs_____integration_____1227,2020-05-23T23:52:32Z,True,hacs_____integration_____1227_____633155421,"> it felt like it was forced because most users of your tool have got used to seeing updates which do not affect how it works in such a fundamental way, and have therefore just got used to doing the updates as they are offered.

Nobody was forced into doing anything. If someone blindly updated HACS without reading, that's entirely their fault. The [release notes](https://github.com/hacs/integration/releases/tag/1.0.0) had a screenshot of the brand new UI and literally the first two bullet points were ""Brand new UI!"" and ""Breaking changes!""

Did you not even notice that the version number jumped from 0.24.5 all the way up to 1.0.0? It should be obvious just from that alone to expect major changes.

Things are rarely ever 100% perfect on the first revision, but people like @GeorgeSG are providing detailed and constructive feedback in a positive way. That's far more helpful than asking for it to be reverted.

",True,True
hacs_____integration_____1227,2020-05-24T00:36:28Z,True,hacs_____integration_____1227_____633159553,"I love these comments of being forced, nobody forced you, you clicked update/upgrade, you nobody else. Instead of blindly updating without even checking anything and that applies to HA also, you only have yourself to blame.
",True,True
hacs_____integration_____1227,2020-05-24T01:09:33Z,True,hacs_____integration_____1227_____633162057,"We need to stop this blame game. It's not helpful to anyone.

There are people who are passionate for keeping the change and people who are passionate for reverting. Each view should be respected and people allowed to have their own opinion.

I think ultimately in the long run we have to keep with the new UI, but in the mean time I believe things need to change.

Educating people is the way to resolve this in my opinion.

I believe if we are keeping the new UI we need to have a ""first launch"" screen.
This screen will be displayed one time when people load to tell them about the changes and help them answer FAQ.

Eg you do not need to click add to lovelace anymore frontend changes are automatically added to the lovelace configuration.

Then we can go on to improving the new UI to 'fix' things that are missing.

- I think there should be a separate tab for custom repositories that way we can easily add or remove additional repositories. I find it's currently to hidden under the three dots at the top right.
- The old version gave you an indication when you were installing repos that something was happening, now you just get a blank screen.
- In the future you could look at adding views as I find the cards are too big, in the old version they were much smaller.

I can understand the goal is to make it look as consistent as possible with the rest of the UI, so we're on the right track just need to work on refining things.

Keep up the good work!
 ",True,True
hacs_____integration_____1227,2020-05-24T01:30:07Z,True,hacs_____integration_____1227_____633163585,"> We need to stop this blame game. It's not helpful to anyone.

The fact that the dev was feeling beaten down enough to consider reverting - begs to differ.
If you don't like it then offer constructive feedback.
The dev is not your bitch and he does not owe you anything. Try being grateful.",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T02:58:59Z,True,coding-blocks_____shortlr2-backend_____167_____633170683,"Hi @YashKumarVerma 

You have been making this generic PR of adding github templates across all our repos. 

So let me take this up at here in one place. 

1. not all projects need this. not all projects even need all four of these. CoC for org is enough, copying everywhere isn't needed
2. are you doing this for getting just some more bounties ? please do not do that. you wrote an email to me accusing others of doing the same, and here I see you doing this
3. writing points like `Lint and unit tests pass locally with my changes` in a project that has neither linter nor tests setup in the checklist.... what for ? 

Can we keep our focus on code that 

1. fixes bugs
2. adds features
3. improves coding standards
4. improves architecture of project
5. adds tests

anything else, administrative work, please leave it to us mentors to do. does that make sense ? ",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T06:59:37Z,True,coding-blocks_____shortlr2-backend_____167_____633189273,"@championswimmer 

Thanks for pointing out and mentioning on the discord server.
It would be helpful for me to correct/update the place where I did the following. If you could specifically point where, i can fix it. I'm sorry but I'm facing issues in searching for it.
> 3. writing points like `Lint and unit tests pass locally with my changes` in a project that has neither linter nor tests setup in the checklist.... what for ?",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T07:35:22Z,True,coding-blocks_____shortlr2-backend_____167_____633192562,"Do you not even read your own PR before making it? This very PR has a checklist that contains that point. 

What kind of irresponsible behaviour is this to make PRs whose contents you have no idea of. ",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T07:35:46Z,True,coding-blocks_____shortlr2-backend_____167_____429608542,Here @YashKumarVerma ,True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T07:49:14Z,True,coding-blocks_____shortlr2-backend_____167_____633193719,"> Do you not even read your own PR before making it? This very PR has a checklist that contains that point.
> 
> What kind of irresponsible behaviour is this to make PRs whose contents you have no idea of.

Thank you for the **polite** reply. Really appreciate it.

> writing points like Lint and unit tests pass locally with my changes in a project that has neither linter nor tests setup in the checklist.... what for ?

![image](https://user-images.githubusercontent.com/14032427/82748582-dcaf9e80-9dc0-11ea-8021-0b1847efa0bc.png)

I'd like to draw attention towards https://github.com/coding-blocks/shortlr2-backend/blob/master/package.json#L32 which has something along the same lines @championswimmer 
",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T07:49:31Z,True,coding-blocks_____shortlr2-backend_____167_____429609518,more context provided as comment,True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T08:11:16Z,True,coding-blocks_____shortlr2-backend_____167_____633195869,"Listen @YashKumarVerma if you want to get into a sarcasm match, feel free to go ahead. I will love to participate. I love Twitter/Github battles. It improves my vocabulary and conversation skills. 

Coming to real business. 

- Regarding this PR.
  - Ok my bad, linter is setup, but having a checklist point in the PR makes no sense when Sider will tell me if there are lint errors anyway. If someone marks that checkbox as done, even if lint fails, then ? If someone forgets marking it done, even if lint is passing then ? 
Also everytime you run the project locally, `lint:fix` already runs, so it is kinda hard to make a PR without lint passing isn't it ? 
  - tests are *NOT* really set up here. one test for one function in a 50 file project, with no coverage over the middlewares and controllers, and no e2e test setup at all isn't called ""tests are setup"" so that checkbox makes no sense
  - `Any dependent changes have been merged and published in downstream modules` Are there other submodules does this repo have that we need to merge changes into ? 

- In general, as I have already said, please do not think that going to every repo and doing administrative tasks is the easiest way to gain points. It is sad that you especially, among other participants (who has so much prior OSS experience) is making this about collecting points rather than focussing on doing some real work. for tasks like adding codecov integration, those accesses anyway are with mentors and they only can do it. also mentors are best to decide at what stage (scale, size) of project it starts making sense to have travis build each pr or codecov to auto comment on the PRs. 


 ",True,True
hacs_____integration_____1227,2020-05-24T10:02:23Z,True,hacs_____integration_____1227_____633207375,"Thanks for all the feedback.
With a 10/42 split, I'm closing this and will start implementing feature requests with the new UI.

If you have ideas not covered with the current pool of feature requests please open them.",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T10:41:25Z,True,coding-blocks_____shortlr2-backend_____167_____633211546,"### Follow a Code of Conduct
 
> Listen @YashKumarVerma if you want to get into a sarcasm match, feel free to go ahead. I will love to participate. I love Twitter/Github battles. It improves my vocabulary and conversation skills.

Sir, all I said was a simple think you for your choice of words, and you're accusing me of sarcasm. Yes, that was sarcasm, because I won't resort to harsh words, as you being my senior and language like this not something that people expect from open source maintainers. 

> Do you not even read your own PR before making it? This very PR has a checklist that contains that point.
> What kind of irresponsible behavior is this to make PRs whose contents you have no idea of.

especially when it was you who made a mistake there. I very respectfully made a valid point. What followed was an act of frustration. 

---

> Coming to real business.
> 
> * Regarding this PR.
>   
>   * Ok my bad, linter is setup, but having a checklist point in the PR makes no sense when Sider will tell me if there are lint errors anyway. If someone marks that checkbox as done, even if lint fails, then? If someone forgets marking it done, even if lint is passing then?

Exactly my point. 
I thought to add it might be a good thing, but it appears that it was not a good idea at all. Third-party integrations would surely point them out in the sidebar. I agree with it.

Regarding tests, yes currently the project does not have extensive tests written, I'm sure it would be done in the near future. Putting those checkboxes there was indeed a wrong attempt, same is the case with the modules line. 

This was expected in the first place instead of `Do you....have no idea of`. If you think this is not to be done, simply saying that it's admin decision and close it. But since it wasn't done that way, I need to reply to the statements made.

> * In general, as I have already said, please do not think that going to every repo and doing administrative tasks is the easiest way to gain points. It is sad that you especially, among other participants (who has so much prior OSS experience) is making this about collecting points rather than focussing on doing some real work. for tasks like adding codecov integration, those accesses anyway are with mentors and they only can do it. also mentors are best to decide at what stage (scale, size) of project it starts making sense to have travis build each pr or codecov to auto comment on the PRs.

+1 to it, but here's my opinion on it.

Sir I am not here to argue with you regarding whether this must be done by a non-admin or not. Neither am I requesting you to reopen this, nor to consider the changes or claiming for points. All these issues / prs were opened about 9-10 days back within a span of few minutes, about the changes that I thought can be implemented. 

There was no message or instruction that similar things are not to be done, (if there was, I'm sorry I must have mistakenly skipped it) so I opened these. My belief regarding this was, even if admins need to grant permissions and install 3rd party applications, someone needs to write the scripts for
it. I was maybe wrong at it. 

---

Now as far as BOSS is concerned, Have a look at this. https://github.com/coding-blocks/boss/issues/created_by/YashKumarVerma. These were again opened with the same date as this pr. 
![image](https://user-images.githubusercontent.com/14032427/82750551-96f9d280-9dce-11ea-9100-0f8f1472d986.png)
Bounty was linked to only one issue, meanwhile, I sent PRs for all of them. 
People who are working on only issues marked for competition are not doing it for bounty, but if someone is sending PRs for issues not tagged for boss, they're doing it for bounty only. It's a bit confusing.

---
### Rejecting valid contribution in the sight of BOSS
On a side note, please do not consider that everything that's done is done for the competition as was done here: https://github.com/coding-blocks/oneauth/pull/994
Was this PR valid?
- Yes, .gitkeep files should be removed if the directory is not empty. Done in [Laravel](https://github.com/laravel/laravel/pull/4008)
Your reply was
> let's not make PRs just for the sake of BOSS bounties. work on productive things please.
So apparently we must overlook the minor issues.

You have all the rights to say so when I do things that don't actually improve the project, but you also know that those files are no longer required. Still? Did I ask for bounty points? No. But there have been similar cases, https://github.com/coding-blocks/boss/pull/303#issuecomment-630332641
- Can you mention a similar case when I asked for points?
- Can you mention any case when I made a claim in the portal?

---

Moving on, a few suggestions if you wish 
- be respectful.
- value every contribution, not everyone comes to OSS to write features and fix bugs.
- make users clearly mention in their PRs if it's for BOSS or not, else you'll keep rejecting valid changes.
- when complaints are raised, instead of trying to target the raiser, try to fix the issues raised. 
",True,True
coding-blocks_____shortlr2-backend_____167,2020-05-24T16:05:09Z,True,coding-blocks_____shortlr2-backend_____167_____633252874,"> I'm sorry but I'm facing issues in searching for it. 

> Thank you for the **polite** reply. Really appreciate it. 
>> (emphasis on polite)

I think I need a Code of Conduct against snarky comments like this 😅

But since we do not have a code of conduct yet for this project, let me happily go ahead and drop a meme to close this discussion 

![](https://thumbs.gfycat.com/TerrificThankfulAmericanbadger-size_restricted.gif)
",True,True
yogstation13_____Yogstation_____8689,2020-05-25T14:02:26Z,True,yogstation13_____Yogstation_____8689_____422767360,"### Intent of your Pull Request

Personally I don't think that making it so anyone who has the game on in the background doesn't get counted for hours is a good idea, although mostly because back in the day that's how lowpop was handled. However, I see the merits when applied to cases where a lot of admins are on at once, and people join and just sit around doing nothing.

Either way, if you're going to apply this policy it should be applied equally :)

#### Changelog

:cl:  
tweak: Admin tracking now doesn't count AFK for all staff rather than just retmins
/:cl:
",True,True
yogstation13_____Yogstation_____8690,2020-05-25T14:14:26Z,True,yogstation13_____Yogstation_____8690_____422772627,"Alternative to #8689.

Some admins might AFK on the server while doing something else, but still handle tickets. Best solution might be to only do this if there are 2 or more admins online. /shrug
",True,True
yogstation13_____Yogstation_____8689,2020-05-25T14:14:47Z,True,yogstation13_____Yogstation_____8689_____633592585,I'll make it a council vote. ,True,True
yogstation13_____Yogstation_____8690,2020-05-25T14:18:19Z,True,yogstation13_____Yogstation_____8690_____633594185,"I think doing it once you get to 3 admins online is probably the sweet spot, since in my experience that's when people start joining to farm hours without doing anything",True,True
yogstation13_____Yogstation_____8690,2020-05-25T14:19:13Z,True,yogstation13_____Yogstation_____8690_____633594520,"Maybe we should make phantom tickets appear at that admincount, and not count the admin if they don't respond to their phantom tickets?
",True,True
yogstation13_____Yogstation_____8690,2020-05-25T14:22:21Z,True,yogstation13_____Yogstation_____8690_____633595840,Made it a council vote. ,True,True
yogstation13_____Yogstation_____8691,2020-05-25T14:31:48Z,True,yogstation13_____Yogstation_____8691_____422780421,"Alternative to #8690 and #8689.

Will not count staff time when afk if there are 3 or more admins online (including the afk admin themselves). This applies to all staff, not only retmin.

#### Changelog

:cl:  
tweak: Staff tracking no longer tracks your time if you are AFK while there are other admins on the server.
/:cl:
",True,True
yogstation13_____Yogstation_____8691,2020-05-25T14:36:04Z,True,yogstation13_____Yogstation_____8691_____633601602,@monster860 How does it not? The admin check is only for logging out,True,True
yogstation13_____Yogstation_____8691,2020-05-25T14:37:17Z,True,yogstation13_____Yogstation_____8691_____633602106,Council vote. ,True,True
yogstation13_____Yogstation_____8691,2020-05-25T14:37:45Z,True,yogstation13_____Yogstation_____8691_____633602313,"Also would like input if I should include afk admins to the total admin count

EDIT:
Added this for now, tell me if you don't like it",True,True
yogstation13_____Yogstation_____8690,2020-05-25T14:53:06Z,True,yogstation13_____Yogstation_____8690_____633608715,"No politics in my codebase, locking PR, drama goes outside my codebase.",True,True
yogstation13_____Yogstation_____8689,2020-05-25T14:53:27Z,True,yogstation13_____Yogstation_____8689_____633608876,"No politics in my codebase, locking PR, drama goes outside my codebase.",True,True
yogstation13_____Yogstation_____8691,2020-05-25T14:53:44Z,True,yogstation13_____Yogstation_____8691_____633608985,"No politics in my codebase, locking PR, drama goes outside my codebase.",True,True
raspberrypi_____linux_____3635,2020-05-26T02:31:14Z,True,raspberrypi_____linux_____3635_____422954865,"**Multi core for RPI4**
Missing configuration for the kernel to support multi core scheduling in its configuration file.

**Desktop Timing for RPI3**
Default RPI 3 config sets ticks to 1000hz which is around a server configuration and not one that would be useful for a desktop (and honestly, I think 1000 ticks is much to high for ARM). Setting to 250hz (Default for Desktop kernel ticks).",True,True
raspberrypi_____linux_____3635,2020-05-26T08:51:33Z,True,raspberrypi_____linux_____3635_____633896492,"These appear to be two entirely unrelated changes, so should be in two PR's.

I suspect the tick change would be unacceptable anyway, but other would need to comment more fully.",True,True
raspberrypi_____linux_____3635,2020-05-26T08:55:54Z,True,raspberrypi_____linux_____3635_____633898811,I want to see an explanation of the changes and why they should be made for all users.,True,True
raspberrypi_____linux_____3635,2020-05-26T23:20:39Z,True,raspberrypi_____linux_____3635_____634330977,"> These appear to be two entirely unrelated changes, so should be in two PR's.
> 
> I suspect the tick change would be unacceptable anyway, but other would need to comment more fully.

Sorry for the two-being-one. First time doing a pull-request, and im generally new to using github. So I apologize for that.



> I want to see an explanation of the changes and why they should be made for all users.

The scheduler is used for the kernel to better use the CPU cores in a multi core system. Basically the Kernel is able to better control what-goes-where on the CPU cores, along with have better control of locks/runs/schedules/ticks/etc.

Also all other RPI Configurations has this option enable, while RPI4 did not. So its also for general consistency around the kernel builds, along with performance gains for many threaded tasks.

For reducing the ticks. Having less ticks per kernel task switch basically allows better multi-tasking and general system responsiveness. Unlike a Server which generally is left alone to do its own bidding, a desktop is more chaotic as users do many different things. As such allowing the kernel to switch tasks more often will allow better multi-tasking capabilities for the kernel.

also this is the default kernel option for all other builds for RPI variants",True,True
opencv_____opencv_____17185,2020-05-27T08:23:38Z,True,opencv_____opencv_____17185_____634508606,"Hi,
Any date for the next release ? 

Thanks",True,True
raspberrypi_____linux_____3635,2020-05-28T04:29:40Z,True,raspberrypi_____linux_____3635_____635092446,This is very interesting. Should these changes also be applied to the other branches as well?,True,True
raspberrypi_____linux_____3635,2020-05-28T09:38:32Z,True,raspberrypi_____linux_____3635_____635233682,"CONFIG_SCHED_MC was considered many years ago (https://github.com/raspberrypi/linux/issues/1221) and decided against. @P33M thought it was unlikely to benefit a single cluster of 4 cores with shared L2 cache.

@IComplainInComments you'll need to provide some test shows a benefit from the option. Find a benchmark or workflow that shows a measurable improvement with the change.",True,True
raspberrypi_____linux_____3635,2020-05-28T09:45:04Z,True,raspberrypi_____linux_____3635_____635236942,"Things may have changed in scheduler land since then, meaning CONFIG_SCHED_MC may now enable other enhancements - or add more side-effects.

I'd be happy to change my mind if there's evidence that this config option provides a net benefit, though.",True,True
raspberrypi_____linux_____3635,2020-05-29T20:13:05Z,True,raspberrypi_____linux_____3635_____636171433,"> CONFIG_SCHED_MC was considered many years ago (#1221) and decided against. @P33M thought it was unlikely to benefit a single cluster of 4 cores with shared L2 cache.
> 
> @IComplainInComments you'll need to provide some test shows a benefit from the option. Find a benchmark or workflow that shows a measurable improvement with the change.

Searching the internet, I honestly cannot find any sort of numbers or tests to give any indication of performance increase or reduction. 

The texts I have found is multiple articles insisting on using that option so the CPU governors can consolidate threads to manage heat/power better to allow less heat to be generated --  which would indicate better overclocking potential, along with heavy loads less likely to throttle the CPU, and obviously less heat == longer life.

The next benefit from my search is that option also allows the kernel to better manage threads and Work Units on a Multicore CPU. So it allows the kernel to better utilize the multiple cores for programs, increasing processing efficiency.

Here are some of the pages I found talking about the config option (indirectly or directly).
https://developer.ibm.com/technologies/linux/tutorials/l-cpufreq-1/
https://www.geeksforgeeks.org/multiple-processor-scheduling-in-operating-system/
https://elinux.org/images/d/dc/Elc2013_Na.pdf
https://elinux.org/images/4/43/Understanding_And_Using_SMP_Multicore_Processors_Anderson.pdf

P.S. If you would like. Give me a set of tasks you would like me to benchmark. Ill swap between the current kernel and the kernel I built and post the statistics :)



> Things may have changed in scheduler land since then, meaning CONFIG_SCHED_MC may now enable other enhancements - or add more side-effects.
> 
> I'd be happy to change my mind if there's evidence that this config option provides a net benefit, though.

Please look above for context.

The Scheduler in general is very aware of what threads are being ran on the CPUs. The scheduler's goal is set from a user setting that can be modified (You can google for setting the options). The defaults goal is consolidating tasks to free up system resources in the goal of reducing power and heat for the processors. With threads consolidated, the CPU cores will be freed up for more tasks, and with the less demand for power due to the other cores not being as busy, reduces power needs, thus reducing heat, thus allowing all cores on the CPU to stay at their top frequencies during work. This also allows for better overclocking abilities, and better task management as the scheduler also utilizes priority tasking, so high-performance tasks are put in a better position. And obviously less heat == better period.

So in general, having the kernel be Multicore aware gains a lot of very nice benefits for the System's benefit of having fine control of all the cores.",True,True
expressjs_____session_____708,2020-06-03T07:31:28Z,True,expressjs_____session_____708_____434364520,"@dougwilson - addressed, changed the log message",True,True
expressjs_____session_____708,2020-06-03T07:31:36Z,True,expressjs_____session_____708_____434364615,ditto as above,True,True
expressjs_____session_____708,2020-06-03T07:31:55Z,True,expressjs_____session_____708_____434364892,"done, moved to `save` method.",True,True
expressjs_____session_____708,2020-06-04T00:19:53Z,True,expressjs_____session_____708_____434925132,"This prints before the session is saved, as the saving operation is async.",True,True
expressjs_____session_____708,2020-06-04T00:24:15Z,True,expressjs_____session_____708_____434926271,"This is based on I am assuming that this line is desired to be similar to the destroy logs, with the behavior of ""destroying.."" being logged before the store call and then ""... destroyed"" called when the store returns back to this module without an error.",True,True
expressjs_____session_____708,2020-06-04T06:14:44Z,True,expressjs_____session_____708_____435014549,"thanks @dougwilson . yes, the desire is to follow `destroy`. the intent is simple - many issues in this repo are about session not being saved or inability to know about it.

thinking about it more, I can achieve this at the `save` site only via structural changes to the `save` function. that is, anchoring the `save` call with a custom callback, check for errors, or else print the debug message and then invoke the original callback, if any.

Before implementing it and submitting for your review, I want to pro-actively check with you on it - will you be open for such a change?",True,True
Icinga_____icinga2_____8046,2020-06-08T13:50:55Z,True,Icinga_____icinga2_____8046_____431155176,,True,True
Icinga_____icinga2_____8046,2020-06-08T13:58:20Z,True,Icinga_____icinga2_____8046_____640621879,ref/IP/25801,True,True
openssl_____openssl_____12089,2020-06-08T20:57:07Z,True,openssl_____openssl_____12089_____431392792,Remove some offensive/archaic terminology from OpenSSL.,True,True
openssl_____openssl_____12089,2020-06-08T22:34:42Z,True,openssl_____openssl_____12089_____437038299,"Main is a better idea, would you mind using ""main"" instead of ""parent""?  My thinking is that ""main"" would indicate that it's the top or root DRBG, while a ""parent"" can be somewhere in the middle of the chain, so not quite as definitive if you see what I mean...",True,True
openssl_____openssl_____12089,2020-06-08T22:37:48Z,True,openssl_____openssl_____12089_____437039432,"Wouldn't ""root"" be even better? ",True,True
openssl_____openssl_____12089,2020-06-08T22:37:58Z,True,openssl_____openssl_____12089_____437039500,"This one is troublesome, as it exists in 1.1.1.",True,True
openssl_____openssl_____12089,2020-06-08T22:43:21Z,True,openssl_____openssl_____12089_____437041341,"Either root or parent is fine to replace master; you guys decide.
",True,True
openssl_____openssl_____12089,2020-06-08T22:44:20Z,True,openssl_____openssl_____12089_____640925862,-1 ,True,True
openssl_____openssl_____12089,2020-06-08T22:44:50Z,True,openssl_____openssl_____12089_____437041775,"Simple enough to keep the old name in addition, or deprecate it; let me know what you prefer.",True,True
openssl_____openssl_____12089,2020-06-08T22:53:39Z,True,openssl_____openssl_____12089_____640928737,"> -1

Hi Tim, a flat ""-1"" feels like applying stop energy without any guidance on how to make progress.  I trust that you will compose a more detailed response when you have a chance to do so.",True,True
facebook_____react_____19102,2020-06-09T06:11:53Z,True,facebook_____react_____19102_____431560140,"<!--
  Thanks for submitting a pull request!
  We appreciate you spending the time to work on these changes. Please provide enough information so that others can review your pull request. The three fields below are mandatory.

  Before submitting a pull request, please make sure the following is done:

  1. Fork [the repository](https://github.com/facebook/react) and create your branch from `master`.
  2. Run `yarn` in the repository root.
  3. If you've fixed a bug or added code that should be tested, add tests!
  4. Ensure the test suite passes (`yarn test`). Tip: `yarn test --watch TestName` is helpful in development.
  5. Run `yarn test-prod` to test in the production environment. It supports the same options as `yarn test`.
  6. If you need a debugger, run `yarn debug-test --watch TestName`, open `chrome://inspect`, and press ""Inspect"".
  7. Format your code with [prettier](https://github.com/prettier/prettier) (`yarn prettier`).
  8. Make sure your code lints (`yarn lint`). Tip: `yarn linc` to only check changed files.
  9. Run the [Flow](https://flowtype.org/) typechecks (`yarn flow`).
  10. If you haven't already, complete the CLA.

  Learn more about contributing: https://reactjs.org/docs/how-to-contribute.html
-->

## Summary

<!-- Explain the **motivation** for making this change. What existing problem does the pull request solve? -->

## Test Plan

<!-- Demonstrate the code is solid. Example: The exact commands you ran and their output, screenshots / videos if the pull request changes the user interface. -->

use allowlist instead of whitelist for some reason
",True,True
facebook_____react_____19102,2020-06-09T06:12:03Z,True,facebook_____react_____19102_____641053699,"Hi @shengxinjing! 

Thank you for your pull request and welcome to our community.We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file.

In order for us to review and merge your code, please sign at <https://code.facebook.com/cla>. **If you are contributing on behalf of someone else (eg your employer)**, the individual CLA may not be sufficient and your employer may need to sign the corporate CLA.

If you have received this in error or have any questions, please contact us at [cla@fb.com](mailto:cla@fb.com?subject=CLA%20for%20facebook%2Freact%20%2319102). Thanks!",True,True
facebook_____react_____19102,2020-06-09T06:14:02Z,True,facebook_____react_____19102_____641054632,"This pull request is automatically built and testable in [CodeSandbox](https://codesandbox.io).

  To see build info of the built libraries, click [here](https://ci.codesandbox.io/status/facebook/react/pr/19102/builds/31450) or the icon next to each commit SHA.

Latest deployment of this branch, based on commit e35dddb53718c6c2da61458518d1a6bb785ad1ad:

|Sandbox| Source |
|--|--|
|[gracious-bas-02j6v](https://codesandbox.io/s/gracious-bas-02j6v)| Configuration |
",True,True
facebook_____react_____19102,2020-06-09T06:19:18Z,True,facebook_____react_____19102_____641057022,"
<!--
  0 failure: 
  0 warning: 
  
  2 markdown notices
  DangerID: danger-id-stable;
-->



No significant bundle size changes to report.

## Size changes (stable)
<p align=""right"">
  Generated by :no_entry_sign: <a href=""https://danger.systems/js"">dangerJS</a> against e35dddb53718c6c2da61458518d1a6bb785ad1ad
</p>
",True,True
facebook_____react_____19102,2020-06-09T06:19:30Z,True,facebook_____react_____19102_____641057107,"
<!--
  0 failure: 
  0 warning: 
  
  2 markdown notices
  DangerID: danger-id-experimental;
-->



No significant bundle size changes to report.

## Size changes (experimental)
<p align=""right"">
  Generated by :no_entry_sign: <a href=""https://danger.systems/js"">dangerJS</a> against e35dddb53718c6c2da61458518d1a6bb785ad1ad
</p>
",True,True
openssl_____openssl_____12089,2020-06-09T10:55:33Z,True,openssl_____openssl_____12089_____437320420,"You'll have to keep the old name in addition no matter what.  If it were me, I would deprecate it, but from what I gather, that may be a bit too rad, so just add a backward compat macro.",True,True
openssl_____openssl_____12089,2020-06-09T10:55:43Z,True,openssl_____openssl_____12089_____641211883,"The most fixes like ""white space => whitespace"" should be applied anyway as they are grammar improvements...",True,True
openssl_____openssl_____12089,2020-06-09T11:04:57Z,True,openssl_____openssl_____12089_____437325175,"I'm actually a little dubious that ""master"" on its own is offensive, whereas it is considered as such when put together with ""slave"" (for obvious reasons)...

However, I had a quick look at https://en.wikipedia.org/wiki/Master/slave_(technology), and other proposed substitutes seem to be ""main"" and ""primary"", primarily.  I see that as an argument for choosing ""main"" in our case.",True,True
openssl_____openssl_____12089,2020-06-09T11:30:53Z,True,openssl_____openssl_____12089_____437337753,Main implies it is somewhat the one that is mainly used. Root or primary please.,True,True
openssl_____openssl_____12089,2020-06-09T11:32:34Z,True,openssl_____openssl_____12089_____437338585,"I'm kind of with @levitte....is ""master"" actually offensive when using it in the context of ""master, public, private""? By avoiding this particular rename we don't have to make any changes to public API symbols - which would be preferable.",True,True
openssl_____openssl_____12089,2020-06-09T11:34:06Z,True,openssl_____openssl_____12089_____437339297,"...or, if so, would we also propose to rename our ""master"" branch in git??",True,True
openssl_____openssl_____12089,2020-06-09T11:54:21Z,True,openssl_____openssl_____12089_____437349741,"This could end up being an interesting discussion in and of itself...  just wanted to point out that ""master"" as a term most likely lives in the fuzzy space between the categorical ""offensive"" / ""not offensive"" classifications, and I really don't have enough of a clue to know which way to lean on this one.  That's not a very strong argument for either way to move from here.

I'll also note that, while this does touch public API symbols, almost all of them are new in 3.0.  Furthermore, if they are deprecated in the RAND for providers PR, this change becomes moot.",True,True
facebook_____react_____19102,2020-06-09T12:18:31Z,True,facebook_____react_____19102_____641251682,"**I REALLY DISAGREE WITH THIS PR**

I worry about the racial discrimination have happened in US from long time ago to recent as a human being, while I also insist to regard `blacklist, whitelist, blackbox testing, whitebox testing, master, slave, etc` to be neutral nouns in `IT area` as a software engineer. They just info to opposite or relevant methods in computer science without any emotion. The more one tries to hide, the more one is exposed.

My voice may seem to be sharp on this rename PR. Indeed, that shows my attitude about racial discrimination and mercy about people who suffer from brutality all around the world.   As a Chinese, we know the eval history of `Negro Slaves` and experienced `Literary Inquisition` about 400 years ago. We should show really action instead of showing shows.

",True,True
facebook_____react_____19102,2020-06-09T12:27:34Z,True,facebook_____react_____19102_____641255748,it's for fun  beacuse google use replace blacklist with blocklist in chrome and [go](https://github.com/golang/go/blob/6bf2eea62a3425c57f3d908ec32047a9ae41c025/src/cmd/compile/internal/gc/plive.go#L905),True,True
openssl_____openssl_____12089,2020-06-09T12:47:23Z,True,openssl_____openssl_____12089_____437384627,I will add a macro in the header file once the hold is removed.  I hope that will happen soon.,True,True
openssl_____openssl_____12089,2020-06-09T12:52:59Z,True,openssl_____openssl_____12089_____437388159,"It's easy to do the good thing, even if some feel that ""it's not necessary.""

Of course, I'm not doing anything here until the hold is removed. It's not a good look, folks.",True,True
openssl_____openssl_____12089,2020-06-09T12:55:41Z,True,openssl_____openssl_____12089_____437389944,"BTW, to address @mattcaswell's concern: renaming something via a define in a public header file (as @levitte proposed) meets the ""just recompile"" bar that the project has publically set.",True,True
openssl_____openssl_____12089,2020-06-09T13:47:17Z,True,openssl_____openssl_____12089_____437432270,Is the function part of the stable ABI? If yes then a macro is not sufficient.,True,True
openssl_____openssl_____12089,2020-06-09T13:50:07Z,True,openssl_____openssl_____12089_____437435209,"> Is the function part of the stable ABI? If yes then a macro is not sufficient.

Sorry, I missed Rich's reply https://github.com/openssl/openssl/pull/12089#discussion_r437389944",True,True
facebook_____react_____19102,2020-06-09T15:39:42Z,True,facebook_____react_____19102_____641387518,Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!,True,True
facebook_____react_____19102,2020-06-09T15:39:59Z,True,facebook_____react_____19102_____641387668,Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!,True,True
openssl_____openssl_____12089,2020-06-09T22:06:23Z,True,openssl_____openssl_____12089_____437749087,"Although there is an instance where master has a negative connotation, I don't think the word should be replaced - as it is a general word describing 'having talent' in pretty much any area. (e.g Headmaster, master-chef).

I have no objection to replacing words that associate a color with good or bad.",True,True
openssl_____openssl_____12089,2020-06-09T23:16:34Z,True,openssl_____openssl_____12089_____437773602,"Languages evolve, as do people's sensitivities. The dominant definition of master, when used as a known, is someone who has others working for them, such as slaves. The dominant definition when used as an adjective is as you said, having talent.  But the main point of the currently-labelled ""master DRBG"" is *not* that it has talent that distinguishes it -- it's just an instance of the exact same code. Does the different entropy source make it more talented that a  private or public DRBG?

So really, the ""polite"" definition isn't accurate, and the ""bad"" definition shouldn't be used. But even if it's just unfair collatoral damage, why is it important to hold on to a term that some feel, even if you disagree or think they are wrong, exclusionary?  What is the harm in this minor change to make a word actually more accurate? Why is it more important to be ""right"" than to be ""good""?
",True,True
openssl_____openssl_____12089,2020-06-09T23:27:16Z,True,openssl_____openssl_____12089_____437776914,"It this context it means it has authority over others (which it what it means here).
The point is the word is in the public API, so aliasing it really solves nothing.
",True,True
openssl_____openssl_____12089,2020-06-09T23:43:09Z,True,openssl_____openssl_____12089_____437781660,"Does that mean that getrandom has authority over the main DRBG?  Or is getrandom just an input? And likewise, then, child DRBG's have another one, the parent, that provides input. What authority does the main DRBG have?

The word is in the public API, yes.  ""Most programs will just require recompiling"" is the public compatibility statement, and this PR will not add to that burden.",True,True
openssl_____openssl_____12089,2020-06-10T09:15:20Z,True,openssl_____openssl_____12089_____641867788,"Rich, could you please split the PR in two? One fixing the non-public API parts and avoiding changes for the 'master' word. That one should be uncontroversial. And keep the public API changes here for OMC to decide.",True,True
openssl_____openssl_____12089,2020-06-10T09:17:15Z,True,openssl_____openssl_____12089_____641868855,The reason I am asking to avoid all the changes to the master word is that replacing it with parent is in my opinion wrong in most cases in this PR. It should be replaced with primary or root or main.,True,True
openssl_____openssl_____12089,2020-06-10T13:22:40Z,True,openssl_____openssl_____12089_____642005244,"I thought about the term ""blanks"" for ""whitespace"", but I'm not sure it quite matches.",True,True
openssl_____openssl_____12089,2020-06-10T13:44:18Z,True,openssl_____openssl_____12089_____642018832,"No, I will not split the PR.  As I said before, I am happy to use whatever word other than parent once you folks decide.",True,True
openzfs_____zfs_____10435,2020-06-10T17:55:21Z,True,openzfs_____zfs_____10435_____432612144,"
<!--- Please fill out the following template, which will help other contributors review your Pull Request. -->

<!--- Provide a general summary of your changes in the Title above -->

<!---
Documentation on ZFS Buildbot options can be found at
https://openzfs.github.io/openzfs-docs/Developer%20Resources/Buildbot%20Options.html
-->

### Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->
The horrible effects of human slavery continue to impact society.  The
casual use of the term ""slave"" in computer software is an unnecessary
reference to a painful human experience.

### Description
<!--- Describe your changes in detail -->
This commit removes all possible references to the term ""slave"".

Implementation notes:

The zpool.d/slaves script is renamed to dm-deps, which uses the same
terminology as `dmsetup deps`.

References to the `/sys/class/block/$dev/slaves` directory remain.  This
directory name is determined by the Linux kernel.  Although
`dmsetup deps` provides the same information, it unfortunately requires
elevated privileges, whereas the `/sys/...` directory is world-readable.

### How Has This Been Tested?
<!--- Please describe in detail how you tested your changes. -->
<!--- Include details of your testing environment, and the tests you ran to -->
<!--- see how your change affects other areas of the code, etc. -->
<!--- If your change is a performance enhancement, please provide benchmarks here. -->
<!--- Please think about using the draft PR feature if appropriate -->

Manual testing of `dm-deps` script and manpage.
Ran the test suite.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [x] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [x] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [x] I have run the ZFS Test Suite with this change applied.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
",True,True
openssl_____openssl_____12089,2020-06-10T22:19:50Z,True,openssl_____openssl_____12089_____642297519,This is quite absurd. Blacklist is standard engineering terminology. Please read up on the etymology of the word before inserting your own misguided ideas into things. https://www.etymonline.com/word/blacklist,True,True
openssl_____openssl_____12089,2020-06-10T22:26:29Z,True,openssl_____openssl_____12089_____642299887,"More so this is API breaking for no purpose other than suiting some people's social ideas. This shouldn't be relevant in engineering discussion. Master/slave are also hardcoded terms in many engineering specifications, especially in device drivers. ",True,True
openssl_____openssl_____12089,2020-06-10T22:30:18Z,True,openssl_____openssl_____12089_____642301206,"> The most fixes like ""white space => whitespace"" should be applied anyway as they are grammar improvements...

Yes I agree. Those are typos and ""whitespace"" is a single word. The master/slave wording is unfortunate but is standard terminology and there is no reason to change it. The removal of ""blacklist"" is pure nonsense based on misunderstanding.",True,True
openssl_____openssl_____12089,2020-06-10T22:31:09Z,True,openssl_____openssl_____12089_____642301530,"> This is quite absurd. Blacklist is standard engineering terminology. Please read up on the etymology of the word before inserting your own misguided ideas into things. https://www.etymonline.com/word/blacklist

Please do some extra reading.. e.g: https://tools.ietf.org/id/draft-knodel-terminology-01.html
Maybe it will change your mind.
",True,True
openssl_____openssl_____12089,2020-06-10T22:33:16Z,True,openssl_____openssl_____12089_____642302267,"> > This is quite absurd. Blacklist is standard engineering terminology. Please read up on the etymology of the word before inserting your own misguided ideas into things. https://www.etymonline.com/word/blacklist
> 
> Please do some extra reading.. e.g: https://tools.ietf.org/id/draft-knodel-terminology-01.html
> Maybe it will change your mind.

One mistaken understanding broadly spread does not suddenly make it correct. ""Black and white"" ascribe values to colors, it has nothing to do with the color of skin. The terminology predates westerners ever encountering people from subsaharan Africa. ",True,True
openssl_____openssl_____12089,2020-06-10T22:51:05Z,True,openssl_____openssl_____12089_____642307993,"Even master/slave, while historically unfortunate is pretty standard. See: https://en.wikipedia.org/wiki/I%C2%B2C We could change to ""master/minion"" while maintaining the same idea of one piece of code controlling the other. ""parent/child"" does not work as the parent doesn't control the child, they just create the child.",True,True
openssl_____openssl_____12089,2020-06-10T22:53:01Z,True,openssl_____openssl_____12089_____642308574,"> One mistaken understanding broadly spread does not suddenly make it correct. ""Black and white"" ascribe values to colors, it has nothing to do with the color of skin. The terminology predates westerners ever encountering people from subsaharan Africa.

Who is talking about skin color? @richsalz is changing words to do me a favor!

I like to wear black cloths and listen to black music (Metal, Goth, DW). I don't like the fact that my choice of music and attire has a negative connotation like *black list*. As a creature of the night and non-native speaker I'm also often confused that *white list* is a positive list and *black list* is negative. I embrace night and loath sun light, so I associate black with positive and white with negative aspects. The term *block list* more understandable for me. 🤪",True,True
openssl_____openssl_____12089,2020-06-10T22:56:23Z,True,openssl_____openssl_____12089_____642309588,"> > One mistaken understanding broadly spread does not suddenly make it correct. ""Black and white"" ascribe values to colors, it has nothing to do with the color of skin. The terminology predates westerners ever encountering people from subsaharan Africa.
> 
> Who is talking about skin color? @richsalz is changing words to do me a favor!
> 
> I like to wear black cloths and listen to black music (Metal, Goth, DW). I don't like the fact that my choice of music and attire has a negative connotation like _black list_. As a creature of the night and non-native speaker I'm also often confused that _white list_ is a positive list and _black list_ is negative. I embrace night and loath sun light, so I associate black with positive and white with negative aspects. The term _block list_ more understandable for me. 🤪

Just to clarify, it should never be ""black list"" or ""white list"". It should always be ""blacklist"" or ""whitelist"". Compound words are quite different than adjective+noun which is not what is being implied here. ""blacklist"" and ""whitelist"" are also verbs. ""blocklist"" is not a word and you can't use ""block list"" as a verb.

""I will blacklist this MAC Address from the lookup table.""",True,True
openssl_____openssl_____12089,2020-06-10T23:02:10Z,True,openssl_____openssl_____12089_____438453305,"As mentioned in a separate comment, ""master/minion"" is also completely fine terminology that preserves the intention that ""this thing is controlling the other thing"".",True,True
openssl_____openssl_____12089,2020-06-10T23:05:45Z,True,openssl_____openssl_____12089_____642312317,"> I thought about the term ""blanks"" for ""whitespace"", but I'm not sure it quite matches.

""whitespace"" doesn't give value judgement so there is zero reason at all (more than any other change in this PR) to remove it. It comes from paper being white and text being black so the spaces between the characters are ""whitespace"". Removing the word ""whitespace"" from vocabulary would be extremely confusing as it's the term used to lump newline/line-break characters, tab characters, space characters and other such things into one classification. There's even a regex symbol ""\s"" that lumps all these as white-space. ",True,True
openssl_____openssl_____12089,2020-06-10T23:11:32Z,True,openssl_____openssl_____12089_____438456320,"I believe ""white-space"" and ""whitespace"" are both valid terminology. ""white space"" is not, so those are good to change, but I think keeping ""white-space"" is fine.",True,True
openssl_____openssl_____12089,2020-06-10T23:24:05Z,True,openssl_____openssl_____12089_____642317580,"Thanks for sharing your opinions, @mlindner.  While it's okay that you don't find the terms objectionable, many do, and you should similarly be okay with that as well, and respectful of their feelings no matter how nonsensical you feel it is.

As for the API/ABI changes, please see this comment upthread. https://github.com/openssl/openssl/pull/12089#discussion_r437389944  ",True,True
openssl_____openssl_____12089,2020-06-10T23:28:39Z,True,openssl_____openssl_____12089_____642318902,"> Even master/slave, while historically unfortunate is pretty standard.

""Historically unfortunate."" 

> while maintaining the same idea of one piece of code controlling the other.

Please see https://github.com/openssl/openssl/pull/12089#discussion_r437776914 and my reply.  The parent is an *input source* it does not ""control"" the child.
",True,True
openssl_____openssl_____12089,2020-06-11T00:47:09Z,True,openssl_____openssl_____12089_____642340313,"> > Even master/slave, while historically unfortunate is pretty standard.
> 
> ""Historically unfortunate.""

I don't see the issue here.

> > while maintaining the same idea of one piece of code controlling the other.
> 
> Please see [#12089 (comment)](https://github.com/openssl/openssl/pull/12089#discussion_r437776914) and my reply. The parent is an _input source_ it does not ""control"" the child.

Thanks for the detail. Having authority over the other is a master/minion relationship, parent/child I've only ever seen used in tree structures where there's an explicit ordering (parent comes first). If the master is an input source where information is fed to the minions then I think minion makes sense as the master/slave meaning made sense.",True,True
openssl_____openssl_____12089,2020-06-11T00:50:09Z,True,openssl_____openssl_____12089_____642341061,"> Thanks for sharing your opinions, @mlindner. While it's okay that you don't find the terms objectionable, many do, and you should similarly be okay with that as well, and respectful of their feelings no matter how nonsensical you feel it is.

I think using accurate language is more important than avoiding offense at the words chosen if they are accurate to the situation they are used in.",True,True
expressjs_____session_____708,2020-06-11T01:43:55Z,True,expressjs_____session_____708_____438497102,"Hi @gireeshpunathil yes, that sounds good to me, to just mimic the destroy way in the save area.",True,True
facebook_____react_____19102,2020-06-11T01:59:59Z,True,facebook_____react_____19102_____642359660,"Agree @pingfengafei .
Don't let word game anesthetize us, If everyone pays attention, discrimination will slowly disappear, but if we pretend that it has disappeared now, it may exist forever, The more one tries to hide, the more one is exposed.",True,True
openssl_____openssl_____12089,2020-06-11T02:15:39Z,True,openssl_____openssl_____12089_____438505068,"_Master_ is in the public APIs already.  We'd have to change it via the deprecation policy.

I'm open to others names: _primal_, _initial_, _basal_, _chief_, _primary_, _dominus_, _foremost_, _principle_, _prime_, _doyen_, _best_, _first_, _suzerain_, _seed_, ...

The entire RAND framework needs some polishing @mspncp and I have some convergent ideas as to the direction we think it should go.  Nonetheless, `RAND_bytes()` and `RAND_priv_bytes()` must remain and be the primary calls -- I suspect the rest is rarely used.
",True,True
openssl_____openssl_____12089,2020-06-11T03:22:10Z,True,openssl_____openssl_____12089_____642382105,https://www.cnet.com/news/master-and-slave-tech-terms-face-scrutiny-amid-anti-racism-efforts/,True,True
openzfs_____zfs_____10435,2020-06-11T05:04:06Z,True,openzfs_____zfs_____10435_____642408745,"There is also:
`  CC [M]  /var/lib/buildbot/slaves/zfs/Amazon_2_x86_64__BUILD_/build/zfs/module/icp/algs/aes/aes_impl.o
`

But not very visible.",True,True
openssl_____openssl_____12089,2020-06-11T05:35:57Z,True,openssl_____openssl_____12089_____642419042,"> https://www.cnet.com/news/master-and-slave-tech-terms-face-scrutiny-amid-anti-racism-efforts/

Just to clarify, I do think that the terms master/slave aren't the best and it's an accident of history/historically unfortunate that they've turned into common technical terms. However some of the terms are engrained into standards of technology so there is no getting rid of them. They're stuck for the foreseeable future, not matter what changes. If master/slave doesn't represent the DRBG setup correctly then it's fine to change them to be more accurate as well. That's the least egregious change in this entire PR and actually makes some sense. The rest, not so much (besides fixing obvious grammar issues).",True,True
expressjs_____session_____708,2020-06-11T06:12:46Z,True,expressjs_____session_____708_____438563372,"@dougwilson - done, pls have a look. Here is a sample output from a simple program with debug on, for your reference:
```
  express-session fetching qs3pPenGDQy0hOXWCw_G8lD_ZLJw5AA1 +0ms
  express-session no session found +5ms
  express-session session generate +1ms
  express-session saving 7G28RiMV20yaNOzU3UeC5_qJMKek7X6f +4ms
  express-session set-cookie connect.sid=s%XXX; Path=/; Expires=YYY; HttpOnly +4ms
  express-session session saved +3ms
```",True,True
openssl_____openssl_____12089,2020-06-11T06:19:26Z,True,openssl_____openssl_____12089_____642434351,"The dispute about compound words is quite futile, really.  Words like ""whitelist"" and ""blacklist"" have been composed of two, where the colours have been attribute the idea of ""good"" and ""bad"".  The words could just as well have been ""goodlist"" and ""badlist"".",True,True
openssl_____openssl_____12089,2020-06-11T08:11:14Z,True,openssl_____openssl_____12089_____642487014,"> The dispute about compound words is quite futile, really. Words like ""whitelist"" and ""blacklist"" have been composed of two, where the colours have been attribute the idea of ""good"" and ""bad"". The words could just as well have been ""goodlist"" and ""badlist"".

Yes, but they aren't. Colors have been associated with value judgements since antiquity. ""The powers of light and darkness."" etc and is present in many types of fiction. Extrapolating them to skin color is the work of nonsense and has never even occurred to me until this ridiculous pull request was posted and talked about. (Also ""black magic"" also has nothing to do with skin color, that's from fiction and ""black mages"" were even in Final Fantasy 1 games and earlier sources of fiction. It's referring to arcane arts as opposed to holy magic. It's saying ""this is mysterious"". Again, stretching this out to some kind of race issue is another work of nonsense.)",True,True
openssl_____openssl_____12089,2020-06-11T08:39:24Z,True,openssl_____openssl_____12089_____642501838,"@mlindner May I ask who you are and why you are spending so much time and effort to debate and dispute this PR?

Your GH profile does not contain a real name, affiliation, employer, or any other personal information. You are not an OpenSSL contributor. It doesn't even look like you developing directly with OpenSSL. It does not look like you are affected by the changeset.",True,True
openssl_____openssl_____12089,2020-06-11T08:47:50Z,True,openssl_____openssl_____12089_____438636258,"```suggestion
    /* Look for first non emptyspace or quote */
```

whitepsace could be offensive to some people.",True,True
openssl_____openssl_____12089,2020-06-11T09:20:47Z,True,openssl_____openssl_____12089_____642525709,"> Yes, but they aren't. Colors have been associated with value judgements since antiquity. ""The powers of light and darkness."" etc and is present in many types of fiction. Extrapolating them to skin color is the work of nonsense and has never even occurred to me until this ridiculous pull request was posted and talked about. (Also ""black magic"" also has nothing to do with skin color, that's from fiction and ""black mages"" were even in Final Fantasy 1 games and earlier sources of fiction. It's referring to arcane arts as opposed to holy magic. It's saying ""this is mysterious"". Again, stretching this out to some kind of race issue is another work of nonsense.)

You seem to misunderstand what the current social justice movement is about - it actually **is** about forcibly removing any value association of dark, light or any other colors from minds of all people, all this because of some people having different skin tones and regardless of where the value association came from.

But yes, I have to agree we are way off-topic here.",True,True
openssl_____openssl_____12089,2020-06-11T09:39:28Z,True,openssl_____openssl_____12089_____642535070,"> it actually is about forcibly removing any value association of dark, light or any other colors from minds of all people

This is nonsense and you'll never be able to achieve that. Colors have always had and will ever have meanings. If you want to destroy all the cultures and languages then go ahead and save the world.",True,True
freeipa_____freeipa_____4809,2020-06-11T12:49:45Z,True,freeipa_____freeipa_____4809_____433053835,See https://tools.ietf.org/id/draft-knodel-terminology-01.html,True,True
freeipa_____freeipa_____4809,2020-06-11T13:08:27Z,True,freeipa_____freeipa_____4809_____642636641,"In `migrate_ds` `oc_blacklist_option` and `attr_blacklist_option` are internal elements, they can be freely changed to `oc_blocklist_option` and `attr_blocklist_option`.",True,True
openssl_____openssl_____12089,2020-06-11T13:22:34Z,True,openssl_____openssl_____12089_____438776480,"As for the deprecation policy, I believe these lines are enough:
```
diff --git a/include/openssl/rand_drbg.h b/include/openssl/rand_drbg.h
index 5ee93a3eab..382d472414 100644
--- a/include/openssl/rand_drbg.h
+++ b/include/openssl/rand_drbg.h
@@ -112,6 +112,10 @@ int RAND_DRBG_set_reseed_defaults(
                                   time_t child_reseed_time_interval
                                   );
 
+# ifndef OPENSSL_NO_DEPRECATED_3_0
+#  define OPENSSL_CTX_get0_master_drbg(ctx) OPENSSL_CTX_get0_parent_drbg(ctx)
+#  define RAND_DRBG_get0_master() RAND_DRBG_get0_parent()
+# endif
```

If you want a HISTORY entry in ```doc/man3/RAND_DRBG_get0_parent.pod``` (point: new name) I can do that.

*HOWEVER* first the project has to decide it wants this.  As I've emailed, https://mta.openssl.org/pipermail/openssl-project/2020-June/002040.html, there's a thread started.",True,True
openssl_____openssl_____12089,2020-06-11T13:32:52Z,True,openssl_____openssl_____12089_____438783471,"On a technical note, the OPENSSL_CTX_get0_master_drbg() compat define is unnecessary because that function does not exist in 1.1.1.",True,True
openssl_____openssl_____12089,2020-06-11T13:33:30Z,True,openssl_____openssl_____12089_____642652425,"> @mlindner May I ask who you are and why you are spending so much time and effort to debate and dispute this PR?
> 
> Your GH profile does not contain a real name, affiliation, employer, or any other personal information. You are not an OpenSSL contributor. It doesn't even look like you developing directly with OpenSSL. It does not look like you are affected by the changeset.

And in the same vein, @blacklistisnotracist joined github 2 days ago.",True,True
openssl_____openssl_____12089,2020-06-11T13:41:42Z,True,openssl_____openssl_____12089_____642656669,"> @mlindner May I ask who you are and why you are spending so much time and effort to debate and dispute this PR?
> 
> Your GH profile does not contain a real name, affiliation, employer, or any other personal information. You are not an OpenSSL contributor. It doesn't even look like you developing directly with OpenSSL. It does not look like you are affected by the changeset.

Without commenting on the viewpoints expressed, I can attest to the fact that @mlindner has been a member of the OpenSSL community for some while, e.g.
#5454, #5768, #5915, etc
",True,True
openssl_____openssl_____12089,2020-06-11T14:28:50Z,True,openssl_____openssl_____12089_____642695474,"@tmshort 

> And in the same vein, @blacklistisnotracist joined github 2 days ago.

Are you saying a newbie can't have an opinion? Do you know the definition of discrimination? 
",True,True
openssl_____openssl_____12089,2020-06-11T14:38:05Z,True,openssl_____openssl_____12089_____438835116,thanks.,True,True
freeipa_____freeipa_____4809,2020-06-11T14:41:29Z,True,freeipa_____freeipa_____4809_____642703112,+1 on Alexander's suggestion.,True,True
openssl_____openssl_____12089,2020-06-11T14:43:59Z,True,openssl_____openssl_____12089_____642704721,"@tiran 

> @mlindner May I ask who you are 

This is a very aggressive attitude. Why their identity matters to have an opinion?

> and why you are spending so much time and effort to debate and dispute this PR?

Interesting, both sides are thinking the other side is spending so much time on unnecessary stuffs.",True,True
freeipa_____freeipa_____4809,2020-06-11T14:47:47Z,True,freeipa_____freeipa_____4809_____642708176,"> In `migrate_ds` `oc_blacklist_option` and `attr_blacklist_option` are internal elements, they can be freely changed to `oc_blocklist_option` and `attr_blocklist_option`.

Thanks Alexander and Rob. I didn't realize that the attributes are only just internally. Fixed!",True,True
openssl_____openssl_____12089,2020-06-11T15:01:58Z,True,openssl_____openssl_____12089_____642718133,"> You seem to misunderstand what the current social justice movement is about - it actually **is** about forcibly removing any value association of dark, light or any other colors from minds of all people, all this because of some people having different skin tones and regardless of where the value association came from.

I understand *exactly* what it is about, thanks for confirming the Orwellian position. This is exactly where we part ways: https://newcriterion.com/issues/2019/10/leninthink

This PR is not inclusive, there is no community of potential contributors excluded by the code as-is, the terms were chosen in good faith, but there definitely is a community excluded by the change, and excluding them is the whole point. This PR should not proceed.",True,True
systemd_____systemd_____16152,2020-06-11T15:47:14Z,True,systemd_____systemd_____16152_____433175402,"We shouldn't be using google dns servers, as dns requests can give out a lot of sensitive information. By changing the default fallback to quad9 we increase user privacy.",True,True
systemd_____systemd_____16152,2020-06-11T16:03:15Z,True,systemd_____systemd_____16152_____642774149,"As was stated multiple times in #12499 and #16148 we don't plan to change the defaults in upstream systemd. The defaults should be (and are) overridden in each downstream distribution separately (see [the documentation on how it's done](https://systemd.io/DISTRO_PORTING/)), so if you're unhappy with them, contact your downstream developers.

Thanks for understanding.",True,True
openssl_____openssl_____12089,2020-06-11T17:55:24Z,True,openssl_____openssl_____12089_____642839026,What a mess.,True,True
openssl_____openssl_____12089,2020-06-11T17:58:15Z,True,openssl_____openssl_____12089_____642840998,"Edit: grouped several comments together.

> @mlindner May I ask who you are and why you are spending so much time and effort to debate and dispute this PR?
> 
> Your GH profile does not contain a real name, affiliation, employer, or any other personal information. You are not an OpenSSL contributor. It doesn't even look like you developing directly with OpenSSL. It does not look like you are affected by the changeset.

I keep my accounts unlinked from each other intentionally. I work at a company that uses OpenSSL extensively (including lots of horrible hacks that were made in the past so OpenSSL 0.9.x versions could be hardware accelerated) so I pay lots of attention to the mailing lists which is how I first heard of this. We're still stuck on 1.0.2 and waiting for 3.0.0 as we need FIPS and hardware acceleration as well so 1.1.1 doesn't work for us (also it will be a huge undertaking to make the code compatible with 1.1.1 or 3.0.0 because of our horrible hacks). Most of my work is on internal gitlab so work doesn't show up on here, but this is off topic.

Also the only reason why the above question is important is if you're trying to doxx me or something else very much not appropriate.

***

@blacklistisnotracist Your previous review comments are not helpful and actually harm my point. Your suggested changes are also being made in bad faith. This is already a contentious issue, mocking people makes things worse.

***

This PR is a mix of changes that are both quite agreeable and completely disagreeable.

Fixing whitespace grammar is good.

Fixing master/slave is begrudgingly understandable especially if it doesn't represent things properly. Though lots of care needs to be taken to pick the most accurate words.

Removing ""blacklist"" is quite disagreeable. Removing ""black magic"" is quite disagreeable.",True,True
systemd_____systemd_____16152,2020-06-11T18:09:56Z,True,systemd_____systemd_____16152_____642847410,"Did anything change since #8899 ? I don't think so.

I am not sure why the people behind quad9 (ibm? i hear the main systemd devs are already in their pocket! omg! omg! omg!) should be any better than those behind googe dns or those behind cloudflare dns. In #8899 we ended up adding cloudflare because it was performant and didn't filter. I really don't care what the fallback servers are as long as they work and don't artificially filter...

Adding new servers just because of conspiracy theories is something I really think is a bad idea.

Anyway, if the people peddling this fud are really that concerned that their downstream distro is making the wrong choices by not specifiying servers appropriate for their distro on the meson build line, then I really wonder why they trust their distro on anything at all, and maybe they should switch distros...",True,True
openssl_____openssl_____12089,2020-06-11T18:25:51Z,True,openssl_____openssl_____12089_____642854863,"> What a mess.

It'll get a whole lot worse as soon as this PR inevitably gets posted to hacker news or a programming subreddit. Hopefully this gets voted on quickly by the OMC.",True,True
openssl_____openssl_____12089,2020-06-11T19:02:07Z,True,openssl_____openssl_____12089_____642872137,"In doing this, I looked at every use of the word black and white. As a result, all the ""whitespace"" corrections to avoid future false positives.  Same for ""black magic.""  If this PR is accepted, then being consistent in the future will be easier.",True,True
openssl_____openssl_____12089,2020-06-11T19:18:59Z,True,openssl_____openssl_____12089_____642880001,"> In doing this, I looked at every use of the word black and white. As a result, all the ""whitespace"" corrections to avoid future false positives. Same for ""black magic."" If this PR is accepted, then being consistent in the future will be easier.

What do you mean ""being consistent"", do you mean you'd reject any future pull request list that uses the words ""black"" or ""white""? I think coming up with official language written down in the submitter guidelines should come before the purge of existing terms.",True,True
openssl_____openssl_____12089,2020-06-11T19:23:56Z,True,openssl_____openssl_____12089_____642882200,"> do you mean you'd reject any future pull request list that uses the words ""black"" or ""white""

No, I don't mean that, I am sorry if I gave you that impression.

And also, I'm not on the project, I don't approve anything.",True,True
openssl_____openssl_____12089,2020-06-11T20:22:28Z,True,openssl_____openssl_____12089_____642907794,"> > do you mean you'd reject any future pull request list that uses the words ""black"" or ""white""
> 
> No, I don't mean that, I am sorry if I gave you that impression.
> 
> And also, I'm not on the project, I don't approve anything.

Sorry, maybe I'm misunderstanding your thoughts. What did you mean by ""avoid future false positives"" then?",True,True
openssl_____openssl_____12089,2020-06-11T21:07:11Z,True,openssl_____openssl_____12089_____642928430,"> What did you mean by ""avoid future false positives"" then?

False positives.  For example, on master and this PR:
```
; g grep --extended -w 'white|black' | wc
     30     287    2518
; g co better-words
Switched to branch 'better-words'
; g grep --extended -w 'white|black' | wc
      4      42     352
; 
```",True,True
openssl_____openssl_____12089,2020-06-11T22:06:12Z,True,openssl_____openssl_____12089_____642955057,"> > What did you mean by ""avoid future false positives"" then?
> 
> False positives. For example, on master and this PR:
> 
> ```
> ; g grep --extended -w 'white|black' | wc
>      30     287    2518
> ; g co better-words
> Switched to branch 'better-words'
> ; g grep --extended -w 'white|black' | wc
>       4      42     352
> ; 
> ```

I fail to see what's ""false positives"" about this. ""white"" and ""black"" are not bad words to be eliminated.",True,True
openssl_____openssl_____12089,2020-06-11T23:46:35Z,True,openssl_____openssl_____12089_____642985083,"Please avoid the temptation to engage in a series of counter-arguments, that's not going to be productive.  If you've already stated your views succinctly and respectfully, nothing further need be said.  [ Comments that are outright trolling, and responses to them, have been and will be deleted. ]",True,True
PaperMC_____Paper_____3544,2020-06-12T01:44:40Z,True,PaperMC_____Paper_____3544_____433418148,See patch notes,True,True
PaperMC_____Paper_____3544,2020-06-12T01:46:28Z,True,PaperMC_____Paper_____3544_____643019070,"inb4 ""this breaks tnt dupers!!!!! literally unplayable am going back to spigot!!!!""",True,True
PaperMC_____Paper_____3544,2020-06-12T01:54:55Z,True,PaperMC_____Paper_____3544_____643021162,@JRoy are you serious?,True,True
PaperMC_____Paper_____3544,2020-06-12T01:56:01Z,True,PaperMC_____Paper_____3544_____643021497,"> @JRoy are you serious?

We get people complaining about the patch that fixes 0tick pretty much weekly. So yes, someone will complain about paper patching this exploit too.",True,True
PaperMC_____Paper_____3544,2020-06-12T01:58:38Z,True,PaperMC_____Paper_____3544_____643022124,Could possibly quell the complaints with a config option...,True,True
PaperMC_____Paper_____3544,2020-06-12T02:00:58Z,True,PaperMC_____Paper_____3544_____643022703,"> Could possibly quell the complaints with a config option...

I agree there should be a toggle. However there's a toggle for 0tick and people still complain about it. 

Overall pls merge I hate piston exploits. Ty leaf. ",True,True
PaperMC_____Paper_____3544,2020-06-12T08:43:18Z,True,PaperMC_____Paper_____3544_____643152625,Please make a toggle for this :D,True,True
PaperMC_____Paper_____3544,2020-06-12T09:56:07Z,True,PaperMC_____Paper_____3544_____643186282,agree with @DoubleGe ,True,True
PaperMC_____Paper_____3544,2020-06-12T11:00:13Z,True,PaperMC_____Paper_____3544_____643211221,Needs a toggle,True,True
PaperMC_____Paper_____3544,2020-06-12T11:39:32Z,True,PaperMC_____Paper_____3544_____643225507,"> Needs a toggle

I vote against a toggle. Dupe exploits should be fixed, it's not a feature. ",True,True
PaperMC_____Paper_____3544,2020-06-12T11:41:03Z,True,PaperMC_____Paper_____3544_____643226000,"lol when you don't realise JRoy was being sarcastic

+1 for config option, some technical servers that want to be as close as possble to vanilla might suffer from exploit fixes. If Mojang decite to fix it, then it's fine for all platforms.",True,True
PaperMC_____Paper_____3544,2020-06-12T11:54:19Z,True,PaperMC_____Paper_____3544_____643230850,"> > Needs a toggle
> 
> I vote against a toggle. Dupe exploits should be fixed, it's not a feature.

With this update server owners lose the possibility to get as close as possible to Vanilla, if Mojang would fix it then everyone knows it. Now people know it's as a vanilla bug like Zero-Tick Farms. I thought it worked on paper but there was a config option, so I turned it on so it works and I know it will be disabled in 1.16 but that's fine (it's the vanilla game). And if the toggle is defaulted to on. So it won't work people that want it to work can just simply disable the fix, and then it just should work. (So everyone can choose what they want)  ",True,True
openssl_____openssl_____12089,2020-06-12T12:05:42Z,True,openssl_____openssl_____12089_____643235211,"> I fail to see what's ""false positives"" about this. ""white"" and ""black"" are not bad words to be eliminated.

If someone wishes to do something similar to this PR, say in a few years from now, rather than scan all instances, they can focus on ones that *might* be problematic.  ",True,True
openssl_____openssl_____12089,2020-06-12T12:15:43Z,True,openssl_____openssl_____12089_____643239445,"Error messages painted in red color is very problematic for Native Americans, going by your logic. I'm pretty sure that kind of PR will never get merged. Sigh. I don't mind changing blacklist to blocklist as long as its purpose is to make meanings clearer. However, no mentioning of racist connotations is required.",True,True
PaperMC_____Paper_____3544,2020-06-12T12:26:40Z,True,PaperMC_____Paper_____3544_____643243905,I'll stick to last build(349) until this being reverted or adding a config option.,True,True
PaperMC_____Paper_____3544,2020-06-12T12:33:28Z,True,PaperMC_____Paper_____3544_____643246545,"> I'll stick to last build(349) until this being reverted or adding a config option.

For me, it's not an option I have a weird bug with paper spawns too much hostile/sea mobs
(Issue: #3523 )",True,True
PaperMC_____Paper_____3544,2020-06-12T12:50:50Z,True,PaperMC_____Paper_____3544_____643253442,"MC-188840 was closed in as duplicate of MC-100579 (private), so yes this looks like mojang thinks it's a bug (although if you needed me to tell you that they consider tnt duplication is a bug you have some serious delusion).

I also provided them the fix, so this will get fixed in vanilla - might as well get used to it.",True,True
PaperMC_____Paper_____3544,2020-06-12T13:06:48Z,True,PaperMC_____Paper_____3544_____643260342,"> MC-188840 was closed in as duplicate of MC-100579 (private), so yes this looks like mojang thinks it's a bug (although if you needed me to tell you that they consider tnt duplication is a bug you have some serious delusion).
> 
> I also provided them the fix, so this will get fixed in vanilla - might as well get used to it.

I get it that this is a bug and it **should** be fixed, but they haven't even fixed it in vanilla.

It's like Mojang accidentally fixed pigman afk xp farm in a 1.16 pre-release and in the next snapshot they brought the bug back even though they said they have aware of the bug but they just have no plan of fixing it in this version.",True,True
PaperMC_____Paper_____3544,2020-06-12T13:20:33Z,True,PaperMC_____Paper_____3544_____643266983,"> lol when you don't realise JRoy was being sarcastic
> 
> +1 for config option, some technical servers that want to be as close as possble to vanilla might suffer from exploit fixes. If Mojang decite to fix it, then it's fine for all platforms.

With the amount of things that Paper ""fixes"", using Paper in the first place is accepting you're not that close to vanilla anymore. ",True,True
PaperMC_____Paper_____3544,2020-06-12T13:29:40Z,True,PaperMC_____Paper_____3544_____643271217,"If you have such a problem with changes like this, why don't you go remove this patch and build Paper yourself? This is a git repository, not a feature request forum.",True,True
PaperMC_____Paper_____3544,2020-06-12T13:37:39Z,True,PaperMC_____Paper_____3544_____643274973,"> > MC-188840 was closed in as duplicate of MC-100579 (private), so yes this looks like mojang thinks it's a bug (although if you needed me to tell you that they consider tnt duplication is a bug you have some serious delusion).
> > I also provided them the fix, so this will get fixed in vanilla - might as well get used to it.
> 
> I get it that this is a bug and it **should** be fixed, but they haven't even fixed it in vanilla.
> 
> It's like Mojang accidentally fixed pigman afk xp farm in a 1.16 pre-release and in the next snapshot they brought the bug back even though they said they have aware of the bug but they just have no plan of fixing it in this version.

Guess what we have a fix coming for soon too.
Note, it wasn't an ACCIDENT. They DO NOT want Zombie Gold farms. They said it directly.",True,True
PaperMC_____Paper_____3544,2020-06-12T13:41:49Z,True,PaperMC_____Paper_____3544_____643276868,"> > > MC-188840 was closed in as duplicate of MC-100579 (private), so yes this looks like mojang thinks it's a bug (although if you needed me to tell you that they consider tnt duplication is a bug you have some serious delusion).
> > > I also provided them the fix, so this will get fixed in vanilla - might as well get used to it.
> > 
> > 
> > I get it that this is a bug and it **should** be fixed, but they haven't even fixed it in vanilla.
> > It's like Mojang accidentally fixed pigman afk xp farm in a 1.16 pre-release and in the next snapshot they brought the bug back even though they said they have aware of the bug but they just have no plan of fixing it in this version.
> 
> Guess what we have a fix coming for soon too.
> Note, it wasn't an ACCIDENT. They DO NOT want Zombie Gold farms. They said it directly.

https://twitter.com/ThatZepheron/status/1269259361706283008",True,True
PaperMC_____Paper_____3544,2020-06-12T13:44:14Z,True,PaperMC_____Paper_____3544_____643277928,"> 
> 
> > > > MC-188840 was closed in as duplicate of MC-100579 (private), so yes this looks like mojang thinks it's a bug (although if you needed me to tell you that they consider tnt duplication is a bug you have some serious delusion).
> > > > I also provided them the fix, so this will get fixed in vanilla - might as well get used to it.
> > > 
> > > 
> > > I get it that this is a bug and it **should** be fixed, but they haven't even fixed it in vanilla.
> > > It's like Mojang accidentally fixed pigman afk xp farm in a 1.16 pre-release and in the next snapshot they brought the bug back even though they said they have aware of the bug but they just have no plan of fixing it in this version.
> > 
> > 
> > Guess what we have a fix coming for soon too.
> > Note, it wasn't an ACCIDENT. They DO NOT want Zombie Gold farms. They said it directly.
> 
> https://twitter.com/ThatZepheron/status/1269259361706283008

https://www.reddit.com/user/sliced_lime/comments/gzpo5p/some_words_on_things_in_116/",True,True
PaperMC_____Paper_____3544,2020-06-12T13:52:45Z,True,PaperMC_____Paper_____3544_____643281884,"I mean the fix of the bug was an accident.

I do think those bugs should be fixed. What I want is just some options to make paper act like vanilla in the same version. If it takes too much effort to implement, then nevermind.",True,True
PaperMC_____Paper_____3544,2020-06-12T14:05:13Z,True,PaperMC_____Paper_____3544_____643288081,"it wasn't actually an accident if you read his comments on reddit, he just kept his twitter message short and avoided debate there.

> To be completely open with you: Zombified Piglin gold farms are based off a mechanic that makes no sense, and should not exist in the game - a glitch where a mob drops player kill drops despite not being killed by a player, which is obviously not right.
> With this in mind, we decided that it would be ok to break these farms, given that it was done early in the update cycle, and especially given that the glitch was very tied into aggro-related bugs that really did need fixing. That obviously never happened.

Ignore the part about ""failure"" to achieve that goal. The message is pretty clear intent to remove it and their thoughts on it.

But the pigmen farm will likely have a config since its a mechanic change and not a dupe bug.

tnt is a duplication bug, which we don't usually add configs for. Ones we've done in past we kind of regret.

Change is hard, but players need to accept these bugs should be fixed. Mojang is much more willing to bow down and avoid the drama than we are. 

At least server owners can say it wasn't their choice and avoid the personal heat.
",True,True
PaperMC_____Paper_____3544,2020-06-12T14:06:57Z,True,PaperMC_____Paper_____3544_____643288927,ok.,True,True
PaperMC_____Paper_____3544,2020-06-12T14:22:41Z,True,PaperMC_____Paper_____3544_____643296680,tnt dupers only dupe the entity which allows people to make massive quarries for building projects. no harm involved. Wont update until theres a config option,True,True
PaperMC_____Paper_____3544,2020-06-12T14:24:57Z,True,PaperMC_____Paper_____3544_____643297858,its like how carpet dupers allow people to make mapart easier,True,True
PaperMC_____Paper_____3544,2020-06-12T14:25:47Z,True,PaperMC_____Paper_____3544_____643298837,"> it wasn't actually an accident if you read his comments on reddit, he just kept his twitter message short and avoided debate there.
> 
> > To be completely open with you: Zombified Piglin gold farms are based off a mechanic that makes no sense, and should not exist in the game - a glitch where a mob drops player kill drops despite not being killed by a player, which is obviously not right.
> > With this in mind, we decided that it would be ok to break these farms, given that it was done early in the update cycle, and especially given that the glitch was very tied into aggro-related bugs that really did need fixing. That obviously never happened.
> 
> Ignore the part about ""failure"" to achieve that goal. The message is pretty clear intent to remove it and their thoughts on it.
> 
> But the pigmen farm will likely have a config since its a mechanic change and not a dupe bug.
> 
> tnt is a duplication bug, which we don't usually add configs for. Ones we've done in past we kind of regret.
> 
> Change is hard, but players need to accept these bugs should be fixed. Mojang is much more willing to bow down and avoid the drama than we are.
> 
> At least server owners can say it wasn't their choice and avoid the personal heat.

Why can the Zero-Tick farms have a config even it's a bug and the tnt dupe issue not.",True,True
PaperMC_____Paper_____3544,2020-06-12T14:32:01Z,True,PaperMC_____Paper_____3544_____643302723,"> > it wasn't actually an accident if you read his comments on reddit, he just kept his twitter message short and avoided debate there.
> > > To be completely open with you: Zombified Piglin gold farms are based off a mechanic that makes no sense, and should not exist in the game - a glitch where a mob drops player kill drops despite not being killed by a player, which is obviously not right.
> > > With this in mind, we decided that it would be ok to break these farms, given that it was done early in the update cycle, and especially given that the glitch was very tied into aggro-related bugs that really did need fixing. That obviously never happened.
> > 
> > 
> > Ignore the part about ""failure"" to achieve that goal. The message is pretty clear intent to remove it and their thoughts on it.
> > But the pigmen farm will likely have a config since its a mechanic change and not a dupe bug.
> > tnt is a duplication bug, which we don't usually add configs for. Ones we've done in past we kind of regret.
> > Change is hard, but players need to accept these bugs should be fixed. Mojang is much more willing to bow down and avoid the drama than we are.
> > At least server owners can say it wasn't their choice and avoid the personal heat.
> 
> Why can the Zero-Tick farms have a config even it's a bug and the tnt dupe issue not.

He said:
> Ones we've done in past we kind of regret.",True,True
PaperMC_____Paper_____3544,2020-06-12T14:34:30Z,True,PaperMC_____Paper_____3544_____643304255,"rail/carpet dupers is on the agenda to fix too...
I've actively tried already. Just haven't found solution yet.",True,True
PaperMC_____Paper_____3544,2020-06-12T14:38:23Z,True,PaperMC_____Paper_____3544_____643306311,"And yes we've regretted the zero tick config too. But that one wasn't a duplication bug. growing crops is already a concept of self growing supply, but the bug just sped up the rate faster than intended.

This patch is directly a duplication. TNT is supposed to be 1 block = 1 explosion.

You want a massive quarry for your build project? Do it like every other person and dig it out, or collect the resources for the TNT.

IT's how everyone did it before discovering they could dupe tnt.",True,True
PaperMC_____Paper_____3544,2020-06-12T14:45:02Z,True,PaperMC_____Paper_____3544_____643310082,"I already made this configurable but won't open a merge request due to the controversy. Defaults to fixing TNT duplication. Feel free to use it if you want configuration:
https://github.com/AJMFactsheets/Paper/blob/configurable-tnt-dupers/Spigot-Server-Patches/0542-Fix-piston-physics-inconsistency-MC-188840.patch",True,True
PaperMC_____Paper_____3544,2020-06-12T16:06:03Z,True,PaperMC_____Paper_____3544_____643353833,"> I already made this configurable but won't open a merge request due to the controversy. Defaults to fixing TNT duplication. Feel free to use it if you want configuration:
> https://github.com/AJMFactsheets/Paper/blob/configurable-tnt-dupers/Spigot-Server-Patches/0542-Fix-piston-physics-inconsistency-MC-188840.patch

I would say make a config so peolpe can choose for them self so they can choose what they want",True,True
openssl_____openssl_____12089,2020-06-12T16:39:33Z,True,openssl_____openssl_____12089_____643375341,"Please avoid do that. It's an endless job, and not a good one like bugfixing, since you'll always find people that complains for something.
Moreover black and white are (also) colors and blacklist word origin is NOT related to the color of the skin so it's ok to keep it. For master/slave I'm dubious to change it, since this can breaks API and for historical reason (master/slave is also used in electronics for flip-flop, in pre-SATA hard disk and in videorecorders).
This is not the correct way to fix discrimination and it's quite hypocritical.",True,True
openssl_____openssl_____12089,2020-06-12T17:03:06Z,True,openssl_____openssl_____12089_____643386044,"> This is not the correct way to fix discrimination and it's quite hypocritical.

This changeset does not fix discrimination. The author does not claim that it fixes anything. It merely replaces archaic, culture specific words with words that are clearer and easier to understand for non-native speakers.
 
This [IETF draft on terminology](https://tools.ietf.org/id/draft-knodel-terminology-01.html) lists some reseach on the matter. Perhaps Muhammad Ali can convince you why the negative co-notation of black is death by a thousands cuts, https://www.youtube.com/watch?v=7eXdt1eGgCA
",True,True
openssl_____openssl_____12089,2020-06-12T17:14:27Z,True,openssl_____openssl_____12089_____643390800,"@tiran 

> This changeset does not fix discrimination. The author does not claim that it fixes anything. 

Well, @richsalz 's [tweet](https://twitter.com/RichSalz/status/1270350008005640195) suggests the other way around, though. Nice try.

> I would not have thought that this would be controversial, especially in these days: https://github.com/openssl/openssl/pull/12089  Hoping my fellow white privileged colleagues do the right thing, soon.
",True,True
openssl_____openssl_____12089,2020-06-12T18:32:58Z,True,openssl_____openssl_____12089_____643425369,"You misunderstand my tweet, nowhere does it say ""fix""",True,True
openssl_____openssl_____12089,2020-06-12T18:42:47Z,True,openssl_____openssl_____12089_____643429023,"I don't understand why you had to mention white privileged colleagues if you didn't mean to fix (or to contribute to fixing) racism against black people. For me, the right thing here is not to reinforce the wrong connotations of these terms.",True,True
openssl_____openssl_____12089,2020-06-12T18:58:06Z,True,openssl_____openssl_____12089_____643434933,"Given that you joined github three days ago, and that you joined twitter this month, @blacklistisnotracist (a) I don't owe you explanation about me; and (b) perhaps assume good intentions as a default.  ",True,True
openssl_____openssl_____12089,2020-06-12T19:12:49Z,True,openssl_____openssl_____12089_____643440848,"> Given that you joined github three days ago, and that you joined twitter this month,

You're saying newbiews' opinions don't matter? Do you know the definition of discrimination?

> (b) perhaps assume good intentions as a default.

Yes. I do believe your motivation was from good place and you're in good faith. However, with all due respect, I don't think removing ""white"" and ""black"" from everywhere will ever fix racism because these are simply colors and idiomatic words that have nothing to do with skin color nor racism.

I would also like to say ""perhaps assume good intentions as a default."" to you and @tiran because [he wants to think I'm a white supremacist](https://twitter.com/ChristianHeimes/status/1271446798872313858) and is trying so hard to exclude me from the community by filing abuse reports.",True,True
openssl_____openssl_____12089,2020-06-12T19:48:36Z,True,openssl_____openssl_____12089_____643455027,"> > This is not the correct way to fix discrimination and it's quite hypocritical.
> 
> This changeset does not fix discrimination. The author does not claim that it fixes anything. It merely replaces archaic, culture specific words with words that are clearer and easier to understand for non-native speakers.
> 
> This [IETF draft on terminology](https://tools.ietf.org/id/draft-knodel-terminology-01.html) lists some reseach on the matter. Perhaps Muhammad Ali can convince you why the negative co-notation of black is death by a thousands cuts, https://www.youtube.com/watch?v=7eXdt1eGgCA

Culture and language are embedded with each other and you can't pull them apart. Even words like ""beef"" and ""cow"" both referring to the same thing via their etymology show that they are cultural. beef comes from old french because the rich in England spoke French while cow is from old english because the farmers were poor and spoke English. This pointed to the societal divide between the aristocracy and the peasants at the time with who consumed meat and who produced it. Use of the English language requires learning bits of the history of the language if you want to understand why certain words mean certain things.

Secondly, the negative connotation of color black being associated with bad things is one of the more universal things in many human cultures. It's much less English-specific than many other parts of the language. I know of several asian languages that have bad connotations to the color black as well.

The IETF draft is harmful in the highest degree to purport to know something when all they're really doing is continuing to spread misinformation (which btw, has already expired based on the dates there).

BTW I'm not defending @blacklistisnotracist. He's clearly just a troll, I was just objecting to your terms here.",True,True
facebook_____react_____19102,2020-06-13T01:11:44Z,True,facebook_____react_____19102_____643546793,Thanks for the PR! Landed in 655affa302437208e6f03c9ca6d170ea1707ace3,True,True
openssl_____openssl_____12089,2020-06-13T07:21:24Z,True,openssl_____openssl_____12089_____643583643,"The interesting bit in that draft on terminology is all the informational references, among others to other softwares that have already changed their terminology.  Is all that misinformation?",True,True
openssl_____openssl_____12089,2020-06-13T07:28:53Z,True,openssl_____openssl_____12089_____643584517,"> The interesting bit in that draft on terminology is all the informational references, among others to other softwares that have already changed their terminology. Is all that misinformation?

Yes, similar changes to those proposed have been made in various other projects. What's in question is the wisdom and priority of such changes, not their present popularity.",True,True
PaperMC_____Paper_____3544,2020-06-14T02:44:18Z,True,PaperMC_____Paper_____3544_____643709566,"On the main website, it doesn't state that it changes gameplay mechanics like this it only mentions the performance, and on the paperdocs it only says ""to fix gameplay and mechanics inconsistencies"" which had made me worried but the [faq id 7](https://paper.readthedocs.io/en/latest/about/faq.html#id7) had made me think the changes were more along the lines of #3527 or entity spawning handling kind of things. Is there documentation elsewhere that states what other changes have been made, like 0tick for example which was already mentioned in this thread? 

Regarding the TNT duping issue: [Sliced Lime](https://www.reddit.com/r/Minecraft/comments/fkt9jf/anchor_yourself_to_the_nether_snapshot_20w12a_is/fkv2yyv/) stated that they do plan on getting rid of this like 0tick but thinks that sand needs to being unlimited is one of the things stopping them from making this change.  

In short: I think a config option and/or documentation of these changes would be nice and greatly appreciated. ",True,True
PaperMC_____Paper_____3544,2020-06-14T03:09:43Z,True,PaperMC_____Paper_____3544_____643711376,"@MissPotato I agree, Paper lacks proper documentation in many places. Not even the configs doc is up-to-date (iirc), you gotta rely on changelog and state of this repo. Part of the job :)

This should be _configurable_ with the fix being enabled by default.

> TNT explosions now have a 100% drop rate.

That was a snapshot for 1.14. Now unless they had thought to have it fixed for 1.14 - let me paraphrase - if 1.14 had an active TNT dupe and despite that fact they decided to make it a 100% drop rate, then this is knowingly/intentional. Regardless of future fixes in Vanilla. Read [MC-129193](https://bugs.mojang.com/browse/MC-129193):

> how much the current community accepts it AND makes content involving it means it qualifies it as a feature. Redstone, particularly slime-block based innovations, are a very large portion of the community

This change is not like an optional ""fixer plugin"". You can't currently switch it off at will. There are many small communities or circles of friends like mine who mess with vanilla in-depth, yet the majority won't be able to recompile Paper and have figured out how to disable the fix.

The perception of ""legal"" as in ""not cheating"" is also vastly different between players. Some (strict) will say everything must be sound methods, even if some loophole exists. Others (relaxed) consider everything legit that is permitted by the game itself. Let me demonstrate this on a singleplayer example:

- Editing inventory via NBT/commands/etc. = cheating

- Duping items via the Drop → Save & Exit → Re-enter = some will accept it as legit

As far as Mojang goes: If they cared, they would do retroactive minor releases with the fixes and have these bugs at high priority. Don't have me remind you how long it took them for the chunk thing. Instead their only focus is new content to further fuel console and Realms subscriptions.

We're doing our own thing here. Despite taking the choice, players will still pressure the admins: @aikar ""At least server owners can say it wasn't their choice and avoid the personal heat."" - no. The admins can still be forced by their playerbase to stay on the outdated versions (of Paper). Same thing happened with 1.8 whether you like it (as a dev, on the receiving side) or not.",True,True
openssl_____openssl_____12089,2020-06-14T06:18:02Z,True,openssl_____openssl_____12089_____643724418,No matter which word you choose you will find someone who's offended by it. Don't change it.,True,True
PaperMC_____Paper_____3544,2020-06-14T08:20:46Z,True,PaperMC_____Paper_____3544_____643734849,"> Regarding the TNT duping issue: [Sliced Lime](https://www.reddit.com/r/Minecraft/comments/fkt9jf/anchor_yourself_to_the_nether_snapshot_20w12a_is/fkv2yyv/) stated that they do plan on getting rid of this like 0tick but thinks that sand needs to being unlimited is one of the things stopping them from making this change.

Heh, I had guessed that there was a reason for Mojang leaving TNT duping alone for three updates now (since the dead coral method was introduced), this statement from slicedlime exactly confirms my suspicions. Without TNT duping, there is currently no way of making a movable machine that destroys blocks (since dispensers, hoppers and chests are not movable), so it fills a hole in the mechanics.
 
> In short: I think a config option and/or documentation of these changes would be nice and greatly appreciated.

In my mind, it doesn't even have to be a separate toggle for each of the glitch/exploit fixes. Just one, `fix-vanilla-exploits` or something would probably make _most_ admins happy. For example, on the small server I admin and play on, we like to experiment with the vanilla glitches and build silly farms, but Paper is the only thing that runs that server with decent performance (probably mostly due to hopper optimizations). If gameplay changes are forced on like this, we'll probably have to resort to compiling our own version of Paper using a patch blacklist/whitelist in the future... :/",True,True
openssl_____openssl_____12089,2020-06-14T10:42:26Z,True,openssl_____openssl_____12089_____643749098,"Words like 'parent/child' might be unappropriate for some people, i.e. 'child-free' or those who can't have their own child. If you mind BLM, why not to mind child-free?",True,True
PaperMC_____Paper_____3544,2020-06-14T16:00:42Z,True,PaperMC_____Paper_____3544_____643786283,"@aikar

> it wasn't actually an accident if you read his comments on reddit, he just kept his twitter message short and avoided debate there.

If you read the entirety of the reddit thread and not just the words you want to read, he clearly stated that it indeed was accidentally fixed _now_. They intend to fix it later, but not this late in the 1.16 release cycle, so that the change is not forced upon the community without giving the community ""[time to adjust and give feedback](https://www.reddit.com/user/sliced_lime/comments/gzpo5p/some_words_on_things_in_116/fthlvtp/?context=1)"".

Also (quoting a different comment),
> Note, it wasn't an ACCIDENT. They DO NOT want Zombie Gold farms. They said it directly.

To be clear, sliced_lime only said they don't want Zombie Pigmen/Zombified Piglins to drop XP and rare loot without being killed by a player, [no complaints about the farms generating gold (nuggets)](https://www.reddit.com/user/sliced_lime/comments/gzpo5p/some_words_on_things_in_116/fthp1ro/?context=1).

> tnt is a duplication bug, which we don't usually add configs for. Ones we've done in past we kind of regret.

Sure, it is a bug, but [Mojang are intentionally holding off on fixing it until they can fill that slot in the intended mechanics in some other way](https://www.reddit.com/r/Minecraft/comments/fkt9jf/anchor_yourself_to_the_nether_snapshot_20w12a_is/fkv33q3/?context=1). I would kind of equate it to quasi connectivity or sticky pistons leaving their blocks behind when single ticked. Not originally intended, but widely accepted (in this specific case: until something replaces it).

> Change is hard, but players need to accept these bugs should be fixed. Mojang is much more willing to bow down and avoid the drama than we are.

and (from another comment)
> You want a massive quarry for your build project? Do it like every other person and dig it out, or collect the resources for the TNT.

I fully understand that some players want to play the game as ""intended"", mining every resource by hand and/or never building a single automated farm, and I let them do so without complaining, but it is not the way I (and many others) want to play the game. Minecraft is, and has always been, a sandbox game, so I don't at all understand the hate many players have against the technical community. Stop the ""holier than thou"" spiel and accept the fact that different people play this game differently. I don't see the harm in adding a config for this, especially since Mojang _intentionally_ aren't fixing this until there's a replacement. You don't even have to write any code to make it configurable, as it has [already been done for you](https://github.com/PaperMC/Paper/pull/3544#issuecomment-643310082).

> At least server owners can say it wasn't their choice and avoid the personal heat.

I'm a server owner, and I don't appreciate the lack of choice or having opinions that I don't share forced on me. Fortunately, no one can stop me from compiling my own version without this silliness shoved down my throat, but that isn't an option for everyone that need the performance benefits of Paper.


Lastly, a side note for @drunderscore
> edit1: And if you look at the repo description, it tells you:
> 
> > High performance Spigot fork that aims to fix gameplay and mechanics inconsistencies https://papermc.io/
> 
> This is, without a doubt, an ""inconsistent game mechanic"".

Sure, but [the website](https://papermc.io/) only mentions the ""high performance"" part of this, and the documentation even claims [players will not be able to tell the difference](https://paper.readthedocs.io/en/latest/about/faq.html#will-players-be-able-to-tell). There are probably a lot of server owners that will only ever look at the website and documentation, never even taking a glance at the git repo and its description. Maybe it's time to update the documentation if this is the route the project is taking.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:38:54Z,True,PaperMC_____Paper_____3544_____643805265,"A config toggle should **NOT** be added for so many reasons. It's your server, if you don't like it fork Paper, remove the patch, and maintain the diff.

The project goal of Paper is removing gameplay inconsistencies and improving performance. They have always done this. Countless dupes and exploits have been fixed by Paper prior to this one. Remember donkey dupes? This also falls under that. I do not want any exploits on my server and I do not want players coming onto my server thinking that exploits are gameplay mechanics. They are not. Mojang is at fault here for leaving these exploits for so long that players have grown to think that they are just part of Minecraft. If you are a technical player, you should stick entirely to Vanilla.

This outcry is ridiculous and I applaud the PaperMC core development team for sticking to this.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:46:01Z,True,PaperMC_____Paper_____3544_____643806098,"Aikar spends 100's of hours on making chunk loading and other shit better and more efficient and almost nothing gets said and you all just leech of hard work but the second Paper fixes an **unintended dupe bug** then its all outcry.

If you care that much, compile paper your self and remove the patch, it takes 15 mins even without much knowledge, or just give people free TNT.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:46:52Z,True,PaperMC_____Paper_____3544_____643806191,"I would like to add that you are using open source software. This is not democracy, this is development; there is a team who has decided that adding a lever (hehe) was a bad idea in the past, and is a bad idea now. If you wish to do this manually, it's still free software, _you can do whatever you want_ (within the licence's limits, which is one of the most permissive licences out there).

Hosting and ultimately managing a server comes with a maintenance burden. This is your burden, not PaperMC's. If you wish to have it done for you, pray @AJMFactsheets's fork will stay up-to-date, but do not expect anything even from them.

If you would like a drag-and-drop solution to all this, you can drop the vanilla server on there, as already mentioned by countless before me. If this is not for you and you are unable to bite the bullet, server-hosting is not for you.

---

As the PaperMC development team has come to a conclusion to _not_ add a switch to this _bug fix_, I, among many more, would like to see the thread be closed.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:47:56Z,True,PaperMC_____Paper_____3544_____643806311,"> I do not want any exploits on my server and I do not want players coming onto my server thinking that exploits are gameplay mechanics.

And in what way is that a reason for not adding a config toggle? If a config is added, you would be free to enable it to not allow TNT duping. I'm advocating for server owners to have a _choice_. I fail to see why that is a problem.

> If you are a technical player, you should stick entirely to Vanilla.

The performance fixes of Paper help my server a lot. Pure Vanilla is not really an option on current hardware.

> If you care that much, compile paper your self and remove the patch, it takes 15 mins even without much knowledge, or just give people free TNT.

I already compile it myself, but I know that's not an option for some.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:50:38Z,True,PaperMC_____Paper_____3544_____643806639,"@HexedHero I told Aikar many times, that he is amazing and Im very glad for his work. But...

Im one of those who run technic server based on MC mechanics, but still use plugins, so Im depended on Paper for perfomance bukkit. But this patch breaks a lot of things. I would be ok with this, if there were any alternative to automate World Eaters, but without moveable tile entities, its not possible.

And no, digging it by hand its not possible either. Or would anyone here enjoy digging 30x30 chunks by hand? 

Well, I guess, if somebody could do simple instructions how to remove patch... I could maintain it myself. Even tho, its a big step in widely used mechanic in game and makes many things just harder and not enjoyable.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:51:34Z,True,PaperMC_____Paper_____3544_____643806737,">I already compile it myself, but I know that's not an option for some.

How is that not an option?

Either way, this conversation should be locked. It's turning into an endless fight.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:55:55Z,True,PaperMC_____Paper_____3544_____643807223,"> > I already compile it myself, but I know that's not an option for some.
> 
> How is that not an option?

Third-party hosting, or lack of knowledge, for example?

> Either way, this conversation should be locked. It's turning into an endless fight.

That, I can actually agree on. I still fail to see how people can be against having a choice in the matter, though.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:56:38Z,True,PaperMC_____Paper_____3544_____643807315,"If you want TNT duping so much, please just give your players /give tnt. It accomplishes the same task and takes the same amount of effort.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:58:21Z,True,PaperMC_____Paper_____3544_____643807516,"I'll also be staying at 349 unless a toggle is implemented, I use paper to improve the performance of minecraft to save my in server costs, not to change vanilla behavior, especially ones that significantly change players' gameplay.",True,True
PaperMC_____Paper_____3544,2020-06-14T18:58:46Z,True,PaperMC_____Paper_____3544_____643807559,"@bartyrealms No it doesnt. The issue isnt that we want to dupe TNT as item. The issue is, it breaks the best automatic way to do World Eaters. I said it before - give players moveable tile entities and it will be patched by itself. But that isnt possible without mods.",True,True
PaperMC_____Paper_____3544,2020-06-14T19:00:33Z,True,PaperMC_____Paper_____3544_____643807764,"> @bartyrealms No it doesnt. The issue isnt that we want to dupe TNT as item. The issue is, it breaks the best automatic way to do World Eaters. I said it before - give players moveable tile entities and it will be patched by itself. But that isnt possible without mods.

Then just make a very very small plugin that just lets dispensers use TNT without a cost.",True,True
PaperMC_____Paper_____3544,2020-06-14T19:01:37Z,True,PaperMC_____Paper_____3544_____643807892,"@HexedHero Wait what. Then please tell me. In vanilla without mods, how would you trigger that moveable dispenser? Im currious. ",True,True
PaperMC_____Paper_____3544,2020-06-14T19:01:51Z,True,PaperMC_____Paper_____3544_____643807928,"> 
> 
> > @bartyrealms No it doesnt. The issue isnt that we want to dupe TNT as item. The issue is, it breaks the best automatic way to do World Eaters. I said it before - give players moveable tile entities and it will be patched by itself. But that isnt possible without mods.
> 
> Then just make a very very small plugin that just lets dispensers use TNT without a cost.

Preposterous! Think of the technical players and the effort to create a TNT duper!",True,True
PaperMC_____Paper_____3544,2020-06-14T19:03:32Z,True,PaperMC_____Paper_____3544_____643808124,"@bartyrealms Well, I bet that you never did World Eater. You would not call it that easy. ;)
If you dont know what Im talking about - https://youtu.be/mS7xxNGhjxs",True,True
PaperMC_____Paper_____3544,2020-06-14T19:10:52Z,True,PaperMC_____Paper_____3544_____643808998,"> Aikar spends 100's of hours on making chunk loading and other shit better and more efficient and almost nothing gets said and you all just leech of hard work but the second Paper fixes an **unintended dupe bug** then its all outcry.
> 
> If you care that much, compile paper your self and remove the patch, it takes 15 mins even without much knowledge, or just give people free TNT.

Hey man, I've only compiled paper myself before once, would you mind pointing to a guide on how to do it, I see above there is a ""merge"" for adding the toggle.  If I use that merge does that mean I'll have to redo this each time I update paper?  If so, can there possibly be a script written.  In the mean time I have to stay 349, players who play my server for vanilla mechanics started quitting when I had 350 going and I can't blame them.",True,True
openssl_____openssl_____12089,2020-06-14T19:17:05Z,True,openssl_____openssl_____12089_____643809755,We live in a clown world ,True,True
PaperMC_____Paper_____3544,2020-06-14T19:27:24Z,True,PaperMC_____Paper_____3544_____643810967,"I did it for you. I'll update this about weekly, perhaps biweekly; we'll see. I will not be testing it, if a build has horrible, awful bugs, that is not my issue. Paperclip jar is in releases with its associated Paper build number and commit. Config option is `exploit-fixes` in `paper.yml`. Enjoy. https://github.com/Proximyst/RetardPaper",True,True
PaperMC_____Paper_____3544,2020-06-14T19:29:49Z,True,PaperMC_____Paper_____3544_____643811256,"@Proximyst Still dont know why are you all so passive agressive to the community, who like to automate things. But I appreciate your help.",True,True
PaperMC_____Paper_____3544,2020-06-14T19:34:34Z,True,PaperMC_____Paper_____3544_____643811823,"> @Proximyst Still dont know why are you all so passive agressive to the community, who like to automate things. But I appreciate your help.

imo it technically an duplication exploit as Aikar said earlier 1 tnt 1 boom not 1 tnt unlimited boom.
it ""can"" use in both good n bad way but still it a dupe exploit ",True,True
openssl_____openssl_____12089,2020-06-14T21:58:12Z,True,openssl_____openssl_____12089_____643827632,"Just want to give my opinion on the topic.  
I'm happy to see an open discussion occurring on the matter, despite the fact I feel it's a bit trivial. I still think it's good to see this discussed, and either acted on, or determined that no action is needed, than only represented by a few thoughts and feelings in peoples heads.

I just hope if any terms do change, it is in fact because the majority believe and agree, and that there is a consensus that it should happen, and not _only_ for ""political correctness"".

I appreciate that language evolves, I just firmly believe this has total disregard for context.

Many examples exist here but to further it: would ""[Master's degree](https://en.wikipedia.org/wiki/Master's_degree)"" have to change, or maybe ""[Brownies](https://en.wikipedia.org/wiki/Chocolate_brownie)"", or ""[Brownie points](https://en.wikipedia.org/wiki/Brownie_points)"", if we disregard context and where the words are derived, could they be linked with slavery or race too?",True,True
PaperMC_____Paper_____3561,2020-06-15T03:02:13Z,True,PaperMC_____Paper_____3561_____434258022,"There is no config to enable or disable the new Piston Inconsistency Fix, the fix that disabled TNT dupers. This is a vanilla mechanic until fixed by Mojang and makes it hard for my players to feel immersed in their game play. Until there is a config I must make a choice to either not update, make my player base unhappy (which is an unlikely choice), or switch back to spigot.
This fix should default true and only be disabled if admins want it to happen like the 0 tick farms.

Not 100% sure how github works. This fork obviously doesn't actually implement a fix and should not be merged. ",True,True
PaperMC_____Paper_____3561,2020-06-15T03:12:13Z,True,PaperMC_____Paper_____3561_____643878886,"I agree to this. I will NOT be updating my server to #350 and will continue to stay on #349 until this is a option in the config. Please listen to your technical players, Paper!! ",True,True
PaperMC_____Paper_____3561,2020-06-15T03:14:07Z,True,PaperMC_____Paper_____3561_____643879305,"Has been discussed at length here: https://github.com/PaperMC/Paper/pull/3544
Please don't make pointless PRs and split discussion.",True,True
PaperMC_____Paper_____3561,2020-06-15T03:18:52Z,True,PaperMC_____Paper_____3561_____643880481,Change looks excellent. Very well implemented.,True,True
PaperMC_____Paper_____3561,2020-06-15T03:21:12Z,True,PaperMC_____Paper_____3561_____643881036,"Thanks Spottedleaf, again sorry not so sure how github works i just want to be heard, I have at least 40 players coming for my throat for updating and i'm going to have to revert changes or the server is going to lose revenue from our patreons. we're just asking for this to be optional instead of a forced fix.",True,True
PaperMC_____Paper_____3561,2020-06-15T03:36:44Z,True,PaperMC_____Paper_____3561_____643884626,"Sorry to break the news, but @Spottedleaf was being sarcastic. The Paper team strongly feels that dupe issues should be fixed with no option to revert, and I concur.",True,True
PaperMC_____Paper_____3561,2020-06-15T03:39:56Z,True,PaperMC_____Paper_____3561_____643885393,"I am aware that he was being sarcastic, I did make that change myself anyway. Whether or not they want the issues fixed we do wish that they would make the fixes optional if they are game changing. My technical Minecraft server loves the performance of paper and the option of being as close to vanilla as possible, but without a config for this change we cannot be as close to vanilla as we'd like.",True,True
PaperMC_____Paper_____3561,2020-06-15T03:41:08Z,True,PaperMC_____Paper_____3561_____643885660,"Please use https://github.com/Proximyst/RetardPaper if you wish to accomplish this. A config option for un-fixing duplication fixes will not end up in Paper itself. Do you complain to mojang when they fix dupes? No, you don't. 

For the week or so that's left in the 1.15 lifecycle, either stay on 349 or migrate to RetardPaper",True,True
PaperMC_____Paper_____3561,2020-06-15T03:49:13Z,True,PaperMC_____Paper_____3561_____643887413,"The disrespect isn't appreciated @JRoy . If Mojang decides to fix their own bugs, thats their thing, of course i wouldnt complain to them. But someone else is fixing them and it makes the game different. Any change that changes the vanilla game this drastically should be configurable. Its funny you say that because paper.yml has allow-perm-block-break-exploits: true and fix-zero-tick-instant-grow-farms: true - so indeed ""A config option for un-fixing duplication"" already exists in paper. We're going to have to update again and again to 1.16 so unless @Proximyst wants to keep updating paper so that this fix isnt implemented in every upcoming version i stand here to request a config.",True,True
PaperMC_____Paper_____3561,2020-06-15T03:50:01Z,True,PaperMC_____Paper_____3561_____643887544,"I don't understand the downside of having the option to turn it off or on. I would really like to understand since both parties would be happy because they have the choice to use it or not. It literally changes nothing for the goal or path Paper wants to accomplish, it would just support the technical players using Paper. If you are against glitches and dupes, great! they got patched! but why would you advocate for others not to have that option to turn it on or off... ",True,True
PaperMC_____Paper_____3561,2020-06-15T03:54:22Z,True,PaperMC_____Paper_____3561_____643888299,"@TwoPointlnfinity no disrespect was intended, it's just the name of the fork.

As for you saying paper already had config options for this, not sure what the first one is but the zero tick thing isn't a duplication glitch per say and more controversial than this.

But it seems you don't understand mojang has fixed both zero tick farms and tnt dupes in 1.16. RetardPaper is just a fork for the remaining 1.15 lifecycle that will be updated bi-weekly as per proxi",True,True
PaperMC_____Paper_____3561,2020-06-15T03:57:14Z,True,PaperMC_____Paper_____3561_____643888819,"https://github.com/PaperMC/Paper/pull/3544#issuecomment-643288081

As you can see, the team has added patches to allow turning off certain dupe fixes and have regretted them:

> tnt is a duplication bug, which we don't usually add configs for. Ones we've done in past we kind of regret.
>
> Change is hard, but players need to accept these bugs should be fixed. Mojang is much more willing to bow down and avoid the drama than we are.

There are many examples of settings Paper has added and then regretted. (Does anyone remember the cannoning settings from the 1.8 era?)

There will be no setting to revert the dupe fixes, so stop asking. Quite frankly, this is getting out of hand and I would like this PR closed and locked.",True,True
PaperMC_____Paper_____3561,2020-06-15T03:59:01Z,True,PaperMC_____Paper_____3561_____643889172,"> ""RetardPaper""
> ""This is a fork of Paper based on the work of byof for the utmost retarded users.""

Yeah, that's not disrespectful at all... 

> But it seems you don't understand mojang has fixed both zero tick farms and tnt dupes in 1.16. 

Half true, they're only patching out 0tick and plan on patching out TNT dupes later down the line when they have an alternative solution. As discussed in the original pull. ",True,True
PaperMC_____Paper_____3561,2020-06-15T04:01:16Z,True,PaperMC_____Paper_____3561_____643889600,"I'm sorry you feel that way @astei 
@JRoy TnT Dupers still work in the latest pre-release and they do not plan to fix them in 1.16",True,True
PaperMC_____Paper_____3561,2020-06-15T04:04:01Z,True,PaperMC_____Paper_____3561_____643890165,"> 
> 
> [#3544 (comment)](https://github.com/PaperMC/Paper/pull/3544#issuecomment-643288081)
> 
> As you can see, the team has added patches to allow turning off certain dupe fixes and have regretted them:
> 
> > tnt is a duplication bug, which we don't usually add configs for. Ones we've done in past we kind of regret.
> > Change is hard, but players need to accept these bugs should be fixed. Mojang is much more willing to bow down and avoid the drama than we are.
> 
> There are many examples of settings Paper has added and then regretted. (Does anyone remember the cannoning settings from the 1.8 era?)
> 
> There will be no setting to revert the dupe fixes, so stop asking. Quite frankly, this is getting out of hand and I would like this PR closed and locked.

Why have they regretted them? Is it because the ones that didn't want the glitches also didn't want other people to have the option to have them? Sounds like selfishness to me. I'm sure the team ""regretted"" it because of some people not wanting dupes for everyone. I would even bet those people don't even play the game on a regular basis...",True,True
PaperMC_____Paper_____3561,2020-06-15T04:06:02Z,True,PaperMC_____Paper_____3561_____643890567,"If you expect this issue to remain open and unlocked you will treat everyone with respect. No name calling, no bad faith arguments, no calling people ‘selfish’. If we were selfish you wouldn’t be here.

If anyone chooses to ignore this post you can expect to be blocked from posting. If it gets even more out of hand this issue will also be locked. Play nice, debate in a friendly way, or at least respectfully.",True,True
PaperMC_____Paper_____3561,2020-06-15T04:09:59Z,True,PaperMC_____Paper_____3561_____643891296,"I understand why they want them fixed @joaoesp i very much appreciate the work put in to make paper and have used it exclusively since they went standalone from spigot. Please dont insult the devs in any way, i understand their pov of glitches and exploits but from the deep technical player standpoint playing in the most vanilla way possible would be great if minecraft had better performance.",True,True
PaperMC_____Paper_____3561,2020-06-15T04:20:25Z,True,PaperMC_____Paper_____3561_____643893509,"At this point, all that can be said is. Glitches get patched/fixed. I don't really know what to say. Players who sit there and abuse them then whine when they're fixed without expecting them to eventually be fixed aren't the brightest bulbs.",True,True
PaperMC_____Paper_____3561,2020-06-15T04:20:42Z,True,PaperMC_____Paper_____3561_____643893554,"I didn't call anyone selfish. I just want to understand the reason to not have a config. Now he's countering my argument by saying that there will not be a setting and to stop asking. How is that debating in a friendly and respectful way? He's also asking to lock the PR because I do not share his opinion. Clearly there is an interest to have a config from a big part of the community, so why would those against it advocate so vehemently if it does not affect them?",True,True
PaperMC_____Paper_____3561,2020-06-15T04:24:20Z,True,PaperMC_____Paper_____3561_____643894368,"Most of us do expect bugs to be fixed @DragonsAscent 
I also do not understand why those opposed to the exploit would argue that there shouldn't be an option to enable/disable it if it would not affect them in any way. Can someone explain this to me?",True,True
PaperMC_____Paper_____3561,2020-06-15T04:27:45Z,True,PaperMC_____Paper_____3561_____643895193,Allowing config options for exploit fixes would require paper to support both configurations. This is a big hassle because no one at paper will be testing with the exploit enabled. There is a high chance the config option will break on some config and then a dev will have to try and fix it. This situation has already happened with the zero-tick exploit.,True,True
PaperMC_____Paper_____3561,2020-06-15T04:32:12Z,True,PaperMC_____Paper_____3561_____643896331,"I do believe by not implementing the fix themselves and waiting for mojang to do it would also solve that issue but they decided they wanted a fixed config version. What you're saying goes both ways. They technically are supporting the ""fixed"" version that they made instead of supporting the vanilla mechanic, having to support both sounds like a situation that can be avoided by either not making a config or not making a fix to the piston inconsistency. I support either not making the dupe fix or support a configuration that is more like vanilla. where the new fix is configurable. ",True,True
PaperMC_____Paper_____3561,2020-06-15T04:35:11Z,True,PaperMC_____Paper_____3561_____643897061,"> 
> 
> Allowing config options for exploit fixes would require paper to support both configurations. This is a big hassle because no one at paper will be testing with the exploit enabled. There is a high chance the config option will break on some config and then a dev will have to try and fix it. This situation has already happened with the zero-tick exploit.

Thank you! Finally a valid reason.",True,True
PaperMC_____Paper_____3561,2020-06-15T04:48:01Z,True,PaperMC_____Paper_____3561_____643900066,since this pr does not actually implement a fix it is now marked as a draft.,True,True
PaperMC_____Paper_____3561,2020-06-15T04:49:19Z,True,PaperMC_____Paper_____3561_____643900402,"![image](https://user-images.githubusercontent.com/734478/84619030-90c0b880-ae99-11ea-9f7d-719149be025d.png)
",True,True
PaperMC_____Paper_____3561,2020-06-15T04:52:59Z,True,PaperMC_____Paper_____3561_____643901296,"that's not exactly the same thing, and the picture doesn't even make sense. The fix wouldn't even stop the op from using his space bar for control purposes. Now his cpu wont overheat. That picture is not relevant to this situation. Is the update in the image talking about a hypothetical game maybe? But lets stay on topic. ",True,True
PaperMC_____Paper_____3561,2020-06-15T08:09:25Z,True,PaperMC_____Paper_____3561_____643973719,"It should be noted that although we fully expect Mojang to patch these exploits, we also expect (or rather, hope) that alternatives will be provided to what these exploits allow survival players to do. Although we do not expect infinite sand, or holes that are hundreds of thousands of blocks in area, we do expect a reasonable alternative that allows for a significant amount of sand without destroying entire deserts, and a reasonable alternative that allows for holes that are thousands of blocks in area.

I suggest a blanket config option for all dupe exploits (name it something like ""allow-unsupported-dupe-exploits""). This would allow private servers to decide for themselves if they want to go full vanilla, and it would not give any expectation that Paper will support these exploits in the future. This will also cover for any additional dupe exploit fixes (such as sand duping).

The only downside is that server owners will not have granular control over individual dupe exploits. I don't think this is a very big problem however, even if serious dupe exploits such as the chunk dupe (just an example, I know it's patched) are included in this config option, as TNT duping can already be used harmfully on public servers.

The second alternative is to put config options for each individual exploit in a category, and add a comment before it saying that none of these config options are guaranteed to work in future versions.",True,True
PaperMC_____Paper_____3561,2020-06-15T08:14:26Z,True,PaperMC_____Paper_____3561_____643976188,"Plugins, custom enchants that let you mine 3x3 or 5x5, VeinMiner, etc

There are solutions to that problem that don't resort to abusing exploits.

Alternatively you can just play modded, setup a quarry, and enjoy all the resources in the world.",True,True
PaperMC_____Paper_____3561,2020-06-15T08:18:49Z,True,PaperMC_____Paper_____3561_____643978520,"Whether or not people want to use these exploits is based on preference, and both arguments are valid. Understand that different things interest us, and you not having the same interests does not make them invalid. However, I do not believe this discussion is about whether these exploits are wanted by the community. The amount of debate has made it clear enough they are.",True,True
openzfs_____zfs_____10454,2020-06-15T08:19:17Z,True,openzfs_____zfs_____10454_____434369084,"against stupid political agitation that has no place in opensource world. Whole world use master/slave terminology in almost all technical sciences and there is no reason to change it. As I am not communist, I am doing regular commit and PR and not rewriting the (git) history by force ...

### Motivation and Context
Removes political agitation from the code. Makes code much more readable and clean. 

### Description
Only clean revert of previous weird commit. No additional changes.

### How Has This Been Tested?
Didn't make any tests.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [x] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ x] Documentation (a change to man pages or other documentation)
",True,True
PaperMC_____Paper_____3561,2020-06-15T09:01:55Z,True,PaperMC_____Paper_____3561_____644001236,"@TwoPointInfinity I will continue updating RetardPaper for the foreseeable future. It's a 2 minute job to do, so no real maintenance burden on me nor anyone wishing to fork it.

@MissPotato When forks such as RetardPaper come around with such names, the point *is* to be disrespectful. But it does what you want, so the choice to use a completely valid fix is ultimately on you.",True,True
openssl_____openssl_____12089,2020-06-15T09:09:08Z,True,openssl_____openssl_____12089_____644005223,"<img width=""724"" alt=""Screen Shot 2020-06-15 at 11 06 53"" src=""https://user-images.githubusercontent.com/33033094/84639232-63572780-aef8-11ea-83db-23f6d48a3c87.png"">

The word ""parent"" causes trauma in me as I grew up without one parent. Use a different word, I find it offensive.",True,True
openssl_____openssl_____12089,2020-06-15T09:24:48Z,True,openssl_____openssl_____12089_____644013353,"black magic -> dark magic ? Originally, it just means satanic forces that must be avoided:)",True,True
openssl_____openssl_____12089,2020-06-15T09:33:36Z,True,openssl_____openssl_____12089_____644017971,"> black magic -> dark magic ? Originally, it just means satanic forces that must be avoided:)

I wonder if ""black magic"" is really offensive to anyone, or is it just guessing? I fail to see any relation to races and discrimination here. I'm not a native English speaker, but calling a race ""black"" seems even more inappropriate to me (because technically their skin color is dark brown, not black) than banning ""black"" as a color.",True,True
openssl_____openssl_____12089,2020-06-15T10:15:51Z,True,openssl_____openssl_____12089_____644039221,"> <img alt=""Screen Shot 2020-06-15 at 11 06 53"" width=""724"" src=""https://user-images.githubusercontent.com/33033094/84639232-63572780-aef8-11ea-83db-23f6d48a3c87.png"">
> 
> The word ""parent"" causes trauma in me as I grew up without one parent. Use a different word, I find it offensive.

I am an orphan and the use of the word ""parent"" also causes me significant trauma, I support the use of a different word. ",True,True
openssl_____openssl_____12089,2020-06-15T10:18:15Z,True,openssl_____openssl_____12089_____644040383,"Sorry to hear that Louise, my condolences go to you.",True,True
PaperMC_____Paper_____3561,2020-06-15T11:00:34Z,True,PaperMC_____Paper_____3561_____644059120,"Not sure if this has been brought up before but especially because Mojangs stance on this is that they don't want to fix it because it ""fills a slot in the game that the intended game mechanics cannot"" I woud like to see a toggle for this. 
https://www.reddit.com/r/Minecraft/comments/fkt9jf/anchor_yourself_to_the_nether_snapshot_20w12a_is/fkv33q3/?context=1

I understand that some people don't want TNT duping on their server and I respect that without complaining but on the other hand there are a lot of people who do and a toggle would make both happy.",True,True
openzfs_____zfs_____10455,2020-06-15T11:17:13Z,True,openzfs_____zfs_____10455_____434469814,"Words such as ""wh\*telist"" or ""b\*acklist"" are racist. We cannot have those absolutely disgusting repulsive words in our codebase. Therefore, we need to change them to race-neutral words.

There are more references to racial supremacy throughout the code. These should be discussed.

Should this macro be renamed to ""blankspace""?
https://github.com/openzfs/zfs/blob/master/module/nvpair/nvpair.c#L46

Also, in the Lua module, we mark objects as ""wh\*te"" or ""b\*ack"". I suggest changing the colors to some non-offensive ones. I propose indigo (`#4B0082`) and forest green (`#228B22`).
https://github.com/openzfs/zfs/blob/master/module/lua/lgc.c

### Motivation and Context
Following other open-source projects, we should strive to keep the ZFS code base clean of any vulgar, racist or other unwelcome remarks and to allow for friendly and welcoming environment for people of all kinds.

### How Has This Been Tested?
It compiles - it's just basic refactoring.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [x] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [ ] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [ ] I have run the ZFS Test Suite with this change applied.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
",True,True
PaperMC_____Paper_____3561,2020-06-15T11:28:43Z,True,PaperMC_____Paper_____3561_____644071916,"![image](https://user-images.githubusercontent.com/29043515/84652480-f64d8d00-af0b-11ea-8775-f3a643206d26.png)

A lot of people want a tnt duping config because it fills a game mechanic gap, dispensers aren't moveable and mining with hand is not really an option. ",True,True
PaperMC_____Paper_____3561,2020-06-15T11:31:03Z,True,PaperMC_____Paper_____3561_____644072912,This project is not run like a democracy. Trying to [appeal to popularity](https://rationalwiki.org/wiki/Argumentum_ad_populum) won't get you anywhere.,True,True
PaperMC_____Paper_____3561,2020-06-15T11:32:00Z,True,PaperMC_____Paper_____3561_____644073294,"@RealityTest
This was from Aikar in paper discord recently.

mojang did mention it in a private meeting recently that sounds like they dont want the tnt dupe issue either",True,True
PaperMC_____Paper_____3561,2020-06-15T11:33:47Z,True,PaperMC_____Paper_____3561_____644074093,"@DoubleGe
There a fork of paper Called RetardPaper by @Proximyst. you can use that if you want to have exploit toggleable ",True,True
PaperMC_____Paper_____3561,2020-06-15T11:36:41Z,True,PaperMC_____Paper_____3561_____644075354,@MrEDok Can't use it because of #3523 big issue on my server,True,True
PaperMC_____Paper_____3561,2020-06-15T11:39:31Z,True,PaperMC_____Paper_____3561_____644076490,"@DoubleGe That makes no sense. RetardPaper is based off the same build as when the patch for TNT duping was introduced. If you don't want to use anything modern, you won't have an issue with dupes at all.",True,True
PaperMC_____Paper_____3561,2020-06-15T11:42:03Z,True,PaperMC_____Paper_____3561_____644077581,@Proximyst The issue isn't fixed so it will probably also be in RetardPaper,True,True
PaperMC_____Paper_____3561,2020-06-15T11:44:14Z,True,PaperMC_____Paper_____3561_____644078558,"@DoubleGe You sure seem to be the target group for the name...

Paper build 350 or whatever the patch for TNT dupes was introduced in has the issue. If you don't want the issue, you'll stick to builds w/o this patch. This entire thread is useless to you as you wouldn't even have the TNT dupe patch at all.",True,True
PaperMC_____Paper_____3561,2020-06-15T11:45:00Z,True,PaperMC_____Paper_____3561_____644078898,"@MrEDok 
Right, I see that Mojang doesn't want the TNT duping. But as it's stated in the reddit post they said that it won't be removed until there's an alternative for it, which there isn't for now. It's not that they are too stupid to fix it.",True,True
PaperMC_____Paper_____3561,2020-06-15T11:45:53Z,True,PaperMC_____Paper_____3561_____644079261,"@Proximyst But I need to update because of that issue and I still want TNT Dupers, but updating doesn't do anything because the issue I have hasn't been fixed my server can't run atm because of the issue.",True,True
PaperMC_____Paper_____3561,2020-06-15T11:48:05Z,True,PaperMC_____Paper_____3561_____644080236,"@DoubleGe Then wait till it's fixed? I've said *several times* that I *will* be updating RetardPaper as new updates come. It's the fix to this entire discussion: you get the switch, PaperMC team gets their will. Win-win, stick to builds before the dupe patch or use RP if you want them to stay even with the patch.",True,True
openzfs_____zfs_____10455,2020-06-15T11:55:13Z,True,openzfs_____zfs_____10455_____644083444,Indigo children are against use of color indigo to color memory.,True,True
PaperMC_____Paper_____3561,2020-06-15T12:51:11Z,True,PaperMC_____Paper_____3561_____644115333,"I think a config option would be great. It would please the technical community, but, in order to please everyone else, including the Paper team, I think that all exploit fixes should be moved into a new configuration section or just into a new single configuration option. However, in addition to this, if any of the fixes were disabled, a error would appear on the console saying that some or all fixes were disabled and that such configurations are not supported. To top it all off, I believe that pausing the thread during startup for 10 seconds or more would be great as it ""forces"" people to read the error (just like the outdated build warning paper had). I think this is enough to please everyone, however, if you don't think so, please let me know!",True,True
PaperMC_____Paper_____3561,2020-06-15T12:58:09Z,True,PaperMC_____Paper_____3561_____644118776,"The Paper description says:
> High performance Spigot fork that aims to fix gameplay and mechanics inconsistencies.

 This is absolutley a gameplay inconsistency. When you started using Paper, you knew this. Stop acting like this is new news, it's been said before they **regret** adding config options for other bugs and exploits.",True,True
PaperMC_____Paper_____3561,2020-06-15T13:49:18Z,True,PaperMC_____Paper_____3561_____644146714,"> This is absolutley a gameplay inconsistency

Is Quasi Connectivity a gameplay inconsistency? In the early days, probably yes, however, nowadays, it has become a fundamental part of gameplay for some player. There are things that would not be possible without Quasi Connectivity. Same thing for TNT dupers. They allow players to move the location where you activate the TNT. As it is recurring in this discussion, most players are not interested in being able to dupe TNT. Most would even be willing to ditch TNT dupers altogether, if a solution for that problem came along, such as moveable Block Entities, but 1.15 doesn't have that nor does 1.16. The lack of a configuration option for TNT duping limits the gameplay for a lot of players and Minecraft would lose a lot of its sandbox feel, where ""anything is possible"". You could even say TNT dupers are a gameplay expander.

> they regret adding config options for other bugs and exploits

That is indeed true, which is why I based my solution of clearly warning users that those settings are unsupported on this:
> Allowing config options for exploit fixes would require paper to support both configurations. This is a big hassle because no one at paper will be testing with the exploit enabled. There is a high chance the config option will break on some config and then a dev will have to try and fix it. This situation has already happened with the zero-tick exploit.
",True,True
PaperMC_____Paper_____3561,2020-06-15T13:57:23Z,True,PaperMC_____Paper_____3561_____644151227,"> I believe that pausing the thread during startup for 10 seconds or more would be great as it ""forces"" people to read the error

Most admins never bother to read console logs carefully, or even care that they run an unsupported configuration. They just run to Discord and when we tell them that ""we won't help because because X isn't supported"", they throw a hissy fit because their server relies on X. This happens every day from people using outdated Paper versions (people asking for support with 1.8.8 is super common, despite 1.8 being almost 6 years old). Adding a warning that says we won't support this configuration isn't going to help at all.

The fact we provide the option implicitly means that Paper will support reverting Paper with the dupe fix and with the dupe fix re-enabled. What if there's a bug in the dupe glitch path?",True,True
openzfs_____zfs_____10455,2020-06-15T13:59:10Z,True,openzfs_____zfs_____10455_____644152235,I identify as a blockhead and find this PR extremely offensive.,True,True
PaperMC_____Paper_____3561,2020-06-15T13:59:24Z,True,PaperMC_____Paper_____3561_____644152368,"> Allowing config options for exploit fixes would require paper to support both configurations. This is a big hassle because no one at paper will be testing with the exploit enabled. There is a high chance the config option will break on some config and then a dev will have to try and fix it. This situation has already happened with the zero-tick exploit.

(this response isn't to you kick)

This is close, but the actual case is that we WON'T try to fix it.


This is the problem with ""dupe fixes"" configs.
With other configs, we WANT to support it. We might not always have the time to investigate why a config is broken and will ask for help, but with dupe fixes, we straight up DON'T want it to work, and are happy when they break and then we can say ""oh well figure it out on your own""

And that's why it doesn't make sense to provide a config. ""You're using Paper but we still don't support you"" is just a silly environment to create.

Additionally, I didn't want to directly say it, but with the nature of what the bug fix was, there COULD be other worse forms of abuse of the mechanic that goes further than just TNT. Stuff that if someone knew how to abuse correctly, who knows what else it could duplicate.

We don't want generic bugs like this to exist in our software.

*We want our software to resolve issues that even Mojang doesn't want to solve (ever or yet)*.

If you disagree with what this project does, you are free to either not use it, or fork it and make it suit your needs.

Thankfully, you're in luck that someone has provided one already, but you're always welcome to fork it yourself and delete the file and compile it too.",True,True
openzfs_____zfs_____10455,2020-06-15T14:24:58Z,True,openzfs_____zfs_____10455_____644167299,"Who put this garbage into your head?  Should we also ban traffic lights because there are red and yellow lights (sorry, I can't even guess anything for green)?",True,True
PaperMC_____Paper_____3561,2020-06-15T14:40:23Z,True,PaperMC_____Paper_____3561_____644176582,"We have asked Proxi to rename their repo to be something not offensive to be a viable option for people looking for exploits to be re-enabled and they said they will later today.

",True,True
PaperMC_____Paper_____3561,2020-06-15T16:34:42Z,True,PaperMC_____Paper_____3561_____644241446,"After talking to slicedlime, I relented on the config option, see https://github.com/PaperMC/Paper/pull/3565
",True,True
openzfs_____zfs_____10455,2020-06-15T17:13:38Z,True,openzfs_____zfs_____10455_____644260709,"Neither ""whitelist"" nor ""blacklist"" are racist. Please check the history and use of terms before
jumping to conclusions.
",True,True
openzfs_____zfs_____10454,2020-06-15T17:32:33Z,True,openzfs_____zfs_____10454_____644269964,"I disagree that reverting to the previous language makes the code more readable and clear.  In fact, it does the opposite.  The patch adopts the ""dependency"" terminology used by `dmsetup(8)` in order to be as precise as possible when describing the functionality.",True,True
openzfs_____zfs_____10455,2020-06-15T19:49:46Z,True,openzfs_____zfs_____10455_____644342588,When this functionality was added more descriptive and clear names could have been used.  I see no reason not to address that now.  PR 10457 makes a very similar change to this with slightly different terms (blocked -> excluded).,True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T21:44:44Z,True,jellyfin_____jellyfin-web_____1423_____435482756,"**Changes**
Whitelist/blacklist replaced with allow list/block list

",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T21:46:07Z,True,jellyfin_____jellyfin-web_____1423_____645028526,"Kudos, SonarCloud Quality Gate passed!

[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug.png' alt='Bug' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=BUG) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=BUG)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability.png' alt='Vulnerability' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=VULNERABILITY) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=VULNERABILITY) (and [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot.png' alt='Security Hotspot' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=SECURITY_HOTSPOT) to review)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell.png' alt='Code Smell' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=CODE_SMELL) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=CODE_SMELL) [0 Code Smells](https://sonarcloud.io/project/issues?id=jellyfin_jellyfin-web&pullRequest=1423&resolved=false&types=CODE_SMELL)

[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/NoCoverageInfo.png' alt='No Coverage information' width='16' height='16' />](https://sonarcloud.io/component_measures?id=jellyfin_jellyfin-web&pullRequest=1423) No Coverage information  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/3.png' alt='0.0%' width='16' height='16' />](https://sonarcloud.io/component_measures?id=jellyfin_jellyfin-web&pullRequest=1423&metric=new_duplicated_lines_density&view=list) [0.0% Duplication](https://sonarcloud.io/component_measures?id=jellyfin_jellyfin-web&pullRequest=1423&metric=new_duplicated_lines_density&view=list)

",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:15:07Z,True,jellyfin_____jellyfin-web_____1423_____645039347,"Actually, can we replace the ""blacklist"" label in all the translations too? Otherwise those will become orphaned and force retranslation.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:15:07Z,True,jellyfin_____jellyfin-web_____1423_____645039348,We could leave this for 10.6.x or 10.7.0 so the server-side info can be changed as well?,True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:15:52Z,True,jellyfin_____jellyfin-web_____1423_____645039617,"> Actually, can we replace the ""blacklist"" label in all the translations too? Otherwise those will become orphaned and force retranslation. 

Do i just add the strings to the other language files and leave the translation blank?
",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:15:53Z,True,jellyfin_____jellyfin-web_____1423_____645039621,"I think for UI puposes, this + changes to the translations is good enough, then we could rename IsRemoteIPFilterBlacklist and such after 10.6.z for 10.7.0.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:19:07Z,True,jellyfin_____jellyfin-web_____1423_____645040737,">Do i just add the strings to the other language files and leave the translation blank?

From a quick check, just a `sed 's/Whitelist/Allowlist/g' 's/Blacklist/Blocklist/g'` on the `src/strings/*.json` files would be sufficient.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:29:16Z,True,jellyfin_____jellyfin-web_____1423_____645044265,"Not to start a political debate or anything, but I think this is a bit reactionary and is generally done more for posturing like ""look, we're inclusive"" than really being for a deeper societal change.

I'm not against it in principle, because racism sucks and should've gone to die in a fire like 500 years ago, but to me, it takes more than getting rid of terms we don't like to change things.

I do think that, if we do this, it should be under a few conditions:

1. Go down the chain. Don't only change the surface terms, that's ridiculous.
2. Enact a Code of Conduct to go with this.
3. Build and discuss a list of the potentially offensive terms with all users of Jellyfin, emphasizing the need for feedback from different cultures and walks of life.

Imo, either we do this properly or we don't do it at all.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:39:48Z,True,jellyfin_____jellyfin-web_____1423_____645047541,"I think that's a reasonable stance @MrTimscampi and I agree that we shouldn't just jump on this bandwaggon because there's a bunch of news stories about project switching their terms this week. If we're going to do this, let's do this right, and that will involve a lot of code tweaks and consultation with our myriad of users, contributors, and translators (note - most of these translations are literal translations of ""black list"" and ""white list"", so for this to actually be anything other than posturing, we'd need to change them all).",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T22:58:54Z,True,jellyfin_____jellyfin-web_____1423_____645053109,"Adding the relevant tags, to make sure it's not merged before being discussed further.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T23:04:08Z,True,jellyfin_____jellyfin-web_____1423_____645054611,"I mean, I vote no if it matters. [Blacklist](https://en.wikipedia.org/wiki/Blacklist_(computing)) and [whitelist](https://en.wikipedia.org/wiki/Whitelisting) have clearly defined meanings in computing. [The term blacklist don't even have racist origins, it was first used to describe a list of people the king had deemed threats to him *in a drama*](https://en.wikipedia.org/wiki/Blacklisting#Origins_of_the_term) (and whitelisting literally only exists in computing as the opposite of blacklisting so...).

To me this is needless pandering and will only serve to muddy the waters on terms used for decades over problems that don't exist for no benefit to the people it supposedly harms (but will anger those less understanding causing them harm over literally nothing).",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T23:08:31Z,True,jellyfin_____jellyfin-web_____1423_____645056009,"I agree, I did not wish to cause any debates or any controversy by this pr. With software like Chrome/Android/GitHub going in the direction of removing the above references, I thought it would be a good step for Jellyfin to follow in a similar direction.

> 1. Go down the chain. Don't only change the surface terms, that's ridiculous.

As for going down the chain. These are the only references to blacklist/whitelist in Jellyfin-web. I can continue and change the values in the Jellyfin server side if we decide to do this.

> 2\. Enact a Code of Conduct to go with this.

There is a [Contributor Covenant Code of Conduct](https://help.github.com/en/github/building-a-strong-community/adding-a-code-of-conduct-to-your-project) available as the default code of conduct that is produced by Github, this could be used as a starting point. 

> 3\. Build and discuss a list of the potentially offensive terms with all users of Jellyfin, emphasizing the need for feedback from different cultures and walks of life.

With regards to above, an issue could be created discussing potentially offensive terms and they could be changed/removed as necessary.

I will be more than happy to close this if it felt that the changes should not be made. ",True,True
jellyfin_____jellyfin-web_____1423,2020-06-16T23:33:38Z,True,jellyfin_____jellyfin-web_____1423_____645063236,"No worries @Influence365 I think it was inevitably going to be brought up given the very high profile discussions of this over the past week. I'm hesitant to open an issue because I'm certain it will have to be locked very quickly, which defeats the entire purpose of an issue about it, but it's definitely something to keep in mind.

Let's let this whole thing simmer for a bit, we can leave this PR open, and revisit this in a couple weeks once the dust settles. Given that I'm *just* about to announce the feature freeze for 10.6.0 it's not the best time to go through the whole codebase anyways.

For 1 we're referring to the actual variable that this sets, `IsRemoteIPFilterBlacklist`, which is a config option that gets saved and used in the backend, so this would touch the backend code as well.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-17T00:26:27Z,True,jellyfin_____jellyfin-web_____1423_____645077802,"For what its worth, I agree with @joshuaboniface @Influence365. With all this stupid term changing going on, *someone* was going to bring it up. Glad it was you rather than someone militantly PC :)

I'm sure we can figure something out given time, even if its just keeping it all as is.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-06-17T02:46:43Z,True,Skyrat-SS13_____Skyrat13_____2578_____435568690,"## About The Pull Request

ports the following PRs from TG:
https://github.com/tgstation/tgstation/pull/48959
https://github.com/tgstation/tgstation/pull/49634
https://github.com/tgstation/tgstation/pull/50558

The only change i did so far is limb separation and making cloning cost biomass, generated by throwing meat on the clone pod - everything else will work really the same. The TG wiki services just fine.
https://tgstation13.org/wiki/Guide_to_Wounds

**List of changes to do:**
[] Generally test and bugfix.
[] Making bleed suppression limb-based, like the bleeding is now.
[] Refactor all current clothing to have correctly set ""wound"" armor values.
[] Make the cloner also takes credits to clone.
[] Fix scars being shown through clothing.
[] Make scars more easily curable.
[] Making scars a set of character setup options

## Why It's Good For The Game

fuck dumb boo boo ointment fixes all medicine

## Changelog
:cl: Bob Joga, Ryll-Ryll, TG Station
refactor: Medicine has been pretty much entirely overhauled. See PR #2575 on github for more info.
/:cl:
",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-06-17T02:49:04Z,True,Skyrat-SS13_____Skyrat13_____2578_____645115181,"Oooh, don't be such a baby. Ribs grow back!




















_No they dont._",True,True
freeipa_____freeipa_____4809,2020-06-17T03:46:57Z,True,freeipa_____freeipa_____4809_____645129784,Should this be for git master only?,True,True
Icinga_____icinga2_____8046,2020-06-17T06:22:31Z,True,Icinga_____icinga2_____8046_____645176859,Again not transparent without description :(,True,True
Icinga_____icinga2_____8046,2020-06-17T08:20:29Z,True,Icinga_____icinga2_____8046_____645229273,Intentionally.,True,True
jellyfin_____jellyfin-web_____1423,2020-06-17T21:17:07Z,True,jellyfin_____jellyfin-web_____1423_____645629738,">Actually, can we replace the ""blacklist"" label in all the translations too? Otherwise those will become orphaned and force retranslation.

Please also consider that ""blacklist"" and ""whitelist"" are easy to translate into other languages where translations of these words don't include colours ""black"" and ""white"" and none non-English native speaker ever thinks about linking them with some racial context. Changing wording in invisible for users variable names is one thing, but changing visible translations is another thing. Maybe it's just my poor language skills, but I have no idea how to translate blocklist and allowlist into my native language without it looking bad and amateurish (making up words), online dictionaries aren't helping.",True,True
jellyfin_____jellyfin-web_____1423,2020-06-17T22:12:39Z,True,jellyfin_____jellyfin-web_____1423_____645653361,"@agilob Indeed, for fun I spot-checked this and at least 5 of the random languages I checked were literal translations of ""black list"" or ""white list"", as diverse as French, Finnish, and Turkish. Clearly this is not just a simple replacement and goes deeper to many other languages.

If the entire tech world wants to change this, that's fine, but I don't see much reason for us to be rushing to the forefront of it. I'd rather see how other well-internationalized projects handle it first and use their examples.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-06-18T01:33:34Z,True,Skyrat-SS13_____Skyrat13_____2578_____645715371,I think it's about ready for a testmerge.,True,True
raspberrypi_____linux_____3635,2020-06-19T22:01:05Z,True,raspberrypi_____linux_____3635_____646875209,"All the pages you reference that argue for multicore-aware scheduling are at least 10 years old. Absent a demonstration of a workload that gains a benefit from your proposed change, I remain unconvinced.
",True,True
raspberrypi_____linux_____3635,2020-06-19T22:08:16Z,True,raspberrypi_____linux_____3635_____646876972,"> All the pages you reference that argue for multicore-aware scheduling are at least 10 years old. Absent a demonstration of a workload that gains a benefit from your proposed change, I remain unconvinced.

...Newton's work is a few hundred years old, but they're still used in physics. If people claimed benefit then, it probably does now, especially since no one is reporting regressions in its use. 

I don't know how I am supposed to drum up recent documentation when I am a person, and not a company/organization with the tools/resources to completely document a Kernel feature I did not write/contribute/design/plan/implement.

I am more than happy to demonstrate a workload for you, but we are not in Goldy Locks and the Three Bears. Tell me which workloads you would like benchmarks to see if a benefit exists, and I will be happy to conduct and measure them for you, but I am not going to run random benchmarks for you to end up telling me ""This doesnt prove anything, xyz benchmark wouldnt benefit from it"". Tell what you would like, and I will do it.",True,True
raspberrypi_____linux_____3635,2020-06-19T22:17:24Z,True,raspberrypi_____linux_____3635_____646879122,"You're proposing a change to our default kernel config. If you propose such a change, you should give at least one reproducible example of where it is of benefit on the target platform - i.e. a Pi.",True,True
raspberrypi_____linux_____3635,2020-06-19T22:21:58Z,True,raspberrypi_____linux_____3635_____646880186,"I've not looked at the details of the changes caused by CONFIG_SCHED_MC=y, but I do note that it is included in arch/arm64/configs/defconfig. The commit responsible says:
```diff
commit aa644fa64c25ab2231a0fa9464892f5579d4e161
Author: Dietmar Eggemann <dietmar.eggemann@arm.com>
Date:   Mon Oct 19 17:55:49 2015 +0100

    ARM64: Enable multi-core scheduler support by default
    
    Make sure that the task scheduler domain hierarchy is set-up correctly
    on systems with single or multi-cluster topology.
    
    Signed-off-by: Dietmar Eggemann <dietmar.eggemann@arm.com>
    Acked-by: Punit Agrawal <punit.agrawal@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/configs/defconfig b/arch/arm64/configs/defconfig
index c8ccda16e079..5f760347aee2 100644
--- a/arch/arm64/configs/defconfig
+++ b/arch/arm64/configs/defconfig
@@ -51,6 +51,7 @@ CONFIG_PCI=y
 CONFIG_PCI_MSI=y
 CONFIG_PCI_XGENE=y
 CONFIG_SMP=y
+CONFIG_SCHED_MC=y
 CONFIG_PREEMPT=y
```
",True,True
raspberrypi_____linux_____3635,2020-06-20T03:52:56Z,True,raspberrypi_____linux_____3635_____646934614,"> You're proposing a change to our default kernel config. If you propose such a change, you should give at least one reproducible example of where it is of benefit on the target platform - i.e. a Pi.

...im just proposing this changed due to every other configuration for the armv7 kernels has this option enabled; as in its default. So you can stop trying to act like you're the Raspberry Pi Linux Kernel Linus Torvalds, when you clearly aren't.



> I've not looked at the details of the changes caused by CONFIG_SCHED_MC=y, but I do note that it is included in arch/arm64/configs/defconfig. The commit responsible says:
> 
> ```diff
> commit aa644fa64c25ab2231a0fa9464892f5579d4e161
> Author: Dietmar Eggemann <dietmar.eggemann@arm.com>
> Date:   Mon Oct 19 17:55:49 2015 +0100
> 
>     ARM64: Enable multi-core scheduler support by default
>     
>     Make sure that the task scheduler domain hierarchy is set-up correctly
>     on systems with single or multi-cluster topology.
>     
>     Signed-off-by: Dietmar Eggemann <dietmar.eggemann@arm.com>
>     Acked-by: Punit Agrawal <punit.agrawal@arm.com>
>     Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
> 
> diff --git a/arch/arm64/configs/defconfig b/arch/arm64/configs/defconfig
> index c8ccda16e079..5f760347aee2 100644
> --- a/arch/arm64/configs/defconfig
> +++ b/arch/arm64/configs/defconfig
> @@ -51,6 +51,7 @@ CONFIG_PCI=y
>  CONFIG_PCI_MSI=y
>  CONFIG_PCI_XGENE=y
>  CONFIG_SMP=y
> +CONFIG_SCHED_MC=y
>  CONFIG_PREEMPT=y
> ```

I noticed this as well, but I didn't bother mentioning it at the time of my initial post due to me assuming the defconfig is just some generic profile made by a platform maintainer for the kernel.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-06-20T11:33:07Z,True,Skyrat-SS13_____Skyrat13_____2578_____646983346,"Nice, more excuses to do surgery so I can make completely unnecessary modifications to people right after fixing the thing that they needed surgery for in the first place.",True,True
raspberrypi_____linux_____3635,2020-06-20T11:35:12Z,True,raspberrypi_____linux_____3635_____646983521,"> ...im just proposing this changed due to every other configuration for the armv7 kernels has this option enabled; as in its default. So you can stop trying to act like you're the Raspberry Pi Linux Kernel Linus Torvalds, when you clearly aren't.
> 

Hmm, when asking for changes, probably best not to offend one of the Raspberry Pi engineers who would actually be responsible for making the change.

He is one of our Torvald's btw.",True,True
raspberrypi_____linux_____3635,2020-06-20T14:55:40Z,True,raspberrypi_____linux_____3635_____647005911,"You know what, it’s not worth it.

I’m not dealing with programmers ego for a device targeted at kids.",True,True
raspberrypi_____linux_____3635,2020-06-20T18:41:28Z,True,raspberrypi_____linux_____3635_____647031767,"> I agree, the change was really not worth it.

Yeah, why on earth would you wanna make sure that the configuration match the armv7 kernel configuration.

Granted with all the warnings that are generated by the compiler for all the BCM drivers you probably think that's a good thing.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-06-22T21:44:55Z,True,Skyrat-SS13_____Skyrat13_____2578_____647785008,Gonna keep this drafted cause i'll have to test it a bit. Don't want a disastrous testmerge.,True,True
openssl_____openssl_____12089,2020-06-23T08:03:13Z,True,openssl_____openssl_____12089_____444037298,typo,True,True
openssl_____openssl_____12089,2020-06-23T08:04:00Z,True,openssl_____openssl_____12089_____444037739,confusion in the patch between primary/parent,True,True
freeipa_____freeipa_____4809,2020-06-23T08:17:17Z,True,freeipa_____freeipa_____4809_____647987094,"master:

* 523f70ae46127161556a0881fc9a01e138a90666 Terminology improvements: CA renewal
* 5c09dcdb981df7837ac1bb75547d23fc7d8946d0 Grammar: whitespace is a word
* 3ce816ba772ffae6b0bd05e4589727513fa76e3c Terminology improvements: use allow list
* 3ec1b77f6a03886936299a9d34ed8fd640c3984d Terminology improvements: use block list

",True,True
openssl_____openssl_____12089,2020-06-23T13:05:35Z,True,openssl_____openssl_____12089_____648132719,"The ""parent"" -> ""primary"" replacement is actually a mistake, as Mark already noted. It should be ""master"" -> ""primary"".",True,True
openssl_____openssl_____12089,2020-06-23T18:05:26Z,True,openssl_____openssl_____12089_____648327103,"> The ""parent"" -> ""primary"" replacement is actually a mistake, as Mark already noted. It should be ""master"" -> ""primary"".

I believe we're both pointing out the same thing, that there are places where it currently says ""parent"" that should say ""primary"" ",True,True
openssl_____openssl_____12089,2020-06-23T18:24:03Z,True,openssl_____openssl_____12089_____444421626,This probably slipped in by mistake,True,True
openssl_____openssl_____12089,2020-06-23T18:28:34Z,True,openssl_____openssl_____12089_____648338490,"A `RAND_DRBG` instance `drbg` has an optional `parent` from which it reseeds. Nowhere is it assumed that the reseeding chain is limited to two elements, that's why it is called `parent`, not `master` resp. `primary`. Changing `drbg->parent` to `drbg->primary` is a mistake.

https://github.com/openssl/openssl/blob/49a36a528a48bb6b8421b8a0363adb85e63d71fe/crypto/rand/rand_local.h#L222-L226
",True,True
openssl_____openssl_____12089,2020-06-23T18:32:07Z,True,openssl_____openssl_____12089_____648340219,"Ok, forget my last comment. Either I looked in the wrong place, or the error has been corrected by Rich in the meantime.",True,True
opencv_____opencv_____17185,2020-06-26T10:53:55Z,True,opencv_____opencv_____17185_____650117527,"> @l-bat @dkurt
Is Yolov4 more than 2 times slower than Yolov3 due to MISH-activation?

@AlexeyAB, please take a look at Mish optimization for CPU: https://github.com/opencv/opencv/pull/17624",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-06-26T14:43:20Z,True,Skyrat-SS13_____Skyrat13_____2578_____650216676,gib plox,True,True
python_____peps_____1470,2020-06-26T22:00:59Z,True,python_____peps_____1470_____440804282,"Instead of requiring that comments be written in Strunk & White Standard English, require instead that English-language comments be clear and easily understandable by other English speakers. This accomplishes the same goal without alienating or putting up barriers for people (especially people of color) whose native dialect of English is not Standard English. This change is a simple way to correct that while maintaining the original intent of the requirement. This change also makes the requirement more clear to people who are not familiar with Strunk & White, since for programmers, the main relevant aspect of that standard is ""be clear and concise;"" simply saying that instead of referencing Strunk & White communicates this more effectively. 
",True,True
python_____peps_____1470,2020-06-28T21:02:27Z,True,python_____peps_____1470_____650821292,"The diff of what was put here in the PR description vs what went in the commit message:

```diff
--- 1-description	2020-06-28 23:52:57.905652782 +0300
+++ 2-commit-message	2020-06-28 23:51:24.953277774 +0300
@@ -1,9 +1,8 @@
 Instead of requiring that comments be written in Strunk & White Standard English, require
 instead that English-language comments be clear and easily understandable by other English
-speakers. This accomplishes the same goal without alienating or putting up barriers for people (especially people of color)
+speakers. This accomplishes the same goal without upholding relics of white supremacy.
+Many native English speakers do not use Standard English as their native dialect, so
+requiring conformation to Standard English centers whiteness in an inappropriate and
+unnecessary way, and can alienate and put up barriers for people of color and those
 whose native dialect of English is not Standard English. This change is a simple way to correct
 that while maintaining the original intent of the requirement.
-This change also makes the requirement more clear to people who are not familiar with
-Strunk & White, since for programmers, the main relevant aspect of that standard is
-""be clear and concise;"" simply saying that instead of referencing Strunk & White
-communicates this more effectively.
```

Some feedback on the python-ideas mailing list to which the original report was posted:
* https://mail.python.org/archives/list/python-ideas@python.org/message/5M56KKP2S3POELVGTHGXGWANEVK72R3E/
* https://mail.python.org/archives/list/python-ideas@python.org/message/N7Z4HDYP7CV75GRCBLMZGSFEDZTFIVQF/
* https://mail.python.org/archives/list/python-ideas@python.org/message/J2LC553NWBTANBRIPI52CQW53JXCCUTH/ 
",True,True
micke_____valid_email2_____153,2020-06-29T08:58:29Z,True,micke_____valid_email2_____153_____441298453,"add hey.com
![7BCBF776-00DE-4A1B-A8D9-79D5D3D9B4B1](https://user-images.githubusercontent.com/67554573/85953667-6c251000-b972-11ea-88b1-e3a81f0a900b.png)
",True,True
PainsPerdus_____gboi-rocket_____102,2020-06-29T23:10:57Z,True,PainsPerdus_____gboi-rocket_____102_____441694388,,True,True
PainsPerdus_____gboi-rocket_____102,2020-06-29T23:15:53Z,True,PainsPerdus_____gboi-rocket_____102_____651416970,I agree with these changes!,True,True
PainsPerdus_____gboi-rocket_____102,2020-06-29T23:18:12Z,True,PainsPerdus_____gboi-rocket_____102_____651417635,You guys are too tired. go get some sleep ,True,True
PainsPerdus_____gboi-rocket_____102,2020-06-29T23:18:35Z,True,PainsPerdus_____gboi-rocket_____102_____651417752,"We know
But I have to finish this IA",True,True
micke_____valid_email2_____153,2020-06-29T23:29:52Z,True,micke_____valid_email2_____153_____651421275,I’m not so sure that adding hey.com is such a great idea as they also provide legitimate addresses. How are these random addresses formatted?,True,True
micke_____valid_email2_____153,2020-06-30T02:46:36Z,True,micke_____valid_email2_____153_____651489501,"@micke 
> ""All temp addresses follow a consistent format of 12 digits with dashes separating each group of 4 digits. So, temporary addresses are all of the formant ####-####-####@hey.com"" 

See this comment from Hey's Director of Operations (and why they declined OP's PR) https://github.com/ivolo/disposable-email-domains/pull/825#issuecomment-651223046",True,True
micke_____valid_email2_____153,2020-06-30T03:33:13Z,True,micke_____valid_email2_____153_____651506832,Also @dhh commented on a [similar PR](https://github.com/martenson/disposable-email-domains/pull/244#issuecomment-651499217),True,True
micke_____valid_email2_____153,2020-06-30T03:38:15Z,True,micke_____valid_email2_____153_____651508652,"@micke This list also includes cock.li as disposable, those accounts don’t expire and are far more likely to remain in use past 2 weeks than hey.com addresses.

Besides the randomized addresses, most hey.com users are signed up to the service on a 2 week trial basis. Presumably the purpose of the list is to filter out short-lived disposable addresses, adding hey.com certainly serves that purpose.


Try signing up for a non-random address at https://app.hey.com/sign_up/welcome , the signup flow is essentially the same as at cock.li (no email or phone verification) but the account will expire in 14 days.",True,True
micke_____valid_email2_____153,2020-06-30T04:18:07Z,True,micke_____valid_email2_____153_____651521661,"HEY is a new email service with over 150,000 users and thousands of paying accounts. There is a separate service mandated by Apple that uses a specific 12 digit email address in the form of ####-####-#### that can be used for 14 days. You could create a similar address for a similar purpose on Gmail or any other service. These addresses are heavily limited and scrutinized to prevent abuse. It represents a vanishingly small part of overall use of HEY. Please close this PR. You can find more information about HEY on https://hey.com. Thank you.

Also, check the account that opened this PR. It’s an anonymous account, created today, which has gone around to repos with block lists trying to get HEY marked. The campaign has been reported to GitHub for harassment.",True,True
micke_____valid_email2_____153,2020-06-30T04:30:09Z,True,micke_____valid_email2_____153_____651525175,"> Try signing up for a non-random address at https://app.hey.com/sign_up/welcome , the signup flow is essentially the same as at cock.li (no email or phone verification) but the account will expire in 14 days.

Let me correct you there. Disposable emails *can only* be signed up via the iOS app, and was implemented so that Apple allows the app. That web signup link is for *permanent, non-disposable* emails, and is no different than singing up for FastMail, Gmail or Yahoo. 
",True,True
micke_____valid_email2_____153,2020-06-30T04:32:41Z,True,micke_____valid_email2_____153_____651526061,">These addresses are heavily limited and scrutinized to prevent abuse. 

Could you describe how that works?



> > Try signing up for a non-random address at https://app.hey.com/sign_up/welcome , the signup flow is essentially the same as at cock.li (no email or phone verification) but the account will expire in 14 days.
> 
> Let me correct you there. Disposable emails _can only_ be signed up via the iOS app, and was implemented so that Apple allows the app. That web signup link is for _permanent, non-disposable_ emails, and is no different than singing up for FastMail, Gmail or Yahoo.

The addresses from that link stop working after 14 days, no? Fastmail, Gmail and Yahoo all require phone verification.",True,True
micke_____valid_email2_____153,2020-06-30T04:41:06Z,True,micke_____valid_email2_____153_____651529226,"> The addresses from that link stop working after 14 days, no? Fastmail, Gmail and Yahoo all require phone verification.

Only if you don't pay after the trial. Same as with any trial. 

Also I just created both a Gmail and a Yahoo account, didn't get asked for any kind of verification. 

",True,True
micke_____valid_email2_____153,2020-06-30T04:48:59Z,True,micke_____valid_email2_____153_____651532000,"Happy to pile on here, but I also managed to create a Gmail account just now without a phone number, using a fake name, birthday, and gender. Not sure how you can include hey.com as burner mail and exclude Gmail by that logic.",True,True
micke_____valid_email2_____153,2020-06-30T04:50:21Z,True,micke_____valid_email2_____153_____651532573,"> > The addresses from that link stop working after 14 days, no? Fastmail, Gmail and Yahoo all require phone verification.
> 
> Only if you don't pay after the trial. Same as with any trial.
> 
> Also I just created both a Gmail and a Yahoo account, didn't get asked for any kind of verification.

Trials aren't exactly common in the email space.

@fm and @esmcelroy try to do the same in an incognito tab, both yahoo and google have heaps of tracking cookie data allowing them to decide whether or not you're a real user.

Here's what happened when I tried to create gmail and yahoo accounts in an incognito tab just now:

![2020-06-30-054223_844x577_scrot](https://user-images.githubusercontent.com/67554573/86084354-94a52b00-ba94-11ea-986e-e76d547c89e7.png)
![2020-06-30-054844_606x929_scrot](https://user-images.githubusercontent.com/67554573/86084687-6247fd80-ba95-11ea-95f1-d3097d63a961.png)
",True,True
micke_____valid_email2_____153,2020-06-30T04:52:38Z,True,micke_____valid_email2_____153_____651533518,"I just used the Gmail app. That’s the workflow for the temp hey email, no?
I got a Gmail account up and running in seconds from the app, no phone verification required. Skipped the step quite easily.",True,True
micke_____valid_email2_____153,2020-06-30T04:55:37Z,True,micke_____valid_email2_____153_____651534600,"> I just used the Gmail app. That’s the workflow for the temp hey email, no?
> I got a Gmail account up and running in seconds from the app, no phone verification required. Skipped the step quite easily.

The Gmail app extracts heaps of data from your phone in order to decide whether or not to ask you for phone confirmation, this isn't exactly comparable.

>That’s the workflow for the temp hey email, no?

You can also sign up for a hey email on the website. Only the randomly generated addresses require you to use the app. The signup flow for both is exactly the same.",True,True
micke_____valid_email2_____153,2020-06-30T04:58:52Z,True,micke_____valid_email2_____153_____651535662,"How about Safari private browsing? Is that comparable enough? Easily skipped past the add a phone number/backup email step. I now have two burner Gmail accounts readily available with none of my real info required.

Edit: We haven’t even talked about Microsoft Account emails yet. Those things are so fast and disposable to set up.
And another addendum, isn’t abuse potential low for hey.com email addresses, since the only usage mechanism is the (web)app? There’s no SMTP/IMAP/POP3 configuration anywhere to be found....",True,True
micke_____valid_email2_____153,2020-06-30T05:02:47Z,True,micke_____valid_email2_____153_____651536973,"I can’t reproduce that, perhaps google just really likes your IP :) Given that they have great visibility into your outgoing traffic, it makes sense for them to be able to make these decisions without cookies.


![FDEF9C78-4B5B-43EB-B9EB-98009D901273](https://user-images.githubusercontent.com/67554573/86085480-8f99a900-ba9f-11ea-83ff-bc89ede95232.png)
",True,True
micke_____valid_email2_____153,2020-06-30T05:05:53Z,True,micke_____valid_email2_____153_____651538285,"Well, we know @dhh was having problems with the validation on the Apple App Store. Here we have 2 options. Since clearly is a disposable email address, probably the hey team and @dhh should change the domain for the disposable email addresses like @not-hey.com or something to differentiate the subscription accounts from the disponsable ones. Or we can forget about this until the issue with apple is solved. ",True,True
micke_____valid_email2_____153,2020-06-30T05:11:39Z,True,micke_____valid_email2_____153_____651540680,">Or we can forget about this until the issue with apple is solved.

This seems like a really easy problem for @dhh to fix, I'm not sure that it really makes sense to blame apple here. Odds are the ""issue with apple"" won't be solved anytime soon anyway, bigger players like netflix have been fighting about this for years.

It's not really too much to ask for hey to disable the creation of disposable addresses until they can put them on a separate domain. And unless Hey are going to add further verification requirements for the free trial, they should probably be treated the same way as cock.li and other similar providers.",True,True
micke_____valid_email2_____153,2020-06-30T05:23:28Z,True,micke_____valid_email2_____153_____651545537,"I get your point on the comparation with similar services, but since your account was created just for adding hey to email verification repos, is suspicious. I think we need to wait for a response from hey about this, to know what is the plan with the disponsable accounts.",True,True
micke_____valid_email2_____153,2020-06-30T05:29:43Z,True,micke_____valid_email2_____153_____651548118,"> I get your point on the comparation with similar services, but since your account was created just for adding hey to email verification repos, is suspicious. 

Given that @dhh [decided to start a witch-hunt](https://twitter.com/dhh/status/1277805249147752449) with his 500k twitter followers, I think I made the right call using a throwaway account for this.

In any case, I think the PR should be evaluated on its technical merits. As of right now it's quite clear that Hey is a disposable email provider.

>I think we need to wait for a response from hey about this, to know what is the plan with the disponsable accounts.

Hey did respond earlier in this thread, they don't seem to have a clear plan besides using this as a PR opportunity by ranting about ""harassment"" on twitter.",True,True
micke_____valid_email2_____153,2020-06-30T08:00:34Z,True,micke_____valid_email2_____153_____651623164,"As mentioned here:

https://github.com/ivolo/disposable-email-domains/pull/825#issuecomment-651586238

> In case anyone wasn't aware, @tuptuptuu is a throwaway account seemingly created solely for the purpose of adding the hey.com domain to disposable email lists. See similar pull requests this person has filed:

>    andreis/disposable#50
>   martenson/disposable-email-domains#244
    wesbos/burner-email-providers#226
    micke/valid_email2#153

Clearly, @tuptuptuu is a cancerous account. What's the best reason to report it to GitHub and get it taken down? Harassment? Spam?
",True,True
micke_____valid_email2_____153,2020-06-30T08:38:22Z,True,micke_____valid_email2_____153_____651646762,"@Phillipus
> Clearly, @tuptuptuu is a cancerous account. What's the best reason to report it to GitHub and get it taken down? Harassment? Spam?

Do you object to the PR or the use of throwaway accounts on github? If you've got nothing to say in regards to the PR I suggest you take this up with github support, although I think they'll be unhappy with your choice of words here.

FWIW if you read the thread you'll notice that the information you brought up was already addressed by dhh in an earlier comment.",True,True
micke_____valid_email2_____153,2020-06-30T08:54:06Z,True,micke_____valid_email2_____153_____651656457,"Hey.com's main product is not the disposable service. If we are looking for how it *could* be exploited as such, we should block all of Gmail, live.com, yahoo.com, hotmail.com and multiple others. I have researched the topic extensively before and it is suprisingly easy to create burner Gmail accounts, and even easier to create live.com accounts that are untraceable. From a fraud perspecitve (since this is @tuptuptuu's main point), Hey.com does not carry the same level of risk as the ones mentioned above. It is a fully legitimate email service and it's domain does not deserve to be blacklisted any more than gmail.com or live.com

@tuptuptuu seems to have personal grudges against @dhh and it is unnaccaptable to change a list like this without proper evidence. You cherry picked your Gmail signup screenshots. There are a million ways to not get phone number prompt, and there are services that offer clean phone numbers to pass that verification - for pennies. This is not heresay from the internet, I have used them extensively before with very high level of success. I ask everybody who is responsible for the merge of this PR to not accept this change. It is solely based on personal reasons and Hey.com does not pose a real threat at all from a fraud and technical perspective.

edit:
I have to add that I am not and likely never will be a Hey.com user. I have a problem with blacklisting legitimate great email domains such as it is happening now, and it has been happening with ProtonMail (where I am a long term customer) - this hits home to many people who are not *throw hands up* Gmail fanboys and see the everyday difficulties of non-monopoly email providers.",True,True
micke_____valid_email2_____153,2020-06-30T09:03:00Z,True,micke_____valid_email2_____153_____651662163,Just why is this PR not closed yet? It's clear that @tuptuptuu has something against @dhh and his new email service. Please close this. ,True,True
micke_____valid_email2_____153,2020-06-30T09:09:23Z,True,micke_____valid_email2_____153_____651665962,"@AlexJuca 
> Just why is this PR not closed yet? It's clear that @tuptuptuu has something against @dhh and his new email service. Please close this.

Why do you think that? I had nothing against @dhh until he decided to send his 500k twitter followers after me.

I think it's far clearer that hey.com does in fact offer a disposable email service.

@what-name 
>From a fraud perspecitve (since this is @tuptuptuu's main point)

It's not. My only point is that hey.com is a disposable email provider.

>it is unnaccaptable to change a list like this without proper evidence

There's proper evidence in the OP.  @dhh has confirmed that hey.com does in fact offer disposable emails.

Again, what makes you think that hey.com is much better than cock.li? At least cock.li addresses don't expire.",True,True
micke_____valid_email2_____153,2020-06-30T09:10:01Z,True,micke_____valid_email2_____153_____651666307,"Sorry for not closing this earlier, due to time zone differences and heavy work pressure i haven't hade the time to address it.

I always try to strive to not block legitimate email providers in this gem. I would rather it let some addresses through that are actually throw-aways than to block legitimate addresses as that could often be more harming to the users business.

If you still would like to block hey.com you can do this in your application specifically by using the local block list.",True,True
micke_____valid_email2_____153,2020-06-30T10:09:43Z,True,micke_____valid_email2_____153_____651698050,"> @AlexJuca
> 
> > Just why is this PR not closed yet? It's clear that @tuptuptuu has something against @dhh and his new email service. Please close this.
> 
> Why do you think that? **I had nothing against @dhh until he decided to send his 500k twitter followers after me.**
> 

I think that clearly summarises the situation.

@tuptuptuu Don't you think there's enough harm in the world already without you adding to it? Closing your cancerous sock puppet account would undo the harm.",True,True
micke_____valid_email2_____153,2020-06-30T10:14:55Z,True,micke_____valid_email2_____153_____651700845,"> > @AlexJuca
> > > Just why is this PR not closed yet? It's clear that @tuptuptuu has something against @dhh and his new email service. Please close this.
> > 
> > 
> > Why do you think that? **I had nothing against @dhh until he decided to send his 500k twitter followers after me.**
> 
> I think that clearly summarises the situation.
> 
> @tuptuptuu Don't you think there's enough harm in the world already without you adding to it? Closing your cancerous sock puppet account would undo the harm.

What harm am I adding?",True,True
micke_____valid_email2_____153,2020-06-30T17:52:07Z,True,micke_____valid_email2_____153_____651948327,@tuptuptuu You did this in bad faith and it must be sad to be you. Please close this account forever and come back to your normal life.,True,True
micke_____valid_email2_____153,2020-06-30T18:24:41Z,True,micke_____valid_email2_____153_____651964944,"> @tuptuptuu You did this in bad faith and it must be sad to be you. Please close this account forever and come back to your normal life.

I’m sorry you think that. There’s no bad faith here, hey.com offers disposable email addresses. It’s perfectly reasonable to list them as such.",True,True
python_____peps_____1470,2020-07-01T10:18:55Z,True,python_____peps_____1470_____652331856,"Black lives matter, so ""White"" should be wiped out.

Totally understandable :)",True,True
openssl_____openssl_____12089,2020-07-03T10:18:26Z,True,openssl_____openssl_____12089_____653471499,"Closing as per OMC vote. 
See https://www.mail-archive.com/openssl-project@openssl.org/msg01913.html
",True,True
python_____peps_____1470,2020-07-04T14:27:47Z,True,python_____peps_____1470_____653772640,"U no dats da greit idea finali I ken write commentz az i like thanks you!!!!!! 😍 ♥
Black lifes matters!!! 👍🏿✊🏿",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-08T15:15:55Z,True,Skyrat-SS13_____Skyrat13_____2578_____655583313,"Issues I've heard of/taken notice of.

- Cannot put hands/feet back on.
- Literally nobody knows how to do anything because there's no documentation/recommended reading.
- Nobody knows how to make biomass or -any- of the new chems. You literally need to code-dive to find them.
- The amount of injuries people get is often ridiculous. With all the stacked wounds, broken bones, missing limbs, and collapsed chest cavities, it incentivises cloning -even more- than before. 

People legit just, avoid playing medical on bobmed rounds. Medical is already severely understaffed, and people don't -want- to do pain/injury roleplay. This medical system keeps people away/out of the things they want to do for an extended period of time, and honestly, it's just making people get incredibly frustrated. Medics end up quitting because they don't know what to do, or -can't- do anything. People get frustrated because they get permanently taken out of the round because they can't be treated or cloned.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-08T20:50:44Z,True,Skyrat-SS13_____Skyrat13_____2578_____655749963,"> Issues I've heard of/taken notice of.
> 
> * Cannot put hands/feet back on.
> * Literally nobody knows how to do anything because ~there's no documentation/recommended reading.~ the documentation is all on the -discord- of all places, which people aren't going to know about/find.
> * Nobody knows how to make biomass or -any- of the new chems. ~You literally need to code-dive to find them.~
> * The amount of injuries people get is often ridiculous. With all the stacked wounds, broken bones, missing limbs, and collapsed chest cavities, it incentivises cloning -even more- than before.
> 
> People legit just, avoid playing medical on bobmed rounds. Medical is already severely understaffed, and people don't -want- to do pain/injury roleplay. This medical system keeps people away/out of the things they want to do for an extended period of time, and honestly, it's just making people get incredibly frustrated. Medics end up quitting because they don't know what to do, or -can't- do anything. People get frustrated because they get permanently taken out of the round because they can't be treated or cloned.
> 
> After making this post, and dredging through the arguments and complaints in all of the discord channels, I found out that a bunch of info is on #bulletin-board for whatever reason. Information like this really needs to be in the PR, and not in the middle of a discord chat nobody knows about..
> 
> Regarding cloning, and you comments on cloning.
> 
> ![image](https://user-images.githubusercontent.com/7543955/86941412-e8a5b480-c111-11ea-86c3-e5afa3936687.png)
> 
> Punishing the victim in these situations for security letting them die, and medical cloning them, does nothing to punish security -or- medical. Being taken out of the round for 10-20 minutes, then being cloned into a half-baked cripple resulting in even more of a round being wasted, doesn't sound fun at all. If you've -ever- tried to get a lawyer or command to do something about incompetency, you know full well that whining and bitching about it is just another waste of time on top of the 30 minutes you're already out.
> 
> Pain mechanics sound cool though because instead of beating someone to crit they'll actually feel pain and go down instead of just, going on like a robot.
> 
> TL:DR - I really wish this was just a straight port without adding all of this anti-cloner/additional limb nonsense so people could learn the basic systems first.

First off: You can put feet and hands in. I have consistently tested this, you just install robo limbs as normal but target the extremity instead. Cloning is not incentivized because it is costly, and wounds are honestly quite easily fixed most of the time even if it takes surgery. The information of this PR is on the #bulletin-board because it is actually the palce where people see changes the most, people barely access this github even to report serious bugs. About the last complaints: It is not punishing the victim, just like credits it is punishing doctors for being incompetent, they can avoid cloning most of the time and it should be a last ditch effort to revive people - it is fluffed to be painful and traumatic, mechanics should by all means convey that. If you are incompetent as a medical doctor, you suffer the consequences of it - cloning will take a hit to your salary and will piss people off since it is traumatic for their character and mechanically annoying. About this TLDR: I am sorry but this is nonsense, adding new limbs does not complicate the medical process at all, and it is a necessary step for any decent medical system.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T03:29:09Z,True,Skyrat-SS13_____Skyrat13_____2578_____655877005,"This has no place on this server. Medical is far too understaffed, and this server guised as a """"HRP"""" server isn't even built to handle the influx of shit that occurs when the antags start to do damage. It has generated nothing positive at all.

Your discord quote is disgusting.

**WHAT YOU WANT DOES NOT MEAN THE SERVER WANTS THIS SHIT** _BOTTOM LINE_

Fat reminder that 99% of the ""Hostage Situations"" I've seen are LRP bullshit of ""EITHER I GET MY WAY OR I'M KILLING XXX"" and then negotiations obviously go in a circle because the antag won't budge an inch and security has to act because they're spread so thin with all the other shit going on and other antags.

Also your quote "" wounds are honestly quite easily fixed most of the time even if it takes surgery. ""
Except it's almost like the stations only have two surgical beds, and sometimes very little staffing to deal with the influx of issues. God fucking help a blob round where people are trying to take it down and _oh look 20 people come in with broken everything haha HRP right?_

I will say it a thousand times. This is outright a huge antag buff because it allows people to wreck shit (which on a HRP server it really should only be conflict initiated by antagonists) in such a one sided way that it's absurd. Someone's already going to counter ""well you can do the same to the antag"" except you're talking about a server that willingly feeds bloodsuckers and continues to coddle antagonists in a way that literally gives them green text on a silver platter.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T03:41:35Z,True,Skyrat-SS13_____Skyrat13_____2578_____655880427,"This PR should be broken up into multiple parts so that people can properly understand and critique the changes. This is already a massive overhaul with just the TG ports, but then Bob has lumped a big pile of changes and an IPC wound system on top of it. 

Clean TG port first, let people play with and learn that, then PR the additional changes so people can judge them once they have context for what the changes will do to the existing system. ",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T03:43:24Z,True,Skyrat-SS13_____Skyrat13_____2578_____655880885,"> 
> 
> This PR should be broken up into multiple parts so that people can properly understand and critique the changes. This is already a massive overhaul with just the TG ports, but then Bob has lumped a big pile of changes and an IPC wound system on top of it.
> 
> Clean TG port first, let people play with and learn that, then PR the additional changes so people can judge them once they have context for what the changes will do to the existing system.

If this was modularized it would be much easier to acclimate to!!",True,True
kyb3r_____modmail_____2820,2020-07-09T07:14:03Z,True,kyb3r_____modmail_____2820_____446665943,Bump to latest dpy version.,True,True
kyb3r_____modmail_____2820,2020-07-09T07:14:06Z,True,kyb3r_____modmail_____2820_____655947289,"## use enum

https://github.com/kyb3r/modmail/blob/178ea9c0ac56a345cf1ddea48e3bcc1524f83136/core/config.py#L84-L87

---

###### This comment was generated by [todo](https://todo.jasonet.co) based on a `TODO` comment in 178ea9c0ac56a345cf1ddea48e3bcc1524f83136 in #2820. cc @kyb3r.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T07:18:46Z,True,Skyrat-SS13_____Skyrat13_____2578_____655949749,The MRP server isnt a good fit for this. There have been many many rounds showing why you either should have it tested on calm rounds. Or have it on the hrp server first so we dont have 20 dead who take longer than the round is to revive all of them.,True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T07:20:10Z,True,Skyrat-SS13_____Skyrat13_____2578_____655950456,"I personally don't like it. I see its potential but the way this is put in as one big Test Merge file isn't good for the game, bobmed needs to be stripped down piecemeal and modularized so that the parts the community likes can be put in, and the parts nobody likes can be tweaked or tossed out. Right now the injury system is over the top, just about everything beyond a basic bruise or burn becomes life threatening, breaking bones and having crap embedded in you causing life threatening bleed injuries over every little thing is too over the top, and when rounds hit high chaos medbay will get overwhelmed to a level it will be impossible to manage and cause more round removal. Frankly its too much realism in a video game, I'd rather take gamey mechanics that allow the game to flow smoothly over injecting an amount of realism that slows down the game, overwhelms medical staff, and is from what I've seen in the ooc chat on testmerged rounds a highly unpopular system. ",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T07:23:23Z,True,Skyrat-SS13_____Skyrat13_____2578_____655952045,"bobmed is god tier

medical just needs to up their skill TBH and we're usually filled on medical anyways

honestly just make any severe trauma like artery/broken bones/whatever to only proc when something does more than 30 brute damage on a single hit
and like at 50 accumulated brute to a limb gives any damage a chance to do that",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T07:44:30Z,True,Skyrat-SS13_____Skyrat13_____2578_____655963573,also we should have a wiki for all the changes or somthing. AS well as having other ways thats not just going to medbay to deal with shit. (Irl you can easily pop your bone in place.),True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T08:30:38Z,True,Skyrat-SS13_____Skyrat13_____2578_____655988512,also if a pre cloned person dies pelase set it to aleart medical if theres no biomass.,True,True
github_____opensource.guide_____1704,2020-07-09T15:21:01Z,True,github_____opensource.guide_____1704_____446930000,This fixes one currently broken link and will fix future cases if people rename their default branches.,True,True
kyb3r_____modmail_____2820,2020-07-09T18:33:53Z,True,kyb3r_____modmail_____2820_____656285384,What a giant chaos of commits. Please create self contained commits. Use `git rebase -i HEAD~n` where `n` is the number of commits you want to review. Then follow instructions in the interactive rebase.,True,True
kyb3r_____modmail_____2820,2020-07-09T18:36:31Z,True,kyb3r_____modmail_____2820_____656286530,"...while I'm at it, what does `Discord.py bump` have to do with ""Deprecated `MONGO_URI`"" and all the other changes in this pull request?",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:39:02Z,True,Skyrat-SS13_____Skyrat13_____2578_____656313699,"> This has no place on this server. Medical is far too understaffed, and this server guised as a """"HRP"""" server isn't even built to handle the influx of shit that occurs when the antags start to do damage. It has generated nothing positive at all.
> 
> Your discord quote is disgusting.
> 
> **WHAT YOU WANT DOES NOT MEAN THE SERVER WANTS THIS SHIT** _BOTTOM LINE_
> 
> Fat reminder that 99% of the ""Hostage Situations"" I've seen are LRP bullshit of ""EITHER I GET MY WAY OR I'M KILLING XXX"" and then negotiations obviously go in a circle because the antag won't budge an inch and security has to act because they're spread so thin with all the other shit going on and other antags.
> 
> Also your quote "" wounds are honestly quite easily fixed most of the time even if it takes surgery. ""
> Except it's almost like the stations only have two surgical beds, and sometimes very little staffing to deal with the influx of issues. God fucking help a blob round where people are trying to take it down and _oh look 20 people come in with broken everything haha HRP right?_
> 
> I will say it a thousand times. This is outright a huge antag buff because it allows people to wreck shit (which on a HRP server it really should only be conflict initiated by antagonists) in such a one sided way that it's absurd. Someone's already going to counter ""well you can do the same to the antag"" except you're talking about a server that willingly feeds bloodsuckers and continues to coddle antagonists in a way that literally gives them green text on a silver platter.

I will not reply to you because your criticism is stupid and deconstructive. Go fuck yourself.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:40:30Z,True,Skyrat-SS13_____Skyrat13_____2578_____656314365,"> This PR should be broken up into multiple parts so that people can properly understand and critique the changes. This is already a massive overhaul with just the TG ports, but then Bob has lumped a big pile of changes and an IPC wound system on top of it.
> 
> Clean TG port first, let people play with and learn that, then PR the additional changes so people can judge them once they have context for what the changes will do to the existing system.

This is the basis for a much larger project. None of these changes can exist separately because i need all of this to get the following work done, this is especially notable on the limb separation part. You simply want me to cut up this PR to get the other changes denied, which will not happen because they are integral for what i am trying to accomplish: a decent medical system.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:40:54Z,True,Skyrat-SS13_____Skyrat13_____2578_____656314571,"> also we should have a wiki for all the changes or somthing. AS well as having other ways thats not just going to medbay to deal with shit. (Irl you can easily pop your bone in place.)

I am dealing with these problems and setting up a guide.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:41:06Z,True,Skyrat-SS13_____Skyrat13_____2578_____656314655,"> also if a pre cloned person dies pelase set it to aleart medical if theres no biomass.

Sure.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:42:54Z,True,Skyrat-SS13_____Skyrat13_____2578_____656315411,"> I personally don't like it. I see its potential but the way this is put in as one big Test Merge file isn't good for the game, bobmed needs to be stripped down piecemeal and modularized so that the parts the community likes can be put in, and the parts nobody likes can be tweaked or tossed out. Right now the injury system is over the top, just about everything beyond a basic bruise or burn becomes life threatening, breaking bones and having crap embedded in you causing life threatening bleed injuries over every little thing is too over the top, and when rounds hit high chaos medbay will get overwhelmed to a level it will be impossible to manage and cause more round removal. Frankly its too much realism in a video game, I'd rather take gamey mechanics that allow the game to flow smoothly over injecting an amount of realism that slows down the game, overwhelms medical staff, and is from what I've seen in the ooc chat on testmerged rounds a highly unpopular system.

I will say it again because these two comments state the same:
This is the basis for a much larger project. None of these changes can exist separately because i need all of this to get the following work done, this is especially notable on the limb separation part. You simply want me to cut up this PR to get the other changes denied, which will not happen because they are integral for what i am trying to accomplish: a decent medical system.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:51:16Z,True,Skyrat-SS13_____Skyrat13_____2578_____656319069,"What you're saying is that you want all of your changes put in at once because you think all of them are great ideas. We're saying that if that's actually true, breaking them up into multiple PRs shouldn't be seen as a threat to you. 

This is a _really, really big_ pile of changes and it's going to take weeks or months for all of them to shake out, be tested and understood by the community. You should start with a tgmed port as a baseline (as that is already documented and has been thoroughly tested for us by tg) and then add in whatever additional features you like one-by-one until we get a system that the community understands and has been vetted for use here. ",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T19:52:43Z,True,Skyrat-SS13_____Skyrat13_____2578_____656319611,"> What you're saying is that you want all of your changes put in at once because you think all of them are great ideas. We're saying that if that's actually true, breaking them up into multiple PRs shouldn't be seen as a threat to you.
> 
> This is a _really, really big_ pile of changes and it's going to take weeks or months for all of them to shake out, be tested and understood by the community. You should start with a tgmed port as a baseline (as that is already documented and has been thoroughly tested for us by tg) and then add in whatever additional features you like one-by-one until we get a system that the community understands and has been vetted for use here.

I can ask maintainers which ideas are bad and take them out. So far they have veto'd none of it. I will not split this up because it is a ton of effort on my part, effort which is absolutely unnecessary.",True,True
kyb3r_____modmail_____2820,2020-07-09T20:04:25Z,True,kyb3r_____modmail_____2820_____656324469,"Hey there @RheaAyase ,
We truly apprectiate you'r cooperation, But it seems like you only are complaining and complaning. Please Keep in mind we try to do what we can, in a messy way or not the result will be fine as it always has been.
Cheers lorenzo, ",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-09T21:34:29Z,True,Skyrat-SS13_____Skyrat13_____2578_____656362483,"Let's take a breather for now. While there have been productive conversations both on the Discord and this PR comment section, I sense a shitstorm brewing.

This will be re-opened some time before Bababooey Medicine is test-merged again. Relay all your concerns to Bob Joga or the maintainers and please do so civilly. We encourage our developers to block those who act rudely, while we, in turn, highly encourage our developers to politely listen to those that act politely and bring up complaints in a civil manner. 

Also, we are recruiting more moderators who are in charge of solely moderating OOC behavior and conversations. Discord Moderators will now have the authority to moderate these discussions in Github as well. 
",True,True
kyb3r_____modmail_____2820,2020-07-09T22:31:12Z,True,kyb3r_____modmail_____2820_____656382226,"I'm not complaining. I'm pointing out these issues so that you can learn from these mistakes. Not everyone is born all cute and nice. Yes I do appreciate your work, but do I have to pre-face every single online message? I prefer getting to the point without wasting anyones time.

So today we learned how to use `rebase -i` with which, if you take a look at it, you can not only squash ""typo fixes"" into their correct commit but also get rid of commits that happen to be in your branch from which you're creating a pull request. (You'd first create a new branch inside of which you'd drop the extra commits. Or just cherry-pick them into clean origin/master branch, whichever means less work.)",True,True
kyb3r_____modmail_____2820,2020-07-09T22:42:22Z,True,kyb3r_____modmail_____2820_____656385889,"These things that I'm describing matter a lot in the open source. 

This is what a complaint looks like: I now have to either deal with all this chaos in order to merge it with my fork, or I'll live with the divergence. In my case it's the latter, with a single cherry-picked commit out of this pull request. The rest is not worth the hassle.",True,True
kyb3r_____modmail_____2820,2020-07-09T23:01:18Z,True,kyb3r_____modmail_____2820_____656391527,"Hey,

I fully agree with the fact that these things matter, specially with a open-source project. Although You also will have to understand also we live in a big chaos to keep all you guys happy > to keep the quality of the end product as high as possible, we dont focus fully on how a simple ""commit"" looks like. And if you think different, Please and be my guest and create your own open-source bot, and then show me how it should be.

Cheers, lorenzo",True,True
github_____opensource.guide_____1704,2020-07-10T09:39:43Z,True,github_____opensource.guide_____1704_____656586013,"Leave me all alone,,, I never going to be INTERESTED in your fucking
BITCOINSHIT, bye

Biccler Sammy

Op vr 10 jul. 2020 10:19 schreef Jojo jackson <notifications@github.com>:

> *@JACKMESON* commented on this pull request.
>
> Have a great life
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/github/opensource.guide/pull/1704#pullrequestreview-446211114>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ANMSNUPYHZ4V3WXOQTB4WYDR23FJ5ANCNFSM4OVWW2SA>
> .
>
",True,True
expressjs_____session_____708,2020-07-10T13:57:24Z,True,expressjs_____session_____708_____452860411,"```suggestion
        debug('destroying session')
```

For StandardJS style",True,True
expressjs_____session_____708,2020-07-10T13:58:18Z,True,expressjs_____session_____708_____452860953,"```suggestion
          debug('session destroyed')
```

for StandardJS style",True,True
expressjs_____session_____708,2020-07-10T13:59:30Z,True,expressjs_____session_____708_____452861670,"```suggestion
      debug('generating session')
```

For both StandardJS style and to match the participle from the other similar debug messages",True,True
expressjs_____session_____708,2020-07-10T13:59:45Z,True,expressjs_____session_____708_____452861812,"```suggestion
      function save (callback) {
```

For StandardJS format",True,True
expressjs_____session_____708,2020-07-10T13:59:59Z,True,expressjs_____session_____708_____452861946,"```suggestion
        _save.call(this, function (error) {
```

For StandardJS format",True,True
expressjs_____session_____708,2020-07-10T14:01:43Z,True,expressjs_____session_____708_____452862926,"```suggestion
          if (error) {
            return callback(error)
          }

          debug('session saved')
          callback.apply(this, arguments)
```",True,True
expressjs_____session_____708,2020-07-10T14:38:11Z,True,expressjs_____session_____708_____656710202," - I have addressed the review comments
 - I have added the word session in the debug statements in touch code
 - request to have a look
 - request to remove the low priority tag",True,True
expressjs_____session_____708,2020-07-10T14:43:50Z,True,expressjs_____session_____708_____656713022,"> request to remove the low priority tag

For what reason? Do you think this is not a low priority against the other aspects the team is attempting to move forward like Express 5.0? I'm trying to apply tags around priorities to help people focus the appropriate attention to get larger efforts like 5.0 moving forward. IMO adding some extra debug wording seems low priority to me, compared to things like new features, bug fixes, etc.

The tag itself doesn't mean that it gets no attention, just that it is comparatively low priority. I'm happy to remove it, but just unsure on the reasoning for removing it, as you didn't provide any.",True,True
expressjs_____session_____708,2020-07-10T14:45:36Z,True,expressjs_____session_____708_____452889547,"Any reason this ones contains `""the""` while the others (like `destroying session`, `generating session`, etc.) does not? Should all the others contain ""the"" or should this one remove the ""the""?",True,True
expressjs_____session_____708,2020-07-10T14:50:11Z,True,expressjs_____session_____708_____452892287,"fixed it, removed `the`",True,True
expressjs_____session_____708,2020-07-10T14:50:18Z,True,expressjs_____session_____708_____452892363,"```suggestion
            return callback(err)
```

Sorry, doing it through the GH UI is hard to count spaces 😆 ",True,True
expressjs_____session_____708,2020-07-10T14:52:34Z,True,expressjs_____session_____708_____452893800,"thanks, fixed it.",True,True
expressjs_____session_____708,2020-07-10T15:07:39Z,True,expressjs_____session_____708_____656724784,"I am not arguing with you; but I cannot find a reason why this  is a low priority: the reasoning for this change is provided in the first comment - to improve self diagnosis of a class of issues that report malfunction of session life-cycle events, more specifically users suspecting missing session persistence. Plus, there are 27 other PRs in this repo, and none of those are low pririty items!

But I am defenitely not arguing with you nor questing your judgement. Also, if this is to compete with express 5.0 for project's attention and focus, I will prefer the later, as that has more user demand than the former.",True,True
expressjs_____session_____708,2020-07-10T15:12:53Z,True,expressjs_____session_____708_____656727425,"I already provided the reason why it is low priority above :) The tag has nothing to do with the timeline for landing the change; it is simply to provide a category of the change itself. The argument that the others are not tagged right is not an argument this is not a low priority change; getting things tagged correctly is actually your primary function as a triager :) So if other PRs are not tagged correctly, it sounds like that is an issue that needs t be addressed with at least the triagers; I was simply tagging this PR since I happened to just interact with it. If it is more important for me to go through all the issues and PRs in this repository and get them all tagged appropriately vs working on other items, I can certainly do that, but the idea was that we're bringing on the large group of triagers to perform these kinds of tasks such that folks like myself can actually focus on the larger-at-hand items.",True,True
expressjs_____session_____708,2020-07-10T15:31:51Z,True,expressjs_____session_____708_____656737180,"> I already provided the reason why it is low priority above :)

I have given response to that - it is not some random debug statements; it is derived from an insight from this repo's issue backlog.

> The argument that the others are not tagged right is not an argument this is not a low priority change; getting things tagged correctly is actually your primary function as a triager :)

There are PRs which are 6 years old with no activities for as long; and acting on those in a meaningful and timely manner is actually your primary function as a maintainer :)

But then let us agree that we are not here to remind each other on their responsibilities.

> So if other PRs are not tagged correctly, it sounds like that is an issue that needs t be addressed with at least the triagers; I was simply tagging this PR since I happened to just interact with it.

It looks incorrect approach to me. If you just happened to interact with a work item cannot be used to derive a priority decision? Priorities are always relative; without looking at other PRs, a 'low priority' item cannot stand in itself. Low against what?
",True,True
expressjs_____session_____708,2020-07-10T15:43:55Z,True,expressjs_____session_____708_____656743298,"> I have given response to that - it is not some random debug statements; it is derived from an insight from this repo's issue backlog.

I get it, but we're also not even actively telling folks to use what is there when triaging issues (see recent issues like #763 )

I think that this conversation is getting a bit out of hand and off topic, and frankly into a bit of the offensive realm. If you could, I would suggest if you could please step away for a bit. I'm going to lock this PR for now.",True,True
expressjs_____session_____708,2020-07-10T15:49:51Z,True,expressjs_____session_____708_____656746503,"@gireeshpunathil I think at this point going forward, I just can no longer act on any issues and PR you raise. You will need to get something else involved to move forward with your issues and PRs, as I do not feel comfortable in interactions between us.",True,True
kyb3r_____modmail_____2820,2020-07-11T10:34:34Z,True,kyb3r_____modmail_____2820_____657038203,"> Please and be my guest and create your own open-source bot

I have, several in fact. And they all actually work and I can [just let em](https://status.valkyrja.app) do their thing for months at a time and it doesn't die on me on every occasion.

Yours is unreliable, and with development that I've observed not only in this pull request, yes I'll be rather writing my own as it will be less time, effort and headaches, than fixing all this mess. You will see mine pop up at https://github.com/RheaAyase/Valkyrja.modmail by the end of the day.",True,True
kyb3r_____modmail_____2820,2020-07-11T10:38:02Z,True,kyb3r_____modmail_____2820_____657038915,"I'll be waiting👍,  And if you only have issues and issues. Feel free to continue to use any other `project`, and have your complaints somewhere else.
Cheers, lorenzo",True,True
kyb3r_____modmail_____2820,2020-07-11T10:47:49Z,True,kyb3r_____modmail_____2820_____657041017,"Again, you see complaints, while the fact is that I tried to help you. This pull request is a nightmare and anyone can clearly see that.",True,True
jellyfin_____jellyfin-web_____1423,2020-07-11T16:01:40Z,True,jellyfin_____jellyfin-web_____1423_____657086210,"Well, I think after 25 days this issue *has* simmered down, and... just about as expected, it was basically forgotten and no one is talking about it any more. I'm sure there's still thousands of software projects using this terminology. So as previously mentioned, let's close this PR for now since it's inadequate, and if someone wants to do the work by all means, but I think keeping these terms is fine. Exporting American sociopolitical arguments to our global community is not something worth encouraging.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-12T19:09:15Z,True,Skyrat-SS13_____Skyrat13_____2578_____657262650,"I will reopen this PR and continue my work, but if the issues i've faced during all of these persist, i am not afraid to kill this project for real.",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-15T23:30:41Z,True,Skyrat-SS13_____Skyrat13_____2578_____659067544,I am not solving these merge conflicts because Citadel is too fucking slow. No.,True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-15T23:51:43Z,True,Skyrat-SS13_____Skyrat13_____2578_____659073610,Closed until i can find a way to fix the bullshit cit did.,True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-16T00:10:20Z,True,Skyrat-SS13_____Skyrat13_____2578_____659079256,"![image](https://user-images.githubusercontent.com/25989101/87611912-93543f00-c6df-11ea-8a23-7de39914745a.png)

PR's closed",True,True
Skyrat-SS13_____Skyrat13_____2578,2020-07-17T00:11:35Z,True,Skyrat-SS13_____Skyrat13_____2578_____659747077,"![flowey-export3](https://user-images.githubusercontent.com/25989101/87734407-ec3bda00-c7a8-11ea-9d6d-5ea9dafa72d6.png)
",True,True
